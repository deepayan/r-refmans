<!DOCTYPE html><html lang="en"><head><title>Help for package mets</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mets}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mets-package'><p>mets: Analysis of Multivariate Event Times</p></a></li>
<li><a href='#aalenfrailty'><p>Aalen frailty model</p></a></li>
<li><a href='#aalenMets'><p>Fast additive hazards model with robust standard errors</p></a></li>
<li><a href='#ACTG175'><p>ACTG175, block randmized study from speff2trial package</p></a></li>
<li><a href='#back2timereg'><p>Convert to timereg object</p></a></li>
<li><a href='#base1cumhaz'><p>rate of CRBSI for HPN patients of Copenhagen</p></a></li>
<li><a href='#base44cumhaz'><p>rate of Occlusion/Thrombosis complication for catheter of HPN patients of Copenhagen</p></a></li>
<li><a href='#base4cumhaz'><p>rate of Mechanical (hole/defect) complication for catheter of HPN patients of Copenhagen</p></a></li>
<li><a href='#basehazplot.phreg'><p>Plotting the baslines of stratified Cox</p></a></li>
<li><a href='#bicomprisk'><p>Estimation of concordance in bivariate competing risks data</p></a></li>
<li><a href='#BinAugmentCifstrata'><p>Augmentation for Binomial regression based on stratified NPMLE Cif (Aalen-Johansen)</p></a></li>
<li><a href='#binomial.twostage'><p>Fits Clayton-Oakes or bivariate Plackett (OR) models for binary data</p>
using marginals that are on logistic form.
If clusters contain more than two times, the algoritm uses a compososite likelihood
based on all pairwise bivariate models.</a></li>
<li><a href='#binreg'><p>Binomial Regression for censored competing risks data</p></a></li>
<li><a href='#binregATE'><p>Average Treatment effect for censored competing risks data using Binomial Regression</p></a></li>
<li><a href='#binregCasewise'><p>Estimates the casewise concordance based on Concordance and marginal estimate using binreg</p></a></li>
<li><a href='#binregG'><p>G-estimator for binomial regression model (Standardized estimates)</p></a></li>
<li><a href='#binregTSR'><p>2 Stage Randomization for Survival Data or competing Risks Data</p></a></li>
<li><a href='#biprobit'><p>Bivariate Probit model</p></a></li>
<li><a href='#blocksample'><p>Block sampling</p></a></li>
<li><a href='#bmt'><p>The Bone Marrow Transplant Data</p></a></li>
<li><a href='#Bootphreg'><p>Wild bootstrap for Cox PH regression</p></a></li>
<li><a href='#bptwin'><p>Liability model for twin data</p></a></li>
<li><a href='#calgb8923'><p>CALGB 8923, twostage randomization SMART design</p></a></li>
<li><a href='#casewise'><p>Estimates the casewise concordance based on Concordance and marginal estimate using prodlim but no testing</p></a></li>
<li><a href='#casewise.test'><p>Estimates the casewise concordance based on Concordance and marginal estimate using timereg and performs test for independence</p></a></li>
<li><a href='#cif'><p>Cumulative incidence with robust standard errors</p></a></li>
<li><a href='#cifreg'><p>CIF regression</p></a></li>
<li><a href='#ClaytonOakes'><p>Clayton-Oakes model with piece-wise constant hazards</p></a></li>
<li><a href='#cluster.index'><p>Finds subjects related to same cluster</p></a></li>
<li><a href='#concordanceCor'><p>Concordance Computes concordance and casewise concordance</p></a></li>
<li><a href='#cor.cif'><p>Cross-odds-ratio, OR or RR risk regression for competing risks</p></a></li>
<li><a href='#count.history'><p>Counts the number of previous events of two types for recurrent events processes</p></a></li>
<li><a href='#covarianceRecurrent'><p>Estimation of covariance for bivariate recurrent events with terminal event</p></a></li>
<li><a href='#daggregate'><p>aggregating for for data frames</p></a></li>
<li><a href='#Dbvn'><p>Derivatives of the bivariate normal cumulative distribution function</p></a></li>
<li><a href='#dby'><p>Calculate summary statistics grouped by</p></a></li>
<li><a href='#dcor'><p>summary, tables, and correlations for data frames</p></a></li>
<li><a href='#dcut'><p>Cutting, sorting, rm (removing), rename for data frames</p></a></li>
<li><a href='#dermalridges'><p>Dermal ridges data (families)</p></a></li>
<li><a href='#dermalridgesMZ'><p>Dermal ridges data (monozygotic twins)</p></a></li>
<li><a href='#diabetes'><p>The Diabetic Retinopathy Data</p></a></li>
<li><a href='#divide.conquer'><p>Split a data set and run function</p></a></li>
<li><a href='#divide.conquer.timereg'><p>Split a data set and run function from timereg and aggregate</p></a></li>
<li><a href='#dlag'><p>Lag operator</p></a></li>
<li><a href='#doubleFGR'><p>Double CIF Fine-Gray model with two causes</p></a></li>
<li><a href='#dprint'><p>list, head, print, tail</p></a></li>
<li><a href='#drcumhaz'><p>Rate for leaving HPN program for patients of Copenhagen</p></a></li>
<li><a href='#dreg'><p>Regression for data frames with dutility call</p></a></li>
<li><a href='#drelevel'><p>relev levels for data frames</p></a></li>
<li><a href='#dsort'><p>Sort data frame</p></a></li>
<li><a href='#dspline'><p>Simple linear spline</p></a></li>
<li><a href='#dtable'><p>tables for data frames</p></a></li>
<li><a href='#dtransform'><p>Transform that allows condition</p></a></li>
<li><a href='#easy.binomial.twostage'><p>Fits two-stage binomial for describing depdendence in binomial data</p>
using marginals that are on logistic form using the binomial.twostage funcion, but
call is different and easier and the data manipulation is build into the function.
Useful in particular for family design data.</a></li>
<li><a href='#Effbinreg'><p>Efficient IPCW for binary data</p></a></li>
<li><a href='#EVaddGam'><p>Relative risk for additive gamma model</p></a></li>
<li><a href='#evalTerminal'><p>Evaluates piece constant covariates at min(D,t) where D is a terminal event</p></a></li>
<li><a href='#Event'><p>Event history object</p></a></li>
<li><a href='#event.split'><p>event.split (SurvSplit).</p></a></li>
<li><a href='#eventpois'><p>Extract survival estimates from lifetable analysis</p></a></li>
<li><a href='#EventSplit'><p>Event split with two time-scales, time and gaptime</p></a></li>
<li><a href='#familycluster.index'><p>Finds all pairs within a cluster (family)</p></a></li>
<li><a href='#familyclusterWithProbands.index'><p>Finds all pairs within a cluster (famly)  with the proband (case/control)</p></a></li>
<li><a href='#fast.approx'><p>Fast approximation</p></a></li>
<li><a href='#fast.pattern'><p>Fast pattern</p></a></li>
<li><a href='#fast.reshape'><p>Fast reshape</p></a></li>
<li><a href='#FG_AugmentCifstrata'><p>Augmentation for Fine-Gray model based on stratified NPMLE Cif (Aalen-Johansen)</p></a></li>
<li><a href='#ghaplos'><p>ghaplos  haplo-types for subjects of haploX data</p></a></li>
<li><a href='#glm_IPTW'><p>IPTW GLM, Inverse Probaibilty of Treatment Weighted GLM</p></a></li>
<li><a href='#gof.phreg'><p>GOF for Cox PH regression</p></a></li>
<li><a href='#gofG.phreg'><p>Stratified baseline graphical GOF test for Cox covariates in PH regression</p></a></li>
<li><a href='#gofM.phreg'><p>GOF for Cox covariates in  PH regression</p></a></li>
<li><a href='#gofZ.phreg'><p>GOF for Cox covariates in  PH regression</p></a></li>
<li><a href='#Grandom.cif'><p>Additive Random effects model for competing risks data for polygenetic modelling</p></a></li>
<li><a href='#hapfreqs'><p>hapfreqs data set</p></a></li>
<li><a href='#haplo.surv.discrete'><p>Discrete time to event haplo type analysis</p></a></li>
<li><a href='#haploX'><p>haploX  covariates and response for haplo survival discrete survival</p></a></li>
<li><a href='#hfaction_cpx12'><p>hfaction, subset of block randmized study HF-ACtion from WA package</p></a></li>
<li><a href='#interval.logitsurv.discrete'><p>Discrete time to event interval censored data</p></a></li>
<li><a href='#ipw'><p>Inverse Probability of Censoring Weights</p></a></li>
<li><a href='#ipw2'><p>Inverse Probability of Censoring Weights</p></a></li>
<li><a href='#km'><p>Kaplan-Meier with robust standard errors</p></a></li>
<li><a href='#lifecourse'><p>Life-course plot</p></a></li>
<li><a href='#lifetable.matrix'><p>Life table</p></a></li>
<li><a href='#LinSpline'><p>Simple linear spline</p></a></li>
<li><a href='#logitSurv'><p>Proportional odds survival model</p></a></li>
<li><a href='#mediatorSurv'><p>Mediation analysis in survival context</p></a></li>
<li><a href='#medweight'><p>Computes mediation weights</p></a></li>
<li><a href='#melanoma'><p>The Melanoma Survival Data</p></a></li>
<li><a href='#mena'><p>Menarche data set</p></a></li>
<li><a href='#mets.options'><p>Set global options for <code>mets</code></p></a></li>
<li><a href='#migr'><p>Migraine data</p></a></li>
<li><a href='#mlogit'><p>Multinomial regression based on phreg regression</p></a></li>
<li><a href='#multcif'><p>Multivariate Cumulative Incidence Function example data set</p></a></li>
<li><a href='#np'><p>np data set</p></a></li>
<li><a href='#npc'><p>For internal use</p></a></li>
<li><a href='#phreg'><p>Fast Cox PH regression</p></a></li>
<li><a href='#phreg_IPTW'><p>IPTW Cox, Inverse Probaibilty of Treatment Weighted Cox regression</p></a></li>
<li><a href='#phreg_rct'><p>Lu-Tsiatis More Efficient Log-Rank for Randomized studies with baseline covariates</p></a></li>
<li><a href='#phregR'><p>Fast Cox PH regression and calculations done in R to make play and adjustments easy</p></a></li>
<li><a href='#plack.cif'><p>plack Computes concordance for or.cif based model, that is Plackett random effects model</p></a></li>
<li><a href='#pmvn'><p>Multivariate normal distribution function</p></a></li>
<li><a href='#predict.phreg'><p>Predictions from proportional hazards model</p></a></li>
<li><a href='#predictRisk.phreg'><p>Risk predictions to work with riskRegression package</p></a></li>
<li><a href='#print.casewise'><p>prints Concordance test</p></a></li>
<li><a href='#prob.exceed.recurrent'><p>Estimation of probability of more that k events for recurrent events process</p></a></li>
<li><a href='#prt'><p>Prostate data set</p></a></li>
<li><a href='#random.cif'><p>Random effects model for competing risks data</p></a></li>
<li><a href='#rchaz'><p>Simulation of Piecewise constant hazard model (Cox).</p></a></li>
<li><a href='#rchazC'><p>Piecewise constant hazard distribution</p></a></li>
<li><a href='#rcrisk'><p>Simulation of Piecewise constant hazard models with two causes (Cox).</p></a></li>
<li><a href='#recreg'><p>Recurrent events regression with terminal event</p></a></li>
<li><a href='#recurrentMarginal'><p>Fast recurrent marginal mean when death is possible</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#resmean.phreg'><p>Restricted mean for stratified Kaplan-Meier or Cox model with martingale standard errors</p></a></li>
<li><a href='#resmeanATE'><p>Average Treatment effect for Restricted Mean for censored competing risks data using IPCW</p></a></li>
<li><a href='#resmeanIPCW'><p>Restricted IPCW mean for censored survival data</p></a></li>
<li><a href='#rpch'><p>Piecewise constant hazard distribution</p></a></li>
<li><a href='#sim.cause.cox'><p>Simulation of cause specific from Cox models.</p></a></li>
<li><a href='#sim.cif'><p>Simulation of output from Cumulative incidence regression model</p></a></li>
<li><a href='#sim.cox'><p>Simulation of output from Cox model.</p></a></li>
<li><a href='#simAalenFrailty'><p>Simulate from the Aalen Frailty model</p></a></li>
<li><a href='#simClaytonOakes'><p>Simulate from the Clayton-Oakes frailty model</p></a></li>
<li><a href='#simClaytonOakesWei'><p>Simulate from the Clayton-Oakes frailty model</p></a></li>
<li><a href='#simMultistate'><p>Simulation of illness-death model</p></a></li>
<li><a href='#simRecurrentII'><p>Simulation of recurrent events data based on cumulative hazards II</p></a></li>
<li><a href='#simRecurrentTS'><p>Simulation of recurrent events data based on cumulative hazards: Two-stage model</p></a></li>
<li><a href='#summary.cor'><p>Summary for dependence models for competing risks</p></a></li>
<li><a href='#summaryGLM'><p>Reporting OR (exp(coef)) from glm with binomial link and glm predictions</p></a></li>
<li><a href='#survival.twostage'><p>Twostage survival model for multivariate survival data</p></a></li>
<li><a href='#survivalG'><p>G-estimator for Cox and Fine-Gray model</p></a></li>
<li><a href='#test.conc'><p>Concordance test Compares two concordance estimates</p></a></li>
<li><a href='#tetrachoric'><p>Estimate parameters from odds-ratio</p></a></li>
<li><a href='#TRACE'><p>The TRACE study group of myocardial infarction</p></a></li>
<li><a href='#ttpd'><p>ttpd discrete survival data on interval form</p></a></li>
<li><a href='#twin.clustertrunc'><p>Estimation of twostage model with cluster truncation in bivariate situation</p></a></li>
<li><a href='#twinbmi'><p>BMI data set</p></a></li>
<li><a href='#twinlm'><p>Classic twin model for quantitative traits</p></a></li>
<li><a href='#twinsim'><p>Simulate twin data</p></a></li>
<li><a href='#twinstut'><p>Stutter data set</p></a></li>
<li><a href='#twostageMLE'><p>Twostage survival model fitted by pseudo MLE</p></a></li>
<li><a href='#WA_recurrent'><p>While-Alive estimands for recurrent events</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analysis of Multivariate Event Times</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-11</td>
</tr>
<tr>
<td>Author:</td>
<td>Klaus K. Holst [aut, cre],
  Thomas Scheike [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Klaus K. Holst &lt;klaus@holst.it&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of various statistical models for multivariate
    event history data &lt;<a href="https://doi.org/10.1007%2Fs10985-013-9244-x">doi:10.1007/s10985-013-9244-x</a>&gt;. Including multivariate
    cumulative incidence models &lt;<a href="https://doi.org/10.1002%2Fsim.6016">doi:10.1002/sim.6016</a>&gt;, and  bivariate random
    effects probit models (Liability models) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2015.01.014">doi:10.1016/j.csda.2015.01.014</a>&gt;.
    Modern methods for survival analysis, including regression modelling (Cox, Fine-Gray, 
    Ghosh-Lin, Binomial regression) with fast computation of influence functions. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://kkholst.github.io/mets/">https://kkholst.github.io/mets/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kkholst/mets/issues">https://github.com/kkholst/mets/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5), timereg (&ge; 1.9.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>compiler, lava (&ge; 1.8.0), methods, numDeriv, mvtnorm, Rcpp,
splines, survival (&ge; 2.43-1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>optimx, prodlim, cmprsk, testthat (&ge; 0.11), ucminf, knitr,
rmarkdown, ggplot2, cowplot, icenReg</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, mvtnorm</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-11 10:20:23 UTC; klaus</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-11 11:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mets-package'>mets: Analysis of Multivariate Event Times</h2><span id='topic+mets-package'></span><span id='topic+mets'></span>

<h3>Description</h3>

<p>Implementation of various statistical models for multivariate event history data <a href="https://doi.org/10.1007/s10985-013-9244-x">doi:10.1007/s10985-013-9244-x</a>. Including multivariate cumulative incidence models <a href="https://doi.org/10.1002/sim.6016">doi:10.1002/sim.6016</a>, and bivariate random effects probit models (Liability models) <a href="https://doi.org/10.1016/j.csda.2015.01.014">doi:10.1016/j.csda.2015.01.014</a>. Modern methods for survival analysis, including regression modelling (Cox, Fine-Gray, Ghosh-Lin, Binomial regression) with fast computation of influence functions.
</p>
<p>Implementation of various statistical models for multivariate
event history data. Including multivariate cumulative incidence models,
and bivariate random effects probit models (Liability models)
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Klaus K. Holst <a href="mailto:klaus@holst.it">klaus@holst.it</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Thomas Scheike
</p>
</li></ul>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://kkholst.github.io/mets/">https://kkholst.github.io/mets/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/kkholst/mets/issues">https://github.com/kkholst/mets/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
## To appear

</code></pre>

<hr>
<h2 id='aalenfrailty'>Aalen frailty model</h2><span id='topic+aalenfrailty'></span>

<h3>Description</h3>

<p>Additive hazards model with (gamma) frailty
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aalenfrailty(time, status, X, id, theta, B = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aalenfrailty_+3A_time">time</code></td>
<td>
<p>Time variable</p>
</td></tr>
<tr><td><code id="aalenfrailty_+3A_status">status</code></td>
<td>
<p>Status variable (0,1)</p>
</td></tr>
<tr><td><code id="aalenfrailty_+3A_x">X</code></td>
<td>
<p>Covariate design matrix</p>
</td></tr>
<tr><td><code id="aalenfrailty_+3A_id">id</code></td>
<td>
<p>cluster variable</p>
</td></tr>
<tr><td><code id="aalenfrailty_+3A_theta">theta</code></td>
<td>
<p>list of thetas (returns score evaluated here), or
starting point for optimization (defaults to magic number 0.1)</p>
</td></tr>
<tr><td><code id="aalenfrailty_+3A_b">B</code></td>
<td>
<p>(optional) Cumulative coefficients (update theta by fixing B)</p>
</td></tr>
<tr><td><code id="aalenfrailty_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Aalen frailty model
</p>


<h3>Value</h3>

<p>Parameter estimates
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("timereg")
dd &lt;- simAalenFrailty(5000)
f &lt;- ~1##+x
X &lt;- model.matrix(f,dd) ## design matrix for non-parametric terms
system.time(out&lt;-timereg::aalen(update(f,Surv(time,status)~.),dd,n.sim=0,robust=0))
dix &lt;- which(dd$status==1)
t1 &lt;- system.time(bb &lt;- .Call("Bhat",as.integer(dd$status),
                              X,0.2,as.integer(dd$id),NULL,NULL,
                              PACKAGE="mets"))
spec &lt;- 1
##plot(out,spec=spec)
## plot(dd$time[dix],bb$B2[,spec],col="red",type="s",
##      ylim=c(0,max(dd$time)*c(beta0,beta)[spec]))
## abline(a=0,b=c(beta0,beta)[spec])
##'

## Not run: 
thetas &lt;- seq(0.1,2,length.out=10)
Us &lt;- unlist(aalenfrailty(dd$time,dd$status,X,dd$id,as.list(thetas)))
##plot(thetas,Us,type="l",ylim=c(-.5,1)); abline(h=0,lty=2); abline(v=theta,lty=2)
op &lt;- aalenfrailty(dd$time,dd$status,X,dd$id)
op

## End(Not run)
</code></pre>

<hr>
<h2 id='aalenMets'>Fast additive hazards model with robust standard errors</h2><span id='topic+aalenMets'></span>

<h3>Description</h3>

<p>Fast Lin-Ying additive hazards model with a possibly stratified baseline. 
Robust variance is default variance with the summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aalenMets(formula, data = data, no.baseline = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aalenMets_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="aalenMets_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="aalenMets_+3A_no.baseline">no.baseline</code></td>
<td>
<p>to fit model without baseline hazard</p>
</td></tr>
<tr><td><code id="aalenMets_+3A_...">...</code></td>
<td>
<p>Additional arguments to phreg</p>
</td></tr>
</table>


<h3>Details</h3>

<p>influence functions (iid) will follow numerical order of given cluster variable
so ordering after $id will give iid in order of data-set.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(bmt); bmt$time &lt;- bmt$time+runif(408)*0.001
out &lt;- aalenMets(Surv(time,cause==1)~tcell+platelet+age,data=bmt)
summary(out)

## out2 &lt;- timereg::aalen(Surv(time,cause==1)~const(tcell)+const(platelet)+const(age),data=bmt)
## summary(out2)

</code></pre>

<hr>
<h2 id='ACTG175'>ACTG175, block randmized study from speff2trial package</h2><span id='topic+ACTG175'></span>

<h3>Description</h3>

<p>Data from speff2trial
</p>


<h3>Format</h3>

<p>Randomized study
</p>


<h3>Source</h3>

<p>Hammer et al. 1996, speff2trial package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ACTG175)
</code></pre>

<hr>
<h2 id='back2timereg'>Convert to timereg object</h2><span id='topic+back2timereg'></span>

<h3>Description</h3>

<p>convert to timereg object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>back2timereg(obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="back2timereg_+3A_obj">obj</code></td>
<td>
<p>no use</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='base1cumhaz'>rate of CRBSI for HPN patients of Copenhagen</h2><span id='topic+base1cumhaz'></span>

<h3>Description</h3>

<p>rate of CRBSI for HPN patients of Copenhagen
</p>


<h3>Source</h3>

<p>Estimated data
</p>

<hr>
<h2 id='base44cumhaz'>rate of Occlusion/Thrombosis complication for catheter of HPN patients of Copenhagen</h2><span id='topic+base44cumhaz'></span>

<h3>Description</h3>

<p>rate of Occlusion/Thrombosis complication for catheter of HPN patients of Copenhagen
</p>


<h3>Source</h3>

<p>Estimated data
</p>

<hr>
<h2 id='base4cumhaz'>rate of Mechanical (hole/defect) complication for catheter of HPN patients of Copenhagen</h2><span id='topic+base4cumhaz'></span>

<h3>Description</h3>

<p>rate of Mechanical (hole/defect) complication for catheter of HPN patients of Copenhagen
</p>


<h3>Source</h3>

<p>Estimated data
</p>

<hr>
<h2 id='basehazplot.phreg'>Plotting the baslines of stratified Cox</h2><span id='topic+basehazplot.phreg'></span><span id='topic+bplot'></span><span id='topic+basecumhaz'></span><span id='topic+plotConfRegion'></span><span id='topic+plotConfRegionSE'></span><span id='topic+plotstrata'></span><span id='topic+kmplot'></span><span id='topic+plotConfregion'></span>

<h3>Description</h3>

<p>Plotting the baselines of stratified Cox
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basehazplot.phreg(
  x,
  se = FALSE,
  time = NULL,
  add = FALSE,
  ylim = NULL,
  xlim = NULL,
  lty = NULL,
  col = NULL,
  lwd = NULL,
  legend = TRUE,
  ylab = NULL,
  xlab = NULL,
  polygon = TRUE,
  level = 0.95,
  stratas = NULL,
  robust = FALSE,
  conf.type = c("plain", "log"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="basehazplot.phreg_+3A_x">x</code></td>
<td>
<p>phreg object</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_se">se</code></td>
<td>
<p>to include standard errors</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_time">time</code></td>
<td>
<p>to plot for specific time variables</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_add">add</code></td>
<td>
<p>to add to previous plot</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_ylim">ylim</code></td>
<td>
<p>to give ylim</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_xlim">xlim</code></td>
<td>
<p>to give xlim</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_lty">lty</code></td>
<td>
<p>to specify lty of components</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_col">col</code></td>
<td>
<p>to specify col of components</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_lwd">lwd</code></td>
<td>
<p>to specify lwd of components</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_legend">legend</code></td>
<td>
<p>to specify col of components</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_ylab">ylab</code></td>
<td>
<p>to specify ylab</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_xlab">xlab</code></td>
<td>
<p>to specify xlab</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_polygon">polygon</code></td>
<td>
<p>to get standard error in shaded form</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_level">level</code></td>
<td>
<p>of standard errors</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_stratas">stratas</code></td>
<td>
<p>wich strata to plot</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_robust">robust</code></td>
<td>
<p>to use robust standard errors if possible</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_conf.type">conf.type</code></td>
<td>
<p>&quot;plain&quot; or &quot;log&quot; transformed</p>
</td></tr>
<tr><td><code id="basehazplot.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst, Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TRACE)
dcut(TRACE) &lt;- ~.
out1 &lt;- phreg(Surv(time,status==9)~vf+chf+strata(wmicat.4),data=TRACE)

par(mfrow=c(2,2))
bplot(out1)
bplot(out1,stratas=c(0,3))
bplot(out1,stratas=c(0,3),col=2:3,lty=1:2,se=TRUE)
bplot(out1,stratas=c(0),col=2,lty=2,se=TRUE,polygon=FALSE)
bplot(out1,stratas=c(0),col=matrix(c(2,1,3),1,3),lty=matrix(c(1,2,3),1,3),se=TRUE,polygon=FALSE)
</code></pre>

<hr>
<h2 id='bicomprisk'>Estimation of concordance in bivariate competing risks data</h2><span id='topic+bicomprisk'></span><span id='topic+bicompriskData'></span>

<h3>Description</h3>

<p>Estimation of concordance in bivariate competing risks data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicomprisk(
  formula,
  data,
  cause = c(1, 1),
  cens = 0,
  causes,
  indiv,
  strata = NULL,
  id,
  num,
  max.clust = 1000,
  marg = NULL,
  se.clusters = NULL,
  wname = NULL,
  prodlim = FALSE,
  messages = TRUE,
  model,
  return.data = 0,
  uniform = 0,
  conservative = 1,
  resample.iid = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bicomprisk_+3A_formula">formula</code></td>
<td>
<p>Formula with left-hand-side being a <code>Event</code> object (see example below) and the left-hand-side specying the covariate structure</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_data">data</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_cause">cause</code></td>
<td>
<p>Causes (default (1,1)) for which to estimate the bivariate cumulative incidence</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_cens">cens</code></td>
<td>
<p>The censoring code</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_causes">causes</code></td>
<td>
<p>causes</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_indiv">indiv</code></td>
<td>
<p>indiv</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_strata">strata</code></td>
<td>
<p>Strata</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_id">id</code></td>
<td>
<p>Clustering variable</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_num">num</code></td>
<td>
<p>num</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_max.clust">max.clust</code></td>
<td>
<p>max number of clusters in timereg::comp.risk call for iid decompostion, max.clust=NULL uses all clusters otherwise rougher grouping.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_marg">marg</code></td>
<td>
<p>marginal cumulative incidence to make stanard errors for same clusters for subsequent use in casewise.test()</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_se.clusters">se.clusters</code></td>
<td>
<p>to specify clusters for standard errors. Either a vector of cluster indices or a column name in <code>data</code>. Defaults to the <code>id</code> variable.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_wname">wname</code></td>
<td>
<p>name of additonal weight used for paired competing risks data.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_prodlim">prodlim</code></td>
<td>
<p>prodlim to use prodlim estimator (Aalen-Johansen) rather than IPCW weighted estimator based on comp.risk function.These are equivalent in the case of no covariates. These esimators are the same in the case of stratified fitting.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_messages">messages</code></td>
<td>
<p>Control amount of output</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_model">model</code></td>
<td>
<p>Type of competing risk model (default is Fine-Gray model &quot;fg&quot;, see comp.risk).</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_return.data">return.data</code></td>
<td>
<p>Should data be returned (skipping modeling)</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_uniform">uniform</code></td>
<td>
<p>to compute uniform standard errors for concordance estimates based on resampling.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_conservative">conservative</code></td>
<td>
<p>for conservative standard errors, recommended for larger data-sets.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_resample.iid">resample.iid</code></td>
<td>
<p>to return iid residual processes for further computations such as tests.</p>
</td></tr>
<tr><td><code id="bicomprisk_+3A_...">...</code></td>
<td>
<p>Additional arguments to timereg::comp.risk function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike, Klaus K. Holst
</p>


<h3>References</h3>

<p>Scheike, T. H.; Holst, K. K. &amp; Hjelmborg, J. B.
Estimating twin concordance for bivariate competing risks twin data
Statistics in Medicine, Wiley Online Library, 2014 , 33 , 1193-204
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("timereg")

## Simulated data example
prt &lt;- simnordic.random(2000,delayed=TRUE,ptrunc=0.7,
	      cordz=0.5,cormz=2,lam0=0.3)
## Bivariate competing risk, concordance estimates
p11 &lt;- bicomprisk(Event(time,cause)~strata(zyg)+id(id),data=prt,cause=c(1,1))

p11mz &lt;- p11$model$"MZ"
p11dz &lt;- p11$model$"DZ"
par(mfrow=c(1,2))
## Concordance
plot(p11mz,ylim=c(0,0.1));
plot(p11dz,ylim=c(0,0.1));

## entry time, truncation weighting
### other weighting procedure
prtl &lt;-  prt[!prt$truncated,]
prt2 &lt;- ipw2(prtl,cluster="id",same.cens=TRUE,
     time="time",cause="cause",entrytime="entry",
     pairs=TRUE,strata="zyg",obs.only=TRUE)

prt22 &lt;- fast.reshape(prt2,id="id")

prt22$event &lt;- (prt22$cause1==1)*(prt22$cause2==1)*1
prt22$timel &lt;- pmax(prt22$time1,prt22$time2)
ipwc &lt;- timereg::comp.risk(Event(timel,event)~-1+factor(zyg1),
  data=prt22,cause=1,n.sim=0,model="rcif2",times=50:90,
  weights=prt22$weights1,cens.weights=rep(1,nrow(prt22)))

p11wmz &lt;- ipwc$cum[,2]
p11wdz &lt;- ipwc$cum[,3]
lines(ipwc$cum[,1],p11wmz,col=3)
lines(ipwc$cum[,1],p11wdz,col=3)

</code></pre>

<hr>
<h2 id='BinAugmentCifstrata'>Augmentation for Binomial regression based on stratified NPMLE Cif (Aalen-Johansen)</h2><span id='topic+BinAugmentCifstrata'></span>

<h3>Description</h3>

<p>Computes  the augmentation term for each individual as well as the sum
</p>
<p style="text-align: center;"><code class="reqn">
A = \int_0^t H(u,X) \frac{1}{S^*(u,s)} \frac{1}{G_c(u)} dM_c(u)
</code>
</p>

<p>with 
</p>
<p style="text-align: center;"><code class="reqn">
H(u,X) = F_1^*(t,s) - F_1^*(u,s)
</code>
</p>

<p>using a KM for </p>
<p style="text-align: center;"><code class="reqn">G_c(t)</code>
</p>
<p> and a working model for cumulative baseline
related to </p>
<p style="text-align: center;"><code class="reqn">F_1^*(t,s)</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">s</code>
</p>
<p> is strata, </p>
<p style="text-align: center;"><code class="reqn">S^*(t,s) = 1 - F_1^*(t,s) - F_2^*(t,s)</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinAugmentCifstrata(
  formula,
  data = data,
  cause = 1,
  cens.code = 0,
  km = TRUE,
  time = NULL,
  weights = NULL,
  offset = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BinAugmentCifstrata_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event', strata model for CIF given by strata, and strataC specifies censoring strata</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_cause">cause</code></td>
<td>
<p>of interest</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_cens.code">cens.code</code></td>
<td>
<p>code of censoring</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_km">km</code></td>
<td>
<p>to use Kaplan-Meier</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_time">time</code></td>
<td>
<p>of interest</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_weights">weights</code></td>
<td>
<p>weights for estimating equations</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_offset">offset</code></td>
<td>
<p>offsets for logistic regression</p>
</td></tr>
<tr><td><code id="BinAugmentCifstrata_+3A_...">...</code></td>
<td>
<p>Additional arguments to binreg function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard errors computed under assumption of correct </p>
<p style="text-align: center;"><code class="reqn">G_c(s)</code>
</p>
<p> model.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bmt)
dcut(bmt,breaks=2) &lt;- ~age 
out1&lt;-BinAugmentCifstrata(Event(time,cause)~platelet+agecat.2+
		  strata(platelet,agecat.2),data=bmt,cause=1,time=40)
summary(out1)

out2&lt;-BinAugmentCifstrata(Event(time,cause)~platelet+agecat.2+
    strata(platelet,agecat.2)+strataC(platelet),data=bmt,cause=1,time=40)
summary(out2)
</code></pre>

<hr>
<h2 id='binomial.twostage'>Fits Clayton-Oakes or bivariate Plackett (OR) models for binary data
using marginals that are on logistic form.
If clusters contain more than two times, the algoritm uses a compososite likelihood
based on all pairwise bivariate models.</h2><span id='topic+binomial.twostage'></span><span id='topic+binomial.twostage.time'></span>

<h3>Description</h3>

<p>The pairwise pairwise odds ratio model provides an alternative to the alternating logistic
regression (ALR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binomial.twostage(
  margbin,
  data = parent.frame(),
  method = "nr",
  detail = 0,
  clusters = NULL,
  silent = 1,
  weights = NULL,
  theta = NULL,
  theta.des = NULL,
  var.link = 0,
  var.par = 1,
  var.func = NULL,
  iid = 1,
  notaylor = 1,
  model = "plackett",
  marginal.p = NULL,
  beta.iid = NULL,
  Dbeta.iid = NULL,
  strata = NULL,
  max.clust = NULL,
  se.clusters = NULL,
  numDeriv = 0,
  random.design = NULL,
  pairs = NULL,
  dim.theta = NULL,
  additive.gamma.sum = NULL,
  pair.ascertained = 0,
  case.control = 0,
  no.opt = FALSE,
  twostage = 1,
  beta = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binomial.twostage_+3A_margbin">margbin</code></td>
<td>
<p>Marginal binomial model</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_method">method</code></td>
<td>
<p>Scoring method &quot;nr&quot;, for lava NR optimizer</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_detail">detail</code></td>
<td>
<p>Detail</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_clusters">clusters</code></td>
<td>
<p>Cluster variable</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_silent">silent</code></td>
<td>
<p>Debug information</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_weights">weights</code></td>
<td>
<p>Weights for log-likelihood, can be used for each type of outcome in 2x2 tables.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_theta">theta</code></td>
<td>
<p>Starting values for variance components</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_theta.des">theta.des</code></td>
<td>
<p>design for dependence parameters, when pairs are given the indeces of the
theta-design for this pair, is given in pairs as column 5</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_var.link">var.link</code></td>
<td>
<p>Link function for variance</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_var.par">var.par</code></td>
<td>
<p>parametrization</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_var.func">var.func</code></td>
<td>
<p>when alternative parametrizations are used this function can specify how the paramters are related to the <code class="reqn">\lambda_j</code>'s.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_iid">iid</code></td>
<td>
<p>Calculate i.i.d. decomposition when iid&gt;=1, when iid=2 then avoids adding the uncertainty for marginal paramters for additive gamma model (default).</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_notaylor">notaylor</code></td>
<td>
<p>Taylor expansion</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_marginal.p">marginal.p</code></td>
<td>
<p>vector of marginal probabilities</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_beta.iid">beta.iid</code></td>
<td>
<p>iid decomposition of marginal probability  estimates for each subject, if based on GLM model this is computed.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_dbeta.iid">Dbeta.iid</code></td>
<td>
<p>derivatives of marginal model wrt marginal parameters, if based on GLM model this is computed.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_strata">strata</code></td>
<td>
<p>strata for fitting: considers only pairs where both are from same strata</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_max.clust">max.clust</code></td>
<td>
<p>max clusters</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_se.clusters">se.clusters</code></td>
<td>
<p>clusters for iid decomposition for roubst standard errors</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_numderiv">numDeriv</code></td>
<td>
<p>uses Fisher scoring aprox of second derivative if 0, otherwise numerical derivatives</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_random.design">random.design</code></td>
<td>
<p>random effect design for additive gamma model, when pairs are given the
indeces of the pairs random.design rows are given as columns 3:4</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_pairs">pairs</code></td>
<td>
<p>matrix with rows of indeces (two-columns) for the pairs considered in the pairwise composite score, useful for case-control sampling when marginal is known.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_dim.theta">dim.theta</code></td>
<td>
<p>dimension of theta when pairs and pairs specific design is given. That is when pairs has 6 columns.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_additive.gamma.sum">additive.gamma.sum</code></td>
<td>
<p>this is specification of the lamtot in the models via a matrix that is multiplied onto the parameters theta (dimensions=(number random effects x number of theta parameters), when null then sums all parameters. Default is a matrix of 1's</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_pair.ascertained">pair.ascertained</code></td>
<td>
<p>if pairs are sampled only when there are events in the pair i.e. Y1+Y2&gt;=1.</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_case.control">case.control</code></td>
<td>
<p>if data is case control data for pair call, and here 2nd column of pairs are probands (cases or controls)</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_no.opt">no.opt</code></td>
<td>
<p>for not optimizing</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_twostage">twostage</code></td>
<td>
<p>default twostage=1, to fit MLE use twostage=0</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_beta">beta</code></td>
<td>
<p>is starting value for beta for MLE version</p>
</td></tr>
<tr><td><code id="binomial.twostage_+3A_...">...</code></td>
<td>
<p>for NR of lava</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reported standard errors are based on a cluster corrected score equations from the
pairwise likelihoods assuming that the marginals are known. This gives correct standard errors
in the case of the Odds-Ratio model (Plackett distribution) for dependence, but incorrect standard
errors for the Clayton-Oakes types model (that is also called &quot;gamma&quot;-frailty). For the additive gamma version of the
standard errors
are adjusted for the uncertainty in the marginal models via an iid deomposition using the iid() function of
lava. For the clayton oakes model that is not speicifed via the random effects these can be
fixed subsequently using the iid influence functions for the marginal model, but typically this does not
change much.
</p>
<p>For the Clayton-Oakes version of the model, given the gamma distributed random effects it is
assumed that the probabilities are indpendent, and that the marginal survival functions are on logistic form
</p>
<p style="text-align: center;"><code class="reqn">
logit(P(Y=1|X)) = \alpha + x^T \beta
</code>
</p>

<p>therefore conditional on the random effect the probability of the event is
</p>
<p style="text-align: center;"><code class="reqn">
logit(P(Y=1|X,Z)) = exp( -Z \cdot Laplace^{-1}(lamtot,lamtot,P(Y=1|x)) )
</code>
</p>

<p>Can also fit a structured additive gamma random effects model, such
the ACE, ADE model for survival data:
</p>
<p>Now random.design specificies the random effects for each subject within a cluster. This is
a matrix of 1's and 0's with dimension n x d.  With d random effects.
For a cluster with two subjects, we let the random.design rows be
<code class="reqn">v_1</code> and <code class="reqn">v_2</code>.
Such that the random effects for subject
1 is </p>
<p style="text-align: center;"><code class="reqn">v_1^T (Z_1,...,Z_d)</code>
</p>
<p>, for d random effects. Each random effect
has an associated parameter <code class="reqn">(\lambda_1,...,\lambda_d)</code>. By construction
subjects 1's random effect are Gamma distributed with
mean <code class="reqn">\lambda_j/v_1^T \lambda</code>
and variance <code class="reqn">\lambda_j/(v_1^T \lambda)^2</code>. Note that the random effect
<code class="reqn">v_1^T (Z_1,...,Z_d)</code> has mean 1 and variance <code class="reqn">1/(v_1^T \lambda)</code>.
It is here asssumed that  <code class="reqn">lamtot=v_1^T \lambda</code> is fixed over all clusters
as it would be for the ACE model below.
</p>
<p>The DEFAULT parametrization uses the variances of the random effecs (var.par=1)
</p>
<p style="text-align: center;"><code class="reqn">
\theta_j  = \lambda_j/(v_1^T \lambda)^2
</code>
</p>

<p>For alternative parametrizations (var.par=0) one can specify how the parameters relate
to <code class="reqn">\lambda_j</code> with the function
</p>
<p>Based on these parameters the relative contribution (the heritability, h) is
equivalent to  the expected values of the random effects  <code class="reqn">\lambda_j/v_1^T \lambda</code>
</p>
<p>Given the random effects the probabilities  are independent and on the form
</p>
<p style="text-align: center;"><code class="reqn">
logit(P(Y=1|X)) = exp( - Laplace^{-1}(lamtot,lamtot,P(Y=1|x)) )
</code>
</p>

<p>with the inverse laplace of the gamma distribution with mean 1 and variance lamtot.
</p>
<p>The parameters <code class="reqn">(\lambda_1,...,\lambda_d)</code>
are related to the parameters of the model
by a regression construction <code class="reqn">pard</code> (d x k), that links the <code class="reqn">d</code>
<code class="reqn">\lambda</code> parameters
with the (k) underlying <code class="reqn">\theta</code> parameters
</p>
<p style="text-align: center;"><code class="reqn">
\lambda = theta.des  \theta
</code>
</p>

<p>here using theta.des to specify these low-dimension association. Default is a diagonal matrix.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Two-stage binomial modelling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(twinstut)
twinstut0 &lt;- subset(twinstut, tvparnr&lt;4000)
twinstut &lt;- twinstut0
twinstut$binstut &lt;- (twinstut$stutter=="yes")*1
theta.des &lt;- model.matrix( ~-1+factor(zyg),data=twinstut)
margbin &lt;- glm(binstut~factor(sex)+age,data=twinstut,family=binomial())
bin &lt;- binomial.twostage(margbin,data=twinstut,var.link=1,
         clusters=twinstut$tvparnr,theta.des=theta.des,detail=0)
summary(bin)

twinstut$cage &lt;- scale(twinstut$age)
theta.des &lt;- model.matrix( ~-1+factor(zyg)+cage,data=twinstut)
bina &lt;- binomial.twostage(margbin,data=twinstut,var.link=1,
		         clusters=twinstut$tvparnr,theta.des=theta.des)
summary(bina)

theta.des &lt;- model.matrix( ~-1+factor(zyg)+factor(zyg)*cage,data=twinstut)
bina &lt;- binomial.twostage(margbin,data=twinstut,var.link=1,
		         clusters=twinstut$tvparnr,theta.des=theta.des)
summary(bina)

 ## Reduce Ex.Timings
## refers to zygosity of first subject in eash pair : zyg1
## could also use zyg2 (since zyg2=zyg1 within twinpair's))
out &lt;- easy.binomial.twostage(stutter~factor(sex)+age,data=twinstut,
                          response="binstut",id="tvparnr",var.link=1,
	             	      theta.formula=~-1+factor(zyg1))
summary(out)

## refers to zygosity of first subject in eash pair : zyg1
## could also use zyg2 (since zyg2=zyg1 within twinpair's))
desfs&lt;-function(x,num1="zyg1",num2="zyg2")
    c(x[num1]=="dz",x[num1]=="mz",x[num1]=="os")*1

out3 &lt;- easy.binomial.twostage(binstut~factor(sex)+age,
      data=twinstut,response="binstut",id="tvparnr",var.link=1,
      theta.formula=desfs,desnames=c("mz","dz","os"))
summary(out3)


### use of clayton oakes binomial additive gamma model
###########################################################
 ## Reduce Ex.Timings
data &lt;- simbinClaytonOakes.family.ace(10000,2,1,beta=NULL,alpha=NULL)
margbin &lt;- glm(ybin~x,data=data,family=binomial())
margbin

head(data)
data$number &lt;- c(1,2,3,4)
data$child &lt;- 1*(data$number==3)

### make ace random effects design
out &lt;- ace.family.design(data,member="type",id="cluster")
out$pardes
head(out$des.rv)

bints &lt;- binomial.twostage(margbin,data=data,
     clusters=data$cluster,detail=0,var.par=1,
     theta=c(2,1),var.link=0,
     random.design=out$des.rv,theta.des=out$pardes)
summary(bints)

data &lt;- simbinClaytonOakes.twin.ace(10000,2,1,beta=NULL,alpha=NULL)
out  &lt;- twin.polygen.design(data,id="cluster",zygname="zygosity")
out$pardes
head(out$des.rv)
margbin &lt;- glm(ybin~x,data=data,family=binomial())

bintwin &lt;- binomial.twostage(margbin,data=data,
     clusters=data$cluster,var.par=1,
     theta=c(2,1),random.design=out$des.rv,theta.des=out$pardes)
summary(bintwin)
concordanceTwinACE(bintwin)


</code></pre>

<hr>
<h2 id='binreg'>Binomial Regression for censored competing risks data</h2><span id='topic+binreg'></span><span id='topic+logitIPCW'></span><span id='topic+binregt'></span>

<h3>Description</h3>

<p>Simple version of comp.risk function of timereg for just one time-point thus fitting the model 
</p>
<p style="text-align: center;"><code class="reqn">P(T \leq t, \epsilon=1 | X ) = expit( X^T beta) </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>binreg(
  formula,
  data,
  cause = 1,
  time = NULL,
  beta = NULL,
  type = c("II", "I"),
  offset = NULL,
  weights = NULL,
  cens.weights = NULL,
  cens.model = ~+1,
  se = TRUE,
  kaplan.meier = TRUE,
  cens.code = 0,
  no.opt = FALSE,
  method = "nr",
  augmentation = NULL,
  outcome = c("cif", "rmst"),
  model = "exp",
  Ydirect = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binreg_+3A_formula">formula</code></td>
<td>
<p>formula with outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="binreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="binreg_+3A_cause">cause</code></td>
<td>
<p>cause of interest (numeric variable)</p>
</td></tr>
<tr><td><code id="binreg_+3A_time">time</code></td>
<td>
<p>time of interest</p>
</td></tr>
<tr><td><code id="binreg_+3A_beta">beta</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="binreg_+3A_type">type</code></td>
<td>
<p>&quot;II&quot; adds augmentation term, and &quot;I&quot; classic binomial regression</p>
</td></tr>
<tr><td><code id="binreg_+3A_offset">offset</code></td>
<td>
<p>offsets for partial likelihood</p>
</td></tr>
<tr><td><code id="binreg_+3A_weights">weights</code></td>
<td>
<p>for score equations</p>
</td></tr>
<tr><td><code id="binreg_+3A_cens.weights">cens.weights</code></td>
<td>
<p>censoring weights</p>
</td></tr>
<tr><td><code id="binreg_+3A_cens.model">cens.model</code></td>
<td>
<p>only stratified cox model without covariates</p>
</td></tr>
<tr><td><code id="binreg_+3A_se">se</code></td>
<td>
<p>to compute se's  based on IPCW</p>
</td></tr>
<tr><td><code id="binreg_+3A_kaplan.meier">kaplan.meier</code></td>
<td>
<p>uses Kaplan-Meier for IPCW in contrast to exp(-Baseline)</p>
</td></tr>
<tr><td><code id="binreg_+3A_cens.code">cens.code</code></td>
<td>
<p>gives censoring code</p>
</td></tr>
<tr><td><code id="binreg_+3A_no.opt">no.opt</code></td>
<td>
<p>to not optimize</p>
</td></tr>
<tr><td><code id="binreg_+3A_method">method</code></td>
<td>
<p>for optimization</p>
</td></tr>
<tr><td><code id="binreg_+3A_augmentation">augmentation</code></td>
<td>
<p>to augment binomial regression</p>
</td></tr>
<tr><td><code id="binreg_+3A_outcome">outcome</code></td>
<td>
<p>can do CIF regression &quot;cif&quot;=F(t|X), &quot;rmst&quot;=E( min(T, t) | X) , or &quot;rmst-cause&quot;=E( I(epsilon==cause) ( t - mint(T,t)) ) | X)</p>
</td></tr>
<tr><td><code id="binreg_+3A_model">model</code></td>
<td>
<p>possible exp model for E( min(T, t) | X)=exp(X^t beta) , or E( I(epsilon==cause) ( t - mint(T,t)) ) | X)=exp(X^t beta)</p>
</td></tr>
<tr><td><code id="binreg_+3A_ydirect">Ydirect</code></td>
<td>
<p>use this Y instead of outcome constructed inside the program (e.g. I(T&lt; t, epsilon=1)), then uses IPCW vesion of the Y, set outcome to &quot;rmst&quot; to fit using the model specified by model</p>
</td></tr>
<tr><td><code id="binreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on binomial regresion IPCW response estimating equation: 
</p>
<p style="text-align: center;"><code class="reqn"> X ( \Delta I(T \leq t, \epsilon=1 )/G_c(T_i-) - expit( X^T beta)) = 0 </code>
</p>

<p>for IPCW adjusted responses, with (default, type=&quot;II&quot;) an additional 
censoring augmentation term </p>
<p style="text-align: center;"><code class="reqn">X \int E(Y(t)| T&gt;s)/G_c(s) dM_c</code>
</p>
<p> with 
</p>
<p style="text-align: center;"><code class="reqn">Y(t) = I(T \leq t, \epsilon=1 )</code>
</p>

<p>logitIPCW instead considers 
</p>
<p style="text-align: center;"><code class="reqn"> X  I(min(T_i,t) &lt; G_i)/G_c(min(T_i ,t)) ( I(T \leq t, \epsilon=1 ) - expit( X^T beta)) = 0 </code>
</p>

<p>a standard logistic regression with weights that adjust for IPCW. 
</p>
<p>Variance is based on  </p>
<p style="text-align: center;"><code class="reqn"> \sum w_i^2 </code>
</p>
<p> with IPCW adjustment, and naive.var is variance 
under known censoring model. 
</p>
<p>Censoring model may depend on strata.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mets)
data(bmt); bmt$time &lt;- bmt$time+runif(408)*0.001
# logistic regresion with IPCW binomial regression 
out &lt;- binreg(Event(time,cause)~tcell+platelet,bmt,time=50)
summary(out)

predict(out,data.frame(tcell=c(0,1),platelet=c(1,1)),se=TRUE)

##outs &lt;- binreg(Event(time,cause)~tcell+platelet,bmt,time=50,cens.model=~strata(tcell,platelet))
##summary(outs)

## glm with IPCW weights 
outl &lt;- logitIPCW(Event(time,cause)~tcell+platelet,bmt,time=50)
summary(outl)

##########################################
### risk-ratio of different causes #######
##########################################
data(bmt)
bmt$id &lt;- 1:nrow(bmt)
bmt$status &lt;- bmt$cause
bmt$strata &lt;- 1
bmtdob &lt;- bmt
bmtdob$strata &lt;-2
bmtdob &lt;- dtransform(bmtdob,status=1,cause==2)
bmtdob &lt;- dtransform(bmtdob,status=2,cause==1)
###
bmtdob &lt;- rbind(bmt,bmtdob)
dtable(bmtdob,cause+status~strata)

cif1 &lt;- cif(Event(time,cause)~+1,bmt,cause=1)
cif2 &lt;- cif(Event(time,cause)~+1,bmt,cause=2)
bplot(cif1)
bplot(cif2,add=TRUE,col=2)

cifs1 &lt;- binreg(Event(time,cause)~tcell+platelet+age,bmt,cause=2,time=50)
cifs2 &lt;- binreg(Event(time,cause)~tcell+platelet+age,bmt,cause=2,time=50)
summary(cifs1)
summary(cifs2)

cifdob &lt;- binreg(Event(time,status)~-1+factor(strata)+
	 tcell*factor(strata)+platelet*factor(strata)+age*factor(strata)
	 +cluster(id),bmtdob,cause=1,time=50,cens.model=~strata(strata)+cluster(id))
summary(cifdob)

riskratio &lt;- function(p) {
  Z &lt;- rbind(c(1,0,1,1,0,0,0,0), c(0,1,1,1,0,1,1,0))
  lp &lt;- c(Z %*% p)
  p &lt;- lava::expit(lp)
  return(p[1]/p[2])
}

lava::estimate(cifdob,f=riskratio)

</code></pre>

<hr>
<h2 id='binregATE'>Average Treatment effect for censored competing risks data using Binomial Regression</h2><span id='topic+binregATE'></span><span id='topic+logitIPCWATE'></span><span id='topic+logitATE'></span><span id='topic+normalATE'></span><span id='topic+kumarsim'></span><span id='topic+kumarsimRCT'></span>

<h3>Description</h3>

<p>Under the standard causal assumptions  we can estimate the average treatment effect E(Y(1) - Y(0)). We need Consistency, ignorability ( Y(1), Y(0) indep A given X), and positivity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binregATE(
  formula,
  data,
  cause = 1,
  time = NULL,
  beta = NULL,
  treat.model = ~+1,
  cens.model = ~+1,
  offset = NULL,
  weights = NULL,
  cens.weights = NULL,
  se = TRUE,
  type = c("II", "I"),
  kaplan.meier = TRUE,
  cens.code = 0,
  no.opt = FALSE,
  method = "nr",
  augmentation = NULL,
  outcome = c("cif", "rmst"),
  model = "exp",
  Ydirect = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binregATE_+3A_formula">formula</code></td>
<td>
<p>formula with outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="binregATE_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="binregATE_+3A_cause">cause</code></td>
<td>
<p>cause of interest</p>
</td></tr>
<tr><td><code id="binregATE_+3A_time">time</code></td>
<td>
<p>time of interest</p>
</td></tr>
<tr><td><code id="binregATE_+3A_beta">beta</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="binregATE_+3A_treat.model">treat.model</code></td>
<td>
<p>logistic treatment model given covariates</p>
</td></tr>
<tr><td><code id="binregATE_+3A_cens.model">cens.model</code></td>
<td>
<p>only stratified cox model without covariates</p>
</td></tr>
<tr><td><code id="binregATE_+3A_offset">offset</code></td>
<td>
<p>offsets for partial likelihood</p>
</td></tr>
<tr><td><code id="binregATE_+3A_weights">weights</code></td>
<td>
<p>for score equations</p>
</td></tr>
<tr><td><code id="binregATE_+3A_cens.weights">cens.weights</code></td>
<td>
<p>censoring weights</p>
</td></tr>
<tr><td><code id="binregATE_+3A_se">se</code></td>
<td>
<p>to compute se's with IPCW  adjustment, otherwise assumes that IPCW weights are known</p>
</td></tr>
<tr><td><code id="binregATE_+3A_type">type</code></td>
<td>
<p>&quot;II&quot; adds augmentation term, and &quot;I&quot; classic binomial regression</p>
</td></tr>
<tr><td><code id="binregATE_+3A_kaplan.meier">kaplan.meier</code></td>
<td>
<p>uses Kaplan-Meier for IPCW in contrast to exp(-Baseline)</p>
</td></tr>
<tr><td><code id="binregATE_+3A_cens.code">cens.code</code></td>
<td>
<p>gives censoring code</p>
</td></tr>
<tr><td><code id="binregATE_+3A_no.opt">no.opt</code></td>
<td>
<p>to not optimize</p>
</td></tr>
<tr><td><code id="binregATE_+3A_method">method</code></td>
<td>
<p>for optimization</p>
</td></tr>
<tr><td><code id="binregATE_+3A_augmentation">augmentation</code></td>
<td>
<p>for augment binomial regression</p>
</td></tr>
<tr><td><code id="binregATE_+3A_outcome">outcome</code></td>
<td>
<p>can do CIF regression &quot;cif&quot;=F(t|X), &quot;rmst&quot;=E( min(T, t) | X) , or E( I(epsilon==cause) ( t - mint(T,t)) ) | X) depending on the number of the number of causes.</p>
</td></tr>
<tr><td><code id="binregATE_+3A_model">model</code></td>
<td>
<p>exp or linear model for E( min(T, t) | X)=exp(X^t beta), or E( I(epsilon==cause) ( t - mint(T,t)) ) | X)=exp(X^t beta)</p>
</td></tr>
<tr><td><code id="binregATE_+3A_ydirect">Ydirect</code></td>
<td>
<p>use this outcome Y with IPCW vesion</p>
</td></tr>
<tr><td><code id="binregATE_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first covariate in the specification of the competing risks regression model must be the treatment effect that is a factor. If the factor has more than two levels
then it uses the mlogit for propensity score modelling. If there are no censorings this is the same as ordinary logistic regression modelling. 
</p>
<p>Estimates the ATE using the the standard binary double robust estimating equations that are IPCW censoring adjusted.
Rather than binomial regression we also consider a IPCW weighted version of standard logistic regression logitIPCWATE.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bmt)
dfactor(bmt)  &lt;-  ~.

brs &lt;- binregATE(Event(time,cause)~tcell.f+platelet+age,bmt,time=50,cause=1,
  treat.model=tcell.f~platelet+age)
summary(brs)

brsi &lt;- binregATE(Event(time,cause)~tcell.f+tcell.f*platelet+tcell.f*age,bmt,time=50,cause=1,
  treat.model=tcell.f~platelet+age)
summary(brsi)

</code></pre>

<hr>
<h2 id='binregCasewise'>Estimates the casewise concordance based on Concordance and marginal estimate using binreg</h2><span id='topic+binregCasewise'></span>

<h3>Description</h3>

<p>Estimates the casewise concordance based on Concordance and marginal estimate using binreg
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binregCasewise(concbreg, margbreg, zygs = c("DZ", "MZ"), newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binregCasewise_+3A_concbreg">concbreg</code></td>
<td>
<p>Concordance</p>
</td></tr>
<tr><td><code id="binregCasewise_+3A_margbreg">margbreg</code></td>
<td>
<p>Marginal estimate</p>
</td></tr>
<tr><td><code id="binregCasewise_+3A_zygs">zygs</code></td>
<td>
<p>order of zygosity for estimation of concordance and casewise.</p>
</td></tr>
<tr><td><code id="binregCasewise_+3A_newdata">newdata</code></td>
<td>
<p>to give instead of zygs.</p>
</td></tr>
<tr><td><code id="binregCasewise_+3A_...">...</code></td>
<td>
<p>to pass to estimate function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses cluster iid for the two binomial-regression estimates  standard errors better than those of casewise that are often conservative.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(prt)
prt &lt;- force.same.cens(prt,cause="status")

dd &lt;- bicompriskData(Event(time, status)~strata(zyg)+id(id), data=prt, cause=c(2, 2))
newdata &lt;- data.frame(zyg=c("DZ","MZ"),id=1)

## concordance 
bcif1 &lt;- binreg(Event(time,status)~-1+factor(zyg)+cluster(id), data=dd,
                time=80, cause=1, cens.model=~strata(zyg))
pconc &lt;- predict(bcif1,newdata)

## marginal estimates 
mbcif1 &lt;- binreg(Event(time,status)~cluster(id), data=prt, time=80, cause=2)
mc &lt;- predict(mbcif1,newdata)
mc

cse &lt;- binregCasewise(bcif1,mbcif1)
cse
</code></pre>

<hr>
<h2 id='binregG'>G-estimator for binomial regression model (Standardized estimates)</h2><span id='topic+binregG'></span>

<h3>Description</h3>

<p>Computes G-estimator </p>
<p style="text-align: center;"><code class="reqn"> \hat F(t,A=a) = n^{-1} \sum_i \hat F(t,A=a,Z_i) </code>
</p>
<p>.
Assumes that the first covariate is $A$.
Gives influence functions of these risk estimates and SE's are based on these.  
If first covariate is a factor then all contrast are computed, and if continuous 
then considered covariate values are given by Avalues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binregG(x, data, Avalues = c(0, 1), varname = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binregG_+3A_x">x</code></td>
<td>
<p>phreg or cifreg object</p>
</td></tr>
<tr><td><code id="binregG_+3A_data">data</code></td>
<td>
<p>data frame for risk averaging</p>
</td></tr>
<tr><td><code id="binregG_+3A_avalues">Avalues</code></td>
<td>
<p>values to compare for first covariate A</p>
</td></tr>
<tr><td><code id="binregG_+3A_varname">varname</code></td>
<td>
<p>if given then averages for this variable, default is first variable</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(bmt); bmt$time &lt;- bmt$time+runif(408)*0.001
bmt$event &lt;- (bmt$cause!=0)*1

b1 &lt;- binreg(Event(time,cause)~age+tcell+platelet,bmt,cause=1,time=50)
sb1 &lt;- binregG(b1,bmt,Avalues=c(0,1,2))
summary(sb1)
</code></pre>

<hr>
<h2 id='binregTSR'>2 Stage Randomization for Survival Data or competing Risks Data</h2><span id='topic+binregTSR'></span>

<h3>Description</h3>

<p>Under two-stage randomization we can estimate the average treatment effect E(Y(i,j)) of treatment regime (i,j). 
The estimator can be agumented in different ways: using the two randomizations and the dynamic censoring augmetatation.
The treatment's must be given as factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binregTSR(
  formula,
  data,
  cause = 1,
  time = NULL,
  cens.code = 0,
  response.code = NULL,
  augmentR0 = NULL,
  treat.model0 = ~+1,
  augmentR1 = NULL,
  treat.model1 = ~+1,
  augmentC = NULL,
  cens.model = ~+1,
  estpr = c(1, 1),
  response.name = NULL,
  offset = NULL,
  weights = NULL,
  cens.weights = NULL,
  beta = NULL,
  kaplan.meier = TRUE,
  no.opt = FALSE,
  method = "nr",
  augmentation = NULL,
  outcome = c("cif", "rmst", "rmst-cause"),
  model = "exp",
  Ydirect = NULL,
  return.dataw = 0,
  pi0 = 0.5,
  pi1 = 0.5,
  cens.time.fixed = 1,
  outcome.iid = 1,
  meanCs = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binregTSR_+3A_formula">formula</code></td>
<td>
<p>formula with outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_cause">cause</code></td>
<td>
<p>cause of interest</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_time">time</code></td>
<td>
<p>time of interest</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_cens.code">cens.code</code></td>
<td>
<p>gives censoring code</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_response.code">response.code</code></td>
<td>
<p>code of status of survival data that indicates a response at which 2nd randomization is performed</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_augmentr0">augmentR0</code></td>
<td>
<p>augmentation model for  1st randomization</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_treat.model0">treat.model0</code></td>
<td>
<p>logistic treatment model for 1st randomization</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_augmentr1">augmentR1</code></td>
<td>
<p>augmentation model for  2nd randomization</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_treat.model1">treat.model1</code></td>
<td>
<p>logistic treatment model for 2ndrandomization</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_augmentc">augmentC</code></td>
<td>
<p>augmentation model for censoring</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_cens.model">cens.model</code></td>
<td>
<p>stratification for censoring model based on observed covariates</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_estpr">estpr</code></td>
<td>
<p>estimate randomization probabilities using model</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_response.name">response.name</code></td>
<td>
<p>can give name of response variable, otherwise reads this as first variable of treat.model1</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_offset">offset</code></td>
<td>
<p>not implemented</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_weights">weights</code></td>
<td>
<p>not implemented</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_cens.weights">cens.weights</code></td>
<td>
<p>can be given</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_beta">beta</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_kaplan.meier">kaplan.meier</code></td>
<td>
<p>for censoring weights, rather than exp cumulative hazard</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_no.opt">no.opt</code></td>
<td>
<p>not implemented</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_method">method</code></td>
<td>
<p>not implemented</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_augmentation">augmentation</code></td>
<td>
<p>not implemented</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_outcome">outcome</code></td>
<td>
<p>can be c(&quot;cif&quot;,&quot;rmst&quot;,&quot;rmst-cause&quot;)</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_model">model</code></td>
<td>
<p>not implemented, uses linear regression for augmentation</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_ydirect">Ydirect</code></td>
<td>
<p>use this Y instead of outcome constructed inside the program (e.g. I(T&lt; t, epsilon=1)), see binreg for more on this</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_return.dataw">return.dataw</code></td>
<td>
<p>to return weighted data for all treatment regimes</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_pi0">pi0</code></td>
<td>
<p>set up known randomization probabilities</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_pi1">pi1</code></td>
<td>
<p>set up known randomization probabilities</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_cens.time.fixed">cens.time.fixed</code></td>
<td>
<p>to use time-dependent weights for censoring estimation using weights</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_outcome.iid">outcome.iid</code></td>
<td>
<p>to get iid contribution from outcome model (here linear regression working models).</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_meancs">meanCs</code></td>
<td>
<p>(0) indicates that censoring augmentation is centered by CensAugment.times/n</p>
</td></tr>
<tr><td><code id="binregTSR_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The solved estimating eqution is 
</p>
<p style="text-align: center;"><code class="reqn">  (  I(min(T_i,t) &lt; G_i)/G_c(min(T_i ,t)) I(T \leq t, \epsilon=1 ) - AUG_0 - AUG_1 + AUG_C  -  p(i,j)) = 0 </code>
</p>

<p>where  using the covariates from augmentR0
</p>
<p style="text-align: center;"><code class="reqn"> AUG_0 = \frac{A_0(i) - \pi_0(i)}{ \pi_0(i)} X_0 \gamma_0</code>
</p>

<p>and  using the covariates from augmentR1
</p>
<p style="text-align: center;"><code class="reqn"> AUG_1 = \frac{A_0(i)}{\pi_0(i)} \frac{A_1(j) - \pi_1(j)}{ \pi_1(j)} X_1 \gamma_1</code>
</p>

<p>and   the censoring augmentation is 
</p>
<p style="text-align: center;"><code class="reqn">  AUG_C =  \int_0^t \gamma_c(s)^T (e(s) - \bar e(s))  \frac{1}{G_c(s) } dM_c(s) </code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn"> \gamma_c(s)</code>
</p>
<p> is chosen to minimize the variance given the dynamic  covariates specified by augmentC.
</p>
<p>In the observational case, we can use propensity score modelling and outcome modelling (using linear regression).
</p>
<p>Standard errors are estimated using the influence function  of all estimators and tests of differences can therefore be computed
subsequently.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ddf &lt;- mets:::gsim(200,covs=1,null=0,cens=1,ce=2)

bb &lt;- binregTSR(Event(entry,time,status)~+1+cluster(id),ddf$datat,time=2,cause=c(1),
        cens.code=0,treat.model0=A0.f~+1,treat.model1=A1.f~A0.f,
        augmentR1=~X11+X12+TR,augmentR0=~X01+X02,
        augmentC=~A01+A02+X01+X02+A11t+A12t+X11+X12+TR,
        response.code=2)
summary(bb) 
</code></pre>

<hr>
<h2 id='biprobit'>Bivariate Probit model</h2><span id='topic+biprobit'></span><span id='topic+biprobit.vector'></span><span id='topic+biprobit.time'></span>

<h3>Description</h3>

<p>Bivariate Probit model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biprobit(
  x,
  data,
  id,
  rho = ~1,
  num = NULL,
  strata = NULL,
  eqmarg = TRUE,
  indep = FALSE,
  weights = NULL,
  weights.fun = function(x) ifelse(any(x &lt;= 0), 0, max(x)),
  randomeffect = FALSE,
  vcov = "robust",
  pairs.only = FALSE,
  allmarg = !is.null(weights),
  control = list(trace = 0),
  messages = 1,
  constrain = NULL,
  table = pairs.only,
  p = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="biprobit_+3A_x">x</code></td>
<td>
<p>formula (or vector)</p>
</td></tr>
<tr><td><code id="biprobit_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="biprobit_+3A_id">id</code></td>
<td>
<p>The name of the column in the dataset containing the cluster id-variable.</p>
</td></tr>
<tr><td><code id="biprobit_+3A_rho">rho</code></td>
<td>
<p>Formula specifying the regression model for the dependence parameter</p>
</td></tr>
<tr><td><code id="biprobit_+3A_num">num</code></td>
<td>
<p>Optional name of order variable</p>
</td></tr>
<tr><td><code id="biprobit_+3A_strata">strata</code></td>
<td>
<p>Strata</p>
</td></tr>
<tr><td><code id="biprobit_+3A_eqmarg">eqmarg</code></td>
<td>
<p>If TRUE same marginals are assumed (exchangeable)</p>
</td></tr>
<tr><td><code id="biprobit_+3A_indep">indep</code></td>
<td>
<p>Independence</p>
</td></tr>
<tr><td><code id="biprobit_+3A_weights">weights</code></td>
<td>
<p>Weights</p>
</td></tr>
<tr><td><code id="biprobit_+3A_weights.fun">weights.fun</code></td>
<td>
<p>Function defining the bivariate weight in each cluster</p>
</td></tr>
<tr><td><code id="biprobit_+3A_randomeffect">randomeffect</code></td>
<td>
<p>If TRUE a random effect model is used (otherwise correlation parameter is estimated allowing for both negative and positive dependence)</p>
</td></tr>
<tr><td><code id="biprobit_+3A_vcov">vcov</code></td>
<td>
<p>Type of standard errors to be calculated</p>
</td></tr>
<tr><td><code id="biprobit_+3A_pairs.only">pairs.only</code></td>
<td>
<p>Include complete pairs only?</p>
</td></tr>
<tr><td><code id="biprobit_+3A_allmarg">allmarg</code></td>
<td>
<p>Should all marginal terms be included</p>
</td></tr>
<tr><td><code id="biprobit_+3A_control">control</code></td>
<td>
<p>Control argument parsed on to the optimization routine. Starting values may be parsed as '<code>start</code>'.</p>
</td></tr>
<tr><td><code id="biprobit_+3A_messages">messages</code></td>
<td>
<p>Control amount of messages shown</p>
</td></tr>
<tr><td><code id="biprobit_+3A_constrain">constrain</code></td>
<td>
<p>Vector of parameter constraints (NA where free). Use this to set an offset.</p>
</td></tr>
<tr><td><code id="biprobit_+3A_table">table</code></td>
<td>
<p>Type of estimation procedure</p>
</td></tr>
<tr><td><code id="biprobit_+3A_p">p</code></td>
<td>
<p>Parameter vector p in which to evaluate log-Likelihood and score function</p>
</td></tr>
<tr><td><code id="biprobit_+3A_...">...</code></td>
<td>
<p>Optional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(prt)
prt0 &lt;- subset(prt,country=="Denmark")
a &lt;- biprobit(cancer~1+zyg, ~1+zyg, data=prt0, id="id")
b &lt;- biprobit(cancer~1+zyg, ~1+zyg, data=prt0, id="id",pairs.only=TRUE)
predict(b,newdata=lava::Expand(prt,zyg=c("MZ")))
predict(b,newdata=lava::Expand(prt,zyg=c("MZ","DZ")))

 ## Reduce Ex.Timings
n &lt;- 2e3
x &lt;- sort(runif(n, -1, 1))
y &lt;- rmvn(n, c(0,0), rho=cbind(tanh(x)))&gt;0
d &lt;- data.frame(y1=y[,1], y2=y[,2], x=x)
dd &lt;- fast.reshape(d)

a &lt;- biprobit(y~1+x,rho=~1+x,data=dd,id="id")
summary(a, mean.contrast=c(1,.5), cor.contrast=c(1,.5))
with(predict(a,data.frame(x=seq(-1,1,by=.1))), plot(p00~x,type="l"))

pp &lt;- predict(a,data.frame(x=seq(-1,1,by=.1)),which=c(1))
plot(pp[,1]~pp$x, type="l", xlab="x", ylab="Concordance", lwd=2, xaxs="i")
lava::confband(pp$x,pp[,2],pp[,3],polygon=TRUE,lty=0,col=lava::Col(1))

pp &lt;- predict(a,data.frame(x=seq(-1,1,by=.1)),which=c(9)) ## rho
plot(pp[,1]~pp$x, type="l", xlab="x", ylab="Correlation", lwd=2, xaxs="i")
lava::confband(pp$x,pp[,2],pp[,3],polygon=TRUE,lty=0,col=lava::Col(1))
with(pp, lines(x,tanh(-x),lwd=2,lty=2))

xp &lt;- seq(-1,1,length.out=6); delta &lt;- mean(diff(xp))
a2 &lt;- biprobit(y~1+x,rho=~1+I(cut(x,breaks=xp)),data=dd,id="id")
pp2 &lt;- predict(a2,data.frame(x=xp[-1]-delta/2),which=c(9)) ## rho
lava::confband(pp2$x,pp2[,2],pp2[,3],center=pp2[,1])




## Time
## Not run: 
    a &lt;- biprobit.time(cancer~1, rho=~1+zyg, id="id", data=prt, eqmarg=TRUE,
                       cens.formula=Surv(time,status==0)~1,
                       breaks=seq(75,100,by=3),fix.censweights=TRUE)

    a &lt;- biprobit.time2(cancer~1+zyg, rho=~1+zyg, id="id", data=prt0, eqmarg=TRUE,
                       cens.formula=Surv(time,status==0)~zyg,
                       breaks=100)

    #a1 &lt;- biprobit.time2(cancer~1, rho=~1, id="id", data=subset(prt0,zyg=="MZ"), eqmarg=TRUE,
    #                   cens.formula=Surv(time,status==0)~1,
    #                   breaks=100,pairs.only=TRUE)

    #a2 &lt;- biprobit.time2(cancer~1, rho=~1, id="id", data=subset(prt0,zyg=="DZ"), eqmarg=TRUE,
    #                    cens.formula=Surv(time,status==0)~1,
    #                    breaks=100,pairs.only=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='blocksample'>Block sampling</h2><span id='topic+blocksample'></span><span id='topic+dsample'></span>

<h3>Description</h3>

<p>Sample blockwise from clustered data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blocksample(data, size, idvar = NULL, replace = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blocksample_+3A_data">data</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="blocksample_+3A_size">size</code></td>
<td>
<p>Size of samples</p>
</td></tr>
<tr><td><code id="blocksample_+3A_idvar">idvar</code></td>
<td>
<p>Column defining the clusters</p>
</td></tr>
<tr><td><code id="blocksample_+3A_replace">replace</code></td>
<td>
<p>Logical indicating wether to sample with replacement</p>
</td></tr>
<tr><td><code id="blocksample_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Original id is stored in the attribute 'id'
</p>


<h3>Value</h3>

<p><code>data.frame</code>
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
d &lt;- data.frame(x=rnorm(5), z=rnorm(5), id=c(4,10,10,5,5), v=rnorm(5))
(dd &lt;- blocksample(d,size=20,~id))
attributes(dd)$id

## Not run: 
blocksample(data.table::data.table(d),1e6,~id)

## End(Not run)


d &lt;- data.frame(x=c(1,rnorm(9)),
               z=rnorm(10),
               id=c(4,10,10,5,5,4,4,5,10,5),
               id2=c(1,1,2,1,2,1,1,1,1,2),
               v=rnorm(10))
dsample(d,~id, size=2)
dsample(d,.~id+id2)
dsample(d,x+z~id|x&gt;0,size=5)

</code></pre>

<hr>
<h2 id='bmt'>The Bone Marrow Transplant Data</h2><span id='topic+bmt'></span>

<h3>Description</h3>

<p>Bone marrow transplant data with 408 rows and 5 columns.
</p>


<h3>Format</h3>

<p>The data has 408 rows and 5 columns. </p>
 <dl>
<dt>cause</dt><dd><p>a
numeric vector code.  Survival status. 1: dead from treatment related
causes, 2: relapse , 0: censored.</p>
</dd> <dt>time</dt><dd><p> a numeric vector. Survival
time.  </p>
</dd> <dt>platelet</dt><dd><p>a numeric vector code. Plalelet 1: more than 100 x
<code class="reqn">10^9</code> per L, 0: less.</p>
</dd> <dt>tcell</dt><dd><p>a numeric vector. T-cell depleted
BMT 1:yes, 0:no.</p>
</dd> <dt>age</dt><dd><p>a numeric vector code. Age of patient, scaled
and centered ((age-35)/15).</p>
</dd> </dl>



<h3>Source</h3>

<p>Simulated data
</p>


<h3>References</h3>

<p>NN
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(bmt)
names(bmt)

</code></pre>

<hr>
<h2 id='Bootphreg'>Wild bootstrap for Cox PH regression</h2><span id='topic+Bootphreg'></span><span id='topic+pred.cif.boot'></span>

<h3>Description</h3>

<p>wild bootstrap for uniform bands for Cox models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bootphreg(
  formula,
  data,
  offset = NULL,
  weights = NULL,
  B = 1000,
  type = c("exp", "poisson", "normal"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bootphreg_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="Bootphreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="Bootphreg_+3A_offset">offset</code></td>
<td>
<p>offsets for cox model</p>
</td></tr>
<tr><td><code id="Bootphreg_+3A_weights">weights</code></td>
<td>
<p>weights for Cox score equations</p>
</td></tr>
<tr><td><code id="Bootphreg_+3A_b">B</code></td>
<td>
<p>bootstraps</p>
</td></tr>
<tr><td><code id="Bootphreg_+3A_type">type</code></td>
<td>
<p>distribution for multiplier</p>
</td></tr>
<tr><td><code id="Bootphreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst, Thomas Scheike
</p>


<h3>References</h3>

<p>Wild bootstrap based confidence intervals for multiplicative hazards models, 
Dobler, Pauly, and Scheike (2018),
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 n &lt;- 100
 x &lt;- 4*rnorm(n)
 time1 &lt;- 2*rexp(n)/exp(x*0.3)
 time2 &lt;- 2*rexp(n)/exp(x*(-0.3))
 status &lt;- ifelse(time1&lt;time2,1,2)
 time &lt;- pmin(time1,time2)
 rbin &lt;- rbinom(n,1,0.5)
 cc &lt;-rexp(n)*(rbin==1)+(rbin==0)*rep(3,n)
 status &lt;- ifelse(time &lt; cc,status,0)
 time  &lt;- ifelse(time &lt; cc,time,cc)
 data &lt;- data.frame(time=time,status=status,x=x)

 b1 &lt;- Bootphreg(Surv(time,status==1)~x,data,B=1000)
 b2 &lt;- Bootphreg(Surv(time,status==2)~x,data,B=1000)
 c1 &lt;- phreg(Surv(time,status==1)~x,data)
 c2 &lt;- phreg(Surv(time,status==2)~x,data)

 ### exp to make all bootstraps positive
 out &lt;- pred.cif.boot(b1,b2,c1,c2,gplot=0)

 cif.true &lt;- (1-exp(-out$time))*.5
 with(out,plot(time,cif,ylim=c(0,1),type="l"))
 lines(out$time,cif.true,col=3)
 with(out,plotConfRegion(time,band.EE,col=1))
 with(out,plotConfRegion(time,band.EE.log,col=3))
 with(out,plotConfRegion(time,band.EE.log.o,col=2))

</code></pre>

<hr>
<h2 id='bptwin'>Liability model for twin data</h2><span id='topic+bptwin'></span><span id='topic+twinlm.time'></span><span id='topic+bptwin.time'></span>

<h3>Description</h3>

<p>Liability-threshold model for twin data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bptwin(
  x,
  data,
  id,
  zyg,
  DZ,
  group = NULL,
  num = NULL,
  weights = NULL,
  weights.fun = function(x) ifelse(any(x &lt;= 0), 0, max(x)),
  strata = NULL,
  messages = 1,
  control = list(trace = 0),
  type = "ace",
  eqmean = TRUE,
  pairs.only = FALSE,
  samecens = TRUE,
  allmarg = samecens &amp; !is.null(weights),
  stderr = TRUE,
  robustvar = TRUE,
  p,
  indiv = FALSE,
  constrain,
  varlink,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bptwin_+3A_x">x</code></td>
<td>
<p>Formula specifying effects of covariates on the response.</p>
</td></tr>
<tr><td><code id="bptwin_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with one observation pr row. In
addition a column with the zygosity (DZ or MZ given as a factor) of
each individual much be
specified as well as a twin id variable giving a unique pair of
numbers/factors to each twin pair.</p>
</td></tr>
<tr><td><code id="bptwin_+3A_id">id</code></td>
<td>
<p>The name of the column in the dataset containing the twin-id variable.</p>
</td></tr>
<tr><td><code id="bptwin_+3A_zyg">zyg</code></td>
<td>
<p>The name of the column in the dataset containing the
zygosity variable.</p>
</td></tr>
<tr><td><code id="bptwin_+3A_dz">DZ</code></td>
<td>
<p>Character defining the level in the zyg variable
corresponding to the dyzogitic twins.</p>
</td></tr>
<tr><td><code id="bptwin_+3A_group">group</code></td>
<td>
<p>Optional. Variable name defining group for interaction analysis (e.g., gender)</p>
</td></tr>
<tr><td><code id="bptwin_+3A_num">num</code></td>
<td>
<p>Optional twin number variable</p>
</td></tr>
<tr><td><code id="bptwin_+3A_weights">weights</code></td>
<td>
<p>Weight matrix if needed by the chosen estimator (IPCW)</p>
</td></tr>
<tr><td><code id="bptwin_+3A_weights.fun">weights.fun</code></td>
<td>
<p>Function defining a single weight each individual/cluster</p>
</td></tr>
<tr><td><code id="bptwin_+3A_strata">strata</code></td>
<td>
<p>Strata</p>
</td></tr>
<tr><td><code id="bptwin_+3A_messages">messages</code></td>
<td>
<p>Control amount of messages shown</p>
</td></tr>
<tr><td><code id="bptwin_+3A_control">control</code></td>
<td>
<p>Control argument parsed on to the optimization routine. Starting values may be parsed as '<code>start</code>'.</p>
</td></tr>
<tr><td><code id="bptwin_+3A_type">type</code></td>
<td>
<p>Character defining the type of analysis to be
performed. Should be a subset of &quot;acde&quot; (additive genetic factors, common
environmental factors, dominant
genetic factors, unique environmental factors).</p>
</td></tr>
<tr><td><code id="bptwin_+3A_eqmean">eqmean</code></td>
<td>
<p>Equal means (with type=&quot;cor&quot;)?</p>
</td></tr>
<tr><td><code id="bptwin_+3A_pairs.only">pairs.only</code></td>
<td>
<p>Include complete pairs only?</p>
</td></tr>
<tr><td><code id="bptwin_+3A_samecens">samecens</code></td>
<td>
<p>Same censoring</p>
</td></tr>
<tr><td><code id="bptwin_+3A_allmarg">allmarg</code></td>
<td>
<p>Should all marginal terms be included</p>
</td></tr>
<tr><td><code id="bptwin_+3A_stderr">stderr</code></td>
<td>
<p>Should standard errors be calculated?</p>
</td></tr>
<tr><td><code id="bptwin_+3A_robustvar">robustvar</code></td>
<td>
<p>If TRUE robust (sandwich) variance estimates of the variance are used</p>
</td></tr>
<tr><td><code id="bptwin_+3A_p">p</code></td>
<td>
<p>Parameter vector p in which to evaluate log-Likelihood and score function</p>
</td></tr>
<tr><td><code id="bptwin_+3A_indiv">indiv</code></td>
<td>
<p>If TRUE the score and log-Likelihood contribution of each twin-pair</p>
</td></tr>
<tr><td><code id="bptwin_+3A_constrain">constrain</code></td>
<td>
<p>Development argument</p>
</td></tr>
<tr><td><code id="bptwin_+3A_varlink">varlink</code></td>
<td>
<p>Link function for variance parameters</p>
</td></tr>
<tr><td><code id="bptwin_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>See Also</h3>

<p><code><a href="#topic+twinlm">twinlm</a></code>, <code><a href="#topic+twinlm.time">twinlm.time</a></code>, <code><a href="#topic+twinlm.strata">twinlm.strata</a></code>, <code><a href="#topic+twinsim">twinsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(twinstut)
b0 &lt;- bptwin(stutter~sex,
             data=droplevels(subset(twinstut,zyg%in%c("mz","dz"))),
             id="tvparnr",zyg="zyg",DZ="dz",type="ae")
summary(b0)
</code></pre>

<hr>
<h2 id='calgb8923'>CALGB 8923, twostage randomization SMART design</h2><span id='topic+calgb8923'></span>

<h3>Description</h3>

<p>Data from CALGB 8923
</p>


<h3>Format</h3>

<p>Data from smart design
</p>


<h3>Source</h3>

<p>https://github.com/ycchao/code_Joint_model_SMART
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calgb8923)
</code></pre>

<hr>
<h2 id='casewise'>Estimates the casewise concordance based on Concordance and marginal estimate using prodlim but no testing</h2><span id='topic+casewise'></span>

<h3>Description</h3>

<p>.. content for description (no empty lines) ..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>casewise(conc, marg, cause.marg)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="casewise_+3A_conc">conc</code></td>
<td>
<p>Concordance</p>
</td></tr>
<tr><td><code id="casewise_+3A_marg">marg</code></td>
<td>
<p>Marginal estimate</p>
</td></tr>
<tr><td><code id="casewise_+3A_cause.marg">cause.marg</code></td>
<td>
<p>specififes which cause that should be used for marginal cif based on prodlim</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Reduce Ex.Timings
library(prodlim)
data(prt);
prt &lt;- force.same.cens(prt,cause="status")

### marginal cumulative incidence of prostate cancer##' 
outm &lt;- prodlim(Hist(time,status)~+1,data=prt)

times &lt;- 60:100
cifmz &lt;- predict(outm,cause=2,time=times,newdata=data.frame(zyg="MZ")) ## cause is 2 (second cause) 
cifdz &lt;- predict(outm,cause=2,time=times,newdata=data.frame(zyg="DZ"))

### concordance for MZ and DZ twins
cc &lt;- bicomprisk(Event(time,status)~strata(zyg)+id(id),data=prt,cause=c(2,2),prodlim=TRUE)
cdz &lt;- cc$model$"DZ"
cmz &lt;- cc$model$"MZ"

cdz &lt;- casewise(cdz,outm,cause.marg=2) 
cmz &lt;- casewise(cmz,outm,cause.marg=2)

plot(cmz,ci=NULL,ylim=c(0,0.5),xlim=c(60,100),legend=TRUE,col=c(3,2,1))
par(new=TRUE)
plot(cdz,ci=NULL,ylim=c(0,0.5),xlim=c(60,100),legend=TRUE)
summary(cdz)
summary(cmz)

</code></pre>

<hr>
<h2 id='casewise.test'>Estimates the casewise concordance based on Concordance and marginal estimate using timereg and performs test for independence</h2><span id='topic+casewise.test'></span><span id='topic+slope.process'></span><span id='topic+casewise.bin'></span>

<h3>Description</h3>

<p>Estimates the casewise concordance based on Concordance and marginal estimate using timereg and performs test for independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>casewise.test(conc, marg, test = "no-test", p = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="casewise.test_+3A_conc">conc</code></td>
<td>
<p>Concordance</p>
</td></tr>
<tr><td><code id="casewise.test_+3A_marg">marg</code></td>
<td>
<p>Marginal estimate</p>
</td></tr>
<tr><td><code id="casewise.test_+3A_test">test</code></td>
<td>
<p>Type of test for independence assumption. &quot;conc&quot; makes test on concordance scale and &quot;case&quot; means a test on the casewise concordance</p>
</td></tr>
<tr><td><code id="casewise.test_+3A_p">p</code></td>
<td>
<p>check that marginal probability is greater at some point than p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses cluster based conservative standard errors for marginal and sometimes only the uncertainty of the concordance estimates. This works prettey well, alternatively one can use also the 
funcions Casewise for a specific time point
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Reduce Ex.Timings
library("timereg")
data("prt",package="mets");
prt &lt;- force.same.cens(prt,cause="status")

prt &lt;- prt[which(prt$id %in% sample(unique(prt$id),7500)),]
### marginal cumulative incidence of prostate cancer
times &lt;- seq(60,100,by=2)
outm &lt;- timereg::comp.risk(Event(time,status)~+1,data=prt,cause=2,times=times)

cifmz &lt;- predict(outm,X=1,uniform=0,resample.iid=1)
cifdz &lt;- predict(outm,X=1,uniform=0,resample.iid=1)

### concordance for MZ and DZ twins
cc &lt;- bicomprisk(Event(time,status)~strata(zyg)+id(id),
                 data=prt,cause=c(2,2))
cdz &lt;- cc$model$"DZ"
cmz &lt;- cc$model$"MZ"

### To compute casewise cluster argument must be passed on,
###  here with a max of 100 to limit comp-time
outm &lt;- timereg::comp.risk(Event(time,status)~+1,data=prt,
                 cause=2,times=times,max.clust=100)
cifmz &lt;- predict(outm,X=1,uniform=0,resample.iid=1)
cc &lt;- bicomprisk(Event(time,status)~strata(zyg)+id(id),data=prt,
                cause=c(2,2),se.clusters=outm$clusters)
cdz &lt;- cc$model$"DZ"
cmz &lt;- cc$model$"MZ"

cdz &lt;- casewise.test(cdz,cifmz,test="case") ## test based on casewise
cmz &lt;- casewise.test(cmz,cifmz,test="conc") ## based on concordance

plot(cmz,ylim=c(0,0.7),xlim=c(60,100))
par(new=TRUE)
plot(cdz,ylim=c(0,0.7),xlim=c(60,100))

slope.process(cdz$casewise[,1],cdz$casewise[,2],iid=cdz$casewise.iid)

slope.process(cmz$casewise[,1],cmz$casewise[,2],iid=cmz$casewise.iid)


</code></pre>

<hr>
<h2 id='cif'>Cumulative incidence with robust standard errors</h2><span id='topic+cif'></span>

<h3>Description</h3>

<p>Cumulative incidence with robust standard errors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cif(formula, data = data, cause = 1, cens.code = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cif_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="cif_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="cif_+3A_cause">cause</code></td>
<td>
<p>NULL looks at all, otherwise specify which cause to consider</p>
</td></tr>
<tr><td><code id="cif_+3A_cens.code">cens.code</code></td>
<td>
<p>censoring code &quot;0&quot; is default</p>
</td></tr>
<tr><td><code id="cif_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TRACE)
TRACE$cluster &lt;- sample(1:100,1878,replace=TRUE)
out1 &lt;- cif(Event(time,status)~+1,data=TRACE,cause=9)
out2 &lt;- cif(Event(time,status)~+1+cluster(cluster),data=TRACE,cause=9)

out1 &lt;- cif(Event(time,status)~strata(vf,chf),data=TRACE,cause=9)
out2 &lt;- cif(Event(time,status)~strata(vf,chf)+cluster(cluster),data=TRACE,cause=9)

par(mfrow=c(1,2))
bplot(out1,se=TRUE)
bplot(out2,se=TRUE)
</code></pre>

<hr>
<h2 id='cifreg'>CIF regression</h2><span id='topic+cifreg'></span><span id='topic+vecAllStrata'></span><span id='topic+diffstrata'></span><span id='topic+IIDbaseline.cifreg'></span><span id='topic+FGprediid'></span><span id='topic+indexstratarightR'></span><span id='topic+gofFG'></span>

<h3>Description</h3>

<p>CIF logistic for propodds=1 default
CIF Fine-Gray (cloglog) regression for propodds=NULL
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cifreg(
  formula,
  data = data,
  cause = 1,
  cens.code = 0,
  cens.model = ~1,
  weights = NULL,
  offset = NULL,
  Gc = NULL,
  propodds = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cifreg_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event' outcome</p>
</td></tr>
<tr><td><code id="cifreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="cifreg_+3A_cause">cause</code></td>
<td>
<p>of interest</p>
</td></tr>
<tr><td><code id="cifreg_+3A_cens.code">cens.code</code></td>
<td>
<p>code of censoring</p>
</td></tr>
<tr><td><code id="cifreg_+3A_cens.model">cens.model</code></td>
<td>
<p>for stratified Cox model without covariates</p>
</td></tr>
<tr><td><code id="cifreg_+3A_weights">weights</code></td>
<td>
<p>weights for FG score equations</p>
</td></tr>
<tr><td><code id="cifreg_+3A_offset">offset</code></td>
<td>
<p>offsets for FG  model</p>
</td></tr>
<tr><td><code id="cifreg_+3A_gc">Gc</code></td>
<td>
<p>censoring weights for time argument, default is to calculate these with a Kaplan-Meier estimator, should then give G_c(T_i-)</p>
</td></tr>
<tr><td><code id="cifreg_+3A_propodds">propodds</code></td>
<td>
<p>1 is logistic model, NULL is fine-gray model</p>
</td></tr>
<tr><td><code id="cifreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For FG model:
</p>
<p style="text-align: center;"><code class="reqn">
\int (X - E ) Y_1(t) w(t) dM_1
</code>
</p>

<p>is computed and summed over clusters  and returned multiplied with inverse
of second derivative as iid.naive. Where </p>
<p style="text-align: center;"><code class="reqn">w(t) = G(t) (I(T_i \wedge t &lt; C_i)/G_c(T_i \wedge t))</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">E(t) = S_1(t)/S_0(t)</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">S_j(t) = \sum X_i^j Y_{i1}(t) w_i(t) \exp(X_i^T \beta)</code>
</p>

<p>The iid decomposition of the beta's, however, also have a censoring term that is also
is computed and added to UUiid (still scaled with inverse second derivative)
</p>
<p style="text-align: center;"><code class="reqn">
\int (X - E ) Y_1(t) w(t) dM_1 + \int q(s)/p(s) dM_c
</code>
</p>

<p>and returned as iid
</p>
<p>For logistic link standard errors are slightly to small since uncertainty from recursive baseline is not considered, so for smaller
data-sets it is recommended to use the prop.odds.subdist of timereg that is also more efficient due to use of different weights for
the estimating equations. Alternatively, one can also bootstrap the standard errors.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## data with no ties
data(bmt,package="timereg")
bmt$time &lt;- bmt$time+runif(nrow(bmt))*0.01
bmt$id &lt;- 1:nrow(bmt)

## logistic link  OR interpretation
ll=cifreg(Event(time,cause)~tcell+platelet+age,data=bmt,cause=1)
summary(ll)
plot(ll)
nd &lt;- data.frame(tcell=c(1,0),platelet=0,age=0)
pll &lt;- predict(ll,nd)
plot(pll)

## Fine-Gray model
fg=cifreg(Event(time,cause)~tcell+platelet+age,data=bmt,cause=1,propodds=NULL)
summary(fg)
plot(fg)
nd &lt;- data.frame(tcell=c(1,0),platelet=0,age=0)
pfg &lt;- predict(fg,nd)
plot(pfg)

## not run to avoid timing issues
## gofFG(Event(time,cause)~tcell+platelet+age,data=bmt,cause=1)

sfg &lt;- cifreg(Event(time,cause)~strata(tcell)+platelet+age,data=bmt,cause=1,propodds=NULL)
summary(sfg)
plot(sfg)

### predictions with CI based on iid decomposition of baseline and beta
fg &lt;- cifreg(Event(time,cause)~tcell+platelet+age,data=bmt,cause=1,propodds=NULL,cox.prep=TRUE)
Biid &lt;- IIDbaseline.cifreg(fg,time=20)
FGprediid(Biid,bmt[1:5,])

</code></pre>

<hr>
<h2 id='ClaytonOakes'>Clayton-Oakes model with piece-wise constant hazards</h2><span id='topic+ClaytonOakes'></span>

<h3>Description</h3>

<p>Clayton-Oakes frailty model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClaytonOakes(
  formula,
  data = parent.frame(),
  cluster,
  var.formula = ~1,
  cuts = NULL,
  type = "piecewise",
  start,
  control = list(),
  var.invlink = exp,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ClaytonOakes_+3A_formula">formula</code></td>
<td>
<p>formula specifying the marginal proportional (piecewise constant) hazard structure with the right-hand-side being a survival object (Surv) specifying the entry time (optional), the follow-up time, and event/censoring status at follow-up. The clustering can be specified using the special function <code>cluster</code> (see example below).</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_data">data</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_cluster">cluster</code></td>
<td>
<p>Variable defining the clustering (if not given in the formula)</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_var.formula">var.formula</code></td>
<td>
<p>Formula specifying the variance component structure (if not given via the cluster special function in the formula) using a linear model with log-link.</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_cuts">cuts</code></td>
<td>
<p>Cut points defining the piecewise constant hazard</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_type">type</code></td>
<td>
<p>when equal to <code>two.stage</code>, the Clayton-Oakes-Glidden estimator will be calculated via the <code>timereg</code> package</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_start">start</code></td>
<td>
<p>Optional starting values</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_control">control</code></td>
<td>
<p>Control parameters to the optimization routine</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_var.invlink">var.invlink</code></td>
<td>
<p>Inverse link function for variance structure model</p>
</td></tr>
<tr><td><code id="ClaytonOakes_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
d &lt;- subset(simClaytonOakes(500,4,2,1,stoptime=2,left=2),truncated)
e &lt;- ClaytonOakes(survival::Surv(lefttime,time,status)~x+cluster(~1,cluster),
                  cuts=c(0,0.5,1,2),data=d)
e

d2 &lt;- simClaytonOakes(500,4,2,1,stoptime=2,left=0)
d2$z &lt;- rep(1,nrow(d2)); d2$z[d2$cluster%in%sample(d2$cluster,100)] &lt;- 0
## Marginal=Cox Proportional Hazards model:
## ts &lt;- ClaytonOakes(survival::Surv(time,status)~timereg::prop(x)+cluster(~1,cluster),
##                   data=d2,type="two.stage")
## Marginal=Aalens additive model:
## ts2 &lt;- ClaytonOakes(survival::Surv(time,status)~x+cluster(~1,cluster),
##                    data=d2,type="two.stage")
## Marginal=Piecewise constant:
e2 &lt;- ClaytonOakes(survival::Surv(time,status)~x+cluster(~-1+factor(z),cluster),
                   cuts=c(0,0.5,1,2),data=d2)
e2


e0 &lt;- ClaytonOakes(survival::Surv(time,status)~cluster(~-1+factor(z),cluster),
                   cuts=c(0,0.5,1,2),data=d2)
##ts0 &lt;- ClaytonOakes(survival::Surv(time,status)~cluster(~1,cluster),
##                   data=d2,type="two.stage")
##plot(ts0)
plot(e0)

e3 &lt;- ClaytonOakes(survival::Surv(time,status)~x+cluster(~1,cluster),cuts=c(0,0.5,1,2),
                   data=d,var.invlink=identity)
e3
</code></pre>

<hr>
<h2 id='cluster.index'>Finds subjects related to same cluster</h2><span id='topic+cluster.index'></span><span id='topic+countID'></span><span id='topic+pairRisk'></span><span id='topic+mystrata'></span><span id='topic+mystrata2index'></span>

<h3>Description</h3>

<p>Finds subjects related to same cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster.index(
  clusters,
  index.type = FALSE,
  num = NULL,
  Rindex = 0,
  mat = NULL,
  return.all = FALSE,
  code.na = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster.index_+3A_clusters">clusters</code></td>
<td>
<p>list of indeces</p>
</td></tr>
<tr><td><code id="cluster.index_+3A_index.type">index.type</code></td>
<td>
<p>if TRUE then already list of integers of index.type</p>
</td></tr>
<tr><td><code id="cluster.index_+3A_num">num</code></td>
<td>
<p>to get numbering according to num-type in separate columns</p>
</td></tr>
<tr><td><code id="cluster.index_+3A_rindex">Rindex</code></td>
<td>
<p>index starts with 1, in C is it is 0</p>
</td></tr>
<tr><td><code id="cluster.index_+3A_mat">mat</code></td>
<td>
<p>to return matrix of indeces</p>
</td></tr>
<tr><td><code id="cluster.index_+3A_return.all">return.all</code></td>
<td>
<p>return all arguments</p>
</td></tr>
<tr><td><code id="cluster.index_+3A_code.na">code.na</code></td>
<td>
<p>how to code missing values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Holst, Thomas Scheike
</p>


<h3>References</h3>

<p>Cluster indeces
</p>


<h3>See Also</h3>

<p>familycluster.index familyclusterWithProbands.index
</p>


<h3>Examples</h3>

<pre><code class='language-R'>i&lt;-c(1,1,2,2,1,3)
d&lt;- cluster.index(i)
print(d)

type&lt;-c("m","f","m","c","c","c")
d&lt;- cluster.index(i,num=type,Rindex=1)
print(d)
</code></pre>

<hr>
<h2 id='concordanceCor'>Concordance Computes concordance and casewise concordance</h2><span id='topic+concordanceCor'></span><span id='topic+concordance.cor'></span>

<h3>Description</h3>

<p>Concordance for Twins
</p>


<h3>Usage</h3>

<pre><code class='language-R'>concordanceCor(
  object,
  cif1,
  cif2 = NULL,
  messages = TRUE,
  model = NULL,
  coefs = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="concordanceCor_+3A_object">object</code></td>
<td>
<p>Output from the cor.cif, rr.cif or or.cif function</p>
</td></tr>
<tr><td><code id="concordanceCor_+3A_cif1">cif1</code></td>
<td>
<p>Marginal cumulative incidence</p>
</td></tr>
<tr><td><code id="concordanceCor_+3A_cif2">cif2</code></td>
<td>
<p>Marginal cumulative incidence of other cause (cause2) if  it is different from cause1</p>
</td></tr>
<tr><td><code id="concordanceCor_+3A_messages">messages</code></td>
<td>
<p>To print messages</p>
</td></tr>
<tr><td><code id="concordanceCor_+3A_model">model</code></td>
<td>
<p>Specfifies wich model that is considered if object not given.</p>
</td></tr>
<tr><td><code id="concordanceCor_+3A_coefs">coefs</code></td>
<td>
<p>Specfifies  dependence parameters if object is not given.</p>
</td></tr>
<tr><td><code id="concordanceCor_+3A_...">...</code></td>
<td>
<p>Extra arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concordance is the probability that both twins have experienced the 
event of interest and is defined as 
</p>
<p style="text-align: center;"><code class="reqn">
 cor(t) = P(T_1 \leq t, \epsilon_1 =1 , T_2 \leq t, \epsilon_2=1) 
 </code>
</p>

<p>Similarly, the casewise concordance is 
</p>
<p style="text-align: center;"><code class="reqn">
 casewise(t) = \frac{cor(t)}{P(T_1 \leq t, \epsilon_1=1) }
</code>
</p>

<p>that is the probability that twin &quot;2&quot; has the event given that twins &quot;1&quot; has.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Estimating twin concordance for bivariate competing risks twin data
Thomas H. Scheike, Klaus K. Holst and Jacob B. Hjelmborg, 
Statistics in Medicine 2014, 1193-1204
</p>
<p>Estimating Twin Pair Concordance for Age of Onset.
Thomas H. Scheike, Jacob V B Hjelmborg, Klaus K. Holst, 2015 
in Behavior genetics DOI:10.1007/s10519-015-9729-3
</p>

<hr>
<h2 id='cor.cif'>Cross-odds-ratio, OR or RR risk regression for competing risks</h2><span id='topic+cor.cif'></span><span id='topic+or.cif'></span><span id='topic+rr.cif'></span>

<h3>Description</h3>

<p>Fits a parametric model for the log-cross-odds-ratio for the 
predictive effect of for the cumulative incidence curves for <code class="reqn">T_1</code> 
experiencing cause i given that <code class="reqn">T_2</code> has experienced a cause k :
</p>
<p style="text-align: center;"><code class="reqn">
\log(COR(i|k))  =  h(\theta,z_1,i,z_2,k,t)=_{default}  \theta^T z =  
</code>
</p>

<p>with the log cross odds ratio being 
</p>
<p style="text-align: center;"><code class="reqn">
COR(i|k) = 
\frac{O(T_1 \leq t,cause_1=i | T_2 \leq t,cause_2=k)}{
O(T_1 \leq t,cause_1=i)}  
</code>
</p>

<p>the conditional odds divided by the unconditional odds, with the odds
being, respectively 
</p>
<p style="text-align: center;"><code class="reqn">
O(T_1 \leq t,cause_1=i | T_2 \leq t,cause_1=k) = 
\frac{
P_x(T_1 \leq t,cause_1=i | T_2 \leq t,cause_2=k)}{
P_x((T_1 \leq t,cause_1=i)^c | T_2 \leq t,cause_2=k)}
</code>
</p>

<p>and 
</p>
<p style="text-align: center;"><code class="reqn">
O(T_1 \leq t,cause_1=i) = 
\frac{P_x(T_1 \leq t,cause_1=i )}{P_x((T_1 \leq t,cause_1=i)^c )}.
</code>
</p>

<p>Here <code class="reqn">B^c</code> is the complement event of <code class="reqn">B</code>,
<code class="reqn">P_x</code> is the distribution given covariates 
(<code class="reqn">x</code> are subject specific and <code class="reqn">z</code> are cluster specific covariates), and 
<code class="reqn">h()</code> is a function that is the simple identity 
<code class="reqn">\theta^T z</code> by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.cif(
  cif,
  data,
  cause = NULL,
  times = NULL,
  cause1 = 1,
  cause2 = 1,
  cens.code = NULL,
  cens.model = "KM",
  Nit = 40,
  detail = 0,
  clusters = NULL,
  theta = NULL,
  theta.des = NULL,
  step = 1,
  sym = 0,
  weights = NULL,
  par.func = NULL,
  dpar.func = NULL,
  dimpar = NULL,
  score.method = "nlminb",
  same.cens = FALSE,
  censoring.weights = NULL,
  silent = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cor.cif_+3A_cif">cif</code></td>
<td>
<p>a model object from the timereg::comp.risk function with the
marginal cumulative incidence of cause1, i.e., the event of interest, and whose
odds the comparision is compared to the conditional odds given cause2</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_data">data</code></td>
<td>
<p>a data.frame with the variables.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_cause">cause</code></td>
<td>
<p>specifies the causes  related to the death
times, the value cens.code is the censoring value. When missing it comes from marginal cif.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_times">times</code></td>
<td>
<p>time-vector that specifies the times used for the estimating euqations for the cross-odds-ratio estimation.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_cause1">cause1</code></td>
<td>
<p>specificies the cause considered.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_cause2">cause2</code></td>
<td>
<p>specificies the cause that is conditioned on.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_cens.code">cens.code</code></td>
<td>
<p>specificies the code for the censoring if NULL then uses the one from the marginal cif model.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_cens.model">cens.model</code></td>
<td>
<p>specified which model to use for the ICPW, KM is Kaplan-Meier alternatively it may be &quot;cox&quot;</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_nit">Nit</code></td>
<td>
<p>number of iterations for Newton-Raphson algorithm.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_detail">detail</code></td>
<td>
<p>if 0 no details are printed during iterations, if 1 details are given.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_clusters">clusters</code></td>
<td>
<p>specifies the cluster structure.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_theta">theta</code></td>
<td>
<p>specifies starting values for the cross-odds-ratio parameters of the model.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_theta.des">theta.des</code></td>
<td>
<p>specifies a regression design for the cross-odds-ratio parameters.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_step">step</code></td>
<td>
<p>specifies the step size for the Newton-Raphson algorithm.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_sym">sym</code></td>
<td>
<p>specifies if symmetry is used in the model.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_weights">weights</code></td>
<td>
<p>weights for estimating equations.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_par.func">par.func</code></td>
<td>
<p>parfunc</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_dpar.func">dpar.func</code></td>
<td>
<p>dparfunc</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_dimpar">dimpar</code></td>
<td>
<p>dimpar</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_score.method">score.method</code></td>
<td>
<p>&quot;nlminb&quot;, can also use &quot;nr&quot;.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_same.cens">same.cens</code></td>
<td>
<p>if true then censoring within clusters are assumed to be the same variable, default is independent censoring.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_censoring.weights">censoring.weights</code></td>
<td>
<p>these probabilities are used for the bivariate censoring dist.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_silent">silent</code></td>
<td>
<p>1 to suppress output about convergence related issues.</p>
</td></tr>
<tr><td><code id="cor.cif_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The OR dependence measure is given by 
</p>
<p style="text-align: center;"><code class="reqn">
OR(i,k) = 
\log ( 
\frac{O(T_1 \leq t,cause_1=i | T_2 \leq t,cause_2=k)}{
O(T_1 \leq t,cause_1=i) | T_2 \leq t,cause_2=k)}  
</code>
</p>

<p>This measure is numerically more stabile than the COR measure, and is symetric in i,k.
</p>
<p>The RR dependence measure is given by 
</p>
<p style="text-align: center;"><code class="reqn">
RR(i,k) = 
\log ( 
\frac{P(T_1 \leq t,cause_1=i , T_2 \leq t,cause_2=k)}{
P(T_1 \leq t,cause_1=i) P(T_2 \leq t,cause_2=k)}  
</code>
</p>

<p>This measure is numerically more stabile than the COR measure, and is symetric in i,k.
</p>
<p>The model is fitted under symmetry (sym=1), i.e., such that it is assumed 
that <code class="reqn">T_1</code> and <code class="reqn">T_2</code> can be interchanged and leads to
the same cross-odd-ratio (i.e.
<code class="reqn">COR(i|k) = COR(k|i))</code>, 
as would be expected for twins 
or without symmetry as might be the case with mothers and daughters (sym=0). 
</p>
<p><code class="reqn">h()</code> may be specified as an R-function of the parameters, 
see example below, but the default is that it is simply <code class="reqn">\theta^T z</code>.
</p>


<h3>Value</h3>

<p>returns an object of type 'cor'. With the following arguments:
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>estimate of proportional odds parameters of model.</p>
</td></tr>
<tr><td><code>var.theta</code></td>
<td>
<p>variance for gamma.  </p>
</td></tr>
<tr><td><code>hess</code></td>
<td>
<p>the derivative of the used score.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>scores at final stage.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>scores at final stage.</p>
</td></tr>
<tr><td><code>theta.iid</code></td>
<td>
<p>matrix of iid decomposition of parametric effects.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Cross odds ratio Modelling of dependence for
Multivariate Competing Risks Data, Scheike and Sun (2012), Biostatistics. 
</p>
<p>A Semiparametric Random Effects Model for Multivariate Competing Risks Data,
Scheike, Zhang, Sun, Jensen (2010), Biometrika.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("timereg")
data(multcif);
multcif$cause[multcif$cause==0] &lt;- 2
zyg &lt;- rep(rbinom(200,1,0.5),each=2)
theta.des &lt;- model.matrix(~-1+factor(zyg))

times=seq(0.05,1,by=0.05) # to speed up computations use only these time-points
add &lt;- timereg::comp.risk(Event(time,cause)~+1+cluster(id),data=multcif,cause=1,
               n.sim=0,times=times,model="fg",max.clust=NULL)
add2 &lt;- timereg::comp.risk(Event(time,cause)~+1+cluster(id),data=multcif,cause=2,
               n.sim=0,times=times,model="fg",max.clust=NULL)

out1 &lt;- cor.cif(add,data=multcif,cause1=1,cause2=1)
summary(out1)

out2 &lt;- cor.cif(add,data=multcif,cause1=1,cause2=1,theta.des=theta.des)
summary(out2)

##out3 &lt;- cor.cif(add,data=multcif,cause1=1,cause2=2,cif2=add2)
##summary(out3)
###########################################################
# investigating further models using parfunc and dparfunc
###########################################################
 ## Reduce Ex.Timings
set.seed(100)
prt&lt;-simnordic.random(2000,cordz=2,cormz=5)
prt$status &lt;-prt$cause
table(prt$status)

times &lt;- seq(40,100,by=10)
cifmod &lt;- timereg::comp.risk(Event(time,cause)~+1+cluster(id),data=prt,
                    cause=1,n.sim=0,
                    times=times,conservative=1,max.clust=NULL,model="fg")
theta.des &lt;- model.matrix(~-1+factor(zyg),data=prt)

parfunc &lt;- function(par,t,pardes)
{
par &lt;- pardes %*% c(par[1],par[2]) +
       pardes %*% c( par[3]*(t-60)/12,par[4]*(t-60)/12)
par
}
head(parfunc(c(0.1,1,0.1,1),50,theta.des))

dparfunc &lt;- function(par,t,pardes)
{
dpar &lt;- cbind(pardes, t(t(pardes) * c( (t-60)/12,(t-60)/12)) )
dpar
}
head(dparfunc(c(0.1,1,0.1,1),50,theta.des))

names(prt)
or1 &lt;- or.cif(cifmod,data=prt,cause1=1,cause2=1,theta.des=theta.des,
              same.cens=TRUE,theta=c(0.6,1.1,0.1,0.1),
              par.func=parfunc,dpar.func=dparfunc,dimpar=4,
              score.method="nr",detail=1)
summary(or1)

 cor1 &lt;- cor.cif(cifmod,data=prt,cause1=1,cause2=1,theta.des=theta.des,
                 same.cens=TRUE,theta=c(0.5,1.0,0.1,0.1),
                 par.func=parfunc,dpar.func=dparfunc,dimpar=4,
                 control=list(trace=TRUE),detail=1)
summary(cor1)

### piecewise contant OR model
gparfunc &lt;- function(par,t,pardes)
{
	cuts &lt;- c(0,80,90,120)
	grop &lt;- diff(t&lt;cuts)
paru  &lt;- (pardes[,1]==1) * sum(grop*par[1:3]) +
    (pardes[,2]==1) * sum(grop*par[4:6])
paru
}

dgparfunc &lt;- function(par,t,pardes)
{
	cuts &lt;- c(0,80,90,120)
	grop &lt;- diff(t&lt;cuts)
par1 &lt;- matrix(c(grop),nrow(pardes),length(grop),byrow=TRUE)
parmz &lt;- par1* (pardes[,1]==1)
pardz &lt;- (pardes[,2]==1) * par1
dpar &lt;- cbind( parmz,pardz)
dpar
}
head(dgparfunc(rep(0.1,6),50,theta.des))
head(gparfunc(rep(0.1,6),50,theta.des))

or1g &lt;- or.cif(cifmod,data=prt,cause1=1,cause2=1,
               theta.des=theta.des, same.cens=TRUE,
               par.func=gparfunc,dpar.func=dgparfunc,
               dimpar=6,score.method="nr",detail=1)
summary(or1g)
names(or1g)
head(or1g$theta.iid)

</code></pre>

<hr>
<h2 id='count.history'>Counts the number of previous events of two types for recurrent events processes</h2><span id='topic+count.history'></span><span id='topic+count.historyVar'></span>

<h3>Description</h3>

<p>Counts the number of previous events of two types for recurrent events processes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count.history(
  data,
  status = "status",
  id = "id",
  types = 1:2,
  names.count = "Count",
  lag = TRUE,
  multitype = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="count.history_+3A_data">data</code></td>
<td>
<p>data-frame</p>
</td></tr>
<tr><td><code id="count.history_+3A_status">status</code></td>
<td>
<p>name of status</p>
</td></tr>
<tr><td><code id="count.history_+3A_id">id</code></td>
<td>
<p>id</p>
</td></tr>
<tr><td><code id="count.history_+3A_types">types</code></td>
<td>
<p>types of the events (code) related to status</p>
</td></tr>
<tr><td><code id="count.history_+3A_names.count">names.count</code></td>
<td>
<p>name of Counts, for example Count1 Count2 when types=c(1,2)</p>
</td></tr>
<tr><td><code id="count.history_+3A_lag">lag</code></td>
<td>
<p>if true counts previously observed, and if lag=FALSE counts up to know</p>
</td></tr>
<tr><td><code id="count.history_+3A_multitype">multitype</code></td>
<td>
<p>if multitype then count number of types also when types=c(1,2) for example</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################
## getting some rates to mimick 
########################################

data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz

######################################################################
### simulating simple model that mimicks data 
### now with two event types and second type has same rate as death rate
######################################################################

rr &lt;- simRecurrentII(1000,base1,base4,death.cumhaz=dr)
rr &lt;-  count.history(rr)
dtable(rr,~"Count*"+status,level=1)

</code></pre>

<hr>
<h2 id='covarianceRecurrent'>Estimation of covariance for bivariate recurrent events with terminal event</h2><span id='topic+covarianceRecurrent'></span><span id='topic+plot.covariace.recurrent'></span><span id='topic+covarianceRecurrentS'></span><span id='topic+Bootcovariancerecurrence'></span><span id='topic+BootcovariancerecurrenceS'></span>

<h3>Description</h3>

<p>Estimation of probability of more that k events for recurrent events process
where there is terminal event
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covarianceRecurrent(
  data,
  type1,
  type2,
  status = "status",
  death = "death",
  start = "start",
  stop = "stop",
  id = "id",
  names.count = "Count"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covarianceRecurrent_+3A_data">data</code></td>
<td>
<p>data-frame</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_type1">type1</code></td>
<td>
<p>type of first event (code) related to status</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_type2">type2</code></td>
<td>
<p>type of second event (code) related to status</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_status">status</code></td>
<td>
<p>name of status</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_death">death</code></td>
<td>
<p>name of death indicator</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_start">start</code></td>
<td>
<p>start stop call of Hist() of prodlim</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_stop">stop</code></td>
<td>
<p>start stop call of Hist() of prodlim</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_id">id</code></td>
<td>
<p>id</p>
</td></tr>
<tr><td><code id="covarianceRecurrent_+3A_names.count">names.count</code></td>
<td>
<p>name of count for number of previous event of different types, here generated by count.history()</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Scheike, Eriksson, Tribler (2019) 
The mean, variance and correlation for bivariate recurrent events
with a terminal event,  JRSS-C
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
########################################
## getting some data to work on 
########################################
data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz
rr &lt;- simRecurrentII(1000,base1,cumhaz2=base4,death.cumhaz=dr)
rr &lt;- count.history(rr)
rr$strata &lt;- 1
dtable(rr,~death+status)

covrp &lt;- covarianceRecurrent(rr,1,2,status="status",death="death",
                        start="entry",stop="time",id="id",names.count="Count")
par(mfrow=c(1,3)) 
plot(covrp)

### with strata, each strata in matrix column, provides basis for fast Bootstrap
covrpS &lt;- covarianceRecurrentS(rr,1,2,status="status",death="death",
        start="entry",stop="time",strata="strata",id="id",names.count="Count")

</code></pre>

<hr>
<h2 id='daggregate'>aggregating for for data frames</h2><span id='topic+daggregate'></span><span id='topic+daggr'></span>

<h3>Description</h3>

<p>aggregating for for data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>daggregate(
  data,
  y = NULL,
  x = NULL,
  subset,
  ...,
  fun = "summary",
  regex = mets.options()$regex,
  missing = FALSE,
  remove.empty = FALSE,
  matrix = FALSE,
  silent = FALSE,
  na.action = na.pass,
  convert = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="daggregate_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="daggregate_+3A_y">y</code></td>
<td>
<p>name of variable, or formula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="daggregate_+3A_x">x</code></td>
<td>
<p>name of variable, or formula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="daggregate_+3A_subset">subset</code></td>
<td>
<p>subset expression</p>
</td></tr>
<tr><td><code id="daggregate_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
<tr><td><code id="daggregate_+3A_fun">fun</code></td>
<td>
<p>function defining aggregation</p>
</td></tr>
<tr><td><code id="daggregate_+3A_regex">regex</code></td>
<td>
<p>interpret x,y as regular expressions</p>
</td></tr>
<tr><td><code id="daggregate_+3A_missing">missing</code></td>
<td>
<p>Missing used in groups (x)</p>
</td></tr>
<tr><td><code id="daggregate_+3A_remove.empty">remove.empty</code></td>
<td>
<p>remove empty groups from output</p>
</td></tr>
<tr><td><code id="daggregate_+3A_matrix">matrix</code></td>
<td>
<p>if TRUE a matrix is returned instead of an array</p>
</td></tr>
<tr><td><code id="daggregate_+3A_silent">silent</code></td>
<td>
<p>suppress messages</p>
</td></tr>
<tr><td><code id="daggregate_+3A_na.action">na.action</code></td>
<td>
<p>How model.frame deals with 'NA's</p>
</td></tr>
<tr><td><code id="daggregate_+3A_convert">convert</code></td>
<td>
<p>if TRUE try to coerce result into matrix. Can also be a user-defined function</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data("sTRACE")
daggregate(iris, "^.e.al", x="Species", fun=cor, regex=TRUE)
daggregate(iris, Sepal.Length+Petal.Length ~Species, fun=summary)
daggregate(iris, log(Sepal.Length)+I(Petal.Length&gt;1.5) ~ Species,
                 fun=summary)
daggregate(iris, "*Length*", x="Species", fun=head)
daggregate(iris, "^.e.al", x="Species", fun=tail, regex=TRUE)
daggregate(sTRACE, status~ diabetes, fun=table)
daggregate(sTRACE, status~ diabetes+sex, fun=table)
daggregate(sTRACE, status + diabetes+sex ~ vf+I(wmi&gt;1.4), fun=table)
daggregate(iris, "^.e.al", x="Species",regex=TRUE)
dlist(iris,Petal.Length+Sepal.Length ~ Species |Petal.Length&gt;1.3 &amp; Sepal.Length&gt;5,
            n=list(1:3,-(3:1)))
daggregate(iris, I(Sepal.Length&gt;7)~Species | I(Petal.Length&gt;1.5))
daggregate(iris, I(Sepal.Length&gt;7)~Species | I(Petal.Length&gt;1.5),
                 fun=table)

dsum(iris, .~Species, matrix=TRUE, missing=TRUE)

par(mfrow=c(1,2))
data(iris)
drename(iris) &lt;- ~.
daggregate(iris,'sepal*'~species|species!="virginica",fun=plot)
daggregate(iris,'sepal*'~I(as.numeric(species))|I(as.numeric(species))!=1,fun=summary)

dnumeric(iris) &lt;- ~species
daggregate(iris,'sepal*'~species.n|species.n!=1,fun=summary)

</code></pre>

<hr>
<h2 id='Dbvn'>Derivatives of the bivariate normal cumulative distribution function</h2><span id='topic+Dbvn'></span>

<h3>Description</h3>

<p>Derivatives of the bivariate normal cumulative distribution function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dbvn(p,design=function(p,...) {
     return(list(mu=cbind(p[1],p[1]),
               dmu=cbind(1,1),
               S=matrix(c(p[2],p[3],p[3],p[4]),ncol=2),
               dS=rbind(c(1,0,0,0),c(0,1,1,0),c(0,0,0,1)))  )},                 
     Y=cbind(0,0))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Dbvn_+3A_p">p</code></td>
<td>
<p>Parameter vector</p>
</td></tr>
<tr><td><code id="Dbvn_+3A_design">design</code></td>
<td>
<p>Design function with defines mean, derivative of mean, variance,
and derivative of variance with respect to the parameter p</p>
</td></tr>
<tr><td><code id="Dbvn_+3A_y">Y</code></td>
<td>
<p>column vector where the CDF is evaluated</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='dby'>Calculate summary statistics grouped by</h2><span id='topic+dby'></span><span id='topic+dby+3C-'></span><span id='topic+dby2'></span><span id='topic+dby2+3C-'></span><span id='topic+dbyr'></span>

<h3>Description</h3>

<p>Calculate summary statistics grouped by variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dby(
  data,
  INPUT,
  ...,
  ID = NULL,
  ORDER = NULL,
  SUBSET = NULL,
  SORT = 0,
  COMBINE = !REDUCE,
  NOCHECK = FALSE,
  ARGS = NULL,
  NAMES,
  COLUMN = FALSE,
  REDUCE = FALSE,
  REGEX = mets.options()$regex,
  ALL = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dby_+3A_data">data</code></td>
<td>
<p>Data.frame</p>
</td></tr>
<tr><td><code id="dby_+3A_input">INPUT</code></td>
<td>
<p>Input variables (character or formula)</p>
</td></tr>
<tr><td><code id="dby_+3A_...">...</code></td>
<td>
<p>functions</p>
</td></tr>
<tr><td><code id="dby_+3A_id">ID</code></td>
<td>
<p>id variable</p>
</td></tr>
<tr><td><code id="dby_+3A_order">ORDER</code></td>
<td>
<p>(optional) order variable</p>
</td></tr>
<tr><td><code id="dby_+3A_subset">SUBSET</code></td>
<td>
<p>(optional) subset expression</p>
</td></tr>
<tr><td><code id="dby_+3A_sort">SORT</code></td>
<td>
<p>sort order (id+order variable)</p>
</td></tr>
<tr><td><code id="dby_+3A_combine">COMBINE</code></td>
<td>
<p>If TRUE result is appended to data</p>
</td></tr>
<tr><td><code id="dby_+3A_nocheck">NOCHECK</code></td>
<td>
<p>No sorting or check for missing data</p>
</td></tr>
<tr><td><code id="dby_+3A_args">ARGS</code></td>
<td>
<p>Optional list of arguments to functions (...)</p>
</td></tr>
<tr><td><code id="dby_+3A_names">NAMES</code></td>
<td>
<p>Optional vector of column names</p>
</td></tr>
<tr><td><code id="dby_+3A_column">COLUMN</code></td>
<td>
<p>If TRUE do the calculations for each column</p>
</td></tr>
<tr><td><code id="dby_+3A_reduce">REDUCE</code></td>
<td>
<p>Reduce number of redundant rows</p>
</td></tr>
<tr><td><code id="dby_+3A_regex">REGEX</code></td>
<td>
<p>Allow regular expressions</p>
</td></tr>
<tr><td><code id="dby_+3A_all">ALL</code></td>
<td>
<p>if FALSE only the subset will be returned</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculate summary statistics grouped by
</p>
<p>dby2 for column-wise calculations
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 4
k &lt;- c(3,rbinom(n-1,3,0.5)+1)
N &lt;- sum(k)
d &lt;- data.frame(y=rnorm(N),x=rnorm(N),id=rep(seq(n),k),num=unlist(sapply(k,seq)))
d2 &lt;- d[sample(nrow(d)),]

dby(d2, y~id, mean)
dby(d2, y~id + order(num), cumsum)

dby(d,y ~ id + order(num), dlag)
dby(d,y ~ id + order(num), dlag, ARGS=list(k=1:2))
dby(d,y ~ id + order(num), dlag, ARGS=list(k=1:2), NAMES=c("l1","l2"))

dby(d, y~id + order(num), mean=mean, csum=cumsum, n=length)
dby(d2, y~id + order(num), a=cumsum, b=mean, N=length, l1=function(x) c(NA,x)[-length(x)])

dby(d, y~id + order(num), nn=seq_along, n=length)
dby(d, y~id + order(num), nn=seq_along, n=length)

d &lt;- d[,1:4]
dby(d, x&lt;0) &lt;- list(z=mean)
d &lt;- dby(d, is.na(z), z=1)

f &lt;- function(x) apply(x,1,min)
dby(d, y+x~id, min=f)

dby(d,y+x~id+order(num), function(x) x)

f &lt;- function(x) { cbind(cumsum(x[,1]),cumsum(x[,2]))/sum(x)}
dby(d, y+x~id, f)

## column-wise
a &lt;- d
dby2(a, mean, median, REGEX=TRUE) &lt;- '^[y|x]'~id
a
## wildcards 
dby2(a,'y*'+'x*'~id,mean) 


## subset
dby(d, x&lt;0) &lt;- list(z=NA)
d
dby(d, y~id|x&gt;-1, v=mean,z=1)
dby(d, y+x~id|x&gt;-1, mean, median, COLUMN=TRUE)

dby2(d, y+x~id|x&gt;0, mean, REDUCE=TRUE)

dby(d,y~id|x&lt;0,mean,ALL=FALSE)

a &lt;- iris
a &lt;- dby(a,y=1)
dby(a,Species=="versicolor") &lt;- list(y=2)
</code></pre>

<hr>
<h2 id='dcor'>summary, tables, and correlations for data frames</h2><span id='topic+dcor'></span><span id='topic+dsummary'></span><span id='topic+dstr'></span><span id='topic+dsubset'></span><span id='topic+dquantile'></span><span id='topic+dcount'></span><span id='topic+dmean'></span><span id='topic+dmeansd'></span><span id='topic+dscalar'></span><span id='topic+deval'></span><span id='topic+deval2'></span><span id='topic+dsum'></span><span id='topic+dsd'></span>

<h3>Description</h3>

<p>summary, tables, and correlations for data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcor(data, y = NULL, x = NULL, use = "pairwise.complete.obs", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dcor_+3A_data">data</code></td>
<td>
<p>if x is formula or names for data frame then data frame is needed.</p>
</td></tr>
<tr><td><code id="dcor_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dcor_+3A_x">x</code></td>
<td>
<p>possible group variable</p>
</td></tr>
<tr><td><code id="dcor_+3A_use">use</code></td>
<td>
<p>how to handle missing values</p>
</td></tr>
<tr><td><code id="dcor_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sTRACE",package="timereg")
dt&lt;- sTRACE
dt$time2 &lt;- dt$time^2
dt$wmi2 &lt;- dt$wmi^2
head(dt)

dcor(dt)

dcor(dt,~time+wmi)
dcor(dt,~time+wmi,~vf+chf)
dcor(dt,time+wmi~vf+chf)

dcor(dt,c("time*","wmi*"),~vf+chf)
</code></pre>

<hr>
<h2 id='dcut'>Cutting, sorting, rm (removing), rename for data frames</h2><span id='topic+dcut'></span><span id='topic+dcut+3C-'></span><span id='topic+dunique'></span><span id='topic+drm'></span><span id='topic+drm+3C-'></span><span id='topic+dnames'></span><span id='topic+dnames+3C-'></span><span id='topic+drename'></span><span id='topic+drename+3C-'></span><span id='topic+dkeep'></span><span id='topic+dkeep+3C-'></span><span id='topic+ddrop'></span><span id='topic+ddrop+3C-'></span>

<h3>Description</h3>

<p>Cut variables, if breaks are given these are used, otherwise cuts into 
using group size given by probs, or equispace groups on range. Default 
is equally sized groups if possible
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcut(
  data,
  y = NULL,
  x = NULL,
  breaks = 4,
  probs = NULL,
  equi = FALSE,
  regex = mets.options()$regex,
  sep = NULL,
  na.rm = TRUE,
  labels = NULL,
  all = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dcut_+3A_data">data</code></td>
<td>
<p>if x is formula or names for data frame then data frame is needed.</p>
</td></tr>
<tr><td><code id="dcut_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dcut_+3A_x">x</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dcut_+3A_breaks">breaks</code></td>
<td>
<p>number of breaks, for variables or vector of break points,</p>
</td></tr>
<tr><td><code id="dcut_+3A_probs">probs</code></td>
<td>
<p>groups defined from quantiles</p>
</td></tr>
<tr><td><code id="dcut_+3A_equi">equi</code></td>
<td>
<p>for equi-spaced breaks</p>
</td></tr>
<tr><td><code id="dcut_+3A_regex">regex</code></td>
<td>
<p>for regular expressions.</p>
</td></tr>
<tr><td><code id="dcut_+3A_sep">sep</code></td>
<td>
<p>seperator for naming of cut names.</p>
</td></tr>
<tr><td><code id="dcut_+3A_na.rm">na.rm</code></td>
<td>
<p>to remove NA for grouping variables.</p>
</td></tr>
<tr><td><code id="dcut_+3A_labels">labels</code></td>
<td>
<p>to use for cut groups</p>
</td></tr>
<tr><td><code id="dcut_+3A_all">all</code></td>
<td>
<p>to do all variables, even when breaks are not unique</p>
</td></tr>
<tr><td><code id="dcut_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sTRACE",package="timereg")
sTRACE$age2 &lt;- sTRACE$age^2
sTRACE$age3 &lt;- sTRACE$age^3

mm &lt;- dcut(sTRACE,~age+wmi)
head(mm)

mm &lt;- dcut(sTRACE,catage4+wmi4~age+wmi)
head(mm)

mm &lt;- dcut(sTRACE,~age+wmi,breaks=c(2,4))
head(mm)

mm &lt;- dcut(sTRACE,c("age","wmi"))
head(mm)

mm &lt;- dcut(sTRACE,~.)
head(mm)

mm &lt;- dcut(sTRACE,c("age","wmi"),breaks=c(2,4))
head(mm)

gx &lt;- dcut(sTRACE$age)
head(gx)


## Removes all cuts variables with these names wildcards
mm1 &lt;- drm(mm,c("*.2","*.4"))
head(mm1)

## wildcards, for age, age2, age4 and wmi
head(dcut(mm,c("a*","?m*")))

## with direct asignment
drm(mm) &lt;- c("*.2","*.4")
head(mm)

dcut(mm) &lt;- c("age","*m*")
dcut(mm) &lt;- ageg1+wmig1~age+wmi
head(mm)

############################
## renaming
############################

head(mm)
drename(mm, ~Age+Wmi) &lt;- c("wmi","age")
head(mm)
mm1 &lt;- mm

## all names to lower
drename(mm1) &lt;- ~.
head(mm1)

## A* to lower
mm2 &lt;-  drename(mm,c("A*","W*"))
head(mm2)
drename(mm) &lt;- "A*"
head(mm)

dd &lt;- data.frame(A_1=1:2,B_1=1:2)
funn &lt;- function(x) gsub("_",".",x)
drename(dd) &lt;- ~.
drename(dd,fun=funn) &lt;- ~.
names(dd)
</code></pre>

<hr>
<h2 id='dermalridges'>Dermal ridges data (families)</h2><span id='topic+dermalridges'></span>

<h3>Description</h3>

<p>Data on dermal ridge counts in left and right hand in (nuclear) families
</p>


<h3>Format</h3>

<p>Data on 50 families with ridge counts in left and right
hand for moter, father and each child. Family id in 'family' and
gender and child number in 'sex' and 'child'.
</p>


<h3>Source</h3>

<p>Sarah B. Holt (1952). Genetics of dermal ridges: bilateral
asymmetry in finger ridge-counts.  Annals of Eugenics 17 (1),
pp.211&ndash;231. DOI: 10.1111/j.1469-1809.1952.tb02513.x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dermalridges)
fast.reshape(dermalridges,id="family",varying=c("child.left","child.right","sex"))
</code></pre>

<hr>
<h2 id='dermalridgesMZ'>Dermal ridges data (monozygotic twins)</h2><span id='topic+dermalridgesMZ'></span>

<h3>Description</h3>

<p>Data on dermal ridge counts in left and right hand in (nuclear) families
</p>


<h3>Format</h3>

<p>Data on dermal ridge counts (left and right hand) in 18
monozygotic twin pairs.
</p>


<h3>Source</h3>

<p>Sarah B. Holt (1952). Genetics of dermal ridges: bilateral
asymmetry in finger ridge-counts.  Annals of Eugenics 17 (1),
pp.211&ndash;231. DOI: 10.1111/j.1469-1809.1952.tb02513.x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dermalridgesMZ)
fast.reshape(dermalridgesMZ,id="id",varying=c("left","right"))
</code></pre>

<hr>
<h2 id='diabetes'>The Diabetic Retinopathy Data</h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>The data was colleceted to test a laser treatment for delaying blindness in
patients with dibetic retinopathy. The subset of 197 patiens given in Huster
et al. (1989) is used.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns: </p>

<dl>
<dt>id</dt><dd><p>a numeric vector. Patient code.</p>
</dd> <dt>agedx</dt><dd><p>a numeric vector.
Age of patient at diagnosis.</p>
</dd> <dt>time</dt><dd><p>a numeric vector. Survival time:
time to blindness or censoring.</p>
</dd> <dt>status</dt><dd><p> a numeric vector code.
Survival status. 1: blindness, 0: censored.</p>
</dd> <dt>trteye</dt><dd><p>a numeric vector
code. Random eye selected for treatment. 1: left eye 2: right eye.</p>
</dd>
<dt>treat</dt><dd><p>a numeric vector. 1: treatment 0: untreated.</p>
</dd> <dt>adult</dt><dd><p>a
numeric vector code. 1: younger than 20, 2: older than 20.</p>
</dd> </dl>



<h3>Source</h3>

<p>Huster W.J. and Brookmeyer, R. and Self. S. (1989) MOdelling paired
survival data with covariates, Biometrics 45, 145-56.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(diabetes)
names(diabetes)

</code></pre>

<hr>
<h2 id='divide.conquer'>Split a data set and run function</h2><span id='topic+divide.conquer'></span>

<h3>Description</h3>

<p>Split a data set and run function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divide.conquer(func = NULL, data, size, splits, id = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="divide.conquer_+3A_func">func</code></td>
<td>
<p>called function</p>
</td></tr>
<tr><td><code id="divide.conquer_+3A_data">data</code></td>
<td>
<p>data-frame</p>
</td></tr>
<tr><td><code id="divide.conquer_+3A_size">size</code></td>
<td>
<p>size of splits</p>
</td></tr>
<tr><td><code id="divide.conquer_+3A_splits">splits</code></td>
<td>
<p>number of splits (ignored if size is given)</p>
</td></tr>
<tr><td><code id="divide.conquer_+3A_id">id</code></td>
<td>
<p>optional cluster variable</p>
</td></tr>
<tr><td><code id="divide.conquer_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike, Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## avoid dependency on timereg
## library(timereg)
## data(TRACE)
## res &lt;- divide.conquer(prop.odds,TRACE,
## 	     formula=Event(time,status==9)~chf+vf+age,n.sim=0,size=200)
</code></pre>

<hr>
<h2 id='divide.conquer.timereg'>Split a data set and run function from timereg and aggregate</h2><span id='topic+divide.conquer.timereg'></span>

<h3>Description</h3>

<p>Split a data set and run function of cox-aalen type and aggregate results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divide.conquer.timereg(func = NULL, data, size, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="divide.conquer.timereg_+3A_func">func</code></td>
<td>
<p>called function</p>
</td></tr>
<tr><td><code id="divide.conquer.timereg_+3A_data">data</code></td>
<td>
<p>data-frame</p>
</td></tr>
<tr><td><code id="divide.conquer.timereg_+3A_size">size</code></td>
<td>
<p>size of splits</p>
</td></tr>
<tr><td><code id="divide.conquer.timereg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike, Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## library(timereg)
## data(TRACE)
## a &lt;- divide.conquer.timereg(prop.odds,TRACE,
##                            formula=Event(time,status==9)~chf+vf+age,n.sim=0,size=200)
## coef(a)
## a2 &lt;- divide.conquer.timereg(prop.odds,TRACE,
##                              formula=Event(time,status==9)~chf+vf+age,n.sim=0,size=500)
## coef(a2)
## 
##if (interactive()) {
##par(mfrow=c(1,1))
##plot(a,xlim=c(0,8),ylim=c(0,0.01))
##par(new=TRUE)
##plot(a2,xlim=c(0,8),ylim=c(0,0.01))
##}
</code></pre>

<hr>
<h2 id='dlag'>Lag operator</h2><span id='topic+dlag'></span><span id='topic+dlag+3C-'></span>

<h3>Description</h3>

<p>Lag operator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlag(data, x, k = 1, combine = TRUE, simplify = TRUE, names, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dlag_+3A_data">data</code></td>
<td>
<p>data.frame or vector</p>
</td></tr>
<tr><td><code id="dlag_+3A_x">x</code></td>
<td>
<p>optional column names or formula</p>
</td></tr>
<tr><td><code id="dlag_+3A_k">k</code></td>
<td>
<p>lag (vector of integers)</p>
</td></tr>
<tr><td><code id="dlag_+3A_combine">combine</code></td>
<td>
<p>combine results with original data.frame</p>
</td></tr>
<tr><td><code id="dlag_+3A_simplify">simplify</code></td>
<td>
<p>Return vector if possible</p>
</td></tr>
<tr><td><code id="dlag_+3A_names">names</code></td>
<td>
<p>optional new column names</p>
</td></tr>
<tr><td><code id="dlag_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- data.frame(y=1:10,x=c(10:1))
dlag(d,k=1:2)
dlag(d,~x,k=0:1)
dlag(d$x,k=1)
dlag(d$x,k=-1:2, names=letters[1:4])
</code></pre>

<hr>
<h2 id='doubleFGR'>Double CIF Fine-Gray model with two causes</h2><span id='topic+doubleFGR'></span><span id='topic+bplotdFG'></span><span id='topic+predictdFG'></span>

<h3>Description</h3>

<p>Estimation based on derived hazards and recursive estimating equations.
fits two parametrizations
1)
</p>
<p style="text-align: center;"><code class="reqn">
F_1(t,X) = 1 - \exp( - \exp( X^T \beta ) \Lambda_1(t))
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
F_2(t,X_2) = 1 - \exp( -  \exp( X_2^T \beta_2 ) \Lambda_2(t))
</code>
</p>

<p>or restricted version
2)
</p>
<p style="text-align: center;"><code class="reqn">
F_1(t,X) = 1 - \exp( -  \exp( X^T \beta ) \Lambda_1(t))
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
F_2(t,X_2,X) = ( 1 - \exp(  - \exp( X_2^T \beta_2 ) \Lambda_2(t)) ) (1 - F_1(\infty,X))
</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>doubleFGR(formula, data, offset = NULL, weights = NULL, X2 = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doubleFGR_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event'</p>
</td></tr>
<tr><td><code id="doubleFGR_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="doubleFGR_+3A_offset">offset</code></td>
<td>
<p>offsets for cox model</p>
</td></tr>
<tr><td><code id="doubleFGR_+3A_weights">weights</code></td>
<td>
<p>weights for Cox score equations</p>
</td></tr>
<tr><td><code id="doubleFGR_+3A_x2">X2</code></td>
<td>
<p>specifies the regression design for second CIF model</p>
</td></tr>
<tr><td><code id="doubleFGR_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- 0
data(bmt)
bmt$age2 &lt;- bmt$age
newdata &lt;- bmt[1:19,]
if (interactive()) par(mfrow=c(5,3))

## same X1 and X2
pr2 &lt;- doubleFGR(Event(time,cause)~age+platelet,data=bmt,restrict=res)
if (interactive()) {
  bplotdFG(pr2,cause=1)
  bplotdFG(pr2,cause=2,add=TRUE)
}
pp21 &lt;- predictdFG(pr2,newdata=newdata)
pp22 &lt;- predictdFG(pr2,newdata=newdata,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}
pp21 &lt;- predictdFG(pr2)
pp22 &lt;- predictdFG(pr2,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}

pr2 &lt;- doubleFGR(Event(time,cause)~strata(platelet),data=bmt,restrict=res)
if (interactive()) {
  bplotdFG(pr2,cause=1)
  bplotdFG(pr2,cause=2,add=TRUE)
}
pp21 &lt;- predictdFG(pr2,newdata=newdata)
pp22 &lt;- predictdFG(pr2,,newdata=newdata,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}
pp21 &lt;- predictdFG(pr2)
pp22 &lt;- predictdFG(pr2,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}

## different X1 and X2
pr2 &lt;- doubleFGR(Event(time,cause)~age+platelet+age2,data=bmt,X2=3,restrict=res)
if (interactive()) {
  bplotdFG(pr2,cause=1)
  bplotdFG(pr2,cause=2,add=TRUE)
}
pp21 &lt;- predictdFG(pr2,newdata=newdata)
pp22 &lt;- predictdFG(pr2,newdata=newdata,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}
pp21 &lt;- predictdFG(pr2)
pp22 &lt;- predictdFG(pr2,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}

### uden X1
pr2 &lt;- doubleFGR(Event(time,cause)~age+platelet,data=bmt,X2=1:2,restrict=res)
if (interactive()) {
  bplotdFG(pr2,cause=1)
  bplotdFG(pr2,cause=2,add=TRUE)
}
pp21 &lt;- predictdFG(pr2,newdata=newdata)
pp22 &lt;- predictdFG(pr2,newdata=newdata,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}
pp21 &lt;- predictdFG(pr2)
p22 &lt;- predictdFG(pr2,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}

### without X2
pr2 &lt;- doubleFGR(Event(time,cause)~age+platelet,data=bmt,X2=0,restrict=res)
if (interactive()) {
  bplotdFG(pr2,cause=1)
  bplotdFG(pr2,cause=2,add=TRUE)
}
pp21 &lt;- predictdFG(pr2,newdata=newdata)
pp22 &lt;- predictdFG(pr2,newdata=newdata,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}
pp21 &lt;- predictdFG(pr2)
pp22 &lt;- predictdFG(pr2,cause=2)
if (interactive()) {
  plot(pp21)
  plot(pp22,add=TRUE,col=2)
}

</code></pre>

<hr>
<h2 id='dprint'>list, head, print, tail</h2><span id='topic+dprint'></span><span id='topic+dlist'></span><span id='topic+dhead'></span><span id='topic+dtail'></span>

<h3>Description</h3>

<p>listing for data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dprint(data, y = NULL, n = 0, ..., x = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dprint_+3A_data">data</code></td>
<td>
<p>if x is formula or names for data frame then data frame is needed.</p>
</td></tr>
<tr><td><code id="dprint_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dprint_+3A_n">n</code></td>
<td>
<p>Index of observations to print (default c(1:nfirst, n-nlast:nlast)</p>
</td></tr>
<tr><td><code id="dprint_+3A_...">...</code></td>
<td>
<p>Optional additional arguments (nfirst,nlast, and print options)</p>
</td></tr>
<tr><td><code id="dprint_+3A_x">x</code></td>
<td>
<p>possible group variable</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- lava::lvm(letters)
d &lt;- lava::sim(m, 20)

dlist(d,~a+b+c)
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0)
## listing all : 
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0,n=0)
dlist(d,a+b+c~I(d&gt;0)|a&lt;0 &amp; b&gt;0)
dlist(d,.~I(d&gt;0)|a&lt;0 &amp; b&gt;0)
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0, nlast=0)
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0, nfirst=3, nlast=3)
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0, 1:5)
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0, -(5:1))
dlist(d,~a+b+c|a&lt;0 &amp; b&gt;0, list(1:5,50:55,-(5:1)))
dprint(d,a+b+c ~ I(d&gt;0) |a&lt;0 &amp; b&gt;0, list(1:5,50:55,-(5:1)))
</code></pre>

<hr>
<h2 id='drcumhaz'>Rate for leaving HPN program for patients of Copenhagen</h2><span id='topic+drcumhaz'></span>

<h3>Description</h3>

<p>Rate for leaving HPN program for patients of Copenhagen
</p>


<h3>Source</h3>

<p>Estimated data
</p>

<hr>
<h2 id='dreg'>Regression for data frames with dutility call</h2><span id='topic+dreg'></span>

<h3>Description</h3>

<p>Regression for data frames with dutility call
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dreg(
  data,
  y,
  x = NULL,
  z = NULL,
  x.oneatatime = TRUE,
  x.base.names = NULL,
  z.arg = c("clever", "base", "group", "condition"),
  fun. = lm,
  summary. = summary,
  regex = FALSE,
  convert = NULL,
  doSummary = TRUE,
  special = NULL,
  equal = TRUE,
  test = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="dreg_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dreg_+3A_x">x</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dreg_+3A_z">z</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dreg_+3A_x.oneatatime">x.oneatatime</code></td>
<td>
<p>x's one at a time</p>
</td></tr>
<tr><td><code id="dreg_+3A_x.base.names">x.base.names</code></td>
<td>
<p>base covarirates</p>
</td></tr>
<tr><td><code id="dreg_+3A_z.arg">z.arg</code></td>
<td>
<p>what is Z, c(&quot;clever&quot;,&quot;base&quot;,&quot;group&quot;,&quot;condition&quot;), clever decides based on type of Z, base means that Z is used as fixed baseline covaraites for all X, group means the analyses is done based on groups of Z, and condition means that Z specifies a condition on the data</p>
</td></tr>
<tr><td><code id="dreg_+3A_fun.">fun.</code></td>
<td>
<p>function  lm is default</p>
</td></tr>
<tr><td><code id="dreg_+3A_summary.">summary.</code></td>
<td>
<p>summary to use</p>
</td></tr>
<tr><td><code id="dreg_+3A_regex">regex</code></td>
<td>
<p>regex</p>
</td></tr>
<tr><td><code id="dreg_+3A_convert">convert</code></td>
<td>
<p>convert</p>
</td></tr>
<tr><td><code id="dreg_+3A_dosummary">doSummary</code></td>
<td>
<p>doSummary or not</p>
</td></tr>
<tr><td><code id="dreg_+3A_special">special</code></td>
<td>
<p>special's</p>
</td></tr>
<tr><td><code id="dreg_+3A_equal">equal</code></td>
<td>
<p>to do pairwise stuff</p>
</td></tr>
<tr><td><code id="dreg_+3A_test">test</code></td>
<td>
<p>development argument</p>
</td></tr>
<tr><td><code id="dreg_+3A_...">...</code></td>
<td>
<p>Additional arguments for fun</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst, Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##'
data(iris)
dat &lt;- iris
drename(dat) &lt;- ~.
names(dat)
set.seed(1)
dat$time &lt;- runif(nrow(dat))
dat$time1 &lt;- runif(nrow(dat))
dat$status &lt;- rbinom(nrow(dat),1,0.5)
dat$S1 &lt;- with(dat, Surv(time,status))
dat$S2 &lt;- with(dat, Surv(time1,status))
dat$id &lt;- 1:nrow(dat)

mm &lt;- dreg(dat, "*.length"~"*.width"|I(species=="setosa" &amp; status==1))
mm &lt;- dreg(dat, "*.length"~"*.width"|species+status)
mm &lt;- dreg(dat, "*.length"~"*.width"|species)
mm &lt;- dreg(dat, "*.length"~"*.width"|species+status,z.arg="group")

 ## Reduce Ex.Timings
y &lt;- "S*"~"*.width"
xs &lt;- dreg(dat, y, fun.=phreg)
xs &lt;- dreg(dat, y, fun.=survdiff)

y &lt;- "S*"~"*.width"
xs &lt;- dreg(dat, y, x.oneatatime=FALSE, fun.=phreg)

## under condition
y &lt;- S1~"*.width"|I(species=="setosa" &amp; sepal.width&gt;3)
xs &lt;- dreg(dat, y, z.arg="condition", fun.=phreg)
xs &lt;- dreg(dat, y, fun.=phreg)

## under condition
y &lt;- S1~"*.width"|species=="setosa"
xs &lt;- dreg(dat, y, z.arg="condition", fun.=phreg)
xs &lt;- dreg(dat, y, fun.=phreg)

## with baseline  after |
y &lt;- S1~"*.width"|sepal.length
xs &lt;- dreg(dat, y, fun.=phreg)

## by group by species, not working
y &lt;- S1~"*.width"|species
ss &lt;- split(dat, paste(dat$species, dat$status))

xs &lt;- dreg(dat, y, fun.=phreg)

## species as base, species is factor so assumes that this is grouping
y &lt;- S1~"*.width"|species
xs &lt;- dreg(dat, y, z.arg="base", fun.=phreg)

##  background var after | and then one of x's at at time
y &lt;- S1~"*.width"|status+"sepal*"
xs &lt;- dreg(dat, y, fun.=phreg)

##  background var after | and then one of x's at at time
##y &lt;- S1~"*.width"|status+"sepal*"
##xs &lt;- dreg(dat, y, x.oneatatime=FALSE, fun.=phreg)
##xs &lt;- dreg(dat, y, fun.=phreg)

##  background var after | and then one of x's at at time
##y &lt;- S1~"*.width"+factor(species)
##xs &lt;- dreg(dat, y, fun.=phreg)
##xs &lt;- dreg(dat, y, fun.=phreg, x.oneatatime=FALSE)

y &lt;- S1~"*.width"|factor(species)
xs &lt;- dreg(dat, y, z.arg="base", fun.=phreg)

y &lt;- S1~"*.width"|cluster(id)+factor(species)
xs &lt;- dreg(dat, y, z.arg="base", fun.=phreg)
xs &lt;- dreg(dat, y, z.arg="base", fun.=coxph)

## under condition with groups
y &lt;- S1~"*.width"|I(sepal.length&gt;4)
xs &lt;- dreg(subset(dat, species=="setosa"), y,z.arg="group",fun.=phreg)

## under condition with groups
y &lt;- S1~"*.width"+I(log(sepal.length))|I(sepal.length&gt;4)
xs &lt;- dreg(subset(dat, species=="setosa"), y,z.arg="group",fun.=phreg)

y &lt;- S1~"*.width"+I(dcut(sepal.length))|I(sepal.length&gt;4)
xs &lt;- dreg(subset(dat,species=="setosa"), y,z.arg="group",fun.=phreg)

ff &lt;- function(formula,data,...) {
 ss &lt;- survfit(formula,data,...)
 kmplot(ss,...)
 return(ss)
}

if (interactive()) {
dcut(dat) &lt;- ~"*.width"
y &lt;- S1~"*.4"|I(sepal.length&gt;4)
par(mfrow=c(1, 2))
xs &lt;- dreg(dat, y, fun.=ff)
}


</code></pre>

<hr>
<h2 id='drelevel'>relev levels for data frames</h2><span id='topic+drelevel'></span><span id='topic+dlevels'></span><span id='topic+dlevel'></span><span id='topic+dlev'></span><span id='topic+drelev'></span><span id='topic+dlev+3C-'></span><span id='topic+dlevel+3C-'></span><span id='topic+drelev+3C-'></span><span id='topic+drelevel+3C-'></span><span id='topic+dfactor'></span><span id='topic+dfactor+3C-'></span><span id='topic+dnumeric'></span><span id='topic+dnumeric+3C-'></span>

<h3>Description</h3>

<p>levels shows levels for variables in data frame, relevel relevels a factor in data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drelevel(
  data,
  y = NULL,
  x = NULL,
  ref = NULL,
  newlevels = NULL,
  regex = mets.options()$regex,
  sep = NULL,
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drelevel_+3A_data">data</code></td>
<td>
<p>if x is formula or names for data frame then data frame is needed.</p>
</td></tr>
<tr><td><code id="drelevel_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="drelevel_+3A_x">x</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="drelevel_+3A_ref">ref</code></td>
<td>
<p>new reference variable</p>
</td></tr>
<tr><td><code id="drelevel_+3A_newlevels">newlevels</code></td>
<td>
<p>to combine levels of factor in data frame</p>
</td></tr>
<tr><td><code id="drelevel_+3A_regex">regex</code></td>
<td>
<p>for regular expressions.</p>
</td></tr>
<tr><td><code id="drelevel_+3A_sep">sep</code></td>
<td>
<p>seperator for naming of cut names.</p>
</td></tr>
<tr><td><code id="drelevel_+3A_overwrite">overwrite</code></td>
<td>
<p>to overwrite variable</p>
</td></tr>
<tr><td><code id="drelevel_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mena)
dstr(mena)
dfactor(mena)  &lt;- ~twinnum
dnumeric(mena) &lt;- ~twinnum.f

dstr(mena)

mena2 &lt;- drelevel(mena,"cohort",ref="(1980,1982]")
mena2 &lt;- drelevel(mena,~cohort,ref="(1980,1982]")
mena2 &lt;- drelevel(mena,cohortII~cohort,ref="(1980,1982]")
dlevels(mena)
dlevels(mena2)
drelevel(mena,ref="(1975,1977]")  &lt;-  ~cohort
drelevel(mena,ref="(1980,1982]")  &lt;-  ~cohort
dlevels(mena,"coh*")
dtable(mena,"coh*",level=1)

### level 1 of zyg as baseline for new variable
drelevel(mena,ref=1) &lt;- ~zyg
drelevel(mena,ref=c("DZ","[1973,1975]")) &lt;- ~ zyg+cohort
drelevel(mena,ref=c("DZ","[1973,1975]")) &lt;- zygdz+cohort.early~ zyg+cohort
### level 2 of zyg and cohort as baseline for new variables
drelevel(mena,ref=2) &lt;- ~ zyg+cohort
dlevels(mena)

##################### combining factor levels with newlevels argument

dcut(mena,labels=c("I","II","III","IV")) &lt;- cat4~agemena
dlevels(drelevel(mena,~cat4,newlevels=1:3))
dlevels(drelevel(mena,ncat4~cat4,newlevels=3:2))
drelevel(mena,newlevels=3:2) &lt;- ncat4~cat4
dlevels(mena)

dlevels(drelevel(mena,nca4~cat4,newlevels=list(c(1,4),2:3)))

drelevel(mena,newlevels=list(c(1,4),2:3)) &lt;- nca4..2 ~ cat4
dlevels(mena)

drelevel(mena,newlevels=list("I-III"=c("I","II","III"),"IV"="IV")) &lt;- nca4..3 ~ cat4
dlevels(mena)

drelevel(mena,newlevels=list("I-III"=c("I","II","III"))) &lt;- nca4..4 ~ cat4
dlevels(mena)

drelevel(mena,newlevels=list(group1=c("I","II","III"))) &lt;- nca4..5 ~ cat4
dlevels(mena)

drelevel(mena,newlevels=list(g1=c("I","II","III"),g2="IV")) &lt;- nca4..6 ~ cat4
dlevels(mena)

</code></pre>

<hr>
<h2 id='dsort'>Sort data frame</h2><span id='topic+dsort'></span><span id='topic+dsort2'></span><span id='topic+dsort+3C-'></span>

<h3>Description</h3>

<p>Sort data according to columns in data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsort(data, x, ..., decreasing = FALSE, return.order = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsort_+3A_data">data</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="dsort_+3A_x">x</code></td>
<td>
<p>variable to order by</p>
</td></tr>
<tr><td><code id="dsort_+3A_...">...</code></td>
<td>
<p>additional variables to order by</p>
</td></tr>
<tr><td><code id="dsort_+3A_decreasing">decreasing</code></td>
<td>
<p>sort order (vector of length x)</p>
</td></tr>
<tr><td><code id="dsort_+3A_return.order">return.order</code></td>
<td>
<p>return order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data="hubble",package="lava")
dsort(hubble, "sigma")
dsort(hubble, hubble$sigma,"v")
dsort(hubble,~sigma+v)
dsort(hubble,~sigma-v)

## with direct asignment
dsort(hubble) &lt;- ~sigma-v
</code></pre>

<hr>
<h2 id='dspline'>Simple linear spline</h2><span id='topic+dspline'></span><span id='topic+dspline+3C-'></span>

<h3>Description</h3>

<p>Constructs simple linear spline  on a data frame using the formula syntax of dutils
that is adds (x-cuti)* (x&gt;cuti) to the data-set for each knot of the spline. 
The full spline is thus given by x and spline variables added to the data-set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dspline(
  data,
  y = NULL,
  x = NULL,
  breaks = 4,
  probs = NULL,
  equi = FALSE,
  regex = mets.options()$regex,
  sep = NULL,
  na.rm = TRUE,
  labels = NULL,
  all = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dspline_+3A_data">data</code></td>
<td>
<p>if x is formula or names for data frame then data frame is needed.</p>
</td></tr>
<tr><td><code id="dspline_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dspline_+3A_x">x</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dspline_+3A_breaks">breaks</code></td>
<td>
<p>number of breaks, for variables or vector of break points,</p>
</td></tr>
<tr><td><code id="dspline_+3A_probs">probs</code></td>
<td>
<p>groups defined from quantiles</p>
</td></tr>
<tr><td><code id="dspline_+3A_equi">equi</code></td>
<td>
<p>for equi-spaced breaks</p>
</td></tr>
<tr><td><code id="dspline_+3A_regex">regex</code></td>
<td>
<p>for regular expressions.</p>
</td></tr>
<tr><td><code id="dspline_+3A_sep">sep</code></td>
<td>
<p>seperator for naming of cut names.</p>
</td></tr>
<tr><td><code id="dspline_+3A_na.rm">na.rm</code></td>
<td>
<p>to remove NA for grouping variables.</p>
</td></tr>
<tr><td><code id="dspline_+3A_labels">labels</code></td>
<td>
<p>to use for cut groups</p>
</td></tr>
<tr><td><code id="dspline_+3A_all">all</code></td>
<td>
<p>to do all variables, even when breaks are not unique</p>
</td></tr>
<tr><td><code id="dspline_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TRACE)
TRACE &lt;- dspline(TRACE,~wmi,breaks=c(1,1.3,1.7))
cca &lt;- coxph(Surv(time,status==9)~age+vf+chf+wmi,data=TRACE)
cca2 &lt;- coxph(Surv(time,status==9)~age+wmi+vf+chf+wmi.spline1+wmi.spline2+wmi.spline3,data=TRACE)
anova(cca,cca2)

nd=data.frame(age=50,vf=0,chf=0,wmi=seq(0.4,3,by=0.01))
nd &lt;- dspline(nd,~wmi,breaks=c(1,1.3,1.7))
pl &lt;- predict(cca2,newdata=nd)
plot(nd$wmi,pl,type="l")

</code></pre>

<hr>
<h2 id='dtable'>tables for data frames</h2><span id='topic+dtable'></span><span id='topic+dtab'></span>

<h3>Description</h3>

<p>tables for data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtable(
  data,
  y = NULL,
  x = NULL,
  ...,
  level = -1,
  response = NULL,
  flat = TRUE,
  total = FALSE,
  prop = FALSE,
  summary = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dtable_+3A_data">data</code></td>
<td>
<p>if x is formula or names for data frame then data frame is needed.</p>
</td></tr>
<tr><td><code id="dtable_+3A_y">y</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dtable_+3A_x">x</code></td>
<td>
<p>name of variable, or fomula, or names of variables on data frame.</p>
</td></tr>
<tr><td><code id="dtable_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
<tr><td><code id="dtable_+3A_level">level</code></td>
<td>
<p>1 for all marginal tables, 2 for all 2 by 2 tables, and null for the full table, possible versus group variable</p>
</td></tr>
<tr><td><code id="dtable_+3A_response">response</code></td>
<td>
<p>For level=2, only produce tables with columns given by 'response' (index)</p>
</td></tr>
<tr><td><code id="dtable_+3A_flat">flat</code></td>
<td>
<p>produce flat tables</p>
</td></tr>
<tr><td><code id="dtable_+3A_total">total</code></td>
<td>
<p>add total counts/proportions</p>
</td></tr>
<tr><td><code id="dtable_+3A_prop">prop</code></td>
<td>
<p>Proportions instead of counts (vector of margins)</p>
</td></tr>
<tr><td><code id="dtable_+3A_summary">summary</code></td>
<td>
<p>summary function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sTRACE",package="timereg")

dtable(sTRACE,~status)
dtable(sTRACE,~status+vf)
dtable(sTRACE,~status+vf,level=1)
dtable(sTRACE,~status+vf,~chf+diabetes)

dtable(sTRACE,c("*f*","status"),~diabetes)
dtable(sTRACE,c("*f*","status"),~diabetes, level=2)
dtable(sTRACE,c("*f*","status"),level=1)

dtable(sTRACE,~"*f*"+status,level=1)
dtable(sTRACE,~"*f*"+status+I(wmi&gt;1.4)|age&gt;60,level=2)
dtable(sTRACE,"*f*"+status~I(wmi&gt;0.5)|age&gt;60,level=1)
dtable(sTRACE,status~dcut(age))

dtable(sTRACE,~status+vf+sex|age&gt;60)
dtable(sTRACE,status+vf+sex~+1|age&gt;60, level=2)
dtable(sTRACE,.~status+vf+sex|age&gt;60,level=1)
dtable(sTRACE,status+vf+sex~diabetes|age&gt;60)
dtable(sTRACE,status+vf+sex~diabetes|age&gt;60, flat=FALSE)

dtable(sTRACE,status+vf+sex~diabetes|age&gt;60, level=1)
dtable(sTRACE,status+vf+sex~diabetes|age&gt;60, level=2)

dtable(sTRACE,status+vf+sex~diabetes|age&gt;60, level=2, prop=1, total=TRUE)
dtable(sTRACE,status+vf+sex~diabetes|age&gt;60, level=2, prop=2, total=TRUE)
dtable(sTRACE,status+vf+sex~diabetes|age&gt;60, level=2, prop=1:2, summary=summary)

</code></pre>

<hr>
<h2 id='dtransform'>Transform that allows condition</h2><span id='topic+dtransform'></span><span id='topic+dtransform+3C-'></span><span id='topic+dtrans'></span><span id='topic+dtrans+3C-'></span>

<h3>Description</h3>

<p>Defines new variables under condition for data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtransform(data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dtransform_+3A_data">data</code></td>
<td>
<p>is data frame</p>
</td></tr>
<tr><td><code id="dtransform_+3A_...">...</code></td>
<td>
<p>new variable definitions including possible if condition</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(mena)

xx &lt;- dtransform(mena,ll=log(agemena)+twinnum)

xx &lt;- dtransform(mena,ll=log(agemena)+twinnum,agemena&lt;15)
xx &lt;- dtransform(xx  ,ll=100+agemena,ll2=1000,agemena&gt;15)
dsummary(xx,ll+ll2~I(agemena&gt;15))
</code></pre>

<hr>
<h2 id='easy.binomial.twostage'>Fits two-stage binomial for describing depdendence in binomial data
using marginals that are on logistic form using the binomial.twostage funcion, but
call is different and easier and the data manipulation is build into the function.
Useful in particular for family design data.</h2><span id='topic+easy.binomial.twostage'></span>

<h3>Description</h3>

<p>If clusters contain more than two times, the algoritm uses a compososite likelihood
based on the pairwise bivariate models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>easy.binomial.twostage(
  margbin = NULL,
  data = parent.frame(),
  method = "nr",
  response = "response",
  id = "id",
  Nit = 60,
  detail = 0,
  silent = 1,
  weights = NULL,
  control = list(),
  theta = NULL,
  theta.formula = NULL,
  desnames = NULL,
  deshelp = 0,
  var.link = 1,
  iid = 1,
  step = 1,
  model = "plackett",
  marginal.p = NULL,
  strata = NULL,
  max.clust = NULL,
  se.clusters = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="easy.binomial.twostage_+3A_margbin">margbin</code></td>
<td>
<p>Marginal binomial model</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_method">method</code></td>
<td>
<p>Scoring method</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_response">response</code></td>
<td>
<p>name of response variable in data frame</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_id">id</code></td>
<td>
<p>name of cluster variable in data frame</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_nit">Nit</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_detail">detail</code></td>
<td>
<p>Detail for more output for iterations</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_silent">silent</code></td>
<td>
<p>Debug information</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_weights">weights</code></td>
<td>
<p>Weights for log-likelihood, can be used for each type of outcome in 2x2 tables.</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_control">control</code></td>
<td>
<p>Optimization arguments</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_theta">theta</code></td>
<td>
<p>Starting values for variance components</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_theta.formula">theta.formula</code></td>
<td>
<p>design for depedence, either formula or design function</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_desnames">desnames</code></td>
<td>
<p>names for dependence parameters</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_deshelp">deshelp</code></td>
<td>
<p>if 1 then prints out some data sets that are used, on on which the design function operates</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_var.link">var.link</code></td>
<td>
<p>Link function for variance</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_iid">iid</code></td>
<td>
<p>Calculate i.i.d. decomposition</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_step">step</code></td>
<td>
<p>Step size</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_marginal.p">marginal.p</code></td>
<td>
<p>vector of marginal probabilities</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_strata">strata</code></td>
<td>
<p>strata for fitting</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_max.clust">max.clust</code></td>
<td>
<p>max clusters used for i.i.d. decompostion</p>
</td></tr>
<tr><td><code id="easy.binomial.twostage_+3A_se.clusters">se.clusters</code></td>
<td>
<p>clusters for iid decomposition for roubst standard errors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reported standard errors are based on the estimated information from the
likelihood assuming that the marginals are known. This gives correct standard errors
in the case of the plackett distribution (OR model for dependence), but incorrect for
the clayton-oakes types model. The OR model is often known as the ALR model.
Our fitting procedures gives correct standard errors due to the ortogonality and is
fast.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(twinstut)
twinstut0 &lt;- subset(twinstut, tvparnr&lt;4000)
twinstut &lt;- twinstut0
twinstut$binstut &lt;- (twinstut$stutter=="yes")*1
theta.des &lt;- model.matrix( ~-1+factor(zyg),data=twinstut)
margbin &lt;- glm(binstut~factor(sex)+age,data=twinstut,family=binomial())
bin &lt;- binomial.twostage(margbin,data=twinstut,var.link=1,
		         clusters=twinstut$tvparnr,theta.des=theta.des,detail=0,
	                 method="nr")
summary(bin)
lava::estimate(coef=bin$theta,vcov=bin$var.theta,f=function(p) exp(p))

twinstut$cage &lt;- scale(twinstut$age)
theta.des &lt;- model.matrix( ~-1+factor(zyg)+cage,data=twinstut)
bina &lt;- binomial.twostage(margbin,data=twinstut,var.link=1,
		         clusters=twinstut$tvparnr,theta.des=theta.des,detail=0)
summary(bina)

theta.des &lt;- model.matrix( ~-1+factor(zyg)+factor(zyg)*cage,data=twinstut)
bina &lt;- binomial.twostage(margbin,data=twinstut,var.link=1,
		         clusters=twinstut$tvparnr,theta.des=theta.des)
summary(bina)

out &lt;- easy.binomial.twostage(stutter~factor(sex)+age,data=twinstut,
                              response="binstut",id="tvparnr",var.link=1,
			          theta.formula=~-1+factor(zyg1))
summary(out)

## refers to zygosity of first subject in eash pair : zyg1
## could also use zyg2 (since zyg2=zyg1 within twinpair's))
## do not run t save time
# desfs &lt;- function(x,num1="zyg1",namesdes=c("mz","dz","os"))
#     c(x[num1]=="mz",x[num1]=="dz",x[num1]=="os")*1
#
#out3 &lt;- easy.binomial.twostage(binstut~factor(sex)+age,
#                               data=twinstut, response="binstut",id="tvparnr",
#                               var.link=1,theta.formula=desfs,
#                               desnames=c("mz","dz","os"))
#summary(out3)

 ## Reduce Ex.Timings
n &lt;- 1000
set.seed(100)
dd &lt;- simBinFam(n,beta=0.3)
binfam &lt;- fast.reshape(dd,varying=c("age","x","y"))
## mother, father, children  (ordered)
head(binfam)

########### ########### ########### ########### ########### ###########
####  simple analyses of binomial family data
########### ########### ########### ########### ########### ###########
desfs &lt;- function(x,num1="num1",num2="num2")
{
     pp &lt;- 1*(((x[num1]=="m")*(x[num2]=="f"))|(x[num1]=="f")*(x[num2]=="m"))
     pc &lt;- (x[num1]=="m" | x[num1]=="f")*(x[num2]=="b1" | x[num2]=="b2")*1
     cc &lt;- (x[num1]=="b1")*(x[num2]=="b1" | x[num2]=="b2")*1
     c(pp,pc,cc)
}

ud &lt;- easy.binomial.twostage(y~+1,data=binfam,
     response="y",id="id",
     theta.formula=desfs,desnames=c("pp","pc","cc"))
summary(ud)

udx &lt;- easy.binomial.twostage(y~+x,data=binfam,
     response="y",id="id",
     theta.formula=desfs,desnames=c("pp","pc","cc"))
summary(udx)

########### ########### ########### ########### ########### ###########
####  now allowing parent child POR to be different for mother and father
########### ########### ########### ########### ########### ###########

desfsi &lt;- function(x,num1="num1",num2="num2")
{
    pp &lt;- (x[num1]=="m")*(x[num2]=="f")*1
    mc &lt;- (x[num1]=="m")*(x[num2]=="b1" | x[num2]=="b2")*1
    fc &lt;- (x[num1]=="f")*(x[num2]=="b1" | x[num2]=="b2")*1
    cc &lt;- (x[num1]=="b1")*(x[num2]=="b1" | x[num2]=="b2")*1
    c(pp,mc,fc,cc)
}

udi &lt;- easy.binomial.twostage(y~+1,data=binfam,
     response="y",id="id",
     theta.formula=desfsi,desnames=c("pp","mother-child","father-child","cc"))
summary(udi)

##now looking to see if interactions with age or age influences marginal models
##converting factors to numeric to make all involved covariates numeric
##to use desfai2 rather then desfai that works on binfam

nbinfam &lt;- binfam
nbinfam$num &lt;- as.numeric(binfam$num)
head(nbinfam)

desfsai &lt;- function(x,num1="num1",num2="num2")
{
    pp &lt;- (x[num1]=="m")*(x[num2]=="f")*1
### av age for pp=1 i.e parent pairs
    agepp &lt;- ((as.numeric(x["age1"])+as.numeric(x["age2"]))/2-30)*pp
    mc &lt;- (x[num1]=="m")*(x[num2]=="b1" | x[num2]=="b2")*1
    fc &lt;- (x[num1]=="f")*(x[num2]=="b1" | x[num2]=="b2")*1
    cc &lt;- (x[num1]=="b1")*(x[num2]=="b1" | x[num2]=="b2")*1
    agecc &lt;- ((as.numeric(x["age1"])+as.numeric(x["age2"]))/2-12)*cc
    c(pp,agepp,mc,fc,cc,agecc)
}

desfsai2 &lt;- function(x,num1="num1",num2="num2")
{
    pp &lt;- (x[num1]==1)*(x[num2]==2)*1
    agepp &lt;- (((x["age1"]+x["age2"]))/2-30)*pp ### av age for pp=1 i.e parent pairs
    mc &lt;- (x[num1]==1)*(x[num2]==3 | x[num2]==4)*1
    fc &lt;- (x[num1]==2)*(x[num2]==3 | x[num2]==4)*1
    cc &lt;- (x[num1]==3)*(x[num2]==3 | x[num2]==4)*1
    agecc &lt;- ((x["age1"]+x["age2"])/2-12)*cc ### av age for children
    c(pp,agepp,mc,fc,cc,agecc)
}

udxai2 &lt;- easy.binomial.twostage(y~+x+age,data=binfam,
     response="y",id="id",
     theta.formula=desfsai,
     desnames=c("pp","pp-age","mother-child","father-child","cc","cc-age"))
summary(udxai2)

</code></pre>

<hr>
<h2 id='Effbinreg'>Efficient IPCW for binary data</h2><span id='topic+Effbinreg'></span>

<h3>Description</h3>

<p>Simple version of comp.risk function of timereg for just one time-point thus fitting the model 
</p>
<p style="text-align: center;"><code class="reqn">E(T \leq t | X ) = expit( X^T beta) </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>Effbinreg(
  formula,
  data,
  cause = 1,
  time = NULL,
  beta = NULL,
  offset = NULL,
  weights = NULL,
  cens.weights = NULL,
  cens.model = ~+1,
  se = TRUE,
  kaplan.meier = TRUE,
  cens.code = 0,
  no.opt = FALSE,
  method = "nr",
  augmentation = NULL,
  h = NULL,
  MCaugment = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Effbinreg_+3A_formula">formula</code></td>
<td>
<p>formula with outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_cause">cause</code></td>
<td>
<p>cause of interest</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_time">time</code></td>
<td>
<p>time of interest</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_beta">beta</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_offset">offset</code></td>
<td>
<p>offsets for partial likelihood</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_weights">weights</code></td>
<td>
<p>for score equations</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_cens.weights">cens.weights</code></td>
<td>
<p>censoring weights</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_cens.model">cens.model</code></td>
<td>
<p>only stratified cox model without covariates</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_se">se</code></td>
<td>
<p>to compute se's  based on IPCW</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_kaplan.meier">kaplan.meier</code></td>
<td>
<p>uses Kaplan-Meier for IPCW in contrast to exp(-Baseline)</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_cens.code">cens.code</code></td>
<td>
<p>gives censoring code</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_no.opt">no.opt</code></td>
<td>
<p>to not optimize</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_method">method</code></td>
<td>
<p>for optimization</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_augmentation">augmentation</code></td>
<td>
<p>to augment binomial regression</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_h">h</code></td>
<td>
<p>h for estimating equation</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_mcaugment">MCaugment</code></td>
<td>
<p>iid of h and censoring model</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
<tr><td><code id="Effbinreg_+3A_model">model</code></td>
<td>
<p>exp or linear</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on binomial regresion IPCW response estimating equation: 
</p>
<p style="text-align: center;"><code class="reqn"> X  ( \Delta (T \leq t)/G_c(T_i-) - expit( X^T beta)) = 0 </code>
</p>

<p>for IPCW adjusted responses. 
</p>
<p>Based on binomial regresion IPCW response estimating equation: 
</p>
<p style="text-align: center;"><code class="reqn"> h(X) X ( \Delta (T \leq t)/G_c(T_i-) - expit( X^T beta)) = 0 </code>
</p>

<p>for IPCW adjusted responses where $h$ is given as an argument together with iid of censoring with h. 
By using appropriately the h argument we can also do the efficient IPCW estimator estimator this works 
the prepsurv and prepcif for survival or competing risks data. In this case also the censoring martingale 
should be given for variance calculation and this also comes out of the prepsurv or prepcif functions. 
(Experimental version at this stage).
</p>
<p>Variance is based on  </p>
<p style="text-align: center;"><code class="reqn"> \sum w_i^2 </code>
</p>
<p> also with IPCW adjustment, and naive.var is variance 
under known censoring model. 
</p>
<p>Censoring model may depend on strata.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='EVaddGam'>Relative risk for additive gamma model</h2><span id='topic+EVaddGam'></span>

<h3>Description</h3>

<p>Computes the relative risk for additive gamma model at time 0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EVaddGam(theta, x1, x2, thetades, ags)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EVaddGam_+3A_theta">theta</code></td>
<td>
<p>theta</p>
</td></tr>
<tr><td><code id="EVaddGam_+3A_x1">x1</code></td>
<td>
<p>x1</p>
</td></tr>
<tr><td><code id="EVaddGam_+3A_x2">x2</code></td>
<td>
<p>x2</p>
</td></tr>
<tr><td><code id="EVaddGam_+3A_thetades">thetades</code></td>
<td>
<p>thetades</p>
</td></tr>
<tr><td><code id="EVaddGam_+3A_ags">ags</code></td>
<td>
<p>ags</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Eriksson and Scheike (2015), Additive Gamma frailty models for competing risks data, Biometrics (2015)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lam0 &lt;- c(0.5,0.3)
pars &lt;- c(1,1,1,1,0,1)
## genetic random effects, cause1, cause2 and overall
parg &lt;- pars[c(1,3,5)]
## environmental random effects, cause1, cause2 and overall
parc &lt;- pars[c(2,4,6)]

## simulate competing risks with two causes with hazards 0.5 and 0.3
## ace for each cause, and overall ace
out &lt;- simCompete.twin.ace(10000,parg,parc,0,2,lam0=lam0,overall=1,all.sum=1)

## setting up design for running the model
mm &lt;- familycluster.index(out$cluster)
head(mm$familypairindex,n=10)
pairs &lt;- matrix(mm$familypairindex,ncol=2,byrow=TRUE)
tail(pairs,n=12)
#
kinship &lt;- (out[pairs[,1],"zyg"]=="MZ")+ (out[pairs[,1],"zyg"]=="DZ")*0.5

# dout &lt;- make.pairwise.design.competing(pairs,kinship,
#          type="ace",compete=length(lam0),overall=1)
# head(dout$ant.rvs)
## MZ
# dim(dout$theta.des)
# dout$random.design[,,1]
## DZ
# dout$theta.des[,,nrow(pairs)]
# dout$random.design[,,nrow(pairs)]
#
# thetades &lt;- dout$theta.des[,,1]
# x &lt;- dout$random.design[,,1]
# x
##EVaddGam(rep(1,6),x[1,],x[3,],thetades,matrix(1,18,6))

# thetades &lt;- dout$theta.des[,,nrow(out)/2]
# x &lt;- dout$random.design[,,nrow(out)/2]
##EVaddGam(rep(1,6),x[1,],x[4,],thetades,matrix(1,18,6))
</code></pre>

<hr>
<h2 id='evalTerminal'>Evaluates piece constant covariates at min(D,t) where D is a terminal event</h2><span id='topic+evalTerminal'></span>

<h3>Description</h3>

<p>returns X(min(D,t)) and min(D,t) and their ratio. for censored observation 0. 
to use with the IPCW models implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evalTerminal(formula, data = data, death.code = 2, time = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evalTerminal_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event' outcome and X to evaluate at min(D,t)</p>
</td></tr>
<tr><td><code id="evalTerminal_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="evalTerminal_+3A_death.code">death.code</code></td>
<td>
<p>codes for death (terminating event, 2 default)</p>
</td></tr>
<tr><td><code id="evalTerminal_+3A_time">time</code></td>
<td>
<p>for evaluation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='Event'>Event history object</h2><span id='topic+Event'></span><span id='topic+as.character.Event'></span><span id='topic+as.matrix.Event'></span><span id='topic++5B.Event'></span><span id='topic+format.Event'></span><span id='topic+print.Event'></span><span id='topic+rbind.Event'></span><span id='topic+summary.Event'></span>

<h3>Description</h3>

<p>Constructur for Event History objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Event(time, time2 = TRUE, cause = NULL, cens.code = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Event_+3A_time">time</code></td>
<td>
<p>Time</p>
</td></tr>
<tr><td><code id="Event_+3A_time2">time2</code></td>
<td>
<p>Time 2</p>
</td></tr>
<tr><td><code id="Event_+3A_cause">cause</code></td>
<td>
<p>Cause</p>
</td></tr>
<tr><td><code id="Event_+3A_cens.code">cens.code</code></td>
<td>
<p>Censoring code (default 0)</p>
</td></tr>
<tr><td><code id="Event_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>... content for details
</p>


<h3>Value</h3>

<p>Object of class Event (a matrix)
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst and Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
	t1 &lt;- 1:10
	t2 &lt;- t1+runif(10)
	ca &lt;- rbinom(10,2,0.4)
	(x &lt;- Event(t1,t2,ca))

</code></pre>

<hr>
<h2 id='event.split'>event.split (SurvSplit).</h2><span id='topic+event.split'></span>

<h3>Description</h3>

<p>contstructs start stop formulation of event time data after a variable in
the data.set. Similar to SurvSplit of the survival package but can also
split after random time given in data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>event.split(
  data,
  time = "time",
  status = "status",
  cuts = "cuts",
  name.id = "id",
  name.start = "start",
  cens.code = 0,
  order.id = TRUE,
  time.group = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="event.split_+3A_data">data</code></td>
<td>
<p>data to be split</p>
</td></tr>
<tr><td><code id="event.split_+3A_time">time</code></td>
<td>
<p>time variable.</p>
</td></tr>
<tr><td><code id="event.split_+3A_status">status</code></td>
<td>
<p>status variable.</p>
</td></tr>
<tr><td><code id="event.split_+3A_cuts">cuts</code></td>
<td>
<p>cuts variable or numeric cut (only one value)</p>
</td></tr>
<tr><td><code id="event.split_+3A_name.id">name.id</code></td>
<td>
<p>name of id variable.</p>
</td></tr>
<tr><td><code id="event.split_+3A_name.start">name.start</code></td>
<td>
<p>name of start variable in data, start can also be numeric &quot;0&quot;</p>
</td></tr>
<tr><td><code id="event.split_+3A_cens.code">cens.code</code></td>
<td>
<p>code for the censoring.</p>
</td></tr>
<tr><td><code id="event.split_+3A_order.id">order.id</code></td>
<td>
<p>order data after id and start.</p>
</td></tr>
<tr><td><code id="event.split_+3A_time.group">time.group</code></td>
<td>
<p>make variable &quot;before&quot;.&quot;cut&quot; that keeps track of wether start,stop is before (1) or after cut (0).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
d &lt;- data.frame(event=round(5*runif(5),2),start=1:5,time=2*1:5,
		status=rbinom(5,1,0.5),x=1:5)
d

d0 &lt;- event.split(d,cuts="event",name.start=0)
d0

dd &lt;- event.split(d,cuts="event")
dd
ddd &lt;- event.split(dd,cuts=3.5)
ddd
event.split(ddd,cuts=5.5)

### successive cutting for many values 
dd &lt;- d
for  (cuts in seq(2,3,by=0.3)) dd &lt;- event.split(dd,cuts=cuts)
dd

###########################################################################
### same but for situation with multiple events along the time-axis
###########################################################################
d &lt;- data.frame(event1=1:5+runif(5)*0.5,start=1:5,time=2*1:5,
		status=rbinom(5,1,0.5),x=1:5,start0=0)
d$event2 &lt;- d$event1+0.2
d$event2[4:5] &lt;- NA 
d

d0 &lt;- event.split(d,cuts="event1",name.start="start",time="time",status="status")
d0
###
d00 &lt;- event.split(d0,cuts="event2",name.start="start",time="time",status="status")
d00

</code></pre>

<hr>
<h2 id='eventpois'>Extract survival estimates from lifetable analysis</h2><span id='topic+eventpois'></span><span id='topic+pcif'></span>

<h3>Description</h3>

<p>Summary for survival analyses via the 'lifetable' function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eventpois(
  object,
  ...,
  timevar,
  time,
  int.len,
  confint = FALSE,
  level = 0.95,
  individual = FALSE,
  length.out = 25
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eventpois_+3A_object">object</code></td>
<td>
<p>glm object (poisson regression)</p>
</td></tr>
<tr><td><code id="eventpois_+3A_...">...</code></td>
<td>
<p>Contrast arguments</p>
</td></tr>
<tr><td><code id="eventpois_+3A_timevar">timevar</code></td>
<td>
<p>Name of time variable</p>
</td></tr>
<tr><td><code id="eventpois_+3A_time">time</code></td>
<td>
<p>Time points (optional)</p>
</td></tr>
<tr><td><code id="eventpois_+3A_int.len">int.len</code></td>
<td>
<p>Time interval length (optional)</p>
</td></tr>
<tr><td><code id="eventpois_+3A_confint">confint</code></td>
<td>
<p>If TRUE confidence limits are supplied</p>
</td></tr>
<tr><td><code id="eventpois_+3A_level">level</code></td>
<td>
<p>Level of confidence limits</p>
</td></tr>
<tr><td><code id="eventpois_+3A_individual">individual</code></td>
<td>
<p>Individual predictions</p>
</td></tr>
<tr><td><code id="eventpois_+3A_length.out">length.out</code></td>
<td>
<p>Length of time vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Summary for survival analyses via the 'lifetable' function
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='EventSplit'>Event split with two time-scales, time and gaptime</h2><span id='topic+EventSplit'></span>

<h3>Description</h3>

<p>splits after cut times for the two time-scales.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EventSplit(
  data,
  time = "time",
  status = "status",
  entry = "start",
  cuts = "cuts",
  name.id = "id",
  gaptime = NULL,
  gaptime.entry = NULL,
  cuttime = c("time", "gaptime"),
  cens.code = 0,
  order.id = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EventSplit_+3A_data">data</code></td>
<td>
<p>data to be split</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_time">time</code></td>
<td>
<p>time variable.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_status">status</code></td>
<td>
<p>status variable.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_entry">entry</code></td>
<td>
<p>name of entry variable.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_cuts">cuts</code></td>
<td>
<p>cuts variable or numeric cut (only one value)</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_name.id">name.id</code></td>
<td>
<p>name of id variable.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_gaptime">gaptime</code></td>
<td>
<p>gaptime variable.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_gaptime.entry">gaptime.entry</code></td>
<td>
<p>name of entry variable for gaptime.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_cuttime">cuttime</code></td>
<td>
<p>to cut after time or gaptime</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_cens.code">cens.code</code></td>
<td>
<p>code for the censoring.</p>
</td></tr>
<tr><td><code id="EventSplit_+3A_order.id">order.id</code></td>
<td>
<p>order data after id and start.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rr  &lt;- data.frame(time=c(500,1000),start=c(0,500),status=c(1,1),id=c(1,1))
rr$gaptime &lt;-  rr$time-rr$start
rr$gapstart &lt;- 0

rr1 &lt;- EventSplit(rr,cuts=600,cuttime="time",   gaptime="gaptime",gaptime.entry="gapstart")
rr2 &lt;- EventSplit(rr1,cuts=100,cuttime="gaptime",gaptime="gaptime",gaptime.entry="gapstart")

dlist(rr1,start-time+status+gapstart+gaptime~id)
dlist(rr2,start-time+status+gapstart+gaptime~id)

</code></pre>

<hr>
<h2 id='familycluster.index'>Finds all pairs within a cluster (family)</h2><span id='topic+familycluster.index'></span>

<h3>Description</h3>

<p>Finds all pairs within a cluster (family)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>familycluster.index(clusters, index.type = FALSE, num = NULL, Rindex = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="familycluster.index_+3A_clusters">clusters</code></td>
<td>
<p>list of indeces</p>
</td></tr>
<tr><td><code id="familycluster.index_+3A_index.type">index.type</code></td>
<td>
<p>argument of cluster index</p>
</td></tr>
<tr><td><code id="familycluster.index_+3A_num">num</code></td>
<td>
<p>num</p>
</td></tr>
<tr><td><code id="familycluster.index_+3A_rindex">Rindex</code></td>
<td>
<p>index starts with 1 in R, and 0 in C</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Holst, Thomas Scheike
</p>


<h3>References</h3>

<p>Cluster indeces
</p>


<h3>See Also</h3>

<p>cluster.index familyclusterWithProbands.index
</p>


<h3>Examples</h3>

<pre><code class='language-R'>i&lt;-c(1,1,2,2,1,3)
d&lt;- familycluster.index(i)
print(d)
</code></pre>

<hr>
<h2 id='familyclusterWithProbands.index'>Finds all pairs within a cluster (famly)  with the proband (case/control)</h2><span id='topic+familyclusterWithProbands.index'></span>

<h3>Description</h3>

<p>second column of pairs are the probands and the first column the related subjects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>familyclusterWithProbands.index(
  clusters,
  probands,
  index.type = FALSE,
  num = NULL,
  Rindex = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="familyclusterWithProbands.index_+3A_clusters">clusters</code></td>
<td>
<p>list of indeces giving the clusters (families)</p>
</td></tr>
<tr><td><code id="familyclusterWithProbands.index_+3A_probands">probands</code></td>
<td>
<p>list of 0,1 where 1 specifices which of the subjects that are probands</p>
</td></tr>
<tr><td><code id="familyclusterWithProbands.index_+3A_index.type">index.type</code></td>
<td>
<p>argument passed to other functions</p>
</td></tr>
<tr><td><code id="familyclusterWithProbands.index_+3A_num">num</code></td>
<td>
<p>argument passed to other functions</p>
</td></tr>
<tr><td><code id="familyclusterWithProbands.index_+3A_rindex">Rindex</code></td>
<td>
<p>index starts with 1, in C is it is 0</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Holst, Thomas Scheike
</p>


<h3>References</h3>

<p>Cluster indeces
</p>


<h3>See Also</h3>

<p>familycluster.index cluster.index
</p>


<h3>Examples</h3>

<pre><code class='language-R'>i&lt;-c(1,1,2,2,1,3)
p&lt;-c(1,0,0,1,0,1)
d&lt;- familyclusterWithProbands.index(i,p)
print(d)
</code></pre>

<hr>
<h2 id='fast.approx'>Fast approximation</h2><span id='topic+fast.approx'></span><span id='topic+indexstrata'></span><span id='topic+predictCumhaz'></span><span id='topic+cpred'></span>

<h3>Description</h3>

<p>Fast approximation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast.approx(
  time,
  new.time,
  equal = FALSE,
  type = c("nearest", "right", "left"),
  sorted = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fast.approx_+3A_time">time</code></td>
<td>
<p>Original ordered time points</p>
</td></tr>
<tr><td><code id="fast.approx_+3A_new.time">new.time</code></td>
<td>
<p>New time points</p>
</td></tr>
<tr><td><code id="fast.approx_+3A_equal">equal</code></td>
<td>
<p>If TRUE a list is returned with additional element</p>
</td></tr>
<tr><td><code id="fast.approx_+3A_type">type</code></td>
<td>
<p>Type of matching, nearest index, nearest greater than
or equal (right), number of elements smaller than y otherwise
the closest value above new.time is returned.</p>
</td></tr>
<tr><td><code id="fast.approx_+3A_sorted">sorted</code></td>
<td>
<p>Set to true if new.time is already sorted</p>
</td></tr>
<tr><td><code id="fast.approx_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>id &lt;- c(1,1,2,2,7,7,10,10)
fast.approx(unique(id),id)

t &lt;- 0:6
n &lt;- c(-1,0,0.1,0.9,1,1.1,1.2,6,6.5)
fast.approx(t,n,type="left")
</code></pre>

<hr>
<h2 id='fast.pattern'>Fast pattern</h2><span id='topic+fast.pattern'></span>

<h3>Description</h3>

<p>Fast pattern
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast.pattern(x, y, categories = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fast.pattern_+3A_x">x</code></td>
<td>
<p>Matrix (binary) of patterns. Optionally if <code>y</code> is
also passed as argument, then the pattern matrix is defined as the
elements agreeing in the two matrices.</p>
</td></tr>
<tr><td><code id="fast.pattern_+3A_y">y</code></td>
<td>
<p>Optional matrix argument with same dimensions as <code>x</code> (see above)</p>
</td></tr>
<tr><td><code id="fast.pattern_+3A_categories">categories</code></td>
<td>
<p>Default 2 (binary)</p>
</td></tr>
<tr><td><code id="fast.pattern_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rbinom(100,1,0.5),ncol=4)
fast.pattern(X)

X &lt;- matrix(rbinom(100,3,0.5),ncol=4)
fast.pattern(X,categories=4)
</code></pre>

<hr>
<h2 id='fast.reshape'>Fast reshape</h2><span id='topic+fast.reshape'></span><span id='topic+dreshape'></span>

<h3>Description</h3>

<p>Fast reshape/tranpose of data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast.reshape(
  data,
  varying,
  id,
  num,
  sep = "",
  keep,
  idname = "id",
  numname = "num",
  factor = FALSE,
  idcombine = TRUE,
  labelnum = FALSE,
  labels,
  regex = mets.options()$regex,
  dropid = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fast.reshape_+3A_data">data</code></td>
<td>
<p>data.frame or matrix</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_varying">varying</code></td>
<td>
<p>Vector of prefix-names of the time varying variables. Optional for Long-&gt;Wide reshaping.</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_id">id</code></td>
<td>
<p>id-variable. If omitted then reshape Wide-&gt;Long.</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_num">num</code></td>
<td>
<p>Optional number/time variable</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_sep">sep</code></td>
<td>
<p>String seperating prefix-name with number/time</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_keep">keep</code></td>
<td>
<p>Vector of column names to keep</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_idname">idname</code></td>
<td>
<p>Name of id-variable (Wide-&gt;Long)</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_numname">numname</code></td>
<td>
<p>Name of number-variable (Wide-&gt;Long)</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_factor">factor</code></td>
<td>
<p>If true all factors are kept (otherwise treated as character)</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_idcombine">idcombine</code></td>
<td>
<p>If TRUE and <code>id</code> is vector of several variables, the unique id is combined from all the variables.
Otherwise the first variable is only used as identifier.</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_labelnum">labelnum</code></td>
<td>
<p>If TRUE varying variables in wide format (going from long-&gt;wide) are labeled 1,2,3,... otherwise use 'num' variable. In long-format (going from wide-&gt;long) varying variables matching 'varying' prefix are only selected if their postfix is a number.</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_labels">labels</code></td>
<td>
<p>Optional labels for the number variable</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_regex">regex</code></td>
<td>
<p>Use regular expressions</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_dropid">dropid</code></td>
<td>
<p>Drop id in long format (default FALSE)</p>
</td></tr>
<tr><td><code id="fast.reshape_+3A_...">...</code></td>
<td>
<p>Optional additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike, Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- lava::lvm(c(y1,y2,y3,y4)~x)
d &lt;- lava::sim(m,5)
d
fast.reshape(d,"y")
fast.reshape(fast.reshape(d,"y"),id="id")

##### From wide-format
(dd &lt;- fast.reshape(d,"y"))
## Same with explicit setting new id and number variable/column names
## and seperator "" (default) and dropping x
fast.reshape(d,"y",idname="a",timevar="b",sep="",keep=c())
## Same with 'reshape' list-syntax
fast.reshape(d,list(c("y1","y2","y3","y4")),labelnum=TRUE)

##### From long-format
fast.reshape(dd,id="id")
## Restrict set up within-cluster varying variables
fast.reshape(dd,"y",id="id")
fast.reshape(dd,"y",id="id",keep="x",sep=".")

#####
x &lt;- data.frame(id=c(5,5,6,6,7),y=1:5,x=1:5,tv=c(1,2,2,1,2))
x
(xw &lt;- fast.reshape(x,id="id"))
(xl &lt;- fast.reshape(xw,c("y","x"),idname="id2",keep=c()))
(xl &lt;- fast.reshape(xw,c("y","x","tv")))
(xw2 &lt;- fast.reshape(xl,id="id",num="num"))
fast.reshape(xw2,c("y","x"),idname="id")

### more generally:
### varying=list(c("ym","yf","yb1","yb2"), c("zm","zf","zb1","zb2"))
### varying=list(c("ym","yf","yb1","yb2")))

##### Family cluster example
d &lt;- mets:::simBinFam(3)
d
fast.reshape(d,var="y")
fast.reshape(d,varying=list(c("ym","yf","yb1","yb2")))

d &lt;- lava::sim(lava::lvm(~y1+y2+ya),10)
d
(dd &lt;- fast.reshape(d,"y"))
fast.reshape(d,"y",labelnum=TRUE)
fast.reshape(dd,id="id",num="num")
fast.reshape(dd,id="id",num="num",labelnum=TRUE)
fast.reshape(d,c(a="y"),labelnum=TRUE) ## New column name


##### Unbalanced data
m &lt;- lava::lvm(c(y1,y2,y3,y4)~ x+z1+z3+z5)
d &lt;- lava::sim(m,3)
d
fast.reshape(d,c("y","z"))

##### not-varying syntax:
fast.reshape(d,-c("x"))

##### Automatically define varying variables from trailing digits
fast.reshape(d)

##### Prostate cancer example
data(prt)
head(prtw &lt;- fast.reshape(prt,"cancer",id="id"))
ftable(cancer1~cancer2,data=prtw)
rm(prtw)
</code></pre>

<hr>
<h2 id='FG_AugmentCifstrata'>Augmentation for Fine-Gray model based on stratified NPMLE Cif (Aalen-Johansen)</h2><span id='topic+FG_AugmentCifstrata'></span><span id='topic+strataC'></span><span id='topic+simul.cifs'></span><span id='topic+setup.cif'></span><span id='topic+drop.strata'></span>

<h3>Description</h3>

<p>Computes  the augmentation term for each individual as well as the sum
</p>
<p style="text-align: center;"><code class="reqn">
A(\beta) = \int H(t,X,\beta) \frac{F_2^*(t,s)}{S^*(t,s)} \frac{1}{G_c(t)} dM_c
</code>
</p>

<p>with
</p>
<p style="text-align: center;"><code class="reqn">
H(t,X,\beta) = \int_t^\infty (X - E(\beta,t) ) G_c(t) d\Lambda_1^*i(t,s)
</code>
</p>

<p>using a KM for </p>
<p style="text-align: center;"><code class="reqn">G_c(t)</code>
</p>
<p> and a working model for cumulative baseline
related to </p>
<p style="text-align: center;"><code class="reqn">F_1^*(t,s)</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">s</code>
</p>
<p> is strata,
</p>
<p style="text-align: center;"><code class="reqn">S^*(t,s) = 1 - F_1^*(t,s) - F_2^*(t,s)</code>
</p>
<p>, and
</p>
<p style="text-align: center;"><code class="reqn">E(\beta^p,t)</code>
</p>
<p> is given. Assumes that no strata for baseline of ine-Gay model that is augmented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FG_AugmentCifstrata(
  formula,
  data = data,
  E = NULL,
  cause = NULL,
  cens.code = 0,
  km = TRUE,
  case.weights = NULL,
  weights = NULL,
  offset = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FG_AugmentCifstrata_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event', strata model for CIF given by strata, and strataC specifies censoring strata</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_e">E</code></td>
<td>
<p>from FG-model</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_cause">cause</code></td>
<td>
<p>of interest</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_cens.code">cens.code</code></td>
<td>
<p>code of censoring</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_km">km</code></td>
<td>
<p>to use Kaplan-Meier</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_case.weights">case.weights</code></td>
<td>
<p>weights for FG score equations (that follow dN_1)</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_weights">weights</code></td>
<td>
<p>weights for FG score equations</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_offset">offset</code></td>
<td>
<p>offsets for FG   model</p>
</td></tr>
<tr><td><code id="FG_AugmentCifstrata_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After a couple of iterations we end up with a solution of
</p>
<p style="text-align: center;"><code class="reqn">
\int (X - E(\beta) ) Y_1(t) w(t) dM_1 + A(\beta)
</code>
</p>

<p>the augmented FG-score.
</p>
<p>Standard errors computed under assumption of correct </p>
<p style="text-align: center;"><code class="reqn">G_c</code>
</p>
<p> model.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)
rho1 &lt;- 0.2; rho2 &lt;- 10
n &lt;- 400
beta=c(0.0,-0.1,-0.5,0.3)
dats &lt;- simul.cifs(n,rho1,rho2,beta,rc=0.2)
dtable(dats,~status)
dsort(dats) &lt;- ~time
fg &lt;- cifreg(Event(time,status)~Z1+Z2,data=dats,cause=1,propodds=NULL)
summary(fg)

fgaugS &lt;- FG_AugmentCifstrata(Event(time,status)~Z1+Z2+strata(Z1,Z2),data=dats,cause=1,E=fg$E)
summary(fgaugS)
fgaugS2 &lt;- FG_AugmentCifstrata(Event(time,status)~Z1+Z2+strata(Z1,Z2),data=dats,cause=1,E=fgaugS$E)
summary(fgaugS2)

</code></pre>

<hr>
<h2 id='ghaplos'>ghaplos  haplo-types for subjects of haploX data</h2><span id='topic+ghaplos'></span>

<h3>Description</h3>

<p>ghaplos  haplo-types for subjects of haploX data
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='glm_IPTW'>IPTW GLM, Inverse Probaibilty of Treatment Weighted GLM</h2><span id='topic+glm_IPTW'></span>

<h3>Description</h3>

<p>Fits GLM model with treatment weights </p>
<p style="text-align: center;"><code class="reqn"> w(A)= \sum_a I(A=a)/P(A=a|X) </code>
</p>
<p>, computes
standard errors via influence functions that are returned as the IID argument. 
Propensity scores are fitted using either logistic regression (glm) or the multinomial model (mlogit) when more
than two categories for treatment. The treatment needs to be a factor and is identified on the rhs
of the &quot;treat.model&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm_IPTW(
  formula,
  data,
  treat.model = NULL,
  family = binomial(),
  id = NULL,
  weights = NULL,
  estpr = 1,
  pi0 = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm_IPTW_+3A_formula">formula</code></td>
<td>
<p>for glm</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_data">data</code></td>
<td>
<p>data frame for risk averaging</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_treat.model">treat.model</code></td>
<td>
<p>propensity score model (binary or multinomial)</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_family">family</code></td>
<td>
<p>of glm (logistic regression)</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_id">id</code></td>
<td>
<p>cluster id for standard errors</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_weights">weights</code></td>
<td>
<p>may be given, and then uses weights*w(A) as the weights</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_estpr">estpr</code></td>
<td>
<p>to estimate propensity scores and get infuence function contribution to uncertainty</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_pi0">pi0</code></td>
<td>
<p>fixed simple weights</p>
</td></tr>
<tr><td><code id="glm_IPTW_+3A_...">...</code></td>
<td>
<p>arguments for glm call</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also works with cluster argument.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='gof.phreg'>GOF for Cox PH regression</h2><span id='topic+gof.phreg'></span>

<h3>Description</h3>

<p>Cumulative score process residuals for Cox PH regression
p-values based on Lin, Wei, Ying resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'phreg'
gof(object, n.sim = 1000, silent = 1, robust = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gof.phreg_+3A_object">object</code></td>
<td>
<p>is phreg object</p>
</td></tr>
<tr><td><code id="gof.phreg_+3A_n.sim">n.sim</code></td>
<td>
<p>number of simulations for score processes</p>
</td></tr>
<tr><td><code id="gof.phreg_+3A_silent">silent</code></td>
<td>
<p>to show timing estimate will be produced for longer jobs</p>
</td></tr>
<tr><td><code id="gof.phreg_+3A_robust">robust</code></td>
<td>
<p>to control wether robust dM_i(t) or dN_i  are used for simulations</p>
</td></tr>
<tr><td><code id="gof.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike and Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mets)
data(sTRACE)

m1 &lt;- phreg(Surv(time,status==9)~vf+chf+diabetes,data=sTRACE) 
gg &lt;- gof(m1)
gg
par(mfrow=c(1,3))
plot(gg)

m1 &lt;- phreg(Surv(time,status==9)~strata(vf)+chf+diabetes,data=sTRACE) 
## to get Martingale ~ dN based simulations
gg &lt;- gof(m1)
gg

## to get Martingale robust simulations, specify cluster in  call 
sTRACE$id &lt;- 1:500
m1 &lt;- phreg(Surv(time,status==9)~vf+chf+diabetes+cluster(id),data=sTRACE) 
gg &lt;- gof(m1)
gg

m1 &lt;- phreg(Surv(time,status==9)~strata(vf)+chf+diabetes+cluster(id),data=sTRACE) 
gg &lt;- gof(m1)
gg
</code></pre>

<hr>
<h2 id='gofG.phreg'>Stratified baseline graphical GOF test for Cox covariates in PH regression</h2><span id='topic+gofG.phreg'></span>

<h3>Description</h3>

<p>Looks at stratified baseline in Cox model and plots all baselines versus each
other to see if lines are straight, with 50 resample versions under the 
assumptiosn that the stratified Cox is correct
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gofG.phreg(x, sim = 0, silent = 1, lm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gofG.phreg_+3A_x">x</code></td>
<td>
<p>phreg object</p>
</td></tr>
<tr><td><code id="gofG.phreg_+3A_sim">sim</code></td>
<td>
<p>to simulate som variation from cox model to put on graph</p>
</td></tr>
<tr><td><code id="gofG.phreg_+3A_silent">silent</code></td>
<td>
<p>to keep it absolutely silent</p>
</td></tr>
<tr><td><code id="gofG.phreg_+3A_lm">lm</code></td>
<td>
<p>addd line to plot, regressing the cumulatives on each other</p>
</td></tr>
<tr><td><code id="gofG.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike and Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tTRACE)

m1 &lt;- phreg(Surv(time,status==9)~strata(vf)+chf+wmi,data=tTRACE) 
m2 &lt;- phreg(Surv(time,status==9)~vf+strata(chf)+wmi,data=tTRACE) 
par(mfrow=c(2,2))

gofG.phreg(m1)
gofG.phreg(m2)

bplot(m1,log="y")
bplot(m2,log="y")
</code></pre>

<hr>
<h2 id='gofM.phreg'>GOF for Cox covariates in  PH regression</h2><span id='topic+gofM.phreg'></span>

<h3>Description</h3>

<p>Cumulative residuals after model matrix for Cox PH regression
p-values based on Lin, Wei, Ying resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gofM.phreg(
  formula,
  data,
  offset = NULL,
  weights = NULL,
  modelmatrix = NULL,
  n.sim = 1000,
  silent = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gofM.phreg_+3A_formula">formula</code></td>
<td>
<p>formula for cox regression</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_data">data</code></td>
<td>
<p>data for model</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_offset">offset</code></td>
<td>
<p>offset</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_modelmatrix">modelmatrix</code></td>
<td>
<p>matrix for cumulating residuals</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_n.sim">n.sim</code></td>
<td>
<p>number of simulations for score processes</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_silent">silent</code></td>
<td>
<p>to keep it absolutely silent, otherwise timing estimate will be prduced for longer jobs.</p>
</td></tr>
<tr><td><code id="gofM.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>That is, computes 
</p>
<p style="text-align: center;"><code class="reqn">
 U(t) = \int_0^t M^t d \hat M 
</code>
</p>

<p>and resamples its asymptotic distribution. 
</p>
<p>This will show if the residuals are consistent with the model. Typically,
M will be a design matrix for the continous covariates that gives for example
the quartiles, and then the plot will show if for the different quartiles of the covariate the risk
prediction is consistent over time  (time x covariate interaction).
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike and Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mets)
data(TRACE)
set.seed(1)
TRACEsam &lt;- blocksample(TRACE,idvar="id",replace=FALSE,100)

dcut(TRACEsam)  &lt;- ~. 
mm &lt;- model.matrix(~-1+factor(wmicat.4),data=TRACEsam)
m1 &lt;- gofM.phreg(Surv(time,status==9)~vf+chf+wmi,data=TRACEsam,modelmatrix=mm)
summary(m1)
if (interactive()) {
par(mfrow=c(2,2))
plot(m1)
}

m1 &lt;- gofM.phreg(Surv(time,status==9)~strata(vf)+chf+wmi,data=TRACEsam,modelmatrix=mm) 
summary(m1)

## cumulative sums in covariates, via design matrix mm 
mm &lt;- cumContr(TRACEsam$wmi,breaks=10,equi=TRUE)
m1 &lt;- gofM.phreg(Surv(time,status==9)~strata(vf)+chf+wmi,data=TRACEsam,
		  modelmatrix=mm,silent=0)
summary(m1)

</code></pre>

<hr>
<h2 id='gofZ.phreg'>GOF for Cox covariates in  PH regression</h2><span id='topic+gofZ.phreg'></span><span id='topic+cumContr'></span>

<h3>Description</h3>

<p>That is, computes 
</p>
<p style="text-align: center;"><code class="reqn">
 U(z,\tau) = \int_0^\tau M(z)^t d \hat M 
</code>
</p>

<p>and resamples its asymptotic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gofZ.phreg(
  formula,
  data,
  vars = NULL,
  offset = NULL,
  weights = NULL,
  breaks = 50,
  equi = FALSE,
  n.sim = 1000,
  silent = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gofZ.phreg_+3A_formula">formula</code></td>
<td>
<p>formula for cox regression</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_data">data</code></td>
<td>
<p>data for model</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_vars">vars</code></td>
<td>
<p>which variables to test for linearity</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_offset">offset</code></td>
<td>
<p>offset</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_breaks">breaks</code></td>
<td>
<p>number of breaks for cumulatives in covarirate direction</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_equi">equi</code></td>
<td>
<p>equidistant breaks  or not</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_n.sim">n.sim</code></td>
<td>
<p>number of simulations for score processes</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_silent">silent</code></td>
<td>
<p>to keep it absolutely silent, otherwise timing estimate will be prduced for longer jobs.</p>
</td></tr>
<tr><td><code id="gofZ.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This will show if the residuals are consistent with the model evaulated in the z covariate. 
M is here chosen based on a grid (z_1, ..., z_m) and the different columns are <code class="reqn">I(Z_i \leq z_l)</code>.
for <code class="reqn">l=1,...,m</code>. 
The process in z is resampled to find extreme values.  The time-points of evuluation is by default
50 points, chosen as 2
</p>
<p>The p-value is valid but depends on the chosen grid. When the number of break points are high
this will give the orginal test of Lin, Wei and Ying for linearity, that is also computed in 
the timereg package.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike and Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mets)
data(TRACE)
set.seed(1)
TRACEsam &lt;- blocksample(TRACE,idvar="id",replace=FALSE,100)

## cumulative sums in covariates, via design matrix mm
 ## Reduce Ex.Timings
m1 &lt;- gofZ.phreg(Surv(time,status==9)~strata(vf)+chf+wmi+age,data=TRACEsam)
summary(m1) 
plot(m1,type="z")

</code></pre>

<hr>
<h2 id='Grandom.cif'>Additive Random effects model for competing risks data for polygenetic modelling</h2><span id='topic+Grandom.cif'></span>

<h3>Description</h3>

<p>Fits a random effects  model describing the dependence in the cumulative 
incidence curves for subjects within a cluster.  Given the gamma distributed
random effects it is assumed that the cumulative incidence curves 
are indpendent, and that the marginal cumulative incidence curves 
are on additive form
</p>
<p style="text-align: center;"><code class="reqn">
P(T \leq t, cause=1 | x,z) = P_1(t,x,z) = 1- exp( -x^T A(t) - t z^T \beta)
</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>Grandom.cif(
  cif,
  data,
  cause = NULL,
  cif2 = NULL,
  times = NULL,
  cause1 = 1,
  cause2 = 1,
  cens.code = NULL,
  cens.model = "KM",
  Nit = 40,
  detail = 0,
  clusters = NULL,
  theta = NULL,
  theta.des = NULL,
  weights = NULL,
  step = 1,
  sym = 0,
  same.cens = FALSE,
  censoring.weights = NULL,
  silent = 1,
  var.link = 0,
  score.method = "nr",
  entry = NULL,
  estimator = 1,
  trunkp = 1,
  admin.cens = NULL,
  random.design = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Grandom.cif_+3A_cif">cif</code></td>
<td>
<p>a model object from the timereg::comp.risk function with the
marginal cumulative incidence of cause2, i.e., the event that is conditioned on, and whose
odds the comparision is made with respect to</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_data">data</code></td>
<td>
<p>a data.frame with the variables.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_cause">cause</code></td>
<td>
<p>specifies the causes  related to the death
times, the value cens.code is the censoring value.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_cif2">cif2</code></td>
<td>
<p>specificies model for cause2 if different from cause1.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_times">times</code></td>
<td>
<p>time points</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_cause1">cause1</code></td>
<td>
<p>cause of first coordinate.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_cause2">cause2</code></td>
<td>
<p>cause of second coordinate.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_cens.code">cens.code</code></td>
<td>
<p>specificies the code for the censoring if NULL then uses the one from the marginal cif model.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_cens.model">cens.model</code></td>
<td>
<p>specified which model to use for the ICPW, KM is Kaplan-Meier alternatively it may be &quot;cox&quot;</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_nit">Nit</code></td>
<td>
<p>number of iterations for Newton-Raphson algorithm.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_detail">detail</code></td>
<td>
<p>if 0 no details are printed during iterations, if 1 details are given.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_clusters">clusters</code></td>
<td>
<p>specifies the cluster structure.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_theta">theta</code></td>
<td>
<p>specifies starting values for the cross-odds-ratio parameters of the model.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_theta.des">theta.des</code></td>
<td>
<p>specifies a regression design for the cross-odds-ratio parameters.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_weights">weights</code></td>
<td>
<p>weights for score equations.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_step">step</code></td>
<td>
<p>specifies the step size for the Newton-Raphson algorith.m</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_sym">sym</code></td>
<td>
<p>1 for symmetri and 0 otherwise</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_same.cens">same.cens</code></td>
<td>
<p>if true then censoring within clusters are assumed to be the same variable, default is independent censoring.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_censoring.weights">censoring.weights</code></td>
<td>
<p>Censoring probabilities</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_silent">silent</code></td>
<td>
<p>debug information</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_var.link">var.link</code></td>
<td>
<p>if var.link=1 then var is on log-scale.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_score.method">score.method</code></td>
<td>
<p>default uses &quot;nlminb&quot; optimzer, alternatively, use the &quot;nr&quot; algorithm.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_entry">entry</code></td>
<td>
<p>entry-age in case of delayed entry. Then two causes must be given.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_estimator">estimator</code></td>
<td>
<p>estimator</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_trunkp">trunkp</code></td>
<td>
<p>gives probability of survival for delayed entry, and related to entry-ages given above.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_admin.cens">admin.cens</code></td>
<td>
<p>Administrative censoring</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_random.design">random.design</code></td>
<td>
<p>specifies a regression design of 0/1's for the random effects.</p>
</td></tr>
<tr><td><code id="Grandom.cif_+3A_...">...</code></td>
<td>
<p>extra arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We allow a regression structure for the indenpendent gamma distributed 
random effects  and their variances that may depend on cluster covariates.
</p>
<p>random.design specificies the random effects for each subject within a cluster. This is
a matrix of 1's and 0's with dimension n x d.  With d random effects. 
For a cluster with two subjects, we let the random.design rows be 
<code class="reqn">v_1</code> and <code class="reqn">v_2</code>. 
Such that the random effects for subject 
1 is </p>
<p style="text-align: center;"><code class="reqn">v_1^T (Z_1,...,Z_d)</code>
</p>
<p>, for d random effects. Each random effect
has an associated parameter <code class="reqn">(\lambda_1,...,\lambda_d)</code>. By construction
subjects 1's random effect are Gamma distributed with 
mean <code class="reqn">\lambda_1/v_1^T \lambda</code>
and variance <code class="reqn">\lambda_1/(v_1^T \lambda)^2</code>. Note that the random effect 
<code class="reqn">v_1^T (Z_1,...,Z_d)</code> has mean 1 and variance <code class="reqn">1/(v_1^T \lambda)</code>.
</p>
<p>The parameters <code class="reqn">(\lambda_1,...,\lambda_d)</code>
are related to the parameters of the model
by a regression construction <code class="reqn">pard</code> (d x k), that links the <code class="reqn">d</code> 
<code class="reqn">\lambda</code> parameters
with the (k) underlying <code class="reqn">\theta</code> parameters 
</p>
<p style="text-align: center;"><code class="reqn">
\lambda = pard \theta 
</code>
</p>



<h3>Value</h3>

<p>returns an object of type 'random.cif'. With the following arguments:
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>estimate of parameters of model.</p>
</td></tr>
<tr><td><code>var.theta</code></td>
<td>
<p>variance for gamma.  </p>
</td></tr>
<tr><td><code>hess</code></td>
<td>
<p>the derivative of the used score.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>scores at final stage.</p>
</td></tr>
<tr><td><code>theta.iid</code></td>
<td>
<p>matrix of iid decomposition of parametric effects.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>A Semiparametric Random Effects Model for Multivariate Competing Risks Data,
Scheike, Zhang, Sun, Jensen (2010), Biometrika.
</p>
<p>Cross odds ratio Modelling of dependence for
Multivariate Competing Risks Data, Scheike and Sun (2013), Biostatitistics.
</p>
<p>Scheike, Holst, Hjelmborg (2014),  LIDA,  
Estimating heritability for cause specific hazards based on twin data
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Reduce Ex.Timings
 d &lt;- simnordic.random(5000,delayed=TRUE,
       cordz=1.0,cormz=2,lam0=0.3,country=TRUE)
 times &lt;- seq(50,90,by=10)
 addm &lt;- timereg::comp.risk(Event(time,cause)~-1+factor(country)+cluster(id),data=d,
 times=times,cause=1,max.clust=NULL)

 ### making group indidcator 
 mm &lt;- model.matrix(~-1+factor(zyg),d)

 out1m&lt;-random.cif(addm,data=d,cause1=1,cause2=1,theta=1,
		   theta.des=mm,same.cens=TRUE)
 summary(out1m)
 
 ## this model can also be formulated as a random effects model 
 ## but with different parameters
 out2m&lt;-Grandom.cif(addm,data=d,cause1=1,cause2=1,
		    theta=c(0.5,1),step=1.0,
		    random.design=mm,same.cens=TRUE)
 summary(out2m)
 1/out2m$theta
 out1m$theta
 
 ####################################################################
 ################### ACE modelling of twin data #####################
 ####################################################################
 ### assume that zygbin gives the zygosity of mono and dizygotic twins
 ### 0 for mono and 1 for dizygotic twins. We now formulate and AC model
 zygbin &lt;- d$zyg=="DZ"

 n &lt;- nrow(d)
 ### random effects for each cluster
 des.rv &lt;- cbind(mm,(zygbin==1)*rep(c(1,0)),(zygbin==1)*rep(c(0,1)),1)
 ### design making parameters half the variance for dizygotic components
 pardes &lt;- rbind(c(1,0), c(0.5,0),c(0.5,0), c(0.5,0), c(0,1))

 outacem &lt;-Grandom.cif(addm,data=d,cause1=1,cause2=1,
		same.cens=TRUE,theta=c(0.35,0.15),
            step=1.0,theta.des=pardes,random.design=des.rv)
 summary(outacem)


</code></pre>

<hr>
<h2 id='hapfreqs'>hapfreqs data set</h2><span id='topic+hapfreqs'></span>

<h3>Description</h3>

<p>hapfreqs data set
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='haplo.surv.discrete'>Discrete time to event haplo type analysis</h2><span id='topic+haplo.surv.discrete'></span><span id='topic+simTTP'></span><span id='topic+predictSurvd'></span><span id='topic+plotSurvd'></span>

<h3>Description</h3>

<p>Can be used for logistic regression when time variable is &quot;1&quot; for all id.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>haplo.surv.discrete(
  X = NULL,
  y = "y",
  time.name = "time",
  Haplos = NULL,
  id = "id",
  desnames = NULL,
  designfunc = NULL,
  beta = NULL,
  no.opt = FALSE,
  method = "NR",
  stderr = TRUE,
  designMatrix = NULL,
  response = NULL,
  idhap = NULL,
  design.only = FALSE,
  covnames = NULL,
  fam = binomial,
  weights = NULL,
  offsets = NULL,
  idhapweights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="haplo.surv.discrete_+3A_x">X</code></td>
<td>
<p>design matrix data-frame (sorted after id and time variable) with id time response  and desnames</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_y">y</code></td>
<td>
<p>name of response (binary response with logistic link) from X</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_time.name">time.name</code></td>
<td>
<p>to sort after time  for X</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_haplos">Haplos</code></td>
<td>
<p>(data.frame with id, haplo1, haplo2 (haplotypes (h)) and  p=P(h|G)) haplotypes given as factor.</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_id">id</code></td>
<td>
<p>name of id variale from X</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_desnames">desnames</code></td>
<td>
<p>names for design matrix</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_designfunc">designfunc</code></td>
<td>
<p>function that computes design given haplotypes h=(h1,h2) x(h)</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_beta">beta</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_no.opt">no.opt</code></td>
<td>
<p>optimization TRUE/FALSE</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_method">method</code></td>
<td>
<p>NR, nlm</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_stderr">stderr</code></td>
<td>
<p>to return only estimate</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_designmatrix">designMatrix</code></td>
<td>
<p>gives response and designMatrix directly not implemented (mush contain: p, id, idhap)</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_response">response</code></td>
<td>
<p>gives response and design directly designMatrix not implemented</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_idhap">idhap</code></td>
<td>
<p>name of id-hap variable to specify different haplotypes for different id</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_design.only">design.only</code></td>
<td>
<p>to return only design matrices for haplo-type analyses.</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_covnames">covnames</code></td>
<td>
<p>names of covariates to extract from object for regression</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_fam">fam</code></td>
<td>
<p>family of models, now binomial default and only option</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_weights">weights</code></td>
<td>
<p>weights following id for GLM</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_offsets">offsets</code></td>
<td>
<p>following id  for GLM</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_idhapweights">idhapweights</code></td>
<td>
<p>weights following id-hap for GLM (WIP)</p>
</td></tr>
<tr><td><code id="haplo.surv.discrete_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions lava::NR  optimizer or nlm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cycle-specific logistic regression of haplo-type effects with known 
haplo-type probabilities. Given observed genotype G and unobserved haplotypes H
we here mix out over the possible haplotypes using that P(H|G) is provided. 
</p>
<p style="text-align: center;"><code class="reqn">
S(t|x,G)) = E( S(t|x,H) | G)  = \sum_{h \in G} P(h|G) S(t|z,h) 
</code>
</p>

<p>so survival can be computed by mixing out over possible h given g.
</p>
<p>Survival is based on logistic regression for the discrete hazard function of the
form 
</p>
<p style="text-align: center;"><code class="reqn">
logit(P(T=t| T \geq t, x,h)) = \alpha_t + x(h) \beta
</code>
</p>

<p>where x(h) is a regression design of x and haplotypes <code class="reqn">h=(h_1,h_2)</code>
</p>
<p>Likelihood is maximized and standard errors assumes that P(H|G) is known. 
</p>
<p>The design over the possible haplotypes is constructed by merging X with Haplos and  
can be viewed by design.only=TRUE
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## some haplotypes of interest
types &lt;- c("DCGCGCTCACG","DTCCGCTGACG","ITCAGTTGACG","ITCCGCTGAGG")

## some haplotypes frequencies for simulations 
data(hapfreqs)

www &lt;-which(hapfreqs$haplotype %in% types)
hapfreqs$freq[www]

baseline=hapfreqs$haplotype[9]
baseline

designftypes &lt;- function(x,sm=0) {# {{{
hap1=x[1]
hap2=x[2]
if (sm==0) y &lt;- 1*( (hap1==types) | (hap2==types))
if (sm==1) y &lt;- 1*(hap1==types) + 1*(hap2==types)
return(y)
}# }}}

tcoef=c(-1.93110204,-0.47531630,-0.04118204,-1.57872602,-0.22176426,-0.13836416,
0.88830288,0.60756224,0.39802821,0.32706859)

data(hHaplos)
data(haploX)

haploX$time &lt;- haploX$times
Xdes &lt;- model.matrix(~factor(time),haploX)
colnames(Xdes) &lt;- paste("X",1:ncol(Xdes),sep="")
X &lt;- dkeep(haploX,~id+y+time)
X &lt;- cbind(X,Xdes)
Haplos &lt;- dkeep(ghaplos,~id+"haplo*"+p)
desnames=paste("X",1:6,sep="")   # six X's related to 6 cycles 
out &lt;- haplo.surv.discrete(X=X,y="y",time.name="time",
         Haplos=Haplos,desnames=desnames,designfunc=designftypes) 
names(out$coef) &lt;- c(desnames,types)
out$coef
summary(out)
</code></pre>

<hr>
<h2 id='haploX'>haploX  covariates and response for haplo survival discrete survival</h2><span id='topic+haploX'></span>

<h3>Description</h3>

<p>haploX  covariates and response for haplo survival discrete survival
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='hfaction_cpx12'>hfaction, subset of block randmized study HF-ACtion from WA package</h2><span id='topic+hfaction_cpx12'></span>

<h3>Description</h3>

<p>Data from HF-action trial slightly modified from WA package
</p>


<h3>Format</h3>

<p>Randomized study
</p>


<h3>Source</h3>

<p>WA package, Connor et al. 2009
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hfaction_cpx12)
</code></pre>

<hr>
<h2 id='interval.logitsurv.discrete'>Discrete time to event interval censored data</h2><span id='topic+interval.logitsurv.discrete'></span><span id='topic+Interval'></span><span id='topic+dInterval'></span><span id='topic+simlogitSurvd'></span><span id='topic+predictlogitSurvd'></span><span id='topic+cumODDS'></span>

<h3>Description</h3>

<p style="text-align: center;"><code class="reqn">
   logit(P(T &gt;t | x)) = log(G(t)) + x \beta
</code>
</p>

<p style="text-align: center;"><code class="reqn">
   P(T &gt;t | x) =  \frac{1}{1 + G(t) exp( x \beta) }
</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>interval.logitsurv.discrete(
  formula,
  data,
  beta = NULL,
  no.opt = FALSE,
  method = "NR",
  stderr = TRUE,
  weights = NULL,
  offsets = NULL,
  exp.link = 1,
  increment = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interval.logitsurv.discrete_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_data">data</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_beta">beta</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_no.opt">no.opt</code></td>
<td>
<p>optimization TRUE/FALSE</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_method">method</code></td>
<td>
<p>NR, nlm</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_stderr">stderr</code></td>
<td>
<p>to return only estimate</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_weights">weights</code></td>
<td>
<p>weights following id for GLM</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_offsets">offsets</code></td>
<td>
<p>following id  for GLM</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_exp.link">exp.link</code></td>
<td>
<p>parametrize increments exp(alpha) &gt; 0</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_increment">increment</code></td>
<td>
<p>using increments dG(t)=exp(alpha) as parameters</p>
</td></tr>
<tr><td><code id="interval.logitsurv.discrete_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions lava::NR  optimizer or nlm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is thus also the cumulative odds model, since 
</p>
<p style="text-align: center;"><code class="reqn">
   P(T \leq t | x) =  \frac{G(t) \exp(x \beta) }{1 + G(t) exp( x \beta) }
</code>
</p>

<p>The baseline <code class="reqn">G(t)</code> is written as <code class="reqn">cumsum(exp(\alpha))</code> and this is not the standard
parametrization that takes log of <code class="reqn">G(t)</code> as the parameters.
</p>
<p>Input are intervals given by ]t_l,t_r] where t_r can be infinity for right-censored intervals 
When truly discrete ]0,1] will be an observation at 1, and  ]j,j+1] will be an observation at j+1
</p>
<p>Likelihood is maximized:
</p>
<p style="text-align: center;"><code class="reqn">
 \prod  P(T_i &gt;t_{il} | x) - P(T_i&gt; t_{ir}| x) 
</code>
</p>



<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ttpd) 
dtable(ttpd,~entry+time2)
out &lt;- interval.logitsurv.discrete(Interval(entry,time2)~X1+X2+X3+X4,ttpd)
summary(out)

pred &lt;- predictlogitSurvd(out,se=FALSE)
plotSurvd(pred)

</code></pre>

<hr>
<h2 id='ipw'>Inverse Probability of Censoring Weights</h2><span id='topic+ipw'></span>

<h3>Description</h3>

<p>Internal function.
Calculates Inverse Probability of Censoring
Weights (IPCW) and adds them to a data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipw(
  formula,
  data,
  cluster,
  same.cens = FALSE,
  obs.only = FALSE,
  weight.name = "w",
  trunc.prob = FALSE,
  weight.name2 = "wt",
  indi.weight = "pr",
  cens.model = "aalen",
  pairs = FALSE,
  theta.formula = ~1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipw_+3A_formula">formula</code></td>
<td>
<p>Formula specifying the censoring model</p>
</td></tr>
<tr><td><code id="ipw_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="ipw_+3A_cluster">cluster</code></td>
<td>
<p>clustering variable</p>
</td></tr>
<tr><td><code id="ipw_+3A_same.cens">same.cens</code></td>
<td>
<p>For clustered data, should same censoring be assumed (bivariate probability calculated as mininum of the marginal probabilities)</p>
</td></tr>
<tr><td><code id="ipw_+3A_obs.only">obs.only</code></td>
<td>
<p>Return data with uncensored observations only</p>
</td></tr>
<tr><td><code id="ipw_+3A_weight.name">weight.name</code></td>
<td>
<p>Name of weight variable in the new data.frame</p>
</td></tr>
<tr><td><code id="ipw_+3A_trunc.prob">trunc.prob</code></td>
<td>
<p>If TRUE truncation probabilities are also calculated and stored in 'weight.name2' (based on Clayton-Oakes gamma frailty model)</p>
</td></tr>
<tr><td><code id="ipw_+3A_weight.name2">weight.name2</code></td>
<td>
<p>Name of truncation probabilities</p>
</td></tr>
<tr><td><code id="ipw_+3A_indi.weight">indi.weight</code></td>
<td>
<p>Name of individual censoring weight  in the new data.frame</p>
</td></tr>
<tr><td><code id="ipw_+3A_cens.model">cens.model</code></td>
<td>
<p>Censoring model (default Aalens additive model)</p>
</td></tr>
<tr><td><code id="ipw_+3A_pairs">pairs</code></td>
<td>
<p>For paired data (e.g. twins) only the complete pairs are returned (With pairs=TRUE)</p>
</td></tr>
<tr><td><code id="ipw_+3A_theta.formula">theta.formula</code></td>
<td>
<p>Model for the dependence parameter in the Clayton-Oakes model (truncation only)</p>
</td></tr>
<tr><td><code id="ipw_+3A_...">...</code></td>
<td>
<p>Additional arguments to censoring model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("prt",package="mets")
prtw &lt;- ipw(Surv(time,status==0)~country, data=prt[sample(nrow(prt),5000),],
            cluster="id",weight.name="w")
plot(0,type="n",xlim=range(prtw$time),ylim=c(0,1),xlab="Age",ylab="Probability")
count &lt;- 0
for (l in unique(prtw$country)) {
    count &lt;- count+1
    prtw &lt;- prtw[order(prtw$time),]
    with(subset(prtw,country==l),
         lines(time,w,col=count,lwd=2))
}
legend("topright",legend=unique(prtw$country),col=1:4,pch=-1,lty=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='ipw2'>Inverse Probability of Censoring Weights</h2><span id='topic+ipw2'></span>

<h3>Description</h3>

<p>Internal function.
Calculates Inverse Probability of Censoring and Truncation 
Weights and adds them to a data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipw2(
  data,
  times = NULL,
  entrytime = NULL,
  time = "time",
  cause = "cause",
  same.cens = FALSE,
  cluster = NULL,
  pairs = FALSE,
  strata = NULL,
  obs.only = TRUE,
  cens.formula = NULL,
  cens.code = 0,
  pair.cweight = "pcw",
  pair.tweight = "ptw",
  pair.weight = "weights",
  cname = "cweights",
  tname = "tweights",
  weight.name = "indi.weights",
  prec.factor = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipw2_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="ipw2_+3A_times">times</code></td>
<td>
<p>possible time argument for speciying a maximum value of time tau=max(times), to specify when things are considered censored or not.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_entrytime">entrytime</code></td>
<td>
<p>nam of entry-time for truncation.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_time">time</code></td>
<td>
<p>name of time variable on data frame.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_cause">cause</code></td>
<td>
<p>name of cause indicator on data frame.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_same.cens">same.cens</code></td>
<td>
<p>For clustered data, should same censoring be assumed and same truncation (bivariate probability calculated as mininum of the marginal probabilities)</p>
</td></tr>
<tr><td><code id="ipw2_+3A_cluster">cluster</code></td>
<td>
<p>name of clustering variable</p>
</td></tr>
<tr><td><code id="ipw2_+3A_pairs">pairs</code></td>
<td>
<p>For paired data (e.g. twins) only the complete pairs are returned (With pairs=TRUE)</p>
</td></tr>
<tr><td><code id="ipw2_+3A_strata">strata</code></td>
<td>
<p>name of strata variable to get weights stratified.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_obs.only">obs.only</code></td>
<td>
<p>Return data with uncensored observations only</p>
</td></tr>
<tr><td><code id="ipw2_+3A_cens.formula">cens.formula</code></td>
<td>
<p>model for Cox models for truncation and right censoring times.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_cens.code">cens.code</code></td>
<td>
<p>censoring.code</p>
</td></tr>
<tr><td><code id="ipw2_+3A_pair.cweight">pair.cweight</code></td>
<td>
<p>Name of weight variable in the new data.frame for right censorig of pairs</p>
</td></tr>
<tr><td><code id="ipw2_+3A_pair.tweight">pair.tweight</code></td>
<td>
<p>Name of weight variable in the new data.frame for left truncation of pairs</p>
</td></tr>
<tr><td><code id="ipw2_+3A_pair.weight">pair.weight</code></td>
<td>
<p>Name of weight variable in the new data.frame for right censoring and left truncation of pairs</p>
</td></tr>
<tr><td><code id="ipw2_+3A_cname">cname</code></td>
<td>
<p>Name of weight variable in the new data.frame for right censoring of individuals</p>
</td></tr>
<tr><td><code id="ipw2_+3A_tname">tname</code></td>
<td>
<p>Name of weight variable in the new data.frame for left truncation of individuals</p>
</td></tr>
<tr><td><code id="ipw2_+3A_weight.name">weight.name</code></td>
<td>
<p>Name of weight variable in the new data.frame for right censoring and left truncation of individuals</p>
</td></tr>
<tr><td><code id="ipw2_+3A_prec.factor">prec.factor</code></td>
<td>
<p>To let tied censoring and truncation times come after the death times.</p>
</td></tr>
<tr><td><code id="ipw2_+3A_...">...</code></td>
<td>
<p>Additional arguments to censoring model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("timereg")
set.seed(1)
d &lt;- simnordic.random(5000,delayed=TRUE,ptrunc=0.7,
      cordz=0.5,cormz=2,lam0=0.3,country=FALSE)
d$strata &lt;- as.numeric(d$country)+(d$zyg=="MZ")*4
times &lt;- seq(60,100,by=10)
## c1 &lt;- timereg::comp.risk(Event(time,cause)~1+cluster(id),data=d,cause=1,
## 	model="fg",times=times,max.clust=NULL,n.sim=0)
## mm=model.matrix(~-1+zyg,data=d)
## out1&lt;-random.cif(c1,data=d,cause1=1,cause2=1,same.cens=TRUE,theta.des=mm)
## summary(out1)
## pc1 &lt;- predict(c1,X=1,se=0)
## plot(pc1)
## 
## dl &lt;- d[!d$truncated,]
## dl &lt;- ipw2(dl,cluster="id",same.cens=TRUE,time="time",entrytime="entry",cause="cause",
##            strata="strata",prec.factor=100)
## cl &lt;- timereg::comp.risk(Event(time,cause)~+1+
## 		cluster(id),
##  		data=dl,cause=1,model="fg",
## 		weights=dl$indi.weights,cens.weights=rep(1,nrow(dl)),
##           times=times,max.clust=NULL,n.sim=0)
## pcl &lt;- predict(cl,X=1,se=0)
## lines(pcl$time,pcl$P1,col=2)
## mm=model.matrix(~-1+factor(zyg),data=dl)
## out2&lt;-random.cif(cl,data=dl,cause1=1,cause2=1,theta.des=mm,
##                  weights=dl$weights,censoring.weights=rep(1,nrow(dl)))
## summary(out2)
</code></pre>

<hr>
<h2 id='km'>Kaplan-Meier with robust standard errors</h2><span id='topic+km'></span>

<h3>Description</h3>

<p>Kaplan-Meier with robust standard errors 
Robust variance is default variance with the summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>km(
  formula,
  data = data,
  conf.type = "log",
  conf.int = 0.95,
  robust = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="km_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="km_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="km_+3A_conf.type">conf.type</code></td>
<td>
<p>transformation</p>
</td></tr>
<tr><td><code id="km_+3A_conf.int">conf.int</code></td>
<td>
<p>level of confidence intervals</p>
</td></tr>
<tr><td><code id="km_+3A_robust">robust</code></td>
<td>
<p>for robust standard errors based on martingales</p>
</td></tr>
<tr><td><code id="km_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TRACE)
TRACE$cluster &lt;- sample(1:100,1878,replace=TRUE)
out1 &lt;- km(Surv(time,status==9)~strata(vf,chf),data=TRACE)
out2 &lt;- km(Surv(time,status==9)~strata(vf,chf)+cluster(cluster),data=TRACE)

par(mfrow=c(1,2))
bplot(out1,se=TRUE)
bplot(out2,se=TRUE)
</code></pre>

<hr>
<h2 id='lifecourse'>Life-course plot</h2><span id='topic+lifecourse'></span>

<h3>Description</h3>

<p>Life-course plot for event life data with recurrent events
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lifecourse(
  formula,
  data,
  id = "id",
  group = NULL,
  type = "l",
  lty = 1,
  col = 1:10,
  alpha = 0.3,
  lwd = 1,
  recurrent.col = NULL,
  recurrent.lty = NULL,
  legend = NULL,
  pchlegend = NULL,
  by = NULL,
  status.legend = NULL,
  place.sl = "bottomright",
  xlab = "Time",
  ylab = "",
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lifecourse_+3A_formula">formula</code></td>
<td>
<p>Formula (Event(start,slut,status) ~ ...)</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_id">id</code></td>
<td>
<p>Id variable</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_group">group</code></td>
<td>
<p>group variable</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_type">type</code></td>
<td>
<p>Type (line 'l', stair 's', ...)</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_lty">lty</code></td>
<td>
<p>Line type</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_col">col</code></td>
<td>
<p>Colour</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_alpha">alpha</code></td>
<td>
<p>transparency (0-1)</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_lwd">lwd</code></td>
<td>
<p>Line width</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_recurrent.col">recurrent.col</code></td>
<td>
<p>col of recurrence type</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_recurrent.lty">recurrent.lty</code></td>
<td>
<p>lty's of  of recurrence type</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_legend">legend</code></td>
<td>
<p>position of optional id legend</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_pchlegend">pchlegend</code></td>
<td>
<p>point type legends</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_by">by</code></td>
<td>
<p>make separate plot for each level in 'by' (formula, name of column, or vector)</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_status.legend">status.legend</code></td>
<td>
<p>Status legend</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_place.sl">place.sl</code></td>
<td>
<p>Placement of status legend</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_add">add</code></td>
<td>
<p>Add to existing device</p>
</td></tr>
<tr><td><code id="lifecourse_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike, Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = data.frame(id=c(1,1,1,2,2),start=c(0,1,2,3,4),slut=c(1,2,4,4,7),
                  type=c(1,2,3,2,3),status=c(0,1,2,1,2),group=c(1,1,1,2,2))
ll = lifecourse(Event(start,slut,status)~id,data,id="id")
ll = lifecourse(Event(start,slut,status)~id,data,id="id",recurrent.col="type")

ll = lifecourse(Event(start,slut,status)~id,data,id="id",group=~group,col=1:2)
op &lt;- par(mfrow=c(1,2))
ll = lifecourse(Event(start,slut,status)~id,data,id="id",by=~group)
par(op)
legends=c("censored","pregnant","married")
ll = lifecourse(Event(start,slut,status)~id,data,id="id",group=~group,col=1:2,status.legend=legends)

</code></pre>

<hr>
<h2 id='lifetable.matrix'>Life table</h2><span id='topic+lifetable.matrix'></span><span id='topic+lifetable'></span><span id='topic+lifetable.formula'></span>

<h3>Description</h3>

<p>Create simple life table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
lifetable(x, strata = list(), breaks = c(),
   weights=NULL, confint = FALSE, ...)

 ## S3 method for class 'formula'
lifetable(x, data=parent.frame(), breaks = c(),
   weights=NULL, confint = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lifetable.matrix_+3A_x">x</code></td>
<td>
<p>time formula (Surv) or matrix/data.frame with columns time,status or entry,exit,status</p>
</td></tr>
<tr><td><code id="lifetable.matrix_+3A_strata">strata</code></td>
<td>
<p>strata</p>
</td></tr>
<tr><td><code id="lifetable.matrix_+3A_breaks">breaks</code></td>
<td>
<p>time intervals</p>
</td></tr>
<tr><td><code id="lifetable.matrix_+3A_weights">weights</code></td>
<td>
<p>weights variable</p>
</td></tr>
<tr><td><code id="lifetable.matrix_+3A_confint">confint</code></td>
<td>
<p>if TRUE 95% confidence limits are calculated</p>
</td></tr>
<tr><td><code id="lifetable.matrix_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
<tr><td><code id="lifetable.matrix_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(timereg)
data(TRACE)

d &lt;- with(TRACE,lifetable(Surv(time,status==9)~sex+vf,breaks=c(0,0.2,0.5,8.5)))
summary(glm(events ~ offset(log(atrisk))+factor(int.end)*vf + sex*vf,
            data=d,poisson))
</code></pre>

<hr>
<h2 id='LinSpline'>Simple linear spline</h2><span id='topic+LinSpline'></span>

<h3>Description</h3>

<p>Simple linear spline
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinSpline(x, knots, num = TRUE, name = "Spline")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LinSpline_+3A_x">x</code></td>
<td>
<p>variable to make into spline</p>
</td></tr>
<tr><td><code id="LinSpline_+3A_knots">knots</code></td>
<td>
<p>cut points</p>
</td></tr>
<tr><td><code id="LinSpline_+3A_num">num</code></td>
<td>
<p>to give names x1 x2 and so forth</p>
</td></tr>
<tr><td><code id="LinSpline_+3A_name">name</code></td>
<td>
<p>name of spline expansion name.1 name.2 and so forth</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='logitSurv'>Proportional odds survival model</h2><span id='topic+logitSurv'></span>

<h3>Description</h3>

<p>Semiparametric Proportional odds model, that has the advantage that 
</p>
<p style="text-align: center;"><code class="reqn">
logit(S(t|x)) = \log(\Lambda(t)) + x \beta
</code>
</p>

<p>so covariate effects give OR of survival.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logitSurv(formula, data, offset = NULL, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logitSurv_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="logitSurv_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="logitSurv_+3A_offset">offset</code></td>
<td>
<p>offsets for exp(x beta) terms</p>
</td></tr>
<tr><td><code id="logitSurv_+3A_weights">weights</code></td>
<td>
<p>weights for score equations</p>
</td></tr>
<tr><td><code id="logitSurv_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is equivalent to using a hazards model 
</p>
<p style="text-align: center;"><code class="reqn">
  Z \lambda(t) \exp(x \beta)
</code>
</p>

<p>where Z is gamma distributed with mean and variance 1.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>The proportional odds cumulative incidence model for competing risks,
Eriksson, Frank and Li, Jianing and Scheike, Thomas and Zhang, Mei-Jie,
Biometrics, 2015, 3, 687&ndash;695, 71,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TRACE)
dcut(TRACE) &lt;- ~.
out1 &lt;- logitSurv(Surv(time,status==9)~vf+chf+strata(wmicat.4),data=TRACE)
summary(out1)
gof(out1)
plot(out1)
</code></pre>

<hr>
<h2 id='mediatorSurv'>Mediation analysis in survival context</h2><span id='topic+mediatorSurv'></span><span id='topic+BootmediatorSurv'></span>

<h3>Description</h3>

<p>Mediation analysis in survival context  with robust standard errors taking the weights into account
via influence function computations. Mediator and exposure must be factors.  This is based on numerical
derivative wrt parameters for weighting.  See vignette for more examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mediatorSurv(
  survmodel,
  weightmodel,
  data = data,
  wdata = wdata,
  id = "id",
  silent = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mediatorSurv_+3A_survmodel">survmodel</code></td>
<td>
<p>with mediation model (binreg, aalenMets, phreg)</p>
</td></tr>
<tr><td><code id="mediatorSurv_+3A_weightmodel">weightmodel</code></td>
<td>
<p>mediation model</p>
</td></tr>
<tr><td><code id="mediatorSurv_+3A_data">data</code></td>
<td>
<p>for computations</p>
</td></tr>
<tr><td><code id="mediatorSurv_+3A_wdata">wdata</code></td>
<td>
<p>weighted data expansion for computations</p>
</td></tr>
<tr><td><code id="mediatorSurv_+3A_id">id</code></td>
<td>
<p>name of id variable, important for SE computations</p>
</td></tr>
<tr><td><code id="mediatorSurv_+3A_silent">silent</code></td>
<td>
<p>to be silent</p>
</td></tr>
<tr><td><code id="mediatorSurv_+3A_...">...</code></td>
<td>
<p>Additional arguments to survival model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 400
dat &lt;- kumarsimRCT(n,rho1=0.5,rho2=0.5,rct=2,censpar=c(0,0,0,0),
          beta = c(-0.67, 0.59, 0.55, 0.25, 0.98, 0.18, 0.45, 0.31),
    treatmodel = c(-0.18, 0.56, 0.56, 0.54),restrict=1)
dfactor(dat) &lt;- dnr.f~dnr
dfactor(dat) &lt;- gp.f~gp
drename(dat) &lt;- ttt24~"ttt24*"
dat$id &lt;- 1:n
dat$ftime &lt;- 1

weightmodel &lt;- fit &lt;- glm(gp.f~dnr.f+preauto+ttt24,data=dat,family=binomial)
wdata &lt;- medweight(fit,data=dat)

### fitting models with and without mediator
aaMss2 &lt;- binreg(Event(time,status)~gp+dnr+preauto+ttt24+cluster(id),data=dat,time=50,cause=2)
aaMss22 &lt;- binreg(Event(time,status)~dnr+preauto+ttt24+cluster(id),data=dat,time=50,cause=2)

### estimating direct and indirect effects (under strong strong assumptions) 
aaMss &lt;- binreg(Event(time,status)~dnr.f0+dnr.f1+preauto+ttt24+cluster(id),
                data=wdata,time=50,weights=wdata$weights,cause=2)
## to compute standard errors , requires numDeriv
library(numDeriv)
ll &lt;- mediatorSurv(aaMss,fit,data=dat,wdata=wdata)
summary(ll)
## not run bootstrap (to save time)
## bll &lt;- BootmediatorSurv(aaMss,fit,data=dat,k.boot=500)

</code></pre>

<hr>
<h2 id='medweight'>Computes mediation weights</h2><span id='topic+medweight'></span>

<h3>Description</h3>

<p>Computes mediation weights for either binary or multinomial mediators.
The important part is that the influence functions can be obtained to compute standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medweight(
  fit,
  data = data,
  var = NULL,
  name.weight = "weights",
  id.name = "id",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="medweight_+3A_fit">fit</code></td>
<td>
<p>either glm-binomial or mlogit (mets package)</p>
</td></tr>
<tr><td><code id="medweight_+3A_data">data</code></td>
<td>
<p>data frame with data</p>
</td></tr>
<tr><td><code id="medweight_+3A_var">var</code></td>
<td>
<p>is NULL reads mediator and exposure from formulae in the fit.</p>
</td></tr>
<tr><td><code id="medweight_+3A_name.weight">name.weight</code></td>
<td>
<p>name of weights</p>
</td></tr>
<tr><td><code id="medweight_+3A_id.name">id.name</code></td>
<td>
<p>name of id variable, important for SE computations</p>
</td></tr>
<tr><td><code id="medweight_+3A_...">...</code></td>
<td>
<p>Additional arguments to</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='melanoma'>The Melanoma Survival Data</h2><span id='topic+melanoma'></span>

<h3>Description</h3>

<p>The melanoma data frame has 205 rows and 7 columns.  It contains data
relating to survival of patients after operation for malignant melanoma
collected at Odense University Hospital by K.T.  Drzewiecki.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns: </p>

<dl>
<dt>no</dt><dd><p> a numeric vector. Patient code. </p>
</dd> <dt>status</dt><dd><p> a numeric vector
code. Survival status. 1: dead from melanoma, 2: alive, 3: dead from other
cause. </p>
</dd> <dt>days</dt><dd><p> a numeric vector. Survival time. </p>
</dd> <dt>ulc</dt><dd><p> a
numeric vector code. Ulceration, 1: present, 0: absent. </p>
</dd> <dt>thick</dt><dd><p> a
numeric vector. Tumour thickness (1/100 mm). </p>
</dd> <dt>sex</dt><dd><p> a numeric vector
code. 0: female, 1: male. </p>
</dd> </dl>



<h3>Source</h3>

<p>Andersen, P.K., Borgan O, Gill R.D., Keiding N. (1993),
<em>Statistical Models Based on Counting Processes</em>, Springer-Verlag.
</p>
<p>Drzewiecki, K.T., Ladefoged, C., and Christensen, H.E. (1980), Biopsy and
prognosis for cutaneous malignant melanoma in clinical stage I. Scand. J.
Plast. Reconstru. Surg. 14, 141-144.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(melanoma)
names(melanoma)

</code></pre>

<hr>
<h2 id='mena'>Menarche data set</h2><span id='topic+mena'></span>

<h3>Description</h3>

<p>Menarche data set
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='mets.options'>Set global options for <code>mets</code></h2><span id='topic+mets.options'></span>

<h3>Description</h3>

<p>Extract and set global parameters of <code>mets</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mets.options(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mets.options_+3A_...">...</code></td>
<td>
<p>Arguments</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code>regex</code>: If TRUE character vectors will be interpreted as regular expressions (<code>dby</code>, <code>dcut</code>, ...)
</p>
</li>
<li> <p><code>silent</code>: Set to <code>FALSE</code> to disable various output messages
</p>
</li></ul>



<h3>Value</h3>

<p><code>list</code> of parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mets.options(regex=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='migr'>Migraine data</h2><span id='topic+migr'></span>

<h3>Description</h3>

<p>Migraine data
</p>

<hr>
<h2 id='mlogit'>Multinomial regression based on phreg regression</h2><span id='topic+mlogit'></span><span id='topic+predictmlogit'></span>

<h3>Description</h3>

<p>Fits multinomial regression model 
</p>
<p style="text-align: center;"><code class="reqn"> P_i = \frac{ \exp( X^\beta_i ) }{ \sum_{j=1}^K \exp( X^\beta_j ) }</code>
</p>
 
<p>for </p>
<p style="text-align: center;"><code class="reqn">i=1,..,K</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">\beta_1 = 0</code>
</p>
<p>, such that </p>
<p style="text-align: center;"><code class="reqn">\sum_j P_j = 1</code>
</p>
<p> using phreg function. 
Thefore the ratio </p>
<p style="text-align: center;"><code class="reqn">\frac{P_i}{P_1} = \exp( X^\beta_i )</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>mlogit(formula, data, offset = NULL, weights = NULL, fix.X = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlogit_+3A_formula">formula</code></td>
<td>
<p>formula with outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="mlogit_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="mlogit_+3A_offset">offset</code></td>
<td>
<p>offsets for partial likelihood</p>
</td></tr>
<tr><td><code id="mlogit_+3A_weights">weights</code></td>
<td>
<p>for score equations</p>
</td></tr>
<tr><td><code id="mlogit_+3A_fix.x">fix.X</code></td>
<td>
<p>to have same coefficients for all categories</p>
</td></tr>
<tr><td><code id="mlogit_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Coefficients give log-Relative-Risk relative to baseline group (first level of factor, so that it can reset by relevel command).  
Standard errors computed based on sandwhich form </p>
<p style="text-align: center;"><code class="reqn"> DU^-1  \sum U_i^2 DU^-1</code>
</p>
<p>.  
</p>
<p>Can also get influence functions (possibly robust) via iid() function, response should be a factor. 
</p>
<p>Can fit cumulative odds model as a special case of interval.logitsurv.discrete
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(bmt)
dfactor(bmt) &lt;- cause1f~cause
drelevel(bmt,ref=3) &lt;- cause3f~cause
dlevels(bmt)

mreg &lt;- mlogit(cause1f~+1,bmt)
summary(mreg)

mreg &lt;- mlogit(cause1f~tcell+platelet,bmt)
summary(mreg)

mreg3 &lt;- mlogit(cause3f~tcell+platelet,bmt)
summary(mreg3)

## inverse information standard errors 
lava::estimate(coef=mreg3$coef,vcov=mreg3$II)

## predictions based on seen response or not 
newdata &lt;- data.frame(tcell=c(1,1,1),platelet=c(0,1,1),cause1f=c("2","1","0"))
predictmlogit(mreg,newdata,response=FALSE)
predictmlogit(mreg,newdata)
</code></pre>

<hr>
<h2 id='multcif'>Multivariate Cumulative Incidence Function example data set</h2><span id='topic+multcif'></span>

<h3>Description</h3>

<p>Multivariate Cumulative Incidence Function example data set
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='np'>np data set</h2><span id='topic+np'></span>

<h3>Description</h3>

<p>np data set
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='npc'>For internal use</h2><span id='topic+npc'></span><span id='topic+plotcr'></span><span id='topic+nonparcuminc'></span><span id='topic+simnordic'></span><span id='topic+corsim.prostate'></span><span id='topic+alpha2kendall'></span><span id='topic+alpha2spear'></span><span id='topic+coefmat'></span><span id='topic+piecewise.twostage'></span><span id='topic+surv.boxarea'></span><span id='topic+faster.reshape'></span><span id='topic+piecewise.data'></span><span id='topic+simBinPlack'></span><span id='topic+simBinFam'></span><span id='topic+simBinFam2'></span><span id='topic+simSurvFam'></span><span id='topic+corsim.prostate.random'></span><span id='topic+simnordic.random'></span><span id='topic+simCox'></span><span id='topic+sim'></span><span id='topic+grouptable'></span><span id='topic+jumptimes'></span><span id='topic+folds'></span><span id='topic+ace.family.design'></span><span id='topic+ascertained.pairs'></span><span id='topic+CCbinomial.twostage'></span><span id='topic+coarse.clust'></span><span id='topic+concordanceTwinACE'></span><span id='topic+concordanceTwostage'></span><span id='topic+fast.cluster'></span><span id='topic+force.same.cens'></span><span id='topic+ilap'></span><span id='topic+kendall.ClaytonOakes.twin.ace'></span><span id='topic+kendall.normal.twin.ace'></span><span id='topic+make.pairwise.design'></span><span id='topic+make.pairwise.design.competing'></span><span id='topic+matplot.mets.twostage'></span><span id='topic+object.defined'></span><span id='topic+p11.binomial.twostage.RV'></span><span id='topic+predictPairPlack'></span><span id='topic+simbinClaytonOakes.family.ace'></span><span id='topic+simbinClaytonOakes.pairs'></span><span id='topic+simbinClaytonOakes.twin.ace'></span><span id='topic+simClaytonOakes.family.ace'></span><span id='topic+simClaytonOakes.twin.ace'></span><span id='topic+simFrailty.simple'></span><span id='topic+simCompete.simple'></span><span id='topic+simCompete.twin.ace'></span><span id='topic+twin.polygen.design'></span><span id='topic+procform'></span><span id='topic+procform3'></span><span id='topic+procformdata'></span><span id='topic+drop.specials'></span>

<h3>Description</h3>

<p>For internal use
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='phreg'>Fast Cox PH regression</h2><span id='topic+phreg'></span><span id='topic+phreg.par'></span><span id='topic+robust.phreg'></span><span id='topic+readPhreg'></span><span id='topic+IIDbaseline.phreg'></span>

<h3>Description</h3>

<p>Fast Cox PH regression
Robust variance is default variance with the summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phreg(formula, data, offset = NULL, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phreg_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="phreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="phreg_+3A_offset">offset</code></td>
<td>
<p>offsets for cox model</p>
</td></tr>
<tr><td><code id="phreg_+3A_weights">weights</code></td>
<td>
<p>weights for Cox score equations</p>
</td></tr>
<tr><td><code id="phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>influence functions (iid) will follow numerical order of given cluster variable
so ordering after $id will give iid in order of data-set.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst, Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TRACE)
dcut(TRACE) &lt;- ~.
out1 &lt;- phreg(Surv(time,status==9)~vf+chf+strata(wmicat.4),data=TRACE)
out2 &lt;- phreg(Event(time,status)~vf+chf+strata(wmicat.4),data=TRACE)
## tracesim &lt;- timereg::sim.cox(out1,1000)
## sout1 &lt;- phreg(Surv(time,status==1)~vf+chf+strata(wmicat.4),data=tracesim)
## robust standard errors default 
summary(out1)
out1 &lt;- phreg(Surv(time,status!=0)~vf+chf+strata(wmicat.4),data=TRACE)
summary(out2)

par(mfrow=c(1,2))
bplot(out1)
## bplot(sout1,se=TRUE)

## computing robust variance for baseline
rob1 &lt;- robust.phreg(out1)
bplot(rob1,se=TRUE,robust=TRUE)

## making iid decomposition of regression parameters
betaiiid &lt;- lava::iid(out1)

## making iid decomposition of baseline at a specific time-point
Aiiid &lt;- mets:::IIDbaseline.phreg(out1,time=30)

</code></pre>

<hr>
<h2 id='phreg_IPTW'>IPTW Cox, Inverse Probaibilty of Treatment Weighted Cox regression</h2><span id='topic+phreg_IPTW'></span>

<h3>Description</h3>

<p>Fits Cox model with treatment weights </p>
<p style="text-align: center;"><code class="reqn"> w(A)= \sum_a I(A=a)/\pi(a|X)</code>
</p>
<p>, where
</p>
<p style="text-align: center;"><code class="reqn">\pi(a|X)=P(A=a|X)</code>
</p>
<p>. Computes
standard errors via influence functions that are returned as the IID argument. 
Propensity scores are fitted using either logistic regression (glm) or the multinomial model (mlogit) when more
than two categories for treatment. The treatment needs to be a factor and is identified on the rhs
of the &quot;treat.model&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phreg_IPTW(
  formula,
  data,
  treat.model = NULL,
  treat.var = NULL,
  weights = NULL,
  estpr = 1,
  pi0 = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phreg_IPTW_+3A_formula">formula</code></td>
<td>
<p>for phreg</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_data">data</code></td>
<td>
<p>data frame for risk averaging</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_treat.model">treat.model</code></td>
<td>
<p>propensity score model (binary or multinomial)</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_treat.var">treat.var</code></td>
<td>
<p>a 1/0 variable that indicates when propensity score is computed over time</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_weights">weights</code></td>
<td>
<p>may be given, and then uses weights*w(A) as the weights</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_estpr">estpr</code></td>
<td>
<p>to estimate propensity scores and get infuence function contribution to uncertainty</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_pi0">pi0</code></td>
<td>
<p>fixed simple weights</p>
</td></tr>
<tr><td><code id="phreg_IPTW_+3A_...">...</code></td>
<td>
<p>arguments for phreg call</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also works with cluster argument. Time-dependent propensity score weights can also be computed when treat.var is 1
and then at time of 2nd treatment (A_1) uses weights w_0(A_0) * w_1(A_1) where A_0 is first treatment.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data &lt;- mets:::simLT(0.7,100,beta=0.3,betac=0,ce=1,betao=0.3)
dfactor(data) &lt;- Z.f~Z
out &lt;- phreg_IPTW(Surv(time,status)~Z.f,data=data,treat.model=Z.f~X)
summary(out)

</code></pre>

<hr>
<h2 id='phreg_rct'>Lu-Tsiatis More Efficient Log-Rank for Randomized studies with baseline covariates</h2><span id='topic+phreg_rct'></span>

<h3>Description</h3>

<p>Efficient implementation of the Lu-Tsiatis improvement using baseline covariates, extended to competing risks and recurrent events. Results
almost equivalent with the speffSurv function of the speff2trial function in the survival case. A dynamic 
censoring augmentation regression is also computed to gain even more from the censoring augmentation. Furhter, we also deal with twostage
randomizations. The function was implemented to deal with recurrent events (start,stop) + cluster, and  more examples in vignette.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phreg_rct(
  formula,
  data,
  cause = 1,
  cens.code = 0,
  typesR = c("R0", "R1", "R01"),
  typesC = c("C", "dynC"),
  augmentR0 = NULL,
  augmentR1 = NULL,
  augmentC = NULL,
  treat.model = ~+1,
  RCT = TRUE,
  treat.var = NULL,
  km = TRUE,
  level = 0.95,
  cens.model = NULL,
  estpr = 1,
  pi0 = 0.5,
  base.augment = FALSE,
  return.augmentR0 = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phreg_rct_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' or 'Event' outcome (see <code>coxph</code>) and treatment (randomization 0/1)</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_cause">cause</code></td>
<td>
<p>to use for competing risks, recurrent events data</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_cens.code">cens.code</code></td>
<td>
<p>to use for competing risks, recurrent events data</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_typesr">typesR</code></td>
<td>
<p>augmentations used for randomization</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_typesc">typesC</code></td>
<td>
<p>augmentations used for censoring</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_augmentr0">augmentR0</code></td>
<td>
<p>formula for the randomization augmentation  (~age+sex)</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_augmentr1">augmentR1</code></td>
<td>
<p>formula for the randomization augmentation  (~age+sex)</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_augmentc">augmentC</code></td>
<td>
<p>formula for the censoring augmentation  (~age+sex)</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_treat.model">treat.model</code></td>
<td>
<p>propensity score model, default is ~+1, assuming RCT study</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_rct">RCT</code></td>
<td>
<p>if false will use propensity score adjustment for marginal model</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_treat.var">treat.var</code></td>
<td>
<p>in case of twostage randomization, this variable is 1 for the treatment times, if start,stop then default assumes that only one treatment at first record</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_km">km</code></td>
<td>
<p>use Kaplan-Meier for the censoring weights (stratified on treatment)</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_level">level</code></td>
<td>
<p>of confidence intervals</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_cens.model">cens.model</code></td>
<td>
<p>default is censoring model ~strata(treatment) but any model can be used to make censoring martingales</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_estpr">estpr</code></td>
<td>
<p>estimates propensity scores</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_pi0">pi0</code></td>
<td>
<p>possible fixed propensity scores for randomizations</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_base.augment">base.augment</code></td>
<td>
<p>TRUE to covariate augment baselines (only for R0 augmentation)</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_return.augmentr0">return.augmentR0</code></td>
<td>
<p>to return augmentation data</p>
</td></tr>
<tr><td><code id="phreg_rct_+3A_...">...</code></td>
<td>
<p>Additional arguments to phreg function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Lu, Tsiatis (2008), Improving the efficiency of the log-rank test using auxiliary covariates, Biometrika, 679&ndash;694
Scheike et al. (2024), WIP, Two-stage randomization for recurrent events,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Lu, Tsiatis simulation
data &lt;- mets:::simLT(0.7,100)
dfactor(data) &lt;- Z.f~Z

out &lt;- phreg_rct(Surv(time,status)~Z.f,data=data,augmentR0=~X,augmentC=~factor(Z):X)
summary(out)
</code></pre>

<hr>
<h2 id='phregR'>Fast Cox PH regression and calculations done in R to make play and adjustments easy</h2><span id='topic+phregR'></span><span id='topic+FastCoxPLstrataR'></span>

<h3>Description</h3>

<p>Fast Cox PH regression with R implementation to play and adjust in R function: FastCoxPLstrataR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phregR(formula, data, offset = NULL, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phregR_+3A_formula">formula</code></td>
<td>
<p>formula with 'Surv' outcome (see <code>coxph</code>)</p>
</td></tr>
<tr><td><code id="phregR_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="phregR_+3A_offset">offset</code></td>
<td>
<p>offsets for cox model</p>
</td></tr>
<tr><td><code id="phregR_+3A_weights">weights</code></td>
<td>
<p>weights for Cox score equations</p>
</td></tr>
<tr><td><code id="phregR_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Robust variance is default variance with the summary. 
</p>
<p>influence functions (iid) will follow numerical order of given cluster variable
so ordering after $id will give iid in order of data-set.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst, Thomas Scheike
</p>

<hr>
<h2 id='plack.cif'>plack Computes concordance for or.cif based model, that is Plackett random effects model</h2><span id='topic+plack.cif'></span><span id='topic+plack.cif2'></span>

<h3>Description</h3>

<p>.. content for description (no empty lines) ..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plack.cif(cif1, cif2, object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plack.cif_+3A_cif1">cif1</code></td>
<td>
<p>Cumulative incidence of first argument.</p>
</td></tr>
<tr><td><code id="plack.cif_+3A_cif2">cif2</code></td>
<td>
<p>Cumulative incidence of second argument.</p>
</td></tr>
<tr><td><code id="plack.cif_+3A_object">object</code></td>
<td>
<p>or.cif object with dependence parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='pmvn'>Multivariate normal distribution function</h2><span id='topic+pmvn'></span><span id='topic+pbvn'></span><span id='topic+loglikMVN'></span><span id='topic+scoreMVN'></span><span id='topic+dmvn'></span><span id='topic+rmvn'></span>

<h3>Description</h3>

<p>Multivariate normal distribution function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmvn(lower, upper, mu, sigma, cor = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pmvn_+3A_lower">lower</code></td>
<td>
<p>lower limits</p>
</td></tr>
<tr><td><code id="pmvn_+3A_upper">upper</code></td>
<td>
<p>upper limits</p>
</td></tr>
<tr><td><code id="pmvn_+3A_mu">mu</code></td>
<td>
<p>mean vector</p>
</td></tr>
<tr><td><code id="pmvn_+3A_sigma">sigma</code></td>
<td>
<p>variance matrix or vector of correlation coefficients</p>
</td></tr>
<tr><td><code id="pmvn_+3A_cor">cor</code></td>
<td>
<p>if TRUE sigma is treated as standardized (correlation matrix)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>lower &lt;- rbind(c(0,-Inf),c(-Inf,0))
upper &lt;- rbind(c(Inf,0),c(0,Inf))
mu &lt;- rbind(c(1,1),c(-1,1))
sigma &lt;- diag(2)+1
pmvn(lower=lower,upper=upper,mu=mu,sigma=sigma)
</code></pre>

<hr>
<h2 id='predict.phreg'>Predictions from proportional hazards model</h2><span id='topic+predict.phreg'></span><span id='topic+headstrata'></span><span id='topic+tailstrata'></span><span id='topic+revcumsumstrata'></span><span id='topic+revcumsumstratasum'></span><span id='topic+cumsumstrata'></span><span id='topic+sumstrata'></span><span id='topic+covfr'></span><span id='topic+covfridstrata'></span><span id='topic+covfridstrataCov'></span><span id='topic+cumsumidstratasum'></span><span id='topic+cumsumidstratasumCov'></span><span id='topic+cumsumstratasum'></span><span id='topic+revcumsum'></span><span id='topic+revcumsumidstratasum'></span><span id='topic+revcumsumidstratasumCov'></span><span id='topic+robust.basehaz.phreg'></span><span id='topic+matdoubleindex'></span><span id='topic+mdi'></span><span id='topic+cumsum2strata'></span><span id='topic+revcumsum2strata'></span><span id='topic+revcumsum2stratafdN'></span>

<h3>Description</h3>

<p>Predictions from proportional hazards model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'phreg'
predict(
  object,
  newdata,
  times = NULL,
  individual.time = FALSE,
  tminus = FALSE,
  se = TRUE,
  robust = FALSE,
  conf.type = "log",
  conf.int = 0.95,
  km = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.phreg_+3A_object">object</code></td>
<td>
<p>phreg object</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_newdata">newdata</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_times">times</code></td>
<td>
<p>Time where to predict variable, default is all time-points from the object sorted</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_individual.time">individual.time</code></td>
<td>
<p>to use one (individual) time per subject, and then newdata and times have same length and makes only predictions for these individual times.</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_tminus">tminus</code></td>
<td>
<p>to make predictions in T- that is strictly before given times, useful for IPCW techniques</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_se">se</code></td>
<td>
<p>with standard errors and upper and lower confidence intervals.</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_robust">robust</code></td>
<td>
<p>to get robust se's.</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_conf.type">conf.type</code></td>
<td>
<p>transformation for suvival estimates, default is log</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_conf.int">conf.int</code></td>
<td>
<p>significance level</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_km">km</code></td>
<td>
<p>to use Kaplan-Meier product-limit for baseline </p>
<p style="text-align: center;"><code class="reqn">S_{s0}(t)= (1 - dA_{s0}(t))</code>
</p>
<p>, otherwise take exp of cumulative baseline.</p>
</td></tr>
<tr><td><code id="predict.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to plot functions</p>
</td></tr>
</table>

<hr>
<h2 id='predictRisk.phreg'>Risk predictions to work with riskRegression package</h2><span id='topic+predictRisk.phreg'></span><span id='topic+predictRisk.cifreg'></span><span id='topic+predictRisk.binreg'></span>

<h3>Description</h3>

<p>Risk predictions to work with riskRegression package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictRisk.phreg(object, newdata, times = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictRisk.phreg_+3A_object">object</code></td>
<td>
<p>phreg/binreg/cifreg object</p>
</td></tr>
<tr><td><code id="predictRisk.phreg_+3A_newdata">newdata</code></td>
<td>
<p>newdata</p>
</td></tr>
<tr><td><code id="predictRisk.phreg_+3A_times">times</code></td>
<td>
<p>times for predictions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='print.casewise'>prints Concordance test</h2><span id='topic+print.casewise'></span>

<h3>Description</h3>

<p>prints Concordance test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'casewise'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.casewise_+3A_x">x</code></td>
<td>
<p>output from casewise.test</p>
</td></tr>
<tr><td><code id="print.casewise_+3A_digits">digits</code></td>
<td>
<p>number of digits</p>
</td></tr>
<tr><td><code id="print.casewise_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='prob.exceed.recurrent'>Estimation of probability of more that k events for recurrent events process</h2><span id='topic+prob.exceed.recurrent'></span><span id='topic+prob.exceedRecurrent'></span><span id='topic+prob.exceedBiRecurrent'></span><span id='topic+prob.exceedRecurrentStrata'></span><span id='topic+prob.exceedBiRecurrentStrata'></span><span id='topic+summaryTimeobject'></span>

<h3>Description</h3>

<p>Estimation of probability of more that k events for recurrent events process
where there is terminal event, based on this also estimate of variance of recurrent events. The estimator is based on cumulative incidence of exceeding &quot;k&quot; events.
In contrast the probability of exceeding k events can also be computed as a 
counting process integral, and this is implemented in prob.exceedRecurrent
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob.exceed.recurrent(
  data,
  type,
  status = "status",
  death = "death",
  start = "start",
  stop = "stop",
  id = "id",
  times = NULL,
  exceed = NULL,
  cifmets = TRUE,
  strata = NULL,
  all.cifs = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prob.exceed.recurrent_+3A_data">data</code></td>
<td>
<p>data-frame</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_type">type</code></td>
<td>
<p>type of evnent (code) related to status</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_status">status</code></td>
<td>
<p>name of status</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_death">death</code></td>
<td>
<p>name of death indicator</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_start">start</code></td>
<td>
<p>start stop call of Hist() of prodlim</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_stop">stop</code></td>
<td>
<p>start stop call of Hist() of prodlim</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_id">id</code></td>
<td>
<p>id</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_times">times</code></td>
<td>
<p>time at which to get probabilites P(N1(t) &gt;= n)</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_exceed">exceed</code></td>
<td>
<p>n's for which which to compute probabilites P(N1(t) &gt;= n)</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_cifmets">cifmets</code></td>
<td>
<p>if true uses cif of mets package rather than prodlim</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_strata">strata</code></td>
<td>
<p>to stratify according to variable, only for cifmets=TRUE, when strata is given then only consider the output in the all.cifs</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_all.cifs">all.cifs</code></td>
<td>
<p>if true then returns list of all fitted objects in cif.exceed</p>
</td></tr>
<tr><td><code id="prob.exceed.recurrent_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Scheike, Eriksson, Tribler (2019) 
The mean, variance and correlation for bivariate recurrent events
with a terminal event,  JRSS-C
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
########################################
## getting some rates to mimick 
########################################

data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz

cor.mat &lt;- corM &lt;- rbind(c(1.0, 0.6, 0.9), c(0.6, 1.0, 0.5), c(0.9, 0.5, 1.0))
rr &lt;- simRecurrentII(1000,base4,cumhaz2=base4,death.cumhaz=dr,cens=2/5000)
rr &lt;-  count.history(rr)
dtable(rr,~death+status)

oo &lt;- prob.exceedRecurrent(rr,1)
bplot(oo)

par(mfrow=c(1,2))
with(oo,plot(time,mu,col=2,type="l"))
###
with(oo,plot(time,varN,type="l"))


### Bivariate probability of exceeding 
oo &lt;- prob.exceedBiRecurrent(rr,1,2,exceed1=c(1,5),exceed2=c(1,2))
with(oo, matplot(time,pe1e2,type="s"))
nc &lt;- ncol(oo$pe1e2)
legend("topleft",legend=colnames(oo$pe1e2),lty=1:nc,col=1:nc)



### do not test to avoid dependence on prodlim 
### now estimation based on cumualative incidence, but do not test to avoid dependence on prodlim 
### library(prodlim)
pp &lt;- prob.exceed.recurrent(rr,1,status="status",death="death",start="entry",stop="time",id="id")
with(pp, matplot(times,prob,type="s"))
###
with(pp, matlines(times,se.lower,type="s"))
with(pp, matlines(times,se.upper,type="s"))

</code></pre>

<hr>
<h2 id='prt'>Prostate data set</h2><span id='topic+prt'></span>

<h3>Description</h3>

<p>Prostate data set
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='random.cif'>Random effects model for competing risks data</h2><span id='topic+random.cif'></span>

<h3>Description</h3>

<p>Fits a random effects  model describing the dependence in the cumulative 
incidence curves for subjects within a cluster.  Given the gamma distributed
random effects it is assumed that the cumulative incidence curves are indpendent, and
that the marginal cumulative incidence curves are on the form
</p>
<p style="text-align: center;"><code class="reqn">
P(T \leq t, cause=1 | x,z) = P_1(t,x,z) = 1- exp( -x^T A(t) exp(z^T \beta))
</code>
</p>

<p>We allow a regression structure for the random effects variances that may depend on
cluster covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random.cif(
  cif,
  data,
  cause = NULL,
  cif2 = NULL,
  cause1 = 1,
  cause2 = 1,
  cens.code = NULL,
  cens.model = "KM",
  Nit = 40,
  detail = 0,
  clusters = NULL,
  theta = NULL,
  theta.des = NULL,
  sym = 1,
  step = 1,
  same.cens = FALSE,
  var.link = 0,
  score.method = "nr",
  entry = NULL,
  trunkp = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="random.cif_+3A_cif">cif</code></td>
<td>
<p>a model object from the comp.risk function with the 
marginal cumulative incidence of cause2, i.e., the event that is conditioned on, and whose
odds the comparision is made with respect to</p>
</td></tr>
<tr><td><code id="random.cif_+3A_data">data</code></td>
<td>
<p>a data.frame with the variables.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_cause">cause</code></td>
<td>
<p>specifies the causes  related to the death
times, the value cens.code is the censoring value.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_cif2">cif2</code></td>
<td>
<p>specificies model for cause2 if different from cause1.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_cause1">cause1</code></td>
<td>
<p>cause of first coordinate.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_cause2">cause2</code></td>
<td>
<p>cause of second coordinate.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_cens.code">cens.code</code></td>
<td>
<p>specificies the code for the censoring if NULL then uses the one from the marginal cif model.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_cens.model">cens.model</code></td>
<td>
<p>specified which model to use for the ICPW, KM is Kaplan-Meier alternatively it may be &quot;cox&quot;</p>
</td></tr>
<tr><td><code id="random.cif_+3A_nit">Nit</code></td>
<td>
<p>number of iterations for Newton-Raphson algorithm.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_detail">detail</code></td>
<td>
<p>if 0 no details are printed during iterations, if 1 details are given.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_clusters">clusters</code></td>
<td>
<p>specifies the cluster structure.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_theta">theta</code></td>
<td>
<p>specifies starting values for the cross-odds-ratio parameters of the model.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_theta.des">theta.des</code></td>
<td>
<p>specifies a regression design for the cross-odds-ratio parameters.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_sym">sym</code></td>
<td>
<p>1 for symmetry 0 otherwise</p>
</td></tr>
<tr><td><code id="random.cif_+3A_step">step</code></td>
<td>
<p>specifies the step size for the Newton-Raphson algorith.m</p>
</td></tr>
<tr><td><code id="random.cif_+3A_same.cens">same.cens</code></td>
<td>
<p>if true then censoring within clusters are assumed to be the same variable, default is independent censoring.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_var.link">var.link</code></td>
<td>
<p>if var.link=1 then var is on log-scale.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_score.method">score.method</code></td>
<td>
<p>default uses &quot;nlminb&quot; optimzer, alternatively, use the &quot;nr&quot; algorithm.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_entry">entry</code></td>
<td>
<p>entry-age in case of delayed entry. Then two causes must be given.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_trunkp">trunkp</code></td>
<td>
<p>gives probability of survival for delayed entry, and related to entry-ages given above.</p>
</td></tr>
<tr><td><code id="random.cif_+3A_...">...</code></td>
<td>
<p>extra arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns an object of type 'cor'. With the following arguments:
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>estimate of proportional odds parameters of model.</p>
</td></tr>
<tr><td><code>var.theta</code></td>
<td>
<p>variance for gamma.  </p>
</td></tr>
<tr><td><code>hess</code></td>
<td>
<p>the derivative of the used score.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>scores at final stage.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>scores at final stage.</p>
</td></tr>
<tr><td><code>theta.iid</code></td>
<td>
<p>matrix of iid decomposition of parametric effects.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>A Semiparametric Random Effects Model for Multivariate Competing Risks Data,
Scheike, Zhang, Sun, Jensen (2010), Biometrika. 
</p>
<p>Cross odds ratio Modelling of dependence for
Multivariate Competing Risks Data, Scheike and Sun (2012), work in progress.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Reduce Ex.Timings
 d &lt;- simnordic.random(5000,delayed=TRUE,cordz=0.5,cormz=2,lam0=0.3,country=TRUE)
 times &lt;- seq(50,90,by=10)
 add1 &lt;- timereg::comp.risk(Event(time,cause)~-1+factor(country)+cluster(id),data=d,
 times=times,cause=1,max.clust=NULL)

 ### making group indidcator 
 mm &lt;- model.matrix(~-1+factor(zyg),d)

 out1&lt;-random.cif(add1,data=d,cause1=1,cause2=1,theta=1,same.cens=TRUE)
 summary(out1)

 out2&lt;-random.cif(add1,data=d,cause1=1,cause2=1,theta=1,
		   theta.des=mm,same.cens=TRUE)
 summary(out2)

#########################################
##### 2 different causes
#########################################

 add2 &lt;- timereg::comp.risk(Event(time,cause)~-1+factor(country)+cluster(id),data=d,
                  times=times,cause=2,max.clust=NULL)
 out3 &lt;- random.cif(add1,data=d,cause1=1,cause2=2,cif2=add2,sym=1,same.cens=TRUE)
 summary(out3) ## negative dependence

 out4 &lt;- random.cif(add1,data=d,cause1=1,cause2=2,cif2=add2,theta.des=mm,sym=1,same.cens=TRUE)
 summary(out4) ## negative dependence

</code></pre>

<hr>
<h2 id='rchaz'>Simulation of Piecewise constant hazard model (Cox).</h2><span id='topic+rchaz'></span><span id='topic+simrchaz'></span><span id='topic+addCums'></span><span id='topic+lin.approx'></span><span id='topic+simCens'></span>

<h3>Description</h3>

<p>Simulates data from piecwise constant baseline hazard that can also be of
Cox type. Censor data at highest value of the break points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rchaz(
  cumhazard,
  rr,
  n = NULL,
  entry = NULL,
  cum.hazard = TRUE,
  cause = 1,
  extend = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rchaz_+3A_cumhazard">cumhazard</code></td>
<td>
<p>cumulative hazard, or piece-constant rates for periods defined by first column of input.</p>
</td></tr>
<tr><td><code id="rchaz_+3A_rr">rr</code></td>
<td>
<p>relative risk for simulations, alternatively when rr=1 specify n</p>
</td></tr>
<tr><td><code id="rchaz_+3A_n">n</code></td>
<td>
<p>number of simulation if rr not given</p>
</td></tr>
<tr><td><code id="rchaz_+3A_entry">entry</code></td>
<td>
<p>delayed entry time for simuations.</p>
</td></tr>
<tr><td><code id="rchaz_+3A_cum.hazard">cum.hazard</code></td>
<td>
<p>specifies wheter input is cumulative hazard or rates.</p>
</td></tr>
<tr><td><code id="rchaz_+3A_cause">cause</code></td>
<td>
<p>name of cause</p>
</td></tr>
<tr><td><code id="rchaz_+3A_extend">extend</code></td>
<td>
<p>to extend piecewise constant with constant rate. Default is average rate over time from cumulative (when TRUE), if numeric then uses given rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a piecewise linear cumulative hazard the inverse is easy to compute with 
and delayed entry x we compute 
</p>
<p style="text-align: center;"><code class="reqn">\Lambda^{-1}(\Lambda(x) + E/RR)</code>
</p>
<p>, 
where RR are the relative risks and E is exponential with mean 1.
This quantity has survival function 
</p>
<p style="text-align: center;"><code class="reqn">P(T &gt; t | T&gt;x) = exp(-RR (\Lambda(t) - \Lambda(x)))</code>
</p>
<p>.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
chaz &lt;-  c(0,1,1.5,2,2.1)
breaks &lt;- c(0,10,   20,  30,   40)
cumhaz &lt;- cbind(breaks,chaz)
n &lt;- 10
X &lt;- rbinom(n,1,0.5)
beta &lt;- 0.2
rrcox &lt;- exp(X * beta)

pctime &lt;- rchaz(cumhaz,n=10)
pctimecox &lt;- rchaz(cumhaz,rrcox,entry=runif(n))

</code></pre>

<hr>
<h2 id='rchazC'>Piecewise constant hazard distribution</h2><span id='topic+rchazC'></span>

<h3>Description</h3>

<p>Piecewise constant hazard distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rchazC(base1, rr, entry)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rchazC_+3A_base1">base1</code></td>
<td>
<p>baseline</p>
</td></tr>
<tr><td><code id="rchazC_+3A_rr">rr</code></td>
<td>
<p>relative risk terms</p>
</td></tr>
<tr><td><code id="rchazC_+3A_entry">entry</code></td>
<td>
<p>entry times for left truncation</p>
</td></tr>
</table>

<hr>
<h2 id='rcrisk'>Simulation of Piecewise constant hazard models with two causes (Cox).</h2><span id='topic+rcrisk'></span><span id='topic+cause.pchazard.sim'></span><span id='topic+rcrisks'></span><span id='topic+rchazl'></span>

<h3>Description</h3>

<p>Simulates data from piecwise constant baseline hazard that can also be of
Cox type. Censor data at highest value of the break points for either of the
cumulatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcrisk(
  cumhaz1,
  cumhaz2,
  rr1,
  rr2,
  n = NULL,
  cens = NULL,
  rrc = NULL,
  extend = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rcrisk_+3A_cumhaz1">cumhaz1</code></td>
<td>
<p>cumulative hazard of cause 1</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_cumhaz2">cumhaz2</code></td>
<td>
<p>cumulative hazard of cause 1</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_rr1">rr1</code></td>
<td>
<p>number of simulations or vector of relative risk for simuations.</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_rr2">rr2</code></td>
<td>
<p>number of simulations or vector of relative risk for simuations.</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_n">n</code></td>
<td>
<p>number of simulation if rr not given</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_cens">cens</code></td>
<td>
<p>to censor further , rate or cumumlative hazard</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_rrc">rrc</code></td>
<td>
<p>retlativ risk for censoring.</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_extend">extend</code></td>
<td>
<p>to extend the cumulative hazards to largest end-point</p>
</td></tr>
<tr><td><code id="rcrisk_+3A_...">...</code></td>
<td>
<p>arguments for rchaz</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bmt); 
cox1 &lt;- phreg(Surv(time,cause==1)~tcell+platelet,data=bmt)
cox2 &lt;- phreg(Surv(time,cause==2)~tcell+platelet,data=bmt)

X1 &lt;- bmt[,c("tcell","platelet")]
n &lt;- 100
xid &lt;- sample(1:nrow(X1),n,replace=TRUE)
Z1 &lt;- X1[xid,]
Z2 &lt;- X1[xid,]
rr1 &lt;- exp(as.matrix(Z1) %*% cox1$coef)
rr2 &lt;- exp(as.matrix(Z2) %*% cox2$coef)

d &lt;-  rcrisk(cox1$cum,cox2$cum,rr1,rr2)
dd &lt;- cbind(d,Z1)

scox1 &lt;- phreg(Surv(time,status==1)~tcell+platelet,data=dd)
scox2 &lt;- phreg(Surv(time,status==2)~tcell+platelet,data=dd)
par(mfrow=c(1,2))
plot(cox1); plot(scox1,add=TRUE)
plot(cox2); plot(scox2,add=TRUE)
cbind(cox1$coef,scox1$coef,cox2$coef,scox2$coef)

</code></pre>

<hr>
<h2 id='recreg'>Recurrent events regression with terminal event</h2><span id='topic+recreg'></span><span id='topic+IIDbaseline.recreg'></span><span id='topic+strataAugment'></span><span id='topic+scalecumhaz'></span><span id='topic+GLprediid'></span><span id='topic+recregIPCW'></span><span id='topic+twostageREC'></span><span id='topic+simGLcox'></span>

<h3>Description</h3>

<p>Fits Ghosh-Lin IPCW Cox-type model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recreg(
  formula,
  data,
  cause = 1,
  death.code = c(2),
  cens.code = 0,
  cens.model = ~1,
  weights = NULL,
  offset = NULL,
  Gc = NULL,
  wcomp = NULL,
  augmentation.type = c("lindyn.augment", "lin.augment"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recreg_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event' outcome</p>
</td></tr>
<tr><td><code id="recreg_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="recreg_+3A_cause">cause</code></td>
<td>
<p>of interest (1 default)</p>
</td></tr>
<tr><td><code id="recreg_+3A_death.code">death.code</code></td>
<td>
<p>codes for death (terminating event, 2 default)</p>
</td></tr>
<tr><td><code id="recreg_+3A_cens.code">cens.code</code></td>
<td>
<p>code of censoring (0 default)</p>
</td></tr>
<tr><td><code id="recreg_+3A_cens.model">cens.model</code></td>
<td>
<p>for stratified Cox model without covariates</p>
</td></tr>
<tr><td><code id="recreg_+3A_weights">weights</code></td>
<td>
<p>weights for score equations</p>
</td></tr>
<tr><td><code id="recreg_+3A_offset">offset</code></td>
<td>
<p>offsets for model</p>
</td></tr>
<tr><td><code id="recreg_+3A_gc">Gc</code></td>
<td>
<p>censoring weights for time argument, default is to calculate these with a Kaplan-Meier estimator, should then give G_c(T_i-)</p>
</td></tr>
<tr><td><code id="recreg_+3A_wcomp">wcomp</code></td>
<td>
<p>weights for composite outcome, so when cause=c(1,3), we might have wcomp=c(1,2).</p>
</td></tr>
<tr><td><code id="recreg_+3A_augmentation.type">augmentation.type</code></td>
<td>
<p>of augmentation when augmentation model is given</p>
</td></tr>
<tr><td><code id="recreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For Cox type model :
</p>
<p style="text-align: center;"><code class="reqn">
E(dN_1(t)|X) = \mu_0(t)dt exp(X^T \beta)
</code>
</p>

<p>by solving Cox-type IPCW weighted score equations 
</p>
<p style="text-align: center;"><code class="reqn">
 \int (Z - E(t)) w(t) dN_1(t) 
</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">w(t) = G(t) (I(T_i \wedge t &lt; C_i)/G_c(T_i \wedge t))</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">E(t) = S_1(t)/S_0(t)</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">S_j(t) = \sum X_i^j w_i(t) \exp(X_i^T \beta)</code>
</p>
<p>.
</p>
<p>The iid decomposition of the beta's are on the form
</p>
<p style="text-align: center;"><code class="reqn">
\int (Z - E ) w(t) dM_1 + \int q(s)/p(s) dM_c
</code>
</p>

<p>and returned as iid.
</p>
<p>Events, deaths and censorings are specified via stop start structure and the Event call, that via a status vector 
and cause (code), censoring-codes (cens.code) and death-codes (death.code) indentifies these. See example and vignette.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## data with no ties
data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
Lam1 &lt;- base1cumhaz;  Lam2 &lt;- base4cumhaz;  LamD &lt;- drcumhaz
## simulates recurrent events of types 1 and 2 and with terminal event D and censoring
rr &lt;- simRecurrentII(100,Lam1,cumhaz2=Lam2,death.cumhaz=LamD,cens=3/5000)
rr &lt;- count.history(rr)
rr$cens &lt;- 0
nid &lt;- max(rr$id)
rr$revnr &lt;- revcumsumstrata(rep(1,nrow(rr)),rr$id-1,nid)
rr$x &lt;- rnorm(nid)[rr$id]
rr$statusG &lt;- rr$status
rr &lt;- dtransform(rr,statusG=3,death==1)
dtable(rr,~statusG+status+death)
dcut(rr) &lt;- gx~x

ll &lt;- recreg(Event(start,stop,statusG)~x+cluster(id),data=rr,cause=1,death.code=3)
summary(ll)

## censoring stratified after quartiles of x
lls &lt;- recreg(Event(start, stop, statusG)~x+cluster(id),data=rr,cause=1,
              death.code=3,cens.model=~strata(gx))
summary(lls)

</code></pre>

<hr>
<h2 id='recurrentMarginal'>Fast recurrent marginal mean when death is possible</h2><span id='topic+recurrentMarginal'></span><span id='topic+tie.breaker'></span><span id='topic+recmarg'></span><span id='topic+recurrentMarginalIPCW'></span><span id='topic+recurrentMarginalAIPCW'></span><span id='topic+recurrentMarginalAIPCWdata'></span>

<h3>Description</h3>

<p>Fast Marginal means of recurrent events. Using the Lin and Ghosh (2000) 
standard errors.  
Fitting two models for death and recurent events these are
combined to prducte the estimator 
</p>
<p style="text-align: center;"><code class="reqn"> \int_0^t  S(u|x=0) dR(u|x=0) </code>
</p>
<p> the mean number of recurrent events, here
</p>
<p style="text-align: center;"><code class="reqn"> S(u|x=0) </code>
</p>
<p>  is the probability of survival for the baseline group, and 
</p>
<p style="text-align: center;"><code class="reqn"> dR(u|x=0) </code>
</p>
<p>  is the hazard rate of an event among survivors for the baseline. 
Here </p>
<p style="text-align: center;"><code class="reqn"> S(u|x=0) </code>
</p>
<p>  is estimated by </p>
<p style="text-align: center;"><code class="reqn"> exp(-\Lambda_d(u|x=0) </code>
</p>
<p>  with 
</p>
<p style="text-align: center;"><code class="reqn">\Lambda_d(u|x=0) </code>
</p>
<p> being the cumulative baseline for death.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recurrentMarginal(recurrent, death, fixbeta = NULL, km = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recurrentMarginal_+3A_recurrent">recurrent</code></td>
<td>
<p>phreg object with recurrent events</p>
</td></tr>
<tr><td><code id="recurrentMarginal_+3A_death">death</code></td>
<td>
<p>phreg object with deaths</p>
</td></tr>
<tr><td><code id="recurrentMarginal_+3A_fixbeta">fixbeta</code></td>
<td>
<p>to force the estimation of standard errors to think of regression coefficients as known/fixed</p>
</td></tr>
<tr><td><code id="recurrentMarginal_+3A_km">km</code></td>
<td>
<p>if true then uses Kaplan-Meier for death, otherwise exp(- Nelson-Aalen )</p>
</td></tr>
<tr><td><code id="recurrentMarginal_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assumes no ties in the sense that jump times needs to be unique, this is particularly so for the stratified version.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Cook, R. J. and Lawless, J. F. (1997) Marginal analysis of recurrent events and a terminating event. Statist. Med., 16, 911–924.
Ghosh and Lin (2002) Nonparametric Analysis of Recurrent events and death, Biometrics, 554&ndash;562.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz
rr &lt;- simRecurrent(1000,base1,death.cumhaz=dr)
rr$x &lt;- rnorm(nrow(rr)) 
rr$strata &lt;- floor((rr$id-0.01)/500)

##  to fit non-parametric models with just a baseline 
xr &lt;- phreg(Surv(entry,time,status)~cluster(id),data=rr)
dr &lt;- phreg(Surv(entry,time,death)~cluster(id),data=rr)
par(mfrow=c(1,3))
bplot(dr,se=TRUE)
title(main="death")
bplot(xr,se=TRUE)
### robust standard errors 
rxr &lt;-   robust.phreg(xr,fixbeta=1)
bplot(rxr,se=TRUE,robust=TRUE,add=TRUE,col=4)

## marginal mean of expected number of recurrent events 
out &lt;- recurrentMarginal(xr,dr)
bplot(out,se=TRUE,ylab="marginal mean",col=2)

########################################################################
###   with strata     ##################################################
########################################################################
xr &lt;- phreg(Surv(entry,time,status)~strata(strata)+cluster(id),data=rr)
dr &lt;- phreg(Surv(entry,time,death)~strata(strata)+cluster(id),data=rr)
par(mfrow=c(1,3))
bplot(dr,se=TRUE)
title(main="death")
bplot(xr,se=TRUE)
rxr &lt;-   robust.phreg(xr,fixbeta=1)
bplot(rxr,se=TRUE,robust=TRUE,add=TRUE,col=1:2)

out &lt;- recurrentMarginal(xr,dr)
bplot(out,se=TRUE,ylab="marginal mean",col=1:2)

########################################################################
###   cox case        ##################################################
########################################################################
xr &lt;- phreg(Surv(entry,time,status)~x+cluster(id),data=rr)
dr &lt;- phreg(Surv(entry,time,death)~x+cluster(id),data=rr)
par(mfrow=c(1,3))
bplot(dr,se=TRUE)
title(main="death")
bplot(xr,se=TRUE)
rxr &lt;-   robust.phreg(xr)
bplot(rxr,se=TRUE,robust=TRUE,add=TRUE,col=1:2)

out &lt;- recurrentMarginal(xr,dr)
bplot(out,se=TRUE,ylab="marginal mean",col=1:2)

########################################################################
###   CIF  #############################################################
########################################################################
### use of function to compute cumulative incidence (cif) with robust standard errors
 data(bmt)
 bmt$id &lt;- 1:nrow(bmt)
 xr  &lt;- phreg(Surv(time,cause==1)~cluster(id),data=bmt)
 dr  &lt;- phreg(Surv(time,cause!=0)~cluster(id),data=bmt)

 out &lt;- recurrentMarginal(xr,dr,km=TRUE)
 bplot(out,se=TRUE,ylab="cumulative incidence")

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+IC'></span><span id='topic+twostage'></span><span id='topic+estimate'></span><span id='topic+gof'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>lava</dt><dd><p><code><a href="lava.html#topic+estimate.default">estimate</a></code>, <code><a href="lava.html#topic+gof">gof</a></code>, <code><a href="lava.html#topic+IC">IC</a></code>, <code><a href="lava.html#topic+twostage">twostage</a></code></p>
</dd>
</dl>

<hr>
<h2 id='resmean.phreg'>Restricted mean for stratified Kaplan-Meier or Cox model with martingale standard errors</h2><span id='topic+resmean.phreg'></span><span id='topic+cif.yearslost'></span><span id='topic+rmst.phreg'></span>

<h3>Description</h3>

<p>Restricted mean for stratified Kaplan-Meier or stratified Cox with martingale 
standard error. Standard error is computed using linear interpolation between 
standard errors at jump-times. Plots gives restricted mean at all times. 
Years lost can be computed based on this and decomposed into years lost for
different causes using the cif.yearslost function that is based on  
integrating the cumulative incidence functions.  
One particular feature of these functions are that the restricted mean and years-lost are 
computed for all event times as functions and can be plotted/viewed.  When times are given and beyond
the last event time withn a strata the curves are extrapolated using the estimates of 
cumulative incidence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resmean.phreg(x, times = NULL, covs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resmean.phreg_+3A_x">x</code></td>
<td>
<p>phreg object</p>
</td></tr>
<tr><td><code id="resmean.phreg_+3A_times">times</code></td>
<td>
<p>possible times for which to report restricted mean</p>
</td></tr>
<tr><td><code id="resmean.phreg_+3A_covs">covs</code></td>
<td>
<p>possible covariate for Cox model</p>
</td></tr>
<tr><td><code id="resmean.phreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bmt); bmt$time &lt;- bmt$time+runif(408)*0.001
out1 &lt;- phreg(Surv(time,cause!=0)~strata(tcell,platelet),data=bmt)

rm1 &lt;- resmean.phreg(out1,times=10*(1:6))
summary(rm1)
par(mfrow=c(1,2))
plot(rm1,se=1)
plot(rm1,years.lost=TRUE,se=1)

## years.lost decomposed into causes
drm1 &lt;- cif.yearslost(Event(time,cause)~strata(tcell,platelet),data=bmt,times=10*(1:6))
par(mfrow=c(1,2)); plot(drm1,cause=1,se=1); plot(drm1,cause=2,se=1);
summary(drm1)
</code></pre>

<hr>
<h2 id='resmeanATE'>Average Treatment effect for Restricted Mean for censored competing risks data using IPCW</h2><span id='topic+resmeanATE'></span><span id='topic+rmstATE'></span>

<h3>Description</h3>

<p>Under the standard causal assumptions  we can estimate the average treatment effect E(Y(1) - Y(0)). We need Consistency, ignorability ( Y(1), Y(0) indep A given X), and positivity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resmeanATE(formula, data, model = "exp", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resmeanATE_+3A_formula">formula</code></td>
<td>
<p>formula with 'Event' outcome</p>
</td></tr>
<tr><td><code id="resmeanATE_+3A_data">data</code></td>
<td>
<p>data-frame</p>
</td></tr>
<tr><td><code id="resmeanATE_+3A_model">model</code></td>
<td>
<p>possible exp model for relevant mean model that is exp(X^t beta)</p>
</td></tr>
<tr><td><code id="resmeanATE_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to binregATE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first covariate in the specification of the competing risks regression model must be the treatment effect that is a factor. If the factor has more than two levels
then it uses the mlogit for propensity score modelling.  We consider the outcome mint(T;tau) or  I(epsion==cause1)(t- min(T;t)) that gives years lost due to cause &quot;cause&quot; depending on 
the number of causes. The default model is the exp(X^ beta) and otherwise a linear model is used. 
</p>
<p>Estimates the ATE using the the standard binary double robust estimating equations that are IPCW censoring adjusted.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mets); data(bmt); bmt$event &lt;- bmt$cause!=0; dfactor(bmt) &lt;- tcell~tcell
out &lt;- resmeanATE(Event(time,event)~tcell+platelet,data=bmt,time=40,treat.model=tcell~platelet)
summary(out)

out1 &lt;- resmeanATE(Event(time,cause)~tcell+platelet,data=bmt,cause=1,time=40,
                   treat.model=tcell~platelet)
summary(out1)

</code></pre>

<hr>
<h2 id='resmeanIPCW'>Restricted IPCW mean for censored survival data</h2><span id='topic+resmeanIPCW'></span><span id='topic+rmstIPCW'></span><span id='topic+resmeanIPCWold'></span>

<h3>Description</h3>

<p>Simple and fast version for IPCW regression for just one time-point thus fitting the model 
</p>
<p style="text-align: center;"><code class="reqn">E( min(T, t) | X ) = exp( X^T beta) </code>
</p>
<p> or in the case of competing risks data
</p>
<p style="text-align: center;"><code class="reqn">E( I(epsilon=1) (t - min(T ,t)) | X ) = exp( X^T beta) </code>
</p>
<p> thus given years lost to 
cause, see <code>binreg</code> for the arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resmeanIPCW(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resmeanIPCW_+3A_formula">formula</code></td>
<td>
<p>formula with outcome on Event form</p>
</td></tr>
<tr><td><code id="resmeanIPCW_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="resmeanIPCW_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the status is binary assumes it is a survival setting and default is to consider outcome Y=min(T,t), 
if status has more than two levels, then computes years lost due to the specified cause, thus
using the response </p>
<p style="text-align: center;"><code class="reqn"> Y = (t-min(T,t)) I(status=cause) </code>
</p>

<p>Based on binomial regresion IPCW response estimating equation: 
</p>
<p style="text-align: center;"><code class="reqn"> X ( \Delta(min(T,t)) Y /G_c(min(T,t)) - exp( X^T beta)) = 0 </code>
</p>

<p>for IPCW adjusted responses. Here </p>
<p style="text-align: center;"><code class="reqn"> \Delta(min(T,t)) = I ( min(T ,t) \leq C ) </code>
</p>
<p> is indicator of
being uncensored.  Concretely, the uncensored observations at time t will count those with an event (of any type) before t and those
with a censoring time at t or further out. One should therefore be a bit careful when data has been constructed such that
some of the event times T are equivalent to t. 
</p>
<p>Can also solve the binomial regresion IPCW response estimating equation: 
</p>
<p style="text-align: center;"><code class="reqn"> h(X) X ( \Delta(min(T,t)) Y /G_c(min(T,t)) - exp( X^T beta)) = 0 </code>
</p>

<p>for IPCW adjusted responses where $h$ is given as an argument together with iid of censoring with h. 
</p>
<p>By using appropriately  the h argument we can also do the efficient IPCW estimator estimator.
</p>
<p>Variance is based on  </p>
<p style="text-align: center;"><code class="reqn"> \sum w_i^2 </code>
</p>
<p> also with IPCW adjustment, and naive.var is variance 
under known censoring model. 
</p>
<p>When Ydirect is given it solves : 
</p>
<p style="text-align: center;"><code class="reqn"> X ( \Delta(min(T,t)) Ydirect /G_c(min(T,t)) - exp( X^T beta)) = 0 </code>
</p>

<p>for IPCW adjusted responses. 
</p>
<p>The actual influence (type=&quot;II&quot;) function is based on augmenting with </p>
<p style="text-align: center;"><code class="reqn"> X \int_0^t E(Y | T&gt;s) /G_c(s) dM_c(s) </code>
</p>

<p>and alternatively just solved directly (type=&quot;I&quot;) without any additional terms. 
</p>
<p>Censoring model may depend on strata.
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(bmt); bmt$time &lt;- bmt$time+runif(nrow(bmt))*0.001
# E( min(T;t) | X ) = exp( a+b X) with IPCW estimation 
out &lt;- resmeanIPCW(Event(time,cause!=0)~tcell+platelet+age,bmt,
                time=50,cens.model=~strata(platelet),model="exp")
summary(out)

### same as Kaplan-Meier for full censoring model 
bmt$int &lt;- with(bmt,strata(tcell,platelet))
out &lt;- resmeanIPCW(Event(time,cause!=0)~-1+int,bmt,time=30,
                             cens.model=~strata(platelet,tcell),model="lin")
estimate(out)
out1 &lt;- phreg(Surv(time,cause!=0)~strata(tcell,platelet),data=bmt)
rm1 &lt;- resmean.phreg(out1,times=30)
summary(rm1)

## competing risks years-lost for cause 1  
out &lt;- resmeanIPCW(Event(time,cause)~-1+int,bmt,time=30,cause=1,
                            cens.model=~strata(platelet,tcell),model="lin")
estimate(out)
## same as integrated cumulative incidence 
rmc1 &lt;- cif.yearslost(Event(time,cause)~strata(tcell,platelet),data=bmt,times=30)
summary(rmc1)
</code></pre>

<hr>
<h2 id='rpch'>Piecewise constant hazard distribution</h2><span id='topic+rpch'></span><span id='topic+ppch'></span>

<h3>Description</h3>

<p>Piecewise constant hazard distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpch(n, lambda = 1, breaks = c(0, Inf))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rpch_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rpch_+3A_lambda">lambda</code></td>
<td>
<p>rate parameters</p>
</td></tr>
<tr><td><code id="rpch_+3A_breaks">breaks</code></td>
<td>
<p>time cut-points</p>
</td></tr>
</table>

<hr>
<h2 id='sim.cause.cox'>Simulation of cause specific from Cox models.</h2><span id='topic+sim.cause.cox'></span>

<h3>Description</h3>

<p>Simulates data that looks like fit from cause specific Cox models. 
Censor data automatically. When censoring is given in the  list of causes this
will give censoring that looks like the data.  Covariates are drawn from data-set
with replacement. This gives covariates like the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.cause.cox(coxs,n,data=NULL,cens=NULL,rrc=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.cause.cox_+3A_coxs">coxs</code></td>
<td>
<p>list of cox models.</p>
</td></tr>
<tr><td><code id="sim.cause.cox_+3A_n">n</code></td>
<td>
<p>number of simulations.</p>
</td></tr>
<tr><td><code id="sim.cause.cox_+3A_data">data</code></td>
<td>
<p>to extract covariates for simulations (draws from observed
covariates).</p>
</td></tr>
<tr><td><code id="sim.cause.cox_+3A_cens">cens</code></td>
<td>
<p>specifies censoring model, if NULL then only censoring for 
each cause at end of last event of this type. 
if &quot;is.matrix&quot; then uses cumulative. 
hazard given, if &quot;is.scalar&quot; then uses rate for exponential, and if not
given then takes average rate of in simulated data from cox model.
But censoring can also be given as a cause.</p>
</td></tr>
<tr><td><code id="sim.cause.cox_+3A_rrc">rrc</code></td>
<td>
<p>possible vector of relative risk for cox-type censoring.</p>
</td></tr>
<tr><td><code id="sim.cause.cox_+3A_...">...</code></td>
<td>
<p>arguments for rchaz, for example entry-time</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nsim &lt;- 100; data(bmt)

cox1 &lt;- phreg(Surv(time,cause==1)~strata(tcell)+platelet,data=bmt)
cox2 &lt;- phreg(Surv(time,cause==2)~tcell+strata(platelet),data=bmt)
coxs &lt;- list(cox1,cox2)
dd &lt;- sim.cause.cox(coxs,nsim,data=bmt)
scox1 &lt;- phreg(Surv(time,status==1)~strata(tcell)+platelet,data=dd)
scox2 &lt;- phreg(Surv(time,status==2)~tcell+strata(platelet),data=dd)
cbind(cox1$coef,scox1$coef)
cbind(cox2$coef,scox2$coef)
par(mfrow=c(1,2))
plot(cox1); plot(scox1,add=TRUE); 
plot(cox2); plot(scox2,add=TRUE); 

</code></pre>

<hr>
<h2 id='sim.cif'>Simulation of output from Cumulative incidence regression model</h2><span id='topic+sim.cif'></span><span id='topic+sim.cifs'></span><span id='topic+subdist'></span><span id='topic+pre.cifs'></span><span id='topic+sim.cifsRestrict'></span><span id='topic+simsubdist'></span><span id='topic+invsubdist'></span>

<h3>Description</h3>

<p>Simulates data that looks like fit from fitted cumulative incidence model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.cif(cif,n,data=NULL,Z=NULL,drawZ=TRUE,cens=NULL,rrc=NULL,cumstart=c(0,0),...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.cif_+3A_cif">cif</code></td>
<td>
<p>output form prop.odds.subdist or ccr (cmprsk), can also call invsubdist with 
with cumulative and linear predictor</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_n">n</code></td>
<td>
<p>number of simulations.</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_data">data</code></td>
<td>
<p>to extract covariates for simulations (draws from observed
covariates).</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_z">Z</code></td>
<td>
<p>to use these covariates for simulation rather than drawing new ones.</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_drawz">drawZ</code></td>
<td>
<p>to random sample from Z or not</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_cens">cens</code></td>
<td>
<p>specifies censoring model, if &quot;is.matrix&quot; then uses cumulative
hazard given, if &quot;is.scalar&quot; then uses rate for exponential, and if not
given then takes average rate of in simulated data from cox model.</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_rrc">rrc</code></td>
<td>
<p>possible vector of relative risk for cox-type censoring.</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_cumstart">cumstart</code></td>
<td>
<p>to start cumulatives at time 0 in 0.</p>
</td></tr>
<tr><td><code id="sim.cif_+3A_...">...</code></td>
<td>
<p>arguments for invsubdist</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bmt)

scif &lt;-  cifreg(Event(time,cause)~tcell+platelet+age,data=bmt,cause=1,prop=NULL)
summary(scif)  
plot(scif)
################################################################
#  simulating several causes with specific cumulatives 
################################################################

cif1 &lt;-  cifreg(Event(time,cause)~tcell+age,data=bmt,cause=1,prop=NULL)
cif2 &lt;-  cifreg(Event(time,cause)~tcell+age,data=bmt,cause=2,prop=NULL)
# dd &lt;- sim.cifsRestrict(list(cif1,cif2),200,data=bmt)
dd &lt;- sim.cifs(list(cif1,cif2),200,data=bmt)
scif1 &lt;-  cifreg(Event(time,cause)~tcell+age,data=dd,cause=1)
scif2 &lt;-  cifreg(Event(time,cause)~tcell+age,data=dd,cause=2)
   
par(mfrow=c(1,2))   
plot(cif1); plot(scif1,add=TRUE,col=2)
plot(cif2); plot(scif2,add=TRUE,col=2)
</code></pre>

<hr>
<h2 id='sim.cox'>Simulation of output from Cox model.</h2><span id='topic+sim.cox'></span><span id='topic+sim.phreg'></span><span id='topic+read.phreg'></span><span id='topic+read.fit'></span><span id='topic+sim.base'></span><span id='topic+simulate.cox'></span><span id='topic+sim.phregs'></span>

<h3>Description</h3>

<p>Simulates data that looks like fit from Cox model. Censor data automatically
for highest value of the event times by using cumulative hazard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.cox(cox,n,data=NULL,cens=NULL,rrc=NULL,entry=NULL,rr=NULL,Z=NULL,extend=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.cox_+3A_cox">cox</code></td>
<td>
<p>output form coxph or cox.aalen model fitting cox model.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_n">n</code></td>
<td>
<p>number of simulations.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_data">data</code></td>
<td>
<p>to extract covariates for simulations (draws from observed
covariates).</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_cens">cens</code></td>
<td>
<p>specifies censoring model, if &quot;is.matrix&quot; then uses cumulative
hazard given, if &quot;is.scalar&quot; then uses rate for exponential, and if not
given then takes average rate of in simulated data from cox model.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_rrc">rrc</code></td>
<td>
<p>possible vector of relative risk for cox-type censoring.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_entry">entry</code></td>
<td>
<p>delayed entry variable for simulation.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_rr">rr</code></td>
<td>
<p>possible vector of relative risk for cox model.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_z">Z</code></td>
<td>
<p>possible covariates to use instead of sampling from data.</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_extend">extend</code></td>
<td>
<p>to extend possible stratified baselines to largest end-point</p>
</td></tr>
<tr><td><code id="sim.cox_+3A_...">...</code></td>
<td>
<p>arguments for rchaz, for example entry-time.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sTRACE)
nsim &lt;- 100
coxs &lt;-  phreg(Surv(time,status==9)~strata(chf)+vf+wmi,data=sTRACE)
sim3 &lt;- sim.phreg(coxs,nsim,data=sTRACE)
cc &lt;-   phreg(Surv(time, status)~strata(chf)+vf+wmi,data=sim3)
cbind(coxs$coef,cc$coef)
plot(coxs,col=1); plot(cc,add=TRUE,col=2)

</code></pre>

<hr>
<h2 id='simAalenFrailty'>Simulate from the Aalen Frailty model</h2><span id='topic+simAalenFrailty'></span>

<h3>Description</h3>

<p>Simulate observations from Aalen Frailty model with Gamma
distributed frailty and constant intensity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simAalenFrailty(
  n = 5000,
  theta = 0.3,
  K = 2,
  beta0 = 1.5,
  beta = 1,
  cens = 1.5,
  cuts = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simAalenFrailty_+3A_n">n</code></td>
<td>
<p>Number of observations in each cluster</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_theta">theta</code></td>
<td>
<p>Dependence paramter (variance of frailty)</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_k">K</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_beta0">beta0</code></td>
<td>
<p>Baseline (intercept)</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_beta">beta</code></td>
<td>
<p>Effect (log hazard ratio) of covariate</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_cens">cens</code></td>
<td>
<p>Censoring rate</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_cuts">cuts</code></td>
<td>
<p>time cuts</p>
</td></tr>
<tr><td><code id="simAalenFrailty_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='simClaytonOakes'>Simulate from the Clayton-Oakes frailty model</h2><span id='topic+simClaytonOakes'></span><span id='topic+simClaytonOakesLam'></span>

<h3>Description</h3>

<p>Simulate observations from the Clayton-Oakes copula model with
piecewise constant marginals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simClaytonOakes(
  K,
  n,
  eta,
  beta,
  stoptime,
  lam = 1,
  left = 0,
  pairleft = 0,
  trunc.prob = 0.5,
  same = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simClaytonOakes_+3A_k">K</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_n">n</code></td>
<td>
<p>Number of observations in each cluster</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_eta">eta</code></td>
<td>
<p>variance</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_beta">beta</code></td>
<td>
<p>Effect (log hazard ratio) of covariate</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_stoptime">stoptime</code></td>
<td>
<p>Stopping time</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_lam">lam</code></td>
<td>
<p>constant hazard</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_left">left</code></td>
<td>
<p>Left truncation</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_pairleft">pairleft</code></td>
<td>
<p>pairwise (1) left truncation or individual (0)</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_trunc.prob">trunc.prob</code></td>
<td>
<p>Truncation probability</p>
</td></tr>
<tr><td><code id="simClaytonOakes_+3A_same">same</code></td>
<td>
<p>if 1 then left-truncation is same also for univariate truncation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike and Klaus K. Holst
</p>

<hr>
<h2 id='simClaytonOakesWei'>Simulate from the Clayton-Oakes frailty model</h2><span id='topic+simClaytonOakesWei'></span>

<h3>Description</h3>

<p>Simulate observations from the Clayton-Oakes copula model with
Weibull type baseline and Cox marginals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simClaytonOakesWei(
  K,
  n,
  eta,
  beta,
  stoptime,
  weiscale = 1,
  weishape = 2,
  left = 0,
  pairleft = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simClaytonOakesWei_+3A_k">K</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_n">n</code></td>
<td>
<p>Number of observations in each cluster</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_eta">eta</code></td>
<td>
<p>1/variance</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_beta">beta</code></td>
<td>
<p>Effect (log hazard ratio) of covariate</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_stoptime">stoptime</code></td>
<td>
<p>Stopping time</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_weiscale">weiscale</code></td>
<td>
<p>weibull scale parameter</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_weishape">weishape</code></td>
<td>
<p>weibull shape parameter</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_left">left</code></td>
<td>
<p>Left truncation</p>
</td></tr>
<tr><td><code id="simClaytonOakesWei_+3A_pairleft">pairleft</code></td>
<td>
<p>pairwise (1) left truncation or individual (0)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='simMultistate'>Simulation of illness-death model</h2><span id='topic+simMultistate'></span><span id='topic+extendCums'></span>

<h3>Description</h3>

<p>Simulation of illness-death model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simMultistate(
  n,
  cumhaz,
  cumhaz2,
  death.cumhaz,
  death.cumhaz2,
  rr = NULL,
  rr2 = NULL,
  rd = NULL,
  rd2 = NULL,
  gap.time = FALSE,
  max.recurrent = 100,
  dependence = 0,
  var.z = 0.22,
  cor.mat = NULL,
  cens = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simMultistate_+3A_n">n</code></td>
<td>
<p>number of id's</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_cumhaz">cumhaz</code></td>
<td>
<p>cumulative hazard of going from state 1 to 2.</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_cumhaz2">cumhaz2</code></td>
<td>
<p>cumulative hazard of going from state 2 to 1.</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_death.cumhaz">death.cumhaz</code></td>
<td>
<p>cumulative hazard of death from state 1.</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_death.cumhaz2">death.cumhaz2</code></td>
<td>
<p>cumulative hazard of death from state 2.</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_rr">rr</code></td>
<td>
<p>relative risk adjustment for cumhaz</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_rr2">rr2</code></td>
<td>
<p>relative risk adjustment for cumhaz2</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_rd">rd</code></td>
<td>
<p>relative risk adjustment for death.cumhaz</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_rd2">rd2</code></td>
<td>
<p>relative risk adjustment for death.cumhaz2</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_gap.time">gap.time</code></td>
<td>
<p>if true simulates gap-times with specified cumulative hazard</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_max.recurrent">max.recurrent</code></td>
<td>
<p>limits number recurrent events to 100</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_dependence">dependence</code></td>
<td>
<p>0:independence; 1:all share same random effect with variance var.z; 2:random effect exp(normal) with correlation structure from cor.mat; 3:additive gamma distributed random effects, z1= (z11+ z12)/2 such that mean is 1 , z2= (z11^cor.mat(1,2)+ z13)/2, z3= (z12^(cor.mat(2,3)+z13^cor.mat(1,3))/2, with z11 z12 z13 are gamma with mean and variance 1 , first random effect is z1 and for N1 second random effect is z2 and for N2 third random effect is for death</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_var.z">var.z</code></td>
<td>
<p>variance of random effects</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_cor.mat">cor.mat</code></td>
<td>
<p>correlation matrix for var.z variance of random effects</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_cens">cens</code></td>
<td>
<p>rate of censoring exponential distribution</p>
</td></tr>
<tr><td><code id="simMultistate_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>simMultistate with different death intensities from states 1 and 2 
</p>
<p>Must give cumulative hazards on some time-range
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################
## getting some rates to mimick 
########################################
data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
dr2 &lt;- drcumhaz
dr2[,2] &lt;- 1.5*drcumhaz[,2]
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz
cens &lt;- rbind(c(0,0),c(2000,0.5),c(5110,3))

iddata &lt;- simMultistate(10000,base1,base1,dr,dr2,cens=cens)
dlist(iddata,.~id|id&lt;3,n=0)
 
### estimating rates from simulated data  
c0 &lt;- phreg(Surv(start,stop,status==0)~+1,iddata)
c3 &lt;- phreg(Surv(start,stop,status==3)~+strata(from),iddata)
c1 &lt;- phreg(Surv(start,stop,status==1)~+1,subset(iddata,from==2))
c2 &lt;- phreg(Surv(start,stop,status==2)~+1,subset(iddata,from==1))
###
par(mfrow=c(2,3))
bplot(c0)
lines(cens,col=2) 
bplot(c3,main="rates 1-&gt; 3 , 2-&gt;3")
lines(dr,col=1,lwd=2)
lines(dr2,col=2,lwd=2)
###
bplot(c1,main="rate 1-&gt;2")
lines(base1,lwd=2)
###
bplot(c2,main="rate 2-&gt;1")
lines(base1,lwd=2)
 
</code></pre>

<hr>
<h2 id='simRecurrentII'>Simulation of recurrent events data based on cumulative hazards II</h2><span id='topic+simRecurrentII'></span><span id='topic+sim.recurrent'></span><span id='topic+simRecurrent'></span><span id='topic+showfitsim'></span><span id='topic+covIntH1dM1IntH2dM2'></span><span id='topic+squareintHdM'></span><span id='topic+simRecurrentIII'></span><span id='topic+showfitsimIII'></span>

<h3>Description</h3>

<p>Simulation of recurrent events data based on cumulative hazards
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simRecurrentII(
  n,
  cumhaz,
  cumhaz2,
  death.cumhaz = NULL,
  r1 = NULL,
  r2 = NULL,
  rd = NULL,
  rc = NULL,
  gap.time = FALSE,
  max.recurrent = 100,
  dhaz = NULL,
  haz2 = NULL,
  dependence = 0,
  var.z = 0.22,
  cor.mat = NULL,
  cens = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simRecurrentII_+3A_n">n</code></td>
<td>
<p>number of id's</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_cumhaz">cumhaz</code></td>
<td>
<p>cumulative hazard of recurrent events</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_cumhaz2">cumhaz2</code></td>
<td>
<p>cumulative hazard of recurrent events  of type 2</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_death.cumhaz">death.cumhaz</code></td>
<td>
<p>cumulative hazard of death</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_r1">r1</code></td>
<td>
<p>potential relative risk adjustment of rate</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_r2">r2</code></td>
<td>
<p>potential relative risk adjustment of rate</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_rd">rd</code></td>
<td>
<p>potential relative risk adjustment of rate</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_rc">rc</code></td>
<td>
<p>potential relative risk adjustment of rate</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_gap.time">gap.time</code></td>
<td>
<p>if true simulates gap-times with specified cumulative hazard</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_max.recurrent">max.recurrent</code></td>
<td>
<p>limits number recurrent events to 100</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_dhaz">dhaz</code></td>
<td>
<p>rate for death hazard if it is extended to time-range of first event</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_haz2">haz2</code></td>
<td>
<p>rate of second cause  if it is extended to time-range of first event</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_dependence">dependence</code></td>
<td>
<p>0:independence; 1:all share same random effect with variance var.z; 2:random effect exp(normal) with correlation structure from cor.mat; 3:additive gamma distributed random effects, z1= (z11+ z12)/2 such that mean is 1 , z2= (z11^cor.mat(1,2)+ z13)/2, z3= (z12^(cor.mat(2,3)+z13^cor.mat(1,3))/2, with z11 z12 z13 are gamma with mean and variance 1 , first random effect is z1 and for N1 second random effect is z2 and for N2 third random effect is for death</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_var.z">var.z</code></td>
<td>
<p>variance of random effects</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_cor.mat">cor.mat</code></td>
<td>
<p>correlation matrix for var.z variance of random effects</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_cens">cens</code></td>
<td>
<p>rate of censoring exponential distribution</p>
</td></tr>
<tr><td><code id="simRecurrentII_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Must give hazard of death and two recurrent events.  Possible with two
event types and their dependence can be specified but the two recurrent events need
to share random effect. Based on drawing the from cumhaz and cumhaz2 and 
taking the first event rather
the cumulative and then distributing it out. Key advantage of this is that 
there is  more flexibility wrt random effects
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################
## getting some rates to mimick 
########################################

data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz

cor.mat &lt;- corM &lt;- rbind(c(1.0, 0.6, 0.9), c(0.6, 1.0, 0.5), c(0.9, 0.5, 1.0))

######################################################################
### simulating simple model that mimicks data 
######################################################################
rr &lt;- simRecurrent(5,base1,death.cumhaz=dr)
dlist(rr,.~id,n=0)

rr &lt;- simRecurrent(10000,base1,death.cumhaz=dr)
par(mfrow=c(1,3))
showfitsim(causes=1,rr,dr,base1,base1)
######################################################################
### simulating simple model 
### random effect for all causes (Z shared for death and recurrent) 
######################################################################
rr &lt;- simRecurrent(100,base1,death.cumhaz=dr,dependence=1,var.gamma=0.4)

######################################################################
### simulating simple model that mimicks data 
### now with two event types and second type has same rate as death rate
######################################################################
set.seed(100)
rr &lt;- simRecurrentII(10000,base1,base4,death.cumhaz=dr)
dtable(rr,~death+status)
par(mfrow=c(2,2))
showfitsim(causes=2,rr,dr,base1,base4)

set.seed(100)
cumhaz &lt;- list(base1,base1,base4)
drl &lt;- list(dr,base4)
rr &lt;- simRecurrentIII(100,cumhaz,death.cumhaz=drl,dep=0)
dtable(rr,~death+status)
showfitsimIII(rr,cumhaz,drl) 

</code></pre>

<hr>
<h2 id='simRecurrentTS'>Simulation of recurrent events data based on cumulative hazards: Two-stage model</h2><span id='topic+simRecurrentTS'></span>

<h3>Description</h3>

<p>Simulation of recurrent events data based on cumulative hazards
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simRecurrentTS(
  n,
  cumhaz,
  cumhaz2,
  death.cumhaz = NULL,
  nu = rep(1, 3),
  share1 = 0.3,
  vargamD = 2,
  vargam12 = 0.5,
  gap.time = FALSE,
  max.recurrent = 100,
  cens = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simRecurrentTS_+3A_n">n</code></td>
<td>
<p>number of id's</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_cumhaz">cumhaz</code></td>
<td>
<p>cumulative hazard of recurrent events</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_cumhaz2">cumhaz2</code></td>
<td>
<p>cumulative hazard of recurrent events  of type 2</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_death.cumhaz">death.cumhaz</code></td>
<td>
<p>cumulative hazard of death</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_nu">nu</code></td>
<td>
<p>powers of random effects where nu &gt; -1/shape</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_share1">share1</code></td>
<td>
<p>how random effect for death splits into two parts</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_vargamd">vargamD</code></td>
<td>
<p>variance of random effect  for death</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_vargam12">vargam12</code></td>
<td>
<p>shared random effect for N1 and N2</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_gap.time">gap.time</code></td>
<td>
<p>if true simulates gap-times with specified cumulative hazard</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_max.recurrent">max.recurrent</code></td>
<td>
<p>limits number recurrent events to 100</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_cens">cens</code></td>
<td>
<p>rate of censoring exponential distribution</p>
</td></tr>
<tr><td><code id="simRecurrentTS_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level funtions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model is constructed such that marginals are on specified form by linear approximations
of cumulative hazards that are on a specific form to make them equivalent to marginals
after integrating out over survivors. Therefore E(dN_1 | D&gt;t) = cumhaz, 
E(dN_2 | D&gt;t) = cumhaz2,  and hazard of death is death.cumhazard 
</p>
<p>Must give hazard of death and two recurrent events.  Hazard of death is death.cumhazard  two
event types and their dependence can be specified but the two recurrent events need
to share random effect. 
</p>
<p>Random effect for  death Z.death=(Zd1+Zd2), Z1=(Zd1^nu1) Z12,  Z2=(Zd2^nu2) Z12^nu3
</p>
<p style="text-align: center;"><code class="reqn">Z.death=Zd1+Zd2</code>
</p>
<p>  gamma distributions 
</p>
<p style="text-align: center;"><code class="reqn">Zdj</code>
</p>
<p>  gamma distribution  with mean parameters (sharej), vargamD,  share2=1-share1
</p>
<p style="text-align: center;"><code class="reqn">Z12</code>
</p>
<p>  gamma distribution with mean 1 and variance vargam12
</p>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################
## getting some rates to mimick 
########################################

data(base1cumhaz)
data(base4cumhaz)
data(drcumhaz)
dr &lt;- drcumhaz
base1 &lt;- base1cumhaz
base4 &lt;- base4cumhaz

rr &lt;- simRecurrentTS(1000,base1,base4,death.cumhaz=dr)
dtable(rr,~death+status)
showfitsim(causes=2,rr,dr,base1,base4)

</code></pre>

<hr>
<h2 id='summary.cor'>Summary for dependence models for competing risks</h2><span id='topic+summary.cor'></span>

<h3>Description</h3>

<p>Computes concordance and casewise concordance for dependence models for competing risks 
models of the type cor.cif, rr.cif or or.cif for the given cumulative incidences and the different dependence
measures in the object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cor'
summary(object, marg.cif = NULL, marg.cif2 = NULL, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.cor_+3A_object">object</code></td>
<td>
<p>object from cor.cif rr.cif or or.cif for dependence between competing risks data for two causes.</p>
</td></tr>
<tr><td><code id="summary.cor_+3A_marg.cif">marg.cif</code></td>
<td>
<p>a number that gives the cumulative incidence in one time point for which concordance and 
casewise concordance are computed.</p>
</td></tr>
<tr><td><code id="summary.cor_+3A_marg.cif2">marg.cif2</code></td>
<td>
<p>the cumulative incidence for cause 2 for concordance and 
casewise concordance are computed. Default is that it is the same as marg.cif.</p>
</td></tr>
<tr><td><code id="summary.cor_+3A_digits">digits</code></td>
<td>
<p>digits in output.</p>
</td></tr>
<tr><td><code id="summary.cor_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints summary for dependence model. 
</p>
<table role = "presentation">
<tr><td><code>casewise</code></td>
<td>
<p>gives casewise concordance that is, probability of cause 2 (related to cif2) given that cause 1 (related to cif1)
has occured.</p>
</td></tr>
<tr><td><code>concordance</code></td>
<td>
<p>gives concordance that is, probability of cause 2 (related to cif2) and cause 1 (related to cif1).</p>
</td></tr>
<tr><td><code>cif1</code></td>
<td>
<p>cumulative incidence for cause1.</p>
</td></tr>
<tr><td><code>cif2</code></td>
<td>
<p>cumulative incidence for cause1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Cross odds ratio Modelling of dependence for
Multivariate Competing Risks Data, Scheike and Sun (2012), Biostatistics. 
</p>
<p>A Semiparametric Random Effects Model for Multivariate Competing Risks Data,
Scheike, Zhang, Sun, Jensen (2010), Biometrika.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## library("timereg")
## data("multcif",package="mets") # simulated data 
## multcif$cause[multcif$cause==0] &lt;- 2
##  
## times=seq(0.1,3,by=0.1) # to speed up computations use only these time-points
## add &lt;- timereg::comp.risk(Event(time,cause)~+1+cluster(id),
##                           data=multcif,n.sim=0,times=times,cause=1)
###
## out1&lt;-cor.cif(add,data=multcif,cause1=1,cause2=1,theta=log(2+1))
## summary(out1)
## 
## pad &lt;- predict(add,X=1,se=0,uniform=0)
## summary(out1,marg.cif=pad)
</code></pre>

<hr>
<h2 id='summaryGLM'>Reporting OR (exp(coef)) from glm with binomial link and glm predictions</h2><span id='topic+summaryGLM'></span><span id='topic+predictGLM'></span>

<h3>Description</h3>

<p>Reporting OR from glm with binomial link  and glm predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryGLM(object, id = NULL, fun = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summaryGLM_+3A_object">object</code></td>
<td>
<p>glm output</p>
</td></tr>
<tr><td><code id="summaryGLM_+3A_id">id</code></td>
<td>
<p>possible id for cluster corrected standard errors</p>
</td></tr>
<tr><td><code id="summaryGLM_+3A_fun">fun</code></td>
<td>
<p>possible function for non-standard predictions based on object</p>
</td></tr>
<tr><td><code id="summaryGLM_+3A_...">...</code></td>
<td>
<p>arguments of estimate of lava for example level=0.95</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sTRACE)
sTRACE$id &lt;- sample(1:100,nrow(sTRACE),replace=TRUE)

model &lt;- glm(I(status==9)~sex+factor(diabetes)+age,data=sTRACE,family=binomial)
summaryGLM(model)
summaryGLM(model,id=sTRACE$id)

nd &lt;- data.frame(sex=c(0,1),age=67,diabetes=1)
predictGLM(model,nd)
</code></pre>

<hr>
<h2 id='survival.twostage'>Twostage survival model for multivariate survival data</h2><span id='topic+survival.twostage'></span><span id='topic+twostage.aalen'></span><span id='topic+twostage.cox.aalen'></span><span id='topic+twostage.coxph'></span><span id='topic+twostage.phreg'></span><span id='topic+randomDes'></span><span id='topic+readmargsurv'></span>

<h3>Description</h3>

<p>Fits Clayton-Oakes or bivariate Plackett models for bivariate survival data
using marginals that are on Cox form. The dependence can be modelled via
</p>

<ol>
<li><p>  Regression design on dependence parameter.
</p>
</li>
<li><p>  Random effects, additive gamma model.
</p>
</li></ol>

<p>If clusters contain more than two subjects, we use a composite likelihood
based on the pairwise bivariate models, for full MLE see twostageMLE.
</p>
<p>The two-stage model is constructed such that
given the gamma distributed random effects it is assumed that the survival functions
are indpendent, and that the marginal survival functions are on Cox form (or additive form)
</p>
<p style="text-align: center;"><code class="reqn">
P(T &gt; t| x) = S(t|x)= exp( -exp(x^T \beta) A_0(t) )
</code>
</p>

<p>One possibility is to model the variance within clusters via a regression design, and
then one can specify a regression structure for the independent gamma distributed
random effect for each cluster, such that the variance is given by
</p>
<p style="text-align: center;"><code class="reqn">
 \theta = h( z_j^T \alpha)
</code>
</p>

<p>where <code class="reqn">z</code> is specified by theta.des, and a possible link function var.link=1 will
will use the exponential link <code class="reqn">h(x)=exp(x)</code>, and var.link=0 the identity link <code class="reqn">h(x)=x</code>.
The reported standard errors are based on the estimated information from the
likelihood assuming that the marginals are known (unlike the twostageMLE and for the
additive gamma model below).
</p>
<p>Can also fit a structured additive gamma random effects model, such
as the ACE, ADE model for survival data.  In this case the
random.design specificies the random effects for each subject within a cluster. This is
a matrix of 1's and 0's with dimension n x d.  With d random effects.
For a cluster with two subjects, we let the random.design rows be
<code class="reqn">v_1</code> and <code class="reqn">v_2</code>.
Such that the random effects for subject
1 is </p>
<p style="text-align: center;"><code class="reqn">v_1^T (Z_1,...,Z_d)</code>
</p>
<p>, for d random effects. Each random effect
has an associated parameter <code class="reqn">(\lambda_1,...,\lambda_d)</code>.
By construction subjects 1's random effect are Gamma distributed with
mean <code class="reqn">\lambda_j/v_1^T \lambda</code>
and variance <code class="reqn">\lambda_j/(v_1^T \lambda)^2</code>. Note that the random effect
<code class="reqn">v_1^T (Z_1,...,Z_d)</code> has mean 1 and variance <code class="reqn">1/(v_1^T \lambda)</code>.
It is here asssumed that  <code class="reqn">lamtot=v_1^T \lambda</code> is fixed within clusters
as it would be for the ACE model below.
</p>
<p>Based on these parameters the relative contribution (the heritability, h) is
equivalent to  the expected values of the random effects: <code class="reqn">\lambda_j/v_1^T \lambda</code>
</p>
<p>The DEFAULT parametrization (var.par=1) uses the variances of the random effecs
</p>
<p style="text-align: center;"><code class="reqn">
\theta_j  = \lambda_j/(v_1^T \lambda)^2
</code>
</p>

<p>For alternative parametrizations one can specify how the parameters relate to <code class="reqn">\lambda_j</code>
with the argument var.par=0.
</p>
<p>For both types of models the basic model assumptions are that
given the random effects of the clusters the survival distributions within a cluster
are independent and ' on the form
</p>
<p style="text-align: center;"><code class="reqn">
P(T &gt; t| x,z) = exp( -Z \cdot Laplace^{-1}(lamtot,lamtot,S(t|x)) )
</code>
</p>

<p>with the inverse laplace of the gamma distribution with mean 1 and variance 1/lamtot.
</p>
<p>The parameters <code class="reqn">(\lambda_1,...,\lambda_d)</code> are related to the parameters of the model
by a regression construction <code class="reqn">pard</code> (d x k), that links the <code class="reqn">d</code>
<code class="reqn">\lambda</code> parameters
with the (k) underlying <code class="reqn">\theta</code> parameters
</p>
<p style="text-align: center;"><code class="reqn">
\lambda = theta.des  \theta
</code>
</p>

<p>here using theta.des to specify these low-dimension association. Default is a diagonal matrix.
This can be used to make structural assumptions about the variances of the random-effects
as is needed for the ACE model for example.
</p>
<p>The case.control option that can be used with the pair specification of the pairwise parts
of the estimating equations. Here it is assumed that the second subject of each pair is the proband.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survival.twostage(
  margsurv,
  data = parent.frame(),
  method = "nr",
  detail = 0,
  clusters = NULL,
  silent = 1,
  weights = NULL,
  theta = NULL,
  theta.des = NULL,
  var.link = 1,
  baseline.iid = 1,
  model = "clayton.oakes",
  marginal.trunc = NULL,
  marginal.survival = NULL,
  strata = NULL,
  se.clusters = NULL,
  numDeriv = 1,
  random.design = NULL,
  pairs = NULL,
  dim.theta = NULL,
  numDeriv.method = "simple",
  additive.gamma.sum = NULL,
  var.par = 1,
  no.opt = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="survival.twostage_+3A_margsurv">margsurv</code></td>
<td>
<p>Marginal model</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_method">method</code></td>
<td>
<p>Scoring method &quot;nr&quot;, for lava NR optimizer</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_detail">detail</code></td>
<td>
<p>Detail</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_clusters">clusters</code></td>
<td>
<p>Cluster variable</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_silent">silent</code></td>
<td>
<p>Debug information</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_weights">weights</code></td>
<td>
<p>Weights</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_theta">theta</code></td>
<td>
<p>Starting values for variance components</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_theta.des">theta.des</code></td>
<td>
<p>design for dependence parameters, when pairs are given the indeces of the
theta-design for this pair, is given in pairs as column 5</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_var.link">var.link</code></td>
<td>
<p>Link function for variance:  exp-link.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_baseline.iid">baseline.iid</code></td>
<td>
<p>to adjust for baseline estimation, using phreg function on same data.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_model">model</code></td>
<td>
<p>model</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_marginal.trunc">marginal.trunc</code></td>
<td>
<p>marginal left truncation probabilities</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_marginal.survival">marginal.survival</code></td>
<td>
<p>optional vector of marginal survival probabilities</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_strata">strata</code></td>
<td>
<p>strata for fitting, see example</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_se.clusters">se.clusters</code></td>
<td>
<p>for clusters for se calculation with iid</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_numderiv">numDeriv</code></td>
<td>
<p>to get numDeriv version of second derivative, otherwise uses sum of squared scores for each pair</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_random.design">random.design</code></td>
<td>
<p>random effect design for additive gamma model, when pairs are given the
indeces of the pairs random.design rows are given as columns 3:4</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_pairs">pairs</code></td>
<td>
<p>matrix with rows of indeces (two-columns) for the pairs considered in the pairwise
composite score, useful for case-control sampling when marginal is known.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_dim.theta">dim.theta</code></td>
<td>
<p>dimension of the theta parameter for pairs situation.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_numderiv.method">numDeriv.method</code></td>
<td>
<p>uses simple to speed up things and second derivative not so important.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_additive.gamma.sum">additive.gamma.sum</code></td>
<td>
<p>for two.stage=0, this is specification of the lamtot in the models via
a matrix that is multiplied onto the parameters theta (dimensions=(number random effects x number
of theta parameters), when null then sums all parameters.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_var.par">var.par</code></td>
<td>
<p>is 1 for the default parametrization with the variances of the random effects,
var.par=0 specifies that the <code class="reqn">\lambda_j</code>'s are used as parameters.</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_no.opt">no.opt</code></td>
<td>
<p>for not optimizng</p>
</td></tr>
<tr><td><code id="survival.twostage_+3A_...">...</code></td>
<td>
<p>Additional arguments to maximizer NR of lava.
and ascertained sampling</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Twostage estimation of additive gamma frailty models for survival data.
Scheike (2019), work in progress
</p>
<p>Shih and Louis (1995) Inference on the association parameter in copula models for bivariate
survival data, Biometrics, (1995).
</p>
<p>Glidden (2000), A Two-Stage estimator of the dependence
parameter for the Clayton Oakes model, LIDA, (2000).
</p>
<p>Measuring early or late dependence for bivariate twin data
Scheike, Holst, Hjelmborg (2015), LIDA
</p>
<p>Estimating heritability for cause specific mortality based on twins studies
Scheike, Holst, Hjelmborg (2014), LIDA
</p>
<p>Additive Gamma frailty models for competing risks data, Biometrics (2015)
Eriksson and Scheike (2015),
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diabetes)

# Marginal Cox model  with treat as covariate
margph &lt;- phreg(Surv(time,status)~treat+cluster(id),data=diabetes)
### Clayton-Oakes, MLE
fitco1&lt;-twostageMLE(margph,data=diabetes,theta=1.0)
summary(fitco1)

### Plackett model
mph &lt;- phreg(Surv(time,status)~treat+cluster(id),data=diabetes)
fitp &lt;- survival.twostage(mph,data=diabetes,theta=3.0,Nit=40,
               clusters=diabetes$id,var.link=1,model="plackett")
summary(fitp)

### Clayton-Oakes
fitco2 &lt;- survival.twostage(mph,data=diabetes,theta=0.0,detail=0,
                 clusters=diabetes$id,var.link=1,model="clayton.oakes")
summary(fitco2)
fitco3 &lt;- survival.twostage(margph,data=diabetes,theta=1.0,detail=0,
                 clusters=diabetes$id,var.link=0,model="clayton.oakes")
summary(fitco3)

### without covariates but with stratafied
marg &lt;- phreg(Surv(time,status)~+strata(treat)+cluster(id),data=diabetes)
fitpa &lt;- survival.twostage(marg,data=diabetes,theta=1.0,
                clusters=diabetes$id,model="clayton.oakes")
summary(fitpa)

fitcoa &lt;- survival.twostage(marg,data=diabetes,theta=1.0,clusters=diabetes$id,
                 model="clayton.oakes")
summary(fitcoa)

### Piecewise constant cross hazards ratio modelling
########################################################

d &lt;- subset(simClaytonOakes(2000,2,0.5,0,stoptime=2,left=0),!truncated)
udp &lt;- piecewise.twostage(c(0,0.5,2),data=d,method="optimize",
                          id="cluster",timevar="time",
                          status="status",model="clayton.oakes",silent=0)
summary(udp)

 ## Reduce Ex.Timings
### Same model using the strata option, a bit slower
########################################################
## makes the survival pieces for different areas in the plane
##ud1=surv.boxarea(c(0,0),c(0.5,0.5),data=d,id="cluster",timevar="time",status="status")
##ud2=surv.boxarea(c(0,0.5),c(0.5,2),data=d,id="cluster",timevar="time",status="status")
##ud3=surv.boxarea(c(0.5,0),c(2,0.5),data=d,id="cluster",timevar="time",status="status")
##ud4=surv.boxarea(c(0.5,0.5),c(2,2),data=d,id="cluster",timevar="time",status="status")

## everything done in one call
ud &lt;- piecewise.data(c(0,0.5,2),data=d,timevar="time",status="status",id="cluster")
ud$strata &lt;- factor(ud$strata);
ud$intstrata &lt;- factor(ud$intstrata)

## makes strata specific id variable to identify pairs within strata
## se's computed based on the id variable across strata "cluster"
ud$idstrata &lt;- ud$id+(as.numeric(ud$strata)-1)*2000

marg2 &lt;- timereg::aalen(Surv(boxtime,status)~-1+factor(num):factor(intstrata),
               data=ud,n.sim=0,robust=0)
tdes &lt;- model.matrix(~-1+factor(strata),data=ud)
fitp2 &lt;- survival.twostage(marg2,data=ud,se.clusters=ud$cluster,clusters=ud$idstrata,
                model="clayton.oakes",theta.des=tdes,step=0.5)
summary(fitp2)

### now fitting the model with symmetry, i.e. strata 2 and 3 same effect
ud$stratas &lt;- ud$strata;
ud$stratas[ud$strata=="0.5-2,0-0.5"] &lt;- "0-0.5,0.5-2"
tdes2 &lt;- model.matrix(~-1+factor(stratas),data=ud)
fitp3 &lt;- survival.twostage(marg2,data=ud,clusters=ud$idstrata,se.cluster=ud$cluster,
                model="clayton.oakes",theta.des=tdes2,step=0.5)
summary(fitp3)

### same model using strata option, a bit slower
fitp4 &lt;- survival.twostage(marg2,data=ud,clusters=ud$cluster,se.cluster=ud$cluster,
                model="clayton.oakes",theta.des=tdes2,step=0.5,strata=ud$strata)
summary(fitp4)


 ## Reduce Ex.Timings
### structured random effects model additive gamma ACE
### simulate structured two-stage additive gamma ACE model
data &lt;- simClaytonOakes.twin.ace(4000,2,1,0,3)
out &lt;- twin.polygen.design(data,id="cluster")
pardes &lt;- out$pardes
pardes
des.rv &lt;- out$des.rv
head(des.rv)
aa &lt;- phreg(Surv(time,status)~x+cluster(cluster),data=data,robust=0)
ts &lt;- survival.twostage(aa,data=data,clusters=data$cluster,detail=0,
	       theta=c(2,1),var.link=0,step=0.5,
	       random.design=des.rv,theta.des=pardes)
summary(ts)


</code></pre>

<hr>
<h2 id='survivalG'>G-estimator for Cox and Fine-Gray model</h2><span id='topic+survivalG'></span><span id='topic+survivalGtime'></span>

<h3>Description</h3>

<p>Computes G-estimator </p>
<p style="text-align: center;"><code class="reqn"> \hat S(t,A=a) = n^{-1} \sum_i \hat S(t,A=a,Z_i) </code>
</p>

<p>for the Cox model based on phreg og the Fine-Gray model based on the
cifreg function. Gives influence functions of these risk estimates and SE's are 
based on  these.  If first covariate is a factor then all contrast are computed, 
and if continuous then considered covariate values are given by Avalues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survivalG(
  x,
  data,
  time = NULL,
  Avalues = c(0, 1),
  varname = NULL,
  same.data = TRUE,
  id = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="survivalG_+3A_x">x</code></td>
<td>
<p>phreg or cifreg object</p>
</td></tr>
<tr><td><code id="survivalG_+3A_data">data</code></td>
<td>
<p>data frame for risk averaging</p>
</td></tr>
<tr><td><code id="survivalG_+3A_time">time</code></td>
<td>
<p>for estimate</p>
</td></tr>
<tr><td><code id="survivalG_+3A_avalues">Avalues</code></td>
<td>
<p>values to compare for first covariate A</p>
</td></tr>
<tr><td><code id="survivalG_+3A_varname">varname</code></td>
<td>
<p>if given then averages for this variable, default is first variable</p>
</td></tr>
<tr><td><code id="survivalG_+3A_same.data">same.data</code></td>
<td>
<p>assumes that same data is used for fitting of survival model and averaging.</p>
</td></tr>
<tr><td><code id="survivalG_+3A_id">id</code></td>
<td>
<p>might be given to link to data to iid decomposition of survival data, must be coded as 1,2,..,</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(bmt); bmt$time &lt;- bmt$time+runif(408)*0.001
bmt$event &lt;- (bmt$cause!=0)*1
dfactor(bmt) &lt;- tcell.f~tcell

fg1 &lt;- cifreg(Event(time,cause)~tcell.f+platelet+age,bmt,cause=1,
              cox.prep=TRUE,propodds=NULL)
summary(survivalG(fg1,bmt,50))

ss &lt;- phreg(Surv(time,event)~tcell.f+platelet+age,bmt) 
summary(survivalG(ss,bmt,50))

sst &lt;- survivalGtime(ss,bmt,n=50)
plot(sst,type=c("survival","risk","survival.ratio")[1])
</code></pre>

<hr>
<h2 id='test.conc'>Concordance test Compares two concordance estimates</h2><span id='topic+test.conc'></span>

<h3>Description</h3>

<p>.. content for description (no empty lines) ..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.conc(conc1, conc2, same.cluster = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.conc_+3A_conc1">conc1</code></td>
<td>
<p>Concordance estimate of group 1</p>
</td></tr>
<tr><td><code id="test.conc_+3A_conc2">conc2</code></td>
<td>
<p>Concordance estimate of group 2</p>
</td></tr>
<tr><td><code id="test.conc_+3A_same.cluster">same.cluster</code></td>
<td>
<p>if FALSE then groups are independent, otherwise estimates are based on same data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

<hr>
<h2 id='tetrachoric'>Estimate parameters from odds-ratio</h2><span id='topic+tetrachoric'></span><span id='topic+or2prob'></span>

<h3>Description</h3>

<p>Calculate tetrachoric correlation of probabilities from odds-ratio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tetrachoric(P, OR, approx = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tetrachoric_+3A_p">P</code></td>
<td>
<p>Joint probabilities or marginals (if OR is given)</p>
</td></tr>
<tr><td><code id="tetrachoric_+3A_or">OR</code></td>
<td>
<p>Odds-ratio</p>
</td></tr>
<tr><td><code id="tetrachoric_+3A_approx">approx</code></td>
<td>
<p>If TRUE an approximation of the tetrachoric correlation is used</p>
</td></tr>
<tr><td><code id="tetrachoric_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>tetrachoric(0.3,1.25) # Marginal p1=p2=0.3, OR=2
P &lt;- matrix(c(0.1,0.2,0.2,0.5),2)
prod(diag(P))/prod(lava::revdiag(P))
##mets:::assoc(P)
tetrachoric(P)
or2prob(2,0.1)
or2prob(2,c(0.1,0.2))
</code></pre>

<hr>
<h2 id='TRACE'>The TRACE study group of myocardial infarction</h2><span id='topic+TRACE'></span><span id='topic+sTRACE'></span><span id='topic+tTRACE'></span>

<h3>Description</h3>

<p>The TRACE data frame contains 1877 patients and is a subset of a data set
consisting of approximately 6000 patients.  It contains data relating
survival of patients after myocardial infarction to various risk factors.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns: </p>

<dl>
<dt>id</dt><dd><p>a numeric vector. Patient code. </p>
</dd> <dt>status</dt><dd><p> a numeric vector
code. Survival status. 9: dead from myocardial infarction, 0: alive, 7: dead
from other causes.  </p>
</dd> <dt>time</dt><dd><p> a numeric vector. Survival time in years.
</p>
</dd> <dt>chf</dt><dd><p> a numeric vector code. Clinical heart pump failure, 1:
present, 0: absent. </p>
</dd> <dt>diabetes</dt><dd><p> a numeric vector code. Diabetes, 1:
present, 0: absent. </p>
</dd> <dt>vf</dt><dd><p> a numeric vector code. Ventricular
fibrillation, 1: present, 0: absent. </p>
</dd> <dt>wmi</dt><dd><p> a numeric vector.
Measure of heart pumping effect based on ultrasound measurements where 2 is
normal and 0 is worst. </p>
</dd> <dt>sex</dt><dd><p> a numeric vector code. 1: female, 0:
male. </p>
</dd> <dt>age</dt><dd><p> a numeric vector code. Age of patient. </p>
</dd> </dl>



<h3>Details</h3>

<p>sTRACE is a subsample consisting of 300 patients.
</p>
<p>tTRACE is a subsample consisting of 1000 patients.
</p>


<h3>Source</h3>

<p>The TRACE study group.
</p>
<p>Jensen, G.V., Torp-Pedersen, C., Hildebrandt, P., Kober, L., F. E. Nielsen,
Melchior, T., Joen, T. and P. K. Andersen (1997), Does in-hospital
ventricular fibrillation affect prognosis after myocardial infarction?,
European Heart Journal 18, 919&ndash;924.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(TRACE)
names(TRACE)

</code></pre>

<hr>
<h2 id='ttpd'>ttpd discrete survival data on interval form</h2><span id='topic+ttpd'></span>

<h3>Description</h3>

<p>ttpd discrete survival data on interval form
</p>


<h3>Source</h3>

<p>Simulated data
</p>

<hr>
<h2 id='twin.clustertrunc'>Estimation of twostage model with cluster truncation in bivariate situation</h2><span id='topic+twin.clustertrunc'></span>

<h3>Description</h3>

<p>Estimation of twostage model with cluster truncation in bivariate situation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twin.clustertrunc(
  survformula,
  data = parent.frame(),
  theta.des = NULL,
  clusters = NULL,
  var.link = 1,
  Nit = 10,
  final.fitting = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twin.clustertrunc_+3A_survformula">survformula</code></td>
<td>
<p>Formula with survival model aalen or cox.aalen, some limitiation on model specification due to call of fast.reshape (so for example interactions and * and : do not work here, expand prior to call)</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_data">data</code></td>
<td>
<p>Data frame</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_theta.des">theta.des</code></td>
<td>
<p>design for dependence parameters in two-stage model</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_clusters">clusters</code></td>
<td>
<p>clustering variable for twins</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_var.link">var.link</code></td>
<td>
<p>exp link for theta</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_nit">Nit</code></td>
<td>
<p>number of iteration</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_final.fitting">final.fitting</code></td>
<td>
<p>TRUE to do final estimation with SE and ... arguments for marginal models</p>
</td></tr>
<tr><td><code id="twin.clustertrunc_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("timereg")
data(diabetes)
v &lt;- diabetes$time*runif(nrow(diabetes))*rbinom(nrow(diabetes),1,0.5)
diabetes$v &lt;- v

aout &lt;- twin.clustertrunc(Surv(v,time,status)~1+treat+adult,
		 data=diabetes,clusters="id")
aout$two        ## twostage output
par(mfrow=c(2,2))
plot(aout$marg) ## marginal model output

out &lt;- twin.clustertrunc(Surv(v,time,status)~1+prop(treat)+prop(adult),
		 data=diabetes,clusters="id")
out$two        ## twostage output
plot(out$marg) ## marginal model output
</code></pre>

<hr>
<h2 id='twinbmi'>BMI data set</h2><span id='topic+twinbmi'></span>

<h3>Description</h3>

<p>BMI data set
</p>


<h3>Format</h3>

<p>Self-reported BMI-values on 11,411 subjects
</p>
<p>tvparnr: twin id
bmi: BMI (m/kg^2)
age: Age
gender: (male/female)
zyg: zygosity, MZ:=mz, DZ(same sex):=dz, DZ(opposite sex):=os
</p>

<hr>
<h2 id='twinlm'>Classic twin model for quantitative traits</h2><span id='topic+twinlm'></span><span id='topic+twinlm.strata'></span>

<h3>Description</h3>

<p>Fits a classical twin model for quantitative traits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twinlm(
  formula,
  data,
  id,
  zyg,
  DZ,
  group = NULL,
  group.equal = FALSE,
  strata = NULL,
  weights = NULL,
  type = c("ace"),
  twinnum = "twinnum",
  binary = FALSE,
  ordinal = 0,
  keep = weights,
  estimator = NULL,
  constrain = TRUE,
  control = list(),
  messages = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twinlm_+3A_formula">formula</code></td>
<td>
<p>Formula specifying effects of covariates on the response</p>
</td></tr>
<tr><td><code id="twinlm_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with one observation pr row. In
addition a column with the zygosity (DZ or MZ given as a factor) of
each individual much be
specified as well as a twin id variable giving a unique pair of
numbers/factors to each twin pair</p>
</td></tr>
<tr><td><code id="twinlm_+3A_id">id</code></td>
<td>
<p>The name of the column in the dataset containing the twin-id variable.</p>
</td></tr>
<tr><td><code id="twinlm_+3A_zyg">zyg</code></td>
<td>
<p>The name of the column in the dataset containing the
zygosity variable</p>
</td></tr>
<tr><td><code id="twinlm_+3A_dz">DZ</code></td>
<td>
<p>Character defining the level in the zyg variable
corresponding to the dyzogitic twins. If this argument is missing,
the reference level (i.e. the first level) will be interpreted as
the dyzogitic twins</p>
</td></tr>
<tr><td><code id="twinlm_+3A_group">group</code></td>
<td>
<p>Optional. Variable name defining group for interaction analysis (e.g., gender)</p>
</td></tr>
<tr><td><code id="twinlm_+3A_group.equal">group.equal</code></td>
<td>
<p>If TRUE marginals of groups are asummed to be the same</p>
</td></tr>
<tr><td><code id="twinlm_+3A_strata">strata</code></td>
<td>
<p>Strata variable name</p>
</td></tr>
<tr><td><code id="twinlm_+3A_weights">weights</code></td>
<td>
<p>Weights matrix if needed by the chosen estimator. For use
with Inverse Probability Weights</p>
</td></tr>
<tr><td><code id="twinlm_+3A_type">type</code></td>
<td>
<p>Character defining the type of analysis to be
performed. Can be a subset of &quot;aced&quot; (additive genetic factors, common
environmental factors, unique environmental factors, dominant
genetic factors). Other choices are:
</p>

<ul>
<li> <p>&quot;0&quot; (or &quot;sat&quot;): Saturated model where twin 1 and twin 2 within each twin
pair may have a different marginal distribution.
</p>
</li>
<li> <p>&quot;1&quot; (or &quot;flex&quot;,&quot;zyg&quot;): Within twin pairs the marginal distribution is
the same, but the marginal distribution may differ between MZ and DZ
twins. A free correlation structure within MZ and DZ twins. 
</p>
</li>
<li> <p>&quot;2&quot; (or &quot;u&quot;, &quot;eqmarg&quot;): All individuals have the same marginals
but a free correlation structure within MZ and DZ twins.
</p>
</li></ul>

<p>The default value is an additive polygenic model <code>type="ace"</code>.</p>
</td></tr>
<tr><td><code id="twinlm_+3A_twinnum">twinnum</code></td>
<td>
<p>The name of the column in the dataset numbering the
twins (1,2). If it does not exist in <code>data</code> it will
automatically be created.</p>
</td></tr>
<tr><td><code id="twinlm_+3A_binary">binary</code></td>
<td>
<p>If <code>TRUE</code> a liability model is fitted. Note that if the right-hand-side of the formula is a factor, character vector, og logical variable, then the liability model is automatically chosen (wrapper of the <code>bptwin</code> function).</p>
</td></tr>
<tr><td><code id="twinlm_+3A_ordinal">ordinal</code></td>
<td>
<p>If non-zero (number of bins) a liability model is fitted.</p>
</td></tr>
<tr><td><code id="twinlm_+3A_keep">keep</code></td>
<td>
<p>Vector of variables from <code>data</code> that are not
specified in <code>formula</code>, to be added to data.frame of the SEM</p>
</td></tr>
<tr><td><code id="twinlm_+3A_estimator">estimator</code></td>
<td>
<p>Choice of estimator/model</p>
</td></tr>
<tr><td><code id="twinlm_+3A_constrain">constrain</code></td>
<td>
<p>Development argument</p>
</td></tr>
<tr><td><code id="twinlm_+3A_control">control</code></td>
<td>
<p>Control argument parsed on to the optimization routine</p>
</td></tr>
<tr><td><code id="twinlm_+3A_messages">messages</code></td>
<td>
<p>Control amount of messages shown</p>
</td></tr>
<tr><td><code id="twinlm_+3A_...">...</code></td>
<td>
<p>Additional arguments parsed on to lower-level functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>twinlm</code>.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bptwin">bptwin</a></code>, <code><a href="#topic+twinlm.time">twinlm.time</a></code>, <code><a href="#topic+twinlm.strata">twinlm.strata</a></code>, <code><a href="#topic+twinsim">twinsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate data
set.seed(1)
d &lt;- twinsim(1000,b1=c(1,-1),b2=c(),acde=c(1,1,0,1))
## E(y|z1,z2) = z1 - z2. var(A) = var(C) = var(E) = 1

## E.g to fit the data to an ACE-model without any confounders we simply write
ace &lt;- twinlm(y ~ 1, data=d, DZ="DZ", zyg="zyg", id="id")
ace
## An AE-model could be fitted as
ae &lt;- twinlm(y ~ 1, data=d, DZ="DZ", zyg="zyg", id="id", type="ae")
## LRT:
lava::compare(ae,ace)
## AIC
AIC(ae)-AIC(ace)
## To adjust for the covariates we simply alter the formula statement
ace2 &lt;- twinlm(y ~ x1+x2, data=d, DZ="DZ", zyg="zyg", id="id", type="ace")
## Summary/GOF
summary(ace2)
 ## Reduce Ex.Timings
## An interaction could be analyzed as:
ace3 &lt;- twinlm(y ~ x1+x2 + x1:I(x2&lt;0), data=d, DZ="DZ", zyg="zyg", id="id", type="ace")
ace3
## Categorical variables are also supported 
d2 &lt;- transform(d,x2cat=cut(x2,3,labels=c("Low","Med","High")))
ace4 &lt;- twinlm(y ~ x1+x2cat, data=d2, DZ="DZ", zyg="zyg", id="id", type="ace")

</code></pre>

<hr>
<h2 id='twinsim'>Simulate twin data</h2><span id='topic+twinsim'></span>

<h3>Description</h3>

<p>Simulate twin data from a linear normal ACE/ADE/AE model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twinsim(
  nMZ = 100,
  nDZ = nMZ,
  b1 = c(),
  b2 = c(),
  mu = 0,
  acde = c(1, 1, 0, 1),
  randomslope = NULL,
  threshold = 0,
  cens = FALSE,
  wide = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twinsim_+3A_nmz">nMZ</code></td>
<td>
<p>Number of monozygotic twin pairs</p>
</td></tr>
<tr><td><code id="twinsim_+3A_ndz">nDZ</code></td>
<td>
<p>Number of dizygotic twin pairs</p>
</td></tr>
<tr><td><code id="twinsim_+3A_b1">b1</code></td>
<td>
<p>Effect of covariates (labelled x1,x2,...) of type 1. One
distinct covariate value for each twin/individual.</p>
</td></tr>
<tr><td><code id="twinsim_+3A_b2">b2</code></td>
<td>
<p>Effect of covariates (labelled g1,g2,...) of type 2. One
covariate value for each twin pair.</p>
</td></tr>
<tr><td><code id="twinsim_+3A_mu">mu</code></td>
<td>
<p>Intercept parameter.</p>
</td></tr>
<tr><td><code id="twinsim_+3A_acde">acde</code></td>
<td>
<p>Variance of random effects (in the order A,C,D,E)</p>
</td></tr>
<tr><td><code id="twinsim_+3A_randomslope">randomslope</code></td>
<td>
<p>Logical indicating wether to include random slopes of
the variance components w.r.t. x1,x2,...</p>
</td></tr>
<tr><td><code id="twinsim_+3A_threshold">threshold</code></td>
<td>
<p>Treshold used to define binary outcome y0</p>
</td></tr>
<tr><td><code id="twinsim_+3A_cens">cens</code></td>
<td>
<p>Logical variable indicating whether to censor outcome</p>
</td></tr>
<tr><td><code id="twinsim_+3A_wide">wide</code></td>
<td>
<p>Logical indicating if wide data format should be returned</p>
</td></tr>
<tr><td><code id="twinsim_+3A_...">...</code></td>
<td>
<p>Additional arguments parsed on to lower-level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>See Also</h3>

<p><code><a href="#topic+twinlm">twinlm</a></code>
</p>

<hr>
<h2 id='twinstut'>Stutter data set</h2><span id='topic+twinstut'></span>

<h3>Description</h3>

<p>Based on nation-wide questionnaire answers from 33,317 Danish twins
</p>


<h3>Format</h3>

<p>tvparnr: twin-pair id
zyg: zygosity, MZ:=mz, DZ(same sex):=dz, DZ(opposite sex):=os
stutter: stutter status (yes/no)
age: age
nr: number within twin-pair
</p>

<hr>
<h2 id='twostageMLE'>Twostage survival model fitted by pseudo MLE</h2><span id='topic+twostageMLE'></span>

<h3>Description</h3>

<p>Fits Clayton-Oakes clustered  survival data
using marginals that are on Cox form in the likelihood for the dependence parameter
as in Glidden (2000). The dependence can be modelled via  a
</p>

<ol>
<li><p>  Regression design on dependence parameter.
</p>
</li></ol>

<p>We allow a regression structure for the indenpendent gamma distributed
random effects  and their variances that may depend on cluster covariates. So
</p>
<p style="text-align: center;"><code class="reqn">
 \theta = h( z_j^T \alpha)
</code>
</p>

<p>where <code class="reqn">z</code> is specified by theta.des . The link function can be the exp when var.link=1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twostageMLE(
  margsurv,
  data = parent.frame(),
  theta = NULL,
  theta.des = NULL,
  var.link = 0,
  method = "NR",
  no.opt = FALSE,
  weights = NULL,
  se.cluster = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twostageMLE_+3A_margsurv">margsurv</code></td>
<td>
<p>Marginal model from phreg</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_theta">theta</code></td>
<td>
<p>Starting values for variance components</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_theta.des">theta.des</code></td>
<td>
<p>design for dependence parameters, when pairs are given this is could be a
(pairs) x (numer of parameters)  x (max number random effects) matrix</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_var.link">var.link</code></td>
<td>
<p>Link function for variance  if 1 then uses exp link</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_method">method</code></td>
<td>
<p>type of opitmizer, default is Newton-Raphson &quot;NR&quot;</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_no.opt">no.opt</code></td>
<td>
<p>to not optimize, for example to get score and iid for specific theta</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_weights">weights</code></td>
<td>
<p>cluster specific weights, but given with length equivalent to data-set, weights for score equations</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_se.cluster">se.cluster</code></td>
<td>
<p>specifies how the influence functions are summed before squared when computing the variance. Note that the id from the marginal model is used to construct MLE, and then these scores can be summed with the se.cluster argument.</p>
</td></tr>
<tr><td><code id="twostageMLE_+3A_...">...</code></td>
<td>
<p>arguments to be passed to  optimizer</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>


<h3>References</h3>

<p>Measuring early or late dependence for bivariate twin data
Scheike, Holst, Hjelmborg (2015), LIDA
</p>
<p>Twostage modelling of additive gamma frailty models for survival data.
Scheike and Holst, working paper
</p>
<p>Shih and Louis (1995) Inference on the association parameter in copula models for bivariate
survival data, Biometrics, (1995).
</p>
<p>Glidden (2000), A Two-Stage estimator of the dependence
parameter for the Clayton Oakes model, LIDA, (2000).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diabetes)
dd &lt;- phreg(Surv(time,status==1)~treat+cluster(id),diabetes)
oo &lt;- twostageMLE(dd,data=diabetes)
summary(oo)

theta.des &lt;- model.matrix(~-1+factor(adult),diabetes)

oo &lt;-twostageMLE(dd,data=diabetes,theta.des=theta.des)
summary(oo)
</code></pre>

<hr>
<h2 id='WA_recurrent'>While-Alive estimands for recurrent events</h2><span id='topic+WA_recurrent'></span>

<h3>Description</h3>

<p>Considers the ratio of means </p>
<p style="text-align: center;"><code class="reqn">E(N(min(D,t)))/E(min(D,t))</code>
</p>
<p> and the
the mean of the events per time unit </p>
<p style="text-align: center;"><code class="reqn">E(N(min(D,t))/min(D,t))</code>
</p>
<p> both based on
IPCW etimation. RMST estimator equivalent to Kaplan-Meier based estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WA_recurrent(
  formula,
  data,
  time = NULL,
  cens.code = 0,
  cause = 1,
  death.code = 2,
  trans = NULL,
  cens.formula = NULL,
  augmentR = NULL,
  augmentC = NULL,
  type = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WA_recurrent_+3A_formula">formula</code></td>
<td>
<p>Event formula first covariate on rhs must be a factor giving the treatment</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_time">time</code></td>
<td>
<p>for estimation</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_cens.code">cens.code</code></td>
<td>
<p>of censorings</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_cause">cause</code></td>
<td>
<p>of events</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_death.code">death.code</code></td>
<td>
<p>of terminal events</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_trans">trans</code></td>
<td>
<p>possible power for mean of events per time-unit</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_cens.formula">cens.formula</code></td>
<td>
<p>censoring model, default is to use strata(treatment)</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_augmentr">augmentR</code></td>
<td>
<p>covariates for model of mean ratio</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_augmentc">augmentC</code></td>
<td>
<p>covariates for censoring augmentation</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_type">type</code></td>
<td>
<p>augmentation for call of binreg, when augmentC is given default is &quot;I&quot; and otherwise &quot;II&quot;</p>
</td></tr>
<tr><td><code id="WA_recurrent_+3A_...">...</code></td>
<td>
<p>arguments for binregATE</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Scheike
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
