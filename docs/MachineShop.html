<!DOCTYPE html><html lang="en"><head><title>Help for package MachineShop</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MachineShop}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MachineShop-package'><p>MachineShop: Machine Learning Models and Tools</p></a></li>
<li><a href='#AdaBagModel'><p>Bagging with Classification Trees</p></a></li>
<li><a href='#AdaBoostModel'><p>Boosting with Classification Trees</p></a></li>
<li><a href='#as.data.frame'><p>Coerce to a Data Frame</p></a></li>
<li><a href='#as.MLInput'><p>Coerce to an MLInput</p></a></li>
<li><a href='#as.MLModel'><p>Coerce to an MLModel</p></a></li>
<li><a href='#BARTMachineModel'><p>Bayesian Additive Regression Trees Model</p></a></li>
<li><a href='#BARTModel'><p>Bayesian Additive Regression Trees Model</p></a></li>
<li><a href='#BlackBoostModel'><p>Gradient Boosting with Regression Trees</p></a></li>
<li><a href='#C50Model'><p>C5.0 Decision Trees and Rule-Based Model</p></a></li>
<li><a href='#calibration'><p>Model Calibration</p></a></li>
<li><a href='#case_weights'><p>Extract Case Weights</p></a></li>
<li><a href='#CForestModel'><p>Conditional Random Forest Model</p></a></li>
<li><a href='#combine'><p>Combine MachineShop Objects</p></a></li>
<li><a href='#confusion'><p>Confusion Matrix</p></a></li>
<li><a href='#CoxModel'><p>Proportional Hazards Regression Model</p></a></li>
<li><a href='#dependence'><p>Partial Dependence</p></a></li>
<li><a href='#diff'><p>Model Performance Differences</p></a></li>
<li><a href='#DiscreteVariate'><p>Discrete Variate Constructors</p></a></li>
<li><a href='#EarthModel'><p>Multivariate Adaptive Regression Splines Model</p></a></li>
<li><a href='#expand_model'><p>Model Expansion Over Tuning Parameters</p></a></li>
<li><a href='#expand_modelgrid'><p>Model Tuning Grid Expansion</p></a></li>
<li><a href='#expand_params'><p>Model Parameters Expansion</p></a></li>
<li><a href='#expand_steps'><p>Recipe Step Parameters Expansion</p></a></li>
<li><a href='#extract'><p>Extract Elements of an Object</p></a></li>
<li><a href='#FDAModel'><p>Flexible and Penalized Discriminant Analysis Models</p></a></li>
<li><a href='#fit'><p>Model Fitting</p></a></li>
<li><a href='#GAMBoostModel'><p>Gradient Boosting with Additive Models</p></a></li>
<li><a href='#GBMModel'><p>Generalized Boosted Regression Model</p></a></li>
<li><a href='#GLMBoostModel'><p>Gradient Boosting with Linear Models</p></a></li>
<li><a href='#GLMModel'><p>Generalized Linear Model</p></a></li>
<li><a href='#GLMNetModel'><p>GLM Lasso or Elasticnet Model</p></a></li>
<li><a href='#ICHomes'><p>Iowa City Home Sales Dataset</p></a></li>
<li><a href='#inputs'><p>Model Inputs</p></a></li>
<li><a href='#KNNModel'><p>Weighted k-Nearest Neighbor Model</p></a></li>
<li><a href='#LARSModel'><p>Least Angle Regression, Lasso and Infinitesimal Forward Stagewise Models</p></a></li>
<li><a href='#LDAModel'><p>Linear Discriminant Analysis Model</p></a></li>
<li><a href='#lift'><p>Model Lift Curves</p></a></li>
<li><a href='#LMModel'><p>Linear Models</p></a></li>
<li><a href='#MDAModel'><p>Mixture Discriminant Analysis Model</p></a></li>
<li><a href='#metricinfo'><p>Display Performance Metric Information</p></a></li>
<li><a href='#metrics'><p>Performance Metrics</p></a></li>
<li><a href='#MLControl'><p>Resampling Controls</p></a></li>
<li><a href='#MLMetric'><p>MLMetric Class Constructor</p></a></li>
<li><a href='#MLModel'><p>MLModel and MLModelFunction Class Constructors</p></a></li>
<li><a href='#ModelFrame'><p>ModelFrame Class</p></a></li>
<li><a href='#modelinfo'><p>Display Model Information</p></a></li>
<li><a href='#models'><p>Models</p></a></li>
<li><a href='#ModelSpecification'><p>Model Specification</p></a></li>
<li><a href='#NaiveBayesModel'><p>Naive Bayes Classifier Model</p></a></li>
<li><a href='#NNetModel'><p>Neural Network Model</p></a></li>
<li><a href='#ParameterGrid'><p>Tuning Parameters Grid</p></a></li>
<li><a href='#ParsnipModel'><p>Parsnip Model</p></a></li>
<li><a href='#performance'><p>Model Performance Metrics</p></a></li>
<li><a href='#performance_curve'><p>Model Performance Curves</p></a></li>
<li><a href='#plot'><p>Model Performance Plots</p></a></li>
<li><a href='#PLSModel'><p>Partial Least Squares Model</p></a></li>
<li><a href='#POLRModel'><p>Ordered Logistic or Probit Regression Model</p></a></li>
<li><a href='#predict'><p>Model Prediction</p></a></li>
<li><a href='#print'><p>Print MachineShop Objects</p></a></li>
<li><a href='#QDAModel'><p>Quadratic Discriminant Analysis Model</p></a></li>
<li><a href='#quote'><p>Quote Operator</p></a></li>
<li><a href='#RandomForestModel'><p>Random Forest Model</p></a></li>
<li><a href='#RangerModel'><p>Fast Random Forest Model</p></a></li>
<li><a href='#recipe_roles'><p>Set Recipe Roles</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#resample'><p>Resample Estimation of Model Performance</p></a></li>
<li><a href='#response'><p>Extract Response Variable</p></a></li>
<li><a href='#rfe'><p>Recursive Feature Elimination</p></a></li>
<li><a href='#RFSRCModel'><p>Fast Random Forest (SRC) Model</p></a></li>
<li><a href='#RPartModel'><p>Recursive Partitioning and Regression Tree Models</p></a></li>
<li><a href='#SelectedInput'><p>Selected Model Inputs</p></a></li>
<li><a href='#SelectedModel'><p>Selected Model</p></a></li>
<li><a href='#set_monitor'><p>Training Parameters Monitoring Control</p></a></li>
<li><a href='#set_optim'><p>Tuning Parameter Optimization</p></a></li>
<li><a href='#set_predict'><p>Resampling Prediction Control</p></a></li>
<li><a href='#set_strata'><p>Resampling Stratification Control</p></a></li>
<li><a href='#settings'><p>MachineShop Settings</p></a></li>
<li><a href='#StackedModel'><p>Stacked Regression Model</p></a></li>
<li><a href='#step_kmeans'><p>K-Means Clustering Variable Reduction</p></a></li>
<li><a href='#step_kmedoids'><p>K-Medoids Clustering Variable Selection</p></a></li>
<li><a href='#step_lincomp'><p>Linear Components Variable Reduction</p></a></li>
<li><a href='#step_sbf'><p>Variable Selection by Filtering</p></a></li>
<li><a href='#step_spca'><p>Sparse Principal Components Analysis Variable Reduction</p></a></li>
<li><a href='#summary'><p>Model Performance Summaries</p></a></li>
<li><a href='#SuperModel'><p>Super Learner Model</p></a></li>
<li><a href='#SurvMatrix'><p>SurvMatrix Class Constructors</p></a></li>
<li><a href='#SurvRegModel'><p>Parametric Survival Model</p></a></li>
<li><a href='#SVMModel'><p>Support Vector Machine Models</p></a></li>
<li><a href='#t.test'><p>Paired t-Tests for Model Comparisons</p></a></li>
<li><a href='#TreeModel'><p>Classification and Regression Tree Models</p></a></li>
<li><a href='#TunedInput'><p>Tuned Model Inputs</p></a></li>
<li><a href='#TunedModel'><p>Tuned Model</p></a></li>
<li><a href='#TuningGrid'><p>Tuning Grid Control</p></a></li>
<li><a href='#unMLModelFit'><p>Revert an MLModelFit Object</p></a></li>
<li><a href='#varimp'><p>Variable Importance</p></a></li>
<li><a href='#XGBModel'><p>Extreme Gradient Boosting Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Machine Learning Models and Tools</td>
</tr>
<tr>
<td>Version:</td>
<td>3.8.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-08-19</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian J Smith [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian J Smith &lt;brian-j-smith@uiowa.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Meta-package for statistical and machine learning with a unified
    interface for model fitting, prediction, performance assessment, and
    presentation of results.  Approaches for model fitting and prediction of
    numerical, categorical, or censored time-to-event outcomes include
    traditional regression models, regularization methods, tree-based methods,
    support vector machines, neural networks, ensembles, data preprocessing,
    filtering, and model tuning and selection.  Performance metrics are provided
    for model assessment and can be estimated with independent test sets, split
    sampling, cross-validation, or bootstrap resampling.  Resample estimation
    can be executed in parallel for faster processing and nested in cases of
    model tuning and selection.  Modeling results can be summarized with
    descriptive statistics; calibration curves; variable importance; partial
    dependence plots; confusion matrices; and ROC, lift, and other performance
    curves.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, cli (&ge; 3.1.0), dials (&ge; 0.0.4), foreach, ggplot2 (&ge;
3.4.0), kernlab, magrittr, Matrix (&ge; 1.5-0), methods, nnet,
party, polspline, progress, recipes (&ge; 1.0.0), rlang, rsample
(&ge; 1.1.0), Rsolnp, survival, tibble, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>adabag, BART, bartMachine, C50, censored, cluster,
doParallel, e1071, earth, elasticnet, generics, gbm, glmnet,
gridExtra, Hmisc, kableExtra, kknn, knitr, lars, MASS, mboost,
mda, ParBayesianOptimization, parsnip (&ge; 1.1.0), partykit,
pls, pso, randomForest, randomForestSRC, ranger,
rBayesianOptimization, rmarkdown, rms, rpart, testthat, tree,
xgboost</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://brian-j-smith.github.io/MachineShop/">https://brian-j-smith.github.io/MachineShop/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/brian-j-smith/MachineShop/issues">https://github.com/brian-j-smith/MachineShop/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Collate:</td>
<td>'classes.R' 'conditions.R' 'MachineShop-package.R'
'MLControl.R' 'MLInput.R' 'MLMetric.R' 'MLModel.R'
'MLOptimization.R' 'ML_AdaBagModel.R' 'ML_AdaBoostModel.R'
'ML_BARTMachineModel.R' 'ML_BARTModel.R' 'ML_BlackBoostModel.R'
'ML_C50Model.R' 'ML_CForestModel.R' 'ML_CoxModel.R'
'ML_EarthModel.R' 'ML_FDAModel.R' 'ML_GAMBoostModel.R'
'ML_GBMModel.R' 'ML_GLMBoostModel.R' 'ML_GLMModel.R'
'ML_GLMNetModel.R' 'ML_KNNModel.R' 'ML_LARSModel.R'
'ML_LDAModel.R' 'ML_LMModel.R' 'ML_MDAModel.R' 'ML_NNetModel.R'
'ML_NaiveBayesModel.R' 'ML_ParsnipModel.R' 'ML_PLSModel.R'
'ML_POLRModel.R' 'ML_QDAModel.R' 'ML_RFSRCModel.R'
'ML_RPartModel.R' 'ML_RandomForestModel.R' 'ML_RangerModel.R'
'ML_SVMModel.R' 'ML_StackedModel.R' 'ML_SuperModel.R'
'ML_SurvRegModel.R' 'ML_TreeModel.R' 'ML_XGBModel.R'
'ModelFrame.R' 'ModelRecipe.R' 'ModelSpecification.R'
'TrainedInputs.R' 'TrainedModels.R' 'TrainingParams.R'
'append.R' 'calibration.R' 'case_comps.R' 'coerce.R'
'combine.R' 'confusion.R' 'convert.R' 'data.R' 'dependence.R'
'diff.R' 'expand.R' 'extract.R' 'fit.R' 'grid.R' 'metricinfo.R'
'metrics.R' 'metrics_factor.R' 'metrics_numeric.R'
'modelinfo.R' 'models.R' 'performance.R' 'performance_curve.R'
'plot.R' 'predict.R' 'print.R' 'recipe_roles.R' 'reexports.R'
'resample.R' 'response.R' 'rfe.R' 'settings.R' 'step_kmeans.R'
'step_kmedoids.R' 'step_lincomp.R' 'step_sbf.R' 'step_spca.R'
'summary.R' 'survival.R' 'utils.R' 'varimp.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-19 16:31:32 UTC; bjsmith</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-19 17:40:16 UTC</td>
</tr>
</table>
<hr>
<h2 id='MachineShop-package'>MachineShop: Machine Learning Models and Tools</h2><span id='topic+MachineShop'></span><span id='topic+MachineShop-package'></span>

<h3>Description</h3>

<p>Meta-package for statistical and machine learning with a unified interface for model fitting, prediction, performance assessment, and presentation of results. Approaches for model fitting and prediction of numerical, categorical, or censored time-to-event outcomes include traditional regression models, regularization methods, tree-based methods, support vector machines, neural networks, ensembles, data preprocessing, filtering, and model tuning and selection. Performance metrics are provided for model assessment and can be estimated with independent test sets, split sampling, cross-validation, or bootstrap resampling. Resample estimation can be executed in parallel for faster processing and nested in cases of model tuning and selection. Modeling results can be summarized with descriptive statistics; calibration curves; variable importance; partial dependence plots; confusion matrices; and ROC, lift, and other performance curves.
</p>


<h3>Details</h3>

<p>The following set of model fitting, prediction, and performance assessment
functions are available for <span class="pkg">MachineShop</span> <a href="#topic+models">models</a>.
</p>
<p>Training:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+fit">fit</a></code> </td><td style="text-align: left;"> Model fitting </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+resample">resample</a></code> </td><td style="text-align: left;"> Resample estimation of model performance </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Tuning Grids:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+expand_model">expand_model</a></code> </td><td style="text-align: left;"> Model expansion over tuning parameters </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+expand_modelgrid">expand_modelgrid</a></code> </td><td style="text-align: left;"> Model tuning grid expansion </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+expand_params">expand_params</a></code> </td><td style="text-align: left;"> Model parameters expansion </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+expand_steps">expand_steps</a></code> </td><td style="text-align: left;"> Recipe step parameters expansion </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Response Values:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+response">response</a></code> </td><td style="text-align: left;"> Observed </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+predict">predict</a></code> </td><td style="text-align: left;"> Predicted </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Performance Assessment:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+calibration">calibration</a></code> </td><td style="text-align: left;"> Model calibration </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+confusion">confusion</a></code> </td><td style="text-align: left;"> Confusion matrix </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+dependence">dependence</a></code> </td><td style="text-align: left;"> Parital dependence </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+diff">diff</a></code> </td><td style="text-align: left;"> Model performance differences </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+lift">lift</a></code> </td><td style="text-align: left;"> Lift curves </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+performance">performance</a> <a href="#topic+metrics">metrics</a></code> </td><td style="text-align: left;"> Model performance metrics </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+performance_curve">performance_curve</a></code> </td><td style="text-align: left;"> Model performance curves </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+rfe">rfe</a></code> </td><td style="text-align: left;"> Recursive feature elimination </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+varimp">varimp</a></code> </td><td style="text-align: left;"> Variable importance </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Methods for resample estimation include
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BootControl">BootControl</a></code> </td><td style="text-align: left;"> Simple bootstrap </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BootOptimismControl">BootOptimismControl</a></code> </td><td style="text-align: left;"> Optimism-corrected bootstrap </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+CVControl">CVControl</a></code> </td><td style="text-align: left;"> Repeated K-fold cross-validation </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+CVOptimismControl">CVOptimismControl</a></code> </td><td style="text-align: left;"> Optimism-corrected cross-validation </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+OOBControl">OOBControl</a></code> </td><td style="text-align: left;"> Out-of-bootstrap </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SplitControl">SplitControl</a></code> </td><td style="text-align: left;"> Split training-testing </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+TrainControl">TrainControl</a></code> </td><td style="text-align: left;"> Training resubstitution </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Graphical and tabular summaries of modeling results can be obtained with
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+plot">plot</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+print">print</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+summary">summary</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Further information on package features is available with
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+metricinfo">metricinfo</a></code> </td><td style="text-align: left;"> Performance metric information </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+modelinfo">modelinfo</a></code> </td><td style="text-align: left;"> Model information </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+settings">settings</a></code> </td><td style="text-align: left;"> Global settings </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Custom metrics and models can be created with the <code><a href="#topic+MLMetric">MLMetric</a></code> and
<code><a href="#topic+MLModel">MLModel</a></code> constructors.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Brian J Smith <a href="mailto:brian-j-smith@uiowa.edu">brian-j-smith@uiowa.edu</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://brian-j-smith.github.io/MachineShop/">https://brian-j-smith.github.io/MachineShop/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/brian-j-smith/MachineShop/issues">https://github.com/brian-j-smith/MachineShop/issues</a>
</p>
</li></ul>


<hr>
<h2 id='AdaBagModel'>Bagging with Classification Trees</h2><span id='topic+AdaBagModel'></span>

<h3>Description</h3>

<p>Fits the Bagging algorithm proposed by Breiman in 1996 using classification
trees as single classifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaBagModel(
  mfinal = 100,
  minsplit = 20,
  minbucket = round(minsplit/3),
  cp = 0.01,
  maxcompete = 4,
  maxsurrogate = 5,
  usesurrogate = 2,
  xval = 10,
  surrogatestyle = 0,
  maxdepth = 30
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AdaBagModel_+3A_mfinal">mfinal</code></td>
<td>
<p>number of trees to use.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_minsplit">minsplit</code></td>
<td>
<p>minimum number of observations that must exist in a node in
order for a split to be attempted.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_minbucket">minbucket</code></td>
<td>
<p>minimum number of observations in any terminal node.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_cp">cp</code></td>
<td>
<p>complexity parameter.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_maxcompete">maxcompete</code></td>
<td>
<p>number of competitor splits retained in the output.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_maxsurrogate">maxsurrogate</code></td>
<td>
<p>number of surrogate splits retained in the output.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_usesurrogate">usesurrogate</code></td>
<td>
<p>how to use surrogates in the splitting process.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_xval">xval</code></td>
<td>
<p>number of cross-validations.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_surrogatestyle">surrogatestyle</code></td>
<td>
<p>controls the selection of a best surrogate.</p>
</td></tr>
<tr><td><code id="AdaBagModel_+3A_maxdepth">maxdepth</code></td>
<td>
<p>maximum depth of any node of the final tree, with the root
node counted as depth 0.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>mfinal</code>, <code>maxdepth</code>
</p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="adabag.html#topic+bagging">bagging</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package adabag to run

fit(Species ~ ., data = iris, model = AdaBagModel(mfinal = 5))


</code></pre>

<hr>
<h2 id='AdaBoostModel'>Boosting with Classification Trees</h2><span id='topic+AdaBoostModel'></span>

<h3>Description</h3>

<p>Fits the AdaBoost.M1 (Freund and Schapire, 1996) and SAMME (Zhu et al., 2009)
algorithms using classification trees as single classifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaBoostModel(
  boos = TRUE,
  mfinal = 100,
  coeflearn = c("Breiman", "Freund", "Zhu"),
  minsplit = 20,
  minbucket = round(minsplit/3),
  cp = 0.01,
  maxcompete = 4,
  maxsurrogate = 5,
  usesurrogate = 2,
  xval = 10,
  surrogatestyle = 0,
  maxdepth = 30
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AdaBoostModel_+3A_boos">boos</code></td>
<td>
<p>if <code>TRUE</code>, then bootstrap samples are drawn from the
training set using the observation weights at each iteration.  If
<code>FALSE</code>, then all observations are used with their weights.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_mfinal">mfinal</code></td>
<td>
<p>number of iterations for which boosting is run.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_coeflearn">coeflearn</code></td>
<td>
<p>learning algorithm.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_minsplit">minsplit</code></td>
<td>
<p>minimum number of observations that must exist in a node in
order for a split to be attempted.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_minbucket">minbucket</code></td>
<td>
<p>minimum number of observations in any terminal node.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_cp">cp</code></td>
<td>
<p>complexity parameter.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_maxcompete">maxcompete</code></td>
<td>
<p>number of competitor splits retained in the output.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_maxsurrogate">maxsurrogate</code></td>
<td>
<p>number of surrogate splits retained in the output.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_usesurrogate">usesurrogate</code></td>
<td>
<p>how to use surrogates in the splitting process.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_xval">xval</code></td>
<td>
<p>number of cross-validations.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_surrogatestyle">surrogatestyle</code></td>
<td>
<p>controls the selection of a best surrogate.</p>
</td></tr>
<tr><td><code id="AdaBoostModel_+3A_maxdepth">maxdepth</code></td>
<td>
<p>maximum depth of any node of the final tree, with the root
node counted as depth 0.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>mfinal</code>, <code>maxdepth</code>, <code>coeflearn</code>*
</p>
</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="adabag.html#topic+boosting">boosting</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package adabag to run

fit(Species ~ ., data = iris, model = AdaBoostModel(mfinal = 5))


</code></pre>

<hr>
<h2 id='as.data.frame'>Coerce to a Data Frame</h2><span id='topic+as.data.frame'></span><span id='topic+as.data.frame.ModelFrame'></span><span id='topic+as.data.frame.Resample'></span><span id='topic+as.data.frame.TabularArray'></span>

<h3>Description</h3>

<p>Functions to coerce objects to data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ModelFrame'
as.data.frame(x, ...)

## S3 method for class 'Resample'
as.data.frame(x, ...)

## S3 method for class 'TabularArray'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.data.frame_+3A_x">x</code></td>
<td>
<p><code><a href="#topic+ModelFrame">ModelFrame</a></code>, <a href="#topic+resample">resample</a> results, resampled
<a href="#topic+performance">performance</a> estimates, model performance <a href="#topic+diff">differences</a>,
or <a href="#topic+t.test">t-test</a> comparisons of the differences.</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code> class object.
</p>

<hr>
<h2 id='as.MLInput'>Coerce to an MLInput</h2><span id='topic+as.MLInput'></span><span id='topic+as.MLInput.MLModelFit'></span><span id='topic+as.MLInput.ModelSpecification'></span>

<h3>Description</h3>

<p>Function to coerce an object to <code>MLInput</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.MLInput(x, ...)

## S3 method for class 'MLModelFit'
as.MLInput(x, ...)

## S3 method for class 'ModelSpecification'
as.MLInput(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.MLInput_+3A_x">x</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result or <span class="pkg">MachineShop</span>
<a href="#topic+ModelSpecification">model specification</a>.</p>
</td></tr>
<tr><td><code id="as.MLInput_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>MLInput</code> class object.
</p>

<hr>
<h2 id='as.MLModel'>Coerce to an MLModel</h2><span id='topic+as.MLModel'></span><span id='topic+as.MLModel.MLModelFit'></span><span id='topic+as.MLModel.ModelSpecification'></span><span id='topic+as.MLModel.model_spec'></span>

<h3>Description</h3>

<p>Function to coerce an object to <code>MLModel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.MLModel(x, ...)

## S3 method for class 'MLModelFit'
as.MLModel(x, ...)

## S3 method for class 'ModelSpecification'
as.MLModel(x, ...)

## S3 method for class 'model_spec'
as.MLModel(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.MLModel_+3A_x">x</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result, <span class="pkg">MachineShop</span>
<a href="#topic+ModelSpecification">model specification</a>, or
<span class="pkg">parsnip</span> <a href="parsnip.html#topic+model_spec">model specification</a>.</p>
</td></tr>
<tr><td><code id="as.MLModel_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ParsnipModel">ParsnipModel</a></code>
</p>

<hr>
<h2 id='BARTMachineModel'>Bayesian Additive Regression Trees Model</h2><span id='topic+BARTMachineModel'></span>

<h3>Description</h3>

<p>Builds a BART model for regression or classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BARTMachineModel(
  num_trees = 50,
  num_burn = 250,
  num_iter = 1000,
  alpha = 0.95,
  beta = 2,
  k = 2,
  q = 0.9,
  nu = 3,
  mh_prob_steps = c(2.5, 2.5, 4)/9,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BARTMachineModel_+3A_num_trees">num_trees</code></td>
<td>
<p>number of trees to be grown in the sum-of-trees model.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_num_burn">num_burn</code></td>
<td>
<p>number of MCMC samples to be discarded as &quot;burn-in&quot;.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_num_iter">num_iter</code></td>
<td>
<p>number of MCMC samples to draw from the posterior
distribution.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_alpha">alpha</code>, <code id="BARTMachineModel_+3A_beta">beta</code></td>
<td>
<p>base and power hyperparameters in tree prior for whether a
node is nonterminal or not.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_k">k</code></td>
<td>
<p>regression prior probability that <code class="reqn">E(Y|X)</code> is
contained in the interval <code class="reqn">(y_{min}, y_{max})</code>, based on a normal
distribution.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_q">q</code></td>
<td>
<p>quantile of the prior on the error variance at which the data-based
estimate is placed.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_nu">nu</code></td>
<td>
<p>regression degrees of freedom for the inverse <code class="reqn">sigma^2</code> prior.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_mh_prob_steps">mh_prob_steps</code></td>
<td>
<p>vector of prior probabilities for proposing changes to
the tree structures: (GROW, PRUNE, CHANGE).</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating whether to print progress information about
the algorithm.</p>
</td></tr>
<tr><td><code id="BARTMachineModel_+3A_...">...</code></td>
<td>
<p>additional arguments to <code><a href="bartMachine.html#topic+bartMachine">bartMachine</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>binary factor</code>, <code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>alpha</code>, <code>beta</code>, <code>k</code>, <code>nu</code>
</p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>BARTMachineModel</code>, argument
<code>type</code> may be specified as <code>"splits"</code> (default) for the
proportion of time each predictor is chosen for a splitting rule or as
<code>"trees"</code> for the proportion of times each predictor appears in a tree.
Argument <code>num_replicates</code> is also available to control the number of
BART replicates used in estimating the inclusion proportions [default: 5].
Variable importance is automatically scaled to range from 0 to 100.  To
obtain unscaled importance values, set <code>scale = FALSE</code>.  See example
below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="bartMachine.html#topic+bartMachine">bartMachine</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package bartMachine to run

model_fit &lt;- fit(sale_amount ~ ., data = ICHomes, model = BARTMachineModel)
varimp(model_fit, method = "model", type = "splits", num_replicates = 20,
       scale = FALSE)


</code></pre>

<hr>
<h2 id='BARTModel'>Bayesian Additive Regression Trees Model</h2><span id='topic+BARTModel'></span>

<h3>Description</h3>

<p>Flexible nonparametric modeling of covariates for continuous, binary,
categorical and time-to-event outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BARTModel(
  K = integer(),
  sparse = FALSE,
  theta = 0,
  omega = 1,
  a = 0.5,
  b = 1,
  rho = numeric(),
  augment = FALSE,
  xinfo = matrix(NA, 0, 0),
  usequants = FALSE,
  sigest = NA,
  sigdf = 3,
  sigquant = 0.9,
  lambda = NA,
  k = 2,
  power = 2,
  base = 0.95,
  tau.num = numeric(),
  offset = numeric(),
  ntree = integer(),
  numcut = 100,
  ndpost = 1000,
  nskip = integer(),
  keepevery = integer(),
  printevery = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BARTModel_+3A_k">K</code></td>
<td>
<p>if provided, then coarsen the times of survival responses per the
quantiles <code class="reqn">1/K, 2/K, ..., K/K</code> to reduce computational burdern.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_sparse">sparse</code></td>
<td>
<p>logical indicating whether to perform variable selection based
on a sparse Dirichlet prior rather than simply uniform; see Linero 2016.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_theta">theta</code>, <code id="BARTModel_+3A_omega">omega</code></td>
<td>
<p><code class="reqn">theta</code> and <code class="reqn">omega</code> parameters; zero means
random.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_a">a</code>, <code id="BARTModel_+3A_b">b</code></td>
<td>
<p>sparse parameters for <code class="reqn">Beta(a, b)</code> prior:
<code class="reqn">0.5 &lt;= a &lt;= 1</code> where lower values induce more sparsity and typically
<code class="reqn">b = 1</code>.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_rho">rho</code></td>
<td>
<p>sparse parameter: typically <code class="reqn">rho = p</code> where <code class="reqn">p</code> is the
number of covariates under consideration.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_augment">augment</code></td>
<td>
<p>whether data augmentation is to be performed in sparse
variable selection.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_xinfo">xinfo</code></td>
<td>
<p>optional matrix whose rows are the covariates and columns their
cutpoints.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_usequants">usequants</code></td>
<td>
<p>whether covariate cutpoints are defined by uniform quantiles
or generated uniformly.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_sigest">sigest</code></td>
<td>
<p>normal error variance prior for numeric response variables.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_sigdf">sigdf</code></td>
<td>
<p>degrees of freedom for error variance prior.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_sigquant">sigquant</code></td>
<td>
<p>quantile at which a rough estimate of the error standard
deviation is placed.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_lambda">lambda</code></td>
<td>
<p>scale of the prior error variance.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_k">k</code></td>
<td>
<p>number of standard deviations <code class="reqn">f(x)</code>  is away from +/-3 for
categorical response variables.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_power">power</code>, <code id="BARTModel_+3A_base">base</code></td>
<td>
<p>power and base parameters for tree prior.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_tau.num">tau.num</code></td>
<td>
<p>numerator in the <code class="reqn">tau</code> definition, i.e.,
<code class="reqn">tau = tau.num / (k * sqrt(ntree))</code>.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_offset">offset</code></td>
<td>
<p>override for the default <code class="reqn">offset</code> of <code class="reqn">F^-1(mean(y))</code>
in the multivariate response probability
<code class="reqn">P(y[j] = 1 | x) = F(f(x)[j] + offset[j])</code>.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_ntree">ntree</code></td>
<td>
<p>number of trees in the sum.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_numcut">numcut</code></td>
<td>
<p>number of possible covariate cutoff values.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_ndpost">ndpost</code></td>
<td>
<p>number of posterior draws returned.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_nskip">nskip</code></td>
<td>
<p>number of MCMC iterations to be treated as burn in.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_keepevery">keepevery</code></td>
<td>
<p>interval at which to keep posterior draws.</p>
</td></tr>
<tr><td><code id="BARTModel_+3A_printevery">printevery</code></td>
<td>
<p>interval at which to print MCMC progress.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>Surv</code></p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="BART.html#topic+gbart">gbart</a></code>, <code><a href="BART.html#topic+mbart">mbart</a></code>,
<code><a href="BART.html#topic+surv.bart">surv.bart</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package BART to run

fit(sale_amount ~ ., data = ICHomes, model = BARTModel)


</code></pre>

<hr>
<h2 id='BlackBoostModel'>Gradient Boosting with Regression Trees</h2><span id='topic+BlackBoostModel'></span>

<h3>Description</h3>

<p>Gradient boosting for optimizing arbitrary loss functions where regression
trees are utilized as base-learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BlackBoostModel(
  family = NULL,
  mstop = 100,
  nu = 0.1,
  risk = c("inbag", "oobag", "none"),
  stopintern = FALSE,
  trace = FALSE,
  teststat = c("quadratic", "maximum"),
  testtype = c("Teststatistic", "Univariate", "Bonferroni", "MonteCarlo"),
  mincriterion = 0,
  minsplit = 10,
  minbucket = 4,
  maxdepth = 2,
  saveinfo = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BlackBoostModel_+3A_family">family</code></td>
<td>
<p>optional <code><a href="mboost.html#topic+Family">Family</a></code> object.  Set
automatically according to the class type of the response variable.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_mstop">mstop</code></td>
<td>
<p>number of initial boosting iterations.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_nu">nu</code></td>
<td>
<p>step size or shrinkage parameter between 0 and 1.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_risk">risk</code></td>
<td>
<p>method to use in computing the empirical risk for each boosting
iteration.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_stopintern">stopintern</code></td>
<td>
<p>logical inidicating whether the boosting algorithm stops
internally when the out-of-bag risk increases at a subsequent iteration.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether status information is printed during
the fitting process.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_teststat">teststat</code></td>
<td>
<p>type of the test statistic to be applied for variable
selection.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_testtype">testtype</code></td>
<td>
<p>how to compute the distribution of the test statistic.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_mincriterion">mincriterion</code></td>
<td>
<p>value of the test statistic or 1 - p-value that must be
exceeded in order to implement a split.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_minsplit">minsplit</code></td>
<td>
<p>minimum sum of weights in a node in order to be considered
for splitting.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_minbucket">minbucket</code></td>
<td>
<p>minimum sum of weights in a terminal node.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_maxdepth">maxdepth</code></td>
<td>
<p>maximum depth of the tree.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_saveinfo">saveinfo</code></td>
<td>
<p>logical indicating whether to store information about
variable selection in <code>info</code> slot of each <code>partynode</code>.</p>
</td></tr>
<tr><td><code id="BlackBoostModel_+3A_...">...</code></td>
<td>
<p>additional arguments to <code><a href="partykit.html#topic+ctree_control">ctree_control</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>binary factor</code>, <code>BinomialVariate</code>,
<code>NegBinomialVariate</code>, <code>numeric</code>, <code>PoissonVariate</code>,
<code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>mstop</code>, <code>maxdepth</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="mboost.html#topic+blackboost">blackboost</a></code>, <code><a href="mboost.html#topic+Family">Family</a></code>,
<code><a href="partykit.html#topic+ctree_control">ctree_control</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested packages mboost and partykit to run

data(Pima.tr, package = "MASS")

fit(type ~ ., data = Pima.tr, model = BlackBoostModel)


</code></pre>

<hr>
<h2 id='C50Model'>C5.0 Decision Trees and Rule-Based Model</h2><span id='topic+C50Model'></span>

<h3>Description</h3>

<p>Fit classification tree models or rule-based models using Quinlan's C5.0
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C50Model(
  trials = 1,
  rules = FALSE,
  subset = TRUE,
  bands = 0,
  winnow = FALSE,
  noGlobalPruning = FALSE,
  CF = 0.25,
  minCases = 2,
  fuzzyThreshold = FALSE,
  sample = 0,
  earlyStopping = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="C50Model_+3A_trials">trials</code></td>
<td>
<p>integer number of boosting iterations.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_rules">rules</code></td>
<td>
<p>logical indicating whether to decompose the tree into a
rule-based model.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_subset">subset</code></td>
<td>
<p>logical indicating whether the model should evaluate groups of
discrete predictors for splits.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_bands">bands</code></td>
<td>
<p>integer between 2 and 1000 specifying a number of bands into
which to group rules ordered by their affect on the error rate.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_winnow">winnow</code></td>
<td>
<p>logical indicating use of predictor winnowing (i.e. feature
selection).</p>
</td></tr>
<tr><td><code id="C50Model_+3A_noglobalpruning">noGlobalPruning</code></td>
<td>
<p>logical indicating a final, global pruning step to
simplify the tree.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_cf">CF</code></td>
<td>
<p>number in (0, 1) for the confidence factor.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_mincases">minCases</code></td>
<td>
<p>integer for the smallest number of samples that must be put
in at least two of the splits.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_fuzzythreshold">fuzzyThreshold</code></td>
<td>
<p>logical indicating whether to evaluate possible
advanced splits of the data.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_sample">sample</code></td>
<td>
<p>value between (0, 0.999) that specifies the random proportion
of data to use in training the model.</p>
</td></tr>
<tr><td><code id="C50Model_+3A_earlystopping">earlyStopping</code></td>
<td>
<p>logical indicating whether the internal method for
stopping boosting should be used.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>trials</code>, <code>rules</code>, <code>winnow</code>
</p>
</dd>
</dl>

<p>Latter arguments are passed to <code><a href="C50.html#topic+C5.0Control">C5.0Control</a></code>.
Further model details can be found in the source link below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>C50Model</code>, argument <code>type</code>
may be specified as <code>"usage"</code> (default) for the percentage of training
set samples that fall into all terminal nodes after the split of each
predictor or as <code>"splits"</code> for the percentage of splits associated with
each predictor.  Variable importance is automatically scaled to range from 0
to 100.  To obtain unscaled importance values, set <code>scale = FALSE</code>.  See
example below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="C50.html#topic+C5.0">C5.0</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package C50 to run

model_fit &lt;- fit(Species ~ ., data = iris, model = C50Model)
varimp(model_fit, method = "model", type = "splits", scale = FALSE)


</code></pre>

<hr>
<h2 id='calibration'>Model Calibration</h2><span id='topic+calibration'></span>

<h3>Description</h3>

<p>Calculate calibration estimates from observed and predicted responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibration(
  x,
  y = NULL,
  weights = NULL,
  breaks = 10,
  span = 0.75,
  distr = character(),
  na.rm = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibration_+3A_x">x</code></td>
<td>
<p><a href="#topic+response">observed responses</a> or <a href="#topic+resample">resample</a> result
containing observed and predicted responses.</p>
</td></tr>
<tr><td><code id="calibration_+3A_y">y</code></td>
<td>
<p><a href="#topic+predict">predicted responses</a> if not contained in <code>x</code>.</p>
</td></tr>
<tr><td><code id="calibration_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative
<a href="#topic+case_weights">case weights</a> for the observed <code>x</code> responses
[default: equal weights].</p>
</td></tr>
<tr><td><code id="calibration_+3A_breaks">breaks</code></td>
<td>
<p>value defining the response variable bins within which to
calculate observed mean values.  May be specified as a number of bins, a
vector of breakpoints, or <code>NULL</code> to fit smooth curves with splines for
predicted survival probabilities and with <a href="stats.html#topic+loess">loess</a> for
others.</p>
</td></tr>
<tr><td><code id="calibration_+3A_span">span</code></td>
<td>
<p>numeric parameter controlling the degree of loess smoothing.</p>
</td></tr>
<tr><td><code id="calibration_+3A_distr">distr</code></td>
<td>
<p>character string specifying a distribution with which to
estimate the observed survival mean.  Possible values are
<code>"empirical"</code> for the Kaplan-Meier estimator, <code>"exponential"</code>,
<code>"extreme"</code>, <code>"gaussian"</code>, <code>"loggaussian"</code>,
<code>"logistic"</code>, <code>"loglogistic"</code>, <code>"lognormal"</code>,
<code>"rayleigh"</code>, <code>"t"</code>, or <code>"weibull"</code>.  Defaults to the
distribution that was used in predicting mean survival times.</p>
</td></tr>
<tr><td><code id="calibration_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to remove observed or predicted
responses that are <code>NA</code> when calculating metrics.</p>
</td></tr>
<tr><td><code id="calibration_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Calibration</code> class object that inherits from <code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+c">c</a></code>, <code><a href="#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

library(survival)

control &lt;- CVControl() %&gt;% set_predict(times = c(90, 180, 360))
res &lt;- resample(Surv(time, status) ~ ., data = veteran, model = GBMModel,
                control = control)
cal &lt;- calibration(res)
plot(cal)


</code></pre>

<hr>
<h2 id='case_weights'>Extract Case Weights</h2><span id='topic+case_weights'></span>

<h3>Description</h3>

<p>Extract the case weights from an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>case_weights(object, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="case_weights_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result, <code><a href="#topic+ModelFrame">ModelFrame</a></code>, or
<code><a href="recipes.html#topic+recipe">recipe</a></code>.</p>
</td></tr>
<tr><td><code id="case_weights_+3A_newdata">newdata</code></td>
<td>
<p>dataset from which to extract the weights if given; otherwise,
<code>object</code> is used.  The dataset should be given as a <code>ModelFrame</code>
or as a <a href="base.html#topic+data.frame">data frame</a> if <code>object</code> contains a
<code>ModelFrame</code> or a <code>recipe</code>, respectively.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Training and test sets
inds &lt;- sample(nrow(ICHomes), nrow(ICHomes) * 2 / 3)
trainset &lt;- ICHomes[inds, ]
testset &lt;- ICHomes[-inds, ]

## ModelFrame case weights
trainmf &lt;- ModelFrame(sale_amount ~ . - built, data = trainset, weights = built)
testmf &lt;- ModelFrame(formula(trainmf), data = testset, weights = built)
mf_fit &lt;- fit(trainmf, model = GLMModel)
rmse(response(mf_fit, testmf), predict(mf_fit, testmf),
     case_weights(mf_fit, testmf))

## Recipe case weights
library(recipes)
rec &lt;- recipe(sale_amount ~ ., data = trainset) %&gt;%
  role_case(weight = built, replace = TRUE)
rec_fit &lt;- fit(rec, model = GLMModel)
rmse(response(rec_fit, testset), predict(rec_fit, testset),
     case_weights(rec_fit, testset))

</code></pre>

<hr>
<h2 id='CForestModel'>Conditional Random Forest Model</h2><span id='topic+CForestModel'></span>

<h3>Description</h3>

<p>An implementation of the random forest and bagging ensemble algorithms
utilizing conditional inference trees as base learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CForestModel(
  teststat = c("quad", "max"),
  testtype = c("Univariate", "Teststatistic", "Bonferroni", "MonteCarlo"),
  mincriterion = 0,
  ntree = 500,
  mtry = 5,
  replace = TRUE,
  fraction = 0.632
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CForestModel_+3A_teststat">teststat</code></td>
<td>
<p>character specifying the type of the test statistic to be
applied.</p>
</td></tr>
<tr><td><code id="CForestModel_+3A_testtype">testtype</code></td>
<td>
<p>character specifying how to compute the distribution of the
test statistic.</p>
</td></tr>
<tr><td><code id="CForestModel_+3A_mincriterion">mincriterion</code></td>
<td>
<p>value of the test statistic that must be exceeded in
order to implement a split.</p>
</td></tr>
<tr><td><code id="CForestModel_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow in a forest.</p>
</td></tr>
<tr><td><code id="CForestModel_+3A_mtry">mtry</code></td>
<td>
<p>number of input variables randomly sampled as candidates at each
node for random forest like algorithms.</p>
</td></tr>
<tr><td><code id="CForestModel_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether sampling of observations is done
with or without replacement.</p>
</td></tr>
<tr><td><code id="CForestModel_+3A_fraction">fraction</code></td>
<td>
<p>fraction of number of observations to draw without
replacement (only relevant if <code>replace = FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>mtry</code>
</p>
</dd>
</dl>

<p>Supplied arguments are passed to <code><a href="party.html#topic+cforest_control">cforest_control</a></code>.
Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="party.html#topic+cforest">cforest</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(sale_amount ~ ., data = ICHomes, model = CForestModel)

</code></pre>

<hr>
<h2 id='combine'>Combine MachineShop Objects</h2><span id='topic+combine'></span><span id='topic+c'></span><span id='topic+c.Calibration'></span><span id='topic+c.ConfusionList'></span><span id='topic+c.ConfusionMatrix'></span><span id='topic+c.LiftCurve'></span><span id='topic+c.ListOf'></span><span id='topic+c.PerformanceCurve'></span><span id='topic+c.Resample'></span><span id='topic++2B+2CSurvMatrix+2CSurvMatrix-method'></span>

<h3>Description</h3>

<p>Combine one or more <span class="pkg">MachineShop</span> objects of the same class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Calibration'
c(...)

## S3 method for class 'ConfusionList'
c(...)

## S3 method for class 'ConfusionMatrix'
c(...)

## S3 method for class 'LiftCurve'
c(...)

## S3 method for class 'ListOf'
c(...)

## S3 method for class 'PerformanceCurve'
c(...)

## S3 method for class 'Resample'
c(...)

## S4 method for signature 'SurvMatrix,SurvMatrix'
e1 + e2
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combine_+3A_...">...</code></td>
<td>
<p>named or unnamed <a href="#topic+calibration">calibration</a>, <a href="#topic+confusion">confusion</a>,
<a href="#topic+lift">lift</a>, <a href="#topic+curves">performance curve</a>, <a href="#topic+summary">summary</a>, or
<a href="#topic+resample">resample</a> results.  Curves must have been generated with the same
performance <a href="#topic+metrics">metrics</a> and resamples with the same resampling
<a href="#topic+controls">control</a>.</p>
</td></tr>
<tr><td><code id="combine_+3A_e1">e1</code>, <code id="combine_+3A_e2">e2</code></td>
<td>
<p>objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of the same class as the arguments.
</p>

<hr>
<h2 id='confusion'>Confusion Matrix</h2><span id='topic+confusion'></span><span id='topic+ConfusionMatrix'></span>

<h3>Description</h3>

<p>Calculate confusion matrices of predicted and observed responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion(
  x,
  y = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  na.rm = TRUE,
  ...
)

ConfusionMatrix(data = NA, ordered = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confusion_+3A_x">x</code></td>
<td>
<p>factor of <a href="#topic+response">observed responses</a> or <a href="#topic+resample">resample</a>
result containing observed and predicted responses.</p>
</td></tr>
<tr><td><code id="confusion_+3A_y">y</code></td>
<td>
<p><a href="#topic+predict">predicted responses</a> if not contained in <code>x</code>.</p>
</td></tr>
<tr><td><code id="confusion_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative
<a href="#topic+case_weights">case weights</a> for the observed <code>x</code> responses
[default: equal weights].</p>
</td></tr>
<tr><td><code id="confusion_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric (0, 1) threshold above which binary factor
probabilities are classified as events and below which survival
probabilities are classified.  If <code>NULL</code>, then factor responses are
summed directly over predicted class probabilities, whereas a default
cutoff of 0.5 is used for survival probabilities.  Class probability
summations and survival will appear as decimal numbers that can be
interpreted as expected counts.</p>
</td></tr>
<tr><td><code id="confusion_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to remove observed or predicted
responses that are <code>NA</code> when calculating metrics.</p>
</td></tr>
<tr><td><code id="confusion_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="confusion_+3A_data">data</code></td>
<td>
<p>square matrix, or object that can be converted to one, of
cross-classified predicted and observed values in the rows and columns,
respectively.</p>
</td></tr>
<tr><td><code id="confusion_+3A_ordered">ordered</code></td>
<td>
<p>logical indicating whether the confusion matrix row and
columns should be regarded as ordered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value is a <code>ConfusionMatrix</code> class object that inherits from
<code>table</code> if <code>x</code> and <code>y</code> responses are specified or a
<code>ConfusionList</code> object that inherits from <code>list</code> if <code>x</code> is a
<code>Resample</code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+c">c</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

res &lt;- resample(Species ~ ., data = iris, model = GBMModel)
(conf &lt;- confusion(res))
plot(conf)


</code></pre>

<hr>
<h2 id='CoxModel'>Proportional Hazards Regression Model</h2><span id='topic+CoxModel'></span><span id='topic+CoxStepAICModel'></span>

<h3>Description</h3>

<p>Fits a Cox proportional hazards regression model. Time dependent variables,
time dependent strata, multiple events per subject, and other extensions are
incorporated using the counting process formulation of Andersen and Gill.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoxModel(ties = c("efron", "breslow", "exact"), ...)

CoxStepAICModel(
  ties = c("efron", "breslow", "exact"),
  ...,
  direction = c("both", "backward", "forward"),
  scope = list(),
  k = 2,
  trace = FALSE,
  steps = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CoxModel_+3A_ties">ties</code></td>
<td>
<p>character string specifying the method for tie handling.</p>
</td></tr>
<tr><td><code id="CoxModel_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="survival.html#topic+coxph.control">coxph.control</a></code>.</p>
</td></tr>
<tr><td><code id="CoxModel_+3A_direction">direction</code></td>
<td>
<p>mode of stepwise search, can be one of <code>"both"</code>
(default), <code>"backward"</code>, or <code>"forward"</code>.</p>
</td></tr>
<tr><td><code id="CoxModel_+3A_scope">scope</code></td>
<td>
<p>defines the range of models examined in the stepwise search.
This should be a list containing components <code>upper</code> and <code>lower</code>,
both formulae.</p>
</td></tr>
<tr><td><code id="CoxModel_+3A_k">k</code></td>
<td>
<p>multiple of the number of degrees of freedom used for the penalty.
Only <code>k = 2</code> gives the genuine AIC; <code>k = .(log(nobs))</code> is
sometimes referred to as BIC or SBC.</p>
</td></tr>
<tr><td><code id="CoxModel_+3A_trace">trace</code></td>
<td>
<p>if positive, information is printed during the running of
<code>stepAIC</code>. Larger values may give more information on the fitting
process.</p>
</td></tr>
<tr><td><code id="CoxModel_+3A_steps">steps</code></td>
<td>
<p>maximum number of steps to be considered.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>Surv</code></p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>CoxModel</code> and
<code>CoxStepAICModel</code>, numeric argument <code>base</code> may be specified for the
(negative) logarithmic transformation of p-values [defaul: <code>exp(1)</code>].
Transformed p-values are automatically scaled in the calculation of variable
importance to range from 0 to 100.  To obtain unscaled importance values, set
<code>scale = FALSE</code>.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="survival.html#topic+coxph">coxph</a></code>,
<code><a href="survival.html#topic+coxph.control">coxph.control</a></code>, <code><a href="MASS.html#topic+stepAIC">stepAIC</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

fit(Surv(time, status) ~ ., data = veteran, model = CoxModel)

</code></pre>

<hr>
<h2 id='dependence'>Partial Dependence</h2><span id='topic+dependence'></span>

<h3>Description</h3>

<p>Calculate partial dependence of a response on select predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dependence(
  object,
  data = NULL,
  select = NULL,
  interaction = FALSE,
  n = 10,
  intervals = c("uniform", "quantile"),
  distr = character(),
  method = character(),
  stats = MachineShop::settings("stats.PartialDependence"),
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dependence_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result.</p>
</td></tr>
<tr><td><code id="dependence_+3A_data">data</code></td>
<td>
<p><a href="base.html#topic+data.frame">data frame</a> containing all predictor
variables.  If not specified, the training data will be used by default.</p>
</td></tr>
<tr><td><code id="dependence_+3A_select">select</code></td>
<td>
<p>expression indicating predictor variables for which to compute
partial dependence (see <code><a href="base.html#topic+subset">subset</a></code> for syntax)
[default: all].</p>
</td></tr>
<tr><td><code id="dependence_+3A_interaction">interaction</code></td>
<td>
<p>logical indicating whether to calculate dependence on the
interacted predictors.</p>
</td></tr>
<tr><td><code id="dependence_+3A_n">n</code></td>
<td>
<p>number of predictor values at which to perform calculations.</p>
</td></tr>
<tr><td><code id="dependence_+3A_intervals">intervals</code></td>
<td>
<p>character string specifying whether the <code>n</code> values are
spaced uniformly (<code>"uniform"</code>) or according to variable quantiles
(<code>"quantile"</code>).</p>
</td></tr>
<tr><td><code id="dependence_+3A_distr">distr</code>, <code id="dependence_+3A_method">method</code></td>
<td>
<p>arguments passed to <code><a href="#topic+predict">predict</a></code>.</p>
</td></tr>
<tr><td><code id="dependence_+3A_stats">stats</code></td>
<td>
<p>function, function name, or vector of these with which to
compute response variable summary statistics over non-selected predictor
variables.</p>
</td></tr>
<tr><td><code id="dependence_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to exclude missing predicted response
values from the calculation of summary statistics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>PartialDependence</code> class object that inherits from
<code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

gbm_fit &lt;- fit(Species ~ ., data = iris, model = GBMModel)
(pd &lt;- dependence(gbm_fit, select = c(Petal.Length, Petal.Width)))
plot(pd)


</code></pre>

<hr>
<h2 id='diff'>Model Performance Differences</h2><span id='topic+diff'></span><span id='topic+diff.MLModel'></span><span id='topic+diff.Performance'></span><span id='topic+diff.Resample'></span>

<h3>Description</h3>

<p>Pairwise model differences in resampled performance metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MLModel'
diff(x, ...)

## S3 method for class 'Performance'
diff(x, ...)

## S3 method for class 'Resample'
diff(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diff_+3A_x">x</code></td>
<td>
<p>model <a href="#topic+performance">performance</a> or <a href="#topic+resample">resample</a> result.</p>
</td></tr>
<tr><td><code id="diff_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>PerformanceDiff</code> class object that inherits from
<code>Performance</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+t.test">t.test</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Survival response example
library(survival)

fo &lt;- Surv(time, status) ~ .
control &lt;- CVControl()

gbm_res1 &lt;- resample(fo, data = veteran, GBMModel(n.trees = 25), control)
gbm_res2 &lt;- resample(fo, data = veteran, GBMModel(n.trees = 50), control)
gbm_res3 &lt;- resample(fo, data = veteran, GBMModel(n.trees = 100), control)

res &lt;- c(GBM1 = gbm_res1, GBM2 = gbm_res2, GBM3 = gbm_res3)
res_diff &lt;- diff(res)
summary(res_diff)
plot(res_diff)


</code></pre>

<hr>
<h2 id='DiscreteVariate'>Discrete Variate Constructors</h2><span id='topic+DiscreteVariate'></span><span id='topic+BinomialVariate'></span><span id='topic+NegBinomialVariate'></span><span id='topic+PoissonVariate'></span>

<h3>Description</h3>

<p>Create a variate of binomial counts, discrete numbers, negative binomial
counts, or Poisson counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinomialVariate(x = integer(), size = integer())

DiscreteVariate(x = integer(), min = -Inf, max = Inf)

NegBinomialVariate(x = integer())

PoissonVariate(x = integer())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DiscreteVariate_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="DiscreteVariate_+3A_size">size</code></td>
<td>
<p>number or numeric vector of binomial trials.</p>
</td></tr>
<tr><td><code id="DiscreteVariate_+3A_min">min</code>, <code id="DiscreteVariate_+3A_max">max</code></td>
<td>
<p>minimum and maximum bounds for discrete numbers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>BinomialVariate</code> object class, <code>DiscreteVariate</code> that
inherits from <code>numeric</code>, or <code>NegBinomialVariate</code> or
<code>PoissonVariate</code> that inherit from <code>DiscreteVariate</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+role_binom">role_binom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BinomialVariate(rbinom(25, 10, 0.5), size = 10)
PoissonVariate(rpois(25, 10))

</code></pre>

<hr>
<h2 id='EarthModel'>Multivariate Adaptive Regression Splines Model</h2><span id='topic+EarthModel'></span>

<h3>Description</h3>

<p>Build a regression model using the techniques in Friedman's papers
&quot;Multivariate Adaptive Regression Splines&quot; and &quot;Fast MARS&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EarthModel(
  pmethod = c("backward", "none", "exhaustive", "forward", "seqrep", "cv"),
  trace = 0,
  degree = 1,
  nprune = integer(),
  nfold = 0,
  ncross = 1,
  stratify = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EarthModel_+3A_pmethod">pmethod</code></td>
<td>
<p>pruning method.</p>
</td></tr>
<tr><td><code id="EarthModel_+3A_trace">trace</code></td>
<td>
<p>level of execution information to display.</p>
</td></tr>
<tr><td><code id="EarthModel_+3A_degree">degree</code></td>
<td>
<p>maximum degree of interaction.</p>
</td></tr>
<tr><td><code id="EarthModel_+3A_nprune">nprune</code></td>
<td>
<p>maximum number of terms (including intercept) in the pruned
model.</p>
</td></tr>
<tr><td><code id="EarthModel_+3A_nfold">nfold</code></td>
<td>
<p>number of cross-validation folds.</p>
</td></tr>
<tr><td><code id="EarthModel_+3A_ncross">ncross</code></td>
<td>
<p>number of cross-validations if <code>nfold &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="EarthModel_+3A_stratify">stratify</code></td>
<td>
<p>logical indicating whether to stratify cross-validation
samples by the response levels.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>nprune</code>, <code>degree</code>*
</p>
</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>Default argument values and further model details can be found in the source
See Also link below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>EarthModel</code>, argument
<code>type</code> may be specified as <code>"nsubsets"</code> (default) for the number of
model subsets that include each predictor, as <code>"gcv"</code> for the
generalized cross-validation decrease over all subsets that include each
predictor, or as <code>"rss"</code> for the residual sums of squares decrease.
Variable importance is automatically scaled to range from 0 to 100.  To
obtain unscaled importance values, set <code>scale = FALSE</code>.  See example
below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="earth.html#topic+earth">earth</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package earth to run

model_fit &lt;- fit(Species ~ ., data = iris, model = EarthModel)
varimp(model_fit, method = "model", type = "gcv", scale = FALSE)


</code></pre>

<hr>
<h2 id='expand_model'>Model Expansion Over Tuning Parameters</h2><span id='topic+expand_model'></span>

<h3>Description</h3>

<p>Expand a model over all combinations of a grid of tuning parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_model(object, ..., random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expand_model_+3A_object">object</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object; or
another object that can be <a href="#topic+as.MLModel">coerced</a> to a model.</p>
</td></tr>
<tr><td><code id="expand_model_+3A_...">...</code></td>
<td>
<p>named vectors or factors or a list of these containing the
parameter values over which to expand <code>object</code>.</p>
</td></tr>
<tr><td><code id="expand_model_+3A_random">random</code></td>
<td>
<p>number of points to be randomly sampled from the parameter grid
or <code>FALSE</code> if all points are to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> of expanded models.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SelectedModel">SelectedModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

data(Boston, package = "MASS")

models &lt;- expand_model(GBMModel, n.trees = c(50, 100),
                                 interaction.depth = 1:2)

fit(medv ~ ., data = Boston, model = SelectedModel(models))


</code></pre>

<hr>
<h2 id='expand_modelgrid'>Model Tuning Grid Expansion</h2><span id='topic+expand_modelgrid'></span><span id='topic+expand_modelgrid.formula'></span><span id='topic+expand_modelgrid.matrix'></span><span id='topic+expand_modelgrid.ModelFrame'></span><span id='topic+expand_modelgrid.recipe'></span><span id='topic+expand_modelgrid.ModelSpecification'></span><span id='topic+expand_modelgrid.MLModel'></span><span id='topic+expand_modelgrid.MLModelFunction'></span>

<h3>Description</h3>

<p>Expand a model grid of tuning parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_modelgrid(...)

## S3 method for class 'formula'
expand_modelgrid(formula, data, model, info = FALSE, ...)

## S3 method for class 'matrix'
expand_modelgrid(x, y, model, info = FALSE, ...)

## S3 method for class 'ModelFrame'
expand_modelgrid(input, model, info = FALSE, ...)

## S3 method for class 'recipe'
expand_modelgrid(input, model, info = FALSE, ...)

## S3 method for class 'ModelSpecification'
expand_modelgrid(object, ...)

## S3 method for class 'MLModel'
expand_modelgrid(model, ...)

## S3 method for class 'MLModelFunction'
expand_modelgrid(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expand_modelgrid_+3A_...">...</code></td>
<td>
<p>arguments passed from the generic function to its methods and from
the <code>MLModel</code> and <code>MLModelFunction</code> methods to others.  The
first argument of each <code>expand_modelgrid</code> method is positional and, as
such, must be given first in calls to them.</p>
</td></tr>
<tr><td><code id="expand_modelgrid_+3A_formula">formula</code>, <code id="expand_modelgrid_+3A_data">data</code></td>
<td>
<p><a href="stats.html#topic+formula">formula</a> defining the model predictor and
response variables and a <a href="base.html#topic+data.frame">data frame</a> containing them.</p>
</td></tr>
<tr><td><code id="expand_modelgrid_+3A_model">model</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object; or
another object that can be <a href="#topic+as.MLModel">coerced</a> to a model.  A model
can be given first followed by any of the variable specifications.</p>
</td></tr>
<tr><td><code id="expand_modelgrid_+3A_info">info</code></td>
<td>
<p>logical indicating whether to return model-defined grid
construction information rather than the grid values.</p>
</td></tr>
<tr><td><code id="expand_modelgrid_+3A_x">x</code>, <code id="expand_modelgrid_+3A_y">y</code></td>
<td>
<p><a href="base.html#topic+matrix">matrix</a> and object containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="expand_modelgrid_+3A_input">input</code></td>
<td>
<p><a href="#topic+inputs">input</a> object defining and containing the model
predictor and response variables.</p>
</td></tr>
<tr><td><code id="expand_modelgrid_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+ModelSpecification">specification</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>expand_modelgrid</code> function enables manual extraction and viewing of
grids created automatically when a <code><a href="#topic+TunedModel">TunedModel</a></code> is fit.
</p>


<h3>Value</h3>

<p>A data frame of parameter values or <code>NULL</code> if data are required
for construction of the grid but not supplied.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TunedModel">TunedModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>expand_modelgrid(TunedModel(GBMModel, grid = 5))

expand_modelgrid(TunedModel(GLMNetModel, grid = c(alpha = 5, lambda = 10)),
                 sale_amount ~ ., data = ICHomes)

gbm_grid &lt;- ParameterGrid(
  n.trees = dials::trees(),
  interaction.depth = dials::tree_depth(),
  size = 5
)
expand_modelgrid(TunedModel(GBMModel, grid = gbm_grid))

rf_grid &lt;- ParameterGrid(
  mtry = dials::mtry(),
  nodesize = dials::max_nodes(),
  size = c(3, 5)
)
expand_modelgrid(TunedModel(RandomForestModel, grid = rf_grid),
                 sale_amount ~ ., data = ICHomes)

</code></pre>

<hr>
<h2 id='expand_params'>Model Parameters Expansion</h2><span id='topic+expand_params'></span>

<h3>Description</h3>

<p>Create a grid of parameter values from all combinations of supplied inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_params(..., random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expand_params_+3A_...">...</code></td>
<td>
<p>named data frames or vectors or a list of these containing the
parameter values over which to create the grid.</p>
</td></tr>
<tr><td><code id="expand_params_+3A_random">random</code></td>
<td>
<p>number of points to be randomly sampled from the parameter grid
or <code>FALSE</code> if all points are to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing one row for each combination of the supplied
inputs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TunedModel">TunedModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

data(Boston, package = "MASS")

grid &lt;- expand_params(
  n.trees = c(50, 100),
  interaction.depth = 1:2
)

fit(medv ~ ., data = Boston, model = TunedModel(GBMModel, grid = grid))


</code></pre>

<hr>
<h2 id='expand_steps'>Recipe Step Parameters Expansion</h2><span id='topic+expand_steps'></span>

<h3>Description</h3>

<p>Create a grid of parameter values from all combinations of lists supplied for
steps of a preprocessing recipe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_steps(..., random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expand_steps_+3A_...">...</code></td>
<td>
<p>one or more lists containing parameter values over which to create
the grid.  For each list an argument name should be given as the <code>id</code>
of the <a href="recipes.html#topic+recipe">recipe</a> step to which it corresponds.</p>
</td></tr>
<tr><td><code id="expand_steps_+3A_random">random</code></td>
<td>
<p>number of points to be randomly sampled from the parameter grid
or <code>FALSE</code> if all points are to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RecipeGrid</code> class object that inherits from <code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TunedInput">TunedInput</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
data(Boston, package = "MASS")

rec &lt;- recipe(medv ~ ., data = Boston) %&gt;%
  step_corr(all_numeric_predictors(), id = "corr") %&gt;%
  step_pca(all_numeric_predictors(), id = "pca")

expand_steps(
  corr = list(threshold = c(0.8, 0.9),
              method = c("pearson", "spearman")),
  pca = list(num_comp = 1:3)
)

</code></pre>

<hr>
<h2 id='extract'>Extract Elements of an Object</h2><span id='topic+extract'></span><span id='topic++5B.BinomialVariate'></span><span id='topic++5B+2CDiscreteVariate+2CANY+2Cmissing+2Cmissing-method'></span><span id='topic++5B+2CListOf+2CANY+2Cmissing+2Cmissing-method'></span><span id='topic++5B+2CModelFrame+2CANY+2CANY+2CANY-method'></span><span id='topic++5B+2CModelFrame+2CANY+2Cmissing+2CANY-method'></span><span id='topic++5B+2CModelFrame+2Cmissing+2CANY+2CANY-method'></span><span id='topic++5B+2CModelFrame+2Cmissing+2Cmissing+2CANY-method'></span><span id='topic++5B+2CRecipeGrid+2CANY+2CANY+2CANY-method'></span><span id='topic++5B+2CResample+2CANY+2CANY+2CANY-method'></span><span id='topic++5B+2CResample+2CANY+2Cmissing+2CANY-method'></span><span id='topic++5B+2CResample+2Cmissing+2Cmissing+2CANY-method'></span><span id='topic++5B+2CSurvMatrix+2CANY+2CANY+2CANY-method'></span><span id='topic++5B+2CSurvTimes+2CANY+2Cmissing+2Cmissing-method'></span>

<h3>Description</h3>

<p>Operators acting on data structures to extract elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BinomialVariate'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'DiscreteVariate,ANY,missing,missing'
x[i]

## S4 method for signature 'ListOf,ANY,missing,missing'
x[i]

## S4 method for signature 'ModelFrame,ANY,ANY,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'ModelFrame,ANY,missing,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'ModelFrame,missing,ANY,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'ModelFrame,missing,missing,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'RecipeGrid,ANY,ANY,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'Resample,ANY,ANY,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'Resample,ANY,missing,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'Resample,missing,missing,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'SurvMatrix,ANY,ANY,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'SurvTimes,ANY,missing,missing'
x[i]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_+3A_x">x</code></td>
<td>
<p>object from which to extract elements.</p>
</td></tr>
<tr><td><code id="extract_+3A_i">i</code>, <code id="extract_+3A_j">j</code>, <code id="extract_+3A_...">...</code></td>
<td>
<p>indices specifying elements to extract.</p>
</td></tr>
<tr><td><code id="extract_+3A_drop">drop</code></td>
<td>
<p>logical indicating that the result be returned as an object
coerced to the lowest dimension possible if <code>TRUE</code> or
with the original dimensions and class otherwise.</p>
</td></tr>
</table>

<hr>
<h2 id='FDAModel'>Flexible and Penalized Discriminant Analysis Models</h2><span id='topic+FDAModel'></span><span id='topic+PDAModel'></span>

<h3>Description</h3>

<p>Performs flexible discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FDAModel(
  theta = matrix(NA, 0, 0),
  dimension = integer(),
  eps = .Machine$double.eps,
  method = .(mda::polyreg),
  ...
)

PDAModel(lambda = 1, df = numeric(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FDAModel_+3A_theta">theta</code></td>
<td>
<p>optional matrix of class scores, typically with number of
columns less than one minus the number of classes.</p>
</td></tr>
<tr><td><code id="FDAModel_+3A_dimension">dimension</code></td>
<td>
<p>dimension of the discriminant subspace, less than the number
of classes, to use for prediction.</p>
</td></tr>
<tr><td><code id="FDAModel_+3A_eps">eps</code></td>
<td>
<p>numeric threshold for small singular values for excluding
discriminant variables.</p>
</td></tr>
<tr><td><code id="FDAModel_+3A_method">method</code></td>
<td>
<p>regression function used in optimal scaling.  The default of
linear regression is provided by <code><a href="mda.html#topic+polyreg">polyreg</a></code> from the
<span class="pkg">mda</span> package.  For penalized discriminant analysis,
<code><a href="mda.html#topic+gen.ridge">gen.ridge</a></code> is appropriate.  Other possibilities are
<code><a href="mda.html#topic+mars">mars</a></code> for multivariate adaptive regression splines and
<code><a href="mda.html#topic+bruto">bruto</a></code> for adaptive backfitting of additive splines.  Use
the <code><a href="#topic+quote">.</a></code> operator to quote specified functions.</p>
</td></tr>
<tr><td><code id="FDAModel_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>method</code> for <code>FDAModel</code> and to
<code>FDAModel</code> for <code>PDAModel</code>.</p>
</td></tr>
<tr><td><code id="FDAModel_+3A_lambda">lambda</code></td>
<td>
<p>shrinkage penalty coefficient.</p>
</td></tr>
<tr><td><code id="FDAModel_+3A_df">df</code></td>
<td>
<p>alternative specification of <code>lambda</code> in terms of equivalent
degrees of freedom.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>

<ul>
<li><p> FDAModel: <code>nprune</code>, <code>degree</code>*
</p>
</li>
<li><p> PDAModel: <code>lambda</code>
</p>
</li></ul>

</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>The <code><a href="#topic+predict">predict</a></code> function for this model additionally accepts the
following argument.
</p>

<dl>
<dt><code>prior</code></dt><dd><p>prior class membership probabilities for prediction
data if different from the training set.</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="mda.html#topic+fda">fda</a></code>, <code><a href="mda.html#topic+predict.fda">predict.fda</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package mda to run

fit(Species ~ ., data = iris, model = FDAModel)



## Requires prior installation of suggested package mda to run

fit(Species ~ ., data = iris, model = PDAModel)


</code></pre>

<hr>
<h2 id='fit'>Model Fitting</h2><span id='topic+fit'></span><span id='topic+fit.formula'></span><span id='topic+fit.matrix'></span><span id='topic+fit.ModelFrame'></span><span id='topic+fit.recipe'></span><span id='topic+fit.ModelSpecification'></span><span id='topic+fit.MLModel'></span><span id='topic+fit.MLModelFunction'></span>

<h3>Description</h3>

<p>Fit a model to estimate its parameters from a data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit(...)

## S3 method for class 'formula'
fit(formula, data, model, ...)

## S3 method for class 'matrix'
fit(x, y, model, ...)

## S3 method for class 'ModelFrame'
fit(input, model, ...)

## S3 method for class 'recipe'
fit(input, model, ...)

## S3 method for class 'ModelSpecification'
fit(object, verbose = FALSE, ...)

## S3 method for class 'MLModel'
fit(model, ...)

## S3 method for class 'MLModelFunction'
fit(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_+3A_...">...</code></td>
<td>
<p>arguments passed from the generic function to its methods, from
the <code>MLModel</code> and <code>MLModelFunction</code> methods to first arguments of
others, and from others to the <code>ModelSpecification</code> method.  The
first argument of each <code>fit</code> method is positional and, as such, must
be given first in calls to them.</p>
</td></tr>
<tr><td><code id="fit_+3A_formula">formula</code>, <code id="fit_+3A_data">data</code></td>
<td>
<p><a href="stats.html#topic+formula">formula</a> defining the model predictor and
response variables and a <a href="base.html#topic+data.frame">data frame</a> containing them.</p>
</td></tr>
<tr><td><code id="fit_+3A_model">model</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object; or
another object that can be <a href="#topic+as.MLModel">coerced</a> to a model.  A model
can be given first followed by any of the variable specifications.</p>
</td></tr>
<tr><td><code id="fit_+3A_x">x</code>, <code id="fit_+3A_y">y</code></td>
<td>
<p><a href="base.html#topic+matrix">matrix</a> and object containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="fit_+3A_input">input</code></td>
<td>
<p><a href="#topic+inputs">input</a> object defining and containing the model
predictor and response variables.</p>
</td></tr>
<tr><td><code id="fit_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+ModelSpecification">specification</a>.</p>
</td></tr>
<tr><td><code id="fit_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating whether to display printed output generated
by some model-specific fit functions to aid in monitoring progress and
diagnosing errors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>User-specified case weights may be specified for <code>ModelFrames</code> upon
creation with the <code><a href="#topic+ModelFrame">weights</a></code> argument in its
constructor.
</p>
<p>Variables in <code>recipe</code> specifications may be designated as case weights
with the <code><a href="#topic+role_case">role_case</a></code> function.
</p>


<h3>Value</h3>

<p><code>MLModelFit</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.MLModel">as.MLModel</a></code>, <code><a href="#topic+response">response</a></code>,
<code><a href="#topic+predict">predict</a></code>, <code><a href="#topic+varimp">varimp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Survival response example
library(survival)

gbm_fit &lt;- fit(Surv(time, status) ~ ., data = veteran, model = GBMModel)
varimp(gbm_fit)


</code></pre>

<hr>
<h2 id='GAMBoostModel'>Gradient Boosting with Additive Models</h2><span id='topic+GAMBoostModel'></span>

<h3>Description</h3>

<p>Gradient boosting for optimizing arbitrary loss functions, where
component-wise arbitrary base-learners, e.g., smoothing procedures, are
utilized as additive base-learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GAMBoostModel(
  family = NULL,
  baselearner = c("bbs", "bols", "btree", "bss", "bns"),
  dfbase = 4,
  mstop = 100,
  nu = 0.1,
  risk = c("inbag", "oobag", "none"),
  stopintern = FALSE,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GAMBoostModel_+3A_family">family</code></td>
<td>
<p>optional <code><a href="mboost.html#topic+Family">Family</a></code> object.  Set
automatically according to the class type of the response variable.</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_baselearner">baselearner</code></td>
<td>
<p>character specifying the component-wise
<code><a href="mboost.html#topic+baselearners">base learner</a></code> to be used.</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_dfbase">dfbase</code></td>
<td>
<p>gobal degrees of freedom for P-spline base learners
(<code>"bbs"</code>).</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_mstop">mstop</code></td>
<td>
<p>number of initial boosting iterations.</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_nu">nu</code></td>
<td>
<p>step size or shrinkage parameter between 0 and 1.</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_risk">risk</code></td>
<td>
<p>method to use in computing the empirical risk for each boosting
iteration.</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_stopintern">stopintern</code></td>
<td>
<p>logical inidicating whether the boosting algorithm stops
internally when the out-of-bag risk increases at a subsequent iteration.</p>
</td></tr>
<tr><td><code id="GAMBoostModel_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether status information is printed during
the fitting process.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>binary factor</code>, <code>BinomialVariate</code>,
<code>NegBinomialVariate</code>, <code>numeric</code>, <code>PoissonVariate</code>,
<code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>mstop</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="mboost.html#topic+gamboost">gamboost</a></code>, <code><a href="mboost.html#topic+Family">Family</a></code>,
<code><a href="mboost.html#topic+baselearners">baselearners</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package mboost to run

data(Pima.tr, package = "MASS")

fit(type ~ ., data = Pima.tr, model = GAMBoostModel)


</code></pre>

<hr>
<h2 id='GBMModel'>Generalized Boosted Regression Model</h2><span id='topic+GBMModel'></span>

<h3>Description</h3>

<p>Fits generalized boosted regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GBMModel(
  distribution = character(),
  n.trees = 100,
  interaction.depth = 1,
  n.minobsinnode = 10,
  shrinkage = 0.1,
  bag.fraction = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GBMModel_+3A_distribution">distribution</code></td>
<td>
<p>optional character string specifying the name of the
distribution to use or list with a component <code>name</code> specifying the
distribution and any additional parameters needed.  Set automatically
according to the class type of the response variable.</p>
</td></tr>
<tr><td><code id="GBMModel_+3A_n.trees">n.trees</code></td>
<td>
<p>total number of trees to fit.</p>
</td></tr>
<tr><td><code id="GBMModel_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>maximum depth of variable interactions.</p>
</td></tr>
<tr><td><code id="GBMModel_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes.</p>
</td></tr>
<tr><td><code id="GBMModel_+3A_shrinkage">shrinkage</code></td>
<td>
<p>shrinkage parameter applied to each tree in the expansion.</p>
</td></tr>
<tr><td><code id="GBMModel_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>fraction of the training set observations randomly
selected to propose the next tree in the expansion.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>,
<code>PoissonVariate</code>, <code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>n.trees</code>, <code>interaction.depth</code>, <code>shrinkage</code>*,
<code>n.minobsinnode</code>*
</p>
</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="gbm.html#topic+gbm">gbm</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

fit(Species ~ ., data = iris, model = GBMModel)


</code></pre>

<hr>
<h2 id='GLMBoostModel'>Gradient Boosting with Linear Models</h2><span id='topic+GLMBoostModel'></span>

<h3>Description</h3>

<p>Gradient boosting for optimizing arbitrary loss functions where
component-wise linear models are utilized as base-learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLMBoostModel(
  family = NULL,
  mstop = 100,
  nu = 0.1,
  risk = c("inbag", "oobag", "none"),
  stopintern = FALSE,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GLMBoostModel_+3A_family">family</code></td>
<td>
<p>optional <code><a href="mboost.html#topic+Family">Family</a></code> object.  Set
automatically according to the class type of the response variable.</p>
</td></tr>
<tr><td><code id="GLMBoostModel_+3A_mstop">mstop</code></td>
<td>
<p>number of initial boosting iterations.</p>
</td></tr>
<tr><td><code id="GLMBoostModel_+3A_nu">nu</code></td>
<td>
<p>step size or shrinkage parameter between 0 and 1.</p>
</td></tr>
<tr><td><code id="GLMBoostModel_+3A_risk">risk</code></td>
<td>
<p>method to use in computing the empirical risk for each boosting
iteration.</p>
</td></tr>
<tr><td><code id="GLMBoostModel_+3A_stopintern">stopintern</code></td>
<td>
<p>logical inidicating whether the boosting algorithm stops
internally when the out-of-bag risk increases at a subsequent iteration.</p>
</td></tr>
<tr><td><code id="GLMBoostModel_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether status information is printed during
the fitting process.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>binary factor</code>, <code>BinomialVariate</code>,
<code>NegBinomialVariate</code>, <code>numeric</code>, <code>PoissonVariate</code>,
<code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>mstop</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="mboost.html#topic+glmboost">glmboost</a></code>, <code><a href="mboost.html#topic+Family">Family</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package mboost to run

data(Pima.tr, package = "MASS")

fit(type ~ ., data = Pima.tr, model = GLMBoostModel)


</code></pre>

<hr>
<h2 id='GLMModel'>Generalized Linear Model</h2><span id='topic+GLMModel'></span><span id='topic+GLMStepAICModel'></span>

<h3>Description</h3>

<p>Fits generalized linear models, specified by giving a symbolic description of
the linear predictor and a description of the error distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLMModel(family = NULL, quasi = FALSE, ...)

GLMStepAICModel(
  family = NULL,
  quasi = FALSE,
  ...,
  direction = c("both", "backward", "forward"),
  scope = list(),
  k = 2,
  trace = FALSE,
  steps = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GLMModel_+3A_family">family</code></td>
<td>
<p>optional error distribution and link function to be used in the
model.  Set automatically according to the class type of the response
variable.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_quasi">quasi</code></td>
<td>
<p>logical indicator for over-dispersion of binomial and Poisson
families; i.e., dispersion parameters not fixed at one.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="stats.html#topic+glm.control">glm.control</a></code>.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_direction">direction</code></td>
<td>
<p>mode of stepwise search, can be one of <code>"both"</code>
(default), <code>"backward"</code>, or <code>"forward"</code>.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_scope">scope</code></td>
<td>
<p>defines the range of models examined in the stepwise search.
This should be a list containing components <code>upper</code> and <code>lower</code>,
both formulae.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_k">k</code></td>
<td>
<p>multiple of the number of degrees of freedom used for the penalty.
Only <code>k = 2</code> gives the genuine AIC; <code>k = .(log(nobs))</code> is
sometimes referred to as BIC or SBC.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_trace">trace</code></td>
<td>
<p>if positive, information is printed during the running of
<code>stepAIC</code>. Larger values may give more information on the fitting
process.</p>
</td></tr>
<tr><td><code id="GLMModel_+3A_steps">steps</code></td>
<td>
<p>maximum number of steps to be considered.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>GLMModel</code> Response types:</dt><dd><p><code>BinomialVariate</code>,
<code>factor</code>, <code>matrix</code>, <code>NegBinomialVariate</code>,
<code>numeric</code>, <code>PoissonVariate</code></p>
</dd>
<dt><code>GLMStepAICModel</code> Response types:</dt><dd><p><code>binary factor</code>,
<code>BinomialVariate</code>, <code>NegBinomialVariate</code>, <code>numeric</code>,
<code>PoissonVariate</code></p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>GLMModel</code> and
<code>GLMStepAICModel</code>, numeric argument <code>base</code> may be specified for the
(negative) logarithmic transformation of p-values [defaul: <code>exp(1)</code>].
Transformed p-values are automatically scaled in the calculation of variable
importance to range from 0 to 100.  To obtain unscaled importance values, set
<code>scale = FALSE</code>.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+glm.control">glm.control</a></code>,
<code><a href="MASS.html#topic+stepAIC">stepAIC</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(sale_amount ~ ., data = ICHomes, model = GLMModel)

</code></pre>

<hr>
<h2 id='GLMNetModel'>GLM Lasso or Elasticnet Model</h2><span id='topic+GLMNetModel'></span>

<h3>Description</h3>

<p>Fit a generalized linear model via penalized maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLMNetModel(
  family = NULL,
  alpha = 1,
  lambda = 0,
  standardize = TRUE,
  intercept = logical(),
  penalty.factor = .(rep(1, nvars)),
  standardize.response = FALSE,
  thresh = 1e-07,
  maxit = 1e+05,
  type.gaussian = .(if (nvars &lt; 500) "covariance" else "naive"),
  type.logistic = c("Newton", "modified.Newton"),
  type.multinomial = c("ungrouped", "grouped")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GLMNetModel_+3A_family">family</code></td>
<td>
<p>optional response type.  Set automatically according to the
class type of the response variable.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_alpha">alpha</code></td>
<td>
<p>elasticnet mixing parameter.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_lambda">lambda</code></td>
<td>
<p>regularization parameter.  The default value <code>lambda = 0</code>
performs no regularization and should be increased to avoid model fitting
issues if the number of predictor variables is greater than the number of
observations.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_standardize">standardize</code></td>
<td>
<p>logical flag for predictor variable standardization, prior
to model fitting.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_intercept">intercept</code></td>
<td>
<p>logical indicating whether to fit intercepts.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>vector of penalty factors to be applied to each
coefficient.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_standardize.response">standardize.response</code></td>
<td>
<p>logical indicating whether to standardize
<code>"mgaussian"</code> response variables.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_thresh">thresh</code></td>
<td>
<p>convergence threshold for coordinate descent.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of passes over the data for all lambda values.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_type.gaussian">type.gaussian</code></td>
<td>
<p>algorithm type for guassian models.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_type.logistic">type.logistic</code></td>
<td>
<p>algorithm type for logistic models.</p>
</td></tr>
<tr><td><code id="GLMNetModel_+3A_type.multinomial">type.multinomial</code></td>
<td>
<p>algorithm type for multinomial models.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>BinomialVariate</code>, <code>factor</code>,
<code>matrix</code>, <code>numeric</code>, <code>PoissonVariate</code>, <code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>lambda</code>, <code>alpha</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package glmnet to run

fit(sale_amount ~ ., data = ICHomes, model = GLMNetModel(lambda = 0.01))


</code></pre>

<hr>
<h2 id='ICHomes'>Iowa City Home Sales Dataset</h2><span id='topic+ICHomes'></span>

<h3>Description</h3>

<p>Characteristics of homes sold in Iowa City, IA from 2005 to 2008 as reported
by the county assessor's office.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICHomes
</code></pre>


<h3>Format</h3>

<p>A data frame with 753 observations of 17 variables:
</p>

<dl>
<dt>sale_amount</dt><dd><p>sale amount in dollars.</p>
</dd>
<dt>sale_year</dt><dd><p>sale year.</p>
</dd>
<dt>sale_month</dt><dd><p>sale month.</p>
</dd>
<dt>built</dt><dd><p>year in which the home was built.</p>
</dd>
<dt>style</dt><dd><p>home stlye (Home/Condo)</p>
</dd>
<dt>construction</dt><dd><p>home construction type.</p>
</dd>
<dt>base_size</dt><dd><p>base foundation size in sq ft.</p>
</dd>
<dt>add_size</dt><dd><p>size of additions made to the base foundation in sq ft.</p>
</dd>
<dt>garage1_size</dt><dd><p>attached garage size in sq ft.</p>
</dd>
<dt>garage2_size</dt><dd><p>detached garage size in sq ft.</p>
</dd>
<dt>lot_size</dt><dd><p>total lot size in sq ft.</p>
</dd>
<dt>bedrooms</dt><dd><p>number of bedrooms.</p>
</dd>
<dt>basement</dt><dd><p>presence of a basement (No/Yes).</p>
</dd>
<dt>ac</dt><dd><p>presence of central air conditioning (No/Yes).</p>
</dd>
<dt>attic</dt><dd><p>presence of a finished attic (No/Yes).</p>
</dd>
<dt>lon,lat</dt><dd><p>home longitude/latitude coordinates.</p>
</dd>
</dl>


<hr>
<h2 id='inputs'>Model Inputs</h2><span id='topic+inputs'></span>

<h3>Description</h3>

<p>Model inputs are the predictor and response variables whose relationship is
determined by a model fit.  Input specifications supported by
<span class="pkg">MachineShop</span> are summarized in the table below.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="stats.html#topic+formula">formula</a></code>         </td><td style="text-align: left;"> Traditional model formula </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="base.html#topic+matrix">matrix</a></code>          </td><td style="text-align: left;"> Design matrix of predictors </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+ModelFrame">ModelFrame</a></code>      </td><td style="text-align: left;"> Model frame </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+ModelSpecification">ModelSpecification</a></code> </td><td style="text-align: left;"> Model specification </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="recipes.html#topic+recipe">recipe</a></code> </td><td style="text-align: left;"> Preprocessing recipe roles and steps </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Response variable types in the input specifications are defined by the user
with the functions and recipe roles:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <strong>Response Functions</strong>
    </td><td style="text-align: left;"> <code><a href="#topic+BinomialVariate">BinomialVariate</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="#topic+DiscreteVariate">DiscreteVariate</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="base.html#topic+factor">factor</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="base.html#topic+matrix">matrix</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="#topic+NegBinomialVariate">NegBinomialVariate</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="base.html#topic+numeric">numeric</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="base.html#topic+ordered">ordered</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="#topic+PoissonVariate">PoissonVariate</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="survival.html#topic+Surv">Surv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
  <strong>Recipe Roles</strong>
    </td><td style="text-align: left;"> <code><a href="#topic+role_binom">role_binom</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code><a href="#topic+role_surv">role_surv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Inputs may be combined, selected, or tuned with the following meta-input
functions.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+ModelSpecification">ModelSpecification</a></code> </td><td style="text-align: left;"> Model specification </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SelectedInput">SelectedInput</a></code> </td><td style="text-align: left;"> Input selection from a candidate set </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+TunedInput">TunedInput</a></code>    </td><td style="text-align: left;"> Input tuning over a parameter grid </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>

<hr>
<h2 id='KNNModel'>Weighted k-Nearest Neighbor Model</h2><span id='topic+KNNModel'></span>

<h3>Description</h3>

<p>Fit a k-nearest neighbor model for which the k nearest training set vectors
(according to Minkowski distance) are found for each row of the test set, and
prediction is done via the maximum of summed kernel densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KNNModel(
  k = 7,
  distance = 2,
  scale = TRUE,
  kernel = c("optimal", "biweight", "cos", "epanechnikov", "gaussian", "inv", "rank",
    "rectangular", "triangular", "triweight")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KNNModel_+3A_k">k</code></td>
<td>
<p>numer of neigbors considered.</p>
</td></tr>
<tr><td><code id="KNNModel_+3A_distance">distance</code></td>
<td>
<p>Minkowski distance parameter.</p>
</td></tr>
<tr><td><code id="KNNModel_+3A_scale">scale</code></td>
<td>
<p>logical indicating whether to scale predictors to have equal
standard deviations.</p>
</td></tr>
<tr><td><code id="KNNModel_+3A_kernel">kernel</code></td>
<td>
<p>kernel to use.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>ordinal</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>k</code>, <code>distance</code>*, <code>kernel</code>*
</p>
</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="kknn.html#topic+kknn">kknn</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package kknn to run

fit(Species ~ ., data = iris, model = KNNModel)


</code></pre>

<hr>
<h2 id='LARSModel'>Least Angle Regression, Lasso and Infinitesimal Forward Stagewise Models</h2><span id='topic+LARSModel'></span>

<h3>Description</h3>

<p>Fit variants of Lasso, and provide the entire sequence of coefficients and
fits, starting from zero to the least squares fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LARSModel(
  type = c("lasso", "lar", "forward.stagewise", "stepwise"),
  trace = FALSE,
  normalize = TRUE,
  intercept = TRUE,
  step = numeric(),
  use.Gram = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LARSModel_+3A_type">type</code></td>
<td>
<p>model type.</p>
</td></tr>
<tr><td><code id="LARSModel_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether status information is printed during
the fitting process.</p>
</td></tr>
<tr><td><code id="LARSModel_+3A_normalize">normalize</code></td>
<td>
<p>whether to standardize each variable to have unit L2 norm.</p>
</td></tr>
<tr><td><code id="LARSModel_+3A_intercept">intercept</code></td>
<td>
<p>whether to include an intercept in the model.</p>
</td></tr>
<tr><td><code id="LARSModel_+3A_step">step</code></td>
<td>
<p>algorithm step number to use for prediction.  May be a decimal
number indicating a fractional distance between steps.  If specified, the
maximum number of algorithm steps will be <code>ceiling(step)</code>; otherwise,
<code>step</code> will be set equal to the source package default maximum
[default: <code>max.steps</code>].</p>
</td></tr>
<tr><td><code id="LARSModel_+3A_use.gram">use.Gram</code></td>
<td>
<p>whether to precompute the Gram matrix.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>step</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="lars.html#topic+lars">lars</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package lars to run

fit(sale_amount ~ ., data = ICHomes, model = LARSModel)


</code></pre>

<hr>
<h2 id='LDAModel'>Linear Discriminant Analysis Model</h2><span id='topic+LDAModel'></span>

<h3>Description</h3>

<p>Performs linear discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDAModel(
  prior = numeric(),
  tol = 1e-04,
  method = c("moment", "mle", "mve", "t"),
  nu = 5,
  dimen = integer(),
  use = c("plug-in", "debiased", "predictive")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LDAModel_+3A_prior">prior</code></td>
<td>
<p>prior probabilities of class membership if specified or the
class proportions in the training set otherwise.</p>
</td></tr>
<tr><td><code id="LDAModel_+3A_tol">tol</code></td>
<td>
<p>tolerance for the determination of singular matrices.</p>
</td></tr>
<tr><td><code id="LDAModel_+3A_method">method</code></td>
<td>
<p>type of mean and variance estimator.</p>
</td></tr>
<tr><td><code id="LDAModel_+3A_nu">nu</code></td>
<td>
<p>degrees of freedom for <code>method = "t"</code>.</p>
</td></tr>
<tr><td><code id="LDAModel_+3A_dimen">dimen</code></td>
<td>
<p>dimension of the space to use for prediction.</p>
</td></tr>
<tr><td><code id="LDAModel_+3A_use">use</code></td>
<td>
<p>type of parameter estimation to use for prediction.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>dimen</code>
</p>
</dd>
</dl>

<p>The <code><a href="#topic+predict">predict</a></code> function for this model additionally accepts the
following argument.
</p>

<dl>
<dt><code>prior</code></dt><dd><p>prior class membership probabilities for prediction
data if different from the training set.</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+lda">lda</a></code>, <code><a href="MASS.html#topic+predict.lda">predict.lda</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(Species ~ ., data = iris, model = LDAModel)

</code></pre>

<hr>
<h2 id='lift'>Model Lift Curves</h2><span id='topic+lift'></span>

<h3>Description</h3>

<p>Calculate lift curves from observed and predicted responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lift(x, y = NULL, weights = NULL, na.rm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lift_+3A_x">x</code></td>
<td>
<p><a href="#topic+response">observed responses</a> or <a href="#topic+resample">resample</a> result
containing observed and predicted responses.</p>
</td></tr>
<tr><td><code id="lift_+3A_y">y</code></td>
<td>
<p><a href="#topic+predict">predicted responses</a> if not contained in <code>x</code>.</p>
</td></tr>
<tr><td><code id="lift_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative
<a href="#topic+case_weights">case weights</a> for the observed <code>x</code> responses
[default: equal weights].</p>
</td></tr>
<tr><td><code id="lift_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to remove observed or predicted
responses that are <code>NA</code> when calculating metrics.</p>
</td></tr>
<tr><td><code id="lift_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>LiftCurve</code> class object that inherits from
<code>PerformanceCurve</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+c">c</a></code>, <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

data(Pima.tr, package = "MASS")

res &lt;- resample(type ~ ., data = Pima.tr, model = GBMModel)
lf &lt;- lift(res)
plot(lf)


</code></pre>

<hr>
<h2 id='LMModel'>Linear Models</h2><span id='topic+LMModel'></span>

<h3>Description</h3>

<p>Fits linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LMModel()
</code></pre>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>matrix</code>, <code>numeric</code></p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>LModel</code>, numeric argument
<code>base</code> may be specified for the (negative) logarithmic transformation of
p-values [defaul: <code>exp(1)</code>].  Transformed p-values are automatically
scaled in the calculation of variable importance to range from 0 to 100.  To
obtain unscaled importance values, set <code>scale = FALSE</code>.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(sale_amount ~ ., data = ICHomes, model = LMModel)

</code></pre>

<hr>
<h2 id='MDAModel'>Mixture Discriminant Analysis Model</h2><span id='topic+MDAModel'></span>

<h3>Description</h3>

<p>Performs mixture discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDAModel(
  subclasses = 3,
  sub.df = numeric(),
  tot.df = numeric(),
  dimension = sum(subclasses) - 1,
  eps = .Machine$double.eps,
  iter = 5,
  method = .(mda::polyreg),
  trace = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MDAModel_+3A_subclasses">subclasses</code></td>
<td>
<p>numeric value or vector of subclasses per class.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_sub.df">sub.df</code></td>
<td>
<p>effective degrees of freedom of the centroids per class if
subclass centroid shrinkage is performed.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_tot.df">tot.df</code></td>
<td>
<p>specification of the total degrees of freedom as an alternative
to <code>sub.df</code>.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_dimension">dimension</code></td>
<td>
<p>dimension of the discriminant subspace to use for
prediction.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_eps">eps</code></td>
<td>
<p>numeric threshold for automatically truncating the dimension.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_iter">iter</code></td>
<td>
<p>limit on the total number of iterations.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_method">method</code></td>
<td>
<p>regression function used in optimal scaling.  The default of
linear regression is provided by <code><a href="mda.html#topic+polyreg">polyreg</a></code> from the
<span class="pkg">mda</span> package.  For penalized mixture discriminant models,
<code><a href="mda.html#topic+gen.ridge">gen.ridge</a></code> is appropriate.  Other possibilities are
<code><a href="mda.html#topic+mars">mars</a></code> for multivariate adaptive regression splines and
<code><a href="mda.html#topic+bruto">bruto</a></code> for adaptive backfitting of additive splines.  Use
the <code><a href="#topic+quote">.</a></code> operator to quote specified functions.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether iteration information is printed.</p>
</td></tr>
<tr><td><code id="MDAModel_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>mda.start</code> and <code>method</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>subclasses</code>
</p>
</dd>
</dl>

<p>The <code><a href="#topic+predict">predict</a></code> function for this model additionally accepts the
following argument.
</p>

<dl>
<dt><code>prior</code></dt><dd><p>prior class membership probabilities for prediction data
if different from the training set.</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="mda.html#topic+mda">mda</a></code>, <code><a href="mda.html#topic+predict.mda">predict.mda</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package mda to run

fit(Species ~ ., data = iris, model = MDAModel)


</code></pre>

<hr>
<h2 id='metricinfo'>Display Performance Metric Information</h2><span id='topic+metricinfo'></span>

<h3>Description</h3>

<p>Display information about metrics provided by the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metricinfo(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metricinfo_+3A_...">...</code></td>
<td>
<p><a href="#topic+metrics">metric</a> functions or function names;
<a href="#topic+response">observed responses</a>; <a href="#topic+response">observed</a> and
<a href="#topic+predict">predicted</a> responses; <a href="#topic+confusion">confusion</a> or <a href="#topic+resample">resample</a>
results for which to display information.  If none are specified, information
is returned on all available metrics by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of named metric elements each containing the following
components:
</p>

<dl>
<dt>label</dt><dd><p>character descriptor for the metric.</p>
</dd>
<dt>maximize</dt><dd><p>logical indicating whether higher values of the metric
correspond to better predictive performance.</p>
</dd>
<dt>arguments</dt><dd><p>closure with the argument names and corresponding default
values of the metric function.</p>
</dd>
<dt>response_types</dt><dd><p>data frame of the observed and predicted response
variable types supported by the metric.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## All metrics
metricinfo()

## Metrics by observed and predicted response types
names(metricinfo(factor(0)))
names(metricinfo(factor(0), factor(0)))
names(metricinfo(factor(0), matrix(0)))
names(metricinfo(factor(0), numeric(0)))

## Metric-specific information
metricinfo(auc)

</code></pre>

<hr>
<h2 id='metrics'>Performance Metrics</h2><span id='topic+metrics'></span><span id='topic+accuracy'></span><span id='topic+auc'></span><span id='topic+brier'></span><span id='topic+cindex'></span><span id='topic+cross_entropy'></span><span id='topic+f_score'></span><span id='topic+fnr'></span><span id='topic+fpr'></span><span id='topic+kappa2'></span><span id='topic+npv'></span><span id='topic+ppr'></span><span id='topic+ppv'></span><span id='topic+pr_auc'></span><span id='topic+precision'></span><span id='topic+recall'></span><span id='topic+roc_auc'></span><span id='topic+roc_index'></span><span id='topic+sensitivity'></span><span id='topic+specificity'></span><span id='topic+tnr'></span><span id='topic+tpr'></span><span id='topic+weighted_kappa2'></span><span id='topic+gini'></span><span id='topic+mae'></span><span id='topic+mse'></span><span id='topic+msle'></span><span id='topic+r2'></span><span id='topic+rmse'></span><span id='topic+rmsle'></span>

<h3>Description</h3>

<p>Compute measures of agreement between observed and predicted responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracy(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

auc(
  observed,
  predicted = NULL,
  weights = NULL,
  multiclass = c("pairs", "all"),
  metrics = c(MachineShop::tpr, MachineShop::fpr),
  stat = MachineShop::settings("stat.Curve"),
  ...
)

brier(observed, predicted = NULL, weights = NULL, ...)

cindex(observed, predicted = NULL, weights = NULL, ...)

cross_entropy(observed, predicted = NULL, weights = NULL, ...)

f_score(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  beta = 1,
  ...
)

fnr(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

fpr(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

kappa2(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

npv(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

ppr(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

ppv(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

pr_auc(
  observed,
  predicted = NULL,
  weights = NULL,
  multiclass = c("pairs", "all"),
  ...
)

precision(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

recall(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

roc_auc(
  observed,
  predicted = NULL,
  weights = NULL,
  multiclass = c("pairs", "all"),
  ...
)

roc_index(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  fun = function(sensitivity, specificity) (sensitivity + specificity)/2,
  ...
)

sensitivity(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

specificity(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

tnr(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

tpr(
  observed,
  predicted = NULL,
  weights = NULL,
  cutoff = MachineShop::settings("cutoff"),
  ...
)

weighted_kappa2(observed, predicted = NULL, weights = NULL, power = 1, ...)

gini(observed, predicted = NULL, weights = NULL, ...)

mae(observed, predicted = NULL, weights = NULL, ...)

mse(observed, predicted = NULL, weights = NULL, ...)

msle(observed, predicted = NULL, weights = NULL, ...)

r2(
  observed,
  predicted = NULL,
  weights = NULL,
  method = c("mse", "pearson", "spearman"),
  distr = character(),
  ...
)

rmse(observed, predicted = NULL, weights = NULL, ...)

rmsle(observed, predicted = NULL, weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metrics_+3A_observed">observed</code></td>
<td>
<p><a href="#topic+response">observed responses</a>; or
<a href="#topic+confusion">confusion</a>, <a href="#topic+curves">performance curve</a>, or <a href="#topic+resample">resample</a>
result containing observed and predicted responses.</p>
</td></tr>
<tr><td><code id="metrics_+3A_predicted">predicted</code></td>
<td>
<p><a href="#topic+predict">predicted responses</a> if not contained in
<code>observed</code>.</p>
</td></tr>
<tr><td><code id="metrics_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative
<a href="#topic+case_weights">case weights</a> for the observed responses [default:
equal weights].</p>
</td></tr>
<tr><td><code id="metrics_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric (0, 1) threshold above which binary factor
probabilities are classified as events and below which survival
probabilities are classified.  If <code>NULL</code>, then confusion matrix-based
metrics are computed on predicted class probabilities if given.</p>
</td></tr>
<tr><td><code id="metrics_+3A_...">...</code></td>
<td>
<p>arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="metrics_+3A_multiclass">multiclass</code></td>
<td>
<p>character string specifying the method for computing
generalized area under the performance curve for multiclass factor
responses.  Options are to average over areas for each pair of classes
(<code>"pairs"</code>) or for each class versus all others (<code>"all"</code>).</p>
</td></tr>
<tr><td><code id="metrics_+3A_metrics">metrics</code></td>
<td>
<p>vector of two metric functions or function names that define a
curve under which to calculate area [default: ROC metrics].</p>
</td></tr>
<tr><td><code id="metrics_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic at each cutoff value of resampled metrics in performance
curves, or <code>NULL</code> for resample-specific metrics.</p>
</td></tr>
<tr><td><code id="metrics_+3A_beta">beta</code></td>
<td>
<p>relative importance of recall to precision in the calculation of
<code>f_score</code> [default: F1 score].</p>
</td></tr>
<tr><td><code id="metrics_+3A_fun">fun</code></td>
<td>
<p>function to calculate a desired sensitivity-specificity tradeoff.</p>
</td></tr>
<tr><td><code id="metrics_+3A_power">power</code></td>
<td>
<p>power to which positional distances of off-diagonals from the
main diagonal in confusion matrices are raised to calculate
<code>weighted_kappa2</code>.</p>
</td></tr>
<tr><td><code id="metrics_+3A_method">method</code></td>
<td>
<p>character string specifying whether to compute <code>r2</code> as
the coefficient of determination (<code>"mse"</code>) or as the square of
<code>"pearson"</code> or <code>"spearman"</code> correlation.</p>
</td></tr>
<tr><td><code id="metrics_+3A_distr">distr</code></td>
<td>
<p>character string specifying a distribution with which to
estimate the observed survival mean in the total sum of square component of
<code>r2</code>.  Possible values are <code>"empirical"</code> for the Kaplan-Meier
estimator, <code>"exponential"</code>, <code>"extreme"</code>, <code>"gaussian"</code>,
<code>"loggaussian"</code>, <code>"logistic"</code>, <code>"loglogistic"</code>,
<code>"lognormal"</code>, <code>"rayleigh"</code>, <code>"t"</code>, or <code>"weibull"</code>.
Defaults to the distribution that was used in predicting mean survival
times.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hand, D. J., &amp; Till, R. J. (2001). A simple generalisation of the area under
the ROC curve for multiple class classification problems. <em>Machine
Learning</em>, <em>45</em>, 171-186.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+metricinfo">metricinfo</a></code>, <code><a href="#topic+performance">performance</a></code>
</p>

<hr>
<h2 id='MLControl'>Resampling Controls</h2><span id='topic+MLControl'></span><span id='topic+controls'></span><span id='topic+BootControl'></span><span id='topic+BootOptimismControl'></span><span id='topic+CVControl'></span><span id='topic+CVOptimismControl'></span><span id='topic+OOBControl'></span><span id='topic+SplitControl'></span><span id='topic+TrainControl'></span>

<h3>Description</h3>

<p>Structures to define and control sampling methods for estimation of model
predictive performance in the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BootControl(
  samples = 25,
  weights = TRUE,
  seed = sample(.Machine$integer.max, 1)
)

BootOptimismControl(
  samples = 25,
  weights = TRUE,
  seed = sample(.Machine$integer.max, 1)
)

CVControl(
  folds = 10,
  repeats = 1,
  weights = TRUE,
  seed = sample(.Machine$integer.max, 1)
)

CVOptimismControl(
  folds = 10,
  repeats = 1,
  weights = TRUE,
  seed = sample(.Machine$integer.max, 1)
)

OOBControl(
  samples = 25,
  weights = TRUE,
  seed = sample(.Machine$integer.max, 1)
)

SplitControl(
  prop = 2/3,
  weights = TRUE,
  seed = sample(.Machine$integer.max, 1)
)

TrainControl(weights = TRUE, seed = sample(.Machine$integer.max, 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MLControl_+3A_samples">samples</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="MLControl_+3A_weights">weights</code></td>
<td>
<p>logical indicating whether to return case weights in resampled
output for the calculation of performance <a href="#topic+metrics">metrics</a>.</p>
</td></tr>
<tr><td><code id="MLControl_+3A_seed">seed</code></td>
<td>
<p>integer to set the seed at the start of resampling.</p>
</td></tr>
<tr><td><code id="MLControl_+3A_folds">folds</code></td>
<td>
<p>number of cross-validation folds (K).</p>
</td></tr>
<tr><td><code id="MLControl_+3A_repeats">repeats</code></td>
<td>
<p>number of repeats of the K-fold partitioning.</p>
</td></tr>
<tr><td><code id="MLControl_+3A_prop">prop</code></td>
<td>
<p>proportion of cases to include in the training set
(<code>0 &lt; prop &lt; 1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BootControl</code> constructs an <code>MLControl</code> object for simple bootstrap
resampling in which models are fit with bootstrap resampled training sets and
used to predict the full data set (Efron and Tibshirani 1993).
</p>
<p><code>BootOptimismControl</code> constructs an <code>MLControl</code> object for
optimism-corrected bootstrap resampling (Efron and Gong 1983, Harrell et al.
1996).
</p>
<p><code>CVControl</code> constructs an <code>MLControl</code> object for repeated K-fold
cross-validation (Kohavi 1995).  In this procedure, the full data set is
repeatedly partitioned into K-folds.  Within a partitioning, prediction is
performed on each of the K folds with models fit on all remaining folds.
</p>
<p><code>CVOptimismControl</code> constructs an <code>MLControl</code> object for
optimism-corrected cross-validation resampling (Davison and Hinkley 1997,
eq. 6.48).
</p>
<p><code>OOBControl</code> constructs an <code>MLControl</code> object for out-of-bootstrap
resampling in which models are fit with bootstrap resampled training sets and
used to predict the unsampled cases.
</p>
<p><code>SplitControl</code> constructs an <code>MLControl</code> object for splitting data
into a separate training and test set (Hastie et al. 2009).
</p>
<p><code>TrainControl</code> constructs an <code>MLControl</code> object for training and
performance evaluation to be performed on the same training set (Efron 1986).
</p>


<h3>Value</h3>

<p>Object that inherits from the <code>MLControl</code> class.
</p>


<h3>References</h3>

<p>Efron, B., &amp; Tibshirani, R. J. (1993). <em>An introduction to the
bootstrap</em>. Chapman &amp; Hall/CRC.
</p>
<p>Efron, B., &amp; Gong, G. (1983). A leisurely look at the bootstrap, the
jackknife, and cross-validation. <em>The American Statistician</em>,
<em>37</em>(1), 36-48.
</p>
<p>Harrell, F. E., Lee, K. L., &amp; Mark, D. B. (1996). Multivariable prognostic
models: Issues in developing models, evaluating assumptions and adequacy, and
measuring and reducing errors. <em>Statistics in Medicine</em>, <em>15</em>(4),
361-387.
</p>
<p>Kohavi, R. (1995). A study of cross-validation and bootstrap for accuracy
estimation and model selection. In <em>IJCAI'95: Proceedings of the 14th
International Joint Conference on Artificial Intelligence</em> (vol. 2, pp.
1137-1143). Morgan Kaufmann Publishers Inc.
</p>
<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap methods and their
application</em>. Cambridge University Press.
</p>
<p>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The elements of
statistical learning: data mining, inference, and prediction</em> (2nd ed.).
Springer.
</p>
<p>Efron, B. (1986). How biased is the apparent error rate of a prediction rule?
<em>Journal of the American Statistical Association</em>, <em>81</em>(394),
461-70.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+set_monitor">set_monitor</a></code>, <code><a href="#topic+set_predict">set_predict</a></code>,
<code><a href="#topic+set_strata">set_strata</a></code>,
<code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+SelectedInput">SelectedInput</a></code>,
<code><a href="#topic+SelectedModel">SelectedModel</a></code>, <code><a href="#topic+TunedInput">TunedInput</a></code>,
<code><a href="#topic+TunedModel">TunedModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Bootstrapping with 100 samples
BootControl(samples = 100)

## Optimism-corrected bootstrapping with 100 samples
BootOptimismControl(samples = 100)

## Cross-validation with 5 repeats of 10 folds
CVControl(folds = 10, repeats = 5)

## Optimism-corrected cross-validation with 5 repeats of 10 folds
CVOptimismControl(folds = 10, repeats = 5)

## Out-of-bootstrap validation with 100 samples
OOBControl(samples = 100)

## Split sample validation with 2/3 training and 1/3 testing
SplitControl(prop = 2/3)

## Training set evaluation
TrainControl()

</code></pre>

<hr>
<h2 id='MLMetric'>MLMetric Class Constructor</h2><span id='topic+MLMetric'></span><span id='topic+MLMetric+3C-'></span>

<h3>Description</h3>

<p>Create a performance metric for use with the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLMetric(object, name = "MLMetric", label = name, maximize = TRUE)

MLMetric(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MLMetric_+3A_object">object</code></td>
<td>
<p>function to compute the metric, defined to accept
<code>observed</code> and <code>predicted</code> as the first two arguments and with an
ellipsis (<code>...</code>) to accommodate others.</p>
</td></tr>
<tr><td><code id="MLMetric_+3A_name">name</code></td>
<td>
<p>character name of the object to which the metric is assigned.</p>
</td></tr>
<tr><td><code id="MLMetric_+3A_label">label</code></td>
<td>
<p>optional character descriptor for the model.</p>
</td></tr>
<tr><td><code id="MLMetric_+3A_maximize">maximize</code></td>
<td>
<p>logical indicating whether higher values of the metric
correspond to better predictive performance.</p>
</td></tr>
<tr><td><code id="MLMetric_+3A_value">value</code></td>
<td>
<p>list of arguments to pass to the <code>MLMetric</code> constructor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>MLMetric</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+metrics">metrics</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f2_score &lt;- MLMetric(
  function(observed, predicted, ...) {
    f_score(observed, predicted, beta = 2, ...)
  },
  name = "f2_score",
  label = "F Score (beta = 2)",
  maximize = TRUE
)

</code></pre>

<hr>
<h2 id='MLModel'>MLModel and MLModelFunction Class Constructors</h2><span id='topic+MLModel'></span><span id='topic+MLModelFunction'></span>

<h3>Description</h3>

<p>Create a model or model function for use with the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLModel(
  name = "MLModel",
  label = name,
  packages = character(),
  response_types = character(),
  weights = FALSE,
  predictor_encoding = c(NA, "model.frame", "model.matrix"),
  na.rm = FALSE,
  params = list(),
  gridinfo = tibble::tibble(param = character(), get_values = list(), default =
    logical()),
  fit = function(formula, data, weights, ...) stop("No fit function."),
  predict = function(object, newdata, times, ...) stop("No predict function."),
  varimp = function(object, ...) NULL,
  ...
)

MLModelFunction(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MLModel_+3A_name">name</code></td>
<td>
<p>character name of the object to which the model is assigned.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_label">label</code></td>
<td>
<p>optional character descriptor for the model.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_packages">packages</code></td>
<td>
<p>character vector of package names upon which the model
depends.  Each name may be optionally followed by a comment in
parentheses specifying a version requirement.  The comment should contain
a comparison operator, whitespace and a valid version number, e.g.
<code>"xgboost (&gt;= 1.3.0)"</code>.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_response_types">response_types</code></td>
<td>
<p>character vector of response variable types to which
the model can be fit.  Supported types are <code>"binary"</code>,
<code>"BinomialVariate"</code>, <code>"DiscreteVariate"</code>, <code>"factor"</code>,
<code>"matrix"</code>, <code>"NegBinomialVariate"</code>, <code>"numeric"</code>,
<code>"ordered"</code>, <code>"PoissonVariate"</code>, and <code>"Surv"</code>.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_weights">weights</code></td>
<td>
<p>logical value or vector of the same length as
<code>response_types</code> indicating whether case weights are supported for
the responses.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_predictor_encoding">predictor_encoding</code></td>
<td>
<p>character string indicating whether the model is
fit with predictor variables encoded as a <code>"<a href="stats.html#topic+model.frame">model.frame</a>"</code>,
a <code>"<a href="stats.html#topic+model.matrix">model.matrix</a>"</code>, or unspecified (default).</p>
</td></tr>
<tr><td><code id="MLModel_+3A_na.rm">na.rm</code></td>
<td>
<p>character string or logical specifying removal of <code>"all"</code>
(<code>TRUE</code>) cases with missing values from model fitting and prediction,
<code>"none"</code> (<code>FALSE</code>), or only those whose missing values are in the
<code>"response"</code> variable.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_params">params</code></td>
<td>
<p>list of user-specified model parameters to be passed to the
<code>fit</code> function.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_gridinfo">gridinfo</code></td>
<td>
<p>tibble of information for construction of tuning grids
consisting of a character column <code>param</code> with the names of parameters
in the grid, a list column <code>get_values</code> with functions to generate grid
points for the corresponding parameters, and an optional logical column
<code>default</code> indicating which parameters to include by default in regular
grids.  Values functions may optionally include arguments <code>n</code> and
<code>data</code> for the number of grid points to generate and a
<code><a href="#topic+ModelFrame">ModelFrame</a></code> of the model fit data and formula, respectively;
and must include an ellipsis (<code>...</code>).</p>
</td></tr>
<tr><td><code id="MLModel_+3A_fit">fit</code></td>
<td>
<p>model fitting function whose arguments are a <code>formula</code>, a
<code><a href="#topic+ModelFrame">ModelFrame</a></code> named <code>data</code>, case <code>weights</code>, and an
ellipsis.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_predict">predict</code></td>
<td>
<p>model prediction function whose arguments are the
<code>object</code> returned by <code>fit</code>, a <code><a href="#topic+ModelFrame">ModelFrame</a></code> named
<code>newdata</code> of predictor variables, optional vector of <code>times</code> at
which to predict survival, and an ellipsis.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_varimp">varimp</code></td>
<td>
<p>variable importance function whose arguments are the
<code>object</code> returned by <code>fit</code>, optional arguments passed from calls
to <code><a href="#topic+varimp">varimp</a></code>, and an ellipsis.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="MLModel_+3A_object">object</code></td>
<td>
<p>function that returns an <code>MLModel</code> object when called
without any supplied argument values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If supplied, the <code>grid</code> function should return a list whose elements are
named after and contain values of parameters to include in a tuning grid to
be constructed automatically by the package.
</p>
<p>Arguments <code>data</code> and <code>newdata</code> in the <code>fit</code> and <code>predict</code>
functions may be converted to data frames with <code>as.data.frame()</code>
if needed for their operation.  The <code>fit</code> function should return the
object resulting from the model fit.  Values returned by the <code>predict</code>
functions should be formatted according to the response variable types below.
</p>

<dl>
<dt>factor</dt><dd><p>matrix whose columns contain the probabilities for
multi-level factors or vector of probabilities for the second level of
binary factors.</p>
</dd>
<dt>matrix</dt><dd><p>matrix of predicted responses.</p>
</dd>
<dt>numeric</dt><dd><p>vector or column matrix of predicted responses.</p>
</dd>
<dt>Surv</dt><dd><p>matrix whose columns contain survival probabilities at
<code>times</code> if supplied or a vector of predicted survival means
otherwise.</p>
</dd>
</dl>

<p>The <code>varimp</code> function should return a vector of importance values named
after the predictor variables or a matrix or data frame whose rows are named
after the predictors.
</p>
<p>The <code>predict</code> and <code>varimp</code> functions are additionally passed a list
named <code>.MachineShop</code> containing the <code><a href="#topic+inputs">input</a></code>
and <code><a href="#topic+models">model</a></code> from <code><a href="#topic+fit">fit</a></code>.  This argument may
be included in the function definitions as needed for their implementations.
Otherwise, it will be captured by the ellipsis.
</p>


<h3>Value</h3>

<p>An <code>MLModel</code> or <code>MLModelFunction</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+models">models</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Logistic regression model
LogisticModel &lt;- MLModel(
  name = "LogisticModel",
  response_types = "binary",
  weights = TRUE,
  fit = function(formula, data, weights, ...) {
    glm(formula, data = as.data.frame(data), weights = weights,
        family = binomial, ...)
  },
  predict = function(object, newdata, ...) {
    predict(object, newdata = as.data.frame(newdata), type = "response")
  },
  varimp = function(object, ...) {
    pchisq(coef(object)^2 / diag(vcov(object)), 1)
  }
)

data(Pima.tr, package = "MASS")
res &lt;- resample(type ~ ., data = Pima.tr, model = LogisticModel)
summary(res)

</code></pre>

<hr>
<h2 id='ModelFrame'>ModelFrame Class</h2><span id='topic+ModelFrame'></span><span id='topic+ModelFrame.formula'></span><span id='topic+ModelFrame.matrix'></span>

<h3>Description</h3>

<p>Class for storing data, formulas, and other attributes for <span class="pkg">MachineShop</span>
model fitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ModelFrame(...)

## S3 method for class 'formula'
ModelFrame(
  formula,
  data,
  groups = NULL,
  strata = NULL,
  weights = NULL,
  na.rm = TRUE,
  ...
)

## S3 method for class 'matrix'
ModelFrame(
  x,
  y = NULL,
  offsets = NULL,
  groups = NULL,
  strata = NULL,
  weights = NULL,
  na.rm = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ModelFrame_+3A_...">...</code></td>
<td>
<p>arguments passed from the generic function to its methods.  The
first argument of each <code>ModelFrame</code> method is positional and, as such,
must be given first in calls to them.</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_formula">formula</code>, <code id="ModelFrame_+3A_data">data</code></td>
<td>
<p><a href="stats.html#topic+formula">formula</a> defining the model predictor and
response variables and a <a href="base.html#topic+data.frame">data frame</a> containing them.
In the associated method, arguments <code>groups</code>, <code>strata</code>, and
<code>weights</code> will be evaluated as expressions, whose objects are searched
for first in the accompanying <code>data</code> environment and, if not found
there, next in the calling environment.</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_groups">groups</code></td>
<td>
<p>vector of values defining groupings of case observations, such
as repeated measurements, to keep together during resampling [default:
none].</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_strata">strata</code></td>
<td>
<p>vector of values to use in conducting stratified
<a href="#topic+resample">resample</a> estimation of model performance [default: none].</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative case weights for the <code>y</code>
response variable [default: equal weights].</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_na.rm">na.rm</code></td>
<td>
<p>character string or logical specifying removal of <code>"all"</code>
(<code>TRUE</code>) cases with missing values, <code>"none"</code> (<code>FALSE</code>), or
only those whose missing values are in the <code>"response"</code> variable.</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_x">x</code>, <code id="ModelFrame_+3A_y">y</code></td>
<td>
<p><a href="base.html#topic+matrix">matrix</a> and object containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="ModelFrame_+3A_offsets">offsets</code></td>
<td>
<p>numeric vector, matrix, or data frame of values to be added
with a fixed coefficient of 1 to linear predictors in compatible regression
models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ModelFrame</code> class object that inherits from <code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+response">response</a></code>,
<code><a href="#topic+SelectedInput">SelectedInput</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

mf &lt;- ModelFrame(ncases / (ncases + ncontrols) ~ agegp + tobgp + alcgp,
                 data = esoph, weights = ncases + ncontrols)
gbm_fit &lt;- fit(mf, model = GBMModel)
varimp(gbm_fit)


</code></pre>

<hr>
<h2 id='modelinfo'>Display Model Information</h2><span id='topic+modelinfo'></span>

<h3>Description</h3>

<p>Display information about models supplied by the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelinfo(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modelinfo_+3A_...">...</code></td>
<td>
<p><a href="#topic+models">model</a> functions, function names, or objects;
<a href="#topic+response">observed responses</a> for which to display information.  If
none are specified, information is returned on all available models by
default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of named model elements each containing the following
components:
</p>

<dl>
<dt>label</dt><dd><p>character descriptor for the model.</p>
</dd>
<dt>packages</dt><dd><p>character vector of source packages required to use the
model.  These need only be installed with the
<code><a href="utils.html#topic+install.packages">install.packages</a></code> function or by equivalent means; but need
not be loaded with, for example, the <code><a href="base.html#topic+library">library</a></code> function.</p>
</dd>
<dt>response_types</dt><dd><p>character vector of response variable types supported
by the model.</p>
</dd>
<dt>weights</dt><dd><p>logical value or vector of the same length as
<code>response_types</code> indicating whether case weights are supported for
the responses.</p>
</dd>
<dt>arguments</dt><dd><p>closure with the argument names and corresponding default
values of the model function.</p>
</dd>
<dt>grid</dt><dd><p>logical indicating whether automatic generation of tuning
parameter grids is implemented for the model.</p>
</dd>
<dt>varimp</dt><dd><p>logical indicating whether model-specific variable importance
is defined.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## All models
modelinfo()

## Models by response types
names(modelinfo(factor(0)))
names(modelinfo(factor(0), numeric(0)))

## Model-specific information
modelinfo(GBMModel)

</code></pre>

<hr>
<h2 id='models'>Models</h2><span id='topic+models'></span>

<h3>Description</h3>

<p>Model constructor functions supplied by <span class="pkg">MachineShop</span> are summarized in
the table below according to the types of response variables with which each
can be used.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <strong>Function</strong> </td><td style="text-align: center;"> <strong>Categorical</strong> </td><td style="text-align: center;"> <strong>Continuous</strong>
  </td><td style="text-align: center;"> <strong>Survival</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+AdaBagModel">AdaBagModel</a></code>         </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+AdaBoostModel">AdaBoostModel</a></code>       </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BARTModel">BARTModel</a></code>           </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BARTMachineModel">BARTMachineModel</a></code>    </td><td style="text-align: center;"> b   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+BlackBoostModel">BlackBoostModel</a></code>     </td><td style="text-align: center;"> b   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+C50Model">C50Model</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+CForestModel">CForestModel</a></code>        </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+CoxModel">CoxModel</a></code>            </td><td style="text-align: center;">     </td><td style="text-align: center;">     </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+CoxStepAICModel">CoxStepAICModel</a></code>     </td><td style="text-align: center;">     </td><td style="text-align: center;">     </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+EarthModel">EarthModel</a></code>          </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+FDAModel">FDAModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GAMBoostModel">GAMBoostModel</a></code>       </td><td style="text-align: center;"> b   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GBMModel">GBMModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GLMBoostModel">GLMBoostModel</a></code>       </td><td style="text-align: center;"> b   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GLMModel">GLMModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> m,n </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GLMStepAICModel">GLMStepAICModel</a></code>     </td><td style="text-align: center;"> b   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+GLMNetModel">GLMNetModel</a></code>         </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> m,n </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+KNNModel">KNNModel</a></code>            </td><td style="text-align: center;"> f,o </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+LARSModel">LARSModel</a></code>           </td><td style="text-align: center;">     </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+LDAModel">LDAModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+LMModel">LMModel</a></code>             </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> m,n </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+MDAModel">MDAModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+NaiveBayesModel">NaiveBayesModel</a></code>     </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+NNetModel">NNetModel</a></code>           </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+ParsnipModel">ParsnipModel</a></code>        </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> m,n </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+PDAModel">PDAModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+PLSModel">PLSModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+POLRModel">POLRModel</a></code>           </td><td style="text-align: center;"> o   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+QDAModel">QDAModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;">     </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+RandomForestModel">RandomForestModel</a></code>   </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+RangerModel">RangerModel</a></code>         </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+RFSRCModel">RFSRCModel</a></code>          </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> m,n </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+RFSRCFastModel">RFSRCFastModel</a></code>      </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> m,n </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+RPartModel">RPartModel</a></code>          </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SurvRegModel">SurvRegModel</a></code>        </td><td style="text-align: center;">     </td><td style="text-align: center;">     </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SurvRegStepAICModel">SurvRegStepAICModel</a></code> </td><td style="text-align: center;">     </td><td style="text-align: center;">     </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMModel">SVMModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMANOVAModel">SVMANOVAModel</a></code>       </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMBesselModel">SVMBesselModel</a></code>      </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMLaplaceModel">SVMLaplaceModel</a></code>     </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMLinearModel">SVMLinearModel</a></code>      </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMPolyModel">SVMPolyModel</a></code>        </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMRadialModel">SVMRadialModel</a></code>      </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMSplineModel">SVMSplineModel</a></code>      </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SVMTanhModel">SVMTanhModel</a></code>        </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+TreeModel">TreeModel</a></code>           </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;">   </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+XGBModel">XGBModel</a></code>            </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+XGBDARTModel">XGBDARTModel</a></code>        </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+XGBLinearModel">XGBLinearModel</a></code>      </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+XGBTreeModel">XGBTreeModel</a></code>        </td><td style="text-align: center;"> f   </td><td style="text-align: center;"> n   </td><td style="text-align: center;"> S </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Categorical: b = binary, f = factor, o = ordered<br />
Continuous: m = matrix, n = numeric<br />
Survival: S = Surv<br />
<br />
Models may be combined, tuned, or selected with the following meta-model
functions.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+ModelSpecification">ModelSpecification</a></code> </td><td style="text-align: left;"> Model specification </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+StackedModel">StackedModel</a></code>  </td><td style="text-align: left;"> Stacked regression </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SuperModel">SuperModel</a></code>    </td><td style="text-align: left;"> Super learner </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+SelectedModel">SelectedModel</a></code> </td><td style="text-align: left;"> Model selection from a candidate set </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code><a href="#topic+TunedModel">TunedModel</a></code>    </td><td style="text-align: left;"> Model tuning over a parameter grid </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>See Also</h3>

<p><code><a href="#topic+modelinfo">modelinfo</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>

<hr>
<h2 id='ModelSpecification'>Model Specification</h2><span id='topic+ModelSpecification'></span><span id='topic+ModelSpecification.default'></span><span id='topic+ModelSpecification.formula'></span><span id='topic+ModelSpecification.matrix'></span><span id='topic+ModelSpecification.ModelFrame'></span><span id='topic+ModelSpecification.recipe'></span>

<h3>Description</h3>

<p>Specification of a relationship between response and predictor variables and
a model to define a relationship between them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ModelSpecification(...)

## Default S3 method:
ModelSpecification(
  input,
  model,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams"),
  ...
)

## S3 method for class 'formula'
ModelSpecification(formula, data, model, ...)

## S3 method for class 'matrix'
ModelSpecification(x, y, model, ...)

## S3 method for class 'ModelFrame'
ModelSpecification(input, model, ...)

## S3 method for class 'recipe'
ModelSpecification(input, model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ModelSpecification_+3A_...">...</code></td>
<td>
<p>arguments passed from the generic function to its methods.  The
first argument of each <code>ModelSpecification</code> method is positional and,
as such, must be given first in calls to them.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_input">input</code></td>
<td>
<p><a href="#topic+inputs">input</a> object defining and containing the model
predictor and response variables.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_model">model</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object; or
another object that can be <a href="#topic+as.MLModel">coerced</a> to a model.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.  If <code>NULL</code> or if
the model specification contains any <code>SelectedInput</code> or
<code>SelectedModel</code> objects, then object-specific control structures and
training parameters are used for selection and tuning, as usual, and
objects are trained sequentially with nested resampling.  Otherwise,
</p>

<ul>
<li><p> tuning of input and model objects is performed simultaneously over
a global grid of their parameter values, and
</p>
</li>
<li><p> the specified <code>control</code> method and training parameters below
override those of any included <code>TunedInput</code> or <code>TunedModel</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.  If not specified, default
metrics defined in the <a href="#topic+performance">performance</a> functions are used.  Model
selection is based on the first calculated metric.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_cutoff">cutoff</code></td>
<td>
<p>argument passed to the <code>metrics</code> functions.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic on resampled metric values for model tuning.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_formula">formula</code>, <code id="ModelSpecification_+3A_data">data</code></td>
<td>
<p><a href="stats.html#topic+formula">formula</a> defining the model predictor and
response variables and a <a href="base.html#topic+data.frame">data frame</a> containing them.</p>
</td></tr>
<tr><td><code id="ModelSpecification_+3A_x">x</code>, <code id="ModelSpecification_+3A_y">y</code></td>
<td>
<p><a href="base.html#topic+matrix">matrix</a> and object containing predictor and response
variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ModelSpecification</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>,
<code><a href="#topic+set_monitor">set_monitor</a></code>, <code><a href="#topic+set_optim">set_optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

modelspec &lt;- ModelSpecification(
  sale_amount ~ ., data = ICHomes, model = GBMModel
)
fit(modelspec)


</code></pre>

<hr>
<h2 id='NaiveBayesModel'>Naive Bayes Classifier Model</h2><span id='topic+NaiveBayesModel'></span>

<h3>Description</h3>

<p>Computes the conditional a-posterior probabilities of a categorical class
variable given independent predictor variables using Bayes rule.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NaiveBayesModel(laplace = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NaiveBayesModel_+3A_laplace">laplace</code></td>
<td>
<p>positive numeric controlling Laplace smoothing.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package e1071 to run

fit(Species ~ ., data = iris, model = NaiveBayesModel)


</code></pre>

<hr>
<h2 id='NNetModel'>Neural Network Model</h2><span id='topic+NNetModel'></span>

<h3>Description</h3>

<p>Fit single-hidden-layer neural network, possibly with skip-layer connections.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NNetModel(
  size = 1,
  linout = logical(),
  entropy = logical(),
  softmax = logical(),
  censored = FALSE,
  skip = FALSE,
  rang = 0.7,
  decay = 0,
  maxit = 100,
  trace = FALSE,
  MaxNWts = 1000,
  abstol = 1e-04,
  reltol = 1e-08
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NNetModel_+3A_size">size</code></td>
<td>
<p>number of units in the hidden layer.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_linout">linout</code></td>
<td>
<p>switch for linear output units.  Set automatically according to
the class type of the response variable [numeric: <code>TRUE</code>, other:
<code>FALSE</code>].</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_entropy">entropy</code></td>
<td>
<p>switch for entropy (= maximum conditional likelihood) fitting.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_softmax">softmax</code></td>
<td>
<p>switch for softmax (log-linear model) and maximum conditional
likelihood fitting.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_censored">censored</code></td>
<td>
<p>a variant on softmax, in which non-zero targets mean possible
classes.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_skip">skip</code></td>
<td>
<p>switch to add skip-layer connections from input to output.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_rang">rang</code></td>
<td>
<p>Initial random weights on [<code>-rang</code>, <code>rang</code>].</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_decay">decay</code></td>
<td>
<p>parameter for weight decay.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_trace">trace</code></td>
<td>
<p>switch for tracing optimization.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_maxnwts">MaxNWts</code></td>
<td>
<p>maximum allowable number of weights.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_abstol">abstol</code></td>
<td>
<p>stop if the fit criterion falls below <code>abstol</code>, indicating
an essentially perfect fit.</p>
</td></tr>
<tr><td><code id="NNetModel_+3A_reltol">reltol</code></td>
<td>
<p>stop if the optimizer is unable to reduce the fit criterion by
a factor of at least <code>1 - reltol</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>size</code>, <code>decay</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+nnet">nnet</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(sale_amount ~ ., data = ICHomes, model = NNetModel)

</code></pre>

<hr>
<h2 id='ParameterGrid'>Tuning Parameters Grid</h2><span id='topic+ParameterGrid'></span><span id='topic+ParameterGrid.param'></span><span id='topic+ParameterGrid.list'></span><span id='topic+ParameterGrid.parameters'></span>

<h3>Description</h3>

<p>Defines a tuning grid from a set of parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParameterGrid(...)

## S3 method for class 'param'
ParameterGrid(..., size = 3, random = FALSE)

## S3 method for class 'list'
ParameterGrid(object, size = 3, random = FALSE, ...)

## S3 method for class 'parameters'
ParameterGrid(object, size = 3, random = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ParameterGrid_+3A_...">...</code></td>
<td>
<p>named <code>param</code> objects as defined in the <span class="pkg">dials</span> package.</p>
</td></tr>
<tr><td><code id="ParameterGrid_+3A_size">size</code></td>
<td>
<p>single integer or vector of integers whose positions or names
match the given parameters and which specify the number of values used to
construct the grid.</p>
</td></tr>
<tr><td><code id="ParameterGrid_+3A_random">random</code></td>
<td>
<p>number of unique points to sample at random from the grid
defined by <code>size</code>, or <code>FALSE</code> for all points.</p>
</td></tr>
<tr><td><code id="ParameterGrid_+3A_object">object</code></td>
<td>
<p>list of named <code>param</code> objects or a
<code><a href="dials.html#topic+parameters">parameters</a></code> object.  This is a positional argument
that must be given first in calls to its methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ParameterGrid</code> class object that inherits from
<code>parameters</code> and <code>TuningGrid</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TunedModel">TunedModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## GBMModel tuning parameters
grid &lt;- ParameterGrid(
  n.trees = dials::trees(),
  interaction.depth = dials::tree_depth(),
  random = 5
)
TunedModel(GBMModel, grid = grid)

</code></pre>

<hr>
<h2 id='ParsnipModel'>Parsnip Model</h2><span id='topic+ParsnipModel'></span>

<h3>Description</h3>

<p>Convert a model specification from the <span class="pkg">parsnip</span> package to one that can
be used with the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParsnipModel(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ParsnipModel_+3A_object">object</code></td>
<td>
<p><a href="parsnip.html#topic+model_spec">model specification</a> from the
<span class="pkg">parsnip</span> package.</p>
</td></tr>
<tr><td><code id="ParsnipModel_+3A_...">...</code></td>
<td>
<p>tuning parameters with which to update <code>object</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ParsnipModel</code> class object that inherits from <code>MLModel</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.MLModel">as.MLModel</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package parsnip to run

prsp_model &lt;- parsnip::linear_reg(engine = "glmnet")

model &lt;- ParsnipModel(prsp_model, penalty = 1, mixture = 1)
model

model_fit &lt;- fit(sale_amount ~ ., data = ICHomes, model = model)
predict(model_fit)


</code></pre>

<hr>
<h2 id='performance'>Model Performance Metrics</h2><span id='topic+performance'></span><span id='topic+performance.BinomialVariate'></span><span id='topic+performance.factor'></span><span id='topic+performance.matrix'></span><span id='topic+performance.numeric'></span><span id='topic+performance.Surv'></span><span id='topic+performance.ConfusionList'></span><span id='topic+performance.ConfusionMatrix'></span><span id='topic+performance.MLModel'></span><span id='topic+performance.Resample'></span><span id='topic+performance.TrainingStep'></span>

<h3>Description</h3>

<p>Compute measures of model performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance(x, ...)

## S3 method for class 'BinomialVariate'
performance(
  x,
  y,
  weights = NULL,
  metrics = MachineShop::settings("metrics.numeric"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'factor'
performance(
  x,
  y,
  weights = NULL,
  metrics = MachineShop::settings("metrics.factor"),
  cutoff = MachineShop::settings("cutoff"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'matrix'
performance(
  x,
  y,
  weights = NULL,
  metrics = MachineShop::settings("metrics.matrix"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'numeric'
performance(
  x,
  y,
  weights = NULL,
  metrics = MachineShop::settings("metrics.numeric"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'Surv'
performance(
  x,
  y,
  weights = NULL,
  metrics = MachineShop::settings("metrics.Surv"),
  cutoff = MachineShop::settings("cutoff"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'ConfusionList'
performance(x, ...)

## S3 method for class 'ConfusionMatrix'
performance(x, metrics = MachineShop::settings("metrics.ConfusionMatrix"), ...)

## S3 method for class 'MLModel'
performance(x, ...)

## S3 method for class 'Resample'
performance(x, ...)

## S3 method for class 'TrainingStep'
performance(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="performance_+3A_x">x</code></td>
<td>
<p><a href="#topic+response">observed responses</a>; or <a href="#topic+confusion">confusion</a>, trained
model <a href="#topic+fit">fit</a>, <a href="#topic+resample">resample</a>, or <a href="#topic+rfe">rfe</a> result.</p>
</td></tr>
<tr><td><code id="performance_+3A_...">...</code></td>
<td>
<p>arguments passed from the <code>Resample</code> method to the response
type-specific methods or from the method for <code>ConfusionList</code> to
<code>ConfusionMatrix</code>.  Elliptical arguments in the response
type-specific methods are passed to <code>metrics</code> supplied as a single
<code><a href="#topic+metrics">MLMetric</a></code> function and are ignored otherwise.</p>
</td></tr>
<tr><td><code id="performance_+3A_y">y</code></td>
<td>
<p><a href="#topic+predict">predicted responses</a> if not contained in <code>x</code>.</p>
</td></tr>
<tr><td><code id="performance_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative
<a href="#topic+case_weights">case weights</a> for the observed <code>x</code> responses
[default: equal weights].</p>
</td></tr>
<tr><td><code id="performance_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.</p>
</td></tr>
<tr><td><code id="performance_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to remove observed or predicted
responses that are <code>NA</code> when calculating metrics.</p>
</td></tr>
<tr><td><code id="performance_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric (0, 1) threshold above which binary factor
probabilities are classified as events and below which survival
probabilities are classified.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

res &lt;- resample(Species ~ ., data = iris, model = GBMModel)
(perf &lt;- performance(res))
summary(perf)
plot(perf)

## Survival response example
library(survival)

gbm_fit &lt;- fit(Surv(time, status) ~ ., data = veteran, model = GBMModel)

obs &lt;- response(gbm_fit, newdata = veteran)
pred &lt;- predict(gbm_fit, newdata = veteran)
performance(obs, pred)


</code></pre>

<hr>
<h2 id='performance_curve'>Model Performance Curves</h2><span id='topic+performance_curve'></span><span id='topic+curves'></span><span id='topic+performance_curve.default'></span><span id='topic+performance_curve.Resample'></span>

<h3>Description</h3>

<p>Calculate curves for the analysis of tradeoffs between metrics for assessing
performance in classifying binary outcomes over the range of possible
cutoff probabilities.  Available curves include receiver operating
characteristic (ROC) and precision recall.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance_curve(x, ...)

## Default S3 method:
performance_curve(
  x,
  y,
  weights = NULL,
  metrics = c(MachineShop::tpr, MachineShop::fpr),
  na.rm = TRUE,
  ...
)

## S3 method for class 'Resample'
performance_curve(
  x,
  metrics = c(MachineShop::tpr, MachineShop::fpr),
  na.rm = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="performance_curve_+3A_x">x</code></td>
<td>
<p><a href="#topic+response">observed responses</a> or <a href="#topic+resample">resample</a> result
containing observed and predicted responses.</p>
</td></tr>
<tr><td><code id="performance_curve_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="performance_curve_+3A_y">y</code></td>
<td>
<p><a href="#topic+predict">predicted responses</a> if not contained in <code>x</code>.</p>
</td></tr>
<tr><td><code id="performance_curve_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative
<a href="#topic+case_weights">case weights</a> for the observed <code>x</code> responses
[default: equal weights].</p>
</td></tr>
<tr><td><code id="performance_curve_+3A_metrics">metrics</code></td>
<td>
<p>list of two performance <a href="#topic+metrics">metrics</a> for the analysis
[default: ROC metrics].  Precision recall curves can be obtained with
<code>c(precision, recall)</code>.</p>
</td></tr>
<tr><td><code id="performance_curve_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to remove observed or predicted
responses that are <code>NA</code> when calculating metrics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>PerformanceCurve</code> class object that inherits from
<code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+auc">auc</a></code>, <code><a href="#topic+c">c</a></code>, <code><a href="#topic+plot">plot</a></code>,
<code><a href="#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

data(Pima.tr, package = "MASS")

res &lt;- resample(type ~ ., data = Pima.tr, model = GBMModel)

## ROC curve
roc &lt;- performance_curve(res)
plot(roc)
auc(roc)


</code></pre>

<hr>
<h2 id='plot'>Model Performance Plots</h2><span id='topic+plot'></span><span id='topic+plot.Calibration'></span><span id='topic+plot.ConfusionList'></span><span id='topic+plot.ConfusionMatrix'></span><span id='topic+plot.LiftCurve'></span><span id='topic+plot.MLModel'></span><span id='topic+plot.PartialDependence'></span><span id='topic+plot.Performance'></span><span id='topic+plot.PerformanceCurve'></span><span id='topic+plot.Resample'></span><span id='topic+plot.TrainingStep'></span><span id='topic+plot.VariableImportance'></span>

<h3>Description</h3>

<p>Plot measures of model performance and predictor variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Calibration'
plot(x, type = c("line", "point"), se = FALSE, ...)

## S3 method for class 'ConfusionList'
plot(x, ...)

## S3 method for class 'ConfusionMatrix'
plot(x, ...)

## S3 method for class 'LiftCurve'
plot(
  x,
  find = numeric(),
  diagonal = TRUE,
  stat = MachineShop::settings("stat.Curve"),
  ...
)

## S3 method for class 'MLModel'
plot(
  x,
  metrics = NULL,
  stat = MachineShop::settings("stat.TrainingParams"),
  type = c("boxplot", "density", "errorbar", "line", "violin"),
  ...
)

## S3 method for class 'PartialDependence'
plot(x, stats = NULL, ...)

## S3 method for class 'Performance'
plot(
  x,
  metrics = NULL,
  stat = MachineShop::settings("stat.Resample"),
  type = c("boxplot", "density", "errorbar", "violin"),
  ...
)

## S3 method for class 'PerformanceCurve'
plot(
  x,
  type = c("tradeoffs", "cutoffs"),
  diagonal = FALSE,
  stat = MachineShop::settings("stat.Curve"),
  ...
)

## S3 method for class 'Resample'
plot(
  x,
  metrics = NULL,
  stat = MachineShop::settings("stat.Resample"),
  type = c("boxplot", "density", "errorbar", "violin"),
  ...
)

## S3 method for class 'TrainingStep'
plot(
  x,
  metrics = NULL,
  stat = MachineShop::settings("stat.TrainingParams"),
  type = c("boxplot", "density", "errorbar", "line", "violin"),
  ...
)

## S3 method for class 'VariableImportance'
plot(x, n = Inf, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p><a href="#topic+calibration">calibration</a>, <a href="#topic+confusion">confusion</a>, <a href="#topic+lift">lift</a>,
trained model <a href="#topic+fit">fit</a>, partial <a href="#topic+dependence">dependence</a>, <a href="#topic+performance">performance</a>,
<a href="#topic+curves">performance curve</a>, <a href="#topic+resample">resample</a>, <a href="#topic+rfe">rfe</a>, or
<a href="#topic+varimp">variable importance</a> result.</p>
</td></tr>
<tr><td><code id="plot_+3A_type">type</code></td>
<td>
<p>type of plot to construct.</p>
</td></tr>
<tr><td><code id="plot_+3A_se">se</code></td>
<td>
<p>logical indicating whether to include standard error bars.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="plot_+3A_find">find</code></td>
<td>
<p>numeric true positive rate at which to display reference lines
identifying the corresponding rates of positive predictions.</p>
</td></tr>
<tr><td><code id="plot_+3A_diagonal">diagonal</code></td>
<td>
<p>logical indicating whether to include a diagonal reference
line.</p>
</td></tr>
<tr><td><code id="plot_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic on resampled metrics for trained <code>MLModel</code> line
plots and <code>Resample</code> model ordering.  The original ordering is
preserved if a value of <code>NULL</code> is given.  For <code>LiftCurve</code> and
<code>PerformanceCurve</code> classes, plots are of resampled metrics aggregated
by the statistic if given or of resample-specific metrics if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_metrics">metrics</code></td>
<td>
<p>vector of numeric indexes or character names of performance
metrics to plot.</p>
</td></tr>
<tr><td><code id="plot_+3A_stats">stats</code></td>
<td>
<p>vector of numeric indexes or character names of partial
dependence summary statistics to plot.</p>
</td></tr>
<tr><td><code id="plot_+3A_n">n</code></td>
<td>
<p>number of most important variables to include in the plot.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Factor response example

fo &lt;- Species ~ .
control &lt;- CVControl()

gbm_fit &lt;- fit(fo, data = iris, model = GBMModel, control = control)
plot(varimp(gbm_fit))

gbm_res1 &lt;- resample(fo, iris, GBMModel(n.trees = 25), control)
gbm_res2 &lt;- resample(fo, iris, GBMModel(n.trees = 50), control)
gbm_res3 &lt;- resample(fo, iris, GBMModel(n.trees = 100), control)
plot(gbm_res3)

res &lt;- c(GBM1 = gbm_res1, GBM2 = gbm_res2, GBM3 = gbm_res3)
plot(res)


</code></pre>

<hr>
<h2 id='PLSModel'>Partial Least Squares Model</h2><span id='topic+PLSModel'></span>

<h3>Description</h3>

<p>Function to perform partial least squares regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLSModel(ncomp = 1, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PLSModel_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components to include in the model.</p>
</td></tr>
<tr><td><code id="PLSModel_+3A_scale">scale</code></td>
<td>
<p>logical indicating whether to scale the predictors by the
sample standard deviation.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>ncomp</code>
</p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="pls.html#topic+mvr">mvr</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package pls to run

fit(sale_amount ~ ., data = ICHomes, model = PLSModel)


</code></pre>

<hr>
<h2 id='POLRModel'>Ordered Logistic or Probit Regression Model</h2><span id='topic+POLRModel'></span>

<h3>Description</h3>

<p>Fit a logistic or probit regression model to an ordered factor response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>POLRModel(method = c("logistic", "probit", "loglog", "cloglog", "cauchit"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="POLRModel_+3A_method">method</code></td>
<td>
<p>logistic or probit or (complementary) log-log or cauchit
(corresponding to a Cauchy latent variable).</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>ordered</code></p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>POLRModel</code>, numeric argument
<code>base</code> may be specified for the (negative) logarithmic transformation of
p-values [defaul: <code>exp(1)</code>].  Transformed p-values are automatically
scaled in the calculation of variable importance to range from 0 to 100.  To
obtain unscaled importance values, set <code>scale = FALSE</code>.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+polr">polr</a></code>, <code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Boston, package = "MASS")

df &lt;- within(Boston,
             medv &lt;- cut(medv,
                         breaks = c(0, 10, 15, 20, 25, 50),
                         ordered = TRUE))
fit(medv ~ ., data = df, model = POLRModel)

</code></pre>

<hr>
<h2 id='predict'>Model Prediction</h2><span id='topic+predict'></span><span id='topic+predict.MLModelFit'></span><span id='topic+predict+2CMLModelFit-method'></span>

<h3>Description</h3>

<p>Predict outcomes with a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MLModelFit'
predict(
  object,
  newdata = NULL,
  times = numeric(),
  type = c("response", "raw", "numeric", "prob", "default"),
  cutoff = MachineShop::settings("cutoff"),
  distr = character(),
  method = character(),
  verbose = FALSE,
  ...
)

## S4 method for signature 'MLModelFit'
predict(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result.</p>
</td></tr>
<tr><td><code id="predict_+3A_newdata">newdata</code></td>
<td>
<p>optional <a href="base.html#topic+data.frame">data frame</a> with which to obtain
predictions.  If not specified, the training data will be used by default.</p>
</td></tr>
<tr><td><code id="predict_+3A_times">times</code></td>
<td>
<p>numeric vector of follow-up times at which to predict
survival events/probabilities or <code>NULL</code> for predicted survival means.</p>
</td></tr>
<tr><td><code id="predict_+3A_type">type</code></td>
<td>
<p>specifies prediction on the original outcome (<code>"response"</code>),
numeric (<code>"numeric"</code>), or probability (<code>"prob"</code>) scale; or
the <code>"raw"</code> predictions returned by the model.  Option
<code>"default"</code> is deprecated and will be removed in the future; use
<code>"raw"</code> instead.</p>
</td></tr>
<tr><td><code id="predict_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric (0, 1) threshold above which binary factor
probabilities are classified as events and below which survival
probabilities are classified.</p>
</td></tr>
<tr><td><code id="predict_+3A_distr">distr</code></td>
<td>
<p>character string specifying distributional approximations to
estimated survival curves.  Possible values are <code>"empirical"</code>,
<code>"exponential"</code>, <code>"rayleigh"</code>, or <code>"weibull"</code>; with defaults
of <code>"empirical"</code> for predicted survival events/probabilities and
<code>"weibull"</code> for predicted survival means.</p>
</td></tr>
<tr><td><code id="predict_+3A_method">method</code></td>
<td>
<p>character string specifying the empirical method of estimating
baseline survival curves for Cox proportional hazards-based models.
Choices are <code>"breslow"</code> or <code>"efron"</code> (default).</p>
</td></tr>
<tr><td><code id="predict_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating whether to display printed output generated
by some model-specific predict functions to aid in monitoring progress and
diagnosing errors.</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>arguments passed from the S4 to the S3 method.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion</a></code>, <code><a href="#topic+performance">performance</a></code>,
<code><a href="#topic+metrics">metrics</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Survival response example
library(survival)

gbm_fit &lt;- fit(Surv(time, status) ~ ., data = veteran, model = GBMModel)
predict(gbm_fit, newdata = veteran, times = c(90, 180, 360), type = "prob")


</code></pre>

<hr>
<h2 id='print'>Print MachineShop Objects</h2><span id='topic+print'></span><span id='topic+print.BinomialVariate'></span><span id='topic+print.Calibration'></span><span id='topic+print.DiscreteVariate'></span><span id='topic+print.ListOf'></span><span id='topic+print.MLControl'></span><span id='topic+print.MLMetric'></span><span id='topic+print.MLModel'></span><span id='topic+print.MLModelFunction'></span><span id='topic+print.ModelFrame'></span><span id='topic+print.ModelRecipe'></span><span id='topic+print.ModelSpecification'></span><span id='topic+print.Performance'></span><span id='topic+print.PerformanceCurve'></span><span id='topic+print.RecipeGrid'></span><span id='topic+print.Resample'></span><span id='topic+print.SurvMatrix'></span><span id='topic+print.SurvTimes'></span><span id='topic+print.TrainingStep'></span><span id='topic+print.VariableImportance'></span>

<h3>Description</h3>

<p>Print methods for objects defined in the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BinomialVariate'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'Calibration'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'DiscreteVariate'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'ListOf'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'MLControl'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'MLMetric'
print(x, ...)

## S3 method for class 'MLModel'
print(x, n = MachineShop::settings("print_max"), id = FALSE, ...)

## S3 method for class 'MLModelFunction'
print(x, ...)

## S3 method for class 'ModelFrame'
print(x, n = MachineShop::settings("print_max"), id = FALSE, data = TRUE, ...)

## S3 method for class 'ModelRecipe'
print(x, n = MachineShop::settings("print_max"), id = FALSE, data = TRUE, ...)

## S3 method for class 'ModelSpecification'
print(x, n = MachineShop::settings("print_max"), id = FALSE, ...)

## S3 method for class 'Performance'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'PerformanceCurve'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'RecipeGrid'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'Resample'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'SurvMatrix'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'SurvTimes'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'TrainingStep'
print(x, n = MachineShop::settings("print_max"), ...)

## S3 method for class 'VariableImportance'
print(x, n = MachineShop::settings("print_max"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print_+3A_x">x</code></td>
<td>
<p>object to print.</p>
</td></tr>
<tr><td><code id="print_+3A_n">n</code></td>
<td>
<p>integer number of models or data frame rows to show.</p>
</td></tr>
<tr><td><code id="print_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods, including the one described
below.
</p>

<dl>
<dt><code>level</code> = 0</dt><dd><p>current nesting level of the corresponding
object in recursive calls to <code>print</code>.  The amount of information
displayed decreases and increases with positive and negative levels,
respectively.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="print_+3A_id">id</code></td>
<td>
<p>logical indicating whether to show object identifiers.</p>
</td></tr>
<tr><td><code id="print_+3A_data">data</code></td>
<td>
<p>logical indicating whether to show model data.</p>
</td></tr>
</table>

<hr>
<h2 id='QDAModel'>Quadratic Discriminant Analysis Model</h2><span id='topic+QDAModel'></span>

<h3>Description</h3>

<p>Performs quadratic discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QDAModel(
  prior = numeric(),
  method = c("moment", "mle", "mve", "t"),
  nu = 5,
  use = c("plug-in", "predictive", "debiased", "looCV")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QDAModel_+3A_prior">prior</code></td>
<td>
<p>prior probabilities of class membership if specified or the
class proportions in the training set otherwise.</p>
</td></tr>
<tr><td><code id="QDAModel_+3A_method">method</code></td>
<td>
<p>type of mean and variance estimator.</p>
</td></tr>
<tr><td><code id="QDAModel_+3A_nu">nu</code></td>
<td>
<p>degrees of freedom for <code>method = "t"</code>.</p>
</td></tr>
<tr><td><code id="QDAModel_+3A_use">use</code></td>
<td>
<p>type of parameter estimation to use for prediction.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code></p>
</dd>
</dl>

<p>The <code><a href="#topic+predict">predict</a></code> function for this model additionally accepts the
following argument.
</p>

<dl>
<dt><code>prior</code></dt><dd><p>prior class membership probabilities for prediction data
if different from the training set.</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+qda">qda</a></code>, <code><a href="MASS.html#topic+predict.qda">predict.qda</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(Species ~ ., data = iris, model = QDAModel)

</code></pre>

<hr>
<h2 id='quote'>Quote Operator</h2><span id='topic+quote'></span><span id='topic+.'></span>

<h3>Description</h3>

<p>Shorthand notation for the <code><a href="base.html#topic+substitute">quote</a></code> function.
The quote operator simply returns its argument unevaluated and can be applied
to any <span class="rlang"><b>R</b></span> expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.(expr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quote_+3A_expr">expr</code></td>
<td>
<p>any syntactically valid <span class="rlang"><b>R</b></span> expression.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Useful for calling <a href="#topic+models">model functions</a> with quoted parameter
values defined in terms of one or more of the following variables.
</p>

<dl>
<dt><code>nobs</code></dt><dd><p>number of observations in data to be <a href="#topic+fit">fit</a>.</p>
</dd>
<dt><code>nvars</code></dt><dd><p>number of predictor variables.</p>
</dd>
<dt><code>y</code></dt><dd><p>the response variable.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The quoted (unevaluated) expression.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+substitute">quote</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Stepwise variable selection with BIC
glm_fit &lt;- fit(sale_amount ~ ., ICHomes, GLMStepAICModel(k = .(log(nobs))))
varimp(glm_fit)

</code></pre>

<hr>
<h2 id='RandomForestModel'>Random Forest Model</h2><span id='topic+RandomForestModel'></span>

<h3>Description</h3>

<p>Implementation of Breiman's random forest algorithm (based on Breiman and
Cutler's original Fortran code) for classification and regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RandomForestModel(
  ntree = 500,
  mtry = .(if (is.factor(y)) floor(sqrt(nvars)) else max(floor(nvars/3), 1)),
  replace = TRUE,
  nodesize = .(if (is.factor(y)) 1 else 5),
  maxnodes = integer()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RandomForestModel_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow.</p>
</td></tr>
<tr><td><code id="RandomForestModel_+3A_mtry">mtry</code></td>
<td>
<p>number of variables randomly sampled as candidates at each split.</p>
</td></tr>
<tr><td><code id="RandomForestModel_+3A_replace">replace</code></td>
<td>
<p>should sampling of cases be done with or without replacement?</p>
</td></tr>
<tr><td><code id="RandomForestModel_+3A_nodesize">nodesize</code></td>
<td>
<p>minimum size of terminal nodes.</p>
</td></tr>
<tr><td><code id="RandomForestModel_+3A_maxnodes">maxnodes</code></td>
<td>
<p>maximum number of terminal nodes trees in the forest can
have.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>mtry</code>, <code>nodesize</code>*
</p>
</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package randomForest to run

fit(sale_amount ~ ., data = ICHomes, model = RandomForestModel)


</code></pre>

<hr>
<h2 id='RangerModel'>Fast Random Forest Model</h2><span id='topic+RangerModel'></span>

<h3>Description</h3>

<p>Fast implementation of random forests or recursive partitioning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RangerModel(
  num.trees = 500,
  mtry = integer(),
  importance = c("impurity", "impurity_corrected", "permutation"),
  min.node.size = integer(),
  replace = TRUE,
  sample.fraction = if (replace) 1 else 0.632,
  splitrule = character(),
  num.random.splits = 1,
  alpha = 0.5,
  minprop = 0.1,
  split.select.weights = numeric(),
  always.split.variables = character(),
  respect.unordered.factors = character(),
  scale.permutation.importance = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RangerModel_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_mtry">mtry</code></td>
<td>
<p>number of variables to possibly split at in each node.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_importance">importance</code></td>
<td>
<p>variable importance mode.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_min.node.size">min.node.size</code></td>
<td>
<p>minimum node size.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to sample with replacement.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_sample.fraction">sample.fraction</code></td>
<td>
<p>fraction of observations to sample.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_splitrule">splitrule</code></td>
<td>
<p>splitting rule.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_num.random.splits">num.random.splits</code></td>
<td>
<p>number of random splits to consider for each
candidate splitting variable in the <code>"extratrees"</code> rule.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_alpha">alpha</code></td>
<td>
<p>significance threshold to allow splitting in the
<code>"maxstat"</code> rule.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_minprop">minprop</code></td>
<td>
<p>lower quantile of covariate distribution to be considered for
splitting in the <code>"maxstat"</code> rule.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_split.select.weights">split.select.weights</code></td>
<td>
<p>numeric vector with weights between 0 and 1,
representing the probability to select variables for splitting.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_always.split.variables">always.split.variables</code></td>
<td>
<p>character vector with variable names to be
always selected in addition to the <code>mtry</code> variables tried for
splitting.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_respect.unordered.factors">respect.unordered.factors</code></td>
<td>
<p>handling of unordered factor covariates.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_scale.permutation.importance">scale.permutation.importance</code></td>
<td>
<p>scale permutation importance by
standard error.</p>
</td></tr>
<tr><td><code id="RangerModel_+3A_verbose">verbose</code></td>
<td>
<p>show computation status and estimated runtime.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>mtry</code>, <code>min.node.size</code>*, <code>splitrule</code>*
</p>
</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="ranger.html#topic+ranger">ranger</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package ranger to run

fit(Species ~ ., data = iris, model = RangerModel)


</code></pre>

<hr>
<h2 id='recipe_roles'>Set Recipe Roles</h2><span id='topic+recipe_roles'></span><span id='topic+role_binom'></span><span id='topic+role_case'></span><span id='topic+role_pred'></span><span id='topic+role_surv'></span>

<h3>Description</h3>

<p>Add to or replace the roles of variables in a preprocessing recipe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>role_binom(recipe, x, size)

role_case(recipe, group, stratum, weight, replace = FALSE)

role_pred(recipe, offset, replace = FALSE)

role_surv(recipe, time, event)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recipe_roles_+3A_recipe">recipe</code></td>
<td>
<p>existing <a href="recipes.html#topic+recipe">recipe</a> object.</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_x">x</code>, <code id="recipe_roles_+3A_size">size</code></td>
<td>
<p>number of counts and trials for the specification of a
<code><a href="#topic+BinomialVariate">BinomialVariate</a></code> outcome.</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_group">group</code></td>
<td>
<p>variable defining groupings of case observations, such as
repeated measurements, to keep together during resampling [default: none].</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_stratum">stratum</code></td>
<td>
<p>variable to use in conducting stratified <a href="#topic+resample">resample</a>
estimation of model performance.</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_weight">weight</code></td>
<td>
<p>numeric variable of case weights for model
<a href="#topic+fit">fitting</a>.</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to replace existing roles.</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_offset">offset</code></td>
<td>
<p>numeric variable to be added to a linear predictor, such as in
a generalized linear model, with known coefficient 1 rather than an
estimated coefficient.</p>
</td></tr>
<tr><td><code id="recipe_roles_+3A_time">time</code>, <code id="recipe_roles_+3A_event">event</code></td>
<td>
<p>numeric follow up time and 0-1 numeric or logical event
indicator for specification of a <code><a href="survival.html#topic+Surv">Surv</a></code> outcome.  If
the event indicator is omitted, all cases are assumed to have events.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated recipe object.
</p>


<h3>See Also</h3>

<p><code><a href="recipes.html#topic+recipe">recipe</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
library(recipes)

df &lt;- within(veteran, {
  y &lt;- Surv(time, status)
  remove(time, status)
})
rec &lt;- recipe(y ~ ., data = df) %&gt;%
  role_case(stratum = y)

(res &lt;- resample(rec, model = CoxModel))
summary(res)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='resample'>Resample Estimation of Model Performance</h2><span id='topic+resample'></span><span id='topic+resample.formula'></span><span id='topic+resample.matrix'></span><span id='topic+resample.ModelFrame'></span><span id='topic+resample.recipe'></span><span id='topic+resample.ModelSpecification'></span><span id='topic+resample.MLModel'></span><span id='topic+resample.MLModelFunction'></span>

<h3>Description</h3>

<p>Estimation of the predictive performance of a model estimated and evaluated
on training and test samples generated from an observed data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample(...)

## S3 method for class 'formula'
resample(formula, data, model, ...)

## S3 method for class 'matrix'
resample(x, y, model, ...)

## S3 method for class 'ModelFrame'
resample(input, model, ...)

## S3 method for class 'recipe'
resample(input, model, ...)

## S3 method for class 'ModelSpecification'
resample(object, control = MachineShop::settings("control"), ...)

## S3 method for class 'MLModel'
resample(model, ...)

## S3 method for class 'MLModelFunction'
resample(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample_+3A_...">...</code></td>
<td>
<p>arguments passed from the generic function to its methods, from
the <code>MLModel</code> and <code>MLModelFunction</code> methods to first arguments of
others, and from others to the <code>ModelSpecification</code> method.  The
first argument of each <code>fit</code> method is positional and, as such, must
be given first in calls to them.</p>
</td></tr>
<tr><td><code id="resample_+3A_formula">formula</code>, <code id="resample_+3A_data">data</code></td>
<td>
<p><a href="stats.html#topic+formula">formula</a> defining the model predictor and
response variables and a <a href="base.html#topic+data.frame">data frame</a> containing them.</p>
</td></tr>
<tr><td><code id="resample_+3A_model">model</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object; or
another object that can be <a href="#topic+as.MLModel">coerced</a> to a model.  A model
can be given first followed by any of the variable specifications.</p>
</td></tr>
<tr><td><code id="resample_+3A_x">x</code>, <code id="resample_+3A_y">y</code></td>
<td>
<p><a href="base.html#topic+matrix">matrix</a> and object containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="resample_+3A_input">input</code></td>
<td>
<p><a href="#topic+inputs">input</a> object defining and containing the model
predictor and response variables.</p>
</td></tr>
<tr><td><code id="resample_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+inputs">input</a> or
<a href="#topic+ModelSpecification">specification</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stratified resampling is performed automatically for the <code>formula</code> and
<code>matrix</code> methods according to the type of response variable.  In
general, strata are constructed from numeric proportions for
<code><a href="#topic+BinomialVariate">BinomialVariate</a></code>; original values for <code>character</code>,
<code>factor</code>, <code>logical</code>, and <code>ordered</code>; first columns of values
for <code>matrix</code>; original values for <code>numeric</code>; and numeric times
within event statuses for <code>Surv</code>.  Numeric values are stratified into
quantile bins and categorical values into factor levels defined by
<code><a href="#topic+MLControl">MLControl</a></code>.
</p>
<p>Resampling stratification variables may be specified manually for
<code>ModelFrames</code> upon creation with the <code><a href="#topic+ModelFrame">strata</a></code>
argument in their constructor.  Resampling of this class is unstratified by
default.
</p>
<p>Stratification variables may be designated in <code>recipe</code> specifications
with the <code><a href="#topic+role_case">role_case</a></code> function.  Resampling will be unstratified
otherwise.
</p>


<h3>Value</h3>

<p><code>Resample</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+c">c</a></code>, <code><a href="#topic+metrics">metrics</a></code>, <code><a href="#topic+performance">performance</a></code>,
<code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Factor response example

fo &lt;- Species ~ .
control &lt;- CVControl()

gbm_res1 &lt;- resample(fo, iris, GBMModel(n.trees = 25), control)
gbm_res2 &lt;- resample(fo, iris, GBMModel(n.trees = 50), control)
gbm_res3 &lt;- resample(fo, iris, GBMModel(n.trees = 100), control)

summary(gbm_res1)
plot(gbm_res1)

res &lt;- c(GBM1 = gbm_res1, GBM2 = gbm_res2, GBM3 = gbm_res3)
summary(res)
plot(res)


</code></pre>

<hr>
<h2 id='response'>Extract Response Variable</h2><span id='topic+response'></span><span id='topic+response.MLModelFit'></span><span id='topic+response.ModelFrame'></span><span id='topic+response.ModelSpecification'></span><span id='topic+response.recipe'></span>

<h3>Description</h3>

<p>Extract the response variable from an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>response(object, ...)

## S3 method for class 'MLModelFit'
response(object, newdata = NULL, ...)

## S3 method for class 'ModelFrame'
response(object, newdata = NULL, ...)

## S3 method for class 'ModelSpecification'
response(object, newdata = NULL, ...)

## S3 method for class 'recipe'
response(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="response_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+fit">fit</a>, <a href="#topic+inputs">input</a>, or
<a href="#topic+ModelSpecification">specification</a> containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="response_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="response_+3A_newdata">newdata</code></td>
<td>
<p><a href="base.html#topic+data.frame">data frame</a> from which to extract the
response variable values if given; otherwise, <code>object</code> is used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Survival response example
library(survival)

mf &lt;- ModelFrame(Surv(time, status) ~ ., data = veteran)
response(mf)

</code></pre>

<hr>
<h2 id='rfe'>Recursive Feature Elimination</h2><span id='topic+rfe'></span><span id='topic+rfe.formula'></span><span id='topic+rfe.matrix'></span><span id='topic+rfe.ModelFrame'></span><span id='topic+rfe.recipe'></span><span id='topic+rfe.ModelSpecification'></span><span id='topic+rfe.MLModel'></span><span id='topic+rfe.MLModelFunction'></span>

<h3>Description</h3>

<p>A wrapper method of backward feature selection in which a given model is fit
to nested subsets of most important predictor variables in order to select
the subset whose resampled predictive performance is optimal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfe(...)

## S3 method for class 'formula'
rfe(formula, data, model, ...)

## S3 method for class 'matrix'
rfe(x, y, model, ...)

## S3 method for class 'ModelFrame'
rfe(input, model, ...)

## S3 method for class 'recipe'
rfe(input, model, ...)

## S3 method for class 'ModelSpecification'
rfe(
  object,
  select = NULL,
  control = MachineShop::settings("control"),
  props = 4,
  sizes = integer(),
  random = FALSE,
  recompute = TRUE,
  optimize = c("global", "local"),
  samples = c(rfe = 1, varimp = 1),
  metrics = NULL,
  stat = c(resample = MachineShop::settings("stat.Resample"), permute =
    MachineShop::settings("stat.TrainingParams")),
  progress = FALSE,
  ...
)

## S3 method for class 'MLModel'
rfe(model, ...)

## S3 method for class 'MLModelFunction'
rfe(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfe_+3A_...">...</code></td>
<td>
<p>arguments passed from the generic function to its methods, from
the <code>MLModel</code> and <code>MLModelFunction</code> methods to first arguments of
others, and from others to the <code>ModelSpecification</code> method.  The
first argument of each <code>fit</code> method is positional and, as such, must
be given first in calls to them.</p>
</td></tr>
<tr><td><code id="rfe_+3A_formula">formula</code>, <code id="rfe_+3A_data">data</code></td>
<td>
<p><a href="stats.html#topic+formula">formula</a> defining the model predictor and
response variables and a <a href="base.html#topic+data.frame">data frame</a> containing them.</p>
</td></tr>
<tr><td><code id="rfe_+3A_model">model</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object; or
another object that can be <a href="#topic+as.MLModel">coerced</a> to a model.  A model
can be given first followed by any of the variable specifications.</p>
</td></tr>
<tr><td><code id="rfe_+3A_x">x</code>, <code id="rfe_+3A_y">y</code></td>
<td>
<p><a href="base.html#topic+matrix">matrix</a> and object containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="rfe_+3A_input">input</code></td>
<td>
<p><a href="#topic+inputs">input</a> object defining and containing the model
predictor and response variables.</p>
</td></tr>
<tr><td><code id="rfe_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+inputs">input</a> or
<a href="#topic+ModelSpecification">specification</a>.</p>
</td></tr>
<tr><td><code id="rfe_+3A_select">select</code></td>
<td>
<p>expression indicating predictor variables that can be
eliminated (see <code><a href="base.html#topic+subset">subset</a></code> for syntax) [default: all].</p>
</td></tr>
<tr><td><code id="rfe_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.</p>
</td></tr>
<tr><td><code id="rfe_+3A_props">props</code></td>
<td>
<p>numeric vector of the proportions of most important predictor
variables to retain in fitted models or an integer number of equal spaced
proportions to generate automatically; ignored if <code>sizes</code> are given.</p>
</td></tr>
<tr><td><code id="rfe_+3A_sizes">sizes</code></td>
<td>
<p>integer vector of the set sizes of most important predictor
variables to retain.</p>
</td></tr>
<tr><td><code id="rfe_+3A_random">random</code></td>
<td>
<p>logical indicating whether to eliminate variables at random
with probabilities proportional to their importance.</p>
</td></tr>
<tr><td><code id="rfe_+3A_recompute">recompute</code></td>
<td>
<p>logical indicating whether to recompute variable importance
after eliminating each set of variables.</p>
</td></tr>
<tr><td><code id="rfe_+3A_optimize">optimize</code></td>
<td>
<p>character string specifying a search through all <code>props</code>
to identify the globally optimal model (<code>"global"</code>) or a search that
stops after identifying the first locally optimal model (<code>"local"</code>).</p>
</td></tr>
<tr><td><code id="rfe_+3A_samples">samples</code></td>
<td>
<p>numeric vector or list giving the number of permutation
samples for each of the <code>rfe</code> and <code><a href="#topic+varimp">varimp</a></code> algorithms.
One or both of the values may be specified as named arguments or in the
order in which their defaults appear.  Larger numbers of samples decrease
variability in estimated model performances and variable importances at the
expense of increased computation time.  Samples are more expensive
computationally for <code>rfe</code> than for <code>varimp</code>.</p>
</td></tr>
<tr><td><code id="rfe_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.  If not specified, default
metrics defined in the <a href="#topic+performance">performance</a> functions are used.</p>
</td></tr>
<tr><td><code id="rfe_+3A_stat">stat</code></td>
<td>
<p>functions or character strings naming functions to compute
summary statistics on resampled metric values and permuted samples.  One or
both of the values may be specified as named arguments or in the order in
which their defaults appear.</p>
</td></tr>
<tr><td><code id="rfe_+3A_progress">progress</code></td>
<td>
<p>logical indicating whether to display iterative progress
during elimination.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TrainingStep</code> class object containing a summary of the numbers
of predictor variables retained (size), their names (terms), logical
indicators for the optimal model selected (selected), and associated
performance metrics (metrics).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+performance">performance</a></code>, <code><a href="#topic+plot">plot</a></code>,
<code><a href="#topic+summary">summary</a></code>, <code><a href="#topic+varimp">varimp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

(res &lt;- rfe(sale_amount ~ ., data = ICHomes, model = GBMModel))
summary(res)
summary(performance(res))
plot(res, type = "line")


</code></pre>

<hr>
<h2 id='RFSRCModel'>Fast Random Forest (SRC) Model</h2><span id='topic+RFSRCModel'></span><span id='topic+RFSRCFastModel'></span>

<h3>Description</h3>

<p>Fast OpenMP computing of Breiman's random forest for a variety of data
settings including right-censored survival, regression, and classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RFSRCModel(
  ntree = 1000,
  mtry = integer(),
  nodesize = integer(),
  nodedepth = integer(),
  splitrule = character(),
  nsplit = 10,
  block.size = integer(),
  samptype = c("swor", "swr"),
  membership = FALSE,
  sampsize = if (samptype == "swor") function(x) 0.632 * x else function(x) x,
  nimpute = 1,
  ntime = integer(),
  proximity = c(FALSE, TRUE, "inbag", "oob", "all"),
  distance = c(FALSE, TRUE, "inbag", "oob", "all"),
  forest.wt = c(FALSE, TRUE, "inbag", "oob", "all"),
  xvar.wt = numeric(),
  split.wt = numeric(),
  var.used = c(FALSE, "all.trees", "by.tree"),
  split.depth = c(FALSE, "all.trees", "by.tree"),
  do.trace = FALSE,
  statistics = FALSE
)

RFSRCFastModel(
  ntree = 500,
  sampsize = function(x) min(0.632 * x, max(x^0.75, 150)),
  ntime = 50,
  terminal.qualts = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RFSRCModel_+3A_ntree">ntree</code></td>
<td>
<p>number of trees.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_mtry">mtry</code></td>
<td>
<p>number of variables randomly selected as candidates for splitting
a node.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_nodesize">nodesize</code></td>
<td>
<p>minumum size of terminal nodes.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_nodedepth">nodedepth</code></td>
<td>
<p>maximum depth to which a tree should be grown.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_splitrule">splitrule</code></td>
<td>
<p>splitting rule (see <code><a href="randomForestSRC.html#topic+rfsrc">rfsrc</a></code>).</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_nsplit">nsplit</code></td>
<td>
<p>non-negative integer value for number of random splits to
consider for each candidate splitting variable.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_block.size">block.size</code></td>
<td>
<p>interval number of trees at which to compute the cumulative
error rate.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_samptype">samptype</code></td>
<td>
<p>whether bootstrap sampling is with or without replacement.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_membership">membership</code></td>
<td>
<p>logical indicating whether to return terminal node
membership.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_sampsize">sampsize</code></td>
<td>
<p>function specifying the bootstrap size.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_nimpute">nimpute</code></td>
<td>
<p>number of iterations of the missing data imputation algorithm.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_ntime">ntime</code></td>
<td>
<p>integer number of time points to constrain ensemble calculations
for survival outcomes.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_proximity">proximity</code></td>
<td>
<p>whether and how to return proximity of cases as measured by
the frequency of sharing the same terminal nodes.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_distance">distance</code></td>
<td>
<p>whether and how to return distance between cases as measured
by the ratio of the sum of edges from each case to the root node.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_forest.wt">forest.wt</code></td>
<td>
<p>whether and how to return the forest weight matrix.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_xvar.wt">xvar.wt</code></td>
<td>
<p>vector of non-negative weights representing the probability of
selecting a variable for splitting.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_split.wt">split.wt</code></td>
<td>
<p>vector of non-negative weights used for multiplying the split
statistic for a variable.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_var.used">var.used</code></td>
<td>
<p>whether and how to return variables used for splitting.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_split.depth">split.depth</code></td>
<td>
<p>whether and how to return minimal depth for each variable.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_do.trace">do.trace</code></td>
<td>
<p>number of seconds between updates to the user on approximate
time to completion.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_statistics">statistics</code></td>
<td>
<p>logical indicating whether to return split statistics.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_terminal.qualts">terminal.qualts</code></td>
<td>
<p>logical indicating whether to return terminal node
membership information.</p>
</td></tr>
<tr><td><code id="RFSRCModel_+3A_...">...</code></td>
<td>
<p>arguments passed to <code>RFSRCModel</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>matrix</code>, <code>numeric</code>,
<code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>
<p><code>mtry</code>, <code>nodesize</code>
</p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>RFSRCModel</code>, argument
<code>type</code> may be specified as <code>"anti"</code> (default) for cases assigned to
the split opposite of the random assignments, as <code>"permute"</code> for
permutation of OOB cases, or as <code>"random"</code> for permutation replaced with
random assignment.  Variable importance is automatically scaled to range from
0 to 100.  To obtain unscaled importance values, set <code>scale = FALSE</code>.
See example below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="randomForestSRC.html#topic+rfsrc">rfsrc</a></code>,
<code><a href="randomForestSRC.html#topic+rfsrc.fast">rfsrc.fast</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package randomForestSRC to run

model_fit &lt;- fit(sale_amount ~ ., data = ICHomes, model = RFSRCModel)
varimp(model_fit, method = "model", type = "random", scale = TRUE)


</code></pre>

<hr>
<h2 id='RPartModel'>Recursive Partitioning and Regression Tree Models</h2><span id='topic+RPartModel'></span>

<h3>Description</h3>

<p>Fit an <code>rpart</code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RPartModel(
  minsplit = 20,
  minbucket = round(minsplit/3),
  cp = 0.01,
  maxcompete = 4,
  maxsurrogate = 5,
  usesurrogate = 2,
  xval = 10,
  surrogatestyle = 0,
  maxdepth = 30
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RPartModel_+3A_minsplit">minsplit</code></td>
<td>
<p>minimum number of observations that must exist in a node in
order for a split to be attempted.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_minbucket">minbucket</code></td>
<td>
<p>minimum number of observations in any terminal node.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_cp">cp</code></td>
<td>
<p>complexity parameter.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_maxcompete">maxcompete</code></td>
<td>
<p>number of competitor splits retained in the output.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_maxsurrogate">maxsurrogate</code></td>
<td>
<p>number of surrogate splits retained in the output.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_usesurrogate">usesurrogate</code></td>
<td>
<p>how to use surrogates in the splitting process.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_xval">xval</code></td>
<td>
<p>number of cross-validations.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_surrogatestyle">surrogatestyle</code></td>
<td>
<p>controls the selection of a best surrogate.</p>
</td></tr>
<tr><td><code id="RPartModel_+3A_maxdepth">maxdepth</code></td>
<td>
<p>maximum depth of any node of the final tree, with the root
node counted as depth 0.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameter:</dt><dd>
<p><code>cp</code>
</p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="rpart.html#topic+rpart">rpart</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested packages rpart and partykit to run

fit(Species ~ ., data = iris, model = RPartModel)


</code></pre>

<hr>
<h2 id='SelectedInput'>Selected Model Inputs</h2><span id='topic+SelectedInput'></span><span id='topic+SelectedModelFrame'></span><span id='topic+SelectedModelRecipe'></span><span id='topic+SelectedModelSpecification'></span><span id='topic+SelectedInput.formula'></span><span id='topic+SelectedInput.matrix'></span><span id='topic+SelectedInput.ModelFrame'></span><span id='topic+SelectedInput.recipe'></span><span id='topic+SelectedInput.ModelSpecification'></span><span id='topic+SelectedInput.list'></span>

<h3>Description</h3>

<p>Formula, design matrix, model frame, or recipe selection from a candidate
set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectedInput(...)

## S3 method for class 'formula'
SelectedInput(
  ...,
  data,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'matrix'
SelectedInput(
  ...,
  y,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'ModelFrame'
SelectedInput(
  ...,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'recipe'
SelectedInput(
  ...,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'ModelSpecification'
SelectedInput(
  ...,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'list'
SelectedInput(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SelectedInput_+3A_...">...</code></td>
<td>
<p><a href="#topic+inputs">inputs</a> defining relationships between model predictor
and response variables.  Supplied inputs must all be of the same type and
may be named or unnamed.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_data">data</code></td>
<td>
<p><a href="base.html#topic+data.frame">data frame</a> containing predictor and response
variables.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.  If not specified, default
metrics defined in the <a href="#topic+performance">performance</a> functions are used.  Recipe
selection is based on the first calculated metric.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_cutoff">cutoff</code></td>
<td>
<p>argument passed to the <code>metrics</code> functions.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic on resampled metric values for recipe selection.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_y">y</code></td>
<td>
<p>response variable.</p>
</td></tr>
<tr><td><code id="SelectedInput_+3A_x">x</code></td>
<td>
<p>list of inputs followed by arguments passed to their method
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>SelectedModelFrame</code>, <code>SelectedModelRecipe</code>, or
<code>SelectedModelSpecification</code> class object that inherits from
<code>SelectedInput</code> and <code>ModelFrame</code>, <code>recipe</code>, or
<code>ModelSpecification</code>, respectively.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Selected model frame
sel_mf &lt;- SelectedInput(
  sale_amount ~ sale_year + built + style + construction,
  sale_amount ~ sale_year + base_size + bedrooms + basement,
  data = ICHomes
)

fit(sel_mf, model = GLMModel)

## Selected recipe
library(recipes)
data(Boston, package = "MASS")

rec1 &lt;- recipe(medv ~ crim + zn + indus + chas + nox + rm, data = Boston)
rec2 &lt;- recipe(medv ~ chas + nox + rm + age + dis + rad + tax, data = Boston)
sel_rec &lt;- SelectedInput(rec1, rec2)

fit(sel_rec, model = GLMModel)

</code></pre>

<hr>
<h2 id='SelectedModel'>Selected Model</h2><span id='topic+SelectedModel'></span><span id='topic+SelectedModel.default'></span><span id='topic+SelectedModel.ModelSpecification'></span><span id='topic+SelectedModel.list'></span>

<h3>Description</h3>

<p>Model selection from a candidate set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectedModel(...)

## Default S3 method:
SelectedModel(
  ...,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'ModelSpecification'
SelectedModel(
  ...,
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)

## S3 method for class 'list'
SelectedModel(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SelectedModel_+3A_...">...</code></td>
<td>
<p><a href="#topic+models">model</a> functions, function names, objects; other
objects that can be <a href="#topic+as.MLModel">coerced</a> to models; vectors of
these to serve as the candidate set from which to select, such as that
returned by <code><a href="#topic+expand_model">expand_model</a></code>; or model
<a href="#topic+ModelSpecification">specifications</a>.</p>
</td></tr>
<tr><td><code id="SelectedModel_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.</p>
</td></tr>
<tr><td><code id="SelectedModel_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.  If not specified, default
metrics defined in the <a href="#topic+performance">performance</a> functions are used.  Model
selection is based on the first calculated metric.</p>
</td></tr>
<tr><td><code id="SelectedModel_+3A_cutoff">cutoff</code></td>
<td>
<p>argument passed to the <code>metrics</code> functions.</p>
</td></tr>
<tr><td><code id="SelectedModel_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic on resampled metric values for model selection.</p>
</td></tr>
<tr><td><code id="SelectedModel_+3A_x">x</code></td>
<td>
<p>list of models followed by arguments passed to their method
function.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>ordered</code>,
<code>Surv</code></p>
</dd>
</dl>



<h3>Value</h3>

<p><code>SelectedModel</code> or <code>SelectedModelSpecification</code> class
object that inherits from <code>MLModel</code> or <code>ModelSpecification</code>,
respectively.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm and glmnet to run

model_fit &lt;- fit(
  sale_amount ~ ., data = ICHomes,
  model = SelectedModel(GBMModel, GLMNetModel, SVMRadialModel)
)
(selected_model &lt;- as.MLModel(model_fit))
summary(selected_model)


</code></pre>

<hr>
<h2 id='set_monitor'>Training Parameters Monitoring Control</h2><span id='topic+set_monitor'></span><span id='topic+set_monitor.MLControl'></span><span id='topic+set_monitor.MLOptimization'></span><span id='topic+set_monitor.ModelSpecification'></span>

<h3>Description</h3>

<p>Set parameters that control the monitoring of resample estimation of model
performance and of tuning parameter optimization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_monitor(object, ...)

## S3 method for class 'MLControl'
set_monitor(object, progress = TRUE, verbose = FALSE, ...)

## S3 method for class 'MLOptimization'
set_monitor(object, progress = FALSE, verbose = FALSE, ...)

## S3 method for class 'ModelSpecification'
set_monitor(object, which = c("all", "control", "optim"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_monitor_+3A_object">object</code></td>
<td>
<p>resampling <a href="#topic+controls">control</a>,
tuning parameter <a href="#topic+set_optim">optimization</a>, or model
<a href="#topic+ModelSpecification">specification</a> object.</p>
</td></tr>
<tr><td><code id="set_monitor_+3A_...">...</code></td>
<td>
<p>arguments passed from the <code>ModelSpecification</code> method to the
others.</p>
</td></tr>
<tr><td><code id="set_monitor_+3A_progress">progress</code></td>
<td>
<p>logical indicating whether to display iterative progress
during resampling or optimization.  In the case of resampling, a progress
bar will be displayed if a computing cluster is not registered or is
registered with the <span class="pkg">doSNOW</span> package.</p>
</td></tr>
<tr><td><code id="set_monitor_+3A_verbose">verbose</code></td>
<td>
<p>numeric or logical value specifying the level of progress
detail to print, with 0 (<code>FALSE</code>) indicating none and 1 (<code>TRUE</code>)
or higher indicating increasing amounts of detail.</p>
</td></tr>
<tr><td><code id="set_monitor_+3A_which">which</code></td>
<td>
<p>character string specifying the monitoring parameters to set as
<code>"all"</code>, <code>"control"</code>, or optimization (<code>"optim"</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Argument <code>object</code> updated with the supplied parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+set_optim">set_optim</a></code>,
<code><a href="#topic+set_predict">set_predict</a></code>, <code><a href="#topic+set_strata">set_strata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CVControl() %&gt;% set_monitor(verbose = TRUE)

</code></pre>

<hr>
<h2 id='set_optim'>Tuning Parameter Optimization</h2><span id='topic+set_optim'></span><span id='topic+set_optim_bayes'></span><span id='topic+set_optim_bayes.ModelSpecification'></span><span id='topic+set_optim_bfgs'></span><span id='topic+set_optim_bfgs.ModelSpecification'></span><span id='topic+set_optim_grid'></span><span id='topic+set_optim_grid.TrainingParams'></span><span id='topic+set_optim_grid.ModelSpecification'></span><span id='topic+set_optim_grid.TunedInput'></span><span id='topic+set_optim_grid.TunedModel'></span><span id='topic+set_optim_pso'></span><span id='topic+set_optim_pso.ModelSpecification'></span><span id='topic+set_optim_sann'></span><span id='topic+set_optim_sann.ModelSpecification'></span><span id='topic+set_optim_method'></span><span id='topic+set_optim_method.ModelSpecification'></span>

<h3>Description</h3>

<p>Set the optimization method and control parameters for tuning of model
parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_optim_bayes(object, ...)

## S3 method for class 'ModelSpecification'
set_optim_bayes(
  object,
  num_init = 5,
  times = 10,
  each = 1,
  acquisition = c("ucb", "ei", "eips", "poi"),
  kappa = stats::qnorm(conf),
  conf = 0.995,
  epsilon = 0,
  control = list(),
  packages = c("ParBayesianOptimization", "rBayesianOptimization"),
  random = FALSE,
  progress = verbose,
  verbose = 0,
  ...
)

set_optim_bfgs(object, ...)

## S3 method for class 'ModelSpecification'
set_optim_bfgs(
  object,
  times = 10,
  control = list(),
  random = FALSE,
  progress = FALSE,
  verbose = 0,
  ...
)

set_optim_grid(object, ...)

## S3 method for class 'TrainingParams'
set_optim_grid(object, random = FALSE, progress = FALSE, ...)

## S3 method for class 'ModelSpecification'
set_optim_grid(object, ...)

## S3 method for class 'TunedInput'
set_optim_grid(object, ...)

## S3 method for class 'TunedModel'
set_optim_grid(object, ...)

set_optim_pso(object, ...)

## S3 method for class 'ModelSpecification'
set_optim_pso(
  object,
  times = 10,
  each = NULL,
  control = list(),
  random = FALSE,
  progress = FALSE,
  verbose = 0,
  ...
)

set_optim_sann(object, ...)

## S3 method for class 'ModelSpecification'
set_optim_sann(
  object,
  times = 10,
  control = list(),
  random = FALSE,
  progress = FALSE,
  verbose = 0,
  ...
)

set_optim_method(object, ...)

## S3 method for class 'ModelSpecification'
set_optim_method(
  object,
  fun,
  label = "Optimization Function",
  packages = character(),
  params = list(),
  random = FALSE,
  progress = FALSE,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_optim_+3A_object">object</code></td>
<td>
<p><a href="#topic+inputs">input</a> or <a href="#topic+models">model</a> object.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_...">...</code></td>
<td>
<p>arguments passed to the <code>TrainingParams</code> method of
<code>set_optim_grid</code> from its other methods.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_num_init">num_init</code></td>
<td>
<p>number of grid points to sample for the initialization of
Bayesian optimization.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_times">times</code></td>
<td>
<p>maximum number of times to repeat the optimization step.
Multiple sets of model parameters are evaluated automatically at each step
of the BFGS algorithm to compute a finite-difference approximation to the
gradient.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_each">each</code></td>
<td>
<p>number of times to sample and evaluate model parameters at each
optimization step.  This is the swarm size in particle swarm optimization,
which defaults to <code>floor(10 + 2 * sqrt(length(bounds)))</code>.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_acquisition">acquisition</code></td>
<td>
<p>character string specifying the acquisition function as
<code>"ucb"</code> (upper confidence bound), <code>"ei"</code> (expected improvement),
<code>"eips"</code> (expected improvement per second), or <code>"poi"</code>
(probability of improvement).</p>
</td></tr>
<tr><td><code id="set_optim_+3A_kappa">kappa</code>, <code id="set_optim_+3A_conf">conf</code></td>
<td>
<p>upper confidence bound (<code>"ucb"</code>) quantile or its
probability to balance exploitation against exploration.  Argument
<code>kappa</code> takes precedence if both are given and multiplies the
predictive standard deviation added to the predictive mean in the
acquisition function.  Larger values encourage exploration of the model
parameter space.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_epsilon">epsilon</code></td>
<td>
<p>improvement methods (<code>"ei"</code>, <code>"eips"</code>, and
<code>"poi"</code>) parameter to balance exploitation against exploration.
Values should be between -0.1 and 0.1 with larger ones encouraging
exploration.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_control">control</code></td>
<td>
<p>list of control parameters passed to
<code><a href="ParBayesianOptimization.html#topic+bayesOpt">bayesOpt</a></code> by <code>set_optim_bayes</code>
with package <code>"ParBayesianOptimization"</code>, to
<code><a href="rBayesianOptimization.html#topic+BayesianOptimization">BayesianOptimization</a></code> by
<code>set_optim_bayes</code> with package <code>"rBayesianOptimization"</code>, to
<code><a href="stats.html#topic+optim">optim</a></code> by <code>set_optim_bfgs</code> and
<code>set_optim_sann</code>, and to <code><a href="pso.html#topic+psoptim">psoptim</a></code> by
<code>set_optim_pso</code>.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_packages">packages</code></td>
<td>
<p>R package or packages to use for the optimization method, or
an empty vector if none are needed.  The first package in
<code>set_optim_bayes</code> is used unless otherwise specified by the user.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_random">random</code></td>
<td>
<p>number of points to sample for a random grid search, or
<code>FALSE</code> for an exhaustive grid search.  Used when a grid search is
specified or as the fallback method for non-numeric model parameters
present during other optimization methods.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_progress">progress</code></td>
<td>
<p>logical indicating whether to display iterative progress
during optimization.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_verbose">verbose</code></td>
<td>
<p>numeric or logical value specifying the level of progress
detail to print, with 0 (<code>FALSE</code>) indicating none and 1 (<code>TRUE</code>)
or higher indicating increasing amounts of detail.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_fun">fun</code></td>
<td>
<p>user-defined optimization function to which the arguments below
are passed in order.  An ellipsis can be included in the function
definition when using only a subset of the arguments and ignoring others.
A tibble returned by the function with the same number of rows as model
evaluations will be included in a <code>TrainingStep</code> summary of
optimization results; other types of return values will be ignored.
</p>

<dl>
<dt>optim</dt><dd><p>function that takes a numeric vector or list of named
model parameters as the first argument, optionally accepts the maximum
number of iterations as argument <code>max_iter</code>, and returns a scalar
measure of performance to be maximized.  Parameter names are available
from the <code>grid</code> and <code>bounds</code> arguments described below.  If
the function cannot be evaluated at a given set of parameter values,
then <code>-Inf</code> is returned.</p>
</dd>
<dt>grid</dt><dd><p>data frame containing a tuning grid of all model parameters.</p>
</dd>
<dt>bounds</dt><dd><p>named list of lower and upper bounds for each finite
numeric model parameter in <code>grid</code>.  The types (integer or double)
of the original parameter values are preserved in the bounds.</p>
</dd>
<dt>params</dt><dd><p>list of optimization parameters as supplied to
<code>set_optim_method</code>.</p>
</dd>
<dt>monitor</dt><dd><p>list of the <code>progress</code> and <code>verbose</code> values.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="set_optim_+3A_label">label</code></td>
<td>
<p>character descriptor for the optimization method.</p>
</td></tr>
<tr><td><code id="set_optim_+3A_params">params</code></td>
<td>
<p>list of user-specified model parameters to be passed to
<code>fun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimization functions implement the following methods.
</p>

<dl>
<dt><code>set_optim_bayes</code></dt><dd><p>Bayesian optimization with a Gaussian process
model (Snoek et al. 2012).</p>
</dd>
<dt><code>set_optim_bfgs</code></dt><dd><p>limited-memory modification of quasi-Newton
BFGS optimization (Byrd et al. 1995).</p>
</dd>
<dt><code>set_optim_grid</code></dt><dd><p>exhaustive or random grid search.</p>
</dd>
<dt><code>set_optim_pso</code></dt><dd><p>particle swarm optimization (Bratton and
Kennedy 2007, Zambrano-Bigiarini et al. 2013).</p>
</dd>
<dt><code>set_optim_sann</code></dt><dd><p>simulated annealing (Belisle 1992).  This
method depends critically on the control parameter settings.  It is
not a general-purpose method but can be very useful in getting to good
parameter values on a very rough optimization surface.</p>
</dd>
<dt><code>set_optim_method</code></dt><dd><p>user-defined optimization function.</p>
</dd>
</dl>

<p>The package-defined optimization functions evaluate and return values of the
tuning parameters that are of same type (e.g. integer, double, character) as
given in the <code>object</code> grid.  Sequential optimization of numeric tuning
parameters is performed over a hypercube defined by their minimum and maximum
grid values.  Non-numeric parameters are optimized with grid searches.
</p>


<h3>Value</h3>

<p>Argument <code>object</code> updated with the specified optimization method
and control parameters.
</p>


<h3>References</h3>

<p>Belisle, C. J. P. (1992). Convergence theorems for a class of simulated
annealing algorithms on Rd. <em>Journal of Applied Probability</em>,
<em>29</em>, 885–895.
</p>
<p>Bratton, D. &amp; Kennedy, J. (2007), Defining a standard for particle swarm
optimization. In <em>IEEE Swarm Intelligence Symposium, 2007</em> (pp.
120-127).
</p>
<p>Byrd, R. H., Lu, P., Nocedal, J., &amp; Zhu, C. (1995). A limited memory
algorithm for bound constrained optimization. <em>SIAM Journal on
Scientific Computing</em>, <em>16</em>, 1190–1208.
</p>
<p>Snoek, J., Larochelle, H., &amp; Adams, R.P. (2012). Practical Bayesian
Optimization of Machine Learning Algorithms. arXiv:1206.2944 [stat.ML].
</p>
<p>Zambrano-Bigiarini, M., Clerc, M., &amp; Rojas, R. (2013). Standard particle
swarm optimisation 2011 at CEC-2013: A baseline for future PSO improvements.
In <em>IEEE Congress on Evolutionary Computation, 2013</em> (pp. 2337-2344).
</p>


<h3>See Also</h3>

<p><code><a href="rBayesianOptimization.html#topic+BayesianOptimization">BayesianOptimization</a></code>,
<code><a href="ParBayesianOptimization.html#topic+bayesOpt">bayesOpt</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="pso.html#topic+psoptim">psoptim</a></code>, <code><a href="#topic+set_monitor">set_monitor</a></code>,
<code><a href="#topic+set_predict">set_predict</a></code>, <code><a href="#topic+set_strata">set_strata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ModelSpecification(
  sale_amount ~ ., data = ICHomes,
  model = TunedModel(GBMModel)
) %&gt;% set_optim_bayes

</code></pre>

<hr>
<h2 id='set_predict'>Resampling Prediction Control</h2><span id='topic+set_predict'></span>

<h3>Description</h3>

<p>Set parameters that control prediction during resample estimation of model
performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_predict(
  object,
  times = numeric(),
  distr = character(),
  method = character(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_predict_+3A_object">object</code></td>
<td>
<p><a href="#topic+controls">control</a> object.</p>
</td></tr>
<tr><td><code id="set_predict_+3A_times">times</code>, <code id="set_predict_+3A_distr">distr</code>, <code id="set_predict_+3A_method">method</code></td>
<td>
<p>arguments passed to <code><a href="#topic+predict">predict</a></code>.</p>
</td></tr>
<tr><td><code id="set_predict_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Argument <code>object</code> updated with the supplied parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+set_monitor">set_monitor</a></code>,
<code><a href="#topic+set_optim">set_optim</a></code>, <code><a href="#topic+set_strata">set_strata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CVControl() %&gt;% set_predict(times = 1:3)

</code></pre>

<hr>
<h2 id='set_strata'>Resampling Stratification Control</h2><span id='topic+set_strata'></span>

<h3>Description</h3>

<p>Set parameters that control the construction of strata during resample
estimation of model performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_strata(object, breaks = 4, nunique = 5, prop = 0.1, size = 20, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_strata_+3A_object">object</code></td>
<td>
<p><a href="#topic+controls">control</a> object.</p>
</td></tr>
<tr><td><code id="set_strata_+3A_breaks">breaks</code></td>
<td>
<p>number of quantile bins desired for stratification of numeric
data during resampling.</p>
</td></tr>
<tr><td><code id="set_strata_+3A_nunique">nunique</code></td>
<td>
<p>number of unique values at or below which numeric data are
stratified as categorical.</p>
</td></tr>
<tr><td><code id="set_strata_+3A_prop">prop</code></td>
<td>
<p>minimum proportion of data in each strata.</p>
</td></tr>
<tr><td><code id="set_strata_+3A_size">size</code></td>
<td>
<p>minimum number of values in each strata.</p>
</td></tr>
<tr><td><code id="set_strata_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments control resampling strata which are constructed from numeric
proportions for <code><a href="#topic+BinomialVariate">BinomialVariate</a></code>; original values for
<code>character</code>, <code>factor</code>, <code>logical</code>, <code>numeric</code>, and
<code>ordered</code>; first columns of values for <code>matrix</code>; and numeric times
within event statuses for <code>Surv</code>.  Stratification of survival data by
event status only can be achieved by setting <code>breaks = 1</code>.  Numeric
values are stratified into quantile bins and categorical values into factor
levels.  The number of bins will be the largest integer less than or equal to
<code>breaks</code> satisfying the <code>prop</code> and <code>size</code> control argument
thresholds.  Categorical levels below the thresholds will be pooled
iteratively by reassigning values in the smallest nominal level to the
remaining ones at random and by combining the smallest adjacent ordinal
levels.  Missing values are replaced with non-missing values sampled at
random with replacement.
</p>


<h3>Value</h3>

<p>Argument <code>object</code> updated with the supplied parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+set_monitor">set_monitor</a></code>,
<code><a href="#topic+set_optim">set_optim</a></code>, <code><a href="#topic+set_predict">set_predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CVControl() %&gt;% set_strata(breaks = 3)

</code></pre>

<hr>
<h2 id='settings'>MachineShop Settings</h2><span id='topic+settings'></span>

<h3>Description</h3>

<p>Allow the user to view or change global settings which affect default
behaviors of functions in the <span class="pkg">MachineShop</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>settings(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="settings_+3A_...">...</code></td>
<td>
<p>character names of settings to view, <code>name = value</code> pairs
giving the values of settings to change, a vector of these, <code>"reset"</code>
to restore all package defaults, or no arguments to view all settings.
Partial matching of setting names is supported.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The setting value if only one is specified to view.  Otherwise, a
list of the values of specified settings as they existed prior to any
requested changes.  Such a list can be passed as an argument to
<code>settings</code> to restore their values.
</p>


<h3>Settings</h3>


<dl>
<dt><code><a href="#topic+controls">control</a></code></dt><dd><p>function, function name, or object
defining a default resampling method [default: <code>"CVControl"</code>].</p>
</dd>
<dt><code>cutoff</code></dt><dd><p>numeric (0, 1) threshold above which binary factor
probabilities are classified as events and below which survival
probabilities are classified [default: 0.5].</p>
</dd>
<dt><code>distr.SurvMeans</code></dt><dd><p>character string specifying distributional
approximations to estimated survival curves for predicting survival
means.  Choices are <code>"empirical"</code> for the Kaplan-Meier estimator,
<code>"exponential"</code>, <code>"rayleigh"</code>, or <code>"weibull"</code> (default).</p>
</dd>
<dt><code>distr.SurvProbs</code></dt><dd><p>character string specifying distributional
approximations to estimated survival curves for predicting survival
events/probabilities.  Choices are <code>"empirical"</code> (default) for the
Kaplan-Meier estimator, <code>"exponential"</code>, <code>"rayleigh"</code>, or
<code>"weibull"</code>.</p>
</dd>
<dt><code>grid</code></dt><dd><p><code>size</code> argument to <code><a href="#topic+TuningGrid">TuningGrid</a></code>
indicating the number of parameter-specific values to generate
automatically for <a href="#topic+TunedModel">tuning</a> of models that have
pre-defined grids or a <code><a href="#topic+TuningGrid">TuningGrid</a></code> function, function name,
or object [default: 3].</p>
</dd>
<dt><code>method.EmpiricalSurv</code></dt><dd><p>character string specifying the
empirical method of estimating baseline survival curves for Cox
proportional hazards-based models.  Choices are <code>"breslow"</code> or
<code>"efron"</code> (default).</p>
</dd>
<dt><code>metrics.ConfusionMatrix</code></dt><dd><p>function, function name, or vector of
these with which to calculate <a href="#topic+performance">performance</a> <a href="#topic+metrics">metrics</a> for
confusion matrices [default: <code>c(Accuracy = "accuracy", Kappa =
    "kappa2", `Weighted Kappa` = "weighted_kappa2", Sensitivity =
    "sensitivity", Specificity = "specificity")</code>].</p>
</dd>
<dt><code>metrics.factor</code></dt><dd><p>function, function name, or vector of these
with which to calculate <a href="#topic+performance">performance</a> <a href="#topic+metrics">metrics</a> for factor
responses [default: <code>c(Brier = "brier", Accuracy = "accuracy",
    Kappa = "kappa2", `Weighted Kappa` = "weighted_kappa2", `ROC AUC` =
    "roc_auc", Sensitivity = "sensitivity", Specificity = "specificity")</code>].</p>
</dd>
<dt><code>metrics.matrix</code></dt><dd><p>function, function name, or vector of these
with which to calculate <a href="#topic+performance">performance</a> <a href="#topic+metrics">metrics</a> for matrix
responses [default: <code>c(RMSE = "rmse", R2 = "r2", MAE = "mae")</code>].</p>
</dd>
<dt><code>metrics.numeric</code></dt><dd><p>function, function name, or vector of these
with which to calculate <a href="#topic+performance">performance</a> <a href="#topic+metrics">metrics</a> for numeric
responses [default: <code>c(RMSE = "rmse", R2 = "r2", MAE = "mae")</code>].</p>
</dd>
<dt><code>metrics.Surv</code></dt><dd><p>function, function name, or vector of these with
which to calculate <a href="#topic+performance">performance</a> <a href="#topic+metrics">metrics</a> for survival
responses [default: <code>c(`C-Index` = "cindex", Brier = "brier",
    `ROC AUC` = "roc_auc", Accuracy = "accuracy")</code>].</p>
</dd>
<dt><code>print_max</code></dt><dd><p>number of models or data rows to show with print
methods or <code>Inf</code> to show all [default: 10].</p>
</dd>
<dt><code>require</code></dt><dd><p>names of installed packages to load during parallel
execution of resampling algorithms [default: <code>"MachineShop"</code>].</p>
</dd>
<dt><code>reset</code></dt><dd><p>character names of settings to reset to their default
values.</p>
</dd>
<dt><code>RHS.formula</code></dt><dd><p>non-modifiable character vector of operators and
functions allowed in traditional formula specifications.</p>
</dd>
<dt><code>stat.Curve</code></dt><dd><p>function or character string naming a function
to compute one <a href="#topic+summary">summary</a> statistic at each cutoff value of resampled
metrics in performance curves, or <code>NULL</code> for resample-specific
metrics [default: <code>"base::mean"</code>].</p>
</dd>
<dt><code>stat.Resample</code></dt><dd><p>function or character string naming a function
to compute one summary statistic to control the ordering of models in
<a href="#topic+plot">plots</a> [default: <code>"base::mean"</code>].</p>
</dd>
<dt><code>stat.TrainingParams</code></dt><dd><p>function or character string naming a function
to compute one summary statistic on resampled performance metrics for
input <a href="#topic+SelectedInput">selection</a> or <a href="#topic+TunedInput">tuning</a> or
for model <a href="#topic+SelectedModel">selection</a> or <a href="#topic+TunedModel">tuning</a>
[default: <code>"base::mean"</code>].</p>
</dd>
<dt><code>stats.PartialDependence</code></dt><dd><p>function, function name, or vector of
these with which to compute <a href="#topic+dependence">partial dependence</a>
summary statistics [default: <code>c(Mean = "base::mean")</code>].</p>
</dd>
<dt><code>stats.Resample</code></dt><dd><p>function, function name, or vector of these
with which to compute <a href="#topic+summary">summary</a> statistics on resampled performance
metrics [default: <code>c(Mean = "base::mean", Median = "stats::median",
    SD = "stats::sd", Min = "base::min", Max = "base::max")</code>].</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## View all current settings
settings()

## Change settings
presets &lt;- settings(control = "BootControl", grid = 10)

## View one setting
settings("control")

## View multiple settings
settings("control", "grid")

## Restore the previous settings
settings(presets)

</code></pre>

<hr>
<h2 id='StackedModel'>Stacked Regression Model</h2><span id='topic+StackedModel'></span>

<h3>Description</h3>

<p>Fit a stacked regression model from multiple base learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StackedModel(
  ...,
  control = MachineShop::settings("control"),
  weights = numeric()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="StackedModel_+3A_...">...</code></td>
<td>
<p><a href="#topic+models">model</a> functions, function names, objects; other
objects that can be <a href="#topic+as.MLModel">coerced</a> to models; or vector of
these to serve as base learners.</p>
</td></tr>
<tr><td><code id="StackedModel_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed for the estimation of base
learner weights.</p>
</td></tr>
<tr><td><code id="StackedModel_+3A_weights">weights</code></td>
<td>
<p>optional fixed base learner weights.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>ordered</code>,
<code>Surv</code></p>
</dd>
</dl>



<h3>Value</h3>

<p><code>StackedModel</code> class object that inherits from <code>MLModel</code>.
</p>


<h3>References</h3>

<p>Breiman, L. (1996). Stacked regression. <em>Machine Learning</em>, <em>24</em>,
49-64.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested packages gbm and glmnet to run

model &lt;- StackedModel(GBMModel, SVMRadialModel, GLMNetModel(lambda = 0.01))
model_fit &lt;- fit(sale_amount ~ ., data = ICHomes, model = model)
predict(model_fit, newdata = ICHomes)


</code></pre>

<hr>
<h2 id='step_kmeans'>K-Means Clustering Variable Reduction</h2><span id='topic+step_kmeans'></span><span id='topic+tidy.step_kmeans'></span><span id='topic+tunable.step_kmeans'></span>

<h3>Description</h3>

<p>Creates a <em>specification</em> of a recipe step that will convert numeric
variables into one or more by averaging within k-means clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_kmeans(
  recipe,
  ...,
  k = 5,
  center = TRUE,
  scale = TRUE,
  algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"),
  max_iter = 10,
  num_start = 1,
  replace = TRUE,
  prefix = "KMeans",
  role = "predictor",
  skip = FALSE,
  id = recipes::rand_id("kmeans")
)

## S3 method for class 'step_kmeans'
tidy(x, ...)

## S3 method for class 'step_kmeans'
tunable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step_kmeans_+3A_recipe">recipe</code></td>
<td>
<p><a href="recipes.html#topic+recipe">recipe</a> object to which the step will be added.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_...">...</code></td>
<td>
<p>one or more selector functions to choose which variables will be
used to compute the components.  See <code><a href="recipes.html#topic+selections">selections</a></code> for
more details.  These are not currently used by the <code>tidy</code> method.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_k">k</code></td>
<td>
<p>number of k-means clusterings of the variables.  The value of
<code>k</code> is constrained to be between 1 and one less than the number of
original variables.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_center">center</code>, <code id="step_kmeans_+3A_scale">scale</code></td>
<td>
<p>logicals indicating whether to mean center and standard
deviation scale the original variables prior to deriving components, or
functions or names of functions for the centering and scaling.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_algorithm">algorithm</code></td>
<td>
<p>character string specifying the clustering algorithm to use.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of algorithm iterations allowed.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_num_start">num_start</code></td>
<td>
<p>number of random cluster centers generated for starting the
Hartigan-Wong algorithm.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to replace the original variables.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_prefix">prefix</code></td>
<td>
<p>character string prefix added to a sequence of zero-padded
integers to generate names for the resulting new variables.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_role">role</code></td>
<td>
<p>analysis role that added step variables should be assigned.  By
default, they are designated as model predictors.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_skip">skip</code></td>
<td>
<p>logical indicating whether to skip the step when the recipe is
baked.  While all operations are baked when <code><a href="recipes.html#topic+prep">prep</a></code> is
run, some operations may not be applicable to new data (e.g. processing
outcome variables).  Care should be taken when using <code>skip = TRUE</code> as
it may affect the computations for subsequent operations.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_id">id</code></td>
<td>
<p>unique character string to identify the step.</p>
</td></tr>
<tr><td><code id="step_kmeans_+3A_x">x</code></td>
<td>
<p><code>step_kmeans</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>K-means clustering partitions variables into k groups such that the sum of
squares between the variables and their assigned cluster means is minimized.
Variables within each cluster are then averaged to derive a new set of k
variables.
</p>


<h3>Value</h3>

<p>Function <code>step_kmeans</code> creates a new step whose class is of
the same name and inherits from <code><a href="#topic+step_lincomp">step_lincomp</a></code>, adds it to the
sequence of existing steps (if any) in the recipe, and returns the updated
recipe.  For the <code>tidy</code> method, a tibble with columns <code>terms</code>
(selectors or variables selected), <code>cluster</code> assignments, <code>sqdist</code>
(squared distance from cluster centers), and <code>name</code> of the new variable
names.
</p>


<h3>References</h3>

<p>Forgy, E. W. (1965). Cluster analysis of multivariate data: efficiency versus
interpretability of classifications. <em>Biometrics</em>, <em>21</em>, 768-769.
</p>
<p>Hartigan, J. A., &amp; Wong, M. A. (1979). A K-means clustering algorithm.
<em>Applied Statistics</em>, <em>28</em>, 100-108.
</p>
<p>Lloyd, S. P. (1982). Least squares quantization in PCM. <em>IEEE
Transactions on Information Theory</em>, <em>28</em>(2), 129-137.
</p>
<p>MacQueen, J. (1967). Some methods for classification and analysis of
multivariate observations. In L. M. Le Cam &amp; J. Neyman (Eds.),
<em>Proceedings of the fifth Berkeley Symposium on Mathematical Statistics
and Probability</em> (vol. 1, pp. 281-297). University of California Press.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code>, <code><a href="recipes.html#topic+recipe">recipe</a></code>,
<code><a href="recipes.html#topic+prep">prep</a></code>, <code><a href="recipes.html#topic+bake">bake</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)

rec &lt;- recipe(rating ~ ., data = attitude)
kmeans_rec &lt;- rec %&gt;%
  step_kmeans(all_predictors(), k = 3)
kmeans_prep &lt;- prep(kmeans_rec, training = attitude)
kmeans_data &lt;- bake(kmeans_prep, attitude)

pairs(kmeans_data, lower.panel = NULL)

tidy(kmeans_rec, number = 1)
tidy(kmeans_prep, number = 1)

</code></pre>

<hr>
<h2 id='step_kmedoids'>K-Medoids Clustering Variable Selection</h2><span id='topic+step_kmedoids'></span><span id='topic+tunable.step_kmedoids'></span>

<h3>Description</h3>

<p>Creates a <em>specification</em> of a recipe step that will partition numeric
variables according to k-medoids clustering and select the cluster medoids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_kmedoids(
  recipe,
  ...,
  k = 5,
  center = TRUE,
  scale = TRUE,
  method = c("pam", "clara"),
  metric = "euclidean",
  optimize = FALSE,
  num_samp = 50,
  samp_size = 40 + 2 * k,
  replace = TRUE,
  prefix = "KMedoids",
  role = "predictor",
  skip = FALSE,
  id = recipes::rand_id("kmedoids")
)

## S3 method for class 'step_kmedoids'
tunable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step_kmedoids_+3A_recipe">recipe</code></td>
<td>
<p><a href="recipes.html#topic+recipe">recipe</a> object to which the step will be added.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_...">...</code></td>
<td>
<p>one or more selector functions to choose which variables will be
used to compute the components.  See <code><a href="recipes.html#topic+selections">selections</a></code> for
more details.  These are not currently used by the <code>tidy</code> method.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_k">k</code></td>
<td>
<p>number of k-medoids clusterings of the variables.  The value of
<code>k</code> is constrained to be between 1 and one less than the number of
original variables.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_center">center</code>, <code id="step_kmedoids_+3A_scale">scale</code></td>
<td>
<p>logicals indicating whether to mean center and median
absolute deviation scale the original variables prior to cluster
partitioning, or functions or names of functions for the centering and
scaling; not applied to selected variables.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_method">method</code></td>
<td>
<p>character string specifying one of the clustering methods
provided by the <span class="pkg">cluster</span> package.  The <code>clara</code> (clustering
large applications) method is an extension of <code>pam</code> (partitioning
around medoids) designed to handle large datasets.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_metric">metric</code></td>
<td>
<p>character string specifying the distance metric for calculating
dissimilarities between observations as <code>"euclidean"</code>,
<code>"manhattan"</code>, or <code>"jaccard"</code> (<code>clara</code> only).</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_optimize">optimize</code></td>
<td>
<p>logical indicator or 0:5 integer level specifying
optimization for the <code><a href="cluster.html#topic+pam">pam</a></code> clustering method.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_num_samp">num_samp</code></td>
<td>
<p>number of sub-datasets to sample for the
<code><a href="cluster.html#topic+clara">clara</a></code> clustering method.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_samp_size">samp_size</code></td>
<td>
<p>number of cases to include in each sub-dataset.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to replace the original variables.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_prefix">prefix</code></td>
<td>
<p>if the original variables are not replaced, the selected
variables are added to the dataset with the character string prefix added
to their names; otherwise, the original variable names are retained.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_role">role</code></td>
<td>
<p>analysis role that added step variables should be assigned.  By
default, they are designated as model predictors.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_skip">skip</code></td>
<td>
<p>logical indicating whether to skip the step when the recipe is
baked.  While all operations are baked when <code><a href="recipes.html#topic+prep">prep</a></code> is
run, some operations may not be applicable to new data (e.g. processing
outcome variables).  Care should be taken when using <code>skip = TRUE</code> as
it may affect the computations for subsequent operations.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_id">id</code></td>
<td>
<p>unique character string to identify the step.</p>
</td></tr>
<tr><td><code id="step_kmedoids_+3A_x">x</code></td>
<td>
<p><code>step_kmedoids</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>K-medoids clustering partitions variables into k groups such that the
dissimilarity between the variables and their assigned cluster medoids is
minimized.  Cluster medoids are then returned as a set of k variables.
</p>


<h3>Value</h3>

<p>Function <code>step_kmedoids</code> creates a new step whose class is of
the same name and inherits from <code><a href="#topic+step_sbf">step_sbf</a></code>, adds it to the
sequence of existing steps (if any) in the recipe, and returns the updated
recipe.  For the <code>tidy</code> method, a tibble with columns <code>terms</code>
(selectors or variables selected), <code>cluster</code> assignments,
<code>selected</code> (logical indicator of selected cluster medoids),
<code>silhouette</code> (silhouette values), and <code>name</code> of the selected
variable names.
</p>


<h3>References</h3>

<p>Kaufman, L., &amp; Rousseeuw, P. J. (1990). <em>Finding groups in data: An
introduction to cluster analysis</em>. Wiley.
</p>
<p>Reynolds, A., Richards, G., de la Iglesia, B., &amp; Rayward-Smith, V. (1992).
Clustering rules: A comparison of partitioning and hierarchical clustering
algorithms. <em>Journal of Mathematical Modelling and Algorithms</em>,
<em>5</em>, 475-504.
</p>


<h3>See Also</h3>

<p><code><a href="cluster.html#topic+pam">pam</a></code>, <code><a href="cluster.html#topic+clara">clara</a></code>,
<code><a href="recipes.html#topic+recipe">recipe</a></code>, <code><a href="recipes.html#topic+prep">prep</a></code>,
<code><a href="recipes.html#topic+bake">bake</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)

rec &lt;- recipe(rating ~ ., data = attitude)
kmedoids_rec &lt;- rec %&gt;%
  step_kmedoids(all_predictors(), k = 3)
kmedoids_prep &lt;- prep(kmedoids_rec, training = attitude)
kmedoids_data &lt;- bake(kmedoids_prep, attitude)

pairs(kmedoids_data, lower.panel = NULL)

tidy(kmedoids_rec, number = 1)
tidy(kmedoids_prep, number = 1)

</code></pre>

<hr>
<h2 id='step_lincomp'>Linear Components Variable Reduction</h2><span id='topic+step_lincomp'></span><span id='topic+tidy.step_lincomp'></span><span id='topic+tunable.step_lincomp'></span>

<h3>Description</h3>

<p>Creates a <em>specification</em> of a recipe step that will compute one or more
linear combinations of a set of numeric variables according to a
user-specified transformation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_lincomp(
  recipe,
  ...,
  transform,
  num_comp = 5,
  options = list(),
  center = TRUE,
  scale = TRUE,
  replace = TRUE,
  prefix = "LinComp",
  role = "predictor",
  skip = FALSE,
  id = recipes::rand_id("lincomp")
)

## S3 method for class 'step_lincomp'
tidy(x, ...)

## S3 method for class 'step_lincomp'
tunable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step_lincomp_+3A_recipe">recipe</code></td>
<td>
<p><a href="recipes.html#topic+recipe">recipe</a> object to which the step will be added.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_...">...</code></td>
<td>
<p>one or more selector functions to choose which variables will be
used to compute the components.  See <code><a href="recipes.html#topic+selections">selections</a></code> for
more details.  These are not currently used by the <code>tidy</code> method.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_transform">transform</code></td>
<td>
<p>function whose first argument <code>x</code> is a matrix of
variables with which to compute linear combinations and second argument
<code>step</code> is the current step.  The function should return a
transformation <code><a href="base.html#topic+matrix">matrix</a></code> or <code><a href="Matrix.html#topic+Matrix">Matrix</a></code> of
variable weights in its columns, or return a list with element
<code>`weights`</code> containing the transformation matrix and possibly with
other elements to be included as attributes in output from the <code>tidy</code>
method.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_num_comp">num_comp</code></td>
<td>
<p>number of components to derive.  The value of <code>num_comp</code>
will be constrained to a minimum of 1 and maximum of the number of original
variables when <code><a href="recipes.html#topic+prep">prep</a></code> is run.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_options">options</code></td>
<td>
<p>list of elements to be added to the step object for use in the
<code>transform</code> function.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_center">center</code>, <code id="step_lincomp_+3A_scale">scale</code></td>
<td>
<p>logicals indicating whether to mean center and standard
deviation scale the original variables prior to deriving components, or
functions or names of functions for the centering and scaling.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to replace the original variables.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_prefix">prefix</code></td>
<td>
<p>character string prefix added to a sequence of zero-padded
integers to generate names for the resulting new variables.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_role">role</code></td>
<td>
<p>analysis role that added step variables should be assigned.  By
default, they are designated as model predictors.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_skip">skip</code></td>
<td>
<p>logical indicating whether to skip the step when the recipe is
baked.  While all operations are baked when <code><a href="recipes.html#topic+prep">prep</a></code> is
run, some operations may not be applicable to new data (e.g. processing
outcome variables).  Care should be taken when using <code>skip = TRUE</code> as
it may affect the computations for subsequent operations.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_id">id</code></td>
<td>
<p>unique character string to identify the step.</p>
</td></tr>
<tr><td><code id="step_lincomp_+3A_x">x</code></td>
<td>
<p><code>step_lincomp</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added to the
sequence of existing steps (if any).  For the <code>tidy</code> method, a tibble
with columns <code>terms</code> (selectors or variables selected), <code>weight</code>
of each variable in the linear transformations, and <code>name</code> of the new
variable names.
</p>


<h3>See Also</h3>

<p><code><a href="recipes.html#topic+recipe">recipe</a></code>, <code><a href="recipes.html#topic+prep">prep</a></code>,
<code><a href="recipes.html#topic+bake">bake</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)

pca_mat &lt;- function(x, step) {
  prcomp(x)$rotation[, 1:step$num_comp, drop = FALSE]
}

rec &lt;- recipe(rating ~ ., data = attitude)
lincomp_rec &lt;- rec %&gt;%
  step_lincomp(all_numeric_predictors(),
               transform = pca_mat, num_comp = 3, prefix = "PCA")

lincomp_prep &lt;- prep(lincomp_rec, training = attitude)
lincomp_data &lt;- bake(lincomp_prep, attitude)

pairs(lincomp_data, lower.panel = NULL)

tidy(lincomp_rec, number = 1)
tidy(lincomp_prep, number = 1)

</code></pre>

<hr>
<h2 id='step_sbf'>Variable Selection by Filtering</h2><span id='topic+step_sbf'></span><span id='topic+tidy.step_sbf'></span>

<h3>Description</h3>

<p>Creates a <em>specification</em> of a recipe step that will select variables
from a candidate set according to a user-specified filtering function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_sbf(
  recipe,
  ...,
  filter,
  multivariate = FALSE,
  options = list(),
  replace = TRUE,
  prefix = "SBF",
  role = "predictor",
  skip = FALSE,
  id = recipes::rand_id("sbf")
)

## S3 method for class 'step_sbf'
tidy(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step_sbf_+3A_recipe">recipe</code></td>
<td>
<p><a href="recipes.html#topic+recipe">recipe</a> object to which the step will be added.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_...">...</code></td>
<td>
<p>one or more selector functions to choose which variables will be
used to compute the components.  See <code><a href="recipes.html#topic+selections">selections</a></code> for
more details.  These are not currently used by the <code>tidy</code> method.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_filter">filter</code></td>
<td>
<p>function whose first argument <code>x</code> is a univariate vector
or a <code>multivariate</code> data frame of candidate variables from which to
select, second argument <code>y</code> is the response variable as
defined in preceding recipe steps, and third argument <code>step</code> is the
current step.  The function should return a logical value or vector of
length equal the number of variables in <code>x</code> indicating whether to
select the corresponding variable, or return a list or data frame with
element <code>`selected`</code> containing the logical(s) and possibly with other
elements of the same length to be included in output from the <code>tidy</code>
method.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_multivariate">multivariate</code></td>
<td>
<p>logical indicating that candidate variables be passed to
the <code>x</code> argument of the <code>filter</code> function separately as
univariate vectors if <code>FALSE</code>, or altogether in one multivariate data
frame if <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_options">options</code></td>
<td>
<p>list of elements to be added to the step object for use in the
<code>filter</code> function.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to replace the original variables.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_prefix">prefix</code></td>
<td>
<p>if the original variables are not replaced, the selected
variables are added to the dataset with the character string prefix added
to their names; otherwise, the original variable names are retained.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_role">role</code></td>
<td>
<p>analysis role that added step variables should be assigned.  By
default, they are designated as model predictors.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_skip">skip</code></td>
<td>
<p>logical indicating whether to skip the step when the recipe is
baked.  While all operations are baked when <code><a href="recipes.html#topic+prep">prep</a></code> is
run, some operations may not be applicable to new data (e.g. processing
outcome variables).  Care should be taken when using <code>skip = TRUE</code> as
it may affect the computations for subsequent operations.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_id">id</code></td>
<td>
<p>unique character string to identify the step.</p>
</td></tr>
<tr><td><code id="step_sbf_+3A_x">x</code></td>
<td>
<p><code>step_sbf</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added to the
sequence of existing steps (if any).  For the <code>tidy</code> method, a tibble
with columns <code>terms</code> (selectors or variables selected), <code>selected</code>
(logical indicator of selected variables), and <code>name</code> of the selected
variable names.
</p>


<h3>See Also</h3>

<p><code><a href="recipes.html#topic+recipe">recipe</a></code>, <code><a href="recipes.html#topic+prep">prep</a></code>,
<code><a href="recipes.html#topic+bake">bake</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)

glm_filter &lt;- function(x, y, step) {
  model_fit &lt;- glm(y ~ ., data = data.frame(y, x))
  p_value &lt;- drop1(model_fit, test = "F")[-1, "Pr(&gt;F)"]
  p_value &lt; step$threshold
}

rec &lt;- recipe(rating ~ ., data = attitude)
sbf_rec &lt;- rec %&gt;%
  step_sbf(all_numeric_predictors(),
           filter = glm_filter, options = list(threshold = 0.05))

sbf_prep &lt;- prep(sbf_rec, training = attitude)
sbf_data &lt;- bake(sbf_prep, attitude)

pairs(sbf_data, lower.panel = NULL)

tidy(sbf_rec, number = 1)
tidy(sbf_prep, number = 1)

</code></pre>

<hr>
<h2 id='step_spca'>Sparse Principal Components Analysis Variable Reduction</h2><span id='topic+step_spca'></span><span id='topic+tunable.step_spca'></span>

<h3>Description</h3>

<p>Creates a <em>specification</em> of a recipe step that will derive sparse
principal components from one or more numeric variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_spca(
  recipe,
  ...,
  num_comp = 5,
  sparsity = 0,
  num_var = integer(),
  shrinkage = 1e-06,
  center = TRUE,
  scale = TRUE,
  max_iter = 200,
  tol = 0.001,
  replace = TRUE,
  prefix = "SPCA",
  role = "predictor",
  skip = FALSE,
  id = recipes::rand_id("spca")
)

## S3 method for class 'step_spca'
tunable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="step_spca_+3A_recipe">recipe</code></td>
<td>
<p><a href="recipes.html#topic+recipe">recipe</a> object to which the step will be added.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_...">...</code></td>
<td>
<p>one or more selector functions to choose which variables will be
used to compute the components.  See <code><a href="recipes.html#topic+selections">selections</a></code> for
more details.  These are not currently used by the <code>tidy</code> method.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_num_comp">num_comp</code></td>
<td>
<p>number of components to derive.  The value of <code>num_comp</code>
will be constrained to a minimum of 1 and maximum of the number of original
variables when <code><a href="recipes.html#topic+prep">prep</a></code> is run.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_sparsity">sparsity</code>, <code id="step_spca_+3A_num_var">num_var</code></td>
<td>
<p>sparsity (L1 norm) penalty for each component or
number of variables with non-zero component loadings.  Larger sparsity
values produce more zero loadings.  Argument <code>sparsity</code> is ignored if
<code>num_var</code> is given.  The argument value may be a single number
applied to all components or a vector of component-specific numbers.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_shrinkage">shrinkage</code></td>
<td>
<p>numeric shrinkage (quadratic) penalty for the components to
improve conditioning; larger values produce more shrinkage of component
loadings toward zero.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_center">center</code>, <code id="step_spca_+3A_scale">scale</code></td>
<td>
<p>logicals indicating whether to mean center and standard
deviation scale the original variables prior to deriving components, or
functions or names of functions for the centering and scaling.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of algorithm iterations allowed.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_tol">tol</code></td>
<td>
<p>numeric tolerance for the convergence criterion.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_replace">replace</code></td>
<td>
<p>logical indicating whether to replace the original variables.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_prefix">prefix</code></td>
<td>
<p>character string prefix added to a sequence of zero-padded
integers to generate names for the resulting new variables.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_role">role</code></td>
<td>
<p>analysis role that added step variables should be assigned.  By
default, they are designated as model predictors.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_skip">skip</code></td>
<td>
<p>logical indicating whether to skip the step when the recipe is
baked.  While all operations are baked when <code><a href="recipes.html#topic+prep">prep</a></code> is
run, some operations may not be applicable to new data (e.g. processing
outcome variables).  Care should be taken when using <code>skip = TRUE</code> as
it may affect the computations for subsequent operations.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_id">id</code></td>
<td>
<p>unique character string to identify the step.</p>
</td></tr>
<tr><td><code id="step_spca_+3A_x">x</code></td>
<td>
<p><code>step_spca</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sparse principal components analysis (SPCA) is a variant of PCA in which
the original variables may have zero loadings in the linear combinations
that form the components.
</p>


<h3>Value</h3>

<p>Function <code>step_spca</code> creates a new step whose class is of
the same name and inherits from <code><a href="#topic+step_lincomp">step_lincomp</a></code>, adds it to the
sequence of existing steps (if any) in the recipe, and returns the updated
recipe.  For the <code>tidy</code> method, a tibble with columns <code>terms</code>
(selectors or variables selected), <code>weight</code> of each variable loading in
the components, and <code>name</code> of the new variable names; and with
attribute <code>pev</code> containing the proportions of explained variation.
</p>


<h3>References</h3>

<p>Zou, H., Hastie, T., &amp; Tibshirani, R. (2006). Sparse principal component
analysis. <em>Journal of Computational and Graphical Statistics</em>,
<em>15</em>(2), 265-286.
</p>


<h3>See Also</h3>

<p><code><a href="elasticnet.html#topic+spca">spca</a></code>, <code><a href="recipes.html#topic+recipe">recipe</a></code>,
<code><a href="recipes.html#topic+prep">prep</a></code>, <code><a href="recipes.html#topic+bake">bake</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)

rec &lt;- recipe(rating ~ ., data = attitude)
spca_rec &lt;- rec %&gt;%
  step_spca(all_predictors(), num_comp = 5, sparsity = 1)
spca_prep &lt;- prep(spca_rec, training = attitude)
spca_data &lt;- bake(spca_prep, attitude)

pairs(spca_data, lower.panel = NULL)

tidy(spca_rec, number = 1)
tidy(spca_prep, number = 1)

</code></pre>

<hr>
<h2 id='summary'>Model Performance Summaries</h2><span id='topic+summary'></span><span id='topic+summary.ConfusionList'></span><span id='topic+summary.ConfusionMatrix'></span><span id='topic+summary.MLModel'></span><span id='topic+summary.MLModelFit'></span><span id='topic+summary.Performance'></span><span id='topic+summary.PerformanceCurve'></span><span id='topic+summary.Resample'></span><span id='topic+summary.TrainingStep'></span>

<h3>Description</h3>

<p>Summary statistics for resampled model performance metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ConfusionList'
summary(object, ...)

## S3 method for class 'ConfusionMatrix'
summary(object, ...)

## S3 method for class 'MLModel'
summary(
  object,
  stats = MachineShop::settings("stats.Resample"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'MLModelFit'
summary(object, .type = c("default", "glance", "tidy"), ...)

## S3 method for class 'Performance'
summary(
  object,
  stats = MachineShop::settings("stats.Resample"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'PerformanceCurve'
summary(object, stat = MachineShop::settings("stat.Curve"), ...)

## S3 method for class 'Resample'
summary(
  object,
  stats = MachineShop::settings("stats.Resample"),
  na.rm = TRUE,
  ...
)

## S3 method for class 'TrainingStep'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p><a href="#topic+confusion">confusion</a>, <a href="#topic+lift">lift</a>, trained model <a href="#topic+fit">fit</a>,
<a href="#topic+performance">performance</a>, <a href="#topic+curves">performance curve</a>, <a href="#topic+resample">resample</a>, or
<a href="#topic+rfe">rfe</a> result.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="summary_+3A_stats">stats</code></td>
<td>
<p>function, function name, or vector of these with which to
compute summary statistics.</p>
</td></tr>
<tr><td><code id="summary_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating whether to exclude missing values.</p>
</td></tr>
<tr><td><code id="summary_+3A_.type">.type</code></td>
<td>
<p>character string specifying that
<code><a href="#topic+unMLModelFit">unMLModelFit(object)</a></code> be passed to
<code><a href="base.html#topic+summary">summary</a></code> (<code>"default"</code>),
<code><a href="generics.html#topic+glance">glance</a></code>, or
<code><a href="generics.html#topic+tidy">tidy</a></code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic at each cutoff value of resampled metrics in
<code>PerformanceCurve</code>, or <code>NULL</code> for resample-specific metrics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of summmary statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Factor response example

fo &lt;- Species ~ .
control &lt;- CVControl()

gbm_res1 &lt;- resample(fo, iris, GBMModel(n.trees = 25), control)
gbm_res2 &lt;- resample(fo, iris, GBMModel(n.trees = 50), control)
gbm_res3 &lt;- resample(fo, iris, GBMModel(n.trees = 100), control)
summary(gbm_res3)

res &lt;- c(GBM1 = gbm_res1, GBM2 = gbm_res2, GBM3 = gbm_res3)
summary(res)


</code></pre>

<hr>
<h2 id='SuperModel'>Super Learner Model</h2><span id='topic+SuperModel'></span>

<h3>Description</h3>

<p>Fit a super learner model to predictions from multiple base learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SuperModel(
  ...,
  model = GBMModel,
  control = MachineShop::settings("control"),
  all_vars = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SuperModel_+3A_...">...</code></td>
<td>
<p><a href="#topic+models">model</a> functions, function names, objects; other
objects that can be <a href="#topic+as.MLModel">coerced</a> to models; or vector of
these to serve as base learners.</p>
</td></tr>
<tr><td><code id="SuperModel_+3A_model">model</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object
defining the super model; or another object that can be
<a href="#topic+as.MLModel">coerced</a> to the model.</p>
</td></tr>
<tr><td><code id="SuperModel_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed for the estimation of base
learner weights.</p>
</td></tr>
<tr><td><code id="SuperModel_+3A_all_vars">all_vars</code></td>
<td>
<p>logical indicating whether to include the original
predictor variables in the super model.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>ordered</code>,
<code>Surv</code></p>
</dd>
</dl>



<h3>Value</h3>

<p><code>SuperModel</code> class object that inherits from <code>MLModel</code>.
</p>


<h3>References</h3>

<p>van der Laan, M. J., Polley, E. C., &amp; Hubbard, A. E. (2007). Super learner.
<em>Statistical Applications in Genetics and Molecular Biology</em>,
<em>6</em>(1).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested packages gbm and glmnet to run

model &lt;- SuperModel(GBMModel, SVMRadialModel, GLMNetModel(lambda = 0.01))
model_fit &lt;- fit(sale_amount ~ ., data = ICHomes, model = model)
predict(model_fit, newdata = ICHomes)


</code></pre>

<hr>
<h2 id='SurvMatrix'>SurvMatrix Class Constructors</h2><span id='topic+SurvMatrix'></span><span id='topic+SurvEvents'></span><span id='topic+SurvProbs'></span>

<h3>Description</h3>

<p>Create a matrix of survival events or probabilites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvEvents(data = NA, times = numeric(), distr = character())

SurvProbs(data = NA, times = numeric(), distr = character())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvMatrix_+3A_data">data</code></td>
<td>
<p>matrix, or object that can be coerced to one, with survival
events or probabilities at points in time in the columns and cases in the
rows.</p>
</td></tr>
<tr><td><code id="SurvMatrix_+3A_times">times</code></td>
<td>
<p>numeric vector of survival times for the columns.</p>
</td></tr>
<tr><td><code id="SurvMatrix_+3A_distr">distr</code></td>
<td>
<p>character string specifying the survival distribution from which
the matrix values were derived.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object that is of the same class as the constructor name and inherits
from <code>SurvMatrix</code>.  Examples of these are predicted survival events and
probabilities returned by the <a href="#topic+predict">predict</a> function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+performance">performance</a></code>, <code><a href="#topic+metrics">metrics</a></code>
</p>

<hr>
<h2 id='SurvRegModel'>Parametric Survival Model</h2><span id='topic+SurvRegModel'></span><span id='topic+SurvRegStepAICModel'></span>

<h3>Description</h3>

<p>Fits the accelerated failure time family of parametric survival models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvRegModel(
  dist = c("weibull", "exponential", "gaussian", "logistic", "lognormal",
    "logloglogistic"),
  scale = 0,
  parms = list(),
  ...
)

SurvRegStepAICModel(
  dist = c("weibull", "exponential", "gaussian", "logistic", "lognormal",
    "logloglogistic"),
  scale = 0,
  parms = list(),
  ...,
  direction = c("both", "backward", "forward"),
  scope = list(),
  k = 2,
  trace = FALSE,
  steps = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvRegModel_+3A_dist">dist</code></td>
<td>
<p>assumed distribution for y variable.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_scale">scale</code></td>
<td>
<p>optional fixed value for the scale.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_parms">parms</code></td>
<td>
<p>list of fixed parameters.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="survival.html#topic+survreg.control">survreg.control</a></code>.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_direction">direction</code></td>
<td>
<p>mode of stepwise search, can be one of <code>"both"</code>
(default), <code>"backward"</code>, or <code>"forward"</code>.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_scope">scope</code></td>
<td>
<p>defines the range of models examined in the stepwise search.
This should be a list containing components <code>upper</code> and <code>lower</code>,
both formulae.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_k">k</code></td>
<td>
<p>multiple of the number of degrees of freedom used for the penalty.
Only <code>k = 2</code> gives the genuine AIC; <code>k = .(log(nobs))</code> is
sometimes referred to as BIC or SBC.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_trace">trace</code></td>
<td>
<p>if positive, information is printed during the running of
<code>stepAIC</code>. Larger values may give more information on the fitting
process.</p>
</td></tr>
<tr><td><code id="SurvRegModel_+3A_steps">steps</code></td>
<td>
<p>maximum number of steps to be considered.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>Surv</code></p>
</dd>
</dl>

<p>Default argument values and further model details can be found in the source
See Also links below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="rms.html#topic+psm">psm</a></code>, <code><a href="survival.html#topic+survreg">survreg</a></code>,
<code><a href="survival.html#topic+survreg.control">survreg.control</a></code>, <code><a href="MASS.html#topic+stepAIC">stepAIC</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>
<p><code><a href="MASS.html#topic+stepAIC">stepAIC</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested packages rms and Hmisc to run

library(survival)

fit(Surv(time, status) ~ ., data = veteran, model = SurvRegModel)


</code></pre>

<hr>
<h2 id='SVMModel'>Support Vector Machine Models</h2><span id='topic+SVMModel'></span><span id='topic+SVMANOVAModel'></span><span id='topic+SVMBesselModel'></span><span id='topic+SVMLaplaceModel'></span><span id='topic+SVMLinearModel'></span><span id='topic+SVMPolyModel'></span><span id='topic+SVMRadialModel'></span><span id='topic+SVMSplineModel'></span><span id='topic+SVMTanhModel'></span>

<h3>Description</h3>

<p>Fits the well known C-svc, nu-svc, (classification) one-class-svc (novelty)
eps-svr, nu-svr (regression) formulations along with native multi-class
classification formulations and the bound-constraint SVM formulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVMModel(
  scaled = TRUE,
  type = character(),
  kernel = c("rbfdot", "polydot", "vanilladot", "tanhdot", "laplacedot", "besseldot",
    "anovadot", "splinedot"),
  kpar = "automatic",
  C = 1,
  nu = 0.2,
  epsilon = 0.1,
  prob.model = FALSE,
  cache = 40,
  tol = 0.001,
  shrinking = TRUE
)

SVMANOVAModel(sigma = 1, degree = 1, ...)

SVMBesselModel(sigma = 1, order = 1, degree = 1, ...)

SVMLaplaceModel(sigma = numeric(), ...)

SVMLinearModel(...)

SVMPolyModel(degree = 1, scale = 1, offset = 1, ...)

SVMRadialModel(sigma = numeric(), ...)

SVMSplineModel(...)

SVMTanhModel(scale = 1, offset = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SVMModel_+3A_scaled">scaled</code></td>
<td>
<p>logical vector indicating the variables to be scaled.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_type">type</code></td>
<td>
<p>type of support vector machine.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_kernel">kernel</code></td>
<td>
<p>kernel function used in training and predicting.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_kpar">kpar</code></td>
<td>
<p>list of hyper-parameters (kernel parameters).</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_c">C</code></td>
<td>
<p>cost of constraints violation defined as the regularization term in
the Lagrange formulation.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_nu">nu</code></td>
<td>
<p>parameter needed for nu-svc, one-svc, and nu-svr.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_epsilon">epsilon</code></td>
<td>
<p>parameter in the insensitive-loss function used for eps-svr,
nu-svr and eps-bsvm.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_prob.model">prob.model</code></td>
<td>
<p>logical indicating whether to calculate the scaling
parameter of the Laplacian distribution fitted on the residuals of numeric
response variables.  Ignored in the case of a factor response variable.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_cache">cache</code></td>
<td>
<p>cache memory in MB.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_tol">tol</code></td>
<td>
<p>tolerance of termination criterion.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_shrinking">shrinking</code></td>
<td>
<p>whether to use the shrinking-heuristics.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_sigma">sigma</code></td>
<td>
<p>inverse kernel width used by the ANOVA, Bessel, and Laplacian
kernels.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_degree">degree</code></td>
<td>
<p>degree of the ANOVA, Bessel, and polynomial kernel functions.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_...">...</code></td>
<td>
<p>arguments passed to <code>SVMModel</code> from the other constructors.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_order">order</code></td>
<td>
<p>order of the Bessel function to be used as a kernel.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_scale">scale</code></td>
<td>
<p>scaling parameter of the polynomial and hyperbolic tangent
kernels as a convenient way of normalizing patterns without the need to
modify the data itself.</p>
</td></tr>
<tr><td><code id="SVMModel_+3A_offset">offset</code></td>
<td>
<p>offset used in polynomial and hyperbolic tangent kernels.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>

<ul>
<li><p> SVMModel: <code>NULL</code>
</p>
</li>
<li><p> SVMANOVAModel: <code>C</code>, <code>degree</code>
</p>
</li>
<li><p> SVMBesselModel: <code>C</code>, <code>order</code>, <code>degree</code>
</p>
</li>
<li><p> SVMLaplaceModel: <code>C</code>, <code>sigma</code>
</p>
</li>
<li><p> SVMLinearModel: <code>C</code>
</p>
</li>
<li><p> SVMPolyModel: <code>C</code>, <code>degree</code>, <code>scale</code>
</p>
</li>
<li><p> SVMRadialModel: <code>C</code>, <code>sigma</code>
</p>
</li></ul>

</dd>
</dl>

<p>The kernel-specific constructor functions <code>SVMANOVAModel</code>,
<code>SVMBesselModel</code>, <code>SVMLaplaceModel</code>, <code>SVMLinearModel</code>,
<code>SVMPolyModel</code>, <code>SVMRadialModel</code>, <code>SVMSplineModel</code>, and
<code>SVMTanhModel</code> are special cases of <code>SVMModel</code> which automatically
set its <code>kernel</code> and <code>kpar</code> arguments.  These are called directly
in typical usage unless <code>SVMModel</code> is needed to specify a more general
model.
</p>
<p>Default argument values and further model details can be found in the source
See Also link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="kernlab.html#topic+ksvm">ksvm</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit(sale_amount ~ ., data = ICHomes, model = SVMRadialModel)

</code></pre>

<hr>
<h2 id='t.test'>Paired t-Tests for Model Comparisons</h2><span id='topic+t.test'></span><span id='topic+t.test.PerformanceDiff'></span>

<h3>Description</h3>

<p>Paired t-test comparisons of resampled performance metrics from different
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PerformanceDiff'
t.test(x, adjust = "holm", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="t.test_+3A_x">x</code></td>
<td>
<p>performance <a href="#topic+diff">difference</a> result.</p>
</td></tr>
<tr><td><code id="t.test_+3A_adjust">adjust</code></td>
<td>
<p>method of p-value adjustment for multiple statistical
comparisons as implemented by <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.</p>
</td></tr>
<tr><td><code id="t.test_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The t-test statistic for pairwise model differences of <code class="reqn">R</code> resampled
performance metric values is calculated as
</p>
<p style="text-align: center;"><code class="reqn">
  t = \frac{\bar{x}_R}{\sqrt{F s^2_R / R}},
</code>
</p>

<p>where <code class="reqn">\bar{x}_R</code> and <code class="reqn">s^2_R</code> are the sample mean and variance.
Statistical testing for a mean difference is then performed by comparing
<code class="reqn">t</code> to a <code class="reqn">t_{R-1}</code> null distribution.  The sample variance in the
t statistic is known to underestimate the true variances of cross-validation
mean estimators.  Underestimation of these variances will lead to increased
probabilities of false-positive statistical conclusions.  Thus, an additional
factor <code class="reqn">F</code> is included in the t statistic to allow for variance
corrections.  A correction of <code class="reqn">F = 1 + K / (K - 1)</code> was found by
Nadeau and Bengio (2003) to be a good choice for cross-validation with
<code class="reqn">K</code> folds and is thus used for that resampling method.  The extension of
this correction by Bouchaert and Frank (2004) to <code class="reqn">F = 1 + T K / (K - 1)</code>
is used for cross-validation with <code class="reqn">K</code> folds repeated <code class="reqn">T</code> times.  For
other resampling methods <code class="reqn">F = 1</code>.
</p>


<h3>Value</h3>

<p><code>PerformanceDiffTest</code> class object that inherits from
<code>array</code>.  p-values and mean differences are contained in the lower and
upper triangular portions, respectively, of the first two dimensions.  Model
pairs are contained in the third dimension.
</p>


<h3>References</h3>

<p>Nadeau, C., &amp; Bengio, Y. (2003). Inference for the generalization error.
<em>Machine Learning</em>, <em>52</em>, 239–81.
</p>
<p>Bouckaert, R. R., &amp; Frank, E. (2004). Evaluating the replicability of
significance tests for comparing learning algorithms. In H. Dai, R. Srikant,
&amp; C. Zhang (Eds.), <em>Advances in knowledge discovery and data mining</em>
(pp. 3–12). Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Numeric response example
fo &lt;- sale_amount ~ .
control &lt;- CVControl()

gbm_res1 &lt;- resample(fo, ICHomes, GBMModel(n.trees = 25), control)
gbm_res2 &lt;- resample(fo, ICHomes, GBMModel(n.trees = 50), control)
gbm_res3 &lt;- resample(fo, ICHomes, GBMModel(n.trees = 100), control)

res &lt;- c(GBM1 = gbm_res1, GBM2 = gbm_res2, GBM3 = gbm_res3)
res_diff &lt;- diff(res)
t.test(res_diff)


</code></pre>

<hr>
<h2 id='TreeModel'>Classification and Regression Tree Models</h2><span id='topic+TreeModel'></span>

<h3>Description</h3>

<p>A tree is grown by binary recursive partitioning using the response in the
specified formula and choosing splits from the terms of the right-hand-side.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TreeModel(
  mincut = 5,
  minsize = 10,
  mindev = 0.01,
  split = c("deviance", "gini"),
  k = numeric(),
  best = integer(),
  method = c("deviance", "misclass")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TreeModel_+3A_mincut">mincut</code></td>
<td>
<p>minimum number of observations to include in either child node.</p>
</td></tr>
<tr><td><code id="TreeModel_+3A_minsize">minsize</code></td>
<td>
<p>smallest allowed node size: a weighted quantity.</p>
</td></tr>
<tr><td><code id="TreeModel_+3A_mindev">mindev</code></td>
<td>
<p>within-node deviance must be at least this times that of the
root node for the node to be split.</p>
</td></tr>
<tr><td><code id="TreeModel_+3A_split">split</code></td>
<td>
<p>splitting criterion to use.</p>
</td></tr>
<tr><td><code id="TreeModel_+3A_k">k</code></td>
<td>
<p>scalar cost-complexity parameter defining a subtree to return.</p>
</td></tr>
<tr><td><code id="TreeModel_+3A_best">best</code></td>
<td>
<p>integer alternative to <code>k</code> requesting the number of terminal
nodes of a subtree in the cost-complexity sequence to return.</p>
</td></tr>
<tr><td><code id="TreeModel_+3A_method">method</code></td>
<td>
<p>character string denoting the measure of node heterogeneity
used to guide cost-complexity pruning.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code></p>
</dd>
</dl>

<p>Further model details can be found in the source link below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="tree.html#topic+tree">tree</a></code>, <code><a href="tree.html#topic+prune.tree">prune.tree</a></code>,
<code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package tree to run

fit(Species ~ ., data = iris, model = TreeModel)


</code></pre>

<hr>
<h2 id='TunedInput'>Tuned Model Inputs</h2><span id='topic+TunedInput'></span><span id='topic+TunedModelRecipe'></span><span id='topic+TunedInput.recipe'></span>

<h3>Description</h3>

<p>Recipe tuning over a grid of parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TunedInput(object, ...)

## S3 method for class 'recipe'
TunedInput(
  object,
  grid = expand_steps(),
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TunedInput_+3A_object">object</code></td>
<td>
<p>untrained <code><a href="recipes.html#topic+recipe">recipe</a></code>.</p>
</td></tr>
<tr><td><code id="TunedInput_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
<tr><td><code id="TunedInput_+3A_grid">grid</code></td>
<td>
<p><code>RecipeGrid</code> containing parameter values at which to
evaluate a recipe, such as those returned by <code><a href="#topic+expand_steps">expand_steps</a></code>.</p>
</td></tr>
<tr><td><code id="TunedInput_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.</p>
</td></tr>
<tr><td><code id="TunedInput_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.  If not specified, default
metrics defined in the <a href="#topic+performance">performance</a> functions are used.  Recipe
selection is based on the first calculated metric.</p>
</td></tr>
<tr><td><code id="TunedInput_+3A_cutoff">cutoff</code></td>
<td>
<p>argument passed to the <code>metrics</code> functions.</p>
</td></tr>
<tr><td><code id="TunedInput_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic on resampled metric values for recipe tuning.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TunedModelRecipe</code> class object that inherits from
<code>TunedInput</code> and <code>recipe</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+set_optim">set_optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
data(Boston, package = "MASS")

rec &lt;- recipe(medv ~ ., data = Boston) %&gt;%
  step_pca(all_numeric_predictors(), id = "pca")

grid &lt;- expand_steps(
  pca = list(num_comp = 1:2)
)

fit(TunedInput(rec, grid = grid), model = GLMModel)

</code></pre>

<hr>
<h2 id='TunedModel'>Tuned Model</h2><span id='topic+TunedModel'></span>

<h3>Description</h3>

<p>Model tuning over a grid of parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TunedModel(
  object,
  grid = MachineShop::settings("grid"),
  control = MachineShop::settings("control"),
  metrics = NULL,
  cutoff = MachineShop::settings("cutoff"),
  stat = MachineShop::settings("stat.TrainingParams")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TunedModel_+3A_object">object</code></td>
<td>
<p><a href="#topic+models">model</a> function, function name, or object
defining the model to be tuned.</p>
</td></tr>
<tr><td><code id="TunedModel_+3A_grid">grid</code></td>
<td>
<p>single integer or vector of integers whose positions or names
match the parameters in the model's pre-defined tuning grid if one exists
and which specify the number of values used to construct the grid;
<code><a href="#topic+TuningGrid">TuningGrid</a></code> function, function name, or object;
<code><a href="#topic+ParameterGrid">ParameterGrid</a></code> object; or <a href="base.html#topic+data.frame">data frame</a>
containing parameter values at which to evaluate the model, such as that
returned by <code><a href="#topic+expand_params">expand_params</a></code>.</p>
</td></tr>
<tr><td><code id="TunedModel_+3A_control">control</code></td>
<td>
<p><a href="#topic+controls">control</a> function, function name, or object
defining the resampling method to be employed.</p>
</td></tr>
<tr><td><code id="TunedModel_+3A_metrics">metrics</code></td>
<td>
<p><a href="#topic+metrics">metric</a> function, function name, or vector of
these with which to calculate performance.  If not specified, default
metrics defined in the <a href="#topic+performance">performance</a> functions are used.  Model
selection is based on the first calculated metric.</p>
</td></tr>
<tr><td><code id="TunedModel_+3A_cutoff">cutoff</code></td>
<td>
<p>argument passed to the <code>metrics</code> functions.</p>
</td></tr>
<tr><td><code id="TunedModel_+3A_stat">stat</code></td>
<td>
<p>function or character string naming a function to compute a
summary statistic on resampled metric values for model tuning.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+expand_modelgrid">expand_modelgrid</a></code> function enables manual extraction and
viewing of grids created automatically when a <code>TunedModel</code> is fit.
</p>

<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>, <code>ordered</code>,
<code>Surv</code></p>
</dd>
</dl>



<h3>Value</h3>

<p><code>TunedModel</code> class object that inherits from <code>MLModel</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit">fit</a></code>, <code><a href="#topic+resample">resample</a></code>, <code><a href="#topic+set_optim">set_optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run
## May require a long runtime

# Automatically generated grid
model_fit &lt;- fit(sale_amount ~ ., data = ICHomes,
                 model = TunedModel(GBMModel))
varimp(model_fit)
(tuned_model &lt;- as.MLModel(model_fit))
summary(tuned_model)
plot(tuned_model, type = "l")

# Randomly sampled grid points
fit(sale_amount ~ ., data = ICHomes,
    model = TunedModel(
      GBMModel,
      grid = TuningGrid(size = 1000, random = 5)
    ))

# User-specified grid
fit(sale_amount ~ ., data = ICHomes,
    model = TunedModel(
      GBMModel,
      grid = expand_params(
        n.trees = c(50, 100),
        interaction.depth = 1:2,
        n.minobsinnode = c(5, 10)
      )
    ))


</code></pre>

<hr>
<h2 id='TuningGrid'>Tuning Grid Control</h2><span id='topic+TuningGrid'></span>

<h3>Description</h3>

<p>Defines control parameters for a tuning grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TuningGrid(size = 3, random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TuningGrid_+3A_size">size</code></td>
<td>
<p>single integer or vector of integers whose positions or names
match the parameters in a model's tuning grid and which specify the number
of values used to construct the grid.</p>
</td></tr>
<tr><td><code id="TuningGrid_+3A_random">random</code></td>
<td>
<p>number of unique points to sample at random from the grid
defined by <code>size</code>.  If <code>size</code> is a single unnamed integer, then
<code>random = Inf</code> will include all values of all grid parameters in the
constructed grid, whereas <code>random = FALSE</code> will include all values of
default grid parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returned <code>TuningGrid</code> objects may be supplied to
<code><a href="#topic+TunedModel">TunedModel</a></code> for automated construction of model tuning grids.
These grids can be extracted manually and viewed with the
<code><a href="#topic+expand_modelgrid">expand_modelgrid</a></code> function.
</p>


<h3>Value</h3>

<p><code>TuningGrid</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TunedModel">TunedModel</a></code>, <code><a href="#topic+expand_modelgrid">expand_modelgrid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TunedModel(XGBTreeModel, grid = TuningGrid(10, random = 5))

</code></pre>

<hr>
<h2 id='unMLModelFit'>Revert an MLModelFit Object</h2><span id='topic+unMLModelFit'></span>

<h3>Description</h3>

<p>Function to revert an <code>MLModelFit</code> object to its original class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unMLModelFit(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unMLModelFit_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The supplied object with its <code>MLModelFit</code> classes and fields
removed.
</p>

<hr>
<h2 id='varimp'>Variable Importance</h2><span id='topic+varimp'></span>

<h3>Description</h3>

<p>Calculate measures of relative importance for model predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varimp(
  object,
  method = c("permute", "model"),
  scale = TRUE,
  sort = c("decreasing", "increasing", "asis"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varimp_+3A_object">object</code></td>
<td>
<p>model <a href="#topic+fit">fit</a> result.</p>
</td></tr>
<tr><td><code id="varimp_+3A_method">method</code></td>
<td>
<p>character string specifying the calculation of variable
importance as permutation-base (<code>"permute"</code>) or model-specific
(<code>"model"</code>).  If model-specific importance is specified but not
defined, the permutation-based method will be used instead with its default
values (below).  Permutation-based variable importance is defined as the
relative change in model predictive performances between datasets with and
without permuted values for the associated variable (Fisher et al. 2019).</p>
</td></tr>
<tr><td><code id="varimp_+3A_scale">scale</code></td>
<td>
<p>logical value or vector indicating whether importance values are
scaled to a maximum of 100.</p>
</td></tr>
<tr><td><code id="varimp_+3A_sort">sort</code></td>
<td>
<p>character string specifying the sort order of importance values
to be <code>"decreasing"</code>, <code>"increasing"</code>, or as predictors appear in
the model formula (<code>"asis"</code>).</p>
</td></tr>
<tr><td><code id="varimp_+3A_...">...</code></td>
<td>
<p>arguments passed to model-specific or permutation-based variable
importance functions.  These include the following arguments and default
values for <code>method = "permute"</code>.
</p>

<dl>
<dt><code>select = NULL</code></dt><dd><p>expression indicating predictor variables for
which to compute variable importance (see <code><a href="base.html#topic+subset">subset</a></code>
for syntax) [default: all].</p>
</dd>
<dt><code>samples = 1</code></dt><dd><p>number of times to permute the values of each
variable.  Larger numbers of samples decrease variability in the
estimates at the expense of increased computation time.</p>
</dd>
<dt><code>prop = numeric()</code></dt><dd><p>proportion of observations to sample
without replacement at each round of variable permutations [default:
all].  Subsampling of observations can decrease computation time.</p>
</dd>
<dt><code>size = integer()</code></dt><dd><p>number of observations to sample at each
round of permutations [default: all].</p>
</dd>
<dt><code>times = numeric()</code></dt><dd><p>numeric vector of follow-up times at
which to predict survival probabilities or <code>NULL</code> for predicted
survival means.</p>
</dd>
<dt><code>metric = NULL</code></dt><dd><p><a href="#topic+metrics">metric</a> function or function
name with which to calculate performance.  If not specified, the first
applicable default metric from the <a href="#topic+performance">performance</a> functions is
used.</p>
</dd>
<dt><code>compare = c("-", "/")</code></dt><dd><p>character specifying the relative
change to compute in comparing model predictive performances between
datasets with and without permuted values.  The choices are difference
(<code>"-"</code>) and ratio (<code>"/"</code>).</p>
</dd>
<dt><code>stats = MachineShop::settings("stat.TrainingParams")</code></dt><dd>
<p>function, function name, or vector of these with which to compute
summary statistics on the set of variable importance values from the
permuted datasets.</p>
</dd>
<dt><code>na.rm = TRUE</code></dt><dd><p>logical indicating whether to exclude missing
variable importance values from the calculation of summary statistics.</p>
</dd>
<dt><code>progress = TRUE</code></dt><dd><p>logical indicating whether to display
iterative progress during computation.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>varimp</code> function supports calculation of variable importance with
the permutation-based method of Fisher et al. (2019) or with model-based
methods where defined.  Permutation-based importance is the default and has
the advantages of being available for any model, any performance metric
defined for the associated response variable type, and any predictor variable
in the original training dataset.  Conversely, model-specific importance is
not defined for some models and will fall back to the permutation method in
such cases; is generally limited to metrics implemented in the source
packages of models; and may be computed on derived, rather than original,
predictor variables.  These disadvantages can make comparisons of
model-specific importance across different classes of models infeasible.  A
downside of the permutation-based approach is increased computation time.  To
counter this, the permutation algorithm can be run in parallel simply by
loading a parallel backend for the <span class="pkg">foreach</span> package <code>%dopar%</code>
function, such as <span class="pkg">doParallel</span> or <span class="pkg">doSNOW</span>.
</p>
<p>Permutation variable importance is interpreted as the contribution of a
predictor variable to the predictive performance of a model as measured by
the performance metric used in the calculation.  Importance of a predictor is
conditional on and, with the default scaling, relative to the values of all
other predictors in the analysis.
</p>


<h3>Value</h3>

<p><code>VariableImportance</code> class object.
</p>


<h3>References</h3>

<p>Fisher, A., Rudin, C., &amp; Dominici, F. (2019). All models are wrong, but many
are useful: Learning a variable's importance by studying an entire class of
prediction models simultaneously. <em>Journal of Machine Learning
Research</em>, <em>20</em>, 1-81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package gbm to run

## Survival response example
library(survival)

gbm_fit &lt;- fit(Surv(time, status) ~ ., data = veteran, model = GBMModel)
(vi &lt;- varimp(gbm_fit))
plot(vi)


</code></pre>

<hr>
<h2 id='XGBModel'>Extreme Gradient Boosting Models</h2><span id='topic+XGBModel'></span><span id='topic+XGBDARTModel'></span><span id='topic+XGBLinearModel'></span><span id='topic+XGBTreeModel'></span>

<h3>Description</h3>

<p>Fits models with an efficient implementation of the gradient boosting
framework from Chen &amp; Guestrin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XGBModel(
  nrounds = 100,
  ...,
  objective = character(),
  aft_loss_distribution = "normal",
  aft_loss_distribution_scale = 1,
  base_score = 0.5,
  verbose = 0,
  print_every_n = 1
)

XGBDARTModel(
  eta = 0.3,
  gamma = 0,
  max_depth = 6,
  min_child_weight = 1,
  max_delta_step = .(0.7 * is(y, "PoissonVariate")),
  subsample = 1,
  colsample_bytree = 1,
  colsample_bylevel = 1,
  colsample_bynode = 1,
  alpha = 0,
  lambda = 1,
  tree_method = "auto",
  sketch_eps = 0.03,
  scale_pos_weight = 1,
  refresh_leaf = 1,
  process_type = "default",
  grow_policy = "depthwise",
  max_leaves = 0,
  max_bin = 256,
  num_parallel_tree = 1,
  sample_type = "uniform",
  normalize_type = "tree",
  rate_drop = 0,
  one_drop = 0,
  skip_drop = 0,
  ...
)

XGBLinearModel(
  alpha = 0,
  lambda = 0,
  updater = "shotgun",
  feature_selector = "cyclic",
  top_k = 0,
  ...
)

XGBTreeModel(
  eta = 0.3,
  gamma = 0,
  max_depth = 6,
  min_child_weight = 1,
  max_delta_step = .(0.7 * is(y, "PoissonVariate")),
  subsample = 1,
  colsample_bytree = 1,
  colsample_bylevel = 1,
  colsample_bynode = 1,
  alpha = 0,
  lambda = 1,
  tree_method = "auto",
  sketch_eps = 0.03,
  scale_pos_weight = 1,
  refresh_leaf = 1,
  process_type = "default",
  grow_policy = "depthwise",
  max_leaves = 0,
  max_bin = 256,
  num_parallel_tree = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="XGBModel_+3A_nrounds">nrounds</code></td>
<td>
<p>number of boosting iterations.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_...">...</code></td>
<td>
<p>model parameters as described below and in the XGBoost
<a href="https://xgboost.readthedocs.io/en/latest/parameter.html">documentation</a>
and arguments passed to <code>XGBModel</code> from the other constructors.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_objective">objective</code></td>
<td>
<p>optional character string defining the learning task and
objective.  Set automatically if not specified according to the following
values available for supported response variable types.
</p>

<dl>
<dt><code>factor</code>:</dt><dd><p><code>"multi:softprob"</code>, <code>"binary:logistic"</code>
(2 levels only)</p>
</dd>
<dt><code>numeric</code>:</dt><dd><p><code>"reg:squarederror"</code>, <code>"reg:logistic"</code>,
<code>"reg:gamma"</code>, <code>"reg:tweedie"</code>, <code>"rank:pairwise"</code>,
<code>"rank:ndcg"</code>, <code>"rank:map"</code></p>
</dd>
<dt><code>PoissonVariate</code>:</dt><dd><p><code>"count:poisson"</code></p>
</dd>
<dt><code>Surv</code>:</dt><dd><p><code>"survival:aft"</code>, <code>"survival:cox"</code></p>
</dd>
</dl>

<p>The first values listed are the defaults for the corresponding response
types.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_aft_loss_distribution">aft_loss_distribution</code></td>
<td>
<p>character string specifying a distribution for
the accelerated failure time objective (<code>"survival:aft"</code>) as
<code>"extreme"</code>, <code>"logistic"</code>, or <code>"normal"</code>.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_aft_loss_distribution_scale">aft_loss_distribution_scale</code></td>
<td>
<p>numeric scaling parameter for the
accelerated failure time distribution.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_base_score">base_score</code></td>
<td>
<p>initial prediction score of all observations, global bias.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_verbose">verbose</code></td>
<td>
<p>numeric value controlling the amount of output printed
during model fitting, such that 0 = none, 1 = performance information, and
2 = additional information.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_print_every_n">print_every_n</code></td>
<td>
<p>numeric value designating the fitting iterations at
at which to print output when <code>verbose &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_eta">eta</code></td>
<td>
<p>shrinkage of variable weights at each iteration to prevent
overfitting.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_gamma">gamma</code></td>
<td>
<p>minimum loss reduction required to split a tree node.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_max_depth">max_depth</code></td>
<td>
<p>maximum tree depth.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_min_child_weight">min_child_weight</code></td>
<td>
<p>minimum sum of observation weights required of nodes.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_max_delta_step">max_delta_step</code>, <code id="XGBModel_+3A_tree_method">tree_method</code>, <code id="XGBModel_+3A_sketch_eps">sketch_eps</code>, <code id="XGBModel_+3A_scale_pos_weight">scale_pos_weight</code>, <code id="XGBModel_+3A_updater">updater</code>, <code id="XGBModel_+3A_refresh_leaf">refresh_leaf</code>, <code id="XGBModel_+3A_process_type">process_type</code>, <code id="XGBModel_+3A_grow_policy">grow_policy</code>, <code id="XGBModel_+3A_max_leaves">max_leaves</code>, <code id="XGBModel_+3A_max_bin">max_bin</code>, <code id="XGBModel_+3A_num_parallel_tree">num_parallel_tree</code></td>
<td>
<p>other tree booster parameters.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_subsample">subsample</code></td>
<td>
<p>subsample ratio of the training observations.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_colsample_bytree">colsample_bytree</code>, <code id="XGBModel_+3A_colsample_bylevel">colsample_bylevel</code>, <code id="XGBModel_+3A_colsample_bynode">colsample_bynode</code></td>
<td>
<p>subsample ratio of
variables for each tree, level, or split.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_alpha">alpha</code>, <code id="XGBModel_+3A_lambda">lambda</code></td>
<td>
<p>L1 and L2 regularization terms for variable weights.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_sample_type">sample_type</code>, <code id="XGBModel_+3A_normalize_type">normalize_type</code></td>
<td>
<p>type of sampling and normalization
algorithms.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_rate_drop">rate_drop</code></td>
<td>
<p>rate at which to drop trees during the dropout procedure.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_one_drop">one_drop</code></td>
<td>
<p>integer indicating whether to drop at least one tree during
the dropout procedure.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_skip_drop">skip_drop</code></td>
<td>
<p>probability of skipping the dropout procedure during a
boosting iteration.</p>
</td></tr>
<tr><td><code id="XGBModel_+3A_feature_selector">feature_selector</code>, <code id="XGBModel_+3A_top_k">top_k</code></td>
<td>
<p>character string specifying the feature
selection and ordering method, and number of top variables to select in the
<code>"greedy"</code> and <code>"thrifty"</code> feature selectors.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Response types:</dt><dd><p><code>factor</code>, <code>numeric</code>,
<code>PoissonVariate</code>, <code>Surv</code></p>
</dd>
<dt><a href="#topic+TunedModel">Automatic tuning</a> of grid parameters:</dt><dd>

<ul>
<li><p> XGBModel: <code>NULL</code>
</p>
</li>
<li><p> XGBDARTModel: <code>nrounds</code>, <code>eta</code>*, <code>gamma</code>*,
<code>max_depth</code>, <code>min_child_weight</code>*, <code>subsample</code>*,
<code>colsample_bytree</code>*, <code>rate_drop</code>*, <code>skip_drop</code>*
</p>
</li>
<li><p> XGBLinearModel: <code>nrounds</code>, <code>alpha</code>, <code>lambda</code>
</p>
</li>
<li><p> XGBTreeModel: <code>nrounds</code>, <code>eta</code>*, <code>gamma</code>*,
<code>max_depth</code>, <code>min_child_weight</code>*, <code>subsample</code>*,
<code>colsample_bytree</code>*
</p>
</li></ul>

</dd>
</dl>

<p>* excluded from grids by default
</p>
<p>The booster-specific constructor functions <code>XGBDARTModel</code>,
<code>XGBLinearModel</code>, and <code>XGBTreeModel</code> are special cases of
<code>XGBModel</code> which automatically set the XGBoost <code>booster</code>
<a href="https://xgboost.readthedocs.io/en/latest/parameter.html">parameter</a>.
These are called directly in typical usage unless <code>XGBModel</code> is needed
to specify a more general model.
</p>
<p>Default argument values and further model details can be found in the source
See Also link below.
</p>
<p>In calls to <code><a href="#topic+varimp">varimp</a></code> for <code>XGBTreeModel</code>, argument
<code>type</code> may be specified as <code>"Gain"</code> (default) for the fractional
contribution of each predictor to the total gain of its splits, as
<code>"Cover"</code> for the number of observations related to each predictor, or
as <code>"Frequency"</code> for the percentage of times each predictor is used in
the trees.  Variable importance is automatically scaled to range from 0 to
100.  To obtain unscaled importance values, set <code>scale = FALSE</code>.  See
example below.
</p>


<h3>Value</h3>

<p><code>MLModel</code> class object.
</p>


<h3>See Also</h3>

<p><code><a href="xgboost.html#topic+xgb.train">xgboost</a></code>, <code><a href="#topic+fit">fit</a></code>,
<code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Requires prior installation of suggested package xgboost to run

model_fit &lt;- fit(Species ~ ., data = iris, model = XGBTreeModel)
varimp(model_fit, method = "model", type = "Frequency", scale = FALSE)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
