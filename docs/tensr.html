<!DOCTYPE html><html><head><title>Help for package tensr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tensr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#tensr'><p>tensr: A package for Kronecker structured covariance inference.</p></a></li>
<li><a href='#amprod'><p><code class="reqn">k</code>-mode product.</p></a></li>
<li><a href='#anorm_cd'><p>Array normal conditional distributions.</p></a></li>
<li><a href='#array_bic_aic'><p>Calculate the AIC and BIC.</p></a></li>
<li><a href='#arrIndices'><p>Array indices.</p></a></li>
<li><a href='#atrans'><p>Tucker product.</p></a></li>
<li><a href='#collapse_mode'><p>Collapse multiple modes into one mode.</p></a></li>
<li><a href='#convert_cov'><p>Convert the output from <code>equi_mcmc</code> to component covariance matrices.</p></a></li>
<li><a href='#demean_tensor'><p>Demeans array data.</p></a></li>
<li><a href='#equi_mcmc'><p>Gibbs sampler using an invariant prior.</p></a></li>
<li><a href='#fnorm'><p>Frobenius norm of an array.</p></a></li>
<li><a href='#get_equi_bayes'><p>Get the Bayes rule under multiway Stein's loss.</p></a></li>
<li><a href='#get_isvd'><p>Calculate the incredible SVD (ISVD).</p></a></li>
<li><a href='#holq'><p>Calculate the incredible higher-order LQ decomposition (HOLQ).</p></a></li>
<li><a href='#hooi'><p>Calculate the higher-order orthogonal iteration (HOOI).</p></a></li>
<li><a href='#hosvd'><p>Calculate the (truncated) higher-order SVD (HOSVD).</p></a></li>
<li><a href='#ihop'><p>The incredible higher-order polar decomposition (IHOP).</p></a></li>
<li><a href='#kendalltau'><p>Kendall's tau measure of association.</p></a></li>
<li><a href='#Kom'><p>Commutation matrix.</p></a></li>
<li><a href='#ldan'><p>Log-likelihood of array normal model.</p></a></li>
<li><a href='#listprod'><p>Element-wise matrix products between two lists.</p></a></li>
<li><a href='#lq'><p>LQ decomposition.</p></a></li>
<li><a href='#lrt_null_dist_dim_same'><p>Draw from null distribution of likelihood ratio test statistic.</p></a></li>
<li><a href='#lrt_stat'><p>Calculate the likelihood ratio test statistic.</p></a></li>
<li><a href='#mat'><p>Unfold a matrix.</p></a></li>
<li><a href='#mhalf'><p>The symmetric square root of a positive definite matrix.</p></a></li>
<li><a href='#mle_from_holq'><p>Get MLE from output of <code>holq</code>.</p></a></li>
<li><a href='#multi_stein_loss'><p>Calculate multiway Stein's loss from square root matrices.</p></a></li>
<li><a href='#multi_stein_loss_cov'><p>Calculate multiway Stein's loss from component covariance matrices.</p></a></li>
<li><a href='#multiway_takemura'><p>Calculate a truncated multiway Takemura estimator.</p></a></li>
<li><a href='#polar'><p>The left polar decomposition.</p></a></li>
<li><a href='#qr2'><p>QR Decomposition.</p></a></li>
<li><a href='#random_ortho'><p>Generate a list of orthogonal matrices drawn from Haar distribution.</p></a></li>
<li><a href='#rmirror_wishart'><p>Sample from the mirror-Wishart distribution.</p></a></li>
<li><a href='#rmvnorm'><p>Multivariate normal simulation.</p></a></li>
<li><a href='#rsan'><p>Standard normal array.</p></a></li>
<li><a href='#rwish'><p>Wishart simulation.</p></a></li>
<li><a href='#sample_right_wishart'><p>Gibbs update of <code>Phi_inv</code>.</p></a></li>
<li><a href='#sample_sig'><p>Update for total variation parameter in <code>equi_mcmc</code>.</p></a></li>
<li><a href='#start_ident'><p>Get list of identity matrices.</p></a></li>
<li><a href='#start_resids'><p>Sample covariance matrices for each mode.</p></a></li>
<li><a href='#topK'><p>Top K elements of a vector.</p></a></li>
<li><a href='#tr'><p>Trace of a matrix.</p></a></li>
<li><a href='#trim'><p>Truncates small numbers to 0.</p></a></li>
<li><a href='#tsum'><p>Tucker sum.</p></a></li>
<li><a href='#zscores'><p>Normal scores.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Covariance Inference and Decompositions for Tensor Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-08-13</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions for Kronecker structured covariance
    estimation and testing under the array normal model. For estimation,
    maximum likelihood and Bayesian equivariant estimation procedures are
    implemented. For testing, a likelihood ratio testing procedure is
    available. This package also contains additional functions for manipulating
    and decomposing tensor data sets. This work was partially supported by NSF
    grant DMS-1505136. Details of the methods are described in
    Gerard and Hoff (2015) &lt;<a href="https://doi.org/10.1016%2Fj.jmva.2015.01.020">doi:10.1016/j.jmva.2015.01.020</a>&gt; and
    Gerard and Hoff (2016) &lt;<a href="https://doi.org/10.1016%2Fj.laa.2016.04.033">doi:10.1016/j.laa.2016.04.033</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/dcgerard/tensr/issues">http://github.com/dcgerard/tensr/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, covr, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>assertthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-08-15 14:49:02 UTC; david</td>
</tr>
<tr>
<td>Author:</td>
<td>David Gerard <a href="https://orcid.org/0000-0001-9450-5023"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Peter Hoff [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Gerard &lt;gerard.1787@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-08-15 18:00:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='tensr'>tensr: A package for Kronecker structured covariance inference.</h2><span id='topic+tensr'></span><span id='topic+tensr-package'></span>

<h3>Description</h3>

<p>This package provides a collection of functions for likelihood and
equivariant inference for covariance matrices under the array
normal model.  Also included are functions for calculating tensor
decompositions that are related to likelihood inference in the
array normal model.
</p>


<h3>Introduction</h3>

<p>Let <code class="reqn">X</code> be a multidimensional array
(also called a tensor) of K dimensions. This package provides a
series of functions to perform statistical inference when
</p>
<p style="text-align: center;"><code class="reqn">vec(X) \sim N(0,\Sigma),</code>
</p>
<p> where <code class="reqn">\Sigma</code> is assumed to
be Kronecker structured. That is, <code class="reqn">\Sigma</code> is the Kronecker
product of <code class="reqn">K</code> covariance matrices, each of which has the
interpretation of being the covariance of <code class="reqn">X</code> along its
<code class="reqn">k</code>th mode, or dimension.
</p>
<p>Pay particular attention to the zero mean assumption. That is,
you need to de-mean your data prior to applying these
functions. If you have more than one sample, <code class="reqn">X_i</code> for <code class="reqn">i
  = 1,\ldots,n</code>, then you can concatenate these tensors along a
<code class="reqn">(K+1)</code>th mode to form a new tensor <code class="reqn">Y</code> and apply the
<code>demean_tensor()</code> function to Y which will return a tensor
that satisfies the mean-zero assumption.
</p>
<p>The details of the methods in this package can be found in
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">Gerard
and Hoff (2015)</a> and <a href="https://doi.org/10.1016/j.laa.2016.04.033">Gerard
and Hoff (2016)</a>.
</p>


<h3>Tensr functions</h3>

<p><code><a href="#topic+amprod">amprod</a></code> <code class="reqn">k</code>-mode product.
</p>
<p><code><a href="#topic+anorm_cd">anorm_cd</a></code> Array normal conditional distributions.
</p>
<p><code><a href="#topic+array_bic_aic">array_bic_aic</a></code> Calculate the AIC and BIC.
</p>
<p><code><a href="#topic+arrIndices">arrIndices</a></code> Array indices.
</p>
<p><code><a href="#topic+atrans">atrans</a></code> Tucker product.
</p>
<p><code><a href="#topic+collapse_mode">collapse_mode</a></code> Collapse multiple modes into one mode.
</p>
<p><code><a href="#topic+convert_cov">convert_cov</a></code> Convert the output from <code>equi_mcmc</code> to
component covariance matrices.
</p>
<p><code><a href="#topic+demean_tensor">demean_tensor</a></code> Demeans array data.
</p>
<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code> Gibbs sampler using an invariant prior.
</p>
<p><code><a href="#topic+fnorm">fnorm</a></code> Frobenius norm of an array.
</p>
<p><code><a href="#topic+get_equi_bayes">get_equi_bayes</a></code> Get the Bayes rule under multiway Stein's
loss.
</p>
<p><code><a href="#topic+get_isvd">get_isvd</a></code> Calculate the incredible SVD (ISVD).
</p>
<p><code><a href="#topic+holq">holq</a></code> Calculate the incredible higher-order LQ decomposition
(HOLQ).
</p>
<p><code><a href="#topic+hooi">hooi</a></code> Calculate the higher-order orthogonal iteration (HOOI).
</p>
<p><code><a href="#topic+hosvd">hosvd</a></code> Calculate the (truncated) higher-order SVD (HOSVD).
</p>
<p><code><a href="#topic+Kom">Kom</a></code> Commutation matrix.
</p>
<p><code><a href="#topic+ihop">ihop</a></code> The incredible higher-order polar decomposition (IHOP).
</p>
<p><code><a href="#topic+ldan">ldan</a></code> Log-likelihood of array normal model.
</p>
<p><code><a href="#topic+listprod">listprod</a></code> Element-wise matrix products between two lists.
</p>
<p><code><a href="#topic+lq">lq</a></code> LQ decomposition.
</p>
<p><code><a href="#topic+lrt_null_dist_dim_same">lrt_null_dist_dim_same</a></code> Draw from null distribution of
likelihood ratio test statistic.
</p>
<p><code><a href="#topic+lrt_stat">lrt_stat</a></code> Calculate the likelihood ratio test statistic.
</p>
<p><code><a href="#topic+mat">mat</a></code> Unfold a matrix.
</p>
<p><code><a href="#topic+mhalf">mhalf</a></code> The symmetric square root of a positive definite
matrix.
</p>
<p><code><a href="#topic+mle_from_holq">mle_from_holq</a></code> Get MLE from output of <code>holq</code>.
</p>
<p><code><a href="#topic+multi_stein_loss">multi_stein_loss</a></code> Calculate multiway Stein's loss from square
root matrices.
</p>
<p><code><a href="#topic+multi_stein_loss_cov">multi_stein_loss_cov</a></code> Calculate multiway Stein's loss from
component covariance matrices.
</p>
<p><code><a href="#topic+multiway_takemura">multiway_takemura</a></code> Calculate a truncated multiway Takemura
estimator.
</p>
<p><code><a href="#topic+polar">polar</a></code> The left polar decomposition.
</p>
<p><code><a href="#topic+qr2">qr2</a></code> QR Decomposition.
</p>
<p><code><a href="#topic+random_ortho">random_ortho</a></code> Generate a list of orthogonal matrices drawn
from Haar distribution.
</p>
<p><code><a href="#topic+rmirror_wishart">rmirror_wishart</a></code> Sample from the mirror-Wishart distribution.
</p>
<p><code><a href="#topic+sample_sig">sample_sig</a></code> Update for total variation parameter in
<code>equi_mcmc</code>.
</p>
<p><code><a href="#topic+sample_right_wishart">sample_right_wishart</a></code>  Gibbs update of <code>Phi_inv</code>.
</p>
<p><code><a href="#topic+start_ident">start_ident</a></code> Get list of identity matrices.
</p>
<p><code><a href="#topic+start_resids">start_resids</a></code> Sample covariance matrices for each mode.
</p>
<p><code><a href="#topic+tsum">tsum</a></code> Tucker sum.
</p>
<p><code><a href="#topic+tr">tr</a></code> Trace of a matrix.
</p>
<p><code><a href="#topic+trim">trim</a></code> Truncates small numbers to 0.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>
<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>

<hr>
<h2 id='amprod'><code class="reqn">k</code>-mode product.</h2><span id='topic+amprod'></span>

<h3>Description</h3>

<p><code>amprod</code> returns the <code class="reqn">k</code>-mode product of an array with a
matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amprod(A, M, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amprod_+3A_a">A</code></td>
<td>
<p>A real valued array.</p>
</td></tr>
<tr><td><code id="amprod_+3A_m">M</code></td>
<td>
<p>A real matrix.</p>
</td></tr>
<tr><td><code id="amprod_+3A_k">k</code></td>
<td>
<p>An integer. The mode along which <code>M</code> is to be
multiplied to <code>A</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">k</code>-mode product of a tensor <code class="reqn">A</code> with a matrix <code class="reqn">M</code>
results in a tensor whose <code class="reqn">k</code>-mode unfolding is <code class="reqn">M</code> times
the <code class="reqn">k</code>-mode unfolding of <code class="reqn">A</code>. That is
<code>mat(amprod(A,M,k)) = M %*% mat(A,k)</code>.  More details of the
<code class="reqn">k</code>-mode product can be found in
<a href="https://doi.org/10.1137/07070111X"> Kolda and
Bader (2009)</a>.
</p>


<h3>Value</h3>

<p>An array whose <code class="reqn">k</code>-mode unfolding is <code>M %*%
    mat(A,k)</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>References</h3>

<p>Kolda, T. G., &amp; Bader, B. W. (2009).
<a href="https://doi.org/10.1137/07070111X">Tensor
decompositions and applications</a>. <em>SIAM review</em>, 51(3), 455-500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+atrans">atrans</a></code> for applying multiple <code class="reqn">k</code>-mode
products.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- array(1:8, dim = c(2,2,2))
M &lt;- matrix(1:4, nrow = 2, ncol = 2)
Y &lt;- amprod(A, M, 2)
Y
identical(M %*% mat(A,2), mat(Y,2))
</code></pre>

<hr>
<h2 id='anorm_cd'>Array normal conditional distributions.</h2><span id='topic+anorm_cd'></span>

<h3>Description</h3>

<p>Conditional mean and variance of a subarray.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anorm_cd(Y, M, S, saidx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anorm_cd_+3A_y">Y</code></td>
<td>
<p>A real valued array.</p>
</td></tr>
<tr><td><code id="anorm_cd_+3A_m">M</code></td>
<td>
<p>Mean of <code>Y</code>.</p>
</td></tr>
<tr><td><code id="anorm_cd_+3A_s">S</code></td>
<td>
<p>List of mode-specific covariance matrices of <code>Y</code>.</p>
</td></tr>
<tr><td><code id="anorm_cd_+3A_saidx">saidx</code></td>
<td>
<p>List of indices for indexing sub-array for which the conditional
mean and variance should be computed. For example, <code>said_x = list(1:2,
1:2, 1:2)</code> will compute the conditional means and variances for the <code class="reqn">2</code>
by <code class="reqn">2</code> by <code class="reqn">2</code> sub-array Y[1:2, 1:2, 1:2]. This is conditional on
every other element in <code>Y</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the conditional mean and variance in the array
normal model. Let <code class="reqn">Y</code> be array normal and let <code class="reqn">Y_a</code> be a subarray of
<code class="reqn">Y</code>. Then this function will calculate the conditional means and
variances of <code class="reqn">Y_a</code>, conditional on every other element in <code class="reqn">Y</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>References</h3>

<p>Hoff, P. D. (2011).
<a href="http://doi.org/10.1214/11-BA606">Separable covariance arrays via the
Tucker product, with applications to multivariate relational data</a>.
<em>Bayesian Analysis</em>, 6(2), 179-196.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(4, 4, 4)
Y &lt;- array(stats::rnorm(prod(p)), dim = p)
saidx &lt;- list(1:2, 1:2, 1:2)
true_cov &lt;- tensr::start_ident(p)
true_mean &lt;- array(0, dim = p)
cond_params &lt;- anorm_cd(Y = Y, M = true_mean, S = true_cov, saidx = saidx)

## Since data are independent standard normals, conditional mean is 0 and
##    conditional covariance matrices are identities.
cond_params$Mab
cond_params$Sab
</code></pre>

<hr>
<h2 id='array_bic_aic'>Calculate the AIC and BIC.</h2><span id='topic+array_bic_aic'></span>

<h3>Description</h3>

<p>Calculate the AIC and BIC for Kronecker structured covariance models,
assuming the array normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>array_bic_aic(sig_squared, p, mode_ident = NULL, mode_diag = NULL,
  mode_unstructured = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="array_bic_aic_+3A_sig_squared">sig_squared</code></td>
<td>
<p>A numeric. The MLE of sigma^2 in the array normal model
(the 'variance' form of the total variation parameter).</p>
</td></tr>
<tr><td><code id="array_bic_aic_+3A_p">p</code></td>
<td>
<p>A vector of integers. The dimension of the data array (including
replication modes).</p>
</td></tr>
<tr><td><code id="array_bic_aic_+3A_mode_ident">mode_ident</code></td>
<td>
<p>A vector of integers. The modes assumed to have identity
covariances.</p>
</td></tr>
<tr><td><code id="array_bic_aic_+3A_mode_diag">mode_diag</code></td>
<td>
<p>A vector of integers. The modes assumed to have diagional
covariances.</p>
</td></tr>
<tr><td><code id="array_bic_aic_+3A_mode_unstructured">mode_unstructured</code></td>
<td>
<p>A vector of integers. The modes of assumed to have
unstructured covariances.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AIC and BIC depend only on the data through the MLE of the total
variation parameter. Given this, the dimension of the array, and a
specification of which modes are the identity and which are unstructured,
this function will calculate the AIC and BIC.
</p>


<h3>Value</h3>

<p><code>AIC</code> A numeric. The AIC of the model.
</p>
<p><code>BIC</code> A numeric. The BIC of the model.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+holq">holq</a></code> for obtaining <code>sig_squared</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate random array data with first mode having unstructured covariance
#  second having diagonal covariance structure and third mode having identity
#  covariance structure.
set.seed(857)
p &lt;- c(4, 4, 4)
Z &lt;- array(stats::rnorm(prod(p)), dim = p)
Y &lt;- atrans(Z, list(tensr:::rwish(diag(p[1])), diag(1:p[2]), diag(p[3])))

# Use holq() to fit various models.
false_fit1 &lt;- holq(Y, mode_rep = 1:3) ## identity for all modes
false_fit2 &lt;- holq(Y, mode_rep = 2:3) ## unstructured first mode
true_fit &lt;- holq(Y, mode_rep = 3, mode_diag = 2) ## correct model

# Get AIC and BIC values.
false_aic1 &lt;- array_bic_aic(false_fit1$sig ^ 2, p, mode_ident = 1:length(p))
false_aic2 &lt;- array_bic_aic(false_fit2$sig ^ 2, p, mode_ident = 2:length(p),
                            mode_unstructured = 1)
true_aic &lt;- array_bic_aic(true_fit$sig ^ 2, p, mode_ident = 2:length(p), mode_diag = 1)

# Plot the results.
plot(c(false_aic1$AIC, false_aic2$AIC, true_aic$AIC), type = "l",
     xaxt = "n", xlab = "Model", ylab = "AIC", main = "AIC")
axis(side = 1, at = 1:3, labels = c("Wrong Model 1", "Wrong Model 2", "Right Model"))

plot(c(false_aic1$BIC, false_aic2$BIC, true_aic$BIC), type = "l", xaxt = "n",
     xlab = "Model", ylab = "BIC", main = "BIC")
axis(side = 1, at = 1:3, labels = c("Wrong Model 1", "Wrong Model 2", "Right Model"))
</code></pre>

<hr>
<h2 id='arrIndices'>Array indices.</h2><span id='topic+arrIndices'></span>

<h3>Description</h3>

<p>Generates indices corresponding to subarrays.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arrIndices(saidx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arrIndices_+3A_saidx">saidx</code></td>
<td>
<p>either a vector of the dimensions of a potential
array, or a list of the indices in the subarray.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates a matrix corresponding to all combinations
of a list of indices, to be used in subsetting arrays.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># all indices of an array
arrIndices(c(4, 3, 2))
# indices of a subarray
arrIndices(list(c(1, 3), c(4, 5), c(2, 3, 6)))
</code></pre>

<hr>
<h2 id='atrans'>Tucker product.</h2><span id='topic+atrans'></span>

<h3>Description</h3>

<p>Performs the Tucker product between an array and a list of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>atrans(A, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="atrans_+3A_a">A</code></td>
<td>
<p>An array of dimension <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code id="atrans_+3A_b">B</code></td>
<td>
<p>A list of matrices of length <code class="reqn">K</code>. It must be that
<code>ncol(B[[k]]) == dim(A)[k]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Tucker product between a list of matrices <code>B</code> and an array <code>A</code>
is formally equivalent to performing the <code class="reqn">k</code>-mode product between
<code>A</code> and each list element in <code>B</code>. For example, if the dimension of
<code>A</code> is three, then <code>atrans(A,B) =
amprod(amprod(amprod(A,B[[1]],1),B[[2]],2),B[[3]],3)</code>.  The ordering of this
<code class="reqn">k</code>-mode product does not matter. See
<a href="https://doi.org/10.1137/07070111X"> Kolda and Bader
(2009)</a> for details.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>References</h3>

<p>Kolda, T. G., &amp; Bader, B. W. (2009).
<a href="https://doi.org/10.1137/07070111X">Tensor
decompositions and applications</a>. <em>SIAM review</em>, 51(3), 455-500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amprod">amprod</a></code> for multiplying one matrix along one mode of an
array.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- array(1:8, dim = c(2,2,2))
B &lt;- list()
B[[1]] &lt;-matrix(1:4, nrow = 2)
B[[2]] &lt;- matrix(1:6, nrow = 3)
B[[3]] &lt;- matrix(1:2, nrow = 1)
atrans(A,B)
</code></pre>

<hr>
<h2 id='collapse_mode'>Collapse multiple modes into one mode.</h2><span id='topic+collapse_mode'></span>

<h3>Description</h3>

<p>Given an array <code>X</code> and a vector of integers <code>m</code>,
<code>collapse_mode</code> returns an array of lower order where the
first mode indexes the modes indicated in <code>m</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapse_mode(X, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collapse_mode_+3A_x">X</code></td>
<td>
<p>An array whose modes we are collapsing.</p>
</td></tr>
<tr><td><code id="collapse_mode_+3A_m">m</code></td>
<td>
<p>A vector of integers giving the modes to collapse.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Transforms an array into another array where the provided modes are
collapsed into one mode. The indexing along this new mode is in
lexicographical order of the indices of the collapsed modes. The
collapsed mode is the first mode unless <code>length(m) == 1</code>, then
<code>collapse_mode</code> simply returns <code>X</code>.
</p>


<h3>Value</h3>

<p>If <code class="reqn">X</code> is of order <code class="reqn">K</code> and <code>length(m) = q</code>,
then returns an array <code class="reqn">Y</code> of order <code class="reqn">K - q + 1</code>, where
the modes indicated in <code>m</code> are combined to be the first
mode in <code class="reqn">Y</code>.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- array(rep(c(1, 2), 8), dim = c(2, 2, 2, 2))
X
#mode 1 is now mode 2, modes 2, 3, and 4 are combined to be mode 1.
collapse_mode(X, c(2, 3, 4))
collapse_mode(X, c(2, 4)) ## another example.
collapse_mode(X, 4) #returns X
</code></pre>

<hr>
<h2 id='convert_cov'>Convert the output from <code>equi_mcmc</code> to component covariance matrices.</h2><span id='topic+convert_cov'></span>

<h3>Description</h3>

<p>This takes the output from <code>equi_mcmc</code>, which are the inverses of the
lower-triangular Cholesky square roots of the component covariance matrices,
and returns the component covariance matrices. These are the more useful
posterior draws to use in actual data analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_cov(equi_mcmc_obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert_cov_+3A_equi_mcmc_obj">equi_mcmc_obj</code></td>
<td>
<p>The output from <code>equi_mcmc</code>, which contains a list.
The first element is a list containing the posterior draws of the inverses
of the lower-triangular Cholesky square roots of each component covariance
matrix. The second list element is a total variation parameter, but the
square root of the version used in calculating the overall covariance
matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output from <code>equi_mcmc</code> is the inverse of the lower-triangular
Cholesky square root of each component covariance matrix. This output is
convenient for calculating the Bayes rule under multiway-Stein's loss (see
<code><a href="#topic+get_equi_bayes">get_equi_bayes</a></code>). Call one of these outputs from
<code>equi_mcmc</code> <code class="reqn">\Psi</code>. Then this function calculates <code class="reqn">\Sigma =
\Psi^-1\Psi^-T</code>, which are the posterior draws of the component covariance
matrices. These component covariance matrices are constrained to have
determinant one, hence there is a total variation parameter <code class="reqn">\sigma^2</code>.
</p>


<h3>Value</h3>

<p><code>cov_post</code> A list containing the posterior draws of each
component covariance matrix.
</p>
<p><code>sig2_post</code> A vector containing the posterior draws of the total
variation parameter.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate data whose true covariance is just the identity.
p &lt;- c(4,4,4)
X &lt;- array(stats::rnorm(prod(p)),dim = p)
#Then run the Gibbs sampler.
mcmc_out &lt;- equi_mcmc(X)
cov_out &lt;- convert_cov(mcmc_out)

# Some trace plots.
plot(cov_out[[2]], type = 'l', xlab = 'Iteration',
     ylab = expression(sigma ^ 2), main = 'Trace Plot')
abline(h = 1, col = 2, lty = 2)
legend('topleft', 'True Value', col = 2, lty = 2, bty = 'n')

k &lt;- sample(1:length(p), size = 1)
i &lt;- sample(1:p[k], size = 1)
j &lt;- sample(1:p[k], size = 1)
plot(cov_out[[1]][[k]][i, j, ], type = 'l', xlab = 'Iteration',
     main = 'Trace Plot',
     ylab = substitute(Sigma[k][group('[', list(i, j), ']')],
                       list(k = k, i = i, j = j)))
abline(h = 1 * (i == j), lty =  2, col = 2)
legend('topleft', 'True Value', col = 2, lty = 2, bty = 'n')
</code></pre>

<hr>
<h2 id='demean_tensor'>Demeans array data.</h2><span id='topic+demean_tensor'></span>

<h3>Description</h3>

<p>Rotates an array into two parts, one of which has mean zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demean_tensor(X, mode_reps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="demean_tensor_+3A_x">X</code></td>
<td>
<p>An array, one of whose modes is assumed to be samples from
the array normal model.</p>
</td></tr>
<tr><td><code id="demean_tensor_+3A_mode_reps">mode_reps</code></td>
<td>
<p>The mode(s) that contain(s) the samples, or
repetitions, from the array normal model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If one mode contains samples (or repetitions), then this function
will rotate the array into two parts, a mean part and a covariance
part. The 'covariance part' has mean zero and the rest of the
methods in this package apply. The 'mean part' is simply the sample
mean. If the data are array normal, then the 'covariance part' will
also be array normal with the <em>exact</em> same covariance
structure as the original tensor, except that there are one fewer
samples.
</p>


<h3>Value</h3>

<p><code>Y</code> An array that has the same dimensions as <code>X</code>
except that the mode <code>mode_reps</code> has dimension one
smaller. This array is mean 0 array normal with the same
covariance structure as <code>X</code>.
</p>
<p><code>X_bar</code> The sample mean of <code>X</code>. Under the array normal
model, <code>X</code> and <code>Y</code> are statistically independent.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>

<hr>
<h2 id='equi_mcmc'>Gibbs sampler using an invariant prior.</h2><span id='topic+equi_mcmc'></span>

<h3>Description</h3>

<p><code>equi_mcmc</code> obtains posterior draws that are useful in optimal
equivariant estimation under the array normal model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equi_mcmc(X, itermax = 1000, start_identity = FALSE, print_iter = FALSE,
  mode_rep = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="equi_mcmc_+3A_x">X</code></td>
<td>
<p>A tensor.</p>
</td></tr>
<tr><td><code id="equi_mcmc_+3A_itermax">itermax</code></td>
<td>
<p>The number of iterations in the Gibb's sampler.</p>
</td></tr>
<tr><td><code id="equi_mcmc_+3A_start_identity">start_identity</code></td>
<td>
<p>Should we start the component covariance
matrices at the identity (TRUE) or the sample covariance
matrices (FALSE)?</p>
</td></tr>
<tr><td><code id="equi_mcmc_+3A_print_iter">print_iter</code></td>
<td>
<p>Should we print the iteration number at each
iteration?</p>
</td></tr>
<tr><td><code id="equi_mcmc_+3A_mode_rep">mode_rep</code></td>
<td>
<p>The mode that contains samples. I.e., the mode
whose component covariance matrix is the identity. If NULL then
no modes are assumed to have identity covariance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>equi_mcmc</code> obtains posterior samples of the component
covariance matrices from the array normal model. This is with
respect to using the right Haar measure over a product group of
lower triangular matrices as the prior.
</p>
<p>This returns only the upper triangular Cholesky square root of the
inverses of the component covariance matrices. Equivalently, these
are the inverses of the lower triangular Cholesky square roots of
the component covariance matrices. This is because sampling the
inverse is faster computationally and the Bayes rules (based on
multiway Stein's loss) only depend on the inverse.
</p>


<h3>Value</h3>

<p><code>Phi_inv</code> List of posterior draws of the inverse of
the cholesky square roots of each component covariance
matrix. <code>Phi_inv[[i]][,,j]</code> provides the <code class="reqn">j</code>th sample
of the <code class="reqn">i</code>th component.
</p>
<p><code>sigma</code> Vector of posterior samples of the overall scale
paramater.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sample_right_wishart">sample_right_wishart</a></code> and
<code><a href="#topic+sample_sig">sample_sig</a></code> for the Gibbs
updates. <code><a href="#topic+convert_cov">convert_cov</a></code> and
<code><a href="#topic+get_equi_bayes">get_equi_bayes</a></code> for getting posterior summaries
based on the output of
<code>equi_mcmc</code>. <code><a href="#topic+multiway_takemura">multiway_takemura</a></code> for an
improvement on this procedure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate data whose true covariance is just the identity.
p &lt;- c(2,2,2)
X &lt;- array(stats::rnorm(prod(p)),dim = p)
#Then run the Gibbs sampler.
mcmc_out &lt;- equi_mcmc(X)
plot(mcmc_out$sigma, type = 'l', lwd = 2, ylab = expression(sigma),
     xlab = 'Iteration', main = 'Trace Plot')
abline(h = 1,col = 2,lty = 2)
</code></pre>

<hr>
<h2 id='fnorm'>Frobenius norm of an array.</h2><span id='topic+fnorm'></span>

<h3>Description</h3>

<p>Calculates the Frobenius norm of an array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnorm(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fnorm_+3A_x">X</code></td>
<td>
<p>An array, a matrix, or a vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Frobenius norm of an array is the square root of the sum of its
squared elements. This function works for vector and matrix
arguments as well.
</p>


<h3>Value</h3>

<p>The square root of the sum of the squared elements of
<code>X</code>.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- c(1:8)
Y &lt;- matrix(1:8, nrow = 2)
Z &lt;- array(1:8, dim = c(2, 2, 2))
fnorm(X)
fnorm(Y)
fnorm(Z)
</code></pre>

<hr>
<h2 id='get_equi_bayes'>Get the Bayes rule under multiway Stein's loss.</h2><span id='topic+get_equi_bayes'></span>

<h3>Description</h3>

<p>Given the output of <code>equi_mcmc</code>, this function will calculate the Bayes
rule under multiway Stein's loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_equi_bayes(psi_inv, sigma, burnin = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_equi_bayes_+3A_psi_inv">psi_inv</code></td>
<td>
<p>A list of arrays where <code>psi_inv[[i]][[, , j]]</code> is the
<code class="reqn">j</code>th update of the <code>i</code>th component. These components are the
inverses of the lower-triangular Cholesky square roots of the component
covariance matrices. You can just use the <code>Phi_inv</code> output from
<code>equi_mcmc</code>.</p>
</td></tr>
<tr><td><code id="get_equi_bayes_+3A_sigma">sigma</code></td>
<td>
<p>A vector of posteior draws of the total variation parameter.
This is just <code>sigma</code> from the output of <code>equi_mcmc</code>.</p>
</td></tr>
<tr><td><code id="get_equi_bayes_+3A_burnin">burnin</code></td>
<td>
<p>A numeric between 0 and 1. What proportion of the posterior
samples do you want to discard as burnin? The default is 0.25.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiway Stein's loss is a generalization of Stein's loss to more than two
dimensions. The Bayes rule under this loss is simply represented in terms of
the posterior moments of the component precision matrices. These moments can
be approximated by using the output of <code>equi_mcmc</code>. When using the
invariant prior that is used in <code>equi_mcmc</code>, the resulting Bayes rule is
the uniformly minimum risk equivariant estimator.
</p>
<p>More details on multiway Stein's loss and the Bayes rules under it can be
found in
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">
Gerard and Hoff (2015)</a>.
</p>


<h3>Value</h3>

<p><code>Sig_hat</code> A list of the Bayes rules of the component covariance
matrices under multiway Stein's loss.
</p>
<p><code>B</code> A list of the lower-triangular Cholesky square roots of the Bayes
rules of the component covariance matrices under multiway Stein's loss. We
have that <code>Sig_hat[[i]]</code> is equal to <code>B[[i]] %*% t(B[[i]])</code>.
</p>
<p><code>b</code> A numeric. This is the bayes rule of the total variation
parameter. This is the 'standard deviation' version. That is, the <code>b ^
  2</code> would be used to calculate the overall covariance matrix.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate data whose true covariance is just the identity.
p &lt;- c(4,4,4)
X &lt;- array(stats::rnorm(prod(p)),dim = p)
#Then run the Gibbs sampler.
mcmc_out &lt;- equi_mcmc(X)
bayes_rules &lt;- get_equi_bayes(mcmc_out$Phi_inv, mcmc_out$sigma)
bayes_rules$Sig_hat[[1]]
</code></pre>

<hr>
<h2 id='get_isvd'>Calculate the incredible SVD (ISVD).</h2><span id='topic+get_isvd'></span>

<h3>Description</h3>

<p>The ISVD is a generalization of the SVD to tensors. It is derived from the
incredible HOLQ.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_isvd(x_holq)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_isvd_+3A_x_holq">x_holq</code></td>
<td>
<p>The output from <code><a href="#topic+holq">holq</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code>sig * atrans(Z, L)</code> be the HOLQ of <code>X</code>. Then the ISVD
calculates the SVD of each <code>L[[i]]</code>, call it <code>U[[i]] %*% D[[i]]
%*% t(W[[i]])</code>. It then returns <code>l = sig</code>, <code>U</code>, <code>D</code>, and
<code>V = atrans(Z, W)</code>. These values have the property that <code>X</code> is
equal to <code>l * atrans(atrans(V, D), U)</code>, up to numerical precision.
<code>V</code> is also scaled all-orthonormal.
</p>
<p>For more details on the ISVD, see
<a href="https://doi.org/10.1016/j.laa.2016.04.033">Gerard and Hoff (2016)</a>.
</p>


<h3>Value</h3>

<p>l A numeric.
</p>
<p>U A list of orthogonal matrices.
</p>
<p>D A list of diagonal matrices with positive diagonal entries and unit
determinant. The diagonal entries are in descending order.
</p>
<p>V A scaled all-orthonormal array.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate random data.
p &lt;- c(4,4,4)
X &lt;- array(stats::rnorm(prod(p)), dim = p)

#Calculate HOLQ, then ISVD
holq_x &lt;- holq(X)
isvd_x &lt;- get_isvd(holq_x)
l &lt;- isvd_x$l
U &lt;- isvd_x$U
D &lt;- isvd_x$D
V &lt;- isvd_x$V

#Recover X
trim(X - l * atrans(atrans(V, D), U))

#V is scaled all-orthonormal
trim(mat(V, 1) %*% t(mat(V, 1)), epsilon = 10^-5)

trim(mat(V, 2) %*% t(mat(V, 2)), epsilon = 10^-5)

trim(mat(V, 3) %*% t(mat(V, 3)), epsilon = 10^-5)
</code></pre>

<hr>
<h2 id='holq'>Calculate the incredible higher-order LQ decomposition (HOLQ).</h2><span id='topic+holq'></span>

<h3>Description</h3>

<p>This function calculates a generalization of the LQ decomposition to tensors.
This decomposition has a close connection to likelihood inference in
Kronecker structured covariande models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>holq(X, tol = 10^-9, itermax = 1000, mode_rep = NULL, mode_diag = NULL,
  mode_ldu = NULL, print_diff = TRUE, start_vals = "identity",
  use_sig = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="holq_+3A_x">X</code></td>
<td>
<p>An array of numerics.</p>
</td></tr>
<tr><td><code id="holq_+3A_tol">tol</code></td>
<td>
<p>A numeric. The maximum difference in frobenius norm between two
successive core arrays before stopping. Or maximum difference of the ratio
of sigs from 1 before stopping (which depends on the value of
<code>use_sig</code>).</p>
</td></tr>
<tr><td><code id="holq_+3A_itermax">itermax</code></td>
<td>
<p>An integer. The maximum number of iterations of the LQ
decomposition to do before stopping.</p>
</td></tr>
<tr><td><code id="holq_+3A_mode_rep">mode_rep</code></td>
<td>
<p>A vector of integers. The optional mode(s) to be considered
identity matrices.</p>
</td></tr>
<tr><td><code id="holq_+3A_mode_diag">mode_diag</code></td>
<td>
<p>A vector of integers. The optional mode(s) to be considered
as independent but heteroscedastic.</p>
</td></tr>
<tr><td><code id="holq_+3A_mode_ldu">mode_ldu</code></td>
<td>
<p>A vector of integers. The optional modes(s) to be considered
as having unit diagonal.</p>
</td></tr>
<tr><td><code id="holq_+3A_print_diff">print_diff</code></td>
<td>
<p>A logical. Should the updates be printed to the screen each
iteration?</p>
</td></tr>
<tr><td><code id="holq_+3A_start_vals">start_vals</code></td>
<td>
<p>Determines how to start the optimization algorithm. Either
'identity' (default), or 'residuals', which results in using the cholesky
square roots of the sample covariance matrices along each mode scaled to
have unit determinant. You can also use your own start values.</p>
</td></tr>
<tr><td><code id="holq_+3A_use_sig">use_sig</code></td>
<td>
<p>A logical. What stopping criterion should we use? Frobenius
norm of difference of cores (FALSE) or absolute value of difference of
ratio of <code>sig</code> from 1 (TRUE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given an array <code>X</code>, the default version of this function will calculate
(1) <code>L</code> a list of lower triangular matricies with positive diagonal
elements and unit determinant, <code>Z</code> an array of the same dimensions as
<code>X</code> that has special orthogonal properties, and (3) <code>sig</code> a numeric
such that <code>X</code> is the same as <code>sig * atrans(Z,L)</code> up to numeric
precision.
</p>
<p>This output (1) can be considered a generalization of the LQ decomposition to
tensors, (2) solves an optimization problem which the matrix LQ decomposition
solves, and (3) has a special connection to likelihood inference in the array
normal model.
</p>
<p>There are options to constrain the matrices in <code>L</code> to either be
diagonal, lower triangular with unit diagonal, or the identity matrix. Each
of these correspond to submodels in Kronecker structured covariance models.
The core array corresponding to each of these options has different
properities (see <a href="https://doi.org/10.1016/j.laa.2016.04.033">Gerard and Hoff
(2016)</a>). These more constrained tensor decompositions are called HOLQ
juniors.
</p>
<p>The MLE of the <code class="reqn">i</code>th component covariance matrix under <em>any</em>
elliptically contoured Kronecker structured covariance model is given by
<code>L[[i]] %*% t(L[[i]])</code>. The MLE for the total variation pamarameter
will be different depending on the distribution of the array, but for the
array normal it is <code>sig ^ 2 / prod(p)</code> (the &quot;variance&quot; form for the
total variation parameter).
</p>
<p>The likelihood ratio test statistic depends only on <code>sig</code> and can be
implemented in <code><a href="#topic+lrt_stat">lrt_stat</a></code>.
</p>
<p>The algorithm used to fit the HOLQ iteratively repeats the LQ decomposition
along each mode.
</p>
<p>For more details on the incredible HOLQ, see
<a href="https://doi.org/10.1016/j.laa.2016.04.033">Gerard and Hoff (2016)</a>.
</p>


<h3>Value</h3>

<p><code>Z</code> The core array with scaled all-orthonormality property.
</p>
<p><code>A</code> A list of matrices.
</p>
<p><code>sig</code> A numeric. The total variation parameter. This is the &quot;standard
deviation&quot; form.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+array_bic_aic">array_bic_aic</a></code> for using the output of <code>holq</code> to
calculate AIC and BIC,
</p>
<p><code><a href="#topic+get_isvd">get_isvd</a></code> for using the output of <code>holq</code> to calculate a
tensor generalization of the singular value decomposition.
</p>
<p><code><a href="#topic+lq">lq</a></code> for the matrix LQ decomposition.
</p>
<p><code><a href="#topic+lrt_stat">lrt_stat</a></code> for using the output of <code>holq</code> to calculate
likelihood ratio test statistics.
</p>
<p><code><a href="#topic+mle_from_holq">mle_from_holq</a></code> for using the output of <code>holq</code> to
calculate the maximum likelihood estimates of the component covariance
matrices under the array normal model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Genrate random data.
p &lt;- c(2, 3, 4)
X &lt;- array(stats::rnorm(prod(p)), dim = p)

#Calculate HOLQ with unit diagonal on 2nd mode,
#  and diagonal along 3rd mode.
holq_x &lt;- holq(X, mode_ldu = 2, mode_diag = 3)
Z &lt;- holq_x$Z
A &lt;- holq_x$A
sig &lt;- holq_x$sig

#Reconstruct X
trim(X - sig * atrans(Z, A), 10^-5)

#Properties of core
#First mode has orthonormal rows.
trim(mat(Z, 1) %*% t(mat(Z, 1)), 10^-5)

#Second mode has orthogonal rows.
trim(mat(Z, 2) %*% t(mat(Z, 2)), 10^-5)

#Third mode has unit diagonal (up to scale).
diag(mat(Z, 3) %*% t(mat(Z, 3)))
</code></pre>

<hr>
<h2 id='hooi'>Calculate the higher-order orthogonal iteration (HOOI).</h2><span id='topic+hooi'></span>

<h3>Description</h3>

<p>This function will calculate the best rank <code>r</code> (where <code>r</code> is a
vector) approximation (in terms of sum of squared differences) to a given
data array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hooi(X, r, tol = 10^-6, print_fnorm = FALSE, itermax = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hooi_+3A_x">X</code></td>
<td>
<p>An array of numerics.</p>
</td></tr>
<tr><td><code id="hooi_+3A_r">r</code></td>
<td>
<p>A vector of integers. This is the given low multilinear rank of the
approximation.</p>
</td></tr>
<tr><td><code id="hooi_+3A_tol">tol</code></td>
<td>
<p>A numeric. Stopping criterion.</p>
</td></tr>
<tr><td><code id="hooi_+3A_print_fnorm">print_fnorm</code></td>
<td>
<p>Should updates of the optimization procedure be printed?
This number should get larger during the optimizaton procedure.</p>
</td></tr>
<tr><td><code id="hooi_+3A_itermax">itermax</code></td>
<td>
<p>The maximum number of iterations to run the optimization procedure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given an array <code>X</code>, this code will find a core array <code>G</code> and a list
of matrices with orthonormal columns <code>U</code> that minimizes <code>fnorm(X -
atrans(G, U))</code>. If <code>r</code> is equal to the dimension of <code>X</code>, then it
returns the HOSVD (see <code><a href="#topic+hosvd">hosvd</a></code>).
</p>
<p>For details on the HOOI see
<a href="https://doi.org/10.1137/S0895479898346995">Lathauwer et
al (2000)</a>.
</p>


<h3>Value</h3>

<p><code>G</code> An all-orthogonal core array.
</p>
<p><code>U</code> A vector of matrices with orthonormal columns.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>De Lathauwer, L., De Moor, B., &amp; Vandewalle, J. (2000).
<a href="http://doi.org/10.1137/S0895479898346995">On the best
rank-1 and rank-(<code class="reqn">r_1, r_2,..., r_n</code>) approximation of higher-order tensors</a>.
<em>SIAM Journal on Matrix Analysis and Applications</em>, 21(4), 1324-1342.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate random data.
p &lt;- c(2, 3, 4)
X &lt;- array(stats::rnorm(prod(p)), dim = p)

## Calculate HOOI
r &lt;- c(2, 2, 2)
hooi_x &lt;- hooi(X, r = r)
G &lt;- hooi_x$G
U &lt;- hooi_x$U

## Reconstruct the hooi approximation.
X_approx &lt;- atrans(G, U)
fnorm(X - X_approx)
</code></pre>

<hr>
<h2 id='hosvd'>Calculate the (truncated) higher-order SVD (HOSVD).</h2><span id='topic+hosvd'></span>

<h3>Description</h3>

<p>Calculates the left singular vectors of each matrix unfolding of an array,
then calculates the core array. The resulting output is a Tucker
decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hosvd(Y, r = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hosvd_+3A_y">Y</code></td>
<td>
<p>An array of numerics.</p>
</td></tr>
<tr><td><code id="hosvd_+3A_r">r</code></td>
<td>
<p>A vector of integers. The rank of the truncated HOSVD.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>r</code> is equal to the rank of <code>Y</code>, then <code>Y</code> is equal to
<code>atrans(S, U)</code>, up to numerical accuracy.
</p>
<p>More details on the HOSVD can be found in
<a href="https://doi.org/10.1137/S0895479896305696"> De Lathauwer
et. al. (2000)</a>.
</p>


<h3>Value</h3>

<p><code>U</code> A list of matrices with orthonormal columns. Each matrix
contains the mode-specific singular vectors of its mode.
</p>
<p><code>S</code> An all-orthogonal array. This is the core array from the HOSVD.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>References</h3>

<p>De Lathauwer, L., De Moor, B., &amp; Vandewalle, J. (2000).
<a href="http://doi.org/10.1137/S0895479896305696">A
multilinear singular value decomposition</a>. <em>SIAM journal on Matrix
Analysis and Applications</em>, 21(4), 1253-1278.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate random data.
p &lt;- c(2, 3, 4)
X &lt;- array(stats::rnorm(prod(p)), dim = p)

#Calculate HOSVD.
hosvd_x &lt;- hosvd(X)
S &lt;- hosvd_x$S
U &lt;- hosvd_x$U

#Recover X.
trim(X - atrans(S, U))

#S is all-orthogonal.
trim(mat(S, 1) %*% t(mat(S, 1)))
trim(mat(S, 2) %*% t(mat(S, 2)))
trim(mat(S, 3) %*% t(mat(S, 3)))
</code></pre>

<hr>
<h2 id='ihop'>The incredible higher-order polar decomposition (IHOP).</h2><span id='topic+ihop'></span>

<h3>Description</h3>

<p>Mmm, pancakes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ihop(X, itermax = 100, tol = 10^-9, print_diff = TRUE, mode_rep = NULL,
  use_sig = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ihop_+3A_x">X</code></td>
<td>
<p>An array of numerics.</p>
</td></tr>
<tr><td><code id="ihop_+3A_itermax">itermax</code></td>
<td>
<p>An integer. The maximum number of iterations to perform during
the optimization procedure.</p>
</td></tr>
<tr><td><code id="ihop_+3A_tol">tol</code></td>
<td>
<p>A numeric. The algorithm will stop when the Frobenius norm of the
difference of core arrays between subsequent iterations is below <code>tol</code>
(for <code>use_sig = FALSE</code>) or when the absolute difference between the
ratio of subsequent values of <code>sig</code> and 1 is less than <code>tol</code> (for
<code>use_sig = TRUE</code>).</p>
</td></tr>
<tr><td><code id="ihop_+3A_print_diff">print_diff</code></td>
<td>
<p>A logical. Should we print the updates of the algorithm?</p>
</td></tr>
<tr><td><code id="ihop_+3A_mode_rep">mode_rep</code></td>
<td>
<p>A vector. Which component matrices should be set to be the
identity?</p>
</td></tr>
<tr><td><code id="ihop_+3A_use_sig">use_sig</code></td>
<td>
<p>A logical. See <code>tol</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will calculate the higher-order polar decomposition, a
generalization of the polar decomposition to tensors. It generalizes a
minimization formulation of the polar decomposition.
</p>
<p>Given an array <code>X</code>, <code>ihop</code> will output <code>L</code> a list of lower
triangular matrices with positive diagonal elements and unit Frobenius norm,
<code>R</code> a core array with certain orthogonality properties, and <code>sig</code> a
total variation parameter. We have that <code>X</code> is equal to <code>sig *
atrans(R, L)</code> up to numerical precision.
</p>
<p><code>t(solve(L[[i]])) %*% mat(R, i)</code> will have orthonormal rows for all
<code>i</code>.
</p>
<p>For more details on the IHOP, see
<a href="https://doi.org/10.1016/j.laa.2016.04.033">Gerard and Hoff (2016)</a>.
</p>


<h3>Value</h3>

<p><code>R</code> A core array which, in combination with <code>L</code>, has
certain orthogonality properties.
</p>
<p><code>L</code> A list of lower triangular matrices with unit Frobenius norm.
</p>
<p><code>sig</code> A numeric.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Generate random data.
p &lt;- c(2, 3, 4)
X &lt;- array(stats::rnorm(prod(p)), dim = p)

#Calculate IHOP.
ihop_x &lt;- ihop(X)
R &lt;- ihop_x$R
L &lt;- ihop_x$L
sig &lt;- ihop_x$sig

#Reconstruct X
trim(X - sig * atrans(R, L))

#Orthogonality properties
ortho_1 &lt;- t(solve(L[[1]])) %*% mat(R, 1)
trim(ortho_1 %*% t(ortho_1))

ortho_2 &lt;- t(solve(L[[2]])) %*% mat(R, 2)
trim(ortho_2 %*% t(ortho_2))

ortho_3 &lt;- t(solve(L[[3]])) %*% mat(R, 3)
trim(ortho_3 %*% t(ortho_3))
</code></pre>

<hr>
<h2 id='kendalltau'>Kendall's tau measure of association.</h2><span id='topic+kendalltau'></span>

<h3>Description</h3>

<p>This function provides a Monte Carlo approximation to Kendall's tau
measure of association.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kendalltau(x, y, nmc = 1e+05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kendalltau_+3A_x">x</code></td>
<td>
<p>a vector.</p>
</td></tr>
<tr><td><code id="kendalltau_+3A_y">y</code></td>
<td>
<p>a vector.</p>
</td></tr>
<tr><td><code id="kendalltau_+3A_nmc">nmc</code></td>
<td>
<p>an integer number of Monte Carlo simulations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Monte Carlo approximation to Kendall's tau measure of
association.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- rexp(30)
tensr:::kendalltau(rpois(30, mu), rpois(30, mu))

</code></pre>

<hr>
<h2 id='Kom'>Commutation matrix.</h2><span id='topic+Kom'></span>

<h3>Description</h3>

<p>Construct the communtation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kom(m, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kom_+3A_m">m</code></td>
<td>
<p>a natural number.</p>
</td></tr>
<tr><td><code id="Kom_+3A_n">n</code></td>
<td>
<p>another natural number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function constructs the commutation matrix <code>K</code>, which maps
<code>c(A)</code> to <code>c(t(A))</code> for an <code class="reqn">m</code> by <code class="reqn">n</code> matrix
<code>A</code>.
</p>


<h3>Value</h3>

<p><code>K</code> The <code>m * n</code> by <code>m * n</code> commutation
matrix.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>References</h3>

<p>Magnus, J. R., &amp; Neudecker,
H. (1979). <a href="http://doi.org/10.1214/aos/1176344621">The
commutation matrix: some properties and
applications</a>. <em>The Annals of Statistics</em>, 381-394.
</p>
<p>Tracy, D. S., &amp; Dwyer,
P. S. (1969). <a href="http://doi.org/10.1080/01621459.1969.10501078">Multivariate
maxima and minima with matrix derivatives</a>. <em>Journal of the
American Statistical Association</em>, 64(328), 1576-1594.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- 5 ; n &lt;- 4
A &lt;- matrix(stats::rnorm(m * n), m, n)
Kom(5, 4) %*% c(A) - c(t(A))
</code></pre>

<hr>
<h2 id='ldan'>Log-likelihood of array normal model.</h2><span id='topic+ldan'></span>

<h3>Description</h3>

<p><code>ldan</code> calculates the log-likelihood of the array normal
model, minus a constant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldan(E, Sig)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldan_+3A_e">E</code></td>
<td>
<p>An array. This is the data.</p>
</td></tr>
<tr><td><code id="ldan_+3A_sig">Sig</code></td>
<td>
<p>A list of symmetric positive definite matrices. These
are the component covariance matrices.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David Gerard.
</p>

<hr>
<h2 id='listprod'>Element-wise matrix products between two lists.</h2><span id='topic+listprod'></span>

<h3>Description</h3>

<p>Given two lists of matrices with conformable dimensions,
<code>listprod</code> returns a list whose elements are the matrix
products of the elements of these two lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listprod(A, B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listprod_+3A_a">A</code></td>
<td>
<p>A list of matrices.</p>
</td></tr>
<tr><td><code id="listprod_+3A_b">B</code></td>
<td>
<p>A second list of matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list <code>C</code> such that <code>C[[i]] = A[[i]] %*% B[[i]]</code>.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>

<hr>
<h2 id='lq'>LQ decomposition.</h2><span id='topic+lq'></span>

<h3>Description</h3>

<p>Computes the LQ decomposition of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lq(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lq_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">n</code> by <code class="reqn">p</code> matrix of rank <code class="reqn">n</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">X</code> is an <code class="reqn">n</code> by <code class="reqn">p</code> matrix with <code class="reqn">n \le p</code>, then
<code>lq</code> computes the LQ decomposition of <code class="reqn">X</code>. That is, <code class="reqn">X
= LQ'</code> where <code class="reqn">Q</code> is <code class="reqn">p</code> by <code class="reqn">n</code> with orthonormal columns
and <code class="reqn">L</code> is <code class="reqn">n</code> by <code class="reqn">n</code> lower triangular with positive
diaognal entries.
</p>


<h3>Value</h3>

<p><code>L</code> An <code class="reqn">n</code> by <code class="reqn">n</code> lower triangular matrix with
positive diagonal entries.
</p>
<p><code>Q</code> An <code class="reqn">n</code> by <code class="reqn">p</code> matrix with orthonormal columns.
</p>
<p>The returned values satisfy <code>X = L %*% t(Q)</code>, up to
numerical precision.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qr2">qr2</a></code> for the related QR decomposition.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(stats::rnorm(12), nrow = 3)
lq_X &lt;- lq(X)
L &lt;- lq_X$L
Q &lt;- lq_X$Q
L
Q
trim(t(Q) %*% Q)
trim(X - L%*%t(Q))
</code></pre>

<hr>
<h2 id='lrt_null_dist_dim_same'>Draw from null distribution of likelihood ratio test statistic.</h2><span id='topic+lrt_null_dist_dim_same'></span>

<h3>Description</h3>

<p>When testing for the covariance structure of modes, this function may be used
to draw a sample from the null distribution of the likelihood ratio test
stistics, whose distribution doesn't depend on any unknown parameters under
the null.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrt_null_dist_dim_same(p, null_ident = NULL, alt_ident = NULL,
  null_diag = NULL, alt_diag = NULL, reference_dist = "normal",
  t_df = NULL, itermax = 100, holq_itermax = 100, holq_tol = 10^-9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrt_null_dist_dim_same_+3A_p">p</code></td>
<td>
<p>A vector of integers. The dimensions of the array.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_null_ident">null_ident</code></td>
<td>
<p>A vector of integers. The modes that under the null have
identity covariance.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_alt_ident">alt_ident</code></td>
<td>
<p>A vector of integers. The modes that under the alternative
have the identity covariance.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_null_diag">null_diag</code></td>
<td>
<p>A vector of integers. The modes that under the null have
diagonal covariance.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_alt_diag">alt_diag</code></td>
<td>
<p>A vector of integers. The modes that under the alternative
have diagonal covariance.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_reference_dist">reference_dist</code></td>
<td>
<p>Two options are supported, 'normal' and 't'. If 't' is
specified, you have to specify <code>t_df</code>.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_t_df">t_df</code></td>
<td>
<p>A numeric. If <code>reference_dist</code> is 't', then this is the
degrees of freedom of the t_distribution that the array is distributed
under.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_itermax">itermax</code></td>
<td>
<p>An integer. The number of draws from the null distribution of
the likelihood ratio test statistic that is to be performed.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_holq_itermax">holq_itermax</code></td>
<td>
<p>An integer. The maximum number of block coordinate ascent
iterations to perform when calculating the MLE at each step.</p>
</td></tr>
<tr><td><code id="lrt_null_dist_dim_same_+3A_holq_tol">holq_tol</code></td>
<td>
<p>A numeric. The stopping criterion when calculating the MLE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">vec(X)</code> be <code class="reqn">N(0,\Sigma)</code>. Given two nested hypotheses, </p>
<p style="text-align: center;"><code class="reqn">H_1:
\Sigma = \Psi_K\otimes\cdots\otimes\Psi_1</code>
</p>
<p> versus </p>
<p style="text-align: center;"><code class="reqn">H_0: \Sigma =
\Omega_K\otimes\cdots\otimes\Omega_1,</code>
</p>
<p> this function will draw from the null
distribution of the likelihood ratio test statistic. The possible options are
that <code class="reqn">\Psi_i</code> or <code class="reqn">\Omega_i</code> are the identity matrix, a diagonal
matrix, or any positive definite matrix. By default, it's assumed that these
matrices are any positive definite matrix.
</p>
<p>Unfortunately, this fuction does not support testing for the hypothesis of
modeling the covariance between two modes with a single covariance matrix. I
might code this up in later versions.
</p>


<h3>Value</h3>

<p>A vector of draws from the null distribution of the likelihood ratio
test statistic.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrt_stat">lrt_stat</a></code> for calculating the likelihood ratio test
statistic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Test for all identity versus all unconstrained.
p = c(4,4,4)
null1 &lt;- lrt_null_dist_dim_same(p,null_ident = 1:3)

#Generate Null Data
X &lt;- array(stats::rnorm(prod(p)), dim = p)
sig_null &lt;- holq(X, mode_rep = 1:3)$sig
sig_alt &lt;- holq(X)$sig
lrt_x &lt;- lrt_stat(sig_null, sig_alt, p = p)
p_value &lt;- mean(null1 &gt; lrt_x)

hist(null1,main = 'Null Distribution of LRT', xlab = 'LRT Statistic')
abline(v = lrt_x, lty = 2, col = 2, lwd = 2)
legend('topleft', 'Observed LRT Statistic', lty = 2, col = 2, lwd = 2)
mtext(side = 1, paste('P-value = ', round(p_value, digits = 2), sep = ''),
      line = 2)

#-------------------------------------------------------------------------

#Test for all identity versus all mode 1 identity,
#  mode 2 diagonal, mode 3 unconstrained.
p = c(4,4,4)
null2 &lt;- lrt_null_dist_dim_same(p,null_ident = 1:3,
                                alt_ident = 1, alt_diag = 2)

#Generate Null Data
X &lt;- array(stats::rnorm(prod(p)), dim = p)
sig_null &lt;- holq(X, mode_rep = 1:3)$sig
sig_alt &lt;- holq(X, mode_rep = 1, mode_diag = 2)$sig
lrt_x &lt;- lrt_stat(sig_null, sig_alt, p = p)
p_value &lt;- mean(null2 &gt; lrt_x)

hist(null2,main = 'Null Distribution of LRT', xlab = 'LRT Statistic')
abline(v = lrt_x, lty = 2, col = 2, lwd = 2)
legend('topleft', 'Observed LRT Statistic', lty = 2, col = 2, lwd = 2)
mtext(side = 1, paste('P-value = ', round(p_value, digits = 2), sep = ''),
      line = 2)
</code></pre>

<hr>
<h2 id='lrt_stat'>Calculate the likelihood ratio test statistic.</h2><span id='topic+lrt_stat'></span>

<h3>Description</h3>

<p>Calulate the likelihood ratio test statistic for Kronecker structured
covariance models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrt_stat(sig_null, sig_alt, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrt_stat_+3A_sig_null">sig_null</code></td>
<td>
<p>A numeric. The MLE of the total variation parameter under the
null (the standard deviation version).</p>
</td></tr>
<tr><td><code id="lrt_stat_+3A_sig_alt">sig_alt</code></td>
<td>
<p>A numeric. The MLE of the total variation parameter under the
alternative (the standard deviation version).</p>
</td></tr>
<tr><td><code id="lrt_stat_+3A_p">p</code></td>
<td>
<p>A vector of integers. The dimension of the array.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LRT statistic is the exact same for all elliptically distributed
Kronecker structured covariance models (not just the normal). The
distribution of the likelihood ratio test statistic does change.
</p>


<h3>Value</h3>

<p>A numeric. The likelihood ratio test statistic.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+holq">holq</a></code> for obtaining the MLE of the total variation
parameter.
</p>
<p><code><a href="#topic+lrt_null_dist_dim_same">lrt_null_dist_dim_same</a></code> for getting the null distribution of
the likelihood ratio test statistic.
</p>

<hr>
<h2 id='mat'>Unfold a matrix.</h2><span id='topic+mat'></span>

<h3>Description</h3>

<p><code>mat</code> returns a matrix version of a provided tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mat(A, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mat_+3A_a">A</code></td>
<td>
<p>An array to be unfolded.</p>
</td></tr>
<tr><td><code id="mat_+3A_k">k</code></td>
<td>
<p>The mode, or dimension, along which the unfolding is to be applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Applies the matrix unfolding operator (also called 'matricization' or 'matrix
flattening' operator) on a provided tensor. There are multiple ways one could
do this. This function performs the matrix unfolding described in
<a href="https://doi.org/10.1137/07070111X">Kolda and Bader
(2009)</a>.
</p>


<h3>Value</h3>

<p>A matrix  whose rows  index the  <code class="reqn">k</code>th mode  and whose columns
index every other mode.  The ordering of the columns is in lexicographical
order of the indices of the array <code class="reqn">A</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>References</h3>

<p>Kolda, T. G., &amp; Bader, B. W. (2009).
<a href="https://doi.org/10.1137/07070111X">Tensor
decompositions and applications</a>. <em>SIAM review</em>, 51(3), 455-500.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- array(1:8, dim = c(2,2,2))
mat(A, 1)
mat(A, 2)
mat(A, 3)
</code></pre>

<hr>
<h2 id='mhalf'>The symmetric square root of a positive definite matrix.</h2><span id='topic+mhalf'></span>

<h3>Description</h3>

<p>Returns the unique symmetric positive definite square root matrix
of a provided symmetric positive definite matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mhalf(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mhalf_+3A_m">M</code></td>
<td>
<p>A symmetric positive definite matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The unique symmetric positive definite matrix <code class="reqn">X</code> such
that <code class="reqn">XX = M</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- matrix(stats::rnorm(4), nrow = 2)
M &lt;- Y %*% t(Y)
X &lt;- mhalf(M)
X
identical(M, X %*% X)
</code></pre>

<hr>
<h2 id='mle_from_holq'>Get MLE from output of <code>holq</code>.</h2><span id='topic+mle_from_holq'></span>

<h3>Description</h3>

<p>From the output of <code>holq</code>, this function will calculate the
MLEs for the component covariance matrices and for the total
variation parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle_from_holq(holq_obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mle_from_holq_+3A_holq_obj">holq_obj</code></td>
<td>
<p>The output returned from <code>holq</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function simply takes the <code>A[[i]]</code> output of <code>holq</code>
and returs <code>A[[i]] %*% t(A[[i]])</code>. The estimate of the total
variation parameter is <code>sqrt(sig ^ 2 / prod{p})</code>, whre <code>p</code> is the
vector of dimensions of the data array and <code>sig</code> is the output
from <code>holq</code>.
</p>


<h3>Value</h3>

<p><code>cov_mle</code> A list of positive definite matrices. These
are the MLEs for the component covariance matrices.
</p>
<p><code>sig_mle</code> A numeric. This is an estimate of the &quot;standard
deviation&quot; form of the total variation parameter.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2016). A higher-order LQ
decomposition for separable covariance models.
<em>Linear Algebra and its Applications</em>, 505, 57-84.
<a href="https://doi.org/10.1016/j.laa.2016.04.033">https://doi.org/10.1016/j.laa.2016.04.033</a>
<a href="http://arxiv.org/pdf/1410.1094v1.pdf">http://arxiv.org/pdf/1410.1094v1.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+holq">holq</a></code>.
</p>

<hr>
<h2 id='multi_stein_loss'>Calculate multiway Stein's loss from square root matrices.</h2><span id='topic+multi_stein_loss'></span>

<h3>Description</h3>

<p>Given a list of estimates of the lower-triangular Cholesky square roots of
component covariance matrices, a list of true lower-triangular Cholesky
square roots of component covariance matrices, an estimate of the total
variation, and the true total variation, <code>multi_stein_loss</code> will
calculate multiway Stein's loss between the estimates and the truth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_stein_loss(B, Psi, b, psi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi_stein_loss_+3A_b">B</code></td>
<td>
<p>A list of lower triangular matrices. These are the 'estimates' of
the lower-triangular Cholesky square roots of the component covariance
matrices.</p>
</td></tr>
<tr><td><code id="multi_stein_loss_+3A_psi">Psi</code></td>
<td>
<p>A list of lower triangular matrices. These are the 'true'
lower-triangular Cholesky square roots of the component covariance
matrices.</p>
</td></tr>
<tr><td><code id="multi_stein_loss_+3A_b">b</code></td>
<td>
<p>A numeric. This is an 'estimate' of the total variation parameter,
the 'standard devation' version of it.</p>
</td></tr>
<tr><td><code id="multi_stein_loss_+3A_psi">psi</code></td>
<td>
<p>A numeric. This is the 'true' total variation parameter, the
'standard devation' version of it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiway Stein's loss is a generalization of Stein's loss. More details on
multiway Stein's loss and the Bayes rules under it can be found in
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">
Gerard and Hoff (2015)</a>.
</p>
<p>The function <code>multi_stien_loss_cov</code> also calculates multiway Stein's
loss, but uses the component covariance matrices (not the Cholesky roots) as
input.
</p>


<h3>Value</h3>

<p>A numeric, the multiway Stein's loss between the 'truth' and the
'estimates'.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multi_stein_loss_cov">multi_stein_loss_cov</a></code>, <code><a href="#topic+get_equi_bayes">get_equi_bayes</a></code>.
</p>

<hr>
<h2 id='multi_stein_loss_cov'>Calculate multiway Stein's loss from component covariance matrices.</h2><span id='topic+multi_stein_loss_cov'></span>

<h3>Description</h3>

<p>Given a list of estimated component covariance matrices, a list of true
component covariance matrices, an estimate of the total variation, and the
true total variation, <code>multi_stein_loss_cov</code> will calculate multiway
Stein's loss between the estimates and the truth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_stein_loss_cov(B, Sigma, b, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi_stein_loss_cov_+3A_b">B</code></td>
<td>
<p>A list of positive definite matrices. These are the 'estimates' of
the component covariance matrices.</p>
</td></tr>
<tr><td><code id="multi_stein_loss_cov_+3A_sigma">Sigma</code></td>
<td>
<p>A list of positive definite matrices. These are the 'true'
component covariance matrices.</p>
</td></tr>
<tr><td><code id="multi_stein_loss_cov_+3A_b">b</code></td>
<td>
<p>A numeric. This is an 'estimate' of the total variation parameter,
the 'standard devation' version of it.</p>
</td></tr>
<tr><td><code id="multi_stein_loss_cov_+3A_sigma">sigma</code></td>
<td>
<p>A numeric. This is the 'true' total variation parameter, the
'standard devation' version of it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiway Stein's loss is a generalization of Stein's loss. More details on
multiway Stein's loss and the Bayes rules under it can be found in
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">
Gerard and Hoff (2015)</a>.
</p>
<p>The function <code>multi_stien_loss</code> also calculates multiway Stein's loss,
but uses the lower-triangular Cholesky square roots of the component
covariance matrices as input.
</p>


<h3>Value</h3>

<p>A numeric, the multiway Stein's loss between the 'truth' and the
'estimates'.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multi_stein_loss">multi_stein_loss</a></code>, <code><a href="#topic+get_equi_bayes">get_equi_bayes</a></code>.
</p>

<hr>
<h2 id='multiway_takemura'>Calculate a truncated multiway Takemura estimator.</h2><span id='topic+multiway_takemura'></span>

<h3>Description</h3>

<p>This function will 'average' Bayes rules given random rotations of the data
array. This 'averaged' estimator has lower risk than the uniformly minimum
risk equivariant estimator under a product group of lower triangular
matrices. Truncated multiway Takemura's estimator is not equivariant with
respect to this product group of lower triangular matrices, but it is an
equivariant randomized estimator with respect to a product group of
orthogonal matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiway_takemura(X, ortho_max = 2, mcmc_itermax = 1000,
  start_identity = FALSE, print_mcmc = FALSE, mode_rep = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiway_takemura_+3A_x">X</code></td>
<td>
<p>An array. This is the data array.</p>
</td></tr>
<tr><td><code id="multiway_takemura_+3A_ortho_max">ortho_max</code></td>
<td>
<p>An integer. The number of 'averagings' to perform.</p>
</td></tr>
<tr><td><code id="multiway_takemura_+3A_mcmc_itermax">mcmc_itermax</code></td>
<td>
<p>An integer. The number of iterations each MCMC should
perform using <code>equi_mcmc</code>.</p>
</td></tr>
<tr><td><code id="multiway_takemura_+3A_start_identity">start_identity</code></td>
<td>
<p>Should each MCMC start their covariance matrices at the
identity (TRUE) or at the sample covariance matrices (FALSE)?</p>
</td></tr>
<tr><td><code id="multiway_takemura_+3A_print_mcmc">print_mcmc</code></td>
<td>
<p>Should the output of the MCMC be printed to the screen
(TRUE) or not (FALSE)?</p>
</td></tr>
<tr><td><code id="multiway_takemura_+3A_mode_rep">mode_rep</code></td>
<td>
<p>A vector of integers. Which mode(s) are considered iid
observations? Default is none.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will (1) randomly rotate <code>X</code> along every mode, then (2) it
will calculate the uniformly minimum risk equivariant estimator using
<code>equi_mcmc</code>, then (3) it will 'average' these estimates.
</p>


<h3>Value</h3>

<p><code>B</code> A list of the truncated multiway Takemura's estimators for
each component covariance matrix. Not their Cholesky square roots.
</p>
<p><code>b</code> Truncated multiway Takemura's estimator for the total variation
parameter. The 'variance' form, not the 'standard devation' form.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code>, <code><a href="#topic+random_ortho">random_ortho</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data.
p &lt;- c(5, 5, 5)
X &lt;- array(stats::rnorm(prod(p)), dim = p)
multi_out &lt;- multiway_takemura(X, mode_rep = 3)
multi_out$b
trim(multi_out$B[[1]])
trim(multi_out$B[[2]])
trim(multi_out$B[[3]])
</code></pre>

<hr>
<h2 id='polar'>The left polar decomposition.</h2><span id='topic+polar'></span>

<h3>Description</h3>

<p><code>polar</code> calculates the left polar decomposition of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polar(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polar_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>polar</code> Takes a matrix <code class="reqn">X</code>, of dimensions <code class="reqn">n</code> by
<code class="reqn">p</code>, and returns two matrices <code class="reqn">P</code> and <code class="reqn">Z</code> such that
<code class="reqn">X = PZ</code>. <code class="reqn">P</code> is a symmetric positive definite matrix of
dimension <code class="reqn">n</code> by <code class="reqn">n</code> and <code class="reqn">Z</code> is an <code class="reqn">n</code> by <code class="reqn">p</code>
matrix with orthonormal rows.
</p>


<h3>Value</h3>

<p><code>P</code> A <code class="reqn">n</code> by <code class="reqn">n</code> symmetric positive definite
matrix.
</p>
<p><code>Z</code> A <code class="reqn">n</code> by <code class="reqn">p</code> matrix with orthonormal rows.
</p>
<p>Note that <code>X == P %*% Z</code>, up to numerical precision.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(1:6, nrow = 2)
polar_x &lt;- polar(X)
P &lt;- polar_x$P
Z &lt;- polar_x$Z
P
Z
trim(Z %*% t(Z))
trim(X - P %*% Z)
</code></pre>

<hr>
<h2 id='qr2'>QR Decomposition.</h2><span id='topic+qr2'></span>

<h3>Description</h3>

<p>QR decomposition, constraining the R matrix to have non-negative diagonal
entries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qr2(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qr2_+3A_x">X</code></td>
<td>
<p>A matrix of dimension <code class="reqn">n</code> by <code class="reqn">p</code> where <code class="reqn">n \ge p</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is almost a wrapper for <code>qr()</code>, <code>qr.R()</code>, and
<code>qr.Q()</code>, except it constrains the diagonal elements of <code>R</code> to be
non-negative. If <code>X</code> is full rank with fewer columns than rows, then
this is sufficient to gaurantee uniqueness of the QR decomposition
(Proposition 5.2 of
<a href="https://books.google.com/books?id=WyvvAAAAMAAJ">Eaton (1983)</a>).
</p>


<h3>Value</h3>

<p><code>Q</code> An <code class="reqn">n</code> by <code class="reqn">p</code> matrix with orthonormal columns.
</p>
<p><code>R</code> A <code class="reqn">p</code> by <code class="reqn">p</code> upper-triangular matrix with non-negative
diagonal elements.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+qr">qr</a></code>, <code><a href="base.html#topic+qr.Q">qr.Q</a></code>, and
<code><a href="base.html#topic+qr.R">qr.R</a></code> for the base methods on the obtaining the QR
decomposition. <code><a href="#topic+lq">lq</a></code> for the related LQ decomposition.
</p>

<hr>
<h2 id='random_ortho'>Generate a list of orthogonal matrices drawn from Haar distribution.</h2><span id='topic+random_ortho'></span>

<h3>Description</h3>

<p>Given a vector <code>p</code>, <code>random_ortho</code> will generate a list
<code>ortho_list</code> such that <code>ortho_list[[i]]</code> is a matrix with row and
column dimensions <code>p[[i]]</code> and is drawn from the uniform (Haar)
distribution over the space of orthogonal matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_ortho(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_ortho_+3A_p">p</code></td>
<td>
<p>A vector of dimensions for the matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is primarily used by <code><a href="#topic+multiway_takemura">multiway_takemura</a></code> in its
averaging over uniformly minimum risk equivariant estimators under rotations
of the data array.
</p>


<h3>Value</h3>

<p><code>ortho_list</code> A list of orthogonal matrices whose dimensions are
given in <code>p</code>.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiway_takemura">multiway_takemura</a></code>.
</p>

<hr>
<h2 id='rmirror_wishart'>Sample from the mirror-Wishart distribution.</h2><span id='topic+rmirror_wishart'></span>

<h3>Description</h3>

<p>Given scale matrix <code>Phi</code> and degrees of freedom <code>nu</code>,
<code>rmirror_wishart</code> will sample from the mirror-Wishart distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmirror_wishart(nu, Phi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmirror_wishart_+3A_nu">nu</code></td>
<td>
<p>An integer. The degrees of freedom in the mirror-Wishart.</p>
</td></tr>
<tr><td><code id="rmirror_wishart_+3A_phi">Phi</code></td>
<td>
<p>A matrix. The scale matrix of the mirror-Wishart.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code class="reqn">S</code> is mirror-Wishart(<code class="reqn">\nu,\Phi</code>) if </p>
<p style="text-align: center;"><code class="reqn">S = UV'VU',</code>
</p>
<p> where
<code class="reqn">VV'</code> is the lower triangular Cholesky decomposition of a
Wishart(<code class="reqn">\nu,I</code>)-distributed random matrix and <code class="reqn">UU'</code> is the upper
triangular Cholesky decomposition of <code class="reqn">\Phi</code>. That is, <code class="reqn">V</code> is lower
triangular and <code class="reqn">U</code> is upper triangular. For details on its applications,
see
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">Gerard and Hoff (2015)</a>.
</p>


<h3>Value</h3>

<p>A matrix drawn from the mirror-Wishart distribution with <code>nu</code>
degrees of freedom and scale matrix <code>Phi</code>.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sample_right_wishart">sample_right_wishart</a></code>
</p>

<hr>
<h2 id='rmvnorm'>Multivariate normal simulation.</h2><span id='topic+rmvnorm'></span>

<h3>Description</h3>

<p>Simulate a multivariate normal random matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnorm(n, mu, Sigma, Sigma.chol = chol(Sigma))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvnorm_+3A_n">n</code></td>
<td>
<p>number of mvnormal vectors to simulate.</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_mu">mu</code></td>
<td>
<p>mean vector.</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix.</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_sigma.chol">Sigma.chol</code></td>
<td>
<p>Cholesky decomposition of <code>Sigma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates multivariate normal random vectors.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate several matrices and compute the mean.
Y &lt;- tensr:::rmvnorm(100, c(1, 2, 3), matrix(c(3, 0, 1, 0, 1, -1, 1, -1, 2), 3, 3))
colMeans(Y)
cov(Y)
</code></pre>

<hr>
<h2 id='rsan'>Standard normal array.</h2><span id='topic+rsan'></span>

<h3>Description</h3>

<p>Generate an array of iid standard normal variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsan(dim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsan_+3A_dim">dim</code></td>
<td>
<p>a vector of positive integers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions generates an array of dimension <code>dim</code> filled
with iid standard normal variables.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tensr:::rsan(c(5,4,3))
</code></pre>

<hr>
<h2 id='rwish'>Wishart simulation.</h2><span id='topic+rwish'></span>

<h3>Description</h3>

<p>Simulate a Wishart-distributed random matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rwish(S0, nu = dim(as.matrix(S0))[1] + 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rwish_+3A_s0">S0</code></td>
<td>
<p>a positive definite matrix.</p>
</td></tr>
<tr><td><code id="rwish_+3A_nu">nu</code></td>
<td>
<p>a positive scalar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates a Wishart random matrix using Bartletts
decomposition, as described in Everson and Morris (2000).
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate several matrices and compute the mean.
SS &lt;- matrix(0, 5, 5)
for(s in 1:1000) { SS &lt;- SS + tensr:::rwish(diag(5), 3) }
SS / s
</code></pre>

<hr>
<h2 id='sample_right_wishart'>Gibbs update of <code>Phi_inv</code>.</h2><span id='topic+sample_right_wishart'></span>

<h3>Description</h3>

<p>Samples an upper triangular Cholesky square root of a
mirror-Wishart distributed random variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_right_wishart(nu, V)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_right_wishart_+3A_nu">nu</code></td>
<td>
<p>A numeric. The degrees of freedom in the mirror-Wishart.</p>
</td></tr>
<tr><td><code id="sample_right_wishart_+3A_v">V</code></td>
<td>
<p>A matrix. The inverse of the scale matrix in the
mirror-Wishart.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X</code> be mirror-Wishart(<code class="reqn">\nu</code>, <code class="reqn">V^-1</code>). Then This code
returns an upper triangular <code class="reqn">C</code> where <code class="reqn">X = CC'</code>. This
function is used primarily during the Gibbs updates of the inverse
of the lower triangular Cholesky square root of the component
covariance matrices in <code>equi_mcmc</code>.
</p>


<h3>Value</h3>

<p><code>C</code> An upper triangular matrix such that <code>C %*% t(C)</code> is
a sample from the mirror-Wishart(<code>nu</code>, <code>V ^ -1</code>) distribution.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code>, <code><a href="#topic+rmirror_wishart">rmirror_wishart</a></code>.
</p>

<hr>
<h2 id='sample_sig'>Update for total variation parameter in <code>equi_mcmc</code>.</h2><span id='topic+sample_sig'></span>

<h3>Description</h3>

<p>Samples from the square root of an inverse-gamma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_sig(X, phi_inv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_sig_+3A_x">X</code></td>
<td>
<p>An array. The tensor data.</p>
</td></tr>
<tr><td><code id="sample_sig_+3A_phi_inv">phi_inv</code></td>
<td>
<p>A list of the current values of inverse of the
lower-triangular Cholesky square root of the the component covariance
matrices. This is equivalent to the transpose of the upper-triangular
Cholesky square root of the inverse component covariance matrices.
</p>
<p><code>phi_inv[[i]]</code> is a lower triangluar matrix where
<code>solve(phi_inv[[i]]) %*% t(solve(phi_inv[[i]]))</code> is the current
estimate of the <code class="reqn">i</code>th component covariance matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides a Gibbs update for the total variation parameter from
the MCMC implemented in <code>equi_mcmc</code>. This corresponds to the square root
of an inverse-gamma distributed random variable whose parameters depend on
the data and the component covariance matrices. Roughly, this is the update
for the standard deviation, not the variance.
</p>


<h3>Value</h3>

<p>A numeric. The update for the total variation parameter in the MCMC
implemented in <code>equi_bayes</code>.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>References</h3>

<p>Gerard, D., &amp; Hoff, P. (2015). Equivariant minimax
dominators of the MLE in the array normal model.
<em>Journal of Multivariate Analysis</em>, 137, 32-49.
<a href="https://doi.org/10.1016/j.jmva.2015.01.020">https://doi.org/10.1016/j.jmva.2015.01.020</a>
<a href="http://arxiv.org/pdf/1408.0424.pdf">http://arxiv.org/pdf/1408.0424.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code> for a Gibbs sampler where this function is
used.
</p>

<hr>
<h2 id='start_ident'>Get list of identity matrices.</h2><span id='topic+start_ident'></span>

<h3>Description</h3>

<p>Will provide a list of identity matrices for the specified modes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>start_ident(p, modes = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="start_ident_+3A_p">p</code></td>
<td>
<p>A vector of integers. This is the dimension of the array and the
length of the list to be created.</p>
</td></tr>
<tr><td><code id="start_ident_+3A_modes">modes</code></td>
<td>
<p>A vector of integers. These are the indices in the list to be
given an identity matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a vector of dimensions <code>p</code> and a vector indicating which
modes will get an identity matrix <code>modes</code>, this function will
return a list <code>start_vals</code> where <code>start_vals[[i]]</code> is the
identity matrix of dimensions <code>p[i]</code> if <code>i</code> is in
<code>modes</code> and will be <code>NULL</code> otherwise.
</p>
<p>This is primarily used when getting starting values in <code>equi_mcmc</code>.
</p>


<h3>Value</h3>

<p><code>start_vals</code> A list of identity matrices and NULL values.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code>.
</p>

<hr>
<h2 id='start_resids'>Sample covariance matrices for each mode.</h2><span id='topic+start_resids'></span>

<h3>Description</h3>

<p>Scaled Cholesky square roots of the sample covariance matrix and
its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>start_resids(Y, mode_rep = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="start_resids_+3A_y">Y</code></td>
<td>
<p>An array of numeric data.</p>
</td></tr>
<tr><td><code id="start_resids_+3A_mode_rep">mode_rep</code></td>
<td>
<p>A vector of integers. The modes specified by
<code>mode_rep</code> will be given an identity matrix instead of a
sample-based matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will take the sample covariance matrix of the
<code class="reqn">i</code>th matricization of an input array <code class="reqn">Y</code> and will return
(1) its lower-triangular Cholesky square root scaled down to have
determinant 1 and (2) the inverse of its lower-triangular Cholesky
square root scaled down to have determinant 1. This function is
primarily used to obtain starting values for the Gibbs sampler
implemented in <code>equi_mcmc</code>.
</p>


<h3>Value</h3>

<p><code>Sig</code> A list where <code>Sig[[i]]</code> is the
lower-triangular Cholesky square root of the sample covariance
matrix of the <code class="reqn">i</code>th mode, scaled down to have determinant
1.
</p>
<p><code>Sig_inv</code> A list where <code>Sig_inv[[i]]</code> is the inverse of the
lower-triangular Cholesky square root of the sample covariance matrix of
the <code class="reqn">i</code>th mode, scaled down to have determinant 1.
</p>
<p>If <code>mode_rep</code> is not <code>NULL</code>, then the list elements in <code>Sig</code>
and <code>Sig_inv</code> specified in <code>mode_rep</code> will be the identity matrix
instead of sample-based matrices.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+equi_mcmc">equi_mcmc</a></code>.
</p>

<hr>
<h2 id='topK'>Top K elements of a vector.</h2><span id='topic+topK'></span>

<h3>Description</h3>

<p>Identify top K elements of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topK(x, K = 1, ignoreties = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="topK_+3A_x">x</code></td>
<td>
<p>The vector.</p>
</td></tr>
<tr><td><code id="topK_+3A_k">K</code></td>
<td>
<p>The number of indices to return.</p>
</td></tr>
<tr><td><code id="topK_+3A_ignoreties">ignoreties</code></td>
<td>
<p>If <code>FALSE</code>, will return a vector of the
indices whose elements are greater than or equal to the Kth
largest element, resulting in a vector possibly of length
greater than <code>K</code> in the case of ties.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns the indices corresponding to the top elements
of a vector.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(3, 6, 2, 4, 1)
tensr:::topK(x, 3)
</code></pre>

<hr>
<h2 id='tr'>Trace of a matrix.</h2><span id='topic+tr'></span>

<h3>Description</h3>

<p>Returns the sum of the diagonal elements of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tr(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tr_+3A_x">X</code></td>
<td>
<p>A matrix whose diagonal elements will be added together.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This returns the trace of a matrix, which is just the sum of its
diagonal elements.
</p>


<h3>Value</h3>

<p>The sum of the diagonal elements of X.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(1:4, nrow = 2, ncol = 2)
X
tr(X)
</code></pre>

<hr>
<h2 id='trim'>Truncates small numbers to 0.</h2><span id='topic+trim'></span>

<h3>Description</h3>

<p>Given an array, matrix, or vector, <code>trim</code> will truncate all
elements smaller than <code>epsilon</code> (in absolute value) to zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim(X, epsilon = 10^-6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trim_+3A_x">X</code></td>
<td>
<p>An array, a matrix, or a vector.</p>
</td></tr>
<tr><td><code id="trim_+3A_epsilon">epsilon</code></td>
<td>
<p>A numeric.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All elements in <code>X</code> that are smaller than <code>epsilon</code> (in
absolute value) will be set to zero then returned.
</p>


<h3>Author(s)</h3>

<p>David Gerard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- c(0, 1, 10^-7, -1, -10^-7)
X
trim(X)
</code></pre>

<hr>
<h2 id='tsum'>Tucker sum.</h2><span id='topic+tsum'></span>

<h3>Description</h3>

<p>Computes the Tucker sum of an array and a list of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tsum(X, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tsum_+3A_x">X</code></td>
<td>
<p>A real array.</p>
</td></tr>
<tr><td><code id="tsum_+3A_a">A</code></td>
<td>
<p>A list of real matrices.</p>
</td></tr>
</table>

<hr>
<h2 id='zscores'>Normal scores.</h2><span id='topic+zscores'></span>

<h3>Description</h3>

<p>This function applies a quantile-quantile transformation to the
data, resulting in a distribution that is approximately normal but
has the same ranks as the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zscores(y, ties.method = "average")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zscores_+3A_y">y</code></td>
<td>
<p>A vector.</p>
</td></tr>
<tr><td><code id="zscores_+3A_ties.method">ties.method</code></td>
<td>
<p>The option <code>ties.method</code> in the <code>rank</code>
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the same length as <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rexp(100)
z &lt;- tensr:::zscores(y)
par(mfrow = c(1, 3))
hist(y)
hist(z)
plot(y,z)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
