<!DOCTYPE html><html><head><title>Help for package IrregLong</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {IrregLong}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abacus.plot'><p>Create an abacus plot</p>
Creates an abacus plot, depicting visits per subject over time</a></li>
<li><a href='#addcensoredrows'><p>Add rows corresponding to censoring times to a longitudinal dataset</p></a></li>
<li><a href='#extent.of.irregularity'><p>Measures of extent of visit irregularity</p>
Provides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset</a></li>
<li><a href='#iiw'><p>Given a proportional hazards model for visit intensities, compute inverse-intensity weights.</p></a></li>
<li><a href='#iiw.weights'><p>Compute inverse-intensity weights.</p></a></li>
<li><a href='#iiwgee'><p>Fit an inverse-intensity weighted GEE.</p></a></li>
<li><a href='#lagfn'><p>Create lagged versions the variables in data</p></a></li>
<li><a href='#Liang'><p>Fit a semi-parametric joint model</p></a></li>
<li><a href='#mo'><p>Multiple outputation for longitudinal data subject to irregular observation.</p></a></li>
<li><a href='#outputation'><p>Create an outputted dataset for use with multiple outputation.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analysis of Longitudinal Data with Irregular Observation Times</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-02-18</td>
</tr>
<tr>
<td>Author:</td>
<td>Eleanor Pullenayegum</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Eleanor Pullenayegum &lt;eleanor.pullenayegum@sickkids.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to help with analysis of longitudinal data featuring irregular observation times, where the observation times may be associated with the outcome process. There are functions to quantify the degree of irregularity, fit inverse-intensity weighted Generalized Estimating Equations (Lin H, Scharfstein DO, Rosenheck RA (2004) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2004.b5543.x">doi:10.1111/j.1467-9868.2004.b5543.x</a>&gt;), perform multiple outputation (Pullenayegum EM (2016) &lt;<a href="https://doi.org/10.1002%2Fsim.6829">doi:10.1002/sim.6829</a>&gt;) and fit semi-parametric joint models (Liang Y (2009) &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2008.01104.x">doi:10.1111/j.1541-0420.2008.01104.x</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>survival, geepack, data.table, graphics</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, nlme, MEMSS</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://epullenayegum.github.io/IrregLong/">https://epullenayegum.github.io/IrregLong/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-19 01:59:50 UTC; Eleanor Pullenayegum</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-21 13:40:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='abacus.plot'>Create an abacus plot
Creates an abacus plot, depicting visits per subject over time</h2><span id='topic+abacus.plot'></span>

<h3>Description</h3>

<p>Create an abacus plot
Creates an abacus plot, depicting visits per subject over time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abacus.plot(
  n,
  time,
  id,
  data,
  tmin,
  tmax,
  xlab.abacus = "Time",
  ylab.abacus = "Subject",
  pch.abacus = 16,
  col.abacus = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abacus.plot_+3A_n">n</code></td>
<td>
<p>the number of subjects to randomly sample. Subjects are sampled without replacement and therefore n must be smaller than the total number of subjects in the dataset</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_data">data</code></td>
<td>
<p>data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_tmin">tmin</code></td>
<td>
<p>the smallest time to include on the x-axis</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_tmax">tmax</code></td>
<td>
<p>the largest time to include on the x-axis</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_xlab.abacus">xlab.abacus</code></td>
<td>
<p>the label for the x-axis</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_ylab.abacus">ylab.abacus</code></td>
<td>
<p>the label for the y-axis</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_pch.abacus">pch.abacus</code></td>
<td>
<p>the plotting character for the points on the abacus plot</p>
</td></tr>
<tr><td><code id="abacus.plot_+3A_col.abacus">col.abacus</code></td>
<td>
<p>the colour of the rails on the abacus plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a plot for n randomly sampled individuals from the supplied dataset, with one row per subject and one point per visit. This can be useful for visualising the extent of irregularity in the visit process. For example, with perfect repeated measures data (i.e., no irregularity), the points will line up vertically. With greater irregularity, the points will be randomly scattered over time.
</p>


<h3>Value</h3>

<p>produces a plot depicting observation times for each subject. No values are returned
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MEMSS)
data(Phenobarb)
Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb[Phenobarb$event==1,]
abacus.plot(n=20,time="time",id="Subject",data=data,tmin=0,tmax=16*24,
xlab.abacus="Time in hours",pch=16,col.abacus=gray(0.8))
</code></pre>

<hr>
<h2 id='addcensoredrows'>Add rows corresponding to censoring times to a longitudinal dataset</h2><span id='topic+addcensoredrows'></span>

<h3>Description</h3>

<p>Add rows corresponding to censoring times to a longitudinal dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addcensoredrows(data, maxfu, tinvarcols, id, time, event)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addcensoredrows_+3A_data">data</code></td>
<td>
<p>The dataset to which rows are to be added. The data should have one row per observation</p>
</td></tr>
<tr><td><code id="addcensoredrows_+3A_maxfu">maxfu</code></td>
<td>
<p>The maximum follow-up time per subject. If all subjects have the same follow-up time, this can be supplied as a single number. Otherwise, maxfu should be a dataframe with the first column specifying subject identifiers and the second giving the follow-up time for each subject.</p>
</td></tr>
<tr><td><code id="addcensoredrows_+3A_tinvarcols">tinvarcols</code></td>
<td>
<p>A vector of column numbers corresponding to variables in data that are time-invariant.</p>
</td></tr>
<tr><td><code id="addcensoredrows_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="addcensoredrows_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="addcensoredrows_+3A_event">event</code></td>
<td>
<p>character string indicating which column of the data indicates whether or not a visit occurred. If every row corresponds to a visit, then this column will consist entirely of ones</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original dataset with extra rows corresponding to censoring times
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1:3,1:2,1:5)
x0 &lt;- c(rep(2,3),rep(0,2),rep(1,5))
id &lt;- c(rep(1,3),rep(2,2),rep(3,5))
time &lt;- c(0,4,6,2,3,1,3,5,6,7)
event &lt;- c(1,1,1,0,1,0,1,1,1,1)
data &lt;- as.data.frame(cbind(x,id,time,event,x0))
addcensoredrows(data,maxfu=8,id="id",time="time",tinvarcols=5,event="event")


x &lt;- c(1:3,1:2,1:5)
x0 &lt;- c(rep(2,3),rep(0,2),rep(1,5))
id &lt;- c(rep(1,3),rep(2,2),rep(3,5))
time &lt;- c(0,4,6,2,3,1,3,5,6,7)
event &lt;- c(1,1,1,0,1,0,1,1,1,1)
data &lt;- as.data.frame(cbind(x,id,time,event,x0))
maxfu.id &lt;- 1:3
maxfu.time &lt;- c(6,5,8)
maxfu &lt;- cbind(maxfu.id,maxfu.time)
maxfu &lt;- as.data.frame(maxfu)
addcensoredrows(data,maxfu=maxfu,id="id",time="time",tinvarcols=5,event="event")
</code></pre>

<hr>
<h2 id='extent.of.irregularity'>Measures of extent of visit irregularity
Provides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset</h2><span id='topic+extent.of.irregularity'></span>

<h3>Description</h3>

<p>Measures of extent of visit irregularity
Provides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extent.of.irregularity(
  data,
  time = "time",
  id = "id",
  scheduledtimes = NULL,
  cutpoints = NULL,
  ncutpts = NULL,
  maxfu = NULL,
  plot = FALSE,
  legendx = NULL,
  legendy = NULL,
  formula = NULL,
  tau = NULL,
  tmin = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extent.of.irregularity_+3A_data">data</code></td>
<td>
<p>The data containing information on subject identifiers and visit times</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_time">time</code></td>
<td>
<p>A character indicating which column of the data contains the times at which each of the observations in data was made</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_id">id</code></td>
<td>
<p>A character indicating which column of the data contains subject identifiers. ids are assumed to be consecutive integers, with the first subject having id 1</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_scheduledtimes">scheduledtimes</code></td>
<td>
<p>For studies with protocol-specified visit times, a vector of these times. Defaults to NULL, in which case it is assumed that there are no protocolized visit times</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_cutpoints">cutpoints</code></td>
<td>
<p>For studies with scheduled visit times, an array of dimension ncutpts by length(scheduledtimes) by 2 giving, for ncutpts sets of left and right cutpoints for each protocolized scheduled visit times. The left-hand cutpoints correspond to cutpoints[,,1] and the right-hand cutpoints to cutpoints[,,2]. Defaults to NULL, in which case cutpoints are computed as described below.</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_ncutpts">ncutpts</code></td>
<td>
<p>The number of sets of cutpoints to consider</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_maxfu">maxfu</code></td>
<td>
<p>The maximum follow-up time per subject. If all subjects have the same follow-up time, this can be supplied as a single number. Otherwise, maxfu should be a dataframe with the first column specifying subject identifiers and the second giving the follow-up time for each subject.</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_plot">plot</code></td>
<td>
<p>logical parameter indicating whether plots should be produced.</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_legendx">legendx</code></td>
<td>
<p>The x-coordinate for the position of the legend in the plot of mean proportion of individuals with 0, 1 and $&gt;$ 1 visit per bin.</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_legendy">legendy</code></td>
<td>
<p>The y-coordinate for the position of the legend in the plot of mean proportion of individuals with 0, 1 and $&gt;$ 1 visit per bin.</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_formula">formula</code></td>
<td>
<p>For studies without protocolized visit times, the formula for the null counting process model for the visit times.</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_tau">tau</code></td>
<td>
<p>The maximum time of interest</p>
</td></tr>
<tr><td><code id="extent.of.irregularity_+3A_tmin">tmin</code></td>
<td>
<p>The minimum time to be considered when constructing cutpoints for bins placed symmetrically around the scheduled observation times.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides plots and a numerical summary of the extent of irregularity in visit times. For any given set of cutpoints, it computes the proportion of individuals with 0, 1 and &gt;1 observation(s) in each bin, then takes the mean over bins. The sizes of the bins are varied and these proportions are plotted against bin size. In addition, then mean proportion of individuals with &gt;1 visit per bin is plotted vs. the mean proportion of individuals with 0 visits per bin, and the area under the curve is calculated (AUC). An AUC of 0 represents perfect repeated measures while a Poisson Process has an AUC of 0. If cutpoints are not supplied, they are computed as follows: (a) for studies with protocolized visit times, the left- and right-hand cutpoints are positioned at the protocolized time minus (or plus, for right-hand cutpoints) (1,...,ncutpts)/ncutpts times the gap to the previous (or next, respectively) protocolized visit time; (b) for studies with no protocolized visit times, cutpoints are calculated by finding, for each j in 1,...,ncutpts the largest times for which the cumulative hazard is less than j divided by the cumulative hazard evaluated at the maximum time of interest. This corresponds to choosing cutpoints such that the expected number of visits per bin is roughly equal within each set.
</p>


<h3>Value</h3>

<p>a list with counts equal to a 3-dimensional by ncutpts matrix giving, for each set of cutpoints, the mean proportion of individuals with zero, 1 and &gt;1 visits per bin, and AUC, the area under the curve of the plot of the proportion of individuals with &gt;1 visit per bin vs. the proportion of individuals with 0 visits per bin. A transformed AUC (equal to 100(1-log(4*(0.2-auc))/log(2))) is also returned for easier interpretation; a transformed auc that is equal to zero represents repeated measures, while a transformed auc from assessment times occurring as a Poisson process has value 100.
</p>


<h3>References</h3>


<ul>
<li><p> Lokku A, Birken CS, Maguire JL, Pullenayegum EM. Quantifying the extent of visit irregularity in longitudinal data. International Journal of Biostatistics 2021; Biometrika 2001; pp. 20200144
</p>
</li>
<li><p> Lokku A, Lim LS, Birken CS, Pullenayegum EM. Summarizing the extent of visit irregularity in longitudinal data. BMC medical research methodology 2020; Vol.20 (1), p.135-135
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# time-consuming so not run in R package build
library(nlme)
library(survival)
data(Phenobarb)
Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb
data &lt;- data[data$event==1,]
data$id &lt;- as.numeric(data$Subject)
counts &lt;- extent.of.irregularity(data,time="time",id="id",scheduledtimes=NULL,
cutpoints=NULL,ncutpts=10, maxfu=16*24,plot=TRUE,legendx=NULL,legendy=NULL,
formula=Surv(time.lag,time,event)~1,tau=16*24)
counts$counts
counts$auc

## End(Not run)
</code></pre>

<hr>
<h2 id='iiw'>Given a proportional hazards model for visit intensities, compute inverse-intensity weights.</h2><span id='topic+iiw'></span>

<h3>Description</h3>

<p>For a longitudinal dataset subject to irregular observation, use a Cox proportional hazards model for visit intensities to compute inverse intensity weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iiw(phfit, data, id, time, first)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iiw_+3A_phfit">phfit</code></td>
<td>
<p>coxph object for the visit process</p>
</td></tr>
<tr><td><code id="iiw_+3A_data">data</code></td>
<td>
<p>The dataset featuring longitudinal data subject to irregular observation for which inverse-intensity weights are desired</p>
</td></tr>
<tr><td><code id="iiw_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="iiw_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="iiw_+3A_first">first</code></td>
<td>
<p>logical variable. If TRUE, the first observation for each individual is assigned an intensity of 1. This is appropriate if the first visit is a baseline visit at which recruitment to the study occurred; in this case the baseline visit is observed with probability 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of inverse-intensity weights for each row of the dataset. The first observation for each subject is assumed to have an intensity of 1.
</p>


<h3>See Also</h3>

<p>Other iiw: 
<code><a href="#topic+iiw.weights">iiw.weights</a>()</code>,
<code><a href="#topic+iiwgee">iiwgee</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
library(survival)
library(geepack)
library(data.table)
data(Phenobarb)
Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb
data &lt;- data[data$event==1,]
data$id &lt;- as.numeric(data$Subject)
data &lt;- data[data$time&lt;16*24,]
data &lt;- lagfn(data, lagvars=c("time","conc"), id="Subject", time="time", lagfirst = NA)
head(data)

mph &lt;- coxph(Surv(time.lag,time,event)~I(conc.lag&gt;0 &amp; conc.lag&lt;=20) + I(conc.lag&gt;20 &amp; conc.lag&lt;=30)
 + I(conc.lag&gt;30)+ cluster(id),,data=data)
summary(mph)
data$weight &lt;- iiw(mph,data,"id","time",TRUE)
head(data)
</code></pre>

<hr>
<h2 id='iiw.weights'>Compute inverse-intensity weights.</h2><span id='topic+iiw.weights'></span>

<h3>Description</h3>

<p>Since the vector of weights is ordered on id and time, if you intend to merge these weights onto your original dataset it is highly recommended that you sort the data before running iiw.weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iiw.weights(
  formulaph,
  formulanull = NULL,
  data,
  id,
  time,
  event,
  lagvars,
  invariant = NULL,
  maxfu,
  lagfirst = lagfirst,
  first
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iiw.weights_+3A_formulaph">formulaph</code></td>
<td>
<p>the formula for the proportional hazards model for the visit intensity that will be used to derive inverse-intensity weights. The formula should usually use the counting process format (i.e. Surv(start,stop,event)). If a frailty model is used, the cluster(id) term should appear before other covariates</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_formulanull">formulanull</code></td>
<td>
<p>if stabilised weights are to be used, the formula for the null model used to stabilise the weights</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_data">data</code></td>
<td>
<p>data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_event">event</code></td>
<td>
<p>character string indicating which column of the data indicates whether or not a visit occurred. If every row corresponds to a visit, then this column will consist entirely of ones</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_lagvars">lagvars</code></td>
<td>
<p>a vector of variable names corresponding to variables which need to be lagged by one visit to fit the visit intensity model. Typically time will be one of these variables. The function will internally add columns to the data containing the values of the lagged variables from the previous visit. Values of lagged variables for a subject's first visit will be set to NA. To access these variables in specifying the proportional hazards formulae, add &quot;.lag&quot; to the variable you wish to lag. For example, if time is the variable for time, time.lag is the time of the previous visit</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_invariant">invariant</code></td>
<td>
<p>a vector of variable names corresponding to variables in data that are time-invariant. It is not necessary to list every such variable, just those that are invariant and also included in the proportional hazards model</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_maxfu">maxfu</code></td>
<td>
<p>the maximum follow-up time(s). If everyone is followed for the same length of time, this can be given as a single value. If individuals have different follow-up times, maxfu should have the same number of elements as there are rows of data</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_lagfirst">lagfirst</code></td>
<td>
<p>A vector giving the value of each lagged variable for the first time within each subject. This is helpful if, for example, time is the variable to be lagged and you know that all subjects entered the study at time zero</p>
</td></tr>
<tr><td><code id="iiw.weights_+3A_first">first</code></td>
<td>
<p>logical variable. If TRUE, the first observation for each individual is assigned an intensity of 1. This is appropriate if the first visit is a baseline visit at which recruitment to the study occurred; in this case the baseline visit is observed with probability 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given longitudinal data with irregular visit times, fit a Cox proportional hazards model for the visit intensity, then use it to compute inverse-intensity weights
</p>


<h3>Value</h3>

<p>a vector of inverse-intensity weights, ordered on id then time
</p>


<h3>References</h3>


<ul>
<li><p> Lin H, Scharfstein DO, Rosenheck RA. Analysis of Longitudinal data with Irregular, Informative Follow-up. Journal of the Royal Statistical Society, Series B (2004), 66:791-813
</p>
</li>
<li><p> Buzkova P, Lumley T. Longitudinal data analysis for generalized linear models with follow-up dependent on outcome-related variables. The Canadian Journal of Statistics 2007; 35:485-500.</p>
</li></ul>



<h3>See Also</h3>

<p>Other iiw: 
<code><a href="#topic+iiwgee">iiwgee</a>()</code>,
<code><a href="#topic+iiw">iiw</a>()</code>
</p>
<p>Other iiw: 
<code><a href="#topic+iiwgee">iiwgee</a>()</code>,
<code><a href="#topic+iiw">iiw</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
data(Phenobarb)
library(survival)
library(geepack)
library(data.table)
Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb
data &lt;- data[data$event==1,]
data$id &lt;- as.numeric(data$Subject)
data &lt;- data[data$time&lt;16*24,]
i &lt;- iiw.weights(Surv(time.lag,time,event)~I(conc.lag&gt;0 &amp; conc.lag&lt;=20) +
I(conc.lag&gt;20 &amp; conc.lag&lt;=30) + I(conc.lag&gt;30)+ cluster(id),
id="id",time="time",event="event",data=data,
invariant="id",lagvars=c("time","conc"),maxfu=16*24,lagfirst=0,first=TRUE)
data$weight &lt;- i$iiw.weight
summary(i$m)
# can use to fit a weighted GEE
mw &lt;- geeglm(conc ~ I(time^3) + log(time) , id=Subject, data=data, weights=weight)
summary(mw)
# agrees with results through the single command iiwgee
miiwgee &lt;- iiwgee(conc ~ I(time^3) + log(time),
Surv(time.lag,time,event)~I(conc.lag&gt;0 &amp; conc.lag&lt;=20) +
I(conc.lag&gt;20 &amp; conc.lag&lt;=30) + I(conc.lag&gt;30)+ cluster(id),
id="id",time="time",event="event",data=data,
invariant="id",lagvars=c("time","conc"),maxfu=16*24,lagfirst=0,first=TRUE)
summary(miiwgee$geefit)
</code></pre>

<hr>
<h2 id='iiwgee'>Fit an inverse-intensity weighted GEE.</h2><span id='topic+iiwgee'></span>

<h3>Description</h3>

<p>Implements inverse-intensity weighted GEEs as first described by Lin, Scharfstein and Rosenheck (2004). A Cox proportional hazards model is applied to the visit intensities, and the hazard multipliers are used to compute inverse-intensity weights. Using the approach described by Buzkova and Lumley (2007) avoids the need to compute the baseline hazard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iiwgee(
  formulagee,
  formulaph,
  formulanull = NULL,
  data,
  id,
  time,
  event,
  family = gaussian,
  lagvars,
  invariant = NULL,
  maxfu,
  lagfirst,
  first
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iiwgee_+3A_formulagee">formulagee</code></td>
<td>
<p>the formula for the GEE model to be fit. The syntax used is the same as in geeglm</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_formulaph">formulaph</code></td>
<td>
<p>the formula for the proportional hazards model for the visit intensity that will be used to derive inverse-intensity weights. The formula should usually use the counting process format (i.e. Surv(start,stop,event))</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_formulanull">formulanull</code></td>
<td>
<p>if stabilised weights are to be used, the formula for the null model used to stabilise the weights</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_data">data</code></td>
<td>
<p>data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_event">event</code></td>
<td>
<p>character string indicating which column of the data indicates whether or not a visit occurred. If every row corresponds to a visit, then this column will consist entirely of ones</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_family">family</code></td>
<td>
<p>family to be used in the GEE fit. See geeglm for documentation</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_lagvars">lagvars</code></td>
<td>
<p>a vector of variable names corresponding to variables which need to be lagged by one visit to fit the visit intensity model. Typically time will be one of these variables. The function will internally add columns to the data containing the values of the lagged variables from the previous visit. Values of lagged variables for a subject's first visit will be set to NA. To access these variables in specifying the proportional hazards formulae, add &quot;.lag&quot; to the variable you wish to lag. For example, if time is the variable for time, time.lag is the time of the previous visit</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_invariant">invariant</code></td>
<td>
<p>a vector of variable names corresponding to variables in data that are time-invariant. It is not necessary to list every such variable, just those that are invariant and also included in the proportional hazards model</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_maxfu">maxfu</code></td>
<td>
<p>the maximum follow-up time(s). If everyone is followed for the same length of time, this can be given as a single value. If individuals have different follow-up times, maxfu should have the same number of elements as there are rows of data</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_lagfirst">lagfirst</code></td>
<td>
<p>A vector giving the value of each lagged variable for the first time within each subject. This is helpful if, for example, time is the variable to be lagged and you know that all subjects entered the study at time zero</p>
</td></tr>
<tr><td><code id="iiwgee_+3A_first">first</code></td>
<td>
<p>logical variable. If TRUE, the first observation for each individual is assigned an intensity of 1. This is appropriate if the first visit is a baseline visit at which recruitment to the study occurred; in this case the baseline visit is observed with probability 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the outcome of interest be <code class="reqn">Y</code> and suppose that subject i has <code class="reqn">j^{th}</code> observation at <code class="reqn">T_{ij}</code>. Let <code class="reqn">N_i(t)</code> be a counting process for the number of observations for subject i up to and including time t. Suppose that <code class="reqn">N_i</code> has intensity <code class="reqn">\lambda</code> given by </p>
<p style="text-align: center;"><code class="reqn">\lambda_i(t)=\lambda0(t)exp(Z_i(t)\gamma).</code>
</p>
<p> Then the inverse-intensity weights are </p>
<p style="text-align: center;"><code class="reqn">exp(-Z_i(t)\gamma).</code>
</p>
<p> If <code class="reqn">Y_i</code> is the vector of observations for subject <code class="reqn">i</code>, to be regressed onto <code class="reqn">X_i</code> (i.e. <code class="reqn">E(Y_i|X_i)=\mu(X_i;\beta)</code> with <code class="reqn">g(\mu(X_i;beta)=X_i\beta</code>, then the inverse-intensity weighted GEE equations are </p>
<p style="text-align: center;"><code class="reqn">\sum_i \frac{\partial\mu_i}{\partial\beta}V_i^{-1}\Delta_i(Y_i X_i\beta)=0</code>
</p>
<p>, where <code class="reqn">\Delta_i</code> is a diagonal matrix with <code class="reqn">j^{th}</code> entry equal to <code class="reqn">\exp(-Z_i(T_{ij})\gamma)</code> and $V_i$ is the working variance matrix.
Warning: Due to the way some gee functions incorporate weights, if using inverse-intensity weighting you should use working independence.
</p>


<h3>Value</h3>

<p>a list, with the following elements:
</p>
<table>
<tr><td><code>geefit</code></td>
<td>
<p>the fitted GEE, see documentation for geeglm for details</p>
</td></tr>
<tr><td><code>phfit</code></td>
<td>
<p>the fitted proportional hazards model, see documentation for coxph for details</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Lin H, Scharfstein DO, Rosenheck RA. Analysis of Longitudinal data with Irregular, Informative Follow-up. Journal of the Royal Statistical Society, Series B (2004), 66:791-813
</p>
</li>
<li><p> Buzkova P, Lumley T. Longitudinal data analysis for generalized linear models with follow-up dependent on outcome-related variables. The Canadian Journal of Statistics 2007; 35:485-500.</p>
</li></ul>



<h3>See Also</h3>

<p>Other iiw: 
<code><a href="#topic+iiw.weights">iiw.weights</a>()</code>,
<code><a href="#topic+iiw">iiw</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
data(Phenobarb)
library(survival)
library(geepack)
library(data.table)
Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb
data &lt;- data[data$event==1,]
data$id &lt;- as.numeric(data$Subject)
data &lt;- data[data$time&lt;16*24,]
miiwgee &lt;- iiwgee(conc ~ I(time^3) + log(time),
Surv(time.lag,time,event)~I(conc.lag&gt;0 &amp; conc.lag&lt;=20) +
I(conc.lag&gt;20 &amp; conc.lag&lt;=30) + I(conc.lag&gt;30)+ cluster(id),
id="id",time="time",event="event",data=data,
invariant="id",lagvars=c("time","conc"),maxfu=16*24,lagfirst=0,first=TRUE)
summary(miiwgee$geefit)
summary(miiwgee$phfit)

# compare to results without weighting
m &lt;- geeglm(conc ~ I(time^3) + log(time) , id=Subject, data=data); print(summary(m))
time &lt;- (1:200)
unweighted &lt;- cbind(rep(1,200),time^3,log(time))%*%m$coefficients
weighted &lt;- cbind(rep(1,200),time^3,log(time))%*%miiwgee$geefit$coefficients
plot(data$time,data$conc,xlim=c(0,200),pch=16)
lines(time,unweighted,type="l")
lines(time,weighted,col=2)
legend (0,60,legend=c("Unweighted","Inverse-intensity weighted"),col=1:2,bty="n",lty=1)
</code></pre>

<hr>
<h2 id='lagfn'>Create lagged versions the variables in data</h2><span id='topic+lagfn'></span>

<h3>Description</h3>

<p>Create lagged versions the variables in data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagfn(data, lagvars, id, time, lagfirst = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lagfn_+3A_data">data</code></td>
<td>
<p>The data to be lagged</p>
</td></tr>
<tr><td><code id="lagfn_+3A_lagvars">lagvars</code></td>
<td>
<p>The names of the columns in the data to be lagged</p>
</td></tr>
<tr><td><code id="lagfn_+3A_id">id</code></td>
<td>
<p>A character indicating which column of the data contains subject identifiers. ids are assumed to be consecutive integers, with the first subject having id 1</p>
</td></tr>
<tr><td><code id="lagfn_+3A_time">time</code></td>
<td>
<p>A character indicating which column of the data contains the times at which each of the observations in data was made</p>
</td></tr>
<tr><td><code id="lagfn_+3A_lagfirst">lagfirst</code></td>
<td>
<p>A vector giving the value of each lagged variable for the first time within each subject. This is helpful if, for example, time is the variable to be lagged and you know that all subjects entered the study at time zero</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original data frame with lagged variables added on as columns. For example, if the data frame contains a variable named x giving the value of x for each subject i at each visit j, the returned data frame will contain a column named x.lag containing the value of x for subject i at visit j-1. If j is the first visit for subject i, the lagged value is set to NA
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
library(data.table)
data(Phenobarb)
head(Phenobarb)

data &lt;- lagfn(Phenobarb,"time","Subject","time")
head(data)
</code></pre>

<hr>
<h2 id='Liang'>Fit a semi-parametric joint model</h2><span id='topic+Liang'></span>

<h3>Description</h3>

<p>Fits a semi-parametric joint model as described by Liang et al. (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Liang(
  data,
  Yname,
  Xnames,
  Wnames,
  Znames = NULL,
  formulaobs = NULL,
  id,
  time,
  invariant = NULL,
  lagvars = NULL,
  lagfirst = NULL,
  maxfu,
  baseline,
  Xfn = NULL,
  Wfn = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Liang_+3A_data">data</code></td>
<td>
<p>data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="Liang_+3A_yname">Yname</code></td>
<td>
<p>character string indicating the column containing the outcome variable</p>
</td></tr>
<tr><td><code id="Liang_+3A_xnames">Xnames</code></td>
<td>
<p>vector of character strings indicating the names of the columns of the fixed effects in the outcome regression model</p>
</td></tr>
<tr><td><code id="Liang_+3A_wnames">Wnames</code></td>
<td>
<p>vector of character strings indicating the names of the columns of the random effects in the outcome regression model</p>
</td></tr>
<tr><td><code id="Liang_+3A_znames">Znames</code></td>
<td>
<p>vector of character strings indicating the names of the columns of the covariates in the visit intensity model</p>
</td></tr>
<tr><td><code id="Liang_+3A_formulaobs">formulaobs</code></td>
<td>
<p>formula for the observation intensity model</p>
</td></tr>
<tr><td><code id="Liang_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="Liang_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="Liang_+3A_invariant">invariant</code></td>
<td>
<p>a vector of variable names corresponding to variables in data that are time-invariant. It is not necessary to list every such variable, just those that are invariant and also included in the visit intensity model</p>
</td></tr>
<tr><td><code id="Liang_+3A_lagvars">lagvars</code></td>
<td>
<p>a vector of variable names corresponding to variables which need to be lagged by one visit to fit the visit intensity model. Typically time will be one of these variables. The function will internally add columns to the data containing the values of the lagged variables from the previous visit. Values of lagged variables for a subject's first visit will be set to NA. To access these variables in specifying the proportional hazards formulae, add &quot;.lag&quot; to the variable you wish to lag. For example, if time is the variable for time, time.lag is the time of the previous visit</p>
</td></tr>
<tr><td><code id="Liang_+3A_lagfirst">lagfirst</code></td>
<td>
<p>A vector giving the value of each lagged variable for the first time within each subject. This is helpful if, for example, time is the variable to be lagged and you know that all subjects entered the study at time zero</p>
</td></tr>
<tr><td><code id="Liang_+3A_maxfu">maxfu</code></td>
<td>
<p>The maximum follow-up time per subject. If all subjects have the same follow-up time, this can be supplied as a single number. Otherwise, maxfu should be a dataframe with the first column specifying subject identifiers and the second giving the follow-up time for each subject.</p>
</td></tr>
<tr><td><code id="Liang_+3A_baseline">baseline</code></td>
<td>
<p>An indicator for whether baseline (time=0) measurements are included by design. Equal to 1 if yes, 0 if no.</p>
</td></tr>
<tr><td><code id="Liang_+3A_xfn">Xfn</code></td>
<td>
<p>A function that takes as its first argument the subject identifier and has time as its second argument, and returns the value of X for the specified subject at the specified time.</p>
</td></tr>
<tr><td><code id="Liang_+3A_wfn">Wfn</code></td>
<td>
<p>A function that takes as its first argument the subject identifier and has time as its second argument, and returns the value of W for the specified subject at the specified time</p>
</td></tr>
<tr><td><code id="Liang_+3A_...">...</code></td>
<td>
<p>other arguments to Xfn and Yfn</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a semi-parametric joint model as described in Liang (2009), using a frailty model to estimate the parameters in the visit intensity model
</p>
<p>The Liang method requires a value of X and W for every time over the observation period. If Xfn is left as NULL, then the Liang function will use, for each subject and for each time t, the values of X and W at the observation time closest to t.
</p>


<h3>Value</h3>

<p>the regression coefficients corresponding to the fixed effects in the outcome regression model.  Closed form expressions for standard errors of the regression coefficients are not available, and Liang et al (2009) recommend obtaining these through bootstrapping.
</p>


<h3>References</h3>

<p>Liang Y, Lu W, Ying Z. Joint modelling and analysis of longitudinal data with informative observation times. Biometrics 2009; 65:377-384.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># replicate simulation in Liang et al.
## Not run: 
library(data.table)
library(survival)
datasimi &lt;- function(id){
X1 &lt;- runif(1,0,1)
X2 &lt;- rbinom(1,1,0.5)
Z &lt;- rgamma(1,1,1)
Z1 &lt;- rnorm(1,Z-1,1)
gamma &lt;- c(0.5,-0.5)
beta &lt;- c(1,-1)
hazard &lt;- Z*exp(X1/2 - X2/2)
C &lt;- runif(1,0,5.8)
t &lt;- 0
tlast &lt;- t
y &lt;- t + X1-X2 + Z1*X2 + rnorm(1,0,1)
wait &lt;- rexp(1,hazard)
while(tlast+wait&lt;C){
  tnew &lt;- tlast+wait
    y &lt;- c(y,tnew + X1-X2 + Z1*X2 + rnorm(1,0,1))
    t &lt;- c(t,tnew)
    tlast &lt;- tnew
    wait &lt;- rexp(1,hazard)
 }
 datai &lt;- list(id=rep(id,length(t)),t=t,y=y,
      X1=rep(X1,length(t)),X2=rep(X2,length(t)),C=rep(C,length(t)))
 return(datai)
 }
 sim1 &lt;- function(it,nsubj){
 data &lt;- lapply(1:nsubj,datasimi)
 data &lt;- as.data.frame(rbindlist(data))
 data$event &lt;- 1
 C &lt;- tapply(data$C,data$id,mean)
 tapply(data$C,data$id,sd)
 maxfu &lt;- cbind(1:nsubj,C)
 maxfu &lt;- as.data.frame(maxfu)
 res &lt;- Liang(data=data, id="id",time="t",Yname="y",
            Xnames=c("X1","X2"),
            Wnames=c("X2"),Znames=c("X1","X2"), formulaobs=Surv(t.lag,t,event)~X1
            + X2+ frailty(id),invariant=c
            ("id","X1","X2"),lagvars="t",lagfirst=NA,maxfu=maxfu,
            baseline=1)
 return(res)
 }
 # change n to 500 to replicate results of Liang et al.
 n &lt;- 10
 s &lt;- lapply(1:n,sim1,nsubj=200)
 smat &lt;- matrix(unlist(s),byrow=TRUE,ncol=4)
 apply(smat,2,mean)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='mo'>Multiple outputation for longitudinal data subject to irregular observation.</h2><span id='topic+mo'></span>

<h3>Description</h3>

<p>Multiple outputation is a procedure whereby excess observations are repeatedly randomly sampled and discarded. The method was originally developed to handle clustered data where cluster size is informative, for example when studying pups in a litter. In this case, analysis that ignores cluster size results in larger litters being over-represented in a marginal analysis. Multiple outputation circumvents this problem by randomly selecting one observation per cluster. Multiple outputation has been further adapted to handle longitudinal data subject to irregular observation; here the probability of being retained on any given outputation is inversely proportional to the visit intensity. This function creates multiply outputted datasets, analyses each separately, and combines the results to produce a single estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mo(
  noutput,
  fn,
  data,
  weights,
  singleobs,
  id,
  time,
  keep.first,
  var = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mo_+3A_noutput">noutput</code></td>
<td>
<p>the number of outputations to be used</p>
</td></tr>
<tr><td><code id="mo_+3A_fn">fn</code></td>
<td>
<p>the function to be applied to the outputted datasets. fn should return a vector or scalar; if var=TRUE the second column of fn should be an estimate of standard error.</p>
</td></tr>
<tr><td><code id="mo_+3A_data">data</code></td>
<td>
<p>the original dataset on which multiple outputation is to be performed</p>
</td></tr>
<tr><td><code id="mo_+3A_weights">weights</code></td>
<td>
<p>the weights to be used in the outputation, i.e. the inverse of the probability that a given observation will be selected in creating an outputted dataset. Ignored if singleobs=TRUE</p>
</td></tr>
<tr><td><code id="mo_+3A_singleobs">singleobs</code></td>
<td>
<p>logical variable indicating whether a single observation should be retained for each subject</p>
</td></tr>
<tr><td><code id="mo_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="mo_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="mo_+3A_keep.first">keep.first</code></td>
<td>
<p>logical variable indicating whether the first observation should be retained with probability 1. This is useful if the data consists of an observation at baseline followed by follow-up at stochastic time points.</p>
</td></tr>
<tr><td><code id="mo_+3A_var">var</code></td>
<td>
<p>logical variable indicating whether fn returns variances in addition to point estimates</p>
</td></tr>
<tr><td><code id="mo_+3A_...">...</code></td>
<td>
<p>other arguments to fn.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the multiple outputation estimate of the function fn applied to the data, its standard error, and the relative efficiency of using noutput outputations as opposed to an infinite number
</p>


<h3>References</h3>


<ul>
<li><p> Hoffman E, Sen P, Weinberg C. Within-cluster resampling. Biometrika 2001; 88:1121-1134
</p>
</li>
<li><p> Follmann D, Proschan M, Leifer E. Multiple outputation: inference for complex clustered data by averaging analyses from independent data. Biometrics 2003; 59:420-429
</p>
</li>
<li><p> Pullenayegum EM. Multiple outputation for the analysis of longitudinal data subject to irregular observation. Statistics in Medicine (in press)</p>
</li></ul>
<p>.
</p>


<h3>See Also</h3>

<p>Other mo: 
<code><a href="#topic+outputation">outputation</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
data(Phenobarb)
library(survival)
library(geepack)
library(data.table)

Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb
data &lt;- data[data$event==1,]
data$id &lt;- as.numeric(data$Subject)
data &lt;- data[data$time&lt;16*24,]
i &lt;- iiw.weights(Surv(time.lag,time,event)~I(conc.lag&gt;0 &amp; conc.lag&lt;=20) +
I(conc.lag&gt;20 &amp; conc.lag&lt;=30) + I(conc.lag&gt;30)+ cluster(id),
id="id",time="time",event="event",data=data, invariant="id",lagvars=c("time","conc"),maxfu=16*24,
         lagfirst=c(0,0),first=TRUE)
wt &lt;- i$iiw.weight
wt[wt&gt;quantile(i$iiw.weight,0.95)] &lt;- quantile(i$iiw.weight,0.95)
data$wt &lt;- wt
reg &lt;- function(data){
est &lt;- summary(geeglm(conc~I(time^3) + log(time), id=id,data=data))$coefficients[,1:2]
est &lt;- data.matrix(est)
return(est)
}

mo(20,reg,data,wt,singleobs=FALSE,id="id",time="time",keep.first=FALSE)
# On outputation, the dataset contains small numbers of observations per subject
# and hence the GEE sandwich variance estimate underestimates variance; this is why
# the outputation-based variance estimate fails. This can be remedied by using a
# sandwich variance error correction (e.g. Fay-Graubard, Mancl-DeRouen).
</code></pre>

<hr>
<h2 id='outputation'>Create an outputted dataset for use with multiple outputation.</h2><span id='topic+outputation'></span>

<h3>Description</h3>

<p>Multiple outputation is a procedure whereby excess observations are repeatedly randomly sampled and discarded. The method was originally developed to handle clustered data where cluster size is informative, for example when studying pups in a litter. In this case, analysis that ignores cluster size results in larger litters being over-represented in a marginal analysis. Multiple outputation circumvents this problem by randomly selecting one observation per cluster. Multiple outputation has been further adapted to handle longitudinal data subject to irregular observation; here the probability of being retained on any given outputation is inversely proportional to the visit intensity. This function creates a single outputted dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outputation(data, weights, singleobs, id, time, keep.first)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outputation_+3A_data">data</code></td>
<td>
<p>the original dataset on which multiple outputation is to be performed</p>
</td></tr>
<tr><td><code id="outputation_+3A_weights">weights</code></td>
<td>
<p>the weights to be used in the outputation, i.e. the inverse of the probability that a given observation will be selected in creating an outputted dataset. Ignored if singleobs=TRUE</p>
</td></tr>
<tr><td><code id="outputation_+3A_singleobs">singleobs</code></td>
<td>
<p>logical variable indicating whether a single observation should be retained for each subject</p>
</td></tr>
<tr><td><code id="outputation_+3A_id">id</code></td>
<td>
<p>character string indicating which column of the data identifies subjects</p>
</td></tr>
<tr><td><code id="outputation_+3A_time">time</code></td>
<td>
<p>character string indicating which column of the data contains the time at which the visit occurred</p>
</td></tr>
<tr><td><code id="outputation_+3A_keep.first">keep.first</code></td>
<td>
<p>logical variable indicating whether the first observation should be retained with probability 1. This is useful if the data consists of an observation at baseline followed by follow-up at stochastic time points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the outputted dataset.
</p>


<h3>References</h3>


<ul>
<li><p> Hoffman E, Sen P, Weinberg C. Within-cluster resampling. Biometrika 2001; 88:1121-1134
</p>
</li>
<li><p> Follmann D, Proschan M, Leifer E. Multiple outputation: inference for complex clustered data by averaging analyses from independent data. Biometrics 2003; 59:420-429
</p>
</li>
<li><p> Pullenayegum EM. Multiple outputation for the analysis of longitudinal data subject to irregular observation. Statistics in Medicine (in press).</p>
</li></ul>



<h3>See Also</h3>

<p>Other mo: 
<code><a href="#topic+mo">mo</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
data(Phenobarb)
library(survival)
library(geepack)
library(data.table)
Phenobarb$event &lt;- 1-as.numeric(is.na(Phenobarb$conc))
data &lt;- Phenobarb
data &lt;- data[data$event==1,]
data$id &lt;- as.numeric(data$Subject)
data &lt;- data[data$time&lt;16*24,]
i &lt;- iiw.weights(Surv(time.lag,time,event)~I(conc.lag&gt;0 &amp; conc.lag&lt;=20) +
I(conc.lag&gt;20 &amp; conc.lag&lt;=30) + I(conc.lag&gt;30)+ cluster(id),
id="id",time="time",event="event",data=data,
invariant="id",lagvars=c("time","conc"),maxfu=16*24,lagfirst=0,first=TRUE)
data$weight &lt;- i$iiw.weight
head(data)
data.output1 &lt;-   outputation(data,data$weight,singleobs=FALSE,
id="id",time="time",keep.first=FALSE)
head(data.output1)
data.output2 &lt;-   outputation(data,data$weight,singleobs=FALSE,
id="id",time="time",keep.first=FALSE)
head(data.output2)
data.output3 &lt;-   outputation(data,data$weight,singleobs=FALSE,
id="id",time="time",keep.first=FALSE)
head(data.output3)
# Note that the outputted dataset varies with each command run; outputation is done at random
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
