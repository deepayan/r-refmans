<!DOCTYPE html><html lang="en"><head><title>Help for package ACSWR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ACSWR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ACSWR-package'>
<p>An R Companion Package for the Book &quot;A Course in Statistics with R&quot;</p></a></li>
<li><a href='#abrasion_index'>
<p>Abrasion Index for the Tire Tread</p></a></li>
<li><a href='#adjectives'>
<p>A Dataset for Factor Analysis</p></a></li>
<li><a href='#atombomb'>
<p>Japanese atomic bomb survivors</p></a></li>
<li><a href='#battery'>
<p>Two Factorial Experiment for Battery Data</p></a></li>
<li><a href='#Binom_Sim'>
<p>Simulation for Binomial Distribution</p></a></li>
<li><a href='#bottling'>
<p>A Three Factorial Experiment for Bottling Data</p></a></li>
<li><a href='#bs'>
<p>Simulated Sample from Binomial Distribution</p></a></li>
<li><a href='#bs1'>
<p>British Doctors Smoking and Coronary Heart Disease</p></a></li>
<li><a href='#caesareans'>
<p>The Cesarean Cases</p></a></li>
<li><a href='#calcium'>
<p>The Calcium in Soil</p></a></li>
<li><a href='#cardata'>
<p>Car Data</p></a></li>
<li><a href='#chdage'>
<p>Coronary Heart Disease</p></a></li>
<li><a href='#chemicaldata'>
<p>Chemical Reaction Experiment</p></a></li>
<li><a href='#chest'>
<p>The Militiamen's Chest Dataset</p></a></li>
<li><a href='#cloud'>
<p>The Cloud Seeding Data</p></a></li>
<li><a href='#cork'>
<p>The Cork Dataset</p></a></li>
<li><a href='#cs'>
<p>Random Samples from Cauchy Distribution</p></a></li>
<li><a href='#depression'>
<p>The Hamilton Depression Scale Factor</p></a></li>
<li><a href='#Disease'>
<p>Disease Outbreak Study</p></a></li>
<li><a href='#Ehrenfest'>
<p>Generate transition probability matrix of Ehrenfest model</p></a></li>
<li><a href='#flight'>
<p>Injuries in Airflights</p></a></li>
<li><a href='#Geom_Sim'>
<p>Simulation for Geometric Distribution</p></a></li>
<li><a href='#girder'>
<p>Strength Data Set of a Girder Experiment</p></a></li>
<li><a href='#hardness'>
<p>Hardness and a Block Experiment</p></a></li>
<li><a href='#hearing'>
<p>Hearing Loss Data</p></a></li>
<li><a href='#hw'>
<p>Height-Weight Covariance Study</p></a></li>
<li><a href='#insurance'>
<p>Insurance Claims Data</p></a></li>
<li><a href='#intensity'>
<p>Blocking for Intensity Data Set</p></a></li>
<li><a href='#kurtcoeff'>
<p>Coefficient of Kurtosis</p></a></li>
<li><a href='#life'>
<p>Life Expectancies</p></a></li>
<li><a href='#lowbwt'>
<p>The Low-Birth Weight Problem</p></a></li>
<li><a href='#LRNormal2Mean'>
<p>Likelihood Ratio Test for Equality of Means when Variance Unknown</p></a></li>
<li><a href='#LRNormalMean_KV'>
<p>Likelihood ratio test for equality of mean when the variance is known</p></a></li>
<li><a href='#LRNormalMean_UV'>
<p>Likelihood ratio test for mean when variance is unknown</p></a></li>
<li><a href='#LRNormalVariance_UM'>
<p>Likelihood ratio test for the variance of normal distribution with mean is unknown</p></a></li>
<li><a href='#lval'>
<p>Letter Values</p></a></li>
<li><a href='#memory'>
<p>Memory Recall Times</p></a></li>
<li><a href='#mfp'>
<p>Psychological Tests for Males and Females</p></a></li>
<li><a href='#MPbinomial'>
<p>Most Powerful Binomial Test</p></a></li>
<li><a href='#MPNormal'>
<p>Most Powerful Test for Normal Distribution</p></a></li>
<li><a href='#MPPoisson'>
<p>Most Powerful Test for Poisson Distribution</p></a></li>
<li><a href='#msteptpm'>
<p>m-step Transition Probability Matrix Computation</p></a></li>
<li><a href='#Mucociliary'>
<p>Mucociliary Clearance</p></a></li>
<li><a href='#nerve'>
<p>The Nerve Data</p></a></li>
<li><a href='#ns'>
<p>Simulated Sample from Normal Distribution</p></a></li>
<li><a href='#olson'>
<p>The Olson Heart Lung Dataset</p></a></li>
<li><a href='#pareto_density'>
<p>Pareto density</p></a></li>
<li><a href='#pareto_quantile'>
<p>Quantile of Pareto RV</p></a></li>
<li><a href='#Poisson_Sim'>
<p>Simulation for Poisson Distribution</p></a></li>
<li><a href='#powertestplot'>
<p>A Function to Plot the Power of a UMP Test for Normal Distribution</p></a></li>
<li><a href='#ps'>
<p>Simulated Sample from Poisson Distribution</p></a></li>
<li><a href='#pw'>
<p>The Linguistic Probe Word Analysis</p></a></li>
<li><a href='#QH_CI'>
<p>Quesenberry-Hurst Simultaneous Confidence Interval</p></a></li>
<li><a href='#reaction'>
<p>Chemical Reaction Experiment</p></a></li>
<li><a href='#resistant_line'>
<p>Resistant Line EDA Regression Technique</p></a></li>
<li><a href='#rocket'>
<p>Rocket Propellant</p></a></li>
<li><a href='#rocket_Graeco'>
<p>Rocket Propellant Example Extended</p></a></li>
<li><a href='#rootstock'>
<p>Apple of Different Rootstock</p></a></li>
<li><a href='#sample'>
<p>Simulated Dataset</p></a></li>
<li><a href='#sheishu'>
<p>The Seishu Wine Study</p></a></li>
<li><a href='#shelf_stock'>
<p>The Shelf-Stocking Data</p></a></li>
<li><a href='#siegel.tukey'>
<p>Siegel-Tukey Nonparametric Test</p></a></li>
<li><a href='#skewcoeff'>
<p>A simple and straightforward function to compute the coefficient of skewness</p></a></li>
<li><a href='#somesamples'>
<p>Scatter Plots for Understanding Correlations</p></a></li>
<li><a href='#SP'>
<p>Understanding Strength of Paper with a Three Factorial Experiment</p></a></li>
<li><a href='#ST_Ordered'>
<p>Simulating Random Observations from an Arbitrary Distribution</p></a></li>
<li><a href='#ST_Unordered'>
<p>Simulating Random Observations from an Arbitrary Distribution (ordered probabilities)</p></a></li>
<li><a href='#stationdistTPM'>
<p>A function which will return the stationary distribution of an ergodic Markov chain</p></a></li>
<li><a href='#stiff'>
<p>The Board Stiffness Dataset</p></a></li>
<li><a href='#swiss'>
<p>Forged Swiss Bank Notes</p></a></li>
<li><a href='#tc'>
<p>The Toluca Company Labour Hours against Lot Size</p></a></li>
<li><a href='#tensile'>
<p>The Tensile Strength Experiment</p></a></li>
<li><a href='#testtpm'>
<p>A transition probability matrix</p></a></li>
<li><a href='#testtpm2'>
<p>A matrix of transition probability matrix, second example</p></a></li>
<li><a href='#testtpm3'>
<p>A matrix of transition probability matrix, third example</p></a></li>
<li><a href='#TM'>
<p>Trimmed Mean</p></a></li>
<li><a href='#TMH'>
<p>Trimean based on hinges instead of quartiles</p></a></li>
<li><a href='#UMPExponential'>
<p>Uniformly Most Powerful Test for Exponential Distribution</p></a></li>
<li><a href='#UMPNormal'>
<p>Uniformly Most Powerful Test for Normal Distribution</p></a></li>
<li><a href='#UMPUniform'>
<p>Uniformly Most Powerful Test for Uniform Sample</p></a></li>
<li><a href='#usc'>
<p>US Crime Data</p></a></li>
<li><a href='#viscos'>
<p>The Box-Cox Transformation for Viscosity Dataset</p></a></li>
<li><a href='#vonNeumann'>
<p>von Neumann Random Number Generator</p></a></li>
<li><a href='#waterquality'>
<p>Testing for Physico-chemical Properties of Water in 4 Cities</p></a></li>
<li><a href='#WilsonCI'>
<p>Wilson Confidence Interval</p></a></li>
<li><a href='#ww.test'>
<p>Wald-Wolfowitz Nonparametric Test</p></a></li>
<li><a href='#x_bimodal'>
<p>Understanding kernel smoothing through a simulated dataset</p></a></li>
<li><a href='#yb'>
<p>Youden and Beale's Data on Lesions of Half-Leaves of Tobacco Plant</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Companion Package for the Book "A Course in Statistics with R"</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-09-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Prabhanjan Tattar</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Prabhanjan Tattar &lt;prabhanjannt@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A book designed to meet the requirements of masters students. Tattar, P.N., Suresh, R., and Manjunath, B.G. "A Course in Statistics with R", J. Wiley, ISBN 978-1-119-15272-9. </td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-09-05 14:57:16 UTC; prabhanjan</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-09-05 17:50:53</td>
</tr>
</table>
<hr>
<h2 id='ACSWR-package'>
An R Companion Package for the Book &quot;A Course in Statistics with R&quot;
</h2><span id='topic+ACSWR-package'></span><span id='topic+ACSWR'></span>

<h3>Description</h3>

<p>&quot;A Course in Statistics with R&quot; has been designed to meet the requirements of masters students.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ACSWR</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2015-08-19</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Prabhanjan Tattar
</p>
<p>Maintainer: Prabhanjan Tattar &lt;prabhanjannt@gmail.com&gt;
</p>


<h3>References</h3>

<p>Tattar, P. N., Suresh, R., and Manjunath, B. G. (2016). A Course in Statistics with R. J. Wiley. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hist(rnorm(100))
</code></pre>

<hr>
<h2 id='abrasion_index'>
Abrasion Index for the Tire Tread
</h2><span id='topic+abrasion_index'></span>

<h3>Description</h3>

<p>To understand the relationship between the abrasion index for the tire tread, the output y, as a linear function of the hydrated silica level x1, silane coupling agent level x2 and the sulfur level x3, Derringer and Suich (1980) collected data on 14 observation points. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("abrasion_index")</code></pre>


<h3>Format</h3>

<p>A data frame with 14 observations on the following 4 variables.
</p>

<dl>
<dt><code>x1</code></dt><dd><p>hydrated silica level</p>
</dd>
<dt><code>x2</code></dt><dd><p>silane coupling agent level</p>
</dd>
<dt><code>x3</code></dt><dd><p>sulfur level</p>
</dd>
<dt><code>y</code></dt><dd><p>abrasion index for the tire tread</p>
</dd>
</dl>



<h3>References</h3>

<p>Derringer, G., and Suich, R. (1980). Simultaneous Optimization of Several Response
Variables. Journal of Quality Technology, 12, 214-219.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(abrasion_index)
ailm &lt;- lm(y~x1+x2+x3,data=abrasion_index)
pairs(abrasion_index)
</code></pre>

<hr>
<h2 id='adjectives'>
A Dataset for Factor Analysis</h2><span id='topic+adjectives'></span>

<h3>Description</h3>

<p>The data set is obtained from Rencher (2002). Here, a 12-year old girl rates 7 of her acquaintances on a differential grade of 1-9 for five adjectives kind, intelligent, happy, likable, and just.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(adjectives)</code></pre>


<h3>Format</h3>

<p>A data frame with 7 observations on the following 6 variables.
</p>

<dl>
<dt><code>People</code></dt><dd><p>a factor with levels <code>FATHER</code> <code>FSM1a</code> <code>FSM2</code> <code>FSM3</code> <code>MSMb</code> <code>SISTER</code> <code>TEACHER</code></p>
</dd>
<dt><code>Kind</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Intelligent</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Happy</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Likeable</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Just</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Rencher, A.C. (2002). Methods of Multivariate Analysis, 2e. J. Wiley.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(adjectives)
adjectivescor &lt;- cor(adjectives[,-1])
round(adjectivescor,3)
adj_eig &lt;- eigen(adjectivescor)
cumsum(adj_eig$values)/sum(adj_eig$values)
adj_eig$vectors[,1:2]
loadings1 &lt;- adj_eig$vectors[,1]*sqrt(adj_eig$values[1])
loadings2 &lt;- adj_eig$vectors[,2]*sqrt(adj_eig$values[2])
cbind(loadings1,loadings2)
communalities &lt;- (adj_eig$vectors[,1]*sqrt(adj_eig$values[1]))^2+
(adj_eig$vectors[,2]*sqrt(adj_eig$values[2]))^2
round(communalities,3)
specific_variances &lt;- 1-communalities
round(specific_variances,3)
var_acc_factors &lt;- adj_eig$values
round(var_acc_factors,3)
prop_var &lt;- adj_eig$values/sum(adj_eig$values)
round(prop_var,3)
cum_prop &lt;- cumsum(adj_eig$values)/sum(adj_eig$values)
round(cum_prop,3)
</code></pre>

<hr>
<h2 id='atombomb'>
Japanese atomic bomb survivors
</h2><span id='topic+atombomb'></span>

<h3>Description</h3>

<p>Gore, et al. (2006) consider the frequencies of cancer deaths of Japanese atomic bomb survivors by extent of exposure, years after exposure, etc. This data set has appeared in the journal &quot;Statistical Sleuth&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("atombomb")</code></pre>


<h3>Format</h3>

<p>A data frame with 84 observations on the following 4 variables.
</p>

<dl>
<dt><code>Radians</code></dt><dd><p>Extent of exposure to the radian levels</p>
</dd>
<dt><code>Count.Type</code></dt><dd><p>the type of count <code>At Risk</code> <code>Death Count</code></p>
</dd>
<dt><code>Count.Age.Group</code></dt><dd><p>age group with levels <code>'0-7'</code> <code>'12-15'</code> <code>'16-19'</code> <code>'20-23'</code> <code>'24-27'</code> <code>'28-41'</code> <code>'8-11'</code></p>
</dd>
<dt><code>Frequency</code></dt><dd><p>the count of deaths</p>
</dd>
</dl>



<h3>References</h3>

<p>Gore, A.P., Paranjape, S. A., and Kulkarni, M.B. (2006). 100 Data Sets for Statistics Education. Department of Statistics, University of Pune.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(atombomb)
atombombxtabs &lt;- xtabs(Frequency~Radians+Count.Type+Count.Age.Group,data=atombomb)
atombombxtabs
</code></pre>

<hr>
<h2 id='battery'>
Two Factorial Experiment for Battery Data
</h2><span id='topic+battery'></span>

<h3>Description</h3>

<p>An experiment where the life of a battery is modeled as a function of the extreme variations in temperature of three levels 15, 70, and 1250 Fahrenheit and three type of plate material. Here, the engineer has no control on the temperature variations once the device leaves the factory. Thus, the task of the engineer is to investigate two major problems: (i) The effect of material type and temperature on the life of the device, and (ii) Finding the type of material which has least variation among the varying temperature levels. For each combination of the temperature
and material, 4 replications of the life of battery are tested.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(battery)</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following 3 variables.
</p>

<dl>
<dt><code>Life</code></dt><dd><p>battery life</p>
</dd>
<dt><code>Material</code></dt><dd><p>the type of plate material</p>
</dd>
<dt><code>Temperature</code></dt><dd><p>three extreme variations of temperature</p>
</dd>
</dl>



<h3>Source</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(battery)
names(battery) &lt;- c("L","M","T")
battery$M &lt;- as.factor(battery$M)
battery$T &lt;- as.factor(battery$T)
battery.aov &lt;- aov(L~M*T,data=battery)
model.matrix(battery.aov)
summary(battery.aov)
</code></pre>

<hr>
<h2 id='Binom_Sim'>
Simulation for Binomial Distribution
</h2><span id='topic+Binom_Sim'></span>

<h3>Description</h3>

<p>A simple function to understand the algorithm to simulate psuedo-observations from binomial distribution. It is an implementation of the algorithm given in Section 11.3.1. This function is not an alternative to the rbinom function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Binom_Sim(size, p, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Binom_Sim_+3A_size">size</code></td>
<td>

<p>Size of the binomial distribution
</p>
</td></tr>
<tr><td><code id="Binom_Sim_+3A_p">p</code></td>
<td>

<p>Denotes the probability of success
</p>
</td></tr>
<tr><td><code id="Binom_Sim_+3A_n">N</code></td>
<td>

<p>The number of observations required from b(n,p)
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is to simply explain the algorithm described in the text. For efficient results, the user should use the rbinom function. 
</p>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>rbinom
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Binom_Sim(10,0.5,100)
</code></pre>

<hr>
<h2 id='bottling'>
A Three Factorial Experiment for Bottling Data</h2><span id='topic+bottling'></span>

<h3>Description</h3>

<p>The height of the fills in the soft drink bottle is required to be as consistent as possible and it is controlled through three factors: (i) the percent carbonation of the drink, (ii) the operating pressure in the filler, and (iii) the line speed which is the number of bottles filled per minute. The first factor variable of the percent of carbonation is available at three levels of 10, 12, and 14, the operating pressure is at 25 and 30 psi units, while the line speed are at 200 and 250 bottles per minute. Two complete replicates are available for each combination of the three factor levels, that is, 24 total number of observations. In this experiment, the deviation from the required height level is measured.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bottling)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 4 variables.
</p>

<dl>
<dt><code>Deviation</code></dt><dd><p>deviation from required height level</p>
</dd>
<dt><code>Carbonation</code></dt><dd><p>the percent carbonation of the drink</p>
</dd>
<dt><code>Pressure</code></dt><dd><p>the operating pressure in the filler</p>
</dd>
<dt><code>Speed</code></dt><dd><p>the number of bottles filled per minute</p>
</dd>
</dl>



<h3>Source</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bottling)
summary(bottling.aov &lt;- aov(Deviation~.^3,bottling))
# Equivalent way
summary(aov(Deviation~ Carbonation + Pressure + Speed+ (Carbonation*Pressure)+
(Carbonation*Speed)+(Pressure*Speed)+(Carbonation*Speed*Pressure),data=bottling)) 
</code></pre>

<hr>
<h2 id='bs'>
Simulated Sample from Binomial Distribution
</h2><span id='topic+bs'></span>

<h3>Description</h3>

<p>The data set is used to understand the sampling variation of the score function. The simulated data is available in Pawitan (2001). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bs)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 20 variables.
</p>

<dl>
<dt><code>Sample.1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.4</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.6</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.8</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.10</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.12</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.13</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.14</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.15</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.16</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.18</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.19</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.20</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>References</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bs)
n &lt;- 10
sample_means &lt;- colMeans(bs)
binomial_score_fn &lt;- function(p,xbar)
      n*(xbar-10*p)/(p*(1-p))
p &lt;- seq(from=0,to=1,by=0.02)
plot(p,sapply(p,binomial_score_fn,xbar=sample_means[1]),"l",xlab=expression(p),
ylab=expression(S(p)))
title(main="C: Score Function Plot of Binomial Model")
for(i in 2:20) lines(p,sapply(p,
binomial_score_fn,xbar=sample_means[i]),"l")
abline(v=4)
abline(h=0)
</code></pre>

<hr>
<h2 id='bs1'>
British Doctors Smoking and Coronary Heart Disease
</h2><span id='topic+bs1'></span>

<h3>Description</h3>

<p>The problem is to investigate the impact of smoking tobacco among British doctors, refer Example 9.2.1 of Dobson. In the year 1951, a survey was sent across among all the British doctors asking them whether they smoked tobacco and their age group <code>Age_Group</code>. The data also collects the person-years <code>Person_Years</code> of the doctors in the respective age group. A follow-up after ten years reveals the number of deaths Deaths, the smoking group indicator <code>Smoker_Cat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bs1)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 9 variables.
</p>

<dl>
<dt><code>Age_Group</code></dt><dd><p>a factor variable of age group with levels <code>35-44</code> <code>45-54</code> <code>55-64</code> <code>65-74</code> <code>75-84</code></p>
</dd>
<dt><code>Age_Cat</code></dt><dd><p>slightly re-coded to extract variables with <code>Age_Cat</code> taking values 1-5 respectively for the age groups 35-44, 45-54, 55-64, 65-74, and 75-84</p>
</dd>
<dt><code>Age_Square</code></dt><dd><p>square of the variable <code>Age_Cat</code></p>
</dd>
<dt><code>Smoker_Cat</code></dt><dd><p>the smoking group indicator <code>NO</code> <code>YES</code></p>
</dd>
<dt><code>Smoke_Ind</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Smoke_Age</code></dt><dd><p>takes the Age_Cat values for the smokers group and 0 for the non-smokers</p>
</dd>
<dt><code>Deaths</code></dt><dd><p>a follow-up after ten years revealing the number of deaths</p>
</dd>
<dt><code>Person_Years</code></dt><dd><p>the number of deaths standardized to 100000</p>
</dd>
<dt><code>Deaths_Per_Lakh_Years</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dobson (2002)
</p>


<h3>References</h3>

<p>Dobson, A. J. (1990-2002). An Introduction to Generalized Linear Models, 2e.
Chapman &amp; Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
data(bs1)
BS_Pois &lt;-  glm(Deaths~Age_Cat+Age_Square+Smoke_Ind+Smoke_Age,offset=
log(Person_Years),data=bs1,family='poisson')
logLik(BS_Pois)
summary(BS_Pois)
with(BS_Pois, pchisq(null.deviance - deviance,df.null - 
df.residual,lower.tail = FALSE)) 
confint(BS_Pois)</code></pre>

<hr>
<h2 id='caesareans'>
The Cesarean Cases
</h2><span id='topic+caesareans'></span>

<h3>Description</h3>

<p>An increasing concern has been the number of cesarean deliveries, especially in the private hospitals. Here, we know the number of births, the type of hospital (private or Government hospital), and the number of cesareans. We would like to model the number of cesareans as a function of the number of births and the type of hospital. A Poisson regression model is fitted for this data set.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(caesareans)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 3 variables.
</p>

<dl>
<dt><code>Births</code></dt><dd><p>total number of births</p>
</dd>
<dt><code>Hospital_Type</code></dt><dd><p>type of hospital, private or government</p>
</dd>
<dt><code>Caesareans</code></dt><dd><p>number of caesareans</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://www.oxfordjournals.org/our_journals/tropej/online/ma_chap13.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(caesareans)
names(caesareans)
cae_pois &lt;- glm(Caesareans~Hospital_Type+Births,data=caesareans,family='poisson')
summary(cae_pois)
</code></pre>

<hr>
<h2 id='calcium'>
The Calcium in Soil</h2><span id='topic+calcium'></span>

<h3>Description</h3>

<p>Kramer and Jensen (1969) collected data on three variables at 10 different locations. The variables of interest are available calcium in the soil, y1, exchangeable soil calcium, y2, and turnip green calcium, y3. The hypothesis of interest is whether the mean vector is [15.0 6.0 2.85].</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(calcium)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 4 variables.
</p>

<dl>
<dt><code>Location.Number</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y3</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kramer, C. Y., and Jensen, D. R. (1969). Fundamentals of Multivariate Analysis, Part I. Inference about Means. Journal of Quality Technology, 1 (2), 120-133.</p>


<h3>References</h3>

<p>Rencher, A.C. (1990-2002). Methods of Multivariate Analysis, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calcium)
n &lt;- nrow(calcium)
meanx &lt;- colMeans(calcium[,-1])
varx &lt;- var(calcium[,-1])
mu0 &lt;- c(15,6,2.85)
t2 &lt;- n*t(meanx-mu0)
t2
</code></pre>

<hr>
<h2 id='cardata'>
Car Data</h2><span id='topic+cardata'></span>

<h3>Description</h3>

<p>The data is used to show the effectiveness of Chernoff faces. </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cardata)</code></pre>


<h3>Format</h3>

<p>A data frame with 74 observations on the following 14 variables.
</p>

<dl>
<dt><code>Model</code></dt><dd><p>various car models </p>
</dd>
<dt><code>P</code></dt><dd><p>Price</p>
</dd>
<dt><code>M</code></dt><dd><p>Mileage (in miles per gallon)</p>
</dd>
<dt><code>R78</code></dt><dd><p>Repair record 1978</p>
</dd>
<dt><code>R77</code></dt><dd><p>Repair record 1977</p>
</dd>
<dt><code>H</code></dt><dd><p>Headroom (in inches)</p>
</dd>
<dt><code>R</code></dt><dd><p>Rear seat clearance</p>
</dd>
<dt><code>Tr</code></dt><dd><p>Trunk space</p>
</dd>
<dt><code>W</code></dt><dd><p>Weight (in pound)</p>
</dd>
<dt><code>L</code></dt><dd><p>Length (in inches)</p>
</dd>
<dt><code>T</code></dt><dd><p>Turning diameter</p>
</dd>
<dt><code>D</code></dt><dd><p>Displacement (in cubic inches)</p>
</dd>
<dt><code>G</code></dt><dd><p>Gear ratio for high gear</p>
</dd>
<dt><code>C</code></dt><dd><p>Company headquarter</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(cardata)
pairs(cardata)
</code></pre>

<hr>
<h2 id='chdage'>
Coronary Heart Disease</h2><span id='topic+chdage'></span>

<h3>Description</h3>

<p>A well known explanation of the heart disease is that as the age increases, the risk of coronary heart disease also increase. The current data set and the example may be found in Chapter 1 of Hosmer and Lemeshow (1990-2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chdage)</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 3 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>patient ID</p>
</dd>
<dt><code>AGE</code></dt><dd><p>age of the patient</p>
</dd>
<dt><code>CHD</code></dt><dd><p>Coronary Heart Disease indicator</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hosmer and Lemeshow (1990-2013).
</p>


<h3>References</h3>

<p>Hosmer, D.W., and Lemeshow, S. (1990-20013). Applied Logistic Regression, 3e.
Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chdage)
plot(chdage$AGE,chdage$CHD,xlab="AGE",ylab="CHD Indicator", 
main="Scatter plot for CHD Data")
agegrp &lt;- cut(chdage$AGE,c(19,29,34,39,44,49,54,59,69),include.lowest=TRUE,
labels=c(25,seq(31.5,56.5,5),64.5))
mp &lt;- c(25,seq(31.5,56.5,5),64.5) # mid-points
chd_percent &lt;- prop.table(table(agegrp,chdage$CHD),1)[,2]
points(mp,chd_percent,"l",col="red")
</code></pre>

<hr>
<h2 id='chemicaldata'>
Chemical Reaction Experiment
</h2><span id='topic+chemicaldata'></span>

<h3>Description</h3>

<p>This data set is used to illustrate the concept of canonical correlations. Here, temperature, concentration, and time have influence on three yield variables, namely outputs, while the percentage of unchanged starting material, the percentage converted to the desired product, and the percentage of unwanted by-product form another set of related variables. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chemicaldata)</code></pre>


<h3>Format</h3>

<p>A data frame with 19 observations on the following 6 variables.
</p>

<dl>
<dt><code>y1</code></dt><dd><p>the percentage of unchanged starting material</p>
</dd>
<dt><code>y2</code></dt><dd><p>the percentage converted to the desired product</p>
</dd>
<dt><code>y3</code></dt><dd><p>the percentage of unwanted by-product</p>
</dd>
<dt><code>x1</code></dt><dd><p>temperature</p>
</dd>
<dt><code>x2</code></dt><dd><p>concentration</p>
</dd>
<dt><code>x3</code></dt><dd><p>time</p>
</dd>
</dl>



<h3>Source</h3>

<p>Box, G. E. P., and Youle, P. V. (1955). The Exploration of Response Surfaces: An
Example of the Link between the Fitted Surface and the Basic Mechanism of
the System. Biometrics, 11, 287-323.
</p>


<h3>References</h3>

<p>Rencher, A.C. (2002). Methods of Multivariate Analysis, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chemicaldata)
names(chemicaldata)
chemicaldata$x12 &lt;- chemicaldata$x1*chemicaldata$x2; 
chemicaldata$x13 &lt;- chemicaldata$x1*chemicaldata$x3; 
chemicaldata$x23 &lt;- chemicaldata$x2*chemicaldata$x3
chemicaldata$x1sq &lt;- chemicaldata$x1^{2}
chemicaldata$x2sq &lt;- chemicaldata$x2^{2}
chemicaldata$x3sq &lt;- chemicaldata$x3^{2}
S_Total &lt;- cov(chemicaldata)
cancor_xy &lt;- sqrt(eigen(solve(S_Total[1:3,1:3])%*%S_Total[1:3,
4:12]%*%solve(S_Total[4:12,4:12])%*%S_Total[4:12,1:3])$values)
cancor_xy
cancor(chemicaldata[,1:3],chemicaldata[,4:12])
</code></pre>

<hr>
<h2 id='chest'>
The Militiamen's Chest Dataset
</h2><span id='topic+chest'></span>

<h3>Description</h3>

<p>Militia means an army composed of ordinary citizens and not of professional soldiers. This data set is available in an 1846 book published by the Belgian statistician Adolphe Quetelet, and the data is believed to have been collected some thirty years before that. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chest)</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 2 variables.
</p>

<dl>
<dt><code>Chest</code></dt><dd><p>chest width measured in inches</p>
</dd>
<dt><code>Count</code></dt><dd><p>the corresponding frequencies</p>
</dd>
</dl>



<h3>References</h3>

<p>Velleman, P.F., and Hoaglin, D.C. (2004). ABC of Exploratory Data Analysis.
Duxbury Press, Boston.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chest)
attach(chest)
names(chest)
militiamen &lt;- rep(Chest,Count)
length(militiamen)
bins &lt;- seq(33,48)
bins
bin.mids &lt;- (bins[-1]+bins[-length(bins)])/2
par(mfrow=c(1,2))
h &lt;- hist(militiamen, breaks = bins, xlab= "Chest Measurements (Inches)",
main= "A: Histogram for the Militiamen")
h$counts &lt;- sqrt(h$counts)
plot(h,xlab= "Chest Measurements (Inches)",ylab= "ROOT FREQUENCY",
main= "B: Rootogram for the Militiamen")
</code></pre>

<hr>
<h2 id='cloud'>
The Cloud Seeding Data
</h2><span id='topic+cloud'></span>

<h3>Description</h3>

<p>Chambers, et al. (1983), page 381, contains the cloud seeding data set. Rainfall in acre-feet for 52 clouds are measured, 50% of which have natural rain (control group) whereas the others are seeded. We need to visually compare whether seeding the clouds lead to increase in rainfall in acre-feet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cloud)</code></pre>


<h3>Format</h3>

<p>A data frame with 26 observations on the following 2 variables.
</p>

<dl>
<dt><code>Control</code></dt><dd><p>Rainfall in acre-feet for 26 clouds are measured which had natural rain, that is, control group</p>
</dd>
<dt><code>Seeded</code></dt><dd><p>Rainfall in acre-feet for 26 clouds are measured which had seeded rain</p>
</dd>
</dl>



<h3>References</h3>

<p>Chambers, J.M., Cleveland, W.S., Kleiner, B., and Tukey, P.A. (1983). Graphical
Methods for Data Analysis. Wadsworth and Brooks/Cole.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cloud)
stem(log(cloud$Seeded),scale=1)
stem(log(cloud$Control),scale=1)
</code></pre>

<hr>
<h2 id='cork'>
The Cork Dataset
</h2><span id='topic+cork'></span>

<h3>Description</h3>

<p>Thickness of cork borings in four directions of North, South, East, and West are measured for 28 trees. The problem here is to examine if the bark deposit is same in all the directions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cork)</code></pre>


<h3>Format</h3>

<p>A data frame with 28 observations on the following 4 variables.
</p>

<dl>
<dt><code>North</code></dt><dd><p>thickness of cork boring in the North direction</p>
</dd>
<dt><code>East</code></dt><dd><p>thickness of cork boring in the East direction</p>
</dd>
<dt><code>South</code></dt><dd><p>thickness of cork boring in the South direction</p>
</dd>
<dt><code>West</code></dt><dd><p>thickness of cork boring in the West direction</p>
</dd>
</dl>



<h3>References</h3>

<p>Rao, C. R. (1973). Linear Statistical Inference and Its Applications, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cork)
corkcent &lt;- cork*0
corkcent[,1] &lt;- cork[,1]-mean(cork[,1])
corkcent[,2] &lt;- cork[,2]-mean(cork[,2])
corkcent[,3] &lt;- cork[,3]-mean(cork[,3])
corkcent[,4] &lt;- cork[,4]-mean(cork[,4])
corkcentsvd &lt;- svd(corkcent)
t(corkcentsvd$u)%*%corkcentsvd$u
t(corkcentsvd$v)%*%corkcentsvd$v
round(corkcentsvd$u %*% diag(corkcentsvd$d) %*% t(corkcentsvd$v),2)
round(corkcent,2)
corkcentsvd$d
</code></pre>

<hr>
<h2 id='cs'>
Random Samples from Cauchy Distribution
</h2><span id='topic+cs'></span>

<h3>Description</h3>

<p>The data set is used to understand the sampling variation of the score function. The simulated data is available in Pawitan (2001).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cs)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 20 variables.
</p>

<dl>
<dt><code>Sample.1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.4</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.6</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.8</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.10</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.12</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.13</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.14</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.15</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.16</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.18</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.19</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.20</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cs)
n &lt;- 10
cauchy_score_fn  &lt;-  function(mu,x)
      sum(2*(x-mu)/(1+(x-mu)^{2}))
mu &lt;- seq(from=-15,to=20,by=0.5)
plot(mu,sapply(mu,cauchy_score_fn,x=cs[,1]),"l",xlab=expression(mu),
ylab=expression(S(mu)),ylim=c(-10,10))
title(main="D: Score Function Plot of Cauchy Model")
for(i in 2:20) lines(mu,sapply(mu,
cauchy_score_fn,x=cs[,i]),"l")
abline(v=4)
abline(h=0)
</code></pre>

<hr>
<h2 id='depression'>
The Hamilton Depression Scale Factor
</h2><span id='topic+depression'></span>

<h3>Description</h3>

<p>Hamilton depression scale factor IV is a measurement of mixed anxiety and depression and it is named after its inventor. In a double-blind experiment, this scale factor is obtained for 9 patients on their entry in a study, denoted by X. Post a tranquilizer T, the scale factor IV is again obtained for the same set of patients, which is denoted by Y. Here, an improvement due to tranquilizer T corresponds to a reduction in factor IV values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(depression)</code></pre>


<h3>Format</h3>

<p>A data frame with 9 observations on the following 3 variables.
</p>

<dl>
<dt><code>Patient_No</code></dt><dd><p>Patient ID</p>
</dd>
<dt><code>X</code></dt><dd><p>measurement of depression at entry in a study</p>
</dd>
<dt><code>Y</code></dt><dd><p>measurement of depression post a tranquilizer</p>
</dd>
</dl>



<h3>References</h3>

<p>Sheshkin, D. J. (1997-2011). Handbook of Parametric and Nonparametric Statistical
Procedures, 5e. Chapman and Hall/CRC. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(depression)
attach(depression)
names(depression)
wilcox.test(Y-X, alternative = "less")
wilcox.test(Y-X, alternative = "less",exact=FALSE,correct=FALSE)
</code></pre>

<hr>
<h2 id='Disease'>
Disease Outbreak Study
</h2><span id='topic+Disease'></span>

<h3>Description</h3>

<p>The purpose of this health study is investigation of an epidemic outbreak due to mosquitoes. A random sample from two sectors of the city among the individuals has been tested to determine if the individual had contracted the disease forming the binary outcome. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Disease)</code></pre>


<h3>Format</h3>

<p>A data frame with 98 observations on the following 5 variables.
</p>

<dl>
<dt><code>x1</code></dt><dd><p>age</p>
</dd>
<dt><code>x2</code></dt><dd><p>socioeconomic status of three categories between <code>x2</code> and <code>x3</code></p>
</dd>
<dt><code>x3</code></dt><dd><p>socioeconomic status of three categories between <code>x2</code> and <code>x3</code></p>
</dd>
<dt><code>x4</code></dt><dd><p>sector of the city</p>
</dd>
<dt><code>y</code></dt><dd><p>if the individual had contracted the disease forming the binary outcome</p>
</dd>
</dl>



<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and Li, W. (1974-2005). Applied
Linear Statistical Models, 5e. McGraw-Hill.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Disease)
DO_LR &lt;- glm(y~.,data=Disease,family='binomial')
LR_Residuals &lt;- data.frame(Y = Disease$y,Fitted = fitted(DO_LR),
Hatvalues = hatvalues(DO_LR),Response = residuals(DO_LR,"response"), Deviance = 
residuals(DO_LR,"deviance"), Pearson = residuals(DO_LR,"pearson"), 
Pearson_Standardized = residuals(DO_LR,"pearson")/sqrt(1-hatvalues(DO_LR)))
LR_Residuals
</code></pre>

<hr>
<h2 id='Ehrenfest'>
Generate transition probability matrix of Ehrenfest model
</h2><span id='topic+Ehrenfest'></span>

<h3>Description</h3>

<p>The Ehrenfest model is an interesting example of a Markov chain. Though the probabilities in decimals are not as interesting as expressed in fractions, the function will help the reader generate the transition probability matrices of 2n balls among two urns. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ehrenfest(n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ehrenfest_+3A_n">n</code></td>
<td>

<p>2n will be the number of balls in the urns. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this experiment there are i balls in Urn I, and remaining 2n-i balls in Urn II. Then at any instance, the probability of selecting a ball from Urn I and placing it in Urn II is i/2n, and the other way of placing a ball from Urn II to Urn I is (2n-i)/2n. At each instant we let the number i of balls in the Urn I to be the state of the system. Thus, the state space is S =  0, 1, 2, ..., 2n . Then we can pass from state i only to either of the states i-1 or i+1.
Here, S = 0, 1, ..., 2n. 
</p>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Ehrenfest(2)
Ehrenfest(3)
</code></pre>

<hr>
<h2 id='flight'>
Injuries in Airflights
</h2><span id='topic+flight'></span>

<h3>Description</h3>

<p>Injuries in airflights, road accidents, etc, are instances of rare occurrences which are appropriately modeled by a Poisson distribution. Two models, before and after transformation, are fit and it is checked if the transformation led to a reduction to the variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(flight)</code></pre>


<h3>Format</h3>

<p>A data frame with 9 observations on the following 2 variables.
</p>

<dl>
<dt><code>Injury_Incidents</code></dt><dd><p>Count of injury incidents</p>
</dd>
<dt><code>Total_Flights</code></dt><dd><p>Total number of flights</p>
</dd>
</dl>



<h3>References</h3>

<p>Chatterjee, S., and Hadi, A. S. (1977-2006). Regression Analysis by Examples, 4e.
J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(flight)
names(flight)
injurylm &lt;- lm(Injury_Incidents~Total_Flights,data=flight)
injurysqrtlm &lt;- lm(sqrt(Injury_Incidents)~Total_Flights,data=flight)
summary(injurylm)
summary(injurysqrtlm)
</code></pre>

<hr>
<h2 id='Geom_Sim'>
Simulation for Geometric Distribution
</h2><span id='topic+Geom_Sim'></span>

<h3>Description</h3>

<p>A simple function to understand the algorithm to simulate (psuedo-)observations from binomial distribution. It is an implementation of the algorithm given in Section 11.3.1 &quot;Simulation from Discrete Distributions&quot;, and as such the function is not an alternative to the &quot;rgeom&quot; function. </p>


<h3>Usage</h3>

<pre><code class='language-R'>Geom_Sim(p, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Geom_Sim_+3A_p">p</code></td>
<td>

<p>probability of success
</p>
</td></tr>
<tr><td><code id="Geom_Sim_+3A_n">n</code></td>
<td>

<p>number of pseudo-observations required
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To simulate a random number from geometric RV, we make use of the algorithm described in the book. 
</p>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>rgeom
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mean(Geom_Sim(0.01,10))
</code></pre>

<hr>
<h2 id='girder'>
Strength Data Set of a Girder Experiment
</h2><span id='topic+girder'></span>

<h3>Description</h3>

<p>The shear strength of steel plate girders need to be modeled as a function of the four methods and nine girders. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(girder)</code></pre>


<h3>Format</h3>

<p>A data frame with 9 observations on the following 5 variables.
</p>

<dl>
<dt><code>Girder</code></dt><dd><p>The row names, varying from S1.1 to S4.2, represent the nine type of girders, <code>S1.1</code> <code>S1.2</code> <code>S2.1</code> <code>S2.2</code> <code>S3.1</code> <code>S3.2</code> <code>S4.1</code> <code>S4.2</code> <code>S5.1</code></p>
</dd>
<dt><code>Aarau</code></dt><dd><p>one of the four methods of preparation of the steel plates</p>
</dd>
<dt><code>Karisruhe</code></dt><dd><p>one of the four methods of preparation of the steel plates</p>
</dd>
<dt><code>Lehigh</code></dt><dd><p>one of the four methods of preparation of the steel plates</p>
</dd>
<dt><code>Cardiff</code></dt><dd><p>one of the four methods of preparation of the steel plates</p>
</dd>
</dl>



<h3>References</h3>

<p>Wu, C.F.J. and M. Hamada (2000-9). Experiments: Planning, Analysis, and Parameter
Design Optimization, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(girder)
girder
boxplot(girder[,2:5])
</code></pre>

<hr>
<h2 id='hardness'>
Hardness and a Block Experiment
</h2><span id='topic+hardness'></span>

<h3>Description</h3>

<p>Four types of tip are used which form the blocks in this experiment. The variable of interest is the hardness which further depends on the type of metal coupon. For each type of the tip, the hardness is observed for 4 different types the metal coupon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hardness)</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 3 variables.
</p>

<dl>
<dt><code>Tip_Type</code></dt><dd><p>Four types of tip which form the blocks</p>
</dd>
<dt><code>Test_Coupon</code></dt><dd><p>Four different types of metal coupons</p>
</dd>
<dt><code>Hardness</code></dt><dd><p>Hardness of the coupon</p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hardness)
hardness$Tip_Type &lt;- as.factor(hardness$Tip_Type)
hardness$Test_Coupon &lt;- as.factor(hardness$Test_Coupon)
hardness_aov &lt;- aov(Hardness~Tip_Type+Test_Coupon,data=hardness)
summary(hardness_aov)
</code></pre>

<hr>
<h2 id='hearing'>
Hearing Loss Data
</h2><span id='topic+hearing'></span>

<h3>Description</h3>

<p>A study was carried in the Eastman Kodak Company which involved the measurement of hearing loss. Such studies are called as audiometric study. This data set contains 100 males, each aged 39, who had no indication of noise exposure or hearing disorders. Here, the individual is exposed to a signal of a given frequency with an increasing intensity till the signal is perceived.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hearing)</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 9 variables.
</p>

<dl>
<dt><code>Sl_No</code></dt><dd><p>Serial Number</p>
</dd>
<dt><code>L500</code></dt><dd><p>Observation for 500Hz in the left ear</p>
</dd>
<dt><code>L1000</code></dt><dd><p>Observation for 1000Hz in the left ear</p>
</dd>
<dt><code>L2000</code></dt><dd><p>Observation for 2000Hz in the left ear</p>
</dd>
<dt><code>L4000</code></dt><dd><p>Observation for 4000Hz in the left ear</p>
</dd>
<dt><code>R500</code></dt><dd><p>Observation for 500Hz in the right ear</p>
</dd>
<dt><code>R1000</code></dt><dd><p>Observation for 1000Hz in the right ear</p>
</dd>
<dt><code>R2000</code></dt><dd><p>Observation for 2000Hz in the right ear</p>
</dd>
<dt><code>R4000</code></dt><dd><p>Observation for 4000Hz in the right ear</p>
</dd>
</dl>



<h3>References</h3>

<p>Jackson, J.E. (1991). A User's Guide to Principal Components. New York: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hearing)
round(cor(hearing[,-1]),2)
round(cov(hearing[,-1]),2)
hearing.pc &lt;- princomp(hearing[,-1])
screeplot(hearing.pc,main="B: Scree Plot for Hearing Loss Data")
</code></pre>

<hr>
<h2 id='hw'>
Height-Weight Covariance Study</h2><span id='topic+hw'></span>

<h3>Description</h3>

<p>The data set highlights the importance of handling covariance when such information is available. If the covariance is not incorporated, hypothesis testing may lead to entirely difference conclusion. </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hw)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 2 variables.
</p>

<dl>
<dt><code>Height</code></dt><dd><p>the height of an individual</p>
</dd>
<dt><code>Weight</code></dt><dd><p>the weight of an individual</p>
</dd>
</dl>



<h3>References</h3>

<p>Rencher, A.C. (2002). Methods of Multivariate Analysis, 2e. J. Wiley.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hw)
sigma0 &lt;- matrix(c(20, 100, 100, 1000),nrow=2)
sigma &lt;- var(hw)
v &lt;- nrow(hw)-1
p &lt;- ncol(hw)
u &lt;- v*(log(det(sigma0))-log(det(sigma)) + sum(diag(sigma%*%solve(sigma0)))-p)
u1 &lt;- (1- (1/(6*v-1))*(2*p+1 - 2/(p+1)))*u
u;u1;qchisq(1-0.05,p*(p+1)/2)
</code></pre>

<hr>
<h2 id='insurance'>
Insurance Claims Data
</h2><span id='topic+insurance'></span>

<h3>Description</h3>

<p>Montgomery (2005), page 42, describes this data set in which the number of days taken by the company to process and settle the claims of employee health insurance customers. The data is recorded for the number of days for settlement from the first to fortieth claim.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(insurance)</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 2 variables.
</p>

<dl>
<dt><code>Claim</code></dt><dd><p>Claim number</p>
</dd>
<dt><code>Days</code></dt><dd><p>Days to settle the claim amount</p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D.C. (1985-2012). Introduction to Statistical Quality Control, 7e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(insurance)
plot(insurance$Claim,insurance$Days,"l",xlab="Claim Sequence",
   ylab="Time to Settle the Claim")
title("B: Run Chart for Insurance Claim Settlement")
</code></pre>

<hr>
<h2 id='intensity'>
Blocking for Intensity Data Set
</h2><span id='topic+intensity'></span>

<h3>Description</h3>

<p>The intent of this experiment is to help the engineer in improving the ability of detecting targets on a radar system. The two variables chosen which are believed to have the most impact on the detecting abilities of the radar system are marked as the amount of the background noise and the type of filter on the screen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(intensity)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 4 variables.
</p>

<dl>
<dt><code>Intensity</code></dt><dd><p>intensity of targets</p>
</dd>
<dt><code>Operator</code></dt><dd><p>different operators who form the blocks <code>1</code> <code>2</code> <code>3</code> <code>4</code></p>
</dd>
<dt><code>Filter</code></dt><dd><p>two types of filter <code>1</code> <code>2</code></p>
</dd>
<dt><code>Ground</code></dt><dd><p>the type of background noise <code>high</code> <code>low</code> <code>medium</code></p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(intensity)
intensity.aov &lt;- aov(Intensity~Ground*Filter+Error(Operator),intensity)
summary(intensity.aov)
intensity.aov
</code></pre>

<hr>
<h2 id='kurtcoeff'>
Coefficient of Kurtosis
</h2><span id='topic+kurtcoeff'></span>

<h3>Description</h3>

<p>A simple function to obtain the coefficient of kurtosis on numeric variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kurtcoeff(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kurtcoeff_+3A_x">x</code></td>
<td>

<p>the numeric vector for which the coefficient of kurtosis is required</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A straight-forward implementation of the formula is give here. A complete function &quot;kurtosis&quot; is available in the &quot;e1071&quot; package. 
</p>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>e1071::kurtosis
</p>

<hr>
<h2 id='life'>
Life Expectancies
</h2><span id='topic+life'></span>

<h3>Description</h3>

<p>This data set consists of life expectancy in years by country, age, and sex. </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(life)</code></pre>


<h3>Format</h3>

<p>A data frame with 31 observations on the following 8 variables.
</p>

<dl>
<dt><code>m0</code></dt><dd><p>life expectancy for males at age 0</p>
</dd>
<dt><code>m25</code></dt><dd><p>life expectancy for males at age 25</p>
</dd>
<dt><code>m50</code></dt><dd><p>life expectancy for males at age 50</p>
</dd>
<dt><code>m75</code></dt><dd><p>life expectancy for males at age 75</p>
</dd>
<dt><code>w0</code></dt><dd><p>life expectancy for females at age 0</p>
</dd>
<dt><code>w25</code></dt><dd><p>life expectancy for females at age 25</p>
</dd>
<dt><code>w50</code></dt><dd><p>life expectancy for females at age 50</p>
</dd>
<dt><code>w75</code></dt><dd><p>life expectancy for females at age 75</p>
</dd>
</dl>



<h3>References</h3>

<p>Everitt, B. S., and Hothorn, T. (2011). An Introduction to Applied Multivariate
Analysis with R. Springer.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(life)
factanal(life,factors=1)$PVAL
factanal(life,factors=2)$PVAL
factanal(life,factors=3)
</code></pre>

<hr>
<h2 id='lowbwt'>
The Low-Birth Weight Problem
</h2><span id='topic+lowbwt'></span>

<h3>Description</h3>

<p>Low birth weight of new-born infants is a serious concern. If the weight of the new-born is less than 2500 grams, we consider that instance as a low-birth weight case. A study was carried out at Baystate Medical Center in Springfield, Massachusetts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lowbwt)</code></pre>


<h3>Format</h3>

<p>A data frame with 189 observations on the following 10 variables.
</p>

<dl>
<dt><code>LOW</code></dt><dd><p>Low Birth Weight</p>
</dd>
<dt><code>AGE</code></dt><dd><p>Age of Mother</p>
</dd>
<dt><code>LWT</code></dt><dd><p>Weight of Mother at Last Menstrual Period</p>
</dd>
<dt><code>RACE</code></dt><dd><p>Race <code>1</code> <code>2</code> <code>3</code></p>
</dd>
<dt><code>SMOKE</code></dt><dd><p>Smoking Status During Pregnancy</p>
</dd>
<dt><code>PTL</code></dt><dd><p>History of Premature Labor</p>
</dd>
<dt><code>HT</code></dt><dd><p>History of Hypertension</p>
</dd>
<dt><code>UI</code></dt><dd><p>Presence of Uterine Irritability</p>
</dd>
<dt><code>FTV</code></dt><dd><p>Number of Physician Visits During the First Trimester</p>
</dd>
<dt><code>BWT</code></dt><dd><p>Birth Weight</p>
</dd>
</dl>



<h3>References</h3>

<p>Hosmer, D.W., and Lemeshow, S. (1989-2000). Applied Logistic Regression, 2e. J. Wiley.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lowbwt)
lowglm &lt;- glm(LOW~AGE+LWT+RACE+FTV,data=lowbwt,family='binomial') 
lowglm$coefficients
</code></pre>

<hr>
<h2 id='LRNormal2Mean'>
Likelihood Ratio Test for Equality of Means when Variance Unknown</h2><span id='topic+LRNormal2Mean'></span>

<h3>Description</h3>

<p>This function sets up the likelihood ratio test for equality of means when the variance term is unknown. Refer Chapter 7 for more details. </p>


<h3>Usage</h3>

<pre><code class='language-R'>LRNormal2Mean(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRNormal2Mean_+3A_x">x</code></td>
<td>

<p>Observations from Population 1
</p>
</td></tr>
<tr><td><code id="LRNormal2Mean_+3A_y">y</code></td>
<td>

<p>Observations from Population 2
</p>
</td></tr>
<tr><td><code id="LRNormal2Mean_+3A_alpha">alpha</code></td>
<td>

<p>Size alpha test
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Likelihood ratio test is setup through this function. For more details, refer Chapter 7 of the book. 
</p>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>t.test
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lisa &lt;- c(234.26, 237.18, 238.16, 259.53, 242.76, 237.81, 250.95, 277.83)
mike &lt;- c(187.73, 206.08, 176.71, 213.69, 224.34, 235.24)
LRNormal2Mean(mike,lisa,0.05)
</code></pre>

<hr>
<h2 id='LRNormalMean_KV'>
Likelihood ratio test for equality of mean when the variance is known
</h2><span id='topic+LRNormalMean_KV'></span>

<h3>Description</h3>

<p> Likelihood ratio test for equality of mean when the variance is known for a sample from normal distribution is setup here. For details, refer Chapter 7 of the book. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRNormalMean_KV(x, mu0, alpha, sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRNormalMean_KV_+3A_x">x</code></td>
<td>

<p>the variable of interest
</p>
</td></tr>
<tr><td><code id="LRNormalMean_KV_+3A_mu0">mu0</code></td>
<td>

<p>the mean of interest 
</p>
</td></tr>
<tr><td><code id="LRNormalMean_KV_+3A_alpha">alpha</code></td>
<td>

<p>size of the LR test
</p>
</td></tr>
<tr><td><code id="LRNormalMean_KV_+3A_sigma">sigma</code></td>
<td>

<p>value of the known standard deviation
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar 
</p>


<h3>See Also</h3>

<p>t.test </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hw)
LRNormalMean_KV(hw$Height,mu0=70, alpha=0.05, sigma=sqrt(20))
</code></pre>

<hr>
<h2 id='LRNormalMean_UV'>
Likelihood ratio test for mean when variance is unknown
</h2><span id='topic+LRNormalMean_UV'></span>

<h3>Description</h3>

<p> Likelihood ratio test for mean when variance is unknown for a sample from normal distribution is setup here. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRNormalMean_UV(x, mu0, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRNormalMean_UV_+3A_x">x</code></td>
<td>

<p>the variable of interest</p>
</td></tr>
<tr><td><code id="LRNormalMean_UV_+3A_mu0">mu0</code></td>
<td>

<p>the mean value of interest
</p>
</td></tr>
<tr><td><code id="LRNormalMean_UV_+3A_alpha">alpha</code></td>
<td>

<p>size of the LR test</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar</p>


<h3>See Also</h3>

<p>LRNormalMean_KV
</p>

<hr>
<h2 id='LRNormalVariance_UM'>
Likelihood ratio test for the variance of normal distribution with mean is unknown
</h2><span id='topic+LRNormalVariance_UM'></span>

<h3>Description</h3>

<p>This function returns the LR test for the variance of normal distribution with the mean being unknown. Refer Chapter 7 for more details. </p>


<h3>Usage</h3>

<pre><code class='language-R'>LRNormalVariance_UM(x, sigma0, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRNormalVariance_UM_+3A_x">x</code></td>
<td>

<p>the vector of sample values
</p>
</td></tr>
<tr><td><code id="LRNormalVariance_UM_+3A_sigma0">sigma0</code></td>
<td>

<p>the standard deviation of interest under the hypothesis
</p>
</td></tr>
<tr><td><code id="LRNormalVariance_UM_+3A_alpha">alpha</code></td>
<td>

<p>the required level of significance
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan Tattar</p>


<h3>Examples</h3>

<pre><code class='language-R'>LRNormalVariance_UM(rnorm(20),1,0.05)
</code></pre>

<hr>
<h2 id='lval'>
Letter Values</h2><span id='topic+lval'></span>

<h3>Description</h3>

<p>This function is adapted from Prof. Jim Albert's &quot;LearnEDA&quot; package. It returns the letter values as discussed in Chapter 4. </p>


<h3>Usage</h3>

<pre><code class='language-R'>lval(x, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lval_+3A_x">x</code></td>
<td>

<p>the variable of interest
</p>
</td></tr>
<tr><td><code id="lval_+3A_na.rm">na.rm</code></td>
<td>

<p>the default setting removes the missing values
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan Tattar 
</p>


<h3>See Also</h3>

<p>LearnEDA
</p>

<hr>
<h2 id='memory'>
Memory Recall Times
</h2><span id='topic+memory'></span>

<h3>Description</h3>

<p>A test had been conducted with the purpose of investigating if people recollect pleasant memories associated with a word earlier than some unpleasant memory related with the same word. The word is flashed on the screen and the time an individual takes to respond via keyboard is recorded for both type of the memories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(memory)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 2 variables.
</p>

<dl>
<dt><code>Pleasant.memory</code></dt><dd><p>time to recollect pleasant memory</p>
</dd>
<dt><code>Unpleasant.memory</code></dt><dd><p>time to recollect unpleasant memory</p>
</dd>
</dl>



<h3>References</h3>

<p>Dunn, and Master. (1982). Obtained from 
</p>
<p><a href="http://openlearn.open.ac.uk/mod/resource/view.php?id=165509">http://openlearn.open.ac.uk/mod/resource/view.php?id=165509</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(memory)
lapply(memory,fivenum)
lapply(memory,mad)
lapply(memory,IQR)
</code></pre>

<hr>
<h2 id='mfp'>
Psychological Tests for Males and Females
</h2><span id='topic+mfp'></span>

<h3>Description</h3>

<p>A psychological study consisting of four tests was conducted on males and females group and the results were noted. Since the four tests are correlated and each one is noted for all the individuals, one is interested to know if the mean vector of the test scores is same across the gender group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mfp)</code></pre>


<h3>Format</h3>

<p>A data frame with 32 observations on the following 8 variables.
</p>

<dl>
<dt><code>M_y1</code></dt><dd><p>pictorial inconsistencies for males</p>
</dd>
<dt><code>M_y2</code></dt><dd><p>paper form board test for males</p>
</dd>
<dt><code>M_y3</code></dt><dd><p>tool recognition test for males</p>
</dd>
<dt><code>M_y4</code></dt><dd><p>vocabulary test for males</p>
</dd>
<dt><code>F_y1</code></dt><dd><p>pictorial inconsistencies for females</p>
</dd>
<dt><code>F_y2</code></dt><dd><p>paper form board test for females</p>
</dd>
<dt><code>F_y3</code></dt><dd><p>tool recognition test for females</p>
</dd>
<dt><code>F_y4</code></dt><dd><p>vocabulary test for females</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(mfp)
males &lt;- mfp[,1:4]; females &lt;- mfp[,5:8]
nm &lt;- nrow(males);nf &lt;- nrow(females)
p &lt;- 4; k &lt;- 2
vm &lt;- nm-1; vf &lt;- nf-1
meanm &lt;- colMeans(males); meanf &lt;- colMeans(females)
sigmam &lt;- var(males); sigmaf &lt;- var(females)
sigmapl &lt;- (1/(nm+nf-2))*((nm-1)*sigmam+(nf-1)*sigmaf)
ln_M &lt;- .5*(vm*log(det(sigmam))+vf*log(det(sigmaf))) -.5*(vm+vf)*log(det(sigmapl))
exact_test &lt;- -2*ln_M # the Exact Test
exact_test
</code></pre>

<hr>
<h2 id='MPbinomial'>
Most Powerful Binomial Test
</h2><span id='topic+MPbinomial'></span>

<h3>Description</h3>

<p>The function returns the level alpha MP test for the testing the hypothesis H:p=p0 against K:p=p_1 as ensured by the application of Neyman-Pearson lemma. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MPbinomial(Hp, Kp, alpha, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MPbinomial_+3A_hp">Hp</code></td>
<td>

<p>the value of p under hypothesis H</p>
</td></tr>
<tr><td><code id="MPbinomial_+3A_kp">Kp</code></td>
<td>

<p>the value of p under hypothesis K
</p>
</td></tr>
<tr><td><code id="MPbinomial_+3A_alpha">alpha</code></td>
<td>

<p>size of the test
</p>
</td></tr>
<tr><td><code id="MPbinomial_+3A_n">n</code></td>
<td>

<p>sample size
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>binom.test
</p>

<hr>
<h2 id='MPNormal'>
Most Powerful Test for Normal Distribution
</h2><span id='topic+MPNormal'></span>

<h3>Description</h3>

<p>The most powerful test for a sample from normal distribution is given here. The test is obtained by an application of the Neyman-Pearson lemma. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MPNormal(mu0, mu1, sigma, n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MPNormal_+3A_mu0">mu0</code></td>
<td>

<p>mean under hypothesis H
</p>
</td></tr>
<tr><td><code id="MPNormal_+3A_mu1">mu1</code></td>
<td>

<p>mean under hypothesis K
</p>
</td></tr>
<tr><td><code id="MPNormal_+3A_sigma">sigma</code></td>
<td>

<p>standard deviation
</p>
</td></tr>
<tr><td><code id="MPNormal_+3A_n">n</code></td>
<td>

<p>sample size
</p>
</td></tr>
<tr><td><code id="MPNormal_+3A_alpha">alpha</code></td>
<td>

<p>size of the test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>t.test
</p>

<hr>
<h2 id='MPPoisson'>
Most Powerful Test for Poisson Distribution
</h2><span id='topic+MPPoisson'></span>

<h3>Description</h3>

<p>The most powerful test for a sample from Poisson distribution is given here. The test is obtained by an application of the Neyman-Pearson lemma. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MPPoisson(Hlambda, Klambda, alpha, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MPPoisson_+3A_hlambda">Hlambda</code></td>
<td>

<p>parameter under hypothesis H
</p>
</td></tr>
<tr><td><code id="MPPoisson_+3A_klambda">Klambda</code></td>
<td>

<p>parameter under hypothesis K
</p>
</td></tr>
<tr><td><code id="MPPoisson_+3A_alpha">alpha</code></td>
<td>

<p>size of the MP test
</p>
</td></tr>
<tr><td><code id="MPPoisson_+3A_n">n</code></td>
<td>

<p>sample size
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>

<hr>
<h2 id='msteptpm'>
m-step Transition Probability Matrix Computation
</h2><span id='topic+msteptpm'></span>

<h3>Description</h3>

<p>The m-step transition probability matrix computation is provided in this function. The equation is based on the well-known &quot;Chapman-Kolmogorov equation&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msteptpm(TPM, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="msteptpm_+3A_tpm">TPM</code></td>
<td>

<p>a transition probability matrix
</p>
</td></tr>
<tr><td><code id="msteptpm_+3A_m">m</code></td>
<td>

<p>the m step required
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EF2 &lt;- Ehrenfest(2)
msteptpm(as.matrix(EF2),4)
</code></pre>

<hr>
<h2 id='Mucociliary'>
Mucociliary Clearance
</h2><span id='topic+Mucociliary'></span>

<h3>Description</h3>

<p>Table 6.1 of Hollander and Wolfe (1999) lists the data for Half-Time of Mucociliary Clearance. We need to test if the time across various treatments is equal or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Mucociliary)</code></pre>


<h3>Format</h3>

<p>A data frame with 14 observations on the following 2 variables.
</p>

<dl>
<dt><code>Treatment</code></dt><dd><p>treatment levels <code>Asbestosis</code> <code>Normal Subjects</code> <code>Obstructive Airways Disease</code></p>
</dd>
<dt><code>Time</code></dt><dd><p>half-time of mucociliary clearance</p>
</dd>
</dl>



<h3>References</h3>

<p>Hollander, M., and Wolfe, D. A. (1973-99). Nonparametric Statistical Methods, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Mucociliary)
Mucociliary$Rank &lt;- rank(Mucociliary$Time)
aggregate(Mucociliary$Rank,by=list(Mucociliary$Treatment),sum)
kruskal.test(Time~Treatment,data=Mucociliary)
</code></pre>

<hr>
<h2 id='nerve'>
The Nerve Data
</h2><span id='topic+nerve'></span>

<h3>Description</h3>

<p>The Nerve data set has been popularized by Cox and Lewis (1966). In this experiment 799 waiting times are recorded for successive pulses along a nerve fiber.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nerve)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:799] 0.21 0.03 0.05 0.11 0.59 0.06 0.18 0.55 0.37 0.09 ...
</p>


<h3>Source</h3>

<p>Cox, D. and Lewis, P. (1966). The Statistical Analysis of Series of Events. Chapman &amp; Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(nerve)
nerve_ecdf &lt;- ecdf(nerve)
knots(nerve_ecdf) # Returns the jump points of the edf
summary(nerve_ecdf) # the usual R summaries
nerve_ecdf(nerve) # returns the percentiles at the data points
</code></pre>

<hr>
<h2 id='ns'>
Simulated Sample from Normal Distribution
</h2><span id='topic+ns'></span>

<h3>Description</h3>

<p>The data set is used to understand the sampling variation of the score function. The simulated data is available in Pawitan (2001). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ns)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 20 variables.
</p>

<dl>
<dt><code>Sample.1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.4</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.6</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.8</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.10</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.12</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.13</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.14</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.15</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.16</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.18</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.19</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.20</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>References</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(stats4)
data(ns)
x &lt;- ns[,1]
nlogl &lt;- function(mean,sd) { -sum(dnorm(x,mean=mean,sd=sd,log=TRUE)) }
norm_mle &lt;- mle(nlogl,start=list(mean=median(x),sd=IQR(x)),nobs=length(x))
summary(norm_mle)
</code></pre>

<hr>
<h2 id='olson'>
The Olson Heart Lung Dataset
</h2><span id='topic+olson'></span>

<h3>Description</h3>

<p>We need to determine the effect of the number of revolutions per minute (rpm) of the rotary pump head of an Olson heart-lung pump on the fluid flow rate <code>Liters_minute</code>. The rpm's are replicated at 50, 75, 100, 125, and 150 levels with respective frequencies 5, 3, 5, 2, and 5. The fluid flow rate is measured in litters per minute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(olson)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 4 variables.
</p>

<dl>
<dt><code>Observation</code></dt><dd><p>observation number</p>
</dd>
<dt><code>rpm</code></dt><dd><p>rmp levels at 50, 75, 100, 125, and 150</p>
</dd>
<dt><code>Level</code></dt><dd><p>the rpm levels</p>
</dd>
<dt><code>Liters_minute</code></dt><dd><p>litters per minute</p>
</dd>
</dl>



<h3>References</h3>

<p>Dean, A., and Voss, D. (1999). Design and Analysis of Experiments. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(olson)
par(mfrow=c(2,2))
plot(olson$rpm,olson$Liters_minute,xlim=c(25,175),xlab="RPM",
  ylab="Flow Rate",main="Scatter Plot")
boxplot(Liters_minute~rpm,data=olson,main="Box Plots")
aggregate(olson$Liters_minute,by=list(olson$rpm),mean)
olson_crd &lt;- aov(Liters_minute ~ as.factor(rpm), data=olson)
</code></pre>

<hr>
<h2 id='pareto_density'>
Pareto density
</h2><span id='topic+pareto_density'></span>

<h3>Description</h3>

<p>A simple function is given here which returns the density function values for a Pareto RV. A more efficient implementation is obtainable in the function &quot;dpareto&quot; from the &quot;VGAM&quot; package. </p>


<h3>Usage</h3>

<pre><code class='language-R'>pareto_density(x, scale, shape)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pareto_density_+3A_x">x</code></td>
<td>

<p>the x value
</p>
</td></tr>
<tr><td><code id="pareto_density_+3A_scale">scale</code></td>
<td>

<p>the scale parameter of Pareto RV
</p>
</td></tr>
<tr><td><code id="pareto_density_+3A_shape">shape</code></td>
<td>

<p>the shape parameter of Pareto RV
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar</p>


<h3>See Also</h3>

<p>VGAM::dpareto
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- 9184
n &lt;- 103
b &lt;- 10000
K &lt;- 10
theta &lt;- seq(1000,20000,500)
plot(theta,as.numeric(sapply(theta,pareto_density,scale=b,shape=K)),"l",
     xlab=expression(theta),ylab="The Posterior Density")
(n+1)*m/n
</code></pre>

<hr>
<h2 id='pareto_quantile'>
Quantile of Pareto RV</h2><span id='topic+pareto_quantile'></span>

<h3>Description</h3>

<p>A simple function is given here which returns the quantiles for a Pareto RV. A more efficient implementation is obtainable in the function &quot;qpareto&quot; from the &quot;VGAM&quot; package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pareto_quantile(p, scale, shape)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pareto_quantile_+3A_p">p</code></td>
<td>

<p>the percentiles required</p>
</td></tr>
<tr><td><code id="pareto_quantile_+3A_scale">scale</code></td>
<td>

<p>scale of Pareto RV 
</p>
</td></tr>
<tr><td><code id="pareto_quantile_+3A_shape">shape</code></td>
<td>

<p>shape of Pareto RV
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>VGAM::qpareto
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pareto_quantile(c(0.05,0.95),scale=10000,shape=10)
</code></pre>

<hr>
<h2 id='Poisson_Sim'>
Simulation for Poisson Distribution
</h2><span id='topic+Poisson_Sim'></span>

<h3>Description</h3>

<p>A simple function to understand the algorithm to simulate (psuedo-)observations from binomial distribution. It is an implementation of the algorithm given in Section 11.3.1 &quot;Simulation from Discrete Distributions&quot;. This function is not an alternative to the &quot;rpois&quot; function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Poisson_Sim(lambda, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Poisson_Sim_+3A_lambda">lambda</code></td>
<td>

<p>rate of the Poisson RV</p>
</td></tr>
<tr><td><code id="Poisson_Sim_+3A_n">n</code></td>
<td>

<p>required number of pseudo-observations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar</p>


<h3>See Also</h3>

<p>rpois</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
mean(Poisson_Sim(4,1000))
</code></pre>

<hr>
<h2 id='powertestplot'>
A Function to Plot the Power of a UMP Test for Normal Distribution
</h2><span id='topic+powertestplot'></span>

<h3>Description</h3>

<p>A simple function for obtaining the plot of power of UMP test. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powertestplot(mu0, sigma, n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="powertestplot_+3A_mu0">mu0</code></td>
<td>

<p>the value of mean
</p>
</td></tr>
<tr><td><code id="powertestplot_+3A_sigma">sigma</code></td>
<td>

<p>standard deviation
</p>
</td></tr>
<tr><td><code id="powertestplot_+3A_n">n</code></td>
<td>

<p>sample size
</p>
</td></tr>
<tr><td><code id="powertestplot_+3A_alpha">alpha</code></td>
<td>

<p>size of the test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>t.test
</p>


<h3>Examples</h3>

<pre><code class='language-R'>UMPNormal &lt;- function(mu0, sigma, n,alpha)  {
  qnorm(alpha)*sigma/sqrt(n)+mu0
}
UMPNormal(mu0=0, sigma=1,n=1,alpha=0.5)
powertestplot &lt;- function(mu0,sigma,n,alpha)	{
  mu0seq &lt;- seq(mu0-3*sigma, mu0+3*sigma,(6*sigma/100))
  betamu &lt;- pnorm(sqrt(n)*(mu0seq-mu0)/sigma-qnorm(1-alpha))
  plot(mu0seq,betamu,"l",xlab=expression(mu),ylab="Power of UMP Test",
    main = expression(paste("H:",mu &lt;= mu[0]," vs K:",mu&gt;mu[0])))
  abline(h=alpha)
  abline(v=mu0)
}
powertestplot(mu0=0,sigma=1,n=10,alpha=0.05)
# H:mu &gt; mu_0 vs K: mu &lt;= mu_0
UMPNormal &lt;- function(mu0, sigma, n,alpha)	{
  mu0-qnorm(alpha)*sigma/sqrt(n)
}
UMPNormal(mu0=0, sigma=1,n=1,alpha=0.5)
powertestplot &lt;- function(mu0,sigma,n,alpha)	{
  mu0seq &lt;- seq(mu0-3*sigma, mu0+3*sigma,(6*sigma/100))
  betamu &lt;- pnorm(sqrt(n)*(mu0-mu0seq)/sigma-qnorm(1-alpha))
  plot(mu0seq,betamu,"l",xlab=expression(mu),ylab="Power of UMP Test",
    main=expression(paste("H:",mu &gt;= mu[0]," vs K:",mu&lt;mu[0])))
  abline(h=alpha)
  abline(v=mu0)
}
powertestplot(mu0=0,sigma=1,n=10,alpha=0.05)
</code></pre>

<hr>
<h2 id='ps'>
Simulated Sample from Poisson Distribution
</h2><span id='topic+ps'></span>

<h3>Description</h3>

<p>The data set is used to understand the sampling variation of the score function. The simulated data is available in Pawitan (2001). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ps)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 20 variables.
</p>

<dl>
<dt><code>Sample.1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.4</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.6</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.8</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.10</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.12</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.13</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.14</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.15</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.16</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.18</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.19</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sample.20</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>References</h3>

<p>Pawitan, Y. (2001). In All Likelihood. Oxford Science Publications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ps)
n &lt;- 10
sample_means &lt;- colMeans(ps)
poisson_score_fn &lt;- function(theta,xbar) n*(xbar-theta)/theta
theta &lt;- seq(from=2,to=8,by=0.2)
plot(theta,sapply(theta,poisson_score_fn,xbar=sample_means[1]),"l",xlab=
  expression(lambda),ylab=expression(S(lambda)),ylim=c(-5,15))
title(main="B: Score Function Plot of the Poisson Model")
for(i in 2:20) 
lines(theta,sapply(theta,poisson_score_fn,xbar=sample_means[i]),"l")
abline(v=4)
abline(h=0)</code></pre>

<hr>
<h2 id='pw'>
The Linguistic Probe Word Analysis
</h2><span id='topic+pw'></span>

<h3>Description</h3>

<p>Probe words are used to test the recall ability of words in various linguistic contexts. In this experiment the response time to five different probe words are recorded for 11 individuals. The interest in the experiment is to examine if the response times to the different words are independent or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pw)</code></pre>


<h3>Format</h3>

<p>A data frame with 11 observations on the following 6 variables.
</p>

<dl>
<dt><code>Subject.Number</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y4</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y5</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Rencher, A.C. (2002). Methods of Multivariate Analysis, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pw)
sigma &lt;- var(pw[2:6])
p &lt;- ncol(pw)-1; v &lt;- nrow(pw)-1
u &lt;- p^p*(det(sigma))/(sum(diag(sigma))^p)
u1 &lt;- -(v-(2*p^2+p+2)/(6*p))*log(u)
u;u1
</code></pre>

<hr>
<h2 id='QH_CI'>
Quesenberry-Hurst Simultaneous Confidence Interval</h2><span id='topic+QH_CI'></span>

<h3>Description</h3>

<p>Quesenberry and Hurst (1964) have obtained the &quot;simultaneous confidence intervals&quot; for the vector of success in a multinomial distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QH_CI(x, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QH_CI_+3A_x">x</code></td>
<td>

<p>a numeric vector </p>
</td></tr>
<tr><td><code id="QH_CI_+3A_alpha">alpha</code></td>
<td>

<p>as in 100 (1-alpha) </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>prop.test
</p>

<hr>
<h2 id='reaction'>
Chemical Reaction Experiment
</h2><span id='topic+reaction'></span>

<h3>Description</h3>

<p>For a chemical reaction experiment, the blocks arise due to the Batch number, Catalyst of different types form the treatments, and the reaction time is the output. Due to a restriction, all the catalysts cannot be analysed within each batch and hence we need to look at the BIBD model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("reaction")</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 3 variables.
</p>

<dl>
<dt><code>Catalyst</code></dt><dd><p>different types forming the treatments</p>
</dd>
<dt><code>Batch</code></dt><dd><p>batch number</p>
</dd>
<dt><code>Reaction</code></dt><dd><p>reaction time</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(reaction)
</code></pre>

<hr>
<h2 id='resistant_line'>
Resistant Line EDA Regression Technique</h2><span id='topic+resistant_line'></span>

<h3>Description</h3>

<p>&quot;Resistant Line&quot; is an important EDA way of fitting a regression model. The function here develops the discussion in Section 4.5.1 Resistant Line. An alternative for this function is available in &quot;rline&quot; function of the &quot;LearnEDA&quot; package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resistant_line(x, y, iterations)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resistant_line_+3A_x">x</code></td>
<td>

<p>the covariate or independent vector</p>
</td></tr>
<tr><td><code id="resistant_line_+3A_y">y</code></td>
<td>

<p>the dependent variate
</p>
</td></tr>
<tr><td><code id="resistant_line_+3A_iterations">iterations</code></td>
<td>

<p>the required number of iterations
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>References</h3>

<p>Velleman, P.F., and Hoaglin, D.C. (2004). ABC of Exploratory Data Analysis.
Duxbury Press, Boston. Republished in 2004 by The Internet-First University
Press.
</p>


<h3>See Also</h3>

<p>LearnEDA::rline
</p>

<hr>
<h2 id='rocket'>
Rocket Propellant
</h2><span id='topic+rocket'></span>

<h3>Description</h3>

<p>Five different formulations of a rocket propellant x1 may be used in an aircrew escape systems on the observed burning rate Y. Here, each of the formulation is prepared by mixing from a batch of raw materials x2 which can support only five formulations required for the purpose of testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rocket)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 4 variables.
</p>

<dl>
<dt><code>y</code></dt><dd><p>burning rate</p>
</dd>
<dt><code>batch</code></dt><dd><p>raw materials batch</p>
</dd>
<dt><code>op</code></dt><dd><p>experience of the operator</p>
</dd>
<dt><code>treat</code></dt><dd><p>formulation type of the propellant <code>A</code> <code>B</code> <code>C</code> <code>D</code> <code>E</code></p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rocket)
matrix(rocket$treat,nrow=5)
par(mfrow=c(1,3))
plot(y~factor(op)+factor(batch)+treat,rocket)
rocket_aov &lt;- aov(y~factor(op)+factor(batch)+treat,rocket)
</code></pre>

<hr>
<h2 id='rocket_Graeco'>
Rocket Propellant Example Extended</h2><span id='topic+rocket_Graeco'></span>

<h3>Description</h3>

<p>In continuation of Example 13.4.7 of the Rocket Propellant data, we now have the added blocking factor in test assemblies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rocket_Graeco)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 5 variables.
</p>

<dl>
<dt><code>y</code></dt><dd><p>burning rate</p>
</dd>
<dt><code>batch</code></dt><dd><p>raw materials batch</p>
</dd>
<dt><code>op</code></dt><dd><p>experience of the operator</p>
</dd>
<dt><code>treat</code></dt><dd><p>formulation type of the propellant <code>A</code> <code>B</code> <code>C</code> <code>D</code> <code>E</code></p>
</dd>
<dt><code>assembly</code></dt><dd><p>test assemblies <code>a</code> <code>b</code> <code>c</code> <code>d</code> <code>e</code></p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rocket_Graeco)
plot(y~op+batch+treat+assembly,rocket_Graeco)
rocket.glsd.aov &lt;- aov(y~factor(op)+factor(batch)+treat+assembly,rocket_Graeco)
summary(rocket.glsd.aov)
</code></pre>

<hr>
<h2 id='rootstock'>
Apple of Different Rootstock
</h2><span id='topic+rootstock'></span>

<h3>Description</h3>

<p>The goal is to test if the mean vector of the four variables is same across 6 stratas of the experiment. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(rootstock)</code></pre>


<h3>Format</h3>

<p>A data frame with 48 observations on the following 5 variables.
</p>

<dl>
<dt><code>rootstock</code></dt><dd><p>Six different rootstocks</p>
</dd>
<dt><code>y1</code></dt><dd><p>trunk girth at 4 years</p>
</dd>
<dt><code>y2</code></dt><dd><p>extension growth at 4 years</p>
</dd>
<dt><code>y3</code></dt><dd><p>trunk girth at 15 years</p>
</dd>
<dt><code>y4</code></dt><dd><p>weight of tree above ground at 15 years</p>
</dd>
</dl>



<h3>References</h3>

<p>Rencher, A.C. (2002). Methods of Multivariate Analysis, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rootstock)
attach(rootstock)
rs &lt;- rootstock[,1]
rs &lt;- factor(rs,ordered=is.ordered(rs)) # Too important a step
root.manova &lt;- manova(cbind(y1,y2,y3,y4)~rs)
summary(root.manova, test = "Wilks")
</code></pre>

<hr>
<h2 id='sample'>
Simulated Dataset</h2><span id='topic+sample'></span>

<h3>Description</h3>

<p>In the data set sample, we have data from five different probability distributions. Histograms are used to intuitively understand the underlying probability model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sample)</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 5 variables.
</p>

<dl>
<dt><code>Sample_1</code></dt><dd><p>A sample 1</p>
</dd>
<dt><code>Sample_2</code></dt><dd><p>A sample 2</p>
</dd>
<dt><code>Sample_3</code></dt><dd><p>A sample 3</p>
</dd>
<dt><code>Sample_4</code></dt><dd><p>A sample 4</p>
</dd>
<dt><code>Sample_5</code></dt><dd><p>A sample 5</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(sample)
layout(matrix(c(1,1,2,2,3,3,0,4,4,5,5,0), 2, 6, byrow=TRUE),respect=FALSE) 
matrix(c(1,1,2,2,3,3,0,4,4,5,5,0), 2, 6, byrow=TRUE)
hist(sample[,1],main="Histogram of Sample 1",xlab="sample1", ylab="frequency")
hist(sample[,2],main="Histogram of Sample 2",xlab="sample2", ylab="frequency")
hist(sample[,3],main="Histogram of Sample 3",xlab="sample3", ylab="frequency")
hist(sample[,4],main="Histogram of Sample 4",xlab="sample4", ylab="frequency")
hist(sample[,5],main="Histogram of Sample 5",xlab="sample5", ylab="frequency")
</code></pre>

<hr>
<h2 id='sheishu'>
The Seishu Wine Study
</h2><span id='topic+sheishu'></span>

<h3>Description</h3>

<p>The odor and taste of wines are recorded in a study. It is believed that the variables such as the pH concentration, alcohol content, total sugar, etc, explain the odor and taste of the wine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sheishu)</code></pre>


<h3>Format</h3>

<p>A data frame with 30 observations on the following 10 variables.
</p>

<dl>
<dt><code>Taste</code></dt><dd><p>taste</p>
</dd>
<dt><code>Odor</code></dt><dd><p>odor</p>
</dd>
<dt><code>pH</code></dt><dd><p>pH concentration</p>
</dd>
<dt><code>Acidity_1</code></dt><dd><p>Acidity 1</p>
</dd>
<dt><code>Acidity_2</code></dt><dd><p>Acidity 2</p>
</dd>
<dt><code>Sake_meter</code></dt><dd><p>Sake meter</p>
</dd>
<dt><code>Direct_reducing_sugar</code></dt><dd><p>Direct reducing sugar</p>
</dd>
<dt><code>Total_sugar</code></dt><dd><p>Total sugar</p>
</dd>
<dt><code>Alcohol</code></dt><dd><p>type of alcohol</p>
</dd>
<dt><code>Formyl_nitrogen</code></dt><dd><p>Formyl nitrogen</p>
</dd>
</dl>



<h3>References</h3>

<p>Rencher, A.C. (2002). Methods of Multivariate Analysis, 2e. J. Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sheishu)
noc &lt;- c(2,3,3,2)
nov &lt;- 10
v &lt;- nrow(sheishu)-1
varsheishu &lt;- var(sheishu)
s11 &lt;- varsheishu[1:2,1:2]
s22 &lt;- varsheishu[3:5,3:5]
s33 &lt;- varsheishu[6:8,6:8]
s44 &lt;- varsheishu[9:10,9:10]
u &lt;- det(varsheishu)/(det(s11)*det(s22)*det(s33)*det(s44))
a2 &lt;- nov^2 - sum(noc^2)
a3 &lt;- nov^3 - sum(noc^3)
f &lt;- a2/2
cc &lt;- 1 - (2*a3 + 3*a2)/(12*f*v)
u1 &lt;- -v*cc*log(u)
u; a2; a3; f; cc; u1
qchisq(1-0.001,37)
</code></pre>

<hr>
<h2 id='shelf_stock'>
The Shelf-Stocking Data
</h2><span id='topic+shelf_stock'></span>

<h3>Description</h3>

<p>A merchandiser stocks soft-drink on a shelf as a multiple number of the number of cases. The time required to put the cases in the shelves is recorded as a response. Clearly, if there are no cases to be stocked, it is natural that the time to put them on the shelf will be 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("shelf_stock")</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 2 variables.
</p>

<dl>
<dt><code>Time</code></dt><dd><p>time required to put the cases in the shelves</p>
</dd>
<dt><code>Cases_Stocked</code></dt><dd><p>number of cases</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(shelf_stock)
sslm &lt;- lm(Time ~ Cases_Stocked -1, data=shelf_stock)
</code></pre>

<hr>
<h2 id='siegel.tukey'>
Siegel-Tukey Nonparametric Test</h2><span id='topic+siegel.tukey'></span>

<h3>Description</h3>

<p>This function provided an implementation of the nonparametric discussed in &quot;Section 8.5.3 The Siegel-Tukey Test&quot;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>siegel.tukey(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="siegel.tukey_+3A_x">x</code></td>
<td>

<p>Values from Sample 1</p>
</td></tr>
<tr><td><code id="siegel.tukey_+3A_y">y</code></td>
<td>

<p>Values from Sample 2
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details, refer Section 8.5.3 The Siegel-Tukey Test. </p>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0.028, 0.029, 0.011, -0.030, 0.017, -0.012, -0.027,-0.018, 0.022, -0.023)
y &lt;- c(-0.002, 0.016, 0.005, -0.001, 0.000, 0.008, -0.005,-0.009, 0.001, -0.019)
siegel.tukey(x,y)
</code></pre>

<hr>
<h2 id='skewcoeff'>
A simple and straightforward function to compute the coefficient of skewness</h2><span id='topic+skewcoeff'></span>

<h3>Description</h3>

<p>The function is fairly easy to follow. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewcoeff(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skewcoeff_+3A_x">x</code></td>
<td>

<p>variable of interest
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>e1071::skewness
</p>

<hr>
<h2 id='somesamples'>
Scatter Plots for Understanding Correlations
</h2><span id='topic+somesamples'></span>

<h3>Description</h3>

<p>A cooked data tailor made for the use of scatter plots towards understanding correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(somesamples)</code></pre>


<h3>Format</h3>

<p>A data frame with 200 observations on the following 12 variables.
</p>

<dl>
<dt><code>x1</code></dt><dd><p>x of Sample 1</p>
</dd>
<dt><code>y1</code></dt><dd><p>y of Sample 1</p>
</dd>
<dt><code>x2</code></dt><dd><p>x of Sample 2</p>
</dd>
<dt><code>y2</code></dt><dd><p>y of Sample 2</p>
</dd>
<dt><code>x3</code></dt><dd><p>x of Sample 3</p>
</dd>
<dt><code>y3</code></dt><dd><p>y of Sample 3</p>
</dd>
<dt><code>x4</code></dt><dd><p>x of Sample 4</p>
</dd>
<dt><code>y4</code></dt><dd><p>y of Sample 4</p>
</dd>
<dt><code>x5</code></dt><dd><p>x of Sample 5</p>
</dd>
<dt><code>y5</code></dt><dd><p>y of Sample 5</p>
</dd>
<dt><code>x6</code></dt><dd><p>x of Sample 6</p>
</dd>
<dt><code>y6</code></dt><dd><p>y of Sample 6</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(somesamples)
attach(somesamples)
par(mfrow=c(2,3))
plot(x1,y1,main="Sample I",xlim=c(-4,4),ylim=c(-4,4))
plot(x2,y2,main="Sample II",xlim=c(-4,4),ylim=c(-4,4))
plot(x3,y3,main="Sample III",xlim=c(-4,4),ylim=c(-4,4))
plot(x4,y4,main="Sample IV",xlim=c(-4,4),ylim=c(-4,4))
plot(x5,y5,main="Sample V",xlim=c(-4,4),ylim=c(-4,4))
plot(x6,y6,main="Sample VI",xlim=c(-4,4),ylim=c(-4,4))
</code></pre>

<hr>
<h2 id='SP'>
Understanding Strength of Paper with a Three Factorial Experiment
</h2><span id='topic+SP'></span>

<h3>Description</h3>

<p>The strength of a paper depends on three variables: (i) the percentage of hardwood concentration in the raw pulp, (ii) the vat pressure, and (iii) the cooking time of the pulp. The hardwood concentration is tested at three levels of 2, 4, and 8 percentage, the vat pressure at 400, 500, and 650, while the cooking time is at 3 and 4 hours. For each combination of the these three factor variables, 2 observations are available, and thus a total of 3.3.2.2 = 36 observations. The goal of the study is investigation of the impact of the three factor variables on the strength of the paper, and the presence of interaction effect, if any.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SP)</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following 4 variables.
</p>

<dl>
<dt><code>Hardwood</code></dt><dd><p>a factor with levels <code>2</code> <code>4</code> <code>8</code></p>
</dd>
<dt><code>Pressure</code></dt><dd><p>a factor with levels <code>400</code> <code>500</code> <code>650</code></p>
</dd>
<dt><code>Cooking_Time</code></dt><dd><p>a factor with levels <code>3</code> <code>4</code></p>
</dd>
<dt><code>Strength</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SP)
summary(SP.aov &lt;- aov(Strength~.^3,SP))
</code></pre>

<hr>
<h2 id='ST_Ordered'>
Simulating Random Observations from an Arbitrary Distribution</h2><span id='topic+ST_Ordered'></span>

<h3>Description</h3>

<p>An implementation of the algorithm for simulation of observations from an arbitrary discrete distribution is provided here. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ST_Ordered(N, x, p_x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ST_Ordered_+3A_n">N</code></td>
<td>

<p>number of required random observations</p>
</td></tr>
<tr><td><code id="ST_Ordered_+3A_x">x</code></td>
<td>

<p>the possible values of the RV</p>
</td></tr>
<tr><td><code id="ST_Ordered_+3A_p_x">p_x</code></td>
<td>

<p>the probability vector associated with x
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar</p>


<h3>See Also</h3>

<p>sample
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 1e4
x &lt;- 1:10
p_x &lt;- c(0.05,0.17,0.02,0.14,0.11,0.06,0.05,0.04,0.17,0.19)
table(ST_Ordered(N, x, p_x))
</code></pre>

<hr>
<h2 id='ST_Unordered'>
Simulating Random Observations from an Arbitrary Distribution (ordered probabilities)</h2><span id='topic+ST_Unordered'></span>

<h3>Description</h3>

<p>Simulation observations from an arbitrary discrete distribution with probabilities arranged in desending/ascending order. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ST_Unordered(N, x, p_x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ST_Unordered_+3A_n">N</code></td>
<td>

<p>number of required random observations
</p>
</td></tr>
<tr><td><code id="ST_Unordered_+3A_x">x</code></td>
<td>

<p>the possible values of the RV
</p>
</td></tr>
<tr><td><code id="ST_Unordered_+3A_p_x">p_x</code></td>
<td>

<p>the probability vector associated with x
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>sample
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 1e2
x &lt;- 1:10
p_x &lt;- c(0.05,0.17,0.02,0.14,0.11,0.06,0.05,0.04,0.17,0.19)
ST_Unordered(N,x,p_x)
</code></pre>

<hr>
<h2 id='stationdistTPM'>
A function which will return the stationary distribution of an ergodic Markov chain
</h2><span id='topic+stationdistTPM'></span>

<h3>Description</h3>

<p>This function returns the stationary distribution of an ergodic Markov chain. For details, refer Chapter 11 of the book. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stationdistTPM(M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stationdistTPM_+3A_m">M</code></td>
<td>

<p>a transition probability matrix (TPM)
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar</p>


<h3>See Also</h3>

<p>eigen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- matrix(nrow=3,ncol=3) # An example
P[1,] &lt;- c(1/3,1/3,1/3)
P[2,] &lt;- c(1/4,1/2,1/4)
P[3,] &lt;- c(1/6,1/3,1/2)
stationdistTPM(P)
</code></pre>

<hr>
<h2 id='stiff'>
The Board Stiffness Dataset
</h2><span id='topic+stiff'></span>

<h3>Description</h3>

<p>Four measures of stiffness of 30 boards are available. The first measure of stiffness is obtained by sending a shock wave down the board, the second measure is obtained by vibrating the board, and remaining are obtained from static tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(stiff)</code></pre>


<h3>Format</h3>

<p>A data frame with 30 observations on the following 4 variables.
</p>

<dl>
<dt><code>x1</code></dt><dd><p>first measure of stiffness is obtained by sending a shock wave down the board</p>
</dd>
<dt><code>x2</code></dt><dd><p>second measure is obtained by vibrating the board</p>
</dd>
<dt><code>x3</code></dt><dd><p>third measure is obtained by a static test</p>
</dd>
<dt><code>x4</code></dt><dd><p>fourth measure is obtained by a static test</p>
</dd>
</dl>



<h3>References</h3>

<p>Johnson, R.A., and Wichern, D.W. (1982-2007). Applied Multivariate Statistical Analysis, 6e. Pearson Education.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stiff)
colMeans(stiff)
var(stiff)
pairs(stiff)
</code></pre>

<hr>
<h2 id='swiss'>
Forged Swiss Bank Notes
</h2><span id='topic+swiss'></span>

<h3>Description</h3>

<p>The swiss data set consists of measurements on the width of bottom margin and image diagonal length for forged and real notes. Histogram smoothing method is applied to understand the width of bottom margins for the forged notes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(swiss)</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 4 variables.
</p>

<dl>
<dt><code>Bottforg</code></dt><dd><p>bottom margin of forged notes</p>
</dd>
<dt><code>Diagforg</code></dt><dd><p>diagonal margin of forged notes</p>
</dd>
<dt><code>Bottreal</code></dt><dd><p>bottom margin of real notes</p>
</dd>
<dt><code>Diagreal</code></dt><dd><p>diagonal margin of real notes</p>
</dd>
</dl>



<h3>References</h3>

<p>Simonoff, J.S. (1996). Smoothing Methods in Statistics. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(swiss)
par(mfrow=c(1,3))
hist(swiss$Bottforg,breaks=28,probability=TRUE,col=0,ylim=c(0,.5),
  xlab="Margin width (mm)",ylab="Density")
hist(swiss$Bottforg,breaks=12,probability=TRUE,col=0,ylim=c(0,.5),
  xlab="Margin width (mm)",ylab="Density")
hist(swiss$Bottforg,breaks=6,probability=TRUE,col=0,ylim=c(0,.5),
  xlab="Margin width (mm)",ylab="Density")
</code></pre>

<hr>
<h2 id='tc'>
The Toluca Company Labour Hours against Lot Size
</h2><span id='topic+tc'></span>

<h3>Description</h3>

<p>The Toluca Company manufactures equipment related to refrigerator. The company, in respect of a particular component of a refrigerator, has data on the labor hours required for the component in various lot sizes. Using this data, the officials wanted to find the optimum lot size for producing this part.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tc")</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 2 variables.
</p>

<dl>
<dt><code>Lot_Size</code></dt><dd><p>size of the lot</p>
</dd>
<dt><code>Labour_Hours</code></dt><dd><p>the labor hours required</p>
</dd>
</dl>



<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and Li, W. (1974-2005). Applied
Linear Statistical Models, 5e. McGraw-Hill.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tc)
tclm &lt;- lm(Labour_Hours~Lot_Size,data=tc)
tclm$coefficients
</code></pre>

<hr>
<h2 id='tensile'>
The Tensile Strength Experiment
</h2><span id='topic+tensile'></span>

<h3>Description</h3>

<p>An engineer wants to find out if the cotton weight percentage in a synthetic fiber effects the tensile strength. Towards this, the cotton weight percentage is fixed at 5 different levels of 15, 20, 25, 30, and 35. Each level of the percentage is assigned 5 experimental units and the tensile strength is measured on each of them. The randomization is specified in the <code>Run_Number</code> column. The goal of the engineer is to investigate if the tensile strength is same across the cotton weight percentage. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tensile)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 4 variables.
</p>

<dl>
<dt><code>Test_Sequence</code></dt><dd><p>the test sequence</p>
</dd>
<dt><code>Run_Number</code></dt><dd><p>the run number</p>
</dd>
<dt><code>CWP</code></dt><dd><p>cotton weight percentage</p>
</dd>
<dt><code>Tensile_Strength</code></dt><dd><p>the tensile strength</p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D. C. (1976-2012). Design and Analysis of Experiments, 8e. J.Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tensile)
tensile$CWP &lt;- as.factor(tensile$CWP)
tensile_aov &lt;- aov(Tensile_Strength~CWP, data=tensile)
summary(tensile_aov)
model.matrix(tensile_aov)
</code></pre>

<hr>
<h2 id='testtpm'>
A transition probability matrix</h2><span id='topic+testtpm'></span>

<h3>Description</h3>

<p>A transition probaility matrix for understanding Markov chains. </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(testtpm)</code></pre>


<h3>Format</h3>

<p>A matrix of transition probability matrix
</p>

<dl>
<dt><code>A</code></dt><dd><p>transitions probabilities from State A</p>
</dd>
<dt><code>B</code></dt><dd><p>transitions probabilities from State B</p>
</dd>
<dt><code>C</code></dt><dd><p>transitions probabilities from State C</p>
</dd>
<dt><code>D</code></dt><dd><p>transitions probabilities from State D</p>
</dd>
<dt><code>E</code></dt><dd><p>transitions probabilities from State E</p>
</dd>
<dt><code>F</code></dt><dd><p>transitions probabilities from State F</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(testtpm)
</code></pre>

<hr>
<h2 id='testtpm2'>
A matrix of transition probability matrix, second example</h2><span id='topic+testtpm2'></span>

<h3>Description</h3>

<p>A transition probaility matrix for understanding Markov chains. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(testtpm2)</code></pre>


<h3>Format</h3>

<p>A matrix of transition probability matrix.
</p>

<dl>
<dt><code>A</code></dt><dd><p>transitions probabilities from State A</p>
</dd>
<dt><code>B</code></dt><dd><p>transitions probabilities from State B</p>
</dd>
<dt><code>C</code></dt><dd><p>transitions probabilities from State C</p>
</dd>
<dt><code>D</code></dt><dd><p>transitions probabilities from State D</p>
</dd>
<dt><code>E</code></dt><dd><p>transitions probabilities from State E</p>
</dd>
<dt><code>F</code></dt><dd><p>transitions probabilities from State F</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(testtpm2)
</code></pre>

<hr>
<h2 id='testtpm3'>
A matrix of transition probability matrix, third example
</h2><span id='topic+testtpm3'></span>

<h3>Description</h3>

<p>A transition probaility matrix for understanding Markov chains 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(testtpm3)</code></pre>


<h3>Format</h3>

<p>A data frame with 7 observations on the following 7 variables.
</p>

<dl>
<dt><code>A</code></dt><dd><p>transitions probabilities from State A</p>
</dd>
<dt><code>B</code></dt><dd><p>transitions probabilities from State B</p>
</dd>
<dt><code>C</code></dt><dd><p>transitions probabilities from State C</p>
</dd>
<dt><code>D</code></dt><dd><p>transitions probabilities from State D</p>
</dd>
<dt><code>E</code></dt><dd><p>transitions probabilities from State E</p>
</dd>
<dt><code>F</code></dt><dd><p>transitions probabilities from State F</p>
</dd>
<dt><code>G</code></dt><dd><p>transitions probabilities from State G</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(testtpm3)
</code></pre>

<hr>
<h2 id='TM'>
Trimmed Mean</h2><span id='topic+TM'></span>

<h3>Description</h3>

<p>The trimean can be viewed as the average of median and average of the lower and upper quartiles. A fairly simply function is defined here.</p>


<h3>Usage</h3>

<pre><code class='language-R'>TM(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TM_+3A_x">x</code></td>
<td>

<p>variable of interest
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>TMH, mean, median
</p>

<hr>
<h2 id='TMH'>
Trimean based on hinges instead of quartiles</h2><span id='topic+TMH'></span>

<h3>Description</h3>

<p>The trimean is modified and defined based on hinges instead of the quartiles. </p>


<h3>Usage</h3>

<pre><code class='language-R'>TMH(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TMH_+3A_x">x</code></td>
<td>

<p>variable of interest
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>See Also</h3>

<p>TM
</p>

<hr>
<h2 id='UMPExponential'>
Uniformly Most Powerful Test for Exponential Distribution</h2><span id='topic+UMPExponential'></span>

<h3>Description</h3>

<p>A function is defined here which will return the uniformly most powerful test for exponential distribution. The function needs a simple use of the &quot;qgamma&quot; function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UMPExponential(theta0, n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="UMPExponential_+3A_theta0">theta0</code></td>
<td>

<p>the parameter of interest</p>
</td></tr>
<tr><td><code id="UMPExponential_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
<tr><td><code id="UMPExponential_+3A_alpha">alpha</code></td>
<td>

<p>level of the UMP test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar</p>

<hr>
<h2 id='UMPNormal'>
Uniformly Most Powerful Test for Normal Distribution
</h2><span id='topic+UMPNormal'></span>

<h3>Description</h3>

<p>The &quot;UMPNormal&quot; function returns the critical points required for the UMP test for a sample from normal distribution. The standard deviation is assumed to be known. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UMPNormal(mu0, sigma, n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="UMPNormal_+3A_mu0">mu0</code></td>
<td>

<p>the value of mean of interest</p>
</td></tr>
<tr><td><code id="UMPNormal_+3A_sigma">sigma</code></td>
<td>

<p>standard deviation
</p>
</td></tr>
<tr><td><code id="UMPNormal_+3A_n">n</code></td>
<td>

<p>sample size
</p>
</td></tr>
<tr><td><code id="UMPNormal_+3A_alpha">alpha</code></td>
<td>

<p>size of the UMP test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>

<hr>
<h2 id='UMPUniform'>
Uniformly Most Powerful Test for Uniform Sample</h2><span id='topic+UMPUniform'></span>

<h3>Description</h3>

<p>A simple and straightforward function for obtaining the UMP test for a random sample from uniform distribution. </p>


<h3>Usage</h3>

<pre><code class='language-R'>UMPUniform(theta0, n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="UMPUniform_+3A_theta0">theta0</code></td>
<td>

<p>the parameter value of interest
</p>
</td></tr>
<tr><td><code id="UMPUniform_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
<tr><td><code id="UMPUniform_+3A_alpha">alpha</code></td>
<td>

<p>the size of the required UMP test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>UMPUniform(0.6,10,0.05)
</code></pre>

<hr>
<h2 id='usc'>
US Crime Data
</h2><span id='topic+usc'></span>

<h3>Description</h3>

<p>Data is available on the crime rates across 47 states in USA, and we have additional information on 13 more explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(usc)</code></pre>


<h3>Format</h3>

<p>A data frame with 47 observations on the following 14 variables.
</p>

<dl>
<dt><code>R</code></dt><dd><p>Crime rate - the number of offenses known to the police per 1,000,000 population</p>
</dd>
<dt><code>Age</code></dt><dd><p>Age distribution - the number of males aged 14 to 24 years per 1000 of total state population</p>
</dd>
<dt><code>S</code></dt><dd><p>Binary variable distinguishing southern states (S = 1) from the rest</p>
</dd>
<dt><code>Ed</code></dt><dd><p>Educational level - mean number of years of schooling times 10 of the population 25 years old and over</p>
</dd>
<dt><code>Ex0</code></dt><dd><p>Police expenditure - per capita expenditure on police protection by state and local governments in 1960</p>
</dd>
<dt><code>Ex1</code></dt><dd><p>Police expenditure - as Ex0, but for 1959</p>
</dd>
<dt><code>LF</code></dt><dd><p>Labour force participation rate per 1000 civilian urban males in the age group 14 to 24 years</p>
</dd>
<dt><code>M</code></dt><dd><p>Number of males per 1000 females</p>
</dd>
<dt><code>N</code></dt><dd><p>State population size in hundred thousands</p>
</dd>
<dt><code>NW</code></dt><dd><p>Number of non-whites per 1000</p>
</dd>
<dt><code>U1</code></dt><dd><p>Unemployment rate of urban males per 1000 in the age group 14 to 24 years</p>
</dd>
<dt><code>U2</code></dt><dd><p>Unemployment rate of urban males per 1000 in the age group 35 to 39 years</p>
</dd>
<dt><code>W</code></dt><dd><p>Wealth, as measured by the median value of transferable goods and assets. or family income (unit 10 dollars)</p>
</dd>
<dt><code>X</code></dt><dd><p>Income inequality: the number of families per 1000 earning below one half of the median income</p>
</dd>
</dl>



<h3>References</h3>

<p>Der, G., and Everitt, B.S. (2002). A Handbook of Statistical Analysis using SAS, 2e. CRC.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(usc)
pairs(usc)
round(cor(usc),2)
</code></pre>

<hr>
<h2 id='viscos'>
The Box-Cox Transformation for Viscosity Dataset
</h2><span id='topic+viscos'></span>

<h3>Description</h3>

<p>The goal of this study is to find the impact of temperature on the viscosity of toluence-tetralin blends.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(viscos)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 2 variables.
</p>

<dl>
<dt><code>Temperature</code></dt><dd><p>temperature </p>
</dd>
<dt><code>Viscosity</code></dt><dd><p>viscosity of toluence-tetralin blends</p>
</dd>
</dl>



<h3>References</h3>

<p>Montgomery, D.C., Peck, E.A., and Vining, G.G. (1983-2012). Introduction to Linear Regression Analysis, 5e. J. Wiley. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(viscos)
names(viscos)
viscoslm &lt;- lm(Viscosity~Temperature,data=viscos)
</code></pre>

<hr>
<h2 id='vonNeumann'>
von Neumann Random Number Generator</h2><span id='topic+vonNeumann'></span>

<h3>Description</h3>

<p>The &quot;vonNeumann&quot; function implements the von Neumann random generator as detailed in Section 11.2. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vonNeumann(x, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vonNeumann_+3A_x">x</code></td>
<td>

<p>the initial seed
</p>
</td></tr>
<tr><td><code id="vonNeumann_+3A_n">n</code></td>
<td>

<p>number of required observations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vonNeumann(x=11,n=10)
vonNeumann(x=675248,n=10)
vonNeumann(x=8653,n=100)
</code></pre>

<hr>
<h2 id='waterquality'>
Testing for Physico-chemical Properties of Water in 4 Cities
</h2><span id='topic+waterquality'></span>

<h3>Description</h3>

<p>Water
samples from four cities are collected and their physico-chemical properties for ten variables, such as <code>pH</code>, <code>Conductivity</code>, <code>Dissolution</code>, etc., are measured. We would then like to test if the properties are same across the four cities and in which case a same water treatment approach can be adopted across the cities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(waterquality)</code></pre>


<h3>Format</h3>

<p>A data frame with 63 observations on the following 10 variables.
</p>

<dl>
<dt><code>City</code></dt><dd><p>four cities <code>City1</code> <code>City2</code> <code>City3</code> <code>City4</code></p>
</dd>
<dt><code>pH</code></dt><dd><p>the pH concentration</p>
</dd>
<dt><code>Conductivity</code></dt><dd><p>water conductivity</p>
</dd>
<dt><code>Dissolution</code></dt><dd><p>water dissolution</p>
</dd>
<dt><code>Alkalinity</code></dt><dd><p>alkalinity of the water sample</p>
</dd>
<dt><code>Hardness</code></dt><dd><p>water hardness</p>
</dd>
<dt><code>Calcium.Hardness</code></dt><dd><p>calcium hardness of the water</p>
</dd>
<dt><code>Magnesium.Hardness</code></dt><dd><p>magnesium hardness of the water</p>
</dd>
<dt><code>Chlorides</code></dt><dd><p>chloride content</p>
</dd>
<dt><code>Sulphates</code></dt><dd><p>sulphate content</p>
</dd>
</dl>



<h3>References</h3>

<p>Gore, A.P., Paranjape, S. A., and Kulkarni, M.B. (2006). 100 Data Sets for Statistics Education. Department of Statistics, University of Pune.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(waterquality)
</code></pre>

<hr>
<h2 id='WilsonCI'>
Wilson Confidence Interval</h2><span id='topic+WilsonCI'></span>

<h3>Description</h3>

<p>The Wilson confidence interval for a sample from binomial distribution is a complex formula. This function helps the reader in easily obtaining the required confidence interval as discussed and detailed in Section 16.5. </p>


<h3>Usage</h3>

<pre><code class='language-R'>WilsonCI(x, n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WilsonCI_+3A_x">x</code></td>
<td>

<p>the number of successes
</p>
</td></tr>
<tr><td><code id="WilsonCI_+3A_n">n</code></td>
<td>

<p>the number of trials
</p>
</td></tr>
<tr><td><code id="WilsonCI_+3A_alpha">alpha</code></td>
<td>

<p>the confidence interval size
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>WilsonCI(x=10658,n=15000,alpha=0.05)
prop.test(x=10658,n=15000)$conf.int
</code></pre>

<hr>
<h2 id='ww.test'>
Wald-Wolfowitz Nonparametric Test
</h2><span id='topic+ww.test'></span>

<h3>Description</h3>

<p>The &quot;ww.test&quot; function is an implementation of the famous Wald-Wolfowitz nonparametric test as discussed in Section 8.5. </p>


<h3>Usage</h3>

<pre><code class='language-R'>ww.test(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ww.test_+3A_x">x</code></td>
<td>

<p>values from sample 1
</p>
</td></tr>
<tr><td><code id="ww.test_+3A_y">y</code></td>
<td>

<p>values from sample 2
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prabhanjan N. Tattar
</p>

<hr>
<h2 id='x_bimodal'>
Understanding kernel smoothing through a simulated dataset</h2><span id='topic+x_bimodal'></span>

<h3>Description</h3>

<p>This is a simulated dataset with two modes at -2 and 2 and we have 400 observations.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(x_bimodal)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:400] -4.68 -4.19 -4.05 -4.04 -4.02 ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(x_bimodal)
h &lt;- 0.5; n &lt;- length(x_bimodal)
dens_unif &lt;- NULL; dens_triangle &lt;- NULL; dens_epanechnikov &lt;- NULL
dens_biweight &lt;- NULL; dens_triweight &lt;- NULL; dens_gaussian &lt;- NULL
for(i in 1:n)  {
  u &lt;- (x_bimodal[i]-x_bimodal)/h
  xlogical &lt;- (u&gt;-1 &amp; u &lt;= 1)
  dens_unif[i] &lt;- (1/(n*h))*(sum(xlogical)/2)
  dens_triangle[i] &lt;- (1/(n*h))*(sum(xlogical*(1-abs(u))))
  dens_epanechnikov[i] &lt;- (1/(n*h))*(sum(3*xlogical*(1-u^2)/4))
  dens_biweight[i] &lt;- (1/(n*h))*(15*sum(xlogical*(1-u^2)^2/16))
  dens_triweight[i] &lt;- (1/(n*h))*(35*sum(xlogical*(1-u^2)^3/32))
  dens_gaussian[i] &lt;- (1/(n*h))*(sum(exp(-u^2/2)/sqrt(2*pi)))
}
plot(x_bimodal,dens_unif,"l",ylim=c(0,.25),xlim=c(-5,7),xlab="x",
     ylab="Density",main="B: Applying Kernel Smoothing")
points(x_bimodal,dens_triangle,"l",col="red")
points(x_bimodal,dens_epanechnikov,"l",col="green")
points(x_bimodal,dens_biweight,"l",col="blue")
points(x_bimodal,dens_triweight,"l",col="yellow")
points(x_bimodal,dens_gaussian,"l",col="orange")
legend(4,.23,legend=c("rectangular","triangular","epanechnikov","biweight",
                      "gaussian"),col=c("black","red","green","blue","orange"),lty=1)
</code></pre>

<hr>
<h2 id='yb'>
Youden and Beale's Data on Lesions of Half-Leaves of Tobacco Plant 
</h2><span id='topic+yb'></span>

<h3>Description</h3>

<p>A simple and innovative design is often priceless. Youden and Beale (1934) sought to find the effect of two preparations of virus on tobacco plants. One half of a tobacco leaf was rubbed with cheesecloth soaked in one preparation of the virus extract and the second half was rubbed with the other virus extract. This experiment was replicated on just eight leaves, and the number of lesions on each half leaf was recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(yb)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 2 variables.
</p>

<dl>
<dt><code>Preparation_1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Preparation_2</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>References</h3>

<p>Youden, W. J., and Beale, H. P. (1934). A Statistical Study of the Local Lesion Method for Estimating Tobacco Mosaic Virus. Contrib. Boyce Thompson Inst, 6, 437-454.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(yb)
summary(yb)
quantile(yb$Preparation_1,seq(0,1,.1)) # here seq gives 0, .1, .2, ...,1
quantile(yb$Preparation_2,seq(0,1,.1))
fivenum(yb$Preparation_1)
fivenum(yb$Preparation_2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
