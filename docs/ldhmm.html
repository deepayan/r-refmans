<!DOCTYPE html><html><head><title>Help for package ldhmm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ldhmm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ecld'><p>Constructor of ecld class</p></a></li>
<li><a href='#ecld-class'><p>An S4 class to represent the lambda distribution</p></a></li>
<li><a href='#ecld.cdf'><p>CDF and CCDF of ecld</p></a></li>
<li><a href='#ecld.pdf'><p>Calculate the PDF of an ecld object</p></a></li>
<li><a href='#ecld.sd'><p>Compute statistics analytically for an ecld object</p></a></li>
<li><a href='#ldhmm'><p>Constructor of ldhmm class</p></a></li>
<li><a href='#ldhmm-class'><p>The ldhmm class</p></a></li>
<li><a href='#ldhmm-package'><p>ldhmm: A package for HMM using lambda distribution.</p></a></li>
<li><a href='#ldhmm.calc_stats_from_obs'><p>Computing the statistics for each state</p></a></li>
<li><a href='#ldhmm.conditional_prob'><p>Computing the conditional probabilities</p></a></li>
<li><a href='#ldhmm.decode_stats_history'><p>Estimating historical statistics (mean, volatility and kurtosis)</p></a></li>
<li><a href='#ldhmm.decoding'><p>Computing the minus log-likelihood (MLLK)</p></a></li>
<li><a href='#ldhmm.df2ts'><p>Utility to standardize timeseries from data.frame to xts</p></a></li>
<li><a href='#ldhmm.forecast_prob'><p>Computing the forecast probability distribution</p></a></li>
<li><a href='#ldhmm.forecast_state'><p>Computing the state forecast</p></a></li>
<li><a href='#ldhmm.forecast_volatility'><p>Computing the volatility forecast for next one period</p></a></li>
<li><a href='#ldhmm.fred_data'><p>Utility to download time series from FRED</p></a></li>
<li><a href='#ldhmm.gamma_init'><p>Initializing tansition probability paramter</p></a></li>
<li><a href='#ldhmm.get_data'><p>Read sample data</p></a></li>
<li><a href='#ldhmm.ld_stats'><p>Computes the theoretical statistics per state</p></a></li>
<li><a href='#ldhmm.log_forward'><p>Computing the log forward and backward probabilities</p></a></li>
<li><a href='#ldhmm.mle'><p>Computing the MLEs</p></a></li>
<li><a href='#ldhmm.mllk'><p>Computing the minus log-likelihood (MLLK)</p></a></li>
<li><a href='#ldhmm.n2w'><p>Transforming natural parameters to a linear working parameter array</p></a></li>
<li><a href='#ldhmm.plot_spx_vix_obs'><p>Plotting HMM expected volatility for SPX overlaid with adjusted VIX</p></a></li>
<li><a href='#ldhmm.pseudo_residuals'><p>Computing pseudo-residuals</p></a></li>
<li><a href='#ldhmm.read_csv_by_symbol'><p>Read csv file of sample data</p></a></li>
<li><a href='#ldhmm.read_sample_object'><p>Read sample ldhmm object</p></a></li>
<li><a href='#ldhmm.simulate_abs_acf'><p>Simulating auto-correlation (ACF)</p></a></li>
<li><a href='#ldhmm.simulate_state_transition'><p>Simulating state transition</p></a></li>
<li><a href='#ldhmm.sma'><p>Simple moving average of a time series</p></a></li>
<li><a href='#ldhmm.state_ld'><p>Constructing the ecld objects per state</p></a></li>
<li><a href='#ldhmm.state_pdf'><p>Computing the PDF per state given the observations</p></a></li>
<li><a href='#ldhmm.ts_abs_acf'><p>Computing ACF of the absolute value of a time series</p></a></li>
<li><a href='#ldhmm.ts_log_rtn'><p>Get log-returns from historic prices of an index</p></a></li>
<li><a href='#ldhmm.viterbi'><p>Computing the global decoding by the Viterbi algorithm</p></a></li>
<li><a href='#ldhmm.w2n'><p>Transforming working parameter array to natural parameters</p></a></li>
<li><a href='#numericOrNull-class'><p>The numericOrNull class</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Hidden Markov Model for Financial Time-Series Based on Lambda
Distribution</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-31</td>
</tr>
<tr>
<td>Author:</td>
<td>Stephen H-T. Lihn [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Stephen H-T. Lihn &lt;stevelihn@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Hidden Markov Model (HMM) based on symmetric lambda distribution
    framework is implemented for the study of return time-series in the financial
    market. Major features in the S&amp;P500 index, such as regime identification,
    volatility clustering, and anti-correlation between return and volatility,
    can be extracted from HMM cleanly. Univariate symmetric lambda distribution
    is essentially a location-scale family of exponential power distribution.
    Such distribution is suitable for describing highly leptokurtic time series
    obtained from the financial market. It provides a theoretically solid foundation
    to explore such data where the normal distribution is not adequate. The HMM
    implementation follows closely the book: "Hidden Markov Models for Time Series",
    by Zucchini, MacDonald, Langrock (2016).</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2979516">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2979516</a>
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3435667">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3435667</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, gnorm, optimx, xts (&ge; 0.10-0), zoo, moments,
parallel, graphics, scales, ggplot2, grid, yaml, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, testthat, depmixS4, roxygen2, R.rsp, shape</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/Artistic-2.0">Artistic-2.0</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Collate:</td>
<td>'ecld-cdf-method.R' 'ecld-class.R' 'ecld-constructor.R'
'ecld-pdf-method.R' 'ecld-sd-method.R'
'ldhmm-calc_stats_from_obs.R' 'ldhmm-numericOrNull-class.R'
'ldhmm-package.R' 'ldhmm-class.R' 'ldhmm-conditional_prob.R'
'ldhmm-constructor.R' 'ldhmm-data-config-internal.R'
'ldhmm-decode_stats_history.R' 'ldhmm-decoding.R'
'ldhmm-df2ts-method.R' 'ldhmm-forecast_prob.R'
'ldhmm-forecast_state.R' 'ldhmm-forecast_volatility.R'
'ldhmm-fred_data.R' 'ldhmm-gamma_init.R'
'ldhmm-get-data-method.R' 'ldhmm-ld_stats.R'
'ldhmm-log_forward.R' 'ldhmm-mle.R' 'ldhmm-mllk.R'
'ldhmm-n2w.R' 'ldhmm-plot_spx_vix_obs.R'
'ldhmm-pseudo_residuals.R' 'ldhmm-read-csv-by-symbol-method.R'
'ldhmm-read_sample_object.R' 'ldhmm-simulate_abs_acf.R'
'ldhmm-simulate_state_transition.R' 'ldhmm-sma.R'
'ldhmm-state_ld.R' 'ldhmm-state_pdf.R' 'ldhmm-ts_abs_acf.R'
'ldhmm-ts_log_rtn.R' 'ldhmm-viterbi.R' 'ldhmm-w2n.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-11 04:53:20 UTC; stephenlihn</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-11 05:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ecld'>Constructor of ecld class</h2><span id='topic+ecld'></span>

<h3>Description</h3>

<p>Construct an <code><a href="#topic+ecld-class">ecld-class</a></code> by providing the required parameters.
The default is the standard symmetric cusp distribution (lambda=3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecld(lambda = 3, sigma = 1, mu = 0, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecld_+3A_lambda">lambda</code></td>
<td>
<p>numeric, the lambda parameter. Must be positive. Default: 3.</p>
</td></tr>
<tr><td><code id="ecld_+3A_sigma">sigma</code></td>
<td>
<p>numeric, the scale parameter. Must be positive. Default: 1.</p>
</td></tr>
<tr><td><code id="ecld_+3A_mu">mu</code></td>
<td>
<p>numeric, the location parameter. Default: 0.</p>
</td></tr>
<tr><td><code id="ecld_+3A_verbose">verbose</code></td>
<td>
<p>logical, display timing information, for debugging purpose, default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of ecld class
</p>


<h3>Author(s)</h3>

<p>Stephen H-T. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ld &lt;- ecld()
ld &lt;- ecld(2, 0.01)
</code></pre>

<hr>
<h2 id='ecld-class'>An S4 class to represent the lambda distribution</h2><span id='topic+ecld-class'></span>

<h3>Description</h3>

<p>The <code>ecld</code> class serves as an object-oriented interface for the lambda distribution,
which is just the exponential power distribution in GSL and Wolfram.
</p>


<h3>Slots</h3>


<dl>
<dt><code>call</code></dt><dd><p>the match.call slot</p>
</dd>
<dt><code>lambda</code></dt><dd><p>numeric</p>
</dd>
<dt><code>sigma</code></dt><dd><p>numeric</p>
</dd>
<dt><code>mu</code></dt><dd><p>numeric</p>
</dd>
</dl>


<h3>Details</h3>

<p>The lambda distribution is just the exponential power distribution in GSL and Wolfram, 
with a different definition in the exponent of the stretched exponential function.
</p>
<p>The distribution is symmetric. Its PDF is </p>
<p style="text-align: center;"><code class="reqn">
    P\left(x; \lambda, \sigma, \mu\right)
    \equiv\, \frac{1}{\lambda \Gamma\left(\frac{2}{\lambda}\right) \sigma} 
    e^{-{\left|\frac{x-\mu}{\sigma}\right|}^{\frac{2}{\lambda}}}.
  </code>
</p>

<p>where 
<code class="reqn">\lambda</code> is the shape parameter, 
<code class="reqn">\sigma</code> is the scale parameter, 
<code class="reqn">\mu</code> is the location parameter.
<br />
This functional form is not unfamiliar and has appeared under several other names, such as
generalized normal distribution and power exponential distribution, etc..
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>References</h3>

<p>This distribution is the same as <em>gnorm</em> and is implemented from it since V0.6. 
See <a href="https://cran.r-project.org/package=gnorm">https://cran.r-project.org/package=gnorm</a>.
<br />
For lambda distribution and option pricing model, see 
Stephen Lihn (2015). 
<em>The Special Elliptic Option Pricing Model and Volatility Smile</em>.
SSRN: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2707810">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2707810</a>.
<br />
Closed form solutions are derived in 
Stephen Lihn (2016). <em>Closed Form Solution and Term Structure for SPX Options</em>.
SSRN: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2805769">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2805769</a>
and <br /> 
Stephen Lihn (2017). <em>From Volatility Smile to Risk Neutral Probability and 
Closed Form Solution of Local Volatility Function</em>.
SSRN: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2906522">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2906522</a>
</p>

<hr>
<h2 id='ecld.cdf'>CDF and CCDF of ecld</h2><span id='topic+ecld.cdf'></span><span id='topic+ecld.ccdf'></span>

<h3>Description</h3>

<p>The analytic solutions for CDF and CCDF of ecld, if available.
<code>ecld.cdf_gamma</code> is a sub-module with the CDF expressed as
incomplete gamma function.
SGED is supported only in <code>ecld.cdf</code> and <code>ecld.ccdf</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecld.cdf(object, x)

ecld.ccdf(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecld.cdf_+3A_object">object</code></td>
<td>
<p>an object of ecld class</p>
</td></tr>
<tr><td><code id="ecld.cdf_+3A_x">x</code></td>
<td>
<p>a numeric vector of <code>x</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The CDF or CCDF vector
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ld &lt;- ecld(sigma=0.01)
x &lt;- seq(-0.1, 0.1, by=0.01)
ecld.cdf(ld,x)
</code></pre>

<hr>
<h2 id='ecld.pdf'>Calculate the PDF of an ecld object</h2><span id='topic+ecld.pdf'></span>

<h3>Description</h3>

<p>Calculate the PDF of an ecld object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecld.pdf(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecld.pdf_+3A_object">object</code></td>
<td>
<p>an object of ecd class</p>
</td></tr>
<tr><td><code id="ecld.pdf_+3A_x">x</code></td>
<td>
<p>numeric vector of <code class="reqn">x</code> dimension</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of the PDF
</p>


<h3>Author(s)</h3>

<p>Stephen H-T. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ld &lt;- ecld(lambda=3)
x &lt;- seq(-10, 10, by=1)
ecld.pdf(ld,x)
</code></pre>

<hr>
<h2 id='ecld.sd'>Compute statistics analytically for an ecld object</h2><span id='topic+ecld.sd'></span><span id='topic+ecld.var'></span><span id='topic+ecld.mean'></span><span id='topic+ecld.skewness'></span><span id='topic+ecld.kurtosis'></span><span id='topic+ecld.kurt'></span>

<h3>Description</h3>

<p>Compute statistics for mean, var, skewness, kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecld.sd(object)

ecld.var(object)

ecld.mean(object)

ecld.skewness(object)

ecld.kurtosis(object)

ecld.kurt(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecld.sd_+3A_object">object</code></td>
<td>
<p>an object of ecld class</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>


<h3>Author(s)</h3>

<p>Stephen H-T. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ld &lt;- ecld(3)
ecld.sd(ld)
ecld.var(ld)
ecld.mean(ld)
ecld.skewness(ld)
ecld.kurt(ld)

</code></pre>

<hr>
<h2 id='ldhmm'>Constructor of ldhmm class</h2><span id='topic+ldhmm'></span>

<h3>Description</h3>

<p>Construct an ldhmm class by providing the required parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm(m, param, gamma, delta = NULL, stationary = TRUE, mle.optimizer = "nlm")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm_+3A_m">m</code></td>
<td>
<p>numeric, number of states</p>
</td></tr>
<tr><td><code id="ldhmm_+3A_param">param</code></td>
<td>
<p>matrix, the ecld parameters of states.</p>
</td></tr>
<tr><td><code id="ldhmm_+3A_gamma">gamma</code></td>
<td>
<p>numeric or matrix, the transition probability matrix, must be conformed to m by m.
if provided as vector, it will be converted to a matrix with <code>byrow=TRUE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm_+3A_delta">delta</code></td>
<td>
<p>numeric, the initial distribution for each state, default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ldhmm_+3A_stationary">stationary</code></td>
<td>
<p>logical, specify whether the initial distribution is stationary or not,
default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm_+3A_mle.optimizer">mle.optimizer</code></td>
<td>
<p>character, specify alternative optimizer, default is <code>nlm</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of ldhmm class
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>param0 &lt;- matrix(c(0.003, 0.02, 1, -0.006, 0.03, 1.3), 2, 3, byrow=TRUE)
gamma0 &lt;- matrix(c(0.9, 0.1, 0.1, 0.9), 2, 2, byrow=TRUE)
d &lt;- ldhmm(m=2, param=param0, gamma=gamma0)

</code></pre>

<hr>
<h2 id='ldhmm-class'>The ldhmm class</h2><span id='topic+ldhmm-class'></span>

<h3>Description</h3>

<p>This S4 class is the major object class for ldhmm package
</p>


<h3>Slots</h3>


<dl>
<dt><code>call</code></dt><dd><p>The match.call slot</p>
</dd>
<dt><code>m</code></dt><dd><p>numeric, length 1, number of states</p>
</dd>
<dt><code>param.nbr</code></dt><dd><p>numeric, number of parameters (2 or 3) for each ecld object</p>
</dd>
<dt><code>param</code></dt><dd><p>matrix, natural parameters for ecld objects, size of states times param.nbr.
Each row can be 2-parameter sequences, or 3-parameter sequences.
Three-parameter unit <code>(mu, sigma, lambda)</code> forms an ecld object
representing a leptokurtic symmetric lambda distribution.
On the other hand, to provide compatibility to a normal distribution HMM,
two-parameter unit <code>(mu, sigma)</code> forms an ecld object with lambda=1.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>matrix, the transition probability matrix, must be m by m.</p>
</dd>
<dt><code>delta</code></dt><dd><p>numeric, the initial distribution for each state, default is <code>NULL</code>.</p>
</dd>
<dt><code>stationary</code></dt><dd><p>logical, specify whether the initial distribution is stationary or not,
default is <code>TRUE</code>.</p>
</dd>
<dt><code>mle.optimizer</code></dt><dd><p>character, the MLE optimizer. Currently it is just set to &quot;nlm&quot;.</p>
</dd>
<dt><code>return.code</code></dt><dd><p>numeric, the return code from the MLE optimizer.</p>
</dd>
<dt><code>iterations</code></dt><dd><p>numeric, number of iterations MLE optimizer takes.</p>
</dd>
<dt><code>mllk</code></dt><dd><p>numeric, the final mllk value.</p>
</dd>
<dt><code>AIC</code></dt><dd><p>numeric, the final AIC.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>numeric, the final BIC.</p>
</dd>
<dt><code>observations</code></dt><dd><p>numeric, stores the observations post optimization</p>
</dd>
<dt><code>states.prob</code></dt><dd><p>matrix, stores the state probabilities post optimization</p>
</dd>
<dt><code>states.local</code></dt><dd><p>numeric, stores the local decoding states post optimization</p>
</dd>
<dt><code>states.global</code></dt><dd><p>numeric, stores the global decoding states post optimization (Viterbi)</p>
</dd>
<dt><code>states.local.stats</code></dt><dd><p>matrix, stores the statistics of local states post optimization</p>
</dd>
<dt><code>states.global.stats</code></dt><dd><p>matrix, stores the statistics of global states post optimization</p>
</dd>
</dl>

<hr>
<h2 id='ldhmm-package'>ldhmm: A package for HMM using lambda distribution.</h2><span id='topic+ldhmm-package'></span>

<h3>Description</h3>

<p>The ldhmm package provides the core class and functions to calculate
Hidden Markov Model (HMM) using lambda distribution framework.
The main goal is to provide a theoretically solid foundation to explore 
the return time-series in the financial market, where the normal distribution 
is not adequate due to the leptokurtic nature of the data. 
Major features in the S&amp;P 500 index, such as regime identification, volatility clustering, 
and anti-correlation between return and volatility, can be extracted from HMM cleanly. 
Univariate symmetric lambda distribution is essentially a location-scale family 
of power-exponential distribution. Such distribution is suitable for describing 
highly leptokurtic time series obtained from the financial market.
</p>


<h3>Details</h3>

<p>The main change compared to a normal-distribution based HMM is to add the third paramter
<code>lambda</code> to describe the kurtosis level of the distribution. When <code>lambda</code> is one, the model
converges back to a normal-distribution based HMM (e.g. using depmixS4 package).
The ability to optimize kurtosis brings the model output to be more consistent with the data.
In particular, for daily data, the level of kurtosis is quite high. This puts
the normal distribution in great disadvantage. This problem is solved by using the
lambda distribution.
</p>


<h3>Author(s)</h3>

<p>Stephen H-T. Lihn
</p>


<h3>References</h3>

<p>Walter Zucchini, Iain L. MacDonald, Roland Langrock (2016). 
&quot;Hidden Markov Models for Time Series, An Introduction Using R.&quot;
Second Edition. CRC Press.
</p>

<hr>
<h2 id='ldhmm.calc_stats_from_obs'>Computing the statistics for each state</h2><span id='topic+ldhmm.calc_stats_from_obs'></span><span id='topic+ldhmm.drop_outliers'></span>

<h3>Description</h3>

<p>This utility computes the statistics (mean, sd, kurtosis, length) for each state.
It can be based on the local or global decoding result. The concept of asymptotic 
statistics can be applied by which the largest N observations (in absolute term)
can be dropped to avoid distortion from outliers. 
It is assumed the object already has come with filled data in 
<code>observations, states.prob, states.local, states.global</code> slots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.calc_stats_from_obs(object, drop = 0, use.local = TRUE)

ldhmm.drop_outliers(x, drop = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.calc_stats_from_obs_+3A_object">object</code></td>
<td>
<p>an ldhmm object that contains the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.calc_stats_from_obs_+3A_drop">drop</code></td>
<td>
<p>numeric, an integer to drop the largest N observations, default is zero.</p>
</td></tr>
<tr><td><code id="ldhmm.calc_stats_from_obs_+3A_use.local">use.local</code></td>
<td>
<p>logical, use local decoding result, default is <code>TURE</code>. 
Otherwise, use global decoding result.</p>
</td></tr>
<tr><td><code id="ldhmm.calc_stats_from_obs_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an ldhmm object containing results of decoding, based on data
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.conditional_prob'>Computing the conditional probabilities</h2><span id='topic+ldhmm.conditional_prob'></span>

<h3>Description</h3>

<p>This utility computes the conditional probabilities that observation at time t 
equals xc, given all observations other than that at time t being the same.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.conditional_prob(object, x, xc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.conditional_prob_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.conditional_prob_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.conditional_prob_+3A_xc">xc</code></td>
<td>
<p>numeric, the conditional observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of probabilities, size of xc times size of x.
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.decode_stats_history'>Estimating historical statistics (mean, volatility and kurtosis)</h2><span id='topic+ldhmm.decode_stats_history'></span>

<h3>Description</h3>

<p>This utility estimates historical statistics (mean, volatility and kurtosis) according to the state probabilities.
The ldhmm object must have been decoded by running through <code>ldhmm.decoding</code> function.
Note that kurtosis is naively implemented as the linear sum from each state weighted by state probabilities.
It is subject to change to more rigorous formula in future releases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.decode_stats_history(
  object,
  ma.order = 0,
  annualize = FALSE,
  days.pa = 252
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.decode_stats_history_+3A_object">object</code></td>
<td>
<p>a decoded ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.decode_stats_history_+3A_ma.order">ma.order</code></td>
<td>
<p>a positive integer or zero, specifying order of moving average. Default is zero.</p>
</td></tr>
<tr><td><code id="ldhmm.decode_stats_history_+3A_annualize">annualize</code></td>
<td>
<p>logical, to annaulize the sd and mean to V (xsqrt(days.pa)x100) and R (xdays.pa). 
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.decode_stats_history_+3A_days.pa">days.pa</code></td>
<td>
<p>a positive integer, specifying number of days per year, default is 252.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an matrix of statistics history, size of observations times size of 3
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.decoding'>Computing the minus log-likelihood (MLLK)</h2><span id='topic+ldhmm.decoding'></span>

<h3>Description</h3>

<p>This utility computes the state probabilities, uses local and global decoding to calculate the states.
The results are saved to the returned <code>ldhmm</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.decoding(object, x, do.global = TRUE, do.stats = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.decoding_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.decoding_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.decoding_+3A_do.global">do.global</code></td>
<td>
<p>logical, if <code>TRUE</code> (default), perform Viterbi decoding.</p>
</td></tr>
<tr><td><code id="ldhmm.decoding_+3A_do.stats">do.stats</code></td>
<td>
<p>logical, if <code>TRUE</code> (default), calculate stats.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an ldhmm object containing results of decoding
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.df2ts'>Utility to standardize timeseries from data.frame to xts</h2><span id='topic+ldhmm.df2ts'></span>

<h3>Description</h3>

<p>This utility converts the df input to an xts object with columns
and statistics required for the fitting/plot utility in the ecd package.
The require columns are Date, Close, logr. This utility can also be used
to convert the input from Quandl.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.df2ts(
  df,
  date_format = "%m/%d/%Y",
  dt = "Date",
  col_in = "Close",
  col_out = "Close",
  do.logr = TRUE,
  rnd.zero = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.df2ts_+3A_df">df</code></td>
<td>
<p>Data.frame of the time serie</p>
</td></tr>
<tr><td><code id="ldhmm.df2ts_+3A_date_format">date_format</code></td>
<td>
<p>Character, date format of the input date column. 
It can be NULL to indicate no date conversion is needed.
Default: &quot;<code>%m/%d/%Y</code>&quot;.</p>
</td></tr>
<tr><td><code id="ldhmm.df2ts_+3A_dt">dt</code></td>
<td>
<p>Character, the name of the input date column. Default: &quot;Date&quot;</p>
</td></tr>
<tr><td><code id="ldhmm.df2ts_+3A_col_in">col_in</code></td>
<td>
<p>Character, the name of the input closing price column. Default: &quot;Close&quot;</p>
</td></tr>
<tr><td><code id="ldhmm.df2ts_+3A_col_out">col_out</code></td>
<td>
<p>Character, the name of the output closing price column. Default: &quot;Close&quot;</p>
</td></tr>
<tr><td><code id="ldhmm.df2ts_+3A_do.logr">do.logr</code></td>
<td>
<p>logical, if <code>TRUE</code> (default), produce xts object of logr; otherwise, just the <code>col_out</code> column.</p>
</td></tr>
<tr><td><code id="ldhmm.df2ts_+3A_rnd.zero">rnd.zero</code></td>
<td>
<p>numeric, a small random factor (scaled to sd of logr) to avoid an unreal peak of zero log-returns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The xts object for the time series
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ldhmm.df2ts(df)

## End(Not run)
</code></pre>

<hr>
<h2 id='ldhmm.forecast_prob'>Computing the forecast probability distribution</h2><span id='topic+ldhmm.forecast_prob'></span>

<h3>Description</h3>

<p>This utility computes the forecast probability distribution (Zucchini, 5.3)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.forecast_prob(object, x, xf, h = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.forecast_prob_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_prob_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_prob_+3A_xf">xf</code></td>
<td>
<p>numeric, the future observations to be forecasted.</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_prob_+3A_h">h</code></td>
<td>
<p>integer, time steps to forecast.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of probabilities, size of h times size of xf.
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.forecast_state'>Computing the state forecast</h2><span id='topic+ldhmm.forecast_state'></span>

<h3>Description</h3>

<p>This utility computes the state forecast, given the sequence of observations in the past.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.forecast_state(object, x, h = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.forecast_state_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_state_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_state_+3A_h">h</code></td>
<td>
<p>integer, time steps to forecast.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of probabilities per state (even if h=1), number of states times size of h
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.forecast_volatility'>Computing the volatility forecast for next one period</h2><span id='topic+ldhmm.forecast_volatility'></span>

<h3>Description</h3>

<p>This utility computes the volatility forecast based on the given future observations for next one period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.forecast_volatility(object, x, xf, ma.order = 0, days.pa = 252)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.forecast_volatility_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_volatility_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_volatility_+3A_xf">xf</code></td>
<td>
<p>numeric, the future observations to be forecasted.</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_volatility_+3A_ma.order">ma.order</code></td>
<td>
<p>a positive integer or zero, specifying order of moving average. Default is zero.</p>
</td></tr>
<tr><td><code id="ldhmm.forecast_volatility_+3A_days.pa">days.pa</code></td>
<td>
<p>a positive integer specifying trading days per year, default is 252.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix of future observations and volatilities, size of 2 times length of <code>xf</code>.
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.fred_data'>Utility to download time series from FRED</h2><span id='topic+ldhmm.fred_data'></span>

<h3>Description</h3>

<p>This utility downloads time series from FRED. It serves as a data source for daily data,
e.g. SP500 for S&amp;P 500, and VIXCLS for CBOE VIX index. This can be concatenated to the 
static data to provide daily updates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.fred_data(symbol, col_out = "Close", do.logr = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.fred_data_+3A_symbol">symbol</code></td>
<td>
<p>character, the name of the time series</p>
</td></tr>
<tr><td><code id="ldhmm.fred_data_+3A_col_out">col_out</code></td>
<td>
<p>character, the name of the output closing price column. Default: &quot;Close&quot;</p>
</td></tr>
<tr><td><code id="ldhmm.fred_data_+3A_do.logr">do.logr</code></td>
<td>
<p>logical, if <code>TRUE</code> (default), produce xts object of logr; otherwise, just the <code>col_out</code> column.
Be aware that, because logr uses diff, the first day close will be deleted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The xts object for the time series
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ldhmm.fred_data("VIXCLS")

## End(Not run)
</code></pre>

<hr>
<h2 id='ldhmm.gamma_init'>Initializing tansition probability paramter</h2><span id='topic+ldhmm.gamma_init'></span>

<h3>Description</h3>

<p>This utility has multiple purposes. It can generate a simple transition probability matrix, 
using p1 and p2, if prob is left as NULL. The generated gamma is raw and not normalized.
If prob is provided as a vector, the utility converts it into a matrix as gamma.
Furthermore, if prob is provided as a vector or matrix, the utility 
applies <code>min.gamma</code>, and normalize the sum of t.p.m. rows to 1.
This is mainly an internal function used by MLE, not be concerned by external users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.gamma_init(m, p1 = 0.04, p2 = 0.01, prob = NULL, min.gamma = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.gamma_init_+3A_m">m</code></td>
<td>
<p>numeric, number of states</p>
</td></tr>
<tr><td><code id="ldhmm.gamma_init_+3A_p1">p1</code></td>
<td>
<p>numeric, the first-neighbor transition probability, default is 0.04.</p>
</td></tr>
<tr><td><code id="ldhmm.gamma_init_+3A_p2">p2</code></td>
<td>
<p>numeric, the second-neighbor transition probability, default is 0.01.</p>
</td></tr>
<tr><td><code id="ldhmm.gamma_init_+3A_prob">prob</code></td>
<td>
<p>numeric or matrix, a fully specified transition probability by user, default is <code>NULL</code>.
If this is specified, p1, p2 would be ignored.</p>
</td></tr>
<tr><td><code id="ldhmm.gamma_init_+3A_min.gamma">min.gamma</code></td>
<td>
<p>numeric, a minimum transition probability added to gamma to avoid singularity, default is 0.
This is only used when <code>prob</code> is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix as gamma
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  gamma0 &lt;- ldhmm.gamma_init(m=3)
  prob=c(0.9, 0.1, 0.1, 
         0.1, 0.9, 0.0,
         0.1, 0.1, 0.8)
  gamma1 &lt;- ldhmm.gamma_init(m=3, prob=prob)
  gamma2 &lt;- ldhmm.gamma_init(m=2, prob=gamma1, min.gamma=1e-6)

</code></pre>

<hr>
<h2 id='ldhmm.get_data'>Read sample data</h2><span id='topic+ldhmm.get_data'></span><span id='topic+ldhmm.get_data.arr'></span><span id='topic+ldhmm.get_data.ts'></span>

<h3>Description</h3>

<p>Read sample data by specifying the symbol. The two utilities, <code>ldhmm.get_data</code> and <code>ldhmm.get_data.arr</code>,
serves for slightly different purpose. 
<code>ldhmm.get_data</code> works off the xts object that has two rows: 
the prices and log-returns indexed by the dates. 
<code>ldhmm.get_data.arr</code> and <code>ldhmm.get_data.ts</code> separate the data into list of three vectors: x is the log-return, p is the prices, and d is the dates.
And allows for more sophisticated call for range of dates, and different ways of slice and lag.
<code>ldhmm.get_data.arr</code> takes symbol as input, while <code>ldhmm.get_data.ts</code> takes an xts object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.get_data(symbol = "dji")

ldhmm.get_data.arr(
  symbol = "dji",
  start.date = "1950-01-01",
  end.date = "2015-12-31",
  on = "days",
  lag = 1,
  drop = 0,
  repeated = TRUE,
  cache = TRUE,
  do.kurtosis = FALSE
)

ldhmm.get_data.ts(
  ts,
  start.date = "1950-01-01",
  end.date = "2015-12-31",
  on = "days",
  lag = 1,
  drop = 0,
  repeated = TRUE,
  do.kurtosis = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.get_data_+3A_symbol">symbol</code></td>
<td>
<p>character, the symbol of the time series. Default: dji</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_start.date">start.date</code>, <code id="ldhmm.get_data_+3A_end.date">end.date</code></td>
<td>
<p>Date or character of ISO format (YYYY-MM-DD), to specify the date range, 
default is from 1950-01-01 to 2015-12-31. 
Set start.date and end.date to NULL or &quot;&quot; if you wish to get the entire time series.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_on">on</code></td>
<td>
<p>character, specify the calendar interval, days, weeks, months. Default is <code>days</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_lag">lag</code></td>
<td>
<p>integer, specify the lags of return calculation, default is 1.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_drop">drop</code></td>
<td>
<p>integer, specify number of largest outliners to drop, default is 0.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_repeated">repeated</code></td>
<td>
<p>logical, specify whether to use repeated sampling or unique sampling, default is <code>TRUE</code>.
Using &quot;repeated&quot; sampling can reduce noise due to insufficient sample size. This is particularly useful for larger lags.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_cache">cache</code></td>
<td>
<p>logical, use R's options memory to cache xts data, default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_do.kurtosis">do.kurtosis</code></td>
<td>
<p>logical, if specified, calculate mean, sd, var, skewness, and kurtosis, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.get_data_+3A_ts">ts</code></td>
<td>
<p>xts, the time series</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ldhmm.get_data</code> returns an xts object for the time series, with two columns - &quot;Close&quot; and &quot;logr&quot;.
<code>ldhmm.get_data.arr</code> and <code>ldhmm.get_data.ts</code> return a list of three vectors: x is the log-return, p is the prices, and d is the dates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dji &lt;- ldhmm.get_data()
wti &lt;- ldhmm.get_data("wti")
spx &lt;- ldhmm.get_data.arr("spx", lag=5)
</code></pre>

<hr>
<h2 id='ldhmm.ld_stats'>Computes the theoretical statistics per state</h2><span id='topic+ldhmm.ld_stats'></span>

<h3>Description</h3>

<p>This utility computes the statistics (mean, sd, kurtosis) based on the lambda distribution.
This is used to compare to the statistics from observations for each state.
<code>alloc</code> is a short-hand for Merton's optimal allocation, <code>mean/sd^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.ld_stats(object, annualize = FALSE, days.pa = 252)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.ld_stats_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.ld_stats_+3A_annualize">annualize</code></td>
<td>
<p>logical, to annaulize the sd and mean to V (xsqrt(days.pa)x100) and R (xdays.pa). 
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.ld_stats_+3A_days.pa">days.pa</code></td>
<td>
<p>a positive integer, specifying number of days per year, default is 252.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of statistics for each state, size of states times 4
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.log_forward'>Computing the log forward and backward probabilities</h2><span id='topic+ldhmm.log_forward'></span><span id='topic+ldhmm.log_backward'></span>

<h3>Description</h3>

<p>This utility computes the logarithms of the forward and backward probabilities, 
aka alpha and beta. 
The logarithm keeps the computation away from floating point under/over-flow. 
(Zucchini, 5.4)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.log_forward(object, x)

ldhmm.log_backward(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.log_forward_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.log_forward_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric, the log probabilities
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.mle'>Computing the MLEs</h2><span id='topic+ldhmm.mle'></span>

<h3>Description</h3>

<p>Computing the MLEs using <code>nlm</code> package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.mle(
  object,
  x,
  min.gamma = 1e-06,
  decode = FALSE,
  plot.fn = NULL,
  plot.interval = 200,
  ssm.fn = NULL,
  print.level = 0,
  iterlim = 1000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.mle_+3A_object">object</code></td>
<td>
<p>an ldhmm object that can supply m, param.nbr and stationary.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_min.gamma">min.gamma</code></td>
<td>
<p>numeric, a minimum transition probability added to gamma to avoid singularity, default is <code>1e-6</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_decode">decode</code></td>
<td>
<p>logical, run decoding after optimization, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_plot.fn">plot.fn</code></td>
<td>
<p>name of the function that takes ldhmm object. It will be called occasionally to track the progress
of the fit, mainly by plotting the time series and states. E.g. When one fits the SPX index,
the function <code>ldhmm.oxford_man_plot_obs</code> can be used to show the expected volatility vs 
Oxford-Man realized volatility. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_plot.interval">plot.interval</code></td>
<td>
<p>a positive integer, specifying how often to invoke plot function, default is 200 iterations.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_ssm.fn">ssm.fn</code></td>
<td>
<p>name of the function that takes ldhmm object. This function is called after the MLLK call.
The purpose is to generate an additional score for optimization. E.g. It can be used to separate
the states into predefined intervals, modeling a state space model. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_print.level">print.level</code></td>
<td>
<p>numeric, this argument determines the level of printing 
which is done during the minimization process. 
The default value of 0 means that no printing occurs, 
a value of 1 means that initial and final details are printed 
and a value of 2 means that full tracing information is printed.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_iterlim">iterlim</code></td>
<td>
<p>numeric, a positive integer specifying the maximum number of iterations 
to be performed before the program is terminated.</p>
</td></tr>
<tr><td><code id="ldhmm.mle_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the MLE optimizer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an ldhmm object containg results of MLE optimization
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    param0 &lt;- matrix(c(0.003, 0.02, 1, -0.006, 0.03, 1.3), 2, 3, byrow=TRUE)
    gamma0 &lt;- ldhmm.gamma_init(m=2, prob=c(0.9, 0.1, 0.1, 0.9))
    h &lt;- ldhmm(m=2, param=param0, gamma=gamma0)
    spx &lt;- ldhmm.ts_log_rtn()
    ldhmm.mle(h, spx$x)

## End(Not run)
</code></pre>

<hr>
<h2 id='ldhmm.mllk'>Computing the minus log-likelihood (MLLK)</h2><span id='topic+ldhmm.mllk'></span>

<h3>Description</h3>

<p>This utility computes the MLLK. It is typically invoked by the MLE optimizer. (Zucchini, 3.2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.mllk(object, x, mllk.print.level = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.mllk_+3A_object">object</code></td>
<td>
<p>an input ldhmm object to provide static reference, 
such as m, param.nbr, stationary.</p>
</td></tr>
<tr><td><code id="ldhmm.mllk_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.mllk_+3A_mllk.print.level">mllk.print.level</code></td>
<td>
<p>numeric, this argument determines the level of printing 
which is done during the minimization process. 
The default value of 0 means that no printing occurs, 
a value of 1 or greater means some tracing information is printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an ldhmm object containing results of MLE optimization
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.n2w'>Transforming natural parameters to a linear working parameter array</h2><span id='topic+ldhmm.n2w'></span>

<h3>Description</h3>

<p>This utility linearizes the natural parameters and transforms the contrained parameters
to unconstrained parameters. (Zucchini, 3.3.1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.n2w(object, mu.scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.n2w_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.n2w_+3A_mu.scale">mu.scale</code></td>
<td>
<p>numeric, if provided, e.g. <code>mean(abs(x))</code>, 
it is used to scale up mu so that the scale is more friendly to the optimizer.
Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric, linear working parameter array
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>param0 &lt;- matrix(c(0.003, 0.02, 1, -0.006, 0.03, 1.3), 2, 3, byrow=TRUE)
gamma0 &lt;- matrix(c(0.9, 0.1, 0.1, 0.9), 2, 2, byrow=TRUE)
d &lt;- ldhmm(m=2, param=param0, gamma=gamma0)
v &lt;- ldhmm.n2w(d)

</code></pre>

<hr>
<h2 id='ldhmm.plot_spx_vix_obs'>Plotting HMM expected volatility for SPX overlaid with adjusted VIX</h2><span id='topic+ldhmm.plot_spx_vix_obs'></span>

<h3>Description</h3>

<p>This utility plots the HMM expected volatility of SPX overlaid with the VIX index adjusted by a ratio.
The expected volatility is shown to have a long-term ratio of 0.79 relative to the VIX index. This plot will
show how HMM deviates from VIX in a shorter time window.
Optionally the insert shows the relation between the return and volatility indicated by each state. 
This plot is also called &quot;volatility yield curve&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.plot_spx_vix_obs(
  object,
  days.pa = 252,
  start.date = NULL,
  end.date = NULL,
  px.origin = NULL,
  px.scale = NULL,
  vix.adj.ratio = NULL,
  insert.plot = TRUE,
  insert.viewport = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_object">object</code></td>
<td>
<p>an ldhmm object with a stationary solution. If this is set to <code>NULL</code>,
an internal 10-state HMM object will be used.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_days.pa">days.pa</code></td>
<td>
<p>a positive integer specifying trading days per year, default is 252.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_start.date">start.date</code></td>
<td>
<p>Date or character of ISO format (YYYY-MM-DD), 
specifying the start date of the plot, default is <code>NULL</code>, which is converted to 1.5 years ago.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_end.date">end.date</code></td>
<td>
<p>Date or character of ISO format (YYYY-MM-DD), 
specifying the end date of the plot, default is <code>NULL</code>, which means the latest date.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_px.origin">px.origin</code></td>
<td>
<p>numeric, specifying the starting value of the index price line,
the default is <code>NULL</code>, which will start the index price line from the middle of y-axis.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_px.scale">px.scale</code></td>
<td>
<p>numeric, specifying the scaling factor when plotting price trend, default is 15.
The closing price is converted to cumulative return by the price of the first date.
Then plot from the mid-point of volatility axis with this scale.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_vix.adj.ratio">vix.adj.ratio</code></td>
<td>
<p>numeric, if specified, VIX index is adjusted and plotted, default is <code>NULL</code>.
Default is to use the long-term ratio between VIX and 10-state HMM, which is about 0.79.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_insert.plot">insert.plot</code></td>
<td>
<p>logical, if true, also plot the volatility-return as insert in upper-right corner, default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.plot_spx_vix_obs_+3A_insert.viewport">insert.viewport</code></td>
<td>
<p>optional viewport for the insert, default is <code>NULL</code>, 
which is internally set to <code>grid::viewport(.8, .75, .3, .3)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    ldhmm.plot_spx_vix_obs(h)

## End(Not run)
</code></pre>

<hr>
<h2 id='ldhmm.pseudo_residuals'>Computing pseudo-residuals</h2><span id='topic+ldhmm.pseudo_residuals'></span>

<h3>Description</h3>

<p>This utility computes  pseudo-residuals. (Zucchini, 6.2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.pseudo_residuals(object, x, xc.length = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.pseudo_residuals_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.pseudo_residuals_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.pseudo_residuals_+3A_xc.length">xc.length</code></td>
<td>
<p>a positive integer specifying the length of <code>xc</code> 
when calculating conditional probabilities, default is 1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of normal quantiles
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  sr &lt;- ldhmm.pseudo_residuals(object, x)
  hist(sr)
  acf(sr)
  qqnorm(sr, cex=0.5)
  L &lt;- seq(-3,3,length.out=100)
  lines(L,L,col="red",lwd=2, lty=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='ldhmm.read_csv_by_symbol'>Read csv file of sample data</h2><span id='topic+ldhmm.read_csv_by_symbol'></span>

<h3>Description</h3>

<p>This is a helper utility to read sample csv file into data frame.
The main use for external users is to read the option data
since it has a different format than other price timeseries data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.read_csv_by_symbol(symbol = "dji", extdata_dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.read_csv_by_symbol_+3A_symbol">symbol</code></td>
<td>
<p>Character for the symbol of the time series. Default: dji</p>
</td></tr>
<tr><td><code id="ldhmm.read_csv_by_symbol_+3A_extdata_dir">extdata_dir</code></td>
<td>
<p>optionally specify user's own extdata folder</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The data.frame object
</p>


<h3>Author(s)</h3>

<p>Stephen H-T. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dji &lt;- ldhmm.read_csv_by_symbol("dji")
spx &lt;- ldhmm.read_csv_by_symbol("spx")

</code></pre>

<hr>
<h2 id='ldhmm.read_sample_object'>Read sample ldhmm object</h2><span id='topic+ldhmm.read_sample_object'></span>

<h3>Description</h3>

<p>This utility is used to read sample ldhmm object so that the user doesn't need to go through
lengthy optimization process to obtain a trained HMM for advanced features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.read_sample_object(symbol = "spx-daily-m10", extdata_dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.read_sample_object_+3A_symbol">symbol</code></td>
<td>
<p>Character for the symbol of the time series. Default is <code>spx-daily-m10</code></p>
</td></tr>
<tr><td><code id="ldhmm.read_sample_object_+3A_extdata_dir">extdata_dir</code></td>
<td>
<p>optionally specify user's own extdata folder</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ldhmm object
</p>


<h3>Author(s)</h3>

<p>Stephen H-T. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hs &lt;- ldhmm.read_sample_object() # SPX daily 10-state HMM

</code></pre>

<hr>
<h2 id='ldhmm.simulate_abs_acf'>Simulating auto-correlation (ACF)</h2><span id='topic+ldhmm.simulate_abs_acf'></span>

<h3>Description</h3>

<p>This utility simulates the auto-correlation. The first few lag of ACF should match 
the ACF from the market data fairly well. This is a major validation of a successful HMM.
Be aware this is a CPU intensive calculation. It uses the multi-core functionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.simulate_abs_acf(object, n = 10000, lag.max = 5, debug = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.simulate_abs_acf_+3A_object">object</code></td>
<td>
<p>an ldhmm object that can supply m, param.nbr and stationary.</p>
</td></tr>
<tr><td><code id="ldhmm.simulate_abs_acf_+3A_n">n</code></td>
<td>
<p>a positive integer specifying number of observations to simulate.</p>
</td></tr>
<tr><td><code id="ldhmm.simulate_abs_acf_+3A_lag.max">lag.max</code></td>
<td>
<p>a positive integer, specifying number of lags to be computed.</p>
</td></tr>
<tr><td><code id="ldhmm.simulate_abs_acf_+3A_debug">debug</code></td>
<td>
<p>logical, specifying to print progress message or not. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of ACF
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.simulate_state_transition'>Simulating state transition</h2><span id='topic+ldhmm.simulate_state_transition'></span>

<h3>Description</h3>

<p>This utility allows to simulate the states and obervations over time. 
Be aware this is a CPU intensive calculation. It uses the multi-core functionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.simulate_state_transition(object, init = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.simulate_state_transition_+3A_object">object</code></td>
<td>
<p>an ldhmm object that can supply m, param.nbr and stationary.</p>
</td></tr>
<tr><td><code id="ldhmm.simulate_state_transition_+3A_init">init</code></td>
<td>
<p>a positive integer specifying number of observations to simulate initially.
The default is NULL, indicating that the simulation should use the (local) states and observations
from within the object, and simulate the next set of random states and observations according to gamma.
When init is an integer, the utility will generate random states and observations according to delta.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an ldhmm object containing the simulated states and observations.
The observations are stored in the <code>observations</code> slot.
The states are stored in the <code>states.local</code> slot.
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.sma'>Simple moving average of a time series</h2><span id='topic+ldhmm.sma'></span>

<h3>Description</h3>

<p>This utility calculates simple moving average, with option to backfill for NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.sma(x, order, na.backfill = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.sma_+3A_x">x</code></td>
<td>
<p>numeric, the time series.</p>
</td></tr>
<tr><td><code id="ldhmm.sma_+3A_order">order</code></td>
<td>
<p>a positive integer to specify order of moving average.</p>
</td></tr>
<tr><td><code id="ldhmm.sma_+3A_na.backfill">na.backfill</code></td>
<td>
<p>logical, specify whether to backfill for NA. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric, simple moving average, same length as x.
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:100
a &lt;- ldhmm.sma(x, 10)
</code></pre>

<hr>
<h2 id='ldhmm.state_ld'>Constructing the ecld objects per state</h2><span id='topic+ldhmm.state_ld'></span>

<h3>Description</h3>

<p>This utility constructs the ecld objects per state and return them in a list of easy query.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.state_ld(object, state = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.state_ld_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.state_ld_+3A_state">state</code></td>
<td>
<p>numeric, the states.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of ecld objects
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.state_pdf'>Computing the PDF per state given the observations</h2><span id='topic+ldhmm.state_pdf'></span>

<h3>Description</h3>

<p>Computing the PDF per state given the observations. Only one of state or x 
can be a vector per call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.state_pdf(object, state, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.state_pdf_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.state_pdf_+3A_state">state</code></td>
<td>
<p>numeric, the states.</p>
</td></tr>
<tr><td><code id="ldhmm.state_pdf_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of PDF. The dimension of matrix is state times x
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.ts_abs_acf'>Computing ACF of the absolute value of a time series</h2><span id='topic+ldhmm.ts_abs_acf'></span>

<h3>Description</h3>

<p>This utility computes the ACF of the absolute value of a time series as a proxy 
of the auto-correlation of the volatility. It allows to drop the largest N outliers
so that they would not skew the ACF calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.ts_abs_acf(x, drop = 0, lag.max = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.ts_abs_acf_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
<tr><td><code id="ldhmm.ts_abs_acf_+3A_drop">drop</code></td>
<td>
<p>a positive integer, specifying number of outliers to be dropped.</p>
</td></tr>
<tr><td><code id="ldhmm.ts_abs_acf_+3A_lag.max">lag.max</code></td>
<td>
<p>a positive integer, specifying number of lags to be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of ACF
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.ts_log_rtn'>Get log-returns from historic prices of an index</h2><span id='topic+ldhmm.ts_log_rtn'></span>

<h3>Description</h3>

<p>This utility returns the dates and log-returns of an index available in the package.
Note that the data is static. A limited set of live daily time series can be appended 
from FRED, e.g. SPX, VIX, DJIA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.ts_log_rtn(
  symbol = "spx",
  start.date = "1950-01-01",
  end.date = "2015-12-31",
  on = "weeks",
  fred.data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.ts_log_rtn_+3A_symbol">symbol</code></td>
<td>
<p>character, specify the symbol of the index, default is <code>spx</code>.
If fred.data is true, the program can infer FRED symbol as upper case of symbol.</p>
</td></tr>
<tr><td><code id="ldhmm.ts_log_rtn_+3A_start.date">start.date</code>, <code id="ldhmm.ts_log_rtn_+3A_end.date">end.date</code></td>
<td>
<p>Date or character of ISO format (YYYY-MM-DD), to specify the date range, 
default is from 1950-01-01 to 2015-12-31. 
Set start.date and end.date to NULL or &quot;&quot; if you wish to get the entire time series.</p>
</td></tr>
<tr><td><code id="ldhmm.ts_log_rtn_+3A_on">on</code></td>
<td>
<p>character, specify the interval, days, weeks, months. Default is <code>weeks</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.ts_log_rtn_+3A_fred.data">fred.data</code></td>
<td>
<p>logical, specify whether to append daily time series data from FRED, default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of three vectors: <code>d</code> is the dates and <code>x</code> is log-returns and <code>p</code> is prices
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- ldhmm.ts_log_rtn()
</code></pre>

<hr>
<h2 id='ldhmm.viterbi'>Computing the global decoding by the Viterbi algorithm</h2><span id='topic+ldhmm.viterbi'></span>

<h3>Description</h3>

<p>This utility computes the global decoding by the Viterbi algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.viterbi(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.viterbi_+3A_object">object</code></td>
<td>
<p>an ldhmm object</p>
</td></tr>
<tr><td><code id="ldhmm.viterbi_+3A_x">x</code></td>
<td>
<p>numeric, the observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of states
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='ldhmm.w2n'>Transforming working parameter array to natural parameters</h2><span id='topic+ldhmm.w2n'></span>

<h3>Description</h3>

<p>This utility transforms the working parameter array back to
the vectors and matrix of the contrained parameters. (Zucchini, 3.3.1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldhmm.w2n(object, par.vector, mu.scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldhmm.w2n_+3A_object">object</code></td>
<td>
<p>an ldhmm object that can supply m, param.nbr and stationary.</p>
</td></tr>
<tr><td><code id="ldhmm.w2n_+3A_par.vector">par.vector</code></td>
<td>
<p>numeric, linear working parameter array. See <code>ldhmm.n2w</code>.</p>
</td></tr>
<tr><td><code id="ldhmm.w2n_+3A_mu.scale">mu.scale</code></td>
<td>
<p>numeric, it should mirror what is provided to <code>ldhmm.n2w</code>.
Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an ldhmm object
</p>


<h3>Author(s)</h3>

<p>Stephen H. Lihn
</p>

<hr>
<h2 id='numericOrNull-class'>The numericOrNull class</h2><span id='topic+numericOrNull-class'></span>

<h3>Description</h3>

<p>The S4 class union of numeric and NULL, primarily used for detla
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
