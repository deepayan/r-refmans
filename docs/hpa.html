<!DOCTYPE html><html><head><title>Help for package hpa</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hpa}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bspline'><p>B-splines generation, estimation and combination</p></a></li>
<li><a href='#coef.hpaBinary'><p>Extract coefficients from hpaBinary object</p></a></li>
<li><a href='#coef.hpaML'><p>Extract coefficients from hpaML object</p></a></li>
<li><a href='#coef.hpaSelection'><p>Extract coefficients from hpaSelection object</p></a></li>
<li><a href='#dnorm_parallel'><p>Calculate normal pdf in parallel</p></a></li>
<li><a href='#hpaBinary'><p>Semi-nonparametric single index binary choice model estimation</p></a></li>
<li><a href='#hpaDist'><p>Probabilities and Moments Hermite Polynomial Approximation</p></a></li>
<li><a href='#hpaDist0'><p>Fast pdf and cdf for standardized univariate PGN distribution</p></a></li>
<li><a href='#hpaML'><p>Semi-nonparametric maximum likelihood estimation</p></a></li>
<li><a href='#hpaSelection'><p>Perform semi-nonparametric selection model estimation</p></a></li>
<li><a href='#hsaDist'><p>Probabilities and Moments Hermite Spline Approximation</p></a></li>
<li><a href='#logLik_hpaBinary'><p>Calculates log-likelihood for &quot;hpaBinary&quot; object</p></a></li>
<li><a href='#logLik_hpaML'><p>Calculates log-likelihood for &quot;hpaML&quot; object</p></a></li>
<li><a href='#logLik_hpaSelection'><p>Calculates log-likelihood for &quot;hpaSelection&quot; object</p></a></li>
<li><a href='#logLik.hpaBinary'><p>Calculates log-likelihood for &quot;hpaBinary&quot; object</p></a></li>
<li><a href='#logLik.hpaML'><p>Calculates log-likelihood for &quot;hpaML&quot; object</p></a></li>
<li><a href='#logLik.hpaSelection'><p>Calculates log-likelihood for &quot;hpaSelection&quot; object</p></a></li>
<li><a href='#mecdf'><p>Calculates multivariate empirical cumulative distribution function</p></a></li>
<li><a href='#normalMoment'><p>Calculate k-th order moment of normal distribution</p></a></li>
<li><a href='#plot.hpaBinary'><p>Plot hpaBinary random errors approximated density</p></a></li>
<li><a href='#plot.hpaML'><p>Plot approximated marginal density using hpaML output</p></a></li>
<li><a href='#plot.hpaSelection'><p>Plot hpaSelection random errors approximated density</p></a></li>
<li><a href='#pnorm_parallel'><p>Calculate normal cdf in parallel</p></a></li>
<li><a href='#polynomialIndex'><p>Multivariate Polynomial Representation</p></a></li>
<li><a href='#predict_hpaBinary'><p>Predict method for hpaBinary</p></a></li>
<li><a href='#predict_hpaML'><p>Predict method for hpaML</p></a></li>
<li><a href='#predict_hpaSelection'><p>Predict outcome and selection equation values from hpaSelection model</p></a></li>
<li><a href='#predict.hpaBinary'><p>Predict method for hpaBinary</p></a></li>
<li><a href='#predict.hpaML'><p>Predict method for hpaML</p></a></li>
<li><a href='#predict.hpaSelection'><p>Predict outcome and selection equation values from hpaSelection model</p></a></li>
<li><a href='#print_summary_hpaBinary'><p>Summary for hpaBinary output</p></a></li>
<li><a href='#print_summary_hpaML'><p>Summary for hpaML output</p></a></li>
<li><a href='#print_summary_hpaSelection'><p>Summary for hpaSelection output</p></a></li>
<li><a href='#print.hpaBinary'><p>Print method for &quot;hpaBinary&quot; object</p></a></li>
<li><a href='#print.hpaML'><p>Print method for &quot;hpaML&quot; object</p></a></li>
<li><a href='#print.hpaSelection'><p>Print method for &quot;hpaSelection&quot; object</p></a></li>
<li><a href='#print.summary.hpaBinary'><p>Summary for &quot;hpaBinary&quot; object</p></a></li>
<li><a href='#print.summary.hpaML'><p>Summary for hpaML output</p></a></li>
<li><a href='#print.summary.hpaSelection'><p>Summary for &quot;hpaSelection&quot; object</p></a></li>
<li><a href='#summary_hpaBinary'><p>Summarizing hpaBinary Fits</p></a></li>
<li><a href='#summary_hpaML'><p>Summarizing hpaML Fits</p></a></li>
<li><a href='#summary_hpaSelection'><p>Summarizing hpaSelection Fits</p></a></li>
<li><a href='#summary.hpaBinary'><p>Summarizing hpaBinary Fits</p></a></li>
<li><a href='#summary.hpaML'><p>Summarizing hpaML Fits</p></a></li>
<li><a href='#summary.hpaSelection'><p>Summarizing hpaSelection Fits</p></a></li>
<li><a href='#truncatedNormalMoment'><p>Calculate k-th order moment of truncated normal distribution</p></a></li>
<li><a href='#vcov.hpaBinary'><p>Extract covariance matrix from hpaBinary object</p></a></li>
<li><a href='#vcov.hpaML'><p>Extract covariance matrix from hpaML object</p></a></li>
<li><a href='#vcov.hpaSelection'><p>Extract covariance matrix from hpaSelection object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Distributions Hermite Polynomial Approximation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Potanin Bogdan</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Potanin Bogdan &lt;bogdanpotanin@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Multivariate conditional and marginal densities, moments, cumulative distribution functions as well as binary choice and sample selection models based on Hermite polynomial approximation which was proposed and described by A. Gallant and D. W. Nychka (1987) &lt;<a href="https://doi.org/10.2307%2F1913241">doi:10.2307/1913241</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.10), RcppParallel (&ge; 5.0.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppParallel</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, mvtnorm, titanic, sampleSelection, GA (&ge; 3.2)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-29 05:10:28 UTC; Bogdan</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-29 07:00:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='bspline'>B-splines generation, estimation and combination</h2><span id='topic+bspline'></span><span id='topic+bsplineGenerate'></span><span id='topic+bsplineEstimate'></span><span id='topic+bsplineComb'></span>

<h3>Description</h3>

<p>Function <code><a href="#topic+bsplineGenerate">bsplineGenerate</a></code> generates a list
of all basis splines with appropriate <code>knots</code> vector and <code>degree</code>.
Function <code><a href="#topic+bsplineComb">bsplineComb</a></code> allows to get linear combinations
of these b-splines with particular <code>weights</code>. 
Function <code><a href="#topic+bsplineEstimate">bsplineEstimate</a></code> estimates the spline at
points <code>x</code>. The structure of this spline should be provided via
<code>m</code> and <code>knots</code> arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bsplineGenerate(knots, degree, is_names = TRUE)

bsplineEstimate(x, m, knots)

bsplineComb(splines, weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bspline_+3A_knots">knots</code></td>
<td>
<p>sorted in ascending order numeric vector representing
knots of the spline.</p>
</td></tr>
<tr><td><code id="bspline_+3A_degree">degree</code></td>
<td>
<p>positive integer representing degree of the spline.</p>
</td></tr>
<tr><td><code id="bspline_+3A_is_names">is_names</code></td>
<td>
<p>logical; if TRUE (default) then rows and columns of the
spline matrices will have a names. Set it to FALSE in order to get notable 
speed boost.</p>
</td></tr>
<tr><td><code id="bspline_+3A_x">x</code></td>
<td>
<p>numeric vector representing the points at which the 
spline should be estimated.</p>
</td></tr>
<tr><td><code id="bspline_+3A_m">m</code></td>
<td>
<p>numeric matrix which rows correspond to spline intervals
while columns represent variables powers. Therefore the element 
in i-th row and j-th column represents the coefficient associated with
the variable that 1) belongs to the i-th interval i.e. between i-th and
(i + 1)-th knots 2) raised to the power of (j - 1).</p>
</td></tr>
<tr><td><code id="bspline_+3A_splines">splines</code></td>
<td>
<p>list being returned by the 
<code><a href="#topic+bsplineGenerate">bsplineGenerate</a></code> function or a manually constructed
list with b-splines knots and matrices entries.</p>
</td></tr>
<tr><td><code id="bspline_+3A_weights">weights</code></td>
<td>
<p>numeric vector of the same length as <code>splines</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In contrast to <code><a href="splines.html#topic+bs">bs</a></code> function 
<code><a href="#topic+bsplineGenerate">bsplineGenerate</a></code> generates a splines basis in a form
of a list containing information concerning these b-splines structure.
In order to evaluate one of these b-splines at particular points
<code><a href="#topic+bsplineEstimate">bsplineEstimate</a></code> function should be applied.
</p>


<h3>Value</h3>

<p>Function <code><a href="#topic+bsplineGenerate">bsplineGenerate</a></code> returns a list. Each
element of this list is a list containing the following
information concerning b-spline structure:
</p>

<ul>
<li> <p><code>knots</code> - knots vector of the b-spline. 
</p>
</li>
<li> <p><code>m</code> - matrix representing polynomial coefficients for each
interval of the spline in the same manner as for <code>m</code> argument
(see this argument description above).
</p>
</li>
<li> <p><code>ind</code> - index of the b-spline.</p>
</li></ul>

<p>Function <code>bsplineComb</code> returns a list with the following arguments:
</p>

<ul>
<li> <p><code>knots</code> - knots vector of the <code>splines</code>. 
</p>
</li>
<li> <p><code>m</code> - linear combination of the <code>splines</code> matrices; 
coefficients of this linear combination are given 
via <code>weights</code> argument.</p>
</li></ul>

<p>Function <code><a href="#topic+bsplineGenerate">bsplineGenerate</a></code> returns a numeric
vector of values being calculated at points <code>x</code> via splines with 
<code>knots</code> vector and matrix <code>m</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Let's generate all b-splines of degree 3 with knots 
# vector (-2.1, 1.5, 1.5, 2.2, 3.7, 4.2, 5)
b &lt;- bsplineGenerate(knots = c(-2.1, 1.5, 1.5, 2.2, 3.7, 4.2, 5), 
                     degree = 3)

# Get the first of these b-splines
b[[1]]

# Take a linear combination of these splines with 
# weights 1.6, -1.2 and 3.2.
b_comb &lt;- bsplineComb(splines = b, weights = c(1.6, -1.2, 3.2))

# Estimate this spline value at points (-3, 0.7, 2.5, 3.8, 10)
b_values &lt;- bsplineEstimate(x = c(-3, 0.7, 2.5, 3.8, 10),  
                            knots = b_comb$knots, 
                            m = b_comb$m)

# Visualize the spline
s &lt;- seq(from = 0, to = 5, length = 1000)
b_values_s &lt;- bsplineEstimate(x = s,  
                              knots = b_comb$knots, 
                              m = b_comb$m)
plot(s, b_values_s)

</code></pre>

<hr>
<h2 id='coef.hpaBinary'>Extract coefficients from hpaBinary object</h2><span id='topic+coef.hpaBinary'></span>

<h3>Description</h3>

<p>Extract coefficients from hpaBinary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="coef.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='coef.hpaML'>Extract coefficients from hpaML object</h2><span id='topic+coef.hpaML'></span>

<h3>Description</h3>

<p>Extract coefficients from hpaML object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="coef.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='coef.hpaSelection'>Extract coefficients from hpaSelection object</h2><span id='topic+coef.hpaSelection'></span>

<h3>Description</h3>

<p>Extract coefficients from hpaSelection object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
coef(object, ..., type = "all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="coef.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
<tr><td><code id="coef.hpaSelection_+3A_type">type</code></td>
<td>
<p>character; if &quot;all&quot; (default) then all estimated parameters
values will be returned. If &quot;selection&quot; then selection equation coefficients
estimates will be provided. If &quot;outcome&quot; then outcome equation coefficients
estimates will be returned.</p>
</td></tr>
</table>

<hr>
<h2 id='dnorm_parallel'>Calculate normal pdf in parallel</h2><span id='topic+dnorm_parallel'></span>

<h3>Description</h3>

<p>Calculate in parallel for each value from vector <code>x</code> 
density function of normal distribution with 
mean equal to <code>mean</code> and standard deviation equal to <code>sd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnorm_parallel(x, mean = 0, sd = 1, is_parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dnorm_parallel_+3A_x">x</code></td>
<td>
<p>numeric vector of quantiles.</p>
</td></tr>
<tr><td><code id="dnorm_parallel_+3A_mean">mean</code></td>
<td>
<p>double value.</p>
</td></tr>
<tr><td><code id="dnorm_parallel_+3A_sd">sd</code></td>
<td>
<p>double positive value.</p>
</td></tr>
<tr><td><code id="dnorm_parallel_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Consider normal distribution with mean 3 and standard deviation 5.
## Calculate its density function at points 2 and 3.

# Create vector of points
my_points &lt;- c(2, 3)

# Calculate pdf at these points 
# (set is_parallel = TRUE in order 
# to turn on parallel computations)
dnorm_parallel(my_points, 3, 5, 
               is_parallel = FALSE)
</code></pre>

<hr>
<h2 id='hpaBinary'>Semi-nonparametric single index binary choice model estimation</h2><span id='topic+hpaBinary'></span>

<h3>Description</h3>

<p>This function performs semi-nonparametric (SNP) maximum 
likelihood estimation of single index binary choice model 
using Hermite polynomial based approximating function proposed by Gallant 
and Nychka in 1987. Please, see <code><a href="#topic+dhpa">dhpa</a></code> 'Details' section to 
get more information concerning this approximating function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hpaBinary(
  formula,
  data,
  K = 1L,
  mean_fixed = NA_real_,
  sd_fixed = NA_real_,
  constant_fixed = 0,
  coef_fixed = TRUE,
  is_x0_probit = TRUE,
  is_sequence = FALSE,
  x0 = numeric(0),
  cov_type = "sandwich",
  boot_iter = 100L,
  is_parallel = FALSE,
  opt_type = "optim",
  opt_control = NULL,
  is_validation = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpaBinary_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;formula&quot; 
(or one that can be coerced to that class):
a symbolic description of the model to be fitted.
All variables in <code>formula</code> should be numeric 
vectors of the same length.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_data">data</code></td>
<td>
<p>data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_k">K</code></td>
<td>
<p>non-negative integer representing polynomial degree (order).</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_mean_fixed">mean_fixed</code></td>
<td>
<p>numeric value for binary choice 
equation random error density mean parameter. 
Set it to <code>NA</code> (default) if this parameter should be 
estimated rather than fixed.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_sd_fixed">sd_fixed</code></td>
<td>
<p>numeric value for binary choice equation random error
density <code>sd</code> parameter. Set it to <code>NA</code> (default) if this parameter
should be estimated rather than fixed.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_constant_fixed">constant_fixed</code></td>
<td>
<p>numeric value for binary choice 
equation constant parameter. Set it to <code>NA</code> (default) if this 
parameter should be estimated rather than fixed.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_coef_fixed">coef_fixed</code></td>
<td>
<p>logical value indicating whether binary 
equation first independent variable coefficient should be fixed 
(<code>TRUE</code>) or estimated (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_is_x0_probit">is_x0_probit</code></td>
<td>
<p>logical; if <code>TRUE</code> (default) then initial
points for optimization routine will be
obtained by probit model estimated via <a href="stats.html#topic+glm">glm</a> function.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_is_sequence">is_sequence</code></td>
<td>
<p>if TRUE then function calculates models with polynomial
degrees from 0 to K each time using initial values obtained from the 
previous step. In this case function will return the list of models where 
i-th list element correspond to model calculated under K=(i-1).</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_x0">x0</code></td>
<td>
<p>numeric vector of optimization routine initial values.
Note that <code>x0 = c(pol_coefficients[-1], mean, sd, coefficients)</code>.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_cov_type">cov_type</code></td>
<td>
<p>character determining the type of covariance matrix to be
returned and used for summary. If <code>cov_type = "hessian"</code> then negative
inverse of Hessian matrix will be applied. If <code>cov_type = "gop"</code> then
inverse of Jacobian outer products will be used.
If <code>cov_type = "sandwich"</code> (default) then sandwich covariance matrix
estimator will be applied. If <code>cov_type = "bootstrap"</code> then bootstrap
with <code>boot_iter</code> iterations will be used.
If <code>cov_type = "hessianFD"</code> or <code>cov_type = "sandwichFD"</code> then
(probably) more accurate but computationally demanding central difference 
Hessian approximation will be calculated for the inverse Hessian and 
sandwich estimators correspondingly. Central differences are computed via
analytically provided gradient. This Hessian matrix estimation approach
seems to be less accurate than BFGS approximation if polynomial order
is high (usually greater then 5).</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_boot_iter">boot_iter</code></td>
<td>
<p>the number of bootstrap iterations
for <code>cov_type = "bootstrap"</code> covariance matrix estimator type.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_opt_type">opt_type</code></td>
<td>
<p>string value determining the type of the optimization
routine to be applied. The default is <code>"optim"</code> meaning that BFGS method
from the <code><a href="stats.html#topic+optim">optim</a></code> function will be applied.
If <code>opt_type = "GA"</code> then <code><a href="GA.html#topic+ga">ga</a></code> function will be
additionally applied.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_opt_control">opt_control</code></td>
<td>
<p>a list containing arguments to be passed to the
optimization routine depending on <code>opt_type</code> argument value.
Please see details to get additional information.</p>
</td></tr>
<tr><td><code id="hpaBinary_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Densities Hermite polynomial approximation approach has been
proposed by A. Gallant and D. W. Nychka in 1987. The main idea is to
approximate unknown distribution density with scaled Hermite polynomial.
For more information please refer to the literature listed below.
</p>
<p>Let's use notations introduced in <code><a href="#topic+dhpa">dhpa</a></code> 'Details' 
section. Function <code><a href="#topic+hpaBinary">hpaBinary</a></code> maximizes the following
quasi log-likelihood function:
</p>
<p style="text-align: center;"><code class="reqn">\ln L(\gamma_{0}, \gamma, \alpha, \mu, \sigma; x) = 
\sum\limits_{i:z_{i}=1} 
\ln\left(\overline{F}_{\xi}
(-(\gamma_{0}+\gamma x_{i}), \infty;\alpha, \mu, \sigma)\right) +</code>
</p>

<p style="text-align: center;"><code class="reqn">
+\sum\limits_{i:z_{i}=0} 
\ln\left(\overline{F}_{\xi}
(-\infty, -(\gamma_{0} + x_{i}\gamma);\alpha, \mu, \sigma)\right),</code>
</p>

<p>where (in addition to previously defined notations):
</p>
<p><code class="reqn">x_{i}</code> - is row vector of regressors derived from <code>data</code> 
according to <code>formula</code>.
</p>
<p><code class="reqn">\gamma</code> - is column vector of regression coefficients.
</p>
<p><code class="reqn">\gamma_{0}</code> - constant.
</p>
<p><code class="reqn">z_{i}</code> - binary (0 or 1) dependent variable defined in <code>formula</code>.
</p>
<p>Note that <code class="reqn">\xi</code> is one dimensional and <code>K</code> corresponds
to <code class="reqn">K=K_{1}</code>.
</p>
<p>The first polynomial coefficient (zero powers) 
set to 1 for identification purposes i.e. <code class="reqn">\alpha_{0}=1</code>.
</p>
<p>If <code>coef_fixed</code> is <code>TRUE</code> then the coefficient for the 
first independent variable in <code>formula</code> will be fixed to 1 i.e.
<code class="reqn">\gamma_{1}=1</code>.
</p>
<p>If <code>mean_fixed</code> is not <code>NA</code> then <code class="reqn">\mu</code>=<code>mean_fixed</code>
fixed.
</p>
<p>If <code>sd_fixed</code> is not <code>NA</code> then <code class="reqn">\sigma</code>=<code>mean_fixed</code>
fixed. However if <code>is_x0_probit = TRUE</code> then parameter <code class="reqn">\sigma</code> will 
be scale adjusted in order to provide better initial point for optimization 
routine. Please, extract <code class="reqn">\sigma</code> adjusted value from the function's 
output list. The same is for <code>mean_fixed</code>.
</p>
<p>Rows in <code>data</code> corresponding to variables mentioned in <code>formula</code>
which have at least one <code>NA</code> value will be ignored.
</p>
<p>All variables mentioned in <code>formula</code> should be numeric vectors.
</p>
<p>The function calculates standard errors via sandwich estimator
and significance levels are reported taking into account quasi maximum
likelihood estimator (QMLE) asymptotic normality. If one wants to switch
from QMLE to semi-nonparametric estimator (SNPE) during hypothesis testing
then covariance matrix should be estimated again using bootstrap.
</p>
<p>This function maximizes (quasi) log-likelihood function 
via <code><a href="stats.html#topic+optim">optim</a></code> function setting its <code>method</code> 
argument to &quot;BFGS&quot;. If <code>opt_type = "GA"</code> then genetic
algorithm from <code><a href="GA.html#topic+ga">ga</a></code> function
will be additionally (after <code><a href="stats.html#topic+optim">optim</a></code> putting its
solution (<code>par</code>) into <code>suggestions</code> matrix) applied in order to 
perform global optimization. Note that global optimization takes
much more time (usually minutes but sometimes hours or even days). 
The number of iterations and population size of the genetic algorithm
will grow linearly along with the number of estimated parameters. 
If it seems that global maximum has not been found then it
is possible to continue the search restarting the function setting 
its input argument <code>x0</code> to <code>x1</code> output value. Note that
if <code>cov_type = "bootstrap"</code> then <code><a href="GA.html#topic+ga">ga</a></code>
function will not be used for bootstrap iterations since it
may be extremely time consuming.
</p>
<p>If <code>opt_type = "GA"</code> then <code>opt_control</code> should be the
list containing the values to be passed to <code><a href="GA.html#topic+ga">ga</a></code>
function. It is possible to pass arguments <code>lower</code>, <code>upper</code>,
<code>popSize</code>, <code>pcrossover</code>, <code>pmutation</code>, <code>elitism</code>,
<code>maxiter</code>, <code>suggestions</code>, <code>optim</code>, <code>optimArgs</code>,
<code>seed</code> and <code>monitor</code>. 
Note that it is possible to set <code>population</code>,
<code>selection</code>, <code>crossover</code> and <code>mutation</code> arguments changing
<code><a href="GA.html#topic+ga">ga</a></code> default parameters via <code><a href="GA.html#topic+gaControl">gaControl</a></code> 
function. These arguments information reported in <code><a href="GA.html#topic+ga">ga</a></code>.
In order to provide manual values for <code>lower</code> and <code>upper</code> bounds
please follow parameters ordering mentioned above for the
<code>x0</code> argument. If these bounds are not provided manually then
they (except those related to the polynomial coefficients)
will depend on the estimates obtained
by local optimization via <code><a href="stats.html#topic+optim">optim</a></code> function
(this estimates will be in the middle
between <code>lower</code> and <code>upper</code>).
Specifically for each sd parameter <code>lower</code> (<code>upper</code>) bound
is 5 times lower (higher) than this
parameter <code><a href="stats.html#topic+optim">optim</a></code> estimate.
For each mean and regression coefficient parameter its lower and 
upper bounds deviate from corresponding <code><a href="stats.html#topic+optim">optim</a></code> estimate
by two absolute values of this estimate.
Finally, lower and upper bounds for each polynomial
coefficient are <code>-10</code> and <code>10</code> correspondingly (do not depend
on their <code><a href="stats.html#topic+optim">optim</a></code> estimates).
</p>
<p>The following arguments are differ from their defaults in
<code><a href="GA.html#topic+ga">ga</a></code>:
</p>

<ul>
<li> <p><code>pmutation = 0.2</code>,
</p>
</li>
<li> <p><code>optim = TRUE</code>,
</p>
</li>
<li> <p><code>optimArgs =
list("method" = "Nelder-Mead", "poptim" = 0.2, "pressel" = 0.5)</code>,
</p>
</li>
<li> <p><code>seed = 8</code>,
</p>
</li>
<li> <p><code>elitism = 2 + round(popSize * 0.1)</code>.</p>
</li></ul>

<p>Let's denote by <code>n_reg</code> the number of regressors
included into the <code>formula</code>.
The arguments <code>popSize</code> and <code>maxiter</code> of
<code><a href="GA.html#topic+ga">ga</a></code> function have been set proportional to the number of
estimated polynomial coefficients and independent variables:
</p>

<ul>
<li> <p><code>popSize = 10 + 5 * (K + 1) + 2 * n_reg</code>
</p>
</li>
<li> <p><code>maxiter = 50 * (1 + K) + 10 * n_reg</code></p>
</li></ul>



<h3>Value</h3>

<p>This function returns an object of class &quot;hpaBinary&quot;.<br /> <br />
An object of class &quot;hpaBinary&quot; is a list containing the 
following components:
</p>

<ul>
<li> <p><code>optim</code> - <code><a href="stats.html#topic+optim">optim</a></code> function output. 
If <code>opt_type = "GA"</code> then it is the list containing 
<code><a href="stats.html#topic+optim">optim</a></code> and <code><a href="GA.html#topic+ga">ga</a></code> functions outputs.
</p>
</li>
<li> <p><code>x1</code> - numeric vector of distribution parameters estimates.
</p>
</li>
<li> <p><code>mean</code> - mean (mu) parameter of density function estimate.
</p>
</li>
<li> <p><code>sd</code> - sd (sigma) parameter of density function estimate.
</p>
</li>
<li> <p><code>pol_coefficients</code> - polynomial coefficients estimates.
</p>
</li>
<li> <p><code>pol_degrees</code> - the same as <code>K</code> input parameter.
</p>
</li>
<li> <p><code>coefficients</code> - regression (single index) 
coefficients estimates.
</p>
</li>
<li> <p><code>cov_mat</code> - covariance matrix estimate.
</p>
</li>
<li> <p><code>marginal_effects</code> - marginal effects matrix where columns are
variables and rows are observations.
</p>
</li>
<li> <p><code>results</code> - numeric matrix representing estimation results.
</p>
</li>
<li> <p><code>log-likelihood</code> - value of Log-Likelihood function.
</p>
</li>
<li> <p><code>AIC</code> - AIC value.
</p>
</li>
<li> <p><code>errors_exp</code> - random error expectation estimate.
</p>
</li>
<li> <p><code>errors_var</code> - random error variance estimate.
</p>
</li>
<li> <p><code>dataframe</code> - data frame containing variables mentioned in 
<code>formula</code> without <code>NA</code> values.
</p>
</li>
<li> <p><code>model_Lists</code> - lists containing information about 
fixed parameters and parameters indexes in <code>x1</code>.
</p>
</li>
<li> <p><code>n_obs</code> - number of observations.
</p>
</li>
<li> <p><code>z_latent</code> - latent variable (single index) estimates.
</p>
</li>
<li> <p><code>z_prob</code> - probabilities of positive 
outcome (i.e. 1) estimates.</p>
</li></ul>



<h3>References</h3>

<p>A. Gallant and D. W. Nychka (1987) &lt;doi:10.2307/1913241&gt;
</p>


<h3>See Also</h3>

<p><a href="#topic+summary.hpaBinary">summary.hpaBinary</a>, <a href="#topic+predict.hpaBinary">predict.hpaBinary</a>, 
<a href="#topic+plot.hpaBinary">plot.hpaBinary</a>,
<a href="#topic+logLik.hpaBinary">logLik.hpaBinary</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimate survival probability on Titanic

library("titanic")

# Prepare data set converting  
# all variables to numeric vectors
h &lt;- data.frame("male" = as.numeric(titanic_train$Sex == "male"))
	h$class_1 &lt;- as.numeric(titanic_train$Pclass == 1)
	h$class_2 &lt;- as.numeric(titanic_train$Pclass == 2)
	h$class_3 &lt;- as.numeric(titanic_train$Pclass == 3)
	h$sibl &lt;- titanic_train$SibSp
	h$survived &lt;- titanic_train$Survived
	h$age &lt;- titanic_train$Age
	h$parch &lt;- titanic_train$Parch
	h$fare &lt;- titanic_train$Fare
	
# Estimate model parameters
model_hpa_1 &lt;- hpaBinary(survived ~class_1 + class_2 +
	male + age + sibl + parch + fare,
	K = 3, data = h)
#get summary
summary(model_hpa_1)

# Get predicted probabilities
pred_hpa_1 &lt;- predict(model_hpa_1)

# Calculate number of correct predictions
hpa_1_correct_0 &lt;- sum((pred_hpa_1 &lt; 0.5) &amp; 
                       (model_hpa_1$dataframe$survived == 0))
hpa_1_correct_1 &lt;- sum((pred_hpa_1 &gt;= 0.5) &amp; 
                       (model_hpa_1$dataframe$survived == 1))
hpa_1_correct &lt;- hpa_1_correct_1 + hpa_1_correct_0

# Plot random errors density approximation
plot(model_hpa_1)



## Estimate parameters on data simulated from Student distribution

library("mvtnorm")
set.seed(123)

# Simulate independent variables from normal distribution
n &lt;- 5000
X &lt;- rmvnorm(n=n, mean = c(0,0), 
sigma = matrix(c(1,0.5,0.5,1), ncol=2))

# Simulate random errors from Student distribution
epsilon &lt;- rt(n, 5) * (3 / sqrt(5))

# Calculate latent and observable variables values
z_star &lt;- 1 + X[, 1] + X[, 2] + epsilon
z &lt;- as.numeric((z_star &gt; 0))

# Store the results into data frame
h &lt;- as.data.frame(cbind(z,X))
names(h) &lt;- c("z", "x1", "x2")

# Estimate model parameters
model &lt;- hpaBinary(formula = z ~ x1 + x2, data=h, K = 3)
summary(model)

# Get predicted probabilities of 1 values
predict(model)

# Plot density function approximation
plot(model)



</code></pre>

<hr>
<h2 id='hpaDist'>Probabilities and Moments Hermite Polynomial Approximation</h2><span id='topic+hpaDist'></span><span id='topic+dhpa'></span><span id='topic+phpa'></span><span id='topic+ihpa'></span><span id='topic+ehpa'></span><span id='topic+etrhpa'></span><span id='topic+dtrhpa'></span><span id='topic+itrhpa'></span><span id='topic+dhpaDiff'></span><span id='topic+ehpaDiff'></span><span id='topic+ihpaDiff'></span><span id='topic+qhpa'></span><span id='topic+rhpa'></span>

<h3>Description</h3>

<p>Approximation of truncated, marginal and conditional densities,
moments and cumulative probabilities of multivariate distributions via
Hermite polynomial based approach proposed by Gallant and Nychka in 1987.
</p>
<p>Density approximating function is scale adjusted product of two terms. 
The first one is squared multivariate polynomial of <code>pol_degrees</code>  
degrees with <code>pol_coefficients</code> coefficients vector. 
The second is product of independent normal random variables' densities with 
expected values and standard deviations given by <code>mean</code> and <code>sd</code> 
vectors correspondingly. Approximating function satisfies properties of 
density function thus generating a broad family of distributions.
Characteristics of these distributions 
(moments, quantiles, probabilities and so on) 
may provide accurate approximations to characteristic of other
distributions. Moreover it is usually possible to provide arbitrary close
approximation by the means of polynomial degrees increase.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhpa(
  x,
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

phpa(
  x,
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

ihpa(
  x_lower = numeric(0),
  x_upper = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

ehpa(
  x = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  expectation_powers = numeric(0),
  is_parallel = FALSE,
  is_validation = TRUE
)

etrhpa(
  tr_left = numeric(0),
  tr_right = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  expectation_powers = numeric(0),
  is_parallel = FALSE,
  is_validation = TRUE
)

dtrhpa(
  x,
  tr_left = numeric(0),
  tr_right = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

itrhpa(
  x_lower = numeric(0),
  x_upper = numeric(0),
  tr_left = numeric(0),
  tr_right = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

dhpaDiff(
  x,
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  type = "pol_coefficients",
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

ehpaDiff(
  x = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  expectation_powers = numeric(0),
  type = "pol_coefficients",
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

ihpaDiff(
  x_lower = numeric(0),
  x_upper = numeric(0),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0),
  type = "pol_coefficients",
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE
)

qhpa(
  p,
  x = matrix(1, 1),
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  mean = numeric(0),
  sd = numeric(0)
)

rhpa(
  n,
  pol_coefficients = numeric(0),
  pol_degrees = numeric(0),
  mean = numeric(0),
  sd = numeric(0)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpaDist_+3A_x">x</code></td>
<td>
<p>numeric matrix of function arguments and
conditional values. Note that <code>x</code> rows are points (observations)
while random vectors components (variables) are columns.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_pol_coefficients">pol_coefficients</code></td>
<td>
<p>numeric vector of polynomial coefficients.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_pol_degrees">pol_degrees</code></td>
<td>
<p>non-negative integer vector of polynomial 
degrees (orders).</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_given_ind">given_ind</code></td>
<td>
<p>logical or numeric vector indicating whether corresponding 
random vector component is conditioned. By default it is a logical 
vector of <code>FALSE</code> values. If <code>give_ind[i]</code> equals <code>TRUE</code> or 
<code>i</code> then <code>i</code>-th column of <code>x</code> matrix will contain 
conditional values.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_omit_ind">omit_ind</code></td>
<td>
<p>logical or numeric vector indicating whether corresponding
random component is omitted. By default it is a logical vector 
of <code>FALSE</code> values. If <code>omit_ind[i]</code> equals <code>TRUE</code> or <code>i</code> 
then values in <code>i</code>-th column of <code>x</code> matrix will be ignored.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_mean">mean</code></td>
<td>
<p>numeric vector of expected values.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_sd">sd</code></td>
<td>
<p>positive numeric vector of standard deviations.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code> then probabilities p are given as log(p)
or derivatives will be given respect to log(p).</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_x_lower">x_lower</code></td>
<td>
<p>numeric matrix of lower integration limits.
Note that <code>x_lower</code> rows are observations while variables are columns.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_x_upper">x_upper</code></td>
<td>
<p>numeric matrix of upper integration limits.
Note that <code>x_upper</code> rows are observations while variables
are columns.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_expectation_powers">expectation_powers</code></td>
<td>
<p>integer vector of random vector components powers.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_tr_left">tr_left</code></td>
<td>
<p>numeric matrix of left (lower) truncation limits.
Note that <code>tr_left</code> rows are observations while variables are columns.
If <code>tr_left</code> and <code>tr_right</code> are single row matrices then the same 
truncation limits will be applied to all observations that are determined 
by the first rows of these matrices.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_tr_right">tr_right</code></td>
<td>
<p>numeric matrix of right (upper) truncation limits.
Note that <code>tr_right</code> rows are observations while variables are columns.
If <code>tr_left</code> and <code>tr_right</code> are single row matrices then the same 
truncation limits will be applied to all observations that are determined 
by the first rows of these matrices.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_type">type</code></td>
<td>
<p>determines the partial derivatives to be included into the
gradient. If <code>type="pol_coefficients"</code> then gradient will contain 
partial derivatives respect to polynomial coefficients listed in the
same order as <code>pol_coefficients</code>. Other available types are 
<code>type = "mean"</code> and <code>type = "sd"</code>.
For function <code><a href="#topic+dhpaDiff">dhpaDiff</a></code> it is possible to take
gradient respect to the x points setting <code>type="x"</code>.
For function <code><a href="#topic+ihpaDiff">ihpaDiff</a></code> it is possible to take
gradient respect to the x lower and upper points setting 
<code>type = "x_lower"</code> or <code>type = "upper"</code> correspondingly.
In order to get full gradient please set <code>type="all"</code>.</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_p">p</code></td>
<td>
<p>numeric vector of probabilities</p>
</td></tr>
<tr><td><code id="hpaDist_+3A_n">n</code></td>
<td>
<p>positive integer representing the number of observations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is possible to approximate densities 
<code><a href="#topic+dhpa">dhpa</a></code>, cumulative probabilities
<code><a href="#topic+phpa">phpa</a></code>, <code><a href="#topic+ihpa">ihpa</a></code>, moments
<code><a href="#topic+ehpa">ehpa</a></code> as well as their truncated
<code><a href="#topic+dtrhpa">dtrhpa</a></code>, <code><a href="#topic+itrhpa">itrhpa</a></code>, 
<code><a href="#topic+etrhpa">etrhpa</a></code> forms
and gradients <code><a href="#topic+dhpaDiff">dhpaDiff</a></code>, <code><a href="#topic+ihpaDiff">ihpaDiff</a></code>.
Note that <code><a href="#topic+phpa">phpa</a></code> is special of <code><a href="#topic+ihpa">ihpa</a></code>
where <code>x</code>
corresponds to <code>x_upper</code> while <code>x_lower</code> is matrix of
negative infinity values. So  <code><a href="#topic+phpa">phpa</a></code> intended to approximate 
cumulative
distribution functions while <code><a href="#topic+ihpa">ihpa</a></code> approximates 
probabilities that
random vector components will be between values determined by rows of 
<code>x_lower</code> and <code>x_upper</code> matrices. Further details are given below.
</p>
<p>Since density approximating function is non-negative and integrates
to 1 it is density function for some <code class="reqn">m</code>-variate 
random vector <code class="reqn">\xi</code>. Approximating function <code class="reqn">f_{\xi }(x)</code> 
has the following form:
</p>
<p style="text-align: center;"><code class="reqn">f_{\xi }(x) = f_{\xi }(x;\mu, \sigma, \alpha) =
\frac{1}{\psi }\prod\limits_{t=1}^{m}\phi 
({x}_{t};{\mu }_{t},{\sigma }_{t}){{\left( \sum\limits_{{i}_{1}=0}^{{K}_{1}}
{...}\sum\limits_{{i}_{m}=0}^{{K}_{m}}{{{\alpha }_{({{i}_{1}},...,{{i}_{m}})
}}\prod\limits_{r=1}^{m}x_{r}^{{{i}_{r}}}} \right)}^{2}}</code>
</p>

<p style="text-align: center;"><code class="reqn">\psi =\sum\limits_{{i}_{1}=0}^{{K}_{1}}{...}\sum
\limits_{{i}_{m}=0}^{{K}_{m}}{\sum\limits_{{j}_{1}=0}^{{K}_{1}}
{...}\sum\limits_{{j}_{m}=0}^{{K}_{m}}{{{\alpha }_{({i}_{1},
\cdots,{i}_{m})}}{{\alpha }_{({j}_{1},\cdots,{j}_{m})}}\prod
\limits_{r=1}^{m}\mathcal{M}({i}_{r}+{j}_{r};{{\mu }_{r}},{\sigma }_{r})}},</code>
</p>

<p>where:
</p>
<p><code class="reqn">x = (x_{1},...x_{m})</code> - is vector of arguments i.e. rows
of <code>x</code> matrix in <code><a href="#topic+dhpa">dhpa</a></code>.
</p>
<p><code class="reqn">{\alpha }_{({i}_{1},\cdots,{i}_{m})}</code> - is polynomial coefficient
corresponding to <code>pol_coefficients[k]</code> element. In order to investigate
correspondence between <code>k</code> and <code class="reqn">({i}_{1},\cdots,{i}_{m})</code> values 
please see 'Examples' section below or <code><a href="#topic+polynomialIndex">polynomialIndex</a></code> 
function 'Details', 'Value' and 'Examples' sections. Note that if <code class="reqn">m=1</code>
then <code>pol_coefficients[k]</code> simply corresponds to <code class="reqn">\alpha_{k-1}</code>.
</p>
<p><code class="reqn">(K_{1},...,K_{m})</code> - are polynomial degrees (orders) provided via
<code>pol_degrees</code> argument so <code>pol_degrees[i]</code> determines <code class="reqn">K_{i}</code>.
</p>
<p><code class="reqn">\phi 
(.;{\mu }_{t},{\sigma }_{t})</code> - is normal random variable density function 
where <code class="reqn">\mu_{t}</code> and <code class="reqn">\sigma_{t}</code> are mean and standard deviation 
determined by <code>mean[t]</code> and <code>sd[t]</code> arguments values.
</p>
<p><code class="reqn">\mathcal{M}(q;{{\mu }_{r}},{\sigma }_{r})</code> - is <code class="reqn">q</code>-th order
moment of normal random variable with mean <code class="reqn">{\mu }_{r}</code> and standard
deviation <code class="reqn">{\sigma }_{r}</code>. Note that function 
<code><a href="#topic+normalMoment">normalMoment</a></code> allows to calculate and differentiate normal 
random variable's moments.
</p>
<p><code class="reqn">\psi</code> - constant term insuring that <code class="reqn">f_{\xi }(x)</code> is
density function.
</p>
<p>Therefore <code><a href="#topic+dhpa">dhpa</a></code> allows to calculate <code class="reqn">f_{\xi}(x)</code> 
values at points
determined by rows of <code>x</code> matrix given polynomial 
degrees <code>pol_degrees</code> (<code class="reqn">K</code>) as well as <code>mean</code> (<code class="reqn">\mu</code>), 
<code>sd</code> (<code class="reqn">\sigma</code>) and <code>pol_coefficients</code> (<code class="reqn">\alpha</code>) 
parameters values. Note that <code>mean</code>, <code>sd</code> and <code>pol_degrees</code> are 
<code class="reqn">m</code>-variate vectors while <code>pol_coefficients</code> has
<code>prod(pol_degrees + 1)</code> elements.
</p>
<p>Cumulative probabilities could be approximated as follows:
</p>
<p style="text-align: center;"><code class="reqn">P\left(\underline{x}_{1}\leq\xi_{1}\leq\overline{x}_{1},...,
\underline{x}_{m}\leq\xi_{m}\leq\overline{x}_{m}\right) = </code>
</p>

<p style="text-align: center;"><code class="reqn">= \bar{F}_{\xi}(\underline{x},\bar{x}) = 
\bar{F}_{\xi}(\underline{x},\bar{x};\mu, \sigma, \alpha) =
\frac{1}{\psi }
\prod\limits_{t=1}^{m}(\Phi ({{{\bar{x}}}_{t}};{{\mu }_{t}},
{{\sigma }_{t}})-\Phi ({{{\underline{x}}}_{t}};{{\mu }_{t}},
{{\sigma }_{t}})) * </code>
</p>

<p><code class="reqn">* \sum\limits_{{{i}_{1}}=0}^{{{K}_{1}}}{...}
\sum\limits_{{{i}_{m}}=0}^{{{K}_{m}}}{\sum\limits_{{{j}_{1}}=0}^{{{K}_{1}}}
{...}\sum\limits_{{{j}_{m}}=0}^{{{K}_{m}}}
{{{\alpha }_{({{i}_{1}},...,{{i}_{m}})}}{{\alpha }_{({{j}_{1}},...,{{j}_{m}})
}}}}\prod\limits_{r=1}^{m}\mathcal{M}_{TR}\left({i}_{r}+{j}_{r};
\underline{x}_{r},\overline{x}_{r},\mu_{r},\sigma_{r}\right)</code>
</p>
<p>where:
</p>
<p><code class="reqn">\Phi 
(.;{\mu }_{t},{\sigma }_{t})</code> - is normal random variable's cumulative 
distribution function where <code class="reqn">\mu_{t}</code> and <code class="reqn">\sigma_{t}</code> are mean and 
standard deviation determined by <code>mean[t]</code> and <code>sd[t]</code> arguments 
values.
</p>
<p><code class="reqn">\mathcal{M}_{TR}(q;
\underline{x}_{r},\overline{x}_{r},\mu_{r},\sigma_{r})</code> - is 
<code class="reqn">q</code>-th order
moment of truncated (from above by <code class="reqn">\overline{x}_{r}</code> and from below by
<code class="reqn">\underline{x}_{r}</code>) 
normal random variable with mean <code class="reqn">{\mu }_{r}</code> and standard
deviation <code class="reqn">{\sigma }_{r}</code>. Note that function 
<code><a href="#topic+truncatedNormalMoment">truncatedNormalMoment</a></code> allows to calculate and 
differentiate truncated normal random variable's moments.
</p>
<p><code class="reqn">\overline{x} = (\overline{x}_{1},...,\overline{x}_{m})</code> - 
vector of upper integration limits
i.e. rows of <code>x_upper</code> matrix in <code><a href="#topic+ihpa">ihpa</a></code>.
</p>
<p><code class="reqn">\underline{x} = (\underline{x}_{1},...,\underline{x}_{m})</code> - 
vector of lower integration limits
i.e. rows of <code>x_lower</code> matrix in <code><a href="#topic+ihpa">ihpa</a></code>.
</p>
<p>Therefore <code><a href="#topic+ihpa">ihpa</a></code> allows to calculate interval distribution 
function <code class="reqn">\bar{F}_{\xi}(\underline{x},\bar{x})</code>
values at points determined by rows of <code>x_lower</code> (<code class="reqn">\underline{x}</code>)
and <code>x_upper</code> (<code class="reqn">\overline{x}</code>) matrices.
The rest of the arguments are similar to <code>dhpa</code>.
</p>
<p>Expected value powered product approximation is as follows:
</p>
<p style="text-align: center;"><code class="reqn">E\left( \prod\limits_{t=1}^{m}\xi_{t}^{{{k}_{t}}} \right)=
\frac{1}{\psi }\sum\limits_{{{i}_{1}}=0}^{{{K}_{1}}}{...}
\sum\limits_{{{i}_{m}}=0}^{{{K}_{m}}}
{\sum\limits_{{{j}_{1}}=0}^{{{K}_{1}}}{...}
\sum\limits_{{{j}_{m}}=0}^{{{K}_{m}}}
{{{\alpha }_{({{i}_{1}},...,{{i}_{m}})}}
{{\alpha }_{({{j}_{1}},...,{{j}_{m}})}}}}
\prod\limits_{r=1}^{m}\mathcal{M}({{i}_{r}}+{{j}_{r}}+{{k}_{t}};
{{\mu }_{r}},{{\sigma }_{r}})</code>
</p>

<p>where <code class="reqn">(k_{1},...,k_{m})</code> are integer powers determined by
<code>expectation_powers</code> argument of <code><a href="#topic+ehpa">ehpa</a></code> so
<code>expectation_powers[t]</code> assigns <code class="reqn">k_{t}</code>. Note that argument <code>x</code>
in <code><a href="#topic+ehpa">ehpa</a></code> allows to determined conditional values.
</p>
<p>Expanding polynomial degrees <code class="reqn">(K_{1},...,K_{m})</code> it is possible to 
provide arbitrary close approximation to density of some <code class="reqn">m</code>-variate 
random vector <code class="reqn">\xi^{\star}</code>. So actually <code class="reqn">f_{\xi}(x)</code>
approximates <code class="reqn">f_{\xi^{\star}}(x)</code>. Accurate approximation requires
appropriate <code>mean</code>, <code>sd</code> and <code>pol_coefficients</code> values
selection. In order to get sample estimates of these parameters please apply 
<code><a href="#topic+hpaML">hpaML</a></code> function.
</p>
<p>In order to perform calculation for marginal distribution of some 
<code class="reqn">\xi</code> components please provide omitted 
components via <code>omit_ind</code> argument.
For examples if ones assume <code class="reqn">m=5</code>-variate distribution
and wants to deal with <code class="reqn">1</code>-st, <code class="reqn">3</code>-rd, and <code class="reqn">5</code>-th components 
only i.e. <code class="reqn">(\xi_{1},\xi_{3},\xi_{5})</code> then set 
<code>omit_ind = c(FALSE, TRUE, FALSE, TRUE, FALSE)</code>
indicating that <code class="reqn">\xi_{2}</code> and <code class="reqn">\xi_{4}</code> should be 'omitted' from
<code class="reqn">\xi</code> since <code class="reqn">2</code>-nd and <code class="reqn">4</code>-th values of <code>omit_ind</code> are
<code>TRUE</code>.
Then <code>x</code> still should be <code class="reqn">5</code> column matrix but 
values in <code class="reqn">2</code>-nd and <code class="reqn">4</code>-th columns will not affect 
calculation results. Meanwhile note that marginal distribution of <code>t</code>
components of <code class="reqn">\xi</code> usually do not coincide with any marginal
distribution generated by <code>t</code>-variate density approximating function.
</p>
<p>In order to perform calculation for conditional distribution i.e. given 
fixed values for some <code class="reqn">\xi</code> components please provide these
components via <code>given_ind</code> argument.
For example if ones assume <code class="reqn">m=5</code>-variate distribution
and wants to deal with <code class="reqn">1</code>-st, <code class="reqn">3</code>-rd, and <code class="reqn">5</code>-th components 
given fixed values (suppose 8 and 10) for the other two components i.e. 
<code class="reqn">(\xi|\xi_{2} = 8, \xi_{4} = 10)</code> then set 
<code>given_ind = c(FALSE, TRUE, FALSE, TRUE, FALSE)</code> and
<code>x[2] = 8</code>, <code>x[4] = 10</code> where for simplicity it is assumed that
<code>x</code> is single row <code class="reqn">5</code> column matrix; it is possible to provide  
different conditional values for the same components simply setting different  
values to different <code>x</code> rows.
</p>
<p>Note that it is possible to combine <code>given_ind</code> and <code>omit_ind</code>
arguments. However it is wrong to set both <code>given_ind[i]</code> and 
<code>omit_ind[i]</code> to <code>TRUE</code>. Also at least one value should be
<code>FALSE</code> both for <code>given_ind</code> and <code>omit_ind</code>.
</p>
<p>In order to consider truncated distribution of <code class="reqn">\xi</code> i.e. 
<code class="reqn">\left(\xi|\overline{a}_{1}\leq\xi_{1}\leq\overline{b}_{1},
\cdots,\overline{a}_{m}\leq\xi_{m}\leq\overline{b}_{m}\right)</code>
please set lower (left) truncation points <code class="reqn">\overline{a}</code> and 
upper (right) truncation points <code class="reqn">\overline{b}</code> via <code>tr_left</code> 
and <code>tr_right</code> arguments correspondingly. Note that if lower truncation
points are negative infinite and upper truncation points are positive
infinite then <code><a href="#topic+dtrhpa">dtrhpa</a></code>, <code><a href="#topic+itrhpa">itrhpa</a></code> and 
<code><a href="#topic+etrhpa">etrhpa</a></code> are similar to <code><a href="#topic+dhpa">dhpa</a></code>,
<code><a href="#topic+ihpa">ihpa</a></code> and <code><a href="#topic+ehpa">ehpa</a></code> correspondingly.
</p>
<p>In order to calculate Jacobian of <code class="reqn">f_{\xi }(x;\mu, \sigma, \alpha)</code>
and <code class="reqn">\bar{F}_{\xi}(\underline{x},\bar{x};\mu, \sigma, \alpha)</code> w.r.t
all ore some particular parameters please apply <code><a href="#topic+dhpaDiff">dhpaDiff</a></code>
and <code><a href="#topic+ihpaDiff">ihpaDiff</a></code> functions correspondingly specifying
parameters of interest via <code>type</code> argument. If <code>x</code> or
<code>x_lower</code> and <code>x_upper</code> are single row matrices then gradients
will be calculated.
</p>
<p>For further information please see 'Examples' section. Note that examples
are given separately for each function.
</p>
<p>If <code>given_ind</code> and (or) <code>omit_ind</code> are numeric vectors
then they are insensitive to the order of elements. 
For example <code>given_ind = c(5, 2, 3)</code> is similar 
to <code>given_ind = c(2, 3, 5)</code>.
</p>
<p>Densities Hermite polynomial approximation approach has been
proposed by A. Gallant and D. W. Nychka in 1987. The main idea is to
approximate unknown distribution density with scaled Hermite polynomial.
For more information please refer to the literature listed below.
</p>


<h3>Value</h3>

<p>Functions <code><a href="#topic+dhpa">dhpa</a></code>, <code><a href="#topic+phpa">phpa</a></code> and 
<code><a href="#topic+dtrhpa">dtrhpa</a></code> return vector of probabilities of length
<code>nrow(x)</code>. 
</p>
<p>Functions <code><a href="#topic+ihpa">ihpa</a></code> and 
<code><a href="#topic+itrhpa">itrhpa</a></code> return vector of probabilities of length
<code>nrow(x_upper)</code>.
</p>
<p>If <code>x</code> argument has not been provided or is a single row
matrix then function 
<code><a href="#topic+ehpa">ehpa</a></code> returns moment value. Otherwise it returns vector of 
length <code>nrow(x)</code> containing moments values.
</p>
<p>If <code>tr_left</code> and <code>tr_right</code> arguments are single row matrices then
function <code><a href="#topic+etrhpa">etrhpa</a></code> returns moment value.
Otherwise it returns vector of length
<code>max(nrow(tr_left), nrow(tr_right))</code> containing moments values.
</p>
<p>Functions <code><a href="#topic+dhpaDiff">dhpaDiff</a></code> and <code><a href="#topic+ihpaDiff">ihpaDiff</a></code> 
return Jacobin matrix. The number
of columns depends on <code>type</code> argument. The number of rows is
<code>nrow(x)</code> for <code><a href="#topic+dhpaDiff">dhpaDiff</a></code> and 
<code>nrow(x_upper)</code> for
<code><a href="#topic+ihpaDiff">ihpaDiff</a></code>
</p>
<p>If <code>mean</code> or <code>sd</code> are not specified they assume the default 
values of <code class="reqn">m</code>-dimensional vectors of 0 and 1, respectively. 
If <code>x_lower</code> is not specified then it is the matrix of the 
same size as <code>x_upper</code> containing negative infinity values only. If
<code>expectation_powers</code> is not specified then it is <code class="reqn">m</code>-dimensional
vector of 0 values.
</p>
<p>Please see 'Details' section for additional information.
</p>


<h3>References</h3>

<p>A. Gallant and D. W. Nychka (1987) &lt;doi:10.2307/1913241&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example demonstrating dhpa function application.
## Let's approximate some three random variables (i.e. X1, X2 and X3) 
## joint density function at points  x = (0,1, 0.2, 0.3) and 
## y = (0.5, 0.8, 0.6) with Hermite polynomial of (1, 2, 3) degrees which 
## polynomial coefficients equal 1 except coefficient related  to x1*(x^3) 
## polynomial element which equals 2. Also suppose that normal density 
## related mean vector equals (1.1, 1.2, 1.3) while standard deviations 
## vector is (2.1, 2.2, 2.3).

# Prepare initial values
x &lt;- matrix(c(0.1, 0.2, 0.3), nrow = 1)   # x point as a single row matrix
y &lt;- matrix(c(0.5, 0.8, 0.6), nrow = 1)   # y point as a single row matrix
x_y &lt;- rbind(x, y)                        # matrix which rows are x and y
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)
# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial 
# elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
   row.names = c("x1 power", "x2 power", "x3 power", "coefficients"),
   optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate density approximation 
   # at point x (note that x should be a matrix)
dhpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd)
   # at points x and y
dhpa(x = x_y,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd)

# Condition second component to be 0.5 i.e. X2 = 0.5.
# Substitute x and y second components with conditional value 0.5
x &lt;- matrix(c(0.1, 0.5, 0.3), nrow = 1) # or simply x[2] &lt;- 0.5
y &lt;- matrix(c(0.4, 0.5, 0.6), nrow = 1) # or simply y[2] &lt;- 0.5
x_y &lt;- rbind(x, y) 
# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on X2 = 0.5) density approximation 
   # at point x
dhpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind)
   # at points x and y
dhpa(x = x_y,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind)	
	
# Consider third component marginal distribution conditioned on the
# second component 0.5 value i.e. (X3 | X2 = 0.5).
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on x2 = 0.5) marginal (for x3) density approximation
   # at point x
dhpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind, 
     omit_ind = omit_ind)
   # at points x and y
dhpa(x = x_y,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind, 
     omit_ind = omit_ind)  
        
## Example demonstrating phpa function application.
## Let's approximate some three random variables (X1, X2, X3) 
## joint cumulative distribution function (cdf) at point (0,1, 0.2, 0.3)
## with Hermite polynomial of (1, 2, 3) degrees which polynomial 
## coefficients equal 1 except coefficient related to x1*(x^3) polynomial 
## element which equals 2. Also suppose that normal density related
## mean vector equals (1.1, 1.2, 1.3) while standard deviations
## vector is (2.1, 2.2, 2.3).

## Prepare initial values
x &lt;- matrix(c(0.1, 0.2, 0.3), nrow = 1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)

# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial
# elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
	           row.names = c("x1 power", "x2 power", 
	                         "x3 power", "coefficients"),
          	 optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate cdf approximation at point x
phpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd)
	
# Condition second component to be 0.5
# Substitute x second component with conditional value 0.5
x &lt;- matrix(c(0.1, 0.5, 0.3), nrow = 1) # or simply x[2] &lt;- 0.5

# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on X2 = 0.5) cdf approximation at point x
phpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind)
	
# Consider third component marginal distribution
# conditioned on the second component 0.5 value

# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) cdf 
# approximation at point x
phpa(x = x,
      pol_coefficients = pol_coefficients, 
      pol_degrees = pol_degrees,
      mean = mean, sd = sd,
      given_ind = given_ind, 
      omit_ind = omit_ind)

## Example demonstrating ihpa function application.
## Let's approximate some three random variables (X1, X2, X3) joint interval 
## distribution function (intdf) at lower and upper points (0,1, 0.2, 0.3) 
## and (0,4, 0.5, 0.6) correspondingly with Hermite polynomial of (1, 2, 3) 
## degrees which polynomial coefficients equal 1 except coefficient related 
## to x1*(x^3) polynomial element which equals 2. Also suppose that normal
## density related mean vector equals (1.1, 1.2, 1.3) while standard
## deviations vector is (2.1, 2.2, 2.3).

## Prepare initial values
x_lower &lt;- matrix(c(0.1, 0.2, 0.3), nrow=1)
x_upper &lt;- matrix(c(0.4, 0.5, 0.6), nrow=1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)

# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial 
# elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
	           row.names = c("x1 power", "x2 power", 
	                         "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate intdf approximation at points x_lower and x_upper
ihpa(x_lower = x_lower, x_upper = x_upper, 
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd)
	
# Condition second component to be 0.7
# Substitute x second component with conditional value 0.7
x_upper &lt;- matrix(c(0.4, 0.7, 0.6), nrow = 1)

# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on X2 = 0.5) intdf approximation 
# at points x_lower and x_upper
ihpa(x_lower = x_lower, x_upper = x_upper,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind)
	
# Consider third component marginal distribution
# conditioned on the second component 0.7 value
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) 
# intdf approximation at points x_lower and x_upper
ihpa(x_lower = x_lower, x_upper = x_upper,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = given_ind, omit_ind = omit_ind)
	
## Example demonstrating ehpa function application.
## Let's approximate some three random variables (X1, X2, X3) powered product 
## expectation for powers (3, 2, 1) with Hermite polynomial of (1, 2, 3) 
## degrees which polynomial coefficients equal 1 except coefficient 
## related to x1*(x^3) polynomial element which equals 2.
## Also suppose that normal density related mean vector equals 
## (1.1, 1.2, 1.3) while standard deviations vector is (2.1, 2.2, 2.3).

# Prepare initial values
expectation_powers = c(3,2,1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)

# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

#Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
              row.names = c("x1 power", "x2 power", 
                            "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate expected powered product approximation
ehpa(pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd, 
     expectation_powers = expectation_powers)
	
# Condition second component to be 0.5
# Substitute x second component with conditional value 0.5
x &lt;- matrix(c(NA, 0.5, NA), nrow = 1)
#Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on X2 = 0.5) expected powered product approximation
ehpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd, 
     expectation_powers = expectation_powers,
     given_ind = given_ind)
	
# Consider third component marginal distribution
# conditioned on the second component 0.5 value
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) expected powered 
# product approximation at points x_lower and x_upper
ehpa(x = x,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd, 
     expectation_powers = expectation_powers,
     given_ind = given_ind, 
     omit_ind = omit_ind)
	
## Example demonstrating etrhpa function application.
## Let's approximate some three truncated random variables (X1, X2, X3) 
## powered product expectation for powers (3, 2, 1) with Hermite polynomial 
## of (1,2,3) degrees which polynomial coefficients equal 1 except 
## coefficient related to x1*(x^3) polynomial element which equals 2. Also
## suppose that normal density related mean vector equals (1.1, 1.2, 1.3) 
## while standard deviations vector is (2.1, 2.2, 2.3). Suppose that lower  
## and upper truncation points are (-1.1,-1.2,-1.3) and (1.1,1.2,1.3) 
## correspondingly.

# Prepare initial values
expectation_powers = c(3,2,1)
tr_left = matrix(c(-1.1,-1.2,-1.3), nrow = 1)
tr_right = matrix(c(1.1,1.2,1.3), nrow = 1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)
# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
              row.names = c("x1 power", "x2 power", 
                            "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate expected powered product approximation for truncated distribution
etrhpa(pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd, 
       expectation_powers = expectation_powers,
       tr_left = tr_left, tr_right = tr_right)
       
## Example demonstrating dtrhpa function application.
## Let's approximate some three random variables (X1, X2, X3) joint density 
## function at point (0,1, 0.2, 0.3) with Hermite polynomial of (1,2,3)  
## degrees which polynomial coefficients equal 1 except coefficient related 
## to x1*(x^3) polynomial element which equals 2. Also suppose that normal 
## density related mean vector equals (1.1, 1.2, 1.3) while standard 
## deviations vector is (2.1, 2.2, 2.3). Suppose that lower and upper 
## truncation points are (-1.1,-1.2,-1.3) and (1.1,1.2,1.3) correspondingly.

# Prepare initial values
x &lt;- matrix(c(0.1, 0.2, 0.3), nrow=1)
tr_left = matrix(c(-1.1,-1.2,-1.3), nrow = 1)
tr_right = matrix(c(1.1,1.2,1.3), nrow = 1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)

# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
              row.names = c("x1 power", "x2 power", 
                            "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate density approximation at point x
dtrhpa(x = x,
       pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd,
       tr_left = tr_left, 
       tr_right = tr_right)
	
# Condition second component to be 0.5
# Substitute x second component with conditional value 0.5
x &lt;- matrix(c(0.1, 0.5, 0.3), nrow = 1)
# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)
# Calculate conditional (on x2 = 0.5) density approximation at point x
dtrhpa(x = x,
       pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd,
       given_ind = given_ind,
       tr_left = tr_left, tr_right = tr_right)
	
# Consider third component marginal distribution
# conditioned on the second component 0.5 value
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) 
# density approximation at point x
dtrhpa(x = x,
       pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd,
       given_ind = given_ind, omit_ind = omit_ind,
       tr_left = tr_left, tr_right = tr_right)
       
## Example demonstrating itrhpa function application.
## Let's approximate some three truncated random variables (X1, X2, X3) joint 
## interval distribution function at lower and upper points (0,1, 0.2, 0.3) 
## and (0,4, 0.5, 0.6) correspondingly with Hermite polynomial of (1 ,2, 3) 
## degrees which polynomial coefficients equal 1 except coefficient
## related to x1*(x^3) polynomial element which equals 2. Also suppose 
## that normal density related mean vector equals (1.1, 1.2, 1.3) while 
## standard deviations vector is (2.1, 2.2, 2.3). Suppose that lower and 
## upper truncation are (-1.1,-1.2,-1.3) and (1.1,1.2,1.3) correspondingly.

# Prepare initial values
x_lower &lt;- matrix(c(0.1, 0.2, 0.3), nrow=1)
x_upper &lt;- matrix(c(0.4, 0.5, 0.6), nrow=1)
tr_left = matrix(c(-1.1,-1.2,-1.3), nrow = 1)
tr_right = matrix(c(1.1,1.2,1.3), nrow = 1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)
# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2
# Visualize correspondence between polynomial 
# elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
              row.names = c("x1 power", "x2 power", 
                            "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate intdf approximation at points x_lower and x_upper
itrhpa(x_lower = x_lower, x_upper = x_upper, 
       pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd,
       tr_left = tr_left, tr_right = tr_right)
    
# Condition second component to be 0.7
# Substitute x second component with conditional value 0.7
x_upper &lt;- matrix(c(0.4, 0.7, 0.6), nrow = 1)
# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on X2 = 0.5) intdf 
# approximation at points x_lower and x_upper
itrhpa(x_lower = x_lower, x_upper = x_upper,
       pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd,
       given_ind = given_ind,
       tr_left = tr_left, tr_right = tr_right)
    
# Consider third component marginal distribution
# conditioned on the second component 0.7 value
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) intdf 
# approximation at points x_lower and x_upper
itrhpa(x_lower = x_lower, x_upper = x_upper,
       pol_coefficients = pol_coefficients, 
       pol_degrees = pol_degrees,
       mean = mean, sd = sd,
       given_ind = given_ind, omit_ind = omit_ind,
       tr_left = tr_left, tr_right = tr_right)
       
## Example demonstrating dhpaDiff function application.
## Let's approximate some three random variables (X1, X2, X3) joint density
## function at point (0,1, 0.2, 0.3) with Hermite polynomial of (1,2,3)
## degrees which polynomial coefficients equal 1 except coefficient related
## to x1*(x^3) polynomial element which equals 2. Also suppose that normal
## density related mean vector equals (1.1, 1.2, 1.3) while standard
## deviations vector is (2.1, 2.2, 2.3). In this example let's calculate
## density approximating function's gradient respect to various parameters

# Prepare initial values
x &lt;- matrix(c(0.1, 0.2, 0.3), nrow = 1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)
# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial
# elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
              row.names = c("x1 power", "x2 power", 
                            "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate density approximation gradient 
# respect to polynomial coefficients at point x
dhpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd)
	
# Condition second component to be 0.5
# Substitute x second component with conditional value 0.5
x &lt;- matrix(c(0.1, 0.5, 0.3), nrow = 1)
# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on x2 = 0.5) density approximation's 
# gradient respect to polynomial coefficients at point x
dhpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind)
	
# Consider third component marginal distribution
# conditioned on the second component 0.5 value
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) density 
# approximation's gradient respect to: 
  # polynomial coefficients
dhpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, 
         omit_ind = omit_ind)
  # mean
dhpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, 
         omit_ind = omit_ind,
         type = "mean")
  # sd
dhpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, 
         omit_ind = omit_ind,
         type = "sd")
 # x
dhpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, 
         omit_ind = omit_ind,
         type = "x")
         
## Example demonstrating ehpaDiff function application.
## Let's approximate some three random variables (X1, X2, X3) expectation
## of the form E((X1 ^ 3) * (x2 ^ 1) * (X3 ^ 2)) and calculate the gradient

# Distribution parameters
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)
pol_coefficients_n &lt;- prod(pol_degrees + 1)
pol_coefficients &lt;- rep(1, pol_coefficients_n)

# Set powers for expectation
expectation_powers &lt;- c(3, 1, 2)

# Calculate expectation approximation gradient 
# respect to all parameters
ehpaDiff(pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         expectation_powers = expectation_powers,
         type = "all")

# Let's calculate gradient of E(X1 ^ 3 | (X2 = 1, X3 = 2))
x &lt;- c(0, 1, 2)                  # x[1] may be arbitrary (not NA) values
expectation_powers &lt;- c(3, 0, 0) # expectation_powers[2:3] may be 
                                 # arbitrary (not NA) values
given_ind &lt;- c(2, 3)
ehpaDiff(x = x,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind,
         expectation_powers = expectation_powers,
         type = "all")
## Example demonstrating ihpaDiff function application.
## Let's approximate some three random variables (X1, X2, X3 ) joint interval 
## distribution function (intdf) at lower and upper points (0,1, 0.2, 0.3) 
## and (0,4, 0.5, 0.6) correspondingly with Hermite polynomial of (1, 2, 3) 
## degrees which polynomial coefficients equal 1 except coefficient 
## related to x1*(x^3) polynomial element which equals 2.
## Also suppose that normal density related mean vector equals 
## (1.1, 1.2, 1.3) while standard deviations vector is (2.1, 2.2, 2.3).
## In this example let's calculate interval distribution approximating 
## function gradient respect to polynomial coefficients.

# Prepare initial values
x_lower &lt;- matrix(c(0.1, 0.2, 0.3), nrow=1)
x_upper &lt;- matrix(c(0.4, 0.5, 0.6), nrow=1)
mean &lt;- c(1.1, 1.2, 1.3)
sd &lt;- c(2.1, 2.2, 2.3)
pol_degrees &lt;- c(1, 2, 3)

# Create polynomial powers and indexes correspondence matrix
pol_ind &lt;- polynomialIndex(pol_degrees)

# Set all polynomial coefficients to 1
pol_coefficients &lt;- rep(1, ncol(pol_ind))
pol_degrees_n &lt;- length(pol_degrees)

# Assign coefficient 2 to the polynomial element (x1 ^ 1)*(x2 ^ 0)*(x3 ^ 2)
pol_coefficients[apply(pol_ind, 2, function(x) all(x == c(1, 0, 2)))] &lt;- 2

# Visualize correspondence between polynomial 
# elements and their coefficients
as.data.frame(rbind(pol_ind, pol_coefficients),
              row.names = c("x1 power", "x2 power", 
                            "x3 power", "coefficients"),
              optional = TRUE)
printPolynomial(pol_degrees, pol_coefficients)

# Calculate intdf approximation gradient respect to 
# polynomial coefficients at points x_lower and x_upper
ihpaDiff(x_lower = x_lower, x_upper = x_upper, 
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd)
	
# Condition second component to be 0.7
# Substitute x second component with conditional value 0.7
x_upper &lt;- matrix(c(0.4, 0.7, 0.6), nrow = 1)

# Set TRUE to the second component indicating that it is conditioned
given_ind &lt;- c(FALSE, TRUE, FALSE)

# Calculate conditional (on X2 = 0.5) intdf approximation
# respect to polynomial coefficients at points x_lower and x_upper
ihpaDiff(x_lower = x_lower, x_upper = x_upper,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind)
	
# Consider third component marginal distribution
# conditioned on the second component 0.7 value
# Set TRUE to the first component indicating that it is omitted
omit_ind &lt;- c(TRUE, FALSE, FALSE)

# Calculate conditional (on X2 = 0.5) marginal (for X3) intdf approximation
# respect to:
  # polynomial coefficients
ihpaDiff(x_lower = x_lower, x_upper = x_upper,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, omit_ind = omit_ind)
  # mean
ihpaDiff(x_lower = x_lower, x_upper = x_upper,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, omit_ind = omit_ind,
         type = "mean")
  # sd
ihpaDiff(x_lower = x_lower, x_upper = x_upper,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, omit_ind = omit_ind,
         type = "sd")
  # x_lower
ihpaDiff(x_lower = x_lower, x_upper = x_upper,
         pol_coefficients = pol_coefficients, 
         pol_degrees = pol_degrees,
         mean = mean, sd = sd,
         given_ind = given_ind, omit_ind = omit_ind,
         type = "x_lower")
  # x_upper
ihpaDiff(x_lower = x_lower, x_upper = x_upper,
          pol_coefficients = pol_coefficients, 
          pol_degrees = pol_degrees,
          mean = mean, sd = sd,
          given_ind = given_ind, omit_ind = omit_ind,
          type = "x_upper")
          
## Examples demonstrating qhpa function application.

## Sub-example 1 - univariate distribution
## Consider random variable X

# Distribution parameters
mean &lt;- 1
sd &lt;- 2
pol_degrees &lt;- 2
pol_coefficients &lt;- c(1, 0.1, -0.01)

# The level of quantile
p &lt;- 0.7

# Calculate quantile of X
qhpa(p = p,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd)
     
## Sub-example 2 - marginal distribution
## Consider random vector (X1, X2) and quantile of X1

# Distribution parameters
mean &lt;- c(1, 1.2)
sd &lt;- c(2, 3)
pol_degrees &lt;- c(2, 2)
pol_coefficients &lt;- c(1, 0.1, -0.01, 0.2, 0.012, 
                      0.0013, 0.0042, 0.00025, 0)

# The level of quantile
p &lt;- 0.7

# Calculate quantile of X1
qhpa(p = p,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     omit_ind = 2)                          # set omitted variable index
     
## Sub-example 3 - marginal and conditional distribution
## Consider random vector (X1, X2, X3) and 

## quantiles of X1|X3 and X1|(X2,X3)
mean &lt;- c(1, 1.2, 0.9)
sd &lt;- c(2, 3, 2.5)
pol_degrees &lt;- c(1, 1, 1)
pol_coefficients &lt;- c(1, 0.1, -0.01, 0.2, 0.012, 
                      0.0013, 0.0042, 0.00025)

# The level of quantile
p &lt;- 0.7

# Calculate quantile of X1|X3 = 0.2
qhpa(p = p,
     x = matrix(c(NA, NA, 0.2), nrow = 1),  # set any values to
                                            # unconditioned and 
                                            # omitted components
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     omit_ind = 2,                          # set omitted variable index
     given_ind = 3)                         # set conditioned variable index
     
# Calculate quantile of X1|(X2 = 0.5, X3 = 0.2)
qhpa(p = p,
     x = matrix(c(NA, 0.5, 0.2), nrow = 1), # set any values to 
                                            # unconditioned and 
                                            # omitted components
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd,
     given_ind = c(2, 3))                   # set conditioned
                                            # variables indexes
        
## Examples demonstrating rhpa function application.

# Set seed for reproducibility
set.seed(123)

# Distribution parameters
mean &lt;- 1
sd &lt;- 2
pol_degrees &lt;- 2
pol_coefficients &lt;- c(1, 0.1, -0.01)

# Simulate two observations from this distribution
rhpa(n = 2,
     pol_coefficients = pol_coefficients, 
     pol_degrees = pol_degrees,
     mean = mean, sd = sd)
        
</code></pre>

<hr>
<h2 id='hpaDist0'>Fast pdf and cdf for standardized univariate PGN distribution</h2><span id='topic+hpaDist0'></span><span id='topic+dhpa0'></span><span id='topic+phpa0'></span>

<h3>Description</h3>

<p>This function uses fast algorithms to calculate densities
and probabilities (along with their derivatives) related to standardized 
PGN distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhpa0(
  x,
  pc,
  mean = 0,
  sd = 1,
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE,
  is_grad = FALSE
)

phpa0(
  x,
  pc,
  mean = 0,
  sd = 1,
  is_parallel = FALSE,
  log = FALSE,
  is_validation = TRUE,
  is_grad = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpaDist0_+3A_x">x</code></td>
<td>
<p>numeric vector of functions arguments.</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_pc">pc</code></td>
<td>
<p>polynomial coefficients without the first term.</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_mean">mean</code></td>
<td>
<p>expected value (mean) of the distribution.</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_sd">sd</code></td>
<td>
<p>standard deviation of the distribution.</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_is_parallel">is_parallel</code></td>
<td>
<p>logical; if TRUE then multiple cores will be used for 
some calculations. Currently unavailable.</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code> then probabilities p are given as log(p)
or derivatives will be given respect to log(p).</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="hpaDist0_+3A_is_grad">is_grad</code></td>
<td>
<p>logical; if <code>TRUE</code> (default) then function returns 
gradients respect to <code>x</code> and <code>pc</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions <code><a href="#topic+dhpa0">dhpa0</a></code> and 
<code><a href="#topic+phpa0">phpa0</a></code> are similar to <code><a href="#topic+dhpa">dhpa</a></code> and
<code><a href="#topic+phpa">phpa</a></code> correspondingly. However there are two key
differences. First, <code><a href="#topic+dhpa0">dhpa0</a></code> and <code><a href="#topic+phpa0">phpa0</a></code>
are deal with univariate PGN distribution only. Second, this distribution
is standardized to zero mean and unit variances. Moreover <code>pc</code> is 
similar to <code>pol_coefficients</code> argument of <code><a href="#topic+dhpa">dhpa</a></code> but
without the first component i.e. <code>pc=pol_coefficients[-1]</code>. Also
<code>mean</code> and <code>sd</code> are not the arguments of the normal density
but actual mean and standard deviation of the resulting distribution. So
if these arguments are different from <code>0</code> and <code>1</code> correspondingly
then standardized PGN distribution will be linearly transformed to have
mean <code>mean</code> and standard deviation <code>sd</code>.
</p>


<h3>Value</h3>

<p>Both functions return a list.
Function <code><a href="#topic+dhpa0">dhpa0</a></code> returns a list with element named
<code>"den"</code> that is a numeric vector of density values. 
Function <code><a href="#topic+phpa0">phpa0</a></code> returns a list with element named
<code>"prob"</code> that is a numeric vector of probabilities. 
</p>
<p>If <code>is_grad = TRUE</code> then elements <code>"grad_x"</code> and <code>"grad_pc"</code>
will be add to the list containing gradients respect to input argument
<code>x</code> and parameters <code>pc</code> correspondingly. If <code>log = TRUE</code> then
additional elements will be add to the list containing density, probability
and gradient values for logarithms of corresponding functions. These
elements will be named as <code>"grad_x_log"</code>, <code>"grad_pc_log"</code>,
<code>"grad_prob_log"</code> and <code>"grad_den_log"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Calculate density and probability of standartized PGN
# distribution
  # distribution parameters
pc &lt;- c(0.5, -0.2)
  # function arguments
x &lt;- c(-0.3, 0.8, 1.5)
  # probability density function
dhpa0(x, pc)
  # cumulative distribution function
phpa0(x, pc)

# Additionally calculate gradients respect to arguments
# and parameters of the PGN distribution
dhpa0(x, pc, is_grad = TRUE)
phpa0(x, pc, is_grad = TRUE)

# Let's denote by X standardized PGN random variable and repeat
# calculations for 2 * X + 1
dhpa0(x, pc, is_grad = TRUE, mean = 1, sd = 2)
phpa0(x, pc, is_grad = TRUE, mean = 1, sd = 2)
</code></pre>

<hr>
<h2 id='hpaML'>Semi-nonparametric maximum likelihood estimation</h2><span id='topic+hpaML'></span>

<h3>Description</h3>

<p>This function performs semi-nonparametric (SNP)
maximum likelihood estimation of unknown (possibly truncated) multivariate  
density using Hermite polynomial based approximating function proposed by 
Gallant and Nychka in 1987. Please, see <code><a href="#topic+dhpa">dhpa</a></code> 'Details' 
section to get more information concerning this approximating function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hpaML(
  data,
  pol_degrees = numeric(0),
  tr_left = numeric(0),
  tr_right = numeric(0),
  given_ind = numeric(0),
  omit_ind = numeric(0),
  x0 = numeric(0),
  cov_type = "sandwich",
  boot_iter = 100L,
  is_parallel = FALSE,
  opt_type = "optim",
  opt_control = NULL,
  is_validation = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpaML_+3A_data">data</code></td>
<td>
<p>numeric matrix which rows are realizations of independent 
identically distributed random vectors while columns correspond to
variables.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_pol_degrees">pol_degrees</code></td>
<td>
<p>non-negative integer vector of polynomial 
degrees (orders).</p>
</td></tr>
<tr><td><code id="hpaML_+3A_tr_left">tr_left</code></td>
<td>
<p>numeric vector of left (lower) truncation limits.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_tr_right">tr_right</code></td>
<td>
<p>numeric vector of right (upper) truncation limits.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_given_ind">given_ind</code></td>
<td>
<p>logical or numeric vector indicating whether corresponding 
random vector component is conditioned. By default it is a logical 
vector of <code>FALSE</code> values. If <code>give_ind[i]</code> equals <code>TRUE</code> or 
<code>i</code> then <code>i</code>-th column of <code>x</code> matrix will contain 
conditional values.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_omit_ind">omit_ind</code></td>
<td>
<p>logical or numeric vector indicating whether corresponding
random component is omitted. By default it is a logical vector 
of <code>FALSE</code> values. If <code>omit_ind[i]</code> equals <code>TRUE</code> or <code>i</code> 
then values in <code>i</code>-th column of <code>x</code> matrix will be ignored.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_x0">x0</code></td>
<td>
<p>numeric vector of optimization routine initial values.
Note that <code>x0=c(pol_coefficients[-1], mean, sd)</code>. For 
<code>pol_coefficients</code>, <code>mean</code> and <code>sd</code> documentation 
see <code><a href="#topic+dhpa">dhpa</a></code> function.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_cov_type">cov_type</code></td>
<td>
<p>character determining the type of covariance matrix to be
returned and used for summary. If <code>cov_type = "hessian"</code> then negative
inverse of Hessian matrix will be applied. If <code>cov_type = "gop"</code> then
inverse of Jacobian outer products will be used.
If <code>cov_type = "sandwich"</code> (default) then sandwich covariance matrix
estimator will be applied. If <code>cov_type = "bootstrap"</code> then bootstrap
with <code>boot_iter</code> iterations will be used.
If <code>cov_type = "hessianFD"</code> or <code>cov_type = "sandwichFD"</code> then
(probably) more accurate but computationally demanding central difference 
Hessian approximation will be calculated for the inverse Hessian and 
sandwich estimators correspondingly. Central differences are computed via
analytically provided gradient. This Hessian matrix estimation approach
seems to be less accurate than BFGS approximation if polynomial order
is high (usually greater then 5).</p>
</td></tr>
<tr><td><code id="hpaML_+3A_boot_iter">boot_iter</code></td>
<td>
<p>the number of bootstrap iterations
for <code>cov_type = "bootstrap"</code> covariance matrix estimator type.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
<tr><td><code id="hpaML_+3A_opt_type">opt_type</code></td>
<td>
<p>string value determining the type of the optimization
routine to be applied. The default is <code>"optim"</code> meaning that BFGS method
from the <code><a href="stats.html#topic+optim">optim</a></code> function will be applied.
If <code>opt_type = "GA"</code> then <code><a href="GA.html#topic+ga">ga</a></code> function will be
additionally applied.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_opt_control">opt_control</code></td>
<td>
<p>a list containing arguments to be passed to the
optimization routine depending on <code>opt_type</code> argument value.
Please see details to get additional information.</p>
</td></tr>
<tr><td><code id="hpaML_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Densities Hermite polynomial approximation approach has been
proposed by A. Gallant and D. W. Nychka in 1987. The main idea is to
approximate unknown distribution density with scaled Hermite polynomial.
For more information please refer to the literature listed below.
</p>
<p>Let's use notations introduced in <code><a href="#topic+dhpa">dhpa</a></code> 'Details' 
section. Function <code><a href="#topic+hpaML">hpaML</a></code> maximizes the following
quasi log-likelihood function:
</p>
<p style="text-align: center;"><code class="reqn">\ln L(\alpha, \mu, \sigma; x) = \sum\limits_{i=1}^{n} 
\ln\left(f_{\xi}(x_{i};\alpha, \mu, \sigma)\right),</code>
</p>

<p>where (in addition to previously defined notations):
</p>
<p><code class="reqn">x_{i}</code> - are observations i.e. <code>data</code> matrix rows.
</p>
<p><code class="reqn">n</code> - is sample size i.e. the number of <code>data</code> matrix rows.
</p>
<p>Arguments <code>pol_degrees</code>, <code>tr_left</code>, <code>tr_right</code>,
<code>given_ind</code> and <code>omit_ind</code> affect the form of 
<code class="reqn">f_{\xi}\left(x_{i};\alpha, \mu, \sigma)\right)</code> in a way described in 
<code><a href="#topic+dhpa">dhpa</a></code> 'Details' section. Note that change of
<code>given_ind</code> and <code>omit_ind</code> values may result in estimator which
statistical properties has not been rigorously investigated yet.
</p>
<p>The first polynomial coefficient (zero powers) 
set to 1 for identification purposes i.e. <code class="reqn">\alpha_{(0,...,0)}=1</code>.
</p>
<p>All <code>NA</code> and <code>NaN</code> values will be removed from <code>data</code> matrix.
</p>
<p>The function calculates standard errors via sandwich estimator
and significance levels are reported taking into account quasi maximum
likelihood estimator (QMLE) asymptotic normality. If one wants to switch
from QMLE to semi-nonparametric estimator (SNPE) during hypothesis testing
then covariance matrix should be estimated again using bootstrap.
</p>
<p>This function maximizes (quasi) log-likelihood function 
via <code><a href="stats.html#topic+optim">optim</a></code> function setting its <code>method</code> 
argument to &quot;BFGS&quot;. If <code>opt_type = "GA"</code> then genetic
algorithm from <code><a href="GA.html#topic+ga">ga</a></code> function
will be additionally (after <code><a href="stats.html#topic+optim">optim</a></code> putting its
solution (<code>par</code>) into <code>suggestions</code> matrix) applied in order to 
perform global optimization. Note that global optimization takes
much more time (usually minutes but sometimes hours or even days). 
The number of iterations and population size of the genetic algorithm
will grow linearly along with the number of estimated parameters. 
If it seems that global maximum has not been found then it
is possible to continue the search restarting the function setting 
its input argument <code>x0</code> to <code>x1</code> output value. Note that
if <code>cov_type = "bootstrap"</code> then <code><a href="GA.html#topic+ga">ga</a></code>
function will not be used for bootstrap iterations since it
may be extremely time consuming.
</p>
<p>If <code>opt_type = "GA"</code> then <code>opt_control</code> should be the
list containing the values to be passed to <code><a href="GA.html#topic+ga">ga</a></code>
function. It is possible to pass arguments <code>lower</code>, <code>upper</code>,
<code>popSize</code>, <code>pcrossover</code>, <code>pmutation</code>, <code>elitism</code>,
<code>maxiter</code>, <code>suggestions</code>, <code>optim</code>, <code>optimArgs</code>,
<code>seed</code> and <code>monitor</code>. 
Note that it is possible to set <code>population</code>,
<code>selection</code>, <code>crossover</code> and <code>mutation</code> arguments changing
<code><a href="GA.html#topic+ga">ga</a></code> default parameters via <code><a href="GA.html#topic+gaControl">gaControl</a></code> 
function. These arguments information reported in <code><a href="GA.html#topic+ga">ga</a></code>.
In order to provide manual values for <code>lower</code> and <code>upper</code> bounds
please follow parameters ordering mentioned above for the
<code>x0</code> argument. If these bounds are not provided manually then
they (except those related to the polynomial coefficients)
will depend on the estimates obtained
by local optimization via <code><a href="stats.html#topic+optim">optim</a></code> function
(this estimates will be in the middle
between <code>lower</code> and <code>upper</code>).
Specifically for each sd parameter <code>lower</code> (<code>upper</code>) bound
is 5 times lower (higher) than this
parameter <code><a href="stats.html#topic+optim">optim</a></code> estimate.
For each mean and regression coefficient parameter its lower and 
upper bounds deviate from corresponding <code><a href="stats.html#topic+optim">optim</a></code> estimate
by two absolute values of this estimate.
Finally, lower and upper bounds for each polynomial
coefficient are <code>-10</code> and <code>10</code> correspondingly (do not depend
on their <code><a href="stats.html#topic+optim">optim</a></code> estimates).
</p>
<p>The following arguments are differ from their defaults in
<code><a href="GA.html#topic+ga">ga</a></code>:
</p>

<ul>
<li> <p><code>pmutation = 0.2</code>,
</p>
</li>
<li> <p><code>optim = TRUE</code>,
</p>
</li>
<li> <p><code>optimArgs =
list("method" = "Nelder-Mead", "poptim" = 0.2, "pressel" = 0.5)</code>,
</p>
</li>
<li> <p><code>seed = 8</code>,
</p>
</li>
<li> <p><code>elitism = 2 + round(popSize * 0.1)</code>.</p>
</li></ul>

<p>The arguments <code>popSize</code> and <code>maxiter</code> of
<code><a href="GA.html#topic+ga">ga</a></code> function have been set proportional to the number of
estimated polynomial coefficients:
</p>

<ul>
<li> <p><code>popSize = 10 + (prod(pol_degrees + 1) - 1) * 2</code>.
</p>
</li>
<li> <p><code>maxiter = 50 * (prod(pol_degrees + 1))</code></p>
</li></ul>



<h3>Value</h3>

<p>This function returns an object of class &quot;hpaML&quot;.<br /> <br />
An object of class &quot;hpaML&quot; is a list containing the following components:
</p>

<ul>
<li> <p><code>optim</code> - <code><a href="stats.html#topic+optim">optim</a></code> function output. 
If <code>opt_type = "GA"</code> then it is the list containing 
<code><a href="stats.html#topic+optim">optim</a></code> and <code><a href="GA.html#topic+ga">ga</a></code> functions outputs.
</p>
</li>
<li> <p><code>x1</code> - numeric vector of distribution parameters estimates.
</p>
</li>
<li> <p><code>mean</code> - density function mean vector estimate.
</p>
</li>
<li> <p><code>sd</code> - density function sd vector estimate.
</p>
</li>
<li> <p><code>pol_coefficients</code> - polynomial coefficients estimates.
</p>
</li>
<li> <p><code>tr_left </code>- the same as <code>tr_left</code> input parameter.
</p>
</li>
<li> <p><code>tr_right</code> - the same as <code>tr_right</code> input parameter.
</p>
</li>
<li> <p><code>omit_ind </code>- the same as <code>omit_ind</code> input parameter.
</p>
</li>
<li> <p><code>given_ind</code> - the same as <code>given_ind</code> input parameter.
</p>
</li>
<li> <p><code>cov_mat</code> - covariance matrix estimate.
</p>
</li>
<li> <p><code>results</code> - numeric matrix representing estimation results.
</p>
</li>
<li> <p><code>log-likelihood</code> - value of Log-Likelihood function.
</p>
</li>
<li> <p><code>AIC</code> - AIC value.
</p>
</li>
<li> <p><code>data</code> - the same as <code>data</code> input parameter but without <code>NA</code> observations.
</p>
</li>
<li> <p><code>n_obs</code> - number of observations.
</p>
</li>
<li> <p><code>bootstrap</code> - list where bootstrap estimation results are stored.</p>
</li></ul>



<h3>References</h3>

<p>A. Gallant and D. W. Nychka (1987) &lt;doi:10.2307/1913241&gt;
</p>


<h3>See Also</h3>

<p><a href="#topic+summary.hpaML">summary.hpaML</a>, <a href="#topic+predict.hpaML">predict.hpaML</a>, 
<a href="#topic+logLik.hpaML">logLik.hpaML</a>, <a href="#topic+plot.hpaML">plot.hpaML</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Approximate Student (t) distribution

# Set seed for reproducibility
set.seed(123)

# Simulate 5000 realizations of Student distribution 
# with 5 degrees of freedom
n &lt;- 5000
df &lt;- 5
x &lt;- matrix(rt(n, df), ncol = 1)
pol_degrees &lt;- c(4)

# Apply pseudo maximum likelihood routine
ml_result &lt;- hpa::hpaML(data = x, pol_degrees = pol_degrees)
summary(ml_result)

# Get predicted probabilites (density values) approximations
predict(ml_result)

# Plot density approximation
plot(ml_result)

## Approximate chi-squared distribution

# Set seed for reproducibility
set.seed(123)

# Simulate 5000 realizations of chi-squared distribution 
# with 5 degrees of freedom

n &lt;- 5000
df &lt;- 5
x &lt;- matrix(rchisq(n, df), ncol = 1)
pol_degrees &lt;- c(5)

# Apply pseudo maximum likelihood routine
ml_result &lt;- hpaML(data = x, pol_degrees = as.vector(pol_degrees), 
				tr_left = 0)
summary(ml_result)

# Get predicted probabilites (density values) approximations
predict(ml_result)

# Plot density approximation
plot(ml_result)

## Approximate multivariate Student (t) distribution
## Note that calculations may take up to a minute

# Set seed for reproducibility
set.seed(123)

# Simulate 5000 realizations of three dimensional Student distribution 
# with 5 degrees of freedom
library("mvtnorm")
cov_mat &lt;- matrix(c(1, 0.5, -0.5, 0.5, 1, 0.5, -0.5, 0.5, 1), ncol = 3)
x &lt;- rmvt(n = 5000, sigma = cov_mat, df = 5)

# Estimate approximating joint distribution parameters
ml_result &lt;- hpaML(data = x, pol_degrees = c(1, 1, 1))

# Get summary
summary(ml_result)

# Get predicted values for joint density function
predict(ml_result)

# Plot density approximation for the
# second random variable
plot(ml_result, ind = 2)

# Plot density approximation for the
# second random variable conditioning
# on x1 = 1
plot(ml_result, ind = 2, given = c(1, NA, NA))

## Approximate Student (t) distribution and plot densities approximated
## under different hermite polynomial degrees against 
## true density (of Student distribution)

# Simulate 5000 realizations of t-distribution with 5 degrees of freedom
n &lt;- 5000
df &lt;- 5
x &lt;- matrix(rt(n, df), ncol=1)

# Apply pseudo maximum likelihood routine
# Create matrix of lists where i-th element contains hpaML results for K=i
ml_result &lt;- matrix(list(), 4, 1)
for(i in 1:4)
{
 ml_result[[i]] &lt;- hpa::hpaML(data = x, pol_degrees = i)
}

# Generate test values
test_values &lt;- seq(qt(0.001, df), qt(0.999, df), 0.001)
n0 &lt;- length(test_values)

# t-distribution density function at test values points
true_pred &lt;- dt(test_values, df)

# Create matrix of lists where i-th element contains 
# densities predictions for K=i
PGN_pred &lt;- matrix(list(), 4, 1)
for(i in 1:4)
{
  PGN_pred[[i]] &lt;- predict(object = ml_result[[i]], 
                           newdata = matrix(test_values, ncol=1))
}
# Plot the result
library("ggplot2")

# prepare the data
h &lt;- data.frame("values" = rep(test_values,5),
                "predictions" = c(PGN_pred[[1]],PGN_pred[[2]],
                                  PGN_pred[[3]],PGN_pred[[4]],
                                  true_pred), 
                "Density" = c(
                  rep("K=1",n0), rep("K=2",n0),
                  rep("K=3",n0), rep("K=4",n0),
                  rep("t-distribution",n0))
                  )
                  
# build the plot
ggplot(h, aes(values, predictions)) + geom_point(aes(color = Density)) +
  theme_minimal() + theme(legend.position = "top", 
                          text = element_text(size=26),
                          legend.title=element_text(size=20), 
                          legend.text=element_text(size=28)) +
  guides(colour = guide_legend(override.aes = list(size=10))
  )

# Get informative estimates summary for K=4
summary(ml_result[[4]])


</code></pre>

<hr>
<h2 id='hpaSelection'>Perform semi-nonparametric selection model estimation</h2><span id='topic+hpaSelection'></span>

<h3>Description</h3>

<p>This function performs semi-nonparametric (SNP) maximum 
likelihood estimation of sample selection model 
using Hermite polynomial based approximating function proposed by Gallant 
and Nychka in 1987. Please, see <code><a href="#topic+dhpa">dhpa</a></code> 'Details' section to 
get more information concerning this approximating function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hpaSelection(
  selection,
  outcome,
  data,
  selection_K = 1L,
  outcome_K = 1L,
  pol_elements = 3L,
  is_Newey = FALSE,
  x0 = numeric(0),
  is_Newey_loocv = FALSE,
  cov_type = "sandwich",
  boot_iter = 100L,
  is_parallel = FALSE,
  opt_type = "optim",
  opt_control = NULL,
  is_validation = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpaSelection_+3A_selection">selection</code></td>
<td>
<p>an object of class &quot;formula&quot; 
(or one that can be coerced to that class): a symbolic description of the 
selection equation form. All variables in <code>selection</code> should be numeric 
vectors of the same length.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_outcome">outcome</code></td>
<td>
<p>an object of class &quot;formula&quot; (or one that can be coerced 
to that class): a symbolic description of the outcome equation form. 
All variables in <code>outcome</code> should be numeric vectors of the 
same length.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_data">data</code></td>
<td>
<p>data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_selection_k">selection_K</code></td>
<td>
<p>non-negative integer representing 
polynomial degree related to selection equation.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_outcome_k">outcome_K</code></td>
<td>
<p>non-negative integer representing polynomial 
degree related to outcome equation.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_pol_elements">pol_elements</code></td>
<td>
<p>number of conditional expectation approximating terms 
for Newey's method. If <code>is_Newey_loocv</code> is <code>TRUE</code> then determines 
maximum number of these terms during leave-one-out cross-validation.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_is_newey">is_Newey</code></td>
<td>
<p>logical; if TRUE then returns only Newey's method 
estimation results (default value is FALSE).</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_x0">x0</code></td>
<td>
<p>numeric vector of optimization routine initial values.
Note that <code>x0 = c(pol_coefficients[-1], mean, sd, z_coef, y_coef)</code>.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_is_newey_loocv">is_Newey_loocv</code></td>
<td>
<p>logical; if TRUE then number of conditional 
expectation approximating terms for Newey's method will be selected
based on leave-one-out cross-validation criteria iterating through 0 
to pol_elements number of these terms.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_cov_type">cov_type</code></td>
<td>
<p>character determining the type of covariance matrix to be
returned and used for summary. If <code>cov_type = "hessian"</code> then negative
inverse of Hessian matrix will be applied. If <code>cov_type = "gop"</code> then
inverse of Jacobian outer products will be used.
If <code>cov_type = "sandwich"</code> (default) then sandwich covariance matrix
estimator will be applied. If <code>cov_type = "bootstrap"</code> then bootstrap
with <code>boot_iter</code> iterations will be used.
If <code>cov_type = "hessianFD"</code> or <code>cov_type = "sandwichFD"</code> then
(probably) more accurate but computationally demanding central difference 
Hessian approximation will be calculated for the inverse Hessian and 
sandwich estimators correspondingly. Central differences are computed via
analytically provided gradient. This Hessian matrix estimation approach
seems to be less accurate than BFGS approximation if polynomial order
is high (usually greater then 5).</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_boot_iter">boot_iter</code></td>
<td>
<p>the number of bootstrap iterations
for <code>cov_type = "bootstrap"</code> covariance matrix estimator type.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_opt_type">opt_type</code></td>
<td>
<p>string value determining the type of the optimization
routine to be applied. The default is <code>"optim"</code> meaning that BFGS method
from the <code><a href="stats.html#topic+optim">optim</a></code> function will be applied.
If <code>opt_type = "GA"</code> then <code><a href="GA.html#topic+ga">ga</a></code> function will be
additionally applied.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_opt_control">opt_control</code></td>
<td>
<p>a list containing arguments to be passed to the
optimization routine depending on <code>opt_type</code> argument value.
Please see details to get additional information.</p>
</td></tr>
<tr><td><code id="hpaSelection_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Densities Hermite polynomial approximation approach has been
proposed by A. Gallant and D. W. Nychka in 1987. The main idea is to
approximate unknown distribution density with scaled Hermite polynomial.
For more information please refer to the literature listed below.
</p>
<p>Let's use notations introduced in <code><a href="#topic+dhpa">dhpa</a></code> 'Details' 
section. Function <code><a href="#topic+hpaSelection">hpaSelection</a></code> maximizes the following
quasi log-likelihood function:
</p>
<p style="text-align: center;"><code class="reqn">\ln L(\gamma, \beta, \alpha, \mu, \sigma; x) = 
\sum\limits_{i:z_{i}=1} 
\ln\left(\overline{F}_{\left(\xi_{1}|\xi_{2}=y_{i}-x_{i}^{o}\beta\right)}
\left(-\gamma x_{i}^{s}, \infty;\alpha, \mu, \sigma\right)\right)
f_{\xi_{2}}\left(y_{i}-x_{i}^{o}\beta\right)+</code>
</p>

<p style="text-align: center;"><code class="reqn">
+\sum\limits_{i:z_{i}=0} 
\ln\left(\overline{F}_{\xi}
(-\infty, -x_{i}^{s}\gamma;\alpha, \mu, \sigma)\right),</code>
</p>

<p>where (in addition to previously defined notations):
</p>
<p><code class="reqn">x_{i}^{s}</code> - is row vector of selection equation regressors derived  
from <code>data</code> according to <code>selection</code> formula.
</p>
<p><code class="reqn">x_{i}^{o}</code> - is row vector of outcome equation regressors derived  
from <code>data</code> according to <code>outcome</code> formula.
</p>
<p><code class="reqn">\gamma</code> - is column vector of selection equation 
regression coefficients (constant will not be added by default).
</p>
<p><code class="reqn">\beta</code> - is column vector of outcome equation 
regression coefficients (constant will not be added by default).
</p>
<p><code class="reqn">z_{i}</code> - binary (0 or 1) dependent variable defined 
in <code>selection</code> formula.
</p>
<p><code class="reqn">y_{i}</code> - continuous dependent variable defined 
in <code>outcome</code> formula.
</p>
<p>Note that <code class="reqn">\xi</code> is two dimensional and <code>selection_K</code> corresponds
to <code class="reqn">K_{1}</code> while <code>outcome_K</code> determines <code class="reqn">K_{2}</code>.
</p>
<p>The first polynomial coefficient (zero powers) 
set to 1 for identification purposes i.e. <code class="reqn">\alpha_{0}=1</code>.
</p>
<p>Rows in <code>data</code> corresponding to variables mentioned in <code>selection</code>
and <code>outcome</code> formulas which have at least one <code>NA</code>
value will be ignored. The exception is continues dependent variable 
<code class="reqn">y</code> which may have <code>NA</code> values for observation where <code class="reqn">z_{i}=0</code>.
</p>
<p>Note that coefficient for the first
independent variable in <code>selection</code> will be fixed
to 1 i.e. <code class="reqn">\gamma_{1}=1</code>.
</p>
<p>All variables mentioned in <code>selection</code> and 
<code>outcome</code> should be numeric vectors.
</p>
<p>The function calculates standard errors via sandwich estimator
and significance levels are reported taking into account quasi maximum
likelihood estimator (QMLE) asymptotic normality. If one wants to switch
from QMLE to semi-nonparametric estimator (SNPE) during hypothesis testing
then covariance matrix should be estimated again using bootstrap.
</p>
<p>Initial values for optimization routine are obtained by Newey's 
method (see the reference below). In order to obtain initial values
via least squares please, set <code>pol_elements = 0</code>. Initial values for
the outcome equation are obtained via <code><a href="#topic+hpaBinary">hpaBinary</a></code> function
setting <code>K</code> to <code>selection_K</code>.
</p>
<p>Note that selection equation dependent variables should have 
exactly two levels (0 and 1) where &quot;0&quot; states for the selection results 
which leads to unobservable values of dependent variable in 
outcome equation.
</p>
<p>This function maximizes (quasi) log-likelihood function 
via <code><a href="stats.html#topic+optim">optim</a></code> function setting its <code>method</code> 
argument to &quot;BFGS&quot;. If <code>opt_type = "GA"</code> then genetic
algorithm from <code><a href="GA.html#topic+ga">ga</a></code> function
will be additionally (after <code><a href="stats.html#topic+optim">optim</a></code> putting its
solution (<code>par</code>) into <code>suggestions</code> matrix) applied in order to 
perform global optimization. Note that global optimization takes
much more time (usually minutes but sometimes hours or even days). 
The number of iterations and population size of the genetic algorithm
will grow linearly along with the number of estimated parameters. 
If it seems that global maximum has not been found then it
is possible to continue the search restarting the function setting 
its input argument <code>x0</code> to <code>x1</code> output value. Note that
if <code>cov_type = "bootstrap"</code> then <code><a href="GA.html#topic+ga">ga</a></code>
function will not be used for bootstrap iterations since it
may be extremely time consuming.
</p>
<p>If <code>opt_type = "GA"</code> then <code>opt_control</code> should be the
list containing the values to be passed to <code><a href="GA.html#topic+ga">ga</a></code>
function. It is possible to pass arguments <code>lower</code>, <code>upper</code>,
<code>popSize</code>, <code>pcrossover</code>, <code>pmutation</code>, <code>elitism</code>,
<code>maxiter</code>, <code>suggestions</code>, <code>optim</code>, <code>optimArgs</code>,
<code>seed</code> and <code>monitor</code>. 
Note that it is possible to set <code>population</code>,
<code>selection</code>, <code>crossover</code> and <code>mutation</code> arguments changing
<code><a href="GA.html#topic+ga">ga</a></code> default parameters via <code><a href="GA.html#topic+gaControl">gaControl</a></code> 
function. These arguments information reported in <code><a href="GA.html#topic+ga">ga</a></code>.
In order to provide manual values for <code>lower</code> and <code>upper</code> bounds
please follow parameters ordering mentioned above for the
<code>x0</code> argument. If these bounds are not provided manually then
they (except those related to the polynomial coefficients)
will depend on the estimates obtained
by local optimization via <code><a href="stats.html#topic+optim">optim</a></code> function
(this estimates will be in the middle
between <code>lower</code> and <code>upper</code>).
Specifically for each sd parameter <code>lower</code> (<code>upper</code>) bound
is 5 times lower (higher) than this
parameter <code><a href="stats.html#topic+optim">optim</a></code> estimate.
For each mean and regression coefficient parameter its lower and 
upper bounds deviate from corresponding <code><a href="stats.html#topic+optim">optim</a></code> estimate
by two absolute values of this estimate.
Finally, lower and upper bounds for each polynomial
coefficient are <code>-10</code> and <code>10</code> correspondingly (do not depend
on their <code><a href="stats.html#topic+optim">optim</a></code> estimates).
</p>
<p>The following arguments are differ from their defaults in
<code><a href="GA.html#topic+ga">ga</a></code>:
</p>

<ul>
<li> <p><code>pmutation = 0.2</code>,
</p>
</li>
<li> <p><code>optim = TRUE</code>,
</p>
</li>
<li> <p><code>optimArgs =
list("method" = "Nelder-Mead", "poptim" = 0.2, "pressel" = 0.5)</code>,
</p>
</li>
<li> <p><code>seed = 8</code>,
</p>
</li>
<li> <p><code>elitism = 2 + round(popSize * 0.1)</code>.</p>
</li></ul>

<p>Let's denote by <code>n_reg</code> the number of regressors
included into the <code>selection</code> and <code>outcome</code> formulas.
The arguments <code>popSize</code> and <code>maxiter</code> of
<code><a href="GA.html#topic+ga">ga</a></code> function have been set proportional to the number of
estimated polynomial coefficients and independent variables:
</p>

<ul>
<li> <p><code>popSize = 10 + 5 * (z_K + 1) * (y_K + 1) + 2 * n_reg</code>
</p>
</li>
<li> <p><code>maxiter = 50 * (z_K + 1) * (y_K + 1) + 10 * n_reg</code></p>
</li></ul>



<h3>Value</h3>

<p>This function returns an object of class &quot;hpaSelection&quot;.<br /> <br />
An object of class &quot;hpaSelection&quot; is a list containing the 
following components:
</p>

<ul>
<li> <p><code>optim</code> - <code><a href="stats.html#topic+optim">optim</a></code> function output. 
If <code>opt_type = "GA"</code> then it is the list containing 
<code><a href="stats.html#topic+optim">optim</a></code> and <code><a href="GA.html#topic+ga">ga</a></code> functions outputs.
</p>
</li>
<li> <p><code>x1</code> - numeric vector of distribution parameters estimates.
</p>
</li>
<li> <p><code>Newey</code> - list containing information concerning Newey's 
method estimation results.
</p>
</li>
<li> <p><code>selection_mean</code> - estimate of the hermite polynomial mean 
parameter related to selection equation random error marginal distribution.
</p>
</li>
<li> <p><code>outcome_mean</code> - estimate of the hermite polynomial mean parameter 
related to outcome equation random error marginal distribution.
</p>
</li>
<li> <p><code>selection_sd</code> - estimate of sd parameter related to 
selection equation random error marginal distribution.
</p>
</li>
<li> <p><code>outcome_sd</code> - estimate of the hermite polynomial sd parameter related 
to outcome equation random error marginal distribution.
</p>
</li>
<li> <p><code>pol_coefficients</code> - polynomial coefficients estimates.
</p>
</li>
<li> <p><code>pol_degrees</code> - numeric vector which first element is <code>selection_K</code> 
and the second is <code>outcome_K</code>.
</p>
</li>
<li> <p><code>selection_coef</code> - selection equation regression coefficients estimates.
</p>
</li>
<li> <p><code>outcome_coef</code> - outcome equation regression coefficients estimates.
</p>
</li>
<li> <p><code>cov_mat</code> - covariance matrix estimate.
</p>
</li>
<li> <p><code>results</code> - numeric matrix representing estimation results.
</p>
</li>
<li> <p><code>log-likelihood</code> - value of Log-Likelihood function.
</p>
</li>
<li> <p><code>re_moments</code> - list which contains information about random 
errors expectations, variances and correlation.
</p>
</li>
<li> <p><code>data_List</code> - list containing model variables and their 
partition according to outcome and selection equations.
</p>
</li>
<li> <p><code>n_obs</code> - number of observations.
</p>
</li>
<li> <p><code>ind_List</code> - list which contains information about parameters 
indexes in <code>x1</code>.
</p>
</li>
<li> <p><code>selection_formula</code> - the same as <code>selection</code> 
input parameter.
</p>
</li>
<li> <p><code>outcome_formula</code> - the same as <code>outcome</code> input parameter.</p>
</li></ul>

<p>Abovementioned list <code>Newey</code> has class &quot;hpaNewey&quot; and contains 
the following components:
</p>

<ul>
<li> <p><code>outcome_coef</code> - regression coefficients estimates (except 
constant term which is part of conditional expectation 
approximating polynomial).
</p>
</li>
<li> <p><code>selection_coef</code> - regression coefficients estimates related 
to selection equation.
</p>
</li>
<li> <p><code>constant_biased</code> - biased estimate of constant term.
</p>
</li>
<li> <p><code>inv_mills</code> - inverse mills ratios estimates and their 
powers (including constant).
</p>
</li>
<li> <p><code>inv_mills_coef</code> - coefficients related to <code>inv_mills</code>.
</p>
</li>
<li> <p><code>pol_elements</code> - the same as <code>pol_elements</code> 
input parameter. However if <code>is_Newey_loocv</code> is <code>TRUE</code>
then it will equal to the number of conditional expectation 
approximating terms for Newey's method which minimize leave-one-out 
cross-validation criteria.
</p>
</li>
<li> <p><code>outcome_exp_cond</code> - dependent variable conditional 
expectation estimates.
</p>
</li>
<li> <p><code>selection_exp</code> - selection equation random error 
expectation estimate.
</p>
</li>
<li> <p><code>selection_var</code> - selection equation random error 
variance estimate.
</p>
</li>
<li> <p><code>hpaBinaryModel</code> - object of class &quot;hpaBinary&quot; which 
contains selection equation estimation results.</p>
</li></ul>

<p>Abovementioned list <code>re_moments</code> contains the following components:
</p>

<ul>
<li> <p><code>selection_exp</code> - selection equation random errors 
expectation estimate.
</p>
</li>
<li> <p><code>selection_var</code> - selection equation random errors 
variance estimate.
</p>
</li>
<li> <p><code>outcome_exp</code> - outcome equation random errors 
expectation estimate.
</p>
</li>
<li> <p><code>outcome_var</code> - outcome equation random errors 
variance estimate.
</p>
</li>
<li> <p><code>errors_covariance</code> - outcome and selection equation 
random errors covariance estimate.
</p>
</li>
<li> <p><code>rho</code> - outcome and selection equation random errors 
correlation estimate.
</p>
</li>
<li> <p><code>rho_std</code> - outcome and selection equation random 
errors correlation estimator standard error estimate.</p>
</li></ul>



<h3>References</h3>

<p>A. Gallant and D. W. Nychka (1987) &lt;doi:10.2307/1913241&gt;
</p>
<p>W. K. Newey (2009) &lt;https://doi.org/10.1111/j.1368-423X.2008.00263.x&gt;
</p>
<p>Mroz T. A. (1987) &lt;doi:10.2307/1911029&gt;
</p>


<h3>See Also</h3>

<p><a href="#topic+summary.hpaSelection">summary.hpaSelection</a>, 
<a href="#topic+predict.hpaSelection">predict.hpaSelection</a>, <a href="#topic+plot.hpaSelection">plot.hpaSelection</a>, 
<a href="#topic+logLik.hpaSelection">logLik.hpaSelection</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Let's estimate wage equation accounting for non-random selection.
## See the reference to Mroz TA (1987) to get additional details about
## the data this examples use

# Prepare data
library("sampleSelection")
data("Mroz87")
h = data.frame("kids" = as.numeric(Mroz87$kids5 + Mroz87$kids618 &gt; 0),
	"age" = as.numeric(Mroz87$age),
	"faminc" = as.numeric(Mroz87$faminc),
	"educ" = as.numeric(Mroz87$educ),
	"exper" = as.numeric(Mroz87$exper),
	"city" = as.numeric(Mroz87$city),
	"wage" = as.numeric(Mroz87$wage),
	"lfp" = as.numeric(Mroz87$lfp))
	
# Estimate model parameters
model &lt;- hpaSelection(selection = lfp ~ educ + age + I(age ^ 2) + 
                                        kids + log(faminc),
                      outcome = log(wage) ~ exper + I(exper ^ 2) + 
                                            educ + city,
                                  selection_K = 2, outcome_K = 3, 
                                  data = h, 
                                  pol_elements = 3, is_Newey_loocv = TRUE)
summary(model)

# Plot outcome equation random errors density
plot(model, type = "outcome")
# Plot selection equation random errors density
plot(model, type = "selection")


## Estimate semi-nonparametric sample selection model
## parameters on simulated data given chi-squared random errors


set.seed(100)
library("mvtnorm")

# Sample size

n &lt;- 1000

# Simulate independent variables
X_rho &lt;- 0.5
X_sigma &lt;- matrix(c(1, X_rho, X_rho,
                    X_rho, 1, X_rho, 
                    X_rho,X_rho,1), 
                  ncol=3)
X &lt;- rmvnorm(n=n, mean = c(0,0,0), 
             sigma = X_sigma)

# Simulate random errors
epsilon &lt;- matrix(0, n, 2)
epsilon_z_y &lt;- rchisq(n, 5)
epsilon[, 1] &lt;- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] &lt;- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
# Simulate selection equation
z_star &lt;- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z &lt;- as.numeric((z_star &gt; 0))

# Simulate outcome equation
y_star &lt;- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z &lt;- as.numeric((z_star &gt; 0))
y &lt;- y_star
y[z==0] &lt;- NA
h &lt;- as.data.frame(cbind(z, y, X))
names(h) &lt;- c("z", "y", "x1", "x2", "x3")

# Estimate parameters
model &lt;- hpaSelection(selection = z ~ x1 + x2, 
                      outcome = y ~ x1 + x3,
                      data = h, 
                      selection_K = 1, outcome_K = 3)
summary(model)

# Get conditional predictions for outcome equation
model_pred_c &lt;- predict(model, is_cond = TRUE)
# Conditional predictions y|z=1
model_pred_c$y_1
# Conditional predictions y|z=0
model_pred_c$y_0

# Get unconditional predictions for outcome equation
model_pred_u &lt;- predict(model, is_cond = FALSE)
model_pred_u$y

# Get conditional predictions for selection equation
# Note that for z=0 these predictions are NA
predict(model, is_cond = TRUE, type = "selection")
# Get unconditional predictions for selection equation
predict(model, is_cond = FALSE, type = "selection")



</code></pre>

<hr>
<h2 id='hsaDist'>Probabilities and Moments Hermite Spline Approximation</h2><span id='topic+hsaDist'></span><span id='topic+dhsa'></span><span id='topic+ehsa'></span>

<h3>Description</h3>

<p>The set of functions similar to <code><a href="#topic+dhpa">dhpa</a></code>-like
functions. The difference is that instead of polynomial these functions
utilize spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhsa(x, m, knots, mean = 0, sd = 1, log = FALSE)

ehsa(m, knots, mean = 0, sd = 1, power = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsaDist_+3A_x">x</code></td>
<td>
<p>numeric vector of values for which the function should 
be estimated.</p>
</td></tr>
<tr><td><code id="hsaDist_+3A_m">m</code></td>
<td>
<p>numeric matrix which rows correspond to spline intervals
while columns represent variables powers. Therefore the element 
in i-th row and j-th column represents the coefficient associated with
the variable that 1) belongs to the i-th interval i.e. between i-th and
(i + 1)-th knots 2) raised to the power of (j - 1).</p>
</td></tr>
<tr><td><code id="hsaDist_+3A_knots">knots</code></td>
<td>
<p>sorted in ascending order numeric vector representing
knots of the spline.</p>
</td></tr>
<tr><td><code id="hsaDist_+3A_mean">mean</code></td>
<td>
<p>expected value of a normal distribution.</p>
</td></tr>
<tr><td><code id="hsaDist_+3A_sd">sd</code></td>
<td>
<p>standard deviation of a normal distribution.</p>
</td></tr>
<tr><td><code id="hsaDist_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code> then probabilities p are given as log(p)
or derivatives will be given respect to log(p).</p>
</td></tr>
<tr><td><code id="hsaDist_+3A_power">power</code></td>
<td>
<p>non-negative integer representing the power of the 
expected value i.e. E(X ^ power) will be estimated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In contrast to <code><a href="#topic+dhpa">dhpa</a></code>-like functions these
functions may deal with univariate distributions only. In future this
functions will be generalized to work with multivariate distributions.
The main idea of these functions is to use squared spline instead of squared 
polynomial in order to provide greater numeric stability and approximation 
accuracy. To provide spline parameters please use <code>m</code> and <code>knots</code>
arguments (i.e. instead of <code>pol_degrees</code> and <code>pol_coefficients</code>
arguments that where used to specify the polynomial
for <code><a href="#topic+dhpa">dhpa</a></code>-like functions).
</p>


<h3>Value</h3>

<p>Function <code><a href="#topic+dhsa">dhsa</a></code> returns vector of probabilities
of the same length as <code>x</code>. Function <code><a href="#topic+ehsa">ehsa</a></code> 
returns moment value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dhpa">dhpa</a></code>, <code><a href="#topic+bsplineGenerate">bsplineGenerate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examples demonstrating dhsa and ehsa functions application.

# Generate a b-splines
b &lt;- bsplineGenerate(knots = c(-2.1, 1.5, 1.5, 2.2, 3.7, 4.2, 5),
                     degree = 3)
                      
# Combine b-splines into a spline
spline &lt;- bsplineComb(splines = b, weights = c(1.6, -1.2, 3.2))

# Assign parameters using the spline created above
knots &lt;- spline$knots
m &lt;- spline$m
mean &lt;- 1
sd &lt;- 2

# Estimate the density at particular points
x &lt;- c(2, 3.7, 8)
dhsa(x, 
     m = m, knots = knots,
     mean = mean, sd = sd)
     
# Calculate expected value
ehsa(m = m, knots = knots,
     mean = mean, sd = sd,
     power = 1) 
     
# Evaluate the third moment
ehsa(m = m, knots = knots,
     mean = mean, sd = sd,
     power = 3) 
</code></pre>

<hr>
<h2 id='logLik_hpaBinary'>Calculates log-likelihood for &quot;hpaBinary&quot; object</h2><span id='topic+logLik_hpaBinary'></span>

<h3>Description</h3>

<p>This function calculates log-likelihood for &quot;hpaBinary&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLik_hpaBinary(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik_hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='logLik_hpaML'>Calculates log-likelihood for &quot;hpaML&quot; object</h2><span id='topic+logLik_hpaML'></span>

<h3>Description</h3>

<p>This function calculates log-likelihood for &quot;hpaML&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLik_hpaML(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik_hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='logLik_hpaSelection'>Calculates log-likelihood for &quot;hpaSelection&quot; object</h2><span id='topic+logLik_hpaSelection'></span>

<h3>Description</h3>

<p>This function calculates log-likelihood for 
&quot;hpaSelection&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLik_hpaSelection(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik_hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='logLik.hpaBinary'>Calculates log-likelihood for &quot;hpaBinary&quot; object</h2><span id='topic+logLik.hpaBinary'></span>

<h3>Description</h3>

<p>This function calculates log-likelihood for &quot;hpaBinary&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="logLik.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='logLik.hpaML'>Calculates log-likelihood for &quot;hpaML&quot; object</h2><span id='topic+logLik.hpaML'></span>

<h3>Description</h3>

<p>This function calculates log-likelihood for &quot;hpaML&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="logLik.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='logLik.hpaSelection'>Calculates log-likelihood for &quot;hpaSelection&quot; object</h2><span id='topic+logLik.hpaSelection'></span>

<h3>Description</h3>

<p>This function calculates log-likelihood for &quot;hpaSelection&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="logLik.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='mecdf'>Calculates multivariate empirical cumulative distribution function</h2><span id='topic+mecdf'></span>

<h3>Description</h3>

<p>This function calculates multivariate 
empirical cumulative distribution function
at each point of the sample
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mecdf(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mecdf_+3A_x">x</code></td>
<td>
<p>numeric matrix which rows are observations</p>
</td></tr>
</table>

<hr>
<h2 id='normalMoment'>Calculate k-th order moment of normal distribution</h2><span id='topic+normalMoment'></span>

<h3>Description</h3>

<p>This function recursively calculates k-th order moment of 
normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalMoment(
  k = 0L,
  mean = 0,
  sd = 1,
  return_all_moments = FALSE,
  is_validation = TRUE,
  is_central = FALSE,
  diff_type = "NO"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalMoment_+3A_k">k</code></td>
<td>
<p>non-negative integer moment order.</p>
</td></tr>
<tr><td><code id="normalMoment_+3A_mean">mean</code></td>
<td>
<p>numeric expected value.</p>
</td></tr>
<tr><td><code id="normalMoment_+3A_sd">sd</code></td>
<td>
<p>positive numeric standard deviation.</p>
</td></tr>
<tr><td><code id="normalMoment_+3A_return_all_moments">return_all_moments</code></td>
<td>
<p>logical; if <code>TRUE</code>, function returns 
(k+1)-dimensional numeric vector of moments of normally distributed random 
variable with mean = <code>mean</code> and standard deviation = <code>sd</code>. 
Note that i-th vector's component value corresponds to the (i-1)-th moment.</p>
</td></tr>
<tr><td><code id="normalMoment_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="normalMoment_+3A_is_central">is_central</code></td>
<td>
<p>logical; if <code>TRUE</code>, then central moments 
will be calculated.</p>
</td></tr>
<tr><td><code id="normalMoment_+3A_diff_type">diff_type</code></td>
<td>
<p>string value indicating the type of the argument
the moment should be differentiated respect to.
Default value is <code>"NO"</code> so the moments itself will be returned. 
Alternative values are <code>"mean"</code> and <code>"sd"</code>. Also 
<code>"x_lower"</code> and <code>"x_upper"</code> values are available for 
<code><a href="#topic+truncatedNormalMoment">truncatedNormalMoment</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates <code>k</code>-th order moment of normal 
distribution which mean equals to <code>mean</code> and standard deviation 
equals to <code>sd</code>.<br />
</p>
<p>Note that parameter <code>k</code> value automatically converts 
to integer. So passing non-integer <code>k</code> value will not cause 
any errors but the calculations will be performed for rounded 
<code>k</code> value only.
</p>


<h3>Value</h3>

<p>This function returns <code>k</code>-th order moment of
normal distribution which mean equals to <code>mean</code> and standard deviation 
is <code>sd</code>. If <code>return_all_moments</code> is <code>TRUE</code> then see this 
argument description above for output details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Calculate 5-th order moment of normal random variable which
## mean equals to 3 and standard deviation is 5.

# 5-th moment
normalMoment(k = 5, mean = 3, sd = 5)

# (0-5)-th moments
normalMoment(k = 5, mean = 3, sd = 5, return_all_moments = TRUE)

# 5-th moment derivative respect to mean
normalMoment(k = 5, mean = 3, sd = 5, diff_type = "mean")

# 5-th moment derivative respect to sd
normalMoment(k = 5, mean = 3, sd = 5, diff_type = "sd")

</code></pre>

<hr>
<h2 id='plot.hpaBinary'>Plot hpaBinary random errors approximated density</h2><span id='topic+plot.hpaBinary'></span>

<h3>Description</h3>

<p>Plot hpaBinary random errors approximated density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
plot(x, y = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hpaBinary_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="plot.hpaBinary_+3A_y">y</code></td>
<td>
<p>this parameter currently ignored</p>
</td></tr>
<tr><td><code id="plot.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code><a href="base.html#topic+plot">plot</a></code>
function.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.hpaML'>Plot approximated marginal density using hpaML output</h2><span id='topic+plot.hpaML'></span>

<h3>Description</h3>

<p>Plot approximated marginal density using hpaML output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
plot(x, y = NULL, ..., ind = 1, given = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hpaML_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="plot.hpaML_+3A_y">y</code></td>
<td>
<p>this parameter currently ignored</p>
</td></tr>
<tr><td><code id="plot.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code><a href="base.html#topic+plot">plot</a></code>
function.</p>
</td></tr>
<tr><td><code id="plot.hpaML_+3A_ind">ind</code></td>
<td>
<p>index of random variable for which
approximation to marginal density should be plotted</p>
</td></tr>
<tr><td><code id="plot.hpaML_+3A_given">given</code></td>
<td>
<p>numeric vector of the same length as given_ind
from <code>x</code>. Determines conditional values for the corresponding
components. <code>NA</code> values in <code>given</code> vector indicate that
corresponding random variable is not conditioned. By default all
<code>given</code> components are <code>NA</code> so unconditional marginal
density will be plotted for the <code>ind</code>-th random variable.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.hpaSelection'>Plot hpaSelection random errors approximated density</h2><span id='topic+plot.hpaSelection'></span>

<h3>Description</h3>

<p>Plot hpaSelection random errors approximated density
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
plot(x, y = NULL, ..., type = "outcome")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hpaSelection_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="plot.hpaSelection_+3A_y">y</code></td>
<td>
<p>this parameter currently ignored</p>
</td></tr>
<tr><td><code id="plot.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code><a href="base.html#topic+plot">plot</a></code>
function.</p>
</td></tr>
<tr><td><code id="plot.hpaSelection_+3A_type">type</code></td>
<td>
<p>character; if &quot;outcome&quot; then function plots the graph for 
outcome equation random errors, if &quot;selection&quot; then plot for selection 
equation random errors will be generated.</p>
</td></tr>
</table>

<hr>
<h2 id='pnorm_parallel'>Calculate normal cdf in parallel</h2><span id='topic+pnorm_parallel'></span>

<h3>Description</h3>

<p>Calculate in parallel for each value from vector <code>x</code> 
distribution function of normal distribution with 
mean equal to <code>mean</code> and standard deviation equal to <code>sd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pnorm_parallel(x, mean = 0, sd = 1, is_parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pnorm_parallel_+3A_x">x</code></td>
<td>
<p>vector of quantiles: should be numeric vector,
not just double value.</p>
</td></tr>
<tr><td><code id="pnorm_parallel_+3A_mean">mean</code></td>
<td>
<p>double value.</p>
</td></tr>
<tr><td><code id="pnorm_parallel_+3A_sd">sd</code></td>
<td>
<p>double positive value.</p>
</td></tr>
<tr><td><code id="pnorm_parallel_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
</table>

<hr>
<h2 id='polynomialIndex'>Multivariate Polynomial Representation</h2><span id='topic+polynomialIndex'></span><span id='topic+printPolynomial'></span>

<h3>Description</h3>

<p>Function <code><a href="#topic+polynomialIndex">polynomialIndex</a></code> 
provides matrix which allows to iterate through the elements 
of multivariate polynomial being aware of these elements powers. 
So (i, j)-th element of the matrix is power of j-th variable in i-th 
multivariate polynomial element.
</p>
<p>Function <code><a href="#topic+printPolynomial">printPolynomial</a></code> prints multivariate polynomial
given its degrees (<code>pol_degrees</code>) and coefficients 
(<code>pol_coefficients</code>) vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polynomialIndex(pol_degrees = numeric(0), is_validation = TRUE)

printPolynomial(pol_degrees, pol_coefficients, is_validation = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polynomialIndex_+3A_pol_degrees">pol_degrees</code></td>
<td>
<p>non-negative integer vector of polynomial 
degrees (orders).</p>
</td></tr>
<tr><td><code id="polynomialIndex_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="polynomialIndex_+3A_pol_coefficients">pol_coefficients</code></td>
<td>
<p>numeric vector of polynomial coefficients.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multivariate polynomial of degrees   
<code class="reqn">(K_{1},...,K_{m})</code> (<code>pol_degrees</code>) has the form:
</p>
<p style="text-align: center;"><code class="reqn">a_{(0,...,0)}x_{1}^{0}*...*x_{m}^{0}+ ... + 
a_{(K_{1},...,K_{m})}x_{1}^{K_{1}}*...*x_{m}^{K_{m}},</code>
</p>

<p>where <code class="reqn">a_{(i_{1},...,i_{m})}</code> are polynomial coefficients, while
polynomial elements are:
</p>
<p style="text-align: center;"><code class="reqn">a_{(i_{1},...,i_{m})}x_{1}^{i_{1}}*...*x_{m}^{i_{m}},</code>
</p>

<p>where <code class="reqn">(i_{1},...,i_{m})</code> are polynomial element's powers corresponding
to variables <code class="reqn">(x_{1},...,x_{m})</code> respectively. Note that 
<code class="reqn">i_{j}\in \{0,...,K_{j}\}</code>. 
</p>
<p>Function <code><a href="#topic+printPolynomial">printPolynomial</a></code> removes polynomial elements 
which coefficients are zero and variables which powers are zero. Output may 
contain long coefficients representation as they are not rounded.
</p>


<h3>Value</h3>

<p>Function <code><a href="#topic+polynomialIndex">polynomialIndex</a></code> 
returns matrix which rows are 
responsible for variables while columns are related to powers. 
So <code class="reqn">(i, j)</code>-th element of this matrix corresponds to the 
power <code class="reqn">i_{j}</code> of the <code class="reqn">x_{j}</code> variable in <code class="reqn">i</code>-th polynomial 
element. Therefore <code class="reqn">i</code>-th column of this matrix contains vector of
powers <code class="reqn">(i_{1},...,i_{m})</code> for the <code class="reqn">i</code>-th polynomial element.
So the function transforms <code class="reqn">m</code>-dimensional elements indexing
to one-dimensional.
</p>
<p>Function <code><a href="#topic+printPolynomial">printPolynomial</a></code> returns the string which 
contains polynomial symbolic representation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Get polynomial indexes matrix for the polynomial 
## which degrees are (1, 3, 5)

polynomialIndex(c(1, 3, 5))

## Consider multivariate polynomial of degrees (2, 1) such that coefficients
## for elements which powers sum is even are 2 and for those which powers sum
## is odd are 5. So the polynomial is 2+5x2+5x1+2x1x2+2x1^2+5x1^2x2 where
## x1 and x2 are polynomial variables.

# Create variable to store polynomial degrees
pol_degrees &lt;- c(2, 1)

# Let's represent its powers (not coefficients) in a matrix form
pol_matrix &lt;- polynomialIndex(pol_degrees)

# Calculate polynomial elements' powers sums
pol_powers_sum &lt;- pol_matrix[1, ] + pol_matrix[2, ]

# Let's create polynomial coefficients vector filling it
# with NA values
pol_coefficients &lt;- rep(NA, (pol_degrees[1] + 1) * (pol_degrees[2] + 1))

# Now let's fill coefficients vector with correct values
pol_coefficients[pol_powers_sum %% 2 == 0] &lt;- 2
pol_coefficients[pol_powers_sum %% 2 != 0] &lt;- 5

# Finally, let's check that correspondence is correct
printPolynomial(pol_degrees, pol_coefficients)

## Let's represent polynomial 0.3+0.5x2-x2^2+2x1+1.5x1x2+x1x2^2

pol_degrees &lt;- c(1, 2)
pol_coefficients &lt;- c(0.3, 0.5, -1, 2, 1.5, 1)

printPolynomial(pol_degrees, pol_coefficients)
</code></pre>

<hr>
<h2 id='predict_hpaBinary'>Predict method for hpaBinary</h2><span id='topic+predict_hpaBinary'></span>

<h3>Description</h3>

<p>Predict method for hpaBinary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_hpaBinary(object, newdata = NULL, is_prob = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="predict_hpaBinary_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame (for <a href="#topic+hpaBinary">hpaBinary</a> and
<a href="#topic+hpaSelection">hpaSelection</a>) or numeric matrix (for <a href="#topic+hpaML">hpaML</a>)
in which to look for variables with which to predict. If omitted,
the original data frame (matrix) used.</p>
</td></tr>
<tr><td><code id="predict_hpaBinary_+3A_is_prob">is_prob</code></td>
<td>
<p>logical; if TRUE (default) 
then function returns predicted probabilities. 
Otherwise latent variable
(single index) estimates will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns predicted probabilities 
based on <code><a href="#topic+hpaBinary">hpaBinary</a></code> estimation results.
</p>

<hr>
<h2 id='predict_hpaML'>Predict method for hpaML</h2><span id='topic+predict_hpaML'></span>

<h3>Description</h3>

<p>Predict method for hpaML
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_hpaML(object, newdata = matrix(1, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="predict_hpaML_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame (for <a href="#topic+hpaBinary">hpaBinary</a> and
<a href="#topic+hpaSelection">hpaSelection</a>) or numeric matrix (for <a href="#topic+hpaML">hpaML</a>)
in which to look for variables with which to predict. If omitted,
the original data frame (matrix) used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns predictions based 
on <code><a href="#topic+hpaML">hpaML</a></code> estimation results.
</p>

<hr>
<h2 id='predict_hpaSelection'>Predict outcome and selection equation values from hpaSelection model</h2><span id='topic+predict_hpaSelection'></span>

<h3>Description</h3>

<p>This function predicts outcome and selection equation 
values from hpaSelection model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_hpaSelection(
  object,
  newdata = NULL,
  method = "HPA",
  is_cond = TRUE,
  is_outcome = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="predict_hpaSelection_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame (for <a href="#topic+hpaBinary">hpaBinary</a> and
<a href="#topic+hpaSelection">hpaSelection</a>) or numeric matrix (for <a href="#topic+hpaML">hpaML</a>)
in which to look for variables with which to predict. If omitted,
the original data frame (matrix) used.</p>
</td></tr>
<tr><td><code id="predict_hpaSelection_+3A_method">method</code></td>
<td>
<p>string value indicating prediction method based on hermite 
polynomial approximation &quot;HPA&quot; or Newey method &quot;Newey&quot;.</p>
</td></tr>
<tr><td><code id="predict_hpaSelection_+3A_is_cond">is_cond</code></td>
<td>
<p>logical; if <code>TRUE</code> (default) then conditional 
predictions will be estimated. Otherwise unconditional predictions 
will be returned.</p>
</td></tr>
<tr><td><code id="predict_hpaSelection_+3A_is_outcome">is_outcome</code></td>
<td>
<p>logical; if <code>TRUE</code> (default) then predictions 
for selection equation will be estimated using &quot;HPA&quot; method.
Otherwise selection equation predictions (probabilities) will be returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that Newey method can't predict conditional outcomes for 
zero selection equation value. Conditional probabilities for 
selection equation could be estimated only when dependent variable from 
outcome equation is observable.
</p>


<h3>Value</h3>

<p>This function returns the list which structure depends 
on <code>method</code>, <code>is_probit</code> and <code>is_outcome</code> values.
</p>

<hr>
<h2 id='predict.hpaBinary'>Predict method for hpaBinary</h2><span id='topic+predict.hpaBinary'></span>

<h3>Description</h3>

<p>Predict method for hpaBinary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
predict(object, ..., newdata = NULL, is_prob = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="predict.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
<tr><td><code id="predict.hpaBinary_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame (for <a href="#topic+hpaBinary">hpaBinary</a> and
<a href="#topic+hpaSelection">hpaSelection</a>) or numeric matrix (for <a href="#topic+hpaML">hpaML</a>)
in which to look for variables with which to predict. If omitted,
the original data frame (matrix) used.</p>
</td></tr>
<tr><td><code id="predict.hpaBinary_+3A_is_prob">is_prob</code></td>
<td>
<p>logical; if TRUE (default) then function returns 
predicted probabilities. Otherwise latent variable
(single index) estimates will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns predicted probabilities based on 
<code><a href="#topic+hpaBinary">hpaBinary</a></code> estimation results.
</p>

<hr>
<h2 id='predict.hpaML'>Predict method for hpaML</h2><span id='topic+predict.hpaML'></span>

<h3>Description</h3>

<p>Predict method for hpaML
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
predict(object, ..., newdata = matrix(c(0)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="predict.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
<tr><td><code id="predict.hpaML_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame (for <a href="#topic+hpaBinary">hpaBinary</a> and
<a href="#topic+hpaSelection">hpaSelection</a>) or numeric matrix (for <a href="#topic+hpaML">hpaML</a>)
in which to look for variables with which to predict. If omitted,
the original data frame (matrix) used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns predictions based on 
<code><a href="#topic+hpaML">hpaML</a></code> estimation results.
</p>

<hr>
<h2 id='predict.hpaSelection'>Predict outcome and selection equation values from hpaSelection model</h2><span id='topic+predict.hpaSelection'></span>

<h3>Description</h3>

<p>This function predicts outcome and selection equation 
values from hpaSelection model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
predict(
  object,
  ...,
  newdata = NULL,
  method = "HPA",
  is_cond = TRUE,
  type = "outcome"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="predict.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
<tr><td><code id="predict.hpaSelection_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame (for <a href="#topic+hpaBinary">hpaBinary</a> and
<a href="#topic+hpaSelection">hpaSelection</a>) or numeric matrix (for <a href="#topic+hpaML">hpaML</a>)
in which to look for variables with which to predict. If omitted,
the original data frame (matrix) used.</p>
</td></tr>
<tr><td><code id="predict.hpaSelection_+3A_method">method</code></td>
<td>
<p>string value indicating prediction method based 
on hermite polynomial approximation &quot;HPA&quot; or Newey method &quot;Newey&quot;.</p>
</td></tr>
<tr><td><code id="predict.hpaSelection_+3A_is_cond">is_cond</code></td>
<td>
<p>logical; if <code>TRUE</code> (default) then conditional 
predictions will be estimated. Otherwise unconditional 
predictions will be returned.</p>
</td></tr>
<tr><td><code id="predict.hpaSelection_+3A_type">type</code></td>
<td>
<p>character; if &quot;outcome&quot; (default) then predictions for 
selection equation will be estimated according to <code>method</code>.
If &quot;selection&quot; then selection equation predictions (probabilities) 
will be returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that Newey method can't predict conditional outcomes 
for zero selection equation value. Conditional probabilities for 
selection equation could be estimated only when dependent variable 
from outcome equation is observable.
</p>


<h3>Value</h3>

<p>This function returns the list which structure 
depends on <code>method</code>, <code>is_probit</code> and <code>is_outcome</code> values.
</p>

<hr>
<h2 id='print_summary_hpaBinary'>Summary for hpaBinary output</h2><span id='topic+print_summary_hpaBinary'></span>

<h3>Description</h3>

<p>Summary for hpaBinary output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_summary_hpaBinary(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_summary_hpaBinary_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='print_summary_hpaML'>Summary for hpaML output</h2><span id='topic+print_summary_hpaML'></span>

<h3>Description</h3>

<p>Summary for hpaML output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_summary_hpaML(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_summary_hpaML_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='print_summary_hpaSelection'>Summary for hpaSelection output</h2><span id='topic+print_summary_hpaSelection'></span>

<h3>Description</h3>

<p>Summary for hpaSelection output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_summary_hpaSelection(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_summary_hpaSelection_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='print.hpaBinary'>Print method for &quot;hpaBinary&quot; object</h2><span id='topic+print.hpaBinary'></span>

<h3>Description</h3>

<p>Print method for &quot;hpaBinary&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hpaBinary_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="print.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='print.hpaML'>Print method for &quot;hpaML&quot; object</h2><span id='topic+print.hpaML'></span>

<h3>Description</h3>

<p>Print method for &quot;hpaML&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hpaML_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="print.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='print.hpaSelection'>Print method for &quot;hpaSelection&quot; object</h2><span id='topic+print.hpaSelection'></span>

<h3>Description</h3>

<p>Print method for &quot;hpaSelection&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hpaSelection_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="print.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='print.summary.hpaBinary'>Summary for &quot;hpaBinary&quot; object</h2><span id='topic+print.summary.hpaBinary'></span>

<h3>Description</h3>

<p>Summary for &quot;hpaBinary&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.hpaBinary'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.hpaBinary_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="print.summary.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='print.summary.hpaML'>Summary for hpaML output</h2><span id='topic+print.summary.hpaML'></span>

<h3>Description</h3>

<p>Summary for hpaML output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.hpaML'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.hpaML_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="print.summary.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='print.summary.hpaSelection'>Summary for &quot;hpaSelection&quot; object</h2><span id='topic+print.summary.hpaSelection'></span>

<h3>Description</h3>

<p>Summary for &quot;hpaSelection&quot; object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.hpaSelection'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.hpaSelection_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="print.summary.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='summary_hpaBinary'>Summarizing hpaBinary Fits</h2><span id='topic+summary_hpaBinary'></span>

<h3>Description</h3>

<p>Summarizing hpaBinary Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_hpaBinary(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the same list as 
<code><a href="#topic+hpaBinary">hpaBinary</a></code> function changing 
its class to &quot;summary.hpaBinary&quot;.
</p>

<hr>
<h2 id='summary_hpaML'>Summarizing hpaML Fits</h2><span id='topic+summary_hpaML'></span>

<h3>Description</h3>

<p>Summarizing hpaML Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_hpaML(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the same 
list as <code><a href="#topic+hpaML">hpaML</a></code> function changing 
its class to &quot;summary.hpaML&quot;.
</p>

<hr>
<h2 id='summary_hpaSelection'>Summarizing hpaSelection Fits</h2><span id='topic+summary_hpaSelection'></span>

<h3>Description</h3>

<p>This function summarizing hpaSelection Fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_hpaSelection(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the same list as 
<code><a href="#topic+hpaSelection">hpaSelection</a></code> function changing its class 
to &quot;summary.hpaSelection&quot;.
</p>

<hr>
<h2 id='summary.hpaBinary'>Summarizing hpaBinary Fits</h2><span id='topic+summary.hpaBinary'></span>

<h3>Description</h3>

<p>Summarizing hpaBinary Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="summary.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the same list as <code><a href="#topic+hpaBinary">hpaBinary</a></code> 
function changing its class to &quot;summary.hpaBinary&quot;.
</p>

<hr>
<h2 id='summary.hpaML'>Summarizing hpaML Fits</h2><span id='topic+summary.hpaML'></span>

<h3>Description</h3>

<p>Summarizing hpaML Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="summary.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the same list as <code><a href="#topic+hpaML">hpaML</a></code> 
function changing its class to &quot;summary.hpaML&quot;.
</p>

<hr>
<h2 id='summary.hpaSelection'>Summarizing hpaSelection Fits</h2><span id='topic+summary.hpaSelection'></span>

<h3>Description</h3>

<p>This function summarizing hpaSelection Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="summary.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the same list 
as <code><a href="#topic+hpaSelection">hpaSelection</a></code> 
function changing its class to &quot;summary.hpaSelection&quot;.
</p>

<hr>
<h2 id='truncatedNormalMoment'>Calculate k-th order moment of truncated normal distribution</h2><span id='topic+truncatedNormalMoment'></span>

<h3>Description</h3>

<p>This function recursively calculates k-th order moment of 
truncated normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truncatedNormalMoment(
  k = 1L,
  x_lower = numeric(0),
  x_upper = numeric(0),
  mean = 0,
  sd = 1,
  pdf_lower = numeric(0),
  cdf_lower = numeric(0),
  pdf_upper = numeric(0),
  cdf_upper = numeric(0),
  cdf_difference = numeric(0),
  return_all_moments = FALSE,
  is_validation = TRUE,
  is_parallel = FALSE,
  diff_type = "NO"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="truncatedNormalMoment_+3A_k">k</code></td>
<td>
<p>non-negative integer moment order.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_x_lower">x_lower</code></td>
<td>
<p>numeric vector of lower truncation points.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_x_upper">x_upper</code></td>
<td>
<p>numeric vector of upper truncation points.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_mean">mean</code></td>
<td>
<p>numeric expected value.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_sd">sd</code></td>
<td>
<p>positive numeric standard deviation.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_pdf_lower">pdf_lower</code></td>
<td>
<p>non-negative numeric matrix of precalculated normal
density functions with mean <code>mean</code> and standard deviation <code>sd</code> at
points given by <code>x_lower</code>.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_cdf_lower">cdf_lower</code></td>
<td>
<p>non-negative numeric matrix of 
precalculated normal cumulative distribution functions
with mean <code>mean</code> and standard deviation 
<code>sd</code> at points given by <code>x_lower</code>.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_pdf_upper">pdf_upper</code></td>
<td>
<p>non-negative numeric matrix of precalculated normal
density functions with mean <code>mean</code> and standard deviation <code>sd</code> at
points given by <code>x_upper</code>.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_cdf_upper">cdf_upper</code></td>
<td>
<p>non-negative numeric matrix of
precalculated normal cumulative distribution functions
with mean <code>mean</code> and standard deviation
<code>sd</code> at points given by <code>x_upper</code>.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_cdf_difference">cdf_difference</code></td>
<td>
<p>non-negative numeric matrix of 
precalculated <code>cdf_upper-cdf_lower</code> values.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_return_all_moments">return_all_moments</code></td>
<td>
<p>logical; if <code>TRUE</code>, function returns the 
matrix of moments of normally distributed random variable with 
mean = <code>mean</code> and standard deviation = <code>sd</code> under lower and upper 
truncation points <code>x_lower</code> and <code>x_upper</code> correspondingly. 
Note that element in i-th row and j-th column of this matrix corresponds to 
the i-th observation (j-1)-th order moment.</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_is_validation">is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_is_parallel">is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td></tr>
<tr><td><code id="truncatedNormalMoment_+3A_diff_type">diff_type</code></td>
<td>
<p>string value indicating the type of the argument
the moment should be differentiated respect to.
Default value is <code>"NO"</code> so the moments itself will be returned. 
Alternative values are <code>"mean"</code> and <code>"sd"</code>. Also 
<code>"x_lower"</code> and <code>"x_upper"</code> values are available for 
<code><a href="#topic+truncatedNormalMoment">truncatedNormalMoment</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates <code>k</code>-th order moment of
normal distribution which mean equals to <code>mean</code> and standard deviation 
equals to <code>sd</code> truncated at points given by <code>x_lower</code> and 
<code>x_upper</code>. Note that the function is vectorized so you can provide
<code>x_lower</code> and <code>x_upper</code> as vectors of equal size. If vectors values 
for <code>x_lower</code> and <code>x_upper</code> are not provided then their default 
values will be set to <code>-(.Machine$double.xmin * 0.99)</code> and 
<code>(.Machine$double.xmax * 0.99)</code> correspondingly.
</p>
<p>Note that parameter <code>k</code> value automatically converts 
to integer. So passing non-integer <code>k</code> value will not cause 
any errors but the calculations will be performed for rounded 
<code>k</code> value only.
</p>
<p>If there is precalculated density or cumulative distribution
functions at standardized truncation points (subtract <code>mean</code> 
and then divide by <code>sd</code>) then it is possible to provide
them through <code>pdf_lower</code>, <code>pdf_upper</code>, 
<code>cdf_lower</code> and <code>cdf_upper</code> arguments in
order to decrease number of calculations.
</p>


<h3>Value</h3>

<p>This function returns vector of k-th order moments for normally 
distributed random variable with mean = <code>mean</code> and standard 
deviation = <code>sd</code> under <code>x_lower</code> and <code>x_upper</code> truncation 
points <code>x_lower</code> and <code>x_upper</code> correspondingly. 
If <code>return_all_moments</code> is <code>TRUE</code> then see this argument 
description above for output details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Calculate 5-th order moment of three truncated normal random  
## variables (x1, x2, x3) which mean is 5 and standard deviation is 3. 
## These random variables truncation points are given 
## as follows:-1&lt;x1&lt;1, 0&lt;x2&lt;2, 1&lt;x3&lt;3.
k &lt;- 3
x_lower &lt;- c(-1, 0, 1, -Inf, -Inf)
x_upper &lt;- c(1, 2 , 3, 2, Inf)
mean &lt;- 3
sd &lt;- 5

# get the moments
truncatedNormalMoment(k, x_lower, x_upper, mean, sd)

# get matrix of (0-5)-th moments (columns) for each variable (rows)
truncatedNormalMoment(k, x_lower, x_upper, 
                      mean, sd, 
                      return_all_moments = TRUE)

# get the moments derivatives respect to mean
truncatedNormalMoment(k, x_lower, x_upper, 
                      mean, sd, 
                      diff_type = "mean")

# get the moments derivatives respect to standard deviation
truncatedNormalMoment(k, x_lower, x_upper, 
                      mean, sd, 
                      diff_type = "sd")

</code></pre>

<hr>
<h2 id='vcov.hpaBinary'>Extract covariance matrix from hpaBinary object</h2><span id='topic+vcov.hpaBinary'></span>

<h3>Description</h3>

<p>Extract covariance matrix from hpaBinary object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaBinary'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov.hpaBinary_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaBinary&quot;</p>
</td></tr>
<tr><td><code id="vcov.hpaBinary_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='vcov.hpaML'>Extract covariance matrix from hpaML object</h2><span id='topic+vcov.hpaML'></span>

<h3>Description</h3>

<p>Extract covariance matrix from hpaML object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaML'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov.hpaML_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaML&quot;</p>
</td></tr>
<tr><td><code id="vcov.hpaML_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

<hr>
<h2 id='vcov.hpaSelection'>Extract covariance matrix from hpaSelection object</h2><span id='topic+vcov.hpaSelection'></span>

<h3>Description</h3>

<p>Extract covariance matrix from hpaSelection object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hpaSelection'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov.hpaSelection_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hpaSelection&quot;</p>
</td></tr>
<tr><td><code id="vcov.hpaSelection_+3A_...">...</code></td>
<td>
<p>further arguments (currently ignored)</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
