<!DOCTYPE html><html lang="en"><head><title>Help for package groupdata2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {groupdata2}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#groupdata2-package'><p>groupdata2: A package for creating groups from data</p></a></li>
<li><a href='#+25primes+25'><p>Find remainder from 'primes' method</p></a></li>
<li><a href='#+25staircase+25'><p>Find remainder from 'staircase' method</p></a></li>
<li><a href='#all_groups_identical'><p>Test if two grouping factors contain the same groups</p></a></li>
<li><a href='#balance'><p>Balance groups by up- and downsampling</p></a></li>
<li><a href='#collapse_groups'><p>Collapse groups with categorical, numerical, ID, and size balancing</p></a></li>
<li><a href='#collapse_groups_by'><p>Collapse groups balanced by a single attribute</p></a></li>
<li><a href='#differs_from_previous'><p>Find values in a vector that differ from the previous value</p></a></li>
<li><a href='#downsample'><p>Downsampling of rows in a data frame</p></a></li>
<li><a href='#find_missing_starts'><p>Find start positions that cannot be found in <code>`data`</code></p></a></li>
<li><a href='#find_starts'><p>Find start positions of groups in data</p></a></li>
<li><a href='#fold'><p>Create balanced folds for cross-validation</p></a></li>
<li><a href='#group'><p>Create groups from your data</p></a></li>
<li><a href='#group_factor'><p>Create grouping factor for subsetting your data</p></a></li>
<li><a href='#partition'><p>Create balanced partitions</p></a></li>
<li><a href='#ranked_balances'><p>Extract ranked standard deviations from summary</p></a></li>
<li><a href='#render_toc'><p>Render Table of Contents</p></a></li>
<li><a href='#splt'><p>Split data by a range of methods</p></a></li>
<li><a href='#summarize_balances'><p>Summarize group balances</p></a></li>
<li><a href='#summarize_group_cols'><p>Summarize group columns</p></a></li>
<li><a href='#upsample'><p>Upsampling of rows in a data frame</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Creating Groups from Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for dividing data into groups. 
    Create balanced partitions and cross-validation folds. 
    Perform time series windowing and general grouping and splitting of data. 
    Balance existing groups with up- and downsampling or collapse them to fewer groups.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ludvigolsen/groupdata2">https://github.com/ludvigolsen/groupdata2</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ludvigolsen/groupdata2/issues">https://github.com/ludvigolsen/groupdata2/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate (&ge; 2.0.0), dplyr (&ge; 0.8.4), numbers (&ge; 0.7-5),
lifecycle, plyr (&ge; 1.8.5), purrr, rearrr (&ge; 0.3.0), rlang (&ge;
0.4.4), stats, tibble (&ge; 2.1.3), tidyr, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>broom, covr, ggplot2, knitr, lmerTest, rmarkdown, testthat,
xpectr (&ge; 0.4.1)</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>lifecycle</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-12-18 16:37:32 UTC; au547627</td>
</tr>
<tr>
<td>Author:</td>
<td>Ludvig Renbo Olsen
    <a href="https://orcid.org/0009-0006-6798-7454"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ludvig Renbo Olsen &lt;r-pkgs@ludvigolsen.dk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-18 17:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='groupdata2-package'>groupdata2: A package for creating groups from data</h2><span id='topic+groupdata2'></span><span id='topic+groupdata2-package'></span>

<h3>Description</h3>

<p>Methods for dividing data into groups.
Create balanced partitions and cross-validation folds.
Perform time series windowing and general grouping and splitting of data.
Balance existing groups with up- and downsampling.
</p>


<h3>Details</h3>

<p>The <code>groupdata2</code> package provides six main functions:
<code>group()</code>, <code>group_factor()</code>, <code>splt()</code>, <code>partition()</code>,
<code>fold()</code>, and <code>balance()</code>.
</p>


<h3>group</h3>

<p>Create groups from your data.
</p>
<p>Divides data into groups by a wide range of methods.
Creates a grouping factor with <code>1</code>s for group 1, <code>2</code>s for group 2, etc.
Returns a <code>data.frame</code> grouped by the grouping factor
for easy use in <code>magrittr</code> pipelines.
</p>
<p>Go to <code><a href="#topic+group">group</a>()</code>
</p>


<h3>group_factor</h3>

<p>Create grouping factor for subsetting your data.
</p>
<p>Divides data into groups by a wide range of methods.
Creates and returns a grouping factor
with <code>1</code>s for group 1, <code>2</code>s for group 2, etc.
</p>
<p>Go to <code><a href="#topic+group_factor">group_factor</a>()</code>
</p>


<h3>splt</h3>

<p>Split data by a wide range of methods.
</p>
<p>Divides data into groups by a wide range of methods.
Splits data by these groups.
</p>
<p>Go to <code><a href="#topic+splt">splt</a>()</code>
</p>


<h3>partition</h3>

<p>Create balanced partitions (e.g. training/test sets).
</p>
<p>Splits data into partitions.
Balances a given categorical variable between partitions
and keeps (if possible) all data points with a shared ID
(e.g. participant_id) in the same partition.
</p>
<p>Go to <code><a href="#topic+partition">partition</a>()</code>
</p>


<h3>fold</h3>

<p>Create balanced folds for cross-validation.
</p>
<p>Divides data into groups (folds) by a wide range of methods.
Balances a given categorical variable between folds and keeps (if possible)
all data points with the same ID (e.g. participant_id) in the same fold.
</p>
<p>Go to <code><a href="#topic+fold">fold</a>()</code>
</p>


<h3>balance</h3>

<p>Balance the sizes of your groups with up- and downsampling.
</p>
<p>Uses up- and/or downsampling to fix the group sizes to the
<code>min</code>, <code>max</code>, <code>mean</code>, or <code>median</code> group size or
to a specific number of rows. Has a set of methods for balancing on
ID level.
</p>
<p>Go to <code><a href="#topic+balance">balance</a>()</code>
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/ludvigolsen/groupdata2">https://github.com/ludvigolsen/groupdata2</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ludvigolsen/groupdata2/issues">https://github.com/ludvigolsen/groupdata2/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25primes+25'>Find remainder from 'primes' method</h2><span id='topic++25primes+25'></span><span id='topic+primes'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>When using the <code>"primes"</code> method,
the last group might not have the size of the associated prime number
if there are not enough elements left. Use <code>%primes%</code> to find this remainder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size %primes% start_at
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25primes+2B25_+3A_size">size</code></td>
<td>
<p>Size to group (Integer)</p>
</td></tr>
<tr><td><code id="+2B25primes+2B25_+3A_start_at">start_at</code></td>
<td>
<p>Prime to start at (Integer)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Remainder (Integer).
Returns <code>0</code> if the last group
has the size of the associated prime number.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other staircase tools: 
<code><a href="#topic++25staircase+25">%staircase%</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>
<p>Other remainder tools: 
<code><a href="#topic++25staircase+25">%staircase%</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

100 %primes% 2
</code></pre>

<hr>
<h2 id='+25staircase+25'>Find remainder from 'staircase' method</h2><span id='topic++25staircase+25'></span><span id='topic+staircase'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>When using the <code>"staircase"</code> method,
the last group might not have the size of the second last
group + step size. Use <code>%staircase%</code> to find this remainder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size %staircase% step_size
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25staircase+2B25_+3A_size">size</code></td>
<td>
<p>Size to staircase (Integer)</p>
</td></tr>
<tr><td><code id="+2B25staircase+2B25_+3A_step_size">step_size</code></td>
<td>
<p>Step size (Integer)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Remainder (Integer).
Returns <code>0</code> if the last group has the size of the second last group + step size.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other staircase tools: 
<code><a href="#topic++25primes+25">%primes%</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>
<p>Other remainder tools: 
<code><a href="#topic++25primes+25">%primes%</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

100 %staircase% 2

# Finding remainder with value 0
size = 150
for (step_size in c(1:30)){
 if(size %staircase% step_size == 0){
   print(step_size)
 }}

</code></pre>

<hr>
<h2 id='all_groups_identical'>Test if two grouping factors contain the same groups</h2><span id='topic+all_groups_identical'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Checks whether two grouping factors contain the same groups,
looking only at the group members, allowing for different group names / identifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>all_groups_identical(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="all_groups_identical_+3A_x">x</code>, <code id="all_groups_identical_+3A_y">y</code></td>
<td>
<p>Two grouping factors (<code>vector</code>s/<code>factor</code>s with group identifiers) to compare.
</p>
<p><strong>N.B.</strong> Both are converted to <code>character vectors</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both factors are sorted by <code>`x`</code>.
A grouping factor is created with new groups starting at the values in
<code>`y`</code> which differ from the previous row
(i.e. <code><a href="#topic+group">group</a>()</code> with <code>method = "l_starts"</code> and <code>n = "auto"</code>).
A similar grouping factor is created for <code>`x`</code>,
to have group identifiers range from <code>1</code> to the number of groups.
The two generated grouping factors are tested for equality.
</p>


<h3>Value</h3>

<p>Whether <strong>all</strong> groups in <code>`x`</code> are the same in <code>`y`</code>, <em>memberwise</em>. (logical)
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other grouping functions: 
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach groupdata2
library(groupdata2)

# Same groups, different identifiers
x1 &lt;- c(1, 1, 2, 2, 3, 3)
x2 &lt;- c(2, 2, 1, 1, 4, 4)
all_groups_identical(x1, x2) # TRUE

# Same groups, different identifier types
x1 &lt;- c(1, 1, 2, 2, 3, 3)
x2 &lt;- c("a", "a", "b", "b", "c", "c")
all_groups_identical(x1, x2) # TRUE

# Not same groups
# Note that all groups must be the same to return TRUE
x1 &lt;- c(1, 1, 2, 2, 3, 3)
x2 &lt;- c(1, 2, 2, 3, 3, 3)
all_groups_identical(x1, x2) # FALSE

# Different number of groups
x1 &lt;- c(1, 1, 2, 2, 3, 3)
x2 &lt;- c(1, 1, 1, 2, 2, 2)
all_groups_identical(x1, x2) # FALSE
</code></pre>

<hr>
<h2 id='balance'>Balance groups by up- and downsampling</h2><span id='topic+balance'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Uses up- and/or downsampling to fix the group sizes to the
<code>min</code>, <code>max</code>, <code>mean</code>, or <code>median</code> group size or
to a specific number of rows. Has a range of methods for balancing on
ID level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>balance(
  data,
  size,
  cat_col,
  id_col = NULL,
  id_method = "n_ids",
  mark_new_rows = FALSE,
  new_rows_col_name = ".new_row"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="balance_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="balance_+3A_size">size</code></td>
<td>
<p>Size to fix group sizes to.
Can be a specific number, given as a whole number, or one of the following strings:
<code>"min"</code>, <code>"max"</code>, <code>"mean"</code>, <code>"median"</code>.
</p>


<h4>number</h4>

<p>Fix each group to have the size of the specified number of row.
Uses downsampling for groups with too many rows and upsampling for groups with too few rows.
</p>



<h4>min</h4>

<p>Fix each group to have the size of smallest group in the dataset.
Uses downsampling on all groups that have too many rows.
</p>



<h4>max</h4>

<p>Fix each group to have the size of largest group in the dataset.
Uses upsampling on all groups that have too few rows.
</p>



<h4>mean</h4>

<p>Fix each group to have the mean group size in the dataset. The mean is rounded.
Uses downsampling for groups with too many rows and upsampling for groups with too few rows.
</p>



<h4>median</h4>

<p>Fix each group to have the median group size in the dataset. The median is rounded.
Uses downsampling for groups with too many rows and upsampling for groups with too few rows.
</p>
</td></tr>
<tr><td><code id="balance_+3A_cat_col">cat_col</code></td>
<td>
<p>Name of categorical variable to balance by. (Character)</p>
</td></tr>
<tr><td><code id="balance_+3A_id_col">id_col</code></td>
<td>
<p>Name of factor with IDs. (Character)
</p>
<p>IDs are considered entities, e.g. allowing us to add or remove all rows for an ID.
How this is used is up to the <code>`id_method`</code>.
</p>
<p>E.g. If we have measured a participant multiple times and
want make sure that we keep all these measurements. Then we would either
remove/add all measurements for the participant or leave in
all measurements for the participant.
</p>
<p>N.B. When <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>
(see <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>), IDs that appear in multiple
groupings are considered separate entities within those groupings.</p>
</td></tr>
<tr><td><code id="balance_+3A_id_method">id_method</code></td>
<td>
<p>Method for balancing the IDs. (Character)
</p>
<p><code>"n_ids"</code>, <code>"n_rows_c"</code>, <code>"distributed"</code>, or <code>"nested"</code>.
</p>


<h4>n_ids (default)</h4>

<p>Balances on ID level only. It makes sure there are the same number of IDs for each category.
This might lead to a different number of rows between categories.
</p>



<h4>n_rows_c</h4>

<p>Attempts to level the number of rows per category, while only removing/adding entire IDs.
This is done in 2 steps:
</p>

<ol>
<li><p> If a category needs to add all its rows one or more times, the data is repeated.
</p>
</li>
<li><p> Iteratively, the ID with the number of rows closest to the
lacking/excessive number of rows is added/removed.
This happens until adding/removing the closest ID would lead to a size further from
the target size than the current size.
If multiple IDs are closest, one is randomly sampled.
</p>
</li></ol>




<h4>distributed</h4>

<p>Distributes the lacking/excess rows equally between the IDs.
If the number to distribute can not be equally divided, some IDs will have 1 row more/less than the others.
</p>



<h4>nested</h4>

<p>Calls <code>balance()</code> on each category with IDs as cat_col.
</p>
<p>I.e. if size is <code>"min"</code>, IDs will have the size of the smallest ID in their category.
</p>
</td></tr>
<tr><td><code id="balance_+3A_mark_new_rows">mark_new_rows</code></td>
<td>
<p>Add column with <code>1</code>s for added rows, and <code>0</code>s for original rows. (Logical)</p>
</td></tr>
<tr><td><code id="balance_+3A_new_rows_col_name">new_rows_col_name</code></td>
<td>
<p>Name of column marking new rows. Defaults to <code>".new_row"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Without <code>`id_col`</code></h4>

<p>Upsampling is done with replacement for added rows,
while the original data remains intact.
Downsampling is done without replacement, meaning that rows are not duplicated but only removed.</p>



<h4>With <code>`id_col`</code></h4>

<p>See <code>`id_method`</code> description.</p>



<h3>Value</h3>

<p><code>data.frame</code> with added and/or deleted rows.
Ordered by potential grouping variables, <code>`cat_col`</code> and (potentially) <code>`id_col`</code>.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other sampling functions: 
<code><a href="#topic+downsample">downsample</a>()</code>,
<code><a href="#topic+upsample">upsample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create data frame
df &lt;- data.frame(
  "participant" = factor(c(1, 1, 2, 3, 3, 3, 3, 4, 4, 5, 5, 5, 5)),
  "diagnosis" = factor(c(0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0)),
  "trial" = c(1, 2, 1, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4),
  "score" = sample(c(1:100), 13)
)

# Using balance() with specific number of rows
balance(df, 3, cat_col = "diagnosis")

# Using balance() with min
balance(df, "min", cat_col = "diagnosis")

# Using balance() with max
balance(df, "max", cat_col = "diagnosis")

# Using balance() with id_method "n_ids"
# With column specifying added rows
balance(df, "max",
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "n_ids",
  mark_new_rows = TRUE
)

# Using balance() with id_method "n_rows_c"
# With column specifying added rows
balance(df, "max",
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "n_rows_c",
  mark_new_rows = TRUE
)

# Using balance() with id_method "distributed"
# With column specifying added rows
balance(df, "max",
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "distributed",
  mark_new_rows = TRUE
)

# Using balance() with id_method "nested"
# With column specifying added rows
balance(df, "max",
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "nested",
  mark_new_rows = TRUE
)
</code></pre>

<hr>
<h2 id='collapse_groups'>Collapse groups with categorical, numerical, ID, and size balancing</h2><span id='topic+collapse_groups'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>Collapses a set of groups into a smaller set of groups.
</p>
<p><em>Attempts</em> to balance the new groups by specified numerical columns,
categorical columns,
level counts in ID columns,
and/or the number of rows (size).
</p>
<p><strong>Note</strong>: The more of these you balance at a time,
the less balanced each of them may become. While, <em>on average</em>,
the balancing work better than without, this is
<strong>not guaranteed on every run</strong>. Enabling <code>`auto_tune`</code> can yield a
much better overall balance than without in most contexts.
This generates a larger set of group columns using all combinations of the
balancing columns and selects the most balanced group column(s).
This is slower and we recommend enabling parallelization (see <code>`parallel`</code>).
</p>
<p>While this balancing algorithm will not be <em>optimal</em> in all cases,
it allows balancing a <strong>large</strong> number of columns at once. Especially
with auto-tuning enabled, this can be very powerful.
</p>
<p><strong>Tip</strong>: Check the balances of the new groups with
<code><a href="#topic+summarize_balances">summarize_balances()</a></code> and
<code><a href="#topic+ranked_balances">ranked_balances()</a></code>.
</p>
<p><strong>Note</strong>: The categorical and ID balancing algorithms are different to those
in <code><a href="#topic+fold">fold()</a></code> and
<code><a href="#topic+partition">partition()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapse_groups(
  data,
  n,
  group_cols,
  cat_cols = NULL,
  cat_levels = NULL,
  num_cols = NULL,
  id_cols = NULL,
  balance_size = TRUE,
  auto_tune = FALSE,
  weights = NULL,
  method = "balance",
  group_aggregation_fn = mean,
  num_new_group_cols = 1,
  unique_new_group_cols_only = TRUE,
  max_iters = 5,
  extreme_pairing_levels = 1,
  combine_method = "avg_standardized",
  col_name = ".coll_groups",
  parallel = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collapse_groups_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_n">n</code></td>
<td>
<p>Number of new groups.
</p>
<p>When <code>`num_new_group_cols` &gt; 1</code>, <code>`n`</code> can also be a vector
with one <code>`n`</code> per new group column. This allows trying multiple <code>`n`</code>
settings at a time. Note that the generated group columns are not guaranteed
to be in the order of <code>`n`</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_group_cols">group_cols</code></td>
<td>
<p>Names of factors in <code>`data`</code> for identifying the <em>existing</em> groups
that should be collapsed.
</p>
<p>Multiple names are treated as in <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>
(i.e., a hierarchy of groups), where each leaf group within each parent group is
considered a unique group to be collapsed.
Parent groups are not considered during collapsing, why leaf groups from different
parent groups can be collapsed together.
</p>
<p><strong>Note</strong>: Do not confuse these group columns with potential columns that <code>`data`</code> is grouped by.
<code>`group_cols`</code> identifies the groups to be collapsed. When <code>`data`</code> is
grouped with <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>, the function is
applied separately to each of those subsets.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_cat_cols">cat_cols</code></td>
<td>
<p>Names of categorical columns to balance the average frequency
of one or more levels of.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_cat_levels">cat_levels</code></td>
<td>
<p>Names of the levels in the <code>`cat_cols`</code> columns to balance the average frequencies
of. When <code>`NULL`</code> (default), all levels are balanced.
Can be weights indicating the balancing importance of each level (within each column).
</p>
<p>The weights are automatically scaled to sum to <code>1</code>.
</p>
<p>Can be <code>".minority"</code> or <code>".majority"</code>, in which case the minority/majority level
are found and used.
</p>


<h4>When <code>`cat_cols`</code> has single column name:</h4>

<p>Either a <code>vector</code> with level names or a named <code>numeric vector</code> with weights:
</p>
<p>E.g. <code>c("dog", "pidgeon", "mouse")</code> or <code>c("dog" = 5, "pidgeon" = 1, "mouse" = 3)</code>
</p>



<h4>When <code>`cat_cols`</code> has multiple column names:</h4>

<p>A named <code>list</code> with <code>vector</code>s for each column name in <code>`cat_cols`</code>.
When not providing a <code>vector</code> for a <code>`cat_cols`</code>
column, all levels are balanced in that column.
</p>
<p>E.g. <code>list("col1" = c("dog" = 5, "pidgeon" = 1, "mouse" = 3),
 "col2" = c("hydrated", "dehydrated"))</code>.
</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_num_cols">num_cols</code></td>
<td>
<p>Names of numerical columns to balance between groups.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_id_cols">id_cols</code></td>
<td>
<p>Names of factor columns with IDs to balance the counts of between groups.
</p>
<p>E.g. useful to get a similar number of participants in each group.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_balance_size">balance_size</code></td>
<td>
<p>Whether to balance the size of the collapsed groups. (logical)</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_auto_tune">auto_tune</code></td>
<td>
<p>Whether to create a larger set of collapsed group columns
from all combinations of the balancing dimensions and select the
overall most balanced group column(s).
</p>
<p>This tends to create much more balanced collapsed group columns.
</p>
<p>Can be slow, why we recommend enabling parallelization (see <code>`parallel`</code>).</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_weights">weights</code></td>
<td>
<p>Named <code>vector</code> with balancing importance weights for each of
the balancing columns. Besides the columns in <code>`cat_cols`</code>, <code>`num_cols`</code>, and <code>`id_cols`</code>,
the <em>size</em> balancing weight can be given as <code>"size"</code>.
</p>
<p>The weights are automatically scaled to sum to <code>1</code>.
</p>
<p>Dimensions that are <em>not</em> given a weight is automatically given the weight <code>1</code>.
</p>
<p>E.g. <code>c("size" = 1, "cat" = 1, "num1" = 4, "num2" = 7, "id" = 2)</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_method">method</code></td>
<td>
<p><code>"balance"</code>, <code>"ascending"</code>, or <code>"descending"</code>:
</p>
<p>After calculating a <em>combined balancing column</em> from each of the balancing columns (see <code>Details &gt;&gt; Balancing columns</code>):
</p>

<ul>
<li> <p><code>"balance"</code> balances the combined balancing column between the groups.
</p>
</li>
<li> <p><code>"ascending"</code> orders the combined balancing column and groups from the lowest to highest value.
</p>
</li>
<li> <p><code>"descending"</code> orders the combined balancing column and groups from the highest to lowest value.
</p>
</li></ul>
</td></tr>
<tr><td><code id="collapse_groups_+3A_group_aggregation_fn">group_aggregation_fn</code></td>
<td>
<p>Function for aggregating values in the <code>`num_cols`</code> columns
for each group in <code>`group_cols`</code>.
</p>
<p>Default is <code>mean()</code>, where the average value(s) are balanced across the new groups.
</p>
<p>When using <code>sum()</code>, the groups will have similar sums across the new groups.
</p>
<p><strong>N.B.</strong> Only used when <code>`num_cols`</code> is specified.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_num_new_group_cols">num_new_group_cols</code></td>
<td>
<p>Number of group columns to create.
</p>
<p>When <code>`num_new_group_cols` &gt; 1</code>, columns are named
with a combination of <code>`col_name`</code> and <code>"_1"</code>, <code>"_2"</code>, etc.
E.g. <code class="reqn">".coll_groups_1"</code>, <code class="reqn">".coll_groups_2"</code>, ...
</p>
<p><strong>N.B.</strong> When <code>`unique_new_group_cols_only`</code> is <code>`TRUE`</code>,
we may end up with fewer columns than specified, see <code>`max_iters`</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_unique_new_group_cols_only">unique_new_group_cols_only</code></td>
<td>
<p>Whether to only return unique new group columns.
</p>
<p>As the number of column comparisons can be quite time consuming,
we recommend enabling parallelization. See <code>`parallel`</code>.
</p>
<p><strong>N.B.</strong> We can end up with fewer columns than specified in
<code>`num_new_group_cols`</code>, see <code>`max_iters`</code>.
</p>
<p><strong>N.B.</strong> Only used when <code>`num_new_group_cols` &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_max_iters">max_iters</code></td>
<td>
<p>Maximum number of attempts at reaching
<code>`num_new_group_cols`</code> <em>unique</em> new group columns.
</p>
<p>When only keeping unique new group columns, we risk having fewer columns than expected.
Hence, we repeatedly create the missing columns and remove those that are not unique.
This is done until we have <code>`num_new_group_cols`</code> unique group columns
or we have attempted <code>`max_iters`</code> times.
</p>
<p>In some cases, it is not possible to create <code>`num_new_group_cols`</code>
unique combinations of the dataset.
<code>`max_iters`</code> specifies when to stop trying.
Note that we can end up with fewer columns than specified in <code>`num_new_group_cols`</code>.
</p>
<p><strong>N.B.</strong> Only used when <code>`num_new_group_cols` &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_extreme_pairing_levels">extreme_pairing_levels</code></td>
<td>
<p>How many levels of extreme pairing to do
when balancing the groups by the combined balancing column (see <code>Details</code>).
</p>
<p><strong>Extreme pairing</strong>: Rows/pairs are ordered as smallest, largest,
second smallest, second largest, etc. If <code>extreme_pairing_levels &gt; 1</code>,
this is done &quot;recursively&quot; on the extreme pairs.
</p>
<p><strong>N.B.</strong> Larger values work best with large datasets. If set too high,
the result might not be stochastic. Always check if an increase
actually makes the groups more balanced.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_combine_method">combine_method</code></td>
<td>
<p>Method to combine the balancing columns by.
One of <code>"avg_standardized"</code> or <code>"avg_min_max_scaled"</code>.
</p>
<p>For each balancing column (all columns in <em><code>num_cols</code></em>, <em><code>cat_cols</code></em>,
and <em><code>id_cols</code></em>, plus <em>size</em>), we calculate a normalized, numeric group summary column, which indicates the
&quot;size&quot; of each group in that dimension. These are then combined to a single
<em>combined balancing column</em>.
</p>
<p>The three steps are:
</p>

<ol>
<li><p> Calculate a numeric representation of the balance for each column.
E.g. the number of unique levels within each group of an ID column
(see <code>Details &gt; Balancing columns</code> for more on this).
</p>
</li>
<li><p> Normalize each column separately with standardization (<code>"avg_standardized"</code>; Default) or MinMax scaling
to the [0, 1] range (<code>"avg_min_max_scaled"</code>).
</p>
</li>
<li><p> Average the columns <em>rowwise</em> to get a single column with one value per group. The averaging
is weighted by <code>`weights`</code>, which is useful when one of the dimensions is
more important to get a good balance of.
</p>
</li></ol>

<p><code>`combine_method`</code> chooses whether to use standardization or MinMax scaling in step 2.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_col_name">col_name</code></td>
<td>
<p>Name of the new group column. When creating multiple new group columns
(<code>`num_new_group_cols`&gt;1</code>), this is the prefix for the names, which will
be suffixed with an underscore and a number (_1, _2, _3, etc.).</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_parallel">parallel</code></td>
<td>
<p>Whether to parallelize the group column comparisons
when <code>`unique_new_group_cols_only`</code> is <code>`TRUE`</code>.
</p>
<p>Especially highly recommended when <code>`auto_tune`</code> is enabled.
</p>
<p>Requires a registered parallel backend.
Like <code>doParallel::registerDoParallel</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_+3A_verbose">verbose</code></td>
<td>
<p>Whether to print information about the process.
May make the function slightly slower.
</p>
<p>N.B. Currently only used during auto-tuning.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The goal of <code>collapse_groups()</code> is to combine existing groups
to a lower number of groups while (optionally) balancing one or more
<em>numeric</em>, <em>categorical</em> and/or <em>ID</em> columns, along with the group
<em>size</em>.
</p>
<p>For each of these columns (and size), we calculate a normalized, numeric <em>&quot;balancing column&quot;</em>
that when balanced between the groups lead to its original column being balanced as well.
</p>
<p>To balance multiple columns at once, we combine their balancing columns with
weighted averaging (see <code>`combine_method`</code> and <code>`weights`</code>) to a single
<em>combined balancing column</em>.
</p>
<p>Finally, we create groups where this combined balancing column is balanced between the groups,
using the numerical balancing in <code><a href="#topic+fold">fold()</a></code>.
</p>


<h4>Auto-tuning</h4>

<p>This strategy is not guaranteed to produce balanced groups in all contexts,
e.g. when the balancing columns cancel out. To increase the probability of
balanced groups, we can produce multiple group columns with all combinations
of the balancing columns and select the overall most balanced group column(s).
We refer to this as auto-tuning (see <code>`auto_tune`</code>).
</p>
<p>We find the overall most balanced group column by ranking the across-group
standard deviations for each of the balancing columns, as found with
<code><a href="#topic+summarize_balances">summarize_balances()</a></code>.
</p>
<p><strong>Example</strong> of finding the overall most balanced group column(s):
</p>
<p>Given a group column with the following average <em>age</em> per group: <code>`c(16, 18, 25, 21)`</code>,
the standard deviation hereof (<code>3.92</code>) is a measure of how balanced the <em>age</em>
column is. Another group column can thus have a lower/higher standard deviation
and be considered more/less balanced.
</p>
<p>We find the rankings of these standard deviations for all the balancing columns
and average them (again weighted by <code>`weights`</code>). We select the group column(s) with the,
on average, highest rank (i.e. lowest standard deviations).
</p>


<h4>Checking balances</h4>

<p>We highly recommend using
<code><a href="#topic+summarize_balances">summarize_balances()</a></code>
and <code><a href="#topic+ranked_balances">ranked_balances()</a></code> to
check how balanced the created groups are on the various dimensions.
When applying <code><a href="#topic+ranked_balances">ranked_balances()</a></code>
to the output of <code><a href="#topic+summarize_balances">summarize_balances()</a></code>,
we get a <code>data.frame</code> with the standard deviations
for each balancing dimension (lower means more balanced),
ordered by the average rank (see <code>Examples</code>).
</p>


<h4>Balancing columns</h4>

<p>The following describes the creation of the balancing columns
for each of the supported column types:
</p>


<h5>cat_cols</h5>

<p>For each column in <code>`cat_cols`</code>:
</p>

<ul>
<li> <p><strong>Count each level</strong> within each group. This creates a <code>data.frame</code> with
one count column per level, with one row per group.
</p>
</li>
<li> <p><strong>Standardize</strong> the count columns.
</p>
</li>
<li> <p><strong>Average</strong> the standardized counts rowwise to create one combined column representing
the balance of the levels for each group. When <code>cat_levels</code> contains weights for each of the levels,
we apply weighted averaging.
</p>
</li></ul>

<p><strong>Example</strong>: Consider a factor column with the levels <code>c("A", "B", "C")</code>.
We count each level per group, <strong>n</strong>ormalize the counts and combine them with weighted averaging:
</p>

<table>
<tr>
 <td style="text-align: right;">
<strong>Group</strong> </td><td style="text-align: right;"> <strong>A</strong> </td><td style="text-align: right;">
<strong>B</strong> </td><td style="text-align: right;"> <strong>C</strong> </td><td style="text-align: right;">
<strong> -&gt; </strong> </td><td style="text-align: right;"> <strong>nA</strong> </td><td style="text-align: right;">
<strong>nB</strong> </td><td style="text-align: right;"> <strong>nC</strong> </td><td style="text-align: right;">
<strong> -&gt; </strong> </td><td style="text-align: right;"> <strong>Combined</strong></td>
</tr>
<tr>
 <td style="text-align: right;">
1 </td><td style="text-align: right;"> 5 </td><td style="text-align: right;"> 57 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.24 </td><td style="text-align: right;"> 0.55 </td><td style="text-align: right;"> -0.77 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.007  </td>
</tr>
<tr>
 <td style="text-align: right;">
2 </td><td style="text-align: right;"> 7 </td><td style="text-align: right;"> 69 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.93 </td><td style="text-align: right;"> 0.64 </td><td style="text-align: right;"> -0.77 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.267 </td>
</tr>
<tr>
 <td style="text-align: right;">
3 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 34 </td><td style="text-align: right;"> 14</td><td style="text-align: right;"> | </td><td style="text-align: right;"> -1.42</td><td style="text-align: right;"> 0.29 </td><td style="text-align: right;"> 1.34  </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.07 </td>
</tr>
<tr>
 <td style="text-align: right;">
4 </td><td style="text-align: right;"> 5 </td><td style="text-align: right;"> 0 </td><td style="text-align: right;"> 4  </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.24 </td><td style="text-align: right;"> -1.48</td><td style="text-align: right;"> 0.19  </td><td style="text-align: right;"> | </td><td style="text-align: right;"> -0.35 </td>
</tr>
<tr>
 <td style="text-align: right;">
... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> | </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> | </td><td style="text-align: right;"> ... </td>
</tr>

</table>




<h5>id_cols</h5>

<p>For each column in <code>`id_cols`</code>:
</p>

<ul>
<li> <p><strong>Count</strong> the unique IDs (levels) within each group.
(Note: The same ID can be counted in multiple groups.)
</p>
</li></ul>




<h5>num_cols</h5>

<p>For each column in <code>`num_cols`</code>:
</p>

<ul>
<li> <p><strong>Aggregate</strong> the numeric columns by group using the <code>`group_aggregation_fn`</code>.
</p>
</li></ul>




<h5>size</h5>


<ul>
<li> <p><strong>Count</strong> the number of rows per group.
</p>
</li></ul>




<h5>Combining balancing columns</h5>


<ul>
<li><p> Apply standardization or MinMax scaling to each of the balancing columns (see <code>`combine_method`</code>).
</p>
</li>
<li><p> Perform weighted averaging to get a single balancing column (see <code>`weights`</code>).
</p>
</li></ul>

<p><strong>Example</strong>: We apply standardization and perform weighted averaging:
</p>

<table>
<tr>
 <td style="text-align: right;">
<strong>Group</strong> </td><td style="text-align: right;"> <strong>Size</strong> </td><td style="text-align: right;">
<strong>Num</strong> </td><td style="text-align: right;"> <strong>Cat</strong> </td><td style="text-align: right;">
<strong>ID</strong> </td><td style="text-align: right;"> <strong>-&gt;</strong> </td><td style="text-align: right;">
<strong>nSize</strong> </td><td style="text-align: right;"> <strong>nNum</strong>
</td><td style="text-align: right;"> <strong>nCat</strong> </td><td style="text-align: right;"> <strong>nID</strong> </td><td style="text-align: right;">
<strong>-&gt;</strong> </td><td style="text-align: right;"> <strong>Combined</strong></td>
</tr>
<tr>
 <td style="text-align: right;">
1 </td><td style="text-align: right;"> 34 </td><td style="text-align: right;"> 1.3 </td><td style="text-align: right;"> 0.007 </td><td style="text-align: right;"> 3 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> -0.33 </td><td style="text-align: right;"> -0.82 </td><td style="text-align: right;"> 0.03 </td><td style="text-align: right;"> -0.46</td><td style="text-align: right;"> | </td><td style="text-align: right;"> -0.395  </td>
</tr>
<tr>
 <td style="text-align: right;">
2 </td><td style="text-align: right;"> 23 </td><td style="text-align: right;"> 4.6 </td><td style="text-align: right;"> 0.267 </td><td style="text-align: right;"> 4 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> -1.12 </td><td style="text-align: right;"> 0.34  </td><td style="text-align: right;"> 1.04 </td><td style="text-align: right;"> 0.0  </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.065 </td>
</tr>
<tr>
 <td style="text-align: right;">
3 </td><td style="text-align: right;"> 56 </td><td style="text-align: right;"> 7.2 </td><td style="text-align: right;"> 0.07  </td><td style="text-align: right;"> 7 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 1.27  </td><td style="text-align: right;"> 1.26  </td><td style="text-align: right;"> 0.28 </td><td style="text-align: right;"> 1.39 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 1.05 </td>
</tr>
<tr>
 <td style="text-align: right;">
4 </td><td style="text-align: right;"> 41 </td><td style="text-align: right;"> 1.4 </td><td style="text-align: right;"> -0.35 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 0.18  </td><td style="text-align: right;"> -0.79 </td><td style="text-align: right;"> -1.35</td><td style="text-align: right;"> -0.93</td><td style="text-align: right;"> | </td><td style="text-align: right;"> -0.723 </td>
</tr>
<tr>
 <td style="text-align: right;">
... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> |
</td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> | </td><td style="text-align: right;"> ... </td>
</tr>

</table>




<h4>Creating the groups</h4>

<p>Finally, we get to the group creation. There are three methods for creating groups based on the
combined balancing column: <code>"balance"</code> (default), <code>"ascending"</code>, and <code>"descending"</code>.
</p>


<h5><code>method</code> is &quot;balance&quot;</h5>

<p>To create groups that are balanced by the combined balancing column, we use the numerical balancing
in <code><a href="#topic+fold">fold()</a></code>.
</p>
<p>The following describes the numerical balancing in broad terms:
</p>

<ol>
<li><p> Rows are shuffled.
<strong>Note</strong> that this will only affect rows with the same value in the combined balancing column.
</p>
</li>
<li><p> Extreme pairing 1: Rows are ordered as <em>smallest, largest, second smallest, second largest</em>, etc.
Each small+large pair get an <em>extreme-group</em> identifier. (See <code><a href="rearrr.html#topic+pair_extremes">rearrr::pair_extremes()</a></code>)
</p>
</li>
<li><p> If <code>`extreme_pairing_levels` &gt; 1</code>: These extreme-group identifiers are reordered as <em>smallest,
largest, second smallest, second largest</em>, etc., by the <code>sum</code> of the combined balancing column in the represented rows.
These pairs (of pairs) get a new set of extreme-group identifiers, and the process is repeated
<code>`extreme_pairing_levels`-2</code> times. Note that the extreme-group identifiers at the last level will represent
<code>2^`extreme_pairing_levels`</code> rows, why you should be careful when choosing a larger setting.
</p>
</li>
<li><p> The extreme-group identifiers from the last pairing are randomly divided into the final groups
and these final identifiers are transferred to the original rows.
</p>
</li></ol>

<p><strong>N.B.</strong> When doing extreme pairing of an unequal number of rows,
the row with the smallest value is placed in a group by itself, and the order is instead:
(smallest), <em>(second smallest, largest), (third smallest, second largest)</em>, etc.
</p>
<p>A similar approach with <em>extreme triplets</em> (i.e. smallest, closest to median, largest,
second smallest, second closest to median, second largest, etc.) may also be utilized in some scenarios.
(See <code><a href="rearrr.html#topic+triplet_extremes">rearrr::triplet_extremes()</a></code>)
</p>
<p><strong>Example</strong>: We order the <code>data.frame</code> by smallest <em>&quot;Num&quot;</em> value,
largest <em>&quot;Num&quot;</em> value, second smallest, and so on.
We <em>could</em> further (when <code>`extreme_pairing_levels` &gt; 1</code>)
find the sum of <em>&quot;Num&quot;</em> for each pair and perform extreme pairing on the pairs.
Finally, we group the <code>data.frame</code>:
</p>

<table>
<tr>
 <td style="text-align: right;">
<strong>Group</strong> </td><td style="text-align: right;"> <strong>Num</strong> </td><td style="text-align: right;">
<strong>-&gt;</strong> </td><td style="text-align: right;">
<strong>Group</strong> </td><td style="text-align: right;"> <strong>Num</strong> </td><td style="text-align: right;">
<strong>Pair</strong> </td><td style="text-align: right;"> <strong>-&gt;</strong> </td><td style="text-align: right;">
<strong>New group</strong></td>
</tr>
<tr>
 <td style="text-align: right;">
1 </td><td style="text-align: right;"> -0.395</td><td style="text-align: right;"> | </td><td style="text-align: right;"> 5 </td><td style="text-align: right;"> -1.23 </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 3 </td>
</tr>
<tr>
 <td style="text-align: right;">
2 </td><td style="text-align: right;"> 0.065 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 3 </td><td style="text-align: right;"> 1.05  </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 3 </td>
</tr>
<tr>
 <td style="text-align: right;">
3 </td><td style="text-align: right;"> 1.05  </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 4 </td><td style="text-align: right;"> -0.723</td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 1 </td>
</tr>
<tr>
 <td style="text-align: right;">
4 </td><td style="text-align: right;"> -0.723</td><td style="text-align: right;"> | </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> 0.065 </td><td style="text-align: right;"> 2 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 1 </td>
</tr>
<tr>
 <td style="text-align: right;">
5 </td><td style="text-align: right;"> -1.23 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 1 </td><td style="text-align: right;"> -0.395</td><td style="text-align: right;"> 3 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 2 </td>
</tr>
<tr>
 <td style="text-align: right;">
6 </td><td style="text-align: right;"> -0.15 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 6 </td><td style="text-align: right;"> -0.15 </td><td style="text-align: right;"> 3 </td><td style="text-align: right;"> | </td><td style="text-align: right;"> 2 </td>
</tr>
<tr>
 <td style="text-align: right;">
... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> | </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> ... </td><td style="text-align: right;"> | </td><td style="text-align: right;"> ... </td>
</tr>

</table>




<h5><code>method</code> is &quot;ascending&quot; or &quot;descending&quot;</h5>

<p>These methods order the data by the combined balancing column and
creates groups such that the sums get increasingly larger (<code>`ascending`</code>)
or smaller (<code>`descending`</code>). This will in turn lead to a <em>pattern</em> of
increasing/decreasing sums in the balancing columns (e.g. increasing/decreasing counts
of the categorical levels, counts of IDs, number of rows and sums of numeric columns).
</p>




<h3>Value</h3>

<p><code>data.frame</code> with one or more new grouping factors.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fold">fold()</a></code> for creating balanced folds/groups.
</p>
<p><code><a href="#topic+partition">partition()</a></code> for creating balanced partitions.
</p>
<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Set seed
if (requireNamespace("xpectr", quietly = TRUE)){
  xpectr::set_test_seed(42)
}

# Create data frame
df &lt;- data.frame(
  "participant" = factor(rep(1:20, 3)),
  "age" = rep(sample(c(1:100), 20), 3),
  "answer" = factor(sample(c("a", "b", "c", "d"), 60, replace = TRUE)),
  "score" = sample(c(1:100), 20 * 3)
)
df &lt;- df %&gt;% dplyr::arrange(participant)
df$session &lt;- rep(c("1", "2", "3"), 20)

# Sample rows to get unequal sizes per participant
df &lt;- dplyr::sample_n(df, size = 53)

# Create the initial groups (to be collapsed)
df &lt;- fold(
  data = df,
  k = 8,
  method = "n_dist",
  id_col = "participant"
)

# Ungroup the data frame
# Otherwise `collapse_groups()` would be
# applied to each fold separately!
df &lt;- dplyr::ungroup(df)

# NOTE: Make sure to check the examples with `auto_tune`
# in the end, as this is where the magic lies

# Collapse to 3 groups with size balancing
# Creates new `.coll_groups` column
df_coll &lt;- collapse_groups(
  data = df,
  n = 3,
  group_cols = ".folds",
  balance_size = TRUE # enabled by default
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = ".coll_groups",
  cat_cols = 'answer',
  num_cols = c('score', 'age'),
  id_cols = 'participant'
))

# Get ranked balances
# NOTE: When we only have a single new group column
# we don't get ranks - but this is good to use
# when comparing multiple group columns!
# The scores are standard deviations across groups
ranked_balances(coll_summary)

# Collapse to 3 groups with size + *categorical* balancing
# We create 2 new `.coll_groups_1/2` columns
df_coll &lt;- collapse_groups(
  data = df,
  n = 3,
  group_cols = ".folds",
  cat_cols = "answer",
  balance_size = TRUE,
  num_new_group_cols = 2
)

# Check balances
# To simplify the output, we only find the
# balance of the `answer` column
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = paste0(".coll_groups_", 1:2),
  cat_cols = 'answer'
))

# Get ranked balances
# All scores are standard deviations across groups or (average) ranks
# Rows are ranked by most to least balanced
# (i.e. lowest average SD rank)
ranked_balances(coll_summary)

# Collapse to 3 groups with size + categorical + *numerical* balancing
# We create 2 new `.coll_groups_1/2` columns
df_coll &lt;- collapse_groups(
  data = df,
  n = 3,
  group_cols = ".folds",
  cat_cols = "answer",
  num_cols = "score",
  balance_size = TRUE,
  num_new_group_cols = 2
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = paste0(".coll_groups_", 1:2),
  cat_cols = 'answer',
  num_cols = 'score'
))

# Get ranked balances
# All scores are standard deviations across groups or (average) ranks
ranked_balances(coll_summary)

# Collapse to 3 groups with size and *ID* balancing
# We create 2 new `.coll_groups_1/2` columns
df_coll &lt;- collapse_groups(
  data = df,
  n = 3,
  group_cols = ".folds",
  id_cols = "participant",
  balance_size = TRUE,
  num_new_group_cols = 2
)

# Check balances
# To simplify the output, we only find the
# balance of the `participant` column
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = paste0(".coll_groups_", 1:2),
  id_cols = 'participant'
))

# Get ranked balances
# All scores are standard deviations across groups or (average) ranks
ranked_balances(coll_summary)

###################
#### Auto-tune ####

# As you might have seen, the balancing does not always
# perform as optimal as we might want or need
# To get a better balance, we can enable `auto_tune`
# which will create a larger set of collapsings
# and select the most balanced new group columns
# While it is not required, we recommend
# enabling parallelization

## Not run: 
# Uncomment for parallelization
# library(doParallel)
# doParallel::registerDoParallel(7) # use 7 cores

# Collapse to 3 groups with lots of balancing
# We enable `auto_tune` to get a more balanced set of columns
# We create 10 new `.coll_groups_1/2/...` columns
df_coll &lt;- collapse_groups(
  data = df,
  n = 3,
  group_cols = ".folds",
  cat_cols = "answer",
  num_cols = "score",
  id_cols = "participant",
  balance_size = TRUE,
  num_new_group_cols = 10,
  auto_tune = TRUE,
  parallel = FALSE # Set to TRUE for parallelization!
)

# Check balances
# To simplify the output, we only find the
# balance of the `participant` column
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = paste0(".coll_groups_", 1:10),
  cat_cols = "answer",
  num_cols = "score",
  id_cols = 'participant'
))

# Get ranked balances
# All scores are standard deviations across groups or (average) ranks
ranked_balances(coll_summary)

# Now we can choose the .coll_groups_* column(s)
# that we favor the balance of
# and move on with our lives!

## End(Not run)


</code></pre>

<hr>
<h2 id='collapse_groups_by'>Collapse groups balanced by a single attribute</h2><span id='topic+collapse_groups_by'></span><span id='topic+collapse_groups_by_size'></span><span id='topic+collapse_groups_by_numeric'></span><span id='topic+collapse_groups_by_levels'></span><span id='topic+collapse_groups_by_ids'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>Collapses a set of groups into a smaller set of groups.
</p>
<p>Balance the new groups by:
</p>

<ul>
<li><p> The <strong>number of rows</strong> with <code>collapse_groups_by_size()</code>
</p>
</li>
<li> <p><strong>Numerical columns</strong> with <code>collapse_groups_by_numeric()</code>
</p>
</li>
<li><p> One or more levels of <strong>categorical columns</strong> with <code>collapse_groups_by_levels()</code>
</p>
</li>
<li><p> Level counts in <strong>ID columns</strong> with <code>collapse_groups_by_ids()</code>
</p>
</li>
<li> <p><strong>Any combination</strong> of these with <code>collapse_groups()</code>
</p>
</li></ul>

<p>These functions wrap <code><a href="#topic+collapse_groups">collapse_groups()</a></code>
to provide a simpler interface. To balance more than one of the attributes at a time
and/or create multiple new unique grouping columns at once, use
<code><a href="#topic+collapse_groups">collapse_groups()</a></code> directly.
</p>
<p>While, <em>on average</em>, the balancing work better than without, this is
<strong>not guaranteed on every run</strong>. <code>`auto_tune`</code> (enabled by default) can yield
a much better overall balance than without in most contexts. This generates a larger set
of group columns using all combinations of the balancing columns and selects the
most balanced group column(s). This is slower and can be speeded up by enabling
parallelization (see <code>`parallel`</code>).
</p>
<p><strong>Tip</strong>: When speed is more important than balancing, disable <code>`auto_tune`</code>.
</p>
<p><strong>Tip</strong>: Check the balances of the new groups with
<code><a href="#topic+summarize_balances">summarize_balances()</a></code> and
<code><a href="#topic+ranked_balances">ranked_balances()</a></code>.
</p>
<p><strong>Note</strong>: The categorical and ID balancing algorithms are different to those
in <code><a href="#topic+fold">fold()</a></code> and
<code><a href="#topic+partition">partition()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapse_groups_by_size(
  data,
  n,
  group_cols,
  auto_tune = TRUE,
  method = "balance",
  col_name = ".coll_groups",
  parallel = FALSE,
  verbose = FALSE
)

collapse_groups_by_numeric(
  data,
  n,
  group_cols,
  num_cols,
  balance_size = FALSE,
  auto_tune = TRUE,
  method = "balance",
  group_aggregation_fn = mean,
  col_name = ".coll_groups",
  parallel = FALSE,
  verbose = FALSE
)

collapse_groups_by_levels(
  data,
  n,
  group_cols,
  cat_cols,
  cat_levels = NULL,
  balance_size = FALSE,
  auto_tune = TRUE,
  method = "balance",
  col_name = ".coll_groups",
  parallel = FALSE,
  verbose = FALSE
)

collapse_groups_by_ids(
  data,
  n,
  group_cols,
  id_cols,
  balance_size = FALSE,
  auto_tune = TRUE,
  method = "balance",
  col_name = ".coll_groups",
  parallel = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collapse_groups_by_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_n">n</code></td>
<td>
<p>Number of new groups.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_group_cols">group_cols</code></td>
<td>
<p>Names of factors in <code>`data`</code> for identifying the <em>existing</em> groups
that should be collapsed.
</p>
<p>Multiple names are treated as in <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>
(i.e., a hierarchy of groups), where each leaf group within each parent group is
considered a unique group to be collapsed.
Parent groups are not considered during collapsing, why leaf groups from different
parent groups can be collapsed together.
</p>
<p><strong>Note</strong>: Do not confuse these group columns with potential columns that <code>`data`</code> is grouped by.
<code>`group_cols`</code> identifies the groups to be collapsed. When <code>`data`</code> is
grouped with <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>, the function is
applied separately to each of those subsets.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_auto_tune">auto_tune</code></td>
<td>
<p>Whether to create a larger set of collapsed group columns
from all combinations of the balancing dimensions and select the
overall most balanced group column(s).
</p>
<p>This tends to create much more balanced collapsed group columns.
</p>
<p>Can be slow, why we recommend enabling parallelization (see <code>`parallel`</code>).</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_method">method</code></td>
<td>
<p><code>"balance"</code>, <code>"ascending"</code>, or <code>"descending"</code>.
</p>

<ul>
<li> <p><code>"balance"</code> balances the attribute between the groups.
</p>
</li>
<li> <p><code>"ascending"</code> orders by the attribute and groups from the lowest to highest value.
</p>
</li>
<li> <p><code>"descending"</code> orders by the attribute and groups from the highest to lowest value.
</p>
</li></ul>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_col_name">col_name</code></td>
<td>
<p>Name of the new group column. When creating multiple new group columns
(<code>`num_new_group_cols`&gt;1</code>), this is the prefix for the names, which will
be suffixed with an underscore and a number (_1, _2, _3, etc.).</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_parallel">parallel</code></td>
<td>
<p>Whether to parallelize the group column comparisons
when <code>`auto_tune`</code> is enabled.
</p>
<p>Requires a registered parallel backend.
Like <code>doParallel::registerDoParallel</code>.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_verbose">verbose</code></td>
<td>
<p>Whether to print information about the process.
May make the function slightly slower.
</p>
<p>N.B. Currently only used during auto-tuning.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_num_cols">num_cols</code></td>
<td>
<p>Names of numerical columns to balance between groups.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_balance_size">balance_size</code></td>
<td>
<p>Whether to balance the size of the collapsed groups. (logical)</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_group_aggregation_fn">group_aggregation_fn</code></td>
<td>
<p>Function for aggregating values in the <code>`num_cols`</code> columns
for each group in <code>`group_cols`</code>.
</p>
<p>Default is <code>mean()</code>, where the average value(s) are balanced across the new groups.
</p>
<p>When using <code>sum()</code>, the groups will have similar sums across the new groups.
</p>
<p><strong>N.B.</strong> Only used when <code>`num_cols`</code> is specified.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_cat_cols">cat_cols</code></td>
<td>
<p>Names of categorical columns to balance the average frequency
of one or more levels of.</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_cat_levels">cat_levels</code></td>
<td>
<p>Names of the levels in the <code>`cat_cols`</code> columns to balance the average frequencies
of. When <code>`NULL`</code> (default), all levels are balanced.
Can be weights indicating the balancing importance of each level (within each column).
</p>
<p>The weights are automatically scaled to sum to <code>1</code>.
</p>
<p>Can be <code>".minority"</code> or <code>".majority"</code>, in which case the minority/majority level
are found and used.
</p>


<h4>When <code>`cat_cols`</code> has single column name:</h4>

<p>Either a <code>vector</code> with level names or a named <code>numeric vector</code> with weights:
</p>
<p>E.g. <code>c("dog", "pidgeon", "mouse")</code> or <code>c("dog" = 5, "pidgeon" = 1, "mouse" = 3)</code>
</p>



<h4>When <code>`cat_cols`</code> has multiple column names:</h4>

<p>A named <code>list</code> with <code>vector</code>s for each column name in <code>`cat_cols`</code>.
When not providing a <code>vector</code> for a <code>`cat_cols`</code>
column, all levels are balanced in that column.
</p>
<p>E.g. <code>list("col1" = c("dog" = 5, "pidgeon" = 1, "mouse" = 3),
 "col2" = c("hydrated", "dehydrated"))</code>.
</p>
</td></tr>
<tr><td><code id="collapse_groups_by_+3A_id_cols">id_cols</code></td>
<td>
<p>Names of factor columns with IDs to balance the counts of between groups.
</p>
<p>E.g. useful to get a similar number of participants in each group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See details in <code><a href="#topic+collapse_groups">collapse_groups()</a></code>.
</p>


<h3>Value</h3>

<p><code>`data`</code> with a new grouping factor column.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Set seed
if (requireNamespace("xpectr", quietly = TRUE)){
  xpectr::set_test_seed(42)
}

# Create data frame
df &lt;- data.frame(
  "participant" = factor(rep(1:20, 3)),
  "age" = rep(sample(c(1:100), 20), 3),
  "answer" = factor(sample(c("a", "b", "c", "d"), 60, replace = TRUE)),
  "score" = sample(c(1:100), 20 * 3)
)
df &lt;- df %&gt;% dplyr::arrange(participant)
df$session &lt;- rep(c("1", "2", "3"), 20)

# Sample rows to get unequal sizes per participant
df &lt;- dplyr::sample_n(df, size = 53)

# Create the initial groups (to be collapsed)
df &lt;- fold(
  data = df,
  k = 8,
  method = "n_dist",
  id_col = "participant"
)

# Ungroup the data frame
# Otherwise `collapse_groups*()` would be
# applied to each fold separately!
df &lt;- dplyr::ungroup(df)

# When `auto_tune` is enabled for larger datasets
# we recommend enabling parallelization
# This can be done with:
# library(doParallel)
# doParallel::registerDoParallel(7) # use 7 cores

## Not run: 

# Collapse to 3 groups with size balancing
# Creates new `.coll_groups` column
df_coll &lt;- collapse_groups_by_size(
  data = df,
  n = 3,
  group_cols = ".folds"
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = ".coll_groups"
))

# Get ranked balances
# This is most useful when having created multiple
# new group columns with `collapse_groups()`
# The scores are standard deviations across groups
ranked_balances(coll_summary)

# Collapse to 3 groups with *categorical* balancing
df_coll &lt;- collapse_groups_by_levels(
  data = df,
  n = 3,
  group_cols = ".folds",
  cat_cols = "answer"
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = ".coll_groups",
  cat_cols = 'answer'
))

# Collapse to 3 groups with *numerical* balancing
# Also balance size to get similar sums
# as well as means
df_coll &lt;- collapse_groups_by_numeric(
  data = df,
  n = 3,
  group_cols = ".folds",
  num_cols = "score",
  balance_size = TRUE
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = ".coll_groups",
  num_cols = 'score'
))

# Collapse to 3 groups with *ID* balancing
# This should give us a similar number of IDs per group
df_coll &lt;- collapse_groups_by_ids(
  data = df,
  n = 3,
  group_cols = ".folds",
  id_cols = "participant"
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = ".coll_groups",
  id_cols = 'participant'
))

# Collapse to 3 groups with balancing of ALL attributes
# We create 5 new grouping factors and compare them
# The latter is in-general a good strategy even if you
# only need a single collapsed grouping factor
# as you can choose your preferred balances
# based on the summary
# NOTE: This is slow (up to a few minutes)
# consider enabling parallelization
df_coll &lt;- collapse_groups(
  data = df,
  n = 3,
  num_new_group_cols = 5,
  group_cols = ".folds",
  cat_cols = "answer",
  num_cols = 'score',
  id_cols = "participant",
  auto_tune = TRUE   # Disabled by default in `collapse_groups()`
  # parallel = TRUE  # Add comma above and uncomment
)

# Check balances
(coll_summary &lt;- summarize_balances(
  data = df_coll,
  group_cols = paste0(".coll_groups_", 1:5),
  cat_cols = "answer",
  num_cols = 'score',
  id_cols = 'participant'
))

# Compare the new grouping columns
# The lowest across-group standard deviation
# is the most balanced
ranked_balances(coll_summary)


## End(Not run)

</code></pre>

<hr>
<h2 id='differs_from_previous'>Find values in a vector that differ from the previous value</h2><span id='topic+differs_from_previous'></span><span id='topic+not_previous'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Finds values, or indices of values, that differ from the previous value by some threshold(s).
</p>
<p>Operates with both a positive and a negative threshold.
Depending on <code>`direction`</code>, it checks if the difference to the previous value is:
</p>

<ul>
<li><p> greater than or equal to the positive threshold.
</p>
</li>
<li><p> less than or equal to the negative threshold.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>differs_from_previous(
  data,
  col = NULL,
  threshold = NULL,
  direction = "both",
  return_index = FALSE,
  include_first = FALSE,
  handle_na = "ignore",
  factor_conversion_warning = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="differs_from_previous_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> or <code>vector</code>.
</p>
<p><strong>N.B.</strong> If checking a <code>factor</code>, it is converted to a <code>character vector</code>.
This means that factors can only be used when <code>`threshold`</code> is <code>NULL</code>.
Conversion will generate a warning, which can be turned off by setting <code>`factor_conversion_warning`</code> to <code>FALSE</code>.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the function is applied group-wise and the output is a <code>list</code> of <code>vector</code>s.
The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).</p>
</td></tr>
<tr><td><code id="differs_from_previous_+3A_col">col</code></td>
<td>
<p>Name of column to find values that differ in. Used when <code>`data`</code> is
<code>data.frame</code>. (Character)</p>
</td></tr>
<tr><td><code id="differs_from_previous_+3A_threshold">threshold</code></td>
<td>
<p>Threshold to check difference to previous value to.
</p>
<p><code>NULL</code>, <em>numeric scalar</em> or <em>numeric vector with length <code>2</code></em>.
</p>


<h4>NULL</h4>

<p>Checks if the value is different from the previous value.
</p>
<p>Ignores <code>`direction`</code>.
</p>
<p>N.B. Works for both numeric and character vectors.
</p>



<h4>Numeric scalar</h4>

<p>Positive number.
</p>
<p>Negative threshold is the negated number.
</p>
<p>N.B. Only works for numeric vectors.
</p>



<h4>Numeric vector with length 2</h4>

<p>Given as <code>c(negative threshold, positive threshold)</code>.
</p>
<p>Negative threshold must be a negative number and positive threshold must be a positive number.
</p>
<p>N.B. Only works for numeric vectors.
</p>
</td></tr>
<tr><td><code id="differs_from_previous_+3A_direction">direction</code></td>
<td>
<p><code>both</code>, <code>positive</code> or <code>negative</code>. (character)
</p>


<h4>both</h4>

<p>Checks whether the difference to the previous value is
</p>

<ul>
<li><p> greater than or equal to the positive threshold.
</p>
</li>
<li><p> less than or equal to the negative threshold.
</p>
</li></ul>




<h4>positive</h4>

<p>Checks whether the difference to the previous value is
</p>

<ul>
<li><p> greater than or equal to the positive threshold.
</p>
</li></ul>




<h4>negative</h4>

<p>Checks whether the difference to the previous value is
</p>

<ul>
<li><p> less than or equal to the negative threshold.
</p>
</li></ul>

</td></tr>
<tr><td><code id="differs_from_previous_+3A_return_index">return_index</code></td>
<td>
<p>Return indices of values that differ. (Logical)</p>
</td></tr>
<tr><td><code id="differs_from_previous_+3A_include_first">include_first</code></td>
<td>
<p>Whether to include the first element of the vector in the output. (Logical)</p>
</td></tr>
<tr><td><code id="differs_from_previous_+3A_handle_na">handle_na</code></td>
<td>
<p>How to handle <code>NA</code>s in the column.
</p>


<h4>&quot;ignore&quot;</h4>

<p>Removes the <code>NA</code>s before finding the differing values, ensuring
that the first value after an <code>NA</code> will be correctly identified as new,
if it differs from the value before the <code>NA</code>(s).
</p>



<h4>&quot;as_element&quot;</h4>

<p>Treats all <code>NA</code>s as the string <code>"NA"</code>.
This means, that <code>threshold</code> must be <code>NULL</code> when using this method.
</p>



<h4>Numeric scalar</h4>

<p>A numeric value to replace <code>NA</code>s with.
</p>
</td></tr>
<tr><td><code id="differs_from_previous_+3A_factor_conversion_warning">factor_conversion_warning</code></td>
<td>
<p>Whether to throw a warning when converting a <code>factor</code> to a <code>character</code>. (Logical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>vector</code> with either the differing values or the indices of the differing values.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the output is a <code>list</code> of <code>vector</code>s
with the differing values. The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other l_starts tools: 
<code><a href="#topic+find_missing_starts">find_missing_starts</a>()</code>,
<code><a href="#topic+find_starts">find_starts</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create a data frame
df &lt;- data.frame(
  "a" = factor(c("a", "a", "b", "b", "c", "c")),
  "n" = c(1, 3, 6, 2, 2, 4)
)

# Get differing values in column 'a' with no threshold.
# This will simply check, if it is different to the previous value or not.
differs_from_previous(df, col = "a")

# Get indices of differing values in column 'a' with no threshold.
differs_from_previous(df, col = "a", return_index = TRUE)

# Get values, that are 2 or more greater than the previous value
differs_from_previous(df, col = "n", threshold = 2, direction = "positive")

# Get values, that are 4 or more less than the previous value
differs_from_previous(df, col = "n", threshold = 4, direction = "negative")

# Get values, that are either 2 or more greater than the previous value
# or 4 or more less than the previous value
differs_from_previous(df, col = "n", threshold = c(-4, 2), direction = "both")
</code></pre>

<hr>
<h2 id='downsample'>Downsampling of rows in a data frame</h2><span id='topic+downsample'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Uses random downsampling to fix the group sizes to the
smallest group in the <code>data.frame</code>.
</p>
<p>Wraps <code><a href="#topic+balance">balance</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downsample(data, cat_col, id_col = NULL, id_method = "n_ids")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="downsample_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="downsample_+3A_cat_col">cat_col</code></td>
<td>
<p>Name of categorical variable to balance by. (Character)</p>
</td></tr>
<tr><td><code id="downsample_+3A_id_col">id_col</code></td>
<td>
<p>Name of factor with IDs. (Character)
</p>
<p>IDs are considered entities, e.g. allowing us to add or remove all rows for an ID.
How this is used is up to the <code>`id_method`</code>.
</p>
<p>E.g. If we have measured a participant multiple times and
want make sure that we keep all these measurements. Then we would either
remove/add all measurements for the participant or leave in
all measurements for the participant.
</p>
<p>N.B. When <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>
(see <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>), IDs that appear in multiple
groupings are considered separate entities within those groupings.</p>
</td></tr>
<tr><td><code id="downsample_+3A_id_method">id_method</code></td>
<td>
<p>Method for balancing the IDs. (Character)
</p>
<p><code>"n_ids"</code>, <code>"n_rows_c"</code>, <code>"distributed"</code>, or <code>"nested"</code>.
</p>


<h4>n_ids (default)</h4>

<p>Balances on ID level only. It makes sure there are the same number of IDs for each category.
This might lead to a different number of rows between categories.
</p>



<h4>n_rows_c</h4>

<p>Attempts to level the number of rows per category, while only removing/adding entire IDs.
This is done in 2 steps:
</p>

<ol>
<li><p> If a category needs to add all its rows one or more times, the data is repeated.
</p>
</li>
<li><p> Iteratively, the ID with the number of rows closest to the
lacking/excessive number of rows is added/removed.
This happens until adding/removing the closest ID would lead to a size further from
the target size than the current size.
If multiple IDs are closest, one is randomly sampled.
</p>
</li></ol>




<h4>distributed</h4>

<p>Distributes the lacking/excess rows equally between the IDs.
If the number to distribute can not be equally divided, some IDs will have 1 row more/less than the others.
</p>



<h4>nested</h4>

<p>Calls <code>balance()</code> on each category with IDs as cat_col.
</p>
<p>I.e. if size is <code>"min"</code>, IDs will have the size of the smallest ID in their category.
</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Without <code>`id_col`</code></h4>

<p>Downsampling is done without replacement, meaning that rows are not duplicated but only removed.</p>



<h4>With <code>`id_col`</code></h4>

<p>See <code>`id_method`</code> description.</p>



<h3>Value</h3>

<p><code>data.frame</code> with some rows removed.
Ordered by potential grouping variables, <code>`cat_col`</code> and (potentially) <code>`id_col`</code>.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other sampling functions: 
<code><a href="#topic+balance">balance</a>()</code>,
<code><a href="#topic+upsample">upsample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create data frame
df &lt;- data.frame(
  "participant" = factor(c(1, 1, 2, 3, 3, 3, 3, 4, 4, 5, 5, 5, 5)),
  "diagnosis" = factor(c(0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0)),
  "trial" = c(1, 2, 1, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4),
  "score" = sample(c(1:100), 13)
)

# Using downsample()
downsample(df, cat_col = "diagnosis")

# Using downsample() with id_method "n_ids"
# With column specifying added rows
downsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "n_ids"
)

# Using downsample() with id_method "n_rows_c"
# With column specifying added rows
downsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "n_rows_c"
)

# Using downsample() with id_method "distributed"
downsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "distributed"
)

# Using downsample() with id_method "nested"
downsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "nested"
)
</code></pre>

<hr>
<h2 id='find_missing_starts'>Find start positions that cannot be found in <code>`data`</code></h2><span id='topic+find_missing_starts'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Tells you which values and (optionally) <code>skip-to-numbers</code> that are
recursively removed when using the <code>"l_starts"</code> method with <code>`remove_missing_starts`</code>
set to <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_missing_starts(data, n, starts_col = NULL, return_skip_numbers = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_missing_starts_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> or <code>vector</code>.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the function is applied group-wise and the output is a
<code>list</code> of either <code>vector</code>s or <code>list</code>s.
The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).</p>
</td></tr>
<tr><td><code id="find_missing_starts_+3A_n">n</code></td>
<td>
<p>List of starting positions.
</p>
<p>Skip values by <code>c(value, skip_to_number)</code> where <code>skip_to_number</code>
is the nth appearance of the value in the vector.
</p>
<p>See <code><a href="#topic+group_factor">group_factor()</a></code> for explanations and
examples of using the <code>"l_starts"</code> method.</p>
</td></tr>
<tr><td><code id="find_missing_starts_+3A_starts_col">starts_col</code></td>
<td>
<p>Name of column with values to match
when <code>`data`</code> is a <code>data.frame</code>. Pass <code>'index'</code> to use row names. (Character)</p>
</td></tr>
<tr><td><code id="find_missing_starts_+3A_return_skip_numbers">return_skip_numbers</code></td>
<td>
<p>Return <code>skip-to-numbers</code> along with values (Logical).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of start values and <code>skip-to-numbers</code> or a <code>vector</code> with the start values.
Returns <code>NULL</code> if no values were found.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the function is applied group-wise and the output is a
<code>list</code> of either <code>vector</code>s or <code>list</code>s.
The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other l_starts tools: 
<code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>,
<code><a href="#topic+find_starts">find_starts</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create a data frame
df &lt;- data.frame(
  "a" = c("a", "a", "b", "b", "c", "c"),
  stringsAsFactors = FALSE
)

# Create list of starts
starts &lt;- c("a", "e", "b", "d", "c")

# Find missing starts with skip_to numbers
find_missing_starts(df, starts, starts_col = "a")

# Find missing starts without skip_to numbers
find_missing_starts(df, starts,
  starts_col = "a",
  return_skip_numbers = FALSE
)
</code></pre>

<hr>
<h2 id='find_starts'>Find start positions of groups in data</h2><span id='topic+find_starts'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Finds values or indices of values that are not the same
as the previous value.
</p>
<p>E.g. to use with the <code>"l_starts"</code> method.
</p>
<p>Wraps <code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_starts(
  data,
  col = NULL,
  return_index = FALSE,
  handle_na = "ignore",
  factor_conversion_warning = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_starts_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> or <code>vector</code>.
</p>
<p><strong>N.B.</strong> If checking a <code>factor</code>, it is converted to a <code>character vector</code>.
Conversion will generate a warning, which can be turned off by
setting <code>`factor_conversion_warning`</code> to <code>FALSE</code>.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the function is applied group-wise and the output is a <code>list</code> of <code>vector</code>s.
The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).</p>
</td></tr>
<tr><td><code id="find_starts_+3A_col">col</code></td>
<td>
<p>Name of column to find starts in. Used when <code>`data`</code> is
a <code>data.frame</code>. (Character)</p>
</td></tr>
<tr><td><code id="find_starts_+3A_return_index">return_index</code></td>
<td>
<p>Whether to return indices of starts. (Logical)</p>
</td></tr>
<tr><td><code id="find_starts_+3A_handle_na">handle_na</code></td>
<td>
<p>How to handle <code>NA</code>s in the column.
</p>


<h4>&quot;ignore&quot;</h4>

<p>Removes the <code>NA</code>s before finding the differing values, ensuring
that the first value after an <code>NA</code> will be correctly identified as new,
if it differs from the value before the <code>NA</code>(s).
</p>



<h4>&quot;as_element&quot;</h4>

<p>Treats all <code>NA</code>s as the string <code>"NA"</code>.
This means, that <code>threshold</code> must be <code>NULL</code> when using this method.
</p>



<h4>Numeric scalar</h4>

<p>A numeric value to replace <code>NA</code>s with.
</p>
</td></tr>
<tr><td><code id="find_starts_+3A_factor_conversion_warning">factor_conversion_warning</code></td>
<td>
<p>Throw warning when
converting <code>factor</code> to <code>character</code>. (Logical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>vector</code> with either the start values or the indices of the start values.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the output is a <code>list</code> of <code>vector</code>s.
The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other l_starts tools: 
<code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>,
<code><a href="#topic+find_missing_starts">find_missing_starts</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create a data frame
df &lt;- data.frame(
  "a" = c("a", "a", "b", "b", "c", "c"),
  stringsAsFactors = FALSE
)

# Get start values for new groups in column 'a'
find_starts(df, col = "a")

# Get indices of start values for new groups
# in column 'a'
find_starts(df,
  col = "a",
  return_index = TRUE
)

## Use found starts with l_starts method
# Notice: This is equivalent to n = 'auto'
# with l_starts method

# Get start values for new groups in column 'a'
starts &lt;- find_starts(df, col = "a")

# Use starts in group() with 'l_starts' method
group(df,
  n = starts, method = "l_starts",
  starts_col = "a"
)

# Similar but with indices instead of values

# Get indices of start values for new groups
# in column 'a'
starts_ind &lt;- find_starts(df,
  col = "a",
  return_index = TRUE
)

# Use starts in group() with 'l_starts' method
group(df,
  n = starts_ind, method = "l_starts",
  starts_col = "index"
)
</code></pre>

<hr>
<h2 id='fold'>Create balanced folds for cross-validation</h2><span id='topic+fold'></span><span id='topic+create_balanced_groups'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Divides data into groups by a wide range of methods.
Balances a given categorical variable and/or numerical variable between folds and keeps (if possible)
all data points with a shared ID (e.g. participant_id) in the same fold.
Can create multiple unique fold columns for repeated cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fold(
  data,
  k = 5,
  cat_col = NULL,
  num_col = NULL,
  id_col = NULL,
  method = "n_dist",
  id_aggregation_fn = sum,
  extreme_pairing_levels = 1,
  num_fold_cols = 1,
  unique_fold_cols_only = TRUE,
  max_iters = 5,
  use_of_triplets = "fill",
  handle_existing_fold_cols = "keep_warn",
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fold_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="fold_+3A_k">k</code></td>
<td>
<p><em>Depends on <code>`method`</code>.</em>
</p>
<p>Number of folds (default), fold size, with more (see <code>`method`</code>).
</p>
<p>When <code>`num_fold_cols` &gt; 1</code>, <code>`k`</code> can also be a vector
with one <code>`k`</code> per fold column. This allows trying multiple <code>`k`</code> settings at a time. Note
that the generated fold columns are not guaranteed to be in the order of <code>`k`</code>.
</p>
<p>Given as whole number or percentage (<code>0 &lt; `k` &lt; 1</code>).</p>
</td></tr>
<tr><td><code id="fold_+3A_cat_col">cat_col</code></td>
<td>
<p>Name of categorical variable to balance between folds.
</p>
<p>E.g. when predicting a binary variable (a or b), we usually want
both classes represented in every fold.
</p>
<p>N.B. If also passing an <code>`id_col`</code>, <code>`cat_col`</code> should be constant within each ID.</p>
</td></tr>
<tr><td><code id="fold_+3A_num_col">num_col</code></td>
<td>
<p>Name of numerical variable to balance between folds.
</p>
<p>N.B. When used with <code>`id_col`</code>, values for each ID are aggregated using
<code>`id_aggregation_fn`</code> before being balanced.
</p>
<p>N.B. When passing <code>`num_col`</code>, the <code>`method`</code> parameter is ignored.</p>
</td></tr>
<tr><td><code id="fold_+3A_id_col">id_col</code></td>
<td>
<p>Name of factor with IDs.
This will be used to keep all rows that share an ID in the same fold
(if possible).
</p>
<p>E.g. If we have measured a participant multiple times and want to see the
effect of time, we want to have all observations of this participant in
the same fold.
</p>
<p>N.B. When <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>
(see <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>), IDs that appear in multiple
groupings might end up in different folds in those groupings.</p>
</td></tr>
<tr><td><code id="fold_+3A_method">method</code></td>
<td>
<p><code>"n_dist"</code>, <code>"n_fill"</code>, <code>"n_last"</code>,
<code>"n_rand"</code>, <code>"greedy"</code>, or <code>"staircase"</code>.
</p>
<p><strong>Notice</strong>: examples are sizes of the generated groups
based on a vector with <code>57</code> elements.
</p>


<h4>n_dist (default)</h4>

<p>Divides the data into a specified number of groups and
distributes excess data points across groups
<code class="reqn">(e.g. 11, 11, 12, 11, 12)</code>.
</p>
<p><code>`k`</code> is number of groups</p>



<h4>n_fill</h4>

<p>Divides the data into a specified number of groups and
fills up groups with excess data points from the beginning
<code class="reqn">(e.g. 12, 12, 11, 11, 11)</code>.
</p>
<p><code>`k`</code> is number of groups</p>



<h4>n_last</h4>

<p>Divides the data into a specified number of groups.
It finds the most equal group sizes possible,
using all data points. Only the last group is able to differ in size
<code class="reqn">(e.g. 11, 11, 11, 11, 13)</code>.
</p>
<p><code>`k`</code> is number of groups</p>



<h4>n_rand</h4>

<p>Divides the data into a specified number of groups.
Excess data points are placed randomly in groups (only 1 per group)
<code class="reqn">(e.g. 12, 11, 11, 11, 12)</code>.
</p>
<p><code>`k`</code> is number of groups</p>



<h4>greedy</h4>

<p>Divides up the data greedily given a specified group size
<code class="reqn">(e.g. 10, 10, 10, 10, 10, 7)</code>.
</p>
<p><code>`k`</code> is group size</p>



<h4>staircase</h4>

<p>Uses step size to divide up the data.
Group size increases with 1 step for every group,
until there is no more data
<code class="reqn">(e.g. 5, 10, 15, 20, 7)</code>.
</p>
<p><code>`k`</code> is step size</p>
</td></tr>
<tr><td><code id="fold_+3A_id_aggregation_fn">id_aggregation_fn</code></td>
<td>
<p>Function for aggregating values in <code>`num_col`</code>
for each ID, before balancing <code>`num_col`</code>.
</p>
<p>N.B. Only used when <code>`num_col`</code> and <code>`id_col`</code> are both specified.</p>
</td></tr>
<tr><td><code id="fold_+3A_extreme_pairing_levels">extreme_pairing_levels</code></td>
<td>
<p>How many levels of extreme pairing to do
when balancing folds by a numerical column (i.e. <code>`num_col`</code> is specified).
</p>
<p><strong>Extreme pairing</strong>: Rows/pairs are ordered as smallest, largest,
second smallest, second largest, etc. If <code>extreme_pairing_levels &gt; 1</code>,
this is done &quot;recursively&quot; on the extreme pairs. See <code>`Details/num_col`</code> for more.
</p>
<p>N.B. Larger values work best with large datasets. If set too high,
the result might not be stochastic. Always check if an increase
actually makes the folds more balanced. See example.</p>
</td></tr>
<tr><td><code id="fold_+3A_num_fold_cols">num_fold_cols</code></td>
<td>
<p>Number of fold columns to create.
Useful for repeated cross-validation.
</p>
<p>If <code>num_fold_cols &gt; 1</code>, columns will be named
<code class="reqn">".folds_1"</code>, <code class="reqn">".folds_2"</code>, etc.
Otherwise simply <code class="reqn">".folds"</code>.
</p>
<p>N.B. If <code>`unique_fold_cols_only`</code> is <code>TRUE</code>,
we can end up with fewer columns than specified, see <code>`max_iters`</code>.
</p>
<p>N.B. If <code>`data`</code> has existing fold columns, see <code>`handle_existing_fold_cols`</code>.</p>
</td></tr>
<tr><td><code id="fold_+3A_unique_fold_cols_only">unique_fold_cols_only</code></td>
<td>
<p>Check if fold columns are identical and
keep only unique columns.
</p>
<p>As the number of column comparisons can be time consuming,
we can run this part in parallel. See <code>`parallel`</code>.
</p>
<p>N.B. We can end up with fewer columns than specified in
<code>`num_fold_cols`</code>, see <code>`max_iters`</code>.
</p>
<p>N.B. Only used when <code>`num_fold_cols` &gt; 1</code> or <code>`data`</code> has existing fold columns.</p>
</td></tr>
<tr><td><code id="fold_+3A_max_iters">max_iters</code></td>
<td>
<p>Maximum number of attempts at reaching
<code>`num_fold_cols`</code> <em>unique</em> fold columns.
</p>
<p>When only keeping unique fold columns, we risk having fewer columns than expected.
Hence, we repeatedly create the missing columns and remove those that are not unique.
This is done until we have <code>`num_fold_cols`</code> unique fold columns
or we have attempted <code>`max_iters`</code> times.
</p>
<p>In some cases, it is not possible to create <code>`num_fold_cols`</code>
unique combinations of the dataset, e.g.
when specifying <code>`cat_col`</code>, <code>`id_col`</code> and <code>`num_col`</code>.
<code>`max_iters`</code> specifies when to stop trying.
Note that we can end up with fewer columns than specified in <code>`num_fold_cols`</code>.
</p>
<p>N.B. Only used when <code>`num_fold_cols` &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="fold_+3A_use_of_triplets">use_of_triplets</code></td>
<td>
<p><code>"fill"</code>, <code>"instead"</code> or <code>"never"</code>.
</p>
<p>When to use extreme triplet grouping in numerical balancing (when <code>`num_col`</code> is specified).
</p>


<h4>fill (default)</h4>

<p>When extreme pairing cannot create enough unique fold columns, use extreme triplet grouping
to create additional unique fold columns.
</p>



<h4>instead</h4>

<p>Use extreme triplet grouping instead of extreme pairing. For some datasets, grouping in triplets
give better balancing than grouping in pairs. This can be worth exploring when
numerical balancing is important.
</p>
<p>Tip: Compare the balances with <code><a href="#topic+summarize_balances">summarize_balances()</a></code> and
<code><a href="#topic+ranked_balances">ranked_balances()</a></code>.
</p>



<h4>never</h4>

<p>Never use extreme triplet grouping.
</p>



<h4>Extreme triplet grouping</h4>

<p>Similar to extreme pairing (see <code>Details &gt;&gt; num_col</code>), extreme triplet grouping
orders the rows as <em>smallest, closest to the median, largest, second smallest, second
closest to the median, second largest,</em> etc. Each triplet gets a group identifier
and we either perform recursive extreme triplet grouping on the identifiers or fold
the identifiers and transfer the fold IDs to the original rows.
</p>
<p>For some datasets, this can be give more balanced groups than extreme pairing, but
on average, extreme pairing works better. Due to the grouping into triplets instead of pairs
they tend to create different groupings though, so when creating many fold columns
and extreme pairing cannot create enough unique fold columns, we can create the remaining
(or at least some additional number) with extreme triplet grouping.
</p>
<p>Extreme triplet grouping is implemented in
<code><a href="rearrr.html#topic+triplet_extremes">rearrr::triplet_extremes()</a></code>.
</p>
</td></tr>
<tr><td><code id="fold_+3A_handle_existing_fold_cols">handle_existing_fold_cols</code></td>
<td>
<p>How to handle existing fold columns.
Either <code>"keep_warn"</code>, <code>"keep"</code>, or <code>"remove"</code>.
</p>
<p>To <strong>add</strong> extra fold columns, use <code>"keep"</code> or <code>"keep_warn"</code>.
Note that existing fold columns might be renamed.
</p>
<p>To <strong>replace</strong> the existing fold columns, use <code>"remove"</code>.</p>
</td></tr>
<tr><td><code id="fold_+3A_parallel">parallel</code></td>
<td>
<p>Whether to parallelize the fold column comparisons,
when <code>`unique_fold_cols_only`</code> is <code>TRUE</code>.
</p>
<p>Requires a registered parallel backend.
Like <code>doParallel::registerDoParallel</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>cat_col</h4>


<ol>
<li> <p><code>`data`</code> is subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> Subsets are grouped and merged.
</p>
</li></ol>




<h4>id_col</h4>


<ol>
<li><p> Groups are created from unique IDs.
</p>
</li></ol>




<h4>num_col</h4>


<ol>
<li><p> Rows are shuffled.
<strong>Note</strong> that this will only affect rows with the same value in <code>`num_col`</code>.
</p>
</li>
<li><p> Extreme pairing 1: Rows are ordered as <em>smallest, largest, second smallest, second largest</em>, etc.
Each pair get a group identifier. (See <code><a href="rearrr.html#topic+pair_extremes">rearrr::pair_extremes()</a></code>)
</p>
</li>
<li><p> If <code>`extreme_pairing_levels` &gt; 1</code>: These group identifiers are reordered as <em>smallest,
largest, second smallest, second largest</em>, etc., by the sum of <code>`num_col`</code> in the represented rows.
These pairs (of pairs) get a new set of group identifiers, and the process is repeated
<code>`extreme_pairing_levels`-2</code> times. Note that the group identifiers at the last level will represent
<code>2^`extreme_pairing_levels`</code> rows, why you should be careful when choosing that setting.
</p>
</li>
<li><p> The group identifiers from the last pairing are folded (randomly divided into groups),
and the fold identifiers are transferred to the original rows.
</p>
</li></ol>

<p>N.B. When doing extreme pairing of an unequal number of rows,
the row with the smallest value is placed in a group by itself, and the order is instead:
smallest, <em>second smallest, largest, third smallest, second largest</em>, etc.
</p>
<p>N.B. When <code>`num_fold_cols` &gt; 1</code> and fewer than <code>`num_fold_cols`</code> fold columns have
been created after <code>`max_iters`</code> attempts, we try with <em>extreme triplets</em> instead
(see <code><a href="rearrr.html#topic+triplet_extremes">rearrr::triplet_extremes()</a></code>). It groups the elements
as <em>smallest, closest to the median, largest, second smallest, second closest to the median, second largest</em>, etc.
We can also choose to never/only use extreme triplets via <code>`use_of_triplets`</code>.
</p>



<h4>cat_col AND id_col</h4>


<ol>
<li> <p><code>`data`</code> is subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> Groups are created from unique IDs in each subset.
</p>
</li>
<li><p> Subsets are merged.
</p>
</li></ol>




<h4>cat_col AND num_col</h4>


<ol>
<li> <p><code>`data`</code> is subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> Subsets are grouped by <code>`num_col`</code>.
</p>
</li>
<li><p> Subsets are merged such that the largest group
(by sum of <code>`num_col`</code>) from the first category
is merged with the smallest group from the second category, etc.
</p>
</li></ol>




<h4>num_col AND id_col</h4>


<ol>
<li><p> Values in <code>`num_col`</code> are aggregated for each ID, using <code>`id_aggregation_fn`</code>.
</p>
</li>
<li><p> The IDs are grouped, using the aggregated values as &quot;<code>num_col</code>&quot;.
</p>
</li>
<li><p> The groups of the IDs are transferred to the rows.
</p>
</li></ol>




<h4>cat_col AND num_col AND id_col</h4>


<ol>
<li><p> Values in <code>`num_col`</code> are aggregated for each ID, using <code>`id_aggregation_fn`</code>.
</p>
</li>
<li><p> IDs are subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> The IDs in each subset are grouped,
by using the aggregated values as &quot;<code>num_col</code>&quot;.
</p>
</li>
<li><p> The subsets are merged such that the largest group
(by sum of the aggregated values) from the first category
is merged with the smallest group from the second category, etc.
</p>
</li>
<li><p> The groups of the IDs are transferred to the rows.
</p>
</li></ol>




<h3>Value</h3>

<p><code>data.frame</code> with grouping factor for subsetting in cross-validation.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partition">partition</a></code> for balanced partitions
</p>
<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Create data frame
df &lt;- data.frame(
  "participant" = factor(rep(c("1", "2", "3", "4", "5", "6"), 3)),
  "age" = rep(sample(c(1:100), 6), 3),
  "diagnosis" = factor(rep(c("a", "b", "a", "a", "b", "b"), 3)),
  "score" = sample(c(1:100), 3 * 6)
)
df &lt;- df %&gt;% arrange(participant)
df$session &lt;- rep(c("1", "2", "3"), 6)

# Using fold()

## Without balancing
df_folded &lt;- fold(data = df, k = 3, method = "n_dist")

## With cat_col
df_folded &lt;- fold(
  data = df,
  k = 3,
  cat_col = "diagnosis",
  method = "n_dist"
)

## With id_col
df_folded &lt;- fold(
  data = df,
  k = 3,
  id_col = "participant",
  method = "n_dist"
)

## With num_col
# Note: 'method' would not be used in this case
df_folded &lt;- fold(data = df, k = 3, num_col = "score")

# With cat_col and id_col
df_folded &lt;- fold(
  data = df,
  k = 3,
  cat_col = "diagnosis",
  id_col = "participant", method = "n_dist"
)

## With cat_col, id_col and num_col
df_folded &lt;- fold(
  data = df,
  k = 3,
  cat_col = "diagnosis",
  id_col = "participant", num_col = "score"
)

# Order by folds
df_folded &lt;- df_folded %&gt;% arrange(.folds)

## Multiple fold columns
# Useful for repeated cross-validation
# Note: Consider running in parallel
df_folded &lt;- fold(
  data = df,
  k = 3,
  cat_col = "diagnosis",
  id_col = "participant",
  num_fold_cols = 5,
  unique_fold_cols_only = TRUE,
  max_iters = 4
)

# Different `k` per fold column
# Note: `length(k) == num_fold_cols`
df_folded &lt;- fold(
  data = df,
  k = c(2, 3),
  cat_col = "diagnosis",
  id_col = "participant",
  num_fold_cols = 2,
  unique_fold_cols_only = TRUE,
  max_iters = 4
)

# Check the generated columns
# with `summarize_group_cols()`
summarize_group_cols(
  data = df_folded,
  group_cols = paste0('.folds_', 1:2)
)

## Check if additional `extreme_pairing_levels`
## improve the numerical balance
set.seed(2) # try with seed 1 as well
df_folded_1 &lt;- fold(
  data = df,
  k = 3,
  num_col = "score",
  extreme_pairing_levels = 1
)
df_folded_1 %&gt;%
  dplyr::ungroup() %&gt;%
  summarize_balances(group_cols = '.folds', num_cols = 'score')

set.seed(2)  # Try with seed 1 as well
df_folded_2 &lt;- fold(
  data = df,
  k = 3,
  num_col = "score",
  extreme_pairing_levels = 2
)
df_folded_2 %&gt;%
  dplyr::ungroup() %&gt;%
  summarize_balances(group_cols = '.folds', num_cols = 'score')

# We can directly compare how balanced the 'score' is
# in the two fold columns using a combination of
# `summarize_balances()` and `ranked_balances()`
# We see that the second fold column (made with `extreme_pairing_levels = 2`)
# has a lower standard deviation of its mean scores - meaning that they
# are more similar and thus more balanced
df_folded_1$.folds_2 &lt;- df_folded_2$.folds
df_folded_1 %&gt;%
  dplyr::ungroup() %&gt;%
  summarize_balances(group_cols = c('.folds', '.folds_2'), num_cols = 'score') %&gt;%
  ranked_balances()

</code></pre>

<hr>
<h2 id='group'>Create groups from your data</h2><span id='topic+group'></span><span id='topic+window'></span><span id='topic+binning'></span><span id='topic+split'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Divides data into groups by a wide range of methods.
Creates a grouping factor with <code>1</code>s for group 1, <code>2</code>s for group 2, etc.
Returns a <code>data.frame</code> grouped by the grouping factor for easy use in
<code>magrittr `%&gt;%`</code> pipelines.
</p>
<p>By default*, the data points in a group are connected sequentially (e.g. <code>c(1, 1, 2, 2, 3, 3)</code>)
and splitting is done from top to bottom. *Except in the <code>"every"</code> method.
</p>
<p>There are <strong>five</strong> types of grouping methods:
</p>
<p>The <code>"n_*"</code> methods split the data into a given <em>number of groups</em>.
They differ in how they handle excess data points.
</p>
<p>The <code>"greedy"</code> method uses a <em>group size</em> to split the data into groups,
greedily grabbing <code>`n`</code> data points from the top.
The last group may thus differ in size (e.g. <code>c(1, 1, 2, 2, 3)</code>).
</p>
<p>The <code>"l_*"</code> methods use a <em>list</em> of either starting points (<code>"l_starts"</code>)
or group sizes (<code>"l_sizes"</code>). The <code>"l_starts"</code> method can also auto-detect group starts
(when a value differs from the previous value).
</p>
<p>The <code>"every"</code> method puts every <code>`n`</code>th data point into the same group
(e.g. <code>c(1, 2, 3, 1, 2, 3)</code>).
</p>
<p>The step methods <code>"staircase"</code> and <code>"primes"</code> increase the group size by a step for each group.
</p>
<p><strong>Note</strong>: To create groups balanced by a categorical and/or numerical variable, see the
<code><a href="#topic+fold">fold()</a></code> and <code><a href="#topic+partition">partition()</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>group(
  data,
  n,
  method = "n_dist",
  starts_col = NULL,
  force_equal = FALSE,
  allow_zero = FALSE,
  return_factor = FALSE,
  descending = FALSE,
  randomize = FALSE,
  col_name = ".groups",
  remove_missing_starts = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="group_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> or <code>vector</code>.
When a <em>grouped</em> <code>data.frame</code>, the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="group_+3A_n">n</code></td>
<td>
<p><em>Depends on <code>`method`</code>.</em>
</p>
<p>Number of groups (default), group size, list of group sizes,
list of group starts, number of data points between group members,
step size or prime number to start at. See <code>`method`</code>.
</p>
<p>Passed as whole number(s) and/or percentage(s) (<code>0</code> &lt; <code>n</code> &lt; <code>1</code>)
and/or character.
</p>
<p>Method <code>"l_starts"</code> allows <code>'auto'</code>.</p>
</td></tr>
<tr><td><code id="group_+3A_method">method</code></td>
<td>
<p><code>"greedy"</code>, <code>"n_dist"</code>, <code>"n_fill"</code>, <code>"n_last"</code>,
<code>"n_rand"</code>, <code>"l_sizes"</code>, <code>"l_starts"</code>, <code>"every"</code>, <code>"staircase"</code>, or
<code>"primes"</code>.
</p>
<p><strong>Note</strong>: examples are sizes of the generated groups
based on a vector with <code>57</code> elements.
</p>


<h4>greedy</h4>

<p>Divides up the data greedily given a specified group size
<code class="reqn">(e.g. 10, 10, 10, 10, 10, 7)</code>.
</p>
<p><code>`n`</code> is group size.</p>



<h4>n_dist (default)</h4>

<p>Divides the data into a specified number of groups and
distributes excess data points across groups
<code class="reqn">(e.g. 11, 11, 12, 11, 12)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_fill</h4>

<p>Divides the data into a specified number of groups and
fills up groups with excess data points from the beginning
<code class="reqn">(e.g. 12, 12, 11, 11, 11)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_last</h4>

<p>Divides the data into a specified number of groups.
It finds the most equal group sizes possible,
using all data points. Only the last group is able to differ in size
<code class="reqn">(e.g. 11, 11, 11, 11, 13)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_rand</h4>

<p>Divides the data into a specified number of groups.
Excess data points are placed randomly in groups (max. 1 per group)
<code class="reqn">(e.g. 12, 11, 11, 11, 12)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>l_sizes</h4>

<p>Divides up the data by a <code>list</code> of group sizes.
Excess data points are placed in an extra group at the end.
</p>
<p><code class="reqn">E.g. n = list(0.2, 0.3) outputs groups with sizes (11, 17, 29)</code>.
</p>
<p><code>`n`</code> is a <code>list</code> of group sizes.</p>



<h4>l_starts</h4>

<p>Starts new groups at specified values in the <code>`starts_col`</code> vector.
</p>
<p><code>n</code> is a <code>list</code> of starting positions.
Skip values by <code>c(value, skip_to_number)</code> where <code>skip_to_number</code> is the
nth appearance of the value in the vector after the previous group start.
The first data point is automatically a starting position.
</p>
<p><code class="reqn">E.g. n = c(1, 3, 7, 25, 50) outputs groups with sizes (2, 4, 18, 25, 8)</code>.
</p>
<p>To skip: <code class="reqn">given vector c("a", "e", "o", "a", "e", "o"), n = list("a", "e", c("o", 2))
 outputs groups with sizes (1, 4, 1)</code>.</p>

<p>If passing <code class="reqn">n = 'auto'</code> the starting positions are automatically found
such that a group is started whenever a value differs from the previous value
(see <code><a href="#topic+find_starts">find_starts</a>()</code>).
Note that all <code>NA</code>s are first replaced by a single unique value,
meaning that they will also cause group starts.
See <code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>
to set a threshold for what is considered &quot;different&quot;.
</p>
<p><code class="reqn">E.g. n = "auto" for c(10, 10, 7, 8, 8, 9) would start groups at
 the first 10, 7, 8 and 9, and give c(1, 1, 2, 3, 3, 4).</code>
</p>


<h4>every</h4>

<p>Combines every <code>`n`</code>th data point into a group.
<code class="reqn">(e.g. 12, 12, 11, 11, 11 with n = 5)</code>.
</p>
<p><code>`n`</code> is the number of data points between group members (&quot;every n&quot;).</p>



<h4>staircase</h4>

<p>Uses step size to divide up the data.
Group size increases with 1 step for every group,
until there is no more data
<code class="reqn">(e.g. 5, 10, 15, 20, 7)</code>.
</p>
<p><code>`n`</code> is step size.</p>



<h4>primes</h4>

<p>Uses prime numbers as group sizes.
Group size increases to the next prime number
until there is no more data.
<code class="reqn">(e.g. 5, 7, 11, 13, 17, 4)</code>.
</p>
<p><code>`n`</code> is the prime number to start at.</p>
</td></tr>
<tr><td><code id="group_+3A_starts_col">starts_col</code></td>
<td>
<p>Name of column with values to match in method <code>"l_starts"</code>
when <code>`data`</code> is a <code>data.frame</code>. Pass <code>'index'</code> to use row names. (Character)</p>
</td></tr>
<tr><td><code id="group_+3A_force_equal">force_equal</code></td>
<td>
<p>Create equal groups by discarding excess data points.
Implementation varies between methods. (Logical)</p>
</td></tr>
<tr><td><code id="group_+3A_allow_zero">allow_zero</code></td>
<td>
<p>Whether <code>`n`</code> can be passed as <code>0</code>.
Can be useful when programmatically finding <code>n</code>. (Logical)</p>
</td></tr>
<tr><td><code id="group_+3A_return_factor">return_factor</code></td>
<td>
<p>Only return the grouping factor. (Logical)</p>
</td></tr>
<tr><td><code id="group_+3A_descending">descending</code></td>
<td>
<p>Change the direction of the method. (Not fully implemented)
(Logical)</p>
</td></tr>
<tr><td><code id="group_+3A_randomize">randomize</code></td>
<td>
<p>Randomize the grouping factor. (Logical)</p>
</td></tr>
<tr><td><code id="group_+3A_col_name">col_name</code></td>
<td>
<p>Name of the added grouping factor.</p>
</td></tr>
<tr><td><code id="group_+3A_remove_missing_starts">remove_missing_starts</code></td>
<td>
<p>Recursively remove elements from the
list of starts that are not found.
For method <code>"l_starts"</code> only.
(Logical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code> grouped by existing grouping variables and the new grouping factor.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>
<p>Other staircase tools: 
<code><a href="#topic++25primes+25">%primes%</a>()</code>,
<code><a href="#topic++25staircase+25">%staircase%</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>
<p>Other l_starts tools: 
<code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>,
<code><a href="#topic+find_missing_starts">find_missing_starts</a>()</code>,
<code><a href="#topic+find_starts">find_starts</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Create data frame
df &lt;- data.frame(
  "x" = c(1:12),
  "species" = factor(rep(c("cat", "pig", "human"), 4)),
  "age" = sample(c(1:100), 12)
)

# Using group()
df_grouped &lt;- group(df, n = 5, method = "n_dist")

# Using group() in pipeline to get mean age
df_means &lt;- df %&gt;%
  group(n = 5, method = "n_dist") %&gt;%
  dplyr::summarise(mean_age = mean(age))

# Using group() with `l_sizes`
df_grouped &lt;- group(
  data = df,
  n = list(0.2, 0.3),
  method = "l_sizes"
)

# Using group_factor() with `l_starts`
# `c('pig', 2)` skips to the second appearance of
# 'pig' after the first appearance of 'cat'
df_grouped &lt;- group(
  data = df,
  n = list("cat", c("pig", 2), "human"),
  method = "l_starts",
  starts_col = "species"
)

</code></pre>

<hr>
<h2 id='group_factor'>Create grouping factor for subsetting your data</h2><span id='topic+group_factor'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Divides data into groups by a wide range of methods.
Creates and returns a grouping factor
with <code>1</code>s for <em>group 1</em>, <code>2</code>s for <em>group 2</em>, etc.
</p>
<p>By default*, the data points in a group are connected sequentially (e.g. <code>c(1, 1, 2, 2, 3, 3)</code>)
and splitting is done from top to bottom. *Except in the <code>"every"</code> method.
</p>
<p>There are <strong>five</strong> types of grouping methods:
</p>
<p>The <code>"n_*"</code> methods split the data into a given <em>number of groups</em>.
They differ in how they handle excess data points.
</p>
<p>The <code>"greedy"</code> method uses a <em>group size</em> to split the data into groups,
greedily grabbing <code>`n`</code> data points from the top.
The last group may thus differ in size (e.g. <code>c(1, 1, 2, 2, 3)</code>).
</p>
<p>The <code>"l_*"</code> methods use a <em>list</em> of either starting points (<code>"l_starts"</code>)
or group sizes (<code>"l_sizes"</code>). The <code>"l_starts"</code> method can also auto-detect group starts
(when a value differs from the previous value).
</p>
<p>The <code>"every"</code> method puts every <code>`n`</code>th data point into the same group
(e.g. <code>c(1, 2, 3, 1, 2, 3)</code>).
</p>
<p>The step methods <code>"staircase"</code> and <code>"primes"</code> increase the group size by a step for each group.
</p>
<p><strong>Note</strong>: To create groups balanced by a categorical and/or numerical variable, see the
<code><a href="#topic+fold">fold()</a></code> and <code><a href="#topic+partition">partition()</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>group_factor(
  data,
  n,
  method = "n_dist",
  starts_col = NULL,
  force_equal = FALSE,
  allow_zero = FALSE,
  descending = FALSE,
  randomize = FALSE,
  remove_missing_starts = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="group_factor_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> or <code>vector</code>.
When a <em>grouped</em> <code>data.frame</code>, the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="group_factor_+3A_n">n</code></td>
<td>
<p><em>Depends on <code>`method`</code>.</em>
</p>
<p>Number of groups (default), group size, list of group sizes,
list of group starts, number of data points between group members,
step size or prime number to start at. See <code>`method`</code>.
</p>
<p>Passed as whole number(s) and/or percentage(s) (<code>0</code> &lt; <code>n</code> &lt; <code>1</code>)
and/or character.
</p>
<p>Method <code>"l_starts"</code> allows <code>'auto'</code>.</p>
</td></tr>
<tr><td><code id="group_factor_+3A_method">method</code></td>
<td>
<p><code>"greedy"</code>, <code>"n_dist"</code>, <code>"n_fill"</code>, <code>"n_last"</code>,
<code>"n_rand"</code>, <code>"l_sizes"</code>, <code>"l_starts"</code>, <code>"every"</code>, <code>"staircase"</code>, or
<code>"primes"</code>.
</p>
<p><strong>Note</strong>: examples are sizes of the generated groups
based on a vector with <code>57</code> elements.
</p>


<h4>greedy</h4>

<p>Divides up the data greedily given a specified group size
<code class="reqn">(e.g. 10, 10, 10, 10, 10, 7)</code>.
</p>
<p><code>`n`</code> is group size.</p>



<h4>n_dist (default)</h4>

<p>Divides the data into a specified number of groups and
distributes excess data points across groups
<code class="reqn">(e.g. 11, 11, 12, 11, 12)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_fill</h4>

<p>Divides the data into a specified number of groups and
fills up groups with excess data points from the beginning
<code class="reqn">(e.g. 12, 12, 11, 11, 11)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_last</h4>

<p>Divides the data into a specified number of groups.
It finds the most equal group sizes possible,
using all data points. Only the last group is able to differ in size
<code class="reqn">(e.g. 11, 11, 11, 11, 13)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_rand</h4>

<p>Divides the data into a specified number of groups.
Excess data points are placed randomly in groups (max. 1 per group)
<code class="reqn">(e.g. 12, 11, 11, 11, 12)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>l_sizes</h4>

<p>Divides up the data by a <code>list</code> of group sizes.
Excess data points are placed in an extra group at the end.
</p>
<p><code class="reqn">E.g. n = list(0.2, 0.3) outputs groups with sizes (11, 17, 29)</code>.
</p>
<p><code>`n`</code> is a <code>list</code> of group sizes.</p>



<h4>l_starts</h4>

<p>Starts new groups at specified values in the <code>`starts_col`</code> vector.
</p>
<p><code>n</code> is a <code>list</code> of starting positions.
Skip values by <code>c(value, skip_to_number)</code> where <code>skip_to_number</code> is the
nth appearance of the value in the vector after the previous group start.
The first data point is automatically a starting position.
</p>
<p><code class="reqn">E.g. n = c(1, 3, 7, 25, 50) outputs groups with sizes (2, 4, 18, 25, 8)</code>.
</p>
<p>To skip: <code class="reqn">given vector c("a", "e", "o", "a", "e", "o"), n = list("a", "e", c("o", 2))
 outputs groups with sizes (1, 4, 1)</code>.</p>

<p>If passing <code class="reqn">n = 'auto'</code> the starting positions are automatically found
such that a group is started whenever a value differs from the previous value
(see <code><a href="#topic+find_starts">find_starts</a>()</code>).
Note that all <code>NA</code>s are first replaced by a single unique value,
meaning that they will also cause group starts.
See <code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>
to set a threshold for what is considered &quot;different&quot;.
</p>
<p><code class="reqn">E.g. n = "auto" for c(10, 10, 7, 8, 8, 9) would start groups at
 the first 10, 7, 8 and 9, and give c(1, 1, 2, 3, 3, 4).</code>
</p>


<h4>every</h4>

<p>Combines every <code>`n`</code>th data point into a group.
<code class="reqn">(e.g. 12, 12, 11, 11, 11 with n = 5)</code>.
</p>
<p><code>`n`</code> is the number of data points between group members (&quot;every n&quot;).</p>



<h4>staircase</h4>

<p>Uses step size to divide up the data.
Group size increases with 1 step for every group,
until there is no more data
<code class="reqn">(e.g. 5, 10, 15, 20, 7)</code>.
</p>
<p><code>`n`</code> is step size.</p>



<h4>primes</h4>

<p>Uses prime numbers as group sizes.
Group size increases to the next prime number
until there is no more data.
<code class="reqn">(e.g. 5, 7, 11, 13, 17, 4)</code>.
</p>
<p><code>`n`</code> is the prime number to start at.</p>
</td></tr>
<tr><td><code id="group_factor_+3A_starts_col">starts_col</code></td>
<td>
<p>Name of column with values to match in method <code>"l_starts"</code>
when <code>`data`</code> is a <code>data.frame</code>. Pass <code>'index'</code> to use row names. (Character)</p>
</td></tr>
<tr><td><code id="group_factor_+3A_force_equal">force_equal</code></td>
<td>
<p>Create equal groups by discarding excess data points.
Implementation varies between methods. (Logical)</p>
</td></tr>
<tr><td><code id="group_factor_+3A_allow_zero">allow_zero</code></td>
<td>
<p>Whether <code>`n`</code> can be passed as <code>0</code>.
Can be useful when programmatically finding <code>n</code>. (Logical)</p>
</td></tr>
<tr><td><code id="group_factor_+3A_descending">descending</code></td>
<td>
<p>Change the direction of the method. (Not fully implemented)
(Logical)</p>
</td></tr>
<tr><td><code id="group_factor_+3A_randomize">randomize</code></td>
<td>
<p>Randomize the grouping factor. (Logical)</p>
</td></tr>
<tr><td><code id="group_factor_+3A_remove_missing_starts">remove_missing_starts</code></td>
<td>
<p>Recursively remove elements from the
list of starts that are not found.
For method <code>"l_starts"</code> only.
(Logical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Grouping factor with <code>1</code>s for group 1, <code>2</code>s for group 2, etc.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>,
the output is a <code>data.frame</code> with the existing groupings
and the generated grouping factor. The row order from <code>`data`</code> is maintained.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>
<p>Other staircase tools: 
<code><a href="#topic++25primes+25">%primes%</a>()</code>,
<code><a href="#topic++25staircase+25">%staircase%</a>()</code>,
<code><a href="#topic+group">group</a>()</code>
</p>
<p>Other l_starts tools: 
<code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>,
<code><a href="#topic+find_missing_starts">find_missing_starts</a>()</code>,
<code><a href="#topic+find_starts">find_starts</a>()</code>,
<code><a href="#topic+group">group</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Create a data frame
df &lt;- data.frame(
  "x" = c(1:12),
  "species" = factor(rep(c("cat", "pig", "human"), 4)),
  "age" = sample(c(1:100), 12)
)

# Using group_factor() with n_dist
groups &lt;- group_factor(df, 5, method = "n_dist")
df$groups &lt;- groups

# Using group_factor() with greedy
groups &lt;- group_factor(df, 5, method = "greedy")
df$groups &lt;- groups

# Using group_factor() with l_sizes
groups &lt;- group_factor(df, list(0.2, 0.3), method = "l_sizes")
df$groups &lt;- groups

# Using group_factor() with l_starts
groups &lt;- group_factor(df, list("cat", c("pig", 2), "human"),
  method = "l_starts", starts_col = "species"
)
df$groups &lt;- groups
</code></pre>

<hr>
<h2 id='partition'>Create balanced partitions</h2><span id='topic+partition'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Splits data into partitions.
Balances a given categorical variable and/or numerical variable between partitions and keeps (if possible)
all data points with a shared ID (e.g. participant_id) in the same partition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partition(
  data,
  p = 0.2,
  cat_col = NULL,
  num_col = NULL,
  id_col = NULL,
  id_aggregation_fn = sum,
  extreme_pairing_levels = 1,
  force_equal = FALSE,
  list_out = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partition_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="partition_+3A_p">p</code></td>
<td>
<p>List or vector of partition sizes.
Given as whole number(s) and/or percentage(s) (<code>0</code> &lt; <code>`p`</code> &lt; <code>1</code>).
</p>
<p>E.g. <code class="reqn">c(0.2, 3, 0.1)</code>.</p>
</td></tr>
<tr><td><code id="partition_+3A_cat_col">cat_col</code></td>
<td>
<p>Name of categorical variable to balance between partitions.
</p>
<p>E.g. when training and testing a model for predicting a binary variable (a or b),
we usually want both classes represented in both the training set and the test set.
</p>
<p>N.B. If also passing an <code>`id_col`</code>, <code>`cat_col`</code> should be constant within each ID.</p>
</td></tr>
<tr><td><code id="partition_+3A_num_col">num_col</code></td>
<td>
<p>Name of numerical variable to balance between partitions.
</p>
<p>N.B. When used with <code>`id_col`</code>, values in <code>`num_col`</code> for each ID are
aggregated using <code>`id_aggregation_fn`</code> before being balanced.</p>
</td></tr>
<tr><td><code id="partition_+3A_id_col">id_col</code></td>
<td>
<p>Name of factor with IDs. Used to keep all rows that share an ID in
the same partition (if possible).
</p>
<p>E.g. If we have measured a participant multiple times and want to see the
effect of time, we want to have all observations of this participant in
the same partition.
</p>
<p>N.B. When <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>
(see <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>), IDs that appear in multiple
groupings might end up in different partitions in those groupings.</p>
</td></tr>
<tr><td><code id="partition_+3A_id_aggregation_fn">id_aggregation_fn</code></td>
<td>
<p>Function for aggregating values in <code>`num_col`</code> for each ID,
before balancing <code>`num_col`</code>.
</p>
<p>N.B. Only used when <code>`num_col`</code> and <code>`id_col`</code> are both specified.</p>
</td></tr>
<tr><td><code id="partition_+3A_extreme_pairing_levels">extreme_pairing_levels</code></td>
<td>
<p>How many levels of extreme pairing to do
when balancing partitions by a numerical column (i.e. <code>`num_col`</code> is specified).
</p>
<p><strong>Extreme pairing</strong>: Rows/pairs are ordered as <em>smallest, largest,
second smallest, second largest</em>, etc. If <code>`extreme_pairing_levels` &gt; 1</code>,
this is done &quot;recursively&quot; on the extreme pairs. See <code>`Details/num_col`</code> for more.
</p>
<p>N.B. Larger values work best with large datasets. If set too high,
the result might not be stochastic. Always check if an increase
actually makes the partitions more balanced. See <code>`Examples`</code>.</p>
</td></tr>
<tr><td><code id="partition_+3A_force_equal">force_equal</code></td>
<td>
<p>Whether to discard excess data. (Logical)</p>
</td></tr>
<tr><td><code id="partition_+3A_list_out">list_out</code></td>
<td>
<p>Whether to return partitions in a <code>list</code>. (Logical)
</p>
<p><strong>N.B.</strong> When <code>`data`</code> is a grouped <code>data.frame</code>, the output is always a <code>data.frame</code>
with partition identifiers.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>cat_col</h4>


<ol>
<li> <p><code>`data`</code> is subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> Subsets are partitioned and merged.
</p>
</li></ol>




<h4>id_col</h4>


<ol>
<li><p> Partitions are created from unique IDs.
</p>
</li></ol>




<h4>num_col</h4>


<ol>
<li><p>Rows are shuffled. <strong>Note</strong> that this will only affect rows with the same value in <code>`num_col`</code>.
</p>
</li>
<li><p>Extreme pairing 1: Rows are ordered as <em>smallest, largest, second smallest, second largest</em>, etc.
Each pair get a group identifier.
</p>
</li>
<li><p>If <code>`extreme_pairing_levels` &gt; 1</code>: The group identifiers are reordered as <em>smallest,
largest, second smallest, second largest</em>, etc., by the sum of <code>`num_col`</code> in the represented rows.
These pairs (of pairs) get a new set of group identifiers, and the process is repeated
<code>`extreme_pairing_levels`-2</code> times. Note that the group identifiers at the last level will represent
<code>2^`extreme_pairing_levels`</code> rows, why you should be careful when choosing that setting.
</p>
</li>
<li><p>The final group identifiers are shuffled, and their order is applied to the full dataset.
</p>
</li>
<li><p>The ordered dataset is split by the sizes in <code>`p`</code>.
</p>
</li></ol>

<p>N.B. When doing extreme pairing of an unequal number of rows,
the row with the largest value is placed in a group by itself, and the order is instead:
<em>smallest, second largest, second smallest, third largest, ...</em> , largest.
</p>



<h4>cat_col AND id_col</h4>


<ol>
<li> <p><code>`data`</code> is subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> Partitions are created from unique IDs in each subset.
</p>
</li>
<li><p> Subsets are merged.
</p>
</li></ol>




<h4>cat_col AND num_col</h4>


<ol>
<li> <p><code>`data`</code> is subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> Subsets are partitioned by <code>`num_col`</code>.
</p>
</li>
<li><p> Subsets are merged.
</p>
</li></ol>




<h4>num_col AND id_col</h4>


<ol>
<li><p> Values in <code>`num_col`</code> are aggregated for each ID, using <code>id_aggregation_fn</code>.
</p>
</li>
<li><p> The IDs are partitioned, using the aggregated values as &quot;<code>num_col</code>&quot;.
</p>
</li>
<li><p> The partition identifiers are transferred to the rows of the IDs.
</p>
</li></ol>




<h4>cat_col AND num_col AND id_col</h4>


<ol>
<li><p> Values in <code>`num_col`</code> are aggregated for each ID, using <code>id_aggregation_fn</code>.
</p>
</li>
<li><p> IDs are subset by <code>`cat_col`</code>.
</p>
</li>
<li><p> The IDs for each subset are partitioned,
by using the aggregated values as &quot;<code>num_col</code>&quot;.
</p>
</li>
<li><p> The partition identifiers are transferred to the rows of the IDs.
</p>
</li></ol>




<h3>Value</h3>

<p>If <code>`list_out`</code> is <code>TRUE</code>:
</p>
<p>A <code>list</code> of partitions where partitions are <code>data.frame</code>s.
</p>
<p>If <code>`list_out`</code> is <code>FALSE</code>:
</p>
<p>A <code>data.frame</code> with grouping factor for subsetting.
</p>
<p><strong>N.B.</strong> When <code>`data`</code> is a grouped <code>data.frame</code>,
the output is always a <code>data.frame</code> with a grouping factor.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+splt">splt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Create data frame
df &lt;- data.frame(
  "participant" = factor(rep(c("1", "2", "3", "4", "5", "6"), 3)),
  "age" = rep(sample(c(1:100), 6), 3),
  "diagnosis" = factor(rep(c("a", "b", "a", "a", "b", "b"), 3)),
  "score" = sample(c(1:100), 3 * 6)
)
df &lt;- df %&gt;% arrange(participant)
df$session &lt;- rep(c("1", "2", "3"), 6)

# Using partition()

# Without balancing
partitions &lt;- partition(data = df, p = c(0.2, 0.3))

# With cat_col
partitions &lt;- partition(data = df, p = 0.5, cat_col = "diagnosis")

# With id_col
partitions &lt;- partition(data = df, p = 0.5, id_col = "participant")

# With num_col
partitions &lt;- partition(data = df, p = 0.5, num_col = "score")

# With cat_col and id_col
partitions &lt;- partition(
  data = df,
  p = 0.5,
  cat_col = "diagnosis",
  id_col = "participant"
)

# With cat_col, num_col and id_col
partitions &lt;- partition(
  data = df,
  p = 0.5,
  cat_col = "diagnosis",
  num_col = "score",
  id_col = "participant"
)

# Return data frame with grouping factor
# with list_out = FALSE
partitions &lt;- partition(df, c(0.5), list_out = FALSE)

# Check if additional extreme_pairing_levels
# improve the numerical balance
set.seed(2) # try with seed 1 as well
partitions_1 &lt;- partition(
  data = df,
  p = 0.5,
  num_col = "score",
  extreme_pairing_levels = 1,
  list_out = FALSE
)
partitions_1 %&gt;%
  dplyr::group_by(.partitions) %&gt;%
  dplyr::summarise(
    sum_score = sum(score),
    mean_score = mean(score)
  )
set.seed(2) # try with seed 1 as well
partitions_2 &lt;- partition(
  data = df,
  p = 0.5,
  num_col = "score",
  extreme_pairing_levels = 2,
  list_out = FALSE
)
partitions_2 %&gt;%
  dplyr::group_by(.partitions) %&gt;%
  dplyr::summarise(
    sum_score = sum(score),
    mean_score = mean(score)
  )
</code></pre>

<hr>
<h2 id='ranked_balances'>Extract ranked standard deviations from summary</h2><span id='topic+ranked_balances'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>Extract the standard deviations (default) from the <code>"Summary" data.frame</code>
from the output of <code><a href="#topic+summarize_balances">summarize_balances()</a></code>,
ordered by the <code>`SD_rank`</code> column.
</p>
<p>See examples of usage in
<code><a href="#topic+summarize_balances">summarize_balances()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranked_balances(summary, measure = "SD")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ranked_balances_+3A_summary">summary</code></td>
<td>
<p><code>"Summary" data.frame</code> from output of
<code><a href="#topic+summarize_balances">summarize_balances()</a></code>.
</p>
<p>Can also be the direct output list of
<code><a href="#topic+summarize_balances">summarize_balances()</a></code>, in which case
the <code>"Summary"</code> element is used.</p>
</td></tr>
<tr><td><code id="ranked_balances_+3A_measure">measure</code></td>
<td>
<p>The measure to extract rows for. One of:
<code>"mean", "median", "SD", "IQR", "min", "max"</code>.
</p>
<p>The most meaningful measures to consider as metrics of balance are <code>`SD`</code> and <code>`IQR`</code>,
as a smaller spread of variables across group summaries means they are more similar.
</p>
<p><strong>NOTE</strong>: Ranks are of standard deviations and not affected by this argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The rows in <code>`summary`</code> where <code>`measure` == "SD"</code>,
ordered by the <code>`SD_rank`</code> column.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other summarization functions: 
<code><a href="#topic+summarize_balances">summarize_balances</a>()</code>,
<code><a href="#topic+summarize_group_cols">summarize_group_cols</a>()</code>
</p>

<hr>
<h2 id='render_toc'>Render Table of Contents</h2><span id='topic+render_toc'></span>

<h3>Description</h3>

<p>From: https://gist.github.com/gadenbuie/c83e078bf8c81b035e32c3fc0cf04ee8
</p>


<h3>Usage</h3>

<pre><code class='language-R'>render_toc(
  filename,
  toc_header_name = "Table of Contents",
  base_level = NULL,
  toc_depth = 3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="render_toc_+3A_filename">filename</code></td>
<td>
<p>Name of RMarkdown or Markdown document</p>
</td></tr>
<tr><td><code id="render_toc_+3A_toc_header_name">toc_header_name</code></td>
<td>
<p>The table of contents header name. If specified, any
header with this format will not be included in the TOC. Set to <code>NULL</code> to
include the TOC itself in the TOC (but why?).</p>
</td></tr>
<tr><td><code id="render_toc_+3A_base_level">base_level</code></td>
<td>
<p>Starting level of the lowest header level. Any headers
prior to the first header at the base_level are dropped silently.</p>
</td></tr>
<tr><td><code id="render_toc_+3A_toc_depth">toc_depth</code></td>
<td>
<p>Maximum depth for TOC, relative to base_level. Default is
<code>toc_depth = 3</code>, which results in a TOC of at most 3 levels.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple function to extract headers from an RMarkdown or Markdown document
and build a table of contents. Returns a markdown list with links to the
headers using pandoc header identifiers.
</p>
<p>WARNING: This function only works with hash-tag headers.
</p>
<p>Because this function returns only the markdown list, the header for the
Table of Contents itself must be manually included in the text. Use
<code>toc_header_name</code> to exclude the table of contents header from the TOC, or
set to <code>NULL</code> for it to be included.
</p>


<h3>Usage</h3>

<p>Just drop in a <strong>chunk</strong> where you want the toc to appear (set <code>echo=FALSE</code>):
<code>render_toc("/path/to/the/file.Rmd")</code>
</p>

<hr>
<h2 id='splt'>Split data by a range of methods</h2><span id='topic+splt'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#stable"><img src="../help/figures/lifecycle-stable.svg" alt='[Stable]' /></a>
</p>
<p>Divides data into groups by a wide range of methods.
Splits data by these groups.
</p>
<p>Wraps <code><a href="#topic+group">group()</a></code> with <code><a href="base.html#topic+split">split()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splt(
  data,
  n,
  method = "n_dist",
  starts_col = NULL,
  force_equal = FALSE,
  allow_zero = FALSE,
  descending = FALSE,
  randomize = FALSE,
  remove_missing_starts = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splt_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> or <code>vector</code>.
When a <em>grouped</em> <code>data.frame</code>, the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="splt_+3A_n">n</code></td>
<td>
<p><em>Depends on <code>`method`</code>.</em>
</p>
<p>Number of groups (default), group size, list of group sizes,
list of group starts, number of data points between group members,
step size or prime number to start at. See <code>`method`</code>.
</p>
<p>Passed as whole number(s) and/or percentage(s) (<code>0</code> &lt; <code>n</code> &lt; <code>1</code>)
and/or character.
</p>
<p>Method <code>"l_starts"</code> allows <code>'auto'</code>.</p>
</td></tr>
<tr><td><code id="splt_+3A_method">method</code></td>
<td>
<p><code>"greedy"</code>, <code>"n_dist"</code>, <code>"n_fill"</code>, <code>"n_last"</code>,
<code>"n_rand"</code>, <code>"l_sizes"</code>, <code>"l_starts"</code>, <code>"every"</code>, <code>"staircase"</code>, or
<code>"primes"</code>.
</p>
<p><strong>Note</strong>: examples are sizes of the generated groups
based on a vector with <code>57</code> elements.
</p>


<h4>greedy</h4>

<p>Divides up the data greedily given a specified group size
<code class="reqn">(e.g. 10, 10, 10, 10, 10, 7)</code>.
</p>
<p><code>`n`</code> is group size.</p>



<h4>n_dist (default)</h4>

<p>Divides the data into a specified number of groups and
distributes excess data points across groups
<code class="reqn">(e.g. 11, 11, 12, 11, 12)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_fill</h4>

<p>Divides the data into a specified number of groups and
fills up groups with excess data points from the beginning
<code class="reqn">(e.g. 12, 12, 11, 11, 11)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_last</h4>

<p>Divides the data into a specified number of groups.
It finds the most equal group sizes possible,
using all data points. Only the last group is able to differ in size
<code class="reqn">(e.g. 11, 11, 11, 11, 13)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>n_rand</h4>

<p>Divides the data into a specified number of groups.
Excess data points are placed randomly in groups (max. 1 per group)
<code class="reqn">(e.g. 12, 11, 11, 11, 12)</code>.
</p>
<p><code>`n`</code> is number of groups.</p>



<h4>l_sizes</h4>

<p>Divides up the data by a <code>list</code> of group sizes.
Excess data points are placed in an extra group at the end.
</p>
<p><code class="reqn">E.g. n = list(0.2, 0.3) outputs groups with sizes (11, 17, 29)</code>.
</p>
<p><code>`n`</code> is a <code>list</code> of group sizes.</p>



<h4>l_starts</h4>

<p>Starts new groups at specified values in the <code>`starts_col`</code> vector.
</p>
<p><code>n</code> is a <code>list</code> of starting positions.
Skip values by <code>c(value, skip_to_number)</code> where <code>skip_to_number</code> is the
nth appearance of the value in the vector after the previous group start.
The first data point is automatically a starting position.
</p>
<p><code class="reqn">E.g. n = c(1, 3, 7, 25, 50) outputs groups with sizes (2, 4, 18, 25, 8)</code>.
</p>
<p>To skip: <code class="reqn">given vector c("a", "e", "o", "a", "e", "o"), n = list("a", "e", c("o", 2))
 outputs groups with sizes (1, 4, 1)</code>.</p>

<p>If passing <code class="reqn">n = 'auto'</code> the starting positions are automatically found
such that a group is started whenever a value differs from the previous value
(see <code><a href="#topic+find_starts">find_starts</a>()</code>).
Note that all <code>NA</code>s are first replaced by a single unique value,
meaning that they will also cause group starts.
See <code><a href="#topic+differs_from_previous">differs_from_previous</a>()</code>
to set a threshold for what is considered &quot;different&quot;.
</p>
<p><code class="reqn">E.g. n = "auto" for c(10, 10, 7, 8, 8, 9) would start groups at
 the first 10, 7, 8 and 9, and give c(1, 1, 2, 3, 3, 4).</code>
</p>


<h4>every</h4>

<p>Combines every <code>`n`</code>th data point into a group.
<code class="reqn">(e.g. 12, 12, 11, 11, 11 with n = 5)</code>.
</p>
<p><code>`n`</code> is the number of data points between group members (&quot;every n&quot;).</p>



<h4>staircase</h4>

<p>Uses step size to divide up the data.
Group size increases with 1 step for every group,
until there is no more data
<code class="reqn">(e.g. 5, 10, 15, 20, 7)</code>.
</p>
<p><code>`n`</code> is step size.</p>



<h4>primes</h4>

<p>Uses prime numbers as group sizes.
Group size increases to the next prime number
until there is no more data.
<code class="reqn">(e.g. 5, 7, 11, 13, 17, 4)</code>.
</p>
<p><code>`n`</code> is the prime number to start at.</p>
</td></tr>
<tr><td><code id="splt_+3A_starts_col">starts_col</code></td>
<td>
<p>Name of column with values to match in method <code>"l_starts"</code>
when <code>`data`</code> is a <code>data.frame</code>. Pass <code>'index'</code> to use row names. (Character)</p>
</td></tr>
<tr><td><code id="splt_+3A_force_equal">force_equal</code></td>
<td>
<p>Create equal groups by discarding excess data points.
Implementation varies between methods. (Logical)</p>
</td></tr>
<tr><td><code id="splt_+3A_allow_zero">allow_zero</code></td>
<td>
<p>Whether <code>`n`</code> can be passed as <code>0</code>.
Can be useful when programmatically finding <code>n</code>. (Logical)</p>
</td></tr>
<tr><td><code id="splt_+3A_descending">descending</code></td>
<td>
<p>Change the direction of the method. (Not fully implemented)
(Logical)</p>
</td></tr>
<tr><td><code id="splt_+3A_randomize">randomize</code></td>
<td>
<p>Randomize the grouping factor. (Logical)</p>
</td></tr>
<tr><td><code id="splt_+3A_remove_missing_starts">remove_missing_starts</code></td>
<td>
<p>Recursively remove elements from the
list of starts that are not found.
For method <code>"l_starts"</code> only.
(Logical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> of the split <code>`data`</code>.
</p>
<p><strong>N.B.</strong> If <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>, there's an outer list
for each group. The names are based on the group indices
(see <code><a href="dplyr.html#topic+group_data">dplyr::group_indices()</a></code>).
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other grouping functions: 
<code><a href="#topic+all_groups_identical">all_groups_identical</a>()</code>,
<code><a href="#topic+collapse_groups">collapse_groups</a>()</code>,
<code><a href="#topic+collapse_groups_by">collapse_groups_by</a></code>,
<code><a href="#topic+fold">fold</a>()</code>,
<code><a href="#topic+group">group</a>()</code>,
<code><a href="#topic+group_factor">group_factor</a>()</code>,
<code><a href="#topic+partition">partition</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

# Create data frame
df &lt;- data.frame(
  "x" = c(1:12),
  "species" = factor(rep(c("cat", "pig", "human"), 4)),
  "age" = sample(c(1:100), 12)
)

# Using splt()
df_list &lt;- splt(df, 5, method = "n_dist")
</code></pre>

<hr>
<h2 id='summarize_balances'>Summarize group balances</h2><span id='topic+summarize_balances'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>Summarize the balances of numeric, categorical, and ID columns
in and between groups in one or more group columns.
</p>
<p>This tool allows you to quickly and thoroughly assess the balance
of different columns between groups. This is for instance useful
after creating groups with <code><a href="#topic+fold">fold()</a></code>,
<code><a href="#topic+partition">partition()</a></code>, or
<code><a href="#topic+collapse_groups">collapse_groups()</a></code> to
check how well they did and to compare multiple
groupings.
</p>
<p>The output contains:
</p>

<ol>
<li> <p><code>`Groups`</code>: a summary per group (per grouping column).
</p>
</li>
<li> <p><code>`Summary`</code>: statistical descriptors of the group summaries.
</p>
</li>
<li> <p><code>`Normalized Summary`</code>: statistical descriptors of a set of
&quot;normalized&quot; group summaries. (Disabled by default)
</p>
</li></ol>

<p>When comparing how balanced the grouping columns are, we can use
the standard deviations of the group summary columns. The lower a standard
deviation is, the more similar the groups are in that column. To quickly
extract these standard deviations, ordered by an aggregated rank,
use <code><a href="#topic+ranked_balances">ranked_balances()</a></code> on the
<code>"Summary" data.frame</code> in the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_balances(
  data,
  group_cols,
  cat_cols = NULL,
  num_cols = NULL,
  id_cols = NULL,
  summarize_size = TRUE,
  include_normalized = FALSE,
  rank_weights = NULL,
  cat_levels_rank_weights = NULL,
  num_normalize_fn = function(x) {
     rearrr::min_max_scale(x, old_min = quantile(x,
    0.025), old_max = quantile(x, 0.975), new_min = 0, new_max = 1)
 }
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarize_balances_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with group columns to summarize
by.
</p>
<p>Can be <em>grouped</em> (see <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>),
in which case the function is applied group-wise. This is not to
be confused with <code>`group_cols`</code>.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_group_cols">group_cols</code></td>
<td>
<p>Names of columns with group identifiers to summarize columns
in <code>`data`</code> by.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_cat_cols">cat_cols</code></td>
<td>
<p>Names of categorical columns to summarize.
</p>
<p>Each categorical level is counted per group.
</p>
<p>To distinguish between levels with the same name from different
<code>`cat_col`</code> columns, we prefix the count column name for each
categorical level with parts of the name of the categorical column.
This amount can be controlled with <code>`max_cat_prefix_chars`</code>.
</p>
<p>Normalization when <code>`include_normalized`</code> is enabled:
The counts of each categorical level is normalized with <code>log(1 + count)</code>.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_num_cols">num_cols</code></td>
<td>
<p>Names of numerical columns to summarize.
</p>
<p>For each column, the <code>mean</code> and <code>sum</code> is calculated per group.
</p>
<p>Normalization when <code>`include_normalized`</code> is enabled:
Each column is normalized with <code>`num_normalize_fn`</code> before
calculating the <code>mean</code> and <code>sum</code> per group.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_id_cols">id_cols</code></td>
<td>
<p>Names of <code>factor</code> columns with IDs to summarize.
</p>
<p>The number of unique IDs are counted per group.
</p>
<p>Normalization when <code>`include_normalized`</code> is enabled:
The count of unique IDs is normalized with <code>log(1 + count)</code>.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_summarize_size">summarize_size</code></td>
<td>
<p>Whether to summarize the number of rows per group.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_include_normalized">include_normalized</code></td>
<td>
<p>Whether to calculate and include the
normalized summary in the output.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_rank_weights">rank_weights</code></td>
<td>
<p>A named <code>vector</code> with weights for averaging the rank columns when calculating the <code>`SD_rank`</code> column.
The name is one of the balancing columns and the number is its weight. Non-specified columns are given the weight <code>1</code>.
The weights are automatically scaled to sum to 1.
</p>
<p>When summarizing size (see <code>`summarize_size`</code>), name its weight <code>"size"</code>.
</p>
<p>E.g. <code>c("size" = 1, "a_cat_col" = 2, "a_num_col" = 4, "an_id_col" = 2)</code>.</p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_cat_levels_rank_weights">cat_levels_rank_weights</code></td>
<td>
<p>Weights for averaging ranks of the categorical levels in <code>`cat_cols`</code>.
Given as a named <code>list</code> with a named <code>vector</code> for each column in <code>`cat_cols`</code>.
Non-specified levels are given the weight <code>1</code>.
The weights are automatically scaled to sum to 1.
</p>
<p>E.g. <code>list("a_cat_col" = c("a" = 3, "b" = 5), "b_cat_col" = c("1" = 3, "2" = 9))</code></p>
</td></tr>
<tr><td><code id="summarize_balances_+3A_num_normalize_fn">num_normalize_fn</code></td>
<td>
<p>Function for normalizing the <code>`num_cols`</code> columns before
calculating normalized group summaries.
</p>
<p>Only used when <code>`include_normalized`</code> is enabled.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list</code> with two/three <code>data.frames</code>:
</p>


<h4>Groups</h4>

<p>A summary per group.
</p>
<p><code>`cat_cols`</code>: Each level has its own column with the count
of the level per group.
</p>
<p><code>`num_cols`</code>: The <code>mean</code> and <code>sum</code> per group.
</p>
<p><code>`id_cols`</code>: The count of unique IDs per group.
</p>



<h4>Summary</h4>

<p>Statistical descriptors of the columns in <code>`Groups`</code>.
</p>
<p>Contains the <code>mean</code>, <code>median</code>, standard deviation (<code>SD</code>),
interquartile range (<code>IQR</code>), <code>min</code>, and <code>max</code> measures.
</p>
<p>Especially the standard deviations and IQR measures can tell us about how
balanced the groups are. When comparing multiple <code>`group_cols`</code>,
the group column with the lowest <code>SD</code> and <code>IQR</code>
can be considered the most balanced.
</p>



<h4>Normalized Summary</h4>

<p>(Disabled by default)
</p>
<p>Same statistical descriptors as in <code>`Summary`</code> but for a
&quot;normalized&quot; version of the group summaries. The motivation
is that these normalized measures can more easily be compared
or combined to a single &quot;balance score&quot;.
</p>
<p>First, we normalize each balance column:
</p>
<p><code>`cat_cols`</code>: The level counts in the original group summaries are
normalized with with <code>log(1 + count)</code>. This eases comparison
of the statistical descriptors (especially standard deviations)
of levels with very different count scales.
</p>
<p><code>`num_cols`</code>: The numeric columns are normalized prior to
summarization by group, using the <code>`num_normalize_fn`</code> function.
By default this applies MinMax scaling to columns such that ~95% of the values
are expected to be in the <code>[0, 1]</code> range.
</p>
<p><code>`id_cols`</code>: The counts of unique IDs in the original group summaries are
normalized with <code>log(1 + count)</code>.
</p>
<p>Contains the <code>mean</code>, <code>median</code>, standard deviation (<code>SD</code>),
interquartile range (<code>IQR</code>), <code>min</code>, and <code>max</code> measures.
</p>



<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other summarization functions: 
<code><a href="#topic+ranked_balances">ranked_balances</a>()</code>,
<code><a href="#topic+summarize_group_cols">summarize_group_cols</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)
library(dplyr)

set.seed(1)

# Create data frame
df &lt;- data.frame(
  "participant" = factor(rep(c("1", "2", "3", "4", "5", "6"), 3)),
  "age" = rep(sample(c(1:100), 6), 3),
  "diagnosis" = factor(rep(c("a", "b", "a", "a", "b", "b"), 3)),
  "score" = sample(c(1:100), 3 * 6)
)
df &lt;- df %&gt;% arrange(participant)
df$session &lt;- rep(c("1", "2", "3"), 6)

# Using fold()

## Without balancing
set.seed(1)
df_folded &lt;- fold(data = df, k = 3)

# Check the balances of the various columns
# As we have not used balancing in `fold()`
# we should not expect it to be amazingly balanced
df_folded %&gt;%
  dplyr::ungroup() %&gt;%
  summarize_balances(
    group_cols = ".folds",
    num_cols = c("score", "age"),
    cat_cols = "diagnosis",
    id_cols = "participant"
  )

## With balancing
set.seed(1)
df_folded &lt;- fold(
  data = df,
  k = 3,
  cat_col = "diagnosis",
  num_col = 'score',
  id_col = 'participant'
)

# Now the balance should be better
# although it may be difficult to get a good balance
# the 'score' column when also balancing on 'diagnosis'
# and keeping all rows per participant in the same fold
df_folded %&gt;%
  dplyr::ungroup() %&gt;%
  summarize_balances(
    group_cols = ".folds",
    num_cols = c("score", "age"),
    cat_cols = "diagnosis",
    id_cols = "participant"
  )

# Comparing multiple grouping columns
# Create 3 fold column that only balance "score"
set.seed(1)
df_folded &lt;- fold(
  data = df,
  k = 3,
  num_fold_cols = 3,
  num_col = 'score'
)

# Summarize all three grouping cols at once
(summ &lt;- df_folded %&gt;%
  dplyr::ungroup() %&gt;%
  summarize_balances(
    group_cols = paste0(".folds_", 1:3),
    num_cols = c("score")
  )
)

# Extract the across-group standard deviations
# The group column with the lowest standard deviation(s)
# is the most balanced group column
summ %&gt;% ranked_balances()

</code></pre>

<hr>
<h2 id='summarize_group_cols'>Summarize group columns</h2><span id='topic+summarize_group_cols'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt='[Experimental]' /></a>
</p>
<p>Get the following summary statistics for each group column:
</p>

<ol>
<li><p> Number of groups
</p>
</li>
<li><p> Mean, median, std., IQR, min, and max number of rows per group.
</p>
</li></ol>

<p>The output can be given in either <em>long</em> (default) or <em>wide</em> format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_group_cols(data, group_cols, long = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarize_group_cols_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with one or more group columns (<code>factor</code>s) to summarize.</p>
</td></tr>
<tr><td><code id="summarize_group_cols_+3A_group_cols">group_cols</code></td>
<td>
<p>Names of columns to summarize. These columns must be factors in <code>`data`</code>.</p>
</td></tr>
<tr><td><code id="summarize_group_cols_+3A_long">long</code></td>
<td>
<p>Whether the output should be in <em>long</em> or <em>wide</em> format.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame (<code>tibble</code>) with summary statistics for each column in <code>`group_cols`</code>.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other summarization functions: 
<code><a href="#topic+ranked_balances">ranked_balances</a>()</code>,
<code><a href="#topic+summarize_balances">summarize_balances</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create data frame
df &lt;- data.frame(
  "some_var" = runif(25),
  "grp_1" = factor(sample(1:5, size = 25, replace=TRUE)),
  "grp_2" = factor(sample(1:8, size = 25, replace=TRUE)),
  "grp_3" = factor(sample(LETTERS[1:3], size = 25, replace=TRUE)),
  "grp_4" = factor(sample(LETTERS[1:12], size = 25, replace=TRUE))
)

# Summarize the group columns (long format)
summarize_group_cols(
  data = df,
  group_cols = paste0("grp_", 1:4),
  long = TRUE
 )

# Summarize the group columns (wide format)
summarize_group_cols(
  data = df,
  group_cols = paste0("grp_", 1:4),
  long = FALSE
 )
</code></pre>

<hr>
<h2 id='upsample'>Upsampling of rows in a data frame</h2><span id='topic+upsample'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#maturing"><img src="../help/figures/lifecycle-maturing.svg" alt='[Maturing]' /></a>
</p>
<p>Uses random upsampling to fix the group sizes to the
largest group in the data frame.
</p>
<p>Wraps <code><a href="#topic+balance">balance</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>upsample(
  data,
  cat_col,
  id_col = NULL,
  id_method = "n_ids",
  mark_new_rows = FALSE,
  new_rows_col_name = ".new_row"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="upsample_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>. Can be <em>grouped</em>, in which case
the function is applied group-wise.</p>
</td></tr>
<tr><td><code id="upsample_+3A_cat_col">cat_col</code></td>
<td>
<p>Name of categorical variable to balance by. (Character)</p>
</td></tr>
<tr><td><code id="upsample_+3A_id_col">id_col</code></td>
<td>
<p>Name of factor with IDs. (Character)
</p>
<p>IDs are considered entities, e.g. allowing us to add or remove all rows for an ID.
How this is used is up to the <code>`id_method`</code>.
</p>
<p>E.g. If we have measured a participant multiple times and
want make sure that we keep all these measurements. Then we would either
remove/add all measurements for the participant or leave in
all measurements for the participant.
</p>
<p>N.B. When <code>`data`</code> is a <em>grouped</em> <code>data.frame</code>
(see <code><a href="dplyr.html#topic+group_by">dplyr::group_by()</a></code>), IDs that appear in multiple
groupings are considered separate entities within those groupings.</p>
</td></tr>
<tr><td><code id="upsample_+3A_id_method">id_method</code></td>
<td>
<p>Method for balancing the IDs. (Character)
</p>
<p><code>"n_ids"</code>, <code>"n_rows_c"</code>, <code>"distributed"</code>, or <code>"nested"</code>.
</p>


<h4>n_ids (default)</h4>

<p>Balances on ID level only. It makes sure there are the same number of IDs for each category.
This might lead to a different number of rows between categories.
</p>



<h4>n_rows_c</h4>

<p>Attempts to level the number of rows per category, while only removing/adding entire IDs.
This is done in 2 steps:
</p>

<ol>
<li><p> If a category needs to add all its rows one or more times, the data is repeated.
</p>
</li>
<li><p> Iteratively, the ID with the number of rows closest to the
lacking/excessive number of rows is added/removed.
This happens until adding/removing the closest ID would lead to a size further from
the target size than the current size.
If multiple IDs are closest, one is randomly sampled.
</p>
</li></ol>




<h4>distributed</h4>

<p>Distributes the lacking/excess rows equally between the IDs.
If the number to distribute can not be equally divided, some IDs will have 1 row more/less than the others.
</p>



<h4>nested</h4>

<p>Calls <code>balance()</code> on each category with IDs as cat_col.
</p>
<p>I.e. if size is <code>"min"</code>, IDs will have the size of the smallest ID in their category.
</p>
</td></tr>
<tr><td><code id="upsample_+3A_mark_new_rows">mark_new_rows</code></td>
<td>
<p>Add column with <code>1</code>s for added rows, and <code>0</code>s for original rows. (Logical)</p>
</td></tr>
<tr><td><code id="upsample_+3A_new_rows_col_name">new_rows_col_name</code></td>
<td>
<p>Name of column marking new rows. Defaults to <code>".new_row"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Without <code>`id_col`</code></h4>

<p>Upsampling is done with replacement for added rows, while the original data remains intact.</p>



<h4>With <code>`id_col`</code></h4>

<p>See <code>`id_method`</code> description.</p>



<h3>Value</h3>

<p><code>data.frame</code> with added rows. Ordered by potential grouping variables, <code>`cat_col`</code> and (potentially) <code>`id_col`</code>.
</p>


<h3>Author(s)</h3>

<p>Ludvig Renbo Olsen, <a href="mailto:r-pkgs@ludvigolsen.dk">r-pkgs@ludvigolsen.dk</a>
</p>


<h3>See Also</h3>

<p>Other sampling functions: 
<code><a href="#topic+balance">balance</a>()</code>,
<code><a href="#topic+downsample">downsample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Attach packages
library(groupdata2)

# Create data frame
df &lt;- data.frame(
  "participant" = factor(c(1, 1, 2, 3, 3, 3, 3, 4, 4, 5, 5, 5, 5)),
  "diagnosis" = factor(c(0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0)),
  "trial" = c(1, 2, 1, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4),
  "score" = sample(c(1:100), 13)
)

# Using upsample()
upsample(df, cat_col = "diagnosis")

# Using upsample() with id_method "n_ids"
# With column specifying added rows
upsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "n_ids",
  mark_new_rows = TRUE
)

# Using upsample() with id_method "n_rows_c"
# With column specifying added rows
upsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "n_rows_c",
  mark_new_rows = TRUE
)

# Using upsample() with id_method "distributed"
# With column specifying added rows
upsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "distributed",
  mark_new_rows = TRUE
)

# Using upsample() with id_method "nested"
# With column specifying added rows
upsample(df,
  cat_col = "diagnosis",
  id_col = "participant",
  id_method = "nested",
  mark_new_rows = TRUE
)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
