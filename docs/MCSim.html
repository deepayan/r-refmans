<!DOCTYPE html><html><head><title>Help for package MCSim</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MCSim}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MCS'><p>MCSim: a Package to Determine the Optimal Number of Clusters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Determine the Optimal Number of Clusters</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-09-30</td>
</tr>
<tr>
<td>Author:</td>
<td>Ahmed N. Albatineh, Meredith L. Wilcox, Bashar Zogheib, Magdalena Niewiadomska-Bugaj</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ahmed N. Albatineh &lt;aalbatineh@hsc.edu.kw&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Identifies the optimal number of clusters by calculating the similarity between
             two clustering methods at the same number of clusters using the corrected indices of Rand and
             Jaccard as described in Albatineh and Niewiadomska-Bugaj (2011). The number of clusters at
             which the index attain its maximum more frequently is a candidate for being the optimal
             number of clusters.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS,CircStats,stats,graphics</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-10-08 10:37:50 UTC; aalbatineh</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-10-08 11:00:17 UTC</td>
</tr>
</table>
<hr>
<h2 id='MCS'>MCSim: a Package to Determine the Optimal Number of Clusters</h2><span id='topic+MCS'></span>

<h3>Description</h3>

<p>This package identifies the optimal number of clusters by calculating the similarity between two clustering methods at the same number of clusters using the corrected indices of Rand and Jaccard as described in Albatineh and Niewiadomska-Bugaj (2011). The number of clusters at which the index attain its maximum more frequently is a candidate for being the optimal number of clusters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCS(data1=data1, nc=nc, method1="method1", method2="method2", index="index",
print.stats=FALSE, st.data=FALSE, plot.hc=FALSE, circ=FALSE,
convert=TRUE, plot.data=FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCS_+3A_data1">data1</code></td>
<td>
<p>Numeric data matrix to be clustered.</p>
</td></tr>
<tr><td><code id="MCS_+3A_nc">nc</code></td>
<td>
<p>Maximum number of clusters, similarity will be calculated for 2&lt;= nc &lt; n-1</p>
</td></tr>
<tr><td><code id="MCS_+3A_method1">method1</code></td>
<td>
<p>First clustering method to be used. One of &quot;single&quot;,&quot;average&quot;,&quot;complete&quot;,&quot;ward&quot;       ,&quot;median&quot;,&quot;mcquitty&quot;,&quot;kmeans&quot;)</p>
</td></tr>
<tr><td><code id="MCS_+3A_method2">method2</code></td>
<td>
<p>Second clustering method to be used. One of &quot;single&quot;,&quot;average&quot;,&quot;complete&quot;,&quot;ward&quot;,&quot;median&quot;,&quot;mcquitty&quot;,&quot;kmeans&quot;)</p>
</td></tr>
<tr><td><code id="MCS_+3A_index">index</code></td>
<td>
<p>Similarity index to be used. Either &quot;rand&quot; or &quot;jaccard&quot; index which will be corrected for chance agreement</p>
</td></tr>
<tr><td><code id="MCS_+3A_print.stats">print.stats</code></td>
<td>
<p>Logical, if &quot;TRUE&quot; the similarity will be outputed for each value between 2 and nc</p>
</td></tr>
<tr><td><code id="MCS_+3A_st.data">st.data</code></td>
<td>
<p>Logical, if &quot;TRUE&quot; data will be standadrized. This is for linear (non-circular) data only</p>
</td></tr>
<tr><td><code id="MCS_+3A_plot.hc">plot.hc</code></td>
<td>
<p>Logical, if &quot;TRUE&quot; hierarchical clustering tree (dendrogram) will be produced. This is for linear (non-circular) data only</p>
</td></tr>
<tr><td><code id="MCS_+3A_circ">circ</code></td>
<td>
<p>Logical, if &quot;TRUE&quot; data are circular or measured as angles</p>
</td></tr>
<tr><td><code id="MCS_+3A_convert">convert</code></td>
<td>
<p>Logical, if &quot;TRUE&quot; data will be converted from angular to radians. This is for circular data only</p>
</td></tr>
<tr><td><code id="MCS_+3A_plot.data">plot.data</code></td>
<td>
<p>Logical, if &quot;TRUE&quot; a circular plot of the data will be produced. This is for circular data only</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The distance measure used to calculate the distance for linear data is the Euclidean distance. For circular data the distance is calculated using the formula dij=0.5*(1 - cos(Aii - Bjj)). The correction for Rand index is based on the expectation by Hubert and Arabie (1985). For correcting Jaccard index, see Albatineh &amp; Niewiadomska-Buga (2011).</p>


<h3>Value</h3>

<p>Similarity between the two clustering algorithms at each value of nc will be calculated, where 2&lt;= nc &lt; n - 1, and a plot of the number of clusters vs. the value of either similarity index rand or jaccard will be produced.</p>


<h3>Note</h3>

<p>The following packages are needed: &quot;MASS&quot;,&quot;CircStats&quot;,&quot;stats&quot;,&quot;datasets&quot;,&quot;graphics&quot;</p>


<h3>Author(s)</h3>

<p>Ahmed N. Albatineh, Meredith L. Wilcox, Bashar Zogheib, Magdalena Niewiadomska-Bugaj</p>


<h3>References</h3>

<p>Albatineh, A. N., Niewiadomska-Bugaj, M., &amp; Mihalko, D. (2006). On similarity indices and correction for chance agreement. Journal of Classification, 23(2), 301-313.
</p>
<p>Albatineh, A. N., &amp; Niewiadomska-Bugaj, M. (2011). Correcting Jaccard and other similarity indices for chance agreement in cluster analysis. Advances in Data Analysis and Classification, 5(3), 179-200.
</p>
<p>Albatineh, A. N., &amp; Niewiadomska-Bugaj, M. (2011). MCS: A method for finding the number of clusters. Journal of classification, 28(2), 184-209.
</p>
<p>Albatineh, A. N. (2010). Means and variances for a family of similarity indices used in cluster analysis. Journal of Statistical Planning and Inference, 140(10), 2828-2838.</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("MASS")
library("CircStats")
library("stats")
library("datasets")
library("graphics")
########  Simulated data from four bivariate normal distributions
set.seed(12345)
clust1&lt;- mvrnorm(100,mu=c(5,5),Sigma=matrix(c(1,0.5,0.5,1),ncol=2))
clust2&lt;- mvrnorm(100,mu=c(5,20),Sigma=matrix(c(1,0.5,0.5,1),ncol=2))
clust3&lt;- mvrnorm(100,mu=c(20,5),Sigma=matrix(c(1,0.5,0.5,1),ncol=2))
clust4&lt;- mvrnorm(100,mu=c(20,20),Sigma=matrix(c(1,0.5,0.5,1),ncol=2))
simdat&lt;- rbind(clust1,clust2,clust3,clust4)

MCS(data1=simdat, nc=10, method1="single", method2="ward.D2", index="rand", print.stats=TRUE,
st.data=FALSE, plot.hc=FALSE)

MCS(data1=simdat, nc=10, method1="kmeans", method2="single", index="rand", print.stats=TRUE,
st.data=FALSE, plot.hc=FALSE)
####################################################
## Data from three bivariate normal distributions (elongated clusters)
set.seed(1965)
clust1&lt;- mvrnorm(100,mu=c(5,5),Sigma=matrix(c(1,0.9,0.9,1),ncol=2))
clust2&lt;- mvrnorm(100,mu=c(5,20),Sigma=matrix(c(1,0.9,0.9,1),ncol=2))
clust3&lt;- mvrnorm(100,mu=c(20,5),Sigma=matrix(c(1,0.9,0.9,1),ncol=2))
simdat&lt;- rbind(clust1,clust2,clust3)

MCS(data1=simdat, nc=10, method1="complete", method2="average", index="rand", print.stats=TRUE,
st.data=FALSE, plot.hc=FALSE)

MCS(data1=simdat, nc=10, method1="median", method2="kmeans", index="rand", print.stats=TRUE,
st.data=FALSE, plot.hc=FALSE)
####################################################
##  Old Faithful Geyser Data Example  #######
library("datasets")
data1&lt;- as.matrix(faithful,nrows=272,ncol=2,byrows=TRUE)

MCS(data1=data1, nc=10, method1="average", method2="ward.D2", index="rand", print.stats=TRUE,
st.data=FALSE, plot.hc=FALSE)

MCS(data1=data1, nc=10, method1="average", method2="kmeans", index="jaccard", print.stats=TRUE,
st.data=FALSE, plot.hc=FALSE)
## Simulated Circular data from five von Mises distributions ####
set.seed(1945)
clust1&lt;- as.vector(rvm(50,5,15))
clust2&lt;- as.vector(rvm(50,10,15))
clust3&lt;- as.vector(rvm(50,15,15))
clust4&lt;- as.vector(rvm(50,20,15))
clust5&lt;- as.vector(rvm(50,25,15))
data1&lt;- rbind(clust1,clust2,clust3,clust4,clust5)
MCS(data1=data1, nc=10, method1="kmeans", method2="complete", index="rand", print.stats=TRUE,
circ=TRUE, convert=FALSE, plot.data=FALSE)
### Turtles Data Example
turtles&lt;- c(8,9,13,13,14,18,22,27,30,34,
38,38,40,44,45,47,48,48,48,48,50,53,56,
57,58,58,61,63,64,64,64,65,65,68,70,73,
78,78,78,83,83,88,88,88,90,92,92,93,95,
96,98,100,103,106,113,118,138,153,153,
155,204,215,223,226,237,238,243,244,250,
251,257,268,285,319,343,350)

MCS(data1=turtles, nc=10, method1="single", method2="ward.D2", index="rand", print.stats=TRUE,
circ=TRUE, convert=TRUE, plot.data=FALSE)

MCS(data1=turtles, nc=10, method1="ward.D2", method2="kmeans", index="jaccard", print.stats=TRUE,
circ=TRUE, convert=TRUE, plot.data=FALSE)
######  Wind data example  ##
wind&lt;- c(67,87,101,101,101,103,131,140,140,142,144,149,182,
199,206,251,253,278,279,287,290,295,299,301,301,307,308,308,
309,310,312,316,319,319,325,325,326,331,344,15)

MCS(data1=wind, nc=10, method1="ward.D2", method2="median", index="jaccard", print.stats=TRUE,
circ=TRUE, convert=TRUE, plot.data=FALSE)

MCS(data1=wind, nc=10, method1="complete", method2="average", index="jaccard", print.stats=TRUE,
circ=TRUE, convert=TRUE, plot.data=FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
