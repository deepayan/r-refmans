<!DOCTYPE html><html><head><title>Help for package multiColl</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {multiColl}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#multiColl-package'>
<p>Collinearity detection in a multiple linear regression model.</p></a></li>
<li><a href='#CN'><p>Condition Number</p></a></li>
<li><a href='#CNs'><p>Condition Number with and without intercept</p></a></li>
<li><a href='#CV'><p>Coeficient of Variation</p></a></li>
<li><a href='#CVs'><p>Coeficients of Variation</p></a></li>
<li><a href='#KG'><p>Klein and Goldberger data</p></a></li>
<li><a href='#ki'><p>Stewart's index</p></a></li>
<li><a href='#lu'><p>Unit length data</p></a></li>
<li><a href='#multiCol'><p>Collinearity detection in a linear regression model</p></a></li>
<li><a href='#multiColLM'><p>All detection measures</p></a></li>
<li><a href='#perturb'><p>Perturbation</p></a></li>
<li><a href='#perturb.n'><p>Perturbation and estimation in a multiple linear model</p></a></li>
<li><a href='#PROPs'><p>Proportions</p></a></li>
<li><a href='#RdetR'><p>Correlation matrix and it's determinat</p></a></li>
<li><a href='#SLM'><p>Simple linear regression model and multicollinearity</p></a></li>
<li><a href='#theil'><p>Henri Theil data</p></a></li>
<li><a href='#VIF'><p>Variance Inflation Factor</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Collinearity Detection in a Multiple Linear Regression Model</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-07-19</td>
</tr>
<tr>
<td>Author:</td>
<td>R. Salmeron, C. Garcia and J. Garcia</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>R. Salmeron &lt;romansg@ugr.es&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The detection of worrying approximate collinearity in a multiple linear regression model is a problem addressed in all existing statistical packages. However, we have detected deficits regarding to the incorrect treatment of qualitative independent variables and the role of the intercept of the model. The objective of this package is to correct these deficits. In this package will be available detection and treatment techniques traditionally used as the recently developed.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://colldetreat.r-forge.r-project.org/">http://colldetreat.r-forge.r-project.org/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-21 07:47:45 UTC; usuario</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-21 08:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='multiColl-package'>
Collinearity detection in a multiple linear regression model.
</h2><span id='topic+multiColl-package'></span><span id='topic+multiColl'></span>

<h3>Description</h3>

<p>R package to detect collinearity in a multiple linear regression model.
</p>


<h3>Details</h3>

<p>The detection of worrying approximate multicollinearity in a multiple linear regression model is a problem addressed in all existing statistical packages. However, we have detected deficits regarding to the incorrect treatment of qualitative independent variables and the role of the intercept of the model. The objective of this package is to correct these deficits. In this package will be available detection and treatment techniques traditionally used as the recently developed.
</p>


<h3>Author(s)</h3>

<p>Román Salmerón Gómez (University of Granada), Catalina García García (University of Granada) and José García García (University of Almería).
</p>


<h3>References</h3>

<p>R. Salmerón, C.B. García and J. García (2021). A guide to using the R package <code>multiColl</code> for detecting multicollinearity. Computational Economics, 57, 529-536.
</p>
<p>R. Salmerón, C.B. García and J. García (2022). The <code>multiColl</code> package versus other existing packages in R to detect multicollinearity. Computational Economics, 60, 439-450.
</p>

<hr>
<h2 id='CN'>Condition Number</h2><span id='topic+CN'></span>

<h3>Description</h3>

<p>This function returns the Condition Number (CN) of the independent variables in a multiple linear regression.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CN(X)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CN_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to the CN takes into account the intercept, it allows to detect not only the essential but also the non-essential collinearity. It also allows to consider non-quantitative independent variables. 
</p>
<p>Its calculation is obtained from the function <code>lu</code>, contrary to the function <code>kappa</code>.
</p>


<h3>Value</h3>

<p>The condition number of a matrix, that is, the maximum condition index.</p>


<h3>Note</h3>

<p>Values of CN between 20 and 30 indicate near moderate multicollinearity while values higher than 30 indicate near worrying collinearity.</p>


<h3>Author(s)</h3>

<p>R. Salmeron (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. Garcia (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>D. A. Belsley (1991). Conditioning diagnostics: collinearity and weak dara in regression. John Wiley &amp; Sons, New York.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lu">lu</a></code>, <code><a href="base.html#topic+kappa">kappa</a></code>, <code><a href="#topic+CNs">CNs</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
CN(theil.X)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
CN(KG.X)
</code></pre>

<hr>
<h2 id='CNs'>Condition Number with and without intercept</h2><span id='topic+CNs'></span>

<h3>Description</h3>

<p>This function returns the Condition Number (CN) of the independent variables of a multiple linear model considering the intercept and without considering it. It also returns the increase produced by going from not taking into account the intercept to having it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CNs(X)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CNs_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>CN1</code></td>
<td>
<p>Condition Number without intercept.</p>
</td></tr>
<tr><td><code>CN2</code></td>
<td>
<p>Condition Number with intercept.</p>
</td></tr>
<tr><td><code>increment</code></td>
<td>
<p>Increase (in percentage) in the CN from CN1 to CN2.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>D. A. Belsley (1991). Conditioning diagnostics: collinearity and weak data in regression. John Wiley &amp; Sons, New York.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lu">lu</a></code>, <code><a href="#topic+CN">CN</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
CNs(theil.X)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
CNs(KG.X)
</code></pre>

<hr>
<h2 id='CV'>Coeficient of Variation</h2><span id='topic+CV'></span>

<h3>Description</h3>

<p>The function calculates the Coeficient of Variation (CV) of a quantitative vector.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV(x)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV_+3A_x">x</code></td>
<td>
<p>A quantitative vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The CV of <code>x</code>.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+var">var</a></code>, <code><a href="stats.html#topic+sd">sd</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># random
x = sample(1:50, 25)
x
CV(x)
</code></pre>

<hr>
<h2 id='CVs'>Coeficients of Variation</h2><span id='topic+CVs'></span>

<h3>Description</h3>

<p>The function returns the Coeficient of Variation (CV) of a matrix with quantitative columns.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVs(X, dummy = FALSE, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVs_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
<tr><td><code id="CVs_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
<tr><td><code id="CVs_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to the calculation of the CV only makes sense for quantitative data, other kind of data should be ignored in the calculation. For this reason, it is necessary to indicate if there are non-quantitative variables and also its position in the matrix. 
</p>


<h3>Value</h3>

<p>The CV of each column of <code>X</code>.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>See Also</h3>

<p><code><a href="#topic+CV">CV</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># random

cte = array(1, 50)
x1 = sample(1:50, 25)
x2 = sample(1:50, 25)
Z = cbind(cte, x1, x2)
head(Z)
CVs(Z)

x3 = sample(c(array(1,25), array(0,25)), 25)
W = cbind(Z, x3)
head(W)
CVs(W, dummy=TRUE, pos = 4)

x0 = sample(c(array(1,25), array(0,25)), 25)
Y = cbind(cte, x0, x1, x2, x3)
head(Y)
CVs(Y, dummy=TRUE, pos=c(2,5))
</code></pre>

<hr>
<h2 id='KG'>Klein and Goldberger data</h2><span id='topic+KG'></span>

<h3>Description</h3>

<p>Klein and Goldberger data on consumption and wage income.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("KG")</code></pre>


<h3>Format</h3>

<p>A data frame with 14 observations in relation to the following four variables:
</p>

<dl>
<dt><code>consumption</code></dt><dd><p>Domestic consumption.</p>
</dd>
<dt><code>wage.income</code></dt><dd><p>Wage income.</p>
</dd>
<dt><code>non.farm.income</code></dt><dd><p>Non-wage-non-farm income.</p>
</dd>
<dt><code>farm.income</code></dt><dd><p>Farm income.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data for the years 1942 to 1944 are not available for the war.</p>


<h3>References</h3>

<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(KG)
head(KG)
</code></pre>

<hr>
<h2 id='ki'>Stewart's index</h2><span id='topic+ki'></span>

<h3>Description</h3>

<p>The function returns the index of Stewart of the independent variables in the multiple linear regession model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ki(X, dummy = FALSE, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ki_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
<tr><td><code id="ki_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
<tr><td><code id="ki_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The index of Stewart allows to detect the near essential and non-essential multicollinearity existing in a multiple linear regression model. In addition, due to its relation with the Variance Inflation Factor (VIF), it allows to calculate the proportion of essential and non-essential multicollinearity  in each independent variable (intercept excluded). The Stewart's index for the intercept indicates the degree of non-essential multicollinearity existing in the model.
</p>
<p>The relation of the the VIF with the index of Stewart implies that it should not be calculated for non-quantitative variables.
</p>


<h3>Value</h3>

<table>
<tr><td><code>ki</code></td>
<td>
<p>Stewart's index for each independent variable.</p>
</td></tr>
<tr><td><code>porc1</code></td>
<td>
<p>Proportion of essential multicollinearity in the i-th independent variable (without intercept).</p>
</td></tr>
<tr><td><code>porc2</code></td>
<td>
<p>Proportion of non-essential multicollinearity in the i-th independent variable (without intercept).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>G. Stewart (1987). Collinearity and least squares regression. Statistical Science, 2 (1), 68-100.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIF">VIF</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
ki(theil.X, TRUE, pos = 4)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
ki(KG.X)
</code></pre>

<hr>
<h2 id='lu'>Unit length data</h2><span id='topic+lu'></span>

<h3>Description</h3>

<p>The function transforms the matrix <code>X</code> so that each column has unit length, it is to say, a module equal to 1.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lu(X)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lu_+3A_x">X</code></td>
<td>
<p>A numeric matrix that should contain more than one column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Original matrix transformed so that each column has a module equal to 1.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>R. Salmerón, C. B. García and J. García (2018). Variance Inflation Factor and
Condition Number in multiple linear regression. Journal of Statistical Computation and Simulation, 88 (12), 2365-2384.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CN">CN</a></code>, <code><a href="#topic+CNs">CNs</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
lu(theil.X)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
lu(KG.X)

# random
x1 = sample(1:10,5)
x2 = sample(1:10,5)
x = cbind(x1, x2)
x
norm(x[,1],"2")
norm(x[,2],"2")
x.lu = lu(x)
x.lu
norm(x.lu[,1],"2")
norm(x.lu[,2],"2")
</code></pre>

<hr>
<h2 id='multiCol'>Collinearity detection in a linear regression model</h2><span id='topic+multiCol'></span>

<h3>Description</h3>

<p>The function collects all existing measures to detect worrying multicollinearity  in the package <code>multiCol</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiCol(X, dummy = FALSE, pos = NULL, graf = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiCol_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
<tr><td><code id="multiCol_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
<tr><td><code id="multiCol_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
<tr><td><code id="multiCol_+3A_graf">graf</code></td>
<td>
<p>A logical value that indicates if the dispersion diagram of the variation coefficients of the independent variables is represented against its variance inflation factor. By default <code>graf=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If X contains two independent variables (intercept included) see <code>SLM</code> function. 
</p>
<p>If X contains more than two independent variables (intercept included):
</p>
<table>
<tr><td><code>CV</code></td>
<td>
<p>Coeficients of variation of quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>Prop</code></td>
<td>
<p>Proportion of ones in the dummy variables.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Matrix correlation of the quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>detR</code></td>
<td>
<p>Determinant of the matrix correlation of the quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>VIF</code></td>
<td>
<p>Variance Inflation Factors of the quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>CN</code></td>
<td>
<p>Condition Number of <code>X</code>.</p>
</td></tr>
<tr><td><code>ki</code></td>
<td>
<p>Stewart's index of the quantitative variables in <code>X</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For more detail, see the help of the functions in <code>See Also</code>.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLM">SLM</a></code>, <code><a href="#topic+CV">CV</a></code>, <code><a href="#topic+PROPs">PROPs</a></code>, <code><a href="#topic+RdetR">RdetR</a></code>, <code><a href="#topic+VIF">VIF</a></code>, <code><a href="#topic+CN">CN</a></code>, <code><a href="#topic+ki">ki</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
multiCol(theil.X, TRUE, pos = 4)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
multiCol(KG.X)

# random
x1 = array(1,25)
x2 = rnorm(25,100,1)
x = cbind(x1,x2)
head(x)
multiCol(x)

# random
x1 = array(1,25)
x2 = sample(cbind(array(1,25),array(0,25)),25)
x = cbind(x1,x2)
head(x)
multiCol(x, TRUE)
</code></pre>

<hr>
<h2 id='multiColLM'>All detection measures</h2><span id='topic+multiColLM'></span>

<h3>Description</h3>

<p>The functions collects all the measure to detect near worrying multicollinearity existing in the package <code>multiCol</code>. In adddition, it provides the estimations by ordinary least squares (OLS) of the multiple linear regession model and the variations in the estimations of the coefficients as a consequence of changes in the observed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiColLM(y, X, dummy=FALSE, pos1=NULL, n, mu, dv, tol=0.01, pos2=NULL, graf=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiColLM_+3A_y">y</code></td>
<td>
<p>Observations of the dependent variable of the model.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_x">X</code></td>
<td>
<p>Observations of the independent variables of the model (intercept included).</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_pos1">pos1</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_n">n</code></td>
<td>
<p>Number of times that the perturbation is performed.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_mu">mu</code></td>
<td>
<p>Any real number.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_dv">dv</code></td>
<td>
<p>Any real positive number.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_tol">tol</code></td>
<td>
<p>A value between 0 and 1. By default <code>tol=0.01</code>.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_pos2">pos2</code></td>
<td>
<p>A numeric vector that indicates the position of the independent variables to disturb once you eliminate in <code>data</code> the dependent variable and the intercept. By default <code>pos=NULL</code>.</p>
</td></tr>
<tr><td><code id="multiColLM_+3A_graf">graf</code></td>
<td>
<p>A logical value that indicates if the dispersion diagram of the variation coefficients of the independent variables is represented against its variance inflation factor. By default <code>graf=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimation by OLS of the linear regression model. 
</p>
<p>Percentiles 2.5 and 97.5 of the proportion of the variations in the estimations of the coefficients obtained from a perturbation of <code>tol</code>% in the quantitative variables of <code>X</code>.
</p>
<p>If X contains two independent variables (intercept included) see <code>SLM</code> function. 
</p>
<p>If X contains more than two independent variables (intercept included):
</p>
<table>
<tr><td><code>CV</code></td>
<td>
<p>Coeficients of variation of quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>Prop</code></td>
<td>
<p>Proportion of ones in the dummy variables.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Matrix correlation of the quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>detR</code></td>
<td>
<p>Determinant of the matrix correlation of the quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>VIF</code></td>
<td>
<p>Variance Inflation Factors of the quantitative variables in <code>X</code>.</p>
</td></tr>
<tr><td><code>CN</code></td>
<td>
<p>Condition Number of <code>X</code>.</p>
</td></tr>
<tr><td><code>ki</code></td>
<td>
<p>Stewart's index of the quantitative variables in <code>X</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For more detail, see the help of the functions in <code>See Also</code>.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SLM">SLM</a></code>, <code><a href="#topic+CV">CV</a></code>, <code><a href="#topic+PROPs">PROPs</a></code>, <code><a href="#topic+RdetR">RdetR</a></code>, <code><a href="#topic+VIF">VIF</a></code>, <code><a href="#topic+CN">CN</a></code>, <code><a href="#topic+ki">ki</a></code>, <code><a href="#topic+multiCol">multiCol</a></code>, <code><a href="#topic+perturb">perturb</a></code>, <code><a href="#topic+perturb.n">perturb.n</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
head(theil.X)
multiColLM(theil[,2], theil.X, dummy = TRUE, pos1 = 4, 5, 5, 5, tol=0.01, pos2 = 1:2)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
head(KG.X)
multiColLM(KG[,1], KG.X, n = 500, mu = 5, dv = 5, tol=0.01, pos2 = 1:3)
</code></pre>

<hr>
<h2 id='perturb'>Perturbation</h2><span id='topic+perturb'></span>

<h3>Description</h3>

<p>The function modifies a set of quantitative data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>perturb(x, mu, dv, tol = 0.01)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perturb_+3A_x">x</code></td>
<td>
<p>A numeric quantitative vector.</p>
</td></tr>
<tr><td><code id="perturb_+3A_mu">mu</code></td>
<td>
<p>Any real number.</p>
</td></tr>
<tr><td><code id="perturb_+3A_dv">dv</code></td>
<td>
<p>Any real positive number.</p>
</td></tr>
<tr><td><code id="perturb_+3A_tol">tol</code></td>
<td>
<p>A value between 0 and 1. By default <code>tol=0.01</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector of data set is modified a <code>tol</code>% by following the procedure presented by Belsley (1982).</p>


<h3>Value</h3>

<p>The vector <code>x</code> modified a <code>tol</code>%.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>D. Belsley (1982). Assessing the presence of harmfull collinearity and other forms of weak data throught a test for signal-to-noise. Journal of Econometrics, 20, 211-253.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perturb.n">perturb.n</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
consume.p1 = perturb(theil[,2], 3, 4, 0.01)
consume.p2 = perturb(theil[,2], 50, 10, 0.01)
x = cbind(theil[,2], consume.p1, consume.p2)
head(x)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
farm.income.p1 = perturb(KG[,4], -3, 40, 0.01)
farm.income.p2 = perturb(KG[,4], 10, 8, 0.01)
x = cbind(KG[,4], farm.income.p1, farm.income.p2)
head(x)
</code></pre>

<hr>
<h2 id='perturb.n'>Perturbation and estimation in a multiple linear model</h2><span id='topic+perturb.n'></span>

<h3>Description</h3>

<p>The function quantifies the variations in the estimations of the coefficients of a multiple linear regression  when a perturbation is introduced in the quantitative data set.</p>


<h3>Usage</h3>

<pre><code class='language-R'>perturb.n(data, n, mu, dv, tol = 0.01, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perturb.n_+3A_data">data</code></td>
<td>
<p>Data set <code>(y, X)</code> where <code>y</code> and <code>X</code>  contain, respectively, the observations of the dependent variable and independients variables (intercept included) of the multiple linear regression.</p>
</td></tr>
<tr><td><code id="perturb.n_+3A_n">n</code></td>
<td>
<p>Number of times that perturbation is performed.</p>
</td></tr>
<tr><td><code id="perturb.n_+3A_mu">mu</code></td>
<td>
<p>Any real number.</p>
</td></tr>
<tr><td><code id="perturb.n_+3A_dv">dv</code></td>
<td>
<p>Any real positive number.</p>
</td></tr>
<tr><td><code id="perturb.n_+3A_tol">tol</code></td>
<td>
<p>A value between 0 and 1. By default <code>tol=0.01</code>.</p>
</td></tr>
<tr><td><code id="perturb.n_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the independent variables to disturb once you eliminate in <code>data</code> the dependent variable and the intercept. By default <code>pos=NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>tols</code></td>
<td>
<p>A vector presenting the percentage of disturbance induced in the variables indicated in each iteration.</p>
</td></tr>
<tr><td><code>norms</code></td>
<td>
<p>A vector presenting the percentage of variation in the estimations of the coefficients in each iteration. </p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>tols</code> must be a constant vector equal to <code>tol</code>. It is obtained to check if data have been correctly perturbed.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>D. Belsley (1982). Assessing the presence of harmfull collinearity and other forms of weak data throught a test for signal-to-noise. Journal of Econometrics, 20, 211-253.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perturb">perturb</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>tol = 0.01
mu = 10
dv = 10

# Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.y.X = cbind(theil[,2], cte, theil[,-(1:2)])
head(theil.y.X)

iterations = 5

perturb.n.T = perturb.n(theil.y.X, iterations, mu, dv, tol, pos = c(1,2))
perturb.n.T
mean(perturb.n.T[,1])
mean(perturb.n.T[,2])
c(min(perturb.n.T[,2]), max(perturb.n.T[,2]))

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.y.X = cbind(KG[,1], cte, KG[,-1])
head(KG.y.X)

iterations = 1000

perturb.n.KG = perturb.n(KG.y.X, iterations, mu, dv, tol, pos = c(1,2,3))
mean(perturb.n.KG[,1])
mean(perturb.n.KG[,2])
c(min(perturb.n.KG[,2]), max(perturb.n.KG[,2]))
</code></pre>

<hr>
<h2 id='PROPs'>Proportions</h2><span id='topic+PROPs'></span>

<h3>Description</h3>

<p>The functions returns the proportion of ones in the dummy variables existing in a matrix.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PROPs(X, dummy = TRUE, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PROPs_+3A_x">X</code></td>
<td>
<p>A numeric matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
<tr><td><code id="PROPs_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the matrix <code>X</code>. By default <code>dummy=TRUE</code>.</p>
</td></tr>
<tr><td><code id="PROPs_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiCol">multiCol</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># random
x1 = sample(1:50, 25)
x2 = sample(1:50, 25)
x3 = sample(cbind(array(1,25), array(0,25)), 25)
x4 = sample(cbind(array(1,25), array(0,25)), 25)
x = cbind(x1, x2, x3, x4)
head(x)
PROPs(x, TRUE, pos = c(3,4))
</code></pre>

<hr>
<h2 id='RdetR'>Correlation matrix and it's determinat</h2><span id='topic+RdetR'></span>

<h3>Description</h3>

<p>The function returns the matrix of simple linear correlations between the independent variables of a multiple linear model and its determinant.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RdetR(X, dummy = FALSE, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RdetR_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
<tr><td><code id="RdetR_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
<tr><td><code id="RdetR_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The measures calculated by this function ignore completelly the role of the intercept in the linear relations between the independent variables. Thus, these measures only detect the near essential multicollinearity. Although the simple correlations only quantify relation between pairs of variables, the determinant of the matrix of correlations is able to detect broader relations.  Due to the coefficients of simple linear regression are calculated for quantitative variables, if the model contains other kinds of variables (such as dummy variables), they should be omitted in the analysis by using the arguments <code>dummy</code> and <code>pos</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>R</code></td>
<td>
<p>Correlation matrix of the independent variables of the multiple linear regression model.</p>
</td></tr>
<tr><td><code>detR</code></td>
<td>
<p>Determinant of <code>R</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Values of the coefficient of simple linear correlation higher than 0.9487 imply worrying near essential multicollinearity between pairs of variables. 
</p>
<p>Values of the determinant of <code>R</code> lower than  <code>0.1013 + 0.00008626*n - 0.01384*k</code>, where <code>n</code> is the number of observations and <code>k</code> the number of indepedent variables (intercept included), indicate worrying near essential multicollinearity.
</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>C. García, R. Salmerón and C. B. García (2019). Choice of the ridge factor from the correlation matrix determinant. Journal of Statistical Computation and Simulation, 89 (2), 211-231.
</p>
<p>D. Marquardt and R. Snee (1975). Ridge regression in practice. The American Statistician, 1 (29), 3&ndash;20.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VIF">VIF</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
RdetR(theil.X, TRUE, pos = 4)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
RdetR(KG.X)
</code></pre>

<hr>
<h2 id='SLM'>Simple linear regression model and multicollinearity</h2><span id='topic+SLM'></span>

<h3>Description</h3>

<p>The function analyzes the presence of near worrying multicollinearity in the Simple Linear Model (SLM).</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLM(X, dummy = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLM_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain two independent variables (intercept included).</p>
</td></tr>
<tr><td><code id="SLM_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The analysis of the presence of near worrying multicolllinearity in the SLM has been systematically ignored in some existing statistical softwares.  However, it is possible to find worrying non essential multicollinearity in the SLM. In this case, the linear relation will be given by a second variable of <code>X</code> with very little variablity. For this reason, the coeficient of variation is calculated when the variable is quantitative and the proportion of ones if the variable is non-quantitative. 
</p>


<h3>Value</h3>

<p>If <code>dummy=TRUE</code>:
</p>
<table>
<tr><td><code>Prop</code></td>
<td>
<p>Proportion of ones in the dummy variable.</p>
</td></tr>
<tr><td><code>CN</code></td>
<td>
<p>Condition Number of <code>X</code>.</p>
</td></tr>
</table>
<p>If <code>dummy=FALSE</code>:
</p>
<table>
<tr><td><code>CV</code></td>
<td>
<p>Coeficient of variation of the second variable in <code>X</code>.</p>
</td></tr>
<tr><td><code>VIF</code></td>
<td>
<p>Variance Inflation Factor.</p>
</td></tr>
<tr><td><code>CN</code></td>
<td>
<p>Condition Number of <code>X</code>.</p>
</td></tr>
<tr><td><code>ki</code></td>
<td>
<p>Stewart's index of <code>X</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The VIF only detects the near essential multicollinearity and for this reason it is not appropriate to detect multicollinearity in the SLM. Indeed, in this case, the VIF will be always equal to 1.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>R. Salmerón, C. B. García and J. García (2018). Variance Inflation Factor and
Condition Number in multiple linear regression. Journal of Statistical Computation and Simulation, 88 (12), 2365-2384.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PROPs">PROPs</a></code>, <code><a href="#topic+CV">CV</a></code>, <code><a href="#topic+CN">CN</a></code>, <code><a href="#topic+ki">ki</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
SLM(theil.X, TRUE)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
SLM(KG.X)

# random
x1 = array(1,25)
x2 = sample(1:50,25)
x = cbind(x1,x2)
head(x)
SLM(x)

# random
x1 = array(1,25)
x2 = rnorm(25,100,1)
x = cbind(x1,x2)
head(x)
SLM(x)

# random
x1 = array(1,25)
x2 = sample(cbind(array(1,25),array(0,25)),25)
x = cbind(x1,x2)
head(x)
SLM(x, TRUE)
</code></pre>

<hr>
<h2 id='theil'>Henri Theil data</h2><span id='topic+theil'></span>

<h3>Description</h3>

<p>Henri Theil's textile consumption data modified.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("theil")</code></pre>


<h3>Format</h3>

<p>A data set with 17 observations in relation to the following five variables:
</p>

<dl>
<dt><code>obs</code></dt><dd><p>Year.</p>
</dd>
<dt><code>consume</code></dt><dd><p>Volume of textile consumption per capita (base 1925=100).</p>
</dd>
<dt><code>income</code></dt><dd><p>Real Income per capita (base 1925=100).</p>
</dd>
<dt><code>relprice</code></dt><dd><p>Relative price of textiles (base 1925=100).</p>
</dd>
<dt><code>twentys</code></dt><dd><p>Dummy variable that differentiates between the twenties and thirties.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data set is developed based on the original Henri Theil's textile consumption data. With the goal of showing the treatment of the detection of collinearity when non-quantitative variables exists in the multiple linear regression, a new dummy variable has been incorporated distinguishing between the twenties and thirties.</p>


<h3>References</h3>

<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(theil)
head(theil)
</code></pre>

<hr>
<h2 id='VIF'>Variance Inflation Factor</h2><span id='topic+VIF'></span>

<h3>Description</h3>

<p>The function returns the Variance Inflation Factors (VIFs) of the independent variables of the multiple linear regression model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>VIF(X, dummy = FALSE, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VIF_+3A_x">X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td></tr>
<tr><td><code id="VIF_+3A_dummy">dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td></tr>
<tr><td><code id="VIF_+3A_pos">pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the VIFs from the main diagonal of the inverse of the matrix of correlations of the independent variables of the multiple linear regression. Due to the VIF is only calculated for the independent variables, it only allows to detect the essential collinearity.  In addition, the VIF is not adequate for dummy variables since it is obtained from the matrix of simple correlations.
</p>


<h3>Value</h3>

<p>Variance Inflation Factor of each independent variable excluded the intercept.</p>


<h3>Note</h3>

<p>Values of VIF that exceed 10 indicate near essential multicolinearity.</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>D. Marquardt and R. Snee (1975). Ridge regression in practice. The American Statistician, 1 (29), 3&ndash;20.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RdetR">RdetR</a></code>, <code><a href="#topic+ki">ki</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
VIF(theil.X, TRUE, pos = 4)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
VIF(KG.X)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
