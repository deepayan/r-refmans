<!DOCTYPE html><html><head><title>Help for package KSgeneral</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {KSgeneral}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#KSgeneral-package'>
<p>Computing P-Values of the One-Sample K-S Test and the Two-Sample</p>
K-S and Kuiper Tests for (Dis)Continuous Null Distribution</a></li>
<li><a href='#cont_ks_c_cdf'>
<p>Computes the complementary cumulative distribution function of the two-sided Kolmogorov-Smirnov statistic when the cdf under the null hypothesis is continuous</p></a></li>
<li><a href='#cont_ks_cdf'>
<p>Computes the cumulative distribution function of the two-sided Kolmogorov-Smirnov statistic when the cdf under the null hypothesis is continuous</p></a></li>
<li><a href='#cont_ks_test'>
<p>Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is continuous</p></a></li>
<li><a href='#disc_ks_c_cdf'>
<p>Computes the complementary cumulative distribution function of the two-sided Komogorov-Smirnov statistic when the cdf under the null hypothesis is purely discrete</p></a></li>
<li><a href='#disc_ks_test'>
<p>Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is purely discrete</p></a></li>
<li><a href='#ks_c_cdf_Rcpp'>
<p>R function calling directly the C++ routines that compute the complementary cumulative distribution function of the two-sided (or one-sided, as a special case) Kolmogorov-Smirnov statistic, when the cdf under the null hypothesis is arbitrary (i.e., purely discrete, mixed or continuous)</p></a></li>
<li><a href='#KS2sample'>
<p>Computes the p-value for a (weighted) two-sample Kolmogorov-Smirnov test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)</p></a></li>
<li><a href='#KS2sample_c_Rcpp'>
<p>R function calling the C++ routines that compute the complementary p-value for a (weighted) two-sample Kolmogorov-Smirnov (KS) test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)</p></a></li>
<li><a href='#KS2sample_Rcpp'>
<p>R function calling the C++ routines that compute the p-value for a (weighted) two-sample Kolmogorov-Smirnov (KS) test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)</p></a></li>
<li><a href='#Kuiper2sample'>
<p>Computes the p-value for a two-sample Kuiper test, given arbitrary data samples on the real line or on the circle with possibly repeated observations (i.e. ties)</p></a></li>
<li><a href='#Kuiper2sample_c_Rcpp'>
<p>R function calling the C++ routines that compute the complementary p-value for a (unweighted) two-sample Kuiper test, given arbitrary data samples on the real line or on the circle with possibly repeated observations (i.e. ties)</p></a></li>
<li><a href='#Kuiper2sample_Rcpp'>
<p>R function calling the C++ routines that compute the p-value for a (unweighted) two-sample Kuiper test, given arbitrary data samples on the real line or on the circle with possibly repeated observations (i.e. ties)</p></a></li>
<li><a href='#mixed_ks_c_cdf'>
<p>Computes the complementary cumulative distribution function of the two-sided Kolmogorov-Smirnov statistic when the cdf under the null hypothesis is mixed</p></a></li>
<li><a href='#mixed_ks_test'>
<p>Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is mixed</p></a></li>
<li><a href='#Population_Data'>
<p>The proportion of inhabitants living within a 200 kilometer wide costal strip in 232 countries in the year 2010</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>Title:</td>
<td>Computing P-Values of the One-Sample K-S Test and the Two-Sample
K-S and Kuiper Tests for (Dis)Continuous Null Distribution</td>
</tr>
<tr>
<td>Author:</td>
<td>Dimitrina S. Dimitrova &lt;D.Dimitrova@city.ac.uk&gt;,
        Yun Jia &lt;yunjia2019@gmail.com&gt;,
        Vladimir K. Kaishev &lt;Vladimir.Kaishev.1@city.ac.uk&gt;,
        Senren Tan &lt;raymondtsrtsr@outlook.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dimitrina S. Dimitrova &lt;D.Dimitrova@city.ac.uk&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>fftw3 (&gt;=3.3.4)</td>
</tr>
<tr>
<td>Copyright:</td>
<td>Copyright holders of FFTW3: Copyright (c) 2003, 2007-11
Matteo Frigo; Copyright (c) 2003, 2007-11 Massachusetts
Institute of Technology</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions to compute p-values for the one-sample and two-sample Kolmogorov-Smirnov (KS) tests and the two-sample Kuiper test for any fixed critical level and arbitrary (possibly very large) sample sizes. For the one-sample KS test, this package implements a novel, accurate and efficient method named Exact-KS-FFT, which allows the pre-specified cumulative distribution function under the null hypothesis to be continuous, purely discrete or mixed. In the two-sample case, it is assumed that both samples come from an unspecified (unknown) continuous, purely discrete or mixed distribution, i.e. ties (repeated observations) are allowed, and exact p-values of the KS and the Kuiper tests are computed. Note, the two-sample Kuiper test is often used when data samples are on the line or on the circle (circular data). To cite this package in publication: (for the use of the one-sample KS test) Dimitrina S. Dimitrova, Vladimir K. Kaishev, and Senren Tan. Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed, or Continuous. Journal of Statistical Software. 2020; 95(10): 1&ndash;42.  &lt;<a href="https://doi.org/10.18637%2Fjss.v095.i10">doi:10.18637/jss.v095.i10</a>&gt;. (for the use of the two-sample KS and Kuiper tests) Dimitrina S. Dimitrova, Yun Jia and Vladimir K. Kaishev (2024). The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests. submitted.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/d-dimitrova/KSgeneral">https://github.com/d-dimitrova/KSgeneral</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.12), MASS, dgof</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-20 17:22:45 UTC; jy</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-21 10:40:24 UTC</td>
</tr>
</table>
<hr>
<h2 id='KSgeneral-package'>
Computing P-Values of the One-Sample K-S Test and the Two-Sample
K-S and Kuiper Tests for (Dis)Continuous Null Distribution
</h2><span id='topic+KSgeneral-package'></span>

<h3>Description</h3>

<p>This package computes p-values of the one-sample and two-sample Kolmogorov-Smirnov (KS) tests and the two-sample Kuiper test.
</p>
<p>The one-sample two-sided Kolmogorov-Smirnov (KS) statistic is one of the most popular goodness-of-fit test statistics that is used to measure how well the distribution of a random sample agrees with a prespecified theoretical distribution.
Given a random sample <code class="reqn">\{X_{1},..., X_{n}\}</code> of size <code class="reqn">n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided KS statistic is defined as
<code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code>  is the cdf of the prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn"> \{ X_{1},..., X_{n} \} </code> comes from <code class="reqn">F(x)</code>.
The package <span class="pkg">KSgeneral</span> implements a novel, accurate and efficient Fast Fourier Transform (FFT)-based method, referred as Exact-KS-FFT method to compute the complementary cdf,
<code class="reqn">P(D_{n} \ge q)</code>, at a fixed <code class="reqn">q\in [0, 1]</code> for a given (hypothezied) purely discrete, mixed or continuous underlying cdf <code class="reqn">F(x)</code>, and arbitrary, possibly very large sample size <code class="reqn">n</code>.
A plot of the complementary cdf <code class="reqn">P(D_{n} \ge q)</code>, <code class="reqn">0 \le q \le 1</code>, can also be produced.
</p>
<p>In other words, the package computes the p-value, <code class="reqn">P(D_{n} \ge q)</code> for any fixed critical level <code class="reqn">q\in [0, 1]</code>.
If an observed (data) sample, <code class="reqn">\{x_{1},..., x_{n}\}</code>  is supplied, <span class="pkg">KSgeneral</span> computes the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code>  is the value of the KS test statistic computed based on <code class="reqn">\{x_{1},..., x_{n}\}</code>.  One can also compute the (complementary) cdf for the one-sided KS statistics <code class="reqn">D_{n}^{-}</code>  or <code class="reqn">D_{n}^{+}</code>  (cf., Dimitrova, Kaishev, Tan (2020)) by appropriately specifying correspondingly <code class="reqn">A_{i} = 0</code>  for all <code class="reqn">i</code>  or <code class="reqn">B_{i} = 1</code>  for all <code class="reqn">i</code>, in the function <code><a href="#topic+ks_c_cdf_Rcpp">ks_c_cdf_Rcpp</a></code>.
</p>
<p>The two-sample Kolmogorov-Smirnov (KS) and the Kuiper statistics are widely used to test the null hypothesis (<code class="reqn">H_0</code>) that two data samples come from the same underlying distribution. Given a pair of random samples <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code> of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from unknown CDFs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. We want to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>,  either against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>, which corresponds to the two-sided test, or against <code class="reqn">H_1: F(x)&gt; G(x)</code>  and <code class="reqn">H_1: F(x)&lt; G(x)</code>   for at least one <code class="reqn">x</code>, which corresponds to the two one-sided tests. The (weighted) two-sample Kolmogorov-Smirnov goodness-of-fit statistics that are used to test these hypotheses are generally defined as:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n} = \sup |F_{m}(t) - G_n(t)|W(E_{m+n}(t), \textnormal{ to test against the alternative } H_1: F(x)\neq G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{+} = \sup [F_{m}(t) - G_n(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&gt; G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{-} = \sup [G_n(t) - F_{m}(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&lt; G(x)</code>
</p>
 
<p>where <code class="reqn">E_{m+n}(t)</code>  is the empirical cdf of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, <code class="reqn">W( )</code>  is a strictly positive weight function defined on <code class="reqn">(0,1)</code>. <span class="pkg">KSgeneral</span> implements an exact algorithm which is an extension of the Fortran 77 subroutine due to Nikiforov (1994), to calculate the exact p-value <code class="reqn">P(D_{m,n} \ge q)</code>, where <code class="reqn">q</code> is the observed value of <code class="reqn">\Delta_{m,n}</code> with respect to the two observed samples <code class="reqn">\bm{X}_m=\{x_1,\ldots,x_m\}</code> and <code class="reqn">\bm{Y}_n=\{y_1,\ldots,y_n\}</code> and <code class="reqn">D_{m,n}</code>  is the two-sample Kolmogorov-Smirnov goodness-of-fit test defined on the space <code class="reqn">\Omega</code> of all possible <code class="reqn">\frac{(m+n)!}{m!n!}</code>  pairs of samples, <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, that are <em>randomly drawn from the pooled sample</em> <code class="reqn">\bm{Z}_{m+n}</code> <em>without replacement</em>. Samples may come from any continuous, discrete or mixed distribution, i.e. the test allows repeated observations to appear in the user provided data samples <code class="reqn">\{x_1,\ldots,x_m\}</code>, <code class="reqn">\{y_1,\ldots,y_n\}</code>  and their pooled sample <code class="reqn">\bm{Z}_{m+n}=\{x_1,\ldots,x_m,y_1,\ldots,y_n\}</code>.
</p>
<p>The two-sample (unweighted) Kuiper goodness-of-fit statistic is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\varsigma_{m,n} = \sup [F_{m}(t) - G_n(t)] - \inf [F_{m}(t) - G_n(t)].</code>
</p>
 
<p>It is widely used when the data samples are periodic or circular (data that are measured in radians). <span class="pkg">KSgeneral</span> calculates the exact p-value <code class="reqn">P(V_{m,n} \ge q)</code>, where <code class="reqn">V_{m,n}</code>  is the two-sample Kuiper goodness-of-fit test defined on the on the space, <code class="reqn">\Omega</code>, as described above, and <code class="reqn">q</code>  is the observed value of <code class="reqn">\varsigma_{m,n}</code> with respect to the two observed samples <code class="reqn">\bm{X}_m=\{x_1,\ldots,x_m\}</code> and <code class="reqn">\bm{Y}_n=\{y_1,\ldots,y_n\}</code>. Similarly, as for the KS test, the two-sample Kuiper test also allows repeated observations in the user provided data samples <code class="reqn">\{x_1,\ldots,x_m\}</code>, <code class="reqn">\{y_1,\ldots,y_n\}</code>  and their pooled sample <code class="reqn">\bm{Z}_{m+n}=\{x_1,\ldots,x_m,y_1,\ldots,y_n\}</code>.
</p>


<h3>Details</h3>

<p><b>One-sample KS test</b>:
</p>
<p>The Exact-KS-FFT method to compute p-values of the one-sample KS test in <span class="pkg">KSgeneral</span> is based on expressing the p-value <code class="reqn">P(D_{n} \ge q)</code> in terms of an appropriate rectangle probability with respect to the uniform order statistics, as noted by Gleser (1985) for <code class="reqn">P(D_{n} &gt; q)</code>.
The latter representation is used to express <code class="reqn">P(D_{n} \ge q)</code> via a double-boundary non-crossing probability for a homogeneous Poisson process, with intensity <code class="reqn">n</code>, which is then efficiently computed using FFT, ensuring total run-time of order <code class="reqn">O(n^{2}log(n))</code> (see Dimitrova, Kaishev, Tan (2020) and also Moscovich and Nadler (2017) for the special case when <code class="reqn">F(x)</code> is continuous).
</p>
<p>The code for the one-sample KS test in <span class="pkg">KSgeneral</span> represents an R wrapper of the original C++ code due to Dimitrova, Kaishev, Tan (2020) and based on the C++ code developed by Moscovich and Nadler (2017).
The package includes the functions <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code>, <code><a href="#topic+mixed_ks_c_cdf">mixed_ks_c_cdf</a></code> and <code><a href="#topic+cont_ks_c_cdf">cont_ks_c_cdf</a></code> that compute the complementary cdf <code class="reqn">P(D_n \ge q)</code>, for a fixed <code class="reqn">q</code>, <code class="reqn">0 \le q \le 1</code>, when <code class="reqn">F(x)</code> is purely discrete, mixed or continuous, respectively.
<span class="pkg">KSgeneral</span> includes also the functions <code><a href="#topic+disc_ks_test">disc_ks_test</a></code>, <code><a href="#topic+mixed_ks_test">mixed_ks_test</a></code> and <code><a href="#topic+cont_ks_test">cont_ks_test</a></code> that compute the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a user provided data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, when <code class="reqn">F(x)</code> is purely discrete, mixed or continuous, respectively.
</p>
<p>The functions <code><a href="#topic+disc_ks_test">disc_ks_test</a></code> and <code><a href="#topic+cont_ks_test">cont_ks_test</a></code> represent accurate and fast (run time <code class="reqn">O(n^{2}log(n))</code>) alternatives to the functions <code><a href="stats.html#topic+ks.test">ks.test</a></code> from the package <span class="pkg">dgof</span> and the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> from the package <span class="pkg">stat</span>, which compute p-values of <code class="reqn">P(D_{n} \ge d_{n})</code>, assuming <code class="reqn">F(x)</code> is purely discrete or continuous, respectively.
</p>
<p>The package also includes the function <code><a href="#topic+ks_c_cdf_Rcpp">ks_c_cdf_Rcpp</a></code> which gives the flexibility to compute the complementary cdf (p-value) for the one-sided KS test statistics <code class="reqn">D_{n}^{-}</code> or <code class="reqn">D_{n}^{+}</code>.
It also allows for faster computation time and possibly higher accuracy in computing <code class="reqn">P(D_{n} \ge q)</code>.
</p>
<p><b>Two-sample KS test and Kuiper test</b>:
</p>
<p>The method underlying for computing p-values of the two-sample KS and Kuiper tests in <span class="pkg">KSgeneral</span> is the extension of the algorithm due to Nikiforov (1994) and is based on expressing the p-value as the probability that a point sequence stays within a certain region in the two-dimensional integer-valued lattice. The algorithm for both tests uses a recursive formula to calculate the total number of point sequences within the region which is divided by the total number of elements in <code class="reqn">\Omega</code>, i.e. <code class="reqn">\frac{(m+n)!}{m!n!}</code>  to obtain the probability.
</p>
<p>For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, the p-values calculated by the functions <code>KS2sample</code> and <code>Kuiper2sample</code> are the probabilities:
</p>
<p style="text-align: center;"><code class="reqn">P(D_{m,n}\geq q), P(V_{m,n}\geq q),</code>
</p>

<p>where <code class="reqn">D_{m,n}</code> and <code class="reqn">V_{m,n}</code>  are the two-sample Kolmogorov-Smirnov and Kuiper test statistics respectively, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em>, i.e. they are defined on the space <code class="reqn">\Omega</code>. As before, <code class="reqn">q</code> is the observed value of the statistic with respect to the two observed samples <code class="reqn">\bm{X}_m</code> and <code class="reqn">\bm{Y}_n</code>.
</p>
<p>Both <code><a href="#topic+KS2sample">KS2sample</a></code> and <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> implement algorithms which generalize the method due to Nikiforov (1994), and calculate the exact p-values of the KS test and the Kuiper test respectively. Both of them allow tested data samples to come from continuous, discrete or mixed distributions (ties are also allowed).
</p>
<p><code><a href="#topic+KS2sample">KS2sample</a></code> ensures a total worst-case run-time of order <code class="reqn">O(nm)</code>. Compared with other known algorithms, it not only allows more flexible choices on weights leading to better power (see Dimitrova, Jia, Kaishev 2024), but also is more efficient and more generally applicable for <em>large sample sizes</em>. <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> is accurate and valid for large sample sizes. It ensures a total worst-case run-time of order <code class="reqn">O((mn)^{2})</code>. When <code>m</code> and <code>n</code> have large greatest common divisor (an extreme case is <code>m</code> = <code>n</code>), it ensures a total worst-case run-time of order <code class="reqn">O((m)^{2}n)</code>. 
</p>


<h3>Author(s)</h3>

<p>Dimitrina S. Dimitrova &lt;D.Dimitrova@city.ac.uk&gt;,
        Yun Jia &lt;yunjia2019@gmail.com&gt;,
        Vladimir K. Kaishev &lt;Vladimir.Kaishev.1@city.ac.uk&gt;,
        Senren Tan &lt;raymondtsrtsr@outlook.com&gt;
</p>
<p>Maintainer: Dimitrina S. Dimitrova &lt;D.Dimitrova@city.ac.uk&gt;
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Gleser L.J. (1985). &quot;Exact Power of Goodness-of-Fit Tests of Kolmogorov Type for Discontinuous Distributions&quot;. Journal of the American Statistical Association, <b>80</b>(392), 954-958.
</p>
<p>Moscovich A., Nadler B. (2017). &quot;Fast Calculation of Boundary Crossing Probabilities for Poisson Processes&quot;. Statistics and Probability Letters, <b>123</b>, 177-182.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;.  <em>submitted</em>
</p>

<hr>
<h2 id='cont_ks_c_cdf'>
Computes the complementary cumulative distribution function of the two-sided Kolmogorov-Smirnov statistic when the cdf under the null hypothesis is continuous
</h2><span id='topic+cont_ks_c_cdf'></span>

<h3>Description</h3>

<p>Computes the complementary cdf <code class="reqn">P(D_{n} \ge q) \equiv P(D_{n} &gt; q)</code> at a fixed <code class="reqn">q</code>, <code class="reqn">q\in[0, 1]</code>, for the one-sample two-sided Kolmogorov-Smirnov statistic, <code class="reqn">D_{n}</code>, for a given sample size <code class="reqn">n</code>, when the cdf <code class="reqn">F(x)</code> under the null hypothesis is continuous.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cont_ks_c_cdf(q, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cont_ks_c_cdf_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 1, at which the complementary cdf <code class="reqn">P(D_{n}\ge q)</code> is computed
</p>
</td></tr>
<tr><td><code id="cont_ks_c_cdf_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+cont_ks_c_cdf">cont_ks_c_cdf</a></code> implements the FFT-based algorithm proposed by Moscovich and Nadler (2017) to compute the complementary cdf, <code class="reqn">P(D_{n} \ge q)</code> at a value <code class="reqn">q</code>, when <code class="reqn">F(x)</code> is continuous.
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code> which makes it more efficient and numerically stable than the algorithm proposed by Marsaglia et al. (2003).
The latter is used by many existing packages computing the cdf of <code class="reqn">D_{n}</code>, e.g., the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">stats</span> and the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">dgof</span>.
More precisely, in these packages, the exact p-value, <code class="reqn">P(D_{n} \ge q)</code> is computed only in the case when <code class="reqn">q = d_{n}</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a user provided sample <code class="reqn"> \{x_{1}, ..., x_{n} \} </code>.
Another limitation of the functions <code><a href="stats.html#topic+ks.test">ks.test</a></code> is that the sample size should be less than 100, and the computation time is <code class="reqn">O(n^{3})</code>.
In contrast, the function <code><a href="#topic+cont_ks_c_cdf">cont_ks_c_cdf</a></code> provides results with at least 10 correct digits after the decimal point for sample sizes <code class="reqn">n</code> up to 100000 and computation time of 16 seconds on a machine with an 2.5GHz Intel Core i5 processor with 4GB RAM, running MacOS X Yosemite.
For <code>n</code> &gt; 100000, accurate results can still be computed with similar accuracy, but at a higher computation time.
See Dimitrova, Kaishev, Tan (2020), Appendix C for further details and examples.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{n} \ge q)</code>.
</p>


<h3>Source</h3>

<p>Based on the C++ code available at <a href="https://github.com/mosco/crossing-probability">https://github.com/mosco/crossing-probability</a> developed by Moscovich and Nadler (2017).
See also Dimitrova, Kaishev, Tan (2020) for more details.
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Marsaglia G., Tsang WW., Wang J. (2003). &quot;Evaluating Kolmogorov's Distribution&quot;. Journal of Statistical Software, <b>8</b>(18), 1-4.
</p>
<p>Moscovich A., Nadler B. (2017). &quot;Fast Calculation of Boundary Crossing Probabilities for Poisson Processes&quot;. Statistics and Probability Letters, <b>123</b>, 177-182.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compute the value for P(D_{100} &gt;= 0.05)

KSgeneral::cont_ks_c_cdf(0.05, 100)


## Compute P(D_{n} &gt;= q)
## for n = 100, q = 1/500, 2/500, ..., 500/500
## and then plot the corresponding values against q

n &lt;- 100
q &lt;- 1:500/500
plot(q, sapply(q, function(x) KSgeneral::cont_ks_c_cdf(x, n)), type='l')

## Compute P(D_{n} &gt;= q) for n = 141, nq^{2} = 2.1 as shown
## in Table 18 of Dimitrova, Kaishev, Tan (2020)

KSgeneral::cont_ks_c_cdf(sqrt(2.1/141), 141)

</code></pre>

<hr>
<h2 id='cont_ks_cdf'>
Computes the cumulative distribution function of the two-sided Kolmogorov-Smirnov statistic when the cdf under the null hypothesis is continuous
</h2><span id='topic+cont_ks_cdf'></span>

<h3>Description</h3>

<p>Computes the cdf <code class="reqn">P(D_{n} \le q) \equiv P(D_{n} &lt; q)</code> at a fixed <code class="reqn">q</code>, <code class="reqn">q\in[0, 1]</code>, for the one-sample two-sided Kolmogorov-Smirnov statistic, <code class="reqn">D_{n}</code>, for a given sample size <code class="reqn">n</code>, when the cdf <code class="reqn">F(x)</code> under the null hypothesis is continuous.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cont_ks_cdf(q, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cont_ks_cdf_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 1, at which the cdf <code class="reqn">P(D_{n} \le q)</code> is computed
</p>
</td></tr>
<tr><td><code id="cont_ks_cdf_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+cont_ks_cdf">cont_ks_cdf</a></code> implements the FFT-based algorithm proposed by Moscovich and Nadler (2017) to compute the cdf <code class="reqn">P(D_{n} \le q)</code> at a value <code class="reqn">q</code>, when <code class="reqn">F(x)</code> is continuous.
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code> which makes it more efficient and numerically stable than the algorithm proposed by Marsaglia et al. (2003).
The latter is used by many existing packages computing the cdf of <code class="reqn">D_{n}</code>, e.g., the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">stats</span> and the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">dgof</span>.
More precisely, in these packages, the exact p-value, <code class="reqn">P(D_{n} \ge q)</code> is computed only in the case when <code class="reqn">q = d_{n}</code>, where <code class="reqn">d_{n}</code> is the value of the KS statistic computed based on a user provided sample <code class="reqn"> \{x_{1}, ..., x_{n} \} </code>.
Another limitation of the functions <code><a href="stats.html#topic+ks.test">ks.test</a></code> is that the sample size should be less than 100, and the computation time is <code class="reqn">O(n^{3})</code>.
In contrast, the function <code><a href="#topic+cont_ks_cdf">cont_ks_cdf</a></code> provides results with at least 10 correct digits after the decimal point for sample sizes <code class="reqn">n</code> up to 100000 and computation time of 16 seconds on a machine with an 2.5GHz Intel Core i5 processor with 4GB RAM, running MacOS X Yosemite.
For <code>n</code> &gt; 100000, accurate results can still be computed with similar accuracy, but at a higher computation time.
See Dimitrova, Kaishev, Tan (2020), Appendix B for further details and examples.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{n} \le q)</code>.
</p>


<h3>Source</h3>

<p>Based on the C++ code available at <a href="https://github.com/mosco/crossing-probability">https://github.com/mosco/crossing-probability</a> developed by Moscovich and Nadler (2017).
See also Dimitrova, Kaishev, Tan (2020) for more details.
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Marsaglia G., Tsang WW., Wang J. (2003). &quot;Evaluating Kolmogorov's Distribution&quot;. Journal of Statistical Software, <b>8</b>(18), 1-4.
</p>
<p>Moscovich A., Nadler B. (2017). &quot;Fast Calculation of Boundary Crossing Probabilities for Poisson Processes&quot;. Statistics and Probability Letters, <b>123</b>, 177-182.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compute the value for P(D_{100} &lt;= 0.05)

KSgeneral::cont_ks_cdf(0.05, 100)


## Compute P(D_{n} &lt;= q)
## for n = 100, q = 1/500, 2/500, ..., 500/500
## and then plot the corresponding values against q

n&lt;-100
q&lt;-1:500/500
plot(q, sapply(q, function(x) KSgeneral::cont_ks_cdf(x, n)), type='l')

## Compute P(D_{n} &lt;= q) for n = 40, nq^{2} = 0.76 as shown
## in Table 9 of Dimitrova, Kaishev, Tan (2020)

KSgeneral::cont_ks_cdf(sqrt(0.76/40), 40)

</code></pre>

<hr>
<h2 id='cont_ks_test'>
Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is continuous
</h2><span id='topic+cont_ks_test'></span>

<h3>Description</h3>

<p>Computes the p-value <code class="reqn">P(D_{n} \ge d_{n}) \equiv P(D_{n} &gt; d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, when <code class="reqn">F(x)</code> is continuous.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cont_ks_test(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cont_ks_test_+3A_x">x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{n}\}</code>.
</p>
</td></tr>
<tr><td><code id="cont_ks_test_+3A_y">y</code></td>
<td>

<p>a pre-specified continuous cdf, <code class="reqn">F(x)</code> under the null hypothesis. Note that <code>y</code> should be a character string naming a continuous cumulative distribution function such as <code><a href="stats.html#topic+pexp">pexp</a></code>, <code><a href="stats.html#topic+pnorm">pnorm</a></code>, etc.
Only continuous cdfs are valid!
</p>
</td></tr>
<tr><td><code id="cont_ks_test_+3A_...">...</code></td>
<td>

<p>values of the parameters of the cdf, <code class="reqn">F(x)</code> specified (as a character string) by <code>y</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+cont_ks_test">cont_ks_test</a></code> implements the FFT-based algorithm proposed by Moscovich and Nadler (2017) to compute the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a user provided data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, assuming <code class="reqn">F(x)</code> is continuous.
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code> which makes it more efficient and numerically stable than the algorithm proposed by Marsaglia et al. (2003).
The latter is used by many existing packages computing the cdf of <code class="reqn">D_{n}</code>, e.g., the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">stats</span> and the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">dgof</span>.
A limitation of the functions <code><a href="stats.html#topic+ks.test">ks.test</a></code> is that the sample size should be less than 100, and the computation time is <code class="reqn">O(n^{3})</code>.
In contrast, the function <code><a href="#topic+cont_ks_test">cont_ks_test</a></code> provides results with at least 10 correct digits after the decimal point for sample sizes <code class="reqn">n</code> up to 100000 and computation time of 16 seconds on a machine with an 2.5GHz Intel Core i5 processor with 4GB RAM, running MacOS X Yosemite.
For <code>n</code> &gt; 100000, accurate results can still be computed with similar accuracy, but at a higher computation time.
See Dimitrova, Kaishev, Tan (2020), Appendix C for further details and examples.
</p>


<h3>Value</h3>

<p>A list with class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>&quot;two-sided&quot;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Based on the C++ code available at <a href="https://github.com/mosco/crossing-probability">https://github.com/mosco/crossing-probability</a> developed by Moscovich and Nadler (2017).
See also Dimitrova, Kaishev, Tan (2020) for more details.
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Moscovich A., Nadler B. (2017). &quot;Fast Calculation of Boundary Crossing Probabilities for Poisson Processes&quot;. Statistics and Probability Letters, <b>123</b>, 177-182.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Comparing the p-values obtained by stat::ks.test
## and KSgeneral::cont_ks_test

x&lt;-abs(rnorm(100))
p.kt &lt;- ks.test(x, "pexp", exact = TRUE)$p
p.kt_fft &lt;- KSgeneral::cont_ks_test(x, "pexp")$p
abs(p.kt-p.kt_fft)


</code></pre>

<hr>
<h2 id='disc_ks_c_cdf'>
Computes the complementary cumulative distribution function of the two-sided Komogorov-Smirnov statistic when the cdf under the null hypothesis is purely discrete
</h2><span id='topic+disc_ks_c_cdf'></span>

<h3>Description</h3>

<p>Computes the complementary cdf, <code class="reqn">P(D_{n} \ge q)</code> at a fixed <code class="reqn">q</code>, <code class="reqn">q\in[0, 1]</code>, of the one-sample two-sided Kolmogorov-Smirnov (KS) statistic, when the cdf <code class="reqn">F(x)</code> under the null hypothesis is purely discrete, using the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
Moreover, for comparison purposes, <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code> gives, as an option, the possibility to compute (an approximate value for) the asymptotic <code class="reqn">P(D_{n} \ge q)</code> using the simulation-based algorithm of Wood and Altavela (1978).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disc_ks_c_cdf(q, n, y, ..., exact = NULL, tol = 1e-08, sim.size = 1e+06, num.sim = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disc_ks_c_cdf_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 1, at which the complementary cdf <code class="reqn">P(D_{n}\ge q)</code> is computed
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_y">y</code></td>
<td>

<p>a pre-specified discrete cdf, <code class="reqn">F(x)</code> under the null hypothesis.
Note that <code>y</code> should be a step function within the class: <code><a href="stats.html#topic+stepfun">stepfun</a></code>, of which <code><a href="stats.html#topic+ecdf">ecdf</a></code> is a subclass!
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_...">...</code></td>
<td>

<p>values of the parameters of the cdf, <code class="reqn">F(x)</code>, specified (as a character string) by <code>y</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_exact">exact</code></td>
<td>

<p>logical variable specifying whether one wants to compute exact p-value <code class="reqn">P(D_{n} \ge q)</code> using the Exact-KS-FFT method, in which case <code>exact = TRUE</code> or wants to compute an approximate p-value <code class="reqn">P(D_{n} \ge q)</code> using the simulation-based algorithm of Wood and Altavela (1978), in which case <code>exact = FALSE</code>. When <code>exact = NULL</code> and <code>n &lt;= 100000</code>, the exact <code class="reqn">P(D_{n} \ge q)</code> will be computed using the Exact-KS-FFT method. Otherwise, the asymptotic complementary cdf is computed based on Wood and Altavela (1978). By default, <code>exact = NULL</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_tol">tol</code></td>
<td>

<p>the value of <code class="reqn">\epsilon</code> that is used to compute the values of <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, as detailed in Step 1 of Section 2.1 in Dimitrova, Kaishev and Tan (2020) (see also (ii) in the Procedure Exact-KS-FFT therein). By default, <code>tol = 1e-08</code>. Note that a value of <code>NA</code> or <code>0</code> will lead to an error!
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_sim.size">sim.size</code></td>
<td>

<p>the required number of simulated trajectories in order to produce one Monte Carlo estimate (one MC run) of the asymptotic complementary cdf using the algorithm of Wood and Altavela (1978). By default, <code>sim.size = 1e+06</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_c_cdf_+3A_num.sim">num.sim</code></td>
<td>

<p>the number of MC runs, each producing one estimate (based on <code>sim.size</code> number of trajectories), which are then averaged in order to produce the final estimate for the asymptotic complementary cdf. This is done in order to reduce the variance of the final estimate. By default, <code>num.sim = 10</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code> implements the Exact-KS-FFT method, proposed by Dimitrova, Kaishev, Tan (2020) to compute the complementary cdf <code class="reqn">P(D_{n} \ge q)</code> at a value <code class="reqn">q</code>, when <code class="reqn">F(x)</code> is purely discrete.
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code> which makes it more efficient and numerically stable than the only alternative algorithm developed by Arnold and Emerson (2011) and implemented as the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> in the package <span class="pkg">dgof</span>.
The latter only computes a p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, corresponding to the value of the KS test statistic <code class="reqn">d_{n}</code> computed based on a user provided sample <code class="reqn"> \{x_{1}, ..., x_{n} \} </code>.
More precisely, in the package <span class="pkg">dgof</span> (function <code><a href="stats.html#topic+ks.test">ks.test</a></code>), the p-value for a one-sample two-sided KS test is calculated by combining the approaches of Gleser (1985) and Niederhausen (1981). However, the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> only provides exact p-values for <code>n</code> <code class="reqn">\le</code> 30, since as noted by the authors (see Arnold and Emerson (2011)), when <code>n</code> is large, numerical instabilities may occur. In the latter case, <code><a href="stats.html#topic+ks.test">ks.test</a></code> uses simulation to approximate p-values, which may be rather slow and inaccurate (see Table 6 of Dimitrova, Kaishev, Tan (2020)).
</p>
<p>Thus, making use of the Exact-KS-FFT method, the function <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code> provides an exact and highly computationally efficient (alternative) way of computing <code class="reqn">P(D_{n} \ge q)</code> at a value <code class="reqn">q</code>, when <code class="reqn">F(x)</code> is purely discrete.
</p>
<p>Lastly, incorporated into the function <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code> is the MC simulation-based method of Wood and Altavela (1978) for estimating the asymptotic complementary cdf of <code class="reqn">D_{n}</code>. The latter method is the default method behind <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code> when the sample size <code>n</code> is <code>n</code> <code class="reqn">\ge</code> 100000.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{n} \ge q)</code>.
</p>


<h3>References</h3>

<p>Arnold T.A., Emerson J.W. (2011). &quot;Nonparametric Goodness-of-Fit Tests for Discrete Null Distributions&quot;. The R Journal, <b>3</b>(2), 34-39.
</p>
<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Gleser L.J. (1985). &quot;Exact Power of Goodness-of-Fit Tests of Kolmogorov Type for Discontinuous Distributions&quot;. Journal of the American Statistical Association, <b>80</b>(392), 954-958.
</p>
<p>Niederhausen H. (1981). &quot;Sheffer Polynomials for Computing Exact Kolmogorov-Smirnov and Renyi Type Distributions&quot;. The Annals of Statistics, 58-64.
</p>
<p>Wood C.L., Altavela M.M. (1978). &quot;Large-Sample Results for Kolmogorov-Smirnov Statistics for Discrete Distributions&quot;. Biometrika, <b>65</b>(1), 235-239.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ks.test">ks.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example to compute the exact complementary cdf for D_{n}
## when the underlying cdf F(x) is a binomial(3, 0.5) distribution,
## as shown in Example 3.4 of Dimitrova, Kaishev, Tan (2020)

binom_3 &lt;- stepfun(c(0:3), c(0,pbinom(0:3,3,0.5)))
KSgeneral::disc_ks_c_cdf(0.05, 400, binom_3)

## Not run: 
## Compute P(D_{n} &gt;= q) for n = 100,
## q = 1/5000, 2/5000, ..., 5000/5000, when
## the underlying cdf F(x) is a binomial(3, 0.5) distribution,
## as shown in Example 3.4 of Dimitrova, Kaishev, Tan (2020),
## and then plot the corresponding values against q,
## i.e. plot the resulting complementary cdf of D_{n}

n &lt;- 100
q &lt;- 1:5000/5000
binom_3 &lt;- stepfun(c(0:3), c(0,pbinom(0:3,3,0.5)))
plot(q, sapply(q, function(x) KSgeneral::disc_ks_c_cdf(x, n, binom_3)), type='l')

## End(Not run)

## Not run: 
## Example to compute the asymptotic complementary cdf for D_{n}
## based on Wood and Altavela (1978),
## when the underlying cdf F(x) is a binomial(3, 0.5) distribution,
## as shown in Example 3.4 of Dimitrova, Kaishev, Tan (2020)

binom_3 &lt;- stepfun(c(0: 3), c(0, pbinom(0 : 3, 3, 0.5)))
KSgeneral::disc_ks_c_cdf(0.05, 400, binom_3, exact = FALSE, tol = 1e-08,
sim.size = 1e+06, num.sim = 10)

## End(Not run)

</code></pre>

<hr>
<h2 id='disc_ks_test'>
Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is purely discrete
</h2><span id='topic+disc_ks_test'></span>

<h3>Description</h3>

<p>Computes the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, when <code class="reqn">F(x)</code> is purely discrete, using the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disc_ks_test(x, y, ..., exact = NULL, tol = 1e-08, sim.size = 1e+06, num.sim = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disc_ks_test_+3A_x">x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{n}\}</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_test_+3A_y">y</code></td>
<td>

<p>a pre-specified discrete cdf, <code class="reqn">F(x)</code>, under the null hypothesis.
Note that <code>y</code> should be a step function within the class: <code><a href="stats.html#topic+stepfun">stepfun</a></code>, of which <code><a href="stats.html#topic+ecdf">ecdf</a></code> is a subclass!
</p>
</td></tr>
<tr><td><code id="disc_ks_test_+3A_...">...</code></td>
<td>

<p>values of the parameters of the cdf, <code class="reqn">F(x)</code>, specified (as a character string) by <code>y</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_test_+3A_exact">exact</code></td>
<td>

<p>logical variable specifying whether one wants to compute exact p-value <code class="reqn">P(D_{n} \ge d_{n})</code> using the Exact-KS-FFT method, in which case <code>exact = TRUE</code> or wants to compute an approximate p-value <code class="reqn">P(D_{n} \ge d_{n})</code> using the simulation-based algorithm of Wood and Altavela (1978), in which case <code>exact = FALSE</code>. When <code>exact = NULL</code> and <code>n &lt;= 100000</code>, the exact <code class="reqn">P(D_{n} \ge d_{n})</code> will be computed using the Exact-KS-FFT method. Otherwise, the asymptotic complementary cdf is computed based on Wood and Altavela (1978). By default, <code>exact = NULL</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_test_+3A_tol">tol</code></td>
<td>

<p>the value of <code class="reqn">\epsilon</code> that is used to compute the values of <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, as detailed in Step 1 of Section 2.1 in Dimitrova, Kaishev and Tan (2020) (see also (ii) in the Procedure Exact-KS-FFT therein). By default, <code>tol = 1e-08</code>. Note that a value of <code>NA</code> or <code>0</code> will lead to an error!
</p>
</td></tr>
<tr><td><code id="disc_ks_test_+3A_sim.size">sim.size</code></td>
<td>

<p>the required number of simulated trajectories in order to produce one Monte Carlo estimate (one MC run) of the asymptotic p-value using the algorithm of Wood and Altavela (1978). By default, <code>sim.size = 1e+06</code>.
</p>
</td></tr>
<tr><td><code id="disc_ks_test_+3A_num.sim">num.sim</code></td>
<td>

<p>the number of MC runs, each producing one estimate (based on <code>sim.size</code> number of trajectories), which are then averaged in order to produce the final estimate for the asymptotic p-value. This is done in order to reduce the variance of the final estimate. By default, <code>num.sim = 10</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+disc_ks_test">disc_ks_test</a></code> implements the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
It represents an accurate and fast (run time <code class="reqn">O(n^{2}log(n))</code>) alternative to the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> from the package <span class="pkg">dgof</span>, which computes a p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a user provided data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, assuming <code class="reqn">F(x)</code> is purely discrete.
</p>
<p>In the function <code><a href="stats.html#topic+ks.test">ks.test</a></code>, the p-value for a one-sample two-sided KS test is calculated by combining the approaches of Gleser (1985) and Niederhausen (1981). However, the function <code><a href="stats.html#topic+ks.test">ks.test</a></code> due to Arnold and Emerson (2011) only provides exact p-values for <code>n</code> <code class="reqn">\le</code> 30, since as noted by the authors, when <code>n</code> is large, numerical instabilities may occur. In the latter case, <code><a href="stats.html#topic+ks.test">ks.test</a></code> uses simulation to approximate p-values, which may be rather slow and inaccurate (see Table 6 of Dimitrova, Kaishev, Tan (2020)).
</p>
<p>Thus, making use of the Exact-KS-FFT method, the function <code><a href="#topic+disc_ks_test">disc_ks_test</a></code> provides an exact and highly computationally efficient (alternative) way of computing the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, when <code class="reqn">F(x)</code> is purely discrete.
</p>
<p>Lastly, incorporated into the function <code><a href="#topic+disc_ks_test">disc_ks_test</a></code> is the MC simulation-based method of Wood and Altavela (1978) for estimating the asymptotic p-value of <code class="reqn">D_{n}</code>. The latter method is the default method behind <code><a href="#topic+disc_ks_test">disc_ks_test</a></code> when the sample size <code>n</code> is <code>n</code> <code class="reqn">\ge</code> 100000.
</p>


<h3>Value</h3>

<p>A list with class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>&quot;two-sided&quot;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Arnold T.A., Emerson J.W. (2011). &quot;Nonparametric Goodness-of-Fit Tests for Discrete Null Distributions&quot;. The R Journal, <b>3</b>(2), 34-39.
</p>
<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Gleser L.J. (1985). &quot;Exact Power of Goodness-of-Fit Tests of Kolmogorov Type for Discontinuous Distributions&quot;. Journal of the American Statistical Association, <b>80</b>(392), 954-958.
</p>
<p>Niederhausen H. (1981). &quot;Sheffer Polynomials for Computing Exact Kolmogorov-Smirnov and Renyi Type Distributions&quot;. The Annals of Statistics, 58-64.
</p>
<p>Wood C.L., Altavela M.M. (1978). &quot;Large-Sample Results for Kolmogorov-Smirnov Statistics for Discrete Distributions&quot;. Biometrika, <b>65</b>(1), 235-239.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ks.test">ks.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Comparison of results obtained from dgof::ks.test
# and KSgeneral::disc_ks_test, when F(x) follows the discrete
# Uniform[1, 10] distribution as in Example 3.5 of
# Dimitrova, Kaishev, Tan (2020)

# When the sample size is larger than 100, the
# function dgof::ks.test will be numerically
# unstable

x3 &lt;- sample(1:10, 25, replace = TRUE)
KSgeneral::disc_ks_test(x3, ecdf(1:10), exact = TRUE)
dgof::ks.test(x3, ecdf(1:10), exact = TRUE)
KSgeneral::disc_ks_test(x3, ecdf(1:10), exact = TRUE)$p -
          dgof::ks.test(x3, ecdf(1:10), exact = TRUE)$p

x4 &lt;- sample(1:10, 500, replace = TRUE)
KSgeneral::disc_ks_test(x4, ecdf(1:10), exact = TRUE)
dgof::ks.test(x4, ecdf(1:10), exact = TRUE)
KSgeneral::disc_ks_test(x4, ecdf(1:10), exact = TRUE)$p -
          dgof::ks.test(x4, ecdf(1:10), exact = TRUE)$p

# Using stepfun() to specify the same discrete distribution as defined by ecdf():

steps &lt;- stepfun(1:10, cumsum(c(0, rep(0.1, 10))))
KSgeneral::disc_ks_test(x3, steps, exact = TRUE)

</code></pre>

<hr>
<h2 id='ks_c_cdf_Rcpp'>
R function calling directly the C++ routines that compute the complementary cumulative distribution function of the two-sided (or one-sided, as a special case) Kolmogorov-Smirnov statistic, when the cdf under the null hypothesis is arbitrary (i.e., purely discrete, mixed or continuous)
</h2><span id='topic+ks_c_cdf_Rcpp'></span>

<h3>Description</h3>

<p>Function calling directly the C++ routines that compute the complementary cdf for the one-sample two-sided Kolmogorov-Smirnov statistic, given the sample size <code>n</code> and the file &quot;Boundary_Crossing_Time.txt&quot; in the working directory.
The latter file contains <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, specified in Steps 1 and 2 of the Exact-KS-FFT method (see Equation (5) in Section 2 of Dimitrova, Kaishev, Tan (2020)).
The latter values form the n-dimensional rectangular region for the uniform order statistics (see Equations (3), (5) and (6) in Dimitrova, Kaishev, Tan (2020)), namely
<code class="reqn">P(D_{n}\ge q) = 1 - P(A_{i} \le U_{(i)} \le B_{i}, 1 \le i \le n) = 1 - P(g(t) \le nU_{n}(t) \le h(t), 0 \le t \le 1)</code>,
where the upper and lower boundary functions <code class="reqn">h(t)</code>, <code class="reqn">g(t)</code> are defined as
<code class="reqn">h(t) = \sum_{i=1}^{n}1_{(A_{i} &lt; t)}</code>, <code class="reqn">g(t) = \sum_{i=1}^{n}1_{(B_{i} \le t)}</code>,
or equivalently, noting that <code class="reqn">h(t)</code> and <code class="reqn">g(t)</code> are correspondingly left and right continuous functions, we have
<code class="reqn">\sup\{t\in[0,1]: h(t) &lt; i \} = A_{i}</code> and <code class="reqn">\inf\{t\in[0,1]: g(t) &gt; i-1 \} = B_{i}</code>.
</p>
<p>Note that on can also compute the (complementary) cdf for the one-sided KS statistics <code class="reqn">D_{n}^{-}</code> or <code class="reqn">D_{n}^{+}</code> (cf., Dimitrova, Kaishev, Tan (2020)) by appropriately specifying correspondingly <code class="reqn">A_{i} = 0</code> for all <code class="reqn">i</code> or <code class="reqn">B_{i} = 1</code> for all <code class="reqn">i</code>, in the function <code><a href="#topic+ks_c_cdf_Rcpp">ks_c_cdf_Rcpp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ks_c_cdf_Rcpp(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ks_c_cdf_Rcpp_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that all calculations here are done directly in C++ and output in R.
That leads to faster computation time, as well as in some cases, possibly higher accuracy (depending on the accuracy of the pre-computed values <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, provided in the file &quot;Boundary_Crossing_Time.txt&quot;) compared to the functions <code><a href="#topic+cont_ks_c_cdf">cont_ks_c_cdf</a></code>, <code><a href="#topic+disc_ks_c_cdf">disc_ks_c_cdf</a></code>, <code><a href="#topic+mixed_ks_c_cdf">mixed_ks_c_cdf</a></code>.
</p>
<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
The one-sided KS test statistics are correspondingly defined as <code class="reqn">D_{n}^{-} = \sup_{x} (F(x) - F_{n}(x))</code> and <code class="reqn">D_{n}^{+} = \sup_{x} (F_{n}(x) - F(x))</code>.
</p>
<p>The function <code><a href="#topic+ks_c_cdf_Rcpp">ks_c_cdf_Rcpp</a></code> implements the Exact-KS-FFT method, proposed by Dimitrova, Kaishev, Tan (2020), to compute the complementary cdf, <code class="reqn">P(D_{n} \ge q)</code> at a value <code class="reqn">q</code>, when <code class="reqn">F(x)</code> is arbitrary (i.e. purely discrete, mixed or continuous).
It is based on expressing the complementary cdf as
<code class="reqn">P(D_{n} \ge q) = 1 - P(A_{i} \le U_{(i)} \le B_{i}, 1 \le i \le n)</code>, where <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code> are defined as in Step 1 of Dimitrova, Kaishev, Tan (2020).
</p>
<p>The complementary cdf is then re-expressed in terms of the conditional probability that a homogeneous Poisson process, <code class="reqn">\xi_{n}(t)</code> with intensity <code class="reqn">n</code> will not cross an upper boundary <code class="reqn">h(t)</code> and a lower boundary <code class="reqn">g(t)</code>, given that <code class="reqn">\xi_{n}(1) = n</code> (see Steps 2 and 3 in Section 2.1 of Dimitrova, Kaishev, Tan (2020)). This conditional probability is evaluated using FFT in Step 4 of the method in order to obtain the value of the complementary cdf <code class="reqn">P(D_{n} \ge q)</code>.
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code> which makes it highly computationally efficient compared to other known algorithms developed for the special cases of continuous or purely discrete <code class="reqn">F(x)</code>.
</p>
<p>The values <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, specified in Steps 1 and 2 of the Exact-KS-FFT method (see Dimitrova, Kaishev, Tan (2020), Section 2) must be pre-computed (in R or, if needed, using alternative softwares offering high accuracy, e.g. Mathematica) and saved in a file with the name &quot;Boundary_Crossing_Time.txt&quot; (in the current working directory).
</p>
<p>The function <code><a href="#topic+ks_c_cdf_Rcpp">ks_c_cdf_Rcpp</a></code> is called in R and it first reads the file &quot;Boundary_Crossing_Time.txt&quot; and then computes the value for the complementaty cdf
<code class="reqn">P(D_{n}\ge q) = 1 - P(A_{i} \le U_{(i)} \le B_{i}, 1 \le i \le n) = 1 - P(g(t) \le nU_{n}(t) \le h(t), 0 \le t \le 1)</code> in C++ and output in R (or as noted above, as a special case, computes the value of the complementary cdf <code class="reqn">P(D_{n}^{+} \ge q) = 1 - P(A_{i} \le U_{(i)} \le 1, 1 \le i \le n)</code> or <code class="reqn">P(D_{n}^{-} \ge q) = 1 - P(0 \le U_{(i)} \le B_{i}, 1 \le i \le n)</code>).
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{n}\ge q) = 1 - P(A_{i} \le U_{(i)} \le B_{i}, 1 \le i \le n) = 1 - P(g(t) \le \eta_{n}(t) \le h(t), 0 \le t \le 1)</code> (or, as a special case, to <code class="reqn">P(D_{n}^{+} \ge q)</code> or <code class="reqn">P(D_{n}^{-} \ge q)</code>), given a sample size <code>n</code> and the file &quot;Boundary_Crossing_Time.txt&quot; containing <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, specified in Steps 1 and 2 of the Exact-KS-FFT method (see Dimitrova, Kaishev, Tan (2020), Section 2).
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Moscovich A., Nadler B. (2017). &quot;Fast Calculation of Boundary Crossing Probabilities for Poisson Processes&quot;. Statistics and Probability Letters, <b>123</b>, 177-182.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Computing the complementary cdf P(D_{n} &gt;= q)
## for n = 10 and q = 0.1, when F(x) is continuous,
## In this case,
## B_i = (i-1)/n + q
## A_i =  i/n - q


n &lt;- 10
q &lt;- 0.1
up_rec &lt;- ((1:n)-1)/n + q
low_rec &lt;- (1:n)/n - q
df &lt;- data.frame(rbind(up_rec, low_rec))
write.table(df,"Boundary_Crossing_Time.txt", sep = ", ",
                  row.names = FALSE, col.names = FALSE)
ks_c_cdf_Rcpp(n)

</code></pre>

<hr>
<h2 id='KS2sample'>
Computes the p-value for a (weighted) two-sample Kolmogorov-Smirnov test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)
</h2><span id='topic+KS2sample'></span>

<h3>Description</h3>

<p>Computes the p-value <code class="reqn">P(D_{m,n} \ge q)</code>, where <code class="reqn">D_{m,n}</code> is the one- or two-sided two-sample Kolmogorov-Smirnov test statistic with weight function <code>weight</code>, <code class="reqn">q</code> is the observed value of KS statistic computed based on two data samples <code class="reqn">\{x_{1},..., x_{m}\}</code> and <code class="reqn">\{y_{1},..., y_{n}\}</code> that may come from continuous, discrete or mixed distribution, i.e. they may have repeated observations (ties).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KS2sample(x, y, alternative = c("two.sided", "less", "greater"),
conservative = F, weight = 0, tol = 1e-08, tail = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KS2sample_+3A_x">x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{m}\}</code>.
</p>
</td></tr>
<tr><td><code id="KS2sample_+3A_y">y</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{y_{1}, ..., y_{n}\}</code>
</p>
</td></tr>
<tr><td><code id="KS2sample_+3A_alternative">alternative</code></td>
<td>

<p>Indicates the alternative hypothesis and must be one of &quot;two.sided&quot; (default), &quot;less&quot;, or &quot;greater&quot;. One can specify just the initial letter of the string, but the argument name must be given in full, e.g. <code>alternative = "t"</code>.   See &lsquo;Details&rsquo; for the meaning of the possible values.
</p>
</td></tr>
<tr><td><code id="KS2sample_+3A_conservative">conservative</code></td>
<td>

<p>logical variable indicating whether ties should be considered. See &lsquo;Details&rsquo; for the meaning.
</p>
</td></tr>
<tr><td><code id="KS2sample_+3A_weight">weight</code></td>
<td>

<p>either a numeric value between 0 and 1 which specifies the form of the weight function from a class of pre-defined functions, or a user-defined strictly positive function of one variable. By default, no weight function is assumed. See &lsquo;Details&rsquo; for the meaning of the possible values.
</p>
</td></tr>
<tr><td><code id="KS2sample_+3A_tol">tol</code></td>
<td>
 
<p>the value of <code class="reqn">\epsilon</code> for computing <code class="reqn">P(D_{m,n} &gt;q- \epsilon)</code>, which is equivalent to <code class="reqn">P(D_{m,n} \geq q)</code>. Non-positive input (<code>tol</code> <code class="reqn">\leq 0</code>) or large input (<code>tol</code> <code class="reqn">&gt;</code><code>1e-6</code>) are replaced by <code>tol = 1e-6</code>. In cases when <code>m</code> and <code>n</code> have large least common multiple, a smaller value is highly recommended.
</p>
</td></tr>
<tr><td><code id="KS2sample_+3A_tail">tail</code></td>
<td>

<p>logical variable indicating whether a p-value, <code class="reqn">P(D_{m,n} \ge q)</code> or one minus the p-value, <code class="reqn">P(D_{m,n} &lt; q)</code>, should be computed. By default, the p-value <code class="reqn">P(D_{m,n} \ge q)</code> is computed.  See &lsquo;Details&rsquo; for the meaning.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a pair of random samples <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code> of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>,  either against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>, which corresponds to the two-sided test, or against <code class="reqn">H_1: F(x)&gt; G(x)</code>  and <code class="reqn">H_1: F(x)&lt; G(x)</code>   for at least one <code class="reqn">x</code>, which corresponds to the two one-sided tests. The (weighted) two-sample Kolmogorov-Smirnov goodness-of-fit statistics that are used to test these hypotheses are generally defined as:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n} = \sup |F_{m}(t) - G_n(t)|W(E_{m+n}(t), \textnormal{ to test against the alternative } H_1: F(x)\neq G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{+} = \sup [F_{m}(t) - G_n(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&gt; G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{-} = \sup [G_n(t) - F_{m}(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&lt; G(x), </code>
</p>

<p>where <code class="reqn">E_{m+n}(t)</code> is the empirical cdf of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, <code class="reqn">W( )</code> is a strictly positive weight function defined on <code class="reqn">[0,1]</code>. 
</p>
<p>Possible values of <code>alternative</code> are <code>"two.sided"</code>, <code>"greater"</code> and <code>"less"</code> which specify the alternative hypothesis, i.e. specify the test statistics to be either <code class="reqn">\Delta_{m,n}</code>, <code class="reqn">\Delta_{m,n}^{+}</code> or  <code class="reqn">\Delta_{m,n}^{-}</code> respectively. 
</p>
<p>When <code>weight</code> is assigned with a numeric value <code class="reqn">\nu</code> between <code>0</code> and <code>1</code>, the test statistic is specified as the weighted two-sample Kolmorogov-Smirnov test with generalized Anderson-Darling weight <code class="reqn">W(t)=1/[t(1-t)]^{\nu}</code> (see Finner and Gontscharuk 2018). Then for example, the two-sided two-sample Kolmogorov-Smirnov statistic has the following form:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}=\sup\limits_{t} \frac{|F_m(t)-G_n(t)|}{[E_{m+n}(t)(1-E_{m+n}(t))]^{\nu}}</code>
</p>

<p>The latter specification defines a family of weighted Kolmogorov-Smirnov tests, covering the unweighted test (when <code>weight = </code> <code class="reqn">\nu = 0</code>), and the widely-known weighted Kolmogorov-Smirnov test with Anderson-Darling weight (when <code>weight = 0.5</code>, see definition of this statistic also in Canner 1975).
If one wants to implement a weighted test with a user-specified weight function, for example, <code class="reqn">W(t)=1/[t(2-t)]^{1/2}</code> suggested by Buning (2001), which ensures higher power when both <code>x</code> and <code>y</code> come from distributions that are left-skewed and heavy-tailed, one can directly assign a univariate function with output value <code>1/sqrt(t*(2-t))</code> to <code>weight</code>.  See &lsquo;Examples&rsquo; for this demonstration.
</p>
<p>For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The p-value is then defined as the probability
</p>
<p style="text-align: center;"><code class="reqn">p=P\left(D_{m,n}\geq q\right),</code>
</p>

<p>where <code class="reqn">D_{m,n}</code> is the two-sample Kolmogorov-Smirnov test statistic defined according to the value of <code>weight</code> and <code>alternative</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em> and <code class="reqn">q</code> is the observed value of the statistic calculated based on the user provided data samples <code>x</code> and <code>y</code>. By default <code>tail = T</code>, the p-value is returned, otherwise <code>1 - p</code> is returned.
</p>
<p>Note that, <code class="reqn">D_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> of all possible pairs,  <code class="reqn">C = \frac{(m+n)!}{m!n!}</code>  of edfs <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code>, <code class="reqn">\omega \in \Omega</code>, that correspond to the pairs of samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code>, randomly drawn from, <code class="reqn">\bm{Z}_{m+n}</code>, as follows.  First, <code class="reqn">m</code> observations are drawn at random without replacement, forming the first sample <code class="reqn">\bm{X}'_m</code>, with corresponding edf, <code class="reqn">F_m(x,\omega)</code>. The remaining <code class="reqn">n</code> observations are then assigned to the second sample <code class="reqn">\bm{Y}'_n</code>, with corresponding edf <code class="reqn">G_n(x,\omega)</code>. Observations are then replaced back in <code class="reqn">\bm{Z}_{m+n}</code> and re-sampling is continued until the occurrence of all the <code class="reqn">C</code> possible pairs of edfs <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code>,  <code class="reqn">\omega \in \Omega</code>. The pairs of edf's may be coincident if there are ties in the data and each pair, <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code> occurs with probability <code class="reqn">1/C</code>.
</p>
<p><code>conservative</code> is a logical variable whether the test should be conducted conservatively. By default, <code>conservative = F</code>, <code><a href="#topic+KS2sample">KS2sample</a></code> returns the p-value that is defined through the conditional probability above. However, when the user has a priori knowledge that both samples are from a continuous distribution even if ties are present, for example, repeated observations are caused by rounding errors, the value <code>conservative = T</code> should be assigned, since the conditional probability is no longer relevant. In this case, <code><a href="#topic+KS2sample">KS2sample</a></code> computes p-values for the Kolmogorov-Smirnov test assuming no ties are present, and returns a p-value which is an upper bound of the true p-value. Note that, if the null hypothesis is rejected using the calculated upper bound for the p-value, it should also be rejected with the true p-value.
</p>
<p><code><a href="#topic+KS2sample">KS2sample</a></code> calculates the exact p-value of the KS test using an algorithm which generalizes the method due to Nikiforov (1994). If <code>tail = F</code>, <code><a href="#topic+KS2sample">KS2sample</a></code> calculates the complementary p-value, <code class="reqn">1 - p</code>. For the purpose, an exact algorithm which generalizes the method due to Nikiforov (1994) is implemented. Alternatively, if <code>tail = T</code>, a version of the Nikiforov's recurrence proposed recently by Viehmann (2021) is implemented, which computes directly the p-value, with higher accuracy, giving up to 17 correct digits, but at up to 3 times higher computational cost. <code><a href="#topic+KS2sample">KS2sample</a></code> ensures a total worst-case run-time of order <code class="reqn">O(nm)</code>. In comparison with other known algorithms, it not only allows the flexible choice of weights which in some cases improve the statistical power (see Dimitrova, Jia, Kaishev 2024), but also is more efficient and generally applicable for <em>large sample sizes</em>.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving names of the data.</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Based on the Fortran subroutine by Nikiforov (1994). See also Dimitrova, Jia, Kaishev (2024).
</p>


<h3>References</h3>

<p>Buning H (2001). &quot;Kolmogorov-Smirnov- and Cramer-von Mises Type Two-sample Tests With Various Weight Functions.&quot; Communications in Statistics - Simulation and Computation, <b>30</b>(4), 847-865.
</p>
<p>Finner H, Gontscharuk V (2018). &quot;Two-sample Kolmogorov-Smirnov-type tests revisited: Old and new tests in terms of local levels.&quot; The Annals of Statistics, <b>46</b>(6A), 3014-3037.
</p>
<p>Paul L. Canner (1975). &quot;A Simulation Study of One- and Two-Sample Kolmogorov-Smirnov Statistics with a Particular Weight Function&quot;. Journal of the American Statistical Association, <b>70</b>(349), 209-211.
</p>
<p>Nikiforov, A. M. (1994). &quot;Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions.&quot; Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265-270.
</p>
<p>Viehmann, T. (2021). Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test. <em>arXiv preprint</em> arXiv:2102.08037.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;. <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Computes p-value of two-sided unweighted test for continuous data 
data1 &lt;- rexp(750, 1)
data2 &lt;- rexp(800, 1)
KS2sample(data1, data2)
##Computes the complementary p-value
KS2sample(data1, data2, tail = FALSE)
##Computes p-value of one-sided test with Anderson-Darling weight function
KS2sample(data1, data2, alternative = "greater", weight = 0.5)

##Computes p-values of two-sided test with Buning's weight function for discrete data
data3 &lt;- rnbinom(100, size = 3, prob = 0.6)
data4 &lt;- rpois(120, lambda = 2)
f &lt;- function(t) 1 / sqrt( t * (2 - t) ) 
KS2sample(data3, data4, weight = f)
</code></pre>

<hr>
<h2 id='KS2sample_c_Rcpp'>
R function calling the C++ routines that compute the complementary p-value for a (weighted) two-sample Kolmogorov-Smirnov (KS) test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)
</h2><span id='topic+KS2sample_c_Rcpp'></span>

<h3>Description</h3>

<p>Function calling directly the C++ routines that compute the exact complementary p-value <code class="reqn">P(D_{m,n} &lt; q)</code> for the (weighed) two-sample one- or two-sided Kolmogorov-Smirnov statistic, at a fixed <code class="reqn">q</code>, <code class="reqn">q\in [0,1]</code>, given the sample sizes <code>m</code> and <code>n</code>, the vector of weights <code>w_vec</code> and the vector <code>M</code> containing the number of times each distinct observation is repeated in the pooled sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KS2sample_c_Rcpp(m, n, kind, M, q, w_vec, tol)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KS2sample_c_Rcpp_+3A_m">m</code></td>
<td>

<p>the sample size of first tested sample.
</p>
</td></tr>
<tr><td><code id="KS2sample_c_Rcpp_+3A_n">n</code></td>
<td>

<p>the sample size of second tested sample.
</p>
</td></tr>
<tr><td><code id="KS2sample_c_Rcpp_+3A_kind">kind</code></td>
<td>

<p>an integer value (= 1,2 or 3) which specified the alternative hypothesis. When = 1, the test is two-sided. When = 2 or 3, the test is one-sided. See &lsquo;Details&rsquo; for the meaning of the possible values. Other value is invalid.
</p>
</td></tr>
<tr><td><code id="KS2sample_c_Rcpp_+3A_m">M</code></td>
<td>

<p>an integer-valued vector with <code class="reqn">k</code> cells, where <code class="reqn">k</code> denotes the number of distinct values in the ordered pooled sample of tested pair of samples(i.e. <code class="reqn">a_1&lt;a_2&lt;\ldots&lt;a_k</code>). <code>M[i]</code> is the number of times that <code class="reqn">a_i</code> is repeated in the pooled sample. A valid <code>M</code> must have strictly positive integer values and have the sum of all cells equals to <code>m+n</code>.
</p>
</td></tr>
<tr><td><code id="KS2sample_c_Rcpp_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 1, at which the p-value <code class="reqn">P(D_{m,n}&lt; q)</code> is computed.
</p>
</td></tr>
<tr><td><code id="KS2sample_c_Rcpp_+3A_w_vec">w_vec</code></td>
<td>
<p>a vector with <code>m+n-1</code> cells, giving weights to each observation in the pooled sample. Valid <code>w_vec</code> must have <code>m+n-1</code> cells and strictly positive value. See &lsquo;Details&rsquo; for the meaning of values in each cell.
</p>
</td></tr>
<tr><td><code id="KS2sample_c_Rcpp_+3A_tol">tol</code></td>
<td>
<p>the value of <code class="reqn">\epsilon</code> for computing <code class="reqn">P(D_{m,n} \leq{}q- \epsilon)</code>, which is equivalent to <code class="reqn">P(D_{m,n} &lt; q)</code>. Non-positive input (<code>tol</code> <code class="reqn">\leq 0</code>) or large input (<code>tol</code> <code class="reqn">&gt;</code><code>1e-6</code>) are replaced by <code>tol=1e-6</code>. In cases when <code>m</code> and <code>n</code> have large least common multiple, a smaller value is highly recommended.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a pair of random samples <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code> of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>,  either against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>, which corresponds to the two-sided test, or against <code class="reqn">H_1: F(x)&gt; G(x)</code>  and <code class="reqn">H_1: F(x)&lt; G(x)</code>   for at least one <code class="reqn">x</code>, which corresponds to the two one-sided tests. The (weighted) two-sample Kolmogorov-Smirnov goodness-of-fit statistics that are used to test these hypotheses are generally defined as:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n} = \sup |F_{m}(t) - G_n(t)|W(E_{m+n}(t), \textnormal{ to test against the alternative } H_1: F(x)\neq G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{+} = \sup [F_{m}(t) - G_n(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&gt; G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{-} = \sup [G_n(t) - F_{m}(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&lt; G(x), </code>
</p>

<p>where <code class="reqn">E_{m+n}(t)</code> is the empirical cdf of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, <code class="reqn">W( )</code> is a strictly positive weight function defined on <code class="reqn">[0,1]</code>. 
</p>
<p><code>w_vec[i]</code> (0<code class="reqn">&lt;</code><code>i</code><code class="reqn">&lt;</code><code class="reqn">m+n</code>) is then equal to <code class="reqn">W(Z_i)=W(\frac{i}{m+n})</code>(<code class="reqn">Z_i</code> is the i-th smallest observation in the pooled sample <code class="reqn">\bm{Z}_{m,n}</code>). 
Different value of <code>w_vec</code> specifies the weighted Kolmogorov-Smirnov test differently. For example, when <code>w_vec=rep(1,m+n-1)</code>, <code><a href="#topic+KS2sample_Rcpp">KS2sample_Rcpp</a></code> calculates the p-value of the unweighted two-sample Kolmogorov-Smirnov test, when <code>w_vec</code> = <code>((1:(m+n-1))*((m+n-1):1))^(-1/2)</code>, it calculates the p-value for the weighted two-sample Kolmogorov-Smirnov test with Anderson-Darling weight <code class="reqn">W(t) = 1/[t(1-t)]^{1/2}</code>.
</p>
<p>Possible values of <code>kind</code> are 1,2 and 3, which specify the alternative hypothesis, i.e. specify the test statistic to be either <code class="reqn">\Delta_{m,n}</code>,  <code class="reqn">\Delta_{m,n}^{+}</code> or <code class="reqn">\Delta_{m,n}^{-}</code> respectively.
</p>
<p>The numeric array <code>M</code> specifies the number of <em>repeated observations</em> in the pooled sample. For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code>=<code>M[i]</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The calculated complementary p-value is the conditional probability:
</p>
<p style="text-align: center;"><code class="reqn">P(D_{m,n}&lt; q)</code>
</p>

<p>where <code class="reqn">D_{m,n}</code> is the two-sample Kolmogorov-Smirnov test statistic defined according to the value of <code>weight</code> and <code>alternative</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em>, i.e. <code class="reqn">D_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> (see further details in <code><a href="#topic+KS2sample">KS2sample</a></code>), and <code class="reqn">q</code> is the observed value of <code class="reqn">\Delta_{m,n}</code> defined according to the value of <code>weight</code> and <code>alternative</code> with respect to the two observed samples <code class="reqn">\bm{X}_m</code> and <code class="reqn">\bm{Y}_n</code>.
</p>
<p><code><a href="#topic+KS2sample_c_Rcpp">KS2sample_c_Rcpp</a></code> implements an exact algorithm, extending the Fortran 77 subroutine due to Nikiforov (1994), an extended functionality by allowing more flexible choice of weight, as well as for <em>large sample sizes</em>. This leads to faster computation time, as well as, relatively high accuracy for very large <code>m</code> and <code>n</code> (less accurate than <code><a href="#topic+KS2sample_Rcpp">KS2sample_Rcpp</a></code>). Compared with other known algorithms, it allows data samples come from <em>continuous, discrete or mixed distribution</em>(i.e. ties may appear), and it is more efficient and more generally applicable for <em>large sample sizes</em>. This algorithm ensures a total worst-case run-time of order <code class="reqn">O(nm)</code>.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{m,n}&lt; q)</code>, given sample sizes <code>m</code>, <code>n</code>, <code>M</code> and <code>w_vec</code>. If the value of <code>m</code>, <code>n</code> are non-positive, or if the length of <code>w_vec</code> is not equal to <code>m+n-1</code>, then the function returns <code>-1</code>, the non-permitted value of <code>M</code> or non-permitted value inside <code>w_vec</code> returns <code>-2</code>, numerically unstable calculation returns <code>-3</code>.
</p>


<h3>Source</h3>

<p>Based on the Fortran subroutine by Nikiforov (1994). See also Dimitrova, Jia, Kaishev (2024).
</p>


<h3>References</h3>

<p>Paul L. Canner (1975). &quot;A Simulation Study of One- and Two-Sample Kolmogorov-Smirnov Statistics with a Particular Weight Function&quot;. Journal of the American Statistical Association, <b>70</b>(349), 209-211.
</p>
<p>Nikiforov, A. M. (1994). &quot;Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions.&quot; Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265–270.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;.  <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Computing the unweighted two-sample Kolmogorov-Smirnov test
## Example see in Nikiforov (1994)

m &lt;- 120
n &lt;- 150
kind &lt;- 1
q &lt;- 0.1
M &lt;- c(80,70,40,80)
w_vec &lt;- rep(1,m+n-1)
tol &lt;- 1e-6
KS2sample_c_Rcpp(m, n, kind, M, q, w_vec, tol)

kind &lt;- 2
KS2sample_c_Rcpp(m, n, kind, M, q, w_vec, tol)

## Computing the weighted two-sample Kolmogorov-Smirnov test
## with Anderson-Darling weight
kind &lt;- 3
w_vec &lt;- ((1:(m+n-1))*((m+n-1):1))^(-1/2)
KS2sample_c_Rcpp(m, n, kind, M, q, w_vec, tol)
</code></pre>

<hr>
<h2 id='KS2sample_Rcpp'>
R function calling the C++ routines that compute the p-value for a (weighted) two-sample Kolmogorov-Smirnov (KS) test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)
</h2><span id='topic+KS2sample_Rcpp'></span>

<h3>Description</h3>

<p>Function calling directly the C++ routines that compute the exact p-value <code class="reqn">P(D_{m,n} \ge q)</code> for the (weighed) two-sample one- or two-sided Kolmogorov-Smirnov statistic, at a fixed <code class="reqn">q</code>, <code class="reqn">q\in [0,1]</code>, given the sample sizes <code>m</code> and <code>n</code>, the vector of weights <code>w_vec</code> and the vector <code>M</code> containing the number of times each distinct observation is repeated in the pooled sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KS2sample_Rcpp(m, n, kind, M, q, w_vec, tol)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KS2sample_Rcpp_+3A_m">m</code></td>
<td>

<p>the sample size of first tested sample.
</p>
</td></tr>
<tr><td><code id="KS2sample_Rcpp_+3A_n">n</code></td>
<td>

<p>the sample size of second tested sample.
</p>
</td></tr>
<tr><td><code id="KS2sample_Rcpp_+3A_kind">kind</code></td>
<td>

<p>an integer value (= 1,2 or 3) which specified the alternative hypothesis. When = 1, the test is two-sided. When = 2 or 3, the test is one-sided. See &lsquo;Details&rsquo; for the meaning of the possible values. Other value is invalid.
</p>
</td></tr>
<tr><td><code id="KS2sample_Rcpp_+3A_m">M</code></td>
<td>

<p>an integer-valued vector with <code class="reqn">k</code> cells, where <code class="reqn">k</code> denotes the number of distinct values in the ordered pooled sample of tested pair of samples(i.e. <code class="reqn">a_1&lt;a_2&lt;\ldots&lt;a_k</code>). <code>M[i]</code> is the number of times that <code class="reqn">a_i</code> is repeated in the pooled sample. A valid <code>M</code> must have strictly positive integer values and have the sum of all cells equals to <code>m+n</code>.
</p>
</td></tr>
<tr><td><code id="KS2sample_Rcpp_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 1, at which the p-value <code class="reqn">P(D_{m,n}\geq q)</code> is computed.
</p>
</td></tr>
<tr><td><code id="KS2sample_Rcpp_+3A_w_vec">w_vec</code></td>
<td>
<p>a vector with <code>m+n-1</code> cells, giving weights to each observation in the pooled sample. Valid <code>w_vec</code> must have <code>m+n-1</code> cells and strictly positive value. See &lsquo;Details&rsquo; for the meaning of values in each cell.
</p>
</td></tr>
<tr><td><code id="KS2sample_Rcpp_+3A_tol">tol</code></td>
<td>
<p>the value of <code class="reqn">\epsilon</code> for computing <code class="reqn">P(D_{m,n} &gt;q- \epsilon)</code>, which is equivalent to <code class="reqn">P(D_{m,n} \geq q)</code>. Non-positive input (<code>tol</code> <code class="reqn">\leq 0</code>) or large input (<code>tol</code> <code class="reqn">&gt;</code><code>1e-6</code>) are replaced by <code>tol = 1e-6</code>. In cases when <code>m</code> and <code>n</code> have large least common multiple, a smaller value is highly recommended.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a pair of random samples <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code> of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>,  either against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>, which corresponds to the two-sided test, or against <code class="reqn">H_1: F(x)&gt; G(x)</code>  and <code class="reqn">H_1: F(x)&lt; G(x)</code>   for at least one <code class="reqn">x</code>, which corresponds to the two one-sided tests. The (weighted) two-sample Kolmogorov-Smirnov goodness-of-fit statistics that are used to test these hypotheses are generally defined as:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n} = \sup |F_{m}(t) - G_n(t)|W(E_{m+n}(t), \textnormal{ to test against the alternative } H_1: F(x)\neq G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{+} = \sup [F_{m}(t) - G_n(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&gt; G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{-} = \sup [G_n(t) - F_{m}(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&lt; G(x), </code>
</p>

<p>where <code class="reqn">E_{m+n}(t)</code> is the empirical cdf of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, <code class="reqn">W( )</code> is a strictly positive weight function defined on <code class="reqn">[0,1]</code>. 
</p>
<p><code>w_vec[i]</code> (0<code class="reqn">&lt;</code><code>i</code><code class="reqn">&lt;</code><code class="reqn">m+n</code>) is then equal to <code class="reqn">W(Z_i)=W(\frac{i}{m+n})</code>(<code class="reqn">Z_i</code> is the i-th smallest observation in the pooled sample <code class="reqn">\bm{Z}_{m,n}</code>). 
Different value of <code>w_vec</code> specifies the weighted Kolmogorov-Smirnov test differently. For example, when <code>w_vec=rep(1,m+n-1)</code>, <code><a href="#topic+KS2sample_Rcpp">KS2sample_Rcpp</a></code> calculates the p-value of the unweighted two-sample Kolmogorov-Smirnov test, when <code>w_vec</code> = <code>((1:(m+n-1))*((m+n-1):1))^(-1/2)</code>, it calculates the p-value for the weighted two-sample Kolmogorov-Smirnov test with Anderson-Darling weight <code class="reqn">W(t) = 1/[t(1-t)]^{1/2}</code>.
</p>
<p>Possible values of <code>kind</code> are 1,2 and 3, which specify the alternative hypothesis, i.e. specify the test statistic to be either <code class="reqn">\Delta_{m,n}</code>,  <code class="reqn">\Delta_{m,n}^{+}</code> or <code class="reqn">\Delta_{m,n}^{-}</code> respectively.
</p>
<p>The numeric array <code>M</code> specifies the number of <em>repeated observations</em> in the pooled sample. For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code>=<code>M[i]</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The p-value is then defined as the probability
</p>
<p style="text-align: center;"><code class="reqn">P\left(D_{m,n}\geq q\right),</code>
</p>

<p>where <code class="reqn">D_{m,n}</code> is the two-sample Kolmogorov-Smirnov test statistic defined according to the value of <code>weight</code> and <code>alternative</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em>, i.e. <code class="reqn">D_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> (see further details in <code><a href="#topic+KS2sample">KS2sample</a></code>), and <code class="reqn">q</code> is the observed value of <code class="reqn">\Delta_{m,n}</code> defined according to the value of <code>weight</code> and <code>alternative</code> with respect to the two observed samples <code class="reqn">\bm{X}_m</code> and <code class="reqn">\bm{Y}_n</code>. 
</p>
<p><code><a href="#topic+KS2sample_Rcpp">KS2sample_Rcpp</a></code> implements an exact algorithm, extending the Fortran 77 subroutine due to Nikiforov (1994), an extended functionality by allowing more flexible choices of weight, as well as for <em>large sample sizes</em>. A version of the Nikiforov's recurrence proposed recently by Viehmann (2021) is further incorporated, which computes directly the p-value, with higher accuracy, giving up to 17 correct digits, but at up to 3 times higher computational cost than <code><a href="#topic+KS2sample_c_Rcpp">KS2sample_c_Rcpp</a></code>. Compared with other known algorithms, it allows data samples to come from <em>continuous, discrete or mixed distribution</em>(i.e. ties may appear), and it is more efficient and more generally applicable for <em>large sample sizes</em>. This algorithm ensures a total worst-case run-time of order <code class="reqn">O(nm)</code>.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{m,n}\geq q)</code>, given sample sizes <code>m</code>, <code>n</code>, <code>M</code> and <code>w_vec</code>. If the value of <code>m</code>, <code>n</code> are non-positive, or if the length of <code>w_vec</code> is not equal to <code>m+n-1</code>, then the function returns <code>-1</code>, the non-permitted value of <code>M</code> or non-permitted value inside <code>w_vec</code> returns <code>-2</code>, numerically unstable calculation returns <code>-3</code>.
</p>


<h3>Source</h3>

<p>Based on the Fortran subroutine by Nikiforov (1994). See also Dimitrova, Jia, Kaishev (2024).
</p>


<h3>References</h3>

<p>Paul L. Canner (1975). &quot;A Simulation Study of One- and Two-Sample Kolmogorov-Smirnov Statistics with a Particular Weight Function&quot;. Journal of the American Statistical Association, <b>70</b>(349), 209-211.
</p>
<p>Nikiforov, A. M. (1994). &quot;Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions.&quot; Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265–270.
</p>
<p>Viehmann, T. (2021). Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test. <em>arXiv preprint</em> arXiv:2102.08037.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;.  <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Computing the unweighted two-sample Kolmogorov-Smirnov test
## Example see in Nikiforov (1994)

m &lt;- 120
n &lt;- 150
kind &lt;- 1
q &lt;- 0.1
M &lt;- c(80,70,40,80)
w_vec &lt;- rep(1,m+n-1)
tol &lt;- 1e-6
KS2sample_Rcpp(m, n, kind, M, q, w_vec, tol)

kind &lt;- 2
KS2sample_Rcpp(m, n, kind, M, q, w_vec, tol)

## Computing the weighted two-sample Kolmogorov-Smirnov test
## with Anderson-Darling weight
kind &lt;- 3
w_vec &lt;- ((1:(m+n-1))*((m+n-1):1))^(-1/2)
KS2sample_Rcpp(m, n, kind, M, q, w_vec, tol)
</code></pre>

<hr>
<h2 id='Kuiper2sample'>
Computes the p-value for a two-sample Kuiper test, given arbitrary data samples on the real line or on the circle with possibly repeated observations (i.e. ties)
</h2><span id='topic+Kuiper2sample'></span>

<h3>Description</h3>

<p>Computes the p-value, <code class="reqn">P(V_{m,n} \geq q)</code>, where <code class="reqn">V_{m,n}</code> is the two-sample Kuiper test statistic, <code class="reqn">q</code> is the observed value of the Kuiper statistic, computed based on two data samples <code class="reqn">\{x_{1},..., x_{m}\}</code> and <code class="reqn">\{y_{1},..., y_{n}\}</code> that may come from continuous, discrete or mixed distribution, i.e. they may have repeated observations (ties).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kuiper2sample(x, y, conservative = F, tail = T)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kuiper2sample_+3A_x">x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{m}\}</code>
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_+3A_y">y</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{y_{1}, ..., y_{n}\}</code>
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_+3A_conservative">conservative</code></td>
<td>

<p>logical variable indicating whether ties should be considered. See &lsquo;Details&rsquo; for the meaning.
</p>
</td></tr>  
<tr><td><code id="Kuiper2sample_+3A_tail">tail</code></td>
<td>

<p>logical variable indicating whether a p-value, <code class="reqn">P(V_{m,n} \ge q)</code> or one minus the p-value, <code class="reqn">P(V_{m,n} &lt; q)</code>, should be computed. By default, the p-value <code class="reqn">P(V_{m,n} \ge q)</code> is computed. See &lsquo;Details&rsquo; for the meaning.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a pair of random samples, either on the real line or the circle, denoted by <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code>, of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>, against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>. The two-sample Kuiper goodness-of-fit statistic that is used to test this hypothesis is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\varsigma_{m,n} = \sup [F_{m}(t) - G_n(t)] - \inf [F_{m}(t) - G_n(t)].</code>
</p>

<p>For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The p-value is then defined as the probability
</p>
<p style="text-align: center;"><code class="reqn">p=P\left(V_{m,n}\geq q\right),</code>
</p>

<p>where <code class="reqn">V_{m,n}</code> is the two-sample Kuiper test statistic defined as <code class="reqn">\varsigma_{m,n}</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em> and <code class="reqn">q</code> is the observed value of the statistic calculated based on the user provided data samples <code>x</code> and <code>y</code>. By default <code>tail = T</code>, the p-value is returned, otherwise <code class="reqn">1-p</code> is returned.
</p>
<p>Note that, <code class="reqn">V_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> of all possible pairs,  <code class="reqn">C = \frac{(m+n)!}{m!n!}</code>  of edfs <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code>, <code class="reqn">\omega \in \Omega</code>, that correspond to the pairs of samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code>, randomly drawn from, <code class="reqn">\bm{Z}_{m+n}</code>, as follows.  First, <code class="reqn">m</code> observations are drawn at random without replacement, forming the first sample <code class="reqn">\bm{X}'_m</code>, with corresponding edf, <code class="reqn">F_m(x,\omega)</code>. The remaining <code class="reqn">n</code> observations are then assigned to the second sample <code class="reqn">\bm{Y}'_n</code>, with corresponding edf <code class="reqn">G_n(x,\omega)</code>. Observations are then replaced back in <code class="reqn">\bm{Z}_{m+n}</code> and re-sampling is continued until the occurrence of all the <code class="reqn">C</code> possible pairs of edfs <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code>,  <code class="reqn">\omega \in \Omega</code>. The pairs of edf's may be coincident if there are ties in the data and each pair, <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code> occurs with probability <code class="reqn">1/C</code>.
</p>
<p><code>conservative</code> is a logical variable whether the test should be conducted conservatively. By default, <code>conservative = F</code>, <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> returns the p-value that is defined through the conditional probability above. However, when the user has a priori knowledge that both samples are from a continuous distribution even if ties are present, for example, repeated observations are caused by rounding errors, the value <code>conservative = T</code> should be assigned, since the conditional probability is no longer relevant. In this case, <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> computes p-values for the Kuiper test assuming no ties are present, and returns a p-value which is an upper bound of the true p-value. Note that, if the null hypothesis is rejected using the calculated upper bound for the p-value, it should also be rejected with the true p-value.
</p>
<p><code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> calculates the exact p-value of the Kuiper test using an algorithm from Dimitrova, Jia, Kaishev (2024), which is based on extending the algorithm provided by Nikiforov (1994) and generalizing the method due to  Maag and Stephens (1968) and Hirakawa (1973). If <code>tail = F</code>, <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> calculates the complementary p-value <code class="reqn">1-p</code>. For the purpose, an exact algorithm which generalizes the method due to Nikiforov (1994) is implemented. Alternatively, if <code>tail = T</code>, a version of the Nikiforov's recurrence proposed recently by Viehmann (2021) is further incorporated, which computes directly the p-value, with up to 4 digits extra accuracy, but at up to 3 times higher computational cost. It is accurate and valid for <em>arbitrary (possibly large) sample sizes</em>. This algorithm ensures a total worst-case run-time of order <code class="reqn">O((mn)^{2})</code>. When  <code>m</code> and <code>n</code> have large greatest common divisor (an extreme case is <code>m</code> = <code>n</code>), it ensures a total worst-case run-time of order <code class="reqn">O((m)^{2}n)</code>. 
</p>
<p><code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> is accurate and fast compared with the function based on the Monte Carlo simulation. Compared to the implementation using asymptotic method, <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code> allows data samples to come from <em>continuous, discrete or mixed distribution</em> (i.e. ties may appear), and is more accurate than asymptotic method when sample sizes are small.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving names of the data.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Maag, U. R., Stephens, M. A. (1968). The <code class="reqn">V_{NM}</code> Two-Sample Test. The Annals of Mathematical Statistics, <b>39</b>(3), 923-935.
</p>
<p>Hirakawa, K. (1973). The two-sample Kuiper test. TRU Mathematics, <b>9</b>, 99-118.
</p>
<p>Nikiforov, A. M. (1994). &quot;Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions.&quot; Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265–270.
</p>
<p>Viehmann, T. (2021). Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test. <em>arXiv preprint</em> arXiv:2102.08037.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;. <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Computes discrete circular data
data1 &lt;- c(rep(pi/2,30),rep(pi,30),rep(3*pi/2,30),rep(2*pi,30))
data2 &lt;- c(rep(pi/2,50),rep(pi,40),rep(3*pi/2,10),rep(2*pi,50))
Kuiper2sample(data1, data2)

##The calculated p-value does not change with the choice of the original point
data3 &lt;- c(rep(pi/2,30),rep(pi,30),rep(3*pi/2,30),rep(2*pi,30))
data4 &lt;- c(rep(pi/2,50),rep(pi,50),rep(3*pi/2,40),rep(2*pi,10))
Kuiper2sample(data3, data4)
</code></pre>

<hr>
<h2 id='Kuiper2sample_c_Rcpp'>
R function calling the C++ routines that compute the complementary p-value for a (unweighted) two-sample Kuiper test, given arbitrary data samples on the real line or on the circle with possibly repeated observations (i.e. ties)
</h2><span id='topic+Kuiper2sample_c_Rcpp'></span>

<h3>Description</h3>

<p>Function calling directly the C++ routines that compute the exact complementary p-value  <code class="reqn">P(V_{m,n} &lt; q)</code> for the two-sample Kuiper test, at a fixed <code class="reqn">q</code>, <code class="reqn">q\in [0,2]</code>, given the sample sizes <code>m</code>, <code>n</code> and the vector <code>M</code> containing the number of times each distinct observation is repeated in the pooled sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kuiper2sample_c_Rcpp(m, n, M, q)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kuiper2sample_c_Rcpp_+3A_m">m</code></td>
<td>

<p>the sample size of first tested sample.
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_c_Rcpp_+3A_n">n</code></td>
<td>

<p>the sample size of second tested sample. 
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_c_Rcpp_+3A_m">M</code></td>
<td>

<p>an integer-valued vector with <code class="reqn">k</code> cells, where <code class="reqn">k</code> denotes the number of distinct values in the ordered pooled sample of tested pair of samples(i.e. <code class="reqn">a_1&lt;a_2&lt;\ldots&lt;a_k</code>). <code>M[i]</code> is the number of times that <code class="reqn">a_i</code> is repeated in the pooled sample. A valid <code>M</code> must have strictly positive integer values and have the sum of all cells equals to <code>m+n</code>.
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_c_Rcpp_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 2, at which the p-value <code class="reqn">P(V_{m,n}&lt; q)</code> is computed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a pair of random samples, either on the real line or the circle, denoted by <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code>, of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>, against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>. The two-sample Kuiper goodness-of-fit statistic that is used to test this hypothesis is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\varsigma_{m,n} = \sup [F_{m}(t) - G_n(t)] - \inf [F_{m}(t) - G_n(t)].</code>
</p>

<p>The numeric array <code>M</code> specifies the number of <em>repeated observations</em> in the pooled sample. For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code> = <code>M[i]</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The calculated complementary p-value is then the conditional probability:
</p>
<p style="text-align: center;"><code class="reqn">P(V_{m,n}&lt; q)</code>
</p>

<p>where <code class="reqn">V_{m,n}</code> is the two-sample Kuiper test statistic defined as <code class="reqn">\varsigma_{m,n}</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em>, i.e. <code class="reqn">V_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> (see further details in <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code>), and <code class="reqn">q</code> is the observed value of <code class="reqn">\varsigma_{m,n}</code> with respect to the two observed samples <code class="reqn">\bm{X}_m</code> and <code class="reqn">\bm{Y}_n</code>.
</p>
<p><code><a href="#topic+Kuiper2sample_c_Rcpp">Kuiper2sample_c_Rcpp</a></code> implements an algorithm from Dimitrova, Jia, Kaishev (2024),  that is based on extending the algorithm provided by Nikiforov (1994) and generalizing the method due to  Maag and Stephens (1968) and Hirakawa (1973). It is relatively accurate (less accurate than <code><a href="#topic+Kuiper2sample_Rcpp">Kuiper2sample_Rcpp</a></code>) and valid for <em>arbitrary (possibly large) sample sizes</em>. This algorithm ensures a total worst-case run-time of order <code class="reqn">O((mn)^{2})</code>. When  <code>m</code> and <code>n</code> have large greatest common divisor (an extreme case is <code>m</code> = <code>n</code>), it ensures a total worst-case run-time of order <code class="reqn">O((m)^{2}n)</code>. 
</p>
<p>Other known implementations for the two-sample Kuiper test mainly use the approximation method or Monte Carlo simulation (See also <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code>). The former method is invalid for data with ties and often gives p-values with large errors when sample sizes are small, the latter method is usually slow and inaccurate. Compared with other known algorithms, <code><a href="#topic+Kuiper2sample_c_Rcpp">Kuiper2sample_c_Rcpp</a></code>  allows data samples to come from <em>continuous, discrete or mixed distribution</em> (i.e. ties may appear), and is more accurate and generally applicable for <em>large sample sizes</em>.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(V_{m,n}&lt; q)</code>, given sample sizes <code>m</code>, <code>n</code> and <code>M</code>. If the value of <code>m</code>, <code>n</code> are non-positive, or their least common multiple exceeds the limit 2147483647, then the function returns <code>-1</code>, the non-permitted value of <code>M</code> returns <code>-2</code>, numerically unstable calculation returns <code>-3</code>.
</p>


<h3>References</h3>

<p>Maag, U. R., Stephens, M. A. (1968). The <code class="reqn">V_{NM}</code> Two-Sample Test. The Annals of Mathematical Statistics, <b>39</b>(3), 923-935.
</p>
<p>Hirakawa, K. (1973). The two-sample Kuiper test. TRU Mathematics, <b>9</b>, 99-118.
</p>
<p>Nikiforov, A. M. (1994). &quot;Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions.&quot; Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265–270.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;. <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Computing the unweighted two-sample Kolmogorov-Smirnov test
## Example see in Nikiforov (1994)

m &lt;- 120
n &lt;- 150
q &lt;- 0.183333333
M &lt;- c(80,70,40,80)
Kuiper2sample_c_Rcpp(m, n, M, q)
</code></pre>

<hr>
<h2 id='Kuiper2sample_Rcpp'>
R function calling the C++ routines that compute the p-value for a (unweighted) two-sample Kuiper test, given arbitrary data samples on the real line or on the circle with possibly repeated observations (i.e. ties)
</h2><span id='topic+Kuiper2sample_Rcpp'></span>

<h3>Description</h3>

<p>Function calling directly the C++ routines that compute the exact p-value  <code class="reqn">P(V_{m,n} \ge q)</code> for the two-sample Kuiper test, at a fixed <code class="reqn">q</code>, <code class="reqn">q\in [0,2]</code>, given the sample sizes <code>m</code>, <code>n</code> and the vector <code>M</code> containing the number of times each distinct observation is repeated in the pooled sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kuiper2sample_Rcpp(m, n, M, q)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kuiper2sample_Rcpp_+3A_m">m</code></td>
<td>

<p>the sample size of first tested sample.
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_Rcpp_+3A_n">n</code></td>
<td>

<p>the sample size of second tested sample. 
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_Rcpp_+3A_m">M</code></td>
<td>

<p>an integer-valued vector with <code class="reqn">k</code> cells, where <code class="reqn">k</code> denotes the number of distinct values in the ordered pooled sample of tested pair of samples(i.e. <code class="reqn">a_1&lt;a_2&lt;\ldots&lt;a_k</code>). <code>M[i]</code> is the number of times that <code class="reqn">a_i</code> is repeated in the pooled sample. A valid <code>M</code> must have strictly positive integer values and have the sum of all cells equals to <code>m+n</code>.
</p>
</td></tr>
<tr><td><code id="Kuiper2sample_Rcpp_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 2, at which the p-value <code class="reqn">P(V_{m,n}\ge q)</code> is computed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a pair of random samples, either on the real line or the circle, denoted by <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code>, of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>, against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>. The two-sample Kuiper goodness-of-fit statistic that is used to test this hypothesis is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\varsigma_{m,n} = \sup [F_{m}(t) - G_n(t)] - \inf [F_{m}(t) - G_n(t)].</code>
</p>

<p>The numeric array <code>M</code> specifies the number of <em>repeated observations</em> in the pooled sample. For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code> = <code>M[i]</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The p-value is then defined as the probability
</p>
<p style="text-align: center;"><code class="reqn">P\left(V_{m,n}\geq q\right),</code>
</p>

<p>where <code class="reqn">V_{m,n}</code> is the two-sample Kuiper test statistic defined as <code class="reqn">\varsigma_{m,n}</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em>, i.e. <code class="reqn">V_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> (see further details in <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code>), and <code class="reqn">q</code> is the observed value of <code class="reqn">\varsigma_{m,n}</code> with respect to the two observed samples <code class="reqn">\bm{X}_m</code> and <code class="reqn">\bm{Y}_n</code>.
</p>
<p><code><a href="#topic+Kuiper2sample_Rcpp">Kuiper2sample_Rcpp</a></code> implements an algorithm from Dimitrova, Jia, Kaishev (2024),  that is based on extending the algorithm provided by Nikiforov (1994) and generalizing the method due to  Maag and Stephens (1968) and Hirakawa (1973). A version of the Nikiforov's recurrence proposed recently by Viehmann (2021) is further incorporated, which computes directly the p-value, with up to 4 digits extra accuracy, but at up to 3 times higher computational cost than <code><a href="#topic+Kuiper2sample_c_Rcpp">Kuiper2sample_c_Rcpp</a></code>. It is accurate and valid for <em>arbitrary (possibly large) sample sizes</em>. This algorithm ensures a total worst-case run-time of order <code class="reqn">O((mn)^{2})</code>. When  <code>m</code> and <code>n</code> have large greatest common divisor (an extreme case is <code>m</code> = <code>n</code>), it ensures a total worst-case run-time of order <code class="reqn">O((m)^{2}n)</code>. 
</p>
<p>Other known implementations for the two-sample Kuiper test mainly use the approximation method or Monte Carlo simulation (See also <code><a href="#topic+Kuiper2sample">Kuiper2sample</a></code>). The former method is invalid for data with ties and often gives p-values with large errors when sample sizes are small, the latter method is usually slow and inaccurate. Compared with other known algorithms, <code><a href="#topic+Kuiper2sample_Rcpp">Kuiper2sample_Rcpp</a></code>  allows data samples to come from <em>continuous, discrete or mixed distribution</em> (i.e. ties may appear), and is more accurate and generally applicable for <em>large sample sizes</em>.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(V_{m,n}\geq q)</code>, given sample sizes <code>m</code>, <code>n</code> and <code>M</code>. If the value of <code>m</code>, <code>n</code> are non-positive, or their least common multiple exceeds the limit 2147483647, then the function returns <code>-1</code>, the non-permitted value of <code>M</code> returns <code>-2</code>, numerically unstable calculation returns <code>-3</code>.
</p>


<h3>References</h3>

<p>Maag, U. R., Stephens, M. A. (1968). The <code class="reqn">V_{NM}</code> Two-Sample Test. The Annals of Mathematical Statistics, <b>39</b>(3), 923-935.
</p>
<p>Hirakawa, K. (1973). The two-sample Kuiper test. TRU Mathematics, <b>9</b>, 99-118.
</p>
<p>Nikiforov, A. M. (1994). &quot;Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions.&quot; Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265–270.
</p>
<p>Viehmann, T. (2021). Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test. <em>arXiv preprint</em> arXiv:2102.08037.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). &quot;The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests&quot;. <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Computing the unweighted two-sample Kolmogorov-Smirnov test
## Example see in Nikiforov (1994)

m &lt;- 120
n &lt;- 150
q &lt;- 0.183333333
M &lt;- c(80,70,40,80)
Kuiper2sample_Rcpp(m, n, M, q)
</code></pre>

<hr>
<h2 id='mixed_ks_c_cdf'>
Computes the complementary cumulative distribution function of the two-sided Kolmogorov-Smirnov statistic when the cdf under the null hypothesis is mixed
</h2><span id='topic+mixed_ks_c_cdf'></span>

<h3>Description</h3>

<p>Computes the complementary cdf, <code class="reqn">P(D_{n} \ge q)</code> at a fixed <code class="reqn">q</code>, <code class="reqn">q\in[0, 1]</code>, of the one-sample two-sided Kolmogorov-Smirnov statistic,  when the cdf <code class="reqn">F(x)</code> under the null hypothesis is mixed, using the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixed_ks_c_cdf(q, n, jump_points, Mixed_dist, ..., tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixed_ks_c_cdf_+3A_q">q</code></td>
<td>

<p>numeric value between 0 and 1, at which the complementary cdf <code class="reqn">P(D_{n} \ge q)</code> is computed
</p>
</td></tr>
<tr><td><code id="mixed_ks_c_cdf_+3A_n">n</code></td>
<td>

<p>the sample size
</p>
</td></tr>
<tr><td><code id="mixed_ks_c_cdf_+3A_jump_points">jump_points</code></td>
<td>

<p>a numeric vector containing the points of (jump) discontinuity, i.e. where the underlying cdf <code class="reqn">F(x)</code> has jump(s)
</p>
</td></tr>
<tr><td><code id="mixed_ks_c_cdf_+3A_mixed_dist">Mixed_dist</code></td>
<td>

<p>a pre-specified (user-defined) mixed cdf, <code class="reqn">F(x)</code>, under the null hypothesis.
</p>
</td></tr>
<tr><td><code id="mixed_ks_c_cdf_+3A_...">...</code></td>
<td>

<p>values of the parameters of the cdf, <code class="reqn">F(x)</code> specified (as a character string) by <code>Mixed_dist</code>.
</p>
</td></tr>
<tr><td><code id="mixed_ks_c_cdf_+3A_tol">tol</code></td>
<td>

<p>the value of <code class="reqn">\epsilon</code> that is used to compute the values of <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, as detailed in Step 1 of Section 2.1 in Dimitrova, Kaishev and Tan (2020) (see also (ii) in the Procedure Exact-KS-FFT therein). By default, <code>tol = 1e-10</code>. Note that a value of <code>NA</code> or <code>0</code> will lead to an error!
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+mixed_ks_c_cdf">mixed_ks_c_cdf</a></code> implements the Exact-KS-FFT method, proposed by Dimitrova, Kaishev, Tan (2020) to compute the complementary cdf <code class="reqn">P(D_{n} \ge q)</code> at a value <code class="reqn">q</code>, when <code class="reqn">F(x)</code> is mixed.
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code>.
</p>
<p>We have not been able to identify alternative, fast and accurate, method (software) that has been developed/implemented when the hypothesized <code class="reqn">F(x)</code> is mixed.
</p>


<h3>Value</h3>

<p>Numeric value corresponding to <code class="reqn">P(D_{n} \ge q)</code>.
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the complementary cdf of D_{n}
# when the underlying distribution is a mixed distribution
# with two jumps at 0 and log(2.5),
# as in Example 3.1 of Dimitrova, Kaishev, Tan (2020)

## Defining the mixed distribution

Mixed_cdf_example &lt;- function(x)
{
     result &lt;- 0
     if (x &lt; 0){
         result &lt;- 0
     }
     else if (x == 0){
         result &lt;- 0.5
     }
     else if (x &lt; log(2.5)){
         result &lt;- 1 - 0.5 * exp(-x)
     }
     else{
         result &lt;- 1
     }

     return (result)
 }

KSgeneral::mixed_ks_c_cdf(0.1, 25, c(0, log(2.5)), Mixed_cdf_example)


## Not run: 
## Compute P(D_{n} &gt;= q) for n = 5,
## q = 1/5000, 2/5000, ..., 5000/5000
## when the underlying distribution is a mixed distribution
## with four jumps at 0, 0.2, 0.8, 1.0,
## as in Example 2.8 of Dimitrova, Kaishev, Tan (2020)

n &lt;- 5
q &lt;- 1:5000/5000

Mixed_cdf_example &lt;- function(x)
{
  result &lt;- 0
  if (x &lt; 0){
    result &lt;- 0
  }
  else if (x == 0){
    result &lt;- 0.2
  }
  else if (x &lt; 0.2){
    result &lt;- 0.2 + x
  }
  else if (x &lt; 0.8){
    result &lt;- 0.5
  }
  else if (x &lt; 1){
    result &lt;- x - 0.1
  }
  else{
    result &lt;- 1
  }

  return (result)
}

plot(q, sapply(q, function(x) KSgeneral::mixed_ks_c_cdf(x, n,
     c(0, 0.2, 0.8, 1.0), Mixed_cdf_example)), type='l')


## End(Not run)

</code></pre>

<hr>
<h2 id='mixed_ks_test'>
Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is mixed
</h2><span id='topic+mixed_ks_test'></span>

<h3>Description</h3>

<p>Computes the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, when <code class="reqn">F(x)</code> is mixed, using the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixed_ks_test(x, jump_points, Mixed_dist, ..., tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixed_ks_test_+3A_x">x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{n}\}</code>.
</p>
</td></tr>
<tr><td><code id="mixed_ks_test_+3A_jump_points">jump_points</code></td>
<td>

<p>a numeric vector containing the points of (jump) discontinuity, i.e. where the underlying cdf <code class="reqn">F(x)</code> has jump(s)
</p>
</td></tr>
<tr><td><code id="mixed_ks_test_+3A_mixed_dist">Mixed_dist</code></td>
<td>

<p>a pre-specified (user-defined) mixed cdf, <code class="reqn">F(x)</code>, under the null hypothesis.
</p>
</td></tr>
<tr><td><code id="mixed_ks_test_+3A_...">...</code></td>
<td>

<p>values of the parameters of the cdf, <code class="reqn">F(x)</code> specified (as a character string) by <code>Mixed_dist</code>.
</p>
</td></tr>
<tr><td><code id="mixed_ks_test_+3A_tol">tol</code></td>
<td>

<p>the value of <code class="reqn">\epsilon</code> that is used to compute the values of <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, as detailed in Step 1 of Section 2.1 in Dimitrova, Kaishev and Tan (2020) (see also (ii) in the Procedure Exact-KS-FFT therein). By default, <code>tol = 1e-10</code>. Note that a value of <code>NA</code> or <code>0</code> will lead to an error!
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code><a href="#topic+mixed_ks_test">mixed_ks_test</a></code> implements the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
This algorithm ensures a total worst-case run-time of order <code class="reqn">O(n^{2}log(n))</code>.
</p>
<p>The function <code><a href="#topic+mixed_ks_test">mixed_ks_test</a></code> computes the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a user-provided data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, when <code class="reqn">F(x)</code> is mixed,
</p>
<p>We have not been able to identify alternative, fast and accurate, method (software) that has been developed/implemented when the hypothesized <code class="reqn">F(x)</code> is mixed.
</p>


<h3>Value</h3>

<p>A list with class &quot;htest&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>&quot;two-sided&quot;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example to compute the p-value of the one-sample two-sided KS test,
# when the underlying distribution is a mixed distribution
# with two jumps at 0 and log(2.5),
# as in Example 3.1 of Dimitrova, Kaishev, Tan (2020)

# Defining the mixed distribution

Mixed_cdf_example &lt;- function(x)
{
     result &lt;- 0
     if (x &lt; 0){
         result &lt;- 0
     }
     else if (x == 0){
         result &lt;- 0.5
     }
     else if (x &lt; log(2.5)){
         result &lt;- 1 - 0.5 * exp(-x)
     }
     else{
         result &lt;- 1
     }

     return (result)
}
test_data &lt;- c(0,0,0,0,0,0,0.1,0.2,0.3,0.4,
            0.5,0.6,0.7,0.8,log(2.5),log(2.5),
            log(2.5),log(2.5),log(2.5),log(2.5))
KSgeneral::mixed_ks_test(test_data, c(0, log(2.5)),
                         Mixed_cdf_example)


## Compute the p-value of a two-sided K-S test
## when F(x) follows a zero-and-one-inflated
## beta distribution, as in Example 3.3
## of Dimitrova, Kaishev, Tan (2020)

## The data set is the proportion of inhabitants
## living within a 200 kilometer wide costal strip
## in 232 countries in the year 2010

data("Population_Data")
mu &lt;- 0.6189
phi &lt;- 0.6615
a &lt;- mu * phi
b &lt;- (1 - mu) * phi

Mixed_cdf_example &lt;- function(x)
{
     result &lt;- 0
     if (x &lt; 0){
         result &lt;- 0
     }
     else if (x == 0){
         result &lt;- 0.1141
     }
     else if (x &lt; 1){
         result &lt;- 0.1141 + 0.4795 * pbeta(x, a, b)
     }
     else{
         result &lt;- 1
     }

     return (result)
}
KSgeneral::mixed_ks_test(Population_Data, c(0, 1), Mixed_cdf_example)


</code></pre>

<hr>
<h2 id='Population_Data'>
The proportion of inhabitants living within a 200 kilometer wide costal strip in 232 countries in the year 2010
</h2><span id='topic+Population_Data'></span>

<h3>Description</h3>

<p>This data set contains the proportion of inhabitants living within a 200 kilometer wide costal strip in 232 countries in the year 2010.
In Example 3.3 of Dimitrova, Kaishev, Tan (2020), the data set is modelled using a zero-and-one-inflated beta distribution in the null hypothesis and a one-sample two-sided Kolmogorov-Smirnov test is performed to test whether the proposed distribution fits the data well enough.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Population_Data")</code></pre>


<h3>Format</h3>

<p>A data frame with 232 observations on the proportion of inhabitants living within a 200 kilometer wide costal strip in 2010.
</p>


<h3>Source</h3>

<p><a href="https://sedac.ciesin.columbia.edu/data/set/nagdc-population-landscape-climate-estimates-v3">https://sedac.ciesin.columbia.edu/data/set/nagdc-population-landscape-climate-estimates-v3</a>
</p>


<h3>References</h3>

<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) &quot;Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous&quot;. Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
