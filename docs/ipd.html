<!DOCTYPE html><html lang="en-US"><head><title>Help for package ipd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ipd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ipd-package'><p>ipd: Inference on Predicted Data</p></a></li>
<li><a href='#A'><p>Calculation of the matrix A based on single dataset</p></a></li>
<li><a href='#augment.ipd'><p>Augment Data from an IPD Fit</p></a></li>
<li><a href='#calc_lhat_glm'><p>Estimate PPI++ Power Tuning Parameter</p></a></li>
<li><a href='#compute_cdf'><p>Empirical CDF of the Data</p></a></li>
<li><a href='#compute_cdf_diff'><p>Empirical CDF Difference</p></a></li>
<li><a href='#est_ini'><p>Initial estimation</p></a></li>
<li><a href='#glance.ipd'><p>Glance at an IPD Fit</p></a></li>
<li><a href='#ipd'><p>Inference on Predicted Data (ipd)</p></a></li>
<li><a href='#link_grad'><p>Gradient of the link function</p></a></li>
<li><a href='#link_Hessian'><p>Hessians of the link function</p></a></li>
<li><a href='#log1pexp'><p>Log1p Exponential</p></a></li>
<li><a href='#logistic_get_stats'><p>Logistic Regression Gradient and Hessian</p></a></li>
<li><a href='#mean_psi'><p>Sample expectation of psi</p></a></li>
<li><a href='#mean_psi_pop'><p>Sample expectation of PSPA psi</p></a></li>
<li><a href='#ols'><p>Ordinary Least Squares</p></a></li>
<li><a href='#ols_get_stats'><p>OLS Gradient and Hessian</p></a></li>
<li><a href='#optim_est'><p>One-step update for obtaining estimator</p></a></li>
<li><a href='#optim_weights'><p>One-step update for obtaining the weight vector</p></a></li>
<li><a href='#postpi_analytic_ols'><p>PostPI OLS (Analytic Correction)</p></a></li>
<li><a href='#postpi_boot_logistic'><p>PostPI Logistic Regression (Bootstrap Correction)</p></a></li>
<li><a href='#postpi_boot_ols'><p>PostPI OLS (Bootstrap Correction)</p></a></li>
<li><a href='#ppi_logistic'><p>PPI Logistic Regression</p></a></li>
<li><a href='#ppi_mean'><p>PPI Mean Estimation</p></a></li>
<li><a href='#ppi_ols'><p>PPI OLS</p></a></li>
<li><a href='#ppi_plusplus_logistic'><p>PPI++ Logistic Regression</p></a></li>
<li><a href='#ppi_plusplus_logistic_est'><p>PPI++ Logistic Regression (Point Estimate)</p></a></li>
<li><a href='#ppi_plusplus_mean'><p>PPI++ Mean Estimation</p></a></li>
<li><a href='#ppi_plusplus_mean_est'><p>PPI++ Mean Estimation (Point Estimate)</p></a></li>
<li><a href='#ppi_plusplus_ols'><p>PPI++ OLS</p></a></li>
<li><a href='#ppi_plusplus_ols_est'><p>PPI++ OLS (Point Estimate)</p></a></li>
<li><a href='#ppi_plusplus_quantile'><p>PPI++ Quantile Estimation</p></a></li>
<li><a href='#ppi_plusplus_quantile_est'><p>PPI++ Quantile Estimation (Point Estimate)</p></a></li>
<li><a href='#ppi_quantile'><p>PPI Quantile Estimation</p></a></li>
<li><a href='#print.ipd'><p>Print IPD Fit</p></a></li>
<li><a href='#print.summary.ipd'><p>Print Summary of IPD Fit</p></a></li>
<li><a href='#psi'><p>Estimating equation</p></a></li>
<li><a href='#pspa_logistic'><p>PSPA Logistic Regression</p></a></li>
<li><a href='#pspa_mean'><p>PSPA Mean Estimation</p></a></li>
<li><a href='#pspa_ols'><p>PSPA OLS Estimation</p></a></li>
<li><a href='#pspa_poisson'><p>PSPA Poisson Regression</p></a></li>
<li><a href='#pspa_quantile'><p>PSPA Quantile Estimation</p></a></li>
<li><a href='#pspa_y'><p>PSPA M-Estimation for ML-predicted labels</p></a></li>
<li><a href='#rectified_cdf'><p>Rectified CDF</p></a></li>
<li><a href='#rectified_p_value'><p>Rectified P-Value</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#Sigma_cal'><p>Variance-covariance matrix of the estimation equation</p></a></li>
<li><a href='#sim_data_y'><p>Simulate the data for testing the functions</p></a></li>
<li><a href='#simdat'><p>Data generation function for various underlying models</p></a></li>
<li><a href='#summary.ipd'><p>Summarize IPD Fit</p></a></li>
<li><a href='#tidy.ipd'><p>Tidy an IPD Fit</p></a></li>
<li><a href='#wls'><p>Weighted Least Squares</p></a></li>
<li><a href='#zconfint_generic'><p>Normal Confidence Intervals</p></a></li>
<li><a href='#zstat_generic'><p>Compute Z-Statistic and P-Value</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Inference on Predicted Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Stephen Salerno &lt;ssalerno@fredhutch.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs valid statistical inference on predicted data (IPD) using recent methods, where for a subset of the data, the outcomes have been predicted by an algorithm. Provides a wrapper function with specified defaults for the type of model and method to be used for estimation and inference. Further provides methods for tidying and summarizing results. Salerno et al., (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2410.09665">doi:10.48550/arXiv.2410.09665</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ipd-tools/ipd">https://github.com/ipd-tools/ipd</a>, <a href="https://ipd-tools.github.io/ipd/">https://ipd-tools.github.io/ipd/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ipd-tools/ipd/issues">https://github.com/ipd-tools/ipd/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, gam, generics, ranger, splines, stats, MASS,
randomForest</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, patchwork, rmarkdown, spelling, testthat (&ge; 3.0.0),
tidyverse</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-06 21:44:59 UTC; saler</td>
</tr>
<tr>
<td>Author:</td>
<td>Stephen Salerno <a href="https://orcid.org/0000-0003-2763-0494"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Jiacheng Miao [aut],
  Awan Afiaz [aut],
  Kentaro Hoffman [aut],
  Anna Neufeld [aut],
  Qiongshi Lu [aut],
  Tyler H McCormick [aut],
  Jeffrey T Leek [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-07 16:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ipd-package'>ipd: Inference on Predicted Data</h2><span id='topic+ipd-package'></span>

<h3>Description</h3>

<p>Performs valid statistical inference on predicted data (IPD) using recent methods, where for a subset of the data, the outcomes have been predicted by an algorithm. Provides a wrapper function with specified defaults for the type of model and method to be used for estimation and inference. Further provides methods for tidying and summarizing results. Salerno et al., (2024) <a href="https://doi.org/10.48550/arXiv.2410.09665">doi:10.48550/arXiv.2410.09665</a>.
</p>
<p>The <code>ipd</code> package provides tools for statistical modeling and inference when
a significant portion of the outcome data is predicted by AI/ML algorithms.
It implements several state-of-the-art methods for inference on predicted
data (IPD), offering a user-friendly interface to facilitate their use in
real-world applications.
</p>


<h3>Details</h3>

<p>This package is particularly useful in scenarios where predicted values
(e.g., from machine learning models) are used as proxies for unobserved
outcomes, which can introduce biases in estimation and inference. The <code>ipd</code>
package integrates methods designed to address these challenges.
</p>


<h3>Features</h3>


<ul>
<li><p> Multiple IPD methods: <code>PostPI</code>, <code>PPI</code>, <code style="white-space: pre;">&#8288;PPI++&#8288;</code>, and <code>PSPA</code> currently.
</p>
</li>
<li><p> Flexible wrapper functions for ease of use.
</p>
</li>
<li><p> Custom methods for model inspection and evaluation.
</p>
</li>
<li><p> Seamless integration with common data structures in R.
</p>
</li>
<li><p> Comprehensive documentation and examples.
</p>
</li></ul>



<h3>Key Functions</h3>


<ul>
<li> <p><code><a href="#topic+ipd">ipd</a></code>: Main wrapper function which implements various methods for inference on predicted data for a specified model/outcome type (e.g., mean estimation, linear regression).
</p>
</li>
<li> <p><code><a href="#topic+simdat">simdat</a></code>: Simulates data for demonstrating the use of the various IPD methods.
</p>
</li>
<li> <p><code><a href="#topic+print.ipd">print.ipd</a></code>: Prints a brief summary of the IPD method/model combination.
</p>
</li>
<li> <p><code><a href="#topic+summary.ipd">summary.ipd</a></code>: Summarizes the results of fitted IPD models.
</p>
</li>
<li> <p><code><a href="#topic+tidy.ipd">tidy.ipd</a></code>: Tidies the IPD method/model fit into a data frame.
</p>
</li>
<li> <p><code><a href="#topic+glance.ipd">glance.ipd</a></code>: Glances at the IPD method/model fit, returning a one-row summary.
</p>
</li>
<li> <p><code><a href="#topic+augment.ipd">augment.ipd</a></code>: Augments the data used for an IPD method/model fit with additional information about each observation.
</p>
</li></ul>



<h3>Documentation</h3>

<p>The package includes detailed documentation for each function, including
usage examples. A vignette is also provided to guide users through common
workflows and applications of the package.
</p>


<h3>References</h3>

<p>For details on the statistical methods implemented in this package, please
refer to the associated manuscripts at the following references:
</p>

<ul>
<li> <p><strong>PostPI</strong>: Wang, S., McCormick, T. H., &amp; Leek, J. T. (2020). Methods for correcting inference based on outcomes predicted by machine learning. Proceedings of the National Academy of Sciences, 117(48), 30266-30275.
</p>
</li>
<li> <p><strong>PPI</strong>: Angelopoulos, A. N., Bates, S., Fannjiang, C., Jordan, M. I., &amp; Zrnic, T. (2023). Prediction-powered inference. Science, 382(6671), 669-674.
</p>
</li>
<li> <p><strong>PPI++</strong>: Angelopoulos, A. N., Duchi, J. C., &amp; Zrnic, T. (2023). PPI++: Efficient prediction-powered inference. arXiv preprint arXiv:2311.01453.
</p>
</li>
<li> <p><strong>PSPA</strong>: Miao, J., Miao, X., Wu, Y., Zhao, J., &amp; Lu, Q. (2023). Assumption-lean and data-adaptive post-prediction inference. arXiv preprint arXiv:2311.14220.
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Stephen Salerno <a href="mailto:ssalerno@fredhutch.org">ssalerno@fredhutch.org</a> (<a href="https://orcid.org/0000-0003-2763-0494">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Jiacheng Miao <a href="mailto:jmiao24@wisc.edu">jmiao24@wisc.edu</a>
</p>
</li>
<li><p> Awan Afiaz <a href="mailto:aafiaz@uw.edu">aafiaz@uw.edu</a>
</p>
</li>
<li><p> Kentaro Hoffman <a href="mailto:khoffm3@uw.edu">khoffm3@uw.edu</a>
</p>
</li>
<li><p> Anna Neufeld <a href="mailto:acn2@williams.edu">acn2@williams.edu</a>
</p>
</li>
<li><p> Qiongshi Lu <a href="mailto:qlu@biostat.wisc.edu">qlu@biostat.wisc.edu</a>
</p>
</li>
<li><p> Tyler H McCormick <a href="mailto:tylermc@uw.edu">tylermc@uw.edu</a>
</p>
</li>
<li><p> Jeffrey T Leek <a href="mailto:jtleek@fredhutch.org">jtleek@fredhutch.org</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/ipd-tools/ipd">https://github.com/ipd-tools/ipd</a>
</p>
</li>
<li> <p><a href="https://ipd-tools.github.io/ipd/">https://ipd-tools.github.io/ipd/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ipd-tools/ipd/issues">https://github.com/ipd-tools/ipd/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#-- Generate Example Data

set.seed(12345)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- PostPI Analytic Correction (Wang et al., 2020)

fit_postpi1 &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

    data = dat, label = "set_label")

#-- PostPI Bootstrap Correction (Wang et al., 2020)

nboot &lt;- 200

fit_postpi2 &lt;- ipd(formula, method = "postpi_boot", model = "ols",

    data = dat, label = "set_label", nboot = nboot)

#-- PPI (Angelopoulos et al., 2023)

fit_ppi &lt;- ipd(formula, method = "ppi", model = "ols",

    data = dat, label = "set_label")

#-- PPI++ (Angelopoulos et al., 2023)

fit_plusplus &lt;- ipd(formula, method = "ppi_plusplus", model = "ols",

    data = dat, label = "set_label")

#-- PSPA (Miao et al., 2023)

fit_pspa &lt;- ipd(formula, method = "pspa", model = "ols",

    data = dat, label = "set_label")

#-- Print the Model

print(fit_postpi1)

#-- Summarize the Model

summ_fit_postpi1 &lt;- summary(fit_postpi1)

#-- Print the Model Summary

print(summ_fit_postpi1)

#-- Tidy the Model Output

tidy(fit_postpi1)

#-- Get a One-Row Summary of the Model

glance(fit_postpi1)

#-- Augment the Original Data with Fitted Values and Residuals

augmented_df &lt;- augment(fit_postpi1)

head(augmented_df)
</code></pre>

<hr>
<h2 id='A'>Calculation of the matrix A based on single dataset</h2><span id='topic+A'></span>

<h3>Description</h3>

<p><code>A</code> function for the calculation of the matrix A based on single dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>A(X, Y, quant = NA, theta, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="A_+3A_x">X</code></td>
<td>
<p>Array or data.frame containing covariates</p>
</td></tr>
<tr><td><code id="A_+3A_y">Y</code></td>
<td>
<p>Array or data.frame of outcomes</p>
</td></tr>
<tr><td><code id="A_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="A_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="A_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix A based on single dataset
</p>

<hr>
<h2 id='augment.ipd'>Augment Data from an IPD Fit</h2><span id='topic+augment.ipd'></span>

<h3>Description</h3>

<p>Augments the data used for an IPD method/model fit with additional
information about each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ipd'
augment(x, data = x$data_u, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="augment.ipd_+3A_x">x</code></td>
<td>
<p>An object of class <code>ipd</code>.</p>
</td></tr>
<tr><td><code id="augment.ipd_+3A_data">data</code></td>
<td>
<p>The <code>data.frame</code> used to fit the model. Default is
<code>x$data</code>.</p>
</td></tr>
<tr><td><code id="augment.ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the augment function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the original data along with fitted
values and residuals.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(2023)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- Fit IPD

fit &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

  data = dat, label = "set_label")

#-- Augment Data

augmented_df &lt;- augment(fit)

head(augmented_df)

</code></pre>

<hr>
<h2 id='calc_lhat_glm'>Estimate PPI++ Power Tuning Parameter</h2><span id='topic+calc_lhat_glm'></span>

<h3>Description</h3>

<p>Calculates the optimal value of lhat for the prediction-powered confidence
interval for GLMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_lhat_glm(
  grads,
  grads_hat,
  grads_hat_unlabeled,
  inv_hessian,
  coord = NULL,
  clip = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_lhat_glm_+3A_grads">grads</code></td>
<td>
<p>(matrix): n x p matrix gradient of the loss function with
respect to the parameter evaluated at the labeled data.</p>
</td></tr>
<tr><td><code id="calc_lhat_glm_+3A_grads_hat">grads_hat</code></td>
<td>
<p>(matrix): n x p matrix gradient of the loss function with
respect to the model parameter evaluated using predictions on the labeled
data.</p>
</td></tr>
<tr><td><code id="calc_lhat_glm_+3A_grads_hat_unlabeled">grads_hat_unlabeled</code></td>
<td>
<p>(matrix): N x p matrix gradient of the loss
function with respect to the parameter evaluated using predictions on the
unlabeled data.</p>
</td></tr>
<tr><td><code id="calc_lhat_glm_+3A_inv_hessian">inv_hessian</code></td>
<td>
<p>(matrix): p x p matrix inverse of the Hessian of the
loss function with respect to the parameter.</p>
</td></tr>
<tr><td><code id="calc_lhat_glm_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize <code>lhat</code>.
If <code>None</code>, it optimizes the total variance over all coordinates.
Must be in (1, ..., d) where d is the shape of the estimand.</p>
</td></tr>
<tr><td><code id="calc_lhat_glm_+3A_clip">clip</code></td>
<td>
<p>(boolean, optional): Whether to clip the value of lhat to be
non-negative. Defaults to <code>False</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(float): Optimal value of <code>lhat</code> in [0,1].
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

est &lt;- ppi_plusplus_ols_est(X_l, Y_l, f_l, X_u, f_u)

stats &lt;- ols_get_stats(est, X_l, Y_l, f_l, X_u, f_u)

calc_lhat_glm(stats$grads, stats$grads_hat, stats$grads_hat_unlabeled,

  stats$inv_hessian, coord = NULL, clip = FALSE)

</code></pre>

<hr>
<h2 id='compute_cdf'>Empirical CDF of the Data</h2><span id='topic+compute_cdf'></span>

<h3>Description</h3>

<p>Computes the empirical CDF of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_cdf(Y, grid, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_cdf_+3A_y">Y</code></td>
<td>
<p>(matrix): n x 1 matrix of observed data.</p>
</td></tr>
<tr><td><code id="compute_cdf_+3A_grid">grid</code></td>
<td>
<p>(matrix): Grid of values to compute the CDF at.</p>
</td></tr>
<tr><td><code id="compute_cdf_+3A_w">w</code></td>
<td>
<p>(vector, optional): n-vector of sample weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): Empirical CDF and its standard deviation at the specified
grid points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Y &lt;- c(1, 2, 3, 4, 5)

grid &lt;- seq(0, 6, by = 0.5)

compute_cdf(Y, grid)

</code></pre>

<hr>
<h2 id='compute_cdf_diff'>Empirical CDF Difference</h2><span id='topic+compute_cdf_diff'></span>

<h3>Description</h3>

<p>Computes the difference between the empirical CDFs of the data and the
predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_cdf_diff(Y, f, grid, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_cdf_diff_+3A_y">Y</code></td>
<td>
<p>(matrix): n x 1 matrix of observed data.</p>
</td></tr>
<tr><td><code id="compute_cdf_diff_+3A_f">f</code></td>
<td>
<p>(matrix): n x 1 matrix of predictions.</p>
</td></tr>
<tr><td><code id="compute_cdf_diff_+3A_grid">grid</code></td>
<td>
<p>(matrix): Grid of values to compute the CDF at.</p>
</td></tr>
<tr><td><code id="compute_cdf_diff_+3A_w">w</code></td>
<td>
<p>(vector, optional): n-vector of sample weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): Difference between the empirical CDFs of the data and the
predictions and its standard deviation at the specified grid points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Y &lt;- c(1, 2, 3, 4, 5)

f &lt;- c(1.1, 2.2, 3.3, 4.4, 5.5)

grid &lt;- seq(0, 6, by = 0.5)

compute_cdf_diff(Y, f, grid)

</code></pre>

<hr>
<h2 id='est_ini'>Initial estimation</h2><span id='topic+est_ini'></span>

<h3>Description</h3>

<p><code>est_ini</code> function for initial estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_ini(X, Y, quant = NA, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="est_ini_+3A_x">X</code></td>
<td>
<p>Array or data.frame containing covariates</p>
</td></tr>
<tr><td><code id="est_ini_+3A_y">Y</code></td>
<td>
<p>Array or data.frame of outcomes</p>
</td></tr>
<tr><td><code id="est_ini_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="est_ini_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>initial estimatior
</p>

<hr>
<h2 id='glance.ipd'>Glance at an IPD Fit</h2><span id='topic+glance.ipd'></span>

<h3>Description</h3>

<p>Glances at the IPD method/model fit, returning a one-row summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ipd'
glance(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glance.ipd_+3A_x">x</code></td>
<td>
<p>An object of class <code>ipd</code>.</p>
</td></tr>
<tr><td><code id="glance.ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the glance function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-row data frame summarizing the IPD method/model fit.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(2023)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- Fit IPD

fit &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

  data = dat, label = "set_label")

#-- Glance Output

glance(fit)

</code></pre>

<hr>
<h2 id='ipd'>Inference on Predicted Data (ipd)</h2><span id='topic+ipd'></span>

<h3>Description</h3>

<p>The main wrapper function to conduct ipd using various methods
and models, and returns a list of fitted model components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipd(
  formula,
  method,
  model,
  data,
  label = NULL,
  unlabeled_data = NULL,
  seed = NULL,
  intercept = TRUE,
  alpha = 0.05,
  alternative = "two-sided",
  n_t = Inf,
  na_action = "na.fail",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipd_+3A_formula">formula</code></td>
<td>
<p>An object of class <code>formula</code>: a symbolic description of
the model to be fitted. Must be of the form <code>Y - f ~ X</code>, where <code>Y</code>
is the name of the column corresponding to the observed outcome in the
labeled data, <code>f</code> is the name of the column corresponding to the
predicted outcome in both labeled and unlabeled data, and <code>X</code>
corresponds to the features of interest (i.e., <code>X = X1 + ... + Xp</code>).
See <strong>1. Formula</strong> in the <strong>Details</strong> below for more information.</p>
</td></tr>
<tr><td><code id="ipd_+3A_method">method</code></td>
<td>
<p>The IPD method to be used for fitting the model. Must be one of
<code>"postpi_analytic"</code>, <code>"postpi_boot"</code>, <code>"ppi"</code>,
<code>"ppi_plusplus"</code>, or <code>"pspa"</code>.
See <strong>3. Method</strong> in the <strong>Details</strong> below for more information.</p>
</td></tr>
<tr><td><code id="ipd_+3A_model">model</code></td>
<td>
<p>The type of downstream inferential model to be fitted, or the
parameter being estimated. Must be one of <code>"mean"</code>,
<code>"quantile"</code>, <code>"ols"</code>, <code>"logistic"</code>, or <code>"poisson"</code>.
See <strong>4. Model</strong> in the <strong>Details</strong> below for more information.</p>
</td></tr>
<tr><td><code id="ipd_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing the variables in the model,
either a stacked data frame with a specific column identifying the labeled
versus unlabeled observations (<code>label</code>), or only the labeled data
set. Must contain columns for the observed outcomes (<code>Y</code>), the
predicted outcomes (<code>f</code>), and the features (<code>X</code>) needed to specify
the <code>formula</code>. See <strong>2. Data</strong> in the <strong>Details</strong> below for
more information.</p>
</td></tr>
<tr><td><code id="ipd_+3A_label">label</code></td>
<td>
<p>A <code>string</code>, <code>int</code>, or <code>logical</code> specifying the
column in the data that distinguishes between the labeled and unlabeled
observations. See the <code>Details</code> section for more information. If NULL,
<code>unlabeled_data</code> must be specified. See <strong>2. Data</strong> in the
<strong>Details</strong> below for more information.</p>
</td></tr>
<tr><td><code id="ipd_+3A_unlabeled_data">unlabeled_data</code></td>
<td>
<p>(optional) A <code>data.frame</code> of unlabeled data. If
NULL, <code>label</code> must be specified. Specifying both the <code>label</code> and
<code>unlabeled_data</code> arguments will result in an error message. If
specified, must contain columns for the predicted outcomes (<code>f</code>), and
the features (<code>X</code>) needed to specify the <code>formula</code>. See
<strong>2. Data</strong> in the <strong>Details</strong> below for more information.</p>
</td></tr>
<tr><td><code id="ipd_+3A_seed">seed</code></td>
<td>
<p>(optional) An <code>integer</code> seed for random number generation.</p>
</td></tr>
<tr><td><code id="ipd_+3A_intercept">intercept</code></td>
<td>
<p><code>Logical</code>. Should an intercept be included in the
model? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ipd_+3A_alpha">alpha</code></td>
<td>
<p>The significance level for confidence intervals. Default is
<code>0.05</code>.</p>
</td></tr>
<tr><td><code id="ipd_+3A_alternative">alternative</code></td>
<td>
<p>A string specifying the alternative hypothesis. Must be
one of <code>"two-sided"</code>, <code>"less"</code>, or <code>"greater"</code>.</p>
</td></tr>
<tr><td><code id="ipd_+3A_n_t">n_t</code></td>
<td>
<p>(integer, optional) Size of the dataset used to train the
prediction function (necessary for the <code>"postpi_analytic"</code> and
<code>"postpi_boot"</code> methods if <code>n_t</code> &lt; <code>nrow(X_l)</code>.
Defaults to <code>Inf</code>.</p>
</td></tr>
<tr><td><code id="ipd_+3A_na_action">na_action</code></td>
<td>
<p>(string, optional) How missing covariate data should be
handled. Currently <code>"na.fail"</code> and <code>"na.omit"</code> are accommodated.
Defaults to <code>"na.fail"</code>.</p>
</td></tr>
<tr><td><code id="ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the fitting function. See
the <code>Details</code> section for more information. See
<strong>5. Auxiliary Arguments</strong> and <strong>6. Other Arguments</strong> in the
<strong>Details</strong> below for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>1. Formula:</strong>
</p>
<p>The <code>ipd</code> function uses one formula argument that specifies both the
calibrating model (e.g., PostPI &quot;relationship model&quot;, PPI &quot;rectifier&quot; model)
and the inferential model. These separate models will be created internally
based on the specific <code>method</code> called.
</p>
<p><strong>2. Data:</strong>
</p>
<p>The data can be specified in two ways:
</p>

<ol>
<li><p> Single data argument (<code>data</code>) containing a stacked
<code>data.frame</code> and a label identifier (<code>label</code>).
</p>
</li>
<li><p> Two data arguments, one for the labeled data (<code>data</code>) and one
for the unlabeled data (<code>unlabeled_data</code>).
</p>
</li></ol>

<p>For option (1), provide one data argument (<code>data</code>) which contains a
stacked <code>data.frame</code> with both the unlabeled and labeled data and a
<code>label</code> argument that specifies the column identifying the labeled
versus the unlabeled observations in the stacked <code>data.frame</code> (e.g.,
<code>label = "set_label"</code> if the column &quot;set_label&quot; in the stacked data
denotes which set an observation belongs to).
</p>
<p>NOTE: Labeled data identifiers can be:
</p>

<dl>
<dt>String</dt><dd><p>&quot;l&quot;, &quot;lab&quot;, &quot;label&quot;, &quot;labeled&quot;, &quot;labelled&quot;, &quot;tst&quot;, &quot;test&quot;,
&quot;true&quot;</p>
</dd>
<dt>Logical</dt><dd><p>TRUE</p>
</dd>
<dt>Factor</dt><dd><p>Non-reference category (i.e., binary 1)</p>
</dd>
</dl>

<p>Unlabeled data identifiers can be:
</p>

<dl>
<dt>String</dt><dd><p>&quot;u&quot;, &quot;unlab&quot;, &quot;unlabeled&quot;, &quot;unlabelled&quot;, &quot;val&quot;,
&quot;validation&quot;, &quot;false&quot;</p>
</dd>
<dt>Logical</dt><dd><p>FALSE</p>
</dd>
<dt>Factor</dt><dd><p>Non-reference category (i.e., binary 0)</p>
</dd>
</dl>

<p>For option (2), provide separate data arguments for the labeled data set
(<code>data</code>) and the unlabeled data set (<code>unlabeled_data</code>). If the
second argument is provided, the function ignores the <code>label</code> identifier
and assumes the data provided are not stacked.
</p>
<p>NOTE: Not all columns in <code>data</code> or <code>unlabeled_data</code> may be used
unless explicitly referenced in the <code>formula</code> argument or in the
<code>label</code> argument (if the data are passed as one stacked data frame).
</p>
<p><strong>3. Method:</strong>
</p>
<p>Use the <code>method</code> argument to specify the fitting method:
</p>

<dl>
<dt>&quot;postpi_analytic&quot;</dt><dd><p>Wang et al. (2020) Post-Prediction Inference (PostPI) Analytic Correction</p>
</dd>
<dt>&quot;postpi_boot&quot;</dt><dd><p>Wang et al. (2020) Post-Prediction Inference (PostPI) Bootstrap Correction</p>
</dd>
<dt>&quot;ppi&quot;</dt><dd><p>Angelopoulos et al. (2023) Prediction-Powered Inference
(PPI)</p>
</dd>
<dt>&quot;ppi_plusplus&quot;</dt><dd><p>Angelopoulos et al. (2023) PPI++</p>
</dd>
<dt>&quot;pspa&quot;</dt><dd><p>Miao et al. (2023) Assumption-Lean and Data-Adaptive
Post-Prediction Inference (PSPA)</p>
</dd>
</dl>

<p><strong>4. Model:</strong>
</p>
<p>Use the <code>model</code> argument to specify the type of downstream inferential
model or parameter to be estimated:
</p>

<dl>
<dt>&quot;mean&quot;</dt><dd><p>Mean value of a continuous outcome</p>
</dd>
<dt>&quot;quantile&quot;</dt><dd><p><code>q</code>th quantile of a continuous outcome</p>
</dd>
<dt>&quot;ols&quot;</dt><dd><p>Linear regression coefficients for a continuous outcome</p>
</dd>
<dt>&quot;logistic&quot;</dt><dd><p>Logistic regression coefficients for a binary outcome</p>
</dd>
<dt>&quot;poisson&quot;</dt><dd><p>Poisson regression coefficients for a count outcome</p>
</dd>
</dl>

<p>The <code>ipd</code> wrapper function will concatenate the <code>method</code> and
<code>model</code> arguments to identify the required helper function, following
the naming convention &quot;method_model&quot;.
</p>
<p><strong>5. Auxiliary Arguments:</strong>
</p>
<p>The wrapper function will take method-specific auxiliary arguments (e.g.,
<code>q</code> for the quantile estimation models) and pass them to the helper
function through the &quot;...&quot; with specified defaults for simplicity.
</p>
<p><strong>6. Other Arguments:</strong>
</p>
<p>All other arguments that relate to all methods (e.g., alpha, ci.type), or
other method-specific arguments, will have defaults.
</p>


<h3>Value</h3>

<p>a summary of model output.
</p>
<p>A list containing the fitted model components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Estimated coefficients of the model</p>
</dd>
<dt>se</dt><dd><p>Standard errors of the estimated coefficients</p>
</dd>
<dt>ci</dt><dd><p>Confidence intervals for the estimated coefficients</p>
</dd>
<dt>formula</dt><dd><p>The formula used to fit the ipd model.</p>
</dd>
<dt>data</dt><dd><p>The data frame used for model fitting.</p>
</dd>
<dt>method</dt><dd><p>The method used for model fitting.</p>
</dd>
<dt>model</dt><dd><p>The type of model fitted.</p>
</dd>
<dt>intercept</dt><dd><p>Logical. Indicates if an intercept was included in the
model.</p>
</dd>
<dt>fit</dt><dd><p>Fitted model object containing estimated coefficients, standard
errors, confidence intervals, and additional method-specific output.</p>
</dd>
<dt>...</dt><dd><p>Additional output specific to the method used.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(12345)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- PostPI Analytic Correction (Wang et al., 2020)

ipd(formula, method = "postpi_analytic", model = "ols",

    data = dat, label = "set_label")

#-- PostPI Bootstrap Correction (Wang et al., 2020)

nboot &lt;- 200

ipd(formula, method = "postpi_boot", model = "ols",

    data = dat, label = "set_label", nboot = nboot)

#-- PPI (Angelopoulos et al., 2023)

ipd(formula, method = "ppi", model = "ols",

    data = dat, label = "set_label")

#-- PPI++ (Angelopoulos et al., 2023)

ipd(formula, method = "ppi_plusplus", model = "ols",

    data = dat, label = "set_label")

#-- PSPA (Miao et al., 2023)

ipd(formula, method = "pspa", model = "ols",

    data = dat, label = "set_label")

</code></pre>

<hr>
<h2 id='link_grad'>Gradient of the link function</h2><span id='topic+link_grad'></span>

<h3>Description</h3>

<p><code>link_grad</code> function for gradient of the link function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>link_grad(t, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="link_grad_+3A_t">t</code></td>
<td>
<p>t</p>
</td></tr>
<tr><td><code id="link_grad_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>gradient of the link function
</p>

<hr>
<h2 id='link_Hessian'>Hessians of the link function</h2><span id='topic+link_Hessian'></span>

<h3>Description</h3>

<p><code>link_Hessian</code> function for Hessians of the link function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>link_Hessian(t, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="link_Hessian_+3A_t">t</code></td>
<td>
<p>t</p>
</td></tr>
<tr><td><code id="link_Hessian_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Hessians of the link function
</p>

<hr>
<h2 id='log1pexp'>Log1p Exponential</h2><span id='topic+log1pexp'></span>

<h3>Description</h3>

<p>Computes the natural logarithm of 1 plus the exponential of the input,
to handle large inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log1pexp(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log1pexp_+3A_x">x</code></td>
<td>
<p>(vector): A numeric vector of inputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(vector): A numeric vector where each element is the result of
log(1 + exp(x)).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- c(-1, 0, 1, 10, 100)

log1pexp(x)

</code></pre>

<hr>
<h2 id='logistic_get_stats'>Logistic Regression Gradient and Hessian</h2><span id='topic+logistic_get_stats'></span>

<h3>Description</h3>

<p>Computes the statistics needed for the logstic regression-based
prediction-powered inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic_get_stats(
  est,
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  w_l = NULL,
  w_u = NULL,
  use_u = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logistic_get_stats_+3A_est">est</code></td>
<td>
<p>(vector): Point estimates of the coefficients.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): Covariates for the labeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): Labels for the labeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_f_l">f_l</code></td>
<td>
<p>(vector): Predictions for the labeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): Covariates for the unlabeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_f_u">f_u</code></td>
<td>
<p>(vector): Predictions for the unlabeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_w_l">w_l</code></td>
<td>
<p>(vector, optional): Sample weights for the labeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_w_u">w_u</code></td>
<td>
<p>(vector, optional): Sample weights for the unlabeled data set.</p>
</td></tr>
<tr><td><code id="logistic_get_stats_+3A_use_u">use_u</code></td>
<td>
<p>(bool, optional): Whether to use the unlabeled data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>grads</dt><dd><p>(matrix): n x p matrix gradient of the loss function with
respect to the coefficients.</p>
</dd>
<dt>grads_hat</dt><dd><p>(matrix): n x p matrix gradient of the loss function
with respect to the coefficients, evaluated using the labeled
predictions.</p>
</dd>
<dt>grads_hat_unlabeled</dt><dd><p>(matrix): N x p matrix gradient of the loss
function with respect to the coefficients, evaluated using the unlabeled
predictions.</p>
</dd>
<dt>inv_hessian</dt><dd><p>(matrix): p x p matrix inverse Hessian of the loss
function with respect to the coefficients.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "logistic")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

est &lt;- ppi_plusplus_logistic_est(X_l, Y_l, f_l, X_u, f_u)

stats &lt;- logistic_get_stats(est, X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='mean_psi'>Sample expectation of psi</h2><span id='topic+mean_psi'></span>

<h3>Description</h3>

<p><code>mean_psi</code> function for sample expectation of psi
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_psi(X, Y, theta, quant = NA, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_psi_+3A_x">X</code></td>
<td>
<p>Array or data.frame containing covariates</p>
</td></tr>
<tr><td><code id="mean_psi_+3A_y">Y</code></td>
<td>
<p>Array or data.frame of outcomes</p>
</td></tr>
<tr><td><code id="mean_psi_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="mean_psi_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="mean_psi_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sample expectation of psi
</p>

<hr>
<h2 id='mean_psi_pop'>Sample expectation of PSPA psi</h2><span id='topic+mean_psi_pop'></span>

<h3>Description</h3>

<p><code>mean_psi_pop</code> function for sample expectation of PSPA psi
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_psi_pop(
  X_lab,
  X_unlab,
  Y_lab,
  Yhat_lab,
  Yhat_unlab,
  w,
  theta,
  quant = NA,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_psi_pop_+3A_x_lab">X_lab</code></td>
<td>
<p>Array or data.frame containing observed covariates in
labeled data.</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_x_unlab">X_unlab</code></td>
<td>
<p>Array or data.frame containing observed or predicted
covariates in unlabeled data.</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_y_lab">Y_lab</code></td>
<td>
<p>Array or data.frame of observed outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_yhat_lab">Yhat_lab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_yhat_unlab">Yhat_unlab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in
unlabeled data.</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_w">w</code></td>
<td>
<p>weights vector PSPA linear regression (d-dimensional, where
d equals the number of covariates).</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="mean_psi_pop_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sample expectation of PSPA psi
</p>

<hr>
<h2 id='ols'>Ordinary Least Squares</h2><span id='topic+ols'></span>

<h3>Description</h3>

<p>Computes the ordinary least squares coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols(X, Y, return_se = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ols_+3A_x">X</code></td>
<td>
<p>(matrix): n x p matrix of covariates.</p>
</td></tr>
<tr><td><code id="ols_+3A_y">Y</code></td>
<td>
<p>(vector): p-vector of outcome values.</p>
</td></tr>
<tr><td><code id="ols_+3A_return_se">return_se</code></td>
<td>
<p>(bool, optional): Whether to return the standard errors of
the coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>theta</dt><dd><p>(vector): p-vector of ordinary least squares estimates of
the coefficients.</p>
</dd>
<dt>se</dt><dd><p>(vector): If return_se == TRUE, return the p-vector of
standard errors of the coefficients.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 1000

X &lt;- rnorm(n, 1, 1)

Y &lt;- X + rnorm(n, 0, 1)

ols(X, Y, return_se = TRUE)

</code></pre>

<hr>
<h2 id='ols_get_stats'>OLS Gradient and Hessian</h2><span id='topic+ols_get_stats'></span>

<h3>Description</h3>

<p>Computes the statistics needed for the OLS-based
prediction-powered inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols_get_stats(
  est,
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  w_l = NULL,
  w_u = NULL,
  use_u = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ols_get_stats_+3A_est">est</code></td>
<td>
<p>(vector): Point estimates of the coefficients.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): Covariates for the labeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): Labels for the labeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_f_l">f_l</code></td>
<td>
<p>(vector): Predictions for the labeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): Covariates for the unlabeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_f_u">f_u</code></td>
<td>
<p>(vector): Predictions for the unlabeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_w_l">w_l</code></td>
<td>
<p>(vector, optional): Sample weights for the labeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_w_u">w_u</code></td>
<td>
<p>(vector, optional): Sample weights for the unlabeled data set.</p>
</td></tr>
<tr><td><code id="ols_get_stats_+3A_use_u">use_u</code></td>
<td>
<p>(boolean, optional): Whether to use the unlabeled data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>grads</dt><dd><p>(matrix): n x p matrix gradient of the loss function with
respect to the coefficients.</p>
</dd>
<dt>grads_hat</dt><dd><p>(matrix): n x p matrix gradient of the loss function
with respect to the coefficients, evaluated using the labeled
predictions.</p>
</dd>
<dt>grads_hat_unlabeled</dt><dd><p>(matrix): N x p matrix gradient of the loss
function with respect to the coefficients, evaluated using the unlabeled
predictions.</p>
</dd>
<dt>inv_hessian</dt><dd><p>(matrix): p x p matrix inverse Hessian of the loss
function with respect to the coefficients.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

est &lt;- ppi_plusplus_ols_est(X_l, Y_l, f_l, X_u, f_u)

stats &lt;- ols_get_stats(est, X_l, Y_l, f_l, X_u, f_u, use_u = TRUE)

</code></pre>

<hr>
<h2 id='optim_est'>One-step update for obtaining estimator</h2><span id='topic+optim_est'></span>

<h3>Description</h3>

<p><code>optim_est</code> function for One-step update for obtaining estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim_est(
  X_lab,
  X_unlab,
  Y_lab,
  Yhat_lab,
  Yhat_unlab,
  w,
  theta,
  quant = NA,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optim_est_+3A_x_lab">X_lab</code></td>
<td>
<p>Array or data.frame containing observed covariates in
labeled data.</p>
</td></tr>
<tr><td><code id="optim_est_+3A_x_unlab">X_unlab</code></td>
<td>
<p>Array or data.frame containing observed or
predicted covariates in unlabeled data.</p>
</td></tr>
<tr><td><code id="optim_est_+3A_y_lab">Y_lab</code></td>
<td>
<p>Array or data.frame of observed outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="optim_est_+3A_yhat_lab">Yhat_lab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="optim_est_+3A_yhat_unlab">Yhat_unlab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in
unlabeled data.</p>
</td></tr>
<tr><td><code id="optim_est_+3A_w">w</code></td>
<td>
<p>weights vector PSPA linear regression (d-dimensional, where
d equals the number of covariates).</p>
</td></tr>
<tr><td><code id="optim_est_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="optim_est_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="optim_est_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>estimator
</p>

<hr>
<h2 id='optim_weights'>One-step update for obtaining the weight vector</h2><span id='topic+optim_weights'></span>

<h3>Description</h3>

<p><code>optim_weights</code> function for One-step update for obtaining estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim_weights(
  X_lab,
  X_unlab,
  Y_lab,
  Yhat_lab,
  Yhat_unlab,
  w,
  theta,
  quant = NA,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optim_weights_+3A_x_lab">X_lab</code></td>
<td>
<p>Array or data.frame containing observed covariates in
labeled data.</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_x_unlab">X_unlab</code></td>
<td>
<p>Array or data.frame containing observed or
predicted covariates in unlabeled data.</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_y_lab">Y_lab</code></td>
<td>
<p>Array or data.frame of observed outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_yhat_lab">Yhat_lab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_yhat_unlab">Yhat_unlab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in unlabeled data.</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_w">w</code></td>
<td>
<p>weights vector PSPA linear regression (d-dimensional, where
d equals the number of covariates).</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="optim_weights_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>weights
</p>

<hr>
<h2 id='postpi_analytic_ols'>PostPI OLS (Analytic Correction)</h2><span id='topic+postpi_analytic_ols'></span>

<h3>Description</h3>

<p>Helper function for PostPI OLS estimation (analytic correction)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postpi_analytic_ols(X_l, Y_l, f_l, X_u, f_u, scale_se = TRUE, n_t = Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="postpi_analytic_ols_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="postpi_analytic_ols_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="postpi_analytic_ols_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="postpi_analytic_ols_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="postpi_analytic_ols_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="postpi_analytic_ols_+3A_scale_se">scale_se</code></td>
<td>
<p>(boolean): Logical argument to scale relationship model
error variance. Defaults to TRUE; FALSE option is retained for posterity.</p>
</td></tr>
<tr><td><code id="postpi_analytic_ols_+3A_n_t">n_t</code></td>
<td>
<p>(integer, optional) Size of the dataset used to train the
prediction function (necessary if <code>n_t</code> &lt; <code>nrow(X_l)</code>.
Defaults to <code>Inf</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods for correcting inference based on outcomes predicted by machine
learning (Wang et al., 2020)
<a href="https://www.pnas.org/doi/abs/10.1073/pnas.2001238117">https://www.pnas.org/doi/abs/10.1073/pnas.2001238117</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of the inference model parameters and
corresponding standard error estimate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

postpi_analytic_ols(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='postpi_boot_logistic'>PostPI Logistic Regression (Bootstrap Correction)</h2><span id='topic+postpi_boot_logistic'></span>

<h3>Description</h3>

<p>Helper function for PostPI logistic regression (bootstrap correction)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postpi_boot_logistic(
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  nboot = 100,
  se_type = "par",
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="postpi_boot_logistic_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_nboot">nboot</code></td>
<td>
<p>(integer): Number of bootstrap samples. Defaults to 100.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_se_type">se_type</code></td>
<td>
<p>(string): Which method to calculate the standard errors.
Options include &quot;par&quot; (parametric) or &quot;npar&quot; (nonparametric).
Defaults to &quot;par&quot;.</p>
</td></tr>
<tr><td><code id="postpi_boot_logistic_+3A_seed">seed</code></td>
<td>
<p>(optional) An <code>integer</code> seed for random number generation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods for correcting inference based on outcomes predicted by machine
learning (Wang et al., 2020)
<a href="https://www.pnas.org/doi/abs/10.1073/pnas.2001238117">https://www.pnas.org/doi/abs/10.1073/pnas.2001238117</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error based on both parametric and non-parametric
bootstrap methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "logistic")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

postpi_boot_logistic(X_l, Y_l, f_l, X_u, f_u, nboot = 200)

</code></pre>

<hr>
<h2 id='postpi_boot_ols'>PostPI OLS (Bootstrap Correction)</h2><span id='topic+postpi_boot_ols'></span>

<h3>Description</h3>

<p>Helper function for PostPI OLS estimation (bootstrap correction)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postpi_boot_ols(
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  nboot = 100,
  se_type = "par",
  rel_func = "lm",
  scale_se = TRUE,
  n_t = Inf,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="postpi_boot_ols_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_nboot">nboot</code></td>
<td>
<p>(integer): Number of bootstrap samples. Defaults to 100.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_se_type">se_type</code></td>
<td>
<p>(string): Which method to calculate the standard errors.
Options include &quot;par&quot; (parametric) or &quot;npar&quot; (nonparametric).
Defaults to &quot;par&quot;.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_rel_func">rel_func</code></td>
<td>
<p>(string): Method for fitting the relationship model.
Options include &quot;lm&quot; (linear model), &quot;rf&quot; (random forest), and &quot;gam&quot;
(generalized additive model). Defaults to &quot;lm&quot;.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_scale_se">scale_se</code></td>
<td>
<p>(boolean): Logical argument to scale relationship model
error variance. Defaults to TRUE; FALSE option is retained for posterity.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_n_t">n_t</code></td>
<td>
<p>(integer, optional) Size of the dataset used to train the
prediction function (necessary if <code>n_t</code> &lt; <code>nrow(X_l)</code>.
Defaults to <code>Inf</code>.</p>
</td></tr>
<tr><td><code id="postpi_boot_ols_+3A_seed">seed</code></td>
<td>
<p>(optional) An <code>integer</code> seed for random number generation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods for correcting inference based on outcomes predicted by machine
learning (Wang et al., 2020)
<a href="https://www.pnas.org/doi/abs/10.1073/pnas.2001238117">https://www.pnas.org/doi/abs/10.1073/pnas.2001238117</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error based on both parametric and non-parametric
bootstrap methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

postpi_boot_ols(X_l, Y_l, f_l, X_u, f_u, nboot = 200)

</code></pre>

<hr>
<h2 id='ppi_logistic'>PPI Logistic Regression</h2><span id='topic+ppi_logistic'></span>

<h3>Description</h3>

<p>Helper function for PPI logistic regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_logistic(X_l, Y_l, f_l, X_u, f_u, opts = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_logistic_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_logistic_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_logistic_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_logistic_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_logistic_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_logistic_+3A_opts">opts</code></td>
<td>
<p>(list, optional): Options to pass to the optimizer.
See ?optim for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://www.science.org/doi/10.1126/science.adi6000">https://www.science.org/doi/10.1126/science.adi6000</a>
</p>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>est</dt><dd><p>(vector): vector of PPI logistic regression coefficient
estimates.</p>
</dd>
<dt>se</dt><dd><p>(vector): vector of standard errors of the coefficients.</p>
</dd>
<dt>rectifier_est</dt><dd><p>(vector): vector of the rectifier logistic
regression coefficient estimates.</p>
</dd>
<dt>var_u</dt><dd><p>(matrix): covariance matrix for the gradients in the
unlabeled data.</p>
</dd>
<dt>var_l</dt><dd><p>(matrix): covariance matrix for the gradients in the
labeled data.</p>
</dd>
<dt>grads</dt><dd><p>(matrix): matrix of gradients for the
labeled data.</p>
</dd>
<dt>grads_hat_unlabeled</dt><dd><p>(matrix): matrix of predicted gradients for
the unlabeled data.</p>
</dd>
<dt>grads_hat</dt><dd><p>(matrix): matrix of predicted gradients for the
labeled data.</p>
</dd>
<dt>inv_hessian</dt><dd><p>(matrix): inverse Hessian matrix.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "logistic")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_logistic(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='ppi_mean'>PPI Mean Estimation</h2><span id='topic+ppi_mean'></span>

<h3>Description</h3>

<p>Helper function for PPI mean estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_mean(Y_l, f_l, f_u, alpha = 0.05, alternative = "two-sided")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_mean_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_mean_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_mean_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_mean_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
<tr><td><code id="ppi_mean_+3A_alternative">alternative</code></td>
<td>
<p>(string): Alternative hypothesis. Must be one of
<code>"two-sided"</code>, <code>"less"</code>, or <code>"greater"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://www.science.org/doi/10.1126/science.adi6000">https://www.science.org/doi/10.1126/science.adi6000</a>
</p>


<h3>Value</h3>

<p>tuple: Lower and upper bounds of the prediction-powered confidence
interval for the mean.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "mean")

form &lt;- Y - f ~ 1

Y_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_mean(Y_l, f_l, f_u)

</code></pre>

<hr>
<h2 id='ppi_ols'>PPI OLS</h2><span id='topic+ppi_ols'></span>

<h3>Description</h3>

<p>Helper function for prediction-powered inference for OLS estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_ols(X_l, Y_l, f_l, X_u, f_u, w_l = NULL, w_u = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_ols_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_ols_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_ols_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_ols_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_ols_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_ols_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_ols_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://www.science.org/doi/10.1126/science.adi6000">https://www.science.org/doi/10.1126/science.adi6000</a>
</p>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>est</dt><dd><p>(vector): vector of PPI OLS regression coefficient
estimates.</p>
</dd>
<dt>se</dt><dd><p>(vector): vector of standard errors of the coefficients.</p>
</dd>
<dt>rectifier_est</dt><dd><p>(vector): vector of the rectifier OLS
regression coefficient estimates.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat()

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_ols(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_logistic'>PPI++ Logistic Regression</h2><span id='topic+ppi_plusplus_logistic'></span>

<h3>Description</h3>

<p>Helper function for PPI++ logistic regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_logistic(
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  lhat = NULL,
  coord = NULL,
  opts = NULL,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_logistic_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_lhat">lhat</code></td>
<td>
<p>(float, optional): Power-tuning parameter (see
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>). The default value, <code>NULL</code>,
will estimate the optimal value from the data. Setting <code>lhat = 1</code>
recovers PPI with no power tuning, and setting <code>lhat = 0</code> recovers
the classical point estimate.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize
<code>lhat = 1</code>. If <code>NULL</code>, it optimizes the total variance over all
coordinates. Must be in (1, ..., d) where d is the dimension of the estimand.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_opts">opts</code></td>
<td>
<p>(list, optional): Options to pass to the optimizer.
See ?optim for details.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>
</p>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>est</dt><dd><p>(vector): vector of PPI++ logistic regression coefficient
estimates.</p>
</dd>
<dt>se</dt><dd><p>(vector): vector of standard errors of the coefficients.</p>
</dd>
<dt>lambda</dt><dd><p>(float): estimated power-tuning parameter.</p>
</dd>
<dt>rectifier_est</dt><dd><p>(vector): vector of the rectifier logistic
regression coefficient estimates.</p>
</dd>
<dt>var_u</dt><dd><p>(matrix): covariance matrix for the gradients in the
unlabeled data.</p>
</dd>
<dt>var_l</dt><dd><p>(matrix): covariance matrix for the gradients in the
labeled data.</p>
</dd>
<dt>grads</dt><dd><p>(matrix): matrix of gradients for the
labeled data.</p>
</dd>
<dt>grads_hat_unlabeled</dt><dd><p>(matrix): matrix of predicted gradients for
the unlabeled data.</p>
</dd>
<dt>grads_hat</dt><dd><p>(matrix): matrix of predicted gradients for the
labeled data.</p>
</dd>
<dt>inv_hessian</dt><dd><p>(matrix): inverse Hessian matrix.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "logistic")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_logistic(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_logistic_est'>PPI++ Logistic Regression (Point Estimate)</h2><span id='topic+ppi_plusplus_logistic_est'></span>

<h3>Description</h3>

<p>Helper function for PPI++ logistic regression (point estimate)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_logistic_est(
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  lhat = NULL,
  coord = NULL,
  opts = NULL,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_logistic_est_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_lhat">lhat</code></td>
<td>
<p>(float, optional): Power-tuning parameter (see
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>). The default value, <code>NULL</code>,
will estimate the optimal value from the data. Setting <code>lhat = 1</code>
recovers PPI with no power tuning, and setting <code>lhat = 0</code> recovers
the classical point estimate.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize
<code>lhat = 1</code>. If <code>NULL</code>, it optimizes the total variance over all
coordinates. Must be in (1, ..., d) where d is the dimension of the estimand.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_opts">opts</code></td>
<td>
<p>(list, optional): Options to pass to the optimizer.
See ?optim for details.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_logistic_est_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>'
</p>


<h3>Value</h3>

<p>(vector): vector of prediction-powered point estimates of the
logistic regression coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "logistic")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_logistic_est(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_mean'>PPI++ Mean Estimation</h2><span id='topic+ppi_plusplus_mean'></span>

<h3>Description</h3>

<p>Helper function for PPI++ mean estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_mean(
  Y_l,
  f_l,
  f_u,
  alpha = 0.05,
  alternative = "two-sided",
  lhat = NULL,
  coord = NULL,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_mean_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_alternative">alternative</code></td>
<td>
<p>(string): Alternative hypothesis. Must be one of
<code>"two-sided"</code>, <code>"less"</code>, or <code>"greater"</code>.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_lhat">lhat</code></td>
<td>
<p>(float, optional): Power-tuning parameter (see
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>). The default value, <code>NULL</code>,
will estimate the optimal value from the data. Setting <code>lhat = 1</code>
recovers PPI with no power tuning, and setting <code>lhat = 0</code> recovers
the classical point estimate.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize
<code>lhat = 1</code>. If <code>NULL</code>, it optimizes the total variance over all
coordinates. Must be in (1, ..., d) where d is the dimension of the estimand.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>'
</p>


<h3>Value</h3>

<p>tuple: Lower and upper bounds of the prediction-powered confidence
interval for the mean.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "mean")

form &lt;- Y - f ~ 1

Y_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_mean(Y_l, f_l, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_mean_est'>PPI++ Mean Estimation (Point Estimate)</h2><span id='topic+ppi_plusplus_mean_est'></span>

<h3>Description</h3>

<p>Helper function for PPI++ mean estimation (point estimate)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_mean_est(
  Y_l,
  f_l,
  f_u,
  lhat = NULL,
  coord = NULL,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_mean_est_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_est_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_est_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_est_+3A_lhat">lhat</code></td>
<td>
<p>(float, optional): Power-tuning parameter (see
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>). The default value, <code>NULL</code>,
will estimate the optimal value from the data. Setting <code>lhat = 1</code>
recovers PPI with no power tuning, and setting <code>lhat = 0</code> recovers
the classical point estimate.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_est_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize
<code>lhat = 1</code>. If <code>NULL</code>, it optimizes the total variance over all
coordinates. Must be in (1, ..., d) where d is the dimension of the estimand.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_est_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_mean_est_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>
</p>


<h3>Value</h3>

<p>float or ndarray: Prediction-powered point estimate of the mean.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "mean")

form &lt;- Y - f ~ 1

Y_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_mean_est(Y_l, f_l, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_ols'>PPI++ OLS</h2><span id='topic+ppi_plusplus_ols'></span>

<h3>Description</h3>

<p>Helper function for PPI++ OLS estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_ols(
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  lhat = NULL,
  coord = NULL,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_ols_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_lhat">lhat</code></td>
<td>
<p>(float, optional): Power-tuning parameter (see
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>). The default value, <code>NULL</code>,
will estimate the optimal value from the data. Setting <code>lhat = 1</code>
recovers PPI with no power tuning, and setting <code>lhat = 0</code> recovers
the classical point estimate.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize
<code>lhat = 1</code>. If <code>NULL</code>, it optimizes the total variance over all
coordinates. Must be in (1, ..., d) where d is the dimension of the estimand.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>'
</p>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>est</dt><dd><p>(vector): vector of PPI++ OLS regression coefficient
estimates.</p>
</dd>
<dt>se</dt><dd><p>(vector): vector of standard errors of the coefficients.</p>
</dd>
<dt>lambda</dt><dd><p>(float): estimated power-tuning parameter.</p>
</dd>
<dt>rectifier_est</dt><dd><p>(vector): vector of the rectifier OLS
regression coefficient estimates.</p>
</dd>
<dt>var_u</dt><dd><p>(matrix): covariance matrix for the gradients in the
unlabeled data.</p>
</dd>
<dt>var_l</dt><dd><p>(matrix): covariance matrix for the gradients in the
labeled data.</p>
</dd>
<dt>grads</dt><dd><p>(matrix): matrix of gradients for the
labeled data.</p>
</dd>
<dt>grads_hat_unlabeled</dt><dd><p>(matrix): matrix of predicted gradients for
the unlabeled data.</p>
</dd>
<dt>grads_hat</dt><dd><p>(matrix): matrix of predicted gradients for the
labeled data.</p>
</dd>
<dt>inv_hessian</dt><dd><p>(matrix): inverse Hessian matrix.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_ols(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_ols_est'>PPI++ OLS (Point Estimate)</h2><span id='topic+ppi_plusplus_ols_est'></span>

<h3>Description</h3>

<p>Helper function for PPI++ OLS estimation (point estimate)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_ols_est(
  X_l,
  Y_l,
  f_l,
  X_u,
  f_u,
  lhat = NULL,
  coord = NULL,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_ols_est_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_lhat">lhat</code></td>
<td>
<p>(float, optional): Power-tuning parameter (see
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>). The default value, <code>NULL</code>,
will estimate the optimal value from the data. Setting <code>lhat = 1</code>
recovers PPI with no power tuning, and setting <code>lhat = 0</code> recovers
the classical point estimate.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_coord">coord</code></td>
<td>
<p>(int, optional): Coordinate for which to optimize
<code>lhat = 1</code>. If <code>NULL</code>, it optimizes the total variance over all
coordinates. Must be in (1, ..., d) where d is the dimension of the estimand.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_ols_est_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>
</p>


<h3>Value</h3>

<p>(vector): vector of prediction-powered point estimates of the OLS
coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_ols_est(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='ppi_plusplus_quantile'>PPI++ Quantile Estimation</h2><span id='topic+ppi_plusplus_quantile'></span>

<h3>Description</h3>

<p>Helper function for PPI++ quantile estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_quantile(
  Y_l,
  f_l,
  f_u,
  q,
  alpha = 0.05,
  exact_grid = FALSE,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_quantile_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_q">q</code></td>
<td>
<p>(float): Quantile to estimate. Must be in the range (0, 1).</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_exact_grid">exact_grid</code></td>
<td>
<p>(bool, optional): Whether to compute the exact solution
(TRUE) or an approximate solution based on a linearly spaced grid of 5000
values (FALSE).</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>
</p>


<h3>Value</h3>

<p>tuple: Lower and upper bounds of the prediction-powered confidence
interval for the quantile.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "quantile")

form &lt;- Y - f ~ X1

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_quantile(Y_l, f_l, f_u, q = 0.5)

</code></pre>

<hr>
<h2 id='ppi_plusplus_quantile_est'>PPI++ Quantile Estimation (Point Estimate)</h2><span id='topic+ppi_plusplus_quantile_est'></span>

<h3>Description</h3>

<p>Helper function for PPI++ quantile estimation (point estimate)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_plusplus_quantile_est(
  Y_l,
  f_l,
  f_u,
  q,
  exact_grid = FALSE,
  w_l = NULL,
  w_u = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_plusplus_quantile_est_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_est_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_est_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_est_+3A_q">q</code></td>
<td>
<p>(float): Quantile to estimate. Must be in the range (0, 1).</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_est_+3A_exact_grid">exact_grid</code></td>
<td>
<p>(bool, optional): Whether to compute the exact solution
(TRUE) or an approximate solution based on a linearly spaced grid of 5000
values (FALSE).</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_est_+3A_w_l">w_l</code></td>
<td>
<p>(ndarray, optional): Sample weights for the labeled data set.
Defaults to a vector of ones.</p>
</td></tr>
<tr><td><code id="ppi_plusplus_quantile_est_+3A_w_u">w_u</code></td>
<td>
<p>(ndarray, optional): Sample weights for the unlabeled
data set. Defaults to a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://arxiv.org/abs/2311.01453">https://arxiv.org/abs/2311.01453</a>'
</p>


<h3>Value</h3>

<p>(float): Prediction-powered point estimate of the quantile.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "quantile")

form &lt;- Y - f ~ 1

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_plusplus_quantile_est(Y_l, f_l, f_u, q = 0.5)

</code></pre>

<hr>
<h2 id='ppi_quantile'>PPI Quantile Estimation</h2><span id='topic+ppi_quantile'></span>

<h3>Description</h3>

<p>Helper function for PPI quantile estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppi_quantile(Y_l, f_l, f_u, q, alpha = 0.05, exact_grid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppi_quantile_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="ppi_quantile_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="ppi_quantile_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="ppi_quantile_+3A_q">q</code></td>
<td>
<p>(float): Quantile to estimate. Must be in the range (0, 1).</p>
</td></tr>
<tr><td><code id="ppi_quantile_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
<tr><td><code id="ppi_quantile_+3A_exact_grid">exact_grid</code></td>
<td>
<p>(bool, optional): Whether to compute the exact solution
(TRUE) or an approximate solution based on a linearly spaced grid of 5000
values (FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prediction Powered Inference (Angelopoulos et al., 2023)
<a href="https://www.science.org/doi/10.1126/science.adi6000">https://www.science.org/doi/10.1126/science.adi6000</a>
</p>


<h3>Value</h3>

<p>tuple: Lower and upper bounds of the prediction-powered confidence
interval for the quantile.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "quantile")

form &lt;- Y - f ~ X1

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

ppi_quantile(Y_l, f_l, f_u, q = 0.5)

</code></pre>

<hr>
<h2 id='print.ipd'>Print IPD Fit</h2><span id='topic+print.ipd'></span>

<h3>Description</h3>

<p>Prints a brief summary of the IPD method/model combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ipd'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.ipd_+3A_x">x</code></td>
<td>
<p>An object of class <code>ipd</code>.</p>
</td></tr>
<tr><td><code id="print.ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the print function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>x</code>, invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(2023)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- Fit IPD

fit &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

  data = dat, label = "set_label")

#-- Print Output

print(fit)

</code></pre>

<hr>
<h2 id='print.summary.ipd'>Print Summary of IPD Fit</h2><span id='topic+print.summary.ipd'></span>

<h3>Description</h3>

<p>Prints a detailed summary of the IPD method/model combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.ipd'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.ipd_+3A_x">x</code></td>
<td>
<p>An object of class <code>summary.ipd</code>.</p>
</td></tr>
<tr><td><code id="print.summary.ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the print function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>x</code>, invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(2023)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- Fit IPD

fit &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

  data = dat, label = "set_label")

#-- Summarize Output

summ_fit &lt;- summary(fit)

print(summ_fit)

</code></pre>

<hr>
<h2 id='psi'>Estimating equation</h2><span id='topic+psi'></span>

<h3>Description</h3>

<p><code>psi</code> function for estimating equation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi(X, Y, theta, quant = NA, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="psi_+3A_x">X</code></td>
<td>
<p>Array or data.frame containing covariates</p>
</td></tr>
<tr><td><code id="psi_+3A_y">Y</code></td>
<td>
<p>Array or data.frame of outcomes</p>
</td></tr>
<tr><td><code id="psi_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="psi_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="psi_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>esimating equation
</p>

<hr>
<h2 id='pspa_logistic'>PSPA Logistic Regression</h2><span id='topic+pspa_logistic'></span>

<h3>Description</h3>

<p>Helper function for PSPA logistic regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pspa_logistic(X_l, Y_l, f_l, X_u, f_u, weights = NA, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pspa_logistic_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_logistic_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of binary labeled outcomes.</p>
</td></tr>
<tr><td><code id="pspa_logistic_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of binary predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_logistic_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_logistic_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of binary predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_logistic_+3A_weights">weights</code></td>
<td>
<p>(array): p-dimensional array of weights vector for variance
reduction. PSPA will estimate the weights if not specified.</p>
</td></tr>
<tr><td><code id="pspa_logistic_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Post-prediction adaptive inference
(Miao et al. 2023) <a href="https://arxiv.org/abs/2311.14220">https://arxiv.org/abs/2311.14220</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "logistic")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

pspa_logistic(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='pspa_mean'>PSPA Mean Estimation</h2><span id='topic+pspa_mean'></span>

<h3>Description</h3>

<p>Helper function for PSPA mean estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pspa_mean(Y_l, f_l, f_u, weights = NA, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pspa_mean_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="pspa_mean_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_mean_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_mean_+3A_weights">weights</code></td>
<td>
<p>(array): 1-dimensional array of weights vector for variance
reduction. PSPA will estimate the weights if not specified.</p>
</td></tr>
<tr><td><code id="pspa_mean_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Post-prediction adaptive inference
(Miao et al., 2023) <a href="https://arxiv.org/abs/2311.14220">https://arxiv.org/abs/2311.14220</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "mean")

form &lt;- Y - f ~ 1

Y_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

pspa_mean(Y_l, f_l, f_u)

</code></pre>

<hr>
<h2 id='pspa_ols'>PSPA OLS Estimation</h2><span id='topic+pspa_ols'></span>

<h3>Description</h3>

<p>Helper function for PSPA OLS for linear regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pspa_ols(X_l, Y_l, f_l, X_u, f_u, weights = NA, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pspa_ols_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_ols_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="pspa_ols_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_ols_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_ols_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_ols_+3A_weights">weights</code></td>
<td>
<p>(array): p-dimensional array of weights vector for variance
reduction. PSPA will estimate the weights if not specified.</p>
</td></tr>
<tr><td><code id="pspa_ols_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Post-prediction adaptive inference
(Miao et al. 2023) <a href="https://arxiv.org/abs/2311.14220">https://arxiv.org/abs/2311.14220</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "ols")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

pspa_ols(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='pspa_poisson'>PSPA Poisson Regression</h2><span id='topic+pspa_poisson'></span>

<h3>Description</h3>

<p>Helper function for PSPA Poisson regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pspa_poisson(X_l, Y_l, f_l, X_u, f_u, weights = NA, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pspa_poisson_+3A_x_l">X_l</code></td>
<td>
<p>(matrix): n x p matrix of covariates in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_poisson_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of count labeled outcomes.</p>
</td></tr>
<tr><td><code id="pspa_poisson_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of binary predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_poisson_+3A_x_u">X_u</code></td>
<td>
<p>(matrix): N x p matrix of covariates in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_poisson_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of binary predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_poisson_+3A_weights">weights</code></td>
<td>
<p>(array): p-dimensional array of weights vector for variance
reduction. PSPA will estimate the weights if not specified.</p>
</td></tr>
<tr><td><code id="pspa_poisson_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Post-prediction adaptive inference
(Miao et al. 2023) <a href="https://arxiv.org/abs/2311.14220">https://arxiv.org/abs/2311.14220</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "poisson")

form &lt;- Y - f ~ X1

X_l &lt;- model.matrix(form, data = dat[dat$set_label == "labeled",])

Y_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

X_u &lt;- model.matrix(form, data = dat[dat$set_label == "unlabeled",])

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

pspa_poisson(X_l, Y_l, f_l, X_u, f_u)

</code></pre>

<hr>
<h2 id='pspa_quantile'>PSPA Quantile Estimation</h2><span id='topic+pspa_quantile'></span>

<h3>Description</h3>

<p>Helper function for PSPA quantile estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pspa_quantile(Y_l, f_l, f_u, q, weights = NA, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pspa_quantile_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): n-vector of labeled outcomes.</p>
</td></tr>
<tr><td><code id="pspa_quantile_+3A_f_l">f_l</code></td>
<td>
<p>(vector): n-vector of predictions in the labeled data.</p>
</td></tr>
<tr><td><code id="pspa_quantile_+3A_f_u">f_u</code></td>
<td>
<p>(vector): N-vector of predictions in the unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_quantile_+3A_q">q</code></td>
<td>
<p>(float): Quantile to estimate. Must be in the range (0, 1).</p>
</td></tr>
<tr><td><code id="pspa_quantile_+3A_weights">weights</code></td>
<td>
<p>(array): 1-dimensional array of weights vector for variance
reduction. PSPA will estimate the weights if not specified.</p>
</td></tr>
<tr><td><code id="pspa_quantile_+3A_alpha">alpha</code></td>
<td>
<p>(scalar): type I error rate for hypothesis testing - values in
(0, 1); defaults to 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Post-prediction adaptive inference
(Miao et al. 2023) <a href="https://arxiv.org/abs/2311.14220">https://arxiv.org/abs/2311.14220</a>
</p>


<h3>Value</h3>

<p>A list of outputs: estimate of inference model parameters and
corresponding standard error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- simdat(model = "quantile")

form &lt;- Y - f ~ 1

Y_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[1]] |&gt; matrix(ncol = 1)

f_l &lt;- dat[dat$set_label == "labeled",   all.vars(form)[2]] |&gt; matrix(ncol = 1)

f_u &lt;- dat[dat$set_label == "unlabeled", all.vars(form)[2]] |&gt; matrix(ncol = 1)

pspa_quantile(Y_l, f_l, f_u, q = 0.5)

</code></pre>

<hr>
<h2 id='pspa_y'>PSPA M-Estimation for ML-predicted labels</h2><span id='topic+pspa_y'></span>

<h3>Description</h3>

<p><code>pspa_y</code> function conducts post-prediction M-Estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pspa_y(
  X_lab = NA,
  X_unlab = NA,
  Y_lab,
  Yhat_lab,
  Yhat_unlab,
  alpha = 0.05,
  weights = NA,
  quant = NA,
  intercept = FALSE,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pspa_y_+3A_x_lab">X_lab</code></td>
<td>
<p>Array or data.frame containing observed covariates in
labeled data.</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_x_unlab">X_unlab</code></td>
<td>
<p>Array or data.frame containing observed or predicted
covariates in unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_y_lab">Y_lab</code></td>
<td>
<p>Array or data.frame of observed outcomes in
labeled data.</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_yhat_lab">Yhat_lab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in
labeled data.</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_yhat_unlab">Yhat_unlab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in
unlabeled data.</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_alpha">alpha</code></td>
<td>
<p>Specifies the confidence level as 1 - alpha for
confidence intervals.</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_weights">weights</code></td>
<td>
<p>weights vector PSPA linear regression (d-dimensional, where
d equals the number of covariates).</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_intercept">intercept</code></td>
<td>
<p>Boolean indicating if the input covariates' data contains
the intercept (TRUE if the input data contains)</p>
</td></tr>
<tr><td><code id="pspa_y_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary table presenting point estimates, standard error,
confidence intervals (1 - alpha), P-values, and weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data &lt;- sim_data_y()

X_lab &lt;- data$X_lab

X_unlab &lt;- data$X_unlab

Y_lab &lt;- data$Y_lab

Yhat_lab &lt;- data$Yhat_lab

Yhat_unlab &lt;- data$Yhat_unlab

pspa_y(X_lab = X_lab, X_unlab = X_unlab,

 Y_lab = Y_lab, Yhat_lab = Yhat_lab, Yhat_unlab = Yhat_unlab,

 alpha = 0.05, method = "ols")

</code></pre>

<hr>
<h2 id='rectified_cdf'>Rectified CDF</h2><span id='topic+rectified_cdf'></span>

<h3>Description</h3>

<p>Computes the rectified CDF of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rectified_cdf(Y_l, f_l, f_u, grid, w_l = NULL, w_u = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rectified_cdf_+3A_y_l">Y_l</code></td>
<td>
<p>(vector): Gold-standard labels.</p>
</td></tr>
<tr><td><code id="rectified_cdf_+3A_f_l">f_l</code></td>
<td>
<p>(vector): Predictions corresponding to the gold-standard labels.</p>
</td></tr>
<tr><td><code id="rectified_cdf_+3A_f_u">f_u</code></td>
<td>
<p>(vector): Predictions corresponding to the unlabeled data.</p>
</td></tr>
<tr><td><code id="rectified_cdf_+3A_grid">grid</code></td>
<td>
<p>(vector): Grid of values to compute the CDF at.</p>
</td></tr>
<tr><td><code id="rectified_cdf_+3A_w_l">w_l</code></td>
<td>
<p>(vector, optional): Sample weights for the labeled data set.</p>
</td></tr>
<tr><td><code id="rectified_cdf_+3A_w_u">w_u</code></td>
<td>
<p>(vector, optional): Sample weights for the unlabeled data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(vector): Rectified CDF of the data at the specified grid points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Y_l &lt;- c(1, 2, 3, 4, 5)

f_l &lt;- c(1.1, 2.2, 3.3, 4.4, 5.5)

f_u &lt;- c(1.2, 2.3, 3.4)

grid &lt;- seq(0, 6, by = 0.5)

rectified_cdf(Y_l, f_l, f_u, grid)

</code></pre>

<hr>
<h2 id='rectified_p_value'>Rectified P-Value</h2><span id='topic+rectified_p_value'></span>

<h3>Description</h3>

<p>Computes a rectified p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rectified_p_value(
  rectifier,
  rectifier_std,
  imputed_mean,
  imputed_std,
  null = 0,
  alternative = "two-sided"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rectified_p_value_+3A_rectifier">rectifier</code></td>
<td>
<p>(float or vector): Rectifier value.</p>
</td></tr>
<tr><td><code id="rectified_p_value_+3A_rectifier_std">rectifier_std</code></td>
<td>
<p>(float or vector): Rectifier standard deviation.</p>
</td></tr>
<tr><td><code id="rectified_p_value_+3A_imputed_mean">imputed_mean</code></td>
<td>
<p>(float or vector): Imputed mean.</p>
</td></tr>
<tr><td><code id="rectified_p_value_+3A_imputed_std">imputed_std</code></td>
<td>
<p>(float or vector): Imputed standard deviation.</p>
</td></tr>
<tr><td><code id="rectified_p_value_+3A_null">null</code></td>
<td>
<p>(float, optional): Value of the null hypothesis to be tested.
Defaults to <code>0</code>.</p>
</td></tr>
<tr><td><code id="rectified_p_value_+3A_alternative">alternative</code></td>
<td>
<p>(str, optional): Alternative hypothesis, either
'two-sided', 'larger' or 'smaller'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(float or vector): The rectified p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rectifier &lt;- 0.7

rectifier_std &lt;- 0.5

imputed_mean &lt;- 1.5

imputed_std &lt;- 0.3

rectified_p_value(rectifier, rectifier_std, imputed_mean, imputed_std)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+tidy'></span><span id='topic+glance'></span><span id='topic+augment'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+augment">augment</a></code>, <code><a href="generics.html#topic+glance">glance</a></code>, <code><a href="generics.html#topic+tidy">tidy</a></code></p>
</dd>
</dl>

<hr>
<h2 id='Sigma_cal'>Variance-covariance matrix of the estimation equation</h2><span id='topic+Sigma_cal'></span>

<h3>Description</h3>

<p><code>Sigma_cal</code> function for variance-covariance matrix of the
estimation equation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sigma_cal(
  X_lab,
  X_unlab,
  Y_lab,
  Yhat_lab,
  Yhat_unlab,
  w,
  theta,
  quant = NA,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sigma_cal_+3A_x_lab">X_lab</code></td>
<td>
<p>Array or data.frame containing observed covariates in
labeled data.</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_x_unlab">X_unlab</code></td>
<td>
<p>Array or data.frame containing observed or predicted
covariates in unlabeled data.</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_y_lab">Y_lab</code></td>
<td>
<p>Array or data.frame of observed outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_yhat_lab">Yhat_lab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in labeled data.</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_yhat_unlab">Yhat_unlab</code></td>
<td>
<p>Array or data.frame of predicted outcomes in
unlabeled data.</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_w">w</code></td>
<td>
<p>weights vector PSPA linear regression (d-dimensional, where
d equals the number of covariates).</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_theta">theta</code></td>
<td>
<p>parameter theta</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_quant">quant</code></td>
<td>
<p>quantile for quantile estimation</p>
</td></tr>
<tr><td><code id="Sigma_cal_+3A_method">method</code></td>
<td>
<p>indicates the method to be used for M-estimation.
Options include &quot;mean&quot;, &quot;quantile&quot;, &quot;ols&quot;, &quot;logistic&quot;, and &quot;poisson&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>variance-covariance matrix of the estimation equation
</p>

<hr>
<h2 id='sim_data_y'>Simulate the data for testing the functions</h2><span id='topic+sim_data_y'></span>

<h3>Description</h3>

<p><code>sim_data_y</code> for simulation with ML-predicted Y
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_data_y(r = 0.9, binary = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_data_y_+3A_r">r</code></td>
<td>
<p>imputation correlation</p>
</td></tr>
<tr><td><code id="sim_data_y_+3A_binary">binary</code></td>
<td>
<p>simulate binary outcome or not</p>
</td></tr>
</table>


<h3>Value</h3>

<p>simulated data
</p>

<hr>
<h2 id='simdat'>Data generation function for various underlying models</h2><span id='topic+simdat'></span>

<h3>Description</h3>

<p>Data generation function for various underlying models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simdat(
  n = c(300, 300, 300),
  effect = 1,
  sigma_Y = 1,
  model = "ols",
  shift = 0,
  scale = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simdat_+3A_n">n</code></td>
<td>
<p>Integer vector of size 3 indicating the sample sizes in the
training, labeled, and unlabeled data sets, respectively</p>
</td></tr>
<tr><td><code id="simdat_+3A_effect">effect</code></td>
<td>
<p>Regression coefficient for the first variable of interest for
inference. Defaults is 1.</p>
</td></tr>
<tr><td><code id="simdat_+3A_sigma_y">sigma_Y</code></td>
<td>
<p>Residual variance for the generated outcome. Defaults is 1.</p>
</td></tr>
<tr><td><code id="simdat_+3A_model">model</code></td>
<td>
<p>The type of model to be generated. Must be one of
<code>"mean"</code>, <code>"quantile"</code>, <code>"ols"</code>, <code>"logistic"</code>, or
<code>"poisson"</code>. Default is <code>"ols"</code>.</p>
</td></tr>
<tr><td><code id="simdat_+3A_shift">shift</code></td>
<td>
<p>Scalar shift of the predictions for continuous outcomes
(i.e., &quot;mean&quot;, &quot;quantile&quot;, and &quot;ols&quot;). Defaults to 0.</p>
</td></tr>
<tr><td><code id="simdat_+3A_scale">scale</code></td>
<td>
<p>Scaling factor for the predictions for continuous outcomes
(i.e., &quot;mean&quot;, &quot;quantile&quot;, and &quot;ols&quot;). Defaults to 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>simdat</code> function generates three datasets consisting of independent
realizations of <code class="reqn">Y</code> (for <code>model</code> = <code>"mean"</code> or
<code>"quantile"</code>), or <code class="reqn">\{Y, \boldsymbol{X}\}</code> (for <code>model</code> =
<code>"ols"</code>, <code>"logistic"</code>, or <code>"poisson"</code>): a <em>training</em>
dataset of size <code class="reqn">n_t</code>, a <em>labeled</em> dataset of size <code class="reqn">n_l</code>, and
an <em>unlabeled</em> dataset of size <code class="reqn">n_u</code>. These sizes are specified by
the argument <code>n</code>.
</p>
<p>NOTE: In the <em>unlabeled</em> data subset, outcome data are still generated
to facilitate a benchmark for comparison with an &quot;oracle&quot; model that uses
the true <code class="reqn">Y^{\mathcal{U}}</code> values for estimation and inference.
</p>
<p><strong>Generating Data</strong>
</p>
<p>For <code>"mean"</code> and <code>"quantile"</code>, we simulate a continuous outcome,
<code class="reqn">Y \in \mathbb{R}</code>, with mean given by the <code>effect</code> argument and
error variance given by the <code>sigma_y</code> argument.
</p>
<p>For <code>"ols"</code>, <code>"logistic"</code>, or <code>"poisson"</code> models, predictor
data, <code class="reqn">\boldsymbol{X} \in \mathbb{R}^4</code> are simulated such that the
<code class="reqn">i</code>th observation follows a standard multivariate normal distribution
with a zero mean vector and identity covariance matrix:
</p>
<p style="text-align: center;"><code class="reqn">
  \boldsymbol{X_i} = (X_{i1}, X_{i2}, X_{i3}, X_{i4}) \sim \mathcal{N}_4(\boldsymbol{0}, \boldsymbol{I}).
</code>
</p>

<p>For <code>"ols"</code>, a continuous outcome <code class="reqn">Y \in \mathbb{R}</code> is simulated
to depend on <code class="reqn">X_1</code> through a linear term with the effect size specified
by the <code>effect</code> argument, while the other predictors,
<code class="reqn">\boldsymbol{X} \setminus X_1</code>, have nonlinear effects:
</p>
<p style="text-align: center;"><code class="reqn">
  Y_i = effect \times Z_{i1} + \frac{1}{2} Z_{i2}^2 + \frac{1}{3} Z_{i3}^3 + \frac{1}{4} Z_{i4}^2 + \varepsilon_y,
</code>
</p>

<p>and <code class="reqn">\varepsilon_y \sim \mathcal{N}(0, sigma_y)</code>, where the
<code>sigma_y</code> argument specifies the error variance.
</p>
<p>For <code>"logistic"</code>, we simulate:
</p>
<p style="text-align: center;"><code class="reqn">
  \Pr(Y_i = 1 \mid \boldsymbol{X}) = logit^{-1}(effect \times Z_{i1} + \frac{1}{2} Z_{i2}^2 + \frac{1}{3} Z_{i3}^3 + \frac{1}{4} Z_{i4}^2 + \varepsilon_y)
</code>
</p>

<p>and generate:
</p>
<p style="text-align: center;"><code class="reqn">
  Y_i \sim Bern[1, \Pr(Y_i = 1 \mid \boldsymbol{X})]
</code>
</p>

<p>where <code class="reqn">\varepsilon_y \sim \mathcal{N}(0, sigma\_y)</code>.
</p>
<p>For <code>"poisson"</code>, we simulate:
</p>
<p style="text-align: center;"><code class="reqn">
  \lambda_Y = exp(effect \times Z_{i1} + \frac{1}{2} Z_{i2}^2 + \frac{1}{3} Z_{i3}^3 + \frac{1}{4} Z_{i4}^2 + \varepsilon_y)
</code>
</p>

<p>and generate:
</p>
<p style="text-align: center;"><code class="reqn">
  Y_i \sim Poisson(\lambda_Y)
</code>
</p>

<p><strong>Generating Predictions</strong>
</p>
<p>To generate predicted outcomes for <code>"mean"</code> and <code>"quantile"</code>, we
simulate a continuous variable with mean given by the empirical mean of the
training data and error variance given by the <code>sigma_y</code> argument.
</p>
<p>For <code>"ols"</code>, we fit a generalized additive model (GAM) on the
simulated <em>training</em> dataset and calculate predictions for the
<em>labeled</em> and <em>unlabeled</em> datasets as deterministic functions of
<code class="reqn">\boldsymbol{X}</code>. Specifically, we fit the following GAM:
</p>
<p style="text-align: center;"><code class="reqn">
  Y^{\mathcal{T}} = s_0 + s_1(X_1^{\mathcal{T}}) + s_2(X_2^{\mathcal{T}}) +
  s_3(X_3^{\mathcal{T}}) + s_4(X_4^{\mathcal{T}}) + \varepsilon_p,
</code>
</p>

<p>where <code class="reqn">\mathcal{T}</code> denotes the <em>training</em> dataset, <code class="reqn">s_0</code> is an
intercept term, and <code class="reqn">s_1(\cdot)</code>, <code class="reqn">s_2(\cdot)</code>, <code class="reqn">s_3(\cdot)</code>,
and <code class="reqn">s_4(\cdot)</code> are smoothing spline functions for <code class="reqn">X_1</code>, <code class="reqn">X_2</code>,
<code class="reqn">X_3</code>, and <code class="reqn">X_4</code>, respectively, with three target equivalent degrees
of freedom. Residual error is modeled as <code class="reqn">\varepsilon_p</code>.
</p>
<p>Predictions for <em>labeled</em> and <em>unlabeled</em> datasets are calculated
as:
</p>
<p style="text-align: center;"><code class="reqn">
 f(\boldsymbol{X}^{\mathcal{L}\cup\mathcal{U}}) = \hat{s}_0 + \hat{s}_1(X_1^{\mathcal{L}\cup\mathcal{U}}) +
\hat{s}_2(X_2^{\mathcal{L}\cup\mathcal{U}}) + \hat{s}_3(X_3^{\mathcal{L}\cup\mathcal{U}}) +
\hat{s}_4(X_4^{\mathcal{L}\cup\mathcal{U}}),
</code>
</p>

<p>where <code class="reqn">\hat{s}_0, \hat{s}_1, \hat{s}_2, \hat{s}_3</code>, and <code class="reqn">\hat{s}_4</code>
are estimates of <code class="reqn">s_0, s_1, s_2, s_3</code>, and <code class="reqn">s_4</code>, respectively.
</p>
<p>NOTE: For continuous outcomes, we provide optional arguments <code>shift</code> and
<code>scale</code> to further apply a location shift and scaling factor,
respectively, to the predicted outcomes. These default to <code>shift = 0</code>
and <code>scale = 1</code>, i.e., no location shift or scaling.
</p>
<p>For <code>"logistic"</code>, we train k-nearest neighbors (k-NN) classifiers on
the simulated <em>training</em> dataset for values of <code class="reqn">k</code> ranging from 1
to 10. The optimal <code class="reqn">k</code> is chosen via cross-validation, minimizing the
misclassification error on the validation folds. Predictions for the
<em>labeled</em> and <em>unlabeled</em> datasets are obtained by applying the
k-NN classifier with the optimal <code class="reqn">k</code> to <code class="reqn">\boldsymbol{X}</code>.
</p>
<p>Specifically, for each observation in the <em>labeled</em> and <em>unlabeled</em>
datasets:
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{Y} = \operatorname{argmax}_c \sum_{i \in \mathcal{N}_k} I(Y_i = c),
</code>
</p>

<p>where <code class="reqn">\mathcal{N}_k</code> represents the set of <code class="reqn">k</code> nearest neighbors in
the training dataset, <code class="reqn">c</code> indexes the possible classes (0 or 1), and
<code class="reqn">I(\cdot)</code> is an indicator function.
</p>
<p>For <code>"poisson"</code>, we fit a generalized linear model (GLM) with a log link
function to the simulated <em>training</em> dataset. The model is of the form:
</p>
<p style="text-align: center;"><code class="reqn">
  \log(\mu^{\mathcal{T}}) = \gamma_0 + \gamma_1 X_1^{\mathcal{T}} + \gamma_2 X_2^{\mathcal{T}} +
  \gamma_3 X_3^{\mathcal{T}} + \gamma_4 X_4^{\mathcal{T}},
</code>
</p>

<p>where <code class="reqn">\mu^{\mathcal{T}}</code> is the expected count for the response variable
in the <em>training</em> dataset, <code class="reqn">\gamma_0</code> is the intercept, and
<code class="reqn">\gamma_1</code>, <code class="reqn">\gamma_2</code>, <code class="reqn">\gamma_3</code>, and <code class="reqn">\gamma_4</code> are the
regression coefficients for the predictors <code class="reqn">X_1</code>, <code class="reqn">X_2</code>, <code class="reqn">X_3</code>,
and <code class="reqn">X_4</code>, respectively.
</p>
<p>Predictions for the <em>labeled</em> and <em>unlabeled</em> datasets are
calculated as:
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{\mu}^{\mathcal{L} \cup \mathcal{U}} = \exp(\hat{\gamma}_0 + \hat{\gamma}_1 X_1^{\mathcal{L} \cup \mathcal{U}} +
  \hat{\gamma}_2 X_2^{\mathcal{L} \cup \mathcal{U}} + \hat{\gamma}_3 X_3^{\mathcal{L} \cup \mathcal{U}} +
  \hat{\gamma}_4 X_4^{\mathcal{L} \cup \mathcal{U}}),
</code>
</p>

<p>where <code class="reqn">\hat{\gamma}_0</code>, <code class="reqn">\hat{\gamma}_1</code>, <code class="reqn">\hat{\gamma}_2</code>, <code class="reqn">\hat{\gamma}_3</code>,
and <code class="reqn">\hat{\gamma}_4</code> are the estimated coefficients.
</p>


<h3>Value</h3>

<p>A data.frame containing n rows and columns corresponding to
the labeled outcome (Y), the predicted outcome (f), a character variable
(set_label) indicating which data set the observation belongs to (training,
labeled, or unlabeled), and four independent, normally distributed
predictors (X1, X2, X3, and X4), where applicable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-- Mean

dat_mean &lt;- simdat(c(100, 100, 100), effect = 1, sigma_Y = 1,

  model = "mean")

head(dat_mean)

#-- Linear Regression

dat_ols &lt;- simdat(c(100, 100, 100), effect = 1, sigma_Y = 1,

  model = "ols")

head(dat_ols)

</code></pre>

<hr>
<h2 id='summary.ipd'>Summarize IPD Fit</h2><span id='topic+summary.ipd'></span>

<h3>Description</h3>

<p>Produces a summary of the IPD method/model combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ipd'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.ipd_+3A_object">object</code></td>
<td>
<p>An object of class <code>ipd</code>.</p>
</td></tr>
<tr><td><code id="summary.ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the summary function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<dl>
<dt>coefficients</dt><dd><p>Model coefficients and related statistics.</p>
</dd>
<dt>performance</dt><dd><p>Performance metrics of the model fit.</p>
</dd>
<dt>...</dt><dd><p>Additional summary information.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(2023)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- Fit IPD

fit &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

  data = dat, label = "set_label")

#-- Summarize Output

summ_fit &lt;- summary(fit)

summ_fit

</code></pre>

<hr>
<h2 id='tidy.ipd'>Tidy an IPD Fit</h2><span id='topic+tidy.ipd'></span>

<h3>Description</h3>

<p>Tidies the IPD method/model fit into a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ipd'
tidy(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tidy.ipd_+3A_x">x</code></td>
<td>
<p>An object of class <code>ipd</code>.</p>
</td></tr>
<tr><td><code id="tidy.ipd_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the tidy function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tidy data frame of the model's coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-- Generate Example Data

set.seed(2023)

dat &lt;- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)

head(dat)

formula &lt;- Y - f ~ X1

#-- Fit IPD

fit &lt;- ipd(formula, method = "postpi_analytic", model = "ols",

  data = dat, label = "set_label")

#-- Tidy Output

tidy(fit)

</code></pre>

<hr>
<h2 id='wls'>Weighted Least Squares</h2><span id='topic+wls'></span>

<h3>Description</h3>

<p>Computes the weighted least squares estimate of the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wls(X, Y, w = NULL, return_se = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wls_+3A_x">X</code></td>
<td>
<p>(matrix): n x p matrix of covariates.</p>
</td></tr>
<tr><td><code id="wls_+3A_y">Y</code></td>
<td>
<p>(vector): p-vector of outcome values.</p>
</td></tr>
<tr><td><code id="wls_+3A_w">w</code></td>
<td>
<p>(vector, optional): n-vector of sample weights.</p>
</td></tr>
<tr><td><code id="wls_+3A_return_se">return_se</code></td>
<td>
<p>(bool, optional): Whether to return the standard errors of
the coefficients.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>theta</dt><dd><p>(vector): p-vector of weighted least squares estimates of
the coefficients.</p>
</dd>
<dt>se</dt><dd><p>(vector): If return_se == TRUE, return the p-vector of
standard errors of the coefficients.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 1000

X &lt;- rnorm(n, 1, 1)

w &lt;- rep(1, n)

Y &lt;- X + rnorm(n, 0, 1)

wls(X, Y, w = w, return_se = TRUE)

</code></pre>

<hr>
<h2 id='zconfint_generic'>Normal Confidence Intervals</h2><span id='topic+zconfint_generic'></span>

<h3>Description</h3>

<p>Calculates normal confidence intervals for a given alternative at a given
significance level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zconfint_generic(mean, std_mean, alpha, alternative)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zconfint_generic_+3A_mean">mean</code></td>
<td>
<p>(float): Estimated normal mean.</p>
</td></tr>
<tr><td><code id="zconfint_generic_+3A_std_mean">std_mean</code></td>
<td>
<p>(float): Estimated standard error of the mean.</p>
</td></tr>
<tr><td><code id="zconfint_generic_+3A_alpha">alpha</code></td>
<td>
<p>(float): Significance level in [0,1]</p>
</td></tr>
<tr><td><code id="zconfint_generic_+3A_alternative">alternative</code></td>
<td>
<p>(string): Alternative hypothesis, either 'two-sided',
'larger' or 'smaller'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(vector): Lower and upper (1 - alpha) * 100% confidence limits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 1000

Y &lt;- rnorm(n, 1, 1)

se_Y &lt;-  sd(Y) / sqrt(n)

zconfint_generic(Y, se_Y, alpha = 0.05, alternative = "two-sided")

</code></pre>

<hr>
<h2 id='zstat_generic'>Compute Z-Statistic and P-Value</h2><span id='topic+zstat_generic'></span>

<h3>Description</h3>

<p>Computes the z-statistic and the corresponding p-value for a given test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zstat_generic(value1, value2, std_diff, alternative, diff = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zstat_generic_+3A_value1">value1</code></td>
<td>
<p>(numeric): The first value or sample mean.</p>
</td></tr>
<tr><td><code id="zstat_generic_+3A_value2">value2</code></td>
<td>
<p>(numeric): The second value or sample mean.</p>
</td></tr>
<tr><td><code id="zstat_generic_+3A_std_diff">std_diff</code></td>
<td>
<p>(numeric): The standard error of the difference between the
two values.</p>
</td></tr>
<tr><td><code id="zstat_generic_+3A_alternative">alternative</code></td>
<td>
<p>(character): The alternative hypothesis. Can be one of
&quot;two-sided&quot; (or &quot;2-sided&quot;, &quot;2s&quot;), &quot;larger&quot; (or &quot;l&quot;), or &quot;smaller&quot; (or &quot;s&quot;).</p>
</td></tr>
<tr><td><code id="zstat_generic_+3A_diff">diff</code></td>
<td>
<p>(numeric, optional): The hypothesized difference between the
two values. Default is 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(list): A list containing the following:
</p>

<dl>
<dt>zstat</dt><dd><p>(numeric): The computed z-statistic.</p>
</dd>
<dt>pvalue</dt><dd><p>(numeric): The corresponding p-value for the test.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
value1 &lt;- 1.5

value2 &lt;- 1.0

std_diff &lt;- 0.2

alternative &lt;- "two-sided"

result &lt;- zstat_generic(value1, value2, std_diff, alternative)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
