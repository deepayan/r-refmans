<!DOCTYPE html><html><head><title>Help for package dimRed</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dimRed}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.data.frame'><p>Converts to data.frame</p></a></li>
<li><a href='#as.dimRedData'><p>Converts to dimRedData</p></a></li>
<li><a href='#AUC_lnK_R_NX,dimRedResult-method'><p>Method AUC_lnK_R_NX</p></a></li>
<li><a href='#AutoEncoder-class'><p>AutoEncoder</p></a></li>
<li><a href='#cophenetic_correlation,dimRedResult-method'><p>Method cophenetic_correlation</p></a></li>
<li><a href='#dataSets'><p>Example Data Sets for dimensionality reduction</p></a></li>
<li><a href='#DiffusionMaps-class'><p>Diffusion Maps</p></a></li>
<li><a href='#dimRed-package'><p>The dimRed package</p></a></li>
<li><a href='#dimRedData-class'><p>Class &quot;dimRedData&quot;</p></a></li>
<li><a href='#dimRedMethod-class'><p>Class &quot;dimRedMethod&quot;</p></a></li>
<li><a href='#dimRedMethodList'><p>dimRedMethodList</p></a></li>
<li><a href='#dimRedResult-class'><p>Class &quot;dimRedResult&quot;</p></a></li>
<li><a href='#distance_correlation,dimRedResult-method'><p>Method distance_correlation</p></a></li>
<li><a href='#DrL-class'><p>Distributed Recursive Graph Layout</p></a></li>
<li><a href='#DRR-class'><p>Dimensionality Reduction via Regression</p></a></li>
<li><a href='#embed'><p>dispatches the different methods for dimensionality reduction</p></a></li>
<li><a href='#FastICA-class'><p>Independent Component Analysis</p></a></li>
<li><a href='#FruchtermanReingold-class'><p>Fruchterman Reingold Graph Layout</p></a></li>
<li><a href='#getData'><p>Method getData</p></a></li>
<li><a href='#getDimRedData'><p>Method getDimRedData</p></a></li>
<li><a href='#getMeta'><p>Method getMeta</p></a></li>
<li><a href='#getNDim'><p>Method getNDim</p></a></li>
<li><a href='#getOrgData'><p>Method getOrgData</p></a></li>
<li><a href='#getOtherData'><p>Method getOtherData</p></a></li>
<li><a href='#getPars'><p>Method getPars</p></a></li>
<li><a href='#getRotationMatrix'><p>getRotationMatrix</p></a></li>
<li><a href='#HLLE-class'><p>Hessian Locally Linear Embedding</p></a></li>
<li><a href='#installSuggests'><p>getSuggests</p></a></li>
<li><a href='#Isomap-class'><p>Isomap embedding</p></a></li>
<li><a href='#KamadaKawai-class'><p>Graph Embedding via the Kamada Kawai Algorithm</p></a></li>
<li><a href='#kPCA-class'><p>Kernel PCA</p></a></li>
<li><a href='#LaplacianEigenmaps-class'><p>Laplacian Eigenmaps</p></a></li>
<li><a href='#LCMC,dimRedResult-method'><p>Method LCMC</p></a></li>
<li><a href='#makeKNNgraph'><p>makeKNNgraph</p></a></li>
<li><a href='#maximize_correlation,dimRedResult-method'><p>Maximize Correlation with the Axes</p></a></li>
<li><a href='#MDS-class'><p>Metric Dimensional Scaling</p></a></li>
<li><a href='#mean_R_NX,dimRedResult-method'><p>Method mean_R_NX</p></a></li>
<li><a href='#mixColorRamps'><p>Mixing color ramps</p></a></li>
<li><a href='#ndims'><p>Method ndims</p></a></li>
<li><a href='#nMDS-class'><p>Non-Metric Dimensional Scaling</p></a></li>
<li><a href='#NNMF-class'><p>Non-Negative Matrix Factorization</p></a></li>
<li><a href='#PCA_L1-class'><p>Principal Component Analysis with L1 error.</p></a></li>
<li><a href='#PCA-class'><p>Principal Component Analysis</p></a></li>
<li><a href='#plot'><p>Plotting of dimRed* objects</p></a></li>
<li><a href='#plot_R_NX'><p>plot_R_NX</p></a></li>
<li><a href='#print'><p>Method print</p></a></li>
<li><a href='#Q_global,dimRedResult-method'><p>Method Q_global</p></a></li>
<li><a href='#Q_local,dimRedResult-method'><p>Method Q_local</p></a></li>
<li><a href='#Q_NX,dimRedResult-method'><p>Method Q_NX</p></a></li>
<li><a href='#quality,dimRedResult-method'><p>Quality Criteria for dimensionality reduction.</p></a></li>
<li><a href='#R_NX,dimRedResult-method'><p>Method R_NX</p></a></li>
<li><a href='#reconstruction_error,dimRedResult-method'><p>Method reconstruction_error</p></a></li>
<li><a href='#reconstruction_rmse,dimRedResult-method'><p>Method reconstruction_rmse</p></a></li>
<li><a href='#total_correlation,dimRedResult-method'><p>Method total_correlation</p></a></li>
<li><a href='#tSNE-class'><p>t-Distributed Stochastic Neighborhood Embedding</p></a></li>
<li><a href='#UMAP-class'><p>Umap embedding</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Framework for Dimensionality Reduction</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.6</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of dimensionality reduction
    techniques from R packages and a common
    interface for calling the methods.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), DRR</td>
</tr>
<tr>
<td>Imports:</td>
<td>magrittr, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>NMF, MASS, Matrix, RANN, RSpectra, Rtsne, cccd, coRanking,
diffusionMap, energy, fastICA, ggplot2, graphics, igraph,
keras, kernlab, knitr, loe, optimx, pcaL1, pcaPP, reticulate,
rgl, scales, scatterplot3d, stats, tensorflow, testthat, tidyr,
tinytex, umap, vegan</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gdkrmr/dimRed/issues">https://github.com/gdkrmr/dimRed/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.guido-kraemer.com/software/dimred/">https://www.guido-kraemer.com/software/dimred/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Collate:</td>
<td>'dimRedMethod-class.R' 'misc.R' 'dimRedData-class.R'
'dimRedResult-class.R' 'autoencoder.R' 'dataSets.R' 'diffmap.R'
'dimRed.R' 'drr.R' 'embed.R' 'fastica.R' 'get_info.R'
'graph_embed.R' 'hlle.R' 'isomap.R' 'kpca.R' 'l1pca.R' 'leim.R'
'lle.R' 'loe.R' 'mds.R' 'mixColorSpaces.R' 'nmds.R' 'nnmf.R'
'pca.R' 'plot.R' 'quality.R' 'rotate.R' 'soe.R' 'tsne.R'
'umap.R'</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-10 15:28:57 UTC; gkraemer</td>
</tr>
<tr>
<td>Author:</td>
<td>Guido Kraemer [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Guido Kraemer &lt;guido.kraemer@uni-leipzig.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-11 12:40:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.data.frame'>Converts to data.frame</h2><span id='topic+as.data.frame'></span>

<h3>Description</h3>

<p>General conversions of objects created by <code>dimRed</code> to <code>data.frame</code>.
See class documentations for details (<code><a href="#topic+dimRedData">dimRedData</a></code>,
<code><a href="#topic+dimRedResult">dimRedResult</a></code>). For the documentation of this function in base
package, see here: <code><a href="base.html#topic+as.data.frame.default">as.data.frame.default</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.data.frame(x, row.names, optional, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame_+3A_x">x</code></td>
<td>
<p>The object to be converted</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_row.names">row.names</code></td>
<td>
<p>unused in <code>dimRed</code></p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_optional">optional</code></td>
<td>
<p>unused in <code>dimRed</code></p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='as.dimRedData'>Converts to dimRedData</h2><span id='topic+as.dimRedData'></span><span id='topic+as.dimRedData+2Cformula-method'></span>

<h3>Description</h3>

<p>Conversion functions to dimRedData.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.dimRedData(formula, ...)

## S4 method for signature 'formula'
as.dimRedData(formula, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.dimRedData_+3A_formula">formula</code></td>
<td>
<p>The formula, left hand side is assigned to the meta slot right
hand side is assigned to the data slot.</p>
</td></tr>
<tr><td><code id="as.dimRedData_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
<tr><td><code id="as.dimRedData_+3A_data">data</code></td>
<td>
<p>Will be coerced into a <code><a href="base.html#topic+data.frame">data.frame</a></code> with
<code><a href="#topic+as.data.frame">as.data.frame</a></code></p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>formula</code>: Convert a <code>data.frame</code> to a dimRedData
object using a formula
</p>
</li></ul>


<h3>See Also</h3>

<p>Other dimRedData: 
<code><a href="#topic+dimRedData-class">dimRedData-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## create a dimRedData object using a formula
as.dimRedData(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
              iris)[1:5]

</code></pre>

<hr>
<h2 id='AUC_lnK_R_NX+2CdimRedResult-method'>Method AUC_lnK_R_NX</h2><span id='topic+AUC_lnK_R_NX+2CdimRedResult-method'></span><span id='topic+AUC_lnK_R_NX'></span>

<h3>Description</h3>

<p>Calculate the Area under the R_NX(ln K), used in Lee et. al. (2015). Note
that despite the name, this does not weight the mean by the logarithm, but by
1/K. If explicit weighting by the logarithm is desired use <code>weight =
"log"</code> or <code>weight = "log10"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
AUC_lnK_R_NX(object, weight = "inv")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_lnK_R_NX+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
<tr><td><code id="AUC_lnK_R_NX+2B2CdimRedResult-method_+3A_weight">weight</code></td>
<td>
<p>the weight function used, one of <code>c("inv", "log", "log10")</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The naming confusion originated from equation 17 in Lee et al (2015) and the
name of this method may change in the future to avoid confusion.
</p>


<h3>References</h3>

<p>Lee, J.A., Peluffo-Ordonez, D.H., Verleysen, M., 2015.
Multi-scale similarities in stochastic neighbour embedding: Reducing
dimensionality while preserving both local and global structure.
Neurocomputing 169, 246-261. https://doi.org/10.1016/j.neucom.2014.12.095
</p>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='AutoEncoder-class'>AutoEncoder</h2><span id='topic+AutoEncoder-class'></span><span id='topic+AutoEncoder'></span>

<h3>Description</h3>

<p>An S4 Class implementing an Autoencoder
</p>


<h3>Details</h3>

<p>Autoencoders are neural networks that try to reproduce their input. Consider
this method unstable, as the internals may still be changed.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>Autoencoder can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of dimensions for reduction.</p>
</dd>
<dt>n_hidden</dt><dd><p>The number of neurons in the hidden
layers, the length specifies the number of layers,
the length must be impair, the middle number must
be the same as ndim.</p>
</dd>
<dt>activation</dt><dd><p>The activation functions for the layers,
one of &quot;tanh&quot;, &quot;sigmoid&quot;, &quot;relu&quot;, &quot;elu&quot;, everything
else will silently be ignored and there will be no
activation function for the layer.</p>
</dd>
<dt>weight_decay</dt><dd><p>the coefficient for weight decay,
set to 0 if no weight decay desired.</p>
</dd>
<dt>learning_rate</dt><dd><p>The learning rate for gradient descend</p>
</dd>
<dt>graph</dt><dd><p>Optional: A list of bits and pieces that define the
autoencoder in tensorflow, see details.</p>
</dd>
<dt>keras_graph</dt><dd><p>Optional: A list of keras layers that define
the encoder and decoder, specifying this, will ignore all
other topology related variables, see details.</p>
</dd>
<dt>batchsize</dt><dd><p>If NA, all data will be used for training,
else only a random subset of size batchsize will be used</p>
</dd>
<dt>n_steps</dt><dd><p>the number of training steps.</p>
</dd>
</dl>



<h3>Details</h3>

<p>There are several ways to specify an autoencoder, the simplest is to pass the
number of neurons per layer in <code>n_hidden</code>, this must be a vector of
integers of impair length and it must be symmetric and the middle number must
be equal to <code>ndim</code>, For every layer an activation function can be
specified with <code>activation</code>.
</p>
<p>For regularization weight decay can be specified by setting
<code>weight_decay</code> &gt; 0.
</p>
<p>Currently only a gradient descent optimizer is used, the learning rate can be
specified by setting <code>learning_rate</code>.
The learner can operate on batches if <code>batchsize</code> is not <code>NA</code>.
The number of steps the learner uses is specified using <code>n_steps</code>.
</p>


<h3>Further training a model</h3>

<p>If the model did not converge in the first training phase or training with
different data is desired, the <code><a href="#topic+dimRedResult">dimRedResult</a></code> object may be
passed as <code>autoencoder</code> parameter; In this case all topology related
parameters will be ignored.
</p>


<h3>Using Keras layers</h3>

<p>The encoder and decoder part can be specified using a list of <span class="pkg">keras</span>
layers. This requires a list with two entries, <code>encoder</code> should contain
a LIST of keras layers WITHOUT the <code><a href="keras.html#topic+layer_input">layer_input</a></code>
that will be concatenated in order to form the encoder part.
<code>decoder</code> should be
defined accordingly, the output of <code>decoder</code> must have the same number
of dimensions as the input data.
</p>


<h3>Using Tensorflow</h3>

<p>The model can be entirely defined in <span class="pkg">tensorflow</span>, it must contain a
list with the following entries:
</p>

<dl>
<dt>encoder</dt><dd><p>A tensor that defines the encoder.</p>
</dd>
<dt>decoder</dt><dd><p>A tensor that defines the decoder.</p>
</dd>
<dt>network</dt><dd><p>A tensor that defines the reconstruction (encoder + decoder).</p>
</dd>
<dt>loss</dt><dd><p>A tensor that calculates the loss (network + loss function).</p>
</dd>
<dt>in_data</dt><dd><p>A <code>placeholder</code> that points to the data input of
the network AND the encoder.</p>
</dd>
<dt>in_decoder</dt><dd><p>A <code>placeholder</code> that points to the input of
the decoder.</p>
</dd>
<dt>session</dt><dd><p>A <span class="pkg">tensorflow</span> <code>Session</code> object that holds
the values of the tensors.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Uses <span class="pkg">tensorflow</span> as a backend, for details an
problems relating tensorflow, see <a href="https://tensorflow.rstudio.com">https://tensorflow.rstudio.com</a>.
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- loadDataSet("3D S Curve")

emb &lt;- embed(dat, "AutoEncoder")

# predicting is possible:
samp &lt;- sample(floor(nrow(dat) / 10))
emb2 &lt;- embed(dat[samp])
emb3 &lt;- predict(emb2, dat[-samp])

plot(emb, type = "2vars")
plot(emb2, type = "2vars")
points(getData(emb3))

## End(Not run)

</code></pre>

<hr>
<h2 id='cophenetic_correlation+2CdimRedResult-method'>Method cophenetic_correlation</h2><span id='topic+cophenetic_correlation+2CdimRedResult-method'></span><span id='topic+cophenetic_correlation'></span>

<h3>Description</h3>

<p>Calculate the correlation between the distance matrices in high and
low dimensioal space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
cophenetic_correlation(object, d = stats::dist, cor_method = "pearson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cophenetic_correlation+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
<tr><td><code id="cophenetic_correlation+2B2CdimRedResult-method_+3A_d">d</code></td>
<td>
<p>the distance function to use.</p>
</td></tr>
<tr><td><code id="cophenetic_correlation+2B2CdimRedResult-method_+3A_cor_method">cor_method</code></td>
<td>
<p>The correlation method.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='dataSets'>Example Data Sets for dimensionality reduction</h2><span id='topic+dataSets'></span><span id='topic+loadDataSet'></span><span id='topic+dataSetList'></span>

<h3>Description</h3>

<p>A compilation of standard data sets that are often being used to
showcase dimensionality reduction techniques.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadDataSet(name = dataSetList(), n = 2000, sigma = 0.05)

dataSetList()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataSets_+3A_name">name</code></td>
<td>
<p>A character vector that specifies the name of the data
set.</p>
</td></tr>
<tr><td><code id="dataSets_+3A_n">n</code></td>
<td>
<p>In generated data sets the number of points to be
generated, else ignored.</p>
</td></tr>
<tr><td><code id="dataSets_+3A_sigma">sigma</code></td>
<td>
<p>In generated data sets the standard deviation of the
noise added, else ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>name</code> should be one of
<code>dataSetList()</code>. Partial matching is possible, see
<code><a href="base.html#topic+match.arg">match.arg</a></code>. Generated data sets contain the internal
coordinates of the manifold in the <code>meta</code> slot.  Call
<code>dataSetList()</code> to see what data sets are available.
</p>


<h3>Value</h3>

<p><code>loadDataSet</code> an object of class
<code><a href="#topic+dimRedData">dimRedData</a></code>. <code>dataSetList()</code> return a
character string with the implemented data sets
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a list of available data sets:
dataSetList()

## Load a data set:
swissRoll &lt;- loadDataSet("Swiss Roll")

if(requireNamespace("scatterplot3d", quietly = TRUE))
  plot(swissRoll, type = "3vars")


## Load Iris data set, partial matching:
loadDataSet("I")

</code></pre>

<hr>
<h2 id='DiffusionMaps-class'>Diffusion Maps</h2><span id='topic+DiffusionMaps-class'></span><span id='topic+DiffusionMaps'></span>

<h3>Description</h3>

<p>An S4 Class implementing Diffusion Maps
</p>


<h3>Details</h3>

<p>Diffusion Maps uses a diffusion probability matrix to robustly
approximate a manifold.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>Diffusion Maps can take the following parameters:
</p>

<dl>
<dt>d</dt><dd><p>a function transforming a matrix row wise into a
distance matrix or <code>dist</code> object,
e.g. <code><a href="stats.html#topic+dist">dist</a></code>.</p>
</dd>
<dt>ndim</dt><dd><p>The number of dimensions</p>
</dd>
<dt>eps</dt><dd><p>The epsilon parameter that determines the
diffusion weight matrix from a distance matrix <code>d</code>,
<code class="reqn">exp(-d^2/eps)</code>, if set to <code>"auto"</code> it will
be set to the median distance to the 0.01*n nearest
neighbor.</p>
</dd>
<dt>t</dt><dd><p>Time-scale parameter. The recommended value, 0,
uses multiscale geometry.</p>
</dd>
<dt>delta</dt><dd><p>Sparsity cut-off for the symmetric graph Laplacian,
a higher value results in more sparsity and faster calculation.
The predefined value is 10^-5.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="diffusionMap.html#topic+diffuse">diffuse</a></code>, see there for
details. It uses the notation of Richards et al. (2009) which is
slightly different from the one in the original paper (Coifman and
Lafon, 2006) and there is no <code class="reqn">\alpha</code> parameter.
There is also an out-of-sample extension, see examples.
</p>


<h3>References</h3>

<p>Richards, J.W., Freeman, P.E., Lee, A.B., Schafer,
C.M., 2009. Exploiting Low-Dimensional Structure in
Astronomical Spectra. ApJ 691,
32. doi:10.1088/0004-637X/691/1/32
</p>
<p>Coifman, R.R., Lafon, S., 2006. Diffusion maps. Applied and
Computational Harmonic Analysis 21,
5-30. doi:10.1016/j.acha.2006.04.006
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("diffusionMap", quietly = TRUE)) {
dat &lt;- loadDataSet("3D S Curve", n = 300)
emb &lt;- embed(dat, "DiffusionMaps")

plot(emb, type = "2vars")

# predicting is possible:
samp &lt;- sample(floor(nrow(dat) / 10))
emb2 &lt;- embed(dat[samp])
emb3 &lt;- predict(emb2, dat[-samp])

plot(emb2, type = "2vars")
points(getData(emb3))
}
</code></pre>

<hr>
<h2 id='dimRed-package'>The dimRed package</h2><span id='topic+dimRed'></span><span id='topic+dimRed-package'></span>

<h3>Description</h3>

<p>This package simplifies dimensionality reduction in R by
providing a framework of S4 classes and methods. dimRed collects
dimensionality reduction methods that are implemented in R and implements
others. It gives them a common interface and provides plotting
functions for visualization and functions for quality assessment.
</p>
<p>Funding provided by the Department for Biogeochemical Integration,
Empirical Inference of the Earth System Group, at the Max Plack
Institute for Biogeochemistry, Jena.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Guido Kraemer <a href="mailto:guido.kraemer@uni-leipzig.de">guido.kraemer@uni-leipzig.de</a>
</p>


<h3>References</h3>

<p>Lee, J.A., Renard, E., Bernard, G., Dupont, P., Verleysen, M.,
2013. Type 1 and 2 mixtures of Kullback-Leibler divergences as cost
functions in dimensionality reduction based on similarity
preservation. Neurocomputing. 112,
92-107. doi:10.1016/j.neucom.2012.12.036
</p>
<p>Lee, J.A., Lee, J.A., Verleysen, M., 2008. Rank-based quality
assessment of nonlinear dimensionality reduction. Proceedings of
ESANN 2008 49-54.
</p>
<p>Chen, L., Buja, A., 2006. Local Multidimensional Scaling for
Nonlinear Dimension Reduction, Graph Layout and Proximity Analysis.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://www.guido-kraemer.com/software/dimred/">https://www.guido-kraemer.com/software/dimred/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/gdkrmr/dimRed/issues">https://github.com/gdkrmr/dimRed/issues</a>
</p>
</li></ul>


<hr>
<h2 id='dimRedData-class'>Class &quot;dimRedData&quot;</h2><span id='topic+dimRedData-class'></span><span id='topic+dimRedData'></span><span id='topic+as.data.frame+2CdimRedData-method'></span><span id='topic+getData+2CdimRedData-method'></span><span id='topic+getMeta+2CdimRedData-method'></span><span id='topic+nrow+2CdimRedData-method'></span><span id='topic++5B+2CdimRedData+2CANY+2CANY+2CANY-method'></span><span id='topic+ndims+2CdimRedData-method'></span>

<h3>Description</h3>

<p>A class to hold data for dimensionality reduction and methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedData'
as.data.frame(x, meta.prefix = "meta.", data.prefix = "")

## S4 method for signature 'dimRedData'
getData(object)

## S4 method for signature 'dimRedData'
getMeta(object)

## S4 method for signature 'dimRedData'
nrow(x)

## S4 method for signature 'dimRedData,ANY,ANY,ANY'
x[i]

## S4 method for signature 'dimRedData'
ndims(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimRedData-class_+3A_x">x</code></td>
<td>
<p>Of class dimRedData</p>
</td></tr>
<tr><td><code id="dimRedData-class_+3A_meta.prefix">meta.prefix</code></td>
<td>
<p>Prefix for the columns of the meta data names.</p>
</td></tr>
<tr><td><code id="dimRedData-class_+3A_data.prefix">data.prefix</code></td>
<td>
<p>Prefix for the columns of the variable names.</p>
</td></tr>
<tr><td><code id="dimRedData-class_+3A_object">object</code></td>
<td>
<p>Of class dimRedData.</p>
</td></tr>
<tr><td><code id="dimRedData-class_+3A_i">i</code></td>
<td>
<p>a valid index for subsetting rows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The class hast two slots, <code>data</code> and <code>meta</code>. The
<code>data</code> slot contains a <code>numeric matrix</code> with variables in
columns and observations in rows. The <code>meta</code> slot may contain
a <code>data.frame</code> with additional information. Both slots need to
have the same number of rows or the <code>meta</code> slot needs to
contain an empty <code>data.frame</code>.
</p>
<p>See examples for easy conversion from and to <code>data.frame</code>.
</p>
<p>For plotting functions see <code><a href="#topic+plot.dimRedData">plot.dimRedData</a></code>.
</p>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>as.data.frame</code>: convert to data.frame
</p>
</li>
<li> <p><code>getData</code>: Get the data slot.
</p>
</li>
<li> <p><code>getMeta</code>: Get the meta slot.
</p>
</li>
<li> <p><code>nrow</code>: Get the number of observations.
</p>
</li>
<li> <p><code>[</code>: Subset rows.
</p>
</li>
<li> <p><code>ndims</code>: Extract the number of Variables from the data.
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>data</code></dt><dd><p>of class <code>matrix</code>, holds the data, observations in
rows, variables in columns</p>
</dd>
<dt><code>meta</code></dt><dd><p>of class <code>data.frame</code>, holds meta data such as
classes, internal manifold coordinates, or simply additional
data of the data set. Must have the same number of rows as the
<code>data</code> slot or be an empty data frame.</p>
</dd>
</dl>


<h3>See Also</h3>

<p>Other dimRedData: 
<code><a href="#topic+as.dimRedData">as.dimRedData</a>()</code>
</p>
<p>Other dimRedData: 
<code><a href="#topic+as.dimRedData">as.dimRedData</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load an example data set:
s3d &lt;- loadDataSet("3D S Curve")

## Create using a constructor:

### without meta information:
dimRedData(iris[, 1:4])

### with meta information:
dimRedData(iris[, 1:4], iris[, 5])

### using slot names:
dimRedData(data = iris[, 1:4], meta = iris[, 5])

## Convert to a dimRedData objects:
Iris &lt;- as(iris[, 1:4], "dimRedData")

## Convert to data.frame:
head(as(s3d, "data.frame"))
head(as.data.frame(s3d))
head(as.data.frame(as(iris[, 1:4], "dimRedData")))

## Extract slots:
head(getData(s3d))
head(getMeta(s3d))

## Get the number of observations:
nrow(s3d)

## Subset:
s3d[1:5, ]

## Shuffle data:
s3 &lt;- s3d[nrow(s3d)]

## Get the number of variables:
ndims(s3d)

</code></pre>

<hr>
<h2 id='dimRedMethod-class'>Class &quot;dimRedMethod&quot;</h2><span id='topic+dimRedMethod-class'></span>

<h3>Description</h3>

<p>A virtual class &quot;dimRedMethod&quot; to serve as a template to implement
methods for dimensionality reduction.
</p>


<h3>Details</h3>

<p>Implementations of dimensionality reductions should inherit from
this class.
</p>
<p>The <code>fun</code> slot should be a function that takes three arguments
</p>

<dl>
<dt>data</dt><dd><p>An object of class <code><a href="#topic+dimRedData">dimRedData</a></code>.</p>
</dd>
<dt>pars</dt><dd><p>A list with the standard parameters.</p>
</dd>
<dt>keep.org.data</dt><dd><p>Logical. If the original data should be kept in the output.</p>
</dd>
</dl>

<p>and returns an object of class <code><a href="#topic+dimRedResult">dimRedResult</a></code>.
</p>
<p>The <code>stdpars</code> slot should take a list that contains standard
parameters for the implemented methods.
</p>
<p>This way the method can be called by <code>embed(data, "method-name",
...)</code>, where <code>...</code> can be used to to change single parameters.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>A list with the default parameters for the <code>fun</code> slot.</p>
</dd>
<dt><code>requires</code></dt><dd><p>A vector with all packages R packages that need to be
installed to run the method. In some occasions a method may work without
one of the packages. Does not include Python dependencies such as
Tensorflow. Used to auto skip tests</p>
</dd>
</dl>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>

<hr>
<h2 id='dimRedMethodList'>dimRedMethodList</h2><span id='topic+dimRedMethodList'></span>

<h3>Description</h3>

<p>Get the names of all methods for dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimRedMethodList(filter = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimRedMethodList_+3A_filter">filter</code></td>
<td>
<p>filter methods by methods that have their dependencies installed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the name of all classes that inherit from
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code> to use with <code><a href="#topic+embed">embed</a></code>.
</p>


<h3>Value</h3>

<p>a character vector with the names of classes that inherit
from <code>dimRedMethod</code>.
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dimRedMethodList()

</code></pre>

<hr>
<h2 id='dimRedResult-class'>Class &quot;dimRedResult&quot;</h2><span id='topic+dimRedResult-class'></span><span id='topic+dimRedResult'></span><span id='topic+predict+2CdimRedResult-method'></span><span id='topic+inverse+2CdimRedResult-method'></span><span id='topic+inverse'></span><span id='topic+as.data.frame+2CdimRedResult-method'></span><span id='topic+getPars+2CdimRedResult-method'></span><span id='topic+getNDim+2CdimRedResult-method'></span><span id='topic+print+2CdimRedResult-method'></span><span id='topic+getOrgData+2CdimRedResult-method'></span><span id='topic+getDimRedData+2CdimRedResult-method'></span><span id='topic+ndims+2CdimRedResult-method'></span><span id='topic+getOtherData+2CdimRedResult-method'></span>

<h3>Description</h3>

<p>A class to hold the results of of a dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
predict(object, xnew)

## S4 method for signature 'dimRedResult'
inverse(object, ynew)

## S4 method for signature 'dimRedResult'
as.data.frame(
  x,
  org.data.prefix = "org.",
  meta.prefix = "meta.",
  data.prefix = ""
)

## S4 method for signature 'dimRedResult'
getPars(object)

## S4 method for signature 'dimRedResult'
getNDim(object)

## S4 method for signature 'dimRedResult'
print(x)

## S4 method for signature 'dimRedResult'
getOrgData(object)

## S4 method for signature 'dimRedResult'
getDimRedData(object)

## S4 method for signature 'dimRedResult'
ndims(object)

## S4 method for signature 'dimRedResult'
getOtherData(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimRedResult-class_+3A_object">object</code></td>
<td>
<p>Of class <code>dimRedResult</code></p>
</td></tr>
<tr><td><code id="dimRedResult-class_+3A_xnew">xnew</code></td>
<td>
<p>new data, of type <code><a href="#topic+dimRedData">dimRedData</a></code></p>
</td></tr>
<tr><td><code id="dimRedResult-class_+3A_ynew">ynew</code></td>
<td>
<p>embedded data, of type <code><a href="#topic+dimRedData">dimRedData</a></code></p>
</td></tr>
<tr><td><code id="dimRedResult-class_+3A_x">x</code></td>
<td>
<p>Of class <code>dimRedResult</code></p>
</td></tr>
<tr><td><code id="dimRedResult-class_+3A_org.data.prefix">org.data.prefix</code></td>
<td>
<p>Prefix for the columns of the org.data slot.</p>
</td></tr>
<tr><td><code id="dimRedResult-class_+3A_meta.prefix">meta.prefix</code></td>
<td>
<p>Prefix for the columns of <code>x@data@meta</code>.</p>
</td></tr>
<tr><td><code id="dimRedResult-class_+3A_data.prefix">data.prefix</code></td>
<td>
<p>Prefix for the columns of <code>x@data@data</code>.</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>predict</code>: apply a trained method to new data, does not work
with all methods, will give an error if there is no <code>apply</code>.
In some cases the apply function may only be an approximation.
</p>
</li>
<li> <p><code>inverse</code>: inverse transformation of embedded data, does not
work with all methods, will give an error if there is no <code>inverse</code>.
In some cases the apply function may only be an approximation.
</p>
</li>
<li> <p><code>as.data.frame</code>: convert to <code>data.frame</code>
</p>
</li>
<li> <p><code>getPars</code>: Get the parameters with which the method
was called.
</p>
</li>
<li> <p><code>getNDim</code>: Get the number of embedding dimensions.
</p>
</li>
<li> <p><code>print</code>: Method for printing.
</p>
</li>
<li> <p><code>getOrgData</code>: Get the original data and meta.data
</p>
</li>
<li> <p><code>getDimRedData</code>: Get the embedded data
</p>
</li>
<li> <p><code>ndims</code>: Extract the number of embedding dimensions.
</p>
</li>
<li> <p><code>getOtherData</code>: Get other data produced by the method
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>data</code></dt><dd><p>Output data of class dimRedData.</p>
</dd>
<dt><code>org.data</code></dt><dd><p>original data, a matrix.</p>
</dd>
<dt><code>apply</code></dt><dd><p>a function to apply the method to out-of-sampledata,
may not exist.</p>
</dd>
<dt><code>inverse</code></dt><dd><p>a function to calculate the original coordinates from
reduced space, may not exist.</p>
</dd>
<dt><code>has.org.data</code></dt><dd><p>logical, if the original data is included in the object.</p>
</dd>
<dt><code>has.apply</code></dt><dd><p>logical, if a forward method is exists.</p>
</dd>
<dt><code>has.inverse</code></dt><dd><p>logical if an inverse method exists.</p>
</dd>
<dt><code>method</code></dt><dd><p>saves the method used.</p>
</dd>
<dt><code>pars</code></dt><dd><p>saves the parameters used.</p>
</dd>
<dt><code>other.data</code></dt><dd><p>other data produced by the method, e.g. a distance matrix.</p>
</dd>
</dl>


<h3>Examples</h3>

<pre><code class='language-R'>## Create object by embedding data
iris.pca &lt;- embed(loadDataSet("Iris"), "PCA")

## Convert the result to a data.frame
head(as(iris.pca, "data.frame"))
head(as.data.frame(iris.pca))

## There are no nameclashes to avoid here:
head(as.data.frame(iris.pca,
                   org.data.prefix = "",
                   meta.prefix     = "",
                   data.prefix     = ""))

## Print it more or less nicely:
print(iris.pca)

## Get the embedded data as a dimRedData object:
getDimRedData(iris.pca)

## Get the original data including meta information:
getOrgData(iris.pca)

## Get the number of variables:
ndims(iris.pca)

</code></pre>

<hr>
<h2 id='distance_correlation+2CdimRedResult-method'>Method distance_correlation</h2><span id='topic+distance_correlation+2CdimRedResult-method'></span><span id='topic+distance_correlation'></span>

<h3>Description</h3>

<p>Calculate the distance correlation between the distance matrices in
high and low dimensioal space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
distance_correlation(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distance_correlation+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='DrL-class'>Distributed Recursive Graph Layout</h2><span id='topic+DrL-class'></span><span id='topic+DrL'></span>

<h3>Description</h3>

<p>An S4 Class implementing Distributed recursive Graph Layout.
</p>


<h3>Details</h3>

<p>DrL uses a complex algorithm to avoid local minima in the graph
embedding which uses several steps.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>DrL can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of dimensions, defaults to 2. Can only be 2 or 3</p>
</dd>
<dt>knn</dt><dd><p>Reduce the graph to keep only the neares neighbors. Defaults to 100.</p>
</dd>
<dt>d</dt><dd><p>The distance function to determine the weights of the graph edges. Defaults to euclidean distances.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="igraph.html#topic+layout_with_drl">layout_with_drl</a></code>. The parameters
maxiter, epsilon and kkconst are set to the default values and
cannot be set, this may change in a future release. The DimRed
Package adds an extra sparsity parameter by constructing a knn
graph which also may improve visualization quality.
</p>


<h3>References</h3>

<p>Martin, S., Brown, W.M., Wylie, B.N., 2007. Dr.l: Distributed Recursive
(graph) Layout (No. dRl; 002182MLTPL00). Sandia National Laboratories.
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if(requireNamespace(c("igraph", "coRanking"), quietly = TRUE)) {

dat &lt;- loadDataSet("Swiss Roll", n = 200)
emb &lt;- embed(dat, "DrL")
plot(emb, type = "2vars")
}


## End(Not run)

</code></pre>

<hr>
<h2 id='DRR-class'>Dimensionality Reduction via Regression</h2><span id='topic+DRR-class'></span><span id='topic+DRR'></span>

<h3>Description</h3>

<p>An S4 Class implementing Dimensionality Reduction via Regression (DRR).
</p>


<h3>Details</h3>

<p>DRR is a non-linear extension of PCA that uses Kernel Ridge regression.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>DRR can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of dimensions</p>
</dd>
<dt>lambda</dt><dd><p>The regularization parameter for the ridge
regression.</p>
</dd>
<dt>kernel</dt><dd><p>The kernel to use for KRR, defaults to
<code>"rbfdot"</code>.</p>
</dd>
<dt>kernel.pars</dt><dd><p>A list with kernel parameters, elements depend
on the kernel used, <code>"rbfdot"</code> uses <code>"sigma"</code>.</p>
</dd>
<dt>pca</dt><dd><p>logical, should an initial pca step be performed,
defaults to <code>TRUE</code>.</p>
</dd>
<dt>pca.center</dt><dd><p>logical, should the data be centered before the
pca step. Defaults to <code>TRUE</code>.</p>
</dd>
<dt>pca.scale</dt><dd><p>logical, should the data be scaled before the
pca ste. Defaults to <code>FALSE</code>.</p>
</dd>
<dt>fastcv</dt><dd><p>logical, should <code><a href="CVST.html#topic+fastCV">fastCV</a></code> from the
CVST package be used instead of normal cross-validation.</p>
</dd>
<dt>fastcv.test</dt><dd><p>If <code>fastcv = TRUE</code>, separate test data set for fastcv.</p>
</dd>
<dt>cv.folds</dt><dd><p>if <code>fastcv = FALSE</code>, specifies the number of
folds for crossvalidation.</p>
</dd>
<dt>fastkrr.nblocks</dt><dd><p>integer, higher values sacrifice numerical
accuracy for speed and less memory, see below for details.</p>
</dd>
<dt>verbose</dt><dd><p>logical, should the cross-validation results be
printed out.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="DRR.html#topic+drr">drr</a></code>, see there for details. DRR is
a non-linear extension of principal components analysis using Kernel
Ridge Regression (KRR, details see <code><a href="CVST.html#topic+constructKRRLearner">constructKRRLearner</a></code>
and <code><a href="DRR.html#topic+constructFastKRRLearner">constructFastKRRLearner</a></code>). Non-linear
regression is used to explain more variance than PCA. DRR provides
an out-of-sample extension and a backward projection.
</p>
<p>The most expensive computations are matrix inversions therefore the
implementation profits a lot from a multithreaded BLAS library.
The best parameters for each KRR are determined by cross-validaton
over all parameter combinations of <code>lambda</code> and
<code>kernel.pars</code>, using less parameter values will speed up
computation time. Calculation of KRR can be accelerated by
increasing <code>fastkrr.nblocks</code>, it should be smaller than
n^1/3 up to sacrificing some accuracy, for details see
<code><a href="DRR.html#topic+constructFastKRRLearner">constructFastKRRLearner</a></code>. Another way to speed up
is to use <code>pars$fastcv = TRUE</code> which might provide a more
efficient way to search the parameter space but may also miss the
global maximum, I have not ran tests on the accuracy of this method.
</p>


<h3>References</h3>

<p>Laparra, V., Malo, J., Camps-Valls, G.,
2015. Dimensionality Reduction via Regression in Hyperspectral
Imagery. IEEE Journal of Selected Topics in Signal Processing
9, 1026-1036. doi:10.1109/JSTSP.2015.2417833
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if(requireNamespace(c("kernlab", "DRR"), quietly = TRUE)) {

dat &lt;- loadDataSet("variable Noise Helix", n = 200)[sample(200)]

emb &lt;- embed(dat, "DRR", ndim = 3)

plot(dat, type = "3vars")
plot(emb, type = "3vars")

# We even have function to reconstruct, also working for only the first few dimensions
rec &lt;- inverse(emb, getData(getDimRedData(emb))[, 1, drop = FALSE])
plot(rec, type = "3vars")
}


## End(Not run)

</code></pre>

<hr>
<h2 id='embed'>dispatches the different methods for dimensionality reduction</h2><span id='topic+embed'></span><span id='topic+embed+2Cformula-method'></span><span id='topic+embed+2CANY-method'></span><span id='topic+embed+2CdimRedData-method'></span>

<h3>Description</h3>

<p>wraps around all dimensionality reduction functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed(.data, ...)

## S4 method for signature 'formula'
embed(
  .formula,
  .data,
  .method = dimRedMethodList(),
  .mute = character(0),
  .keep.org.data = TRUE,
  ...
)

## S4 method for signature 'ANY'
embed(
  .data,
  .method = dimRedMethodList(),
  .mute = character(0),
  .keep.org.data = TRUE,
  ...
)

## S4 method for signature 'dimRedData'
embed(
  .data,
  .method = dimRedMethodList(),
  .mute = character(0),
  .keep.org.data = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="embed_+3A_.data">.data</code></td>
<td>
<p>object of class <code><a href="#topic+dimRedData">dimRedData</a></code>, will be converted to
be of class <code><a href="#topic+dimRedData">dimRedData</a></code> if necessary; see examples for
details.</p>
</td></tr>
<tr><td><code id="embed_+3A_...">...</code></td>
<td>
<p>the parameters, internally passed as a list to the dimensionality
reduction method as <code>pars = list(...)</code></p>
</td></tr>
<tr><td><code id="embed_+3A_.formula">.formula</code></td>
<td>
<p>a formula, see <code><a href="#topic+as.dimRedData">as.dimRedData</a></code>.</p>
</td></tr>
<tr><td><code id="embed_+3A_.method">.method</code></td>
<td>
<p>character vector naming one of the dimensionality reduction
techniques.</p>
</td></tr>
<tr><td><code id="embed_+3A_.mute">.mute</code></td>
<td>
<p>a character vector containing the elements you want to mute
(<code>c("message", "output")</code>), defaults to <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="embed_+3A_.keep.org.data">.keep.org.data</code></td>
<td>
<p><code>TRUE</code>/<code>FALSE</code> keep the original data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method must be one of <code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>, partial matching
is performed. All parameters start with a dot, to avoid clashes
with partial argument matching (see the R manual section 4.3.2), if
there should ever occur any clashes in the arguments, call the
function with all arguments named, e.g. <code>embed(.data = dat,
.method = "mymethod", .d = "some parameter")</code>.
</p>


<h3>Value</h3>

<p>an object of class <code><a href="#topic+dimRedResult">dimRedResult</a></code>
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>formula</code>: embed a data.frame using a formula.
</p>
</li>
<li> <p><code>ANY</code>: Embed anything as long as it can be coerced to
<code><a href="#topic+dimRedData">dimRedData</a></code>.
</p>
</li>
<li> <p><code>dimRedData</code>: Embed a dimRedData object
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>## embed a data.frame using a formula:
as.data.frame(
  embed(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
        iris, "PCA")
)

## embed a data.frame and return a data.frame
as.data.frame(embed(iris[, 1:4], "PCA"))

## embed a matrix and return a data.frame
as.data.frame(embed(as.matrix(iris[, 1:4]), "PCA"))

## Not run: 
## embed dimRedData objects
embed_methods &lt;- dimRedMethodList()
quality_methods &lt;- dimRedQualityList()
dataset &lt;- loadDataSet("Iris")

quality_results &lt;- matrix(NA, length(embed_methods), length(quality_methods),
                              dimnames = list(embed_methods, quality_methods))
embedded_data &lt;- list()

for (e in embed_methods) {
  message("embedding: ", e)
  embedded_data[[e]] &lt;- embed(dataset, e, .mute = c("message", "output"))
  for (q in quality_methods) {
    message("  quality: ", q)
    quality_results[e, q] &lt;- tryCatch(
      quality(embedded_data[[e]], q),
      error = function(e) NA
    )
  }
}

print(quality_results)

## End(Not run)
</code></pre>

<hr>
<h2 id='FastICA-class'>Independent Component Analysis</h2><span id='topic+FastICA-class'></span><span id='topic+FastICA'></span>

<h3>Description</h3>

<p>An S4 Class implementing the FastICA algorithm for Indepentend
Component Analysis.
</p>


<h3>Details</h3>

<p>ICA is used for blind signal separation of different sources. It is
a linear Projection.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>FastICA can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of output dimensions. Defaults to <code>2</code></p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="fastICA.html#topic+fastICA">fastICA</a></code>. FastICA uses a very
fast approximation for negentropy to estimate statistical
independences between signals. Because it is a simple
rotation/projection, forward and backward functions can be given.
</p>


<h3>References</h3>

<p>Hyvarinen, A., 1999. Fast and robust fixed-point algorithms for independent
component analysis. IEEE Transactions on Neural Networks 10, 626-634.
https://doi.org/10.1109/72.761722
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("fastICA", quietly = TRUE)) {

dat &lt;- loadDataSet("3D S Curve")
emb &lt;- embed(dat, "FastICA", ndim = 2)
plot(getData(getDimRedData(emb)))

}
</code></pre>

<hr>
<h2 id='FruchtermanReingold-class'>Fruchterman Reingold Graph Layout</h2><span id='topic+FruchtermanReingold-class'></span><span id='topic+FruchtermanReingold'></span>

<h3>Description</h3>

<p>An S4 Class implementing the Fruchterman Reingold Graph Layout
algorithm.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>


<dl>
<dt>ndim</dt><dd><p>The number of dimensions, defaults to 2. Can only be 2 or 3</p>
</dd>
<dt>knn</dt><dd><p>Reduce the graph to keep only the neares neighbors. Defaults to 100.</p>
</dd>
<dt>d</dt><dd><p>The distance function to determine the weights of the graph edges. Defaults to euclidean distances.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="igraph.html#topic+layout_with_fr">layout_with_fr</a></code>, see there for
details. The Fruchterman Reingold algorithm puts the data into
a circle and puts connected points close to each other.
</p>


<h3>References</h3>

<p>Fruchterman, T.M.J., Reingold, E.M., 1991. Graph drawing by force-directed
placement. Softw: Pract. Exper. 21, 1129-1164.
https://doi.org/10.1002/spe.4380211102
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("igraph", "coRanking"), quietly = TRUE)) {

dat &lt;- loadDataSet("Swiss Roll", n = 100)
emb &lt;- embed(dat, "FruchtermanReingold")
plot(emb, type = "2vars")

}

</code></pre>

<hr>
<h2 id='getData'>Method getData</h2><span id='topic+getData'></span>

<h3>Description</h3>

<p>Extracts the data slot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getData(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getData_+3A_object">object</code></td>
<td>
<p>The object to be converted.</p>
</td></tr>
</table>

<hr>
<h2 id='getDimRedData'>Method getDimRedData</h2><span id='topic+getDimRedData'></span>

<h3>Description</h3>

<p>Extract dimRedData.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDimRedData(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getDimRedData_+3A_object">object</code></td>
<td>
<p>The object to extract data from.</p>
</td></tr>
<tr><td><code id="getDimRedData_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='getMeta'>Method getMeta</h2><span id='topic+getMeta'></span>

<h3>Description</h3>

<p>Extracts the meta slot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMeta(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMeta_+3A_object">object</code></td>
<td>
<p>The object to be converted.</p>
</td></tr>
<tr><td><code id="getMeta_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='getNDim'>Method getNDim</h2><span id='topic+getNDim'></span>

<h3>Description</h3>

<p>Extract the number of embedding dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNDim(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getNDim_+3A_object">object</code></td>
<td>
<p>The object to get the dimensions from.</p>
</td></tr>
<tr><td><code id="getNDim_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='getOrgData'>Method getOrgData</h2><span id='topic+getOrgData'></span>

<h3>Description</h3>

<p>Extract the Original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getOrgData(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getOrgData_+3A_object">object</code></td>
<td>
<p>The object to extract data from.</p>
</td></tr>
<tr><td><code id="getOrgData_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='getOtherData'>Method getOtherData</h2><span id='topic+getOtherData'></span>

<h3>Description</h3>

<p>Extract other data produced by a dimRedMethod
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getOtherData(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getOtherData_+3A_object">object</code></td>
<td>
<p>The object to extract data from.</p>
</td></tr>
<tr><td><code id="getOtherData_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='getPars'>Method getPars</h2><span id='topic+getPars'></span>

<h3>Description</h3>

<p>Extracts the pars slot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPars(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPars_+3A_object">object</code></td>
<td>
<p>The object to be converted.</p>
</td></tr>
<tr><td><code id="getPars_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='getRotationMatrix'>getRotationMatrix</h2><span id='topic+getRotationMatrix'></span>

<h3>Description</h3>

<p>Extract the rotation matrix from <code><a href="#topic+dimRedResult">dimRedResult</a></code> objects derived from PCA and FastICA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRotationMatrix(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRotationMatrix_+3A_x">x</code></td>
<td>
<p>of type <code><a href="#topic+dimRedResult">dimRedResult</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data has to be pre-processed the same way as the method does, e.g.
centering and/or scaling.
</p>


<h3>Value</h3>

<p>a matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- loadDataSet("Iris")

pca &lt;- embed(dat, "PCA")
rot_pca &lt;- getRotationMatrix(pca)
scale(getData(dat), TRUE, FALSE) %*% rot_pca - getData(getDimRedData(pca))


if(requireNamespace("fastICA", quietly = TRUE)) {
  ica &lt;- embed(dat, "FastICA")
  rot_ica &lt;- getRotationMatrix(ica)
  scale(getData(dat), TRUE, FALSE) %*% rot_ica - getData(getDimRedData(ica))
}


</code></pre>

<hr>
<h2 id='HLLE-class'>Hessian Locally Linear Embedding</h2><span id='topic+HLLE-class'></span><span id='topic+HLLE'></span>

<h3>Description</h3>

<p>An S4 Class implementing Hessian Locally Linear Embedding (HLLE)
</p>


<h3>Details</h3>

<p>HLLE uses local hessians to approximate the curvines and is an
extension to non-convex subsets in lowdimensional space.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>HLLE can take the following parameters:
</p>

<dl>
<dt>knn</dt><dd><p>neighborhood size</p>
</dd>
<dt>ndim</dt><dd><p>number of output dimensions</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Own implementation, sticks to the algorithm in Donoho and Grimes
(2003). Makes use of sparsity to speed up final embedding.
</p>


<h3>References</h3>

<p>Donoho, D.L., Grimes, C., 2003. Hessian eigenmaps: Locally linear
embedding techniques for high-dimensional data. PNAS 100,
5591-5596. doi:10.1073/pnas.1031596100
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("RSpectra", "Matrix", "RANN"), quietly = TRUE)) {

dat &lt;- loadDataSet("3D S Curve", n = 300)
emb &lt;- embed(dat, "HLLE", knn = 15)
plot(emb, type = "2vars")

}

</code></pre>

<hr>
<h2 id='installSuggests'>getSuggests</h2><span id='topic+installSuggests'></span>

<h3>Description</h3>

<p>Install packages wich are suggested by dimRed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>installSuggests(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="installSuggests_+3A_...">...</code></td>
<td>
<p>additional options passed to install.packages.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default dimRed will not install all the dependencies, because
there are quite a lot and in case some of them are not available
for your platform you will not be able to install dimRed without
problems.
</p>
<p>To solve this I provide a function which automatically installes
all the suggested packages.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
installSuggests()

## End(Not run)
</code></pre>

<hr>
<h2 id='Isomap-class'>Isomap embedding</h2><span id='topic+Isomap-class'></span><span id='topic+Isomap'></span>

<h3>Description</h3>

<p>An S4 Class implementing the Isomap Algorithm
</p>


<h3>Details</h3>

<p>The Isomap algorithm approximates a manifold using geodesic
distances on a k nearest neighbor graph. Then classical scaling is
performed on the resulting distance matrix.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>Isomap can take the following parameters:
</p>

<dl>
<dt>knn</dt><dd><p>The number of nearest neighbors in the graph. Defaults to 50.</p>
</dd>
<dt>ndim</dt><dd><p>The number of embedding dimensions, defaults to 2.</p>
</dd>
<dt>get_geod</dt><dd><p>Should the geodesic distance matrix be kept,
if <code>TRUE</code>, access it as <code>getOtherData(x)$geod</code></p>
</dd>
</dl>



<h3>Implementation</h3>

<p>The dimRed package uses its own implementation of Isomap which also
comes with an out of sample extension (known as landmark
Isomap). The default Isomap algorithm scales computationally not
very well, the implementation here uses <code><a href="RANN.html#topic+nn2">nn2</a></code> for
a faster search of the nearest neighbors.  If data are too large it
may be useful to fit a subsample of the data and use the
out-of-sample extension for the other points.
</p>


<h3>References</h3>

<p>Tenenbaum, J.B., Silva, V. de, Langford, J.C., 2000. A Global Geometric
Framework for Nonlinear Dimensionality Reduction. Science 290, 2319-2323.
https://doi.org/10.1126/science.290.5500.2319
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("RSpectra", "igraph", "RANN"), quietly = TRUE)) {

dat &lt;- loadDataSet("3D S Curve", n = 500)
emb &lt;- embed(dat, "Isomap", knn = 10)
plot(emb)

## or simpler, use embed():
samp &lt;- sample(nrow(dat), size = 200)
emb2 &lt;- embed(dat[samp], "Isomap", .mute = NULL, knn = 10)
emb3 &lt;- predict(emb2, dat[-samp])

plot(emb2, type = "2vars")
plot(emb3, type = "2vars")

}
</code></pre>

<hr>
<h2 id='KamadaKawai-class'>Graph Embedding via the Kamada Kawai Algorithm</h2><span id='topic+KamadaKawai-class'></span><span id='topic+KamadaKawai'></span>

<h3>Description</h3>

<p>An S4 Class implementing the Kamada Kawai Algorithm for graph embedding.
</p>


<h3>Details</h3>

<p>Graph embedding algorithms se the data as a graph. Between the
nodes of the graph exist attracting and repelling forces which can
be modeled as electrical fields or springs connecting the
nodes. The graph is then forced into a lower dimensional
representation that tries to represent the forces betweent he nodes
accurately by minimizing the total energy of the attracting and
repelling forces.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>KamadaKawai can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of dimensions, defaults to 2. Can only be 2 or 3</p>
</dd>
<dt>knn</dt><dd><p>Reduce the graph to keep only the neares neighbors. Defaults to 100.</p>
</dd>
<dt>d</dt><dd><p>The distance function to determine the weights of the graph edges. Defaults to euclidean distances.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="igraph.html#topic+layout_with_kk">layout_with_kk</a></code>. The parameters
maxiter, epsilon and kkconst are set to the default values and
cannot be set, this may change in a future release. The DimRed
Package adds an extra sparsity parameter by constructing a knn
graph which also may improve visualization quality.
</p>


<h3>References</h3>

<p>Kamada, T., Kawai, S., 1989. An algorithm for drawing general undirected
graphs. Information Processing Letters 31, 7-15.
https://doi.org/10.1016/0020-0190(89)90102-6
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("igraph", "coRanking"), quietly = TRUE)) {

dat &lt;- loadDataSet("Swiss Roll", n = 200)
emb &lt;- embed(dat, "KamadaKawai")
plot(emb, type = "2vars")

}
</code></pre>

<hr>
<h2 id='kPCA-class'>Kernel PCA</h2><span id='topic+kPCA-class'></span><span id='topic+kPCA'></span>

<h3>Description</h3>

<p>An S4 Class implementing Kernel PCA
</p>


<h3>Details</h3>

<p>Kernel PCA is a nonlinear extension of PCA using kernel methods.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>Kernel PCA can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>the number of output dimensions, defaults to 2</p>
</dd>
<dt>kernel</dt><dd><p>The kernel function, either as a function or a
character vector with the name of the kernel. Defaults to
<code>"rbfdot"</code></p>
</dd>
<dt>kpar</dt><dd><p>A list with the parameters for the kernel function,
defaults to <code>list(sigma = 0.1)</code></p>
</dd>
</dl>

<p>The most comprehensive collection of kernel functions can be found in
<code><a href="kernlab.html#topic+kpca">kpca</a></code>. In case the function does not take any
parameters <code>kpar</code> has to be an empty list.
</p>


<h3>Implementation</h3>

<p>Wraps around <code><a href="kernlab.html#topic+kpca">kpca</a></code>, but provides additionally
forward and backward projections.
</p>


<h3>References</h3>

<p>Sch\&quot;olkopf, B., Smola, A., M\&quot;uller, K.-R., 1998. Nonlinear Component Analysis
as a Kernel Eigenvalue Problem. Neural Computation 10, 1299-1319.
https://doi.org/10.1162/089976698300017467
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if(requireNamespace("kernlab", quietly = TRUE)) {

dat &lt;- loadDataSet("3D S Curve")
emb &lt;- embed(dat, "kPCA")
plot(emb, type = "2vars")
}


## End(Not run)
</code></pre>

<hr>
<h2 id='LaplacianEigenmaps-class'>Laplacian Eigenmaps</h2><span id='topic+LaplacianEigenmaps-class'></span><span id='topic+LaplacianEigenmaps'></span>

<h3>Description</h3>

<p>An S4 Class implementing Laplacian Eigenmaps
</p>


<h3>Details</h3>

<p>Laplacian Eigenmaps use a kernel and were originally developed to
separate non-convex clusters under the name spectral clustering.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p><code>LaplacianEigenmaps</code> can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>the number of output dimensions.</p>
</dd>
<dt>sparse</dt><dd><p>A character vector specifying hot to make the graph
sparse, <code>"knn"</code> means that a K-nearest neighbor graph is
constructed, <code>"eps"</code> an epsilon neighborhood graph is
constructed, else a dense distance matrix is used.</p>
</dd>
<dt>knn</dt><dd><p>The number of nearest neighbors to use for the knn graph.</p>
</dd>
<dt>eps</dt><dd><p>The distance for the epsilon neighborhood graph.</p>
</dd>
<dt>t</dt><dd><p>Parameter for the transformation of the distance matrix
by <code class="reqn">w=exp(-d^2/t)</code>, larger values give less weight to
differences in distance, <code>t == Inf</code> treats all distances != 0 equally.</p>
</dd>
<dt>norm</dt><dd><p>logical, should the normed laplacian be used?</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="loe.html#topic+spec.emb">spec.emb</a></code>.
</p>


<h3>References</h3>

<p>Belkin, M., Niyogi, P., 2003. Laplacian Eigenmaps for
Dimensionality Reduction and Data Representation. Neural
Computation 15, 1373.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("loe", "RSpectra", "Matrix"), quietly = TRUE)) {

dat &lt;- loadDataSet("3D S Curve")
emb &lt;- embed(dat, "LaplacianEigenmaps")
plot(emb@data@data)

}
</code></pre>

<hr>
<h2 id='LCMC+2CdimRedResult-method'>Method LCMC</h2><span id='topic+LCMC+2CdimRedResult-method'></span><span id='topic+LCMC'></span>

<h3>Description</h3>

<p>Calculates the Local Continuity Meta Criterion, which is
<code><a href="#topic+Q_NX">Q_NX</a></code> adjusted for random overlap inside the K-ary
neighborhood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
LCMC(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LCMC+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='makeKNNgraph'>makeKNNgraph</h2><span id='topic+makeKNNgraph'></span>

<h3>Description</h3>

<p>Create a K-nearest neighbor graph from data x. Uses
<code><a href="RANN.html#topic+nn2">nn2</a></code> as a fast way to find the neares neighbors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeKNNgraph(x, k, eps = 0, diag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeKNNgraph_+3A_x">x</code></td>
<td>
<p>data, a matrix, observations in rows, dimensions in
columns</p>
</td></tr>
<tr><td><code id="makeKNNgraph_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors.</p>
</td></tr>
<tr><td><code id="makeKNNgraph_+3A_eps">eps</code></td>
<td>
<p>number, if <code>eps &gt; 0</code> the KNN search is approximate,
see <code><a href="RANN.html#topic+nn2">nn2</a></code></p>
</td></tr>
<tr><td><code id="makeKNNgraph_+3A_diag">diag</code></td>
<td>
<p>logical, if <code>TRUE</code> every edge of the returned
graph will have an edge with weight <code>0</code> to itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of type <code><a href="igraph.html#topic+igraph">igraph</a></code> with edge
weight being the distances.
</p>

<hr>
<h2 id='maximize_correlation+2CdimRedResult-method'>Maximize Correlation with the Axes</h2><span id='topic+maximize_correlation+2CdimRedResult-method'></span><span id='topic+maximize_correlation'></span>

<h3>Description</h3>

<p>Rotates the data in such a way that the correlation with the first
<code>naxes</code> axes is maximized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
maximize_correlation(
  object,
  naxes = ncol(object@data@data),
  cor_method = "pearson"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maximize_correlation+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>A dimRedResult object</p>
</td></tr>
<tr><td><code id="maximize_correlation+2B2CdimRedResult-method_+3A_naxes">naxes</code></td>
<td>
<p>the number of axes to optimize for.</p>
</td></tr>
<tr><td><code id="maximize_correlation+2B2CdimRedResult-method_+3A_cor_method">cor_method</code></td>
<td>
<p>which correlation method to use</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods that do not use eigenvector decomposition, like t-SNE often
do not align the data with axes according to the correlation of
variables with the data. <code>maximize_correlation</code> uses the
<code><a href="optimx.html#topic+optimx">optimx</a></code> package to rotate the data in such a
way that the original variables have maximum correlation with the
embedding axes.
</p>

<hr>
<h2 id='MDS-class'>Metric Dimensional Scaling</h2><span id='topic+MDS-class'></span><span id='topic+MDS'></span>

<h3>Description</h3>

<p>An S4 Class implementing classical scaling (MDS).
</p>


<h3>Details</h3>

<p>MDS tries to maintain distances in high- and low-dimensional space,
it has the advantage over PCA that arbitrary distance functions can
be used, but it is computationally more demanding.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>MDS can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of dimensions.</p>
</dd>
<dt>d</dt><dd><p>The function to calculate the distance matrix from the input coordinates, defaults to euclidean distances.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>. The implementation also
provides an out-of-sample extension which is not completely
optimized yet.
</p>


<h3>References</h3>

<p>Torgerson, W.S., 1952. Multidimensional scaling: I. Theory and method.
Psychometrika 17, 401-419. https://doi.org/10.1007/BF02288916
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- loadDataSet("3D S Curve")
emb &lt;- embed(dat, "MDS")
plot(emb, type = "2vars")

# a "manual" kPCA:
emb2 &lt;- embed(dat, "MDS", d = function(x) exp(stats::dist(x)))
plot(emb2, type = "2vars")

# a "manual", more customizable, and slower Isomap:
emb3 &lt;- embed(dat, "MDS", d = function(x) vegan::isomapdist(vegan::vegdist(x, "manhattan"), k = 20))
plot(emb3)


## End(Not run)
</code></pre>

<hr>
<h2 id='mean_R_NX+2CdimRedResult-method'>Method mean_R_NX</h2><span id='topic+mean_R_NX+2CdimRedResult-method'></span><span id='topic+mean_R_NX'></span>

<h3>Description</h3>

<p>Calculate the mean_R_NX score to assess the quality of a dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
mean_R_NX(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean_R_NX+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='mixColorRamps'>Mixing color ramps</h2><span id='topic+mixColorRamps'></span><span id='topic+mixColor1Ramps'></span><span id='topic+mixColor2Ramps'></span><span id='topic+mixColor3Ramps'></span>

<h3>Description</h3>

<p>mix different color ramps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixColorRamps(vars, ramps)

mixColor1Ramps(vars, ramps = colorRamp(c("blue", "black", "red")))

mixColor2Ramps(
  vars,
  ramps = list(colorRamp(c("blue", "green")), colorRamp(c("blue", "red")))
)

mixColor3Ramps(
  vars,
  ramps = list(colorRamp(c("#001A00", "#00E600")), colorRamp(c("#00001A", "#0000E6")),
    colorRamp(c("#1A0000", "#E60000")))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixColorRamps_+3A_vars">vars</code></td>
<td>
<p>a list of variables</p>
</td></tr>
<tr><td><code id="mixColorRamps_+3A_ramps">ramps</code></td>
<td>
<p>a list of color ramps, one for each variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>automatically create colors to represent a varying number of
dimensions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cols &lt;- expand.grid(x = seq(0, 1, length.out = 10),
                    y = seq(0, 1, length.out = 10),
                    z = seq(0, 1, length.out = 10))
mixed &lt;- mixColor3Ramps(cols)

## Not run: 
if(requireNamespace("rgl", quietly = TRUE)) {
rgl::plot3d(cols$x, cols$y, cols$z, col = mixed, pch = 15)
}

cols &lt;- expand.grid(x = seq(0, 1, length.out = 10),
                    y = seq(0, 1, length.out = 10))
mixed &lt;- mixColor2Ramps(cols)

if(requireNamespace("graphics", quietly = TRUE)) {
plot(cols$x, cols$y, col = mixed, pch = 15)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='ndims'>Method ndims</h2><span id='topic+ndims'></span>

<h3>Description</h3>

<p>Extract the number of dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ndims(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ndims_+3A_object">object</code></td>
<td>
<p>To extract the number of dimensions from.</p>
</td></tr>
<tr><td><code id="ndims_+3A_...">...</code></td>
<td>
<p>Arguments for further methods</p>
</td></tr>
</table>

<hr>
<h2 id='nMDS-class'>Non-Metric Dimensional Scaling</h2><span id='topic+nMDS-class'></span><span id='topic+nMDS'></span>

<h3>Description</h3>

<p>An S4 Class implementing Non-Metric Dimensional Scaling.
</p>


<h3>Details</h3>

<p>A non-linear extension of MDS using monotonic regression
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>nMDS can take the following parameters:
</p>

<dl>
<dt>d</dt><dd><p>A distance function.</p>
</dd>
<dt>ndim</dt><dd><p>The number of embedding dimensions.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around the
<code><a href="vegan.html#topic+monoMDS">monoMDS</a></code>. For parameters that are not
available here, the standard configuration is used.
</p>


<h3>References</h3>

<p>Kruskal, J.B., 1964. Nonmetric multidimensional scaling: A numerical method.
Psychometrika 29, 115-129. https://doi.org/10.1007/BF02289694
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("vegan", quietly = TRUE)) {

dat &lt;- loadDataSet("3D S Curve", n = 300)
emb &lt;- embed(dat, "nMDS")
plot(emb, type = "2vars")

}
</code></pre>

<hr>
<h2 id='NNMF-class'>Non-Negative Matrix Factorization</h2><span id='topic+NNMF-class'></span><span id='topic+NNMF'></span>

<h3>Description</h3>

<p>S4 Class implementing NNMF.
</p>


<h3>Details</h3>

<p>NNMF is a method for decomposing a matrix into a smaller
dimension such that the constraint that the data (and the
projection) are not negative is taken into account.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>The method can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of output dimensions.</p>
</dd>
<dt>method</dt><dd><p>character, which algorithm should be used. See
<code><a href="NMF.html#topic+nmf">nmf</a></code> for possible values. Defaults to
&quot;brunet&quot;</p>
</dd>
<dt>nrun</dt><dd><p>integer, the number of times the computations are
conducted. See <code><a href="NMF.html#topic+nmf">nmf</a></code></p>
</dd>
<dt>seed</dt><dd><p>integer, a value to control the random numbers used.</p>
</dd>
<dt>options</dt><dd><p>named list, other options to pass to  <code><a href="NMF.html#topic+nmf">nmf</a></code></p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="NMF.html#topic+nmf">nmf</a></code>. Note that the estimation uses random
numbers. To create reproducible results, set the random number seed in the
function call. Also, in many cases, the computations will be conducted
in parallel using multiple cores. To disable this, use the option
<code>.pbackend = NULL</code>.
</p>


<h3>References</h3>

<p>Lee, D.D., Seung, H.S., 1999. Learning the parts of objects by non-negative
matrix factorization. Nature 401, 788-791. https://doi.org/10.1038/44565
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("NNMF", "MASS"), quietly = TRUE)) {

set.seed(4646)
dat &lt;- loadDataSet("Iris")
emb &lt;- embed(dat, "NNMF")

plot(emb)

# project new values:
nn_proj &lt;- predict(emb, dat[1:7])
plot(nn_proj)

}
</code></pre>

<hr>
<h2 id='PCA_L1-class'>Principal Component Analysis with L1 error.</h2><span id='topic+PCA_L1-class'></span><span id='topic+PCA_L1'></span>

<h3>Description</h3>

<p>S4 Class implementing PCA with L1 error.
</p>


<h3>Details</h3>

<p>PCA transforms the data so that the L2 reconstruction error is minimized or
the variance of the projected data is maximized. This is sensitive to
outliers, L1 PCA minimizes the L1 reconstruction error or maximizes the sum
of the L1 norm of the projected observations.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>PCA can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of output dimensions.</p>
</dd>
<dt>center</dt><dd><p>logical, should the data be centered, defaults to <code>TRUE</code>.</p>
</dd>
<dt>scale.</dt><dd><p>logical, should the data be scaled, defaults to <code>FALSE</code>.</p>
</dd>
<dt>fun</dt><dd><p>character or function, the method to apply, see the <code>pcaL1</code> package</p>
</dd>
<dt>...</dt><dd><p>other parameters for <code>fun</code></p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around the different methods is the <code>pcaL1</code> package. Because PCA
can be reduced to a simple rotation, forward and backward projection
functions are supplied.
</p>


<h3>References</h3>

<p>Park, Y.W., Klabjan, D., 2016. Iteratively Reweighted Least Squares
Algorithms for L1-Norm Principal Component Analysis, in: Data Mining (ICDM),
2016 IEEE 16th International Conference On. IEEE, pp. 430-438.
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("pcaL1", quietly = TRUE)) {

dat &lt;- loadDataSet("Iris")
emb &lt;- embed(dat, "PCA_L1")

plot(emb, type = "2vars")
plot(inverse(emb, getData(getDimRedData((emb)))), type = "3vars")

}

</code></pre>

<hr>
<h2 id='PCA-class'>Principal Component Analysis</h2><span id='topic+PCA-class'></span><span id='topic+PCA'></span>

<h3>Description</h3>

<p>S4 Class implementing PCA.
</p>


<h3>Details</h3>

<p>PCA transforms the data in orthogonal components so that the first
axis accounts for the larges variance in the data, all the
following axes account for the highest variance under the
constraint that they are orthogonal to the preceding axes.  PCA is
sensitive to the scaling of the variables. PCA is by far the
fastest and simples method of dimensionality reduction and should
probably always be applied as a baseline if other methods are tested.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>PCA can take the following parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of output dimensions.</p>
</dd>
<dt>center</dt><dd><p>logical, should the data be centered, defaults to <code>TRUE</code>.</p>
</dd>
<dt>scale.</dt><dd><p>logical, should the data be scaled, defaults to <code>FALSE</code>.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="stats.html#topic+prcomp">prcomp</a></code>. Because PCA can be reduced to a
simple rotation, forward and backward projection functions are
supplied.
</p>


<h3>References</h3>

<p>Pearson, K., 1901. On lines and planes of closest fit to systems of points in
space. Philosophical Magazine 2, 559-572.
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- loadDataSet("Iris")
emb &lt;- embed(dat, "PCA")

plot(emb, type = "2vars")
if(requireNamespace("scatterplot3d", quietly = TRUE))
  plot(inverse(emb, getDimRedData(emb)), type = "3vars")

</code></pre>

<hr>
<h2 id='plot'>Plotting of dimRed* objects</h2><span id='topic+plot'></span><span id='topic+plot.dimRed'></span><span id='topic+plot+2CdimRedData+2CANY-method'></span><span id='topic+plot.dimRedData'></span><span id='topic+plot+2CdimRedResult+2CANY-method'></span><span id='topic+plot.dimRedResult'></span>

<h3>Description</h3>

<p>Plots a object of class dimRedResult and dimRedData. For the
documentation of the plotting function in base see here:
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot(x, y, ...)

## S4 method for signature 'dimRedData,ANY'
plot(
  x,
  type = "pairs",
  vars = seq_len(ncol(x@data)),
  col = seq_len(min(3, ncol(x@meta))),
  ...
)

## S4 method for signature 'dimRedResult,ANY'
plot(
  x,
  type = "pairs",
  vars = seq_len(ncol(x@data@data)),
  col = seq_len(min(3, ncol(x@data@meta))),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>dimRedResult/dimRedData class, e.g. output of
embedded/loadDataSet</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>Ignored</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>handed over to the underlying plotting function.</p>
</td></tr>
<tr><td><code id="plot_+3A_type">type</code></td>
<td>
<p>plot type, one of <code>c("pairs", "parpl", "2vars",
"3vars", "3varsrgl")</code></p>
</td></tr>
<tr><td><code id="plot_+3A_vars">vars</code></td>
<td>
<p>the axes of the embedding to use for plotting</p>
</td></tr>
<tr><td><code id="plot_+3A_col">col</code></td>
<td>
<p>the columns of the meta slot to use for coloring, can be
referenced as the column names or number of x@data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plotting functions for the classes usind in <code>dimRed</code>. they are
intended to give a quick overview over the results, so they are
somewhat inflexible, e.g. it is hard to modify color scales or
plotting parameters.
</p>
<p>If you require more control over plotting, it is better to convert
the object to a <code>data.frame</code> first and use the standard
functions for plotting.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>x = dimRedData,y = ANY</code>: Ploting of dimRedData objects
</p>
</li>
<li> <p><code>x = dimRedResult,y = ANY</code>: Ploting of dimRedResult objects.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>scurve = loadDataSet("3D S Curve")
if(requireNamespace("graphics", quietly = TRUE))
  plot(scurve, type = "pairs", main = "pairs plot of S curve")
if(requireNamespace("MASS", quietly = TRUE))
  plot(scurve, type = "parpl")
if(requireNamespace("graphics", quietly = TRUE))
  plot(scurve, type = "2vars", vars = c("y", "z"))
if(requireNamespace("scatterplot3d", quietly = TRUE))
  plot(scurve, type = "3vars")
if(requireNamespace("rgl", quietly = TRUE))
  plot(scurve, type = "3varsrgl")

</code></pre>

<hr>
<h2 id='plot_R_NX'>plot_R_NX</h2><span id='topic+plot_R_NX'></span>

<h3>Description</h3>

<p>Plot the R_NX curve for different embeddings. Takes a list of
<code><a href="#topic+dimRedResult">dimRedResult</a></code> objects as input.
Also the Area under the curve values are computed for a weighted K
(see <a href="#topic+AUC_lnK_R_NX">AUC_lnK_R_NX</a> for details) and appear in the legend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_R_NX(x, ndim = NA, weight = "inv")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_R_NX_+3A_x">x</code></td>
<td>
<p>a list of <code><a href="#topic+dimRedResult">dimRedResult</a></code> objects. The names of the list
will appear in the legend with the AUC_lnK value.</p>
</td></tr>
<tr><td><code id="plot_R_NX_+3A_ndim">ndim</code></td>
<td>
<p>the number of dimensions, if <code>NA</code> the original number of
embedding dimensions is used, can be a vector giving the embedding
dimensionality for each single list element of <code>x</code>.</p>
</td></tr>
<tr><td><code id="plot_R_NX_+3A_weight">weight</code></td>
<td>
<p>the weight function used for K when calculating the AUC, one of
<code>c("inv", "log", "log10")</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object, the design can be changed by appending
<code>theme(...)</code>
</p>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace(c("RSpectra", "igraph", "RANN", "ggplot", "tidyr", "scales"), quietly = TRUE)) {
## define which methods to apply
embed_methods &lt;- c("Isomap", "PCA")
## load test data set
data_set &lt;- loadDataSet("3D S Curve", n = 200)
## apply dimensionality reduction
data_emb &lt;- lapply(embed_methods, function(x) embed(data_set, x))
names(data_emb) &lt;- embed_methods
## plot the R_NX curves:
plot_R_NX(data_emb) +
    ggplot2::theme(legend.title = ggplot2::element_blank(),
                   legend.position = c(0.5, 0.1),
                   legend.justification = c(0.5, 0.1))
}
</code></pre>

<hr>
<h2 id='print'>Method print</h2><span id='topic+print'></span>

<h3>Description</h3>

<p>Imports the print method into the package namespace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_+3A_x">x</code></td>
<td>
<p>The object to be printed.</p>
</td></tr>
<tr><td><code id="print_+3A_...">...</code></td>
<td>
<p>Other arguments for printing.</p>
</td></tr>
</table>

<hr>
<h2 id='Q_global+2CdimRedResult-method'>Method Q_global</h2><span id='topic+Q_global+2CdimRedResult-method'></span><span id='topic+Q_global'></span>

<h3>Description</h3>

<p>Calculate the Q_global score to assess the quality of a dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
Q_global(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Q_global+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='Q_local+2CdimRedResult-method'>Method Q_local</h2><span id='topic+Q_local+2CdimRedResult-method'></span><span id='topic+Q_local'></span>

<h3>Description</h3>

<p>Calculate the Q_local score to assess the quality of a dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
Q_local(object, ndim = getNDim(object))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Q_local+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult.</p>
</td></tr>
<tr><td><code id="Q_local+2B2CdimRedResult-method_+3A_ndim">ndim</code></td>
<td>
<p>use the first ndim columns of the embedded data for calculation.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='Q_NX+2CdimRedResult-method'>Method Q_NX</h2><span id='topic+Q_NX+2CdimRedResult-method'></span><span id='topic+Q_NX'></span>

<h3>Description</h3>

<p>Calculate the Q_NX score (Chen &amp; Buja 2006, the notation in the
publication is M_k). Which is the fraction of points that remain inside
the same K-ary neighborhood in high and low dimensional space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
Q_NX(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Q_NX+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='quality+2CdimRedResult-method'>Quality Criteria for dimensionality reduction.</h2><span id='topic+quality+2CdimRedResult-method'></span><span id='topic+quality'></span><span id='topic+quality.dimRedResult'></span><span id='topic+dimRedQualityList'></span>

<h3>Description</h3>

<p>A collection of functions to compute quality measures on
<code><a href="#topic+dimRedResult">dimRedResult</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
quality(.data, .method = dimRedQualityList(), .mute = character(0), ...)

dimRedQualityList(filter = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quality+2B2CdimRedResult-method_+3A_.data">.data</code></td>
<td>
<p>object of class <code>dimRedResult</code></p>
</td></tr>
<tr><td><code id="quality+2B2CdimRedResult-method_+3A_.method">.method</code></td>
<td>
<p>character vector naming one of the methods</p>
</td></tr>
<tr><td><code id="quality+2B2CdimRedResult-method_+3A_.mute">.mute</code></td>
<td>
<p>what output from the embedding method should be muted.</p>
</td></tr>
<tr><td><code id="quality+2B2CdimRedResult-method_+3A_...">...</code></td>
<td>
<p>the pameters, internally passed as a list to the
quality method as <code>pars = list(...)</code></p>
</td></tr>
<tr><td><code id="quality+2B2CdimRedResult-method_+3A_filter">filter</code></td>
<td>
<p>filter methods by installed packages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>dimRedResult</code>: Calculate a quality index from a dimRedResult object.
</p>
</li></ul>


<h3>Implemented methods</h3>

<p>Method must be one of <code>"<a href="#topic+Q_local">Q_local</a>", "<a href="#topic+Q_global">Q_global</a>",
"<a href="#topic+mean_R_NX">mean_R_NX</a>", "<a href="#topic+total_correlation">total_correlation</a>",
"<a href="#topic+cophenetic_correlation">cophenetic_correlation</a>", "<a href="#topic+distance_correlation">distance_correlation</a>",
"<a href="#topic+reconstruction_rmse">reconstruction_rmse</a>"</code>
</p>


<h3>Rank based criteria</h3>

<p><code>Q_local</code>, <code>Q_global</code>, and <code>mean_R_NX</code> are
quality criteria based on the Co-ranking matrix.  <code>Q_local</code>
and <code>Q_global</code> determine the local/global quality of the
embedding, while <code>mean_R_NX</code> determines the quality of the
overall embedding. They are parameter free and return a single
number. The object must include the original data.  The number
returns is in the range [0, 1], higher values mean a better
local/global embedding.
</p>


<h3>Correlation based criteria</h3>

<p><code>total_correlation</code> calculates the sum of the mean squared
correlations of the original axes with the axes in reduced
dimensions, because some methods do not care about correlations
with axes, there is an option to rotate data in reduced space to
maximize this criterium. The number may be greater than one if more
dimensions are summed up.
</p>
<p><code>cophenetic_correlation</code> calculate the correlation between the
lower triangles of distance matrices, the correlation and distance
methods may be specified. The result is in range [-1, 1].
</p>
<p><code>distance_correlation</code> measures the independes of samples by
calculating the correlation of distances. For details see
<code><a href="energy.html#topic+dcor">dcor</a></code>.
</p>


<h3>Reconstruction error</h3>

<p><code>reconstruction_rmse</code> calculates the root mean squared error
of the reconstrucion. <code>object</code> requires an inverse function.
</p>


<h3>Author(s)</h3>

<p>Guido Kraemer
</p>


<h3>References</h3>

<p>Lueks, W., Mokbel, B., Biehl, M., Hammer, B., 2011. How
to Evaluate Dimensionality Reduction? - Improving the
Co-ranking Matrix. arXiv:1110.3917 [cs].
</p>
<p>Szekely, G.J., Rizzo, M.L., Bakirov, N.K., 2007. Measuring and
testing dependence by correlation of distances. Ann. Statist. 35,
2769-2794. doi:10.1214/009053607000000505
</p>
<p>Lee, J.A., Peluffo-Ordonez, D.H., Verleysen, M., 2015. Multi-scale
similarities in stochastic neighbour embedding: Reducing
dimensionality while preserving both local and global
structure. Neurocomputing, 169,
246-261. doi:10.1016/j.neucom.2014.12.095
</p>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
embed_methods &lt;- dimRedMethodList()
quality_methods &lt;- dimRedQualityList()
scurve &lt;- loadDataSet("Iris")

quality_results &lt;- matrix(NA, length(embed_methods), length(quality_methods),
                              dimnames = list(embed_methods, quality_methods))
embedded_data &lt;- list()

for (e in embed_methods) {
  message("embedding: ", e)
  embedded_data[[e]] &lt;- embed(scurve, e, .mute = c("message", "output"))
  for (q in quality_methods) {
    message("  quality: ", q)
    quality_results[e, q] &lt;- tryCatch(
      quality(embedded_data[[e]], q),
      error = function (e) NA
    )
  }
}

print(quality_results)

## End(Not run)
</code></pre>

<hr>
<h2 id='R_NX+2CdimRedResult-method'>Method R_NX</h2><span id='topic+R_NX+2CdimRedResult-method'></span><span id='topic+R_NX'></span>

<h3>Description</h3>

<p>Calculate the R_NX score from Lee et. al. (2013) which shows the neighborhood
preservation for the Kth nearest neighbors, corrected for random point
distributions and scaled to range [0, 1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
R_NX(object, ndim = getNDim(object))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R_NX+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
<tr><td><code id="R_NX+2B2CdimRedResult-method_+3A_ndim">ndim</code></td>
<td>
<p>the number of dimensions to take from the embedded data.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='reconstruction_error+2CdimRedResult-method'>Method reconstruction_error</h2><span id='topic+reconstruction_error+2CdimRedResult-method'></span><span id='topic+reconstruction_error'></span>

<h3>Description</h3>

<p>Calculate the error using only the first <code>n</code> dimensions of the embedded
data. <code>error_fun</code> can either be one of <code>c("rmse", "mae")</code> to
calculate the root mean square error or the mean absolute error respectively,
or a function that takes to equally sized vectors as input and returns a
single number as output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
reconstruction_error(object, n = seq_len(ndims(object)), error_fun = "rmse")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reconstruction_error+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
<tr><td><code id="reconstruction_error+2B2CdimRedResult-method_+3A_n">n</code></td>
<td>
<p>a positive integer or vector of integers <code>&lt;= ndims(object)</code></p>
</td></tr>
<tr><td><code id="reconstruction_error+2B2CdimRedResult-method_+3A_error_fun">error_fun</code></td>
<td>
<p>a function or string indicating an error function, if
indication a function it must take to matrices of the same size and return
a scalar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of number with the same length as <code>n</code> with the
</p>


<h3>Author(s)</h3>

<p>Guido Kraemer
</p>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ir &lt;- loadDataSet("Iris")
ir.drr &lt;- embed(ir, "DRR", ndim = ndims(ir))
ir.pca &lt;- embed(ir, "PCA", ndim = ndims(ir))

rmse &lt;- data.frame(
  rmse_drr = reconstruction_error(ir.drr),
  rmse_pca = reconstruction_error(ir.pca)
)

matplot(rmse, type = "l")
plot(ir)
plot(ir.drr)
plot(ir.pca)

## End(Not run)
</code></pre>

<hr>
<h2 id='reconstruction_rmse+2CdimRedResult-method'>Method reconstruction_rmse</h2><span id='topic+reconstruction_rmse+2CdimRedResult-method'></span><span id='topic+reconstruction_rmse'></span>

<h3>Description</h3>

<p>Calculate the reconstruction root mean squared error a dimensionality reduction, the method must have an inverse mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
reconstruction_rmse(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reconstruction_rmse+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+total_correlation+2CdimRedResult-method">total_correlation,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='total_correlation+2CdimRedResult-method'>Method total_correlation</h2><span id='topic+total_correlation+2CdimRedResult-method'></span><span id='topic+total_correlation'></span>

<h3>Description</h3>

<p>Calculate the total correlation of the variables with the axes to
assess the quality of a dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dimRedResult'
total_correlation(
  object,
  naxes = ndims(object),
  cor_method = "pearson",
  is.rotated = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="total_correlation+2B2CdimRedResult-method_+3A_object">object</code></td>
<td>
<p>of class dimRedResult</p>
</td></tr>
<tr><td><code id="total_correlation+2B2CdimRedResult-method_+3A_naxes">naxes</code></td>
<td>
<p>the number of axes to use for optimization.</p>
</td></tr>
<tr><td><code id="total_correlation+2B2CdimRedResult-method_+3A_cor_method">cor_method</code></td>
<td>
<p>the correlation method to use.</p>
</td></tr>
<tr><td><code id="total_correlation+2B2CdimRedResult-method_+3A_is.rotated">is.rotated</code></td>
<td>
<p>if FALSE the object is rotated.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Quality scores for dimensionality reduction: 
<code><a href="#topic+AUC_lnK_R_NX+2CdimRedResult-method">AUC_lnK_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+LCMC+2CdimRedResult-method">LCMC,dimRedResult-method</a></code>,
<code><a href="#topic+Q_NX+2CdimRedResult-method">Q_NX,dimRedResult-method</a></code>,
<code><a href="#topic+Q_global+2CdimRedResult-method">Q_global,dimRedResult-method</a></code>,
<code><a href="#topic+Q_local+2CdimRedResult-method">Q_local,dimRedResult-method</a></code>,
<code><a href="#topic+R_NX+2CdimRedResult-method">R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+cophenetic_correlation+2CdimRedResult-method">cophenetic_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+distance_correlation+2CdimRedResult-method">distance_correlation,dimRedResult-method</a></code>,
<code><a href="#topic+mean_R_NX+2CdimRedResult-method">mean_R_NX,dimRedResult-method</a></code>,
<code><a href="#topic+plot_R_NX">plot_R_NX</a>()</code>,
<code><a href="#topic+quality+2CdimRedResult-method">quality,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_error+2CdimRedResult-method">reconstruction_error,dimRedResult-method</a></code>,
<code><a href="#topic+reconstruction_rmse+2CdimRedResult-method">reconstruction_rmse,dimRedResult-method</a></code>
</p>

<hr>
<h2 id='tSNE-class'>t-Distributed Stochastic Neighborhood Embedding</h2><span id='topic+tSNE-class'></span><span id='topic+tSNE'></span>

<h3>Description</h3>

<p>An S4 Class for t-SNE.
</p>


<h3>Details</h3>

<p>t-SNE is a method that uses Kullback-Leibler divergence between the
distance matrices in high and low-dimensional space to embed the
data. The method is very well suited to visualize complex
structures in low dimensions.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>t-SNE can take the following parameters:
</p>

<dl>
<dt>d</dt><dd><p>A distance function, defaults to euclidean distances</p>
</dd>
<dt>perplexity</dt><dd><p>The perplexity parameter, roughly equivalent to neighborhood size.</p>
</dd>
<dt>theta</dt><dd><p>Approximation for the nearest neighbour search, large values are more inaccurate.</p>
</dd>
<dt>ndim</dt><dd><p>The number of embedding dimensions.</p>
</dd>
</dl>



<h3>Implementation</h3>

<p>Wraps around <code><a href="Rtsne.html#topic+Rtsne">Rtsne</a></code>, which is very well
documented. Setting <code>theta = 0</code> does a normal t-SNE, larger
values for <code>theta &lt; 1</code> use the Barnes-Hut algorithm which
scales much nicer with data size. Larger values for perplexity take
larger neighborhoods into account.
</p>


<h3>References</h3>

<p>Maaten, L. van der, 2014. Accelerating t-SNE using Tree-Based
Algorithms. Journal of Machine Learning Research 15, 3221-3245.
</p>
<p>van der Maaten, L., Hinton, G., 2008. Visualizing Data using
t-SNE. J. Mach. Learn. Res. 9, 2579-2605.
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+UMAP-class">UMAP-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- loadDataSet("3D S Curve", n = 300)
emb &lt;- embed(dat, "tSNE", perplexity = 80)
plot(emb, type = "2vars")

## End(Not run)
</code></pre>

<hr>
<h2 id='UMAP-class'>Umap embedding</h2><span id='topic+UMAP-class'></span><span id='topic+UMAP'></span>

<h3>Description</h3>

<p>An S4 Class implementing the UMAP algorithm
</p>


<h3>Details</h3>

<p>Uniform Manifold Approximation is a gradient descend based algorithm that
gives results similar to t-SNE, but scales better with the number of points.
</p>


<h3>Slots</h3>


<dl>
<dt><code>fun</code></dt><dd><p>A function that does the embedding and returns a
dimRedResult object.</p>
</dd>
<dt><code>stdpars</code></dt><dd><p>The standard parameters for the function.</p>
</dd>
</dl>


<h3>General usage</h3>

<p>Dimensionality reduction methods are S4 Classes that either be used
directly, in which case they have to be initialized and a full
list with parameters has to be handed to the <code>@fun()</code>
slot, or the method name be passed to the embed function and
parameters can be given to the <code>...</code>, in which case
missing parameters will be replaced by the ones in the
<code>@stdpars</code>.
</p>


<h3>Parameters</h3>

<p>UMAP can take the follwing parameters:
</p>

<dl>
<dt>ndim</dt><dd><p>The number of embedding dimensions.</p>
</dd>
<dt>knn</dt><dd><p>The number of neighbors to be used.</p>
</dd>
<dt>d</dt><dd><p>The distance metric to use.</p>
</dd>
<dt>method</dt><dd><p><code>"naive"</code> for an R implementation, <code>"python"</code>
for the reference implementation.</p>
</dd>
</dl>

<p>Other method parameters can also be passed, see
<code><a href="umap.html#topic+umap.defaults">umap.defaults</a></code> for details. The ones above have been
standardized for the use with <code>dimRed</code> and will get automatically
translated for <code><a href="umap.html#topic+umap">umap</a></code>.
</p>


<h3>Implementation</h3>

<p>The dimRed package wraps the <code><a href="umap.html#topic+umap">umap</a></code> packages which provides
an implementation in pure R and also a wrapper around the original python
package <code>umap-learn</code> (https://github.com/lmcinnes/umap/). This requires
<code>umap-learn</code> version 0.4 installed, at the time of writing, there is
already <code>umap-learn</code> 0.5 but it is not supported by the R package
<code><a href="umap.html#topic+umap">umap</a></code>.
</p>
<p>The <code>"naive"</code> implementation is a pure R implementation and considered
experimental at the point of writing this, it is also much slower than the
python implementation.
</p>
<p>The <code>"python"</code> implementation is the reference implementation used by
McInees et. al. (2018). It requires the <code><a href="reticulate.html#topic+reticulate">reticulate</a></code>
package for the interaction with python and the python package
<code>umap-learn</code> installed (use <code>pip install umap-learn</code>).
</p>


<h3>References</h3>

<p>McInnes, Leland, and John Healy.
&quot;UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction.&quot;
https://arxiv.org/abs/1802.03426
</p>


<h3>See Also</h3>

<p>Other dimensionality reduction methods: 
<code><a href="#topic+AutoEncoder-class">AutoEncoder-class</a></code>,
<code><a href="#topic+DRR-class">DRR-class</a></code>,
<code><a href="#topic+DiffusionMaps-class">DiffusionMaps-class</a></code>,
<code><a href="#topic+DrL-class">DrL-class</a></code>,
<code><a href="#topic+FastICA-class">FastICA-class</a></code>,
<code><a href="#topic+FruchtermanReingold-class">FruchtermanReingold-class</a></code>,
<code><a href="#topic+HLLE-class">HLLE-class</a></code>,
<code><a href="#topic+Isomap-class">Isomap-class</a></code>,
<code><a href="#topic+KamadaKawai-class">KamadaKawai-class</a></code>,
<code><a href="#topic+MDS-class">MDS-class</a></code>,
<code><a href="#topic+NNMF-class">NNMF-class</a></code>,
<code><a href="#topic+PCA-class">PCA-class</a></code>,
<code><a href="#topic+PCA_L1-class">PCA_L1-class</a></code>,
<code><a href="#topic+dimRedMethod-class">dimRedMethod-class</a></code>,
<code><a href="#topic+dimRedMethodList">dimRedMethodList</a>()</code>,
<code><a href="#topic+kPCA-class">kPCA-class</a></code>,
<code><a href="#topic+nMDS-class">nMDS-class</a></code>,
<code><a href="#topic+tSNE-class">tSNE-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- loadDataSet("3D S Curve", n = 300)
emb &lt;- embed(dat, "UMAP", .mute = NULL, knn = 10)
plot(emb, type = "2vars")

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
