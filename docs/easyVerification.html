<!DOCTYPE html><html><head><title>Help for package easyVerification</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {easyVerification}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#changearg'><p>Change Function Default Arguments</p></a></li>
<li><a href='#climFairRpss'><p>Calculate Fair Ranked Probability Skill Score Against Climatological</p>
Reference Forecast.</a></li>
<li><a href='#convert2prob'><p>Convert to Probability / Category Forecast</p></a></li>
<li><a href='#count2prob'><p>Convert Ensemble Counts to Probabilities</p></a></li>
<li><a href='#easyVerification'><p>Ensemble Forecast Verification for Large Data Sets</p></a></li>
<li><a href='#Ens2AFC'><p>Generalized Discrimination Score</p></a></li>
<li><a href='#EnsCorr'><p>Correlation with Ensemble Mean</p></a></li>
<li><a href='#EnsError'><p>Ensemble Mean Error</p></a></li>
<li><a href='#EnsErrorss'><p>Ensemble Mean Error Skill scores</p></a></li>
<li><a href='#EnsIgn'><p>Ignorance Score</p></a></li>
<li><a href='#EnsRoca'><p>Area Under the ROC Curve</p></a></li>
<li><a href='#EnsSprErr'><p>Spread to Error Ratio</p></a></li>
<li><a href='#FairSprErr'><p>Fair Spread to Error Ratio</p></a></li>
<li><a href='#generateRef'><p>Generate Probabilistic Climatological Ensemble Forecast from</p>
Observations</a></li>
<li><a href='#size'><p>Size of Array or Vector</p></a></li>
<li><a href='#toymodel'><p>Create Example Forecast-Observation Pairs</p></a></li>
<li><a href='#veriApply'><p>Apply Verification Metrics to Large Datasets</p></a></li>
<li><a href='#veriUnwrap'><p>Unwrap Arguments and Hand Over to Verification Function</p></a></li>
<li><a href='#weisheimer'><p>Compute Reliability Categories as in Weisheimer et al. (2014)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Ensemble Forecast Verification for Large Data Sets</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Set of tools to simplify application of atomic forecast
    verification metrics for (comparative) verification of ensemble forecasts
    to large data sets. The forecast metrics are imported from the
    'SpecsVerification' package, and additional forecast metrics are provided
    with this package. Alternatively, new user-defined forecast scores can be
    implemented using the example scores provided and applied using the
    functionality of this package.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0), SpecsVerification (&ge; 0.5), stats, utils</td>
</tr>
<tr>
<td>Imports:</td>
<td>pbapply, Rcpp (&ge; 0.12.9)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, parallel, R.rsp, verification</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Copyright:</td>
<td>MeteoSwiss</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.meteoswiss.admin.ch">https://www.meteoswiss.admin.ch</a>,
<a href="https://github.com/jonasbhend/easyVerification">https://github.com/jonasbhend/easyVerification</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>rmarkdown, R.rsp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Config/build/clean-inst-doc:</td>
<td>FALSE</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jonasbhend/easyVerification/issues">https://github.com/jonasbhend/easyVerification/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-15 04:50:23 UTC; bhj</td>
</tr>
<tr>
<td>Author:</td>
<td>MeteoSwiss [aut, cph],
  Jonas Bhend [cre],
  Jacopo Ripoldi [ctb],
  Claudia Mignani [ctb],
  Irina Mahlstein [ctb],
  Rebecca Hiller [ctb],
  Christoph Spirig [ctb],
  Mark Liniger [ctb],
  Andreas Weigel [ctb],
  Joaqu'in Bedia Jimenez [ctb],
  Matteo De Felice [ctb],
  Stefan Siegert [ctb],
  Katrin Sedlmeier [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jonas Bhend &lt;jonas.bhend@meteoswiss.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-15 05:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='changearg'>Change Function Default Arguments</h2><span id='topic+changearg'></span>

<h3>Description</h3>

<p>Override default arguments of functions. This functionality is used to
deal with the updated default representation in the SpecsVerification
package (&gt;= v0.5).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>changearg(FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="changearg_+3A_fun">FUN</code></td>
<td>
<p>name of function</p>
</td></tr>
<tr><td><code id="changearg_+3A_...">...</code></td>
<td>
<p>arguments to be overriden (e.g. format = 'member')</p>
</td></tr>
</table>

<hr>
<h2 id='climFairRpss'>Calculate Fair Ranked Probability Skill Score Against Climatological
Reference Forecast.</h2><span id='topic+climFairRpss'></span>

<h3>Description</h3>

<p>Calculate the fair ranked probability skill score (fair RPSS) between an
ensemble forecasts and a climatological reference forecast derived from the
observations. The categories of the climatological reference forecast have
been defined based on the distribution of the observations and the exact
forecast probabilities are known. The 'fair' correction therefore should not
be applied to the reference forecast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>climFairRpss(ens, ens.ref, obs, format = c("category", "member"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="climFairRpss_+3A_ens">ens</code></td>
<td>
<p>N*K matrix. ens[i,j] is the number of ensemble members that
predict category j at time i.</p>
</td></tr>
<tr><td><code id="climFairRpss_+3A_ens.ref">ens.ref</code></td>
<td>
<p>N*K matrix, similar to ens</p>
</td></tr>
<tr><td><code id="climFairRpss_+3A_obs">obs</code></td>
<td>
<p>N*K matrix. obs[i,j] = 1 if category j is observed at time i, 0
otherwise.</p>
</td></tr>
<tr><td><code id="climFairRpss_+3A_format">format</code></td>
<td>
<p>additional argument for use with <code>SpecsVerification &gt;= 0.5</code>.
Do not change this argument manually (except when using <code>climFairRpss</code>,
as standalone function).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements: <code>rpss|skillscore</code>: The value of the
skill score. <code>sigma.rpss|skillscore.sd</code>: The standard deviation of the skill score,
approximated by propagation of uncertainty. Please note that the naming changes with the
new version of <code>SpecsVerification</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## compute RPSS using veriApply
veriApply("climFairRpss", tm$fcst, tm$obs, prob = 1:2 / 3)

</code></pre>

<hr>
<h2 id='convert2prob'>Convert to Probability / Category Forecast</h2><span id='topic+convert2prob'></span><span id='topic+prob2thresh'></span><span id='topic+expandthresh'></span>

<h3>Description</h3>

<p><code>convert2prob</code> Converts the continuous ensemble forecast to
counts of ensemble members per category. The categories can be defined
relative to the ensemble distribution (using <code>prob</code>) or relative to
absolute values for the category thresholds (using <code>threshold</code>, see
details). <code>prob2thresh</code> converts the relative threshold to absolute
thresholds for later processing. <code>expandthresh</code> expands the vector or
matrix of thresholds to fit the input data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert2prob(
  x,
  prob = NULL,
  threshold = NULL,
  ref.ind = NULL,
  multi.model = FALSE
)

prob2thresh(x, prob, ref.ind = NULL, multi.model = FALSE)

expandthresh(threshold, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert2prob_+3A_x">x</code></td>
<td>
<p>input vector or matrix</p>
</td></tr>
<tr><td><code id="convert2prob_+3A_prob">prob</code></td>
<td>
<p>thresholds for categorical forecasts (defaults to NULL)</p>
</td></tr>
<tr><td><code id="convert2prob_+3A_threshold">threshold</code></td>
<td>
<p>absolute thresholds for categorical forecasts (defaults to
NULL)</p>
</td></tr>
<tr><td><code id="convert2prob_+3A_ref.ind">ref.ind</code></td>
<td>
<p>list of forecast/obs instances to be used to estimate
percentile thresholds</p>
</td></tr>
<tr><td><code id="convert2prob_+3A_multi.model">multi.model</code></td>
<td>
<p>logical, are we dealing with initial condition (the
default) or multi-model ensembles (see details)?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In case both <code>prob</code> and <code>threshold</code> are set to
<code>NULL</code>, the function returns the input <code>x</code> without modification.
If <code>prob</code> is set, a matrix with the number of occurrences per class for
a given quantile of the full distribution (e.g. temperature above/below the
median). If <code>threshold</code> is set, the classes are defined based on the
absolute value (e.g. temperature above/below 13 deg. C). Multiple classes
are
</p>
<p>Only certain formats of <code>threshold</code> and <code>prob</code> are supported.
<code>prob</code> has to be a vector with percentile thresholds separating the
different classes. <code>threshold</code> can be a vector, matrix or array with
the first entry corresponding to the different classes, and the last to the
different ensemble members (if present). Thereby, time/forecast varying
thresholds can potentially be supplied (although I am not sure this is
useful or needed).
</p>
<p>If <code>ref.ind</code> is specified, only the specified indices of the input
variables are used to estimate the percentile thresholds (<code>prob</code>). If
used with <code>threshold</code>, or without anything, <code>ref.ind</code> has no effect.
</p>
<p>If <code>multi.model = TRUE</code>, the relative thresholds supplied by
<code>prob</code> are ensemble member specific, i.e. are estimated for each
ensemble member separately. This is in particular applicable for
multi-model ensembles with model dependent biases.
</p>


<h3>Value</h3>

<p>Matrix of occurences per class (i.e. the number of ensemble members
per class, or an indicator for the observations)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## convert to tercile forecasts (only display first forecast and obs)
convert2prob(tm$fcst, prob = 1:2 / 3)[1, ]
convert2prob(tm$obs, prob = 1:2 / 3)[1, ]

## convert to category forecasts (smaller and larger than 1)
convert2prob(tm$fcst, threshold = 1)[1, ]
convert2prob(tm$obs, threshold = 1)[1, ]

</code></pre>

<hr>
<h2 id='count2prob'>Convert Ensemble Counts to Probabilities</h2><span id='topic+count2prob'></span>

<h3>Description</h3>

<p>Using plotting positions as described in Wilks (2011), counts of
occurrences per forecast category are converted to probabilities
of occurrence. For ensembles of size 1 (e.g. verifying observations),
the count vector is returned unaltered (corresponding to occurrence
probabilities of 0 or 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count2prob(x, type = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count2prob_+3A_x">x</code></td>
<td>
<p>input matrix of counts from <code><a href="#topic+convert2prob">convert2prob</a></code></p>
</td></tr>
<tr><td><code id="count2prob_+3A_type">type</code></td>
<td>
<p>selection of plotting positions (default to 3, see Types)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of probabilities per category
</p>


<h3>Types</h3>

<p>The types characterize the plotting positions as specified in Wilks (2011). The
plotting positions are computed using the following relationship:
</p>
<p style="text-align: center;"><code class="reqn">p(x_i) = \frac{i + 1 - a}{n + 1 - a}</code>
</p>

<p>where i is the number of ensemble members not exceeding x, and n is the
number of ensemble members. The types are characterized as follows:
</p>

<table>
<tr>
 <td style="text-align: center;">
  type </td><td style="text-align: left;"> description </td><td style="text-align: center;"> a </td>
</tr>
<tr>
 <td style="text-align: center;">
  1 </td><td style="text-align: left;"> Weibull </td><td style="text-align: center;"> 0 </td>
</tr>
<tr>
 <td style="text-align: center;">
  2 </td><td style="text-align: left;"> Bernard and Bos-Levenbach </td><td style="text-align: center;"> 0.3 </td>
</tr>
<tr>
 <td style="text-align: center;">
  3 </td><td style="text-align: left;"> Tukey </td><td style="text-align: center;"> 1/3 </td>
</tr>
<tr>
 <td style="text-align: center;">
  4 </td><td style="text-align: left;"> Gumbel </td><td style="text-align: center;"> 1 </td>
</tr>
<tr>
 <td style="text-align: center;">
  5 </td><td style="text-align: left;"> Hazen </td><td style="text-align: center;"> 1/2 </td>
</tr>
<tr>
 <td style="text-align: center;">
  6 </td><td style="text-align: left;"> Cunnane </td><td style="text-align: center;"> 2/5
</td>
</tr>

</table>



<h3>References</h3>

<p>Wilks, D.S. (2011). Statistical methods in the atmospheric sciences (Third Edition).
Academic press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+convert2prob">convert2prob</a></code> for conversion of continuous forecasts to ensemble counts
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## convert to tercile forecasts (only display first forecast and obs)
count2prob(convert2prob(tm$fcst, prob = 1:2 / 3))[1, ]
count2prob(convert2prob(tm$obs, prob = 1:2 / 3))[1, ]

</code></pre>

<hr>
<h2 id='easyVerification'>Ensemble Forecast Verification for Large Data Sets</h2><span id='topic+easyVerification'></span>

<h3>Description</h3>

<p>Set of tools to simplify application of atomic forecast
verification metrics for (comparative) verification of ensemble forecasts
to large data sets. The forecast metrics are imported from the
'SpecsVerification' package, and additional forecast metrics are provided
with this package. Alternatively, new user-defined forecast scores can be
implemented using the example scores provided and applied using the
functionality of this package.
</p>

<hr>
<h2 id='Ens2AFC'>Generalized Discrimination Score</h2><span id='topic+Ens2AFC'></span><span id='topic+rank.ensembles'></span>

<h3>Description</h3>

<p>Computes the generalized discrimination score for ensemble
forecasts after (Weigel and Mason, 2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ens2AFC(ens, obs, ...)

rank.ensembles(ens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ens2AFC_+3A_ens">ens</code></td>
<td>
<p>n x m matrix of n forecasts for m ensemble members</p>
</td></tr>
<tr><td><code id="Ens2AFC_+3A_obs">obs</code></td>
<td>
<p>vector of n verifying observations</p>
</td></tr>
<tr><td><code id="Ens2AFC_+3A_...">...</code></td>
<td>
<p>additional arguments not used in function (for compatibility)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the generalized discrimination score for
ensemble forecasts with continuous observations as described in Weigel and
Mason (2011).
</p>


<h3>References</h3>

<p>Weigel, A.P., and S.J. Mason (2011). The Generalized
Discrimination Score for Ensemble Forecasts. Monthly Weather Review, 139(9),
3069-3074. doi:10.1175/MWR-D-10-05069.1
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()
Ens2AFC(tm$fcst, tm$obs)

</code></pre>

<hr>
<h2 id='EnsCorr'>Correlation with Ensemble Mean</h2><span id='topic+EnsCorr'></span>

<h3>Description</h3>

<p>Computes the ensemble mean correlation (Pearson) with the verifying
observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsCorr(ens, obs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsCorr_+3A_ens">ens</code></td>
<td>
<p>n x k matrix of n forecasts from k ensemble members</p>
</td></tr>
<tr><td><code id="EnsCorr_+3A_obs">obs</code></td>
<td>
<p>n verifying observations</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## compute correlation directly
EnsCorr(tm$fcst, tm$obs)

## compute correlation using veriApply
veriApply("EnsCorr", tm$fcst, tm$obs)

</code></pre>

<hr>
<h2 id='EnsError'>Ensemble Mean Error</h2><span id='topic+EnsError'></span><span id='topic+EnsMe'></span><span id='topic+EnsMae'></span><span id='topic+EnsMse'></span><span id='topic+EnsRmse'></span>

<h3>Description</h3>

<p>Computes various ensemble mean error scores. <code>EnsMe</code>
computes the mean error, <code>EnsMae</code> the mean absolute error, <code>EnsMse</code>
the mean squared error, and <code>EnsRmse</code> the square root of the mean
squared error (for consistency with the veri package).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsError(ens, obs, type)

EnsMe(ens, obs)

EnsMae(ens, obs)

EnsMse(ens, obs)

EnsRmse(ens, obs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsError_+3A_ens">ens</code></td>
<td>
<p>n x k matrix of n forecasts from k ensemble members</p>
</td></tr>
<tr><td><code id="EnsError_+3A_obs">obs</code></td>
<td>
<p>n verifying observations</p>
</td></tr>
<tr><td><code id="EnsError_+3A_type">type</code></td>
<td>
<p>specifying what error metric to compute, one of [me, mae, mse,
rmse]</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>, <code><a href="#topic+EnsErrorss">EnsErrorss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># forecast and observations
tm &lt;- toymodel()

# compute the mean bias
EnsError(tm$fcst, tm$obs, type = "me")
# equivalently
EnsMe(tm$fcst, tm$obs)

</code></pre>

<hr>
<h2 id='EnsErrorss'>Ensemble Mean Error Skill scores</h2><span id='topic+EnsErrorss'></span><span id='topic+EnsMaess'></span><span id='topic+EnsMsess'></span><span id='topic+EnsRmsess'></span>

<h3>Description</h3>

<p>Computes various ensemble mean error skill scores.
<code>EnsMaess</code> computes the mean absolute error, <code>EnsMsess</code> the mean
squared error, and <code>EnsRmsess</code> the square root of the mean squared
error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsErrorss(ens, ens.ref, obs, type)

EnsMaess(ens, ens.ref, obs)

EnsMsess(ens, ens.ref, obs)

EnsRmsess(ens, ens.ref, obs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsErrorss_+3A_ens">ens</code></td>
<td>
<p>n x k matrix of n forecasts from k ensemble members</p>
</td></tr>
<tr><td><code id="EnsErrorss_+3A_ens.ref">ens.ref</code></td>
<td>
<p>n x l matrix of m reference forecasts from l ensemble members</p>
</td></tr>
<tr><td><code id="EnsErrorss_+3A_obs">obs</code></td>
<td>
<p>n verifying observations</p>
</td></tr>
<tr><td><code id="EnsErrorss_+3A_type">type</code></td>
<td>
<p>specifying what error metric to compute, one of [me, mae, mse,
rmse]</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>, <code><a href="#topic+EnsError">EnsError</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## compute RMSE skill score against reference forecast with a bias of +2
EnsErrorss(ens = tm$fcst, ens.ref = tm$fcst + 2, obs = tm$obs, type = "rmse")

## compute skill score using veriApply
veriApply("EnsRmsess", fcst = tm$fcst, obs = tm$obs, fcst.ref = tm$fcst + 2)

</code></pre>

<hr>
<h2 id='EnsIgn'>Ignorance Score</h2><span id='topic+EnsIgn'></span><span id='topic+EnsIgnss'></span>

<h3>Description</h3>

<p>Computes the ignorance score <code>EnsIgn</code> and skill score
<code>EnsIgnss</code> for an interpretation of the ensemble as a probability
forecast
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsIgn(ens, obs, type = 3, ...)

EnsIgnss(ens, ens.ref, obs, type = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsIgn_+3A_ens">ens</code></td>
<td>
<p>n x j matrix of n probability forecasts for j categories</p>
</td></tr>
<tr><td><code id="EnsIgn_+3A_obs">obs</code></td>
<td>
<p>n x j matrix of occurence of n verifying observations in j
categories</p>
</td></tr>
<tr><td><code id="EnsIgn_+3A_type">type</code></td>
<td>
<p>selection of plotting positions to convert ensemble counts to
probabilities (default to 3, see <code><a href="#topic+count2prob">count2prob</a></code></p>
</td></tr>
<tr><td><code id="EnsIgn_+3A_...">...</code></td>
<td>
<p>additional arguments for consistency with other functions (not
used)</p>
</td></tr>
<tr><td><code id="EnsIgn_+3A_ens.ref">ens.ref</code></td>
<td>
<p>n x j matrix of n probability forecasts for j categories</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wilks, D.S. (2011). Statistical methods in the atmospheric
sciences (Third Edition). Academic press. Jolliffe, I.T. and D.B.
Stephenson (2012). Forecast Verification. A Practitioner's Guide in
Atmospheric Science. Wiley-Blackwell.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>, <code><a href="#topic+count2prob">count2prob</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## compute ignorance score for tercile forecasts
veriApply("EnsIgn", fcst = tm$fcst, obs = tm$obs, prob = 1:2 / 3)

## compute skill score
veriApply("EnsIgnss", fcst = tm$fcst, obs = tm$obs, prob = 1:2 / 3)

</code></pre>

<hr>
<h2 id='EnsRoca'>Area Under the ROC Curve</h2><span id='topic+EnsRoca'></span><span id='topic+oldEnsRoca'></span><span id='topic+EnsRocss'></span>

<h3>Description</h3>

<p>Computes the area under the ROC curve given the observations.
<code>EnsRoca</code> computes the Area Under the Curve (AUC). For ease of interpretation,
<code>EnsRocss</code> converts the AUC to the range from -1 to 1 with zero indicating
a forecast with no discrimination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsRoca(ens, obs, use.easy = FALSE)

EnsRocss(ens, obs, use.easy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsRoca_+3A_ens">ens</code></td>
<td>
<p>n x j matrix of n probability forecasts for j categories</p>
</td></tr>
<tr><td><code id="EnsRoca_+3A_obs">obs</code></td>
<td>
<p>n x j matrix of occurence of n verifying observations in j categories</p>
</td></tr>
<tr><td><code id="EnsRoca_+3A_use.easy">use.easy</code></td>
<td>
<p>logical, should implementation of standard errors as implemented
in <code>easyVerifcation</code> be used (see below)?</p>
</td></tr>
</table>


<h3>Standard Error</h3>

<p>If used with <code>SpecsVerification &gt;= 0.5</code>, the standard errors as implemented
in the function <code>SpecsVerification::Auc</code> are used.
</p>
<p>If <code>use.easy = TRUE</code> or when used with an older version of <code>SpecsVerification</code>,
the standard error <code class="reqn">\sigma</code> of the ROC area
skill score is given by the following formula after Broecker (2012).
</p>
<p style="text-align: center;"><code class="reqn">\sigma^2 = \frac{1}{3} \left(\frac{1}{N_0} + \frac{1}{N_1} +
  \frac{1}{N_0 N_1} \right)</code>
</p>

<p>Where <code class="reqn">\sigma</code> is the standard error, <code class="reqn">N_1</code> the number of
events, and <code class="reqn">N_0</code> the number of non-events in category <code>i</code>.
</p>


<h3>References</h3>

<p>Br\&quot;ocker, J. (2012). Probability forecasts. Forecast
Verification: A Practitioner's Guide in Atmospheric Science, Second
Edition, 119-139.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>, <code><a href="#topic+EnsRocss">EnsRocss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

## compute ROC area for tercile forecasts using veriApply
veriApply("EnsRoca", fcst = tm$fcst, obs = tm$obs, prob = 1:2 / 3)

</code></pre>

<hr>
<h2 id='EnsSprErr'>Spread to Error Ratio</h2><span id='topic+EnsSprErr'></span>

<h3>Description</h3>

<p>Computes the spread to error ratio (SPR) for probabilistic forecasts - not
unlike the functions in SpecsVerification. SPR &gt; 1 indicates overdispersion
(underconfidence), whereas SPR &lt; indicates overconfidence in the forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsSprErr(ens, obs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsSprErr_+3A_ens">ens</code></td>
<td>
<p>n x k matrix of n forecasts for k ensemble members</p>
</td></tr>
<tr><td><code id="EnsSprErr_+3A_obs">obs</code></td>
<td>
<p>vector with n verifying observations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here we define the spread-error rate as the square root of the ratio
of mean ensemble variance to the mean squared error of the ensemble mean with
the verifying observations
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>, <code><a href="#topic+FairSprErr">FairSprErr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()
EnsSprErr(tm$fcst, tm$obs)

## compute spread to error ratio using veriApply
veriApply("EnsSprErr", fcst = tm$fcst, obs = tm$obs)

</code></pre>

<hr>
<h2 id='FairSprErr'>Fair Spread to Error Ratio</h2><span id='topic+FairSprErr'></span>

<h3>Description</h3>

<p>Compute the spread to error ratio (<code>SPR</code>) for probabilistic forecasts -
not unlike the functions in SpecsVerification. <code>SPR &gt; 1</code> indicates
overdispersion (underconfidence), whereas <code>SPR &lt; 1</code> indicates
overconfidence in the forecasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FairSprErr(ens, obs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FairSprErr_+3A_ens">ens</code></td>
<td>
<p>n x k matrix of n forecasts for k ensemble members</p>
</td></tr>
<tr><td><code id="FairSprErr_+3A_obs">obs</code></td>
<td>
<p>vector with n verifying observations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here we define the spread-error rate as the square root of the ratio
of mean ensemble variance to the mean squared error of the ensemble mean
with the verifying observations. We inflate the intra ensemble sample
variance to account for the finite ensemble size as in Weigel (2011).
</p>


<h3>References</h3>

<p>Weigel, A.P. (2012). Ensemble forecasts. Forecast Verification: A
Practitioner's Guide in Atmospheric Science, Second Edition, 141-166.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>, <code><a href="#topic+FairSprErr">FairSprErr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()
FairSprErr(tm$fcst, tm$obs)

## compute spread to error ratio using veriApply
veriApply("FairSprErr", fcst = tm$fcst, obs = tm$obs)

## compare with 'unfair' spread to error ratio
veriApply("EnsSprErr", fcst = tm$fcst, obs = tm$obs)

</code></pre>

<hr>
<h2 id='generateRef'>Generate Probabilistic Climatological Ensemble Forecast from
Observations</h2><span id='topic+generateRef'></span><span id='topic+indRef'></span>

<h3>Description</h3>

<p>To generate reference ensemble forecasts for forecast evaluation
based on the available observations, <code>indRef</code> implements the
out-of-sample or in-sample protocol to be used and <code>generateRef</code>
produces the corresponding ensemble forecast given the actual observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indRef(
  nfcst,
  type = c("none", "forward", "crossval", "block"),
  indices = 1:nfcst,
  blocklength = 1
)

generateRef(obs, ind)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateRef_+3A_nfcst">nfcst</code></td>
<td>
<p>number of forecast instances to be produce</p>
</td></tr>
<tr><td><code id="generateRef_+3A_type">type</code></td>
<td>
<p>type of out-of-sample protocol to be applied (see below)</p>
</td></tr>
<tr><td><code id="generateRef_+3A_indices">indices</code></td>
<td>
<p>Subset of the observations / forecast times to be used for
reference forecasts</p>
</td></tr>
<tr><td><code id="generateRef_+3A_blocklength">blocklength</code></td>
<td>
<p>for cross-validation and split-sample</p>
</td></tr>
<tr><td><code id="generateRef_+3A_obs">obs</code></td>
<td>
<p>vector of observations</p>
</td></tr>
<tr><td><code id="generateRef_+3A_ind">ind</code></td>
<td>
<p>list or matrix of dimension (<code>n x nref</code>) of indices
of the observations to be used for each forecast instance</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ind</code></td>
<td>
<p>A list of indices to be used for each forecast from
<code>1</code> to <code>nfcst</code></p>
</td></tr>
</table>


<h3>Cross-validation</h3>

<p>Leave-one-out and leave-n-out cross-validation
reference forecasts can be produced by setting <code>type = "crossval"</code>. By
default, the blocklength is set to <code>1</code>, but moving blocks of length
<code>n</code> can be specified by setting <code>blocklength = n</code>.
</p>


<h3>Split sample</h3>

<p>In contrast to <code>type="crossval"</code>,
<code>type="block"</code> is used for split-sample validation with
non-overlapping blocks of length <code>blocklength</code> retained for
validation.
</p>


<h3>Forward</h3>

<p>Correspondingly, reference forecasts that are only based on
past (future) observations can be produced using <code>type = "forward"</code>.
For this, the first half of the reference forecasts only uses future
information, i.e. observations <code>2:n</code> for forecast <code>1</code>, <code>3:n</code>
for <code>2</code> and so forth. The second half of the reference forecasts use
only past observations, i.e. observations <code>1:(n-1)</code> for forecast
<code>n</code>, <code>1:(n-2)</code> for <code>n-1</code>, etc.
</p>


<h3>Subsetting</h3>

<p>In combination with the above, a subset of the
observations can be specified for use as reference forecasts by providing
the explicit indices of the observations to be used via <code>indices=1:k</code>.
In combination with the <code>forward</code> method, all observations in
<code>indices</code> will be used to construct the reference forecast for
forecasts not included in <code>indices</code> (i.e. if <code>nfcst &gt;
  max(indices)</code>).
</p>

<hr>
<h2 id='size'>Size of Array or Vector</h2><span id='topic+size'></span>

<h3>Description</h3>

<p>Return dimension of array or length of vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="size_+3A_x">x</code></td>
<td>
<p>array or vector</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toymodel()

sapply(tm, size)

</code></pre>

<hr>
<h2 id='toymodel'>Create Example Forecast-Observation Pairs</h2><span id='topic+toymodel'></span><span id='topic+toyarray'></span>

<h3>Description</h3>

<p>This toy model lets you create forecast-observation pairs with specified
ensemble and forecast size, correlation skill, and overconfidence
(underdispersion) for application with the verification functionality
provided as part of the easyVerification package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toymodel(N = 35, nens = 51, alpha = 0.5, beta = 0)

toyarray(dims = c(10, 5), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="toymodel_+3A_n">N</code></td>
<td>
<p>number of forecast instances</p>
</td></tr>
<tr><td><code id="toymodel_+3A_nens">nens</code></td>
<td>
<p>number of ensemble members</p>
</td></tr>
<tr><td><code id="toymodel_+3A_alpha">alpha</code></td>
<td>
<p>nominal correlation skill of forecasts</p>
</td></tr>
<tr><td><code id="toymodel_+3A_beta">beta</code></td>
<td>
<p>overconfidence parameter (see details)</p>
</td></tr>
<tr><td><code id="toymodel_+3A_dims">dims</code></td>
<td>
<p>independent (e.g. spatial) dimensions for the toy model</p>
</td></tr>
<tr><td><code id="toymodel_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="#topic+toymodel">toymodel</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The toy model is the TM2 model as introduced by Weigel and Bowler
(2009) with a slight modification to allow for forecasts with negative
correlation skill. In this toy model, the observations <code class="reqn">x</code> and forecasts
<code class="reqn">f_i</code> are defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">x = \mu_x + \epsilon_x</code>
</p>

<p style="text-align: center;"><code class="reqn">f_i = \alpha / |\alpha| \mu_x + \epsilon_{\beta} + \epsilon_i</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\mu_x ~ N(0, \alpha^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_x ~ N(0, 1 - \alpha^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_{\beta} ~ N(0, \beta^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_i ~ N(0, 1 - \alpha^2 - \beta^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha^2 \le 1</code>
</p>

<p style="text-align: center;"><code class="reqn">0 \le \beta \le 1 - \alpha^2</code>
</p>



<h3>Note</h3>

<p>This toy model is intended to provide example forecast observation
pairs and not to serve as a conceptual model to study real forecasts. For
models to do the latter, please refer to Siegert et al. (2015).
</p>


<h3>References</h3>

<p>A. Weigel and N. Bowler (2009). Comment on 'Can multi-model
combination really enhance the prediction skill of probabilistic ensemble
forecasts?'. <em>Quarterly Journal of the Royal Meteorological Society</em>,
135, 535-539.
</p>
<p>S. Siegert <em>et al.</em> (2015). A Bayesian framework for verification and
recalibration of ensemble forecasts: How uncertain is NAO predictability?
Preprint on ArXiv, <a href="https://arxiv.org/abs/1504.01933">https://arxiv.org/abs/1504.01933</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## compute the correlation for a toy forecast with default parameters
tm &lt;- toyarray()
f.corr &lt;- veriApply("EnsCorr", fcst = tm$fcst, obs = tm$obs)

</code></pre>

<hr>
<h2 id='veriApply'>Apply Verification Metrics to Large Datasets</h2><span id='topic+veriApply'></span>

<h3>Description</h3>

<p>This wrapper applies verification metrics to arrays of forecast ensembles and
verifying observations. Various array-based data formats are supported.
Additionally, continuous forecasts (and observations) are transformed to
category forecasts using user-defined absolute thresholds or percentiles of
the long-term climatology (see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>veriApply(
  verifun,
  fcst,
  obs,
  fcst.ref = NULL,
  tdim = length(dim(fcst)) - 1,
  ensdim = length(dim(fcst)),
  prob = NULL,
  threshold = NULL,
  strategy = "none",
  na.rm = FALSE,
  fracmin = 0.8,
  nmin = NULL,
  parallel = FALSE,
  maxncpus = 16,
  ncpus = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="veriApply_+3A_verifun">verifun</code></td>
<td>
<p>Name of function to compute verification metric (score, skill
score)</p>
</td></tr>
<tr><td><code id="veriApply_+3A_fcst">fcst</code></td>
<td>
<p>array of forecast values (at least 2-dimensional)</p>
</td></tr>
<tr><td><code id="veriApply_+3A_obs">obs</code></td>
<td>
<p>array or vector of verifying observations</p>
</td></tr>
<tr><td><code id="veriApply_+3A_fcst.ref">fcst.ref</code></td>
<td>
<p>array of forecast values for the reference forecast (skill
scores only)</p>
</td></tr>
<tr><td><code id="veriApply_+3A_tdim">tdim</code></td>
<td>
<p>index of dimension with the different forecasts</p>
</td></tr>
<tr><td><code id="veriApply_+3A_ensdim">ensdim</code></td>
<td>
<p>index of dimension with the different ensemble members</p>
</td></tr>
<tr><td><code id="veriApply_+3A_prob">prob</code></td>
<td>
<p>probability threshold for category forecasts (see below)</p>
</td></tr>
<tr><td><code id="veriApply_+3A_threshold">threshold</code></td>
<td>
<p>absolute threshold for category forecasts (see below)</p>
</td></tr>
<tr><td><code id="veriApply_+3A_strategy">strategy</code></td>
<td>
<p>type of out-of-sample reference forecasts or  namelist with
arguments as in <code><a href="#topic+indRef">indRef</a></code> or list of indices for each
forecast instance</p>
</td></tr>
<tr><td><code id="veriApply_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should incomplete forecasts be used?</p>
</td></tr>
<tr><td><code id="veriApply_+3A_fracmin">fracmin</code></td>
<td>
<p>fraction of forecasts that are not-missing for forecast to
be evaluated. Used to determine <code>nmin</code> when <code>is.null(nmin)</code></p>
</td></tr>
<tr><td><code id="veriApply_+3A_nmin">nmin</code></td>
<td>
<p>number of forecasts that are not-missing for forecast to
be evaluated. If both <code>nmin</code> an d <code>fracmin</code> are set, <code>nmin</code>
takes precedence</p>
</td></tr>
<tr><td><code id="veriApply_+3A_parallel">parallel</code></td>
<td>
<p>logical, should parallel execution of verification be used
(see below)?</p>
</td></tr>
<tr><td><code id="veriApply_+3A_maxncpus">maxncpus</code></td>
<td>
<p>upper bound for self-selected number of CPUs</p>
</td></tr>
<tr><td><code id="veriApply_+3A_ncpus">ncpus</code></td>
<td>
<p>number of CPUs used in parallel computation, self-selected
number of CPUs is used when <code>is.null(ncpus)</code> (the default).</p>
</td></tr>
<tr><td><code id="veriApply_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>verifun</code></p>
</td></tr>
</table>


<h3>List of functions to be called</h3>

<p>The selection of verification
functions supplied with this package and as part of
<code>SpecsVerification</code> can be enquired using
<code>ls(pos='package:easyVerification')</code> and
<code>ls(pos='package:SpecsVerification')</code> respectively. Please note,
however, that only some of the functions provided as part of
<code>SpecsVerification</code> can be used with <code><a href="#topic+veriApply">veriApply</a></code>.
Functions that can be used include for example the (fair) ranked
probability score <code><a href="SpecsVerification.html#topic+EnsRps">EnsRps</a></code>,
<code><a href="SpecsVerification.html#topic+FairRps">FairRps</a></code>, and its skill score
<code><a href="SpecsVerification.html#topic+EnsRpss">EnsRpss</a></code>,
<code><a href="SpecsVerification.html#topic+FairRpss">FairRpss</a></code>, or the continuous ranked
probability score <code><a href="SpecsVerification.html#topic+EnsCrps">EnsCrps</a></code>, etc.
</p>


<h3>Conversion to category forecasts</h3>

<p>To automatically convert
continuous forecasts into category forecasts, absolute (<code>threshold</code>)
or relative thresholds (<code>prob</code>) have to be supplied. For some scores
and skill scores (e.g. the ROC area and skill score), a list of categories
will be supplied with categories ordered. That is, if <code>prob = 1:2/3</code>
for tercile forecasts, <code>cat1</code> corresponds to the lower tercile,
<code>cat2</code> to the middle, and <code>cat3</code> to the upper tercile.
</p>
<p>Absolute and relative thresholds can be supplied in various formats. If a
vector of thresholds is supplied with the <code>threshold</code> argument, the
same threshold is applied to all forecasts (e.g. lead times, spatial
locations). If a vector of relative thresholds is supplied using
<code>prob</code>, the category boundaries to be applied are computed separately
for each space-time location. Relative boundaries specified using
<code>prob</code> are computed separately for the observations and forecasts, but
jointly for all available ensemble members.
</p>
<p>Location specific thresholds can also be supplied. If the thresholds are
supplied as a matrix, the number of rows has to correspond to the number of
forecast space-time locations (i.e. same length as
<code>length(fcst)/prod(dim(fcst)[c(tdim, ensdim)])</code>). Alternatively, but
equivalently, the thresholds can also be supplied with the dimensionality
corresponding to the <code>obs</code> array with the difference that the forecast
dimension in <code>obs</code> contains the category boundaries (absolute or
relative) and thus may differ in length.
</p>


<h3>Out-of-sample reference forecasts</h3>

<p><code>strategy</code> specifies the
set-up of the climatological reference forecast for skill scores if no
explicit reference forecast is provided. The default is <code>strategy = "none"</code>,
that is all available observations are used as equiprobable
members of a reference forecast. Alternatively, <code>strategy = "crossval"</code>
can be used for leave-one-out crossvalidated reference forecasts,
or <code>strategy = "forward"</code> for a forward protocol (see <code><a href="#topic+indRef">indRef</a></code>).
</p>
<p>Alternatively, a list with named parameters corresponding to the input
arguments of <code><a href="#topic+indRef">indRef</a></code> can be supplied for more fine-grained
control over standard cases. Finally, also a list with observation indices
to be used for each forecast can be supplied (see <code><a href="#topic+generateRef">generateRef</a></code>).
</p>


<h3>Parallel processing</h3>

<p>Parallel processing is enabled using the
<code><a href="parallel.html#topic+parallel">parallel</a></code> package. Parallel verification is using
<code>ncpus</code> <code>FORK</code> clusters or, if <code>ncpus</code> are not specified,
one less than the autod-etected number of cores. The maximum number of cores
used for parallel processing with auto-detection of the number of available
cores can be set with the <code>maxncpus</code> argument.
</p>
<p>Progress bars are available for non-parallel computation of the
verification metrics. Please note, however, that the progress bar only
indicates the time of computation needed for the actual verification
metrics, input and output re-arrangement is not included in the progress
bar.
</p>


<h3>Note</h3>

<p>If the forecasts and observations are only available as category
probabilities (or ensemble counts as used in <code>SpecsVerification</code>) as
opposed to as continuous numeric variables, <code>veriApply</code> cannot be used
but the atomic verification functions for category forecasts have to be
applied directly.
</p>
<p>Out-of-sample reference forecasts are not fully supported for
categorical forecasts defined on the distribution of forecast values (e.g.
using the argument <code>prob</code>). Whereas only the years specified in
<code>strategy</code> are used for the reference forecasts, the probability
thresholds for the reference forecasts are defined on the collection of
years specified in <code>strategy</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+convert2prob">convert2prob</a></code> for conversion of continuous into
category forecasts (and observations)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tm &lt;- toyarray()
f.me &lt;- veriApply("EnsMe", tm$fcst, tm$obs)

## find more examples and instructions in the vignette
## Not run: 
devtools::install_github("MeteoSwiss/easyVerification", build_vignettes = TRUE)
library("easyVerification")
vignette("easyVerification")

## End(Not run)

</code></pre>

<hr>
<h2 id='veriUnwrap'>Unwrap Arguments and Hand Over to Verification Function</h2><span id='topic+veriUnwrap'></span>

<h3>Description</h3>

<p>Decomposes input arguments into forecast, verifying observations, and
reference forecast and hands these over to the function provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>veriUnwrap(
  x,
  verifun,
  nind = c(nens = ncol(x) - 1, nref = 0, nobs = 1, nprob = 0, nthresh = 0),
  ref.ind = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="veriUnwrap_+3A_x">x</code></td>
<td>
<p>n x k + 1 matrix with n forecasts of k ensemble members plus the
verifying observations</p>
</td></tr>
<tr><td><code id="veriUnwrap_+3A_verifun">verifun</code></td>
<td>
<p>character string with function name to be executed</p>
</td></tr>
<tr><td><code id="veriUnwrap_+3A_nind">nind</code></td>
<td>
<p>named vector with number of ensemble members, ensemble members of
reference forecasts, observations (defaults to 1), probability or absolute
thresholds (see details)</p>
</td></tr>
<tr><td><code id="veriUnwrap_+3A_ref.ind">ref.ind</code></td>
<td>
<p>list with specifications for the reference forecast
(see details)</p>
</td></tr>
<tr><td><code id="veriUnwrap_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code>verifun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Forecast verification metrics are only computed for forecasts with
non-missing verifying observation and at least one non-missing ensemble
member. Metrics for all other forecasts are set to missing. For aggregate
metrics (e.g. skill scores) the metric is computed over non-missing
observation/forecast pairs only.
</p>
<p>For computation of skill scores, reference forecasts can be provided. That
is, the first <code>nens</code> columns of <code>x</code> contain the forecasts, the
<code>(nens + 1):(ncol(x) - 1)</code> following columns contain the reference
forecast, and the final column contains the observations. If no reference
forecast is provided (i.e. <code>ncol(x) == nens + 1</code>), a climatological
forecast is constructed from the <code>n</code> verifying observations.
</p>
<p>The elements of vector <code>nind</code> have to be named with <code>nens</code>
containing the number of ensemble members, <code>nref</code> the number of
ensemble members in the reference forecast for skill scores, <code>nobs</code>
the number of observations (only one supported), <code>nprob</code> the number of
probability thresholds, and <code>nthresh</code> the number of absolute threshold
for conversion of continuous forecasts to category forecasts.
</p>
<p><code>ref.ind</code> specifies the set-up of the climatological reference
forecast for skill scores if no explicit reference forecast is provided
(see <code><a href="#topic+indRef">indRef</a></code>). Also, <code>ref.ind</code> is used to determine the
baseline to estimate the percentile-based category boundaries to convert
continuous forecasts to category probabilities.
</p>


<h3>Note</h3>

<p>Out-of-sample reference forecasts are now fully supported.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veriApply">veriApply</a></code>
</p>

<hr>
<h2 id='weisheimer'>Compute Reliability Categories as in Weisheimer et al. (2014)</h2><span id='topic+weisheimer'></span>

<h3>Description</h3>

<p>This function implements the reliability categorisation for forecasts of binary
events as documented in Weisheimer et al. (2014). It has only been implemented for
category forecasts with categories defined relative to the forecast and observed
climatological distribution (i.e. without systematic bias).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weisheimer(
  ens,
  obs,
  pthresh = 2/3,
  nboot = 100,
  brier.thresholds = seq(0, 1, 0.2),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weisheimer_+3A_ens">ens</code></td>
<td>
<p>n x k matrix of n forecasts from k ensemble members</p>
</td></tr>
<tr><td><code id="weisheimer_+3A_obs">obs</code></td>
<td>
<p>n verifying observations</p>
</td></tr>
<tr><td><code id="weisheimer_+3A_pthresh">pthresh</code></td>
<td>
<p>probability threshold to convert to category forecasts.
If negative, event falling below threshold is used, else, event
above threshold is used.</p>
</td></tr>
<tr><td><code id="weisheimer_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap replicates to estimate 75 percent
confidence interval</p>
</td></tr>
<tr><td><code id="weisheimer_+3A_brier.thresholds">brier.thresholds</code></td>
<td>
<p>Thresholds used to bin the forecasts (see
<code><a href="verification.html#topic+brier">brier</a></code>)</p>
</td></tr>
<tr><td><code id="weisheimer_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility with other scores</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
