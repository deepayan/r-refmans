<!DOCTYPE html><html><head><title>Help for package mmcif</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mmcif}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#log_chol'><p>Computes the Log Cholesky Decomposition and the Inverse</p></a></li>
<li><a href='#mmcif_data'><p>Sets up an Object to Compute the Log Composite Likelihood</p></a></li>
<li><a href='#mmcif_fit'><p>Fits a Mixed Competing Risk Model</p></a></li>
<li><a href='#mmcif_logLik'><p>Evaluates the Log Composite Likelihood and its Gradient</p></a></li>
<li><a href='#mmcif_pd_cond'><p>Computes Marginal Measures Using Two Observations</p></a></li>
<li><a href='#mmcif_pd_univariate'><p>Computes Marginal Measures for One Observation</p></a></li>
<li><a href='#mmcif_sandwich'><p>Computes the Sandwich Estimator</p></a></li>
<li><a href='#mmcif_start_values'><p>Finds Staring Values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Mixed Multivariate Cumulative Incidence Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits the mixed cumulative incidence functions model suggested by 
    &lt;<a href="https://doi.org/10.1093%2Fbiostatistics%2Fkxx072">doi:10.1093/biostatistics/kxx072</a>&gt; which decomposes within cluster 
    dependence of risk and timing. The estimation method supports computation in 
    parallel using a shared memory C++ implementation. A sandwich estimator of the 
    covariance matrix is available. Natural cubic splines are used to provide a 
    flexible model for the cumulative incidence functions.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/boennecd/mmcif">https://github.com/boennecd/mmcif</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/boennecd/mmcif/issues">https://github.com/boennecd/mmcif/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, testthat, psqn</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, stats, alabama</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), xml2, mvtnorm, R.rsp, mets</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-15 21:22:13 UTC; boennecd</td>
</tr>
<tr>
<td>Author:</td>
<td>Benjamin Christoffersen
    <a href="https://orcid.org/0000-0002-7182-1346"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre, aut],
  Mark Clements [cph],
  Alan Genz [cph],
  Frank Bretz [cph],
  Torsten Hothorn [cph],
  R-core [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Benjamin Christoffersen &lt;boennecd@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-17 20:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='log_chol'>Computes the Log Cholesky Decomposition and the Inverse</h2><span id='topic+log_chol'></span><span id='topic+log_chol_inv'></span>

<h3>Description</h3>

<p>Computes the log Cholesky decomposition and the inverse of it. The functions
are provided as the log Cholesky decomposition is used in the
parameterization of the covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_chol(x)

log_chol_inv(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log_chol_+3A_x">x</code></td>
<td>
<p>A positive definite matrix or a vector with a log Cholesky
decomposition.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector with the log Cholesky decomposition or a matrix with the
inverse.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
S &lt;- drop(rWishart(1, 10, diag(10)))
log_chol(S)
stopifnot(isTRUE(all.equal(S, log_chol_inv(log_chol(S)))),
          (NCOL(S) * (NCOL(S) + 1L)) %/% 2L == length(log_chol(S)))

</code></pre>

<hr>
<h2 id='mmcif_data'>Sets up an Object to Compute the Log Composite Likelihood</h2><span id='topic+mmcif_data'></span>

<h3>Description</h3>

<p>Sets up the R and C++ objects that are needed to evaluate the log composite
likelihood. This reduces to a log likelihood when only clusters of size one
or two are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_data(
  formula,
  data,
  cause,
  time,
  cluster_id,
  max_time,
  spline_df = 3L,
  left_trunc = NULL,
  ghq_data = NULL,
  strata = NULL,
  knots = NULL,
  boundary_quantiles = c(0.025, 0.975)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_data_+3A_formula">formula</code></td>
<td>
<p><code>formula</code> for covariates in the risk and trajectories.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with the covariate and outcome information.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_cause">cause</code></td>
<td>
<p>an integer vector with the cause of each outcome. If there are
<code>n_causes</code> of outcome, then the vector should have values in
<code>1:(n_causes + 1)</code> with <code>n_causes + 1</code> indicating censoring.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_time">time</code></td>
<td>
<p>a numeric vector with the observed times.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_cluster_id">cluster_id</code></td>
<td>
<p>an integer vector with the cluster id of each individual.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_max_time">max_time</code></td>
<td>
<p>the maximum time after which there are no observed events. It
is denoted by <code class="reqn">\tau</code> in the original article (Cederkvist et al., 2019).</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_spline_df">spline_df</code></td>
<td>
<p>degrees of freedom to use for each spline in the
cumulative incidence functions.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_left_trunc">left_trunc</code></td>
<td>
<p>numeric vector with left-truncation times. <code>NULL</code>
implies that there are not any individuals with left-truncation.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_ghq_data">ghq_data</code></td>
<td>
<p>the default Gauss-Hermite quadrature nodes and weights to
use. It should be a list with two elements called <code>"node"</code>
and <code>"weight"</code>. A default is provided if <code>NULL</code> is passed.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_strata">strata</code></td>
<td>
<p>an integer vector or a factor vector with the strata of each
individual. <code>NULL</code> implies that there are no strata.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_knots">knots</code></td>
<td>
<p>A list of lists with knots for the splines. The inner lists
needs to have elements called <code>"knots"</code> and
<code>"boundary_knots"</code> which are passed to a function like <code><a href="splines.html#topic+ns">ns</a></code>.
<code>NULL</code> yields defaults based on the quantiles of the observed event
times. Note that the knots needs to be on the
<code>atanh((time - max_time / 2) / (max_time / 2))</code> scale.</p>
</td></tr>
<tr><td><code id="mmcif_data_+3A_boundary_quantiles">boundary_quantiles</code></td>
<td>
<p>two dimensional numerical vector with boundary
quantile probabilities after which the natural cubic splines for the time
transformations are restricted to be linear. Only relevant if <code>knots</code> is
not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class mmcif which is needed for the other functions in the
package.
</p>


<h3>References</h3>

<p>Cederkvist, L., Holst, K. K., Andersen, K. K., &amp;
Scheike, T. H. (2019).
<em>Modeling the cumulative incidence function of multivariate competing
risks data allowing for within-cluster dependence of risk and timing</em>.
Biostatistics, Apr 1, 20(2), 199-217.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mmcif_fit">mmcif_fit</a></code>, <code><a href="#topic+mmcif_start_values">mmcif_start_values</a></code> and
<code><a href="#topic+mmcif_sandwich">mmcif_sandwich</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  # prepare the data
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # randomly sub-sample
  set.seed(1)
  prt_use &lt;- subset(
    prt_use, id %in% sample(unique(id), length(unique(id)) %/% 10L))

  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country)
}

</code></pre>

<hr>
<h2 id='mmcif_fit'>Fits a Mixed Competing Risk Model</h2><span id='topic+mmcif_fit'></span>

<h3>Description</h3>

<p>Fits mixed cumulative incidence functions model by maximizing the log
composite likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_fit(
  par,
  object,
  n_threads = 1L,
  control.outer = list(itmax = 100L, method = "nlminb", kkt2.check = FALSE, trace =
    FALSE),
  control.optim = list(eval.max = 10000L, iter.max = 10000L),
  ghq_data = object$ghq_data,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_fit_+3A_par">par</code></td>
<td>
<p>numeric vector with parameters. This is using a log
Cholesky decomposition for the covariance matrix.</p>
</td></tr>
<tr><td><code id="mmcif_fit_+3A_object">object</code></td>
<td>
<p>an object from <code><a href="#topic+mmcif_data">mmcif_data</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_fit_+3A_n_threads">n_threads</code></td>
<td>
<p>the number of threads to use.</p>
</td></tr>
<tr><td><code id="mmcif_fit_+3A_control.outer">control.outer</code>, <code id="mmcif_fit_+3A_control.optim">control.optim</code>, <code id="mmcif_fit_+3A_...">...</code></td>
<td>
<p>arguments passed to
<code><a href="alabama.html#topic+auglag">auglag</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_fit_+3A_ghq_data">ghq_data</code></td>
<td>
<p>the Gauss-Hermite quadrature nodes and weights to use.
It should be a list with two elements called <code>"node"</code> and <code>"weight"</code>.
The argument can also be a list with lists with different sets of quadrature
nodes. In this case, fits are successively made using the previous fit as the
starting value. This may
reduce the computation time by starting with fewer quadrature nodes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output from <code><a href="nloptr.html#topic+auglag">auglag</a></code>.
</p>


<h3>References</h3>

<p>Cederkvist, L., Holst, K. K., Andersen, K. K., &amp;
Scheike, T. H. (2019).
<em>Modeling the cumulative incidence function of multivariate competing
risks data allowing for within-cluster dependence of risk and timing</em>.
Biostatistics, Apr 1, 20(2), 199-217.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mmcif_data">mmcif_data</a></code>, <code><a href="#topic+mmcif_start_values">mmcif_start_values</a></code> and
<code><a href="#topic+mmcif_sandwich">mmcif_sandwich</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  # prepare the data
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # randomly sub-sample
  set.seed(1)
  prt_use &lt;- subset(
    prt_use, id %in% sample(unique(id), length(unique(id)) %/% 10L))

  n_threads &lt;- 2L
  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country)

  # get the staring values
  start_vals &lt;- mmcif_start_values(mmcif_obj, n_threads = n_threads)

  # estimate the parameters
  ests &lt;- mmcif_fit(start_vals$upper, mmcif_obj, n_threads = n_threads)

  # show the estimated covariance matrix of the random effects
  tail(ests$par, 10L) |&gt; log_chol_inv() |&gt; print()

  # gradient is ~ zero
  mmcif_logLik_grad(
    mmcif_obj, ests$par, is_log_chol = TRUE, n_threads = n_threads) |&gt;
    print()
}

</code></pre>

<hr>
<h2 id='mmcif_logLik'>Evaluates the Log Composite Likelihood and its Gradient</h2><span id='topic+mmcif_logLik'></span><span id='topic+mmcif_logLik_grad'></span>

<h3>Description</h3>

<p>Evaluates the log composite likelihood and its gradient using adaptive
Gauss-Hermite quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_logLik(
  object,
  par,
  ghq_data = object$ghq_data,
  n_threads = 1L,
  is_log_chol = FALSE
)

mmcif_logLik_grad(
  object,
  par,
  ghq_data = object$ghq_data,
  n_threads = 1L,
  is_log_chol = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_logLik_+3A_object">object</code></td>
<td>
<p>an object from <code><a href="#topic+mmcif_data">mmcif_data</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_logLik_+3A_par">par</code></td>
<td>
<p>numeric vector with parameters. This is either using a log
Cholesky decomposition for the covariance matrix or the covariance matrix.</p>
</td></tr>
<tr><td><code id="mmcif_logLik_+3A_ghq_data">ghq_data</code></td>
<td>
<p>the Gauss-Hermite quadrature nodes and weights to
use. It should be a list with two elements called <code>"node"</code>
and <code>"weight"</code>. A default is provided if <code>NULL</code> is passed.</p>
</td></tr>
<tr><td><code id="mmcif_logLik_+3A_n_threads">n_threads</code></td>
<td>
<p>the number of threads to use.</p>
</td></tr>
<tr><td><code id="mmcif_logLik_+3A_is_log_chol">is_log_chol</code></td>
<td>
<p>logical for whether a log Cholesky decomposition is used
for the covariance matrix or the full covariance matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector with either the log composite likelihood or the gradient of
it.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  # prepare the data
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # randomly sub-sample
  set.seed(1)
  prt_use &lt;- subset(
    prt_use, id %in% sample(unique(id), length(unique(id)) %/% 10L))

  n_threads &lt;- 2L
  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country)

  # get the staring values
  start_vals &lt;- mmcif_start_values(mmcif_obj, n_threads = n_threads)

  # compute the log composite likelihood and the gradient at the starting
  # values
  mmcif_logLik(
    mmcif_obj, start_vals$upper, is_log_chol = TRUE, n_threads = n_threads) |&gt;
    print()
  mmcif_logLik_grad(
    mmcif_obj, start_vals$upper, is_log_chol = TRUE, n_threads = n_threads) |&gt;
    print()
}

</code></pre>

<hr>
<h2 id='mmcif_pd_cond'>Computes Marginal Measures Using Two Observations</h2><span id='topic+mmcif_pd_cond'></span><span id='topic+mmcif_pd_bivariate'></span>

<h3>Description</h3>

<p>Computes bivariate figures such as conditional CIFs, survival probabilities,
and  hazards or bivariate CIFs, densities, and survival probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_pd_cond(
  par,
  object,
  newdata,
  cause,
  time,
  left_trunc = NULL,
  ghq_data = object$ghq_data,
  strata = NULL,
  which_cond,
  type_cond = "derivative",
  type_obs = "cumulative"
)

mmcif_pd_bivariate(
  par,
  object,
  newdata,
  cause,
  time,
  left_trunc = NULL,
  ghq_data = object$ghq_data,
  strata = NULL,
  use_log = FALSE,
  type = c("cumulative", "cumulative")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_pd_cond_+3A_par">par</code></td>
<td>
<p>numeric vector with the model parameters.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_object">object</code></td>
<td>
<p>an object from <code><a href="#topic+mmcif_data">mmcif_data</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_newdata">newdata</code></td>
<td>
<p>a <code>data.frame</code> with data for the observations. It needs
to have two rows.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_cause">cause</code></td>
<td>
<p>an integer vector with the cause of each outcome. If there are
<code>n_causes</code> of outcome, then the vector should have values in
<code>1:(n_causes + 1)</code> with <code>n_causes + 1</code> indicating censoring.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_time">time</code></td>
<td>
<p>a numeric vector with the observed times.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_left_trunc">left_trunc</code></td>
<td>
<p>numeric vector with left-truncation times. <code>NULL</code>
implies that there are not any individuals with left-truncation.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_ghq_data">ghq_data</code></td>
<td>
<p>the Gauss-Hermite quadrature nodes and weights to
use. It should be a list with two elements called <code>"node"</code>
and <code>"weight"</code>. A default is provided if <code>NULL</code> is passed.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_strata">strata</code></td>
<td>
<p>an integer vector or a factor vector with the strata of each
individual. <code>NULL</code> implies that there are no strata.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_which_cond">which_cond</code></td>
<td>
<p>an integer with value one or two for the index of the
individual that is being conditioned on.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_type_cond">type_cond</code></td>
<td>
<p>a character for the type of outcome that is being
conditioned on.
<code>"derivative"</code> for the derivative of a CIF or
<code>"cumulative"</code> for a CIF or the survival probability.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_type_obs">type_obs</code></td>
<td>
<p>a character the type of conditional measure. It can be
<code>"derivative"</code> for the derivative of a CIF,
<code>"cumulative"</code> for a CIF or the survival probability, and
<code>"hazard"</code> for the hazard.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_use_log">use_log</code></td>
<td>
<p>a logical for whether the returned output should be on the
log scale.</p>
</td></tr>
<tr><td><code id="mmcif_pd_cond_+3A_type">type</code></td>
<td>
<p>a 2D character vector for the type of measures for each
observation. The elements can be
<code>"derivative"</code> for the derivative of a CIF or
<code>"cumulative"</code> for a CIF or the survival probability.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric scalar with the requested quantity.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mmcif_pd_univariate">mmcif_pd_univariate</a></code> and <code><a href="#topic+mmcif_fit">mmcif_fit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # Gauss Hermite quadrature nodes and weights from fastGHQuad::gaussHermiteData
  ghq_data &lt;- list(
    node = c(-3.43615911883774, -2.53273167423279, -1.75668364929988, -1.03661082978951,
             -0.342901327223705, 0.342901327223705, 1.03661082978951, 1.75668364929988,
             2.53273167423279, 3.43615911883774),
    weight = c(7.6404328552326e-06, 0.00134364574678124, 0.0338743944554811, 0.240138611082314,
               0.610862633735326,0.610862633735326, 0.240138611082315, 0.033874394455481,
               0.00134364574678124, 7.64043285523265e-06))

  # setup the object for the computation
  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country, ghq_data = ghq_data)

  # previous estimates
  par &lt;- c(0.727279974859164, 0.640534073288067, 0.429437766165371, 0.434367104339573,
           -2.4737847536253, -1.49576564624673, -1.89966050143904, -1.58881346649412,
           -5.5431198001029, -3.5328359024178, -5.82305147022587, -3.4531896212114,
           -5.29132887832377, -3.36106297109548, -6.03690322125729, -3.49516746825624,
           2.55000711185704, 2.71995985605891, 2.61971498736444, 3.05976391058032,
           -5.97173564860957, -3.37912051983482, -5.14324860374941, -3.36396780694965,
           -6.02337246348561, -3.03754644968859, -5.51267338700737, -3.01148582224673,
           2.69665543753264, 2.59359057553995, 2.7938341786374, 2.70689750644755,
           -0.362056555418564, 0.24088005091276, 0.124070380635372, -0.246152029808377,
           -0.0445628476462479, -0.911485513197845, -0.27911988106887, -0.359648419277058,
           -0.242711959678559, -6.84897302527358)

  # the test data we will use
  test_dat &lt;- data.frame(
    country = factor(c("Norway", "Norway"), levels(prt_use$country)),
    status = c(1L, 2L), time = c(60, 75))

  # probability that both experience the event prior to the two times
  mmcif_pd_bivariate(
    par = par, object = mmcif_obj, newdata = test_dat, cause = status,
    strata = country, ghq_data = ghq_data, time = time, type =
      c("cumulative", "cumulative")) |&gt;
    print()

  # density that one experiences an event at the point and the other
  # experiences an event prior to the point
  mmcif_pd_bivariate(
    par = par, object = mmcif_obj, newdata = test_dat, cause = status,
    strata = country, ghq_data = ghq_data, time = time, type =
      c("derivative", "cumulative")) |&gt;
    print()

  # probability that both survive up to the passed points
  mmcif_pd_bivariate(
    par = par, object = mmcif_obj, newdata = test_dat, cause = c(3L, 3L),
    strata = country, ghq_data = ghq_data, time = time, type =
      c("cumulative", "cumulative")) |&gt;
    print()

  # conditional hazard given that the other experiences an event prior to time
  mmcif_pd_cond(
    par = par, object = mmcif_obj, newdata = test_dat, cause = status,
    strata = country, ghq_data = ghq_data, time = time, which_cond = 1L,
    type_cond = "cumulative", type_obs = "hazard") |&gt;
    print()

  # conditional CIF given that the other experiences an event prior to the
  # time
  mmcif_pd_cond(
    par = par, object = mmcif_obj, newdata = test_dat, cause = c(2L, 2L),
    strata = country, ghq_data = ghq_data, time = time, which_cond = 1L,
    type_cond = "cumulative", type_obs = "cumulative") |&gt;
    print()

  # same but given that the other experiences the event at the point
  mmcif_pd_cond(
    par = par, object = mmcif_obj, newdata = test_dat, cause = c(2L, 2L),
    strata = country, ghq_data = ghq_data, time = time, which_cond = 1L,
    type_cond = "derivative", type_obs = "cumulative") |&gt;
    print()
}

</code></pre>

<hr>
<h2 id='mmcif_pd_univariate'>Computes Marginal Measures for One Observation</h2><span id='topic+mmcif_pd_univariate'></span>

<h3>Description</h3>

<p>Computes the marginal cumulative incidence functions (CIF), marginal survival
function or the derivative of the CIF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_pd_univariate(
  par,
  object,
  newdata,
  cause,
  time,
  left_trunc = NULL,
  ghq_data = object$ghq_data,
  strata = NULL,
  use_log = FALSE,
  type = "cumulative"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_pd_univariate_+3A_par">par</code></td>
<td>
<p>numeric vector with the model parameters.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_object">object</code></td>
<td>
<p>an object from <code><a href="#topic+mmcif_data">mmcif_data</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_newdata">newdata</code></td>
<td>
<p>a <code>data.frame</code> with data for the observation. It needs
to have one row.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_cause">cause</code></td>
<td>
<p>an integer vector with the cause of each outcome. If there are
<code>n_causes</code> of outcome, then the vector should have values in
<code>1:(n_causes + 1)</code> with <code>n_causes + 1</code> indicating censoring.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_time">time</code></td>
<td>
<p>a numeric vector with the observed times.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_left_trunc">left_trunc</code></td>
<td>
<p>numeric vector with left-truncation times. <code>NULL</code>
implies that there are not any individuals with left-truncation.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_ghq_data">ghq_data</code></td>
<td>
<p>the Gauss-Hermite quadrature nodes and weights to
use. It should be a list with two elements called <code>"node"</code>
and <code>"weight"</code>. A default is provided if <code>NULL</code> is passed.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_strata">strata</code></td>
<td>
<p>an integer vector or a factor vector with the strata of each
individual. <code>NULL</code> implies that there are no strata.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_use_log">use_log</code></td>
<td>
<p>a logical for whether the returned output should be on the
log scale.</p>
</td></tr>
<tr><td><code id="mmcif_pd_univariate_+3A_type">type</code></td>
<td>
<p>a character for the type of measures for the observation. It
can have value
<code>"derivative"</code> for the derivative of a CIF or
<code>"cumulative"</code> for a CIF or the survival probability.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric scalar with the requested quantity.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mmcif_pd_bivariate">mmcif_pd_bivariate</a></code> and <code><a href="#topic+mmcif_pd_cond">mmcif_pd_cond</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # Gauss Hermite quadrature nodes and weights from fastGHQuad::gaussHermiteData
  ghq_data &lt;- list(
    node = c(-3.43615911883774, -2.53273167423279, -1.75668364929988, -1.03661082978951,
             -0.342901327223705, 0.342901327223705, 1.03661082978951, 1.75668364929988,
             2.53273167423279, 3.43615911883774),
    weight = c(7.6404328552326e-06, 0.00134364574678124, 0.0338743944554811, 0.240138611082314,
               0.610862633735326,0.610862633735326, 0.240138611082315, 0.033874394455481,
               0.00134364574678124, 7.64043285523265e-06))

  # setup the object for the computation
  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country, ghq_data = ghq_data)

  # previous estimates
  par &lt;- c(0.727279974859164, 0.640534073288067, 0.429437766165371, 0.434367104339573,
           -2.4737847536253, -1.49576564624673, -1.89966050143904, -1.58881346649412,
           -5.5431198001029, -3.5328359024178, -5.82305147022587, -3.4531896212114,
           -5.29132887832377, -3.36106297109548, -6.03690322125729, -3.49516746825624,
           2.55000711185704, 2.71995985605891, 2.61971498736444, 3.05976391058032,
           -5.97173564860957, -3.37912051983482, -5.14324860374941, -3.36396780694965,
           -6.02337246348561, -3.03754644968859, -5.51267338700737, -3.01148582224673,
           2.69665543753264, 2.59359057553995, 2.7938341786374, 2.70689750644755,
           -0.362056555418564, 0.24088005091276, 0.124070380635372, -0.246152029808377,
           -0.0445628476462479, -0.911485513197845, -0.27911988106887, -0.359648419277058,
           -0.242711959678559, -6.84897302527358)

  # the test data we will use
  test_dat &lt;- data.frame(country = factor("Norway", levels(prt_use$country)),
                         status = 2L)

  # compute the CIF
  mmcif_pd_univariate(
    par = par, object = mmcif_obj, newdata = test_dat, cause = status,
    strata = country, ghq_data = ghq_data, time = 75, type = "cumulative") |&gt;
    print()

  # compute the derivative of the CIF
  mmcif_pd_univariate(
    par = par, object = mmcif_obj, newdata = test_dat, cause = status,
    strata = country, ghq_data = ghq_data, time = 75, type = "derivative") |&gt;
    print()

  # compute the survival probability
  mmcif_pd_univariate(
    par = par, object = mmcif_obj, newdata = test_dat, cause = 3L,
    strata = country, ghq_data = ghq_data, time = 75, type = "cumulative") |&gt;
    print()
}

</code></pre>

<hr>
<h2 id='mmcif_sandwich'>Computes the Sandwich Estimator</h2><span id='topic+mmcif_sandwich'></span>

<h3>Description</h3>

<p>Computes the sandwich estimator of the covariance matrix. The parameter that
is passed is using the log Cholesky decomposition. The Hessian is computed
using numerical differentiation with Richardson extrapolation to refine the
estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_sandwich(
  object,
  par,
  ghq_data = object$ghq_data,
  n_threads = 1L,
  eps = 0.01,
  scale = 2,
  tol = 1e-08,
  order = 3L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_sandwich_+3A_object">object</code></td>
<td>
<p>an object from <code><a href="#topic+mmcif_data">mmcif_data</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_par">par</code></td>
<td>
<p>numeric vector with the parameters to compute the sandwich
estimator at.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_ghq_data">ghq_data</code></td>
<td>
<p>the Gauss-Hermite quadrature nodes and weights to
use. It should be a list with two elements called <code>"node"</code>
and <code>"weight"</code>. A default is provided if <code>NULL</code> is passed.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_n_threads">n_threads</code></td>
<td>
<p>the number of threads to use.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_eps">eps</code></td>
<td>
<p>determines the step size in the numerical differentiation using
<code>max(sqrt(.Machine$double.eps), |par[i]| * eps)</code>
for each parameter <code>i</code>.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_scale">scale</code></td>
<td>
<p>scaling factor in the Richardson extrapolation. Each step is
smaller by a factor <code>scale</code>.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_tol">tol</code></td>
<td>
<p>relative convergence criteria in the extrapolation given
by <code>max(tol, |g[i]| * tol)</code> with <code>g</code> being the gradient and for
each parameter <code>i</code>.</p>
</td></tr>
<tr><td><code id="mmcif_sandwich_+3A_order">order</code></td>
<td>
<p>maximum number of iteration of the Richardson extrapolation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The sandwich estimator along attributes called
</p>

<ul>
<li> <p><code>"meat"</code> for the &quot;meat&quot; of the sandwich estimator.
</p>
</li>
<li> <p><code>"hessian"</code> for the Hessian of the log composite likelihood.
</p>
</li>
<li> <p><code>"res vcov"</code> which is the sandwich estimator where the
last elements are the upper triangle of the covariance matrix of the random
effects rather than the log Cholesky decomposition of the matrix.
</p>
</li></ul>



<h3>References</h3>

<p>Cederkvist, L., Holst, K. K., Andersen, K. K., &amp;
Scheike, T. H. (2019).
<em>Modeling the cumulative incidence function of multivariate competing
risks data allowing for within-cluster dependence of risk and timing</em>.
Biostatistics, Apr 1, 20(2), 199-217.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mmcif_fit">mmcif_fit</a></code> and <code><a href="#topic+mmcif_data">mmcif_data</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  # prepare the data
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # randomly sub-sample
  set.seed(1)
  prt_use &lt;- subset(
    prt_use, id %in% sample(unique(id), length(unique(id)) %/% 10L))

  n_threads &lt;- 2L
  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country)

  # get the staring values
  start_vals &lt;- mmcif_start_values(mmcif_obj, n_threads = n_threads)

  # estimate the parameters
  ests &lt;- mmcif_fit(start_vals$upper, mmcif_obj, n_threads = n_threads)

  # get the sandwich estimator
  vcov_est &lt;- mmcif_sandwich(
    mmcif_obj, ests$par, n_threads = n_threads, order = 2L)

  # show the parameter estimates along with the standard errors
  rbind(Estimate = ests$par,
        SE = sqrt(diag(vcov_est))) |&gt;
    print()

  # show the upper triangle of the covariance matrix and the SEs
  rbind(`Estimate (vcov)` = tail(ests$par, 10) |&gt; log_chol_inv() |&gt;
          (\(x) x[upper.tri(x, TRUE)])() ,
        SE = attr(vcov_est, "res vcov") |&gt; diag() |&gt; sqrt() |&gt; tail(10)) |&gt;
    print()
}

</code></pre>

<hr>
<h2 id='mmcif_start_values'>Finds Staring Values</h2><span id='topic+mmcif_start_values'></span>

<h3>Description</h3>

<p>Fast heuristic for finding starting values for the mixed cumulative incidence
functions model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmcif_start_values(object, n_threads = 1L, vcov_start = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmcif_start_values_+3A_object">object</code></td>
<td>
<p>an object from <code><a href="#topic+mmcif_data">mmcif_data</a></code>.</p>
</td></tr>
<tr><td><code id="mmcif_start_values_+3A_n_threads">n_threads</code></td>
<td>
<p>the number of threads to use.</p>
</td></tr>
<tr><td><code id="mmcif_start_values_+3A_vcov_start">vcov_start</code></td>
<td>
<p>starting value for the covariance matrix of the random
effects. <code>NULL</code> yields the identity matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with
</p>

<ul>
<li><p> an element called <code>"full"</code> with the starting value where the
last components are the covariance matrix.
</p>
</li>
<li><p> an element called <code>"upper"</code> the staring values where the
covariance matrix is stored as a log Cholesky decomposition. This is used
e.g. for optimization with <code><a href="#topic+mmcif_fit">mmcif_fit</a></code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>if(require(mets)){
  # prepare the data
  data(prt)

  # truncate the time
  max_time &lt;- 90
  prt &lt;- within(prt, {
    status[time &gt;= max_time] &lt;- 0
    time &lt;- pmin(time, max_time)
  })

  # select the DZ twins and re-code the status
  prt_use &lt;- subset(prt, zyg == "DZ") |&gt;
    transform(status = ifelse(status == 0, 3L, status))

  # randomly sub-sample
  set.seed(1)
  prt_use &lt;- subset(
    prt_use, id %in% sample(unique(id), length(unique(id)) %/% 10L))

  n_threads &lt;- 2L
  mmcif_obj &lt;- mmcif_data(
    ~ country - 1, prt_use, status, time, id, max_time,
    2L, strata = country)

  # get the staring values
  start_vals &lt;- mmcif_start_values(mmcif_obj, n_threads = n_threads)

  # the starting values
  print(start_vals)
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
