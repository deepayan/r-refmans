<!DOCTYPE html><html><head><title>Help for package vita</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {vita}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#vita-package'>
<p>Variable importance testing approaches (vita)</p></a></li>
<li><a href='#compVarImp'>
<p>Compute permutation variable importance measure</p></a></li>
<li><a href='#CVPVI'>
<p>Cross-validated permutation variable importance measure</p></a></li>
<li><a href='#NTA'>
<p>Novel testing approach</p></a></li>
<li><a href='#PIMP'>
<p>PIMP-algorithm for the permutation variable importance measure</p></a></li>
<li><a href='#PimpTest'>
<p>PIMP testing approach</p></a></li>
<li><a href='#summary.NTA'>
<p>Summarizing the results of novel testing approach</p></a></li>
<li><a href='#summary.PimpTest'>
<p>Summarizing PIMP-algorithm outcomes</p></a></li>
<li><a href='#VarImpCVl'>
<p>Fold-specific permutation variable importance measure</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Importance Testing Approaches</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-12-12</td>
</tr>
<tr>
<td>Author:</td>
<td>Ender Celik [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ender Celik &lt;celik.p.ender@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the novel testing approach by Janitza et al.(2015)
    <a href="http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4">http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4</a>
    for the permutation variable importance measure in a random forest and the
    PIMP-algorithm by Altmann et al.(2010) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtq134">doi:10.1093/bioinformatics/btq134</a>&gt;.
    Janitza et al.(2015) <a href="http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4">http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4</a>
    do not use the "standard" permutation variable
    importance but the cross-validated permutation variable
    importance for the novel test approach. The cross-validated
    permutation variable importance is not based on the out-of-bag
    observations but uses a similar strategy which is inspired by
    the cross-validation procedure. The novel test approach can be
    applied for classification trees as well as for regression
    trees. However, the use of the novel testing approach has not
    been tested for regression trees so far, so this routine is
    meant for the expert user only and its current state is rather
    experimental.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.6),parallel,randomForest,stats</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mnormt</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-12-14 17:52:38 UTC; ender</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-12-14 19:05:44</td>
</tr>
</table>
<hr>
<h2 id='vita-package'>
Variable importance testing approaches (vita)
</h2><span id='topic+vita-package'></span>

<h3>Description</h3>

<p>Implements the novel testing approach by Janitza et al.(2015) for the permutation variable importance measure
in a random forest and the PIMP-algorithm by Altmann et al.(2010). Janitza  et al.(2015) do not use
the &quot;standard&quot; permutation variable importance but the cross-validated permutation variable
importance for the novel test approach. The cross-validated permutation variable importance
is not based on the out-of-bag observations but uses a similar strategy which is inspired by
the cross-validation procedure. The novel test approach can be applied for classification trees
as well as for regression trees.
However, the use of the novel testing approach has not been tested for regression trees so far, so
this routine is meant for the expert user only and its current state is rather experimental.
</p>


<h3>Details</h3>

<p><strong>The novel test approach (<code><a href="#topic+NTA">NTA</a></code>)</strong>:
</p>
<p>The observed non-positive permutation variable importance values are used to approximate the distribution of
variable importance for non-relevant variables. The null distribution Fn0 is computed by mirroring the
non-positive variable importance values on the y-axis. Given the approximated null importance distribution,
the p-value is the probability of observing the <code>original PerVarImp</code> or a larger value. This testing
approach is suitable for data with large number of variables without any effect.
</p>
<p><code>PerVarImp</code> should be computed based on the hold-out permutation variable importance measures. If using
standard variable importance measures the results may be biased.
</p>
<p>This function has not been tested for regression tasks so far, so this routine is meant for the expert user
only and its current state is rather experimental.
</p>
<p><strong>Cross-validated permutation variable importance (<code><a href="#topic+CVPVI">CVPVI</a></code>)</strong>:
</p>
<p>This method randomly splits the dataset into k sets of equal size. The method constructs k random forests, where the l-th forest is constructed based on observations that are not part of the l-th set. For each forest the fold-specific permutation variable importance measure is computed using all observations in the l-th data set: For each tree, the prediction error on the l-th data set is recorded. Then the same is done after permuting the values of each predictor variable.
</p>
<p>The differences between the two prediction errors are then averaged over all trees. The cross-validated permutation variable importance is the average of all k-fold-specific permutation variable importances. For classification the mean decrease in accuracy over all classes is used and for regression the mean decrease in MSE.
</p>
<p><strong>PIMP testing approach (<code><a href="#topic+PIMP">PIMP</a></code>)</strong>:
</p>
<p>The PIMP-algorithm by Altmann et al.(2010) permutes <code class="reqn">S</code> times the response variable <code class="reqn">y</code>.
For each permutation of the response vector <code class="reqn">y^{*s}</code>, a new forest is grown and the permutation
variable importance measure (<code class="reqn">VarImp^{*s}</code>) for all predictor variables <code class="reqn">X</code> is computed.
The vector <code>perVarImp^{s}</code> for every predictor variables are used to approximate the null importance distributions.
</p>
<p>Given the fitted null importance distribution, the p-value is the probability of observing the <em>original VarImp</em> or a larger value.
</p>


<h3>Author(s)</h3>

<p>Ender Celik
</p>


<h3>References</h3>

<p>Breiman L. (2001), <em>Random Forests</em>, Machine Learning 45(1),5-32, &lt;doi:10.1023/A:1010933404324&gt;
</p>
<p>Altmann A.,Tolosi L., Sander O. and  Lengauer T. (2010),<em>Permutation importance: a corrected feature importance measure</em>, Bioinformatics Volume 26 (10), 1340-1347, &lt;doi:10.1093/bioinformatics/btq134&gt;
</p>
<p>Janitza S, Celik E, Boulesteix A-L, (2015),<em> A computationally fast variable importance test for random forest for high dimensional data</em>,Technical Report 185, University of Munich &lt;<a href="http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4">http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PIMP">PIMP</a></code>, <code><a href="#topic+NTA">NTA</a></code>, <code><a href="#topic+CVPVI">CVPVI</a></code>, <code><a href="randomForest.html#topic+importance">importance</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>
</p>

<hr>
<h2 id='compVarImp'>
Compute permutation variable importance measure
</h2><span id='topic+compVarImp'></span>

<h3>Description</h3>

<p>Compute permutation variable importance measure from a random forest for classification and regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compVarImp(X, y,rForest,nPerm=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compVarImp_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix of predictors.</p>
</td></tr>
<tr><td><code id="compVarImp_+3A_y">y</code></td>
<td>
<p>a response vector. If a factor, classification is assumed, otherwise regression is assumed.</p>
</td></tr>
<tr><td><code id="compVarImp_+3A_rforest">rForest</code></td>
<td>
<p>an object of class <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, keep.forest,keep.inbag must
be set to True.</p>
</td></tr>
<tr><td><code id="compVarImp_+3A_nperm">nPerm</code></td>
<td>
<p>Number of times the OOB data are permuted per tree for assessing variable importance.
Number larger than 1 gives slightly more stable estimate, but not very effective.
Currently only implemented for regression. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The permutation variable importance measure is computed from permuting OOB data: For each tree,
the prediction error on the out-of-bag observations is recorded. Then the same is done
after permuting a predictor variable. The differences between the two error rates are then averaged over all
trees.
</p>


<h3>Value</h3>

<table>
<tr><td><code>importance</code></td>
<td>
<p>The permutation variable importance measure. A matrix with nclass + 1
(for classification) or one (for regression) columns. For classification, the first
nclass columns are the class-specific measures computed as mean decrease in accuracy.
The nclass + 1st column is the mean decrease in accuracy over all classes. For regression
the mean decrease in MSE is given. </p>
</td></tr>
<tr><td><code>importanceSD</code></td>
<td>
<p>The &quot;standard errors&quot; of the permutation-based importance measure. For classification, a p
by nclass + 1 matrix corresponding to the first nclass + 1 columns of the importance matrix.
For regression a vector of length p.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>one of regression, classification</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman L. (2001), <em>Random Forests</em>, Machine Learning 45(1),5-32, &lt;doi:10.1023/A:101093340432&gt;
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+importance">importance</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>,<code><a href="#topic+CVPVI">CVPVI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################
#      Classification        #
##############################
## Simulating data
X = replicate(8,rnorm(100))
X= data.frame( X) #"X" can also be a matrix
z  = with(X,5*X1 + 3*X2 + 2*X3 + 1*X4 -
            5*X5 - 9*X6 - 2*X7 + 1*X8 )
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = as.factor(rbinom(100,1,pr))
##############################
## Classification with Random Forest:
library("randomForest")
cl.rf= randomForest(X,y,mtry = 3,ntree=100,
                    importance=TRUE,keep.inbag = TRUE)

##############################
## Permutation variable importance measure
vari= compVarImp(X,y,cl.rf)

##############################
#compare them with the original results
cbind(cl.rf$importance[,1:3],vari$importance)
cbind(cl.rf$importance[,3],vari$importance[,3])
cbind(cl.rf$importanceSD,vari$importanceSD)
cbind(cl.rf$importanceSD[,3],vari$importanceSD[,3])
cbind(cl.rf$type,vari$type)


###############################
#      Regression             #
###############################
## Simulating data
X = replicate(8,rnorm(100))
X= data.frame( X) #"X" can also be a matrix
y= with(X,5*X1 + 3*X2 + 2*X3 + 1*X4 -
          5*X5 - 9*X6 - 2*X7 + 1*X8 )
##############################
## Regression with Random Forest:
library("randomForest")
reg.rf= randomForest(X,y,mtry = 3,ntree=100,
                     importance=TRUE,keep.inbag = TRUE)

##############################
## Permutation variable importance measure
vari= compVarImp(X,y,reg.rf)

##############################
#compare them with the original results
cbind(importance(reg.rf, type=1, scale=FALSE),vari$importance)
cbind(reg.rf$importanceSD,vari$importanceSD)
cbind(reg.rf$type,vari$type)

</code></pre>

<hr>
<h2 id='CVPVI'>
Cross-validated permutation variable importance measure
</h2><span id='topic+CVPVI'></span><span id='topic+CVPVI.default'></span><span id='topic+print.CVPVI'></span>

<h3>Description</h3>

<p>Compute cross-validated permutation variable importance measure from a random forest for classification and regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## Default S3 method:
CVPVI(X, y, k = 2, mtry= if (!is.null(y) &amp;&amp; !is.factor(y))
                        max(floor(ncol(X)/3), 1) else floor(sqrt(ncol(X))),
    ntree = 500, nPerm = 1, parallel = FALSE, ncores = 0, seed = 123, ...)
## S3 method for class 'CVPVI'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVPVI_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix of predictors. </p>
</td></tr>
<tr><td><code id="CVPVI_+3A_y">y</code></td>
<td>
<p>a response vector.</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_k">k</code></td>
<td>
<p>an integer for the number of folds. Default is <code>k = 2</code></p>
</td></tr>
<tr><td><code id="CVPVI_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables randomly sampled as candidates at each split for the l-th forest. Note that
the default values are different for classification (<code>mtry=sqrt(p)</code> where <code>p</code> is number
of variables in <code>x</code>) and regression (<code>mtry=p/3</code>).</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_ntree">ntree</code></td>
<td>
<p>Number of trees to grow for the l-th forest. Default is <code>ntree=500</code>.</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_nperm">nPerm</code></td>
<td>
<p>Number of times the l-th data set are permuted per tree for assessing variable fold-specific
permutation variable importance. Default is <code>nPerm=1</code>.</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_parallel">parallel</code></td>
<td>
<p>Should the CVPVI implementation run parallel? Default is <code>parallel=FALSE</code> and the number of cores is
set to one. The parallelized version of the CVPVI implementation are based on
<code><a href="parallel.html#topic+mclapply">mclapply</a></code> and so are not available on Windows.</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores to use, i.e. at most how many child processes will be run
simultaneously. Must be at least one, and parallelization requires at least two cores.
If <code>ncores=0</code>, then the half of CPU cores on the current host are used.</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_seed">seed</code></td>
<td>
<p>a single integer value to specify seeds. The &quot;combined multiple-recursive generator&quot;
from L'Ecuyer (1999) is set as random number generator for the parallelized version of
the CVPVI implementation. Default is <code> seed = 123</code>.</p>
</td></tr>
<tr><td><code id="CVPVI_+3A_...">...</code></td>
<td>
<p>optional parameters for <code><a href="randomForest.html#topic+randomForest">randomForest</a> </code> </p>
</td></tr>
<tr><td><code id="CVPVI_+3A_x">x</code></td>
<td>
<p>for the print method, an <code>CVPVI</code> object </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method randomly splits the dataset into k sets of equal size. The method constructs k random forests, where the l-th forest is constructed based on observations that are not part of the l-th set. For each forest the fold-specific permutation variable importance measure is computed using all observations in the l-th data set: For each tree, the prediction error on the l-th data set is recorded. Then the same is done after permuting the values of each predictor variable.
The differences between the two prediction errors are then averaged over all trees. The cross-validated permutation variable importance is the average of all k-fold-specific permutation variable importances. For classification the mean decrease in accuracy over all classes is used and for regression the mean decrease in MSE.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fold_varim</code></td>
<td>
<p>a p by k matrix of fold-specific permutation variable importances. For classification the mean decrease in accuracy over all classes. For regression mean decrease in MSE. </p>
</td></tr>
<tr><td><code>cv_varim</code></td>
<td>
<p>cross-validated permutation variable importances. For classification the mean decrease in accuracy over all classes. For regression mean decrease in MSE. </p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>one of regression, classification</p>
</td></tr>
</table>


<h3>References</h3>

<p>Janitza S, Celik E, Boulesteix A-L, (2015),<em> A computationally fast variable importance test for random forest for high dimensional data</em>,Technical Report 185, University of Munich, &lt;<a href="http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4">http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VarImpCVl">VarImpCVl</a></code>, <code><a href="randomForest.html#topic+importance">importance</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, <code><a href="parallel.html#topic+mclapply">mclapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################
#      Classification        #
##############################
## Simulating data
X = replicate(10,rnorm(100))
X= data.frame( X) #"X" can also be a matrix
z  = with(X,5*X1 + 3*X2 + 2*X3 + 1*X4 -
            5*X5 - 9*X6 - 2*X7 + 1*X8 )
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = as.factor(rbinom(100,1,pr))
##################################################################
# cross-validated permutation variable importance
cv_vi = CVPVI(X,y,k = 2,mtry = 3,ntree = 1000,ncores = 4)
print(cv_vi)

##################################################################
#compare them with the original permutation variable importance
library("randomForest")
cl.rf = randomForest(X,y,mtry = 3,ntree = 1000, importance = TRUE)

round(cbind(importance(cl.rf, type=1, scale=FALSE),cv_vi$cv_varim),digits=5)


###############################
#      Regression            #
##############################

##################################################################
## Simulating data:
X = replicate(10,rnorm(100))
X = data.frame( X) #"X" can also be a matrix
y = with(X,2*X1 + 2*X2 + 2*X3 + 1*X4 - 2*X5 - 2*X6 - 1*X7 + 2*X8 )

##################################################################
# cross-validated permutation variable importance
cv_vi = CVPVI(X,y,k = 3,mtry = 3,ntree = 1000,ncores = 2)
print(cv_vi)
##################################################################
#compare them with the original permutation variable importance
library("randomForest")
reg.rf = randomForest(X,y,mtry = 3,ntree = 1000, importance = TRUE)

round(cbind(importance(reg.rf, type=1, scale=FALSE),cv_vi$cv_varim),digits=5)

</code></pre>

<hr>
<h2 id='NTA'>
Novel testing approach
</h2><span id='topic+NTA'></span><span id='topic+NTA.default'></span><span id='topic+print.NTA'></span>

<h3>Description</h3>

<p>Calculates the p-values for each permutation variable importance measure, based on the empirical null distribution
from non-positive importance values as described in Janitza et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
NTA(PerVarImp)
## S3 method for class 'NTA'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NTA_+3A_pervarimp">PerVarImp</code></td>
<td>
<p> permutation variable importance measures in a vector.</p>
</td></tr>
<tr><td><code id="NTA_+3A_x">x</code></td>
<td>
<p>for the print method, an <code>NTA</code> object </p>
</td></tr>
<tr><td><code id="NTA_+3A_...">...</code></td>
<td>
<p>optional parameters for <code><a href="base.html#topic+print">print</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed non-positive permutation variable importance values are used to approximate the distribution of
variable importance for non-relevant variables. The null distribution Fn0 is computed by mirroring the
non-positive variable importance values on the y-axis. Given the approximated null importance distribution,
the p-value is the probability of observing the <code>original PerVarImp</code> or a larger value. This testing
approach is suitable for data with large number of variables without any effect.
</p>
<p><code>PerVarImp</code> should be computed based on the hold-out permutation variable importance measures. If using
standard variable importance measures the results may be biased.
</p>
<p>This function has not been tested for regression tasks so far, so this routine is meant for the expert user
only and its current state is rather experimental.
</p>


<h3>Value</h3>

<table>
<tr><td><code>PerVarImp</code></td>
<td>
<p> the orginal permutation variable importance measures. </p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>The non-positive variable importance values with the mirrored values on the y-axis.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>the p-value is the probability of observing the <code>orginal PerVarImp</code> or a
larger value, given the approximated null importance distribution.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Janitza S, Celik E, Boulesteix A-L, (2015),<em> A computationally fast variable importance test for random forest for high dimensional data</em>,Technical Report 185, University of Munich, &lt;<a href="http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4">http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CVPVI">CVPVI</a></code>,<code><a href="randomForest.html#topic+importance">importance</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################
#      Classification        #
##############################
## Simulating data
X = replicate(100,rnorm(200))
X= data.frame( X) #"X" can also be a matrix
z  = with(X,2*X1 + 3*X2 + 2*X3 + 1*X4 -
            2*X5 - 2*X6 - 2*X7 + 1*X8 )
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = as.factor(rbinom(200,1,pr))
##################################################################
# cross-validated permutation variable importance

cv_vi = CVPVI(X,y,k = 2,mtry = 3,ntree = 500,ncores = 2)
##################################################################
#compare them with the original permutation variable importance
library("randomForest")
cl.rf = randomForest(X,y,mtry = 3,ntree = 500, importance = TRUE)
##################################################################
# Novel Test approach
cv_p = NTA(cv_vi$cv_varim)
summary(cv_p,pless = 0.1)
pvi_p = NTA(importance(cl.rf, type=1, scale=FALSE))
summary(pvi_p)


###############################
#      Regression             #
###############################
##################################################################
## Simulating data:
X = replicate(100,rnorm(200))
X = data.frame( X) #"X" can also be a matrix
y = with(X,2*X1 + 2*X2 + 2*X3 + 1*X4 - 2*X5 - 2*X6 - 1*X7 + 2*X8 )

##################################################################
# cross-validated permutation variable importance
cv_vi = CVPVI(X,y,k = 2,mtry = 3,ntree = 500,ncores = 2)
##################################################################
#compare them with the original permutation variable importance
reg.rf = randomForest(X,y,mtry = 3,ntree = 500, importance = TRUE)
##################################################################
# Novel Test approach (not tested for regression so far!)
cv_p = NTA(cv_vi$cv_varim)
summary(cv_p,pless = 0.1)
pvi_p = NTA(importance(reg.rf, type=1, scale=FALSE))
summary(pvi_p)
</code></pre>

<hr>
<h2 id='PIMP'>
PIMP-algorithm for the permutation variable importance measure
</h2><span id='topic+PIMP'></span><span id='topic+PIMP.default'></span><span id='topic+print.PIMP'></span>

<h3>Description</h3>

<p><code>PIMP</code> implements the test approach of Altmann et al. (2010) for the permutation variable importance measure <code>VarImp</code>
in a random forest for classification and regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
PIMP(X, y, rForest, S = 100, parallel = FALSE, ncores=0, seed = 123, ...)
## S3 method for class 'PIMP'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PIMP_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix of predictors</p>
</td></tr>
<tr><td><code id="PIMP_+3A_y">y</code></td>
<td>
<p>a response vector. If a factor, classification is assumed,
otherwise regression is assumed.</p>
</td></tr>
<tr><td><code id="PIMP_+3A_rforest">rForest</code></td>
<td>
<p>an object of class <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, <code>importance</code> must
be set to True.</p>
</td></tr>
<tr><td><code id="PIMP_+3A_s">S</code></td>
<td>
<p>The number of permutations for the response vector <code>y</code>. Default is <code>S=100</code>. </p>
</td></tr>
<tr><td><code id="PIMP_+3A_parallel">parallel</code></td>
<td>
<p>Should the PIMP-algorithm run parallel?  Default is <code>parallel=FALSE</code> and the number of cores is
set to one. The parallelized version of the PIMP-algorithm are based on
<code><a href="parallel.html#topic+mclapply">mclapply</a></code> and so is not available on Windows.</p>
</td></tr>
<tr><td><code id="PIMP_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores to use, i.e. at most how many child processes will be run
simultaneously. Must be at least one, and parallelization requires at least two cores.
If <code>ncores=0</code>, then the half of CPU cores on the current host are used.</p>
</td></tr>
<tr><td><code id="PIMP_+3A_seed">seed</code></td>
<td>
<p>a single integer value to specify seeds. The &quot;combined multiple-recursive generator&quot;
from L'Ecuyer (1999) is set as random number generator for the parallelized version of
the PIMP-algorithm.  Default is <code> seed = 123</code>.</p>
</td></tr>
<tr><td><code id="PIMP_+3A_...">...</code></td>
<td>
<p>optional parameters for <code><a href="randomForest.html#topic+randomForest">randomForest</a> </code> </p>
</td></tr>
<tr><td><code id="PIMP_+3A_x">x</code></td>
<td>
<p>for the print method, an <code>PIMP</code> object </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PIMP-algorithm by Altmann et al. (2010) permutes <code class="reqn">S</code> times the response variable <code class="reqn">y</code>.
For each permutation of the response vector <code class="reqn">y^{*s}</code>, a new forest is grown and the permutation
variable importance measure (<code class="reqn">VarImp^{*s}</code>) for all predictor variables <code class="reqn">X</code> is computed.
The vector <code>perVarImp</code> of <code class="reqn">S</code> <code class="reqn">VarImp</code> measures for every predictor variables are used
to approximate the null importance distributions (<code><a href="#topic+PimpTest">PimpTest</a></code>).
</p>


<h3>Value</h3>

<table>
<tr><td><code>VarImp</code></td>
<td>
<p> the <em>original permutation variable importance</em> measures of the random forest. </p>
</td></tr>
<tr><td><code>PerVarImp</code></td>
<td>
<p>a matrix, where each row is a vector containing the <code>S</code> permuted VarImp
measures for each predictor variables. </p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>one of regression, classification</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman L. (2001), <em>Random Forests</em>, Machine Learning 45(1),5-32, &lt;doi:10.1023/A:1010933404324&gt;
</p>
<p>Altmann A.,Tolosi L., Sander O. and  Lengauer T. (2010),<em>Permutation importance: a corrected feature importance measure</em>, Bioinformatics Volume 26 (10), 1340-1347, &lt;doi:10.1093/bioinformatics/btq134&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PimpTest">PimpTest</a></code>, <code><a href="randomForest.html#topic+importance">importance</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, <code><a href="parallel.html#topic+mclapply">mclapply</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
###############################
#      Regression            #
##############################
##############################
## Simulating data
X = replicate(12,rnorm(100))
X = data.frame(X) #"X" can also be a matrix
y = with(X,2*X1 + 1*X2 + 2*X3 + 1*X4 - 2*X5 - 1*X6 - 1*X7 + 2*X8 )

##############################
## Regression with Random Forest:
library("randomForest")
reg.rf = randomForest(X,y,mtry = 3,ntree=500,importance=TRUE)
##############################
## PIMP-Permutation variable importance measure
# the parallelized version of the PIMP-algorithm
system.time(pimp.varImp.reg&lt;-PIMP(X,y,reg.rf,S=10, parallel=TRUE, ncores=2))
# the non parallelized version of the PIMP-algorithm
system.time(pimp.varImp.reg&lt;-PIMP(X,y,reg.rf,S=10, parallel=FALSE))

##############################
#      Classification        #
##############################
## Simulating data
X = replicate(12,rnorm(100))
X= data.frame( X) #"X" can also be a matrix
z  = with(X,2*X1 + 3*X2 + 2*X3 + 1*X4 -
            2*X5 - 2*X6 - 2*X7 + 1*X8 )
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = as.factor(rbinom(100,1,pr))

##############################
## Classification with Random Forest:
cl.rf = randomForest(X,y,mtry = 3,ntree = 500, importance = TRUE)
##############################
## PIMP-Permutation variable importance measure
# the parallelized version of the PIMP-algorithm
system.time(pimp.varImp.cl&lt;-PIMP(X,y,cl.rf,S=10, parallel=TRUE, ncores=2))
# the non parallelized version of the PIMP-algorithm
system.time(pimp.varImp.cl&lt;-PIMP(X,y,cl.rf,S=10, parallel=FALSE))

</code></pre>

<hr>
<h2 id='PimpTest'>
PIMP testing approach
</h2><span id='topic+PimpTest'></span><span id='topic+PimpTest.default'></span><span id='topic+print.PimpTest'></span>

<h3>Description</h3>

<p>Uses permutations to approximate the null importance distributions for all variables and computes the p-values based on the null importance distribution according to the approach of Altmann et al. (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
PimpTest(Pimp, para = FALSE, ...)
## S3 method for class 'PimpTest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PimpTest_+3A_pimp">Pimp</code></td>
<td>
<p> an object of class <code><a href="#topic+PIMP">PIMP</a></code> </p>
</td></tr>
<tr><td><code id="PimpTest_+3A_para">para</code></td>
<td>
<p> If para is TRUE  the null importance distributions are approximated with Gaussian
distributions else with empirical cumulative distributions. Default is <code> para = FALSE</code></p>
</td></tr>
<tr><td><code id="PimpTest_+3A_...">...</code></td>
<td>
<p> optional parameters, not used </p>
</td></tr>
<tr><td><code id="PimpTest_+3A_x">x</code></td>
<td>
<p>for the print method, an <code>PimpTest</code> object </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector <code>perVarImp</code> of <code class="reqn">S</code> variable importance measures for every predictor variables from code <a href="#topic+PIMP">PIMP</a> are used to approximate the null importance distributions.
If <code>para</code> is <code>TRUE</code> this implementation of the PIMP algorithm fits for each variable a <em>Gaussian distribution</em> to the <code class="reqn">S</code> null importances. If <code>para</code> is <code>FALSE</code> the PIMP algorithm uses the empirical distribution of the <code class="reqn">S</code> null importances.
Given the fitted null importance distribution, the p-value is the probability of observing the <em>original VarImp</em> or a larger value.
</p>


<h3>Value</h3>

<table>
<tr><td><code>VarImp</code></td>
<td>
<p> the <em>original permutation variable importance</em> measures of the random forest. </p>
</td></tr>
<tr><td><code>PerVarImp</code></td>
<td>
<p>a matrix, where the l-th row contains the <code>S</code> permuted VarImp
measures for the l-th predictor variable. </p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p> Was the null distribution approximated by a Gaussian distribution or by the empirical distribution? </p>
</td></tr>
<tr><td><code>meanPerVarImp</code></td>
<td>
<p>mean for each row of <code>PerVarImp</code>. <code>NULL</code> if <code> para = FALSE</code> </p>
</td></tr>
<tr><td><code>sdPerVarImp</code></td>
<td>
<p> standard deviation for each row of <code>PerVarImp</code>.<code>NULL</code> if <code> para = FALSE</code> </p>
</td></tr>
<tr><td><code>p.ks.test</code></td>
<td>
<p>the p-values of the Kolmogorov-Smirnov Tests for each row <code>PerVarImp</code>. Is the
null importance distribution significantly different from a normal distribution with the mean(PerVarImp) and
sd(PerVarImp)? <code>NULL</code> if <code> para = FALSE</code> </p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p> the p-value is the probability of observing the <code>original VarImp</code> or a larger value, given the fitted null importance distribution.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman L. (2001), <em>Random Forests</em>, Machine Learning 45(1),5-32, &lt;doi:10.1023/A:1010933404324&gt;
</p>
<p>Altmann A.,Tolosi L., Sander O. and  Lengauer T. (2010),<em>Permutation importance: a corrected feature importance measure</em>, Bioinformatics Volume 26 (10), 1340-1347, &lt;doi:10.1093/bioinformatics/btq134&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PIMP">PIMP</a></code>,  <code><a href="#topic+summary.PimpTest">summary.PimpTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
###############################
#      Regression            #
##############################

## Simulating data
X = replicate(15,rnorm(100))
X = data.frame(X) #"X" can also be a matrix
y = with(X,2*X1 + 1*X2 + 2*X3 + 1*X4 - 2*X5 - 1*X6 - 1*X7 + 2*X8 )

##############################
## Regression with Random Forest:
library("randomForest")
reg.rf = randomForest(X,y,mtry = 3,ntree=500,importance=TRUE)
##############################
## PIMP-Permutation variable importance measure

system.time(pimp.varImp.reg&lt;-PIMP(X,y,reg.rf,S=100, parallel=TRUE, ncores=2))
pimp.t.reg = PimpTest(pimp.varImp.reg)
summary(pimp.t.reg,pless = 0.1)

##############################
#      Classification        #
##############################

## Simulating data
X = replicate(10,rnorm(200))
X= data.frame( X) #"X" can also be a matrix
z  = with(X,2*X1 + 3*X2 + 2*X3 + 1*X4 -
            2*X5 - 2*X6 - 2*X7 + 1*X8 )
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = as.factor(rbinom(200,1,pr))

##############################
## Classification with Random Forest:
cl.rf = randomForest(X,y,mtry = 3,ntree = 500, importance = TRUE)
##############################
## PIMP-Permutation variable importance measure
system.time(pimp.varImp.cl&lt;-PIMP(X,y,cl.rf,S=100, parallel=TRUE, ncores=2))
pimp.t.cl = PimpTest(pimp.varImp.cl,para = TRUE)
summary(pimp.t.cl,pless = 0.1)

</code></pre>

<hr>
<h2 id='summary.NTA'>
Summarizing the results of novel testing approach
</h2><span id='topic+summary.NTA'></span><span id='topic+print.summary.NTA'></span>

<h3>Description</h3>

<p><code>summary </code>method for class <code>"NTA"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'NTA'
summary(object, pless=0.05,...)
## S3 method for class 'summary.NTA'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.NTA_+3A_object">object</code></td>
<td>
<p>an object of class <code>NTA</code>, a result of a call to <code><a href="#topic+NTA">NTA</a></code>.</p>
</td></tr>
<tr><td><code id="summary.NTA_+3A_pless">pless</code></td>
<td>
<p> print only p-values less than pless.  Default is <code>pless=0.05</code>.</p>
</td></tr>
<tr><td><code id="summary.NTA_+3A_x">x</code></td>
<td>
<p>an object of class <code>summary.NTA</code>, a result of a call to <code>summary.NTA</code>.</p>
</td></tr>
<tr><td><code id="summary.NTA_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.summary.NTA</code> tries to be smart about formatting the permutation variable importance values,
pvalue and  gives &quot;significance stars&quot;.
</p>


<h3>Value</h3>

<table>
<tr><td><code>cmat</code></td>
<td>
<p>a p x 2 matrix with columns for the <em>original permutation variable importance</em> values
and corresponding p-values.</p>
</td></tr>
<tr><td><code>pless</code></td>
<td>
<p> p-values less than pless</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call to <code>NTA</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+NTA">NTA</a></code>
</p>

<hr>
<h2 id='summary.PimpTest'>
Summarizing PIMP-algorithm outcomes
</h2><span id='topic+summary.PimpTest'></span><span id='topic+print.summary.PimpTest'></span>

<h3>Description</h3>

<p><code>summary </code>method for class <code>"PimpTest"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PimpTest'
summary(object, pless=0.05,...)
## S3 method for class 'summary.PimpTest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.PimpTest_+3A_object">object</code></td>
<td>
<p>an object of class <code>PimpTest</code>, a result of a call to <code><a href="#topic+PimpTest">PimpTest</a></code>.</p>
</td></tr>
<tr><td><code id="summary.PimpTest_+3A_pless">pless</code></td>
<td>
<p> print only p-values less than pless.  Default is <code>pless=0.05</code>.</p>
</td></tr>
<tr><td><code id="summary.PimpTest_+3A_x">x</code></td>
<td>
<p>an object of class <code>summary.PimpTest</code>, a result of a call to <code>summary.PimpTest</code>.</p>
</td></tr>
<tr><td><code id="summary.PimpTest_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.summary.PimpTest</code> tries to be smart about formatting the VarImp, pvalue etc. and  gives &quot;significance stars&quot;.
</p>


<h3>Value</h3>

<table>
<tr><td><code>cmat</code></td>
<td>
<p>a p x 3 matrix with columns for the <code>mean(PerVarImp)</code>,<code>sd(PerVarImp)</code> and
the the p-values of the Kolmogorov-Smirnov Tests. </p>
</td></tr>
<tr><td><code>cmat2</code></td>
<td>
<p>a p x 2 matrix with columns for the <em>original permutation variable importance</em> values
and corresponding p-value.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p> Shall the null distribution be modelled by a Gaussian distribution? </p>
</td></tr>
<tr><td><code>pless</code></td>
<td>
<p> p-values less than pless</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call to <code>PimpTest</code>.</p>
</td></tr>
<tr><td><code>call.PIMP</code></td>
<td>
<p>the matched call to <code>PIMP</code>.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>one of regression, classification</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+PimpTest">PimpTest</a></code>, <code><a href="#topic+PIMP">PIMP</a></code>
</p>

<hr>
<h2 id='VarImpCVl'>
Fold-specific permutation variable importance measure
</h2><span id='topic+VarImpCVl'></span>

<h3>Description</h3>

<p>Compute fold-specific permutation variable importance measure from a random forest for classification and regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarImpCVl(X_l, y_l, rForest, nPerm = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarImpCVl_+3A_x_l">X_l</code></td>
<td>
<p> a data frame or a matrix of predictors from the l-th data set</p>
</td></tr>
<tr><td><code id="VarImpCVl_+3A_y_l">y_l</code></td>
<td>
<p> a response vector from the l-th data set. If a factor, classification is assumed,
otherwise regression is assumed.</p>
</td></tr>
<tr><td><code id="VarImpCVl_+3A_rforest">rForest</code></td>
<td>
<p>an object of class <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, keep.forest must be set to True.
The l-th Forest based on observations that are not part of the l-th data set.</p>
</td></tr>
<tr><td><code id="VarImpCVl_+3A_nperm">nPerm</code></td>
<td>
<p> Number of permutations performed per tree for computing fold-specific
permutation variable importance. Currently only implemented for regression. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fold-specific permutation variable importance measure is computed from permuting predictor values for the l-th data set:
For each tree, the prediction error on the l-th data set is recorded. Then the same is done
after permuting each predictor variable from the l-th data set. The difference between the two prediction errors are
then averaged over all trees.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fold_importance</code></td>
<td>
<p> Fold-specific permutation variable importance measure. For classification the mean
decrease in accuracy over all classes is used, for regression the mean decrease in MSE. </p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>one of regression, classification</p>
</td></tr>
</table>


<h3>References</h3>

<p>Janitza S, Celik E, Boulesteix A-L, (2015),<em> A computationally fast variable
importance test for random forest for high dimensional data</em>,Technical Report 185,
University of Munich, &lt;<a href="http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4">http://nbn-resolving.de/urn/resolver.pl?urn=nbn:de:bvb:19-epub-25587-4</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+importance">importance</a></code>, <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##############################
#      Classification        #
##############################
## Simulating data
X = replicate(8,rnorm(100))
X= data.frame( X) #"X" can also be a matrix
z  = with(X,5*X1 + 3*X2 + 2*X3 + 1*X4 -
          5*X5 - 9*X6 - 2*X7 + 1*X8 )
pr = 1/(1+exp(-z))         # pass through an inv-logit function
y = as.factor(rbinom(100,1,pr))

##################################################################
## Split indexes 2- folds
k = 2
cuts = round(length(y)/k)
from = (0:(k-1)*cuts)+1
to = (1:k*cuts)
rs = sample(1:length(y))
l = 1
##################################################################
## Compute fold-specific permutation variable importance
library("randomForest")

lth = rs[from[l]:to[l]]
# without the l-th data set
Xl = X[-lth,]
yl = y[-lth]
cl.rf_l = randomForest(Xl,yl,keep.forest = TRUE)
# the l-th data set
X_l = X[lth,]
y_l = y[lth]
# Compute l-th fold-specific variable importance
cvl_varim=VarImpCVl(X_l,y_l,cl.rf_l)

##############################
#      Regression            #
##############################
##################################################################
## Simulating data:
X = replicate(15,rnorm(120))
X = data.frame( X) #"X" can also be a matrix
y = with(X,2*X1 + 2*X2 + 2*X3 + 1*X4 - 2*X5 - 2*X6 - 1*X7 + 2*X8 )
##################################################################
## Split indexes 2- folds
k = 2
cuts = round(length(y)/k)
from = (0:(k-1)*cuts)+1
to = (1:k*cuts)
rs = sample(1:length(y))
l = 1

##################################################################
## Compute fold-specific permutation variable importance
library("randomForest")

lth = rs[from[l]:to[l]]
# without the l-th data set
Xl = X[-lth,]
yl = y[-lth]
reg.rf_l = randomForest(Xl,yl,keep.forest = TRUE)
# the l-th data set
X_l = X[lth,]
y_l = y[lth]
# Compute l-th fold-specific variable importance
CVVI_l = VarImpCVl(X_l,y_l,reg.rf_l)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
