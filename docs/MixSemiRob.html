<!DOCTYPE html><html><head><title>Help for package MixSemiRob</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MixSemiRob}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AFDP'><p>AFDP data</p></a></li>
<li><a href='#complh'><p>Complete Likelihood Frequency Method for Label Switching</p></a></li>
<li><a href='#distlat'><p>Euclidean Distance Based Labeling Method for Label Switching</p></a></li>
<li><a href='#elbow'><p>Elbow data</p></a></li>
<li><a href='#EMnormal'><p>Parameter Estimation of Normal Mixture Using EM Algorithm</p></a></li>
<li><a href='#ethanol'><p>Ethanol data</p></a></li>
<li><a href='#kdeem'><p>Kernel Density-based EM-type algorithm for Semiparametric Mixture Regression</p>
with Unspecified Error Distributions</a></li>
<li><a href='#kdeem.h'><p>Kernel Density-based EM-type algorithm for Semiparametric Mixture Regression</p>
with Unspecified Homogenous Error Distributions</a></li>
<li><a href='#kdeem.lse'><p>Kernel Density-based EM-type algorithm with Least Square Estimation</p>
for Semiparametric Mixture Regression with Unspecified Homogenous
Error Distributions</a></li>
<li><a href='#mixLogconc'><p>Clustering with Mixtures of Log-concave Distributions using EM Algorithm (Univariate)</p></a></li>
<li><a href='#mixLogconcHD'><p>Clustering with Mixtures of Log-concave Distributions using EM Algorithm (Multivariate)</p></a></li>
<li><a href='#mixMPHD'><p>Semiparametric Mixture Model by Minimizing Profile Hellinger Distance</p></a></li>
<li><a href='#mixnorm'><p>Parameter Estimation for Uni- or Multivariate Normal Mixture Models</p></a></li>
<li><a href='#mixOnekn'><p>Two-component Normal Mixture Estimation with One Known Component</p></a></li>
<li><a href='#mixpf'><p>Profile Likelihood Method for Normal Mixture with Unequal Variance</p></a></li>
<li><a href='#mixreg'><p>MLE of Mixture Regression with Normal Errors</p></a></li>
<li><a href='#mixregBisq'><p>Robust EM Algorithm For Mixture of Linear Regression Based on Bisquare Function</p></a></li>
<li><a href='#mixregLap'><p>Robust Mixture Regression with Laplace Distribution</p></a></li>
<li><a href='#mixregPvary'><p>Mixture of Regression Models with Varying Mixing Proportions</p></a></li>
<li><a href='#mixregPvaryGen'><p>Varying Proportion Mixture Data Generator</p></a></li>
<li><a href='#mixregRM2'><p>Robust Mixture Regression with Thresholding-Embedded EM Algorithm for Penalized Estimation</p></a></li>
<li><a href='#mixregT'><p>Robust Mixture Regression with T-distribution</p></a></li>
<li><a href='#mixregTrim'><p>Robust Regression Estimator Using Trimmed Likelihood</p></a></li>
<li><a href='#mixScale'><p>Continuous Scale Mixture Approach for Normal Scale Mixture Model</p></a></li>
<li><a href='#mixTest'><p>Goodness of Fit Test for Finite Mixture Models</p></a></li>
<li><a href='#NBA'><p>NBA data</p></a></li>
<li><a href='#ROE'><p>ROE data</p></a></li>
<li><a href='#semimrBin'><p>Semiparametric Mixture of Binomial Regression with a Degenerate Component</p>
with Time-Varying Proportion and Time-Varying Success Probability</a></li>
<li><a href='#semimrBinFull'><p>Semiparametric Mixture of Binomial Regression with a Degenerate Component</p>
with Constant Proportion and Time-Varying Success Probability (Backfitting)</a></li>
<li><a href='#semimrBinOne'><p>Semiparametric Mixture of Binomial Regression with a Degenerate Component</p>
with Constant Proportion and Time-Varying Success Probability (One-step Backfitting)</a></li>
<li><a href='#semimrFull'><p>Semiparametric Mixture Regression Models with Single-index Proportion and Fully Iterative Backfitting</p></a></li>
<li><a href='#semimrGen'><p>Semiparametric Mixture Data Generator</p></a></li>
<li><a href='#semimrGlobal'><p>Semiparametric Mixtures of Nonparametric Regressions with Global EM-type Algorithm</p></a></li>
<li><a href='#semimrLocal'><p>Semiparametric Mixtures of Nonparametric Regressions with Local EM-type Algorithm</p></a></li>
<li><a href='#semimrOne'><p>Semiparametric Mixture Regression Models with Single-index and One-step Backfitting</p></a></li>
<li><a href='#sinvreg'><p>Dimension Reduction Based on Sliced Inverse Regression</p></a></li>
<li><a href='#tone'><p>Tone perception data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Mixture Models: Parametric, Semiparametric, and Robust</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Various functions are provided to estimate parametric mixture models
    (with Gaussian, t, Laplace, log-concave distributions, etc.) and
    non-parametric mixture models. The package performs hypothesis tests
    and addresses label switching issues in mixture models.
    The package also allows for parameter estimation in mixture of regressions,
    proportion-varying mixture of regressions, and robust mixture of regressions. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>GoFKernel, MASS, mixtools, mvtnorm, Rlab, robustbase, ucminf,
pracma, quadprog, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>Suyeon Kang <a href="https://orcid.org/0000-0001-6506-3035"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Xin Shen <a href="https://orcid.org/0000-0002-7332-4669"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Weixin Yao <a href="https://orcid.org/0000-0001-5925-5081"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Sijia Xiang [aut],
  Yan Ge [aut, trl]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Suyeon Kang &lt;suyeon.kang@ufl.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-19 21:51:25 UTC; suyeon.kang</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-20 07:20:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='AFDP'>AFDP data</h2><span id='topic+AFDP'></span>

<h3>Description</h3>

<p>The data contains the 11 sensor measures aggregated over one hour (by means of
average or sum) from a gas turbine located in Turkey's north western region for
the purpose of studying flue gas emissions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AFDP
</code></pre>


<h3>Format</h3>

<p>A data frame containing 7411 observations.
</p>

<hr>
<h2 id='complh'>Complete Likelihood Frequency Method for Label Switching</h2><span id='topic+complh'></span>

<h3>Description</h3>

<p>&lsquo;complh&rsquo; is used to address the label switching problem by maximizing
the complete likelihood (Yao, 2015). This method leverages information from the latent
component label, which is the label the user used to generate the sample.
The function supports both one-dimensional (with equal variances or unequal variances)
and multi-dimensional data (with equal variances).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complh(est, lat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="complh_+3A_est">est</code></td>
<td>
<p>a list with four elements representing the estimated mixture model,
which can be obtained using the <code><a href="#topic+mixnorm">mixnorm</a></code> function. When specified,
it has the form of <code>list(mu, sigma, pi, p)</code>, where
<code>mu</code> is a C by p matrix of estimated component means where p is the dimension of data
and C is the number of mixture components,
<code>sigma</code> is a p by p matrix of estimated common standard deviation for all components
(when the data is multi-dimensional) or a C-dimensional vector of estimated component
standard deviations (when the data is one-dimensional),
<code>pi</code> is a C-dimensional vector of mixing proportions, and
<code>p</code> is a C by n matrix of the classification probabilities,
where the (i, j)th element corresponds to the probability of the jth observation
belonging to the ith component.</p>
</td></tr>
<tr><td><code id="complh_+3A_lat">lat</code></td>
<td>
<p>a C by n zero-one matrix representing the latent component labels for all observations,
where C is the number of components in the mixture model and n is the number of observations.
If the (i, j)th cell is 1, it indicates that the jth observation belongs to the ith component.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimation results adjusted to account for potential label switching problems are returned,
as a list containing the following elements:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>C by p matrix of estimated component means.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated component standard deviations (for univariate data) or
p by p matrix of estimated component variance (for multivariate data).</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yao, W. (2015). Label switching and its solutions for frequentist mixture models.
Journal of Statistical Computation and Simulation, 85(5), 1000-1012.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+distlat">distlat</a></code>, <code><a href="#topic+mixnorm">mixnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-----------------------------------------------------------------------------------------#
# Example 1: Two-component Univariate Normal Mixture
#-----------------------------------------------------------------------------------------#
# Simulate the data
set.seed(827)
n = 200
prop = 0.3
n1 = rbinom(1, n, prop)
mudif = 1.5
x1 = rnorm(n1, 0, 1)
x2 = rnorm(n - n1, mudif, 1)
x = c(x1, x2)
pm = c(2, 1, 3, 5, 4)

# Use the `mixnorm' function to get the MLE and the estimated classification probabilities
out = mixnorm(x, 2)

# Prepare latent component label
lat = rbind(rep(c(1, 0), times = c(n1, n - n1)),
            rep(c(0, 1), times = c(n1, n - n1)))

# Fit the complh/distlat function
clhest = complh(out, lat)
clhest
# Result:
# mean of the first component: -0.1037359,
# mean of the second component: 1.6622397,
# sigma is 0.8137515 for both components, and
# the proportions for the two components are
# 0.3945660 and 0.6054340, respectively.
ditlatest = distlat(out, lat)

#-----------------------------------------------------------------------------------------#
# Example 2: Two-component Multivariate Normal Mixture
#-----------------------------------------------------------------------------------------#
# Simulate the data
n = 400
prop = 0.3
n1 = rbinom(1, n, prop)
pi = c(prop, 1 - prop)
mu1 = 0.5
mu2 = 0.5
mu = matrix(c(0, mu1, 0, mu2), ncol = 2)
pm = c(2, 1, 4, 3, 6, 5)
sigma = diag(c(1, 1))
ini = list(sigma = sigma, mu = mu, pi = pi)
x1 = mvtnorm::rmvnorm(n1, c(0, 0), ini$sigma)
x2 = mvtnorm::rmvnorm(n - n1, c(mu1, mu2), ini$sigma)
x = rbind(x1, x2)

# Use the `mixnorm' function to get the MLE and the estimated classification probabilities
out = mixnorm(x, 2)

# Prepare latent component label
lat = rbind(rep(c(1, 0), times = c(n1, n - n1)),
            rep(c(0, 1), times = c(n1, n - n1)))

# Fit the complh/distlat function
clhest = complh(out, lat)
distlatest = distlat(out, lat)

#-----------------------------------------------------------------------------------------#
# Example 3: Three-component Multivariate Normal Mixture
#-----------------------------------------------------------------------------------------#
# Simulate the data
n = 100
pi = c(0.2, 0.3, 0.5)
ns = stats::rmultinom(1, n, pi)
n1 = ns[1]; n2 = ns[2]; n3 = ns[3]
mu1 = 1
mu2 = 1
mu = matrix(c(0, mu1, 2 * mu1, 0, mu2, 2 * mu2), ncol = 2)
sigma = diag(c(1, 1))
ini = list(sigma = sigma, mu = mu, pi = pi)
x1 = mvtnorm::rmvnorm(n1, c(0, 0), ini$sigma)
x2 = mvtnorm::rmvnorm(n2, c(mu1, mu2), ini$sigma)
x3 = mvtnorm::rmvnorm(n3, c(2 * mu1, 2 * mu2), ini$sigma)
x = rbind(x1, x2, x3)

# Use the `mixnorm' function to get the MLE and the estimated classification probabilities
out = mixnorm(x, 3)

# Prepare latent component label
lat = rbind(rep(c(1, 0), times = c(n1, n - n1)),
            rep(c(0, 1, 0), times = c(n1, n2, n3)),
            rep(c(0, 1), times = c(n - n3, n3)))

# Fit the complh/distlat function
clhest = complh(out, lat)
distlatest = distlat(out, lat)
</code></pre>

<hr>
<h2 id='distlat'>Euclidean Distance Based Labeling Method for Label Switching</h2><span id='topic+distlat'></span>

<h3>Description</h3>

<p>&lsquo;distlat&rsquo; is used to address the label switching problem by minimizing
the distance between the classification probabilities and the latent component label,
which is the label used by the user to generate the sample (Yao, 2015).
The function supports both one-dimensional (with equal variances or unequal variances)
and multi-dimensional data (with equal variances).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distlat(est, lat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distlat_+3A_est">est</code></td>
<td>
<p>a list with four elements representing the estimated mixture model,
which can be obtained using the <code><a href="#topic+mixnorm">mixnorm</a></code> function. When specified,
it has the form of <code>list(mu, sigma, pi, p)</code>, where
<code>mu</code> is a C by p matrix of estimated component means where p is the dimension of data
and C is the number of mixture components,
<code>sigma</code> is a p by p matrix of estimated common standard deviation for all components
(when the data is multi-dimensional) or a C-dimensional vector of estimated component
standard deviations (when the data is one-dimensional),
<code>pi</code> is a C-dimensional vector of mixing proportions, and
<code>p</code> is a C by n matrix of the classification probabilities,
where the (i, j)th element corresponds to the probability of the jth observation
belonging to the ith component.</p>
</td></tr>
<tr><td><code id="distlat_+3A_lat">lat</code></td>
<td>
<p>a C by n zero-one matrix representing the latent component labels for all observations,
where C is the number of components in the mixture model and n is the number of observations.
If the (i, j)th cell is 1, it indicates that the jth observation belongs to the ith component.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimation results adjusted to account for potential label switching problems are returned,
as a list containing the following elements:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>C by p matrix of estimated component means.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated component standard deviations (for univariate data) or
p by p matrix of estimated component variance (for multivariate data).</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yao, W. (2015). Label switching and its solutions for frequentist mixture models.
Journal of Statistical Computation and Simulation, 85(5), 1000-1012.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+complh">complh</a></code>, <code><a href="#topic+mixnorm">mixnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for the `complh' function.
</code></pre>

<hr>
<h2 id='elbow'>Elbow data</h2><span id='topic+elbow'></span>

<h3>Description</h3>

<p>The data contains elbow dimension measurements on 507 individuals (247 men and
260 women), primarily in their twenties and thirties, all of whom exercise several
hours a week.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elbow
</code></pre>


<h3>Format</h3>

<p>A data frame containing 507 observations (elbow diameter, sum of two elbows).
</p>


<h3>References</h3>

<p>Heinz, G., Peterson, L. J., Johnson, R. W., and Kerk, C. J. (2003).
Exploring relationships in body dimensions. Journal of Statistics Education, 11(2)
</p>

<hr>
<h2 id='EMnormal'>Parameter Estimation of Normal Mixture Using EM Algorithm</h2><span id='topic+EMnormal'></span>

<h3>Description</h3>

<p>&lsquo;EMnormal&rsquo; is used to estimate the parameters of a univariate or multivariate
normal mixture model using the expectation-maximization (EM) algorithm.
The result can be used as the initial value for the <code><a href="#topic+mixLogconc">mixLogconc</a></code> and
<code><a href="#topic+mixLogconcHD">mixLogconcHD</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMnormal(x, C = 2, nstart = 20, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EMnormal_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and
p is the dimension of the data.</p>
</td></tr>
<tr><td><code id="EMnormal_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="EMnormal_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="EMnormal_+3A_tol">tol</code></td>
<td>
<p>stopping criteria (threshold value) for the EM algorithm. Default is 1e-05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>final log-likelihood.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated component means.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated component standard deviation or covariance matrix.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mixLogconc">mixLogconc</a></code>, <code><a href="#topic+mixLogconcHD">mixLogconcHD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-----------------------------------------------------------------------------------------#
# Univariate Case
#-----------------------------------------------------------------------------------------#
x = matrix(rnorm(100, 2, sqrt(2)), nrow = 100)
x[1:60] = x[1:60] + 5
ini = EMnormal(x)
</code></pre>

<hr>
<h2 id='ethanol'>Ethanol data</h2><span id='topic+ethanol'></span>

<h3>Description</h3>

<p>The data contains 88 sets of measurements of peak nitrogen oxide emission levels from an experiment
in which ethanol was burned in a single-cylinder engine. The emission levels of nitrogen oxides were
recorded under different settings of the compression ratio and equivalence ratio of the engine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ethanol
</code></pre>


<h3>Format</h3>

<p>A data frame containing 88 observations and the following 3 variables.
</p>

<dl>
<dt>NO:</dt><dd><p> concentration of nitric oxide (NO) and nitrogen dioxide (NO2) in engine exhaust.</p>
</dd>
<dt>Compression:</dt><dd><p> compression ratio of engine.</p>
</dd>
<dt>Equivalence:</dt><dd><p> equivalence ratio. This is a measure of the richness of the air and ethanol fuel mixture.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Original source:
</p>
<p>Brinkman, N. D. (1981). Ethanol fuel—single—cylinder engine study of efficiency and exhaust emissions.
SAE transactions, 1410-1424.
</p>
<p>R source:
</p>
<p>Wand M (2018). SemiPar: Semiparametic Regression. R package version 1.0-4.2,
<a href="https://CRAN.R-project.org/package=SemiPar">https://CRAN.R-project.org/package=SemiPar</a>.
</p>
<p>Sarkar D (2008). Lattice: Multivariate Data Visualization with R. Springer, New York. ISBN
978-0-387-75968-5, <a href="http://lmdvr.r-forge.r-project.org">http://lmdvr.r-forge.r-project.org</a>.
</p>


<h3>References</h3>

<p>Ruppert, D., Wand, M. P., and Carroll, R. J. (2003). Semiparametric regression (No. 12).
Cambridge university press.
</p>
<p>Hurn, M., Justel, A., and Robert, C. P. (2003). Estimating mixtures of regressions.
Journal of computational and graphical statistics, 12(1), 55-79.
</p>

<hr>
<h2 id='kdeem'>Kernel Density-based EM-type algorithm for Semiparametric Mixture Regression
with Unspecified Error Distributions</h2><span id='topic+kdeem'></span>

<h3>Description</h3>

<p>&lsquo;kdeem&rsquo; is used for semiparametric mixture regression using a kernel density-based
expectation-maximization (EM)-type algorithm with unspecified
homogeneous or heterogenous error distributions (Ma et al., 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdeem(x, y, C = 2, ini = NULL, maxiter = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kdeem_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the
number of explanatory variables (including the intercept).</p>
</td></tr>
<tr><td><code id="kdeem_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="kdeem_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="kdeem_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code><a href="#topic+kdeem.lse">kdeem.lse</a></code> function.
If specified, it can be a list with the form of <code>list(beta, prop, tau, pi, h)</code>, where
<code>beta</code> is a p by C matrix for regression coefficients of C components,
<code>prop</code> is an n by C matrix for probabilities of each observation belonging to each component,
caculated based on the initial <code>beta</code> and <code>h</code>, <code>tau</code> is a vector of C precision parameters
(inverse of standard deviation), <code>pi</code> is a vector of C mixing proportions, and
<code>h</code> is the bandwidth for kernel estimation.</p>
</td></tr>
<tr><td><code id="kdeem_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for the algorithm. Default is 200.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It can be used for a semiparametric mixture of linear regression models with
unspecified component error distributions. The errors can be either homogeneous or heterogenous.
The model is as follows:
</p>
<p style="text-align: center;"><code class="reqn">f_{Y|\boldsymbol{X}}(y,\boldsymbol{x},\boldsymbol{\theta},g) = \sum_{j=1}^C\pi_j\tau_jg\{(y-\boldsymbol{x}^{\top}\boldsymbol{\beta}_j)\tau_j\}.</code>
</p>

<p>Here, <code class="reqn">\boldsymbol{\theta}=(\pi_1,...,\pi_{C-1},\boldsymbol{\beta}_1^{\top},..,\boldsymbol{\beta}_C^{\top},\tau_1,...,\tau_C)^{\top}</code>,
<code class="reqn">g(\cdot)</code> is an unspecified density function with mean 0 and variance 1, and <code class="reqn">\tau_j</code> is a precision parameter.
For the calculation of <code class="reqn">\beta</code> in the M-step, this function employs the universal optimizer function <code>ucminf</code> from the &lsquo;ucminf&rsquo; package.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>posterior</code></td>
<td>
<p>posterior probabilities of each observation belonging to each component.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>estimated regression coefficients.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>estimated precision parameters, the inverse of standard deviation.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>bandwidth used for the kernel estimation.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Ma, Y., Wang, S., Xu, L., &amp; Yao, W. (2021). Semiparametric mixture regression
with unspecified error distributions. Test, 30, 429-444.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kdeem.h">kdeem.h</a></code>, <code><a href="#topic+kdeem.lse">kdeem.lse</a></code>, and <code><a href="ucminf.html#topic+ucminf">ucminf</a></code> for beta calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 300
C = 2
Dimen = 2
Beta.true.matrix = matrix(c(-3, 3, 3, -3), Dimen, C)
PI.true = c(0.5, 0.5)
x = runif(n)
X = cbind(1, x)
Group.ID = Rlab::rbern(n, prob = 0.5)
Error = rnorm(n, 0, 1)
n1 = sum(Group.ID)
n2 = n - n1
y = rep(0, n)
err = rep(0, n)

for(i in 1:n){
  if(Group.ID[i] == 1){
    err[i] = Error[i]
    y[i] = X[i, ] %*% Beta.true.matrix[, 1] + err[i]
  } else {
    err[i] = 0.5 * Error[i]
    y[i] = X[i, ] %*% Beta.true.matrix[, 2] + err[i]
  }
}
Result.kdeem.lse = kdeem.lse(x, y)
Result.kdeem.h = kdeem.h(x, y, 2, Result.kdeem.lse, maxiter = 200)
Result.kdeem = kdeem(x, y, 2, Result.kdeem.lse, maxiter = 200)
</code></pre>

<hr>
<h2 id='kdeem.h'>Kernel Density-based EM-type algorithm for Semiparametric Mixture Regression
with Unspecified Homogenous Error Distributions</h2><span id='topic+kdeem.h'></span>

<h3>Description</h3>

<p>&lsquo;kdeem.h&rsquo; is used for semiparametric mixture regression using a kernel density-based
expectation-maximization (EM)-type algorithm with unspecified
homogeneous error distributions (Hunter and Young, 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdeem.h(x, y, C = 2, ini = NULL, maxiter = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kdeem.h_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the
number of explanatory variables (including the intercept).</p>
</td></tr>
<tr><td><code id="kdeem.h_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="kdeem.h_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="kdeem.h_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code><a href="#topic+kdeem.lse">kdeem.lse</a></code> function.
If specified, it can be a list with the form of <code>list(beta, prop, tau, pi, h)</code>, where
<code>beta</code> is a p by C matrix for regression coefficients of C components,
<code>prop</code> is an n by C matrix for probabilities of each observation belonging to each component,
calculated based on the initial <code>beta</code> and <code>h</code>, <code>tau</code> is a vector of C precision parameters
(inverse of standard deviation), <code>pi</code> is a vector of C mixing proportions, and
<code>h</code> is the bandwidth for kernel estimation.</p>
</td></tr>
<tr><td><code id="kdeem.h_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for the algorithm. Default is 200.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>'kdeem.h' can be used to estimate parameters in a mixture-of-regressions model
with independent identically distributed errors. The model is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">f_{Y|\boldsymbol{X}}(y,\boldsymbol{x},\boldsymbol{\theta},g) = \sum_{j=1}^C\pi_jg(y-\boldsymbol{x}^{\top}\boldsymbol{\beta}_j).</code>
</p>

<p>Here, <code class="reqn">\boldsymbol{\theta}=(\pi_1,...,\pi_{C-1},\boldsymbol{\beta}_1^{\top},\cdots,\boldsymbol{\beta}_C^{\top})</code>,
and <code class="reqn">g(\cdot)</code> represents identical unspecified density functions.
The bandwidth of the kernel density estimation is calculated adaptively using the <code><a href="stats.html#topic+bw.SJ">bw.SJ</a></code> function from the &lsquo;stats&rsquo;
package, which implements the method of Sheather &amp; Jones (1991) for bandwidth selection based on pilot estimation
of derivatives.
</p>
<p>For the calculation of <code class="reqn">\beta</code> in the M-step,
this function employs the universal optimizer <code><a href="ucminf.html#topic+ucminf">ucminf</a></code> from the &lsquo;ucminf&rsquo; package.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>posterior</code></td>
<td>
<p>posterior probabilities of each observation belonging to each component.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>estimated regression coefficients.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>bandwidth used for the kernel estimation.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hunter, D. R., &amp; Young, D. S. (2012). Semiparametric mixtures of regressions.
Journal of Nonparametric Statistics, 24(1), 19-38.
</p>
<p>Ma, Y., Wang, S., Xu, L., &amp; Yao, W. (2021). Semiparametric mixture regression
with unspecified error distributions. Test, 30, 429-444.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kdeem">kdeem</a></code>, <code><a href="#topic+kdeem.lse">kdeem.lse</a></code>, <code><a href="stats.html#topic+bw.SJ">bw.SJ</a></code>
for bandwidth calculation, and <code><a href="ucminf.html#topic+ucminf">ucminf</a></code> for beta calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for the `kdeem' function.
</code></pre>

<hr>
<h2 id='kdeem.lse'>Kernel Density-based EM-type algorithm with Least Square Estimation
for Semiparametric Mixture Regression with Unspecified Homogenous
Error Distributions</h2><span id='topic+kdeem.lse'></span>

<h3>Description</h3>

<p>&lsquo;kdeem.lse&rsquo; is used for semiparametric mixture regression based on least squares estimation (Hunter and Young, 2012)
using a kernel density-based expectation-maximization (EM)-type algorithm with unspecified
homogeneous error distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdeem.lse(x, y, C = 2, ini = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kdeem.lse_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the
number of explanatory variables (including the intercept).</p>
</td></tr>
<tr><td><code id="kdeem.lse_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="kdeem.lse_+3A_c">C</code></td>
<td>
<p>number of mixture components. As of version 1.1.0, C must be set to 2.</p>
</td></tr>
<tr><td><code id="kdeem.lse_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code><a href="mixtools.html#topic+regmixEM">regmixEM</a></code> function from the &lsquo;mixtools&rsquo; package.
If specified, it can be a list with the form of <code>list(beta, prop, tau, pi, h)</code>, where
<code>beta</code> is a p by C matrix for regression coefficients of C components,
<code>prop</code> is an n by C matrix for probabilities of each observation belonging to each component,
caculated based on the initial <code>beta</code> and <code>h</code>, <code>tau</code> is a vector of C precision parameters
(inverse of standard deviation), <code>pi</code> is a vector of C mixing proportions, and
<code>h</code> is the bandwidth for kernel estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As of version 1.1.0, this function can only be used for a two-component mixture-of-regressions model
with independent identically distributed errors. Assuming <code class="reqn">C=2</code>, the model is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">f_{Y|\boldsymbol{X}}(y,\boldsymbol{x},\boldsymbol{\theta},g) = \sum_{j=1}^C\pi_jg(y-\boldsymbol{x}^{\top}\boldsymbol{\beta}_j).</code>
</p>

<p>Here, <code class="reqn">\boldsymbol{\theta}=(\pi_1,...,\pi_{C-1},\boldsymbol{\beta}_1^{\top},\cdots,\boldsymbol{\beta}_C^{\top})</code>,
and <code class="reqn">g(\cdot)</code> represents identical unspecified density functions.
The bandwidth of the kernel density estimation is calculated adaptively using the <code><a href="stats.html#topic+bw.SJ">bw.SJ</a></code> function from the &lsquo;stats&rsquo;
package, which implements the method of Sheather &amp; Jones (1991) for bandwidth selection based on pilot estimation
of derivatives. This function employs weighted least square estimation for <code class="reqn">\beta</code> in the M-step (Hunter and Young, 2012),
where the weight is the posterior probability of an observation belonging to each component.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>posterior</code></td>
<td>
<p>posterior probabilities of each observation belonging to each component.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>estimated regression coefficients.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>estimated precision parameter, the inverse of standard deviation.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>bandwidth used for the kernel estimation.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hunter, D. R., and Young, D. S. (2012). Semiparametric mixtures of regressions.
Journal of Nonparametric Statistics, 24(1), 19-38.
</p>
<p>Ma, Y., Wang, S., Xu, L., and Yao, W. (2021). Semiparametric mixture regression
with unspecified error distributions. Test, 30, 429-444.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kdeem">kdeem</a></code>, <code><a href="#topic+kdeem.h">kdeem.h</a></code>, <code><a href="stats.html#topic+bw.SJ">bw.SJ</a></code>
for bandwidth calculation, and <code><a href="mixtools.html#topic+regmixEM">regmixEM</a></code> for initial value calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for the `kdeem' function.
</code></pre>

<hr>
<h2 id='mixLogconc'>Clustering with Mixtures of Log-concave Distributions using EM Algorithm (Univariate)</h2><span id='topic+mixLogconc'></span>

<h3>Description</h3>

<p>&lsquo;mixLogconc&rsquo; is used to estimate the parameters of a mixture of univariate
log-concave distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixLogconc(x, C = 2, ini = NULL, nstart = 20, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixLogconc_+3A_x">x</code></td>
<td>
<p>an n by 1 data matrix where n is the number of observations.</p>
</td></tr>
<tr><td><code id="mixLogconc_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixLogconc_+3A_ini">ini</code></td>
<td>
<p>initial value for the EM algorithm. Default value is NULL, which
obtains the initial value using the <code><a href="#topic+EMnormal">EMnormal</a></code> function. It can be a list
with the form of <code>list(pi, mu, sigma)</code>, where <code>pi</code> is a 1 by C matrix
of mixing proportions, <code>mu</code> is a C by 1 matrix of component means, and
<code>sigma</code> is a p by p by 1 array of standard deviations or covariance matrices
of <code>C</code> mixture components.</p>
</td></tr>
<tr><td><code id="mixLogconc_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="mixLogconc_+3A_tol">tol</code></td>
<td>
<p>stopping criteria (threshold value) for the EM algorithm. Default is 1e-05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>final log-likelihood.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>component densities at x.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, G. T., and Walther, G. (2007). Clustering with mixtures of log-concave
distributions. Computational Statistics &amp; Data Analysis, 51(12), 6242-6251.
</p>
<p>Hu, H., Wu, Y., and Yao, W. (2016). Maximum likelihood estimation of the mixture
of log-concave densities. Computational Statistics &amp; Data Analysis, 101, 137-147.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMnormal">EMnormal</a></code>, <code><a href="#topic+mixLogconcHD">mixLogconcHD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(4)
x = matrix(rnorm(100, 2, sqrt(2)), nrow = 100)
x[1:60] = x[1:60] + 5
EMlogc = mixLogconc(x, C = 2)
</code></pre>

<hr>
<h2 id='mixLogconcHD'>Clustering with Mixtures of Log-concave Distributions using EM Algorithm (Multivariate)</h2><span id='topic+mixLogconcHD'></span>

<h3>Description</h3>

<p>&lsquo;mixLogconcHD&rsquo; is used to estimate the parameters of a mixture of multivariate
log-concave distributions. The correlation structure among components is
calculated by the normal copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixLogconcHD(x, C, ini = NULL, nstart = 20, tol = 1e-05, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixLogconcHD_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and
p is the dimension of the data.</p>
</td></tr>
<tr><td><code id="mixLogconcHD_+3A_c">C</code></td>
<td>
<p>number of mixture components.</p>
</td></tr>
<tr><td><code id="mixLogconcHD_+3A_ini">ini</code></td>
<td>
<p>initial value for the EM algorithm. Default value is NULL, which
obtains the initial value using the <code><a href="#topic+EMnormal">EMnormal</a></code> function. It can be a list
with the form of <code>list(pi, mu, sigma)</code>, where <code>pi</code> is a 1 by C matrix
of mixing proportions, <code>mu</code> is a C by p matrix of component means, and
<code>sigma</code> is a p by p by C array of standard deviations or covariance matrices
of <code>C</code> mixture components.</p>
</td></tr>
<tr><td><code id="mixLogconcHD_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="mixLogconcHD_+3A_tol">tol</code></td>
<td>
<p>stopping criteria (threshold value) for the EM algorithm. Default is 1e-05.</p>
</td></tr>
<tr><td><code id="mixLogconcHD_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for the EM algorithm. Default is 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>final log-likelihood.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>component densities at x.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated standard deviation or covariance matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chang, G. T., and Walther, G. (2007). Clustering with mixtures of log-concave
distributions. Computational Statistics &amp; Data Analysis, 51(12), 6242-6251.
</p>
<p>Hu, H., Wu, Y., and Yao, W. (2016). Maximum likelihood estimation of the mixture
of log-concave densities. Computational Statistics &amp; Data Analysis, 101, 137-147.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixLogconc">mixLogconc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = mvtnorm::rmvnorm(100, c(0, 0), matrix(c(2, 1, 1, 2), nrow = 2))
x = matrix(x, nrow = 100)
x[1:60, ] = x[1:60, ] + 5
EMlogc = mixLogconcHD(x, C = 2)
</code></pre>

<hr>
<h2 id='mixMPHD'>Semiparametric Mixture Model by Minimizing Profile Hellinger Distance</h2><span id='topic+mixMPHD'></span>

<h3>Description</h3>

<p>&lsquo;mixMPHD&rsquo; provides an efficient and robust estimation of a mixture of unknown
location-shifted symmetric distributions using a semiparamatric method (Wu et al., 2017).
As of version 1.1.0, 'mixMPHD' supports a two-component model, which is defined as
</p>
<p style="text-align: center;"><code class="reqn">h(x;\boldsymbol{\theta},f) = \pi f(x-\mu_1)+(1-\pi)f(x-\mu_2),</code>
</p>

<p>where <code class="reqn">\boldsymbol{\theta}=(\pi,\mu_1,\mu_2)^{\top}</code> is the parameter to estimate,
<code class="reqn">f</code> is an unknown density function that is symmetric at zero.
The parameters are estimated by minimizing the profile Hellinger distance (MPHD)
between the parametric model and a non-parametric density estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixMPHD(x, sigma.known = NULL, ini = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixMPHD_+3A_x">x</code></td>
<td>
<p>a vector of observations.</p>
</td></tr>
<tr><td><code id="mixMPHD_+3A_sigma.known">sigma.known</code></td>
<td>
<p>standard deviation of one component (if known). Default is NULL.</p>
</td></tr>
<tr><td><code id="mixMPHD_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code><a href="#topic+mixOnekn">mixOnekn</a></code> function. It can be a list with the form of <code>list(mu, pi, sigma)</code>, where
<code>mu</code> is a vector of component means,
<code>pi</code> is a vector of component mixing proportions,
<code>sigma</code> is a vector of component standard deviations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportion.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated component standard deviation. Only returned when <code>sigma.known</code> is not provided.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated component mean.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wu, J., Yao, W., and Xiang, S. (2017). Computation of an efficient and robust estimator
in a semiparametric mixture model. Journal of Statistical Computation and Simulation, 87(11), 2128-2137.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixOnekn">mixOnekn</a></code> for initial value calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Model: X ~ 0.3*N(0, 1) + 0.7*N(3, 1)
set.seed(4)
n = 100
p = 0.3
n1 = rbinom(1, n, p)
sigma1 = 1
sigma2 = 1
x1 = rnorm(n1, mean = 0, sd = sigma1)
x2 = rnorm(n - n1, mean = 3, sd = sigma2)
x = c(x1, x2)
ini = mixOnekn(x, sigma1)
mixMPHDest = mixMPHD(x, sigma1, ini = ini)
</code></pre>

<hr>
<h2 id='mixnorm'>Parameter Estimation for Uni- or Multivariate Normal Mixture Models</h2><span id='topic+mixnorm'></span>

<h3>Description</h3>

<p>&lsquo;mixnorm&rsquo; is used to estimate parameters of a normal mixture model with equal variance.
The function supports both one-dimensional and multi-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixnorm(x, C = 2, sigma.known = NULL, ini = NULL, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixnorm_+3A_x">x</code></td>
<td>
<p>an n by p matrix of observations where n is the number of observations and
s is the dimension of data.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_sigma.known">sigma.known</code></td>
<td>
<p>a vector or matrix of component standard deviations. Default is NULL, which means
the standard deviations are unknown.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which randomly sets the initial values
using the given observations. If specified, it can be a list with the form of <code>list(mu, pi, sigma)</code>, where
<code>mu</code> is a vector of C component means,
<code>pi</code> is a vector of C mixing proportions, and
<code>sigma</code> is a vector of C component standard deviations (this element is only needed when <code>sigma.known</code> is not given).</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_tol">tol</code></td>
<td>
<p>stopping criteria for the algorithm. Default is 1e-05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>estimated component means.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated component standard deviations. Only returned when <code>sigma.known</code> is not specified.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>matrix containing estimated classification probabilities where the (i, j)th element is the probability of
the jth observation belonging to the ith component.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+complh">complh</a></code>, <code><a href="#topic+distlat">distlat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for the `complh' function.
</code></pre>

<hr>
<h2 id='mixOnekn'>Two-component Normal Mixture Estimation with One Known Component</h2><span id='topic+mixOnekn'></span>

<h3>Description</h3>

<p>&lsquo;mixOnekn&rsquo; is used for the estimation of the following two-component mixture model:
</p>
<p style="text-align: center;"><code class="reqn">h(x;\boldsymbol{\theta},f) = \pi f(x-\mu_1)+(1-\pi)f(x-\mu_2),</code>
</p>

<p>where <code class="reqn">\boldsymbol{\theta}=(\pi,\mu_1,\mu_2)^{\top}</code> is the parameter to estimate,
<code class="reqn">f</code> is an unknown density function that is symmetric at zero.
The parameters are estimated by assuming <code class="reqn">f</code> is the normal density and the
first component has a mean of 0.
This function can be used to obtain initial values for the <code><a href="#topic+mixMPHD">mixMPHD</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixOnekn(x, sigma.known = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixOnekn_+3A_x">x</code></td>
<td>
<p>a vector of observations.</p>
</td></tr>
<tr><td><code id="mixOnekn_+3A_sigma.known">sigma.known</code></td>
<td>
<p>standard deviation of the first component (if known). Default is NULL,
which calculates the component standard deviations using the given observations <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>estimated 2 component means, where the first mean is 0.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated 2 component standard deviations.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated 2 mixing proportions.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mixMPHD">mixMPHD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see examples for the `mixMPHD' function.
</code></pre>

<hr>
<h2 id='mixpf'>Profile Likelihood Method for Normal Mixture with Unequal Variance</h2><span id='topic+mixpf'></span>

<h3>Description</h3>

<p>&lsquo;mixpf&rsquo; is used to estimate the following <code class="reqn">C</code>-component univariate normal mixture model,
using the profile likelihood method (Yao, 2010), with the assumption that the ratio of
the smallest variance to the largest variance is <code class="reqn">k</code>:
</p>
<p style="text-align: center;"><code class="reqn">f(x;\boldsymbol{\theta}) = \sum_{j=1}^C\pi_j\phi(x;\mu_j,\sigma_j^2),</code>
</p>

<p>where <code class="reqn">\boldsymbol{\theta}=(\pi_1,\mu_1,\sigma_1,..,\pi_{C},\mu_C,\sigma_C)^{\top}</code>
is the parameter to estimate, <code class="reqn">\phi(\cdot;\mu,\sigma^2)</code> is the normal density with a
mean of <code class="reqn">\mu</code> and a standard deviation of <code class="reqn">\sigma</code>, and <code class="reqn">\pi</code>'s are mixing
proportions that sum up to 1.
Once the results are obtained, one can also find the maximum likelihood estimate (MLE) of <code class="reqn">k</code> by
plotting the likelihood vs. <code class="reqn">k</code> for different <code class="reqn">k</code> values and finding the maximum
interior mode in the likelihood. See examples below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixpf(x, k = 0.5, C = 2, nstart = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixpf_+3A_x">x</code></td>
<td>
<p>a vector of observations.</p>
</td></tr>
<tr><td><code id="mixpf_+3A_k">k</code></td>
<td>
<p>ratio of the smallest variance to the largest variance. Default is 0.5.</p>
</td></tr>
<tr><td><code id="mixpf_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixpf_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>vector of estimated component means.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>vector of estimated component standard deviations.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yao, W. (2010). A profile likelihood method for normal mixture with unequal variance.
Journal of Statistical Planning and Inference, 140(7), 2089-2098.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(4)
n = 100
u = runif(n, 0, 1)
x2 = (u &lt;= 0.3) * rnorm(n, 0, 0.5) + (u &gt; 0.3) * rnorm(n, 1.5, 1)

# please set ngrid to 200 to get a smooth likelihood curve
ngrid = 5
grid = seq(from = 0.01, to = 1, length = ngrid)
likelihood = numeric()
for(i in 1:ngrid){
  k = grid[i]
  est = mixpf(x2, k)
  lh = est$lik
  likelihood[i] = lh
}

# visualize likelihood to find the best k
plot(grid, likelihood, type = "l", lty = 2, xlab = "k", ylab = "profile log-likelihood")
</code></pre>

<hr>
<h2 id='mixreg'>MLE of Mixture Regression with Normal Errors</h2><span id='topic+mixreg'></span>

<h3>Description</h3>

<p>&lsquo;mixreg&rsquo; provides the MLE estimates of a mixture of regression models with normal errors.
The result from this function can be used as initial values of the <code><a href="#topic+mixregRM2">mixregRM2</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixreg(x, y, C = 2, nstart = 20, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixreg_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the number of explanatory variables.
The intercept term will automatically be added to the data.</p>
</td></tr>
<tr><td><code id="mixreg_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixreg_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixreg_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="mixreg_+3A_tol">tol</code></td>
<td>
<p>stopping criteria (threshold value) for the EM algorithm. Default is 1e-05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>C by (p + 1) matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated standard deviations.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mixregRM2">mixregRM2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tone)
y = tone$tuned
x = tone$stretchratio
k = 160
x[151:k] = 0
y[151:k] = 5
est = mixreg(x, y, 2, nstart = 1)
</code></pre>

<hr>
<h2 id='mixregBisq'>Robust EM Algorithm For Mixture of Linear Regression Based on Bisquare Function</h2><span id='topic+mixregBisq'></span>

<h3>Description</h3>

<p>&lsquo;mixregBisq&rsquo; is used to robustly estimate the parameters of a mixture regression model
using the bisquare function based on multiple initial values (Bai et al., 2012). The solution is the mode
of the solutions obtained from all initial values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregBisq(x, y, C = 2, nstart = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregBisq_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the number of explanatory variables.
The intercept term will automatically be added to the data.</p>
</td></tr>
<tr><td><code id="mixregBisq_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixregBisq_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixregBisq_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following element:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>C by (p + 1) matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated standard deviations.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai, X., Yao, W., and Boyer, J. E. (2012). Robust fitting of mixture regression models.
Computational Statistics &amp; Data Analysis, 56(7), 2347-2359.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tone)
y = tone$tuned
x = tone$stretchratio
k = 160
x[151:k] = 0
y[151:k] = 5
est_bi = mixregBisq(x, y, 2, nstart = 20)
</code></pre>

<hr>
<h2 id='mixregLap'>Robust Mixture Regression with Laplace Distribution</h2><span id='topic+mixregLap'></span>

<h3>Description</h3>

<p>&lsquo;mixregLap&rsquo; provides robust estimation for a mixture of linear regression models
by assuming that the error terms follow the Laplace distribution (Song et al., 2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregLap(x, y, C = 2, nstart = 20, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregLap_+3A_x">x</code></td>
<td>
<p>an n by p matrix of observations (one observation per row). The intercept will be automatically added to <code>x</code>.</p>
</td></tr>
<tr><td><code id="mixregLap_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixregLap_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixregLap_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="mixregLap_+3A_tol">tol</code></td>
<td>
<p>stopping criteria (threshold value) for the EM algorithm. Default is 1e-05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>C by (p + 1) matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated component standard deviations.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Song, W., Yao, W., and Xing, Y. (2014). Robust mixture regression model fitting by Laplace distribution.
Computational Statistics &amp; Data Analysis, 71, 128-137.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixregT">mixregT</a></code> for robust estimation with t-distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tone)
y = tone$tuned          # length(y) = 160
x = tone$stretchratio   # length(x) = 160
k = 160
x[151:k] = 0
y[151:k] = 5
est_lap = mixregLap(x, y, 2)
</code></pre>

<hr>
<h2 id='mixregPvary'>Mixture of Regression Models with Varying Mixing Proportions</h2><span id='topic+mixregPvary'></span>

<h3>Description</h3>

<p>&lsquo;mixregPvary&rsquo; is used to estimate a mixture of regression models with varying proportions:
</p>
<p style="text-align: center;"><code class="reqn">Y|_{\boldsymbol{x},Z=z} \sim \sum_{c=1}^C\pi_c(z)N(\boldsymbol{x}^{\top}\boldsymbol{\beta}_c,\sigma_c^2).</code>
</p>

<p>The varying proportions are estimated using a local constant regression method (kernel regression).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregPvary(x, y, C = 2, z = NULL, u = NULL, h = NULL,
             kernel = c("Gaussian", "Epanechnikov"), ini = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregPvary_+3A_x">x</code></td>
<td>
<p>an n by p matrix of explanatory variables. The intercept will be automatically added to x.</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_z">z</code></td>
<td>
<p>a vector of a variable with varying-proportions. It can be any of the variables in <code>x</code>.
Default is NULL, and the first variable in <code>x</code> will be used.</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_u">u</code></td>
<td>
<p>a vector of grid points for the local constant regression method to estimate the proportions.
If NULL (default), 100 equally spaced grid points are automatically generated
between the minimum and maximum values of z.</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_h">h</code></td>
<td>
<p>bandwidth for kernel density estimation. If NULL (default), the bandwidth is
calculated based on the method of Botev et al. (2010).</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_kernel">kernel</code></td>
<td>
<p>character, determining the kernel function used in local constant method:
<code>Gaussian</code> or <code>Epanechnikov</code>. Default is <code>Gaussian</code>.</p>
</td></tr>
<tr><td><code id="mixregPvary_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code>regmixEM</code> function of the &lsquo;mixtools&rsquo; package.
If specified, it can be a list with the form of
<code>list(pi, beta, var)</code>, where
<code>pi</code> is a vector of length C of mixing proportions,
<code>beta</code> is a (p + 1) by C matrix for component regression coefficients, and
<code>var</code> is a vector of length C of component variances.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi_u</code></td>
<td>
<p>length(u) by C matrix of estimated mixing proportions at grid points.</p>
</td></tr>
<tr><td><code>pi_z</code></td>
<td>
<p>n by C matrix of estimated mixing proportions at z.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>(p + 1) by C matrix of estimated component regression coefficients.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>C-dimensional vector of estimated component variances.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>final log-likelihood.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Huang, M. and Yao, W. (2012). Mixture of regression models with varying mixing proportions:
a semiparametric approach. Journal of the American Statistical Association, 107(498), 711-724.
</p>
<p>Botev, Z. I., Grotowski, J. F., and Kroese, D. P. (2010). Kernel density estimation via diffusion.
The Annals of Statistics, 38(5), 2916-2957.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixregPvaryGen">mixregPvaryGen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100
C = 2
u = seq(from = 0, to = 1, length = 100)
true_beta = cbind(c(4, - 2), c(0, 3))
true_var = c(0.09, 0.16)
data = mixregPvaryGen(n, C)
x = data$x
y = data$y
est = mixregPvary(x, y, C, z = x, u, h = 0.08)
</code></pre>

<hr>
<h2 id='mixregPvaryGen'>Varying Proportion Mixture Data Generator</h2><span id='topic+mixregPvaryGen'></span>

<h3>Description</h3>

<p>&lsquo;mixregPvaryGen&rsquo; is used to generate a mixture of normal distributions with varying proportions:
</p>
<p style="text-align: center;"><code class="reqn">Y|_{\boldsymbol{x},Z=z} \sim \sum_{c=1}^C\pi_c(z)N(\boldsymbol{x}^{\top}\boldsymbol{\beta}_c,\sigma_c^2).</code>
</p>

<p>See <code><a href="#topic+mixregPvary">mixregPvary</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregPvaryGen(n, C = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregPvaryGen_+3A_n">n</code></td>
<td>
<p>number of observations.</p>
</td></tr>
<tr><td><code id="mixregPvaryGen_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>vector of length n.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>vector of length n.</p>
</td></tr>
<tr><td><code>true_p</code></td>
<td>
<p>n by C matrix of probabilities of an observations belonging to each component.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mixregPvary">mixregPvary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mixregPvaryGen(n = 100, C = 2)
</code></pre>

<hr>
<h2 id='mixregRM2'>Robust Mixture Regression with Thresholding-Embedded EM Algorithm for Penalized Estimation</h2><span id='topic+mixregRM2'></span>

<h3>Description</h3>

<p>A robust mixture regression model that simultaneously conducts outlier detection and
robust parameter estimation. It uses a sparse, case-specific, and scale-dependent
mean-shift mixture model parameterization (Yu et al., 2017):
</p>
<p style="text-align: center;"><code class="reqn">f(y_i|\boldsymbol{x}_i,\boldsymbol{\theta},\boldsymbol{\gamma}_i) = \sum_{j=1}^C\pi_j\phi(y_i;\boldsymbol{x}^{\top}\boldsymbol{\beta}_j+\gamma_{ij}\sigma_j,\sigma_j^2),</code>
</p>

<p><code class="reqn">i=1,\cdots,n</code>, where <code class="reqn">C</code> is the number of components in the model,
<code class="reqn">\boldsymbol{\theta}=(\pi_1,\boldsymbol{\beta}_1,\sigma_1,..,\pi_{C},\boldsymbol{\beta}_C,\sigma_C)^{\top}</code>
is the parameter to estimate,
and <code class="reqn">\boldsymbol{\gamma}_i=(\gamma_{i1},...,\gamma_{iC})^{\top}</code> is a vector of mean-shift parameter for the ith observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregRM2(x, y, C = 2, ini = NULL, nstart = 20, tol = 1e-02, maxiter = 50,
          method = c("HARD", "SOFT"), sigma.const = 0.001, lambda = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregRM2_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the number of explanatory variables.
The intercept term will automatically be added to the data.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code><a href="#topic+mixreg">mixreg</a></code> function. It can be a list with the form of <code>list(pi, beta, sigma, gamma)</code>, where
<code>pi</code> is a vector of C mixing proportions,
<code>beta</code> is a C by (p + 1) matrix for regression coefficients of C components,
<code>sigma</code> is a vector of C standard deviations, and
<code>gamma</code> is a vector of C mean shift values.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_tol">tol</code></td>
<td>
<p>stopping criteria (threshold value) for the EM algorithm. Default is 1e-02.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for the EM algorithm. Default is 50.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_method">method</code></td>
<td>
<p>character, determining which threshold method to use: <code>HARD</code> or <code>SOFT</code>.
Default is <code>HARD</code>. See details.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_sigma.const">sigma.const</code></td>
<td>
<p>constraint on the ratio of minimum and maximum values of sigma. Default is 0.001.</p>
</td></tr>
<tr><td><code id="mixregRM2_+3A_lambda">lambda</code></td>
<td>
<p>tuning parameter in the penalty term. It can be found based on BIC. See Yu et al. (2017) for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters are estimated by maximizing the corresponding penalized log-likelihood function using an EM algorithm.
The thresholding rule involes the estimation of <code class="reqn">\gamma_{ij}</code> corresponding to different penalty:
</p>

<ul>
<li><p> Soft threshold: <code class="reqn">\hat{\gamma}_{ij} = sgn(\epsilon_{ij})(|\epsilon_{ij}|-\lambda_{ij}^*)_{+})</code>, corresponding to the <code class="reqn">l_1</code> penalty.
</p>
</li>
<li><p> Hard threshold: <code class="reqn">\hat{\gamma}_{ij} = \epsilon_{ij}I(|\epsilon_{ij}|&gt;\lambda_{ij}^*))</code>, corresponding to the <code class="reqn">l_0</code> penalty.
</p>
</li></ul>

<p>Here, <code class="reqn">\epsilon_{ij} = (y_i-\boldsymbol{x}_i^{\top}\boldsymbol{\beta_j})/\sigma_j</code> and
<code class="reqn">(\cdot)_{+}=\max(\cdot,0)</code>. Also, <code class="reqn">\lambda_{ij}^*</code> is taken as <code class="reqn">\lambda/p_{ij}^{(k+1)}</code> for soft threshold and
<code class="reqn">\lambda/\sqrt{p_{ij}^{(k+1)}}</code> for hard threshold.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>C by (p + 1) matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated standard deviations.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>n-dimensional vector of estimated mean shift values.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>n by C matrix of posterior probabilities of each observation belonging to each component.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yu, C., Yao, W., and Chen, K. (2017). A new method for robust mixture regression.
Canadian Journal of Statistics, 45(1), 77-94.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixreg">mixreg</a></code> for initial value calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tone)
y = tone$tuned
x = tone$stretchratio
k = 160
x[151:k] = 0
y[151:k] = 5
est_RM2 = mixregRM2(x, y, lambda = 1)
</code></pre>

<hr>
<h2 id='mixregT'>Robust Mixture Regression with T-distribution</h2><span id='topic+mixregT'></span>

<h3>Description</h3>

<p>&lsquo;mixregT&rsquo; provides a robust estimation for a mixture of linear regression models
by assuming that the error terms follow the t-distribution (Yao et al., 2014). The degrees of freedom
is adaptively estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregT(x, y, C = 2, maxdf = 30, nstart = 20, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregT_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the number of explanatory variables.
The intercept term will automatically be added to the data.</p>
</td></tr>
<tr><td><code id="mixregT_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixregT_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixregT_+3A_maxdf">maxdf</code></td>
<td>
<p>maximum degrees of freedom for the t-distribution. Default is 30.</p>
</td></tr>
<tr><td><code id="mixregT_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
<tr><td><code id="mixregT_+3A_tol">tol</code></td>
<td>
<p>threshold value (stopping criteria) for the EM algorithm. Default is 1e-05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>C by (p + 1) matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated standard deviations.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>estimated degrees of freedom of the t-distribution.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yao, W., Wei, Y., and Yu, C. (2014). Robust mixture regression using the t-distribution.
Computational Statistics &amp; Data Analysis, 71, 116-127.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixregLap">mixregLap</a></code> for robust estimation with Laplace distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tone)
y = tone$tuned
x = tone$stretchratio
k = 160
x[151:k] = 0
y[151:k] = 5
est_t = mixregT(x, y, 2, nstart = 20, tol = 0.1)
</code></pre>

<hr>
<h2 id='mixregTrim'>Robust Regression Estimator Using Trimmed Likelihood</h2><span id='topic+mixregTrim'></span>

<h3>Description</h3>

<p>&lsquo;mixregTrim&rsquo; is used for robust regression estimation of a mixture model using the trimmed likelihood estimator
(Neykov et al., 2007). It trims the data to reduce the impact of outliers on the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixregTrim(x, y, C = 2, keep = 0.95, nstart = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixregTrim_+3A_x">x</code></td>
<td>
<p>an n by p data matrix where n is the number of observations and p is the number of explanatory variables.
The intercept term will automatically be added to the data.</p>
</td></tr>
<tr><td><code id="mixregTrim_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response variable.</p>
</td></tr>
<tr><td><code id="mixregTrim_+3A_c">C</code></td>
<td>
<p>number of mixture components. Default is 2.</p>
</td></tr>
<tr><td><code id="mixregTrim_+3A_keep">keep</code></td>
<td>
<p>proportion of data to be kept after trimming, ranging from 0 to 1. Default is 0.95.</p>
</td></tr>
<tr><td><code id="mixregTrim_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default is 20.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>C-dimensional vector of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>C by (p + 1) matrix of estimated regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>C-dimensional vector of estimated standard deviations.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Neykov, N., Filzmoser, P., Dimova, R., and Neytchev, P. (2007). Robust fitting of mixtures using
the trimmed likelihood estimator. Computational Statistics &amp; Data Analysis, 52(1), 299-308.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tone)
y = tone$tuned
x = tone$stretchratio
k = 160
x[151:k] = 0
y[151:k] = 5
est_TLE = mixregTrim(x, y, 2, 0.95, nstart = 1)
</code></pre>

<hr>
<h2 id='mixScale'>Continuous Scale Mixture Approach for Normal Scale Mixture Model</h2><span id='topic+mixScale'></span>

<h3>Description</h3>

<p>&lsquo;mixScale&rsquo; is used to estimate a two-component continuous normal scale mixture model, based on a backfitting method (Xiang et al., 2016):
</p>
<p style="text-align: center;"><code class="reqn">p(x;\boldsymbol{\theta},f) = \pi f_1(x-\mu_1) + (1-\pi)  f_2(x-\mu_2),</code>
</p>

<p>where <code class="reqn">\boldsymbol{\theta}=(\pi,\mu_1,\mu_2)</code>. Here, <code class="reqn">f</code> is assumed to be a member of
<code class="reqn">\mathcal{F} = \left\{ f(x) \big| \int\frac{1}{\sigma}\phi(x/\sigma)dQ(\sigma) \right\}</code>,
where <code class="reqn">\phi(x)</code> is the standard normal density and <code class="reqn">Q</code> is an unspecified probability measure on positive real numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixScale(x, ini = NULL, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixScale_+3A_x">x</code></td>
<td>
<p>a vector of observations.</p>
</td></tr>
<tr><td><code id="mixScale_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using the <code><a href="#topic+mixnorm">mixnorm</a></code> function. If specified, it can be a list with the form of
<code>list(pi, mu, sigma)</code>, where
<code>pi</code> is a vector of 2 mixing proportions,
<code>mu</code> is a vector of 2 component means, and
<code>sigma</code> is a vector of 2 component (common) standard deviations.</p>
</td></tr>
<tr><td><code id="mixScale_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for the EM algorithm. Default is 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>estimated component means.</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>suppQ</code></td>
<td>
<p>support of Q.</p>
</td></tr>
<tr><td><code>weightQ</code></td>
<td>
<p>weight of Q corresponding to initial standard deviations.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>final log-likelihood.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>number of iterations after convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Xiang, S., Yao, W., and Seo, B. (2016). Semiparametric mixture: Continuous scale mixture approach.
Computational Statistics &amp; Data Analysis, 103, 413-425.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixnorm">mixnorm</a></code> for initial value calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(quadprog)

#-----------------------------------------------------------------------------------------#
# Example 1: simulation
#-----------------------------------------------------------------------------------------#
n = 10
mu = c(-2.5, 0)
sd = c(0.8, 0.6)
pi = c(0.3, 0.7)
set.seed(2023)
n1 = rbinom(n, 1, pi[1])
x = c(rnorm(sum(n1), mu[1], sd[1]), rnorm(n - sum(n1), mu[2], sd[2]))
ini = list(pi = pi, mu = mu, sigma = sd)
out = mixScale(x, ini)

#-----------------------------------------------------------------------------------------#
# Example 2: elbow data
#-----------------------------------------------------------------------------------------#
ini = mixnorm(elbow)
res = mixScale(elbow, ini)
</code></pre>

<hr>
<h2 id='mixTest'>Goodness of Fit Test for Finite Mixture Models</h2><span id='topic+mixTest'></span>

<h3>Description</h3>

<p>&lsquo;mixTest&rsquo; is used to perform a goodness-of-fit test for finite mixture models (Wichitchan et al., 2019).
It returns five types of goodness-of-fit statistics and determines the number of components
in the mixture model based on the Kolmogorov-Smirnov (KS) statistic.
The test is performed using bootstrapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixTest(x, alpha = 0.10, C.max = 10, nboot = 500, nstart = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixTest_+3A_x">x</code></td>
<td>
<p>a vector of observations.</p>
</td></tr>
<tr><td><code id="mixTest_+3A_alpha">alpha</code></td>
<td>
<p>significance level of the test.</p>
</td></tr>
<tr><td><code id="mixTest_+3A_c.max">C.max</code></td>
<td>
<p>maximum number of mixture components considered in the test.
The test is performed for 2 to <code>C.max</code> components.</p>
</td></tr>
<tr><td><code id="mixTest_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap resampling. Default is 500.</p>
</td></tr>
<tr><td><code id="mixTest_+3A_nstart">nstart</code></td>
<td>
<p>number of initializations to try. Default if 5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>GOFstats</code></td>
<td>
<p>vector of test statistics calculated from data, in the order <code>of c(ks, cvm, kui, wat, ad)</code>.</p>
</td></tr>
<tr><td><code>ks</code></td>
<td>
<p>vector of the Kolmogorov-Smirnov (KS) statistic for each bootstrap sample.</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>vector of the Cramer-Von Mises statistic for each bootstrap sample.</p>
</td></tr>
<tr><td><code>kui</code></td>
<td>
<p>vector of the Kuiper's statistic for each bootstrap sample.</p>
</td></tr>
<tr><td><code>wat</code></td>
<td>
<p>vector of the Watson statistic for each bootstrap sample.</p>
</td></tr>
<tr><td><code>ad</code></td>
<td>
<p>vector of the Anderson Darling statistic for each bootstrap sample.</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>vector of test results based on the KS statistic.
If the kth element in the vector is 1, k-component mixture model is significant
based on the KS statistic; If 0, otherwise. See examples for details.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wichitchan, S., Yao, W., and Yang, G. (2019). Hypothesis testing for finite mixture models.
Computational Statistics &amp; Data Analysis, 132, 180-189.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100
mu = c(-2.5, 0)
sd = c(0.8, 0.6)
n1 = rbinom(n, 1, 0.3)
x = c(rnorm(sum(n1), mu[1], sd[1]), rnorm(n - sum(n1), mu[2], sd[2]))

# The result shows that two-component mixture model is statistically significant based on the KS.
out = mixTest(x, alpha = 0.10, C.max = 10, nboot = 500, nstart = 5)
</code></pre>

<hr>
<h2 id='NBA'>NBA data</h2><span id='topic+NBA'></span>

<h3>Description</h3>

<p>The data contains four descriptive statistics for all 95 guards for the 1992-1993
season. There are many ways to measure the (statistical) performance of guards in
the NBA. Of interest is how the the player's height (Height), minutes per game (MPG),
and free throw percentage (FTP) affect points per game (PPM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NBA
</code></pre>


<h3>Format</h3>

<p>A data frame containing 95 observations and the following 4 variables.
</p>

<dl>
<dt>Height:</dt><dd><p> height of the player.</p>
</dd>
<dt>MPG:</dt><dd><p> minutes per game.</p>
</dd>
<dt>FTP:</dt><dd><p> free throw percentage.</p>
</dd>
<dt>PPM:</dt><dd><p> points per game.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chatterjee, S., Handcock, M. S., and Simonoff, J. S. (1995). A casebook for a
first course in statistics and data analysis (No. 04; QA276. 12, C4.).
New York: Wiley.
</p>
<p>Xiang, S. and Yao, W. (2020). Semiparametric mixtures of regressions with
single-index for model based clustering. Advances in Data Analysis and
Classification, 14(2), 261-292.
</p>

<hr>
<h2 id='ROE'>ROE data</h2><span id='topic+ROE'></span>

<h3>Description</h3>

<p>The data contains a total of 2110 Chinese listed companies on their Return on
Equity (ROE), which represents the amount of net income returned as a percentage of
shareholders' equity. ROE is an important index used to measure a corporation's
profitability and is also a useful indicator for fundamental analysts to assess
the value of stocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ROE
</code></pre>


<h3>Format</h3>

<p>A data frame containing 2110 observations.
</p>


<h3>References</h3>

<p>Huang, M., Wang, S., Wang, H., and Jin, T. (2018). Maximum smoothed
likelihood estimation for a class of semiparametric Pareto mixture densities.
Statistics and Its Interface, 11(1), 31-40.
</p>

<hr>
<h2 id='semimrBin'>Semiparametric Mixture of Binomial Regression with a Degenerate Component
with Time-Varying Proportion and Time-Varying Success Probability</h2><span id='topic+semimrBin'></span>

<h3>Description</h3>

<p>&lsquo;semimrBin&rsquo; is used for semiparametric estimation of a mixture of binomial distributions
with one degenerate component, with time-varying proportions and time-varying success probability
(Cao and Yao, 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrBin(t, x, N, tg = NULL, tune = 1, tol = 1e-02)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrBin_+3A_t">t</code></td>
<td>
<p>a vector of time variable along which <code class="reqn">w(t)</code> and <code class="reqn">p(t)</code> vary.
See details for the explanations of those notations.</p>
</td></tr>
<tr><td><code id="semimrBin_+3A_x">x</code></td>
<td>
<p>a vector of observed number of successes. The length of <code>t</code> and <code>x</code> must be the same.</p>
</td></tr>
<tr><td><code id="semimrBin_+3A_n">N</code></td>
<td>
<p>a scalar, specifying the number of trials for the Binomial distribution.</p>
</td></tr>
<tr><td><code id="semimrBin_+3A_tg">tg</code></td>
<td>
<p>grid points of time used in the kernel regression for the estimation of <code class="reqn">w(t)</code> and <code class="reqn">p(t)</code>.
Default is NULL, and 100 equally spaced grid points will automatically generated
using the minimum and maximum values of <code>t</code>.</p>
</td></tr>
<tr><td><code id="semimrBin_+3A_tune">tune</code></td>
<td>
<p>a scalar related to the bandwidth selection and local estimation. Default is 1.
If greater than 0.2, the bandwidth is found based on the method in Cao and Yao (2012).
If smaller than or equal to 0.2, this value is used as the percentage of data included in local estimation.</p>
</td></tr>
<tr><td><code id="semimrBin_+3A_tol">tol</code></td>
<td>
<p>stopping criteria for the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The semiparametric mixture of binomial regression model is as follows:
</p>
<p style="text-align: center;"><code class="reqn">w(t) \times B(N,p(t))+(1-w(t))\times B(N,0),</code>
</p>

<p>where <code class="reqn">B(N,p)</code> is the probability mass function of a binomial distribution
with the number of trials <code class="reqn">N</code> and the success probability <code class="reqn">p</code>.
Here, the second component is a degenerate distribution with mass 1 on 0.
The time-varying proportion <code class="reqn">w(t)</code> and success probability <code class="reqn">p(t)</code> for the binomial components
are estimated by the kernel regression with some bandwidth.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pt</code></td>
<td>
<p>estimated time-varying success probabilities for the first component.</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>
<p>estimated time-varying proportions for the first component.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>bandwidth for the kernel regression. The bandwidth calculation can be found in Section 4 of Cao and Yao (2012).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cao, J. and Yao, W. (2012). Semiparametric mixture of binomial regression with a degenerate component.
Statistica Sinica, 27-46.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrBinOne">semimrBinOne</a></code>, <code><a href="#topic+semimrBinFull">semimrBinFull</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100
tg = seq(from = 0, to = 1, length.out = 50)
t = seq(from = 0, to = 1, length.out = n)
pt = 0.5 * (1 - cos(2 * pi * t))
b = rbinom(n, 1, 0.2)
y = apply(X = matrix(pt), 1, rbinom, n = 1, size = 7)
y = ifelse(b == 1, 0, y)
ft = semimrBin(t = t, x = y, N = 7, tg = tg)
</code></pre>

<hr>
<h2 id='semimrBinFull'>Semiparametric Mixture of Binomial Regression with a Degenerate Component
with Constant Proportion and Time-Varying Success Probability (Backfitting)</h2><span id='topic+semimrBinFull'></span>

<h3>Description</h3>

<p>&lsquo;semimrBinFull&rsquo; implements the backfitting method (Cao and Yao, 2012)
for semiparametric estimation of a mixture of binomial distributions with one degenerate component,
with constant proportion and time-varying success probability <code class="reqn">p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrBinFull(t, x, N, tg = NULL, tune = 1, tol = 1e-02)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrBinFull_+3A_t">t</code></td>
<td>
<p>a vector of time variable along which <code class="reqn">p(t)</code> varies.</p>
</td></tr>
<tr><td><code id="semimrBinFull_+3A_x">x</code></td>
<td>
<p>a vector of observed number of successes. The length of <code>t</code> and <code>x</code> must be the same.</p>
</td></tr>
<tr><td><code id="semimrBinFull_+3A_n">N</code></td>
<td>
<p>a scalar, specifying the number of trials for the Binomial distribution.</p>
</td></tr>
<tr><td><code id="semimrBinFull_+3A_tg">tg</code></td>
<td>
<p>grid points of time used in the kernel regression for the estimation of <code class="reqn">p(t)</code>.
Default is NULL, and 100 equally spaced grid points will automatically generated
using the minimum and maximum values of <code>t</code>.</p>
</td></tr>
<tr><td><code id="semimrBinFull_+3A_tune">tune</code></td>
<td>
<p>a scalar, specifying the percentage of data included in local estimation.
related to the bandwidth selection and local estimation. Default is 1.</p>
</td></tr>
<tr><td><code id="semimrBinFull_+3A_tol">tol</code></td>
<td>
<p>stopping criteria for the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The semiparametric mixture of binomial regression model is as follows:
</p>
<p style="text-align: center;"><code class="reqn">w \times (N,p(t))+(1-w)\times B(N,0),</code>
</p>

<p>where <code class="reqn">B(N,p)</code> is the probability mass function of a binomial distribution
with the number of trials <code class="reqn">N</code> and the success probability <code class="reqn">p</code>.
Here, the second component is a degenerate distribution with mass 1 on 0.
The time-varying success probability <code class="reqn">p(t)</code> for the binomial components
are estimated by the kernel regression using a full iterative backfitting procedure with some bandwidth.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pt</code></td>
<td>
<p>estimated time-varying success probabilities for the first component.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>estimated constant proportion for the first component.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>bandwidth for the kernel regression. The bandwidth calculation can be found in Section 4 of Cao and Yao (2012).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cao, J. and Yao, W. (2012). Semiparametric mixture of binomial regression with a degenerate component.
Statistica Sinica, 27-46.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrBin">semimrBin</a></code>, <code><a href="#topic+semimrBinOne">semimrBinOne</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nobs = 50
tobs = seq(from = 0, to = 1, length.out = nobs)
pi1Tru = 0.4
ptTru = 0.3 * (1.5 + cos(2 * pi * tobs))
nfine = nobs
tfine = seq(from = 0, to = 1, length.out = nfine)
b = rbinom(nobs, size = 1, pi1Tru)
yobs = apply(X = matrix(ptTru), 1, rbinom, n = 1, size = 7)
yobs = ifelse(b == 1, 0, yobs)
ftfull = semimrBinFull(t = tobs, x = yobs, N = 7, tg = tfine)
</code></pre>

<hr>
<h2 id='semimrBinOne'>Semiparametric Mixture of Binomial Regression with a Degenerate Component
with Constant Proportion and Time-Varying Success Probability (One-step Backfitting)</h2><span id='topic+semimrBinOne'></span>

<h3>Description</h3>

<p>&lsquo;semimrBinOne&rsquo; implements the one-step backfitting method (Cao and Yao, 2012)
for semiparametric estimation of a mixture of binomial distributions with one degenerate component,
with constant proportion and time-varying success probability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrBinOne(t, x, N, tg = NULL, tune = 1, tol = 1e-02)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrBinOne_+3A_t">t</code></td>
<td>
<p>a vector of time variable along which <code class="reqn">p(t)</code> varies.</p>
</td></tr>
<tr><td><code id="semimrBinOne_+3A_x">x</code></td>
<td>
<p>a vector of observed number of successes. The length of <code>t</code> and <code>x</code> must be the same.</p>
</td></tr>
<tr><td><code id="semimrBinOne_+3A_n">N</code></td>
<td>
<p>a scalar, specifying the number of trials for the Binomial distribution.</p>
</td></tr>
<tr><td><code id="semimrBinOne_+3A_tg">tg</code></td>
<td>
<p>grid points of time used in the kernel regression for the estimation of <code class="reqn">p(t)</code>.
Default is NULL, and 100 equally spaced grid points will automatically generated
using the minimum and maximum values of <code>t</code>.</p>
</td></tr>
<tr><td><code id="semimrBinOne_+3A_tune">tune</code></td>
<td>
<p>a scalar, specifying the percentage of data included in local estimation.
related to the bandwidth selection and local estimation. Default is 1.</p>
</td></tr>
<tr><td><code id="semimrBinOne_+3A_tol">tol</code></td>
<td>
<p>stopping criteria for the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The semiparametric mixture of binomial regression model is as follows:
</p>
<p style="text-align: center;"><code class="reqn">w \times B(N,p(t))+(1-w)\times B(N,0),</code>
</p>

<p>where <code class="reqn">B(N,p)</code> is the probability mass function of a binomial distribution
with the number of trials <code class="reqn">N</code> and the success probability <code class="reqn">p</code>.
Here, the second component is a degenerate distribution with mass 1 on 0.
The time-varying success probability <code class="reqn">p(t)</code> for the binomial components
are estimated by the kernel regression using one-step estimation for faster computation with some bandwidth.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pt</code></td>
<td>
<p>estimated time-varying success probabilities for the first component.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>estimated constant proportion for the first component.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>bandwidth for the kernel regression. The bandwidth calculation can be found in Section 4 of Cao and Yao (2012).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cao, J. and Yao, W. (2012). Semiparametric mixture of binomial regression with a degenerate component.
Statistica Sinica, 27-46.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrBin">semimrBin</a></code>, <code><a href="#topic+semimrBinFull">semimrBinFull</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nobs = 50
tobs = seq(from = 0, to = 1, length.out = nobs)
pi1Tru = 0.4
ptTru = 0.3 * (1.5 + cos(2 * pi * tobs))
nfine = nobs
tfine = seq(from = 0, to = 1, length.out = nfine)
b = rbinom(nobs, size = 1, pi1Tru)
yobs = apply(X = matrix(ptTru), 1, rbinom, n = 1, size = 7)
yobs = ifelse(b == 1, 0, yobs)
ftonestep = semimrBinOne(t = tobs, x = yobs, N = 7, tg = tfine)
</code></pre>

<hr>
<h2 id='semimrFull'>Semiparametric Mixture Regression Models with Single-index Proportion and Fully Iterative Backfitting</h2><span id='topic+semimrFull'></span>

<h3>Description</h3>

<p>Assume that <code class="reqn">\boldsymbol{x} = (\boldsymbol{x}_1,\cdots,\boldsymbol{x}_n)</code> is an n by p matrix and
<code class="reqn">Y = (Y_1,\cdots,Y_n)</code> is an n-dimensional vector of response variable.
The conditional distribution of <code class="reqn">Y</code> given
<code class="reqn">\boldsymbol{x}</code> can be written as:
</p>
<p style="text-align: center;"><code class="reqn">f(y|\boldsymbol{x},\boldsymbol{\alpha},\pi,m,\sigma^2) =
\sum_{j=1}^C\pi_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x})
\phi(y|m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x}),\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x})).</code>
</p>

<p>&lsquo;semimrFull&rsquo; is used to estimate the mixture of single-index models described above,
where <code class="reqn">\phi(y|m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x}),\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x}))</code>
represents the normal density with a mean of <code class="reqn">m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x})</code> and
a variance of <code class="reqn">\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x})</code>, and
<code class="reqn">\pi_j(\cdot), \mu_j(\cdot), \sigma_j^2(\cdot)</code> are unknown smoothing single-index functions
capable of handling high-dimensional non-parametric problem.
This function employs kernel regression and a fully iterative backfitting (FIB) estimation procedure
(Xiang and Yao, 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrFull(x, y, h = NULL, coef = NULL, ini = NULL, grid = NULL, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrFull_+3A_x">x</code></td>
<td>
<p>an n by p matrix of observations where n is the number of observations and
p is the number of explanatory variables.</p>
</td></tr>
<tr><td><code id="semimrFull_+3A_y">y</code></td>
<td>
<p>an n-dimensional vector of response values.</p>
</td></tr>
<tr><td><code id="semimrFull_+3A_h">h</code></td>
<td>
<p>bandwidth for the kernel regression. Default is NULL, and
the bandwidth is computed in the function by cross-validation.</p>
</td></tr>
<tr><td><code id="semimrFull_+3A_coef">coef</code></td>
<td>
<p>initial value of <code class="reqn">\boldsymbol{\alpha}^{\top}</code> in the model, which plays a role
of regression coefficient in a regression model. Default is NULL, and
the value is computed in the function by sliced inverse regression (Li, 1991).</p>
</td></tr>
<tr><td><code id="semimrFull_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values,
assuming a linear mixture model.
If specified, it can be a list with the form of <code>list(pi, mu, var)</code>, where
<code>pi</code> is a vector of mixing proportions,
<code>mu</code> is a vector of component means, and
<code>var</code> is a vector of component variances.</p>
</td></tr>
<tr><td><code id="semimrFull_+3A_grid">grid</code></td>
<td>
<p>grid points at which nonparametric functions are estimated.
Default is NULL, which uses the estimated mixing proportions, component means, and
component variances as the grid points after the algorithm converges.</p>
</td></tr>
<tr><td><code id="semimrFull_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations. Default is 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>matrix of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated component means.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>estimated component variances.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>estimated regression coefficients.</p>
</td></tr>
<tr><td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Xiang, S. and Yao, W. (2020). Semiparametric mixtures of regressions with single-index
for model based clustering. Advances in Data Analysis and Classification, 14(2), 261-292.
</p>
<p>Li, K. C. (1991). Sliced inverse regression for dimension reduction.
Journal of the American Statistical Association, 86(414), 316-327.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrOne">semimrOne</a></code>, <code><a href="#topic+sinvreg">sinvreg</a></code> for initial value calculation of
<code class="reqn">\boldsymbol{\alpha}^{\top}</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx = NBA[, c(1, 2, 4)]
yy = NBA[, 3]
x = xx/t(matrix(rep(sqrt(diag(var(xx))), length(yy)), nrow = 3))
y = yy/sd(yy)
ini_bs = sinvreg(x, y)
ini_b = ini_bs$direction[, 1]
est = semimrFull(x[1:50, ], y[1:50], h = 0.3442, coef = ini_b)
</code></pre>

<hr>
<h2 id='semimrGen'>Semiparametric Mixture Data Generator</h2><span id='topic+semimrGen'></span>

<h3>Description</h3>

<p>&lsquo;semimrGen&rsquo; is used to generate data for a two-component semiparametric mixture of regression models:
</p>
<p style="text-align: center;"><code class="reqn">p m_1(x) + (1-p) m_2(x),</code>
</p>

<p>where <code class="reqn">m_1(x) = 4 -\sin(2\pi x)</code> and <code class="reqn">m_2(x) = 1.5 + \cos(3\pi x).</code>
This function is used in the examples for the <code><a href="#topic+semimrLocal">semimrLocal</a></code> and <code><a href="#topic+semimrGlobal">semimrGlobal</a></code> functions.
See the examples for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrGen(n, p = 0.5, var = c(.1, .1), u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrGen_+3A_n">n</code></td>
<td>
<p>a scalar, specifying the number of observations in <code class="reqn">x</code>.</p>
</td></tr>
<tr><td><code id="semimrGen_+3A_p">p</code></td>
<td>
<p>a scalar, specifying the probability of an observation belonging to the first component,
i.e., <code class="reqn">p</code> in the model.</p>
</td></tr>
<tr><td><code id="semimrGen_+3A_var">var</code></td>
<td>
<p>a vector of variances of observations for the two components.</p>
</td></tr>
<tr><td><code id="semimrGen_+3A_u">u</code></td>
<td>
<p>a vector of grid points for <code class="reqn">x</code>. If some specific explanatory variable are needed, create a vector and assign to <code>u</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>vector of length n, which represents the explanatory variable
that is randomly generated from Uniform(0,1).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>vector of length n, which represent the response variable
that is generated based on the mean functions <code class="reqn">m_1(x)</code> and <code class="reqn">m_2(x)</code>,
with the addition of normal errors having a mean of 0 and a standard deviation specified by the user.</p>
</td></tr>
<tr><td><code>true_mu</code></td>
<td>
<p>n by 2 matrix containing the values of <code class="reqn">m_1(x)</code> and <code class="reqn">m_2(x)</code> at x.</p>
</td></tr>
<tr><td><code>true_mu_u</code></td>
<td>
<p>length(u) by 2 matrix containing the values of <code class="reqn">m_1(x)</code> and <code class="reqn">m_2(x)</code> at u.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+semimrLocal">semimrLocal</a></code>, <code><a href="#topic+semimrGlobal">semimrGlobal</a></code>, <code><a href="#topic+semimrBinFull">semimrBinFull</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100
u = seq(from = 0, to = 1, length = 100)
true_p = c(0.3, 0.7)
true_var = c(0.09, 0.16)
out = semimrGen(n = n, p = true_p[1], var = true_var, u = u)
</code></pre>

<hr>
<h2 id='semimrGlobal'>Semiparametric Mixtures of Nonparametric Regressions with Global EM-type Algorithm</h2><span id='topic+semimrGlobal'></span>

<h3>Description</h3>

<p>&lsquo;semimrGlobal&rsquo; is used to estimate a mixture of regression models, where the mixing proportions
and variances remain constant, but the component regression functions are smooth functions (<code class="reqn">m(\cdot)</code>)
of a covariate. The model is expressed as follows:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{j=1}^C\pi_j\phi(y|m(x_j),\sigma^2_j).</code>
</p>

<p>This function provides the one-step backfitting estimate using the global EM-type algorithm (GEM) (Xiang and Yao, 2018).
As of version 1.1.0, this function supports a two-component model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrGlobal(x, y, u = NULL, h = NULL, ini = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrGlobal_+3A_x">x</code></td>
<td>
<p>a vector of covariate values.</p>
</td></tr>
<tr><td><code id="semimrGlobal_+3A_y">y</code></td>
<td>
<p>a vector of response values.</p>
</td></tr>
<tr><td><code id="semimrGlobal_+3A_u">u</code></td>
<td>
<p>a vector of grid points for spline method to estimate the proportions.
If NULL (default), 100 equally spaced grid points are automatically generated
between the minimum and maximum values of x.</p>
</td></tr>
<tr><td><code id="semimrGlobal_+3A_h">h</code></td>
<td>
<p>bandwidth for the nonparametric regression. If NULL (default), the bandwidth is
calculated based on the method of Botev et al. (2010).</p>
</td></tr>
<tr><td><code id="semimrGlobal_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using regression spline approximation. If specified, it can be a list with the form of
<code>list(pi, mu, var)</code>, where
<code>pi</code> is a vector of length 2 of mixing proportions,
<code>mu</code> is a length(x) by 2 matrix of component means, and
<code>var</code> is a vector of length 2 of component variances.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>vector of length 2 of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>length(x) by 2 matrix of estimated mean functions at x, <code class="reqn">m(x)</code>.</p>
</td></tr>
<tr><td><code>mu_u</code></td>
<td>
<p>length(u) by 2 matrix of estimated mean functions at grid point u, <code class="reqn">m(u)</code>.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>vector of length 2 estimated component variances.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Xiang, S. and Yao, W. (2018). Semiparametric mixtures of nonparametric regressions.
Annals of the Institute of Statistical Mathematics, 70, 131-154.
</p>
<p>Botev, Z. I., Grotowski, J. F., and Kroese, D. P. (2010). Kernel density estimation via diffusion.
The Annals of Statistics, 38(5), 2916-2957.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrLocal">semimrLocal</a></code>, <code><a href="#topic+semimrGen">semimrGen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># produce data that matches the description using semimrGen function
# true_mu = (4 - sin(2 * pi * x), 1.5 + cos(3 * pi * x))
n = 100
u = seq(from = 0, to = 1, length = 100)
true_p = c(0.3, 0.7)
true_var = c(0.09, 0.16)
out = semimrGen(n, true_p[1], true_var, u)

x = out$x
y = out$y
true_mu = out$true_mu
true = list(true_p = true_p, true_mu = true_mu, true_var = true_var)

# estimate parameters using semimrGlobal function.
est = semimrGlobal(x, y)
</code></pre>

<hr>
<h2 id='semimrLocal'>Semiparametric Mixtures of Nonparametric Regressions with Local EM-type Algorithm</h2><span id='topic+semimrLocal'></span>

<h3>Description</h3>

<p>&lsquo;semimrLocal&rsquo; is used to estimate a mixture of regression models, where the mixing proportions
and variances remain constant, but the component regression functions are smooth functions (<code class="reqn">m(\cdot)</code>)
of a covariate. The model is expressed as follows:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{j=1}^C\pi_j\phi(y|m(x_j),\sigma^2_j).</code>
</p>

<p>This function provides the one-step backfitting estimate using the local EM-type algorithm (LEM) (Xiang and Yao, 2018).
As of version 1.1.0, this function supports a two-component model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrLocal(x, y, u = NULL, h = NULL, ini = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrLocal_+3A_x">x</code></td>
<td>
<p>a vector of covariate values.</p>
</td></tr>
<tr><td><code id="semimrLocal_+3A_y">y</code></td>
<td>
<p>a vector of response values.</p>
</td></tr>
<tr><td><code id="semimrLocal_+3A_u">u</code></td>
<td>
<p>a vector of grid points for spline method to estimate the proportions.
If NULL (default), 100 equally spaced grid points are automatically generated
between the minimum and maximum values of x.</p>
</td></tr>
<tr><td><code id="semimrLocal_+3A_h">h</code></td>
<td>
<p>bandwidth for the nonparametric regression. If NULL (default), the bandwidth is
calculated based on the method of Botev et al. (2010).</p>
</td></tr>
<tr><td><code id="semimrLocal_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values
using regression spline approximation. If specified, it can be a list with the form of
<code>list(pi, mu, var)</code>, where
<code>pi</code> is a vector of length 2 of mixing proportions,
<code>mu</code> is a length(x) by 2 matrix of component means with length(x) rows, and
<code>var</code> is a vector of length 2 of variances.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>vector of length 2 of estimated mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>length(x) by 2 matrix of estimated mean functions at x, <code class="reqn">m(x)</code>.</p>
</td></tr>
<tr><td><code>mu_u</code></td>
<td>
<p>length(u) by 2 matrix of estimated mean functions at grid point u, <code class="reqn">m(u)</code>.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>vector of length 2 estimated component variances.</p>
</td></tr>
<tr><td><code>lik</code></td>
<td>
<p>final likelihood.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Xiang, S. and Yao, W. (2018). Semiparametric mixtures of nonparametric regressions.
Annals of the Institute of Statistical Mathematics, 70, 131-154.
</p>
<p>Botev, Z. I., Grotowski, J. F., and Kroese, D. P. (2010). Kernel density estimation via diffusion.
The Annals of Statistics, 38(5), 2916-2957.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrGlobal">semimrGlobal</a></code>, <code><a href="#topic+semimrGen">semimrGen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># produce data that matches the description using semimrGen function
# true_mu = (4 - sin(2 * pi * x), 1.5 + cos(3 * pi * x))
n = 100
u = seq(from = 0, to = 1, length = 100)
true_p = c(0.3, 0.7)
true_var = c(0.09, 0.16)
out = semimrGen(n, true_p[1], true_var, u)

x = out$x
y = out$y
true_mu = out$true_mu
true = list(true_p = true_p, true_mu = true_mu, true_var = true_var)

# estimate parameters using semimrLocal function.
est = semimrLocal(x, y)
</code></pre>

<hr>
<h2 id='semimrOne'>Semiparametric Mixture Regression Models with Single-index and One-step Backfitting</h2><span id='topic+semimrOne'></span>

<h3>Description</h3>

<p>Assume that <code class="reqn">\boldsymbol{x} = (\boldsymbol{x}_1,\cdots,\boldsymbol{x}_n)</code> is an n by p matrix and
<code class="reqn">Y = (Y_1,\cdots,Y_n)</code> is an n-dimensional vector of response variable.
The conditional distribution of <code class="reqn">Y</code> given
<code class="reqn">\boldsymbol{x}</code> can be written as:
</p>
<p style="text-align: center;"><code class="reqn">f(y|\boldsymbol{x},\boldsymbol{\alpha},\pi,m,\sigma^2) =
\sum_{j=1}^C\pi_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x})
\phi(y|m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x}),\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x})).</code>
</p>

<p>&lsquo;semimrFull&rsquo; is used to estimate the mixture of single-index models described above,
where <code class="reqn">\phi(y|m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x}),\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x}))</code>
represents the normal density with a mean of <code class="reqn">m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x})</code> and
a variance of <code class="reqn">\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x})</code>, and
<code class="reqn">\pi_j(\cdot), \mu_j(\cdot), \sigma_j^2(\cdot)</code> are unknown smoothing single-index functions
capable of handling high-dimensional non-parametric problem.
This function employs kernel regression and a one-step estimation procedure (Xiang and Yao, 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimrOne(x, y, h, coef = NULL, ini = NULL, grid = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semimrOne_+3A_x">x</code></td>
<td>
<p>an n by p matrix of observations where n is the number of observations and
p is the number of explanatory variables.</p>
</td></tr>
<tr><td><code id="semimrOne_+3A_y">y</code></td>
<td>
<p>a vector of response values.</p>
</td></tr>
<tr><td><code id="semimrOne_+3A_h">h</code></td>
<td>
<p>bandwidth for the kernel regression. Default is NULL, and
the bandwidth is computed in the function by cross-validation.</p>
</td></tr>
<tr><td><code id="semimrOne_+3A_coef">coef</code></td>
<td>
<p>initial value of <code class="reqn">\boldsymbol{\alpha}^{\top}</code> in the model, which plays a role
of regression coefficient in a regression model. Default is NULL, and
the value is computed in the function by sliced inverse regression (Li, 1991).</p>
</td></tr>
<tr><td><code id="semimrOne_+3A_ini">ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values,
assuming a linear mixture model.
If specified, it can be a list with the form of <code>list(pi, mu, var)</code>, where
<code>pi</code> is a vector of mixing proportions,
<code>mu</code> is a vector of component means, and
<code>var</code> is a vector of component variances.</p>
</td></tr>
<tr><td><code id="semimrOne_+3A_grid">grid</code></td>
<td>
<p>grid points at which nonparametric functions are estimated.
Default is NULL, which uses the estimated mixing proportions, component means, and
component variances as the grid points after the algorithm converges.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>pi</code></td>
<td>
<p>estimated mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated component means.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>estimated component variances.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>estimated regression coefficients.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Xiang, S. and Yao, W. (2020). Semiparametric mixtures of regressions with single-index
for model based clustering. Advances in Data Analysis and Classification, 14(2), 261-292.
</p>
<p>Li, K. C. (1991). Sliced inverse regression for dimension reduction.
Journal of the American Statistical Association, 86(414), 316-327.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrFull">semimrFull</a></code>, <code><a href="#topic+sinvreg">sinvreg</a></code> for initial value calculation of
<code class="reqn">\boldsymbol{\alpha}^{\top}</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx = NBA[, c(1, 2, 4)]
yy = NBA[, 3]
x = xx/t(matrix(rep(sqrt(diag(var(xx))), length(yy)), nrow = 3))
y = yy/sd(yy)
ini_bs = sinvreg(x, y)
ini_b = ini_bs$direction[, 1]

# used a smaller sample for a quicker demonstration of the function
set.seed(123)
est_onestep = semimrOne(x[1:50, ], y[1:50], h = 0.3442, coef = ini_b)
</code></pre>

<hr>
<h2 id='sinvreg'>Dimension Reduction Based on Sliced Inverse Regression</h2><span id='topic+sinvreg'></span>

<h3>Description</h3>

<p>&lsquo;sinvreg&rsquo; is used in the examples for the <code><a href="#topic+semimrFull">semimrFull</a></code> and <code><a href="#topic+semimrOne">semimrOne</a></code> functions to obtain
initial values based on sliced inverse regression (Li, 1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sinvreg(x, y, nslice = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sinvreg_+3A_x">x</code></td>
<td>
<p>an n by p matrix of observations where n is the number of observations and
p is the number of explanatory variables.</p>
</td></tr>
<tr><td><code id="sinvreg_+3A_y">y</code></td>
<td>
<p>an n-dimentionsl vector of response values.</p>
</td></tr>
<tr><td><code id="sinvreg_+3A_nslice">nslice</code></td>
<td>
<p>number of slices. Default is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>direction</code></td>
<td>
<p>direction vector.</p>
</td></tr>
<tr><td><code>reducedx</code></td>
<td>
<p>reduced x.</p>
</td></tr>
<tr><td><code>eigenvalue</code></td>
<td>
<p>eigenvalues for reduced x.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>number of observations within each slice.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Li, K. C. (1991). Sliced inverse regression for dimension reduction.
Journal of the American Statistical Association, 86(414), 316-327.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semimrFull">semimrFull</a></code>, <code><a href="#topic+semimrOne">semimrOne</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for the 'semimrFull' function.
</code></pre>

<hr>
<h2 id='tone'>Tone perception data</h2><span id='topic+tone'></span>

<h3>Description</h3>

<p>The data originates from an experiment of Cohen (1980) and has been analyzed in de Veaux (1989) and
Viele and Tong (2002). In this experiment, a pure fundamental tone was played to a trained musician.
To create different auditory conditions, electronically generated overtones were introduced, which were
determined by a stretching ratio. When <code>stretchratio = 2.0</code>, it aligns with the harmonic pattern
usually heard in traditional definite pitched instruments. The musician was asked to tune an adjustable
tone to the octave above the fundamental tone. The variable <code>tuned</code> gives the ratio of the adjusted
tone to the fundamental tone. For example, <code>tuned = 2.0</code>,  would be the correct tuning for all
<code>stretchratio</code> values. This dataset comprises data collected from 150 trials conducted with
the same musician. In the original study, data were gathered from an additional four musicians as well.
The dataset and the description have been sourced from the <code>tonedata</code> of the &lsquo;fpc&rsquo; package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tone
</code></pre>


<h3>Format</h3>

<p>A data frame containing 150 observations and the following 2 variables.
</p>

<dl>
<dt>stretchratio:</dt><dd><p> electronically generated overtones added to a pure fundamental tone.</p>
</dd>
<dt>tuned:</dt><dd><p> ratio of the adjusted tone to the fundamental tone.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Original source:
</p>
<p>Cohen, E. (1980). Inharmonic tone perception. Unpublished Ph. D. Dissertation, Stanford University.
</p>
<p>R source:
</p>
<p>Hennig C (2023). fpc: Flexible Procedures for Clustering. R package version 2.2-10,
<a href="https://CRAN.R-project.org/package=fpc">https://CRAN.R-project.org/package=fpc</a>
</p>
<p>Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D. S. (2010).
mixtools: an R package for analyzing mixture models. Journal of statistical software, 32, 1-29.
</p>


<h3>References</h3>

<p>De Veaux, R. D. (1989). Mixtures of linear regressions. Computational Statistics &amp; Data Analysis,
8(3), 227-245.
</p>
<p>Viele, K. and Tong, B. (2002). Modeling with mixtures of linear regressions. Statistics and Computing, 12, 315-330.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
