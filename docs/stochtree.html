<!DOCTYPE html><html lang="en"><head><title>Help for package stochtree</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {stochtree}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#stochtree-package'><p>stochtree: Stochastic Tree Ensembles (XBART and BART) for Supervised Learning and Causal Inference</p></a></li>
<li><a href='#bart'><p>Run the BART algorithm for supervised learning.</p></a></li>
<li><a href='#bcf'><p>Run the Bayesian Causal Forest (BCF) algorithm for regularized causal effect estimation.</p></a></li>
<li><a href='#calibrateInverseGammaErrorVariance'><p>Calibrate the scale parameter on an inverse gamma prior for the global error variance as in Chipman et al (2022)</p></a></li>
<li><a href='#computeForestLeafIndices'><p>Compute vector of forest leaf indices</p></a></li>
<li><a href='#computeForestLeafVariances'><p>Compute vector of forest leaf scale parameters</p></a></li>
<li><a href='#computeForestMaxLeafIndex'><p>Compute and return the largest possible leaf index computable by <code>computeForestLeafIndices</code> for the forests in a designated forest sample container.</p></a></li>
<li><a href='#convertPreprocessorToJson'><p>Convert the persistent aspects of a covariate preprocessor to (in-memory) C++ JSON object</p></a></li>
<li><a href='#CppJson'><p>Class that stores draws from an random ensemble of decision trees</p></a></li>
<li><a href='#CppRNG'><p>Class that wraps a C++ random number generator (for reproducibility)</p></a></li>
<li><a href='#createBARTModelFromCombinedJson'><p>Convert a list of (in-memory) JSON representations of a BART model to a single combined BART model object</p>
which can be used for prediction, etc...</a></li>
<li><a href='#createBARTModelFromCombinedJsonString'><p>Convert a list of (in-memory) JSON strings that represent BART models to a single combined BART model object</p>
which can be used for prediction, etc...</a></li>
<li><a href='#createBARTModelFromJson'><p>Convert an (in-memory) JSON representation of a BART model to a BART model object</p>
which can be used for prediction, etc...</a></li>
<li><a href='#createBARTModelFromJsonFile'><p>Convert a JSON file containing sample information on a trained BART model</p>
to a BART model object which can be used for prediction, etc...</a></li>
<li><a href='#createBARTModelFromJsonString'><p>Convert a JSON string containing sample information on a trained BART model</p>
to a BART model object which can be used for prediction, etc...</a></li>
<li><a href='#createBCFModelFromCombinedJson'><p>Convert a list of (in-memory) JSON strings that represent BCF models to a single combined BCF model object</p>
which can be used for prediction, etc...</a></li>
<li><a href='#createBCFModelFromCombinedJsonString'><p>Convert a list of (in-memory) JSON strings that represent BCF models to a single combined BCF model object</p>
which can be used for prediction, etc...</a></li>
<li><a href='#createBCFModelFromJson'><p>Convert an (in-memory) JSON representation of a BCF model to a BCF model object</p>
which can be used for prediction, etc...</a></li>
<li><a href='#createBCFModelFromJsonFile'><p>Convert a JSON file containing sample information on a trained BCF model</p>
to a BCF model object which can be used for prediction, etc...</a></li>
<li><a href='#createBCFModelFromJsonString'><p>Convert a JSON string containing sample information on a trained BCF model</p>
to a BCF model object which can be used for prediction, etc...</a></li>
<li><a href='#createCppJson'><p>Create a new (empty) C++ Json object</p></a></li>
<li><a href='#createCppJsonFile'><p>Create a C++ Json object from a Json file</p></a></li>
<li><a href='#createCppJsonString'><p>Create a C++ Json object from a Json string</p></a></li>
<li><a href='#createCppRNG'><p>Create an R class that wraps a C++ random number generator</p></a></li>
<li><a href='#createForest'><p>Create a forest</p></a></li>
<li><a href='#createForestDataset'><p>Create a forest dataset object</p></a></li>
<li><a href='#createForestModel'><p>Create a forest model object</p></a></li>
<li><a href='#createForestModelConfig'><p>Create a forest model config object</p></a></li>
<li><a href='#createForestSamples'><p>Create a container of forest samples</p></a></li>
<li><a href='#createGlobalModelConfig'><p>Create a global model config object</p></a></li>
<li><a href='#createOutcome'><p>Create an outcome object</p></a></li>
<li><a href='#createPreprocessorFromJson'><p>Reload a covariate preprocessor object from a JSON string containing a serialized preprocessor</p></a></li>
<li><a href='#createPreprocessorFromJsonString'><p>Reload a covariate preprocessor object from a JSON string containing a serialized preprocessor</p></a></li>
<li><a href='#createRandomEffectSamples'><p>Create a <code>RandomEffectSamples</code> object</p></a></li>
<li><a href='#createRandomEffectsDataset'><p>Create a random effects dataset object</p></a></li>
<li><a href='#createRandomEffectsModel'><p>Create a <code>RandomEffectsModel</code> object</p></a></li>
<li><a href='#createRandomEffectsTracker'><p>Create a <code>RandomEffectsTracker</code> object</p></a></li>
<li><a href='#Forest'><p>Class that stores a single ensemble of decision trees (often treated as the &quot;active forest&quot;)</p></a></li>
<li><a href='#ForestDataset'><p>Dataset used to sample a forest</p></a></li>
<li><a href='#ForestModel'><p>Class that defines and samples a forest model</p></a></li>
<li><a href='#ForestModelConfig'><p>Object used to get / set parameters and other model configuration options</p>
for a forest model in the &quot;low-level&quot; stochtree interface</a></li>
<li><a href='#ForestSamples'><p>Class that stores draws from an random ensemble of decision trees</p></a></li>
<li><a href='#getRandomEffectSamples'><p>Generic function for extracting random effect samples from a model object (BCF, BART, etc...)</p></a></li>
<li><a href='#getRandomEffectSamples.bartmodel'><p>Extract raw sample values for each of the random effect parameter terms.</p></a></li>
<li><a href='#getRandomEffectSamples.bcfmodel'><p>Extract raw sample values for each of the random effect parameter terms.</p></a></li>
<li><a href='#GlobalModelConfig'><p>Object used to get / set global parameters and other global model</p>
configuration options in the &quot;low-level&quot; stochtree interface</a></li>
<li><a href='#loadForestContainerCombinedJson'><p>Combine multiple JSON model objects containing forests (with the same hierarchy / schema) into a single forest_container</p></a></li>
<li><a href='#loadForestContainerCombinedJsonString'><p>Combine multiple JSON strings representing model objects containing forests (with the same hierarchy / schema) into a single forest_container</p></a></li>
<li><a href='#loadForestContainerJson'><p>Load a container of forest samples from json</p></a></li>
<li><a href='#loadRandomEffectSamplesCombinedJson'><p>Combine multiple JSON model objects containing random effects (with the same hierarchy / schema) into a single container</p></a></li>
<li><a href='#loadRandomEffectSamplesCombinedJsonString'><p>Combine multiple JSON strings representing model objects containing random effects (with the same hierarchy / schema) into a single container</p></a></li>
<li><a href='#loadRandomEffectSamplesJson'><p>Load a container of random effect samples from json</p></a></li>
<li><a href='#loadScalarJson'><p>Load a scalar from json</p></a></li>
<li><a href='#loadVectorJson'><p>Load a vector from json</p></a></li>
<li><a href='#Outcome'><p>Outcome / partial residual used to sample an additive model.</p></a></li>
<li><a href='#predict.bartmodel'><p>Predict from a sampled BART model on new data</p></a></li>
<li><a href='#predict.bcfmodel'><p>Predict from a sampled BCF model on new data</p></a></li>
<li><a href='#preprocessPredictionData'><p>Preprocess covariates. DataFrames will be preprocessed based on their column</p>
types. Matrices will be passed through assuming all columns are numeric.</a></li>
<li><a href='#preprocessTrainData'><p>Preprocess covariates. DataFrames will be preprocessed based on their column</p>
types. Matrices will be passed through assuming all columns are numeric.</a></li>
<li><a href='#RandomEffectSamples'><p>Class that wraps the &quot;persistent&quot; aspects of a C++ random effects model</p>
(draws of the parameters and a map from the original label indices to the
0-indexed label numbers used to place group samples in memory (i.e. the
first label is stored in column 0 of the sample matrix, the second label
is store in column 1 of the sample matrix, etc...))</a></li>
<li><a href='#RandomEffectsDataset'><p>Dataset used to sample a random effects model</p></a></li>
<li><a href='#RandomEffectsModel'><p>The core &quot;model&quot; class for sampling random effects.</p></a></li>
<li><a href='#RandomEffectsTracker'><p>Class that defines a &quot;tracker&quot; for random effects models, most notably</p>
storing the data indices available in each group for quicker posterior
computation and sampling of random effects terms.</a></li>
<li><a href='#resetActiveForest'><p>Reset an active forest, either from a specific forest in a <code>ForestContainer</code></p>
or to an ensemble of single-node (i.e. root) trees</a></li>
<li><a href='#resetForestModel'><p>Re-initialize a forest model (tracking data structures) from a specific forest in a <code>ForestContainer</code></p></a></li>
<li><a href='#resetRandomEffectsModel'><p>Reset a <code>RandomEffectsModel</code> object based on the parameters indexed by <code>sample_num</code> in a <code>RandomEffectsSamples</code> object</p></a></li>
<li><a href='#resetRandomEffectsTracker'><p>Reset a <code>RandomEffectsTracker</code> object based on the parameters indexed by <code>sample_num</code> in a <code>RandomEffectsSamples</code> object</p></a></li>
<li><a href='#rootResetRandomEffectsModel'><p>Reset a <code>RandomEffectsModel</code> object to its &quot;default&quot; state</p></a></li>
<li><a href='#rootResetRandomEffectsTracker'><p>Reset a <code>RandomEffectsTracker</code> object to its &quot;default&quot; state</p></a></li>
<li><a href='#sampleGlobalErrorVarianceOneIteration'><p>Sample one iteration of the (inverse gamma) global variance model</p></a></li>
<li><a href='#sampleLeafVarianceOneIteration'><p>Sample one iteration of the leaf parameter variance model (only for univariate basis and constant leaf!)</p></a></li>
<li><a href='#saveBARTModelToJson'><p>Convert the persistent aspects of a BART model to (in-memory) JSON</p></a></li>
<li><a href='#saveBARTModelToJsonFile'><p>Convert the persistent aspects of a BART model to (in-memory) JSON and save to a file</p></a></li>
<li><a href='#saveBARTModelToJsonString'><p>Convert the persistent aspects of a BART model to (in-memory) JSON string</p></a></li>
<li><a href='#saveBCFModelToJson'><p>Convert the persistent aspects of a BCF model to (in-memory) JSON</p></a></li>
<li><a href='#saveBCFModelToJsonFile'><p>Convert the persistent aspects of a BCF model to (in-memory) JSON and save to a file</p></a></li>
<li><a href='#saveBCFModelToJsonString'><p>Convert the persistent aspects of a BCF model to (in-memory) JSON string</p></a></li>
<li><a href='#savePreprocessorToJsonString'><p>Convert the persistent aspects of a covariate preprocessor to (in-memory) JSON string</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Stochastic Tree Ensembles (XBART and BART) for Supervised
Learning and Causal Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Copyright:</td>
<td>Copyright details for stochtree's C++ dependencies, which
are vendored along with the core stochtree source code, are
detailed in inst/COPYRIGHTS</td>
</tr>
<tr>
<td>Description:</td>
<td>Flexible stochastic tree ensemble software. 
    Robust implementations of Bayesian Additive Regression Trees (BART) 
    Chipman, George, McCulloch (2010) &lt;<a href="https://doi.org/10.1214%2F09-AOAS285">doi:10.1214/09-AOAS285</a>&gt; 
    for supervised learning and Bayesian Causal Forests (BCF) 
    Hahn, Murray, Carvalho (2020) &lt;<a href="https://doi.org/10.1214%2F19-BA1195">doi:10.1214/19-BA1195</a>&gt; 
    for causal inference. Enables model serialization and parallel sampling 
    and provides a low-level interface for custom stochastic forest samplers.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>cpp11, BH</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0),</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>Imports:</td>
<td>R6, stats</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://stochtree.ai/">https://stochtree.ai/</a>, <a href="https://github.com/StochasticTree/stochtree">https://github.com/StochasticTree/stochtree</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/StochasticTree/stochtree/issues">https://github.com/StochasticTree/stochtree/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-08 07:14:14 UTC; drew</td>
</tr>
<tr>
<td>Author:</td>
<td>Drew Herren <a href="https://orcid.org/0000-0003-4109-6611"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Richard Hahn [aut],
  Jared Murray [aut],
  Carlos Carvalho [aut],
  Jingyu He [aut],
  Pedro Lima [ctb],
  stochtree contributors [cph],
  Eigen contributors [cph] (C++ source uses the Eigen library for matrix
    operations, see inst/COPYRIGHTS),
  xgboost contributors [cph] (C++ tree code and related operations
    include or are inspired by code from the xgboost library, see
    inst/COPYRIGHTS),
  treelite contributors [cph] (C++ tree code and related operations
    include or are inspired by code from the treelite library, see
    inst/COPYRIGHTS),
  Microsoft Corporation [cph] (C++ I/O and various project structure code
    include or are inspired by code from the LightGBM library, which is
    a copyright of Microsoft, see inst/COPYRIGHTS),
  Niels Lohmann [cph] (C++ source uses the JSON for Modern C++ library
    for JSON operations, see inst/COPYRIGHTS),
  Daniel Lemire [cph] (C++ source uses the fast_double_parser library
    internally, see inst/COPYRIGHTS),
  Victor Zverovich [cph] (C++ source uses the fmt library internally, see
    inst/COPYRIGHTS)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Drew Herren &lt;drewherrenopensource@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-08 16:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='stochtree-package'>stochtree: Stochastic Tree Ensembles (XBART and BART) for Supervised Learning and Causal Inference</h2><span id='topic+stochtree'></span><span id='topic+stochtree-package'></span>

<h3>Description</h3>

<p>Flexible stochastic tree ensemble software. Robust implementations of Bayesian Additive Regression Trees (BART) Chipman, George, McCulloch (2010) <a href="https://doi.org/10.1214/09-AOAS285">doi:10.1214/09-AOAS285</a> for supervised learning and Bayesian Causal Forests (BCF) Hahn, Murray, Carvalho (2020) <a href="https://doi.org/10.1214/19-BA1195">doi:10.1214/19-BA1195</a> for causal inference. Enables model serialization and parallel sampling and provides a low-level interface for custom stochastic forest samplers.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Drew Herren <a href="mailto:drewherrenopensource@gmail.com">drewherrenopensource@gmail.com</a> (<a href="https://orcid.org/0000-0003-4109-6611">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Richard Hahn
</p>
</li>
<li><p> Jared Murray
</p>
</li>
<li><p> Carlos Carvalho
</p>
</li>
<li><p> Jingyu He
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Pedro Lima [contributor]
</p>
</li>
<li><p> stochtree contributors [copyright holder]
</p>
</li>
<li><p> Eigen contributors (C++ source uses the Eigen library for matrix operations, see inst/COPYRIGHTS) [copyright holder]
</p>
</li>
<li><p> xgboost contributors (C++ tree code and related operations include or are inspired by code from the xgboost library, see inst/COPYRIGHTS) [copyright holder]
</p>
</li>
<li><p> treelite contributors (C++ tree code and related operations include or are inspired by code from the treelite library, see inst/COPYRIGHTS) [copyright holder]
</p>
</li>
<li><p> Microsoft Corporation (C++ I/O and various project structure code include or are inspired by code from the LightGBM library, which is a copyright of Microsoft, see inst/COPYRIGHTS) [copyright holder]
</p>
</li>
<li><p> Niels Lohmann (C++ source uses the JSON for Modern C++ library for JSON operations, see inst/COPYRIGHTS) [copyright holder]
</p>
</li>
<li><p> Daniel Lemire (C++ source uses the fast_double_parser library internally, see inst/COPYRIGHTS) [copyright holder]
</p>
</li>
<li><p> Victor Zverovich (C++ source uses the fmt library internally, see inst/COPYRIGHTS) [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://stochtree.ai/">https://stochtree.ai/</a>
</p>
</li>
<li> <p><a href="https://github.com/StochasticTree/stochtree">https://github.com/StochasticTree/stochtree</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/StochasticTree/stochtree/issues">https://github.com/StochasticTree/stochtree/issues</a>
</p>
</li></ul>


<hr>
<h2 id='bart'>Run the BART algorithm for supervised learning.</h2><span id='topic+bart'></span>

<h3>Description</h3>

<p>Run the BART algorithm for supervised learning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bart(
  X_train,
  y_train,
  leaf_basis_train = NULL,
  rfx_group_ids_train = NULL,
  rfx_basis_train = NULL,
  X_test = NULL,
  leaf_basis_test = NULL,
  rfx_group_ids_test = NULL,
  rfx_basis_test = NULL,
  num_gfr = 5,
  num_burnin = 0,
  num_mcmc = 100,
  previous_model_json = NULL,
  previous_model_warmstart_sample_num = NULL,
  general_params = list(),
  mean_forest_params = list(),
  variance_forest_params = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bart_+3A_x_train">X_train</code></td>
<td>
<p>Covariates used to split trees in the ensemble. May be provided either as a dataframe or a matrix.
Matrix covariates will be assumed to be all numeric. Covariates passed as a dataframe will be
preprocessed based on the variable types (e.g. categorical columns stored as unordered factors will be one-hot encoded,
categorical columns stored as ordered factors will passed as integers to the core algorithm, along with the metadata
that the column is ordered categorical).</p>
</td></tr>
<tr><td><code id="bart_+3A_y_train">y_train</code></td>
<td>
<p>Outcome to be modeled by the ensemble.</p>
</td></tr>
<tr><td><code id="bart_+3A_leaf_basis_train">leaf_basis_train</code></td>
<td>
<p>(Optional) Bases used to define a regression model <code>y ~ W</code> in
each leaf of each regression tree. By default, BART assumes constant leaf node
parameters, implicitly regressing on a constant basis of ones (i.e. <code>y ~ 1</code>).</p>
</td></tr>
<tr><td><code id="bart_+3A_rfx_group_ids_train">rfx_group_ids_train</code></td>
<td>
<p>(Optional) Group labels used for an additive random effects model.</p>
</td></tr>
<tr><td><code id="bart_+3A_rfx_basis_train">rfx_basis_train</code></td>
<td>
<p>(Optional) Basis for &quot;random-slope&quot; regression in an additive random effects model.
If <code>rfx_group_ids_train</code> is provided with a regression basis, an intercept-only random effects model
will be estimated.</p>
</td></tr>
<tr><td><code id="bart_+3A_x_test">X_test</code></td>
<td>
<p>(Optional) Test set of covariates used to define &quot;out of sample&quot; evaluation data.
May be provided either as a dataframe or a matrix, but the format of <code>X_test</code> must be consistent with
that of <code>X_train</code>.</p>
</td></tr>
<tr><td><code id="bart_+3A_leaf_basis_test">leaf_basis_test</code></td>
<td>
<p>(Optional) Test set of bases used to define &quot;out of sample&quot; evaluation data.
While a test set is optional, the structure of any provided test set must match that
of the training set (i.e. if both <code>X_train</code> and <code>leaf_basis_train</code> are provided, then a test set must
consist of <code>X_test</code> and <code>leaf_basis_test</code> with the same number of columns).</p>
</td></tr>
<tr><td><code id="bart_+3A_rfx_group_ids_test">rfx_group_ids_test</code></td>
<td>
<p>(Optional) Test set group labels used for an additive random effects model.
We do not currently support (but plan to in the near future), test set evaluation for group labels
that were not in the training set.</p>
</td></tr>
<tr><td><code id="bart_+3A_rfx_basis_test">rfx_basis_test</code></td>
<td>
<p>(Optional) Test set basis for &quot;random-slope&quot; regression in additive random effects model.</p>
</td></tr>
<tr><td><code id="bart_+3A_num_gfr">num_gfr</code></td>
<td>
<p>Number of &quot;warm-start&quot; iterations run using the grow-from-root algorithm (He and Hahn, 2021). Default: 5.</p>
</td></tr>
<tr><td><code id="bart_+3A_num_burnin">num_burnin</code></td>
<td>
<p>Number of &quot;burn-in&quot; iterations of the MCMC sampler. Default: 0.</p>
</td></tr>
<tr><td><code id="bart_+3A_num_mcmc">num_mcmc</code></td>
<td>
<p>Number of &quot;retained&quot; iterations of the MCMC sampler. Default: 100.</p>
</td></tr>
<tr><td><code id="bart_+3A_previous_model_json">previous_model_json</code></td>
<td>
<p>(Optional) JSON string containing a previous BART model. This can be used to &quot;continue&quot; a sampler interactively after inspecting the samples or to run parallel chains &quot;warm-started&quot; from existing forest samples. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="bart_+3A_previous_model_warmstart_sample_num">previous_model_warmstart_sample_num</code></td>
<td>
<p>(Optional) Sample number from <code>previous_model_json</code> that will be used to warmstart this BART sampler. One-indexed (so that the first sample is used for warm-start by setting <code>previous_model_warmstart_sample_num = 1</code>). Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="bart_+3A_general_params">general_params</code></td>
<td>
<p>(Optional) A list of general (non-forest-specific) model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>cutpoint_grid_size</code> Maximum size of the &quot;grid&quot; of potential cutpoints to consider in the GFR algorithm. Default: <code>100</code>.
</p>
</li>
<li> <p><code>standardize</code> Whether or not to standardize the outcome (and store the offset / scale in the model object). Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>sample_sigma2_global</code> Whether or not to update the <code>sigma^2</code> global error variance parameter based on <code>IG(sigma2_global_shape, sigma2_global_scale)</code>. Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>sigma2_global_init</code> Starting value of global error variance parameter. Calibrated internally as <code>1.0*var(y_train)</code>, where <code>y_train</code> is the possibly standardized outcome, if not set.
</p>
</li>
<li> <p><code>sigma2_global_shape</code> Shape parameter in the <code>IG(sigma2_global_shape, sigma2_global_scale)</code> global error variance model. Default: <code>0</code>.
</p>
</li>
<li> <p><code>sigma2_global_scale</code> Scale parameter in the <code>IG(sigma2_global_shape, sigma2_global_scale)</code> global error variance model. Default: <code>0</code>.
</p>
</li>
<li> <p><code>variable_weights</code> Numeric weights reflecting the relative probability of splitting on each variable. Does not need to sum to 1 but cannot be negative. Defaults to <code>rep(1/ncol(X_train), ncol(X_train))</code> if not set here. Note that if the propensity score is included as a covariate in either forest, its weight will default to <code>1/ncol(X_train)</code>.
</p>
</li>
<li> <p><code>random_seed</code> Integer parameterizing the C++ random number generator. If not specified, the C++ random number generator is seeded according to <code>std::random_device</code>.
</p>
</li>
<li> <p><code>keep_burnin</code> Whether or not &quot;burnin&quot; samples should be included in the stored samples of forests and other parameters. Default <code>FALSE</code>. Ignored if <code>num_mcmc = 0</code>.
</p>
</li>
<li> <p><code>keep_gfr</code> Whether or not &quot;grow-from-root&quot; samples should be included in the stored samples of forests and other parameters. Default <code>FALSE</code>. Ignored if <code>num_mcmc = 0</code>.
</p>
</li>
<li> <p><code>keep_every</code> How many iterations of the burned-in MCMC sampler should be run before forests and parameters are retained. Default <code>1</code>. Setting <code>keep_every &lt;- k</code> for some <code>k &gt; 1</code> will &quot;thin&quot; the MCMC samples by retaining every <code>k</code>-th sample, rather than simply every sample. This can reduce the autocorrelation of the MCMC samples.
</p>
</li>
<li> <p><code>num_chains</code> How many independent MCMC chains should be sampled. If <code>num_mcmc = 0</code>, this is ignored. If <code>num_gfr = 0</code>, then each chain is run from root for <code>num_mcmc * keep_every + num_burnin</code> iterations, with <code>num_mcmc</code> samples retained. If <code>num_gfr &gt; 0</code>, each MCMC chain will be initialized from a separate GFR ensemble, with the requirement that <code>num_gfr &gt;= num_chains</code>. Default: <code>1</code>.
</p>
</li>
<li> <p><code>verbose</code> Whether or not to print progress during the sampling loops. Default: <code>FALSE</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bart_+3A_mean_forest_params">mean_forest_params</code></td>
<td>
<p>(Optional) A list of mean forest model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>num_trees</code> Number of trees in the ensemble for the conditional mean model. Default: <code>200</code>. If <code>num_trees = 0</code>, the conditional mean will not be modeled using a forest, and the function will only proceed if <code>num_trees &gt; 0</code> for the variance forest.
</p>
</li>
<li> <p><code>alpha</code> Prior probability of splitting for a tree of depth 0 in the mean model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>0.95</code>.
</p>
</li>
<li> <p><code>beta</code> Exponent that decreases split probabilities for nodes of depth &gt; 0 in the mean model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>2</code>.
</p>
</li>
<li> <p><code>min_samples_leaf</code> Minimum allowable size of a leaf, in terms of training samples, in the mean model. Default: <code>5</code>.
</p>
</li>
<li> <p><code>max_depth</code> Maximum depth of any tree in the ensemble in the mean model. Default: <code>10</code>. Can be overridden with <code>-1</code> which does not enforce any depth limits on trees.
</p>
</li>
<li> <p><code>sample_sigma2_leaf</code> Whether or not to update the leaf scale variance parameter based on <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code>. Cannot (currently) be set to true if <code>ncol(leaf_basis_train)&gt;1</code>. Default: <code>FALSE</code>.
</p>
</li>
<li> <p><code>sigma2_leaf_init</code> Starting value of leaf node scale parameter. Calibrated internally as <code>1/num_trees</code> if not set here.
</p>
</li>
<li> <p><code>sigma2_leaf_shape</code> Shape parameter in the <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code> leaf node parameter variance model. Default: <code>3</code>.
</p>
</li>
<li> <p><code>sigma2_leaf_scale</code> Scale parameter in the <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code> leaf node parameter variance model. Calibrated internally as <code>0.5/num_trees</code> if not set here.
</p>
</li>
<li> <p><code>keep_vars</code> Vector of variable names or column indices denoting variables that should be included in the forest. Default: <code>NULL</code>.
</p>
</li>
<li> <p><code>drop_vars</code> Vector of variable names or column indices denoting variables that should be excluded from the forest. Default: <code>NULL</code>. If both <code>drop_vars</code> and <code>keep_vars</code> are set, <code>drop_vars</code> will be ignored.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bart_+3A_variance_forest_params">variance_forest_params</code></td>
<td>
<p>(Optional) A list of variance forest model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>num_trees</code> Number of trees in the ensemble for the conditional variance model. Default: <code>0</code>. Variance is only modeled using a tree / forest if <code>num_trees &gt; 0</code>.
</p>
</li>
<li> <p><code>alpha</code> Prior probability of splitting for a tree of depth 0 in the variance model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>0.95</code>.
</p>
</li>
<li> <p><code>beta</code> Exponent that decreases split probabilities for nodes of depth &gt; 0 in the variance model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>2</code>.
</p>
</li>
<li> <p><code>min_samples_leaf</code> Minimum allowable size of a leaf, in terms of training samples, in the variance model. Default: <code>5</code>.
</p>
</li>
<li> <p><code>max_depth</code> Maximum depth of any tree in the ensemble in the variance model. Default: <code>10</code>. Can be overridden with <code>-1</code> which does not enforce any depth limits on trees.
</p>
</li>
<li> <p><code>leaf_prior_calibration_param</code> Hyperparameter used to calibrate the <code>IG(var_forest_prior_shape, var_forest_prior_scale)</code> conditional error variance model. If <code>var_forest_prior_shape</code> and <code>var_forest_prior_scale</code> are not set below, this calibration parameter is used to set these values to <code>num_trees / leaf_prior_calibration_param^2 + 0.5</code> and <code>num_trees / leaf_prior_calibration_param^2</code>, respectively. Default: <code>1.5</code>.
</p>
</li>
<li> <p><code>var_forest_leaf_init</code> Starting value of root forest prediction in conditional (heteroskedastic) error variance model. Calibrated internally as <code>log(0.6*var(y_train))/num_trees</code>, where <code>y_train</code> is the possibly standardized outcome, if not set.
</p>
</li>
<li> <p><code>var_forest_prior_shape</code> Shape parameter in the <code>IG(var_forest_prior_shape, var_forest_prior_scale)</code> conditional error variance model (which is only sampled if <code>num_trees &gt; 0</code>). Calibrated internally as <code>num_trees / leaf_prior_calibration_param^2 + 0.5</code> if not set.
</p>
</li>
<li> <p><code>var_forest_prior_scale</code> Scale parameter in the <code>IG(var_forest_prior_shape, var_forest_prior_scale)</code> conditional error variance model (which is only sampled if <code>num_trees &gt; 0</code>). Calibrated internally as <code>num_trees / leaf_prior_calibration_param^2</code> if not set.
</p>
</li>
<li> <p><code>keep_vars</code> Vector of variable names or column indices denoting variables that should be included in the forest. Default: <code>NULL</code>.
</p>
</li>
<li> <p><code>drop_vars</code> Vector of variable names or column indices denoting variables that should be excluded from the forest. Default: <code>NULL</code>. If both <code>drop_vars</code> and <code>keep_vars</code> are set, <code>drop_vars</code> will be ignored.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>List of sampling outputs and a wrapper around the sampled forests (which can be used for in-memory prediction on new data, or serialized to JSON on disk).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, X_test = X_test, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
</code></pre>

<hr>
<h2 id='bcf'>Run the Bayesian Causal Forest (BCF) algorithm for regularized causal effect estimation.</h2><span id='topic+bcf'></span>

<h3>Description</h3>

<p>Run the Bayesian Causal Forest (BCF) algorithm for regularized causal effect estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcf(
  X_train,
  Z_train,
  y_train,
  propensity_train = NULL,
  rfx_group_ids_train = NULL,
  rfx_basis_train = NULL,
  X_test = NULL,
  Z_test = NULL,
  propensity_test = NULL,
  rfx_group_ids_test = NULL,
  rfx_basis_test = NULL,
  num_gfr = 5,
  num_burnin = 0,
  num_mcmc = 100,
  previous_model_json = NULL,
  previous_model_warmstart_sample_num = NULL,
  general_params = list(),
  prognostic_forest_params = list(),
  treatment_effect_forest_params = list(),
  variance_forest_params = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bcf_+3A_x_train">X_train</code></td>
<td>
<p>Covariates used to split trees in the ensemble. May be provided either as a dataframe or a matrix.
Matrix covariates will be assumed to be all numeric. Covariates passed as a dataframe will be
preprocessed based on the variable types (e.g. categorical columns stored as unordered factors will be one-hot encoded,
categorical columns stored as ordered factors will passed as integers to the core algorithm, along with the metadata
that the column is ordered categorical).</p>
</td></tr>
<tr><td><code id="bcf_+3A_z_train">Z_train</code></td>
<td>
<p>Vector of (continuous or binary) treatment assignments.</p>
</td></tr>
<tr><td><code id="bcf_+3A_y_train">y_train</code></td>
<td>
<p>Outcome to be modeled by the ensemble.</p>
</td></tr>
<tr><td><code id="bcf_+3A_propensity_train">propensity_train</code></td>
<td>
<p>(Optional) Vector of propensity scores. If not provided, this will be estimated from the data.</p>
</td></tr>
<tr><td><code id="bcf_+3A_rfx_group_ids_train">rfx_group_ids_train</code></td>
<td>
<p>(Optional) Group labels used for an additive random effects model.</p>
</td></tr>
<tr><td><code id="bcf_+3A_rfx_basis_train">rfx_basis_train</code></td>
<td>
<p>(Optional) Basis for &quot;random-slope&quot; regression in an additive random effects model.
If <code>rfx_group_ids_train</code> is provided with a regression basis, an intercept-only random effects model
will be estimated.</p>
</td></tr>
<tr><td><code id="bcf_+3A_x_test">X_test</code></td>
<td>
<p>(Optional) Test set of covariates used to define &quot;out of sample&quot; evaluation data.
May be provided either as a dataframe or a matrix, but the format of <code>X_test</code> must be consistent with
that of <code>X_train</code>.</p>
</td></tr>
<tr><td><code id="bcf_+3A_z_test">Z_test</code></td>
<td>
<p>(Optional) Test set of (continuous or binary) treatment assignments.</p>
</td></tr>
<tr><td><code id="bcf_+3A_propensity_test">propensity_test</code></td>
<td>
<p>(Optional) Vector of propensity scores. If not provided, this will be estimated from the data.</p>
</td></tr>
<tr><td><code id="bcf_+3A_rfx_group_ids_test">rfx_group_ids_test</code></td>
<td>
<p>(Optional) Test set group labels used for an additive random effects model.
We do not currently support (but plan to in the near future), test set evaluation for group labels
that were not in the training set.</p>
</td></tr>
<tr><td><code id="bcf_+3A_rfx_basis_test">rfx_basis_test</code></td>
<td>
<p>(Optional) Test set basis for &quot;random-slope&quot; regression in additive random effects model.</p>
</td></tr>
<tr><td><code id="bcf_+3A_num_gfr">num_gfr</code></td>
<td>
<p>Number of &quot;warm-start&quot; iterations run using the grow-from-root algorithm (He and Hahn, 2021). Default: 5.</p>
</td></tr>
<tr><td><code id="bcf_+3A_num_burnin">num_burnin</code></td>
<td>
<p>Number of &quot;burn-in&quot; iterations of the MCMC sampler. Default: 0.</p>
</td></tr>
<tr><td><code id="bcf_+3A_num_mcmc">num_mcmc</code></td>
<td>
<p>Number of &quot;retained&quot; iterations of the MCMC sampler. Default: 100.</p>
</td></tr>
<tr><td><code id="bcf_+3A_previous_model_json">previous_model_json</code></td>
<td>
<p>(Optional) JSON string containing a previous BCF model. This can be used to &quot;continue&quot; a sampler interactively after inspecting the samples or to run parallel chains &quot;warm-started&quot; from existing forest samples. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="bcf_+3A_previous_model_warmstart_sample_num">previous_model_warmstart_sample_num</code></td>
<td>
<p>(Optional) Sample number from <code>previous_model_json</code> that will be used to warmstart this BCF sampler. One-indexed (so that the first sample is used for warm-start by setting <code>previous_model_warmstart_sample_num = 1</code>). Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="bcf_+3A_general_params">general_params</code></td>
<td>
<p>(Optional) A list of general (non-forest-specific) model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>cutpoint_grid_size</code> Maximum size of the &quot;grid&quot; of potential cutpoints to consider in the GFR algorithm. Default: <code>100</code>.
</p>
</li>
<li> <p><code>standardize</code> Whether or not to standardize the outcome (and store the offset / scale in the model object). Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>sample_sigma2_global</code> Whether or not to update the <code>sigma^2</code> global error variance parameter based on <code>IG(sigma2_global_shape, sigma2_global_scale)</code>. Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>sigma2_global_init</code> Starting value of global error variance parameter. Calibrated internally as <code>1.0*var((y_train-mean(y_train))/sd(y_train))</code> if not set.
</p>
</li>
<li> <p><code>sigma2_global_shape</code> Shape parameter in the <code>IG(sigma2_global_shape, sigma2_global_scale)</code> global error variance model. Default: <code>0</code>.
</p>
</li>
<li> <p><code>sigma2_global_scale</code> Scale parameter in the <code>IG(sigma2_global_shape, sigma2_global_scale)</code> global error variance model. Default: <code>0</code>.
</p>
</li>
<li> <p><code>variable_weights</code> Numeric weights reflecting the relative probability of splitting on each variable. Does not need to sum to 1 but cannot be negative. Defaults to <code>rep(1/ncol(X_train), ncol(X_train))</code> if not set here. Note that if the propensity score is included as a covariate in either forest, its weight will default to <code>1/ncol(X_train)</code>. A workaround if you wish to provide a custom weight for the propensity score is to include it as a column in <code>X_train</code> and then set <code>propensity_covariate</code> to <code>'none'</code> adjust <code>keep_vars</code> accordingly for the <code>mu</code> or <code>tau</code> forests.
</p>
</li>
<li> <p><code>propensity_covariate</code> Whether to include the propensity score as a covariate in either or both of the forests. Enter <code>"none"</code> for neither, <code>"mu"</code> for the prognostic forest, <code>"tau"</code> for the treatment forest, and <code>"both"</code> for both forests. If this is not <code>"none"</code> and a propensity score is not provided, it will be estimated from (<code>X_train</code>, <code>Z_train</code>) using <code>stochtree::bart()</code>. Default: <code>"mu"</code>.
</p>
</li>
<li> <p><code>adaptive_coding</code> Whether or not to use an &quot;adaptive coding&quot; scheme in which a binary treatment variable is not coded manually as (0,1) or (-1,1) but learned via parameters <code>b_0</code> and <code>b_1</code> that attach to the outcome model <code style="white-space: pre;">&#8288;[b_0 (1-Z) + b_1 Z] tau(X)&#8288;</code>. This is ignored when Z is not binary. Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>control_coding_init</code> Initial value of the &quot;control&quot; group coding parameter. This is ignored when Z is not binary. Default: <code>-0.5</code>.
</p>
</li>
<li> <p><code>treated_coding_init</code> Initial value of the &quot;treatment&quot; group coding parameter. This is ignored when Z is not binary. Default: <code>0.5</code>.
</p>
</li>
<li> <p><code>rfx_prior_var</code> Prior on the (diagonals of the) covariance of the additive group-level random regression coefficients. Must be a vector of length <code>ncol(rfx_basis_train)</code>. Default: <code>rep(1, ncol(rfx_basis_train))</code>
</p>
</li>
<li> <p><code>random_seed</code> Integer parameterizing the C++ random number generator. If not specified, the C++ random number generator is seeded according to <code>std::random_device</code>.
</p>
</li>
<li> <p><code>keep_burnin</code> Whether or not &quot;burnin&quot; samples should be included in the stored samples of forests and other parameters. Default <code>FALSE</code>. Ignored if <code>num_mcmc = 0</code>.
</p>
</li>
<li> <p><code>keep_gfr</code> Whether or not &quot;grow-from-root&quot; samples should be included in the stored samples of forests and other parameters. Default <code>FALSE</code>. Ignored if <code>num_mcmc = 0</code>.
</p>
</li>
<li> <p><code>keep_every</code> How many iterations of the burned-in MCMC sampler should be run before forests and parameters are retained. Default <code>1</code>. Setting <code>keep_every &lt;- k</code> for some <code>k &gt; 1</code> will &quot;thin&quot; the MCMC samples by retaining every <code>k</code>-th sample, rather than simply every sample. This can reduce the autocorrelation of the MCMC samples.
</p>
</li>
<li> <p><code>num_chains</code> How many independent MCMC chains should be sampled. If <code>num_mcmc = 0</code>, this is ignored. If <code>num_gfr = 0</code>, then each chain is run from root for <code>num_mcmc * keep_every + num_burnin</code> iterations, with <code>num_mcmc</code> samples retained. If <code>num_gfr &gt; 0</code>, each MCMC chain will be initialized from a separate GFR ensemble, with the requirement that <code>num_gfr &gt;= num_chains</code>. Default: <code>1</code>.
</p>
</li>
<li> <p><code>verbose</code> Whether or not to print progress during the sampling loops. Default: <code>FALSE</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bcf_+3A_prognostic_forest_params">prognostic_forest_params</code></td>
<td>
<p>(Optional) A list of prognostic forest model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>num_trees</code> Number of trees in the ensemble for the prognostic forest. Default: <code>250</code>. Must be a positive integer.
</p>
</li>
<li> <p><code>alpha</code> Prior probability of splitting for a tree of depth 0 in the prognostic forest. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>0.95</code>.
</p>
</li>
<li> <p><code>beta</code> Exponent that decreases split probabilities for nodes of depth &gt; 0 in the prognostic forest. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>2</code>.
</p>
</li>
<li> <p><code>min_samples_leaf</code> Minimum allowable size of a leaf, in terms of training samples, in the prognostic forest. Default: <code>5</code>.
</p>
</li>
<li> <p><code>max_depth</code> Maximum depth of any tree in the ensemble in the prognostic forest. Default: <code>10</code>. Can be overridden with <code>-1</code> which does not enforce any depth limits on trees.
</p>
</li>
<li> <p><code>variable_weights</code> Numeric weights reflecting the relative probability of splitting on each variable in the prognostic forest. Does not need to sum to 1 but cannot be negative. Defaults to <code>rep(1/ncol(X_train), ncol(X_train))</code> if not set here.
</p>
</li>
<li> <p><code>sample_sigma2_leaf</code> Whether or not to update the leaf scale variance parameter based on <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code>.
</p>
</li>
<li> <p><code>sigma2_leaf_init</code> Starting value of leaf node scale parameter. Calibrated internally as <code>1/num_trees</code> if not set here.
</p>
</li>
<li> <p><code>sigma2_leaf_shape</code> Shape parameter in the <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code> leaf node parameter variance model. Default: <code>3</code>.
</p>
</li>
<li> <p><code>sigma2_leaf_scale</code> Scale parameter in the <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code> leaf node parameter variance model. Calibrated internally as <code>0.5/num_trees</code> if not set here.
</p>
</li>
<li> <p><code>keep_vars</code> Vector of variable names or column indices denoting variables that should be included in the forest. Default: <code>NULL</code>.
</p>
</li>
<li> <p><code>drop_vars</code> Vector of variable names or column indices denoting variables that should be excluded from the forest. Default: <code>NULL</code>. If both <code>drop_vars</code> and <code>keep_vars</code> are set, <code>drop_vars</code> will be ignored.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bcf_+3A_treatment_effect_forest_params">treatment_effect_forest_params</code></td>
<td>
<p>(Optional) A list of treatment effect forest model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>num_trees</code> Number of trees in the ensemble for the treatment effect forest. Default: <code>50</code>. Must be a positive integer.
</p>
</li>
<li> <p><code>alpha</code> Prior probability of splitting for a tree of depth 0 in the treatment effect forest. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>0.25</code>.
</p>
</li>
<li> <p><code>beta</code> Exponent that decreases split probabilities for nodes of depth &gt; 0 in the treatment effect forest. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>3</code>.
</p>
</li>
<li> <p><code>min_samples_leaf</code> Minimum allowable size of a leaf, in terms of training samples, in the treatment effect forest. Default: <code>5</code>.
</p>
</li>
<li> <p><code>max_depth</code> Maximum depth of any tree in the ensemble in the treatment effect forest. Default: <code>5</code>. Can be overridden with <code>-1</code> which does not enforce any depth limits on trees.
</p>
</li>
<li> <p><code>variable_weights</code> Numeric weights reflecting the relative probability of splitting on each variable in the treatment effect forest. Does not need to sum to 1 but cannot be negative. Defaults to <code>rep(1/ncol(X_train), ncol(X_train))</code> if not set here.
</p>
</li>
<li> <p><code>sample_sigma2_leaf</code> Whether or not to update the leaf scale variance parameter based on <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code>. Cannot (currently) be set to true if <code>ncol(Z_train)&gt;1</code>. Default: <code>FALSE</code>.
</p>
</li>
<li> <p><code>sigma2_leaf_init</code> Starting value of leaf node scale parameter. Calibrated internally as <code>1/num_trees</code> if not set here.
</p>
</li>
<li> <p><code>sigma2_leaf_shape</code> Shape parameter in the <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code> leaf node parameter variance model. Default: <code>3</code>.
</p>
</li>
<li> <p><code>sigma2_leaf_scale</code> Scale parameter in the <code>IG(sigma2_leaf_shape, sigma2_leaf_scale)</code> leaf node parameter variance model. Calibrated internally as <code>0.5/num_trees</code> if not set here.
</p>
</li>
<li> <p><code>keep_vars</code> Vector of variable names or column indices denoting variables that should be included in the forest. Default: <code>NULL</code>.
</p>
</li>
<li> <p><code>drop_vars</code> Vector of variable names or column indices denoting variables that should be excluded from the forest. Default: <code>NULL</code>. If both <code>drop_vars</code> and <code>keep_vars</code> are set, <code>drop_vars</code> will be ignored.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bcf_+3A_variance_forest_params">variance_forest_params</code></td>
<td>
<p>(Optional) A list of variance forest model parameters, each of which has a default value processed internally, so this argument list is optional.
</p>

<ul>
<li> <p><code>num_trees</code> Number of trees in the ensemble for the conditional variance model. Default: <code>0</code>. Variance is only modeled using a tree / forest if <code>num_trees &gt; 0</code>.
</p>
</li>
<li> <p><code>alpha</code> Prior probability of splitting for a tree of depth 0 in the variance model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>0.95</code>.
</p>
</li>
<li> <p><code>beta</code> Exponent that decreases split probabilities for nodes of depth &gt; 0 in the variance model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>. Default: <code>2</code>.
</p>
</li>
<li> <p><code>min_samples_leaf</code> Minimum allowable size of a leaf, in terms of training samples, in the variance model. Default: <code>5</code>.
</p>
</li>
<li> <p><code>max_depth</code> Maximum depth of any tree in the ensemble in the variance model. Default: <code>10</code>. Can be overridden with <code>-1</code> which does not enforce any depth limits on trees.
</p>
</li>
<li> <p><code>leaf_prior_calibration_param</code> Hyperparameter used to calibrate the <code>IG(var_forest_prior_shape, var_forest_prior_scale)</code> conditional error variance model. If <code>var_forest_prior_shape</code> and <code>var_forest_prior_scale</code> are not set below, this calibration parameter is used to set these values to <code>num_trees / leaf_prior_calibration_param^2 + 0.5</code> and <code>num_trees / leaf_prior_calibration_param^2</code>, respectively. Default: <code>1.5</code>.
</p>
</li>
<li> <p><code>variance_forest_init</code> Starting value of root forest prediction in conditional (heteroskedastic) error variance model. Calibrated internally as <code>log(0.6*var((y_train-mean(y_train))/sd(y_train)))/num_trees</code> if not set.
</p>
</li>
<li> <p><code>var_forest_prior_shape</code> Shape parameter in the <code>IG(var_forest_prior_shape, var_forest_prior_scale)</code> conditional error variance model (which is only sampled if <code>num_trees &gt; 0</code>). Calibrated internally as <code>num_trees / 1.5^2 + 0.5</code> if not set.
</p>
</li>
<li> <p><code>var_forest_prior_scale</code> Scale parameter in the <code>IG(var_forest_prior_shape, var_forest_prior_scale)</code> conditional error variance model (which is only sampled if <code>num_trees &gt; 0</code>). Calibrated internally as <code>num_trees / 1.5^2</code> if not set.
</p>
</li>
<li> <p><code>keep_vars</code> Vector of variable names or column indices denoting variables that should be included in the forest. Default: <code>NULL</code>.
</p>
</li>
<li> <p><code>drop_vars</code> Vector of variable names or column indices denoting variables that should be excluded from the forest. Default: <code>NULL</code>. If both <code>drop_vars</code> and <code>keep_vars</code> are set, <code>drop_vars</code> will be ignored.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>List of sampling outputs and a wrapper around the sampled forests (which can be used for in-memory prediction on new data, or serialized to JSON on disk).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
noise_sd &lt;- 1
y &lt;- mu_x + tau_x*Z + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, X_test = X_test, Z_test = Z_test, 
                 propensity_test = pi_test, num_gfr = 10, 
                 num_burnin = 0, num_mcmc = 10)
</code></pre>

<hr>
<h2 id='calibrateInverseGammaErrorVariance'>Calibrate the scale parameter on an inverse gamma prior for the global error variance as in Chipman et al (2022)</h2><span id='topic+calibrateInverseGammaErrorVariance'></span>

<h3>Description</h3>

<p>Chipman, H., George, E., Hahn, R., McCulloch, R., Pratola, M. and Sparapani, R. (2022). Bayesian Additive Regression Trees, Computational Approaches. In Wiley StatsRef: Statistics Reference Online (eds N. Balakrishnan, T. Colton, B. Everitt, W. Piegorsch, F. Ruggeri and J.L. Teugels). https://doi.org/10.1002/9781118445112.stat08288
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrateInverseGammaErrorVariance(
  y,
  X,
  W = NULL,
  nu = 3,
  quant = 0.9,
  standardize = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibrateInverseGammaErrorVariance_+3A_y">y</code></td>
<td>
<p>Outcome to be modeled using BART, BCF or another nonparametric ensemble method.</p>
</td></tr>
<tr><td><code id="calibrateInverseGammaErrorVariance_+3A_x">X</code></td>
<td>
<p>Covariates to be used to partition trees in an ensemble or series of ensemble.</p>
</td></tr>
<tr><td><code id="calibrateInverseGammaErrorVariance_+3A_w">W</code></td>
<td>
<p>(Optional) Basis used to define a &quot;leaf regression&quot; model for each decision tree. The &quot;classic&quot; BART model assumes a constant leaf parameter, which is equivalent to a &quot;leaf regression&quot; on a basis of all ones, though it is not necessary to pass a vector of ones, here or to the BART function. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calibrateInverseGammaErrorVariance_+3A_nu">nu</code></td>
<td>
<p>The shape parameter for the global error variance's IG prior. The scale parameter in the Sparapani et al (2021) parameterization is defined as <code>nu*lambda</code> where <code>lambda</code> is the output of this function. Default: <code>3</code>.</p>
</td></tr>
<tr><td><code id="calibrateInverseGammaErrorVariance_+3A_quant">quant</code></td>
<td>
<p>(Optional) Quantile of the inverse gamma prior distribution represented by a linear-regression-based overestimate of <code>sigma^2</code>. Default: <code>0.9</code>.</p>
</td></tr>
<tr><td><code id="calibrateInverseGammaErrorVariance_+3A_standardize">standardize</code></td>
<td>
<p>(Optional) Whether or not outcome should be standardized (<code>(y-mean(y))/sd(y)</code>) before calibration of <code>lambda</code>. Default: <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of <code>lambda</code> which determines the scale parameter of the global error variance prior (<code>sigma^2 ~ IG(nu,nu*lambda)</code>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
y &lt;- 10*X[,1] - 20*X[,2] + rnorm(n)
nu &lt;- 3
lambda &lt;- calibrateInverseGammaErrorVariance(y, X, nu = nu)
sigma2hat &lt;- mean(resid(lm(y~X))^2)
mean(var(y)/rgamma(100000, nu, rate = nu*lambda) &lt; sigma2hat)
</code></pre>

<hr>
<h2 id='computeForestLeafIndices'>Compute vector of forest leaf indices</h2><span id='topic+computeForestLeafIndices'></span>

<h3>Description</h3>

<p>Compute and return a vector representation of a forest's leaf predictions for
every observation in a dataset.
</p>
<p>The vector has a &quot;row-major&quot; format that can be easily re-represented as
as a CSR sparse matrix: elements are organized so that the first <code>n</code> elements
correspond to leaf predictions for all <code>n</code> observations in a dataset for the
first tree in an ensemble, the next <code>n</code> elements correspond to predictions for
the second tree and so on. The &quot;data&quot; for each element corresponds to a uniquely
mapped column index that corresponds to a single leaf of a single tree (i.e.
if tree 1 has 3 leaves, its column indices range from 0 to 2, and then tree 2's
leaf indices begin at 3, etc...).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeForestLeafIndices(
  model_object,
  covariates,
  forest_type = NULL,
  forest_inds = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeForestLeafIndices_+3A_model_object">model_object</code></td>
<td>
<p>Object of type <code>bartmodel</code>, <code>bcfmodel</code>, or <code>ForestSamples</code> corresponding to a BART / BCF model with at least one forest sample, or a low-level <code>ForestSamples</code> object.</p>
</td></tr>
<tr><td><code id="computeForestLeafIndices_+3A_covariates">covariates</code></td>
<td>
<p>Covariates to use for prediction. Must have the same dimensions / column types as the data used to train a forest.</p>
</td></tr>
<tr><td><code id="computeForestLeafIndices_+3A_forest_type">forest_type</code></td>
<td>
<p>Which forest to use from <code>model_object</code>.
Valid inputs depend on the model type, and whether or not a given forest was sampled in that model.
</p>
<p><strong>1. BART</strong>
</p>

<ul>
<li> <p><code>'mean'</code>: Extracts leaf indices for the mean forest
</p>
</li>
<li> <p><code>'variance'</code>: Extracts leaf indices for the variance forest
</p>
</li></ul>

<p><strong>2. BCF</strong>
</p>

<ul>
<li> <p><code>'prognostic'</code>: Extracts leaf indices for the prognostic forest
</p>
</li>
<li> <p><code>'treatment'</code>: Extracts leaf indices for the treatment effect forest
</p>
</li>
<li> <p><code>'variance'</code>: Extracts leaf indices for the variance forest
</p>
</li></ul>

<p><strong>3. ForestSamples</strong>
</p>

<ul>
<li> <p><code>NULL</code>: It is not necessary to disambiguate when this function is called directly on a <code>ForestSamples</code> object. This is the default value of this
</p>
</li></ul>
</td></tr>
<tr><td><code id="computeForestLeafIndices_+3A_forest_inds">forest_inds</code></td>
<td>
<p>(Optional) Indices of the forest sample(s) for which to compute leaf indices. If not provided,
this function will return leaf indices for every sample of a forest.
This function uses 0-indexing, so the first forest sample corresponds to <code>forest_num = 0</code>, and so on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of vectors. Each vector is of size <code>num_obs * num_trees</code>, where <code>num_obs = nrow(covariates)</code>
and <code>num_trees</code> is the number of trees in the relevant forest of <code>model_object</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
bart_model &lt;- bart(X, y, num_gfr=0, num_mcmc=10)
computeForestLeafIndices(bart_model, X, "mean")
computeForestLeafIndices(bart_model, X, "mean", 0)
computeForestLeafIndices(bart_model, X, "mean", c(1,3,9))
</code></pre>

<hr>
<h2 id='computeForestLeafVariances'>Compute vector of forest leaf scale parameters</h2><span id='topic+computeForestLeafVariances'></span>

<h3>Description</h3>

<p>Return each forest's leaf node scale parameters.
</p>
<p>If leaf scale is not sampled for the forest in question, throws an error that the
leaf model does not have a stochastic scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeForestLeafVariances(model_object, forest_type, forest_inds = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeForestLeafVariances_+3A_model_object">model_object</code></td>
<td>
<p>Object of type <code>bartmodel</code> or <code>bcfmodel</code> corresponding to a BART / BCF model with at least one forest sample</p>
</td></tr>
<tr><td><code id="computeForestLeafVariances_+3A_forest_type">forest_type</code></td>
<td>
<p>Which forest to use from <code>model_object</code>.
Valid inputs depend on the model type, and whether or not a given forest was sampled in that model.
</p>
<p><strong>1. BART</strong>
</p>

<ul>
<li> <p><code>'mean'</code>: Extracts leaf indices for the mean forest
</p>
</li>
<li> <p><code>'variance'</code>: Extracts leaf indices for the variance forest
</p>
</li></ul>

<p><strong>2. BCF</strong>
</p>

<ul>
<li> <p><code>'prognostic'</code>: Extracts leaf indices for the prognostic forest
</p>
</li>
<li> <p><code>'treatment'</code>: Extracts leaf indices for the treatment effect forest
</p>
</li>
<li> <p><code>'variance'</code>: Extracts leaf indices for the variance forest
</p>
</li></ul>
</td></tr>
<tr><td><code id="computeForestLeafVariances_+3A_forest_inds">forest_inds</code></td>
<td>
<p>(Optional) Indices of the forest sample(s) for which to compute leaf indices. If not provided,
this function will return leaf indices for every sample of a forest.
This function uses 0-indexing, so the first forest sample corresponds to <code>forest_num = 0</code>, and so on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of size <code>length(forest_inds)</code> with the leaf scale parameter for each requested forest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
bart_model &lt;- bart(X, y, num_gfr=0, num_mcmc=10)
computeForestLeafVariances(bart_model, "mean")
computeForestLeafVariances(bart_model, "mean", 0)
computeForestLeafVariances(bart_model, "mean", c(1,3,5))
</code></pre>

<hr>
<h2 id='computeForestMaxLeafIndex'>Compute and return the largest possible leaf index computable by <code>computeForestLeafIndices</code> for the forests in a designated forest sample container.</h2><span id='topic+computeForestMaxLeafIndex'></span>

<h3>Description</h3>

<p>Compute and return the largest possible leaf index computable by <code>computeForestLeafIndices</code> for the forests in a designated forest sample container.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeForestMaxLeafIndex(
  model_object,
  covariates,
  forest_type = NULL,
  forest_inds = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeForestMaxLeafIndex_+3A_model_object">model_object</code></td>
<td>
<p>Object of type <code>bartmodel</code>, <code>bcfmodel</code>, or <code>ForestSamples</code> corresponding to a BART / BCF model with at least one forest sample, or a low-level <code>ForestSamples</code> object.</p>
</td></tr>
<tr><td><code id="computeForestMaxLeafIndex_+3A_covariates">covariates</code></td>
<td>
<p>Covariates to use for prediction. Must have the same dimensions / column types as the data used to train a forest.</p>
</td></tr>
<tr><td><code id="computeForestMaxLeafIndex_+3A_forest_type">forest_type</code></td>
<td>
<p>Which forest to use from <code>model_object</code>.
Valid inputs depend on the model type, and whether or not a
</p>
<p><strong>1. BART</strong>
</p>

<ul>
<li> <p><code>'mean'</code>: Extracts leaf indices for the mean forest
</p>
</li>
<li> <p><code>'variance'</code>: Extracts leaf indices for the variance forest
</p>
</li></ul>

<p><strong>2. BCF</strong>
</p>

<ul>
<li> <p><code>'prognostic'</code>: Extracts leaf indices for the prognostic forest
</p>
</li>
<li> <p><code>'treatment'</code>: Extracts leaf indices for the treatment effect forest
</p>
</li>
<li> <p><code>'variance'</code>: Extracts leaf indices for the variance forest
</p>
</li></ul>

<p><strong>3. ForestSamples</strong>
</p>

<ul>
<li> <p><code>NULL</code>: It is not necessary to disambiguate when this function is called directly on a <code>ForestSamples</code> object. This is the default value of this
</p>
</li></ul>
</td></tr>
<tr><td><code id="computeForestMaxLeafIndex_+3A_forest_inds">forest_inds</code></td>
<td>
<p>(Optional) Indices of the forest sample(s) for which to compute max leaf indices. If not provided,
this function will return max leaf indices for every sample of a forest.
This function uses 0-indexing, so the first forest sample corresponds to <code>forest_num = 0</code>, and so on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector containing the largest possible leaf index computable by <code>computeForestLeafIndices</code> for the forests in a designated forest sample container.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
bart_model &lt;- bart(X, y, num_gfr=0, num_mcmc=10)
computeForestMaxLeafIndex(bart_model, X, "mean")
computeForestMaxLeafIndex(bart_model, X, "mean", 0)
computeForestMaxLeafIndex(bart_model, X, "mean", c(1,3,9))
</code></pre>

<hr>
<h2 id='convertPreprocessorToJson'>Convert the persistent aspects of a covariate preprocessor to (in-memory) C++ JSON object</h2><span id='topic+convertPreprocessorToJson'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a covariate preprocessor to (in-memory) C++ JSON object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertPreprocessorToJson(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convertPreprocessorToJson_+3A_object">object</code></td>
<td>
<p>List containing information on variables, including train set
categories for categorical variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>wrapper around in-memory C++ JSON object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov_mat &lt;- matrix(1:12, ncol = 3)
preprocess_list &lt;- preprocessTrainData(cov_mat)
preprocessor_json &lt;- convertPreprocessorToJson(preprocess_list$metadata)
</code></pre>

<hr>
<h2 id='CppJson'>Class that stores draws from an random ensemble of decision trees</h2><span id='topic+CppJson'></span>

<h3>Description</h3>

<p>Wrapper around a C++ container of tree ensembles
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>json_ptr</code></dt><dd><p>External pointer to a C++ nlohmann::json object</p>
</dd>
<dt><code>num_forests</code></dt><dd><p>Number of forests in the nlohmann::json object</p>
</dd>
<dt><code>forest_labels</code></dt><dd><p>Names of forest objects in the overall nlohmann::json object</p>
</dd>
<dt><code>num_rfx</code></dt><dd><p>Number of random effects terms in the nlohman::json object</p>
</dd>
<dt><code>rfx_container_labels</code></dt><dd><p>Names of rfx container objects in the overall nlohmann::json object</p>
</dd>
<dt><code>rfx_mapper_labels</code></dt><dd><p>Names of rfx label mapper objects in the overall nlohmann::json object</p>
</dd>
<dt><code>rfx_groupid_labels</code></dt><dd><p>Names of rfx group id objects in the overall nlohmann::json object</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CppJson-new"><code>CppJson$new()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_forest"><code>CppJson$add_forest()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_random_effects"><code>CppJson$add_random_effects()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_scalar"><code>CppJson$add_scalar()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_integer"><code>CppJson$add_integer()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_boolean"><code>CppJson$add_boolean()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_string"><code>CppJson$add_string()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_vector"><code>CppJson$add_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_integer_vector"><code>CppJson$add_integer_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_string_vector"><code>CppJson$add_string_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_list"><code>CppJson$add_list()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-add_string_list"><code>CppJson$add_string_list()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_scalar"><code>CppJson$get_scalar()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_integer"><code>CppJson$get_integer()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_boolean"><code>CppJson$get_boolean()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_string"><code>CppJson$get_string()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_vector"><code>CppJson$get_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_integer_vector"><code>CppJson$get_integer_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_string_vector"><code>CppJson$get_string_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_numeric_list"><code>CppJson$get_numeric_list()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-get_string_list"><code>CppJson$get_string_list()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-return_json_string"><code>CppJson$return_json_string()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-save_file"><code>CppJson$save_file()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-load_from_file"><code>CppJson$load_from_file()</code></a>
</p>
</li>
<li> <p><a href="#method-CppJson-load_from_string"><code>CppJson$load_from_string()</code></a>
</p>
</li></ul>


<hr>
<a id="method-CppJson-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new CppJson object.
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$new()</pre></div>



<h5>Returns</h5>

<p>A new <code>CppJson</code> object.
</p>


<hr>
<a id="method-CppJson-add_forest"></a>



<h4>Method <code>add_forest()</code></h4>

<p>Convert a forest container to json and add to the current <code>CppJson</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_forest(forest_samples)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_samples</code></dt><dd><p><code>ForestSamples</code> R class</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_random_effects"></a>



<h4>Method <code>add_random_effects()</code></h4>

<p>Convert a random effects container to json and add to the current <code>CppJson</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_random_effects(rfx_samples)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rfx_samples</code></dt><dd><p><code>RandomEffectSamples</code> R class</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_scalar"></a>



<h4>Method <code>add_scalar()</code></h4>

<p>Add a scalar to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_scalar(field_name, field_value, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_value</code></dt><dd><p>Numeric value of the field to be added to json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_integer"></a>



<h4>Method <code>add_integer()</code></h4>

<p>Add a scalar to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_integer(field_name, field_value, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_value</code></dt><dd><p>Integer value of the field to be added to json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_boolean"></a>



<h4>Method <code>add_boolean()</code></h4>

<p>Add a boolean value to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_boolean(field_name, field_value, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_value</code></dt><dd><p>Numeric value of the field to be added to json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_string"></a>



<h4>Method <code>add_string()</code></h4>

<p>Add a string value to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_string(field_name, field_value, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_value</code></dt><dd><p>Numeric value of the field to be added to json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_vector"></a>



<h4>Method <code>add_vector()</code></h4>

<p>Add a vector to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_vector(field_name, field_vector, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_vector</code></dt><dd><p>Vector to be stored in json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_integer_vector"></a>



<h4>Method <code>add_integer_vector()</code></h4>

<p>Add an integer vector to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_integer_vector(field_name, field_vector, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_vector</code></dt><dd><p>Vector to be stored in json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_string_vector"></a>



<h4>Method <code>add_string_vector()</code></h4>

<p>Add an array to the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_string_vector(field_name, field_vector, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_vector</code></dt><dd><p>Character vector to be stored in json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which to place the value</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_list"></a>



<h4>Method <code>add_list()</code></h4>

<p>Add a list of vectors (as an object map of arrays) to the json object under the name &quot;field_name&quot;
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_list(field_name, field_list)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_list</code></dt><dd><p>List to be stored in json</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-add_string_list"></a>



<h4>Method <code>add_string_list()</code></h4>

<p>Add a list of vectors (as an object map of arrays) to the json object under the name &quot;field_name&quot;
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$add_string_list(field_name, field_list)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>field_list</code></dt><dd><p>List to be stored in json</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_scalar"></a>



<h4>Method <code>get_scalar()</code></h4>

<p>Retrieve a scalar value from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_scalar(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_integer"></a>



<h4>Method <code>get_integer()</code></h4>

<p>Retrieve a integer value from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_integer(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_boolean"></a>



<h4>Method <code>get_boolean()</code></h4>

<p>Retrieve a boolean value from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_boolean(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_string"></a>



<h4>Method <code>get_string()</code></h4>

<p>Retrieve a string value from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_string(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_vector"></a>



<h4>Method <code>get_vector()</code></h4>

<p>Retrieve a vector from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_vector(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_integer_vector"></a>



<h4>Method <code>get_integer_vector()</code></h4>

<p>Retrieve an integer vector from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_integer_vector(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_string_vector"></a>



<h4>Method <code>get_string_vector()</code></h4>

<p>Retrieve a character vector from the json object under the name &quot;field_name&quot; (with optional subfolder &quot;subfolder_name&quot;)
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_string_vector(field_name, subfolder_name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be accessed from json</p>
</dd>
<dt><code>subfolder_name</code></dt><dd><p>(Optional) Name of the subfolder / hierarchy under which the field is stored</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_numeric_list"></a>



<h4>Method <code>get_numeric_list()</code></h4>

<p>Reconstruct a list of numeric vectors from the json object stored under &quot;field_name&quot;
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_numeric_list(field_name, key_names)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>key_names</code></dt><dd><p>Vector of names of list elements (each of which is a vector)</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-get_string_list"></a>



<h4>Method <code>get_string_list()</code></h4>

<p>Reconstruct a list of string vectors from the json object stored under &quot;field_name&quot;
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$get_string_list(field_name, key_names)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>field_name</code></dt><dd><p>The name of the field to be added to json</p>
</dd>
<dt><code>key_names</code></dt><dd><p>Vector of names of list elements (each of which is a vector)</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-return_json_string"></a>



<h4>Method <code>return_json_string()</code></h4>

<p>Convert a JSON object to in-memory string
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$return_json_string()</pre></div>



<h5>Returns</h5>

<p>JSON string
</p>


<hr>
<a id="method-CppJson-save_file"></a>



<h4>Method <code>save_file()</code></h4>

<p>Save a json object to file
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$save_file(filename)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>filename</code></dt><dd><p>String of filepath, must end in &quot;.json&quot;</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-load_from_file"></a>



<h4>Method <code>load_from_file()</code></h4>

<p>Load a json object from file
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$load_from_file(filename)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>filename</code></dt><dd><p>String of filepath, must end in &quot;.json&quot;</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-CppJson-load_from_string"></a>



<h4>Method <code>load_from_string()</code></h4>

<p>Load a json object from string
</p>


<h5>Usage</h5>

<div class="r"><pre>CppJson$load_from_string(json_string)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_string</code></dt><dd><p>JSON string dump</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>



<hr>
<h2 id='CppRNG'>Class that wraps a C++ random number generator (for reproducibility)</h2><span id='topic+CppRNG'></span>

<h3>Description</h3>

<p>Persists a C++ random number generator throughout an R session to
ensure reproducibility from a given random seed. If no seed is provided,
the C++ random number generator is initialized using <code>std::random_device</code>.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>rng_ptr</code></dt><dd><p>External pointer to a C++ std::mt19937 class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CppRNG-new"><code>CppRNG$new()</code></a>
</p>
</li></ul>


<hr>
<a id="method-CppRNG-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new CppRNG object.
</p>


<h5>Usage</h5>

<div class="r"><pre>CppRNG$new(random_seed = -1)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>random_seed</code></dt><dd><p>(Optional) random seed for sampling</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>CppRNG</code> object.
</p>



<hr>
<h2 id='createBARTModelFromCombinedJson'>Convert a list of (in-memory) JSON representations of a BART model to a single combined BART model object
which can be used for prediction, etc...</h2><span id='topic+createBARTModelFromCombinedJson'></span>

<h3>Description</h3>

<p>Convert a list of (in-memory) JSON representations of a BART model to a single combined BART model object
which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBARTModelFromCombinedJson(json_object_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBARTModelFromCombinedJson_+3A_json_object_list">json_object_list</code></td>
<td>
<p>List of objects of type <code>CppJson</code> containing Json representation of a BART model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bartmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bart_json &lt;- list(saveBARTModelToJson(bart_model))
bart_model_roundtrip &lt;- createBARTModelFromCombinedJson(bart_json)
</code></pre>

<hr>
<h2 id='createBARTModelFromCombinedJsonString'>Convert a list of (in-memory) JSON strings that represent BART models to a single combined BART model object
which can be used for prediction, etc...</h2><span id='topic+createBARTModelFromCombinedJsonString'></span>

<h3>Description</h3>

<p>Convert a list of (in-memory) JSON strings that represent BART models to a single combined BART model object
which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBARTModelFromCombinedJsonString(json_string_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBARTModelFromCombinedJsonString_+3A_json_string_list">json_string_list</code></td>
<td>
<p>List of JSON strings which can be parsed to objects of type <code>CppJson</code> containing Json representation of a BART model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bartmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bart_json_string_list &lt;- list(saveBARTModelToJsonString(bart_model))
bart_model_roundtrip &lt;- createBARTModelFromCombinedJsonString(bart_json_string_list)
</code></pre>

<hr>
<h2 id='createBARTModelFromJson'>Convert an (in-memory) JSON representation of a BART model to a BART model object
which can be used for prediction, etc...</h2><span id='topic+createBARTModelFromJson'></span>

<h3>Description</h3>

<p>Convert an (in-memory) JSON representation of a BART model to a BART model object
which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBARTModelFromJson(json_object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBARTModelFromJson_+3A_json_object">json_object</code></td>
<td>
<p>Object of type <code>CppJson</code> containing Json representation of a BART model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bartmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bart_json &lt;- saveBARTModelToJson(bart_model)
bart_model_roundtrip &lt;- createBARTModelFromJson(bart_json)
</code></pre>

<hr>
<h2 id='createBARTModelFromJsonFile'>Convert a JSON file containing sample information on a trained BART model
to a BART model object which can be used for prediction, etc...</h2><span id='topic+createBARTModelFromJsonFile'></span>

<h3>Description</h3>

<p>Convert a JSON file containing sample information on a trained BART model
to a BART model object which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBARTModelFromJsonFile(json_filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBARTModelFromJsonFile_+3A_json_filename">json_filename</code></td>
<td>
<p>String of filepath, must end in &quot;.json&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bartmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
tmpjson &lt;- tempfile(fileext = ".json")
saveBARTModelToJsonFile(bart_model, file.path(tmpjson))
bart_model_roundtrip &lt;- createBARTModelFromJsonFile(file.path(tmpjson))
unlink(tmpjson)
</code></pre>

<hr>
<h2 id='createBARTModelFromJsonString'>Convert a JSON string containing sample information on a trained BART model
to a BART model object which can be used for prediction, etc...</h2><span id='topic+createBARTModelFromJsonString'></span>

<h3>Description</h3>

<p>Convert a JSON string containing sample information on a trained BART model
to a BART model object which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBARTModelFromJsonString(json_string)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBARTModelFromJsonString_+3A_json_string">json_string</code></td>
<td>
<p>JSON string dump</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bartmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bart_json &lt;- saveBARTModelToJsonString(bart_model)
bart_model_roundtrip &lt;- createBARTModelFromJsonString(bart_json)
y_hat_mean_roundtrip &lt;- rowMeans(predict(bart_model_roundtrip, X_train)$y_hat)
</code></pre>

<hr>
<h2 id='createBCFModelFromCombinedJson'>Convert a list of (in-memory) JSON strings that represent BCF models to a single combined BCF model object
which can be used for prediction, etc...</h2><span id='topic+createBCFModelFromCombinedJson'></span>

<h3>Description</h3>

<p>Convert a list of (in-memory) JSON strings that represent BCF models to a single combined BCF model object
which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBCFModelFromCombinedJson(json_object_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBCFModelFromCombinedJson_+3A_json_object_list">json_object_list</code></td>
<td>
<p>List of objects of type <code>CppJson</code> containing Json representation of a BCF model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bcfmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bcf_json_list &lt;- list(saveBCFModelToJson(bcf_model))
bcf_model_roundtrip &lt;- createBCFModelFromCombinedJson(bcf_json_list)
</code></pre>

<hr>
<h2 id='createBCFModelFromCombinedJsonString'>Convert a list of (in-memory) JSON strings that represent BCF models to a single combined BCF model object
which can be used for prediction, etc...</h2><span id='topic+createBCFModelFromCombinedJsonString'></span>

<h3>Description</h3>

<p>Convert a list of (in-memory) JSON strings that represent BCF models to a single combined BCF model object
which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBCFModelFromCombinedJsonString(json_string_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBCFModelFromCombinedJsonString_+3A_json_string_list">json_string_list</code></td>
<td>
<p>List of JSON strings which can be parsed to objects of type <code>CppJson</code> containing Json representation of a BCF model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bcfmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bcf_json_string_list &lt;- list(saveBCFModelToJsonString(bcf_model))
bcf_model_roundtrip &lt;- createBCFModelFromCombinedJsonString(bcf_json_string_list)
</code></pre>

<hr>
<h2 id='createBCFModelFromJson'>Convert an (in-memory) JSON representation of a BCF model to a BCF model object
which can be used for prediction, etc...</h2><span id='topic+createBCFModelFromJson'></span>

<h3>Description</h3>

<p>Convert an (in-memory) JSON representation of a BCF model to a BCF model object
which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBCFModelFromJson(json_object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBCFModelFromJson_+3A_json_object">json_object</code></td>
<td>
<p>Object of type <code>CppJson</code> containing Json representation of a BCF model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bcfmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
mu_params &lt;- list(sample_sigma_leaf = TRUE)
tau_params &lt;- list(sample_sigma_leaf = FALSE)
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10, 
                 prognostic_forest_params = mu_params, 
                 treatment_effect_forest_params = tau_params)
bcf_json &lt;- saveBCFModelToJson(bcf_model)
bcf_model_roundtrip &lt;- createBCFModelFromJson(bcf_json)
</code></pre>

<hr>
<h2 id='createBCFModelFromJsonFile'>Convert a JSON file containing sample information on a trained BCF model
to a BCF model object which can be used for prediction, etc...</h2><span id='topic+createBCFModelFromJsonFile'></span>

<h3>Description</h3>

<p>Convert a JSON file containing sample information on a trained BCF model
to a BCF model object which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBCFModelFromJsonFile(json_filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBCFModelFromJsonFile_+3A_json_filename">json_filename</code></td>
<td>
<p>String of filepath, must end in &quot;.json&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bcfmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
mu_params &lt;- list(sample_sigma_leaf = TRUE)
tau_params &lt;- list(sample_sigma_leaf = FALSE)
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10, 
                 prognostic_forest_params = mu_params, 
                 treatment_effect_forest_params = tau_params)
tmpjson &lt;- tempfile(fileext = ".json")
saveBCFModelToJsonFile(bcf_model, file.path(tmpjson))
bcf_model_roundtrip &lt;- createBCFModelFromJsonFile(file.path(tmpjson))
unlink(tmpjson)
</code></pre>

<hr>
<h2 id='createBCFModelFromJsonString'>Convert a JSON string containing sample information on a trained BCF model
to a BCF model object which can be used for prediction, etc...</h2><span id='topic+createBCFModelFromJsonString'></span>

<h3>Description</h3>

<p>Convert a JSON string containing sample information on a trained BCF model
to a BCF model object which can be used for prediction, etc...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBCFModelFromJsonString(json_string)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createBCFModelFromJsonString_+3A_json_string">json_string</code></td>
<td>
<p>JSON string dump</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>bcfmodel</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bcf_json &lt;- saveBCFModelToJsonString(bcf_model)
bcf_model_roundtrip &lt;- createBCFModelFromJsonString(bcf_json)
</code></pre>

<hr>
<h2 id='createCppJson'>Create a new (empty) C++ Json object</h2><span id='topic+createCppJson'></span>

<h3>Description</h3>

<p>Create a new (empty) C++ Json object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createCppJson()
</code></pre>


<h3>Value</h3>

<p><code>CppJson</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_vec &lt;- runif(10)
example_json &lt;- createCppJson()
example_json$add_vector("myvec", example_vec)
</code></pre>

<hr>
<h2 id='createCppJsonFile'>Create a C++ Json object from a Json file</h2><span id='topic+createCppJsonFile'></span>

<h3>Description</h3>

<p>Create a C++ Json object from a Json file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createCppJsonFile(json_filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createCppJsonFile_+3A_json_filename">json_filename</code></td>
<td>
<p>Name of file to read. Must end in <code>.json</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>CppJson</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_vec &lt;- runif(10)
example_json &lt;- createCppJson()
example_json$add_vector("myvec", example_vec)
tmpjson &lt;- tempfile(fileext = ".json")
example_json$save_file(file.path(tmpjson))
example_json_roundtrip &lt;- createCppJsonFile(file.path(tmpjson))
unlink(tmpjson)
</code></pre>

<hr>
<h2 id='createCppJsonString'>Create a C++ Json object from a Json string</h2><span id='topic+createCppJsonString'></span>

<h3>Description</h3>

<p>Create a C++ Json object from a Json string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createCppJsonString(json_string)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createCppJsonString_+3A_json_string">json_string</code></td>
<td>
<p>JSON string dump</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>CppJson</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_vec &lt;- runif(10)
example_json &lt;- createCppJson()
example_json$add_vector("myvec", example_vec)
example_json_string &lt;- example_json$return_json_string()
example_json_roundtrip &lt;- createCppJsonString(example_json_string)
</code></pre>

<hr>
<h2 id='createCppRNG'>Create an R class that wraps a C++ random number generator</h2><span id='topic+createCppRNG'></span>

<h3>Description</h3>

<p>Create an R class that wraps a C++ random number generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createCppRNG(random_seed = -1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createCppRNG_+3A_random_seed">random_seed</code></td>
<td>
<p>(Optional) random seed for sampling</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>CppRng</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rng &lt;- createCppRNG(1234)
rng &lt;- createCppRNG()
</code></pre>

<hr>
<h2 id='createForest'>Create a forest</h2><span id='topic+createForest'></span>

<h3>Description</h3>

<p>Create a forest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createForest(
  num_trees,
  leaf_dimension = 1,
  is_leaf_constant = FALSE,
  is_exponentiated = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createForest_+3A_num_trees">num_trees</code></td>
<td>
<p>Number of trees in the forest</p>
</td></tr>
<tr><td><code id="createForest_+3A_leaf_dimension">leaf_dimension</code></td>
<td>
<p>Dimensionality of the outcome model</p>
</td></tr>
<tr><td><code id="createForest_+3A_is_leaf_constant">is_leaf_constant</code></td>
<td>
<p>Whether leaf is constant</p>
</td></tr>
<tr><td><code id="createForest_+3A_is_exponentiated">is_exponentiated</code></td>
<td>
<p>Whether forest predictions should be exponentiated before being returned</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Forest</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_trees &lt;- 100
leaf_dimension &lt;- 2
is_leaf_constant &lt;- FALSE
is_exponentiated &lt;- FALSE
forest &lt;- createForest(num_trees, leaf_dimension, is_leaf_constant, is_exponentiated)
</code></pre>

<hr>
<h2 id='createForestDataset'>Create a forest dataset object</h2><span id='topic+createForestDataset'></span>

<h3>Description</h3>

<p>Create a forest dataset object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createForestDataset(covariates, basis = NULL, variance_weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createForestDataset_+3A_covariates">covariates</code></td>
<td>
<p>Matrix of covariates</p>
</td></tr>
<tr><td><code id="createForestDataset_+3A_basis">basis</code></td>
<td>
<p>(Optional) Matrix of bases used to define a leaf regression</p>
</td></tr>
<tr><td><code id="createForestDataset_+3A_variance_weights">variance_weights</code></td>
<td>
<p>(Optional) Vector of observation-specific variance weights</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ForestDataset</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>covariate_matrix &lt;- matrix(runif(10*100), ncol = 10)
basis_matrix &lt;- matrix(rnorm(3*100), ncol = 3)
weight_vector &lt;- rnorm(100)
forest_dataset &lt;- createForestDataset(covariate_matrix)
forest_dataset &lt;- createForestDataset(covariate_matrix, basis_matrix)
forest_dataset &lt;- createForestDataset(covariate_matrix, basis_matrix, weight_vector)
</code></pre>

<hr>
<h2 id='createForestModel'>Create a forest model object</h2><span id='topic+createForestModel'></span>

<h3>Description</h3>

<p>Create a forest model object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createForestModel(forest_dataset, forest_model_config, global_model_config)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createForestModel_+3A_forest_dataset">forest_dataset</code></td>
<td>
<p>ForestDataset object, used to initialize forest sampling data structures</p>
</td></tr>
<tr><td><code id="createForestModel_+3A_forest_model_config">forest_model_config</code></td>
<td>
<p>ForestModelConfig object containing forest model parameters and settings</p>
</td></tr>
<tr><td><code id="createForestModel_+3A_global_model_config">global_model_config</code></td>
<td>
<p>GlobalModelConfig object containing global model parameters and settings</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ForestModel</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_trees &lt;- 100
n &lt;- 100
p &lt;- 10
alpha &lt;- 0.95
beta &lt;- 2.0
min_samples_leaf &lt;- 2
max_depth &lt;- 10
feature_types &lt;- as.integer(rep(0, p))
X &lt;- matrix(runif(n*p), ncol = p)
forest_dataset &lt;- createForestDataset(X)
forest_model_config &lt;- createForestModelConfig(feature_types=feature_types, 
                                               num_trees=num_trees, num_features=p, 
                                               num_observations=n, alpha=alpha, beta=beta, 
                                               min_samples_leaf=min_samples_leaf, 
                                               max_depth=max_depth, leaf_model_type=1)
global_model_config &lt;- createGlobalModelConfig(global_error_variance=1.0)
forest_model &lt;- createForestModel(forest_dataset, forest_model_config, global_model_config)
</code></pre>

<hr>
<h2 id='createForestModelConfig'>Create a forest model config object</h2><span id='topic+createForestModelConfig'></span>

<h3>Description</h3>

<p>Create a forest model config object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createForestModelConfig(
  feature_types = NULL,
  num_trees = NULL,
  num_features = NULL,
  num_observations = NULL,
  variable_weights = NULL,
  leaf_dimension = 1,
  alpha = 0.95,
  beta = 2,
  min_samples_leaf = 5,
  max_depth = -1,
  leaf_model_type = 1,
  leaf_model_scale = NULL,
  variance_forest_shape = 1,
  variance_forest_scale = 1,
  cutpoint_grid_size = 100
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createForestModelConfig_+3A_feature_types">feature_types</code></td>
<td>
<p>Vector of integer-coded feature types (integers where 0 = numeric, 1 = ordered categorical, 2 = unordered categorical)</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_num_trees">num_trees</code></td>
<td>
<p>Number of trees in the forest being sampled</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_num_features">num_features</code></td>
<td>
<p>Number of features in training dataset</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_num_observations">num_observations</code></td>
<td>
<p>Number of observations in training dataset</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_variable_weights">variable_weights</code></td>
<td>
<p>Vector specifying sampling probability for all p covariates in ForestDataset</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_leaf_dimension">leaf_dimension</code></td>
<td>
<p>Dimension of the leaf model (default: <code>1</code>)</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_alpha">alpha</code></td>
<td>
<p>Root node split probability in tree prior (default: <code>0.95</code>)</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_beta">beta</code></td>
<td>
<p>Depth prior penalty in tree prior (default: <code>2.0</code>)</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_min_samples_leaf">min_samples_leaf</code></td>
<td>
<p>Minimum number of samples in a tree leaf (default: <code>5</code>)</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum depth of any tree in the ensemble in the model. Setting to <code>-1</code> does not enforce any depth limits on trees. Default: <code>-1</code>.</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_leaf_model_type">leaf_model_type</code></td>
<td>
<p>Integer specifying the leaf model type (0 = constant leaf, 1 = univariate leaf regression, 2 = multivariate leaf regression). Default: <code>0</code>.</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_leaf_model_scale">leaf_model_scale</code></td>
<td>
<p>Scale parameter used in Gaussian leaf models (can either be a scalar or a q x q matrix, where q is the dimensionality of the basis and is only &gt;1 when <code>leaf_model_int = 2</code>). Calibrated internally as <code>1/num_trees</code>, propagated along diagonal if needed for multivariate leaf models.</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_variance_forest_shape">variance_forest_shape</code></td>
<td>
<p>Shape parameter for IG leaf models (applicable when <code>leaf_model_type = 3</code>). Default: <code>1</code>.</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_variance_forest_scale">variance_forest_scale</code></td>
<td>
<p>Scale parameter for IG leaf models (applicable when <code>leaf_model_type = 3</code>). Default: <code>1</code>.</p>
</td></tr>
<tr><td><code id="createForestModelConfig_+3A_cutpoint_grid_size">cutpoint_grid_size</code></td>
<td>
<p>Number of unique cutpoints to consider (default: <code>100</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ForestModelConfig object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>config &lt;- createForestModelConfig(num_trees = 10, num_features = 5, num_observations = 100)
</code></pre>

<hr>
<h2 id='createForestSamples'>Create a container of forest samples</h2><span id='topic+createForestSamples'></span>

<h3>Description</h3>

<p>Create a container of forest samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createForestSamples(
  num_trees,
  leaf_dimension = 1,
  is_leaf_constant = FALSE,
  is_exponentiated = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createForestSamples_+3A_num_trees">num_trees</code></td>
<td>
<p>Number of trees</p>
</td></tr>
<tr><td><code id="createForestSamples_+3A_leaf_dimension">leaf_dimension</code></td>
<td>
<p>Dimensionality of the outcome model</p>
</td></tr>
<tr><td><code id="createForestSamples_+3A_is_leaf_constant">is_leaf_constant</code></td>
<td>
<p>Whether leaf is constant</p>
</td></tr>
<tr><td><code id="createForestSamples_+3A_is_exponentiated">is_exponentiated</code></td>
<td>
<p>Whether forest predictions should be exponentiated before being returned</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ForestSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_trees &lt;- 100
leaf_dimension &lt;- 2
is_leaf_constant &lt;- FALSE
is_exponentiated &lt;- FALSE
forest_samples &lt;- createForestSamples(num_trees, leaf_dimension, is_leaf_constant, is_exponentiated)
</code></pre>

<hr>
<h2 id='createGlobalModelConfig'>Create a global model config object</h2><span id='topic+createGlobalModelConfig'></span>

<h3>Description</h3>

<p>Create a global model config object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createGlobalModelConfig(global_error_variance = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createGlobalModelConfig_+3A_global_error_variance">global_error_variance</code></td>
<td>
<p>Global error variance parameter (default: <code>1.0</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>GlobalModelConfig object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>config &lt;- createGlobalModelConfig(global_error_variance = 100)
</code></pre>

<hr>
<h2 id='createOutcome'>Create an outcome object</h2><span id='topic+createOutcome'></span>

<h3>Description</h3>

<p>Create an outcome object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createOutcome(outcome)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createOutcome_+3A_outcome">outcome</code></td>
<td>
<p>Vector of outcome values</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Outcome</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
outcome &lt;- createOutcome(y)
</code></pre>

<hr>
<h2 id='createPreprocessorFromJson'>Reload a covariate preprocessor object from a JSON string containing a serialized preprocessor</h2><span id='topic+createPreprocessorFromJson'></span>

<h3>Description</h3>

<p>Reload a covariate preprocessor object from a JSON string containing a serialized preprocessor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createPreprocessorFromJson(json_object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createPreprocessorFromJson_+3A_json_object">json_object</code></td>
<td>
<p>in-memory wrapper around JSON C++ object containing covariate preprocessor metadata</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Preprocessor object that can be used with the <code>preprocessPredictionData</code> function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov_mat &lt;- matrix(1:12, ncol = 3)
preprocess_list &lt;- preprocessTrainData(cov_mat)
preprocessor_json &lt;- convertPreprocessorToJson(preprocess_list$metadata)
preprocessor_roundtrip &lt;- createPreprocessorFromJson(preprocessor_json)
</code></pre>

<hr>
<h2 id='createPreprocessorFromJsonString'>Reload a covariate preprocessor object from a JSON string containing a serialized preprocessor</h2><span id='topic+createPreprocessorFromJsonString'></span>

<h3>Description</h3>

<p>Reload a covariate preprocessor object from a JSON string containing a serialized preprocessor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createPreprocessorFromJsonString(json_string)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createPreprocessorFromJsonString_+3A_json_string">json_string</code></td>
<td>
<p>in-memory JSON string containing covariate preprocessor metadata</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Preprocessor object that can be used with the <code>preprocessPredictionData</code> function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov_mat &lt;- matrix(1:12, ncol = 3)
preprocess_list &lt;- preprocessTrainData(cov_mat)
preprocessor_json_string &lt;- savePreprocessorToJsonString(preprocess_list$metadata)
preprocessor_roundtrip &lt;- createPreprocessorFromJsonString(preprocessor_json_string)
</code></pre>

<hr>
<h2 id='createRandomEffectSamples'>Create a <code>RandomEffectSamples</code> object</h2><span id='topic+createRandomEffectSamples'></span>

<h3>Description</h3>

<p>Create a <code>RandomEffectSamples</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createRandomEffectSamples(num_components, num_groups, random_effects_tracker)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createRandomEffectSamples_+3A_num_components">num_components</code></td>
<td>
<p>Number of &quot;components&quot; or bases defining the random effects regression</p>
</td></tr>
<tr><td><code id="createRandomEffectSamples_+3A_num_groups">num_groups</code></td>
<td>
<p>Number of random effects groups</p>
</td></tr>
<tr><td><code id="createRandomEffectSamples_+3A_random_effects_tracker">random_effects_tracker</code></td>
<td>
<p>Object of type <code>RandomEffectsTracker</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_tracker &lt;- createRandomEffectsTracker(rfx_group_ids)
rfx_samples &lt;- createRandomEffectSamples(num_components, num_groups, rfx_tracker)
</code></pre>

<hr>
<h2 id='createRandomEffectsDataset'>Create a random effects dataset object</h2><span id='topic+createRandomEffectsDataset'></span>

<h3>Description</h3>

<p>Create a random effects dataset object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createRandomEffectsDataset(group_labels, basis, variance_weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createRandomEffectsDataset_+3A_group_labels">group_labels</code></td>
<td>
<p>Vector of group labels</p>
</td></tr>
<tr><td><code id="createRandomEffectsDataset_+3A_basis">basis</code></td>
<td>
<p>Matrix of bases used to define the random effects regression (for an intercept-only model, pass an array of ones)</p>
</td></tr>
<tr><td><code id="createRandomEffectsDataset_+3A_variance_weights">variance_weights</code></td>
<td>
<p>(Optional) Vector of observation-specific variance weights</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectsDataset</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rfx_group_ids &lt;- sample(1:2, size = 100, replace = TRUE)
rfx_basis &lt;- matrix(rnorm(3*100), ncol = 3)
weight_vector &lt;- rnorm(100)
rfx_dataset &lt;- createRandomEffectsDataset(rfx_group_ids, rfx_basis)
rfx_dataset &lt;- createRandomEffectsDataset(rfx_group_ids, rfx_basis, weight_vector)
</code></pre>

<hr>
<h2 id='createRandomEffectsModel'>Create a <code>RandomEffectsModel</code> object</h2><span id='topic+createRandomEffectsModel'></span>

<h3>Description</h3>

<p>Create a <code>RandomEffectsModel</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createRandomEffectsModel(num_components, num_groups)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createRandomEffectsModel_+3A_num_components">num_components</code></td>
<td>
<p>Number of &quot;components&quot; or bases defining the random effects regression</p>
</td></tr>
<tr><td><code id="createRandomEffectsModel_+3A_num_groups">num_groups</code></td>
<td>
<p>Number of random effects groups</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectsModel</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_model &lt;- createRandomEffectsModel(num_components, num_groups)
</code></pre>

<hr>
<h2 id='createRandomEffectsTracker'>Create a <code>RandomEffectsTracker</code> object</h2><span id='topic+createRandomEffectsTracker'></span>

<h3>Description</h3>

<p>Create a <code>RandomEffectsTracker</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createRandomEffectsTracker(rfx_group_indices)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createRandomEffectsTracker_+3A_rfx_group_indices">rfx_group_indices</code></td>
<td>
<p>Integer indices indicating groups used to define random effects</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectsTracker</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_tracker &lt;- createRandomEffectsTracker(rfx_group_ids)
</code></pre>

<hr>
<h2 id='Forest'>Class that stores a single ensemble of decision trees (often treated as the &quot;active forest&quot;)</h2><span id='topic+Forest'></span>

<h3>Description</h3>

<p>Wrapper around a C++ tree ensemble
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>forest_ptr</code></dt><dd><p>External pointer to a C++ TreeEnsemble class</p>
</dd>
<dt><code>internal_forest_is_empty</code></dt><dd><p>Whether the forest has not yet been &quot;initialized&quot; such that its <code>predict</code> function can be called.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Forest-new"><code>Forest$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-predict"><code>Forest$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-predict_raw"><code>Forest$predict_raw()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-set_root_leaves"><code>Forest$set_root_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-prepare_for_sampler"><code>Forest$prepare_for_sampler()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-adjust_residual"><code>Forest$adjust_residual()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-num_trees"><code>Forest$num_trees()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-leaf_dimension"><code>Forest$leaf_dimension()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-is_constant_leaf"><code>Forest$is_constant_leaf()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-is_exponentiated"><code>Forest$is_exponentiated()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-add_numeric_split_tree"><code>Forest$add_numeric_split_tree()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-get_tree_leaves"><code>Forest$get_tree_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-get_tree_split_counts"><code>Forest$get_tree_split_counts()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-get_forest_split_counts"><code>Forest$get_forest_split_counts()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-tree_max_depth"><code>Forest$tree_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-average_max_depth"><code>Forest$average_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-Forest-is_empty"><code>Forest$is_empty()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Forest-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new Forest object.
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$new(
  num_trees,
  leaf_dimension = 1,
  is_leaf_constant = FALSE,
  is_exponentiated = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_trees</code></dt><dd><p>Number of trees in the forest</p>
</dd>
<dt><code>leaf_dimension</code></dt><dd><p>Dimensionality of the outcome model</p>
</dd>
<dt><code>is_leaf_constant</code></dt><dd><p>Whether leaf is constant</p>
</dd>
<dt><code>is_exponentiated</code></dt><dd><p>Whether forest predictions should be exponentiated before being returned</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>Forest</code> object.
</p>


<hr>
<a id="method-Forest-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict forest on every sample in <code>forest_dataset</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$predict(forest_dataset)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> R class</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>vector of predictions with as many rows as in <code>forest_dataset</code>
</p>


<hr>
<a id="method-Forest-predict_raw"></a>



<h4>Method <code>predict_raw()</code></h4>

<p>Predict &quot;raw&quot; leaf values (without being multiplied by basis) for every sample in <code>forest_dataset</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$predict_raw(forest_dataset)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> R class</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Array of predictions for each observation in <code>forest_dataset</code> and
each sample in the <code>ForestSamples</code> class with each prediction having the
dimensionality of the forests' leaf model. In the case of a constant leaf model
or univariate leaf regression, this array is a vector (length is the number of
observations). In the case of a multivariate leaf regression,
this array is a matrix (number of observations by leaf model dimension,
number of samples).
</p>


<hr>
<a id="method-Forest-set_root_leaves"></a>



<h4>Method <code>set_root_leaves()</code></h4>

<p>Set a constant predicted value for every tree in the ensemble.
Stops program if any tree is more than a root node.
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$set_root_leaves(leaf_value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>leaf_value</code></dt><dd><p>Constant leaf value(s) to be fixed for each tree in the ensemble indexed by <code>forest_num</code>. Can be either a single number or a vector, depending on the forest's leaf dimension.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-prepare_for_sampler"></a>



<h4>Method <code>prepare_for_sampler()</code></h4>

<p>Set a constant predicted value for every tree in the ensemble.
Stops program if any tree is more than a root node.
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$prepare_for_sampler(
  dataset,
  outcome,
  forest_model,
  leaf_model_int,
  leaf_value
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dataset</code></dt><dd><p><code>ForestDataset</code> Dataset class (covariates, basis, etc...)</p>
</dd>
<dt><code>outcome</code></dt><dd><p><code>Outcome</code> Outcome class (residual / partial residual)</p>
</dd>
<dt><code>forest_model</code></dt><dd><p><code>ForestModel</code> object storing tracking structures used in training / sampling</p>
</dd>
<dt><code>leaf_model_int</code></dt><dd><p>Integer value encoding the leaf model type (0 = constant gaussian, 1 = univariate gaussian, 2 = multivariate gaussian, 3 = log linear variance).</p>
</dd>
<dt><code>leaf_value</code></dt><dd><p>Constant leaf value(s) to be fixed for each tree in the ensemble indexed by <code>forest_num</code>. Can be either a single number or a vector, depending on the forest's leaf dimension.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-adjust_residual"></a>



<h4>Method <code>adjust_residual()</code></h4>

<p>Adjusts residual based on the predictions of a forest
</p>
<p>This is typically run just once at the beginning of a forest sampling algorithm.
After trees are initialized with constant root node predictions, their root predictions are subtracted out of the residual.
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$adjust_residual(dataset, outcome, forest_model, requires_basis, add)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dataset</code></dt><dd><p><code>ForestDataset</code> object storing the covariates and bases for a given forest</p>
</dd>
<dt><code>outcome</code></dt><dd><p><code>Outcome</code> object storing the residuals to be updated based on forest predictions</p>
</dd>
<dt><code>forest_model</code></dt><dd><p><code>ForestModel</code> object storing tracking structures used in training / sampling</p>
</dd>
<dt><code>requires_basis</code></dt><dd><p>Whether or not a forest requires a basis for prediction</p>
</dd>
<dt><code>add</code></dt><dd><p>Whether forest predictions should be added to or subtracted from residuals</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-num_trees"></a>



<h4>Method <code>num_trees()</code></h4>

<p>Return number of trees in each ensemble of a <code>Forest</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$num_trees()</pre></div>



<h5>Returns</h5>

<p>Tree count
</p>


<hr>
<a id="method-Forest-leaf_dimension"></a>



<h4>Method <code>leaf_dimension()</code></h4>

<p>Return output dimension of trees in a <code>Forest</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$leaf_dimension()</pre></div>



<h5>Returns</h5>

<p>Leaf node parameter size
</p>


<hr>
<a id="method-Forest-is_constant_leaf"></a>



<h4>Method <code>is_constant_leaf()</code></h4>

<p>Return constant leaf status of trees in a <code>Forest</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$is_constant_leaf()</pre></div>



<h5>Returns</h5>

<p><code>TRUE</code> if leaves are constant, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-Forest-is_exponentiated"></a>



<h4>Method <code>is_exponentiated()</code></h4>

<p>Return exponentiation status of trees in a <code>Forest</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$is_exponentiated()</pre></div>



<h5>Returns</h5>

<p><code>TRUE</code> if leaf predictions must be exponentiated, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-Forest-add_numeric_split_tree"></a>



<h4>Method <code>add_numeric_split_tree()</code></h4>

<p>Add a numeric (i.e. <code>X[,i] &lt;= c</code>) split to a given tree in the ensemble
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$add_numeric_split_tree(
  tree_num,
  leaf_num,
  feature_num,
  split_threshold,
  left_leaf_value,
  right_leaf_value
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be split</p>
</dd>
<dt><code>leaf_num</code></dt><dd><p>Leaf to be split</p>
</dd>
<dt><code>feature_num</code></dt><dd><p>Feature that defines the new split</p>
</dd>
<dt><code>split_threshold</code></dt><dd><p>Value that defines the cutoff of the new split</p>
</dd>
<dt><code>left_leaf_value</code></dt><dd><p>Value (or vector of values) to assign to the newly created left node</p>
</dd>
<dt><code>right_leaf_value</code></dt><dd><p>Value (or vector of values) to assign to the newly created right node</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-get_tree_leaves"></a>



<h4>Method <code>get_tree_leaves()</code></h4>

<p>Retrieve a vector of indices of leaf nodes for a given tree in a given forest
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$get_tree_leaves(tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>tree_num</code></dt><dd><p>Index of the tree for which leaf indices will be retrieved</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-get_tree_split_counts"></a>



<h4>Method <code>get_tree_split_counts()</code></h4>

<p>Retrieve a vector of split counts for every training set variable in a given tree in the forest
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$get_tree_split_counts(tree_num, num_features)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>tree_num</code></dt><dd><p>Index of the tree for which split counts will be retrieved</p>
</dd>
<dt><code>num_features</code></dt><dd><p>Total number of features in the training set</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-get_forest_split_counts"></a>



<h4>Method <code>get_forest_split_counts()</code></h4>

<p>Retrieve a vector of split counts for every training set variable in the forest
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$get_forest_split_counts(num_features)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_features</code></dt><dd><p>Total number of features in the training set</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Forest-tree_max_depth"></a>



<h4>Method <code>tree_max_depth()</code></h4>

<p>Maximum depth of a specific tree in the forest
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$tree_max_depth(tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>tree_num</code></dt><dd><p>Tree index within forest</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Maximum leaf depth
</p>


<hr>
<a id="method-Forest-average_max_depth"></a>



<h4>Method <code>average_max_depth()</code></h4>

<p>Average the maximum depth of each tree in the forest
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$average_max_depth()</pre></div>



<h5>Returns</h5>

<p>Average maximum depth
</p>


<hr>
<a id="method-Forest-is_empty"></a>



<h4>Method <code>is_empty()</code></h4>

<p>When a forest object is created, it is &quot;empty&quot; in the sense that none
of its component trees have leaves with values. There are two ways to
&quot;initialize&quot; a Forest object. First, the <code>set_root_leaves()</code> method
simply initializes every tree in the forest to a single node carrying
the same (user-specified) leaf value. Second, the <code>prepare_for_sampler()</code>
method initializes every tree in the forest to a single node with the
same value and also propagates this information through to a ForestModel
object, which must be synchronized with a Forest during a forest
sampler loop.
</p>


<h5>Usage</h5>

<div class="r"><pre>Forest$is_empty()</pre></div>



<h5>Returns</h5>

<p><code>TRUE</code> if a Forest has not yet been initialized with a constant
root value, <code>FALSE</code> otherwise if the forest has already been
initialized / grown.
</p>



<hr>
<h2 id='ForestDataset'>Dataset used to sample a forest</h2><span id='topic+ForestDataset'></span>

<h3>Description</h3>

<p>A dataset consists of three matrices / vectors: covariates,
bases, and variance weights. Both the basis vector and variance
weights are optional.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>data_ptr</code></dt><dd><p>External pointer to a C++ ForestDataset class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ForestDataset-new"><code>ForestDataset$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestDataset-update_basis"><code>ForestDataset$update_basis()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestDataset-num_observations"><code>ForestDataset$num_observations()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestDataset-num_covariates"><code>ForestDataset$num_covariates()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestDataset-num_basis"><code>ForestDataset$num_basis()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestDataset-has_basis"><code>ForestDataset$has_basis()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestDataset-has_variance_weights"><code>ForestDataset$has_variance_weights()</code></a>
</p>
</li></ul>


<hr>
<a id="method-ForestDataset-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new ForestDataset object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$new(covariates, basis = NULL, variance_weights = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>covariates</code></dt><dd><p>Matrix of covariates</p>
</dd>
<dt><code>basis</code></dt><dd><p>(Optional) Matrix of bases used to define a leaf regression</p>
</dd>
<dt><code>variance_weights</code></dt><dd><p>(Optional) Vector of observation-specific variance weights</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>ForestDataset</code> object.
</p>


<hr>
<a id="method-ForestDataset-update_basis"></a>



<h4>Method <code>update_basis()</code></h4>

<p>Update basis matrix in a dataset
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$update_basis(basis)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>basis</code></dt><dd><p>Updated matrix of bases used to define a leaf regression</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestDataset-num_observations"></a>



<h4>Method <code>num_observations()</code></h4>

<p>Return number of observations in a <code>ForestDataset</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$num_observations()</pre></div>



<h5>Returns</h5>

<p>Observation count
</p>


<hr>
<a id="method-ForestDataset-num_covariates"></a>



<h4>Method <code>num_covariates()</code></h4>

<p>Return number of covariates in a <code>ForestDataset</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$num_covariates()</pre></div>



<h5>Returns</h5>

<p>Covariate count
</p>


<hr>
<a id="method-ForestDataset-num_basis"></a>



<h4>Method <code>num_basis()</code></h4>

<p>Return number of bases in a <code>ForestDataset</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$num_basis()</pre></div>



<h5>Returns</h5>

<p>Basis count
</p>


<hr>
<a id="method-ForestDataset-has_basis"></a>



<h4>Method <code>has_basis()</code></h4>

<p>Whether or not a dataset has a basis matrix
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$has_basis()</pre></div>



<h5>Returns</h5>

<p>True if basis matrix is loaded, false otherwise
</p>


<hr>
<a id="method-ForestDataset-has_variance_weights"></a>



<h4>Method <code>has_variance_weights()</code></h4>

<p>Whether or not a dataset has variance weights
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestDataset$has_variance_weights()</pre></div>



<h5>Returns</h5>

<p>True if variance weights are loaded, false otherwise
</p>



<hr>
<h2 id='ForestModel'>Class that defines and samples a forest model</h2><span id='topic+ForestModel'></span>

<h3>Description</h3>

<p>Hosts the C++ data structures needed to sample an ensemble of decision
trees, and exposes functionality to run a forest sampler
(using either MCMC or the grow-from-root algorithm).
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>tracker_ptr</code></dt><dd><p>External pointer to a C++ ForestTracker class</p>
</dd>
<dt><code>tree_prior_ptr</code></dt><dd><p>External pointer to a C++ TreePrior class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ForestModel-new"><code>ForestModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-sample_one_iteration"><code>ForestModel$sample_one_iteration()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-propagate_basis_update"><code>ForestModel$propagate_basis_update()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-propagate_residual_update"><code>ForestModel$propagate_residual_update()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-update_alpha"><code>ForestModel$update_alpha()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-update_beta"><code>ForestModel$update_beta()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-update_min_samples_leaf"><code>ForestModel$update_min_samples_leaf()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModel-update_max_depth"><code>ForestModel$update_max_depth()</code></a>
</p>
</li></ul>


<hr>
<a id="method-ForestModel-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new ForestModel object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$new(
  forest_dataset,
  feature_types,
  num_trees,
  n,
  alpha,
  beta,
  min_samples_leaf,
  max_depth = -1
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> object, used to initialize forest sampling data structures</p>
</dd>
<dt><code>feature_types</code></dt><dd><p>Feature types (integers where 0 = numeric, 1 = ordered categorical, 2 = unordered categorical)</p>
</dd>
<dt><code>num_trees</code></dt><dd><p>Number of trees in the forest being sampled</p>
</dd>
<dt><code>n</code></dt><dd><p>Number of observations in <code>forest_dataset</code></p>
</dd>
<dt><code>alpha</code></dt><dd><p>Root node split probability in tree prior</p>
</dd>
<dt><code>beta</code></dt><dd><p>Depth prior penalty in tree prior</p>
</dd>
<dt><code>min_samples_leaf</code></dt><dd><p>Minimum number of samples in a tree leaf</p>
</dd>
<dt><code>max_depth</code></dt><dd><p>Maximum depth that any tree can reach</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>ForestModel</code> object.
</p>


<hr>
<a id="method-ForestModel-sample_one_iteration"></a>



<h4>Method <code>sample_one_iteration()</code></h4>

<p>Run a single iteration of the forest sampling algorithm (MCMC or GFR)
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$sample_one_iteration(
  forest_dataset,
  residual,
  forest_samples,
  active_forest,
  rng,
  forest_model_config,
  global_model_config,
  keep_forest = TRUE,
  gfr = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p>Dataset used to sample the forest</p>
</dd>
<dt><code>residual</code></dt><dd><p>Outcome used to sample the forest</p>
</dd>
<dt><code>forest_samples</code></dt><dd><p>Container of forest samples</p>
</dd>
<dt><code>active_forest</code></dt><dd><p>&quot;Active&quot; forest updated by the sampler in each iteration</p>
</dd>
<dt><code>rng</code></dt><dd><p>Wrapper around C++ random number generator</p>
</dd>
<dt><code>forest_model_config</code></dt><dd><p>ForestModelConfig object containing forest model parameters and settings</p>
</dd>
<dt><code>global_model_config</code></dt><dd><p>GlobalModelConfig object containing global model parameters and settings</p>
</dd>
<dt><code>keep_forest</code></dt><dd><p>(Optional) Whether the updated forest sample should be saved to <code>forest_samples</code>. Default: <code>TRUE</code>.</p>
</dd>
<dt><code>gfr</code></dt><dd><p>(Optional) Whether or not the forest should be sampled using the &quot;grow-from-root&quot; (GFR) algorithm. Default: <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModel-propagate_basis_update"></a>



<h4>Method <code>propagate_basis_update()</code></h4>

<p>Propagates basis update through to the (full/partial) residual by iteratively
(a) adding back in the previous prediction of each tree, (b) recomputing predictions
for each tree (caching on the C++ side), (c) subtracting the new predictions from the residual.
</p>
<p>This is useful in cases where a basis (for e.g. leaf regression) is updated outside
of a tree sampler (as with e.g. adaptive coding for binary treatment BCF).
Once a basis has been updated, the overall &quot;function&quot; represented by a tree model has
changed and this should be reflected through to the residual before the next sampling loop is run.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$propagate_basis_update(dataset, outcome, active_forest)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dataset</code></dt><dd><p><code>ForestDataset</code> object storing the covariates and bases for a given forest</p>
</dd>
<dt><code>outcome</code></dt><dd><p><code>Outcome</code> object storing the residuals to be updated based on forest predictions</p>
</dd>
<dt><code>active_forest</code></dt><dd><p>&quot;Active&quot; forest updated by the sampler in each iteration</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModel-propagate_residual_update"></a>



<h4>Method <code>propagate_residual_update()</code></h4>

<p>Update the current state of the outcome (i.e. partial residual) data by subtracting the current predictions of each tree.
This function is run after the <code>Outcome</code> class's <code>update_data</code> method, which overwrites the partial residual with an entirely new stream of outcome data.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$propagate_residual_update(residual)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>residual</code></dt><dd><p>Outcome used to sample the forest</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-ForestModel-update_alpha"></a>



<h4>Method <code>update_alpha()</code></h4>

<p>Update alpha in the tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$update_alpha(alpha)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>alpha</code></dt><dd><p>New value of alpha to be used</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-ForestModel-update_beta"></a>



<h4>Method <code>update_beta()</code></h4>

<p>Update beta in the tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$update_beta(beta)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>beta</code></dt><dd><p>New value of beta to be used</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-ForestModel-update_min_samples_leaf"></a>



<h4>Method <code>update_min_samples_leaf()</code></h4>

<p>Update min_samples_leaf in the tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$update_min_samples_leaf(min_samples_leaf)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>min_samples_leaf</code></dt><dd><p>New value of min_samples_leaf to be used</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-ForestModel-update_max_depth"></a>



<h4>Method <code>update_max_depth()</code></h4>

<p>Update max_depth in the tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModel$update_max_depth(max_depth)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>max_depth</code></dt><dd><p>New value of max_depth to be used</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>



<hr>
<h2 id='ForestModelConfig'>Object used to get / set parameters and other model configuration options
for a forest model in the &quot;low-level&quot; stochtree interface</h2><span id='topic+ForestModelConfig'></span>

<h3>Description</h3>

<p>The &quot;low-level&quot; stochtree interface enables a high degreee of sampler
customization, in which users employ R wrappers around C++ objects
like ForestDataset, Outcome, CppRng, and ForestModel to run the
Gibbs sampler of a BART model with custom modifications.
ForestModelConfig allows users to specify / query the parameters of a
forest model they wish to run.
</p>


<h3>Value</h3>

<p>Vector of integer-coded feature types (integers where 0 = numeric, 1 = ordered categorical, 2 = unordered categorical)
</p>
<p>Vector specifying sampling probability for all p covariates in ForestDataset
</p>
<p>Root node split probability in tree prior
</p>
<p>Depth prior penalty in tree prior
</p>
<p>Minimum number of samples in a tree leaf
</p>
<p>Maximum depth of any tree in the ensemble in the model
</p>
<p>Scale parameter used in Gaussian leaf models
</p>
<p>Shape parameter for IG leaf models
</p>
<p>Scale parameter for IG leaf models
</p>
<p>Number of unique cutpoints to consider
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>feature_types</code></dt><dd><p>Vector of integer-coded feature types (integers where 0 = numeric, 1 = ordered categorical, 2 = unordered categorical)</p>
</dd>
<dt><code>num_trees</code></dt><dd><p>Number of trees in the forest being sampled</p>
</dd>
<dt><code>num_features</code></dt><dd><p>Number of features in training dataset</p>
</dd>
<dt><code>num_observations</code></dt><dd><p>Number of observations in training dataset</p>
</dd>
<dt><code>leaf_dimension</code></dt><dd><p>Dimension of the leaf model</p>
</dd>
<dt><code>alpha</code></dt><dd><p>Root node split probability in tree prior</p>
</dd>
<dt><code>beta</code></dt><dd><p>Depth prior penalty in tree prior</p>
</dd>
<dt><code>min_samples_leaf</code></dt><dd><p>Minimum number of samples in a tree leaf</p>
</dd>
<dt><code>max_depth</code></dt><dd><p>Maximum depth of any tree in the ensemble in the model. Setting to <code>-1</code> does not enforce any depth limits on trees.</p>
</dd>
<dt><code>leaf_model_type</code></dt><dd><p>Integer specifying the leaf model type (0 = constant leaf, 1 = univariate leaf regression, 2 = multivariate leaf regression)</p>
</dd>
<dt><code>leaf_model_scale</code></dt><dd><p>Scale parameter used in Gaussian leaf models</p>
</dd>
<dt><code>variable_weights</code></dt><dd><p>Vector specifying sampling probability for all p covariates in ForestDataset</p>
</dd>
<dt><code>variance_forest_shape</code></dt><dd><p>Shape parameter for IG leaf models (applicable when <code>leaf_model_type = 3</code>)</p>
</dd>
<dt><code>variance_forest_scale</code></dt><dd><p>Scale parameter for IG leaf models (applicable when <code>leaf_model_type = 3</code>)</p>
</dd>
<dt><code>cutpoint_grid_size</code></dt><dd><p>Number of unique cutpoints to consider
Create a new ForestModelConfig object.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ForestModelConfig-new"><code>ForestModelConfig$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_feature_types"><code>ForestModelConfig$update_feature_types()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_variable_weights"><code>ForestModelConfig$update_variable_weights()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_alpha"><code>ForestModelConfig$update_alpha()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_beta"><code>ForestModelConfig$update_beta()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_min_samples_leaf"><code>ForestModelConfig$update_min_samples_leaf()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_max_depth"><code>ForestModelConfig$update_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_leaf_model_scale"><code>ForestModelConfig$update_leaf_model_scale()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_variance_forest_shape"><code>ForestModelConfig$update_variance_forest_shape()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_variance_forest_scale"><code>ForestModelConfig$update_variance_forest_scale()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-update_cutpoint_grid_size"><code>ForestModelConfig$update_cutpoint_grid_size()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_feature_types"><code>ForestModelConfig$get_feature_types()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_variable_weights"><code>ForestModelConfig$get_variable_weights()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_alpha"><code>ForestModelConfig$get_alpha()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_beta"><code>ForestModelConfig$get_beta()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_min_samples_leaf"><code>ForestModelConfig$get_min_samples_leaf()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_max_depth"><code>ForestModelConfig$get_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_leaf_model_scale"><code>ForestModelConfig$get_leaf_model_scale()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_variance_forest_shape"><code>ForestModelConfig$get_variance_forest_shape()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_variance_forest_scale"><code>ForestModelConfig$get_variance_forest_scale()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestModelConfig-get_cutpoint_grid_size"><code>ForestModelConfig$get_cutpoint_grid_size()</code></a>
</p>
</li></ul>


<hr>
<a id="method-ForestModelConfig-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$new(
  feature_types = NULL,
  num_trees = NULL,
  num_features = NULL,
  num_observations = NULL,
  variable_weights = NULL,
  leaf_dimension = 1,
  alpha = 0.95,
  beta = 2,
  min_samples_leaf = 5,
  max_depth = -1,
  leaf_model_type = 1,
  leaf_model_scale = NULL,
  variance_forest_shape = 1,
  variance_forest_scale = 1,
  cutpoint_grid_size = 100
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>feature_types</code></dt><dd><p>Vector of integer-coded feature types (integers where 0 = numeric, 1 = ordered categorical, 2 = unordered categorical)</p>
</dd>
<dt><code>num_trees</code></dt><dd><p>Number of trees in the forest being sampled</p>
</dd>
<dt><code>num_features</code></dt><dd><p>Number of features in training dataset</p>
</dd>
<dt><code>num_observations</code></dt><dd><p>Number of observations in training dataset</p>
</dd>
<dt><code>variable_weights</code></dt><dd><p>Vector specifying sampling probability for all p covariates in ForestDataset</p>
</dd>
<dt><code>leaf_dimension</code></dt><dd><p>Dimension of the leaf model (default: <code>1</code>)</p>
</dd>
<dt><code>alpha</code></dt><dd><p>Root node split probability in tree prior (default: <code>0.95</code>)</p>
</dd>
<dt><code>beta</code></dt><dd><p>Depth prior penalty in tree prior (default: <code>2.0</code>)</p>
</dd>
<dt><code>min_samples_leaf</code></dt><dd><p>Minimum number of samples in a tree leaf (default: <code>5</code>)</p>
</dd>
<dt><code>max_depth</code></dt><dd><p>Maximum depth of any tree in the ensemble in the model. Setting to <code>-1</code> does not enforce any depth limits on trees. Default: <code>-1</code>.</p>
</dd>
<dt><code>leaf_model_type</code></dt><dd><p>Integer specifying the leaf model type (0 = constant leaf, 1 = univariate leaf regression, 2 = multivariate leaf regression). Default: <code>0</code>.</p>
</dd>
<dt><code>leaf_model_scale</code></dt><dd><p>Scale parameter used in Gaussian leaf models (can either be a scalar or a q x q matrix, where q is the dimensionality of the basis and is only &gt;1 when <code>leaf_model_int = 2</code>). Calibrated internally as <code>1/num_trees</code>, propagated along diagonal if needed for multivariate leaf models.</p>
</dd>
<dt><code>variance_forest_shape</code></dt><dd><p>Shape parameter for IG leaf models (applicable when <code>leaf_model_type = 3</code>). Default: <code>1</code>.</p>
</dd>
<dt><code>variance_forest_scale</code></dt><dd><p>Scale parameter for IG leaf models (applicable when <code>leaf_model_type = 3</code>). Default: <code>1</code>.</p>
</dd>
<dt><code>cutpoint_grid_size</code></dt><dd><p>Number of unique cutpoints to consider (default: <code>100</code>)</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new ForestModelConfig object.
</p>


<hr>
<a id="method-ForestModelConfig-update_feature_types"></a>



<h4>Method <code>update_feature_types()</code></h4>

<p>Update feature types
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_feature_types(feature_types)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>feature_types</code></dt><dd><p>Vector of integer-coded feature types (integers where 0 = numeric, 1 = ordered categorical, 2 = unordered categorical)</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_variable_weights"></a>



<h4>Method <code>update_variable_weights()</code></h4>

<p>Update variable weights
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_variable_weights(variable_weights)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>variable_weights</code></dt><dd><p>Vector specifying sampling probability for all p covariates in ForestDataset</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_alpha"></a>



<h4>Method <code>update_alpha()</code></h4>

<p>Update root node split probability in tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_alpha(alpha)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>alpha</code></dt><dd><p>Root node split probability in tree prior</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_beta"></a>



<h4>Method <code>update_beta()</code></h4>

<p>Update depth prior penalty in tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_beta(beta)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>beta</code></dt><dd><p>Depth prior penalty in tree prior</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_min_samples_leaf"></a>



<h4>Method <code>update_min_samples_leaf()</code></h4>

<p>Update root node split probability in tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_min_samples_leaf(min_samples_leaf)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>min_samples_leaf</code></dt><dd><p>Minimum number of samples in a tree leaf</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_max_depth"></a>



<h4>Method <code>update_max_depth()</code></h4>

<p>Update root node split probability in tree prior
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_max_depth(max_depth)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>max_depth</code></dt><dd><p>Maximum depth of any tree in the ensemble in the model</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_leaf_model_scale"></a>



<h4>Method <code>update_leaf_model_scale()</code></h4>

<p>Update scale parameter used in Gaussian leaf models
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_leaf_model_scale(leaf_model_scale)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>leaf_model_scale</code></dt><dd><p>Scale parameter used in Gaussian leaf models</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_variance_forest_shape"></a>



<h4>Method <code>update_variance_forest_shape()</code></h4>

<p>Update shape parameter for IG leaf models
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_variance_forest_shape(variance_forest_shape)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>variance_forest_shape</code></dt><dd><p>Shape parameter for IG leaf models</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_variance_forest_scale"></a>



<h4>Method <code>update_variance_forest_scale()</code></h4>

<p>Update scale parameter for IG leaf models
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_variance_forest_scale(variance_forest_scale)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>variance_forest_scale</code></dt><dd><p>Scale parameter for IG leaf models</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-update_cutpoint_grid_size"></a>



<h4>Method <code>update_cutpoint_grid_size()</code></h4>

<p>Update number of unique cutpoints to consider
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$update_cutpoint_grid_size(cutpoint_grid_size)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>cutpoint_grid_size</code></dt><dd><p>Number of unique cutpoints to consider</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestModelConfig-get_feature_types"></a>



<h4>Method <code>get_feature_types()</code></h4>

<p>Query feature types for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_feature_types()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_variable_weights"></a>



<h4>Method <code>get_variable_weights()</code></h4>

<p>Query variable weights for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_variable_weights()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_alpha"></a>



<h4>Method <code>get_alpha()</code></h4>

<p>Query root node split probability in tree prior for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_alpha()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_beta"></a>



<h4>Method <code>get_beta()</code></h4>

<p>Query depth prior penalty in tree prior for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_beta()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_min_samples_leaf"></a>



<h4>Method <code>get_min_samples_leaf()</code></h4>

<p>Query root node split probability in tree prior for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_min_samples_leaf()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_max_depth"></a>



<h4>Method <code>get_max_depth()</code></h4>

<p>Query root node split probability in tree prior for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_max_depth()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_leaf_model_scale"></a>



<h4>Method <code>get_leaf_model_scale()</code></h4>

<p>Query scale parameter used in Gaussian leaf models for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_leaf_model_scale()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_variance_forest_shape"></a>



<h4>Method <code>get_variance_forest_shape()</code></h4>

<p>Query shape parameter for IG leaf models for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_variance_forest_shape()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_variance_forest_scale"></a>



<h4>Method <code>get_variance_forest_scale()</code></h4>

<p>Query scale parameter for IG leaf models for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_variance_forest_scale()</pre></div>


<hr>
<a id="method-ForestModelConfig-get_cutpoint_grid_size"></a>



<h4>Method <code>get_cutpoint_grid_size()</code></h4>

<p>Query number of unique cutpoints to consider for this ForestModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestModelConfig$get_cutpoint_grid_size()</pre></div>



<hr>
<h2 id='ForestSamples'>Class that stores draws from an random ensemble of decision trees</h2><span id='topic+ForestSamples'></span>

<h3>Description</h3>

<p>Wrapper around a C++ container of tree ensembles
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>forest_container_ptr</code></dt><dd><p>External pointer to a C++ ForestContainer class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ForestSamples-new"><code>ForestSamples$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-load_from_json"><code>ForestSamples$load_from_json()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-append_from_json"><code>ForestSamples$append_from_json()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-load_from_json_string"><code>ForestSamples$load_from_json_string()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-append_from_json_string"><code>ForestSamples$append_from_json_string()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-predict"><code>ForestSamples$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-predict_raw"><code>ForestSamples$predict_raw()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-predict_raw_single_forest"><code>ForestSamples$predict_raw_single_forest()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-predict_raw_single_tree"><code>ForestSamples$predict_raw_single_tree()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-set_root_leaves"><code>ForestSamples$set_root_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-prepare_for_sampler"><code>ForestSamples$prepare_for_sampler()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-adjust_residual"><code>ForestSamples$adjust_residual()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-save_json"><code>ForestSamples$save_json()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-load_json"><code>ForestSamples$load_json()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_samples"><code>ForestSamples$num_samples()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_trees"><code>ForestSamples$num_trees()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-leaf_dimension"><code>ForestSamples$leaf_dimension()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-is_constant_leaf"><code>ForestSamples$is_constant_leaf()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-is_exponentiated"><code>ForestSamples$is_exponentiated()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-add_forest_with_constant_leaves"><code>ForestSamples$add_forest_with_constant_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-add_numeric_split_tree"><code>ForestSamples$add_numeric_split_tree()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-get_tree_leaves"><code>ForestSamples$get_tree_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-get_tree_split_counts"><code>ForestSamples$get_tree_split_counts()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-get_forest_split_counts"><code>ForestSamples$get_forest_split_counts()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-get_aggregate_split_counts"><code>ForestSamples$get_aggregate_split_counts()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-get_granular_split_counts"><code>ForestSamples$get_granular_split_counts()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-ensemble_tree_max_depth"><code>ForestSamples$ensemble_tree_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-average_ensemble_max_depth"><code>ForestSamples$average_ensemble_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-average_max_depth"><code>ForestSamples$average_max_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_forest_leaves"><code>ForestSamples$num_forest_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-sum_leaves_squared"><code>ForestSamples$sum_leaves_squared()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-is_leaf_node"><code>ForestSamples$is_leaf_node()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-is_numeric_split_node"><code>ForestSamples$is_numeric_split_node()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-is_categorical_split_node"><code>ForestSamples$is_categorical_split_node()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-parent_node"><code>ForestSamples$parent_node()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-left_child_node"><code>ForestSamples$left_child_node()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-right_child_node"><code>ForestSamples$right_child_node()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-node_depth"><code>ForestSamples$node_depth()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-node_split_index"><code>ForestSamples$node_split_index()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-node_split_threshold"><code>ForestSamples$node_split_threshold()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-node_split_categories"><code>ForestSamples$node_split_categories()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-node_leaf_values"><code>ForestSamples$node_leaf_values()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_nodes"><code>ForestSamples$num_nodes()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_leaves"><code>ForestSamples$num_leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_leaf_parents"><code>ForestSamples$num_leaf_parents()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-num_split_nodes"><code>ForestSamples$num_split_nodes()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-nodes"><code>ForestSamples$nodes()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-leaves"><code>ForestSamples$leaves()</code></a>
</p>
</li>
<li> <p><a href="#method-ForestSamples-delete_sample"><code>ForestSamples$delete_sample()</code></a>
</p>
</li></ul>


<hr>
<a id="method-ForestSamples-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new ForestContainer object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$new(
  num_trees,
  leaf_dimension = 1,
  is_leaf_constant = FALSE,
  is_exponentiated = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_trees</code></dt><dd><p>Number of trees</p>
</dd>
<dt><code>leaf_dimension</code></dt><dd><p>Dimensionality of the outcome model</p>
</dd>
<dt><code>is_leaf_constant</code></dt><dd><p>Whether leaf is constant</p>
</dd>
<dt><code>is_exponentiated</code></dt><dd><p>Whether forest predictions should be exponentiated before being returned</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>ForestContainer</code> object.
</p>


<hr>
<a id="method-ForestSamples-load_from_json"></a>



<h4>Method <code>load_from_json()</code></h4>

<p>Create a new <code>ForestContainer</code> object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$load_from_json(json_object, json_forest_label)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_object</code></dt><dd><p>Object of class <code>CppJson</code></p>
</dd>
<dt><code>json_forest_label</code></dt><dd><p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>ForestContainer</code> object.
</p>


<hr>
<a id="method-ForestSamples-append_from_json"></a>



<h4>Method <code>append_from_json()</code></h4>

<p>Append to a <code>ForestContainer</code> object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$append_from_json(json_object, json_forest_label)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_object</code></dt><dd><p>Object of class <code>CppJson</code></p>
</dd>
<dt><code>json_forest_label</code></dt><dd><p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-ForestSamples-load_from_json_string"></a>



<h4>Method <code>load_from_json_string()</code></h4>

<p>Create a new <code>ForestContainer</code> object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$load_from_json_string(json_string, json_forest_label)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_string</code></dt><dd><p>JSON string which parses into object of class <code>CppJson</code></p>
</dd>
<dt><code>json_forest_label</code></dt><dd><p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>ForestContainer</code> object.
</p>


<hr>
<a id="method-ForestSamples-append_from_json_string"></a>



<h4>Method <code>append_from_json_string()</code></h4>

<p>Append to a <code>ForestContainer</code> object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$append_from_json_string(json_string, json_forest_label)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_string</code></dt><dd><p>JSON string which parses into object of class <code>CppJson</code></p>
</dd>
<dt><code>json_forest_label</code></dt><dd><p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-ForestSamples-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict every tree ensemble on every sample in <code>forest_dataset</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$predict(forest_dataset)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> R class</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>matrix of predictions with as many rows as in forest_dataset
and as many columns as samples in the <code>ForestContainer</code>
</p>


<hr>
<a id="method-ForestSamples-predict_raw"></a>



<h4>Method <code>predict_raw()</code></h4>

<p>Predict &quot;raw&quot; leaf values (without being multiplied by basis) for every tree ensemble on every sample in <code>forest_dataset</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$predict_raw(forest_dataset)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> R class</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Array of predictions for each observation in <code>forest_dataset</code> and
each sample in the <code>ForestSamples</code> class with each prediction having the
dimensionality of the forests' leaf model. In the case of a constant leaf model
or univariate leaf regression, this array is two-dimensional (number of observations,
number of forest samples). In the case of a multivariate leaf regression,
this array is three-dimension (number of observations, leaf model dimension,
number of samples).
</p>


<hr>
<a id="method-ForestSamples-predict_raw_single_forest"></a>



<h4>Method <code>predict_raw_single_forest()</code></h4>

<p>Predict &quot;raw&quot; leaf values (without being multiplied by basis) for a specific forest on every sample in <code>forest_dataset</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$predict_raw_single_forest(forest_dataset, forest_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> R class</p>
</dd>
<dt><code>forest_num</code></dt><dd><p>Index of the forest sample within the container</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>matrix of predictions with as many rows as in forest_dataset
and as many columns as dimensions in the leaves of trees in <code>ForestContainer</code>
</p>


<hr>
<a id="method-ForestSamples-predict_raw_single_tree"></a>



<h4>Method <code>predict_raw_single_tree()</code></h4>

<p>Predict &quot;raw&quot; leaf values (without being multiplied by basis) for a specific tree in a specific forest on every observation in <code>forest_dataset</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$predict_raw_single_tree(forest_dataset, forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_dataset</code></dt><dd><p><code>ForestDataset</code> R class</p>
</dd>
<dt><code>forest_num</code></dt><dd><p>Index of the forest sample within the container</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>matrix of predictions with as many rows as in <code>forest_dataset</code>
and as many columns as dimensions in the leaves of trees in <code>ForestContainer</code>
</p>


<hr>
<a id="method-ForestSamples-set_root_leaves"></a>



<h4>Method <code>set_root_leaves()</code></h4>

<p>Set a constant predicted value for every tree in the ensemble.
Stops program if any tree is more than a root node.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$set_root_leaves(forest_num, leaf_value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest sample within the container.</p>
</dd>
<dt><code>leaf_value</code></dt><dd><p>Constant leaf value(s) to be fixed for each tree in the ensemble indexed by <code>forest_num</code>. Can be either a single number or a vector, depending on the forest's leaf dimension.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-prepare_for_sampler"></a>



<h4>Method <code>prepare_for_sampler()</code></h4>

<p>Set a constant predicted value for every tree in the ensemble.
Stops program if any tree is more than a root node.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$prepare_for_sampler(
  dataset,
  outcome,
  forest_model,
  leaf_model_int,
  leaf_value
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dataset</code></dt><dd><p><code>ForestDataset</code> Dataset class (covariates, basis, etc...)</p>
</dd>
<dt><code>outcome</code></dt><dd><p><code>Outcome</code> Outcome class (residual / partial residual)</p>
</dd>
<dt><code>forest_model</code></dt><dd><p><code>ForestModel</code> object storing tracking structures used in training / sampling</p>
</dd>
<dt><code>leaf_model_int</code></dt><dd><p>Integer value encoding the leaf model type (0 = constant gaussian, 1 = univariate gaussian, 2 = multivariate gaussian, 3 = log linear variance).</p>
</dd>
<dt><code>leaf_value</code></dt><dd><p>Constant leaf value(s) to be fixed for each tree in the ensemble indexed by <code>forest_num</code>. Can be either a single number or a vector, depending on the forest's leaf dimension.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-adjust_residual"></a>



<h4>Method <code>adjust_residual()</code></h4>

<p>Adjusts residual based on the predictions of a forest
</p>
<p>This is typically run just once at the beginning of a forest sampling algorithm.
After trees are initialized with constant root node predictions, their root predictions are subtracted out of the residual.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$adjust_residual(
  dataset,
  outcome,
  forest_model,
  requires_basis,
  forest_num,
  add
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dataset</code></dt><dd><p><code>ForestDataset</code> object storing the covariates and bases for a given forest</p>
</dd>
<dt><code>outcome</code></dt><dd><p><code>Outcome</code> object storing the residuals to be updated based on forest predictions</p>
</dd>
<dt><code>forest_model</code></dt><dd><p><code>ForestModel</code> object storing tracking structures used in training / sampling</p>
</dd>
<dt><code>requires_basis</code></dt><dd><p>Whether or not a forest requires a basis for prediction</p>
</dd>
<dt><code>forest_num</code></dt><dd><p>Index of forest used to update residuals</p>
</dd>
<dt><code>add</code></dt><dd><p>Whether forest predictions should be added to or subtracted from residuals</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-save_json"></a>



<h4>Method <code>save_json()</code></h4>

<p>Store the trees and metadata of <code>ForestDataset</code> class in a json file
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$save_json(json_filename)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_filename</code></dt><dd><p>Name of output json file (must end in &quot;.json&quot;)</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-load_json"></a>



<h4>Method <code>load_json()</code></h4>

<p>Load trees and metadata for an ensemble from a json file. Note that
any trees and metadata already present in <code>ForestDataset</code> class will
be overwritten.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$load_json(json_filename)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_filename</code></dt><dd><p>Name of model input json file (must end in &quot;.json&quot;)</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-num_samples"></a>



<h4>Method <code>num_samples()</code></h4>

<p>Return number of samples in a <code>ForestContainer</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_samples()</pre></div>



<h5>Returns</h5>

<p>Sample count
</p>


<hr>
<a id="method-ForestSamples-num_trees"></a>



<h4>Method <code>num_trees()</code></h4>

<p>Return number of trees in each ensemble of a <code>ForestContainer</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_trees()</pre></div>



<h5>Returns</h5>

<p>Tree count
</p>


<hr>
<a id="method-ForestSamples-leaf_dimension"></a>



<h4>Method <code>leaf_dimension()</code></h4>

<p>Return output dimension of trees in a <code>ForestContainer</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$leaf_dimension()</pre></div>



<h5>Returns</h5>

<p>Leaf node parameter size
</p>


<hr>
<a id="method-ForestSamples-is_constant_leaf"></a>



<h4>Method <code>is_constant_leaf()</code></h4>

<p>Return constant leaf status of trees in a <code>ForestContainer</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$is_constant_leaf()</pre></div>



<h5>Returns</h5>

<p><code>TRUE</code> if leaves are constant, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-ForestSamples-is_exponentiated"></a>



<h4>Method <code>is_exponentiated()</code></h4>

<p>Return exponentiation status of trees in a <code>ForestContainer</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$is_exponentiated()</pre></div>



<h5>Returns</h5>

<p><code>TRUE</code> if leaf predictions must be exponentiated, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-ForestSamples-add_forest_with_constant_leaves"></a>



<h4>Method <code>add_forest_with_constant_leaves()</code></h4>

<p>Add a new all-root ensemble to the container, with all of the leaves
set to the value / vector provided
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$add_forest_with_constant_leaves(leaf_value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>leaf_value</code></dt><dd><p>Value (or vector of values) to initialize root nodes in tree</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-add_numeric_split_tree"></a>



<h4>Method <code>add_numeric_split_tree()</code></h4>

<p>Add a numeric (i.e. <code>X[,i] &lt;= c</code>) split to a given tree in the ensemble
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$add_numeric_split_tree(
  forest_num,
  tree_num,
  leaf_num,
  feature_num,
  split_threshold,
  left_leaf_value,
  right_leaf_value
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest which contains the tree to be split</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be split</p>
</dd>
<dt><code>leaf_num</code></dt><dd><p>Leaf to be split</p>
</dd>
<dt><code>feature_num</code></dt><dd><p>Feature that defines the new split</p>
</dd>
<dt><code>split_threshold</code></dt><dd><p>Value that defines the cutoff of the new split</p>
</dd>
<dt><code>left_leaf_value</code></dt><dd><p>Value (or vector of values) to assign to the newly created left node</p>
</dd>
<dt><code>right_leaf_value</code></dt><dd><p>Value (or vector of values) to assign to the newly created right node</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-get_tree_leaves"></a>



<h4>Method <code>get_tree_leaves()</code></h4>

<p>Retrieve a vector of indices of leaf nodes for a given tree in a given forest
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$get_tree_leaves(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest which contains tree <code>tree_num</code></p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree for which leaf indices will be retrieved</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-get_tree_split_counts"></a>



<h4>Method <code>get_tree_split_counts()</code></h4>

<p>Retrieve a vector of split counts for every training set variable in a given tree in a given forest
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$get_tree_split_counts(forest_num, tree_num, num_features)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest which contains tree <code>tree_num</code></p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree for which split counts will be retrieved</p>
</dd>
<dt><code>num_features</code></dt><dd><p>Total number of features in the training set</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-get_forest_split_counts"></a>



<h4>Method <code>get_forest_split_counts()</code></h4>

<p>Retrieve a vector of split counts for every training set variable in a given forest
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$get_forest_split_counts(forest_num, num_features)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest for which split counts will be retrieved</p>
</dd>
<dt><code>num_features</code></dt><dd><p>Total number of features in the training set</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-get_aggregate_split_counts"></a>



<h4>Method <code>get_aggregate_split_counts()</code></h4>

<p>Retrieve a vector of split counts for every training set variable in a given forest, aggregated across ensembles and trees
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$get_aggregate_split_counts(num_features)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_features</code></dt><dd><p>Total number of features in the training set</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-get_granular_split_counts"></a>



<h4>Method <code>get_granular_split_counts()</code></h4>

<p>Retrieve a vector of split counts for every training set variable in a given forest, reported separately for each ensemble and tree
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$get_granular_split_counts(num_features)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_features</code></dt><dd><p>Total number of features in the training set</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ForestSamples-ensemble_tree_max_depth"></a>



<h4>Method <code>ensemble_tree_max_depth()</code></h4>

<p>Maximum depth of a specific tree in a specific ensemble in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$ensemble_tree_max_depth(ensemble_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>ensemble_num</code></dt><dd><p>Ensemble number</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Tree index within ensemble <code>ensemble_num</code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Maximum leaf depth
</p>


<hr>
<a id="method-ForestSamples-average_ensemble_max_depth"></a>



<h4>Method <code>average_ensemble_max_depth()</code></h4>

<p>Average the maximum depth of each tree in a given ensemble in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$average_ensemble_max_depth(ensemble_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>ensemble_num</code></dt><dd><p>Ensemble number</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Average maximum depth
</p>


<hr>
<a id="method-ForestSamples-average_max_depth"></a>



<h4>Method <code>average_max_depth()</code></h4>

<p>Average the maximum depth of each tree in each ensemble in a <code>ForestContainer</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$average_max_depth()</pre></div>



<h5>Returns</h5>

<p>Average maximum depth
</p>


<hr>
<a id="method-ForestSamples-num_forest_leaves"></a>



<h4>Method <code>num_forest_leaves()</code></h4>

<p>Number of leaves in a given ensemble in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_forest_leaves(forest_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the ensemble to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Count of leaves in the ensemble stored at <code>forest_num</code>
</p>


<hr>
<a id="method-ForestSamples-sum_leaves_squared"></a>



<h4>Method <code>sum_leaves_squared()</code></h4>

<p>Sum of squared (raw) leaf values in a given ensemble in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$sum_leaves_squared(forest_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the ensemble to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Average maximum depth
</p>


<hr>
<a id="method-ForestSamples-is_leaf_node"></a>



<h4>Method <code>is_leaf_node()</code></h4>

<p>Whether or not a given node of a given tree in a given forest in the <code>ForestSamples</code> is a leaf
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$is_leaf_node(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>TRUE</code> if node is a leaf, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-ForestSamples-is_numeric_split_node"></a>



<h4>Method <code>is_numeric_split_node()</code></h4>

<p>Whether or not a given node of a given tree in a given forest in the <code>ForestSamples</code> is a numeric split node
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$is_numeric_split_node(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>TRUE</code> if node is a numeric split node, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-ForestSamples-is_categorical_split_node"></a>



<h4>Method <code>is_categorical_split_node()</code></h4>

<p>Whether or not a given node of a given tree in a given forest in the <code>ForestSamples</code> is a categorical split node
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$is_categorical_split_node(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>TRUE</code> if node is a categorical split node, <code>FALSE</code> otherwise
</p>


<hr>
<a id="method-ForestSamples-parent_node"></a>



<h4>Method <code>parent_node()</code></h4>

<p>Parent node of given node of a given tree in a given forest in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$parent_node(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Integer ID of the parent node
</p>


<hr>
<a id="method-ForestSamples-left_child_node"></a>



<h4>Method <code>left_child_node()</code></h4>

<p>Left child node of given node of a given tree in a given forest in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$left_child_node(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Integer ID of the left child node
</p>


<hr>
<a id="method-ForestSamples-right_child_node"></a>



<h4>Method <code>right_child_node()</code></h4>

<p>Right child node of given node of a given tree in a given forest in a <code>ForestSamples</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$right_child_node(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Integer ID of the right child node
</p>


<hr>
<a id="method-ForestSamples-node_depth"></a>



<h4>Method <code>node_depth()</code></h4>

<p>Depth of given node of a given tree in a given forest in a <code>ForestSamples</code> object, with 0 depth for the root node.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$node_depth(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Integer valued depth of the node
</p>


<hr>
<a id="method-ForestSamples-node_split_index"></a>



<h4>Method <code>node_split_index()</code></h4>

<p>Split index of given node of a given tree in a given forest in a <code>ForestSamples</code> object. Returns <code>-1</code> is node is a leaf.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$node_split_index(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Integer valued depth of the node
</p>


<hr>
<a id="method-ForestSamples-node_split_threshold"></a>



<h4>Method <code>node_split_threshold()</code></h4>

<p>Threshold that defines a numeric split for a given node of a given tree in a given forest in a <code>ForestSamples</code> object.
Returns <code>Inf</code> if the node is a leaf or a categorical split node.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$node_split_threshold(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Threshold defining a split for the node
</p>


<hr>
<a id="method-ForestSamples-node_split_categories"></a>



<h4>Method <code>node_split_categories()</code></h4>

<p>Array of category indices that define a categorical split for a given node of a given tree in a given forest in a <code>ForestSamples</code> object.
Returns <code>c(Inf)</code> if the node is a leaf or a numeric split node.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$node_split_categories(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Categories defining a split for the node
</p>


<hr>
<a id="method-ForestSamples-node_leaf_values"></a>



<h4>Method <code>node_leaf_values()</code></h4>

<p>Leaf node value(s) for a given node of a given tree in a given forest in a <code>ForestSamples</code> object.
Values are stale if the node is a split node.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$node_leaf_values(forest_num, tree_num, node_id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
<dt><code>node_id</code></dt><dd><p>Index of the node to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Vector (often univariate) of leaf values
</p>


<hr>
<a id="method-ForestSamples-num_nodes"></a>



<h4>Method <code>num_nodes()</code></h4>

<p>Number of nodes in a given tree in a given forest in a <code>ForestSamples</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_nodes(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Count of total tree nodes
</p>


<hr>
<a id="method-ForestSamples-num_leaves"></a>



<h4>Method <code>num_leaves()</code></h4>

<p>Number of leaves in a given tree in a given forest in a <code>ForestSamples</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_leaves(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Count of total tree leaves
</p>


<hr>
<a id="method-ForestSamples-num_leaf_parents"></a>



<h4>Method <code>num_leaf_parents()</code></h4>

<p>Number of leaf parents (split nodes with two leaves as children) in a given tree in a given forest in a <code>ForestSamples</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_leaf_parents(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Count of total tree leaf parents
</p>


<hr>
<a id="method-ForestSamples-num_split_nodes"></a>



<h4>Method <code>num_split_nodes()</code></h4>

<p>Number of split nodes in a given tree in a given forest in a <code>ForestSamples</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$num_split_nodes(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Count of total tree split nodes
</p>


<hr>
<a id="method-ForestSamples-nodes"></a>



<h4>Method <code>nodes()</code></h4>

<p>Array of node indices in a given tree in a given forest in a <code>ForestSamples</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$nodes(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Indices of tree nodes
</p>


<hr>
<a id="method-ForestSamples-leaves"></a>



<h4>Method <code>leaves()</code></h4>

<p>Array of leaf indices in a given tree in a given forest in a <code>ForestSamples</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$leaves(forest_num, tree_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be queried</p>
</dd>
<dt><code>tree_num</code></dt><dd><p>Index of the tree to be queried</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Indices of leaf nodes
</p>


<hr>
<a id="method-ForestSamples-delete_sample"></a>



<h4>Method <code>delete_sample()</code></h4>

<p>Modify the <code>ForestSamples</code> object by removing the forest sample indexed by 'forest_num
</p>


<h5>Usage</h5>

<div class="r"><pre>ForestSamples$delete_sample(forest_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>forest_num</code></dt><dd><p>Index of the forest to be removed</p>
</dd>
</dl>

</div>



<hr>
<h2 id='getRandomEffectSamples'>Generic function for extracting random effect samples from a model object (BCF, BART, etc...)</h2><span id='topic+getRandomEffectSamples'></span>

<h3>Description</h3>

<p>Generic function for extracting random effect samples from a model object (BCF, BART, etc...)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRandomEffectSamples(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRandomEffectSamples_+3A_object">object</code></td>
<td>
<p>Fitted model object from which to extract random effects</p>
</td></tr>
<tr><td><code id="getRandomEffectSamples_+3A_...">...</code></td>
<td>
<p>Other parameters to be used in random effects extraction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of random effect samples
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
X &lt;- matrix(runif(n*p), ncol = p)
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- rep(1.0, n)
y &lt;- (-5 + 10*(X[,1] &gt; 0.5)) + (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
bart_model &lt;- bart(X_train=X, y_train=y, rfx_group_ids_train=rfx_group_ids,
                   rfx_basis_train = rfx_basis, num_gfr=0, num_mcmc=10)
rfx_samples &lt;- getRandomEffectSamples(bart_model)
</code></pre>

<hr>
<h2 id='getRandomEffectSamples.bartmodel'>Extract raw sample values for each of the random effect parameter terms.</h2><span id='topic+getRandomEffectSamples.bartmodel'></span>

<h3>Description</h3>

<p>Extract raw sample values for each of the random effect parameter terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bartmodel'
getRandomEffectSamples(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRandomEffectSamples.bartmodel_+3A_object">object</code></td>
<td>
<p>Object of type <code>bartmodel</code> containing draws of a BART model and associated sampling outputs.</p>
</td></tr>
<tr><td><code id="getRandomEffectSamples.bartmodel_+3A_...">...</code></td>
<td>
<p>Other parameters to be used in random effects extraction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of arrays. The alpha array has dimension (<code>num_components</code>, <code>num_samples</code>) and is simply a vector if <code>num_components = 1</code>.
The xi and beta arrays have dimension (<code>num_components</code>, <code>num_groups</code>, <code>num_samples</code>) and is simply a matrix if <code>num_components = 1</code>.
The sigma array has dimension (<code>num_components</code>, <code>num_samples</code>) and is simply a vector if <code>num_components = 1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
snr &lt;- 3
group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[group_ids,] * rfx_basis)
E_y &lt;- f_XW + rfx_term
y &lt;- E_y + rnorm(n, 0, 1)*(sd(E_y)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
rfx_group_ids_test &lt;- group_ids[test_inds]
rfx_group_ids_train &lt;- group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, X_test = X_test, 
                   rfx_group_ids_train = rfx_group_ids_train, 
                   rfx_group_ids_test = rfx_group_ids_test, 
                   rfx_basis_train = rfx_basis_train, 
                   rfx_basis_test = rfx_basis_test, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
rfx_samples &lt;- getRandomEffectSamples(bart_model)
</code></pre>

<hr>
<h2 id='getRandomEffectSamples.bcfmodel'>Extract raw sample values for each of the random effect parameter terms.</h2><span id='topic+getRandomEffectSamples.bcfmodel'></span>

<h3>Description</h3>

<p>Extract raw sample values for each of the random effect parameter terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bcfmodel'
getRandomEffectSamples(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRandomEffectSamples.bcfmodel_+3A_object">object</code></td>
<td>
<p>Object of type <code>bcfmodel</code> containing draws of a Bayesian causal forest model and associated sampling outputs.</p>
</td></tr>
<tr><td><code id="getRandomEffectSamples.bcfmodel_+3A_...">...</code></td>
<td>
<p>Other parameters to be used in random effects extraction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of arrays. The alpha array has dimension (<code>num_components</code>, <code>num_samples</code>) and is simply a vector if <code>num_components = 1</code>.
The xi and beta arrays have dimension (<code>num_components</code>, <code>num_groups</code>, <code>num_samples</code>) and is simply a matrix if <code>num_components = 1</code>.
The sigma array has dimension (<code>num_components</code>, <code>num_samples</code>) and is simply a vector if <code>num_components = 1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
mu_params &lt;- list(sample_sigma_leaf = TRUE)
tau_params &lt;- list(sample_sigma_leaf = FALSE)
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10, 
                 prognostic_forest_params = mu_params, 
                 treatment_effect_forest_params = tau_params)
rfx_samples &lt;- getRandomEffectSamples(bcf_model)
</code></pre>

<hr>
<h2 id='GlobalModelConfig'>Object used to get / set global parameters and other global model
configuration options in the &quot;low-level&quot; stochtree interface</h2><span id='topic+GlobalModelConfig'></span>

<h3>Description</h3>

<p>The &quot;low-level&quot; stochtree interface enables a high degreee of sampler
customization, in which users employ R wrappers around C++ objects
like ForestDataset, Outcome, CppRng, and ForestModel to run the
Gibbs sampler of a BART model with custom modifications.
GlobalModelConfig allows users to specify / query the global parameters
of a model they wish to run.
</p>


<h3>Value</h3>

<p>Global error variance parameter
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>global_error_variance</code></dt><dd><p>Global error variance parameter
Create a new GlobalModelConfig object.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-GlobalModelConfig-new"><code>GlobalModelConfig$new()</code></a>
</p>
</li>
<li> <p><a href="#method-GlobalModelConfig-update_global_error_variance"><code>GlobalModelConfig$update_global_error_variance()</code></a>
</p>
</li>
<li> <p><a href="#method-GlobalModelConfig-get_global_error_variance"><code>GlobalModelConfig$get_global_error_variance()</code></a>
</p>
</li></ul>


<hr>
<a id="method-GlobalModelConfig-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>GlobalModelConfig$new(global_error_variance = 1)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>global_error_variance</code></dt><dd><p>Global error variance parameter (default: <code>1.0</code>)</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new GlobalModelConfig object.
</p>


<hr>
<a id="method-GlobalModelConfig-update_global_error_variance"></a>



<h4>Method <code>update_global_error_variance()</code></h4>

<p>Update global error variance parameter
</p>


<h5>Usage</h5>

<div class="r"><pre>GlobalModelConfig$update_global_error_variance(global_error_variance)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>global_error_variance</code></dt><dd><p>Global error variance parameter</p>
</dd>
</dl>

</div>


<hr>
<a id="method-GlobalModelConfig-get_global_error_variance"></a>



<h4>Method <code>get_global_error_variance()</code></h4>

<p>Query global error variance parameter for this GlobalModelConfig object
</p>


<h5>Usage</h5>

<div class="r"><pre>GlobalModelConfig$get_global_error_variance()</pre></div>



<hr>
<h2 id='loadForestContainerCombinedJson'>Combine multiple JSON model objects containing forests (with the same hierarchy / schema) into a single forest_container</h2><span id='topic+loadForestContainerCombinedJson'></span>

<h3>Description</h3>

<p>Combine multiple JSON model objects containing forests (with the same hierarchy / schema) into a single forest_container
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadForestContainerCombinedJson(json_object_list, json_forest_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadForestContainerCombinedJson_+3A_json_object_list">json_object_list</code></td>
<td>
<p>List of objects of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadForestContainerCombinedJson_+3A_json_forest_label">json_forest_label</code></td>
<td>
<p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy (must exist in every json object in the list)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ForestSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
bart_model &lt;- bart(X, y, num_gfr=0, num_mcmc=10)
bart_json &lt;- list(saveBARTModelToJson(bart_model))
mean_forest &lt;- loadForestContainerCombinedJson(bart_json, "forest_0")
</code></pre>

<hr>
<h2 id='loadForestContainerCombinedJsonString'>Combine multiple JSON strings representing model objects containing forests (with the same hierarchy / schema) into a single forest_container</h2><span id='topic+loadForestContainerCombinedJsonString'></span>

<h3>Description</h3>

<p>Combine multiple JSON strings representing model objects containing forests (with the same hierarchy / schema) into a single forest_container
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadForestContainerCombinedJsonString(json_string_list, json_forest_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadForestContainerCombinedJsonString_+3A_json_string_list">json_string_list</code></td>
<td>
<p>List of strings that parse into objects of type <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadForestContainerCombinedJsonString_+3A_json_forest_label">json_forest_label</code></td>
<td>
<p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy (must exist in every json object in the list)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ForestSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
bart_model &lt;- bart(X, y, num_gfr=0, num_mcmc=10)
bart_json_string &lt;- list(saveBARTModelToJsonString(bart_model))
mean_forest &lt;- loadForestContainerCombinedJsonString(bart_json_string, "forest_0")
</code></pre>

<hr>
<h2 id='loadForestContainerJson'>Load a container of forest samples from json</h2><span id='topic+loadForestContainerJson'></span>

<h3>Description</h3>

<p>Load a container of forest samples from json
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadForestContainerJson(json_object, json_forest_label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadForestContainerJson_+3A_json_object">json_object</code></td>
<td>
<p>Object of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadForestContainerJson_+3A_json_forest_label">json_forest_label</code></td>
<td>
<p>Label referring to a particular forest (i.e. &quot;forest_0&quot;) in the overall json hierarchy</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ForestSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
bart_model &lt;- bart(X, y, num_gfr=0, num_mcmc=10)
bart_json &lt;- saveBARTModelToJson(bart_model)
mean_forest &lt;- loadForestContainerJson(bart_json, "forest_0")
</code></pre>

<hr>
<h2 id='loadRandomEffectSamplesCombinedJson'>Combine multiple JSON model objects containing random effects (with the same hierarchy / schema) into a single container</h2><span id='topic+loadRandomEffectSamplesCombinedJson'></span>

<h3>Description</h3>

<p>Combine multiple JSON model objects containing random effects (with the same hierarchy / schema) into a single container
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadRandomEffectSamplesCombinedJson(json_object_list, json_rfx_num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadRandomEffectSamplesCombinedJson_+3A_json_object_list">json_object_list</code></td>
<td>
<p>List of objects of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadRandomEffectSamplesCombinedJson_+3A_json_rfx_num">json_rfx_num</code></td>
<td>
<p>Integer index indicating the position of the random effects term to be unpacked</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
X &lt;- matrix(runif(n*p), ncol = p)
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- rep(1.0, n)
y &lt;- (-5 + 10*(X[,1] &gt; 0.5)) + (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
bart_model &lt;- bart(X_train=X, y_train=y, rfx_group_ids_train=rfx_group_ids,
                   rfx_basis_train = rfx_basis, num_gfr=0, num_mcmc=10)
bart_json &lt;- list(saveBARTModelToJson(bart_model))
rfx_samples &lt;- loadRandomEffectSamplesCombinedJson(bart_json, 0)
</code></pre>

<hr>
<h2 id='loadRandomEffectSamplesCombinedJsonString'>Combine multiple JSON strings representing model objects containing random effects (with the same hierarchy / schema) into a single container</h2><span id='topic+loadRandomEffectSamplesCombinedJsonString'></span>

<h3>Description</h3>

<p>Combine multiple JSON strings representing model objects containing random effects (with the same hierarchy / schema) into a single container
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadRandomEffectSamplesCombinedJsonString(json_string_list, json_rfx_num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadRandomEffectSamplesCombinedJsonString_+3A_json_string_list">json_string_list</code></td>
<td>
<p>List of objects of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadRandomEffectSamplesCombinedJsonString_+3A_json_rfx_num">json_rfx_num</code></td>
<td>
<p>Integer index indicating the position of the random effects term to be unpacked</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
X &lt;- matrix(runif(n*p), ncol = p)
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- rep(1.0, n)
y &lt;- (-5 + 10*(X[,1] &gt; 0.5)) + (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
bart_model &lt;- bart(X_train=X, y_train=y, rfx_group_ids_train=rfx_group_ids,
                   rfx_basis_train = rfx_basis, num_gfr=0, num_mcmc=10)
bart_json_string &lt;- list(saveBARTModelToJsonString(bart_model))
rfx_samples &lt;- loadRandomEffectSamplesCombinedJsonString(bart_json_string, 0)
</code></pre>

<hr>
<h2 id='loadRandomEffectSamplesJson'>Load a container of random effect samples from json</h2><span id='topic+loadRandomEffectSamplesJson'></span>

<h3>Description</h3>

<p>Load a container of random effect samples from json
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadRandomEffectSamplesJson(json_object, json_rfx_num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadRandomEffectSamplesJson_+3A_json_object">json_object</code></td>
<td>
<p>Object of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadRandomEffectSamplesJson_+3A_json_rfx_num">json_rfx_num</code></td>
<td>
<p>Integer index indicating the position of the random effects term to be unpacked</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>RandomEffectSamples</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
X &lt;- matrix(runif(n*p), ncol = p)
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- rep(1.0, n)
y &lt;- (-5 + 10*(X[,1] &gt; 0.5)) + (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
bart_model &lt;- bart(X_train=X, y_train=y, rfx_group_ids_train=rfx_group_ids,
                   rfx_basis_train = rfx_basis, num_gfr=0, num_mcmc=10)
bart_json &lt;- saveBARTModelToJson(bart_model)
rfx_samples &lt;- loadRandomEffectSamplesJson(bart_json, 0)
</code></pre>

<hr>
<h2 id='loadScalarJson'>Load a scalar from json</h2><span id='topic+loadScalarJson'></span>

<h3>Description</h3>

<p>Load a scalar from json
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadScalarJson(json_object, json_scalar_label, subfolder_name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadScalarJson_+3A_json_object">json_object</code></td>
<td>
<p>Object of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadScalarJson_+3A_json_scalar_label">json_scalar_label</code></td>
<td>
<p>Label referring to a particular scalar / string value (i.e. &quot;num_samples&quot;) in the overall json hierarchy</p>
</td></tr>
<tr><td><code id="loadScalarJson_+3A_subfolder_name">subfolder_name</code></td>
<td>
<p>(Optional) Name of the subfolder / hierarchy under which vector sits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>R vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_scalar &lt;- 5.4
example_json &lt;- createCppJson()
example_json$add_scalar("myscalar", example_scalar)
roundtrip_scalar &lt;- loadScalarJson(example_json, "myscalar")
</code></pre>

<hr>
<h2 id='loadVectorJson'>Load a vector from json</h2><span id='topic+loadVectorJson'></span>

<h3>Description</h3>

<p>Load a vector from json
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadVectorJson(json_object, json_vector_label, subfolder_name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadVectorJson_+3A_json_object">json_object</code></td>
<td>
<p>Object of class <code>CppJson</code></p>
</td></tr>
<tr><td><code id="loadVectorJson_+3A_json_vector_label">json_vector_label</code></td>
<td>
<p>Label referring to a particular vector (i.e. &quot;sigma2_samples&quot;) in the overall json hierarchy</p>
</td></tr>
<tr><td><code id="loadVectorJson_+3A_subfolder_name">subfolder_name</code></td>
<td>
<p>(Optional) Name of the subfolder / hierarchy under which vector sits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>R vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_vec &lt;- runif(10)
example_json &lt;- createCppJson()
example_json$add_vector("myvec", example_vec)
roundtrip_vec &lt;- loadVectorJson(example_json, "myvec")
</code></pre>

<hr>
<h2 id='Outcome'>Outcome / partial residual used to sample an additive model.</h2><span id='topic+Outcome'></span>

<h3>Description</h3>

<p>The outcome class is wrapper around a vector of (mutable)
outcomes for ML tasks (supervised learning, causal inference).
When an additive tree ensemble is sampled, the outcome used to
sample a specific model term is the &quot;partial residual&quot; consisting
of the outcome minus the predictions of every other model term
(trees, group random effects, etc...).
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>data_ptr</code></dt><dd><p>External pointer to a C++ Outcome class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Outcome-new"><code>Outcome$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Outcome-get_data"><code>Outcome$get_data()</code></a>
</p>
</li>
<li> <p><a href="#method-Outcome-add_vector"><code>Outcome$add_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-Outcome-subtract_vector"><code>Outcome$subtract_vector()</code></a>
</p>
</li>
<li> <p><a href="#method-Outcome-update_data"><code>Outcome$update_data()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Outcome-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new Outcome object.
</p>


<h5>Usage</h5>

<div class="r"><pre>Outcome$new(outcome)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>outcome</code></dt><dd><p>Vector of outcome values</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>Outcome</code> object.
</p>


<hr>
<a id="method-Outcome-get_data"></a>



<h4>Method <code>get_data()</code></h4>

<p>Extract raw data in R from the underlying C++ object
</p>


<h5>Usage</h5>

<div class="r"><pre>Outcome$get_data()</pre></div>



<h5>Returns</h5>

<p>R vector containing (copy of) the values in <code>Outcome</code> object
</p>


<hr>
<a id="method-Outcome-add_vector"></a>



<h4>Method <code>add_vector()</code></h4>

<p>Update the current state of the outcome (i.e. partial residual) data by adding the values of <code>update_vector</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>Outcome$add_vector(update_vector)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>update_vector</code></dt><dd><p>Vector to be added to outcome</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-Outcome-subtract_vector"></a>



<h4>Method <code>subtract_vector()</code></h4>

<p>Update the current state of the outcome (i.e. partial residual) data by subtracting the values of <code>update_vector</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>Outcome$subtract_vector(update_vector)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>update_vector</code></dt><dd><p>Vector to be subtracted from outcome</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-Outcome-update_data"></a>



<h4>Method <code>update_data()</code></h4>

<p>Update the current state of the outcome (i.e. partial residual) data by replacing each element with the elements of <code>new_vector</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>Outcome$update_data(new_vector)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>new_vector</code></dt><dd><p>Vector from which to overwrite the current data</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>



<hr>
<h2 id='predict.bartmodel'>Predict from a sampled BART model on new data</h2><span id='topic+predict.bartmodel'></span>

<h3>Description</h3>

<p>Predict from a sampled BART model on new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bartmodel'
predict(
  object,
  X,
  leaf_basis = NULL,
  rfx_group_ids = NULL,
  rfx_basis = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.bartmodel_+3A_object">object</code></td>
<td>
<p>Object of type <code>bart</code> containing draws of a regression forest and associated sampling outputs.</p>
</td></tr>
<tr><td><code id="predict.bartmodel_+3A_x">X</code></td>
<td>
<p>Covariates used to determine tree leaf predictions for each observation. Must be passed as a matrix or dataframe.</p>
</td></tr>
<tr><td><code id="predict.bartmodel_+3A_leaf_basis">leaf_basis</code></td>
<td>
<p>(Optional) Bases used for prediction (by e.g. dot product with leaf values). Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="predict.bartmodel_+3A_rfx_group_ids">rfx_group_ids</code></td>
<td>
<p>(Optional) Test set group labels used for an additive random effects model.
We do not currently support (but plan to in the near future), test set evaluation for group labels
that were not in the training set.</p>
</td></tr>
<tr><td><code id="predict.bartmodel_+3A_rfx_basis">rfx_basis</code></td>
<td>
<p>(Optional) Test set basis for &quot;random-slope&quot; regression in additive random effects model.</p>
</td></tr>
<tr><td><code id="predict.bartmodel_+3A_...">...</code></td>
<td>
<p>(Optional) Other prediction parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of prediction matrices. If model does not have random effects, the list has one element &ndash; the predictions from the forest.
If the model does have random effects, the list has three elements &ndash; forest predictions, random effects predictions, and their sum (<code>y_hat</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
y_hat_test &lt;- predict(bart_model, X_test)$y_hat
</code></pre>

<hr>
<h2 id='predict.bcfmodel'>Predict from a sampled BCF model on new data</h2><span id='topic+predict.bcfmodel'></span>

<h3>Description</h3>

<p>Predict from a sampled BCF model on new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bcfmodel'
predict(
  object,
  X,
  Z,
  propensity = NULL,
  rfx_group_ids = NULL,
  rfx_basis = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.bcfmodel_+3A_object">object</code></td>
<td>
<p>Object of type <code>bcfmodel</code> containing draws of a Bayesian causal forest model and associated sampling outputs.</p>
</td></tr>
<tr><td><code id="predict.bcfmodel_+3A_x">X</code></td>
<td>
<p>Covariates used to determine tree leaf predictions for each observation. Must be passed as a matrix or dataframe.</p>
</td></tr>
<tr><td><code id="predict.bcfmodel_+3A_z">Z</code></td>
<td>
<p>Treatments used for prediction.</p>
</td></tr>
<tr><td><code id="predict.bcfmodel_+3A_propensity">propensity</code></td>
<td>
<p>(Optional) Propensities used for prediction.</p>
</td></tr>
<tr><td><code id="predict.bcfmodel_+3A_rfx_group_ids">rfx_group_ids</code></td>
<td>
<p>(Optional) Test set group labels used for an additive random effects model.
We do not currently support (but plan to in the near future), test set evaluation for group labels
that were not in the training set.</p>
</td></tr>
<tr><td><code id="predict.bcfmodel_+3A_rfx_basis">rfx_basis</code></td>
<td>
<p>(Optional) Test set basis for &quot;random-slope&quot; regression in additive random effects model.</p>
</td></tr>
<tr><td><code id="predict.bcfmodel_+3A_...">...</code></td>
<td>
<p>(Optional) Other prediction parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of 3-5 <code>nrow(X)</code> by <code>object$num_samples</code> matrices: prognostic function estimates, treatment effect estimates, (optionally) random effects predictions, (optionally) variance forest predictions, and outcome predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
noise_sd &lt;- 1
y &lt;- mu_x + tau_x*Z + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, num_gfr = 10, 
                 num_burnin = 0, num_mcmc = 10)
preds &lt;- predict(bcf_model, X_test, Z_test, pi_test)
</code></pre>

<hr>
<h2 id='preprocessPredictionData'>Preprocess covariates. DataFrames will be preprocessed based on their column
types. Matrices will be passed through assuming all columns are numeric.</h2><span id='topic+preprocessPredictionData'></span>

<h3>Description</h3>

<p>Preprocess covariates. DataFrames will be preprocessed based on their column
types. Matrices will be passed through assuming all columns are numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocessPredictionData(input_data, metadata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preprocessPredictionData_+3A_input_data">input_data</code></td>
<td>
<p>Covariates, provided as either a dataframe or a matrix</p>
</td></tr>
<tr><td><code id="preprocessPredictionData_+3A_metadata">metadata</code></td>
<td>
<p>List containing information on variables, including train set
categories for categorical variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Preprocessed data with categorical variables appropriately handled
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov_df &lt;- data.frame(x1 = 1:5, x2 = 5:1, x3 = 6:10)
metadata &lt;- list(num_ordered_cat_vars = 0, num_unordered_cat_vars = 0, 
                 num_numeric_vars = 3, numeric_vars = c("x1", "x2", "x3"))
X_preprocessed &lt;- preprocessPredictionData(cov_df, metadata)
</code></pre>

<hr>
<h2 id='preprocessTrainData'>Preprocess covariates. DataFrames will be preprocessed based on their column
types. Matrices will be passed through assuming all columns are numeric.</h2><span id='topic+preprocessTrainData'></span>

<h3>Description</h3>

<p>Preprocess covariates. DataFrames will be preprocessed based on their column
types. Matrices will be passed through assuming all columns are numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preprocessTrainData(input_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preprocessTrainData_+3A_input_data">input_data</code></td>
<td>
<p>Covariates, provided as either a dataframe or a matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with preprocessed (unmodified) data and details on the number of each type
of variable, unique categories associated with categorical variables, and the
vector of feature types needed for calls to BART and BCF.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov_mat &lt;- matrix(1:12, ncol = 3)
preprocess_list &lt;- preprocessTrainData(cov_mat)
X &lt;- preprocess_list$X
</code></pre>

<hr>
<h2 id='RandomEffectSamples'>Class that wraps the &quot;persistent&quot; aspects of a C++ random effects model
(draws of the parameters and a map from the original label indices to the
0-indexed label numbers used to place group samples in memory (i.e. the
first label is stored in column 0 of the sample matrix, the second label
is store in column 1 of the sample matrix, etc...))</h2><span id='topic+RandomEffectSamples'></span>

<h3>Description</h3>

<p>Coordinates various C++ random effects classes and persists those
needed for prediction / serialization
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>rfx_container_ptr</code></dt><dd><p>External pointer to a C++ StochTree::RandomEffectsContainer class</p>
</dd>
<dt><code>label_mapper_ptr</code></dt><dd><p>External pointer to a C++ StochTree::LabelMapper class</p>
</dd>
<dt><code>training_group_ids</code></dt><dd><p>Unique vector of group IDs that were in the training dataset</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-RandomEffectSamples-new"><code>RandomEffectSamples$new()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-load_in_session"><code>RandomEffectSamples$load_in_session()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-load_from_json"><code>RandomEffectSamples$load_from_json()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-append_from_json"><code>RandomEffectSamples$append_from_json()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-load_from_json_string"><code>RandomEffectSamples$load_from_json_string()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-append_from_json_string"><code>RandomEffectSamples$append_from_json_string()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-predict"><code>RandomEffectSamples$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-extract_parameter_samples"><code>RandomEffectSamples$extract_parameter_samples()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-delete_sample"><code>RandomEffectSamples$delete_sample()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectSamples-extract_label_mapping"><code>RandomEffectSamples$extract_label_mapping()</code></a>
</p>
</li></ul>


<hr>
<a id="method-RandomEffectSamples-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new RandomEffectSamples object.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$new()</pre></div>



<h5>Returns</h5>

<p>A new <code>RandomEffectSamples</code> object.
</p>


<hr>
<a id="method-RandomEffectSamples-load_in_session"></a>



<h4>Method <code>load_in_session()</code></h4>

<p>Construct RandomEffectSamples object from other &quot;in-session&quot; R objects
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$load_in_session(
  num_components,
  num_groups,
  random_effects_tracker
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_components</code></dt><dd><p>Number of &quot;components&quot; or bases defining the random effects regression</p>
</dd>
<dt><code>num_groups</code></dt><dd><p>Number of random effects groups</p>
</dd>
<dt><code>random_effects_tracker</code></dt><dd><p>Object of type <code>RandomEffectsTracker</code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectSamples-load_from_json"></a>



<h4>Method <code>load_from_json()</code></h4>

<p>Construct RandomEffectSamples object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$load_from_json(
  json_object,
  json_rfx_container_label,
  json_rfx_mapper_label,
  json_rfx_groupids_label
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_object</code></dt><dd><p>Object of class <code>CppJson</code></p>
</dd>
<dt><code>json_rfx_container_label</code></dt><dd><p>Label referring to a particular rfx sample container (i.e. &quot;random_effect_container_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_mapper_label</code></dt><dd><p>Label referring to a particular rfx label mapper (i.e. &quot;random_effect_label_mapper_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_groupids_label</code></dt><dd><p>Label referring to a particular set of rfx group IDs (i.e. &quot;random_effect_groupids_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>RandomEffectSamples</code> object.
</p>


<hr>
<a id="method-RandomEffectSamples-append_from_json"></a>



<h4>Method <code>append_from_json()</code></h4>

<p>Append random effect draws to <code>RandomEffectSamples</code> object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$append_from_json(
  json_object,
  json_rfx_container_label,
  json_rfx_mapper_label,
  json_rfx_groupids_label
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_object</code></dt><dd><p>Object of class <code>CppJson</code></p>
</dd>
<dt><code>json_rfx_container_label</code></dt><dd><p>Label referring to a particular rfx sample container (i.e. &quot;random_effect_container_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_mapper_label</code></dt><dd><p>Label referring to a particular rfx label mapper (i.e. &quot;random_effect_label_mapper_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_groupids_label</code></dt><dd><p>Label referring to a particular set of rfx group IDs (i.e. &quot;random_effect_groupids_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectSamples-load_from_json_string"></a>



<h4>Method <code>load_from_json_string()</code></h4>

<p>Construct RandomEffectSamples object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$load_from_json_string(
  json_string,
  json_rfx_container_label,
  json_rfx_mapper_label,
  json_rfx_groupids_label
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_string</code></dt><dd><p>JSON string which parses into object of class <code>CppJson</code></p>
</dd>
<dt><code>json_rfx_container_label</code></dt><dd><p>Label referring to a particular rfx sample container (i.e. &quot;random_effect_container_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_mapper_label</code></dt><dd><p>Label referring to a particular rfx label mapper (i.e. &quot;random_effect_label_mapper_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_groupids_label</code></dt><dd><p>Label referring to a particular set of rfx group IDs (i.e. &quot;random_effect_groupids_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>RandomEffectSamples</code> object.
</p>


<hr>
<a id="method-RandomEffectSamples-append_from_json_string"></a>



<h4>Method <code>append_from_json_string()</code></h4>

<p>Append random effect draws to <code>RandomEffectSamples</code> object from a json object
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$append_from_json_string(
  json_string,
  json_rfx_container_label,
  json_rfx_mapper_label,
  json_rfx_groupids_label
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>json_string</code></dt><dd><p>JSON string which parses into object of class <code>CppJson</code></p>
</dd>
<dt><code>json_rfx_container_label</code></dt><dd><p>Label referring to a particular rfx sample container (i.e. &quot;random_effect_container_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_mapper_label</code></dt><dd><p>Label referring to a particular rfx label mapper (i.e. &quot;random_effect_label_mapper_0&quot;) in the overall json hierarchy</p>
</dd>
<dt><code>json_rfx_groupids_label</code></dt><dd><p>Label referring to a particular set of rfx group IDs (i.e. &quot;random_effect_groupids_0&quot;) in the overall json hierarchy</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectSamples-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict random effects for each observation implied by <code>rfx_group_ids</code> and <code>rfx_basis</code>.
If a random effects model is &quot;intercept-only&quot; the <code>rfx_basis</code> will be a vector of ones of size <code>length(rfx_group_ids)</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$predict(rfx_group_ids, rfx_basis = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rfx_group_ids</code></dt><dd><p>Indices of random effects groups in a prediction set</p>
</dd>
<dt><code>rfx_basis</code></dt><dd><p>(Optional ) Basis used for random effects prediction</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Matrix with as many rows as observations provided and as many columns as samples drawn of the model.
</p>


<hr>
<a id="method-RandomEffectSamples-extract_parameter_samples"></a>



<h4>Method <code>extract_parameter_samples()</code></h4>

<p>Extract the random effects parameters sampled. With the &quot;redundant parameterization&quot;
of Gelman et al (2008), this includes four parameters: alpha (the &quot;working parameter&quot;
shared across every group), xi (the &quot;group parameter&quot; sampled separately for each group),
beta (the product of alpha and xi, which corresponds to the overall group-level random effects),
and sigma (group-independent prior variance for each component of xi).
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$extract_parameter_samples()</pre></div>



<h5>Returns</h5>

<p>List of arrays. The alpha array has dimension (<code>num_components</code>, <code>num_samples</code>) and is simply a vector if <code>num_components = 1</code>.
The xi and beta arrays have dimension (<code>num_components</code>, <code>num_groups</code>, <code>num_samples</code>) and is simply a matrix if <code>num_components = 1</code>.
The sigma array has dimension (<code>num_components</code>, <code>num_samples</code>) and is simply a vector if <code>num_components = 1</code>.
</p>


<hr>
<a id="method-RandomEffectSamples-delete_sample"></a>



<h4>Method <code>delete_sample()</code></h4>

<p>Modify the <code>RandomEffectsSamples</code> object by removing the parameter samples index by <code>sample_num</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$delete_sample(sample_num)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>sample_num</code></dt><dd><p>Index of the RFX sample to be removed</p>
</dd>
</dl>

</div>


<hr>
<a id="method-RandomEffectSamples-extract_label_mapping"></a>



<h4>Method <code>extract_label_mapping()</code></h4>

<p>Convert the mapping of group IDs to random effect components indices from C++ to R native format
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectSamples$extract_label_mapping()</pre></div>



<h5>Returns</h5>

<p>List mapping group ID to random effect components.
</p>



<hr>
<h2 id='RandomEffectsDataset'>Dataset used to sample a random effects model</h2><span id='topic+RandomEffectsDataset'></span>

<h3>Description</h3>

<p>A dataset consists of three matrices / vectors: group labels,
bases, and variance weights. Variance weights are optional.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>data_ptr</code></dt><dd><p>External pointer to a C++ RandomEffectsDataset class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-RandomEffectsDataset-new"><code>RandomEffectsDataset$new()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsDataset-num_observations"><code>RandomEffectsDataset$num_observations()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsDataset-has_group_labels"><code>RandomEffectsDataset$has_group_labels()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsDataset-has_basis"><code>RandomEffectsDataset$has_basis()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsDataset-has_variance_weights"><code>RandomEffectsDataset$has_variance_weights()</code></a>
</p>
</li></ul>


<hr>
<a id="method-RandomEffectsDataset-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new RandomEffectsDataset object.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsDataset$new(group_labels, basis, variance_weights = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>group_labels</code></dt><dd><p>Vector of group labels</p>
</dd>
<dt><code>basis</code></dt><dd><p>Matrix of bases used to define the random effects regression (for an intercept-only model, pass an array of ones)</p>
</dd>
<dt><code>variance_weights</code></dt><dd><p>(Optional) Vector of observation-specific variance weights</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>RandomEffectsDataset</code> object.
</p>


<hr>
<a id="method-RandomEffectsDataset-num_observations"></a>



<h4>Method <code>num_observations()</code></h4>

<p>Return number of observations in a <code>RandomEffectsDataset</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsDataset$num_observations()</pre></div>



<h5>Returns</h5>

<p>Observation count
</p>


<hr>
<a id="method-RandomEffectsDataset-has_group_labels"></a>



<h4>Method <code>has_group_labels()</code></h4>

<p>Whether or not a dataset has group label indices
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsDataset$has_group_labels()</pre></div>



<h5>Returns</h5>

<p>True if group label vector is loaded, false otherwise
</p>


<hr>
<a id="method-RandomEffectsDataset-has_basis"></a>



<h4>Method <code>has_basis()</code></h4>

<p>Whether or not a dataset has a basis matrix
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsDataset$has_basis()</pre></div>



<h5>Returns</h5>

<p>True if basis matrix is loaded, false otherwise
</p>


<hr>
<a id="method-RandomEffectsDataset-has_variance_weights"></a>



<h4>Method <code>has_variance_weights()</code></h4>

<p>Whether or not a dataset has variance weights
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsDataset$has_variance_weights()</pre></div>



<h5>Returns</h5>

<p>True if variance weights are loaded, false otherwise
</p>



<hr>
<h2 id='RandomEffectsModel'>The core &quot;model&quot; class for sampling random effects.</h2><span id='topic+RandomEffectsModel'></span>

<h3>Description</h3>

<p>Stores current model state, prior parameters, and procedures for
sampling from the conditional posterior of each parameter.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>rfx_model_ptr</code></dt><dd><p>External pointer to a C++ StochTree::RandomEffectsModel class</p>
</dd>
<dt><code>num_groups</code></dt><dd><p>Number of groups in the random effects model</p>
</dd>
<dt><code>num_components</code></dt><dd><p>Number of components (i.e. dimension of basis) in the random effects model</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-RandomEffectsModel-new"><code>RandomEffectsModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-sample_random_effect"><code>RandomEffectsModel$sample_random_effect()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-predict"><code>RandomEffectsModel$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-set_working_parameter"><code>RandomEffectsModel$set_working_parameter()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-set_group_parameters"><code>RandomEffectsModel$set_group_parameters()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-set_working_parameter_cov"><code>RandomEffectsModel$set_working_parameter_cov()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-set_group_parameter_cov"><code>RandomEffectsModel$set_group_parameter_cov()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-set_variance_prior_shape"><code>RandomEffectsModel$set_variance_prior_shape()</code></a>
</p>
</li>
<li> <p><a href="#method-RandomEffectsModel-set_variance_prior_scale"><code>RandomEffectsModel$set_variance_prior_scale()</code></a>
</p>
</li></ul>


<hr>
<a id="method-RandomEffectsModel-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new RandomEffectsModel object.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$new(num_components, num_groups)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>num_components</code></dt><dd><p>Number of &quot;components&quot; or bases defining the random effects regression</p>
</dd>
<dt><code>num_groups</code></dt><dd><p>Number of random effects groups</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>RandomEffectsModel</code> object.
</p>


<hr>
<a id="method-RandomEffectsModel-sample_random_effect"></a>



<h4>Method <code>sample_random_effect()</code></h4>

<p>Sample from random effects model.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$sample_random_effect(
  rfx_dataset,
  residual,
  rfx_tracker,
  rfx_samples,
  keep_sample,
  global_variance,
  rng
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rfx_dataset</code></dt><dd><p>Object of type <code>RandomEffectsDataset</code></p>
</dd>
<dt><code>residual</code></dt><dd><p>Object of type <code>Outcome</code></p>
</dd>
<dt><code>rfx_tracker</code></dt><dd><p>Object of type <code>RandomEffectsTracker</code></p>
</dd>
<dt><code>rfx_samples</code></dt><dd><p>Object of type <code>RandomEffectSamples</code></p>
</dd>
<dt><code>keep_sample</code></dt><dd><p>Whether sample should be retained in <code>rfx_samples</code>. If <code>FALSE</code>, the state of <code>rfx_tracker</code> will be updated, but the parameter values will not be added to the sample container. Samples are commonly discarded due to burn-in or thinning.</p>
</dd>
<dt><code>global_variance</code></dt><dd><p>Scalar global variance parameter</p>
</dd>
<dt><code>rng</code></dt><dd><p>Object of type <code>CppRNG</code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectsModel-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict from (a single sample of a) random effects model.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$predict(rfx_dataset, rfx_tracker)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rfx_dataset</code></dt><dd><p>Object of type <code>RandomEffectsDataset</code></p>
</dd>
<dt><code>rfx_tracker</code></dt><dd><p>Object of type <code>RandomEffectsTracker</code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Vector of predictions with size matching number of observations in rfx_dataset
</p>


<hr>
<a id="method-RandomEffectsModel-set_working_parameter"></a>



<h4>Method <code>set_working_parameter()</code></h4>

<p>Set value for the &quot;working parameter.&quot; This is typically
used for initialization, but could also be used to interrupt
or override the sampler.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$set_working_parameter(value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>value</code></dt><dd><p>Parameter input</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectsModel-set_group_parameters"></a>



<h4>Method <code>set_group_parameters()</code></h4>

<p>Set value for the &quot;group parameters.&quot; This is typically
used for initialization, but could also be used to interrupt
or override the sampler.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$set_group_parameters(value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>value</code></dt><dd><p>Parameter input</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectsModel-set_working_parameter_cov"></a>



<h4>Method <code>set_working_parameter_cov()</code></h4>

<p>Set value for the working parameter covariance. This is typically
used for initialization, but could also be used to interrupt
or override the sampler.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$set_working_parameter_cov(value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>value</code></dt><dd><p>Parameter input</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectsModel-set_group_parameter_cov"></a>



<h4>Method <code>set_group_parameter_cov()</code></h4>

<p>Set value for the group parameter covariance. This is typically
used for initialization, but could also be used to interrupt
or override the sampler.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$set_group_parameter_cov(value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>value</code></dt><dd><p>Parameter input</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectsModel-set_variance_prior_shape"></a>



<h4>Method <code>set_variance_prior_shape()</code></h4>

<p>Set shape parameter for the group parameter variance prior.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$set_variance_prior_shape(value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>value</code></dt><dd><p>Parameter input</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>


<hr>
<a id="method-RandomEffectsModel-set_variance_prior_scale"></a>



<h4>Method <code>set_variance_prior_scale()</code></h4>

<p>Set shape parameter for the group parameter variance prior.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsModel$set_variance_prior_scale(value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>value</code></dt><dd><p>Parameter input</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None
</p>



<hr>
<h2 id='RandomEffectsTracker'>Class that defines a &quot;tracker&quot; for random effects models, most notably
storing the data indices available in each group for quicker posterior
computation and sampling of random effects terms.</h2><span id='topic+RandomEffectsTracker'></span>

<h3>Description</h3>

<p>Stores a mapping from every observation to its group index, a mapping
from group indices to the training sample observations available in that
group, and predictions for each observation.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>rfx_tracker_ptr</code></dt><dd><p>External pointer to a C++ StochTree::RandomEffectsTracker class</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-RandomEffectsTracker-new"><code>RandomEffectsTracker$new()</code></a>
</p>
</li></ul>


<hr>
<a id="method-RandomEffectsTracker-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new RandomEffectsTracker object.
</p>


<h5>Usage</h5>

<div class="r"><pre>RandomEffectsTracker$new(rfx_group_indices)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rfx_group_indices</code></dt><dd><p>Integer indices indicating groups used to define random effects</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>RandomEffectsTracker</code> object.
</p>



<hr>
<h2 id='resetActiveForest'>Reset an active forest, either from a specific forest in a <code>ForestContainer</code>
or to an ensemble of single-node (i.e. root) trees</h2><span id='topic+resetActiveForest'></span>

<h3>Description</h3>

<p>Reset an active forest, either from a specific forest in a <code>ForestContainer</code>
or to an ensemble of single-node (i.e. root) trees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resetActiveForest(active_forest, forest_samples = NULL, forest_num = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resetActiveForest_+3A_active_forest">active_forest</code></td>
<td>
<p>Current active forest</p>
</td></tr>
<tr><td><code id="resetActiveForest_+3A_forest_samples">forest_samples</code></td>
<td>
<p>(Optional) Container of forest samples from which to re-initialize active forest. If not provided, active forest will be reset to an ensemble of single-node (i.e. root) trees.</p>
</td></tr>
<tr><td><code id="resetActiveForest_+3A_forest_num">forest_num</code></td>
<td>
<p>(Optional) Index of forest samples from which to initialize active forest. If not provided, active forest will be reset to an ensemble of single-node (i.e. root) trees.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_trees &lt;- 100
leaf_dimension &lt;- 1
is_leaf_constant &lt;- TRUE
is_exponentiated &lt;- FALSE
active_forest &lt;- createForest(num_trees, leaf_dimension, is_leaf_constant, is_exponentiated)
forest_samples &lt;- createForestSamples(num_trees, leaf_dimension, is_leaf_constant, is_exponentiated)
forest_samples$add_forest_with_constant_leaves(0.0)
forest_samples$add_numeric_split_tree(0, 0, 0, 0, 0.5, -1.0, 1.0)
forest_samples$add_numeric_split_tree(0, 1, 0, 1, 0.75, 3.4, 0.75)
active_forest$set_root_leaves(0.1)
resetActiveForest(active_forest, forest_samples, 0)
resetActiveForest(active_forest)
</code></pre>

<hr>
<h2 id='resetForestModel'>Re-initialize a forest model (tracking data structures) from a specific forest in a <code>ForestContainer</code></h2><span id='topic+resetForestModel'></span>

<h3>Description</h3>

<p>Re-initialize a forest model (tracking data structures) from a specific forest in a <code>ForestContainer</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resetForestModel(forest_model, forest, dataset, residual, is_mean_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resetForestModel_+3A_forest_model">forest_model</code></td>
<td>
<p>Forest model with tracking data structures</p>
</td></tr>
<tr><td><code id="resetForestModel_+3A_forest">forest</code></td>
<td>
<p>Forest from which to re-initialize forest model</p>
</td></tr>
<tr><td><code id="resetForestModel_+3A_dataset">dataset</code></td>
<td>
<p>Training dataset object</p>
</td></tr>
<tr><td><code id="resetForestModel_+3A_residual">residual</code></td>
<td>
<p>Residual which will also be updated</p>
</td></tr>
<tr><td><code id="resetForestModel_+3A_is_mean_model">is_mean_model</code></td>
<td>
<p>Whether the model being updated is a conditional mean model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
num_trees &lt;- 100
leaf_dimension &lt;- 1
is_leaf_constant &lt;- TRUE
is_exponentiated &lt;- FALSE
alpha &lt;- 0.95
beta &lt;- 2.0
min_samples_leaf &lt;- 2
max_depth &lt;- 10
feature_types &lt;- as.integer(rep(0, p))
leaf_model &lt;- 0
sigma2 &lt;- 1.0
leaf_scale &lt;- as.matrix(1.0)
variable_weights &lt;- rep(1/p, p)
a_forest &lt;- 1
b_forest &lt;- 1
cutpoint_grid_size &lt;- 100
X &lt;- matrix(runif(n*p), ncol = p)
forest_dataset &lt;- createForestDataset(X)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(n)
outcome &lt;- createOutcome(y)
rng &lt;- createCppRNG(1234)
global_model_config &lt;- createGlobalModelConfig(global_error_variance=sigma2)
forest_model_config &lt;- createForestModelConfig(feature_types=feature_types, 
                                               num_trees=num_trees, num_observations=n, 
                                               num_features=p, alpha=alpha, beta=beta, 
                                               min_samples_leaf=min_samples_leaf, 
                                               max_depth=max_depth, 
                                               variable_weights=variable_weights, 
                                               cutpoint_grid_size=cutpoint_grid_size, 
                                               leaf_model_type=leaf_model, 
                                               leaf_model_scale=leaf_scale)
forest_model &lt;- createForestModel(forest_dataset, forest_model_config, global_model_config)
active_forest &lt;- createForest(num_trees, leaf_dimension, is_leaf_constant, is_exponentiated)
forest_samples &lt;- createForestSamples(num_trees, leaf_dimension, 
                                      is_leaf_constant, is_exponentiated)
active_forest$prepare_for_sampler(forest_dataset, outcome, forest_model, 0, 0.)
forest_model$sample_one_iteration(
    forest_dataset, outcome, forest_samples, active_forest, 
    rng, forest_model_config, global_model_config, 
    keep_forest = TRUE, gfr = FALSE
)
resetActiveForest(active_forest, forest_samples, 0)
resetForestModel(forest_model, active_forest, forest_dataset, outcome, TRUE)
</code></pre>

<hr>
<h2 id='resetRandomEffectsModel'>Reset a <code>RandomEffectsModel</code> object based on the parameters indexed by <code>sample_num</code> in a <code>RandomEffectsSamples</code> object</h2><span id='topic+resetRandomEffectsModel'></span>

<h3>Description</h3>

<p>Reset a <code>RandomEffectsModel</code> object based on the parameters indexed by <code>sample_num</code> in a <code>RandomEffectsSamples</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resetRandomEffectsModel(rfx_model, rfx_samples, sample_num, sigma_alpha_init)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resetRandomEffectsModel_+3A_rfx_model">rfx_model</code></td>
<td>
<p>Object of type <code>RandomEffectsModel</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsModel_+3A_rfx_samples">rfx_samples</code></td>
<td>
<p>Object of type <code>RandomEffectSamples</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsModel_+3A_sample_num">sample_num</code></td>
<td>
<p>Index of sample stored in <code>rfx_samples</code> from which to reset the state of a random effects model. Zero-indexed, so resetting based on the first sample would require setting <code>sample_num = 0</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsModel_+3A_sigma_alpha_init">sigma_alpha_init</code></td>
<td>
<p>Initial value of the &quot;working parameter&quot; scale parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
rfx_dataset &lt;- createRandomEffectsDataset(rfx_group_ids, rfx_basis)
y &lt;- (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
y_std &lt;- (y-mean(y))/sd(y)
outcome &lt;- createOutcome(y_std)
rng &lt;- createCppRNG(1234)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_model &lt;- createRandomEffectsModel(num_components, num_groups)
rfx_tracker &lt;- createRandomEffectsTracker(rfx_group_ids)
rfx_samples &lt;- createRandomEffectSamples(num_components, num_groups, rfx_tracker)
alpha_init &lt;- rep(1,num_components)
xi_init &lt;- matrix(rep(alpha_init, num_groups),num_components,num_groups)
sigma_alpha_init &lt;- diag(1,num_components,num_components)
sigma_xi_init &lt;- diag(1,num_components,num_components)
sigma_xi_shape &lt;- 1
sigma_xi_scale &lt;- 1
rfx_model$set_working_parameter(alpha_init)
rfx_model$set_group_parameters(xi_init)
rfx_model$set_working_parameter_cov(sigma_alpha_init)
rfx_model$set_group_parameter_cov(sigma_xi_init)
rfx_model$set_variance_prior_shape(sigma_xi_shape)
rfx_model$set_variance_prior_scale(sigma_xi_scale)
for (i in 1:3) {
    rfx_model$sample_random_effect(rfx_dataset=rfx_dataset, residual=outcome, 
                                   rfx_tracker=rfx_tracker, rfx_samples=rfx_samples, 
                                   keep_sample=TRUE, global_variance=1.0, rng=rng)
}
resetRandomEffectsModel(rfx_model, rfx_samples, 0, 1.0)
</code></pre>

<hr>
<h2 id='resetRandomEffectsTracker'>Reset a <code>RandomEffectsTracker</code> object based on the parameters indexed by <code>sample_num</code> in a <code>RandomEffectsSamples</code> object</h2><span id='topic+resetRandomEffectsTracker'></span>

<h3>Description</h3>

<p>Reset a <code>RandomEffectsTracker</code> object based on the parameters indexed by <code>sample_num</code> in a <code>RandomEffectsSamples</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resetRandomEffectsTracker(
  rfx_tracker,
  rfx_model,
  rfx_dataset,
  residual,
  rfx_samples
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resetRandomEffectsTracker_+3A_rfx_tracker">rfx_tracker</code></td>
<td>
<p>Object of type <code>RandomEffectsTracker</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsTracker_+3A_rfx_model">rfx_model</code></td>
<td>
<p>Object of type <code>RandomEffectsModel</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsTracker_+3A_rfx_dataset">rfx_dataset</code></td>
<td>
<p>Object of type <code>RandomEffectsDataset</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsTracker_+3A_residual">residual</code></td>
<td>
<p>Object of type <code>Outcome</code>.</p>
</td></tr>
<tr><td><code id="resetRandomEffectsTracker_+3A_rfx_samples">rfx_samples</code></td>
<td>
<p>Object of type <code>RandomEffectSamples</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
rfx_dataset &lt;- createRandomEffectsDataset(rfx_group_ids, rfx_basis)
y &lt;- (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
y_std &lt;- (y-mean(y))/sd(y)
outcome &lt;- createOutcome(y_std)
rng &lt;- createCppRNG(1234)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_model &lt;- createRandomEffectsModel(num_components, num_groups)
rfx_tracker &lt;- createRandomEffectsTracker(rfx_group_ids)
rfx_samples &lt;- createRandomEffectSamples(num_components, num_groups, rfx_tracker)
alpha_init &lt;- rep(1,num_components)
xi_init &lt;- matrix(rep(alpha_init, num_groups),num_components,num_groups)
sigma_alpha_init &lt;- diag(1,num_components,num_components)
sigma_xi_init &lt;- diag(1,num_components,num_components)
sigma_xi_shape &lt;- 1
sigma_xi_scale &lt;- 1
rfx_model$set_working_parameter(alpha_init)
rfx_model$set_group_parameters(xi_init)
rfx_model$set_working_parameter_cov(sigma_alpha_init)
rfx_model$set_group_parameter_cov(sigma_xi_init)
rfx_model$set_variance_prior_shape(sigma_xi_shape)
rfx_model$set_variance_prior_scale(sigma_xi_scale)
for (i in 1:3) {
    rfx_model$sample_random_effect(rfx_dataset=rfx_dataset, residual=outcome, 
                                   rfx_tracker=rfx_tracker, rfx_samples=rfx_samples, 
                                   keep_sample=TRUE, global_variance=1.0, rng=rng)
}
resetRandomEffectsModel(rfx_model, rfx_samples, 0, 1.0)
resetRandomEffectsTracker(rfx_tracker, rfx_model, rfx_dataset, outcome, rfx_samples)
</code></pre>

<hr>
<h2 id='rootResetRandomEffectsModel'>Reset a <code>RandomEffectsModel</code> object to its &quot;default&quot; state</h2><span id='topic+rootResetRandomEffectsModel'></span>

<h3>Description</h3>

<p>Reset a <code>RandomEffectsModel</code> object to its &quot;default&quot; state
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rootResetRandomEffectsModel(
  rfx_model,
  alpha_init,
  xi_init,
  sigma_alpha_init,
  sigma_xi_init,
  sigma_xi_shape,
  sigma_xi_scale
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rootResetRandomEffectsModel_+3A_rfx_model">rfx_model</code></td>
<td>
<p>Object of type <code>RandomEffectsModel</code>.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsModel_+3A_alpha_init">alpha_init</code></td>
<td>
<p>Initial value of the &quot;working parameter&quot;.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsModel_+3A_xi_init">xi_init</code></td>
<td>
<p>Initial value of the &quot;group parameters&quot;.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsModel_+3A_sigma_alpha_init">sigma_alpha_init</code></td>
<td>
<p>Initial value of the &quot;working parameter&quot; scale parameter.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsModel_+3A_sigma_xi_init">sigma_xi_init</code></td>
<td>
<p>Initial value of the &quot;group parameters&quot; scale parameter.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsModel_+3A_sigma_xi_shape">sigma_xi_shape</code></td>
<td>
<p>Shape parameter for the inverse gamma variance model on the group parameters.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsModel_+3A_sigma_xi_scale">sigma_xi_scale</code></td>
<td>
<p>Scale parameter for the inverse gamma variance model on the group parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
rfx_dataset &lt;- createRandomEffectsDataset(rfx_group_ids, rfx_basis)
y &lt;- (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
y_std &lt;- (y-mean(y))/sd(y)
outcome &lt;- createOutcome(y_std)
rng &lt;- createCppRNG(1234)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_model &lt;- createRandomEffectsModel(num_components, num_groups)
rfx_tracker &lt;- createRandomEffectsTracker(rfx_group_ids)
rfx_samples &lt;- createRandomEffectSamples(num_components, num_groups, rfx_tracker)
alpha_init &lt;- rep(1,num_components)
xi_init &lt;- matrix(rep(alpha_init, num_groups),num_components,num_groups)
sigma_alpha_init &lt;- diag(1,num_components,num_components)
sigma_xi_init &lt;- diag(1,num_components,num_components)
sigma_xi_shape &lt;- 1
sigma_xi_scale &lt;- 1
rfx_model$set_working_parameter(alpha_init)
rfx_model$set_group_parameters(xi_init)
rfx_model$set_working_parameter_cov(sigma_alpha_init)
rfx_model$set_group_parameter_cov(sigma_xi_init)
rfx_model$set_variance_prior_shape(sigma_xi_shape)
rfx_model$set_variance_prior_scale(sigma_xi_scale)
for (i in 1:3) {
    rfx_model$sample_random_effect(rfx_dataset=rfx_dataset, residual=outcome, 
                                   rfx_tracker=rfx_tracker, rfx_samples=rfx_samples, 
                                   keep_sample=TRUE, global_variance=1.0, rng=rng)
}
rootResetRandomEffectsModel(rfx_model, alpha_init, xi_init, sigma_alpha_init,
                            sigma_xi_init, sigma_xi_shape, sigma_xi_scale)
</code></pre>

<hr>
<h2 id='rootResetRandomEffectsTracker'>Reset a <code>RandomEffectsTracker</code> object to its &quot;default&quot; state</h2><span id='topic+rootResetRandomEffectsTracker'></span>

<h3>Description</h3>

<p>Reset a <code>RandomEffectsTracker</code> object to its &quot;default&quot; state
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rootResetRandomEffectsTracker(rfx_tracker, rfx_model, rfx_dataset, residual)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rootResetRandomEffectsTracker_+3A_rfx_tracker">rfx_tracker</code></td>
<td>
<p>Object of type <code>RandomEffectsTracker</code>.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsTracker_+3A_rfx_model">rfx_model</code></td>
<td>
<p>Object of type <code>RandomEffectsModel</code>.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsTracker_+3A_rfx_dataset">rfx_dataset</code></td>
<td>
<p>Object of type <code>RandomEffectsDataset</code>.</p>
</td></tr>
<tr><td><code id="rootResetRandomEffectsTracker_+3A_residual">residual</code></td>
<td>
<p>Object of type <code>Outcome</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 10
rfx_group_ids &lt;- sample(1:2, size = n, replace = TRUE)
rfx_basis &lt;- matrix(rep(1.0, n), ncol=1)
rfx_dataset &lt;- createRandomEffectsDataset(rfx_group_ids, rfx_basis)
y &lt;- (-2*(rfx_group_ids==1)+2*(rfx_group_ids==2)) + rnorm(n)
y_std &lt;- (y-mean(y))/sd(y)
outcome &lt;- createOutcome(y_std)
rng &lt;- createCppRNG(1234)
num_groups &lt;- length(unique(rfx_group_ids))
num_components &lt;- ncol(rfx_basis)
rfx_model &lt;- createRandomEffectsModel(num_components, num_groups)
rfx_tracker &lt;- createRandomEffectsTracker(rfx_group_ids)
rfx_samples &lt;- createRandomEffectSamples(num_components, num_groups, rfx_tracker)
alpha_init &lt;- rep(1,num_components)
xi_init &lt;- matrix(rep(alpha_init, num_groups),num_components,num_groups)
sigma_alpha_init &lt;- diag(1,num_components,num_components)
sigma_xi_init &lt;- diag(1,num_components,num_components)
sigma_xi_shape &lt;- 1
sigma_xi_scale &lt;- 1
rfx_model$set_working_parameter(alpha_init)
rfx_model$set_group_parameters(xi_init)
rfx_model$set_working_parameter_cov(sigma_alpha_init)
rfx_model$set_group_parameter_cov(sigma_xi_init)
rfx_model$set_variance_prior_shape(sigma_xi_shape)
rfx_model$set_variance_prior_scale(sigma_xi_scale)
for (i in 1:3) {
    rfx_model$sample_random_effect(rfx_dataset=rfx_dataset, residual=outcome, 
                                   rfx_tracker=rfx_tracker, rfx_samples=rfx_samples, 
                                   keep_sample=TRUE, global_variance=1.0, rng=rng)
}
rootResetRandomEffectsModel(rfx_model, alpha_init, xi_init, sigma_alpha_init,
                            sigma_xi_init, sigma_xi_shape, sigma_xi_scale)
rootResetRandomEffectsTracker(rfx_tracker, rfx_model, rfx_dataset, outcome)
</code></pre>

<hr>
<h2 id='sampleGlobalErrorVarianceOneIteration'>Sample one iteration of the (inverse gamma) global variance model</h2><span id='topic+sampleGlobalErrorVarianceOneIteration'></span>

<h3>Description</h3>

<p>Sample one iteration of the (inverse gamma) global variance model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleGlobalErrorVarianceOneIteration(residual, dataset, rng, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleGlobalErrorVarianceOneIteration_+3A_residual">residual</code></td>
<td>
<p>Outcome class</p>
</td></tr>
<tr><td><code id="sampleGlobalErrorVarianceOneIteration_+3A_dataset">dataset</code></td>
<td>
<p>ForestDataset class</p>
</td></tr>
<tr><td><code id="sampleGlobalErrorVarianceOneIteration_+3A_rng">rng</code></td>
<td>
<p>C++ random number generator</p>
</td></tr>
<tr><td><code id="sampleGlobalErrorVarianceOneIteration_+3A_a">a</code></td>
<td>
<p>Global variance shape parameter</p>
</td></tr>
<tr><td><code id="sampleGlobalErrorVarianceOneIteration_+3A_b">b</code></td>
<td>
<p>Global variance scale parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(10*100), ncol = 10)
y &lt;- -5 + 10*(X[,1] &gt; 0.5) + rnorm(100)
y_std &lt;- (y-mean(y))/sd(y)
forest_dataset &lt;- createForestDataset(X)
outcome &lt;- createOutcome(y_std)
rng &lt;- createCppRNG(1234)
a &lt;- 1.0
b &lt;- 1.0
sigma2 &lt;- sampleGlobalErrorVarianceOneIteration(outcome, forest_dataset, rng, a, b)
</code></pre>

<hr>
<h2 id='sampleLeafVarianceOneIteration'>Sample one iteration of the leaf parameter variance model (only for univariate basis and constant leaf!)</h2><span id='topic+sampleLeafVarianceOneIteration'></span>

<h3>Description</h3>

<p>Sample one iteration of the leaf parameter variance model (only for univariate basis and constant leaf!)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleLeafVarianceOneIteration(forest, rng, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleLeafVarianceOneIteration_+3A_forest">forest</code></td>
<td>
<p>C++ forest</p>
</td></tr>
<tr><td><code id="sampleLeafVarianceOneIteration_+3A_rng">rng</code></td>
<td>
<p>C++ random number generator</p>
</td></tr>
<tr><td><code id="sampleLeafVarianceOneIteration_+3A_a">a</code></td>
<td>
<p>Leaf variance shape parameter</p>
</td></tr>
<tr><td><code id="sampleLeafVarianceOneIteration_+3A_b">b</code></td>
<td>
<p>Leaf variance scale parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>num_trees &lt;- 100
leaf_dimension &lt;- 1
is_leaf_constant &lt;- TRUE
is_exponentiated &lt;- FALSE
active_forest &lt;- createForest(num_trees, leaf_dimension, is_leaf_constant, is_exponentiated)
rng &lt;- createCppRNG(1234)
a &lt;- 1.0
b &lt;- 1.0
tau &lt;- sampleLeafVarianceOneIteration(active_forest, rng, a, b)
</code></pre>

<hr>
<h2 id='saveBARTModelToJson'>Convert the persistent aspects of a BART model to (in-memory) JSON</h2><span id='topic+saveBARTModelToJson'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a BART model to (in-memory) JSON
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveBARTModelToJson(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveBARTModelToJson_+3A_object">object</code></td>
<td>
<p>Object of type <code>bartmodel</code> containing draws of a BART model and associated sampling outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>CppJson</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bart_json &lt;- saveBARTModelToJson(bart_model)
</code></pre>

<hr>
<h2 id='saveBARTModelToJsonFile'>Convert the persistent aspects of a BART model to (in-memory) JSON and save to a file</h2><span id='topic+saveBARTModelToJsonFile'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a BART model to (in-memory) JSON and save to a file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveBARTModelToJsonFile(object, filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveBARTModelToJsonFile_+3A_object">object</code></td>
<td>
<p>Object of type <code>bartmodel</code> containing draws of a BART model and associated sampling outputs.</p>
</td></tr>
<tr><td><code id="saveBARTModelToJsonFile_+3A_filename">filename</code></td>
<td>
<p>String of filepath, must end in &quot;.json&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
tmpjson &lt;- tempfile(fileext = ".json")
saveBARTModelToJsonFile(bart_model, file.path(tmpjson))
unlink(tmpjson)
</code></pre>

<hr>
<h2 id='saveBARTModelToJsonString'>Convert the persistent aspects of a BART model to (in-memory) JSON string</h2><span id='topic+saveBARTModelToJsonString'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a BART model to (in-memory) JSON string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveBARTModelToJsonString(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveBARTModelToJsonString_+3A_object">object</code></td>
<td>
<p>Object of type <code>bartmodel</code> containing draws of a BART model and associated sampling outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>in-memory JSON string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
f_XW &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
noise_sd &lt;- 1
y &lt;- f_XW + rnorm(n, 0, noise_sd)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
bart_model &lt;- bart(X_train = X_train, y_train = y_train, 
                   num_gfr = 10, num_burnin = 0, num_mcmc = 10)
bart_json_string &lt;- saveBARTModelToJsonString(bart_model)
</code></pre>

<hr>
<h2 id='saveBCFModelToJson'>Convert the persistent aspects of a BCF model to (in-memory) JSON</h2><span id='topic+saveBCFModelToJson'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a BCF model to (in-memory) JSON
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveBCFModelToJson(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveBCFModelToJson_+3A_object">object</code></td>
<td>
<p>Object of type <code>bcfmodel</code> containing draws of a Bayesian causal forest model and associated sampling outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of type <code>CppJson</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
mu_params &lt;- list(sample_sigma_leaf = TRUE)
tau_params &lt;- list(sample_sigma_leaf = FALSE)
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10, 
                 prognostic_forest_params = mu_params, 
                 treatment_effect_forest_params = tau_params)
bcf_json &lt;- saveBCFModelToJson(bcf_model)
</code></pre>

<hr>
<h2 id='saveBCFModelToJsonFile'>Convert the persistent aspects of a BCF model to (in-memory) JSON and save to a file</h2><span id='topic+saveBCFModelToJsonFile'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a BCF model to (in-memory) JSON and save to a file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveBCFModelToJsonFile(object, filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveBCFModelToJsonFile_+3A_object">object</code></td>
<td>
<p>Object of type <code>bcfmodel</code> containing draws of a Bayesian causal forest model and associated sampling outputs.</p>
</td></tr>
<tr><td><code id="saveBCFModelToJsonFile_+3A_filename">filename</code></td>
<td>
<p>String of filepath, must end in &quot;.json&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>in-memory JSON string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
mu_params &lt;- list(sample_sigma_leaf = TRUE)
tau_params &lt;- list(sample_sigma_leaf = FALSE)
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10, 
                 prognostic_forest_params = mu_params, 
                 treatment_effect_forest_params = tau_params)
tmpjson &lt;- tempfile(fileext = ".json")
saveBCFModelToJsonFile(bcf_model, file.path(tmpjson))
unlink(tmpjson)
</code></pre>

<hr>
<h2 id='saveBCFModelToJsonString'>Convert the persistent aspects of a BCF model to (in-memory) JSON string</h2><span id='topic+saveBCFModelToJsonString'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a BCF model to (in-memory) JSON string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveBCFModelToJsonString(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveBCFModelToJsonString_+3A_object">object</code></td>
<td>
<p>Object of type <code>bcfmodel</code> containing draws of a Bayesian causal forest model and associated sampling outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>JSON string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
p &lt;- 5
X &lt;- matrix(runif(n*p), ncol = p)
mu_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (-7.5) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (-2.5) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (2.5) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (7.5)
)
pi_x &lt;- (
    ((0 &lt;= X[,1]) &amp; (0.25 &gt; X[,1])) * (0.2) + 
    ((0.25 &lt;= X[,1]) &amp; (0.5 &gt; X[,1])) * (0.4) + 
    ((0.5 &lt;= X[,1]) &amp; (0.75 &gt; X[,1])) * (0.6) + 
    ((0.75 &lt;= X[,1]) &amp; (1 &gt; X[,1])) * (0.8)
)
tau_x &lt;- (
    ((0 &lt;= X[,2]) &amp; (0.25 &gt; X[,2])) * (0.5) + 
    ((0.25 &lt;= X[,2]) &amp; (0.5 &gt; X[,2])) * (1.0) + 
    ((0.5 &lt;= X[,2]) &amp; (0.75 &gt; X[,2])) * (1.5) + 
    ((0.75 &lt;= X[,2]) &amp; (1 &gt; X[,2])) * (2.0)
)
Z &lt;- rbinom(n, 1, pi_x)
E_XZ &lt;- mu_x + Z*tau_x
snr &lt;- 3
rfx_group_ids &lt;- rep(c(1,2), n %/% 2)
rfx_coefs &lt;- matrix(c(-1, -1, 1, 1), nrow=2, byrow=TRUE)
rfx_basis &lt;- cbind(1, runif(n, -1, 1))
rfx_term &lt;- rowSums(rfx_coefs[rfx_group_ids,] * rfx_basis)
y &lt;- E_XZ + rfx_term + rnorm(n, 0, 1)*(sd(E_XZ)/snr)
test_set_pct &lt;- 0.2
n_test &lt;- round(test_set_pct*n)
n_train &lt;- n - n_test
test_inds &lt;- sort(sample(1:n, n_test, replace = FALSE))
train_inds &lt;- (1:n)[!((1:n) %in% test_inds)]
X_test &lt;- X[test_inds,]
X_train &lt;- X[train_inds,]
pi_test &lt;- pi_x[test_inds]
pi_train &lt;- pi_x[train_inds]
Z_test &lt;- Z[test_inds]
Z_train &lt;- Z[train_inds]
y_test &lt;- y[test_inds]
y_train &lt;- y[train_inds]
mu_test &lt;- mu_x[test_inds]
mu_train &lt;- mu_x[train_inds]
tau_test &lt;- tau_x[test_inds]
tau_train &lt;- tau_x[train_inds]
rfx_group_ids_test &lt;- rfx_group_ids[test_inds]
rfx_group_ids_train &lt;- rfx_group_ids[train_inds]
rfx_basis_test &lt;- rfx_basis[test_inds,]
rfx_basis_train &lt;- rfx_basis[train_inds,]
rfx_term_test &lt;- rfx_term[test_inds]
rfx_term_train &lt;- rfx_term[train_inds]
mu_params &lt;- list(sample_sigma_leaf = TRUE)
tau_params &lt;- list(sample_sigma_leaf = FALSE)
bcf_model &lt;- bcf(X_train = X_train, Z_train = Z_train, y_train = y_train, 
                 propensity_train = pi_train, 
                 rfx_group_ids_train = rfx_group_ids_train, 
                 rfx_basis_train = rfx_basis_train, X_test = X_test, 
                 Z_test = Z_test, propensity_test = pi_test, 
                 rfx_group_ids_test = rfx_group_ids_test,
                 rfx_basis_test = rfx_basis_test, 
                 num_gfr = 10, num_burnin = 0, num_mcmc = 10, 
                 prognostic_forest_params = mu_params, 
                 treatment_effect_forest_params = tau_params)
saveBCFModelToJsonString(bcf_model)
</code></pre>

<hr>
<h2 id='savePreprocessorToJsonString'>Convert the persistent aspects of a covariate preprocessor to (in-memory) JSON string</h2><span id='topic+savePreprocessorToJsonString'></span>

<h3>Description</h3>

<p>Convert the persistent aspects of a covariate preprocessor to (in-memory) JSON string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>savePreprocessorToJsonString(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="savePreprocessorToJsonString_+3A_object">object</code></td>
<td>
<p>List containing information on variables, including train set
categories for categorical variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>in-memory JSON string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov_mat &lt;- matrix(1:12, ncol = 3)
preprocess_list &lt;- preprocessTrainData(cov_mat)
preprocessor_json_string &lt;- savePreprocessorToJsonString(preprocess_list$metadata)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
