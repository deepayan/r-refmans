<!DOCTYPE html><html lang="en"><head><title>Help for package chinese.misc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {chinese.misc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#chinese.misc-package'><p>Miscellaneous Tools for Chinese Text Mining and More</p></a></li>
<li><a href='#as.character2'><p>An Enhanced Version of as.character</p></a></li>
<li><a href='#as.numeric2'><p>An Enhanced Version of as.numeric</p></a></li>
<li><a href='#corp_or_dtm'><p>Create Corpus or Document Term Matrix with 1 Line</p></a></li>
<li><a href='#create_ttm'><p>Create Term-Term Matrix (Term-Cooccurrence Matrix)</p></a></li>
<li><a href='#csv2txt'><p>Write Texts in CSV into Many TXT/RTF Files</p></a></li>
<li><a href='#DEFAULT_control1'><p>A Default Value for corp_or_dtm 1</p></a></li>
<li><a href='#DEFAULT_control2'><p>A Default Value for corp_or_dtm 2</p></a></li>
<li><a href='#DEFAULT_cutter'><p>A Default Cutter</p></a></li>
<li><a href='#dictionary_dtm'><p>Making DTM/TDM for Groups of Words</p></a></li>
<li><a href='#dir_or_file'><p>Collect Full Filenames from a Mix of Directories and Files</p></a></li>
<li><a href='#get_tag_word'><p>Extract Words of Some Certain Tags through Pos-Tagging</p></a></li>
<li><a href='#get_tmp_chi_locale'><p>Check The Locale Functions are to Assume</p></a></li>
<li><a href='#is_character_vector'><p>A Convenient Version of is.character</p></a></li>
<li><a href='#is_positive_integer'><p>A Convenient Version of is.integer</p></a></li>
<li><a href='#m2doc'><p>Rewrite Terms and Frequencies into Many Files</p></a></li>
<li><a href='#m3m'><p>Convert Objects among matrix, dgCMatrix, simple_triplet_matrix,</p>
DocumentTermMatrix, TermDocumentMatrix</a></li>
<li><a href='#make_stoplist'><p>Input a Filename and Return a Vector of Stop Words</p></a></li>
<li><a href='#match_pattern'><p>Extract Strings by Regular Expression Quickly</p></a></li>
<li><a href='#output_dtm'><p>Convert or Write DTM/TDM Object Quickly</p></a></li>
<li><a href='#scancn'><p>Read a Text File by Auto-Detecting Encoding</p></a></li>
<li><a href='#seg_file'><p>Convenient Tool to Segment Chinese Texts</p></a></li>
<li><a href='#slim_text'><p>Remove Words through Speech Tagging</p></a></li>
<li><a href='#sort_tf'><p>Find High Frequency Terms</p></a></li>
<li><a href='#sparse_left'><p>Check How many Words are Left under Certain Sparse Values</p></a></li>
<li><a href='#tf2doc'><p>Transform Terms and Frequencies into a Text</p></a></li>
<li><a href='#topic_trend'><p>Simple Rise or Fall Trend of Several Years</p></a></li>
<li><a href='#txt2csv'><p>Write Many Separated Files into a CSV</p></a></li>
<li><a href='#V'><p>Copy and Paste from Excel-Like Files</p></a></li>
<li><a href='#VC'><p>Copy and Paste from Excel-Like Files</p></a></li>
<li><a href='#VCR'><p>Copy and Paste from Excel-Like Files</p></a></li>
<li><a href='#VR'><p>Copy and Paste from Excel-Like Files</p></a></li>
<li><a href='#VRC'><p>Copy and Paste from Excel-Like Files</p></a></li>
<li><a href='#word_cor'><p>Word Correlation in DTM/TDM</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Miscellaneous Tools for Chinese Text Mining and More</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-09-10</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jiang Wu &lt;textidea@sina.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efforts are made to make Chinese text mining easier, faster, and robust to errors. 
    Document term matrix can be generated by only one line of code; detecting encoding, 
    segmenting and removing stop words are done automatically. 
	Some convenient tools are also supplied.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/githubwwwjjj/chinese.misc/blob/master/README.md">https://github.com/githubwwwjjj/chinese.misc/blob/master/README.md</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>jiebaR, NLP, tm (&ge; 0.7), stringi, slam (&ge; 0.1-37), Matrix,
purrr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-09-11 21:25:55 UTC; useruser</td>
</tr>
<tr>
<td>Author:</td>
<td>Jiang Wu [aut, cre] (from Capital Normal University)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-09-11 21:50:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='chinese.misc-package'>Miscellaneous Tools for Chinese Text Mining and More</h2><span id='topic+chinese.misc-package'></span><span id='topic+chinese.misc'></span>

<h3>Description</h3>

<p>This package aims to help accomplish the basic tasks of Chinese text mining 
in a more efficient way. The manual in Chinese is 
in <a href="https://github.com/githubwwwjjj/chinese.misc">https://github.com/githubwwwjjj/chinese.misc</a>.
Compared with other packages and functions, the package puts more weight 
on the following three points:
(1) It helps save users' time.
(2) It helps decrease errors (it tolerates and corrects input errors, if it can;  
and if it cannot, it gives meaningful error messages).
(3) Although the functions in this package depend on <span class="pkg">tm</span> and 
<span class="pkg">stringi</span>, several steps and the values of arguments have been 
specially set to facilitate processing Chinese text.
For example, <code>corp_or_dtm</code> creates corpus or 
document term matrix, users only need to input folder names or file names, and the function 
will automatically detect file encoding, segment terms, modify texts, 
remove stop words. 
<code>txt2csv</code> and <code>csv2txt</code> help convert the format of texts and do some data 
cleaning. And there are some functions for object class assertion and coercion.
</p>


<h3>Author(s)</h3>

<p>Jiang Wu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tm)
# Since no Chinese character is allowed, here we 
# use English instead.
# Make a document term matrix in 1 step, few arguments have 
# to be modified by the user.
x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water", 
  "hello, drink a cup of coffee")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
# Coerce list containing data frames and other lists
df &lt;- data.frame(matrix(c(66, 77, NA, 99), nr = 2))
l &lt;- list(a = 1:4, b = factor(c(10, 20, NA, 30)), c = c('x', 'y', NA, 'z'), d = df)
l2 &lt;- list(l, l, cha = c('a', 'b', 'c'))
as.character2(l2)
</code></pre>

<hr>
<h2 id='as.character2'>An Enhanced Version of as.character</h2><span id='topic+as.character2'></span>

<h3>Description</h3>

<p>This function manages to coerce one or more objects into a character vector. Unlike 
<code>as.character</code>, this function can handle data frames, lists and recursive lists 
(lists of lists), even when there are factor objects inside data frames and lists. If there is any 
<code>NULL</code> object in a list, <code>as.character2</code> will coerce that element into 
<code>character(0)</code> rather than the character &quot;NULL&quot;, which is what 
<code>as.character</code> does. When the object is of class matrix or data frame, the function 
will open it by column. The order of characters in result manages to keep accordance 
with that of the input object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.character2(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.character2_+3A_...">...</code></td>
<td>
<p>one or more objects to be coerced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.character2(NULL, NULL)
# Try a list of NULLs
null_list &lt;- list(a = NULL, b = NULL, c = NULL)
# Compare the different results of as.character 
# and as.character2. In fact, we usually 
# want the latter one.
as.character(null_list)
as.character2(null_list)
# Try a list with a data frame in it
df &lt;- data.frame(matrix(c(66,77,NA,99), nrow = 2))
l &lt;- list(a = 1:4, b = factor(c(10,20,NA, 30)), c = c('x', 'y', NA, 'z'), d = df)
as.character2(l)
# Try a list of lists
l2 &lt;- list(l, l, cha = c('a', 'b', 'c'))
as.character2(l2)
</code></pre>

<hr>
<h2 id='as.numeric2'>An Enhanced Version of as.numeric</h2><span id='topic+as.numeric2'></span>

<h3>Description</h3>

<p>This function coerces objects into a numeric vector. There are several differences between 
this function and <code>as.numeric</code>. First, if <code>as.character2</code> fails to coerce (this is 
usually because there are characters in the input object), it will raise an error and stop 
rather than to give a warning. Second, it can handle data frame object, list, and recursive 
list. Third, it can coerce number-like factors exactly into what users see on the screen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.numeric2(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.numeric2_+3A_...">...</code></td>
<td>
<p>one or more objects to be coerced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector, or, if fails, an error will be raised.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Try to coerce data frame
a &lt;- c(55, 66, 77, 88, 66, 77, 88)
b &lt;- factor(a)
df &lt;- data.frame(a, b)
as.numeric2(df, a*2)
# Try a list
l &lt;- list(a, a*2)
as.numeric2(l)
# Try a list of lists
l2 &lt;- list(l, l)
as.numeric2(l2)
</code></pre>

<hr>
<h2 id='corp_or_dtm'>Create Corpus or Document Term Matrix with 1 Line</h2><span id='topic+corp_or_dtm'></span>

<h3>Description</h3>

<p>This function allows you to input a vector of characters, or a mixture of files and folders, it 
will automatically detect file encodings, segment Chinese texts, 
do specified modification, 
remove stop words,  and then generate corpus or dtm (tdm). Since <span class="pkg">tm</span> 
does not support Chinese well, this function manages to solve some problems. See Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corp_or_dtm(
  ...,
  from = "dir",
  type = "corpus",
  enc = "auto",
  mycutter = DEFAULT_cutter,
  stop_word = NULL,
  stop_pattern = NULL,
  control = "auto",
  myfun1 = NULL,
  myfun2 = NULL,
  special = "",
  use_stri_replace_all = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corp_or_dtm_+3A_...">...</code></td>
<td>
<p>names of folders, files, or the mixture of the two kinds. It can also be a character 
vector of texts to be processed when setting <code>from</code> to &quot;v&quot;, see below.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_from">from</code></td>
<td>
<p>should be &quot;dir&quot; or &quot;v&quot;. If your inputs are filenames, it should be &quot;dir&quot; (default), 
If the input is a character vector of texts, it should be &quot;v&quot;. However, if it is set to &quot;v&quot;, 
make sure each element is not identical to filename in your working
directory; and, if they are identical, the function will raise an error. To do this check is 
because if they are identical, <code>jiebaR::segment</code> 
will take the input as a file to read!</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_type">type</code></td>
<td>
<p>what do you want for result. It is case insensitive, thus those start with 
&quot;c&quot; or &quot;C&quot; represent a corpus 
result; and those start with &quot;d&quot; or &quot;D&quot; for document term matrix, 
and those start with &quot;t&quot; or &quot;T&quot; for term document matrix. 
Input other than the above represents 
a corpus result. The default value is &quot;corpus&quot;.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_enc">enc</code></td>
<td>
<p>a length 1 character specifying encoding when reading files. If your files 
may have different encodings, or you do not know their encodings, 
set it to &quot;auto&quot; (default) 
to let the function auto-detect encoding for each file.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_mycutter">mycutter</code></td>
<td>
<p>the jiebar cutter to segment text. A default cutter is used. See Details.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_stop_word">stop_word</code></td>
<td>
<p>a character vector to specify stop words that should be removed. 
If it is <code>NULL</code>, nothing is removed. If it is &quot;jiebar&quot;, &quot;jiebaR&quot; or &quot;auto&quot;, the stop words used by 
<span class="pkg">jiebaR</span> are used, see <code><a href="#topic+make_stoplist">make_stoplist</a></code>.
Please note the default value is <code>NULL</code>. Texts are transformed to lower case before 
removing stop words, so your stop words only need to contain lower case characters.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_stop_pattern">stop_pattern</code></td>
<td>
<p>vector of regular expressions. These patterns are similar to stop words. 
Terms that match the patterns will be removed.
Note: the function will automatically adds &quot;^&quot; and &quot;$&quot; to the pattern, which means 
first, the pattern you provide should not contain these two; second, the matching
is complete matching. That is  to say, if a word is to be removed, it not just
contains the pattern (which is to be checked by <code>grepl</code>, but the whole
word match the pattern.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_control">control</code></td>
<td>
<p>a named list similar to that 
which is used by <code>DocumentTermMatrix</code> 
or <code>TermDocumentMatrix</code> to create dtm or tdm. But 
there are some significant differences. 
Most of the time you do not need to 
set this value because a default value is used. When you set the argument to <code>NULL</code>, 
it still points to this default value. See Details.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_myfun1">myfun1</code></td>
<td>
<p>a function used to modify each text after being read by <code>scancn</code> 
and before being segmented.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_myfun2">myfun2</code></td>
<td>
<p>a function used to modify each text after they are segmented.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_special">special</code></td>
<td>
<p>a length 1 character or regular expression to be passed to <code>dir_or_file</code> 
to specify what pattern should be met by filenames. The default is to read all files.
See <code><a href="#topic+dir_or_file">dir_or_file</a></code>.</p>
</td></tr>
<tr><td><code id="corp_or_dtm_+3A_use_stri_replace_all">use_stri_replace_all</code></td>
<td>
<p>default is FALSE. If it is TRUE, 
<code>stringi::stri_replace_all</code> is used to delete stop words, which has 
a slightly higher speed. This is still experimental.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Package <span class="pkg">tm</span> sometimes
tries to segment an already segmented Chinese Corpus and put together terms that 
should not be put together. The function is to deal with the problem.
It calls <code><a href="#topic+scancn">scancn</a></code> to read files and 
auto-detect file encodings, 
and calls <code>jiebaR::segment</code> to segment Chinese text, and finally 
calls <code>tm::Corpus</code> to generate corpus.
When creating DTM/TDM, it 
partially depends on <code>tm::DocumentTermMatrix</code> 
and <code>tm::TermDocumentMatrix</code>, but also has some significant
differences in setting control argument. 
</p>
<p>Users should provide their jiebar cutter by <code>mycutter</code>. Otherwise, the function 
uses <code>DEFAULT_cutter</code> which is created when the package is loaded. 
The <code>DEFAULT_cutter</code> is simply <code>worker(write = FALSE)</code>.
See <code>jiebaR::worker</code>.
</p>
<p>As long as 
you have not manually created another variable called &quot;DEFAULT_cutter&quot;, 
you can directly use <code>jiebaR::new_user_word(DEFAULT_cutter...)</code> 
to add new words. By the way, whether you manually create an object 
called &quot;DEFAULT_cutter&quot;, the original loaded DEFAULT_cutter which is 
used by default by functions in this package will not be removed by you.
So, whenever you want to use this default value, you do not need to set 
<code>mycutter</code> and keep it as default.
</p>
<p>The argument <code>control</code> is very similar to the argument used by 
<code>tm::DocumentTermMatrix</code>, but is quite different and will not be passed
to it! The permitted elements are below:
</p>

<ul>
<li><p> (1) wordLengths: length 2 positive integer vector. 0 and <code>inf</code>
is not allowed. If you only want words of 4 to 10, then set it to c(4, 10).
If you do not want to limit the ceiling value, just choose a large value, 
e.g., c(4, 100).
In package tm (&gt;= 0.7), 1 Chinese character is roughly
of length 2 (but not always computed by multiplying 2), 
so if a Chinese words is of 4 characters, the min value 
of wordLengths is 8. But here in <code>corp_or_dtm</code>, word length is exactly
the same as what you see on the screen. So, a Chinese word with 4 characters is
of length 4 rather than 8.
</p>
</li>
<li><p> (2) dictionary: a character vetcor of the words which will appear in DTM/TDM 
when you do not want a full one. If none of the words in the dictionary appears in 
corpus, a blank DTM/TDM will be created. The vector should not contain 
<code>NA</code>, if it does, only non-NA elements will be kept. Make sure at least 1
element is not <code>NA</code>. Note: if both dictionary and wordLengths appear in 
your control list, wordLengths will be ignored.
</p>
</li>
<li><p> (3) bounds: an integer vector of length 2 which limits the term frequency
of words. Only words whose total frequencies are in this range will appear in 
the DTM/TDM. 0 and <code>inf</code> is not allowed. Let a large enough value to 
indicate the unlimited ceiling.
</p>
</li>
<li><p> (4) have: an integer vector of length 2 which limits the time a word 
appears in the corpus. Suppose a word appears 3 times in the 1st article and 2 
times in the 2nd article, and 0 in the 3rd, 
then its bounds value = 3 + 2 + 0 = 5; but its have 
value = 1 + 1 + 0 = 2.
</p>
</li>
<li><p> (5) weighting: a function to compute word weights. The default is to 
compute term frequency. But you can use other weighting functions, typically
<code>tm::weightBin</code> or <code>tm::weightTfIdf</code>.
</p>
</li>
<li><p> (6) tokenizer: this value is temporarily deprecated and  
it cannot be modified by users. 
</p>
</li></ul>

<p>By default, the argument <code>control</code> is set 
to &quot;auto&quot;, &quot;auto1&quot;, or <code>DEFAULT_control1</code>, 
which are the same. This control list is created 
when the package is loaded. It is simply <code>list(wordLengths = c(1, 25))</code>, 
Alternatively, <code>DEFAULT_control2</code> (or &quot;auto2&quot;) is also created 
when loading package, which sets 
word length to 2 to 25.
</p>


<h3>Value</h3>

<p>a corpus, or document term matrix, or term document matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water")
# The simplest argument setting
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
# Modify argument control to see what happens
dtm &lt;- corp_or_dtm(x, from = "v", type="d", control = list(wordLengths = c(3, 20)))
tdm &lt;- corp_or_dtm(x, from = "v", type = "T", stop_word = c("you", "to", "a", "of"))
</code></pre>

<hr>
<h2 id='create_ttm'>Create Term-Term Matrix (Term-Cooccurrence Matrix)</h2><span id='topic+create_ttm'></span>

<h3>Description</h3>

<p>This is a convenient function to create term-term matrix from document-term matrix, term-document
matrix, or a matrix that represents one of the two. Sparse matrix is used  
to speed up computing.
The output can be either a matrix or a sparse matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_ttm(x, type = "dtm", tomatrix = FALSE, checks = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_ttm_+3A_x">x</code></td>
<td>
<p>an object of class DocumentTermMatrix or TermDocumentMatrix, or a matrix which has
its rownames or colnames as terms.</p>
</td></tr>
<tr><td><code id="create_ttm_+3A_type">type</code></td>
<td>
<p>if <code>x</code> is a matrix, this argument tells whether it is a DTM or a TDM; for the former, 
a character starting with &quot;D/d&quot;, and for the latter, starting with &quot;T/t&quot;.</p>
</td></tr>
<tr><td><code id="create_ttm_+3A_tomatrix">tomatrix</code></td>
<td>
<p>should be logical, whether to output a matrix result. If <code>TRUE</code>, a matrix
representing a TTM is returned. If <code>FALSE</code> (default), a list is returned: the first element is 
a sparse matrix created by package Matrix, with no words, the second element is a character 
vector of these words.</p>
</td></tr>
<tr><td><code id="create_ttm_+3A_checks">checks</code></td>
<td>
<p>if <code>x</code> is a matrix, whether to check its validity, that is, whether it is numeric, all 
values are 0 or positive, there is no <code>NA</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
ttm1 &lt;- create_ttm(dtm)
ttm2 &lt;- create_ttm(dtm, tomatrix = TRUE)
tdm &lt;- t(dtm)
ttm3 &lt;- create_ttm(tdm)
ttm_sparse &lt;- ttm3[[1]]
ttm_ordinary &lt;- as.matrix(ttm_sparse)
colnames(ttm_ordinary) &lt;- ttm3[[2]]
rownames(ttm_ordinary) &lt;- ttm3[[2]]
# You can also use Matrix::writeMM(ttm_sparse, filename) 
# to write it on your disk.
</code></pre>

<hr>
<h2 id='csv2txt'>Write Texts in CSV into Many TXT/RTF Files</h2><span id='topic+csv2txt'></span>

<h3>Description</h3>

<p>The function writes texts in a given .csv file into separated .txt/.rtf files with file names added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>csv2txt(
  csv,
  folder,
  which,
  header = TRUE,
  na_in_csv = c(NA, "", " ", "?", "NA", "999"),
  na_in_txt = " ",
  name_col = NULL,
  ext = "txt"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="csv2txt_+3A_csv">csv</code></td>
<td>
<p>a .csv file. One of its columns contains texts to be written.</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_folder">folder</code></td>
<td>
<p>a name of a folder that stores the .txt/.rtf files 
created by the function. The folder may 
already exist. If it does not exist, the function will try to create it recursively. If it cannot 
be created, an error will be raised. See <code><a href="base.html#topic+dir.create">dir.create</a></code>. Note: a name that contains 
no punctuation is preferred.</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_which">which</code></td>
<td>
<p>a number: which column 
of the csv file contains texts.</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_header">header</code></td>
<td>
<p>should the .csv file be read with its first row as header? This argument is 
passed to <code><a href="utils.html#topic+read.csv">read.csv</a></code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_na_in_csv">na_in_csv</code></td>
<td>
<p>character vector indicating what content in the .csv file's cells should be 
taken as <code>NA</code>. The default values are &quot;&quot;, &quot; &quot;, &quot;?&quot;, &quot;NA&quot;, &quot;999&quot;; and you can 
specify other values. But whatever you specify, the default values will always be taken 
as <code>NA</code>. If you do not provide a character vector, the default values are used.</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_na_in_txt">na_in_txt</code></td>
<td>
<p>a length 1 character specifying what to write into a .txt file if 
a csv cell is <code>NA</code>. The default is &quot; &quot; (a space).</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_name_col">name_col</code></td>
<td>
<p>a length 1 number to indicate which column of your data should be taken 
as filenames. If it is <code>NULL</code> (default), a unique number will be given to each file, 
See Detail. If a cell is taken to be <code>NA</code>, it will be converted to &quot;&quot;; if it is too long, 
only the first 90 characters are used; one or more blanks and punctuations 
will be replaced by &quot; &quot; (a space).</p>
</td></tr>
<tr><td><code id="csv2txt_+3A_ext">ext</code></td>
<td>
<p>the extension of files to be written. Should be &quot;txt&quot;, &quot;rtf&quot; or &quot;&quot;. 
If it is not one of the three, it is set to &quot;&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In writing .txt/.rtf files, the function gives each file a unique number as part of its filename. The 
mechanism is as follows: suppose you have 1234 files, as this number has four digits, a 
series of numbers 0001, 0002,...0012,...0300,...1234 are assigned rather 
than 1, 2,...12,...300,...1234. There are several reasons to do this: first, if <code>name_col</code> 
is <code>NULL</code>, this procedure automatically assigns names. Second, the column you 
specify may have duplicate names. Third, even the column does not have duplicate names, 
the process the function modifies the names to make them valid may 
also produce duplicate names. Fourth, numbers with full digits make it easy to sort them 
in any software.
</p>


<h3>Value</h3>

<p>nothing is returned and .txt/rtf files are written into the folder.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# First, we create a csv file
x1 &lt;- file.path(find.package("base"), "CITATION")
x2 &lt;- file.path(find.package("base"), "DESCRIPTION")
txt2csv(x1, x2, must_txt = FALSE, csv = "x1x2csv.csv")
# Now try to write files
wd &lt;- getwd()
wd &lt;- gsub("/$|\\\\$", "", wd)
f &lt;- paste(wd, "x1x2csv", sep="/")
csv2txt(csv = "x1x2csv.csv", folder = f, which = 3, ext = "")

## End(Not run)
</code></pre>

<hr>
<h2 id='DEFAULT_control1'>A Default Value for corp_or_dtm 1</h2><span id='topic+DEFAULT_control1'></span>

<h3>Description</h3>

<p>In the previous version, this list object is by default
used by <code>corp_or_dtm</code>. In this version, it is not the default value
but it can still be used by the user. See details in <code><a href="#topic+corp_or_dtm">corp_or_dtm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DEFAULT_control1
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>


<h3>Details</h3>

<p>The object specifies word length from 1 to 
25. The second element, a tokenizer, is temporally deprecated.
Also, <code>DEFAULT_control2</code>
sets length from 2 to 25.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tm)
x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm", control = DEFAULT_control1)
</code></pre>

<hr>
<h2 id='DEFAULT_control2'>A Default Value for corp_or_dtm 2</h2><span id='topic+DEFAULT_control2'></span>

<h3>Description</h3>

<p>The object specifies word length from 2 to 
25. The second element, a tokenizer, is temporally deprecated.
Also, <code>DEFAULT_control1</code>
sets length from 1 to 25.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DEFAULT_control2
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tm)
x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm", control = DEFAULT_control2)
</code></pre>

<hr>
<h2 id='DEFAULT_cutter'>A Default Cutter</h2><span id='topic+DEFAULT_cutter'></span>

<h3>Description</h3>

<p>This is simply a jiebar object created when the package is loaded. 
<code>write</code> is set to <code>FALSE</code>, so as to prevent segmented text from 
being automatically written into disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DEFAULT_cutter
</code></pre>


<h3>Format</h3>

<p>An object of class <code>jiebar</code> (inherits from <code>segment</code>, <code>jieba</code>) of length 11.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(jiebaR)
x &lt;- c("drink a bottle of milk", 
  "drink a cup of coffee", 
 "drink some water")
seg_file(x, from = "v")
seg_file(x, from = "v", mycutter = DEFAULT_cutter)
</code></pre>

<hr>
<h2 id='dictionary_dtm'>Making DTM/TDM for Groups of Words</h2><span id='topic+dictionary_dtm'></span>

<h3>Description</h3>

<p>A dictionary has several groups of words. Sometimes what we want is not the term frequency of this or that single word, 
but rather the total sum of words that belong to the same group. 
Given a dictionary, this function can save you a lot of time because 
it sums up the frequencies of all groups of words and you do not need to do it manually.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dictionary_dtm(
  x,
  dictionary,
  type = "dtm",
  simple_sum = FALSE,
  return_dictionary = FALSE,
  checks = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dictionary_dtm_+3A_x">x</code></td>
<td>
<p>an object of class DocumentTermMatrix or TermDocumentMatrix created by
<code><a href="#topic+corp_or_dtm">corp_or_dtm</a></code> or <code>tm::DocumentTermMatrix</code> or 
<code>tm::TermDocumentMatrix</code>. But it can also be a numeric matrix and you have to specify its type, 
see below.</p>
</td></tr>
<tr><td><code id="dictionary_dtm_+3A_dictionary">dictionary</code></td>
<td>
<p>a dictionary telling the function how you group the words. It can be a list, matrix, data.frame 
or character vector. Please see details for how to set this argument.</p>
</td></tr>
<tr><td><code id="dictionary_dtm_+3A_type">type</code></td>
<td>
<p>if x is a matrix, you have to tell whether it represents a document term matrix or a term document 
matrix. Character starting with &quot;D&quot; or &quot;d&quot; for document term matrix, and that with &quot;T&quot; or &quot;t&quot; for term document 
matrix. The default is &quot;dtm&quot;.</p>
</td></tr>
<tr><td><code id="dictionary_dtm_+3A_simple_sum">simple_sum</code></td>
<td>
<p>if it is <code>FALSE</code> (default), a DTM/TDM will be returned. If <code>TRUE</code>, you will not 
see the term frequency of each word in each text. Rather, a numeric vector is returned, each of its element 
represents the sum of the corresponding group of words in the corpus as a whole.</p>
</td></tr>
<tr><td><code id="dictionary_dtm_+3A_return_dictionary">return_dictionary</code></td>
<td>
<p>if <code>TRUE</code>, a modified dictionary is returned, which only contains words that
do exist in the DTM/TDM. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dictionary_dtm_+3A_checks">checks</code></td>
<td>
<p>The default is <code>TRUE</code>. This will check whether <code>x</code> and <code>dictionary</code> is valid.
For <code>dictionary</code>, if the input is not a list of characters, the function will manage to convert. You should not set 
this to <code>FALSE</code> unless you do believe that your input is OK.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>dictionary</code> can be set in different ways:
</p>

<ul>
<li><p> (1) list: if it is a list, each element represents a group of words. The element should be a character vector; if it
is not, the function will manage to convert. However, the length of the element should be &gt; 0 and has 
to contain at least 1 non-NA word.
</p>
</li>
<li><p> (2) matrix or data.frame: each entry of the input should be character; if it is not, the function will manage to convert.
At least one of the entries should not be <code>NA</code>. Each column (not row) represents a group of words.
</p>
</li>
<li><p> (3) character vector: it represents one group of words.
</p>
</li>
<li><p> (4) Note: you do not need to worry about two same words existing in the same group, because the function
will only count one of them. Neither should you worry about that the words in a certain group do not really
exist in the DTM/TDM, because the function will simply ignore those non-existent words. If none of the words 
of that group exists, the group will still appear in the final result, although the total frequencies of that group 
are all 0's. By setting <code>return_dictionary = TRUE</code>, you can see which words do exist.
</p>
</li></ul>



<h3>Value</h3>

<p>if <code>return_dictionary = FALSE</code>, an object of class DocumentTermMatrix or TermDocumentMatrix is 
returned; if <code>TRUE</code>, a list is returned, the 1st element is the DTM/TDM, and the 2nd
element is a named list of words. However, if <code>simple_sum = TRUE</code>, the DTM/TDM in the above two 
situations will be replaced by a vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
  "Hello, what do you want to drink and eat?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water", 
  "eat a cake", 
  "eat a piece of pizza"
)
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
D1 &lt;- list(
  aa &lt;- c("drink", "eat"),
  bb &lt;- c("cake", "pizza"),
  cc &lt;- c("cup", "bottle")
)
y1 &lt;- dictionary_dtm(dtm, D1, return_dictionary = TRUE)
#
# NA, duplicated words, non-existent words, 
# non-character elements do not affect the
# result.
D2 &lt;-list(
  has_na &lt;- c("drink", "eat", NA),
  this_is_factor &lt;- factor(c("cake", "pizza")),
  this_is_duplicated &lt;- c("cup", "bottle", "cup", "bottle"), 
  do_not_exist &lt;- c("tiger", "dream")
)
y2 &lt;- dictionary_dtm(dtm, D2, return_dictionary = TRUE)
#
# You can read into a data.frame 
# dictionary from a csv file.
# Each column represents a group.
D3 &lt;- data.frame(
  aa &lt;- c("drink", "eat", NA, NA),
  bb &lt;- c("cake", "pizza", NA, NA),
  cc &lt;- c("cup", "bottle", NA, NA),
  dd &lt;- c("do", "to", "of", "and")
)
y3 &lt;- dictionary_dtm(dtm, D3, simple_sum = TRUE)
#
# If it is a matrix:
mt &lt;- t(as.matrix(dtm))
y4 &lt;- dictionary_dtm(mt, D3, type = "t", return_dictionary = TRUE)
</code></pre>

<hr>
<h2 id='dir_or_file'>Collect Full Filenames from a Mix of Directories and Files</h2><span id='topic+dir_or_file'></span>

<h3>Description</h3>

<p>The input can be one or more directories, one or more files, or the mixture of the two. 
It will return the full paths of all files in a recursive way, 
and sort them in increasing order. When files are put in 
different areas of your disk, you may need this function to collect them. 
It is essentially a wrapper of <code><a href="base.html#topic+list.files">list.files</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dir_or_file(..., special = "")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dir_or_file_+3A_...">...</code></td>
<td>
<p>names of directories and files; if the input is not vector, the function will try to 
coerce it. Relative paths and paths starting with &quot;~/&quot; are also accepted. 
In Windows, both &quot;/&quot;  and double inversed slashes inside filenames are accepted.</p>
</td></tr>
<tr><td><code id="dir_or_file_+3A_special">special</code></td>
<td>
<p>a length 1 character or regular expression. Only filenames that have this pattern
will be collected. Default value is &quot;&quot; (character with size 0), and is to collect everything.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Failure may occur when obtaining absolute paths, please see <code><a href="base.html#topic+normalizePath">normalizePath</a></code> 
for possible reasons.
</p>


<h3>Value</h3>

<p>a character vector of full filenames with increasing order, and every name is 
unique. If no filename is collected, an error will be raised.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- find.package("base")
x2 &lt;- find.package("utils")
all_file &lt;- dir_or_file(x1, x2, special = "rds$")
</code></pre>

<hr>
<h2 id='get_tag_word'>Extract Words of Some Certain Tags through Pos-Tagging</h2><span id='topic+get_tag_word'></span>

<h3>Description</h3>

<p>Given a group of Chinese texts, this function manages to extract words of some specified types. For example, sometimes
you want to collect all verbs that are used in your texts. Note: this function uses <code>jiebaR::tagging</code> to segment
texts and do pos-tagging. The types assigned are not all correct. So, alternatively, you can first pos-tag your texts with
other methods and then use this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tag_word(
  x,
  tag = NULL,
  tag_pattern = NULL,
  mycutter = DEFAULT_cutter,
  type = "word",
  each = TRUE,
  only_unique = FALSE,
  keep_name = FALSE,
  checks = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_tag_word_+3A_x">x</code></td>
<td>
<p>it must be a list of character vectors, even when the list contains only one element. 
Each element of the list is either a length 1 character vector of a text, or 
a length &gt;= 1 character vector which is the result of former tagging work. It should not contain <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_tag">tag</code></td>
<td>
<p>one or more tags should be specified. Words with these tags will be chosen. Possible tags are &quot;v&quot;, &quot;n&quot;, 
&quot;vn&quot;, etc.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_tag_pattern">tag_pattern</code></td>
<td>
<p>should be a length 1 regular expression. You can specify tags by this pattern rather than directly 
provide tag names. For example, you can specify tag names starting with &quot;n&quot; by <code>tag_pattern = "^n"</code>.
At least and at most one of tag and tag_pattern should be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_mycutter">mycutter</code></td>
<td>
<p>a cutter created with package jiebaR and
given by users to tag texts. If your texts have already been pos-tagged, you
can set this to <code>NULL</code>.
By default, a <code>DEFAULT_cutter</code> is used, which is 
assigned as <code>worker(write = FALSE)</code> when loading the package.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_type">type</code></td>
<td>
<p>if it is &quot;word&quot; (default), then extract the words that match your tags. If it is &quot;position&quot;, only the positions
of the words are returned. Note: if it is &quot;positions&quot;, argument <code>each</code> (see below) will always be set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_each">each</code></td>
<td>
<p>if this is <code>TRUE</code> (default), the return will be a list, each element of which is a extraction result of a text.
If it is <code>FALSE</code>, the return will be a character vector with extracted words. See detail.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_only_unique">only_unique</code></td>
<td>
<p>if it is <code>TRUE</code>, only unique words are returned. The default is <code>FALSE</code>. See detail.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_keep_name">keep_name</code></td>
<td>
<p>whether to keep the tag names of the extracted words. The default is <code>FALSE</code>. Note: if 
<code>only_unique = TRUE</code>, all tag names will be removed.</p>
</td></tr>
<tr><td><code id="get_tag_word_+3A_checks">checks</code></td>
<td>
<p>whether to check the correctness of arguments. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Argument each and only_unique decide what kind of return you can get.
</p>

<ul>
<li><p> if <code>each = TRUE</code> and <code>only_unique = FALSE</code>, you can get a list, each element of which 
contains words extracted. This is the default.
</p>
</li>
<li><p> if <code>each = TRUE</code> and <code>only_unique = TRUE</code>, each element of the list only contains unique words.
</p>
</li>
<li><p> if <code>each = FALSE</code> and <code>only_unique = FALSE</code>, all words extracted will be put into a single vector.
</p>
</li>
<li><p> if <code>each = FALSE</code> and <code>only_unique = TRUE</code>, words extracted will be put into a single vector, but 
only unique words will be returned.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># No Chinese, so use English instead.
x1 &lt;- c(v = "drink", xdrink = "coffee", v = "drink", xdrink = "cola", v = "eat", xfood = "banana")
x2 &lt;- c(v = "drink", xdrink = "tea", v = "buy", x = "computer")
x &lt;- list(x1, x2)
get_tag_word(x, tag = "v", mycutter = NULL)
get_tag_word(x, tag = "v", mycutter = NULL, only_unique = TRUE)
get_tag_word(x, tag_pattern = "^x", mycutter = NULL)
get_tag_word(x, tag_pattern = "^x", mycutter = NULL, keep_name = TRUE)
get_tag_word(x, tag = "v", mycutter = NULL, each = FALSE)
get_tag_word(x, tag = "v", mycutter = NULL, each = FALSE, only_unique = TRUE)
get_tag_word(x, tag = "v", mycutter = NULL, type = "position")
</code></pre>

<hr>
<h2 id='get_tmp_chi_locale'>Check The Locale Functions are to Assume</h2><span id='topic+get_tmp_chi_locale'></span>

<h3>Description</h3>

<p>The locale setting of R is different on different operating systems or different versions of one system.
However, some functions in this package try to convert the locale setting of R to a new value.
The new value, by default, is 
&quot;Chinese (Simplified)_China.936&quot; in Windows, and &quot;zh_CN.UTF-8&quot; in other systems. But
users can modify this by <code>options(tmp_chi_locale = "...")</code> and then check this by 
<code>get_tmp_chi_locale( )</code>. Note: if this value is <code>NULL</code> or <code>NA</code>, it means no
locale modification will be done by functions in this package. If this value is &quot;auto&quot;, it will be 
automatically converted to the default values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tmp_chi_locale()
</code></pre>

<hr>
<h2 id='is_character_vector'>A Convenient Version of is.character</h2><span id='topic+is_character_vector'></span>

<h3>Description</h3>

<p>This function checks to see if the object is a character vector. It is designed to have different
actions from <code><a href="base.html#topic+is.character">is.character</a></code> and thus sometimes more convenient. See Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_character_vector(x, len = NULL, allow_all_na = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_character_vector_+3A_x">x</code></td>
<td>
<p>object to be checked</p>
</td></tr>
<tr><td><code id="is_character_vector_+3A_len">len</code></td>
<td>
<p>numeric vector represents the permitted length of character vector. If an 
object is a character vector, but its length is not in <code>len</code>, the function 
still returns <code>FALSE</code>. The default is <code>NULL</code>,
which means any length is OK.</p>
</td></tr>
<tr><td><code id="is_character_vector_+3A_allow_all_na">allow_all_na</code></td>
<td>
<p>for length&gt;1 character vector whose elements are 
all <code>NA</code>, if this argument is <code>FALSE</code>, then the function returns <code>FALSE</code>, 
if this argument is <code>TRUE</code> (default), then returns <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sometimes we want to check if an object is a character vector. But <code>is.character</code> cannot
do this, because it also returns <code>TRUE</code> for a character matrix or data frame.
What's more, we usually not only want to see if an object is of class 
character, but also want to see 
if it is valid, that is, can be passed to other functions without errors. But <code>is.character</code> 
even returns <code>TRUE</code> for <code>character(0)</code>. 
Also, <code>is.character(NA)</code> returns <code>FALSE</code>, but 
<code>is.character(as.character(NA))</code> returns <code>TRUE</code>, but in fact there is really 
no difference between the two for users and many functions that do not allow <code>NA</code>.
</p>
<p>We list below the returns of <code>is.character2</code>: 
</p>

<ul>
<li><p> (1) if the object is <code>NULL</code>, <code>is.character2</code> returns <code>FALSE</code>. 
</p>
</li>
<li><p> (2) if the object is of length 0, it always returns <code>FALSE</code>. 
</p>
</li>
<li><p> (3) if the object is not vector, <code>FALSE</code>. 
</p>
</li>
<li><p> (4) if it has only one element and this element is <code>NA</code>, under all circumstances it 
returns <code>FALSE</code>. 
</p>
</li>
<li><p> (5) if the vector is of length&gt;1, all the elements are <code>NA</code>, 
but the vector's class is not character, it returns <code>FALSE</code>. 
</p>
</li>
<li><p> (6) if a character vector is of length&gt;1, and all the elements
are <code>NA</code>, then the result depends on argument <code>allow_all_na</code>, if 
<code>allow_all_na = TRUE</code>, then <code>TRUE</code>, otherwise, <code>FALSE</code>.
</p>
</li></ul>



<h3>Value</h3>

<p><code>TRUE</code> or <code>FALSE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is_character_vector(character(0))
is_character_vector(NA)
is_character_vector(as.character(NA))
is_character_vector(c(NA, NA))
is_character_vector(as.character(c(NA,NA)))
is_character_vector(as.character(c(NA, NA)), allow_all_na = FALSE)
is_character_vector(as.character(c(NA, NA)), allow_all_na = TRUE)
is_character_vector(matrix(c("a", "b", "c", "d"), nr = 2))
is_character_vector(c("a", "b", "c"), len = c(1, 10))
is_character_vector(c("a", "b", "c"), len = c(1:10))
</code></pre>

<hr>
<h2 id='is_positive_integer'>A Convenient Version of is.integer</h2><span id='topic+is_positive_integer'></span>

<h3>Description</h3>

<p>This function checks if all elements of an object can be taken to be valid integers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_positive_integer(x, len = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_positive_integer_+3A_x">x</code></td>
<td>
<p>an object to be checked</p>
</td></tr>
<tr><td><code id="is_positive_integer_+3A_len">len</code></td>
<td>
<p>numeric vector specifying the allowed length of the <code>x</code>. If the length 
of the checked object is not in <code>len</code>, the function will return <code>FALSE</code>, even 
when it is a positive integer vector. 
The default is <code>NULL</code>, which means any length is OK.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reasons to use <code>is_positive_integer</code> are: 
</p>

<ul>
<li><p> (1) We often check if an object is a vector of positive integer. 
But <code>is.numeric</code> cannot 
do this because it also returns <code>TRUE</code> for a numeric matrix. 
</p>
</li>
<li><p> (2) Sometimes <code>is.integer</code> 
returns a too strict result. For example, <code>is.integer(3.0)</code> returns <code>FALSE</code>,  
but the number 3.0 is 
valid in codes such as <code>rep(10, 3.0)</code>, that is to say, as long as a number can be taken 
to be a valid integer, we take it to be a integer, even when <code>is.integer</code> 
returns <code>FALSE</code>. 
</p>
</li>
<li><p> (3) <code>is_positive_integer</code> returns <code>FALSE</code> for 
length = 0 object, even when it is <code>integer(0)</code>. To let the function return this result is 
because integer of length 0 is a invalid input for many functions. 
</p>
</li>
<li><p> (4) <code>is_positive_integer</code> 
returns <code>FALSE</code> for any object that contains <code>NA</code>, so that object that gets a 
<code>TRUE</code> from this function is more likely to be a valid value to be passed to 
other functions.
</p>
</li></ul>



<h3>Value</h3>

<p><code>TRUE</code> or <code>FALSE</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is_positive_integer(NULL)
is_positive_integer(as.integer(NA))
is_positive_integer(integer(0))
is_positive_integer(3.0)
is_positive_integer(3.3)
is_positive_integer(1:5)
is_positive_integer(1:5, len = c(2, 10))
is_positive_integer(1:5, len = c(2:10))
</code></pre>

<hr>
<h2 id='m2doc'>Rewrite Terms and Frequencies into Many Files</h2><span id='topic+m2doc'></span>

<h3>Description</h3>

<p>Given a matrix representing a document term matrix, this function takes each row as term 
frequencies for one file, and rewrite each row as a text.
Some text mining tools other than R accept
segmented Chinese texts.
If you already convert texts into a matrix, you can use this function to convert 
it into texts, corpus
or create document term matrix again.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m2doc(m, checks = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m2doc_+3A_m">m</code></td>
<td>
<p>a numeric matrix, data frame is not allowed. It must represent a document term 
matrix, rather than a term document matrix. Each row of the matrix represents a text. The 
matrix should have column names as terms to be written, but if it is <code>NULL</code>, the 
function will take them as &quot;term1&quot;, &quot;term2&quot;, &quot;term3&quot;, ...No <code>NA</code> in the matrix 
is allowed.</p>
</td></tr>
<tr><td><code id="m2doc_+3A_checks">checks</code></td>
<td>
<p>should be <code>TRUE</code> or <code>FALSE</code>. If it is TRUE, the function will 
check whether there is any <code>NA</code> in the input, whether it is numeric,  and whether 
there is any negative number. Default is <code>FALSE</code> to save time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector, each element is a text with repeated 
terms (by <code><a href="base.html#topic+rep">rep</a></code>) linked by a space.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- sample(1:5, 20, replace = TRUE)
m &lt;- matrix(s, nrow = 5)
colnames(m) &lt;- c("r", "text", "mining", "data")
m2doc(m)
</code></pre>

<hr>
<h2 id='m3m'>Convert Objects among matrix, dgCMatrix, simple_triplet_matrix, 
DocumentTermMatrix, TermDocumentMatrix</h2><span id='topic+m3m'></span>

<h3>Description</h3>

<p>This is to convert objects conveniently. The three types of matrix are 
1st, &quot;matrix&quot;; 2nd, &quot;dgCMatrix&quot; in package Matrix; 3rd, 
&quot;simple_triplet_matrix&quot;, &quot;DocumentTermMatrix&quot;, &quot;TermDocumentMatrix&quot; 
in package slam, tm. 
This function is to be used when you read a csv file and 
want it to be a dtm; or, when you have a very large dtm and you want 
it to be saved or passed to another function that deals with
dgCMatrix object. Note, it cannot convert between simple_triplet_matrix
on one side, and dtm or tdm on the other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m3m(x, to, keep_name = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m3m_+3A_x">x</code></td>
<td>
<p>object of class matrix, dgCMatrix, simple_triplet_matrix, 
DocumentTermMatrix, TermDocumentMatrix.</p>
</td></tr>
<tr><td><code id="m3m_+3A_to">to</code></td>
<td>
<p>to what class do you want to convert <code>x</code> to. Abbreviations 
can be used: &quot;matrix&quot; and &quot;m&quot; mean &quot;matrix&quot;: &quot;dgCMatrix&quot; and &quot;M&quot; 
mean &quot;dgCMatrix&quot;; &quot;simple_triplet_matrix&quot; and &quot;stm&quot; mean 
&quot;simple_triplet_matrix&quot;; &quot;DocumentTermMatrix&quot;, &quot;dtm&quot;, &quot;DTM&quot; 
mean &quot;DocumentTermMatrix&quot;; &quot;TermDocumentMatrix&quot;, &quot;tdm&quot;, &quot;TDM&quot; 
mean &quot;TermDocumentMatrix&quot;.</p>
</td></tr>
<tr><td><code id="m3m_+3A_keep_name">keep_name</code></td>
<td>
<p>whether to keep names or 
dimnames, which are, for dtm-like object, 
documents and terms. <code>TRUE</code> by default. 
If you set it to <code>FALSE</code>, 
you will lose them. But if you convert dgCMatrix to 
dtm or tdm, it is required that the dgCMatrix object
has a list of length 2 as dimnames.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the object whose class is specified by argument <code>to</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Make a matrix and convert to a dtm
m &lt;- sample(0: 1, 50, replace = TRUE)
m &lt;- matrix(m, nrow = 5)
colnames(m) &lt;- letters[1: 10]
rownames(m) &lt;- as.character(1: 5)
dtm &lt;- m3m(m, "dtm")
# Convert dtm to dgCMatrix
M &lt;- m3m(dtm, "M")
</code></pre>

<hr>
<h2 id='make_stoplist'>Input a Filename and Return a Vector of Stop Words</h2><span id='topic+make_stoplist'></span>

<h3>Description</h3>

<p>When a filename is provided, the function will return a vector of terms. If nothing is provided, 
it will return the stop words used in package <code>jiebaR</code>. See Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_stoplist(x = "jiebar", print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_stoplist_+3A_x">x</code></td>
<td>
<p>a length 1 character specifying a valid stop word file. 
If it is not provided,  or 
is &quot;jiebar&quot; (default), &quot;jiebaR&quot; or &quot;auto&quot;, it will return part of the stop words used by package 
<code>jiebaR</code>.
See Details.</p>
</td></tr>
<tr><td><code id="make_stoplist_+3A_print">print</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>, whether to print the first 5 words</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a valid text file that saves stop words, each word should occupy a single line. However, 
if any line that contains more than one word and these words are separated by blanks, 
punctuations, numbers, it is also accepted, for the function will try to split them.
Duplicated words will also be automatically removed.
The encoding of a stop words file is auto-detected by the function.
</p>
<p>For stop word list from <code>jiebaR</code>, see <code>jiebaR::STOPPATH</code>.  It contains 
many words that are often removed in analyzing Chinese text.
However, the result returned by <code>make_stoplist</code> is slightly different.
</p>


<h3>Value</h3>

<p>a character vector of words. If no word is obtained, it will return <code>NULL</code>.
</p>

<hr>
<h2 id='match_pattern'>Extract Strings by Regular Expression Quickly</h2><span id='topic+match_pattern'></span>

<h3>Description</h3>

<p>Given a pattern and a character vector, the function will extract 
parts of these characters that match 
the pattern. It is simply a wrapper of <code><a href="base.html#topic+regmatches">regmatches</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match_pattern(pattern, where, vec_result = TRUE, perl = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match_pattern_+3A_pattern">pattern</code></td>
<td>
<p>a length 1 regular expression to be matched.</p>
</td></tr>
<tr><td><code id="match_pattern_+3A_where">where</code></td>
<td>
<p>a character vector, each of its elements may or may not have parts that 
match the specified pattern.</p>
</td></tr>
<tr><td><code id="match_pattern_+3A_vec_result">vec_result</code></td>
<td>
<p>should be <code>TRUE</code> or <code>FALSE</code>. If <code>TRUE</code> (default), 
all matched parts will be returned in a character vector. If <code>FALSE</code>, a list is returned, 
each element of the list represents the matching result of the corresponding element 
in <code>where</code>. If an element in <code>where</code> has nothing matching the pattern, the result 
is still an element in the list and assigned <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="match_pattern_+3A_perl">perl</code></td>
<td>
<p>default is <code>FALSE</code>.
Should Perl-compatible regexps be used?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector or a list. If an element in <code>where</code> is <code>NA</code>, the result 
corresponds to this element is <code>character(0)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- "x.*?y"
x &lt;- c("x6yx8y", "x10yx30y", "aaaaaa", NA, "x00y")
y &lt;- match_pattern(p, x)
y &lt;- match_pattern(p, x, vec_result = FALSE)
</code></pre>

<hr>
<h2 id='output_dtm'>Convert or Write DTM/TDM Object Quickly</h2><span id='topic+output_dtm'></span>

<h3>Description</h3>

<p>Given a TermDocumentMatrix or DocumentTermMatrix object, the function converts it 
to a matrix or write it into a .csv file, with additional filenames attached to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>output_dtm(x, outputfile = NULL, doc_name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="output_dtm_+3A_x">x</code></td>
<td>
<p>an object created by <code>tm::TermDocumentMatrix</code> 
or <code>tm::DocumentTermMatrix</code>.</p>
</td></tr>
<tr><td><code id="output_dtm_+3A_outputfile">outputfile</code></td>
<td>
<p>when it is NULL (default), no file is written and a matrix is returned. 
When a filename is provided, it will write the matrix into a file. The filename must end 
with &quot;.csv&quot;.</p>
</td></tr>
<tr><td><code id="output_dtm_+3A_doc_name">doc_name</code></td>
<td>
<p>whether <code>NULL</code> or a character vector specifying the 
names you want to give to texts. If it is not a character vector, the function will try to coerce. 
Then the names become the row names of the returned matrix. 
Double inversed slashes will be converted to &quot;/&quot; by the function. The 
length of the argument must be equal to the number of files. <code>NA</code> element is not allowed.
By default it is <code>NULL</code>, which means no name is added.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require(tm)
x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
output_dtm(dtm, doc_name = paste("doc", 1:4))
</code></pre>

<hr>
<h2 id='scancn'>Read a Text File by Auto-Detecting Encoding</h2><span id='topic+scancn'></span>

<h3>Description</h3>

<p>The function reads a text file and tries to detect file encoding. If you have Chinese files from 
different sources and cannot give them a single encoding, just let this function detect and 
read them. The function can save you much time on dealing with unrecognizable characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scancn(x, enc = "auto", collapse = "   ")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scancn_+3A_x">x</code></td>
<td>
<p>a length 1 character specifying filename.</p>
</td></tr>
<tr><td><code id="scancn_+3A_enc">enc</code></td>
<td>
<p>a length 1 character of file encoding specified by user. The default is &quot;auto&quot;, which 
means let the function detect encoding.</p>
</td></tr>
<tr><td><code id="scancn_+3A_collapse">collapse</code></td>
<td>
<p>this is used by the <code>collapse</code> argument 
of <code>paste</code> in order to link characters together.
Default is &quot;   &quot; (three spaces).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code>scan(x, what = "character", ...)</code> and 
auto-detects file 
encoding. Sometimes 
a Chinese file is encoded in &quot;UTF-8&quot;, but what is actually read is a &quot;?&quot;. When this happens, 
the function reads it twice and uses <code>stringi::stri_encode</code> to convert it.
If invalid inputs are found in the content, the file will also be read twice.
</p>
<p>The function always returns a length 1 character. If the return of <code>scan</code> is a vector 
with length larger than 1, 
elements will be pasted together with three spaces 
or other specified symbols. 
</p>
<p>It will return 
a &quot; &quot; (one space) when all the elements of the vector are <code>NA</code>.
If not all elements 
are <code>NA</code>, those equal to <code>NA</code> will be changed to &quot;&quot; (a size 0 string) before being 
pasted together.
</p>


<h3>Value</h3>

<p>a length 1 character of text.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># No Chinese is allowed, so try an English file
x &lt;- file.path(find.package("base"), "CITATION")
scancn(x)
</code></pre>

<hr>
<h2 id='seg_file'>Convenient Tool to Segment Chinese Texts</h2><span id='topic+seg_file'></span>

<h3>Description</h3>

<p>The function first collects filenames or text vectors, then it 
calls <code>jiebaR::segment</code> to segment texts. In 
this process, it allows users to do additional modification. 
File encoding is detected automatically. 
After segmenting, segmented words that belong to a text will be pasted 
together into a single character with words split by &quot; &quot;.
The segmented result will be returned or written 
on the disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seg_file(
  ...,
  from = "dir",
  folder = NULL,
  mycutter = DEFAULT_cutter,
  enc = "auto",
  myfun1 = NULL,
  myfun2 = NULL,
  special = "",
  ext = "txt"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seg_file_+3A_...">...</code></td>
<td>
<p>names of folders, files, or the mixture of the two kinds. It can also be a character 
vector of text to be processed when setting <code>from</code> to &quot;v&quot;, see below.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_from">from</code></td>
<td>
<p>should only be &quot;dir&quot; or &quot;v&quot;. 
If your inputs are filenames, it should be &quot;dir&quot; (default), 
If the inputs is a character vector of texts, it should be &quot;v&quot;. However, if it is set to &quot;v&quot;, 
make sure each element of the vector is not identical to filename in your working
directory; if they are identical, an error will be raised. 
To do this check is because if they are identical, the function 
<code>segment</code> will take the input as a file to read!</p>
</td></tr>
<tr><td><code id="seg_file_+3A_folder">folder</code></td>
<td>
<p>a length 1 character indicating the folder to put the segmented text. 
Set it to <code>NULL</code> if you want the result to be a character vector rather than to be written 
on your disk. Otherwise, it should be a valid directory path, each segmented 
text will be written into a .txt/.rtf file. If the specified folder does not exist, the function 
will try to create it.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_mycutter">mycutter</code></td>
<td>
<p>the jiebar cutter to segment text. A default cutter is used. See Details.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_enc">enc</code></td>
<td>
<p>the file encoding used to read files. If files have different encodings or you do not 
know their encodings, set it to &quot;auto&quot; (default) to let encodings be detected automatically.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_myfun1">myfun1</code></td>
<td>
<p>a function used to modify each text after being read by <code>scancn</code> 
and before being segmented.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_myfun2">myfun2</code></td>
<td>
<p>a function used to modify each text after they are segmented.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_special">special</code></td>
<td>
<p>a length 1 character or regular expression to be passed to <code>dir_or_file</code> 
to specify what pattern should be met by filenames. The default is to read all files.</p>
</td></tr>
<tr><td><code id="seg_file_+3A_ext">ext</code></td>
<td>
<p>the extension of written files. Should be &quot;txt&quot;, &quot;rtf&quot; or &quot;&quot;. If it is not one of the 
three, it is set to &quot;&quot;. This is only used when your input is a text vector rather than 
filenames and you want to write the outcome into your disk.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users should provide their jiebar cutter by <code>mycutter</code>. Otherwise, the function 
uses <code>DEFAULT_cutter</code> which is created when the package is loaded. 
The <code>DEFAULT_cutter</code> is simply <code>worker(write = FALSE)</code>. 
See <code>jiebaR::worker</code>. 
</p>
<p>As long as 
you have not manually created another variable called &quot;DEFAULT_cutter&quot;, 
you can directly use <code>jiebaR::new_user_word(DEFAULT_cutter...)</code> 
to add new words. By the way, whether you manually create an object 
called &quot;DEFAULT_cutter&quot;, the original loaded DEFAULT_cutter which is 
used by default by functions in this package will not be removed by you.
So, whenever you want to use this default value, either you do not set 
<code>mycutter</code>, or 
set it to <code>mycutter = chinese.misc::DEFAULT_cutter</code>.
</p>
<p>The encoding for writing files (if <code>folder</code> is not NULL) is always &quot;UTF-8&quot;.
</p>


<h3>Value</h3>

<p>a character vector, each element is a segmented text, with words split by &quot; &quot;. 
If <code>folder</code> is a folder name, the result will be written into your disk and 
nothing returns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(jiebaR)
# No Chinese word is allowed, so we use English here.
x &lt;- c("drink a bottle of milk", 
  "drink a cup of coffee", 
 "DRINK SOME WATER")
seg_file(x, from = "v", myfun1 = tolower)
</code></pre>

<hr>
<h2 id='slim_text'>Remove Words through Speech Tagging</h2><span id='topic+slim_text'></span>

<h3>Description</h3>

<p>The function calls <code>jiebaR::tagging</code> to do speech tagging on a Chinese text, and then 
removes words that have certain tags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slim_text(
  x,
  mycutter = DEFAULT_cutter,
  rm_place = TRUE,
  rm_time = TRUE,
  rm_eng = FALSE,
  rm_alpha = FALSE,
  paste = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slim_text_+3A_x">x</code></td>
<td>
<p>a length 1 character of Chinese text to be tagged</p>
</td></tr>
<tr><td><code id="slim_text_+3A_mycutter">mycutter</code></td>
<td>
<p>a jiebar cutter provided by users to tag text. It has a default value, see Details.</p>
</td></tr>
<tr><td><code id="slim_text_+3A_rm_place">rm_place</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>. if <code>TRUE</code> (default), words related 
to a specified place (&quot;ns&quot;) are removed.</p>
</td></tr>
<tr><td><code id="slim_text_+3A_rm_time">rm_time</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>. if <code>TRUE</code> (default), time related 
words (&quot;t&quot;) are removed.</p>
</td></tr>
<tr><td><code id="slim_text_+3A_rm_eng">rm_eng</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>. if <code>TRUE</code>,  English words are 
removed. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="slim_text_+3A_rm_alpha">rm_alpha</code></td>
<td>
<p>should be &quot;any&quot;, <code>TRUE</code> or <code>FALSE</code> (default). Some English words
are tagged as &quot;x&quot;, so cannot be remove by setting <code>rm_eng</code>. But when
<code>rm_alpha</code> is <code>TRUE</code>, any word that contains only a-zA-Z 
will be removed. If it is &quot;any&quot;, then words that are mixtures of a-zA-Z and Chinese/digits 
will be removed.</p>
</td></tr>
<tr><td><code id="slim_text_+3A_paste">paste</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>, whether to paste the segmented words
together into a length 1 character. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stop words are often removed from texts. But a stop word list hardly includes all words that need 
to be removed. So, before removing stop words, we can remove a lot of insignificant 
words by tagging and make the texts &quot;slim&quot;.
The webpage 
http://www.docin.com/p-341417726.html?_t_t_t=0.3930890985844252 
provides details about Chinese word tags.
</p>
<p>Only words with the following tags are to be preserved: 
</p>

<ul>
<li><p> (1) &quot;n&quot;: nouns;
</p>
</li>
<li><p> (2) &quot;t&quot;: time related words;
</p>
</li>
<li><p> (3) &quot;s&quot;: space related words;
</p>
</li>
<li><p> (4) &quot;v&quot;: verbs;
</p>
</li>
<li><p> (5) &quot;a&quot;: adjectives;
</p>
</li>
<li><p> (6) &quot;b&quot;: words only used as attributes in Chinese;
</p>
</li>
<li><p> (7) &quot;x&quot;: strings;
</p>
</li>
<li><p> (8) &quot;j&quot;, &quot;l&quot;, &quot;i&quot;, &quot;z&quot;: some specific Chinese letters and phrases;
</p>
</li>
<li><p> (9) &quot;unknown&quot;: words of unknown type;
</p>
</li>
<li><p> (10) &quot;eng&quot;: English words. 
</p>
</li></ul>

<p>Optionally, words related to a specified place (&quot;ns&quot;), time related words (&quot;t&quot;) and 
english words (&quot;eng&quot;) can be removed.
</p>
<p>By default, a <code>DEFAULT_cutter</code> is used by the <code>mycutter</code> argument, which is 
assigned as <code>worker(write = FALSE)</code> when loading the package. 
As long as 
you have not manually created another variable called &quot;DEFAULT_cutter&quot;, 
you can directly use <code>jiebaR::new_user_word(DEFAULT_cutter...)</code> 
to add new words. By the way, whether you manually create an object 
called &quot;DEFAULT_cutter&quot;, the original loaded DEFAULT_cutter which is 
used by default by functions in this package will not be removed by you.
So, whenever you want to use this default value, you just do not set 
<code>mycutter</code>.
</p>


<h3>Value</h3>

<p>a length 1 character of segmented text, or a character vector, each element of which 
is a word.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(jiebaR)
cutter &lt;- jiebaR::worker()
# Give some English words a new tag.
new_user_word(cutter, c("aaa", "bbb", "ccc"),  rep("x", 3))
x &lt;- "we have new words: aaa, bbb, ccc."
# The default is to keep English words.
slim_text(x, mycutter = cutter)
# Remove words tagged as "eng" but others are kept.
slim_text(x, mycutter = cutter, rm_eng = TRUE)
# Remove any word that only has a-zA-Z, 
# even when rm_eng = FALSE.
slim_text(x, mycutter = cutter, rm_eng = TRUE, rm_alpha = TRUE)
slim_text(x, mycutter = cutter, rm_eng = FALSE, rm_alpha = TRUE)

</code></pre>

<hr>
<h2 id='sort_tf'>Find High Frequency Terms</h2><span id='topic+sort_tf'></span>

<h3>Description</h3>

<p>By inputting a matrix, or a document term matrix, or term document matrix, this function counts
the sum of each term and output top n terms. The result can be messaged on the screen, so 
that you can manually copy them to other places (e. g., Excel).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_tf(x, top = 10, type = "dtm", todf = FALSE, must_exact = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sort_tf_+3A_x">x</code></td>
<td>
<p>a matrix, or an object created by <code><a href="#topic+corp_or_dtm">corp_or_dtm</a></code> or 
by <code>tm::DocumentTermMatrix</code>, or <code>tm::TermDocumentMatrix</code>.
Data frame is not allowed. If it is a matrix, the column names (if <code>type</code> is &quot;dtm&quot;) 
or row names (if <code>type</code> is &quot;tdm&quot;) is taken to be terms, see below. If the names 
are <code>NULL</code>, terms are set to &quot;term1&quot;, &quot;term2&quot;, &quot;term3&quot;...automatically.</p>
</td></tr>
<tr><td><code id="sort_tf_+3A_top">top</code></td>
<td>
<p>a length 1 integer. As terms are in the decreasing 
order of the term frequency, this argument decides how many top terms should be returned.
The default is 10. If the number of terms is smaller than <code>top</code>, all terms are returned.
Sometimes the returned terms are more than <code>top</code>, see below.</p>
</td></tr>
<tr><td><code id="sort_tf_+3A_type">type</code></td>
<td>
<p>should start with &quot;D/d&quot; representing document term matrix, 
or &quot;T/t&quot; representing term document matrix.
It is only used when <code>x</code> is a matrix. The default is &quot;dtm&quot;.</p>
</td></tr>
<tr><td><code id="sort_tf_+3A_todf">todf</code></td>
<td>
<p>should be <code>TRUE</code> or <code>FALSE</code>. If it is <code>FALSE</code> (default) 
terms and their frequencies will be pasted by &quot;&amp;&quot; and messaged on the screen, nothing is 
returned. Otherwise, terms and frequencies will be returned as data frame.</p>
</td></tr>
<tr><td><code id="sort_tf_+3A_must_exact">must_exact</code></td>
<td>
<p>should be <code>TRUE</code> or <code>FALSE</code> (default). It decides whether 
the number of returned words should be equal to that specified by <code>top</code>. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sometimes you may pick more terms than specified by <code>top</code>. For example, you specify to 
pick up the top 5 terms, and the frequency of the 5th term is 20. But in fact there are 
two more terms that 
have frequency of 20. As a result, <code>sort_tf</code> may pick up 7 terms. If you want the 
number is exactly 5, set <code>must_exact</code> to <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>return nothing and message the result, or return a data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tm)
x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water", 
  "hello, drink a cup of coffee")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
# Argument top is 5, but more than 5 terms are returned
sort_tf(dtm, top = 5)
# Set must_exact to TRUE, return exactly 5 terms
sort_tf(dtm, top=5, must_exact=TRUE)
# Input is a matrix and terms are not specified
m=as.matrix(dtm)
colnames(m)=NULL
mt=t(m)
sort_tf(mt, top=5, type="tdm")
</code></pre>

<hr>
<h2 id='sparse_left'>Check How many Words are Left under Certain Sparse Values</h2><span id='topic+sparse_left'></span>

<h3>Description</h3>

<p>This function does not really remove sparse words (which is what 
<code>tm::removeSparseTerms</code> does); rather, it only shows how 
many words are left when you specify some sparse values. 
See Examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparse_left(x, sparse)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparse_left_+3A_x">x</code></td>
<td>
<p>a DocumentTermMatrix or TermDocumentMatrix object.</p>
</td></tr>
<tr><td><code id="sparse_left_+3A_sparse">sparse</code></td>
<td>
<p>a numeric vector with elements &gt;= 0 and &lt;= 1.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
  "Hello, what do you want to drink?", 
  "drink a bottle of milk", 
  "drink a cup of coffee", 
  "drink some water")
dtm &lt;- corp_or_dtm(x, from = "v", type = "dtm")
y &lt;- sparse_left(dtm, seq(0, 1, 0.1))
# Then you can use plot(sort(y, decreasing = TRUE), type = "b") to 
# see which sparse value is proper.
</code></pre>

<hr>
<h2 id='tf2doc'>Transform Terms and Frequencies into a Text</h2><span id='topic+tf2doc'></span>

<h3>Description</h3>

<p>This function is simply a wrapper of <code>rep</code>, but allows different structures of input.
For rewriting more texts in the same time, see <code><a href="#topic+m2doc">m2doc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf2doc(term, num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tf2doc_+3A_term">term</code></td>
<td>
<p>terms that you want to rewrite into a text. A character vector is preferred, but 
matrix, list, data frame are also OK. <code>NA</code> in the argument will be taken as 
letters &quot;NA&quot; and repeated.</p>
</td></tr>
<tr><td><code id="tf2doc_+3A_num">num</code></td>
<td>
<p>frequencies of terms in <code>term</code>. A numeric vector is preferred, but 
matrix, list, data frame are also OK. Its length must be equal to that of <code>term</code>.
No <code>NA</code> is allowed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector. Terms are pasted with a space.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(c("coffee", "milk", "tea", "cola"), nrow = 2)
y &lt;- factor(c(5:8))
tf2doc(x, y)
</code></pre>

<hr>
<h2 id='topic_trend'>Simple Rise or Fall Trend of Several Years</h2><span id='topic+topic_trend'></span>

<h3>Description</h3>

<p>When topic names and corresponding years are given, this function computes 
the rise and fall trend during the period by <code>lm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topic_trend(year, topic, relative = FALSE, zero = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="topic_trend_+3A_year">year</code></td>
<td>
<p>a numeric vector of years for corresponding topics, 
if it is not numeric, the function will try to 
coerce. The years should be written in full-digit, that is, if they are 1998 and 2013, 
do not simply write 98 and 13. No <code>NA</code> is allowed. And, the number of 
unique years is at least 3, otherwise an error will be raised.</p>
</td></tr>
<tr><td><code id="topic_trend_+3A_topic">topic</code></td>
<td>
<p>a character vector of topics. If it is not character, the function will
try to coerce. The length of topic and year should be the same. No <code>NA</code>
is allowed.</p>
</td></tr>
<tr><td><code id="topic_trend_+3A_relative">relative</code></td>
<td>
<p>if <code>FALSE</code> (default), the numbers of topics is used. If 
<code>TRUE</code>, the percentage of a topic in a year against the total number
of that year is used. Suppose this year we have 200 texts on art, and the total
number of texts in this year is 1000, then the relative value 
is 200/1000 = 0.2 rather than the absolute number 200. Note: if to use
relative value, <code>NA</code> of the amount of a topic will be 
automatically set to 0.</p>
</td></tr>
<tr><td><code id="topic_trend_+3A_zero">zero</code></td>
<td>
<p>this can only be 0 (default) or <code>NA</code>. Suppose we have
0 text on a certain topic, then you will make sure whether the amount 
is really 0, or the data of this topic in that year is missing. Set this
argument to <code>NA</code> to make all 0 into <code>NA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The detail of trend info in the result is as follows:
</p>

<ul>
<li><p> (1) trendIndex: a regression with function <code>lm</code> is done for every
topic with year as x and amount of topics as y. The value of trendIndex
is the slope k in y = kx+b. 
</p>
</li>
<li><p> (2) trendLevel: the p value of k.
</p>
</li>
<li><p> (3) totalTrend: if trendIndex is larger than 0, then &quot;rise&quot;, otherwise &quot;fall&quot;.
If trendLevel is smaller than 0.05, than &quot;significant rise&quot; or &quot;significant fall&quot;. 
</p>
</li>
<li><p> (4) maxminYear: if totalTrend is &quot;rise&quot; or &quot;significant rise&quot;, then this value
points out which year has the largest amount. If several years have the largest 
value, the most recent year is returned. If totalTrend is &quot;fall&quot; or &quot;significant fall&quot;, 
the year has the smallest amount is returned.
</p>
</li>
<li><p> (5) detailTrend: if totalTrend is &quot;rise&quot; or &quot;significant rise&quot;, then the function
will see whether the year has the largest amount is the last year, if it is, then 
&quot;rise along&quot;, otherwise &quot;rise and fall&quot;. If totalTrend is &quot;fall&quot; or &quot;significant fall&quot;, 
the function will see whether the year has the smallest amount is the
last year, if it is, then &quot;fall along&quot;, otherwise &quot;fall and rise&quot;.
</p>
</li>
<li><p> (6) simpleTrend: it is simply whether the amount of the last year 
is larger than that of the first year. If yes, then &quot;rise&quot;, if smaller, then &quot;fall&quot;, if 
the same, then &quot;equal&quot;. 
</p>
</li></ul>

<p>When computing trend for a topic, if less than 3 years has valid value and value
in other years are all <code>NA</code>, then trendIndex, trendLevel and 
maxminYear will be -999, and other cells are &quot;less than 3y&quot;. If the numbers of a topic do not
change through years, then trendIndex will be 0, trendLevel and maxminYear will be -999, totalTrend 
and detailTrend will be &quot;almost same&quot;.
</p>


<h3>Value</h3>

<p>a list. The 1st element is trend info. The 2nd is a summary of amount
of each topic in each year. If argument relative is <code>TRUE</code>, a 3rd
element is returned, which is the relative value (percentage) of each
topic in each year.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
topic &lt;- sample(c("art", "economy", "law", "politics", "sociology"), 50, replace = TRUE)
set.seed(2)
year &lt;- sample(2011: 2016, 50, replace = TRUE)
tr1 &lt;- topic_trend(year, topic)
tr2 &lt;- topic_trend(year, topic, zero = NA)
tr3 &lt;- topic_trend(year, topic, relative=TRUE)
</code></pre>

<hr>
<h2 id='txt2csv'>Write Many Separated Files into a CSV</h2><span id='topic+txt2csv'></span>

<h3>Description</h3>

<p>Given filenames, folder names, or the mixture of the two, the function will read texts 
in .txt or other separated files, and then write 
them into one .csv file. It helps those who prefer texts in a table format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>txt2csv(..., csv, must_txt = TRUE, na_in_txt = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="txt2csv_+3A_...">...</code></td>
<td>
<p>names of folders and files, obtained files may end with &quot;.txt&quot; or not , see below.
Encoding for each file is auto-detected.</p>
</td></tr>
<tr><td><code id="txt2csv_+3A_csv">csv</code></td>
<td>
<p>a .csv file that will contain texts. It must end with &quot;.csv&quot;.</p>
</td></tr>
<tr><td><code id="txt2csv_+3A_must_txt">must_txt</code></td>
<td>
<p>should be <code>TRUE</code> or <code>FALSE</code>. Should all qualified texts 
end with &quot;.txt&quot;? If you want to read other types of file, such as .rtf, set 
it to <code>FALSE</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="txt2csv_+3A_na_in_txt">na_in_txt</code></td>
<td>
<p>character vector that specifies what content, when it occupies a single line, 
should be treated as <code>NA</code>. See Details. Length of it can be larger than 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Whether a file is taken as <code>NA</code> is judged by <code><a href="#topic+scancn">scancn</a></code>. &quot; &quot; (a space) 
is also taken as <code>NA</code>. However, you 
can further decide what else is deemed as <code>NA</code>, e. g., &quot;404 ERROR&quot;, if your texts are from 
websites. If a file cannot be accessed, the result to be 
written in the corresponding cell of csv file will become <code>NA</code>, and there will be a 
message, but no error is raised.
In the .csv file, full filenames of txt occupy a column and fulltexts occupy another.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x1 &lt;- file.path(find.package("base"), "CITATION")
x2 &lt;- file.path(find.package("base"), "DESCRIPTION")
txt2csv(x1, x2, must_txt = FALSE, csv = 'x1x2csv.csv')

## End(Not run)
</code></pre>

<hr>
<h2 id='V'>Copy and Paste from Excel-Like Files</h2><span id='topic+V'></span>

<h3>Description</h3>

<p>These functions make it easy for copy and paste data from Excel-like files, especially when there are 
blank cells or when different columns have different lengths. All of them have the same arguments.
</p>

<ul>
<li> <p><code>V</code>, when you do not copy rownames or colnames
</p>
</li>
<li> <p><code>VR</code>, when the 1st column is for rownames and there are no colnames in what you copy
</p>
</li>
<li> <p><code>VC</code>, when there are colnames but no rownames
</p>
</li>
<li> <p><code>VRC</code> and the same: <code>VCR</code>, when there are both rownames and colnames
</p>
</li></ul>

<p>If you copy something from a text document (e.g., Windows Notepad), the function may warn 
&quot;incomplete final line found by readTableHeader...&quot;. This is because your content does not end with an end of
line sign. You can simply ignore this warning!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>V(tofactor = 0, keepblank = 0, sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="V_+3A_tofactor">tofactor</code></td>
<td>
<p>if this is equal to numeric 1 or <code>TRUE</code>, characters will be converted to factors. Otherwise no 
conversion will be done. The default is not to convert.</p>
</td></tr>
<tr><td><code id="V_+3A_keepblank">keepblank</code></td>
<td>
<p>if characters are not to be converted to factors, this argument decides how to deal with 
blank cells in character columns. If it is numeric 1 or <code>TRUE</code>, a blank cell will be converted
to &quot;&quot; (size 0 string). Otherwise it is viewed as <code>NA</code> (default).</p>
</td></tr>
<tr><td><code id="V_+3A_sep">sep</code></td>
<td>
<p>a single character to differentiate cells of a table. The default value should be used when 
your data is from Excel.</p>
</td></tr>
</table>

<hr>
<h2 id='VC'>Copy and Paste from Excel-Like Files</h2><span id='topic+VC'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+V">V</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VC(tofactor = 0, keepblank = 0, sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VC_+3A_tofactor">tofactor</code></td>
<td>
<p>if this is equal to numeric 1 or <code>TRUE</code>, characters will be converted to factors. Otherwise no 
conversion will be done. The default is not to convert.</p>
</td></tr>
<tr><td><code id="VC_+3A_keepblank">keepblank</code></td>
<td>
<p>if characters are not to be converted to factors, this argument decides how to deal with 
blank cells in character columns. If it is numeric 1 or <code>TRUE</code>, a blank cell will be converted
to &quot;&quot; (size 0 string). Otherwise it is viewed as <code>NA</code> (default).</p>
</td></tr>
<tr><td><code id="VC_+3A_sep">sep</code></td>
<td>
<p>a single character to differentiate cells of a table. The default value should be used when 
your data is from Excel.</p>
</td></tr>
</table>

<hr>
<h2 id='VCR'>Copy and Paste from Excel-Like Files</h2><span id='topic+VCR'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+V">V</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VCR(tofactor = 0, keepblank = 0, sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VCR_+3A_tofactor">tofactor</code></td>
<td>
<p>if this is equal to numeric 1 or <code>TRUE</code>, characters will be converted to factors. Otherwise no 
conversion will be done. The default is not to convert.</p>
</td></tr>
<tr><td><code id="VCR_+3A_keepblank">keepblank</code></td>
<td>
<p>if characters are not to be converted to factors, this argument decides how to deal with 
blank cells in character columns. If it is numeric 1 or <code>TRUE</code>, a blank cell will be converted
to &quot;&quot; (size 0 string). Otherwise it is viewed as <code>NA</code> (default).</p>
</td></tr>
<tr><td><code id="VCR_+3A_sep">sep</code></td>
<td>
<p>a single character to differentiate cells of a table. The default value should be used when 
your data is from Excel.</p>
</td></tr>
</table>

<hr>
<h2 id='VR'>Copy and Paste from Excel-Like Files</h2><span id='topic+VR'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+V">V</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VR(tofactor = 0, keepblank = 0, sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VR_+3A_tofactor">tofactor</code></td>
<td>
<p>if this is equal to numeric 1 or <code>TRUE</code>, characters will be converted to factors. Otherwise no 
conversion will be done. The default is not to convert.</p>
</td></tr>
<tr><td><code id="VR_+3A_keepblank">keepblank</code></td>
<td>
<p>if characters are not to be converted to factors, this argument decides how to deal with 
blank cells in character columns. If it is numeric 1 or <code>TRUE</code>, a blank cell will be converted
to &quot;&quot; (size 0 string). Otherwise it is viewed as <code>NA</code> (default).</p>
</td></tr>
<tr><td><code id="VR_+3A_sep">sep</code></td>
<td>
<p>a single character to differentiate cells of a table. The default value should be used when 
your data is from Excel.</p>
</td></tr>
</table>

<hr>
<h2 id='VRC'>Copy and Paste from Excel-Like Files</h2><span id='topic+VRC'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+V">V</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VRC(tofactor = 0, keepblank = 0, sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VRC_+3A_tofactor">tofactor</code></td>
<td>
<p>if this is equal to numeric 1 or <code>TRUE</code>, characters will be converted to factors. Otherwise no 
conversion will be done. The default is not to convert.</p>
</td></tr>
<tr><td><code id="VRC_+3A_keepblank">keepblank</code></td>
<td>
<p>if characters are not to be converted to factors, this argument decides how to deal with 
blank cells in character columns. If it is numeric 1 or <code>TRUE</code>, a blank cell will be converted
to &quot;&quot; (size 0 string). Otherwise it is viewed as <code>NA</code> (default).</p>
</td></tr>
<tr><td><code id="VRC_+3A_sep">sep</code></td>
<td>
<p>a single character to differentiate cells of a table. The default value should be used when 
your data is from Excel.</p>
</td></tr>
</table>

<hr>
<h2 id='word_cor'>Word Correlation in DTM/TDM</h2><span id='topic+word_cor'></span>

<h3>Description</h3>

<p>Given a DTM/TDM/matrix, the function computes the pearson/spearman/kendall 
correlation between pairs of words and filters the values by p value and minimum value of correlation.
It is a little more flexible than <code>tm::findAssocs</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_cor(x, word, type = "dtm", method = "kendall", p = NULL, min = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="word_cor_+3A_x">x</code></td>
<td>
<p>a DocumentTermMatrix, TermDocumentMatrix object, or a matrix. If it is a matrix, 
you must specify its type by the argument <code>type</code>. If it is a matrix, <code>NA</code> is not allowed, 
and rownames/colnames that are taken as words should not be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_word">word</code></td>
<td>
<p>a character vector of words that you want to know their correlation in you data. If 
it is not a vector, the function will try to coerce. The length of it should not larger than 200. The function
only computes for words that do exist in data, and those not in data will not be included.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_type">type</code></td>
<td>
<p>if it starts with &quot;d/D&quot;, it represents a DTM; if with &quot;t/T&quot;, TDM; others are not valid. This
is only used when x is a matrix. The default is &quot;dtm&quot;.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_method">method</code></td>
<td>
<p>what index is to be computed? It can only be &quot;pearson&quot;, &quot;spearman&quot;, or &quot;kendall&quot;
(default). The method is passed to <code>stats::cor.test</code>. The default is &quot;kendall&quot;.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_p">p</code></td>
<td>
<p>if the p value of a correlation index is &gt;= this value, the index will be convert to <code>NA</code>
in the correlation matrix. The default is <code>NULL</code>, which means no filter is done.
Note: if both argument p and min are non-Null, their relation is &quot;or&quot; rather than &quot;and&quot;.</p>
</td></tr>
<tr><td><code id="word_cor_+3A_min">min</code></td>
<td>
<p>if the correlation index is smaller than this value, it will be convert to <code>NA</code>.
The default is <code>NULL</code>, which means no filter is done.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list. The 1st element is the correlation matrix with diagonal converted to <code>NA</code>. 
The 2nd element is the p value matrix with diagonal converted to <code>NA</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
s &lt;- sample(1:10, 100, replace = TRUE)
m &lt;- matrix(s, nrow = 20)
myword&lt;- c("alpha", "apple", "cake", "data", "r")
colnames(m) &lt;- myword
mycor1 &lt;- word_cor(m, myword)
mycor2 &lt;- word_cor(m, myword, method = "pearson", min = 0.1, p = 0.4)
mt &lt;- t(m)
mycor3 &lt;- word_cor(mt, myword, type = "T", method = "spearman", p = 0.5)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
