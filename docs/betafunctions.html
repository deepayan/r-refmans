<!DOCTYPE html><html><head><title>Help for package betafunctions</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {betafunctions}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#afac'><p>Ascending (rising) factorial.</p></a></li>
<li><a href='#AMS'><p>Alpha Shape-Parameter Given Location-Parameters, Mean, and Variance a Four-Parameter Beta Probability Density Distribution.</p></a></li>
<li><a href='#AUC'><p>Area Under the ROC Curve.</p></a></li>
<li><a href='#Beta.2p.fit'><p>Method of Moment Estimates of Shape-Parameters of the Two-Parameter (Standard) Beta Distribution.</p></a></li>
<li><a href='#Beta.4p.fit'><p>Method of Moment Estimates of Shape- and Location Parameters of the Four-Parameter Beta Distribution.</p></a></li>
<li><a href='#Beta.gfx.poly.cdf'><p>Coordinate Generation for Marking an Area Under the Curve for the Beta Cumulative Probability Density Distribution.</p></a></li>
<li><a href='#Beta.gfx.poly.pdf'><p>Coordinate Generation for Marking an Area Under the Curve for the Beta Probability Density Distribution.</p></a></li>
<li><a href='#Beta.gfx.poly.qdf'><p>Coordinate Generation for Marking an Area Under the Curve for the Beta Quantile Density Distribution.</p></a></li>
<li><a href='#Beta.tp.fit'><p>Estimate Beta true-score distribution based on observed-score raw-moments and the effective test length.</p></a></li>
<li><a href='#betabinomialmoments'><p>Compute Moments of Beta-Binomial Probability Mass Functions.</p></a></li>
<li><a href='#betamedian'><p>Compute Median of Two- and Four-Parameter Beta Probability Density distribution.</p></a></li>
<li><a href='#betamode'><p>Compute Mode of Two- and Four-Parameter Beta Probability Density distribution.</p></a></li>
<li><a href='#betamoments'><p>Compute Moments of Two-to-Four Parameter Beta Probability Density Distributions.</p></a></li>
<li><a href='#binomialmoments'><p>Compute Moments of Binomial Probability Mass Functions.</p></a></li>
<li><a href='#BMS'><p>Beta Shape-Parameter Given Location-Parameters, Mean, and Variance of a Four-Parameter Beta Probability Density Distribution.</p></a></li>
<li><a href='#caStats'><p>Classification Accuracy Statistics.</p></a></li>
<li><a href='#cba'><p>Calculate Cronbach's Alpha reliability-coefficient from supplied variables.</p></a></li>
<li><a href='#ccStats'><p>Classification Consistency Statistics.</p></a></li>
<li><a href='#confmat'><p>Confusion matrix</p></a></li>
<li><a href='#dBeta.4P'><p>Probability Density under the Four-Parameter Beta Probability Density Distribution.</p></a></li>
<li><a href='#dBeta.pBeta'><p>An implementation of a Beta-density Compound Cumulative-Beta Distribution.</p></a></li>
<li><a href='#dBeta.pBinom'><p>An implementation of the Beta-density Compound Cumulative Binomial Distribution.</p></a></li>
<li><a href='#dBeta.pGammaBinom'><p>An implementation of a Beta-density Compound Cumulative Gamma-Binomial Distribution.</p></a></li>
<li><a href='#dBetaBinom'><p>Probability Mass under the Beta-Binomial Probability-Mass Distribution.</p></a></li>
<li><a href='#dBetacBinom'><p>Probability Mass function for Lord's Beta Compound Binomial Distribution.</p></a></li>
<li><a href='#dBetaMS'><p>Density Under a Specific Point of the Beta Probability Density Distribution with Specific Location Parameters, Mean, and Variance.</p></a></li>
<li><a href='#dcBinom'><p>Probability Mass function for Lord's Two-Term Approximation to the Compound Binomial Distribution.</p></a></li>
<li><a href='#dfac'><p>Descending (falling) factorial.</p></a></li>
<li><a href='#dGammaBinom'><p>Probability density function under the Gamma-extended Binomial distribution.</p></a></li>
<li><a href='#ETL'><p>Livingston and Lewis' &quot;Effective Test Length&quot;.</p></a></li>
<li><a href='#gchoose'><p>Gamma-extended Binomial coefficient (choose function).</p></a></li>
<li><a href='#HB.beta.tp.fit'><p>Estimate Beta True-Score Distribution Based on Observed-Score Raw-Moments and Lord's k.</p></a></li>
<li><a href='#HB.CA'><p>An Implementation of the Hanson and Brennan Approach to Estimate Classification Consistency and Accuracy based on Observed Test Scores and Test Reliability.</p></a></li>
<li><a href='#HB.CA.MC'><p>An Extension of the Hanson and Brennan Approach to Estimate Classification Consistency and Accuracy for Multiple Classifications based on Observed Test Scores and Test Reliability.</p></a></li>
<li><a href='#HB.ROC'><p>ROC curves for the Hanson and Brennan approach.</p></a></li>
<li><a href='#HB.tsm'><p>Proportional True-Score Distribution Raw Moments for the Hanson-Brennan Approach to Classification Accuracy and Consistency.</p></a></li>
<li><a href='#LABMSU'><p>Lower Location Parameter Given Shape Parameters, Mean, Variance, and Upper Location Parameter of a Four-Parameter Beta Probability Density Distribution.</p></a></li>
<li><a href='#LL.CA'><p>An Implementation of the Livingston and Lewis (1995) Approach to Estimate Classification Consistency and Accuracy based on Observed Test Scores and Test Reliability.</p></a></li>
<li><a href='#LL.CA.MC'><p>An Extension of the Livingston and Lewis (1995) Approach to Estimate Classification Consistency and Accuracy for Multiple Classifications based on Observed Test Scores and Test Reliability.</p></a></li>
<li><a href='#LL.ROC'><p>ROC curves for the Livingston and Lewis approach.</p></a></li>
<li><a href='#Lords.k'><p>Function for estimating &quot;Lord's k&quot; for Lord's two-term approximation to the compound binomial distribution.</p></a></li>
<li><a href='#MC.out.tabular'><p>Tabular organization of accuracy and consistency output from the <code>LL.CA.MC()</code> function.</p></a></li>
<li><a href='#mdlfit.gfx'><p>Graphical presentation of model fit for the Beta-Binomial classification accuracy and consistency model.</p></a></li>
<li><a href='#mdo'><p>Calculate McDonald's Omega reliability-coefficient from supplied variables.</p></a></li>
<li><a href='#MLA'><p>Most Likely True Alpha Value Given Observed Outcome.</p></a></li>
<li><a href='#MLB'><p>Most Likely True Beta Value Given Observed Outcome.</p></a></li>
<li><a href='#MLM'><p>Most Likely Mean of the Standard Beta Probability Density Distribution, Given that the Observation is Considered the Most Likely Observation of the Standard Beta Probability Density Distribution (i.e., the mode).</p></a></li>
<li><a href='#observedmoments'><p>Compute Moments of Observed Value Distribution.</p></a></li>
<li><a href='#pBeta.4P'><p>Cumulative Probability Function under the Four-Parameter Beta Probability Density Distribution.</p></a></li>
<li><a href='#pBetaBinom'><p>Cumulative Probability Function under the Beta-Binomial Probability Distribution.</p></a></li>
<li><a href='#pBetaMS'><p>Probability of Some Specific Observation under the Beta Probability Density Distribution with Specific Location Parameters, Mean, and Variance.</p></a></li>
<li><a href='#pcBinom'><p>Cumulative Probability Mass function for Lord's Two-Term Approximation to the Compound Binomial Distribution.</p></a></li>
<li><a href='#pGammaBinom'><p>Cumulative probability density function under the Gamma-extended Binomial distribution.</p></a></li>
<li><a href='#qBeta.4P'><p>Quantile Given Probability Under the Four-Parameter Beta Distribution.</p></a></li>
<li><a href='#qBetaMS'><p>Quantile Containing Specific Proportion of the Distribution, Given a Specific Probability of the Beta Probability Density Distribution with Specific Mean and Variance.</p></a></li>
<li><a href='#qGammaBinom'><p>Quantile function for the Gamma-extended Binomial distribution.</p></a></li>
<li><a href='#R.ETL'><p>Model Implied Reliability from Livingston and Lewis' &quot;Effective Test Length&quot;.</p></a></li>
<li><a href='#rBeta.4P'><p>Random Number Generation under the Four-Parameter Beta Probability Density Distribution.</p></a></li>
<li><a href='#rBetaBinom'><p>Random Number Generation under the Beta-Binomial Probability Mass Distribution.</p></a></li>
<li><a href='#rBetacBinom'><p>Random Number Generation under Lord's Beta Compound-Binomial Distribution.</p></a></li>
<li><a href='#rBetaMS'><p>Random Draw from the Beta Probability Density Distribution With Specific Mean and Variance.</p></a></li>
<li><a href='#rcBinom'><p>Random Number Generation under Lord's Two-Term Approximation to the Compound Binomial Distribution.</p></a></li>
<li><a href='#rGammaBinom'><p>Random number generation under the Gamma-extended Binomial distribution.</p></a></li>
<li><a href='#tsm'><p>Proportional true-score distribution raw moments from Livingston and Lewis' effective test-score and effective test-length.</p></a></li>
<li><a href='#UABMSL'><p>Upper Location Parameter Given Shape Parameters, Mean, Variance, and Lower Location Parameter of a Four-Parameter Beta Probability Density Distribution.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions for Working with Two- And Four-Parameter Beta
Probability Distributions and Psychometric Analysis of
Classifications</td>
</tr>
<tr>
<td>Version:</td>
<td>1.9.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Haakon Eidem Haakstad</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Haakon Eidem Haakstad &lt;h.e.haakstad@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Package providing a number of functions for working with Two- and 
    Four-parameter Beta and closely related distributions (i.e., the Gamma-
    Binomial-, and Beta-Binomial distributions).
        Includes, among other things: 
    - d/p/q/r functions for Four-Parameter Beta distributions and Generalized
    "Binomial" (continuous) distributions, and d/p/r- functions for Beta-
    Binomial distributions.
    - d/p/q/r functions for Two- and Four-Parameter Beta distributions
    parameterized in terms of their means and variances rather than their
    shape-parameters.
    - Moment generating functions for Binomial distributions, Beta-Binomial 
    distributions, and observed value distributions.
    - Functions for estimating classification accuracy and consistency, 
    making use of the Classical Test-Theory based 'Livingston and Lewis' (L&amp;L) 
    and 'Hanson and Brennan' approaches.
      A shiny app is available, providing a GUI for the L&amp;L approach when used 
    for binary classifications. For url to the app, see documentation for the 
    LL.CA() function.
    Livingston and Lewis (1995) &lt;<a href="https://doi.org/10.1111%2Fj.1745-3984.1995.tb00462.x">doi:10.1111/j.1745-3984.1995.tb00462.x</a>&gt;.
    Lord (1965) &lt;<a href="https://doi.org/10.1007%2FBF02289490">doi:10.1007/BF02289490</a>&gt;.
    Hanson (1991) <a href="https://files.eric.ed.gov/fulltext/ED344945.pdf">https://files.eric.ed.gov/fulltext/ED344945.pdf</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode">CC0</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-06 21:43:06 UTC; thorb</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-06 22:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='afac'>Ascending (rising) factorial.</h2><span id='topic+afac'></span>

<h3>Description</h3>

<p>Calculate the ascending (or rising) factorial of a value <code>x</code> of order <code>r</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>afac(x, r, method = "product")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="afac_+3A_x">x</code></td>
<td>
<p>A value for which the ascending factorial is to be calculated.</p>
</td></tr>
<tr><td><code id="afac_+3A_r">r</code></td>
<td>
<p>The power <code>x</code> is to be raised to.</p>
</td></tr>
<tr><td><code id="afac_+3A_method">method</code></td>
<td>
<p>The method by which the descending factorials are to be calculated. Default is <code>"product"</code> which uses direct arithmetic. Alternative is <code>"gamma"</code> which calculates the descending factorial using the Gamma function. The alternative method might be faster but might fail because the Gamma function is not defined for negative integers (returning Inf).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ascending factorial of value <code>x</code> raised to the <code>r</code>'th power.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To calculate the 4th ascending factorial for a value (e.g., 3.14):
afac(x = 3.14, r = 4)

# To calculate the 5th ascending factorial for values 3.14, 2.72, and 0.58:
afac(x = c(3.14, 2.72, 0.58), r = 5)
</code></pre>

<hr>
<h2 id='AMS'>Alpha Shape-Parameter Given Location-Parameters, Mean, and Variance a Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+AMS'></span>

<h3>Description</h3>

<p>Calculates the Beta value required to produce a Beta probability density distribution with defined moments and parameters. Be advised that not all combinations of moments and parameters can be satisfied (e.g., specifying mean, variance, skewness and kurtosis uniquely determines both location-parameters, meaning that the value of the lower-location parameter will take on which ever value it must, and cannot be specified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AMS(mean, variance, l = 0, u = 1, sd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AMS_+3A_mean">mean</code></td>
<td>
<p>The mean (first raw moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="AMS_+3A_variance">variance</code></td>
<td>
<p>The variance (second central moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="AMS_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the Beta distribution. Default is 0 (as it is for the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="AMS_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the Beta distribution. Default is 1 (as it is for the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="AMS_+3A_sd">sd</code></td>
<td>
<p>Optional alternative to specifying <code>var</code>. The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the required value for the Alpha shape-parameter in order to produce a  Beta probability density distribution with the target mean and variance, given specified lower- and upper bounds of the Beta distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0, rescaled to proportion
# of maximum.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, 0.25, 0.75, 5, 3)) / 100
hist(testdata, xlim = c(0, 1))

# To find the alpha shape-parameter of a Standard (two-parameter) Beta
# distribution with the same mean and variance as the observed-score
# distribution using AMS():
AMS(mean(testdata), var(testdata))
</code></pre>

<hr>
<h2 id='AUC'>Area Under the ROC Curve.</h2><span id='topic+AUC'></span>

<h3>Description</h3>

<p>Given a vector of false-positive rates and a vector of true-positive rates, calculate the area under the Receiver Operator Characteristic (ROC) curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC(FPR, TPR)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_+3A_fpr">FPR</code></td>
<td>
<p>Vector of False-Positive Rates.</p>
</td></tr>
<tr><td><code id="AUC_+3A_tpr">TPR</code></td>
<td>
<p>Vector of True-Positive Rates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value representing the area under the ROC curve.
</p>


<h3>Note</h3>

<p>Script originally retrieved and modified from https://blog.revolutionanalytics.com/2016/11/calculating-auc.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, 0.25, 0.75, 5, 3))
hist(testdata, xlim = c(0, 100))

# Suppose the cutoff value for attaining a pass is 50 items correct, and
# that the reliability of this test was estimated to 0.7. To calculate the
# necessary (x, y) coordinates to compute the area under the curve statistic
# one can use the LL.ROC() function with the argument
# raw.out = TRUE.
coords &lt;- LL.ROC(x = testdata, reliability = .7, truecut = 50, min = 0,
max = 100, raw.out = TRUE)

# To calculate and retrieve the Area Under the Curve (AUC) with the AUC()
# function, feed it the raw coordinates calculated above.
AUC(coords[, "FPR"], coords[, "TPR"])
</code></pre>

<hr>
<h2 id='Beta.2p.fit'>Method of Moment Estimates of Shape-Parameters of the Two-Parameter (Standard) Beta Distribution.</h2><span id='topic+Beta.2p.fit'></span>

<h3>Description</h3>

<p>An implementation of the method of moments estimation of two-parameter Beta distribution parameters. Given a vector of values, calculates the shape parameters required to produce a two-parameter Beta distribution with the same mean and variance (i.e., the first two moments) as the observed-score distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta.2p.fit(scores = NULL, mean = NULL, variance = NULL, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta.2p.fit_+3A_scores">scores</code></td>
<td>
<p>A vector of values to which the two-parameter Beta distribution is to be fitted. The values ought to fall within the [0, 1] interval.</p>
</td></tr>
<tr><td><code id="Beta.2p.fit_+3A_mean">mean</code></td>
<td>
<p>The mean of the target Beta distribution. Alternative to feeding the function raw scores.</p>
</td></tr>
<tr><td><code id="Beta.2p.fit_+3A_variance">variance</code></td>
<td>
<p>The variance of the target Beta distribution. Alternative to feeding the function raw scores.</p>
</td></tr>
<tr><td><code id="Beta.2p.fit_+3A_l">l</code></td>
<td>
<p>Optional specification of a lower-bound parameter of the Beta distribution. Default is 0 (i.e., the lower-bound of the Standard two-parameter Beta distribution).</p>
</td></tr>
<tr><td><code id="Beta.2p.fit_+3A_u">u</code></td>
<td>
<p>Optional specification of an upper-bound parameter of the Beta distribution. Default is 1 (i.e., the lower-bound of the Standard two-parameter Beta distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of parameter-values required to produce a Standard two-parameter Beta distribution with the same first two moments as the observed distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, 0.25, 0.75, 5, 3)) / 100
hist(testdata, xlim = c(0, 1), freq = FALSE)

# To fit and retrieve the parameters for a two-parameter Beta distribution
# to the observed-score distribution using Beta.2p.fit():
(params.2p &lt;- Beta.2p.fit(testdata))
curve(dbeta(x, params.2p$alpha, params.2p$beta), add = TRUE)
</code></pre>

<hr>
<h2 id='Beta.4p.fit'>Method of Moment Estimates of Shape- and Location Parameters of the Four-Parameter Beta Distribution.</h2><span id='topic+Beta.4p.fit'></span>

<h3>Description</h3>

<p>An implementation of the method of moments estimation of four-parameter Beta distribution parameters presented by Hanson (1991). Given a vector of values, calculates the shape- and location parameters required to produce a four-parameter Beta distribution with the same mean, variance, skewness and kurtosis (i.e., the first four moments) as the observed-score distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta.4p.fit(
  scores,
  mean = NULL,
  variance = NULL,
  skewness = NULL,
  kurtosis = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta.4p.fit_+3A_scores">scores</code></td>
<td>
<p>A vector of values to which the four-parameter Beta distribution is to be fitted.</p>
</td></tr>
<tr><td><code id="Beta.4p.fit_+3A_mean">mean</code></td>
<td>
<p>If scores are not supplied: specification of the mean for the target four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="Beta.4p.fit_+3A_variance">variance</code></td>
<td>
<p>If scores are not supplied: specification of the variance for the target four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="Beta.4p.fit_+3A_skewness">skewness</code></td>
<td>
<p>If scores are not supplied: specification of the skewness for the target four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="Beta.4p.fit_+3A_kurtosis">kurtosis</code></td>
<td>
<p>If scores are not supplied: specification of the kurtosis for the target four-parameter Beta distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of parameter-values required to produce a four-parameter Beta distribution with the same first four moments as the observed distribution.
</p>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes.American College Testing Research Report Series.
</p>
<p>Lord, Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, 0.25, 0.75, 5, 3))
hist(testdata, xlim = c(0, 100), freq = FALSE)

# To fit and retrieve the parameters for a four-parameter Beta distribution
# to the observed-score distribution using Beta.4p.fit():
(params.4p &lt;- Beta.4p.fit(testdata))
curve(dBeta.4P(x, params.4p$l, params.4p$u, params.4p$alpha, params.4p$beta), add = TRUE)
</code></pre>

<hr>
<h2 id='Beta.gfx.poly.cdf'>Coordinate Generation for Marking an Area Under the Curve for the Beta Cumulative Probability Density Distribution.</h2><span id='topic+Beta.gfx.poly.cdf'></span>

<h3>Description</h3>

<p>Plotting tool, producing a two-column matrix with values of <code>y</code> corresponding to locations on <code>x</code>. Useful for shading areas under the curve when tracing the line for the Beta cumulative probability functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta.gfx.poly.cdf(from, to, by, alpha, beta, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_from">from</code></td>
<td>
<p>The point of the <code>x</code>-axis from where to start producing <code>y</code>-density values.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_to">to</code></td>
<td>
<p>The point of the <code>x</code>-axis to where <code>y</code>-density values are to be produced.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_by">by</code></td>
<td>
<p>The resolution (or spacing) at which to produce <code>y</code>-density values.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape-parameter value for the Standard Beta cumulative probability distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_beta">beta</code></td>
<td>
<p>The beta shape-parameter for the Standard Beta cumulative probability distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.cdf_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the Beta distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-column matrix with cumulative probability-values of y to plot against corresponding location values of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To box in an area under a four-parameter Beta cumulative distribution with
# location parameters l = 0.25 and u = 0.75, and shape parameters
# alpha = 5 and beta = 3, from 0.4 to 0.6:
plot(NULL, xlim = c(0, 1), ylim = c(0, 1))
coords &lt;- Beta.gfx.poly.cdf(from = 0.4, to = 0.6, by = 0.001, alpha = 5,
beta = 3, l = 0.25, u = 0.75)
polygon(coords)
</code></pre>

<hr>
<h2 id='Beta.gfx.poly.pdf'>Coordinate Generation for Marking an Area Under the Curve for the Beta Probability Density Distribution.</h2><span id='topic+Beta.gfx.poly.pdf'></span>

<h3>Description</h3>

<p>Plotting tool, producing a two-column matrix with values of <code>y</code> corresponding to locations on <code>x</code>. Useful for shading areas under the curve when tracing the line for the Beta probability density functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta.gfx.poly.pdf(from, to, by, alpha, beta, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_from">from</code></td>
<td>
<p>The point of the <code>x</code>-axis from where to start producing <code>y</code>-density values.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_to">to</code></td>
<td>
<p>The point of the x-axis to where y-density values are to be produced.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_by">by</code></td>
<td>
<p>The resolution (or spacing) at which to produce y-density values.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_alpha">alpha</code></td>
<td>
<p>The alpha (first) shape-parameter value for the Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_beta">beta</code></td>
<td>
<p>The beta (second) shape-parameter for the Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.pdf_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the Beta distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-column matrix with density-values of y to plot against corresponding location values of x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To box in an area under a four-parameter Beta distribution with location
# parameters l = .25 and u = .75, and shape parameters alpha = 5 and
# rbeta = 3, from 0.4 to 0.6:
plot(NULL, xlim = c(0, 1), ylim = c(0, 7))
coords &lt;- Beta.gfx.poly.pdf(from = 0.4, to = 0.6, by = 0.001, alpha = 5,
beta = 3, l = 0.25, u = 0.75)
polygon(coords)
</code></pre>

<hr>
<h2 id='Beta.gfx.poly.qdf'>Coordinate Generation for Marking an Area Under the Curve for the Beta Quantile Density Distribution.</h2><span id='topic+Beta.gfx.poly.qdf'></span>

<h3>Description</h3>

<p>Plotting tool, producing a two-column matrix with values of <code>y</code> corresponding to locations on <code>x</code>. Useful for shading areas under the curve when tracing the line for the Beta probability quantile functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta.gfx.poly.qdf(from, to, by, alpha, beta, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_from">from</code></td>
<td>
<p>The point of the <code>x</code>-axis from where to start producing <code>y</code>-quantile values.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_to">to</code></td>
<td>
<p>The point of the <code>x</code>-axis to where <code>y</code>-quantile values are to be produced.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_by">by</code></td>
<td>
<p>The resolution (or spacing) at which to produce <code>y</code>-density values.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape-parameter value for the Standard Beta probability distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_beta">beta</code></td>
<td>
<p>The beta shape-parameter for the Standard Beta probability distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="Beta.gfx.poly.qdf_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the Beta distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two-column matrix with quantile-values of <code>y</code> to plot against corresponding location values of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To box in an area under a four-parameter Beta quantile distribution with
# location parameters l = .25 and u = 75, and shape parameters alpha = 5 and
# beta = 3, from .4 to .6:
plot(NULL, xlim = c(0, 1), ylim = c(0, 1))
coords &lt;- Beta.gfx.poly.qdf(from = 0.4, to = 0.6, by = 0.001, alpha = 5,
beta = 3, l = 0.25, u = 0.75)
polygon(coords)
</code></pre>

<hr>
<h2 id='Beta.tp.fit'>Estimate Beta true-score distribution based on observed-score raw-moments and the effective test length.</h2><span id='topic+Beta.tp.fit'></span>

<h3>Description</h3>

<p>Estimator for the Beta true-score distribution shape-parameters from the observed-score distribution and Livingston and Lewis' effective test length. Returns a list with entries representing the lower- and upper shape parameters (l and u), and the shape parameters (alpha and beta) of the four-parameters beta distribution, and the effective test length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta.tp.fit(
  x,
  min,
  max,
  etl = NULL,
  reliability = NULL,
  true.model = "4P",
  failsafe = FALSE,
  l = 0,
  u = 1,
  output = "parameters"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta.tp.fit_+3A_x">x</code></td>
<td>
<p>Vector of observed-scores.</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_min">min</code></td>
<td>
<p>The minimum possible score to attain on the test.</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_max">max</code></td>
<td>
<p>The maximum possible score to attain on the test.</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_etl">etl</code></td>
<td>
<p>The value of Livingston and Lewis' effective test length. See <code>?ETL()</code>. Not necessary to specify if reliability is supplied to the <code>reliability</code> argument.</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_reliability">reliability</code></td>
<td>
<p>Optional specification of the test-score reliability coefficient. If specified, overrides the input of the <code>etl</code> argument.</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_true.model">true.model</code></td>
<td>
<p>The type of Beta distribution which is to be fit to the moments of the true-score distribution. Options are <code>"4P"</code> and <code>"2P"</code>, where <code>"4P"</code> refers to the four-parameter (with the same mean, variance, skewness, and kurtosis), and <code>"2P"</code> the two-parameter solution where both location-parameters are specified (with the same mean and variance).</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_failsafe">failsafe</code></td>
<td>
<p>Logical. Whether to revert to a fail-safe two-parameter solution should the four-parameter solution contain invalid parameter estimates.</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_l">l</code></td>
<td>
<p>If <code>failsafe = TRUE</code> or <code>true.model = "2P"</code>: The lower-bound of the Beta distribution. Default is 0 (i.e., the lower-bound of the Standard, two-parameter Beta distribution).</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_u">u</code></td>
<td>
<p>If <code>failsafe = TRUE</code> or <code>true.model = "2P"</code>: The upper-bound of the Beta distribution. Default is 1 (i.e., the upper-bound of the Standard, two-parameter Beta distribution).</p>
</td></tr>
<tr><td><code id="Beta.tp.fit_+3A_output">output</code></td>
<td>
<p>Option to specify true-score distribution moments as output if the value of the output argument does not equal <code>"parameters"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the parameter values of a four-parameter Beta distribution. &quot;l&quot; is the lower location-parameter, &quot;u&quot; the upper location-parameter, &quot;alpha&quot; the first shape-parameter, &quot;beta&quot; the second shape-parameter, and &quot;etl&quot; the effective test length.
</p>


<h3>References</h3>

<p>Hanson, B. A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing Research Report Series. Retrieved from https://files.eric.ed.gov/fulltext/ED344945.pdf
</p>
<p>Lord, F. M. (1965). A strong true-score theory, with applications. Psychometrika. 30(3). pp. 239&ndash;270. doi: 10.1007/BF02289490
</p>
<p>Rogosa, D. &amp;  Finkelman, M. (2004). How Accurate Are the STAR Scores for Individual Students? An Interpretive Guide. Retrieved from http://statweb.stanford.edu/~rag/accguide/guide04.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say 1000 individuals take a 100-item test
# where all items are equally difficult, and the true-score distribution
# is a four-parameter Beta distribution with location parameters l = 0.25,
# u = 0.75, alpha = 5, and beta = 3:
set.seed(12)
testdata &lt;- rbinom(1000, 100, rBeta.4P(1000, 0.25, 0.75, 5, 3))

# Since this test contains items which are all equally difficult, the true
# effective test length (etl) is the actual test length. I.e., etl = 100.
# To estimate the four-parameter Beta distribution parameters underlying
# the draws from the binomial distribution:
Beta.tp.fit(testdata, 0, 100, 100)

# Imagine a case where the fitting procedure produces an impermissible
# estimate (e.g., l &lt; 0 or u &gt; 1).
set.seed(1234)
testdata &lt;- rbinom(1000, 50, rBeta.4P(1000, 0.25, 0.75, 5, 3))
Beta.tp.fit(testdata, 0, 50, 50)

# This example produced an l-value estimate less than 0. One way of
# dealing with such an occurrence is to revert to a two-parameter
# model, specifying the l and u parameters and estimating the
# alpha and beta parameters necessary to produce a Beta distribution
# with the same mean and variance as the estimated true-score distribution.

# Suppose you have good theoretical reasons to fix the l parameter at a
# value of 0.25 (e.g., the test is composed of multiple-choice questions
# with four response-options, resulting in a 25% chance of guessing the
# correct answer). The l-parameter could be specified to this theoretically
# justified value, and the u-parameter could be specified to be equal to the
# estimate above (u = 0.7256552) as such:
Beta.tp.fit(testdata, 0, 50, 50, true.model = "2P", l = 0.25, u = 0.7256552)
</code></pre>

<hr>
<h2 id='betabinomialmoments'>Compute Moments of Beta-Binomial Probability Mass Functions.</h2><span id='topic+betabinomialmoments'></span>

<h3>Description</h3>

<p>Computes Raw, Central, or Standardized moment properties of defined Beta-Binomial probability mass functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betabinomialmoments(
  N,
  l,
  u,
  alpha,
  beta,
  types = c("raw", "central", "standardized"),
  orders = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betabinomialmoments_+3A_n">N</code></td>
<td>
<p>Number of trials.</p>
</td></tr>
<tr><td><code id="betabinomialmoments_+3A_l">l</code></td>
<td>
<p>The first (lower) location-parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="betabinomialmoments_+3A_u">u</code></td>
<td>
<p>The second (upper) location-parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="betabinomialmoments_+3A_alpha">alpha</code></td>
<td>
<p>The alpha (first) shape-parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="betabinomialmoments_+3A_beta">beta</code></td>
<td>
<p>The beta (second) shape-parameter of the Beta-distribution.</p>
</td></tr>
<tr><td><code id="betabinomialmoments_+3A_types">types</code></td>
<td>
<p>A character vector determining which moment-types are to be calculated. Permissible values are &quot;raw&quot;, &quot;central&quot;, and &quot;standardized&quot;.</p>
</td></tr>
<tr><td><code id="betabinomialmoments_+3A_orders">orders</code></td>
<td>
<p>The number of moment-orders to be calculated for each of the moment-types.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of moment types, each a list of moment orders.
</p>


<h3>References</h3>

<p>Hanson, B. A (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing Research Report Series.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume 100 observations of a discrete variable with probabilities of
# positive outcomes adhering to a four-parameter Beta distribution with
# location parameters l = 0.25 and u = .95, and shape parameters a = 5 and
# b = 3. To compute the first four raw, central, and standardized moments of
# this distrubution using betabinomialmoments():
betabinomialmoments(N = 100, l = .25, u = .95, alpha = 5, beta = 3,
types = c("raw", "central", "standardized"), orders = 4)
</code></pre>

<hr>
<h2 id='betamedian'>Compute Median of Two- and Four-Parameter Beta Probability Density distribution.</h2><span id='topic+betamedian'></span>

<h3>Description</h3>

<p>Computes the median of a Beta distribution with specified shape- and location parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betamedian(alpha, beta, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betamedian_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape parameter.</p>
</td></tr>
<tr><td><code id="betamedian_+3A_beta">beta</code></td>
<td>
<p>The beta shape parameter.</p>
</td></tr>
<tr><td><code id="betamedian_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter. Default set to <code>0</code>.</p>
</td></tr>
<tr><td><code id="betamedian_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter. Default set to <code>1</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># To calculate the median of a two-parameter (standard) Beta distribution with
# shape parameters alpha = 5 and beta = 3:
betamedian(alpha = 5, beta = 3)

# To calculate the median of a four-parameter Beta distribution with shape
# parameters alpha = 5 and beta = 3, and location parameters l = 25 and
# u = 150:
betamedian(alpha = 5, beta = 3, l = 25, u = 150)
</code></pre>

<hr>
<h2 id='betamode'>Compute Mode of Two- and Four-Parameter Beta Probability Density distribution.</h2><span id='topic+betamode'></span>

<h3>Description</h3>

<p>Computes the mode of a Beta distribution with specified shape- and location parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betamode(alpha, beta, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betamode_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape parameter of the Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="betamode_+3A_beta">beta</code></td>
<td>
<p>The beta shape parameter of the Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="betamode_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter of a four-parameter distribution. Default set to <code>0</code>.</p>
</td></tr>
<tr><td><code id="betamode_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter of a four-parameter distribution. Default set to <code>1</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># To calculate the mode of a two-parameter (standard) Beta distribution with
# shape parameters alpha = 5 and beta = 3:
betamode(alpha = 5, beta = 3)

# To calculate the mode of a four-parameter Beta distribution with shape
# parameters alpha = 5 and beta = 3, and location parameters l = 25 and
# u = 150:
betamode(alpha = 5, beta = 3, l = 25, u = 150)
</code></pre>

<hr>
<h2 id='betamoments'>Compute Moments of Two-to-Four Parameter Beta Probability Density Distributions.</h2><span id='topic+betamoments'></span>

<h3>Description</h3>

<p>Computes Raw, Central, or Standardized moment properties of defined Beta probability density distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betamoments(
  alpha,
  beta,
  l = 0,
  u = 1,
  types = c("raw", "central", "standardized"),
  orders = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betamoments_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape parameter.</p>
</td></tr>
<tr><td><code id="betamoments_+3A_beta">beta</code></td>
<td>
<p>The beta shape parameter.</p>
</td></tr>
<tr><td><code id="betamoments_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="betamoments_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="betamoments_+3A_types">types</code></td>
<td>
<p>A character vector determining which moment-types are to be calculated. Permissible values are &quot;raw&quot;, &quot;central&quot;, and &quot;standardized&quot;.</p>
</td></tr>
<tr><td><code id="betamoments_+3A_orders">orders</code></td>
<td>
<p>The number of moment-orders to be calculated for each of the moment-types.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of moment types, each a list of moment orders.
</p>


<h3>References</h3>

<p>Hanson, B. A (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing Research Report Series.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a four-parameter Beta distribution with
# location parameters l = 0.25 and u = 0.75, and shape parameters alpha = 5
# and beta = 3. To compute the first four raw, central, and standardized
# moments of this distribution using betamoments():
betamoments(alpha = 5, beta = 3, l = 0.25, u = 0.75,
types = c("raw", "central", "standardized"), orders = 4)
</code></pre>

<hr>
<h2 id='binomialmoments'>Compute Moments of Binomial Probability Mass Functions.</h2><span id='topic+binomialmoments'></span>

<h3>Description</h3>

<p>Computes Raw, Central, or Standardized moment properties of defined Binomial probability mass functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binomialmoments(n, p, types = c("raw", "central", "standardized"), orders = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomialmoments_+3A_n">n</code></td>
<td>
<p>Number of Binomial trials</p>
</td></tr>
<tr><td><code id="binomialmoments_+3A_p">p</code></td>
<td>
<p>Probability of success per trial.</p>
</td></tr>
<tr><td><code id="binomialmoments_+3A_types">types</code></td>
<td>
<p>A character vector determining which moment-types are to be calculated. Permissible values are &quot;raw&quot;, &quot;central&quot;, and &quot;standardized&quot;.</p>
</td></tr>
<tr><td><code id="binomialmoments_+3A_orders">orders</code></td>
<td>
<p>The number of moment-orders to be calculated for each of the moment-types.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of moment types, each a list of moment orders.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a Binomial distribution with number of trials
# equal to 100 and a probability of success on each trial of 0.75. To compute
# the first four raw, central, and standardized moments of this distribution
# using binomialmoments():
binomialmoments(n = 100, p = 0.75, types = c("raw", "central",
"standardized"), orders = 4)

# To only compute the (e.g.) standardized moments:
binomialmoments(n = 100, p = 0.75, types = "standardized")

# To compute moments beyond the fourth order (e.g., the sixth):
binomialmoments(n = 100, p = 0.75, orders = 6)
</code></pre>

<hr>
<h2 id='BMS'>Beta Shape-Parameter Given Location-Parameters, Mean, and Variance of a Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+BMS'></span>

<h3>Description</h3>

<p>Calculates the Beta value required to produce a Beta probability density distribution with defined moments and parameters. Be advised that not all combinations of moments and parameters can be satisfied (e.g., specifying mean, variance, skewness and kurtosis uniquely determines both location-parameters, meaning that the value of the lower-location parameter will take on which ever value it must, and cannot be specified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BMS(mean, variance, l = 0, u = 1, sd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BMS_+3A_mean">mean</code></td>
<td>
<p>The mean (first raw moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="BMS_+3A_variance">variance</code></td>
<td>
<p>The variance (second central moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="BMS_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the Beta distribution. Default is 0 (as it is for the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="BMS_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the Beta distribution. Default is 1 (as it is for the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="BMS_+3A_sd">sd</code></td>
<td>
<p>Optional alternative to specifying <code>var</code>. The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the required value for the Beta shape-parameter in order to produce a Standard Beta probability density distribution with the target mean and variance, given specified lower- and upper bounds of the Beta distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0, rescaled to proportion
# of maximum.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, 0.25, 0.75, 5, 3)) / 100
hist(testdata, xlim = c(0, 1))

# To find the beta shape-parameter of a Standard (two-parameter) Beta
# distribution with the same mean and variance as the observed-score
# distribution using BMS():
BMS(mean(testdata), var(testdata))

# To find the beta shape-parameter of a four-parameter Beta
# distribution with specified lower- and upper-bounds of l = 0.25 and
# u = 0.75 using BMS:
BMS(mean(testdata), var(testdata), 0.25, 0.75)
</code></pre>

<hr>
<h2 id='caStats'>Classification Accuracy Statistics.</h2><span id='topic+caStats'></span>

<h3>Description</h3>

<p>Provides a set of statistics often used for conveying information regarding the certainty of classifications based on tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>caStats(tp, tn, fp, fn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="caStats_+3A_tp">tp</code></td>
<td>
<p>The frequency or rate of true-positive classifications.</p>
</td></tr>
<tr><td><code id="caStats_+3A_tn">tn</code></td>
<td>
<p>The frequency or rate of true-negative classifications.</p>
</td></tr>
<tr><td><code id="caStats_+3A_fp">fp</code></td>
<td>
<p>The frequency or rate of false-positive classifications.</p>
</td></tr>
<tr><td><code id="caStats_+3A_fn">fn</code></td>
<td>
<p>The frequency or rate of false-negative classifications.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of diagnostic performance statistics based on true/false positive/negative statistics. Specifically, the sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), Youden's J. (Youden.J), and Accuracy.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(1000, 100, rBeta.4P(1000, 0.25, 0.75, 5, 3))
hist(testdata, xlim = c(0, 100))

# Suppose the cutoff value for attaining a pass is 50 items correct, and
# that the reliability of this test was estimated to 0.7. First, compute the
# estimated confusion matrix using LL.CA():
cmat &lt;- LL.CA(x = testdata, reliability = 0.7, cut = 50, min = 0,
max = 100)$confusionmatrix

# To estimate and retrieve diagnostic performance statistics using caStats(),
# feed it the appropriate entries of the confusion matrix.
caStats(tp = cmat["True", "Positive"], tn = cmat["True", "Negative"],
fp = cmat["False", "Positive"], fn = cmat["False", "Negative"])
</code></pre>

<hr>
<h2 id='cba'>Calculate Cronbach's Alpha reliability-coefficient from supplied variables.</h2><span id='topic+cba'></span>

<h3>Description</h3>

<p>Calculates Cronbach's Alpha reliability coefficient of the sum-score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cba(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cba_+3A_x">x</code></td>
<td>
<p>A data-frame or matrix of numerical values where rows represent respondents, and columns represent items.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Cronbach's Alpha for the sum-score of supplied variables.
</p>


<h3>Note</h3>

<p>Missing values are treated by passing <code>na.rm = TRUE</code> to the <code>var</code> function call.
</p>
<p>Be aware that this function does not issue a warning if there are negative correlations between variables in the supplied data-set.
</p>


<h3>References</h3>

<p>Cronbach, L.J. (1951). Coefficient alpha and the internal structure of tests. Psychometrika 16, 297&ndash;334. doi: 10.1007/BF02310555
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say 100 students take a 50-item long test
# where all items are equally difficult.
set.seed(1234)
p.success &lt;- rBeta.4P(100, 0.25, 0.75, 5, 3)
for (i in 1:50) {
  if (i == 1) {
    rawdata &lt;- matrix(nrow = 100, ncol = 50)
  }
  rawdata[, i] &lt;- rbinom(100, 1, p.success)
}
# To calculate Cronbach's Alpha for this test:
cba(rawdata)
</code></pre>

<hr>
<h2 id='ccStats'>Classification Consistency Statistics.</h2><span id='topic+ccStats'></span>

<h3>Description</h3>

<p>Provides a set of statistics often used for conveying information regarding the consistency of classifications based on tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ccStats(ii, ij, ji, jj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ccStats_+3A_ii">ii</code></td>
<td>
<p>The frequency or rate of consistent classifications into category &quot;i&quot;.</p>
</td></tr>
<tr><td><code id="ccStats_+3A_ij">ij</code></td>
<td>
<p>The frequency or rate of inconsistent classifications into categories &quot;i&quot; and &quot;j&quot;.</p>
</td></tr>
<tr><td><code id="ccStats_+3A_ji">ji</code></td>
<td>
<p>The frequency or rate of inconsistent classifications into categories &quot;j&quot; and &quot;i&quot;.</p>
</td></tr>
<tr><td><code id="ccStats_+3A_jj">jj</code></td>
<td>
<p>The frequency or rate of consistent classifications into category &quot;j&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of classification consistency statistics. Specifically, the coefficient of consistent classification (p), the coefficient of consistent classification by chance (p_c), the proportion of positive classifications due to chance (p_c_pos), the proportion of negative classifications due to chance (p_c_neg), and Cohen's Kappa coefficient.
</p>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(1000, 100, rBeta.4P(1000, .25, .75, 5, 3))
hist(testdata, xlim = c(0, 100))

# Suppose the cutoff value for attaining a pass is 50 items correct, and
# that the reliability of this test was estimated to 0.7. First, compute the
# estimated consistency matrix using LL.CA():
cmat &lt;- LL.CA(x = testdata, reliability = .7, cut = 50, min = 0,
max = 100)$consistencymatrix

# To estimate and retrieve consistency statistics using ccStats(),
# feed it the appropriate entries of the consistency matrix.
ccStats(ii = cmat["i", "i"], ij = cmat["i", "j"],
ji = cmat["j", "i"], jj = cmat["j", "j"])
</code></pre>

<hr>
<h2 id='confmat'>Confusion matrix</h2><span id='topic+confmat'></span>

<h3>Description</h3>

<p>Organizes supplied values of true and false positives and negatives into a confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confmat(tp, tn, fp, fn, output = "freq")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confmat_+3A_tp">tp</code></td>
<td>
<p>The frequency or rate of true-positive classifications.</p>
</td></tr>
<tr><td><code id="confmat_+3A_tn">tn</code></td>
<td>
<p>The frequency or rate of true-negative classifications.</p>
</td></tr>
<tr><td><code id="confmat_+3A_fp">fp</code></td>
<td>
<p>The frequency or rate of false-positive classifications.</p>
</td></tr>
<tr><td><code id="confmat_+3A_fn">fn</code></td>
<td>
<p>The frequency or rate of false-negative classifications.</p>
</td></tr>
<tr><td><code id="confmat_+3A_output">output</code></td>
<td>
<p>Whether the returned output reflects frequencies or proportions. Defaults to returning frequencies.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A confusion matrix organizing the input values of true and false positive and negatives.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some true and observed conditions.
set.seed(1234)
true.ability &lt;- rbeta(50, 4, 4)
true.category &lt;- ifelse(true.ability &lt; 0.5, 0, 1)
observed.score &lt;- rbinom(50, 50, true.ability)
observed.category &lt;- ifelse(observed.score &lt; 25, 0, 1)
# Calculate the frequencies of true and false positives and negatives based on the true and
# observed conditions.
TP &lt;- sum(ifelse(observed.category == 0 &amp; true.category == 0, 1, 0))
FP &lt;- sum(ifelse(observed.category == 0 &amp; true.category != 0, 1, 0))
TN &lt;- sum(ifelse(observed.category == 1 &amp; true.category == 1, 1, 0))
FN &lt;- sum(ifelse(observed.category == 1 &amp; true.category != 1, 1, 0))
# Organize the above values in a confusion matrix using the confmat function:
confmat(tp = TP, fp = FP, tn = TN, fn = FN)
</code></pre>

<hr>
<h2 id='dBeta.4P'>Probability Density under the Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+dBeta.4P'></span>

<h3>Description</h3>

<p>Gives the density at desired values of <code>x</code> under the Four-Parameter Beta Probability Density Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBeta.4P(x, l, u, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBeta.4P_+3A_x">x</code></td>
<td>
<p>Value of <code>x</code>.</p>
</td></tr>
<tr><td><code id="dBeta.4P_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="dBeta.4P_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="dBeta.4P_+3A_alpha">alpha</code></td>
<td>
<p>The first shape parameter.</p>
</td></tr>
<tr><td><code id="dBeta.4P_+3A_beta">beta</code></td>
<td>
<p>The second shape parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for the probability density at specified values of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a four-parameter Beta distribution with
# location parameters l = 0.25 and u = 0.75, and shape parameters alpha = 5
# and beta = 3. To compute the probability density at a specific point of
# the distribution (e.g., 0.5) using dBeta.4P():
dBeta.4P(x = 0.5, l = 0.25, u = 0.75, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='dBeta.pBeta'>An implementation of a Beta-density Compound Cumulative-Beta Distribution.</h2><span id='topic+dBeta.pBeta'></span>

<h3>Description</h3>

<p>The Beta Compound Beta distribution: The product of the four-parameter Beta probability density function and the Beta cumulative probability function. Used in the Livingston and Lewis approach to classification accuracy and consistency, the output can be interpreted as the population density of passing scores produced at &quot;x&quot; (a value of true-score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBeta.pBeta(x, l, u, alpha, beta, n, c, lower.tail = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBeta.pBeta_+3A_x">x</code></td>
<td>
<p>x-axis input for which <code>p</code> (proportion or probability) is to be computed.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_l">l</code></td>
<td>
<p>The lower-bound of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_u">u</code></td>
<td>
<p>The upper-bound of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape-parameter of the Beta density distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_beta">beta</code></td>
<td>
<p>The beta shape-parameter of the Beta density distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_n">n</code></td>
<td>
<p>The number of trials for the Beta cumulative probability distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_c">c</code></td>
<td>
<p>The &quot;true-cut&quot; (proportion) of on the Beta cumulative probability distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBeta_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. Whether to compute the lower or upper tail of the Beta cumulative probability distribution. Default is <code>FALSE</code> (i.e., upper tail).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes.American College Testing Research Report Series.
</p>
<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>
<p>Lord, Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Given a four-parameter Beta distribution with parameters l = 0.25, u = 0.75,
# alpha = 5, and beta = 3, and a Beta error distribution with number of
# trials (n) = 10 and a cutoff-point (c) at 50% correct (i.e., proportion correct
# of 0.5), the population density of passing scores produced at true-score
# (x) = 0.5 can be calculated as:
dBeta.pBeta(x = 0.5, l = 0.25, u = 0.75, a = 5, b = 3, n = 10, c = 0.5)

# Conversely, the density of failing scores produced at x can be calculated
# by passing the additional argument "lower.tail = TRUE" to the function.
# That is:
dBeta.pBeta(x = 0.5, l = 0.25, u = 0.75, a = 5, b = 3, n = 10, c = 0.5,
lower.tail = TRUE)

# By integration, the population proportion of (e.g.) passing scores in some
# region of the true-score distribution (e.g. between 0.25 and 0.5) can be
# calculated as:
integrate(function(x) { dBeta.pBeta(x, 0.25, 0.75, 5, 3, 10, 0.5) },
lower = 0.25, upper = 0.5)
</code></pre>

<hr>
<h2 id='dBeta.pBinom'>An implementation of the Beta-density Compound Cumulative Binomial Distribution.</h2><span id='topic+dBeta.pBinom'></span>

<h3>Description</h3>

<p>The Beta Compound Binomial distribution: The product of the four-parameter Beta probability density function and the binomial cumulative probability mass function. Used in the Livingston and Lewis approach to classification accuracy and consistency, the output can be interpreted as the population density of passing scores produced at &quot;x&quot; (a value of true-score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBeta.pBinom(x, l, u, alpha, beta, n, c, lower.tail = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBeta.pBinom_+3A_x">x</code></td>
<td>
<p>x-axis input for which <code>p</code> (proportion or probability) is to be computed.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_l">l</code></td>
<td>
<p>The lower-bound of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_u">u</code></td>
<td>
<p>The upper-bound of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape-parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_beta">beta</code></td>
<td>
<p>The beta shape-parameter of the Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_n">n</code></td>
<td>
<p>The number of trials for the Binomial distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_c">c</code></td>
<td>
<p>The &quot;true-cut&quot; (proportion) of the Binomial distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pBinom_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. Whether to compute the lower or upper tail of the Binomial distribution. Default is <code>FALSE</code> (i.e., upper tail).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Binomial distribution cut-point is up-to but not including, unlike the standard behaviour of base-R pbinom() function.
</p>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes.American College Testing Research Report Series.
</p>
<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>
<p>Lord, Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Given a four-parameter Beta distribution with parameters l = 0.25, u = 0.75,
# alpha = 5, and beta = 3, and a Binomial error distribution with number of
# trials (n) = 10 and a cutoff-point (c) at 50% correct (i.e., proportion correct
# of 0.5), the population density of passing scores produced at true-score
# (x) = 0 can be calculated as:
dBeta.pBinom(x = 0.5, l = 0.25, u = 0.75, a = 5, b = 3, n = 10, c = 0.5)

# Conversely, the density of failing scores produced at x can be calculated
# by passing the additional argument "lower.tail = TRUE" to the function.
# That is:
dBeta.pBinom(x = 0.5, l = 0.25, u = 0.75, a = 5, b = 3, n = 10, c = 0.5,
lower.tail = TRUE)

#By integration, the population proportion of (e.g.) passing scores in some
#region of the true-score distribution (e.g. between 0.25 and 0.5) can be
#calculated as:
integrate(function(x) { dBeta.pBinom(x, 0.25, .75, 5, 3, 10, 0.5) },
lower = 0.25, upper = 0.5)
</code></pre>

<hr>
<h2 id='dBeta.pGammaBinom'>An implementation of a Beta-density Compound Cumulative Gamma-Binomial Distribution.</h2><span id='topic+dBeta.pGammaBinom'></span>

<h3>Description</h3>

<p>The Beta Compound Binomial distribution: The product of the four-parameter Beta probability density function and the binomial cumulative probability mass function. Used in the Livingston and Lewis approach to classification accuracy and consistency, the output can be interpreted as the population density of passing scores produced at &quot;x&quot; (a value of true-score).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBeta.pGammaBinom(x, l, u, alpha, beta, n, c, lower.tail = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBeta.pGammaBinom_+3A_x">x</code></td>
<td>
<p>x-axis input for which <code>p</code> (proportion or probability) is to be computed.</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_l">l</code></td>
<td>
<p>The lower-bound of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_u">u</code></td>
<td>
<p>The upper-bound of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape-parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_beta">beta</code></td>
<td>
<p>The beta shape-parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_n">n</code></td>
<td>
<p>The number of &quot;trials&quot; for the Gamma-Binomial distribution.</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_c">c</code></td>
<td>
<p>The &quot;true-cut&quot; (proportion) on the Gamma-Binomial distribution. Need not be an integer (unlike Binomial distribution).</p>
</td></tr>
<tr><td><code id="dBeta.pGammaBinom_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. Whether to compute the lower or upper tail of the Binomial distribution. Default is <code>FALSE</code> (i.e., upper tail).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes.American College Testing Research Report Series.
</p>
<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>
<p>Lord, Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>
<p>Loeb, D. E. (1992). A generalization of the binomial coefficients. Discrete Mathematics, 105(1-3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Given a four-parameter Beta distribution with parameters l = 0.25, u = 0.75,
# alpha = 5, and beta = 3, and a Binomial error distribution with number of
# trials (n) = 10 and a cutoff-point (c) at 50% correct (i.e., proportion correct
# of 0.5), the population density of passing scores produced at true-score
# (x) = 0 can be calculated as:
dBeta.pGammaBinom(x = 0.5, l = 0.25, u = 0.75, a = 5, b = 3, n = 10, c = 0.5)

# Conversely, the density of failing scores produced at x can be calculated
# by passing the additional argument "lower.tail = TRUE" to the function.
# That is:
dBeta.pGammaBinom(x = 0.5, l = 0.25, u = 0.75, a = 5, b = 3, n = 10.1, c = 0.5,
lower.tail = TRUE)

#By integration, the population proportion of (e.g.) passing scores in some
#region of the true-score distribution (e.g. between 0.25 and 0.5) can be
#calculated as:
integrate(function(x) { dBeta.pGammaBinom(x, 0.25, 0.75, 5, 3, 10, 0.5) },
lower = 0.25, upper = 0.5)
</code></pre>

<hr>
<h2 id='dBetaBinom'>Probability Mass under the Beta-Binomial Probability-Mass Distribution.</h2><span id='topic+dBetaBinom'></span>

<h3>Description</h3>

<p>Gives the density at <code>x</code> under the Beta-Binomial PMF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBetaBinom(x, N, l, u, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBetaBinom_+3A_x">x</code></td>
<td>
<p>Value of <code>x</code> (a specific number of successes).</p>
</td></tr>
<tr><td><code id="dBetaBinom_+3A_n">N</code></td>
<td>
<p>The total number of trials.</p>
</td></tr>
<tr><td><code id="dBetaBinom_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="dBetaBinom_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="dBetaBinom_+3A_alpha">alpha</code></td>
<td>
<p>The first shape parameter.</p>
</td></tr>
<tr><td><code id="dBetaBinom_+3A_beta">beta</code></td>
<td>
<p>The second shape parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for the probability mass at <code>x</code> given the specified Beta-Binomial distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a Beta-Binomial distribution with 100 number
# of trials, and with probabilities of successful trials drawn from a four-
# parameter Beta distribution with location parameters l = 0.25 and u = 0.75
# and shape parameters alpha = 5 and beta = 3. To compute the probability
# density at a specific point of the distribution (e.g., 50):
dBetaBinom(x = 50, N = 100, l = 0.25, u = 0.75, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='dBetacBinom'>Probability Mass function for Lord's Beta Compound Binomial Distribution.</h2><span id='topic+dBetacBinom'></span>

<h3>Description</h3>

<p>Gives the density at <code>x</code> under the Beta Compound-Binomial distribution, where the Compound-Binomial distribution is Lord's two-term approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBetacBinom(x, N, k, l, u, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBetacBinom_+3A_x">x</code></td>
<td>
<p>Value of <code>x</code> (a specific number of successes).</p>
</td></tr>
<tr><td><code id="dBetacBinom_+3A_n">N</code></td>
<td>
<p>Number of trials.</p>
</td></tr>
<tr><td><code id="dBetacBinom_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function).</p>
</td></tr>
<tr><td><code id="dBetacBinom_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBetacBinom_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBetacBinom_+3A_alpha">alpha</code></td>
<td>
<p>The first shape-parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="dBetacBinom_+3A_beta">beta</code></td>
<td>
<p>The second shape-parameter of the four-parameter Beta distribution.
# Assume some variable follows a Beta compound Binomial distribution with 100
# trials, Lord's k = 1, and probabilities of successful trials drawn from a
# four-parameter Beta distribution with location-parameters l = .15 and u =
# .85, and shape parameters alpha = 6 and beta = 4. To compute the
# probability density at a specific point of the distribution (e.g., 50):
dBetacBinom(x = 50, N = 100, k = 1, l = .15, u = .85, alpha = 6, beta = 4)</p>
</td></tr>
</table>

<hr>
<h2 id='dBetaMS'>Density Under a Specific Point of the Beta Probability Density Distribution with Specific Location Parameters, Mean, and Variance.</h2><span id='topic+dBetaMS'></span>

<h3>Description</h3>

<p>Calculates the density under specific points of the Standard Beta probability density distribution with defined mean and variance or standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBetaMS(x, mean, variance = NULL, sd = NULL, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBetaMS_+3A_x">x</code></td>
<td>
<p>A specific point on the x-axis of the Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="dBetaMS_+3A_mean">mean</code></td>
<td>
<p>The mean of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="dBetaMS_+3A_variance">variance</code></td>
<td>
<p>The variance of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="dBetaMS_+3A_sd">sd</code></td>
<td>
<p>The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="dBetaMS_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter. Default set to 0 (the standard Beta distribution).</p>
</td></tr>
<tr><td><code id="dBetaMS_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter. Default set to 1 (the standard Beta distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the required value for the beta Shape-parameter in order to produce a Standard Beta probability density distribution with the target mean and variance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To compute the density at a specific point (e.g., 0.5) along the Standard
# (two-parameter) Probability Density Distribution with mean of 0.6 and variance of 0.04:
dBetaMS(x = 0.5, mean = 0.6, variance = 0.04)

# To compute the density at a specific point (e.g., 50) along the four-
# parameter Beta distribution with a mean of 60, variance of 400, and lower-
# bound of 0 and upper-bound of 100:
dBetaMS(x = 50, mean = 60, variance = 400, l = 0, u = 100)
</code></pre>

<hr>
<h2 id='dcBinom'>Probability Mass function for Lord's Two-Term Approximation to the Compound Binomial Distribution.</h2><span id='topic+dcBinom'></span>

<h3>Description</h3>

<p>Gives the density at <code>x</code> under Lord's two-term approximation to the compound Binomial PMF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcBinom(x, N, k, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dcBinom_+3A_x">x</code></td>
<td>
<p>Value of <code>x</code> (a specific number of successes).</p>
</td></tr>
<tr><td><code id="dcBinom_+3A_n">N</code></td>
<td>
<p>The total number of trials.</p>
</td></tr>
<tr><td><code id="dcBinom_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function).</p>
</td></tr>
<tr><td><code id="dcBinom_+3A_p">p</code></td>
<td>
<p>Probability of success for each trial.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a compound Binomial distribution with 100
# trials, a 50% probability of success on each trial, and Lord's k = 1. To
# compute the probability density at a specific point of the distribution
# (e.g., 50):
dcBinom(x = 50, N = 100, k = 1, p = .5)
</code></pre>

<hr>
<h2 id='dfac'>Descending (falling) factorial.</h2><span id='topic+dfac'></span>

<h3>Description</h3>

<p>Calculate the descending (or falling) factorial of a value <code>x</code> of order <code>r</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfac(x, r, method = "product")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfac_+3A_x">x</code></td>
<td>
<p>A value for which the descending factorial is to be calculated.</p>
</td></tr>
<tr><td><code id="dfac_+3A_r">r</code></td>
<td>
<p>The power <code>x</code> is to be raised to.</p>
</td></tr>
<tr><td><code id="dfac_+3A_method">method</code></td>
<td>
<p>The method by which the descending factorials are to be calculated. Default is <code>"product"</code> which uses direct arithmetic. Alternative is <code>"gamma"</code> which calculates the ascending factorial using the Gamma function. The alternative method might be faster but might fail because the Gamma function is not defined for negative integers (returning Inf).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The descending factorial of value <code>x</code> raised to the <code>r</code>'th power.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To calculate the 4th descending factorial for a value (e.g., 3.14):
dfac(x = 3.14, r = 4)

# To calculate the 5th descending factorial for values 3.14, 2.72, and 0.58:
dfac(x = c(3.14, 2.72, 0.58), r = 5)
</code></pre>

<hr>
<h2 id='dGammaBinom'>Probability density function under the Gamma-extended Binomial distribution.</h2><span id='topic+dGammaBinom'></span>

<h3>Description</h3>

<p>Probability density function under the Gamma-extended Binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dGammaBinom(x, size, prob, nc = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dGammaBinom_+3A_x">x</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="dGammaBinom_+3A_size">size</code></td>
<td>
<p>Number of &quot;trials&quot; (zero or more). Need not be integer.</p>
</td></tr>
<tr><td><code id="dGammaBinom_+3A_prob">prob</code></td>
<td>
<p>Probability of &quot;success&quot; on each &quot;trial&quot;. Need not be integer.</p>
</td></tr>
<tr><td><code id="dGammaBinom_+3A_nc">nc</code></td>
<td>
<p>Whether to include a normalizing constant making sure that the sum of the distribution's density is 1.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Loeb, D. E. (1992). A generalization of the binomial coefficients. Discrete Mathematics, 105(1-3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' # Assume some variable follows a Gamma-Binomial distribution with
# "number of trials" = 10.5 and probability of "success" for each "trial"
# = 0.75, to compute the probability density to attain a "number of success"
# at a specific point (e.g., 7.5 "successes"):
dGammaBinom(x = 7.5, size = 10.5, prob = 0.75)

# Including a normalizing constant (then diverges from binomial dist.):
dGammaBinom(x = 7.5, size = 10.5, prob = 0.75, nc = TRUE)
dGammaBinom(x = 7, size = 10, prob = 0.75) == dbinom(7, 10, 0.75)
dGammaBinom(x = 7, size = 10, prob = 0.75, nc = TRUE) == dbinom(7, 10, 0.75)
</code></pre>

<hr>
<h2 id='ETL'>Livingston and Lewis' &quot;Effective Test Length&quot;.</h2><span id='topic+ETL'></span>

<h3>Description</h3>

<p>According to Livingston and Lewis (1995), &quot;The effective test length corresponding to a test score is the number of discrete, dichotomously scored, locally independent, equally difficult items required to produce a total score of the same reliability.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ETL(mean, variance, min = 0, max = 1, reliability)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ETL_+3A_mean">mean</code></td>
<td>
<p>The mean of the observed-score distribution.</p>
</td></tr>
<tr><td><code id="ETL_+3A_variance">variance</code></td>
<td>
<p>The variance of the observed-score distribution.</p>
</td></tr>
<tr><td><code id="ETL_+3A_min">min</code></td>
<td>
<p>The lower-bound (minimum possible value) of the observed-score distribution. Default is 0 (assuming observed scores represent proportions).</p>
</td></tr>
<tr><td><code id="ETL_+3A_max">max</code></td>
<td>
<p>The upper-bound (maximum possible value) of the observed-score distribution. Default is 1 (assuming observed scores represent proportions).</p>
</td></tr>
<tr><td><code id="ETL_+3A_reliability">reliability</code></td>
<td>
<p>The reliability of the observed scores (proportion of observed-score distribution variance shared with true-score distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An estimate of the effective length of a test, given the stability of the observations it produces.
</p>


<h3>References</h3>

<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, .25, .75, 5, 3))
hist(testdata, xlim = c(0, 100))

# Suppose the reliability of this test was estimated to 0.7. To estimate and
# retrieve the effective test length using ETL():
ETL(mean = mean(testdata), variance = var(testdata), min = 0, max = 100,
reliability = .7)
</code></pre>

<hr>
<h2 id='gchoose'>Gamma-extended Binomial coefficient (choose function).</h2><span id='topic+gchoose'></span>

<h3>Description</h3>

<p>Extends the Binomial coefficient for positive non-integers (including 0) by employing the Gamma rather than the factorial function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gchoose(n, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gchoose_+3A_n">n</code></td>
<td>
<p>In Binomial terms, the number of Binomial &quot;trials&quot;. Need not be an integer.</p>
</td></tr>
<tr><td><code id="gchoose_+3A_k">k</code></td>
<td>
<p>In Binomial terms, the number of successful &quot;trials&quot;. Need not be an integer.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Not defined for negative integers.
</p>


<h3>References</h3>

<p>Loeb, D. E. (1992). A generalization of the binomial coefficients. Discrete Mathematics, 105(1-3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compare choose function with gchoose function for integers:
gchoose(c(8, 9, 10), c(3, 4, 5)) == choose(c(8, 9, 10), c(3, 4, 5))

# The gchoose function also works for non-integers:
gchoose(10.5, 7.5)
</code></pre>

<hr>
<h2 id='HB.beta.tp.fit'>Estimate Beta True-Score Distribution Based on Observed-Score Raw-Moments and Lord's k.</h2><span id='topic+HB.beta.tp.fit'></span>

<h3>Description</h3>

<p>Estimator for the Beta true-score distribution shape-parameters from the observed-score distribution and Lord's k. Returns a list with entries representing the lower- and upper shape parameters (l and u), and the shape parameters (alpha and beta) of the four-parameters beta distribution, as well as Lord's k and the test length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HB.beta.tp.fit(x, N, k, true.model = "4P", failsafe = FALSE, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HB.beta.tp.fit_+3A_x">x</code></td>
<td>
<p>Vector of observed-scores.</p>
</td></tr>
<tr><td><code id="HB.beta.tp.fit_+3A_n">N</code></td>
<td>
<p>The test length.</p>
</td></tr>
<tr><td><code id="HB.beta.tp.fit_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function).</p>
</td></tr>
<tr><td><code id="HB.beta.tp.fit_+3A_true.model">true.model</code></td>
<td>
<p>The type of Beta distribution which is to be fit to the moments of the true-score distribution. Options are <code>"4P"</code> and <code>"2P"</code>, where <code>"4P"</code> refers to the four-parameter (with the same mean, variance, skewness, and kurtosis), and <code>"2P"</code> the two-parameter solution where both location-parameters are specified (with the same mean and variance).</p>
</td></tr>
<tr><td><code id="HB.beta.tp.fit_+3A_failsafe">failsafe</code></td>
<td>
<p>Logical. Whether to revert to a fail-safe two-parameter solution should the four-parameter solution contain invalid parameter estimates.</p>
</td></tr>
<tr><td><code id="HB.beta.tp.fit_+3A_l">l</code></td>
<td>
<p>If <code>failsafe = TRUE</code> or <code>true.model = "2P"</code>: The lower-bound of the Beta distribution. Default is 0 (i.e., the lower-bound of the Standard, two-parameter Beta distribution).</p>
</td></tr>
<tr><td><code id="HB.beta.tp.fit_+3A_u">u</code></td>
<td>
<p>If <code>failsafe = TRUE</code> or <code>true.model = "2P"</code>: The upper-bound of the Beta distribution. Default is 1 (i.e., the upper-bound of the Standard, two-parameter Beta distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the parameter values of a four-parameter Beta distribution. &quot;l&quot; is the lower location-parameter, &quot;u&quot; the upper location-parameter, &quot;alpha&quot; the first shape-parameter, and &quot;beta&quot; the second shape-parameter. Also includes Lord's k and the test length.
</p>


<h3>References</h3>

<p>Hanson, B. A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing Research Report Series. Retrieved from https://files.eric.ed.gov/fulltext/ED344945.pdf
</p>
<p>Lord, F. M. (1965). A strong true-score theory, with applications. Psychometrika. 30(3). pp. 239&ndash;270. doi: 10.1007/BF02289490
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say 1000 individuals take a 100-item test
# where all items are equally difficult, and the true-score distribution
# is a four-parameter Beta distribution with location parameters l = 0.25,
# u = 0.75, alpha = 5, and beta = 3, and the error distribution is Binomial
# with Lord's k = 0:
set.seed(12)
testdata &lt;- rbinom(1000, 100, rBeta.4P(1000, 0.25, 0.75, 5, 3))

# To estimate the four-parameter Beta distribution parameters from this
# sample of observations:
HB.beta.tp.fit(testdata, 100, 0)
</code></pre>

<hr>
<h2 id='HB.CA'>An Implementation of the Hanson and Brennan Approach to Estimate Classification Consistency and Accuracy based on Observed Test Scores and Test Reliability.</h2><span id='topic+HB.CA'></span>

<h3>Description</h3>

<p>An implementation of what has been come to be known as the &quot;Hanson and Brennan approach&quot; to classification consistency and accuracy, which by employing a compound beta-binomial distribution assumes that true-scores conform to the four-parameter beta distribution, and errors of measurement to a two-term approximation of the compound binomial distribution. Under these assumptions, the expected classification consistency and accuracy of tests can be estimated from observed outcomes and test reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HB.CA(
  x = NULL,
  reliability,
  cut,
  testlength,
  true.model = "4P",
  truecut = NULL,
  output = c("accuracy", "consistency"),
  failsafe = TRUE,
  l = 0,
  u = 1,
  modelfit = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HB.CA_+3A_x">x</code></td>
<td>
<p>A vector of observed scores, or a list specifying parameter values. If a list is provided, the list entries must be named after the parameters: <code>l</code> and <code>u</code> for the location-, and <code>alpha</code> and <code>beta</code> for the shape parameters of the Beta true-score distribution, and <code>k</code> for the &quot;Lord's k&quot; parameter (see documentation for the <code>Lords.k</code> function).</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_reliability">reliability</code></td>
<td>
<p>The observed-score squared correlation (i.e., proportion of shared variance) with the true-score.</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_cut">cut</code></td>
<td>
<p>The cutoff value for classifying observations into above/below categories.</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_testlength">testlength</code></td>
<td>
<p>The total number of test items (or maximum possible score). Must be an integer.</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_true.model">true.model</code></td>
<td>
<p>The probability distribution to be fitted to the moments of the true-score distribution. Options are <code>"4P"</code> (default) and <code>"2P"</code>, referring to four- and two-parameter Beta distributions. The &quot;4P&quot; method produces a four-parameter Beta distribution with the same first four moments (mean, variance, skewness, and kurtosis) as the estimated true-score distribution, while the &quot;2P&quot; method produces a two-parameter Beta distribution with the first two moments (mean and variance) as the estimated true-score distribution.</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_truecut">truecut</code></td>
<td>
<p>Optional specification of a &quot;true&quot; cutoff. Useful for producing ROC curves (see documentation for the <code>HB.ROC()</code> function).</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_output">output</code></td>
<td>
<p>Character vector indicating which types of statistics (i.e, accuracy and/or consistency) are to be computed and included in the output. Permissible values are <code>"accuracy"</code> and <code>"consistency"</code>.</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_failsafe">failsafe</code></td>
<td>
<p>Logical value indicating whether to engage the automatic fail-safe defaulting to the two-parameter Beta true-score distribution if the four-parameter fitting procedure produces impermissible parameter estimates. Default is <code>TRUE</code> (i.e., the function will engage failsafe if the four-parameter Beta-distribution fitting-procedure produced impermissible estimates).</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_l">l</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the lower-bound location parameter to be used in the two-parameter fitting procedure. Default is 0 (i.e., the lower-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_u">u</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the upper-bound location parameter to be used in the two-parameter fitting procedure. Default is 1 (i.e., the upper-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="HB.CA_+3A_modelfit">modelfit</code></td>
<td>
<p>Allows for controlling the chi-square test for model fit by setting the minimum bin-size for expected observations. Can alternatively be set to <code>NULL</code> to forego model-fit testing (speeding up the function). In accordance with standard recommendations for chi-square tests the default input to this argument is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the estimated parameters necessary for the approach (i.e., the effective test-length and the beta distribution parameters), a chi-square test of model-fit, the confusion matrix containing estimated proportions of true/false pass/fail categorizations for a test, diagnostic performance statistics, and / or a classification consistency matrix and indices. Accuracy output includes a confusion matrix and diagnostic performance indices, and consistency output includes a consistency matrix and consistency indices <code>p</code> (expected proportion of agreement between two independent test administrations), <code>p_c</code> (proportion of agreement on two independent administrations expected by chance alone), and <code>Kappa</code> (Cohen's Kappa).
</p>


<h3>Note</h3>

<p>This implementation of the Hanson-Brennan approach is much slower than the implementation of the Livingston and Lewis approach, as there is no native implementation of Lord's two-term approximation to the Compound-Binomial distribution in R. This implementation uses a &quot;brute-force&quot; method of computing the cumulative probabilities from the compound-Binomial distribution, which will by necessity be more resource intensive.
</p>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing.
</p>
<p>Lord. Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>
<p>Lewis, Don and Burke, C. J. (1949). The Use and Misuse of the Chi-Square Test. Psychological Bulletin, 46(6).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 50.
# Generate some fictional data. Say, 1000 individuals take a 20-item test.
set.seed(1234)
p.success &lt;- rBeta.4P(1000, 0.15, 0.85, 6, 4)
 for (i in 1:20) {
   if (i == 1) {
     rawdata &lt;- matrix(nrow = 1000, ncol = 20)
     }
   rawdata[, i] &lt;- rbinom(1000, 1, p.success)
 }

# Suppose the cutoff value for attaining a pass is 10 items correct, and
# that the reliability of this test was estimated using the Cronbach's Alpha
# estimator. To estimate and retrieve the estimated parameters, confusion and
# consistency matrices, and accuracy and consistency indices using HB.CA():
HB.CA(x = rowSums(rawdata), reliability = cba(rawdata), cut = 10,
testlength = 20)
</code></pre>

<hr>
<h2 id='HB.CA.MC'>An Extension of the Hanson and Brennan Approach to Estimate Classification Consistency and Accuracy for Multiple Classifications based on Observed Test Scores and Test Reliability.</h2><span id='topic+HB.CA.MC'></span>

<h3>Description</h3>

<p>An implementation of what has been come to be known as the &quot;Hanson and Brennan approach&quot; to classification consistency and accuracy, which by employing a compound beta-binomial distribution assumes that true-scores conform to the four-parameter beta distribution, and errors of measurement to the binomial distribution. Under these assumptions, the expected classification consistency and accuracy of tests can be estimated from observed outcomes and test reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HB.CA.MC(
  x = NULL,
  reliability,
  cut,
  testlength,
  true.model = "4P",
  failsafe = TRUE,
  l = 0,
  u = 1,
  modelfit = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HB.CA.MC_+3A_x">x</code></td>
<td>
<p>A vector of observed scores, or a list specifying parameter values. If a list is provided, the list entries must be named after the parameters: <code>l</code> and <code>u</code> for the location-, and <code>alpha</code> and <code>beta</code> for the shape parameters of the Beta true-score distribution, and <code>k</code> for the &quot;Lord's k&quot; parameter (see documentation for the <code>Lords.k</code> function).</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_reliability">reliability</code></td>
<td>
<p>The observed-score squared correlation (i.e., proportion of shared variance) with the true-score.</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_cut">cut</code></td>
<td>
<p>A vector of cut-off values for classifying observations into two or more categories.</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_testlength">testlength</code></td>
<td>
<p>The total number of test items (or maximum possible score). Must be an integer.</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_true.model">true.model</code></td>
<td>
<p>The probability distribution to be fitted to the moments of the true-score distribution. Options are <code>"4P"</code> (default) and <code>"2P"</code>, referring to four- and two-parameter Beta distributions. The &quot;4P&quot; method produces a four-parameter Beta distribution with the same first four moments (mean, variance, skewness, and kurtosis) as the estimated true-score distribution, while the &quot;2P&quot; method produces a two-parameter Beta distribution with the first two moments (mean and variance) as the estimated true-score distribution.</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_failsafe">failsafe</code></td>
<td>
<p>Logical value indicating whether to engage the automatic fail-safe defaulting to the two-parameter Beta true-score distribution if the four-parameter fitting procedure produces impermissible parameter estimates. Default is <code>TRUE</code> (i.e., the function will engage failsafe if the four-parameter Beta-distribution fitting-procedure produced impermissible estimates).</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_l">l</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the lower-bound location parameter to be used in the two-parameter fitting procedure. Default is 0 (i.e., the lower-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_u">u</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the upper-bound location parameter to be used in the two-parameter fitting procedure. Default is 1 (i.e., the upper-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="HB.CA.MC_+3A_modelfit">modelfit</code></td>
<td>
<p>Allows for controlling the chi-square test for model fit by setting the minimum bin-size for expected observations. Can alternatively be set to <code>NULL</code> to forego model-fit testing (speeding up the function). In accordance with standard recommendations for chi-square tests the default input to this argument is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the estimated parameters necessary for the approach (i.e., Lord's k, test-length, and the true-score Beta distribution parameters), a chi-square test of model-fit, the confusion matrix containing estimated proportions of true/false positive/negative categorizations for a test, diagnostic performance statistics, and/or a classification consistency matrix and indices. Accuracy output includes a confusion matrix and diagnostic performance indices, and consistency output includes a consistency matrix and consistency indices <code>p</code> (expected proportion of agreement between two independent test administrations), <code>p_c</code> (proportion of agreement on two independent administrations expected by chance alone), and <code>Kappa</code> (Cohen's Kappa).
</p>


<h3>Note</h3>

<p>This implementation of the Hanson-Brennan approach is much slower than the implementation of the Livingston and Lewis approach, as there is no native implementation of Lord's two-term approximation to the Compound-Binomial distribution in R. This implementation uses a &quot;brute-force&quot; method of computing the cumulative probabilities from the compound-Binomial distribution, which will by necessity be more resource intensive.
</p>


<h3>References</h3>

<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing.
</p>
<p>Lord. Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>
<p>Lewis, Don and Burke, C. J. (1949). The Use and Misuse of the Chi-Square Test. Psychological Bulletin, 46(6).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a 20-item test.
set.seed(1234)
p.success &lt;- rBeta.4P(1000, 0.15, 0.85, 6, 4)
 for (i in 1:20) {
   if (i == 1) {
     rawdata &lt;- matrix(nrow = 1000, ncol = 20)
     }
   rawdata[, i] &lt;- rbinom(1000, 1, p.success)
 }

# Suppose the cutoff value for attaining a pass is 10 items correct, and
# that the reliability of this test was estimated using the Cronbach's Alpha
# estimator. To estimate and retrieve the estimated parameters, confusion and
# consistency matrices, and accuracy and consistency indices using HB.CA():
(output &lt;- HB.CA.MC(x = rowSums(rawdata), reliability = cba(rawdata),
cut = c(8, 12), testlength = 20))

# The output for this function can get quite verbose as more categories are
# included. The output from the function can be fed to the MC.out.tabular()
# function in order to organize the output in a tabular format.
MC.out.tabular(output)

</code></pre>

<hr>
<h2 id='HB.ROC'>ROC curves for the Hanson and Brennan approach.</h2><span id='topic+HB.ROC'></span>

<h3>Description</h3>

<p>Generate a ROC curve plotting the false-positive rate against the true-positive rate at different cut-off values across the observed-score scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HB.ROC(
  x = NULL,
  reliability,
  testlength,
  truecut,
  true.model = "4P",
  failsafe = TRUE,
  l = 0,
  u = 1,
  AUC = FALSE,
  maxJ = FALSE,
  maxAcc = FALSE,
  locate = NULL,
  raw.out = FALSE,
  grainsize = testlength
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HB.ROC_+3A_x">x</code></td>
<td>
<p>A vector of observed results (sum scores) or a list of parameter values (see documentation for the <code>HB.beta.tp.fit() function</code>.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_reliability">reliability</code></td>
<td>
<p>The reliability coefficient of the test.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_testlength">testlength</code></td>
<td>
<p>The total number of test items (or maximum possible score). Must be an integer.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_truecut">truecut</code></td>
<td>
<p>The point along the x-scale that marks true category membership.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_true.model">true.model</code></td>
<td>
<p>The probability distribution to be fitted to the moments of the true-score distribution. Options are <code>"4P"</code> (default) and <code>"2P"</code>, referring to four- and two-parameter Beta distributions. The <code>"4P"</code> method produces a four-parameter Beta distribution with the same first four moments (mean, variance, skewness, and kurtosis) as the estimated true-score distribution, while the <code>"2P"</code> method produces a two-parameter Beta distribution with the first two moments (mean and variance) as the estimated true-score distribution.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_failsafe">failsafe</code></td>
<td>
<p>If true-model == &quot;4P&quot;: Whether to engage a fail-safe reverting to a two-parameter true-score distribution solution should the four-parameter fitting procedure produce impermissible results. Default is TRUE (engage fail-safe in the event of impermissible estimates).</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_l">l</code></td>
<td>
<p>If <code>true.model == "2P"</code> or <code>failsafe == TRUE</code>: The lower-bound location parameter of the two-parameter true-score distribution solution.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_u">u</code></td>
<td>
<p>If <code>true.model == "2P"</code> or <code>failsafe == TRUE</code>: The upper-bound location parameter of the two-parameter true-score distribution solution.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_auc">AUC</code></td>
<td>
<p>Logical. Calculate and include the area under the curve? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_maxj">maxJ</code></td>
<td>
<p>Logical. Mark the point along the curve where Youden's J statistic is maximized? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_maxacc">maxAcc</code></td>
<td>
<p>Logical. Mark the point along the curve where the Accuracy statistic is maximized? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_locate">locate</code></td>
<td>
<p>Ask the function to locate the cut-point at which sensitivity or NPV is greater than or equal to some value, or specificity or PPV is lesser than or equal to some value. Take as input a character-vector of length 2, with the first argument being which index is to be found (e.g., &quot;sensitivity&quot;), and the second argument the value to locate (e.g., &quot;0.75&quot;). For example: c(&quot;sensitivity&quot;, &quot;0.75&quot;).</p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_raw.out">raw.out</code></td>
<td>
<p>Give raw coordinates as output rather than plot? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="HB.ROC_+3A_grainsize">grainsize</code></td>
<td>
<p>Specify the number of cutoff-points for which the ROC curve is to be calculated. The greater this number the greater the accuracy. Default is set to the stated test length (N).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot tracing the ROC curve for the test, or matrix of coordinates if raw.out is <code>TRUE</code>.
</p>


<h3>Note</h3>

<p>This implementation of the Hanson-Brennan approach is much slower than the implementation of the Livingston and Lewis approach, as there is no native implementation of Lord's two-term approximation to the Compound-Binomial distribution in R. This implementation uses a &quot;brute-force&quot; method of computing the cumulative probabilities from the compound-Binomial distribution, which will by necessity be more resource intensive.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 50.
# Generate some fictional data. Say, 1000 individuals take a 20-item test.
set.seed(1234)
p.success &lt;- rBeta.4P(1000, 0.15, 0.85, 6, 4)
 for (i in 1:20) {
   if (i == 1) {
     rawdata &lt;- matrix(nrow = 1000, ncol = 20)
     }
   rawdata[, i] &lt;- rbinom(1000, 1, p.success)
 }

# Suppose the cutoff value for attaining a pass is 10 items correct, and
# that the reliability of this test was estimated using the Cronbach's Alpha
# estimator. To draw the ROC-graph and locate the points at which Youden's J
# and Accuracy are maximized:
HB.ROC(rowSums(rawdata), cba(rawdata), 20, 10, maxAcc = TRUE, maxJ = TRUE)

# For further examples regarding how to use the locate argument to locate
# points at which various criteria are satisfied, see documentation for the
# LL.ROC() function.
</code></pre>

<hr>
<h2 id='HB.tsm'>Proportional True-Score Distribution Raw Moments for the Hanson-Brennan Approach to Classification Accuracy and Consistency.</h2><span id='topic+HB.tsm'></span>

<h3>Description</h3>

<p>An implementation of Lords (1965, p. 265) equation 37 for estimating the raw moments of the true-score distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HB.tsm(x, r, N, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HB.tsm_+3A_x">x</code></td>
<td>
<p>Vector of values representing sum-scores.</p>
</td></tr>
<tr><td><code id="HB.tsm_+3A_r">r</code></td>
<td>
<p>The number of raw moments to be calculated.</p>
</td></tr>
<tr><td><code id="HB.tsm_+3A_n">N</code></td>
<td>
<p>The number of test items (i.e., test length).</p>
</td></tr>
<tr><td><code id="HB.tsm_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data under the Beta Compound-Binomial distribution, where the
# Compound Binomial distribution has 100 trials and Lord's k = 2, and the
# Beta distribution has location parameters l = .15 and u = .85, and shape
# parameters alpha = 6 and beta = 4:
obs &lt;- rBetacBinom(1000, 100, 2, .15, .85, 6, 4)

# To estimate the first four raw moments of the underlying Beta distribution:
HB.tsm(x = obs, r = 4, N = 100, k = 2)
</code></pre>

<hr>
<h2 id='LABMSU'>Lower Location Parameter Given Shape Parameters, Mean, Variance, and Upper Location Parameter of a Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+LABMSU'></span>

<h3>Description</h3>

<p>Calculates the lower-bound value required to produce a Beta probability density distribution with defined moments and parameters. Be advised that not all combinations of moments and parameters can be satisfied (e.g., specifying mean, variance, skewness and kurtosis uniquely determines both location-parameters, meaning that the value of the lower-location parameter will take on which ever value it must, and cannot be specified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LABMSU(
  alpha = NULL,
  beta = NULL,
  u = NULL,
  mean = NULL,
  variance = NULL,
  sd = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LABMSU_+3A_alpha">alpha</code></td>
<td>
<p>The alpha (first) shape-parameter of the target Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="LABMSU_+3A_beta">beta</code></td>
<td>
<p>The beta (second) shape-parameter of the target Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="LABMSU_+3A_u">u</code></td>
<td>
<p>The upper-bound of the Beta distribution. Default is NULL (i.e., does not take a specified u-parameter into account).</p>
</td></tr>
<tr><td><code id="LABMSU_+3A_mean">mean</code></td>
<td>
<p>The mean (first raw moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="LABMSU_+3A_variance">variance</code></td>
<td>
<p>The variance (second central moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="LABMSU_+3A_sd">sd</code></td>
<td>
<p>Optional alternative to specifying <code>var</code>. The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the required value for the Beta lower location-parameter (<code>l</code>) in order to produce a Beta probability density distribution with the target moments and parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data.
set.seed(1234)
testdata &lt;- rBeta.4P(100000, 0.25, 0.75, 5, 3)
hist(testdata, xlim = c(0, 1), freq = FALSE)

# Suppose you know three of the four necessary parameters to fit a four-
# parameter Beta distribution (i. e., u = 0.75, alpha = 5, beta = 3) to this
# data. To find the value for the necessary l parameter, estimate the mean
# and variance of the distribution:
M &lt;- mean(testdata)
S2 &lt;- var(testdata)

# To find the l parameter necessary to produce a four-parameter Beta
# distribution with the target mean, variance, and u, alpha, and beta
# parameters using the LMSBAU() function:
(l &lt;- LABMSU(alpha = 5, beta = 3, mean = M, variance = S2, u = 0.75))
curve(dBeta.4P(x, l, .75, 5, 3), add = TRUE, lwd = 2)
</code></pre>

<hr>
<h2 id='LL.CA'>An Implementation of the Livingston and Lewis (1995) Approach to Estimate Classification Consistency and Accuracy based on Observed Test Scores and Test Reliability.</h2><span id='topic+LL.CA'></span>

<h3>Description</h3>

<p>An implementation of what has been come to be known as the &quot;Livingston and Lewis approach&quot; to classification consistency and accuracy, which by employing a compound beta-binomial distribution assumes that true-scores conform to the four-parameter beta distribution, and errors of measurement to the binomial distribution. Under these assumptions, the expected classification consistency and accuracy of tests can be estimated from observed outcomes and test reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL.CA(
  x = NULL,
  reliability,
  cut,
  min = 0,
  max = 1,
  true.model = "4P",
  truecut = NULL,
  output = c("accuracy", "consistency"),
  failsafe = TRUE,
  l = 0,
  u = 1,
  modelfit = c(nbins = 100, minbin = 10)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL.CA_+3A_x">x</code></td>
<td>
<p>A vector of observed scores, or a list specifying parameter values. If a list is provided, the list entries must be named after the parameters: <code>l</code> and <code>u</code> for the location-, and <code>alpha</code> and <code>beta</code> for the shape parameters of the Beta true-score distribution, and <code>etl</code> for the effective test length (see documentation for the <code>ETL</code> function).</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_reliability">reliability</code></td>
<td>
<p>The observed-score squared correlation (i.e., proportion of shared variance) with the true-score.</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_cut">cut</code></td>
<td>
<p>The cutoff value for classifying observations into pass or fail categories.</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_min">min</code></td>
<td>
<p>The minimum value possible to attain on the test. Default is 0.</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_max">max</code></td>
<td>
<p>The maximum value possible to attain on the test. Default is 1 (assumes that the values contained in <code>x</code> represents proportions of maximum credit).</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_true.model">true.model</code></td>
<td>
<p>The probability distribution to be fitted to the moments of the true-score distribution. Options are <code>"4P"</code> (default) and <code>"2P"</code>, referring to four- and two-parameter Beta distributions. The &quot;4P&quot; method produces a four-parameter Beta distribution with the same first four moments (mean, variance, skewness, and kurtosis) as the estimated true-score distribution, while the &quot;2P&quot; method produces a two-parameter Beta distribution with the first two moments (mean and variance) as the estimated true-score distribution.</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_truecut">truecut</code></td>
<td>
<p>Optional specification of a &quot;true&quot; cutoff. Useful for producing ROC curves (see documentation for the <code>LL.ROC()</code> function).</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_output">output</code></td>
<td>
<p>Character vector indicating which types of statistics (i.e, accuracy and/or consistency) are to be computed and included in the output. Permissible values are <code>"accuracy"</code> and <code>"consistency"</code>.</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_failsafe">failsafe</code></td>
<td>
<p>Logical value indicating whether to engage the automatic fail-safe defaulting to the two-parameter Beta true-score distribution if the four-parameter fitting procedure produces impermissible parameter estimates. Default is <code>TRUE</code> (i.e., the function will engage failsafe if the four-parameter Beta-distribution fitting-procedure produced impermissible estimates).</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_l">l</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the lower-bound location parameter to be used in the two-parameter fitting procedure. Default is 0 (i.e., the lower-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_u">u</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the upper-bound location parameter to be used in the two-parameter fitting procedure. Default is 1 (i.e., the upper-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="LL.CA_+3A_modelfit">modelfit</code></td>
<td>
<p>Allows for controlling the chi-square test for model fit. The argument takes either a vector of two values, or <code>NULL</code>. If set to <code>NULL</code>, the model-fit test is not executed. If a vector of values is supplied, the first value is to represent the initial number of bins the distribution of scores is to be divided in to. This value is set to a default of 100. If this default results in too few bins to conduct the chi-square test, this value can be made larger. The second value represents the minimum expected number of observations that the bins should consist of. In accordance with standard recommendations for chi-square tests, the default value is set to 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the estimated parameters necessary for the approach (i.e., the effective test-length and the beta distribution parameters), a chi-square test of model-fit, the confusion matrix containing estimated proportions of true/false pass/fail categorizations for a test, diagnostic performance statistics, and / or a classification consistency matrix and indices. Accuracy output includes a confusion matrix and diagnostic performance indices, and consistency output includes a consistency matrix and consistency indices <code>p</code> (expected proportion of agreement between two independent test administrations), <code>p_c</code> (proportion of agreement on two independent administrations expected by chance alone), and <code>Kappa</code> (Cohen's Kappa).
</p>


<h3>Note</h3>

<p>It should be noted that this implementation differs from the original articulation of Livingston and Lewis (1995) in some respects. First, the procedure includes a number of diagnostic performance (accuracy) indices which the original procedure enables but that were not included. Second, the way consistency is calculated differs substantially from the original articulation of the procedure, which made use of a split-half approach. Rather, this implementation uses the approach to estimating classification consistency outlined by Hanson (1991).
</p>
<p>A shiny application providing a GUI for this method is available at https://hthaa.shinyapps.io/shinybeta/ .
</p>


<h3>References</h3>

<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>
<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing.
</p>
<p>Lord. Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>
<p>Lewis, Don and Burke, C. J. (1949). The Use and Misuse of the Chi-Square Test. Psychological Bulletin, 46(6).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(1000, 100, rBeta.4P(1000, 0.25, 0.75, 5, 3))
hist(testdata, xlim = c(0, 100))

# Suppose the cutoff value for attaining a pass is 50 items correct, and
# that the reliability of this test was estimated to 0.7. To estimate and
# retrieve the estimated parameters, confusion matrix, consistency and
# accuracy statistics using LL.CA():
LL.CA(x = testdata, reliability = .7, cut = 50, min = 0, max = 100)

# Suppose the true-score parameter estimation procedure arrived at
# impermissible parameter estimates (i.e., l &lt; 0, u &gt; 1, alpha &lt; 0, or
# beta &lt; 0). For example:
set.seed(9)
testdata &lt;- rbinom(100, 25, rBeta.4P(100, 0.25, 1, 5, 3))
Beta.tp.fit(testdata, 0, 25, 25, failsafe = TRUE)

# Suppose further that you have good grounds for assuming that the lower-
# bound parameter is equal to 0.25 (e.g., the test consists of multiple-
# choice questions with four response options, leading to a 25% probability
# of guessing the correct answer per question), and good reason to believe
# that the upper-bound parameter is equal to 1 (i.e., there is no reason to
# believe that there are no members of the population who will attain a
# perfect score across all possible test-forms.) To set these lower and
# upper bounds for the fitting procedure in the LL.CA() function, set
# the argument true.model = "2p", and specify the location parameters
# l = 0.25 and u = 1:
LL.CA(testdata, 0.6287713, 12, 0, 25, true.model = "2p", l = 0.25, u = 1)

# Alternatively to supplying scores to which a true-score distribution is
# to be fit, a list with true-score distribution parameter values can be
# supplied manually along with the effective test length (see documentation
# for the ETL() function), foregoing the need for actual data. The list
# entries must be named. "l" is the lower-bound and "u" the upper-bound
# location parameters of the true-score distribution, "alpha" and "beta" for
# the shape parameters, and "etl" for the effective test-length..
trueparams &lt;- list("l" = 0.25, "u" = 0.75, "alpha" = 5, "beta" = 3, "etl" = 50)
LL.CA(x = trueparams, cut = 50, min = 0, max = 100)
</code></pre>

<hr>
<h2 id='LL.CA.MC'>An Extension of the Livingston and Lewis (1995) Approach to Estimate Classification Consistency and Accuracy for Multiple Classifications based on Observed Test Scores and Test Reliability.</h2><span id='topic+LL.CA.MC'></span>

<h3>Description</h3>

<p>An implementation of what has been come to be known as the &quot;Livingston and Lewis approach&quot; to classification consistency and accuracy, which by employing a compound beta-binomial distribution assumes that true-scores conform to the four-parameter beta distribution, and errors of measurement to the binomial distribution. Under these assumptions, the expected classification consistency and accuracy of tests can be estimated from observed outcomes and test reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL.CA.MC(
  x = NULL,
  reliability,
  cut,
  min = 0,
  max = 1,
  true.model = "4P",
  failsafe = TRUE,
  l = 0,
  u = 1,
  modelfit = c(nbins = 100, minbin = 10)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL.CA.MC_+3A_x">x</code></td>
<td>
<p>A vector of observed scores, or a list specifying parameter values. If a list is provided, the list entries must be named after the parameters: <code>l</code> and <code>u</code> for the location-, and <code>alpha</code> and <code>beta</code> for the shape parameters of the Beta true-score distribution, and <code>etl</code> for the effective test length (see documentation for the <code>ETL</code> function).</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_reliability">reliability</code></td>
<td>
<p>The observed-score squared correlation (i.e., proportion of shared variance) with the true-score.</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_cut">cut</code></td>
<td>
<p>A vector of cut-off values for classifying observations into two or more categories.</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_min">min</code></td>
<td>
<p>The minimum value possible to attain on the test. Default is 0.</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_max">max</code></td>
<td>
<p>The maximum value possible to attain on the test. Default is 1 (assumes that the values contained in <code>x</code> represents proportions of maximum credit).</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_true.model">true.model</code></td>
<td>
<p>The probability distribution to be fitted to the moments of the true-score distribution. Options are <code>"4P"</code> (default) and <code>"2P"</code>, referring to four- and two-parameter Beta distributions. The &quot;4P&quot; method produces a four-parameter Beta distribution with the same first four moments (mean, variance, skewness, and kurtosis) as the estimated true-score distribution, while the &quot;2P&quot; method produces a two-parameter Beta distribution with the first two moments (mean and variance) as the estimated true-score distribution.</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_failsafe">failsafe</code></td>
<td>
<p>Logical value indicating whether to engage the automatic fail-safe defaulting to the two-parameter Beta true-score distribution if the four-parameter fitting procedure produces impermissible parameter estimates. Default is <code>TRUE</code> (i.e., the function will engage failsafe if the four-parameter Beta-distribution fitting-procedure produced impermissible estimates).</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_l">l</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the lower-bound location parameter to be used in the two-parameter fitting procedure. Default is 0 (i.e., the lower-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_u">u</code></td>
<td>
<p>If <code>true.model = "2P"</code> or <code>failsafe = TRUE</code>, the upper-bound location parameter to be used in the two-parameter fitting procedure. Default is 1 (i.e., the upper-bound of the Standard Beta distribution).</p>
</td></tr>
<tr><td><code id="LL.CA.MC_+3A_modelfit">modelfit</code></td>
<td>
<p>Allows for controlling the chi-square test for model fit. The argument takes either a vector of two values, or <code>NULL</code>. If set to <code>NULL</code>, the model-fit test is not executed. If a vector of values is supplied, the first value is to represent the initial number of bins the distribution of scores is to be divided in to. This value is set to a default of 100. If this default results in too few bins to conduct the chi-square test, this value can be made larger. The second value represents the minimum expected number of observations that the bins should consist of. In accordance with standard recommendations for chi-square tests, the default value is set to 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the estimated parameters necessary for the approach (i.e., the effective test-length and the beta distribution parameters), a chi-square test of model-fit, the confusion matrix containing estimated proportions of true/false positive/negative categorizations for a test, diagnostic performance statistics, and/or a classification consistency matrix and indices. Accuracy output includes a confusion matrix and diagnostic performance indices, and consistency output includes a consistency matrix and consistency indices <code>p</code> (expected proportion of agreement between two independent test administrations), <code>p_c</code> (proportion of agreement on two independent administrations expected by chance alone), and <code>Kappa</code> (Cohen's Kappa).
</p>


<h3>Note</h3>

<p>It should be noted that this implementation differs from the original articulation of Livingston and Lewis (1995) in some respects. First, the procedure includes a number of diagnostic performance (accuracy) indices which the original procedure enables but that were not included. Second, the way consistency is calculated differs substantially from the original articulation of the procedure, which made use of a split-half approach. Rather, this implementation uses the approach to estimating classification consistency outlined by Hanson (1991).
</p>


<h3>References</h3>

<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>
<p>Hanson, Bradley A. (1991). Method of Moments Estimates for the Four-Parameter Beta Compound Binomial Model and the Calculation of Classification Consistency Indexes. American College Testing.
</p>
<p>Lord. Frederic M. (1965). A Strong True-Score Theory, With Applications. Psychometrika, 30(3).
</p>
<p>Lewis, Don and Burke, C. J. (1949). The Use and Misuse of the Chi-Square Test. Psychological Bulletin, 46(6).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
p.success &lt;- rBeta.4P(1000, 0.1, 0.95, 5, 3)
for (i in 1:100) {
  if (i == 1) {
    rawdata &lt;- matrix(nrow = 1000, ncol = 100)
  }
  rawdata[, i] &lt;- rbinom(1000, 1, p.success)
}

# Suppose the cutoff value for being placed in the lower category is a score
# below 50, second lowest 60, then 70, 80, and 90. Using the cba() function
# to estimate the reliability of this test, to use the LL.CA.MC() function
# or estimating diagnostic performance and consistency indices of
# classifications when using several cut-points:
LL.CA.MC(rowSums(rawdata), cba(rawdata), c(50, 60, 70, 80, 90), min = 0, max = 100)

# The output from this function can get quite verbose when operating with
# several cut-points. In order to retrieve only model parameter estimates:
LL.CA.MC(rowSums(rawdata), cba(rawdata), c(50, 60, 70, 80, 90), min = 0, max = 100)$parameters

# To retrieve only the model-fit estimate:
LL.CA.MC(rowSums(rawdata), cba(rawdata), c(50, 60, 70, 80, 90), min = 0, max = 100)$modelfit

# To retrieve only the diagnostic performance estimates:
LL.CA.MC(rowSums(rawdata), cba(rawdata), c(50, 60, 70, 80, 90), min = 0, max = 100)$accuracy

# To retrieve only the classification consistency indices:
LL.CA.MC(rowSums(rawdata), cba(rawdata), c(50, 60, 70, 80, 90), min = 0, max = 100)$consistency

# Alternatively, the MC.out.tabular() function can be used to organize the
# category-specific indices in a tabular format:
MC.out.tabular(LL.CA.MC(rowSums(rawdata), cba(rawdata), c(50, 60, 70, 80, 90), min = 0, max = 100))

</code></pre>

<hr>
<h2 id='LL.ROC'>ROC curves for the Livingston and Lewis approach.</h2><span id='topic+LL.ROC'></span>

<h3>Description</h3>

<p>Generate a ROC curve plotting the false-positive rate against the true-positive rate at different cut-off values across the observed-score scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL.ROC(
  x = NULL,
  reliability,
  min = 0,
  max = 1,
  truecut,
  true.model = "4P",
  failsafe = TRUE,
  l = 0,
  u = 1,
  AUC = FALSE,
  maxJ = FALSE,
  maxAcc = FALSE,
  locate = NULL,
  raw.out = FALSE,
  grainsize = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL.ROC_+3A_x">x</code></td>
<td>
<p>A vector of observed results.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_reliability">reliability</code></td>
<td>
<p>The reliability coefficient of the test.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_min">min</code></td>
<td>
<p>The minimum possible value to attain on the observed-score scale.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_max">max</code></td>
<td>
<p>The maximum value possible to attain on the test. Default is 1 (assumes that the values contained in <code>x</code> represents proportions of maximum credit).</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_truecut">truecut</code></td>
<td>
<p>The true point along the x-scale that marks the categorization-threshold.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_true.model">true.model</code></td>
<td>
<p>The probability distribution to be fitted to the moments of the true-score distribution. Options are <code>"4P"</code> (default) and <code>"2P"</code>, referring to four- and two-parameter Beta distributions. The <code>"4P"</code> method produces a four-parameter Beta distribution with the same first four moments (mean, variance, skewness, and kurtosis) as the estimated true-score distribution, while the <code>"2P"</code> method produces a two-parameter Beta distribution with the first two moments (mean and variance) as the estimated true-score distribution.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_failsafe">failsafe</code></td>
<td>
<p>If true-model == &quot;4P&quot;: Whether to engage a fail-safe reverting to a two-parameter true-score distribution solution should the four-parameter fitting procedure produce impermissible results. Default is TRUE (engage fail-safe in the event of impermissible estimates).</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_l">l</code></td>
<td>
<p>If <code>true.model == "2P"</code> or <code>failsafe == TRUE</code>: The lower-bound location parameter of the two-parameter true-score distribution solution.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_u">u</code></td>
<td>
<p>If <code>true.model == "2P"</code> or <code>failsafe == TRUE</code>: The upper-bound location parameter of the two-parameter true-score distribution solution.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_auc">AUC</code></td>
<td>
<p>Logical. Calculate and include the area under the curve? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_maxj">maxJ</code></td>
<td>
<p>Logical. Mark the point along the curve where Youden's J statistic is maximized? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_maxacc">maxAcc</code></td>
<td>
<p>Logical. Mark the point along the curve where the Accuracy statistic is maximized? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_locate">locate</code></td>
<td>
<p>Ask the function to locate the cut-point at which sensitivity or NPV is greater than or equal to some value, or specificity or PPV is lesser than or equal to some value. Take as input a character-vector of length 2, with the first argument being which index is to be found (e.g., &quot;sensitivity&quot;), and the second argument the value to locate (e.g., &quot;0.75&quot;). For example: c(&quot;sensitivity&quot;, &quot;0.75&quot;).</p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_raw.out">raw.out</code></td>
<td>
<p>Give raw coordinates as output rather than plot? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="LL.ROC_+3A_grainsize">grainsize</code></td>
<td>
<p>Specify the number of cutoff-points for which the ROC curve is to be calculated. The greater this number the greater the accuracy. Default is 100 points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot tracing the ROC curve for the test, or matrix of coordinates if raw.out is <code>TRUE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(1000, 100, rBeta.4P(1000, 0.25, 0.75, 5, 3))
hist(testdata / 100, xlim = c(0, 1), freq = FALSE)

# Suppose the cutoff value for attaining a pass is 50 items correct.
# Suppose further that the reliability of the test-scores were estimated to
# 0.75. To produce a plot with an ROC curve using LL.ROC(), along with the
# AUC statistics and the points at which Youden's J. is maximized:
LL.ROC(x = testdata, reliability = 0.7, truecut = 50, min = 0, max = 100,
AUC = TRUE, maxJ = TRUE)
# Or to locate the point at which accuracy is maximized:
LL.ROC(x = testdata, reliability = 0.7, truecut = 50, min = 0, max = 100,
maxAcc = TRUE)

# Using the example data above, the function can be instructed to locate an
# operational cut-point at which sensitivity or specificity is equal to or
# greater than some specified value by specifying the "locate" argument with
# c("statistic", value). For example, to locate the operational cut-point at
# which sensitivity is first equal to or greater than 0.9:
LL.ROC(testdata, reliability = 0.7, min = 0, max = 100, truecut = 50,
locate = c("sensitivity", 0.9))
# For Negative Predictive value, the point at which it is equal or greater:
LL.ROC(testdata, reliability = 0.7, min = 0, max = 100, truecut = 50,
locate = c("NPV", 0.9))
# And so on for other statistics such as Specificity and Positive Predictive
# Value.
</code></pre>

<hr>
<h2 id='Lords.k'>Function for estimating &quot;Lord's k&quot; for Lord's two-term approximation to the compound binomial distribution.</h2><span id='topic+Lords.k'></span>

<h3>Description</h3>

<p>Calculates Lord's k.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lords.k(x, N, reliability)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lords.k_+3A_x">x</code></td>
<td>
<p>A vector of observed-scores.</p>
</td></tr>
<tr><td><code id="Lords.k_+3A_n">N</code></td>
<td>
<p>The test length.</p>
</td></tr>
<tr><td><code id="Lords.k_+3A_reliability">reliability</code></td>
<td>
<p>The test-score reliability coefficient.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value representing Lord's k
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say 100 students take a 50-item long test
# where all items are equally difficult (i.e., where the true Lord's k = 0).
set.seed(1234)
p.success &lt;- rBeta.4P(100, 0.25, 0.75, 5, 3)
for (i in 1:50) {
  if (i == 1) {
    rawdata &lt;- matrix(nrow = 100, ncol = 50)
  }
  rawdata[, i] &lt;- rbinom(100, 1, p.success)
}

# Estimate the reliability of these scores with Cronbach's Alpha:
reliability &lt;- cba(rawdata)

# Estimate Lord's k using Lords.k():
Lords.k(rowSums(rawdata), 50, reliability)
</code></pre>

<hr>
<h2 id='MC.out.tabular'>Tabular organization of accuracy and consistency output from the <code>LL.CA.MC()</code> function.</h2><span id='topic+MC.out.tabular'></span>

<h3>Description</h3>

<p>Function that takes the output from the <code>LL.CA.MC()</code> function and organizes it in a table with accuracy and consistency indices represented by columns and categories as rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MC.out.tabular(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MC.out.tabular_+3A_x">x</code></td>
<td>
<p>The list-output from the <code>LL.CA.MC()</code> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 1000 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
p.success &lt;- rBeta.4P(1000, 0.1, 0.95, 5, 3)
for (i in 1:100) {
  if (i == 1) {
    rawdata &lt;- matrix(nrow = 1000, ncol = 100)
  }
  rawdata[, i] &lt;- rbinom(1000, 1, p.success)
}

# Estimate accuracy and consistency where the lowest category are scores
# below 50, second lowest 60, then 70, 80, and 90. Using the cba() function
# to estimate the reliability of this test, to use the LL.CA.MC() function
# or estimating diagnostic performance and consistency indices of
# classifications when using several cut-points:
output &lt;- LL.CA.MC(rowSums(rawdata), cba(rawdata), seq(50, 90, 10), 0, 100)

# As this output can get quite verbose as the number of categories increase,
# the MC.out.tabular() function can be used to organize the output more
# concisely in a tabular format.
MC.out.tabular(output)
</code></pre>

<hr>
<h2 id='mdlfit.gfx'>Graphical presentation of model fit for the Beta-Binomial classification accuracy and consistency model.</h2><span id='topic+mdlfit.gfx'></span>

<h3>Description</h3>

<p>Tool for visually gauging the discrepancy between the observed and model-implied frequencies of observed-scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdlfit.gfx(
  x,
  x.tickat = NULL,
  y.tickat = NULL,
  y.lim = NULL,
  main.lab = "Observed vs. Expected Frequencies",
  x.lab = "Bins",
  y.lab = "Frequency",
  x.grid = NULL,
  y.grid = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdlfit.gfx_+3A_x">x</code></td>
<td>
<p>The output object from the <code>LL.CA()</code>, <code>LL.MC.CA()</code>, <code>HB.CA()</code>, or <code>HB.CA.MC()</code> functions.</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_x.tickat">x.tickat</code></td>
<td>
<p>The points along the x-axis that bins are to be labeled. Default is <code>NULL</code> (places a tick for each of the bins).</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_y.tickat">y.tickat</code></td>
<td>
<p>The points along the y-axis where frequencies are to be labelled. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_y.lim">y.lim</code></td>
<td>
<p>The limits of the y-axis (frequencies). Useful for keeping the scale equal across several plots.</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_main.lab">main.lab</code></td>
<td>
<p>The main label (title) of the plot.</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_x.lab">x.lab</code></td>
<td>
<p>The label for the x-axis (the bins).</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_y.lab">y.lab</code></td>
<td>
<p>The label for the y-axis (the frequencies).</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_x.grid">x.grid</code></td>
<td>
<p>Control the vertical grid-lines of the plot. Takes <code>NULL</code>, <code>NA</code>, or a vector of values as input. If <code>NULL</code>, grid-lines are drawn automatically for each bin. If <code>NA</code>, no grid-lines are drawn. If a vector of values are supplied, lines are drawn at each value provided along the x-axis.</p>
</td></tr>
<tr><td><code id="mdlfit.gfx_+3A_y.grid">y.grid</code></td>
<td>
<p>Control the horizontal grid-lines of the plot. Takes <code>NULL</code>, <code>NA</code>, or a vector of values as input. If <code>NULL</code>, grid-lines are drawn automatically for each frequency (i.e., increments of 1). If <code>NA</code>, no grid-lines are drawn. If a vector of values are supplied, lines are drawn at each value provided along the y-axis.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data. 1000 respondents taking 100 item test:
set.seed(060121)
p.success &lt;- rBeta.4P(1000, 0.25, 0.75, 5, 3)
for (i in 1:100) {
  if (i == 1) {
   rawdata &lt;- matrix(nrow = 1000, ncol = 100)
 }
 rawdata[, i] &lt;- rbinom(1000, 1, p.success)
}

# Analyse the accuracy and consistency of the test and store the object:
out &lt;- LL.CA(x = rowSums(rawdata), reliability = cba(rawdata), cut = 50,
min = 0, max = 100, modelfit = c(nbins = 20, minbin = 1))

# Feed the object to the mdlfit.gfx() function:
mdlfit.gfx(out)

# Given the number of observations, the y-axis ticks are a bit crowded. We
# can make it look less crowded by changing the number of ticks, labels, and
# the grid-lines:
mdlfit.gfx(out, y.tickat = seq(0, 250, 25), y.lim = c(0, 250),
y.grid = seq(0, 250, 12.5))
</code></pre>

<hr>
<h2 id='mdo'>Calculate McDonald's Omega reliability-coefficient from supplied variables.</h2><span id='topic+mdo'></span>

<h3>Description</h3>

<p>Calculates McDonalds's Omega reliability-coefficient of the sum-score from the Spearman one-factor model using the procedure outlined in McDonald (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdo(x, fit = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdo_+3A_x">x</code></td>
<td>
<p>A data-frame or matrix of numerical values where rows represent respondents, and columns represent items.</p>
</td></tr>
<tr><td><code id="mdo_+3A_fit">fit</code></td>
<td>
<p>Logical. Default is <code>FALSE</code>. If <code>TRUE</code>, the output changes from a vector containing the Omega reliability-estimate to a list containing additional detailed information concerning the fitted factor model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>fit = FALSE</code>, A vector of length 1 containing the estimated McDonalds's Omega reliability-coefficient for the sum-score of the supplied variables. If <code>fit = TRUE</code>, a list containing the Omega-coefficient reliability-estimate as the first entry, followed by the goodness-of-fit index (GFI), a two-row matrix containing the estimated factor-loadings and error-variances, and the observed and fitted covariance-matrices and the discrepancy matrix.
</p>


<h3>Note</h3>

<p>Missing values are treated by passing <code>na.rm = TRUE</code> to the <code>var</code> function call and <code>use = "pairwise.complete.obs"</code> to the <code>cov</code> function call.
</p>
<p>The function terminates with an error if there are negative covariance-matrix entries.
</p>


<h3>References</h3>

<p>McDonald, R. P. (1999). Test Theory: A Unified Treatment. Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data.
set.seed(1234)
rawdata &lt;- matrix(rnorm(500), ncol = 5)
common &lt;- rnorm(100)
rawdata &lt;- apply(rawdata, 2, function(x) {x + common})

# To estimate McDonald's Omega from this data:
mdo(rawdata)

# To retrieve additional information such as the GFI fit-index and model-
# parameter estimates:
mdo(rawdata, fit = TRUE)
</code></pre>

<hr>
<h2 id='MLA'>Most Likely True Alpha Value Given Observed Outcome.</h2><span id='topic+MLA'></span>

<h3>Description</h3>

<p>Given a fitted Standard (two-parameter) Beta Distribution, return the alpha shape-parameter value where the observed mean becomes the mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLA(alpha, beta, x = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLA_+3A_alpha">alpha</code></td>
<td>
<p>Observed alpha-parameter value for fitted Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="MLA_+3A_beta">beta</code></td>
<td>
<p>Observed beta-parameter value for fitted Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="MLA_+3A_x">x</code></td>
<td>
<p>Observed proportion-correct outcome.</p>
</td></tr>
<tr><td><code id="MLA_+3A_n">n</code></td>
<td>
<p>Test-length.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Alpha shape-parameter value for the Standard Beta probability density distribution where the observed mean is the expected mode.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assuming a prior Standard (two-parameter) Beta distribution is fit, which
# yield an alpha parameter of 10 and a beta parameter of 8, calculate the
# true-alpha parameter most likely to have produced the observations:
MLA(a = 10, b = 8)
</code></pre>

<hr>
<h2 id='MLB'>Most Likely True Beta Value Given Observed Outcome.</h2><span id='topic+MLB'></span>

<h3>Description</h3>

<p>Assuming a prior standard (two-parameter) Beta Distribution, return the beta shape-parameter value where the observed mean becomes the mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLB(alpha, beta, x = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLB_+3A_alpha">alpha</code></td>
<td>
<p>Observed alpha-parameter value for fitted Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="MLB_+3A_beta">beta</code></td>
<td>
<p>Observed beta-parameter value for fitted Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="MLB_+3A_x">x</code></td>
<td>
<p>Observed proportion-correct outcome.</p>
</td></tr>
<tr><td><code id="MLB_+3A_n">n</code></td>
<td>
<p>Test-length.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Beta shape-parameter value for the Standard Beta probability density distribution where the observed mean is the expected mode.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assuming a prior Standard (two-parameter) Beta distribution is fit, which
# yield an alpha parameter of 10 and a beta parameter of 8, calculate the
# true-beta parameter most likely to have produced the observations:
MLB(a = 10, b = 8)
</code></pre>

<hr>
<h2 id='MLM'>Most Likely Mean of the Standard Beta Probability Density Distribution, Given that the Observation is Considered the Most Likely Observation of the Standard Beta Probability Density Distribution (i.e., the mode).</h2><span id='topic+MLM'></span>

<h3>Description</h3>

<p>Assuming a prior Standard (two-parameter) Beta Distribution, returns the expected mean of the distribution under the assumption that the observed value is the most likely value of the distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLM(alpha, beta, x = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLM_+3A_alpha">alpha</code></td>
<td>
<p>Observed alpha value for fitted Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="MLM_+3A_beta">beta</code></td>
<td>
<p>Observed beta value for fitted Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="MLM_+3A_x">x</code></td>
<td>
<p>Observed proportion-correct outcome.</p>
</td></tr>
<tr><td><code id="MLM_+3A_n">n</code></td>
<td>
<p>Test-length.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The expected mean of the Standard Beta probability density distribution, for which the observed mean is the most likely value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assuming a prior Standard (two-parameter) Beta distribution is fit, which
# yield an alpha parameter of 10 and a beta parameter of 8, calculate the
# true-mean most likely to have produced the observations:
MLM(a = 10, b = 8)
</code></pre>

<hr>
<h2 id='observedmoments'>Compute Moments of Observed Value Distribution.</h2><span id='topic+observedmoments'></span>

<h3>Description</h3>

<p>Computes Raw, Central, or Standardized moment properties of a vector of observed scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observedmoments(
  x,
  type = c("raw", "central", "standardized"),
  orders = 4,
  correct = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="observedmoments_+3A_x">x</code></td>
<td>
<p>A vector of values, the distribution of which moments are to be calculated.</p>
</td></tr>
<tr><td><code id="observedmoments_+3A_type">type</code></td>
<td>
<p>A character vector determining which moment-types are to be calculated. Permissible values are <code>"raw"</code>, <code>"central"</code>, and <code>"standardized"</code>.</p>
</td></tr>
<tr><td><code id="observedmoments_+3A_orders">orders</code></td>
<td>
<p>The number of moment-orders to be calculated for each of the moment-types.</p>
</td></tr>
<tr><td><code id="observedmoments_+3A_correct">correct</code></td>
<td>
<p>Logical. Whether to include bias correction in estimation of orders. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of moment types, each a list of moment orders.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, 0.25, 0.75, 5, 3))
hist(testdata, xlim = c(0, 100))

# To compute the first four raw, central, and standardized moments for this
# distribution of observed scores using observedmoments():
observedmoments(x = testdata, type = c("raw", "central", "standardized"),
orders = 4, correct = TRUE)
</code></pre>

<hr>
<h2 id='pBeta.4P'>Cumulative Probability Function under the Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+pBeta.4P'></span>

<h3>Description</h3>

<p>Function for calculating the proportion of observations up to a specifiable quantile under the Four-Parameter Beta Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pBeta.4P(q, l, u, alpha, beta, lower.tail = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pBeta.4P_+3A_q">q</code></td>
<td>
<p>The quantile or a vector of quantiles for which the proportion is to be calculated.</p>
</td></tr>
<tr><td><code id="pBeta.4P_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="pBeta.4P_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="pBeta.4P_+3A_alpha">alpha</code></td>
<td>
<p>The first shape parameter.</p>
</td></tr>
<tr><td><code id="pBeta.4P_+3A_beta">beta</code></td>
<td>
<p>The second shape parameter.</p>
</td></tr>
<tr><td><code id="pBeta.4P_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Whether the proportion to be calculated is to be under the lower or upper tail. Default is <code>TRUE</code> (lower tail).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of proportions of observations falling under specified quantiles under the four-parameter Beta distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a four-parameter Beta distribution with
# location parameters l = 0.25 and u = 0.75, and shape parameters alpha = 5
# and beta = 3. To compute the cumulative probability at a specific point of
# the distribution (e.g., 0.5)
# using pBeta.4P():
pBeta.4P(q = 0.5, l = 0.25, u = 0.75, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='pBetaBinom'>Cumulative Probability Function under the Beta-Binomial Probability Distribution.</h2><span id='topic+pBetaBinom'></span>

<h3>Description</h3>

<p>Function for calculating the proportion of observations up to a specifiable quantile under the Beta-Binomial Probability Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pBetaBinom(q, N, l, u, alpha, beta, lower.tail = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pBetaBinom_+3A_q">q</code></td>
<td>
<p>The quantile or a vector of quantiles for which the proportion is to be calculated.</p>
</td></tr>
<tr><td><code id="pBetaBinom_+3A_n">N</code></td>
<td>
<p>The total number of trials.</p>
</td></tr>
<tr><td><code id="pBetaBinom_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="pBetaBinom_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="pBetaBinom_+3A_alpha">alpha</code></td>
<td>
<p>The first shape parameter.</p>
</td></tr>
<tr><td><code id="pBetaBinom_+3A_beta">beta</code></td>
<td>
<p>The second shape parameter.</p>
</td></tr>
<tr><td><code id="pBetaBinom_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Whether the proportion to be calculated is to be under the lower or upper tail. Default is <code>TRUE</code> (lower tail).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of proportions of observations falling under specified quantiles under the four-parameter Beta distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a Beta-Binomial distribution with number of
# trials = 50, and probabilities of successful trials are drawn from a four-
# parameter Beta distribution with location parameters l = 0.25 and u =
# 0.75, and shape parameters alpha = 5 and beta = 3. To compute the
# cumulative probability at a specific point of the distribution (e.g., 25):
pBetaBinom(q = 25, N = 50, l = .25, u = .75, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='pBetaMS'>Probability of Some Specific Observation under the Beta Probability Density Distribution with Specific Location Parameters, Mean, and Variance.</h2><span id='topic+pBetaMS'></span>

<h3>Description</h3>

<p>Calculates the probability of some specific observation falling under a specified interval  ([0, x] or [x, 1]) under the Standard Beta probability density distribution with defined mean and variance or standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pBetaMS(q, mean, variance = NULL, sd = NULL, lower.tail = TRUE, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pBetaMS_+3A_q">q</code></td>
<td>
<p>A specific point on the x-axis of the Standard Beta probability density distribution with a defined mean and variance.</p>
</td></tr>
<tr><td><code id="pBetaMS_+3A_mean">mean</code></td>
<td>
<p>The mean of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="pBetaMS_+3A_variance">variance</code></td>
<td>
<p>The variance of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="pBetaMS_+3A_sd">sd</code></td>
<td>
<p>The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="pBetaMS_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Whether the density that should be considered is between the lower-end (i.e., [0 -&gt; x]) or the higher-end of the distribution (i.e., [x -&gt; 1]).</p>
</td></tr>
<tr><td><code id="pBetaMS_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter. Default set to 0 (the standard Beta distribution).</p>
</td></tr>
<tr><td><code id="pBetaMS_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter. Default set to 1 (the standard Beta distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value representing the probability of a random draw from the Standard Beta probability density distribution with a defined mean and variance being from one of two defined intervals (i.e., [0 -&gt; x] or [x -&gt; 1]).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To compute the proportion of the density under the lower-end tail of a
# point along the Standard (two-parameter) Probability Density Distribution
# (e.g., 0.5) with mean of 0.6 and variance of 0.04:
pBetaMS(q = 0.5, mean = 0.6, variance = 0.04)

# To compute the proportion of the density under the lower-end tail of a
# point along the Four-Parameter Beta Probability Density Distribution
# (e.g., 50) with mean of 60 and variance of 400, and lower-bound of 0 and
# upper-bound of 100:
pBetaMS(q = 50, mean = 60, variance = 400, l = 0, u = 100)
</code></pre>

<hr>
<h2 id='pcBinom'>Cumulative Probability Mass function for Lord's Two-Term Approximation to the Compound Binomial Distribution.</h2><span id='topic+pcBinom'></span>

<h3>Description</h3>

<p>Function for calculating the proportion of observations up to a specifiable quantile under Lord's two-term approximation to the compound Binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcBinom(q, N, k, p, lower.tail = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcBinom_+3A_q">q</code></td>
<td>
<p>The quantile or vector of quantiles for which the proportion is to be calculated.</p>
</td></tr>
<tr><td><code id="pcBinom_+3A_n">N</code></td>
<td>
<p>Total number of trials.</p>
</td></tr>
<tr><td><code id="pcBinom_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function).</p>
</td></tr>
<tr><td><code id="pcBinom_+3A_p">p</code></td>
<td>
<p>Probability of success for each trial.</p>
</td></tr>
<tr><td><code id="pcBinom_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. If TRUE (default), probabilities are P[X&lt;x], otherwise, P[X &gt;= x]. Note that this differs from base-R <code>binom()</code> functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a compound Binomial distribution with 100
# trials, a 50% probability of success on each trial, and Lord's k = 1. To
# compute the cumulative probability at a specific point of the distribution
# (e.g., 50):
pcBinom(q = 50, N = 100, k = 1, p = .5)
</code></pre>

<hr>
<h2 id='pGammaBinom'>Cumulative probability density function under the Gamma-extended Binomial distribution.</h2><span id='topic+pGammaBinom'></span>

<h3>Description</h3>

<p>Extends the cumulative Binomial probability mass function to positive non-integers, effectively turning the mass-function into a density-function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pGammaBinom(q, size, prob, lower.tail = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pGammaBinom_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="pGammaBinom_+3A_size">size</code></td>
<td>
<p>Number of &quot;trials&quot; (zero or more). Need not be integer.</p>
</td></tr>
<tr><td><code id="pGammaBinom_+3A_prob">prob</code></td>
<td>
<p>Probability of &quot;success&quot; on each &quot;trial&quot;. Need not be integer.</p>
</td></tr>
<tr><td><code id="pGammaBinom_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. If TRUE (default), probabilities are P[X&lt;x], otherwise, P[X &gt;= x]. Note that this differs from base-R <code>binom()</code> functions.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Loeb, D. E. (1992). A generalization of the binomial coefficients. Discrete Mathematics, 105(1-3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a Gamma-Binomial  distribution with
# "number of trials" = 10.5 and probability of "success" for each "trial"
# = 0.75, to compute the cumulative probability to attain a "number of
# success" below a specific point (e.g., less than 7.5 "successes":
pGammaBinom(q = 7.5, size = 10.5, prob = 0.75)

# Conversely, to attain a value at or above 7.5:
pGammaBinom(q = 7.5, size = 10.5, prob = 0.75, lower.tail = FALSE)
</code></pre>

<hr>
<h2 id='qBeta.4P'>Quantile Given Probability Under the Four-Parameter Beta Distribution.</h2><span id='topic+qBeta.4P'></span>

<h3>Description</h3>

<p>Function for calculating the quantile (i.e., value of <code>x</code>) for a given proportion (i.e., the value of <code>y</code>) under the Four-Parameter Beta Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qBeta.4P(p, l, u, alpha, beta, lower.tail = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qBeta.4P_+3A_p">p</code></td>
<td>
<p>A vector (or single value) of proportions or probabilities for which the corresponding value of <code>x</code> (i.e., the quantiles) are to be calculated.</p>
</td></tr>
<tr><td><code id="qBeta.4P_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="qBeta.4P_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="qBeta.4P_+3A_alpha">alpha</code></td>
<td>
<p>The first shape parameter.</p>
</td></tr>
<tr><td><code id="qBeta.4P_+3A_beta">beta</code></td>
<td>
<p>The second shape parameter.</p>
</td></tr>
<tr><td><code id="qBeta.4P_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. Whether the quantile(s) to be calculated is to be under the lower or upper tail. Default is <code>TRUE</code> (lower tail).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of quantiles for specified probabilities or proportions of observations under the four-parameter Beta distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a four-parameter Beta distribution with
# location parameters l = 0.25 and u = 0.75, and shape parameters alpha = 5
# and beta = 3. To compute the quantile at a specific point of the
# distribution (e.g., 0.5) using qBeta.4P():
qBeta.4P(p = 0.5, l = 0.25, u = 0.75, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='qBetaMS'>Quantile Containing Specific Proportion of the Distribution, Given a Specific Probability of the Beta Probability Density Distribution with Specific Mean and Variance.</h2><span id='topic+qBetaMS'></span>

<h3>Description</h3>

<p>Calculates the quantile corresponding to a specific probability of some observation falling within the [0, x] (<code>lt = TRUE</code>) or [x, 1] (<code>lt = FALSE</code>) interval under the Standard Beta probability density distribution with defined mean and variance or standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qBetaMS(p, mean, variance = NULL, sd = NULL, lower.tail = TRUE, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qBetaMS_+3A_p">p</code></td>
<td>
<p>A value of probability marking the point of the Y-axis to correspond to the X-axis.</p>
</td></tr>
<tr><td><code id="qBetaMS_+3A_mean">mean</code></td>
<td>
<p>The mean of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="qBetaMS_+3A_variance">variance</code></td>
<td>
<p>The variance of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="qBetaMS_+3A_sd">sd</code></td>
<td>
<p>The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="qBetaMS_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. Specifies which end of the tail for which to calculate quantile. Default is <code>TRUE</code> (meaning, find q for lower tail.)</p>
</td></tr>
<tr><td><code id="qBetaMS_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter. Default set to 0 (the standard Beta distribution).</p>
</td></tr>
<tr><td><code id="qBetaMS_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter. Default set to 1 (the standard Beta distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the quantile for which the specified proportion of observations fall within.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To compute the quantile at a specific point (e.g., 0.5) along the Standard
# (two-parameter) Probability Density Distribution with mean of 0.6 and variance of 0.04:
qBetaMS(p = 0.5, mean = 0.6, variance = 0.04)

# To compute the quantile at a specific points(e.g., 0.5) along the four-
# parameter Beta distribution with a mean of 60, variance of 400, and lower-
# bound of 0 and upper-bound of 100:
qBetaMS(p = 0.5, mean = 60, variance = 400, l = 0, u = 100)
</code></pre>

<hr>
<h2 id='qGammaBinom'>Quantile function for the Gamma-extended Binomial distribution.</h2><span id='topic+qGammaBinom'></span>

<h3>Description</h3>

<p>Quantile function for the Gamma-extended Binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qGammaBinom(p, size, prob, lower.tail = TRUE, precision = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qGammaBinom_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="qGammaBinom_+3A_size">size</code></td>
<td>
<p>Number of &quot;trials&quot; (zero or more, including positive non-integers).</p>
</td></tr>
<tr><td><code id="qGammaBinom_+3A_prob">prob</code></td>
<td>
<p>Probability of success on each &quot;trial&quot;.</p>
</td></tr>
<tr><td><code id="qGammaBinom_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical. If TRUE (default), probabilities are P[X &lt; x], otherwise P[X &gt; x].</p>
</td></tr>
<tr><td><code id="qGammaBinom_+3A_precision">precision</code></td>
<td>
<p>The precision with which the quantile is to be calculated. Default is 1e-7 (i.e., search terminates when there is no registered change in estimate at the seventh decimal). Tuning this value will impact the time it takes for the search algorithm to arrive at an estimate.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function uses a bisection search-algorithm to find the number of successes corresponding to the specified quantile(s). This algorithm is inefficient with respect to the number of iterations required to converge on the solution. More efficient algorithms might be added in later versions.
</p>


<h3>References</h3>

<p>Loeb, D. E. (1992). A generalization of the binomial coefficients. Discrete Mathematics, 105(1-3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a Gamma-extended Binomial distribution with number of trials = 10 and
# probability of success per trial of 0.75, calculate the number of success-
# ful trials at or below the 25% quantile:
qGammaBinom(p = 0.25, size = 10, prob = 0.75)

# Conversely, for a Gamma-extended Binomial distribution with number of
# trials = 10 and probability of success per trial of 0.75, calculate the
# number of successful trials at or above the 25% quantile:
qGammaBinom(p = 0.25, size = 10, prob = 0.75, lower.tail = FALSE)
</code></pre>

<hr>
<h2 id='R.ETL'>Model Implied Reliability from Livingston and Lewis' &quot;Effective Test Length&quot;.</h2><span id='topic+R.ETL'></span>

<h3>Description</h3>

<p>Calculate model-implied reliability given mean, variance, the minimum and maximum possible scores, and the effective test length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R.ETL(mean, variance, min = 0, max = 1, ETL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R.ETL_+3A_mean">mean</code></td>
<td>
<p>The mean of the observed-score distribution.</p>
</td></tr>
<tr><td><code id="R.ETL_+3A_variance">variance</code></td>
<td>
<p>The variance of the observed-score distribution.</p>
</td></tr>
<tr><td><code id="R.ETL_+3A_min">min</code></td>
<td>
<p>The lower-bound (minimum possible value) of the observed-score distribution. Default is 0 (assuming observed scores represent proportions).</p>
</td></tr>
<tr><td><code id="R.ETL_+3A_max">max</code></td>
<td>
<p>The upper-bound (maximum possible value) of the observed-score distribution. Default is 1 (assuming observed scores represent proportions).</p>
</td></tr>
<tr><td><code id="R.ETL_+3A_etl">ETL</code></td>
<td>
<p>The effective test length as defined by Livingston and Lewis (1995).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An estimate of the reliability of a test, given the effective test length, mean, variance, and minimum and maximum possible scores of the observed-score distribution..
</p>


<h3>References</h3>

<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data. Say, 100 individuals take a test with a
# maximum score of 100 and a minimum score of 0.
set.seed(1234)
testdata &lt;- rbinom(100, 100, rBeta.4P(100, .25, .75, 5, 3))
hist(testdata, xlim = c(0, 100))

# From the data-generating script above, the effective test length is 100.
# To estimate and retrieve the model-implied reliability using R.ETL():
R.ETL(mean = mean(testdata), variance = var(testdata), min = 0, max = 100,
ETL = 100)
</code></pre>

<hr>
<h2 id='rBeta.4P'>Random Number Generation under the Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+rBeta.4P'></span>

<h3>Description</h3>

<p>Function for generating random numbers from a specified Four-Parameter Beta Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rBeta.4P(n, l, u, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rBeta.4P_+3A_n">n</code></td>
<td>
<p>Number of draws.</p>
</td></tr>
<tr><td><code id="rBeta.4P_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="rBeta.4P_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="rBeta.4P_+3A_alpha">alpha</code></td>
<td>
<p>The alpha (first) shape parameter.</p>
</td></tr>
<tr><td><code id="rBeta.4P_+3A_beta">beta</code></td>
<td>
<p>The beta (second) shape parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with length <code>n</code> of random values drawn from the Four-Parameter Beta Distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a four-parameter Beta distribution with
# location parameters l = 0.25 and u = 0.75, and shape parameters alpha = 5
# and beta = 3. To draw a random value from this distribution using
# rBeta.4P():
rBeta.4P(n = 1, l = 0.25, u = 0.75, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='rBetaBinom'>Random Number Generation under the Beta-Binomial Probability Mass Distribution.</h2><span id='topic+rBetaBinom'></span>

<h3>Description</h3>

<p>Random Number Generation under the Beta-Binomial Probability Mass Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rBetaBinom(n, N, l, u, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rBetaBinom_+3A_n">n</code></td>
<td>
<p>Number of draws.</p>
</td></tr>
<tr><td><code id="rBetaBinom_+3A_n">N</code></td>
<td>
<p>Number of trials.</p>
</td></tr>
<tr><td><code id="rBetaBinom_+3A_l">l</code></td>
<td>
<p>The first (lower) location parameter.</p>
</td></tr>
<tr><td><code id="rBetaBinom_+3A_u">u</code></td>
<td>
<p>The second (upper) location parameter.</p>
</td></tr>
<tr><td><code id="rBetaBinom_+3A_alpha">alpha</code></td>
<td>
<p>The alpha (first) shape parameter.</p>
</td></tr>
<tr><td><code id="rBetaBinom_+3A_beta">beta</code></td>
<td>
<p>The beta (second) shape parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with length <code>n</code> of random values drawn from the Beta-Binomial Distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To draw a sample of 50 values from a Beta-Binomial distribution with
# number of trials = 100, and with success-probabilities drawn from a
# Four-Parameter Beta distribution with location parameters l = 0.25 and
# u = 0.95, and shape-parameters alpha = 5 and beta = 3:
rBetaBinom(n = 50, N = 100, l = 0.25, u = 0.95, alpha = 5, beta = 3)
</code></pre>

<hr>
<h2 id='rBetacBinom'>Random Number Generation under Lord's Beta Compound-Binomial Distribution.</h2><span id='topic+rBetacBinom'></span>

<h3>Description</h3>

<p>Random number generation under Lord's Beta Compound-Binomial distribution, where the Compound-Binomial distribution is Lord's two-term approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rBetacBinom(x, N, k, l, u, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rBetacBinom_+3A_x">x</code></td>
<td>
<p>Number of draws.</p>
</td></tr>
<tr><td><code id="rBetacBinom_+3A_n">N</code></td>
<td>
<p>Number of trials.</p>
</td></tr>
<tr><td><code id="rBetacBinom_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function).</p>
</td></tr>
<tr><td><code id="rBetacBinom_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="rBetacBinom_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="rBetacBinom_+3A_alpha">alpha</code></td>
<td>
<p>The first shape-parameter of the four-parameter Beta distribution.</p>
</td></tr>
<tr><td><code id="rBetacBinom_+3A_beta">beta</code></td>
<td>
<p>The second shape-parameter of the four-parameter Beta distribution.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For larger values of <code>k</code>, the distribution can yield negative probabilities which returns an error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To draw a sample of 50 values from a Beta Compound-Binomial distribution
# with number of trials = 100, Lord's k = 1, and probabilities of successful
# trials drawn from a four-parameter Beta distribution with location-
# parameters l = .15 and u = .85, and shape parameters alpha = 6 and
# beta = 4:
rBetacBinom(x = 50, N = 100, k = 1, l = .15, u = .85, alpha = 6, beta = 4)
</code></pre>

<hr>
<h2 id='rBetaMS'>Random Draw from the Beta Probability Density Distribution With Specific Mean and Variance.</h2><span id='topic+rBetaMS'></span>

<h3>Description</h3>

<p>Draws random samples of observations from the Standard Beta probability density distribution with defined mean and variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rBetaMS(n, mean, variance = NULL, sd = NULL, l = 0, u = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rBetaMS_+3A_n">n</code></td>
<td>
<p>Number of observations to be drawn from under the Standard Beta Probability Density Distribution.</p>
</td></tr>
<tr><td><code id="rBetaMS_+3A_mean">mean</code></td>
<td>
<p>The mean of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="rBetaMS_+3A_variance">variance</code></td>
<td>
<p>The variance of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="rBetaMS_+3A_sd">sd</code></td>
<td>
<p>The standard deviation of the target Standard probability density distribution.</p>
</td></tr>
<tr><td><code id="rBetaMS_+3A_l">l</code></td>
<td>
<p>The lower-bound location parameter. Default set to 0 (the standard Beta distribution).</p>
</td></tr>
<tr><td><code id="rBetaMS_+3A_u">u</code></td>
<td>
<p>The upper-bound location parameter. Default set to 1 (the standard Beta distribution).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>n</code>, each value representing a random draw from the Standard Beta probability density distribution with defined mean and variance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To draw a random sample of 100 values from a Standard Beta distribution
# with a mean of 0.6 and variance = 0.04:
rBetaMS(n = 100, mean = 0.6, variance = 0.04)

# To draw a random sample of 100 values from a Four-Parameter Beta
# 0 and an upper-bound of 100:
rBetaMS(n = 100, mean = 60, variance = 400, l = 0, u = 100)
</code></pre>

<hr>
<h2 id='rcBinom'>Random Number Generation under Lord's Two-Term Approximation to the Compound Binomial Distribution.</h2><span id='topic+rcBinom'></span>

<h3>Description</h3>

<p>Random Number Generation under Lord's Two-Term Approximation to the Compound Binomial Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcBinom(n, N, k, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcBinom_+3A_n">n</code></td>
<td>
<p>Number of draws.</p>
</td></tr>
<tr><td><code id="rcBinom_+3A_n">N</code></td>
<td>
<p>Number of trials.</p>
</td></tr>
<tr><td><code id="rcBinom_+3A_k">k</code></td>
<td>
<p>Lord's k (see documentation for the <code>Lords.k()</code> function).</p>
</td></tr>
<tr><td><code id="rcBinom_+3A_p">p</code></td>
<td>
<p>Probability of success for each trial.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For larger values of <code>k</code>, the distribution can yield negative probabilities. This function handles such occurrences by adding the absolute value of the minimum probability to all observations if there are any negative probabilities and then normalize the distribution so that the total density is equal to 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To draw a sample of 50 values from a Compound-Binomial distribution with
# number of trials = 100, a 50% probability of success for each trial, and
# Lord's k = 1:
set.seed(1234)
rcBinom(n = 50, N = 100, k = 1, p = .5)

# To draw values where the probabilities vary for each draw:
rcBinom(n = 50, N = 100, k = 1, p = runif(50))
</code></pre>

<hr>
<h2 id='rGammaBinom'>Random number generation under the Gamma-extended Binomial distribution.</h2><span id='topic+rGammaBinom'></span>

<h3>Description</h3>

<p>Random number generation under the Gamma-extended Binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rGammaBinom(n, size, prob, precision = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rGammaBinom_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="rGammaBinom_+3A_size">size</code></td>
<td>
<p>Number of &quot;trials&quot; (zero or more). Need not be integer.</p>
</td></tr>
<tr><td><code id="rGammaBinom_+3A_prob">prob</code></td>
<td>
<p>Probability of &quot;success&quot; on each &quot;trial&quot;. Need not be integer.</p>
</td></tr>
<tr><td><code id="rGammaBinom_+3A_precision">precision</code></td>
<td>
<p>The precision with which the quantile is to be calculated. Default is 1e-4 (i.e., search terminates when there is no registered change in estimate at the fourth decimal). Tuning this value will impact the time it takes for the search algorithm to arrive at an estimate.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Calls <code>qGammaBinom()</code>, which makes the random draw slower than what one might be used to (since <code>qGammaBinom()</code> calls <code>pGammaBinom()</code> and employs a search-algorithm to find the appropriate value down to a specifiable level of precision).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Assume some variable follows a Gamma-Binomial distribution with
# "number of trials" = 10.5 and probability of "success" for each "trial"
# = 0.75 To draw a random value from this distribution:
rGammaBinom(n = 1, size = 10, prob = 0.75)
</code></pre>

<hr>
<h2 id='tsm'>Proportional true-score distribution raw moments from Livingston and Lewis' effective test-score and effective test-length.</h2><span id='topic+tsm'></span>

<h3>Description</h3>

<p>An implementation of Lords (1965, p. 265) equation 37 for estimating the raw moments of the true-score distribution, modified to function for the Livingston and Lewis approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tsm(x, r, n, method = "product")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tsm_+3A_x">x</code></td>
<td>
<p>The effective test-score of test-takers.</p>
</td></tr>
<tr><td><code id="tsm_+3A_r">r</code></td>
<td>
<p>The moment-order that is to be calculated (where 1 is the mean, 2 is the raw variance, 3 is the raw skewness, etc.).</p>
</td></tr>
<tr><td><code id="tsm_+3A_n">n</code></td>
<td>
<p>The effective test-length.</p>
</td></tr>
<tr><td><code id="tsm_+3A_method">method</code></td>
<td>
<p>The method by which the descending factorials are to be calculated. Default is <code>"product"</code> which uses direct arithmetic. Alternative is &quot;gamma&quot; which calculates the descending factorial using the Gamma function. The alternative method might be faster but might fail because the Gamma function is not defined for negative integers (returning Inf).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Lord, F. M. (1965). A strong true-score theory, with applications. Psychometrika. 30(3). pp. 239&ndash;270. doi: 10.1007/BF02289490
</p>
<p>Livingston, Samuel A. and Lewis, Charles. (1995). Estimating the Consistency and Accuracy of Classifications Based on Test Scores. Journal of Educational Measurement, 32(2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examine the raw moments of the underlying Beta distribution that is to provide the basis for
# observed-scores:
betamoments(alpha = 5, beta = 3, l = 0.25, u = 0.75, types = "raw")

# Generate observed-scores from true-scores by passing the true-scores as binomial probabilities
# for the rbinom function.
set.seed(1234)
obs.scores &lt;- rbinom(1000, 100, rBeta.4P(1000, 0.25, 0.75, 5, 3))
# Examine the raw moments of the observed-score distribution.
observedmoments(obs.scores, type = "raw")

# First four estimated raw moment of the proportional true-score distribution from the observed-
# score distribution. As all items are equally difficult, the effective test-length is equal to
# the actual test-length.
tsm(x = obs.scores, r = 1, n = 100)
tsm(x = obs.scores, r = 2, n = 100)
tsm(x = obs.scores, r = 3, n = 100)
tsm(x = obs.scores, r = 4, n = 100)
# Which is fairly close to the true raw moments of the proportional true-score distribution
# calculated above.
</code></pre>

<hr>
<h2 id='UABMSL'>Upper Location Parameter Given Shape Parameters, Mean, Variance, and Lower Location Parameter of a Four-Parameter Beta Probability Density Distribution.</h2><span id='topic+UABMSL'></span>

<h3>Description</h3>

<p>Calculates the upper-bound value required to produce a Beta probability density distribution with defined moments and parameters. Be advised that not all combinations of moments and parameters can be satisfied (e.g., specifying mean, variance, skewness and kurtosis uniquely determines both location-parameters, meaning that the value of the upper-location parameter will take on which ever value it must, and cannot be specified).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UABMSL(
  alpha = NULL,
  beta = NULL,
  mean = NULL,
  variance = NULL,
  l = NULL,
  sd = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UABMSL_+3A_alpha">alpha</code></td>
<td>
<p>The alpha shape-parameter of the target Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="UABMSL_+3A_beta">beta</code></td>
<td>
<p>The beta shape-parameter of the target Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="UABMSL_+3A_mean">mean</code></td>
<td>
<p>The mean (first raw moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="UABMSL_+3A_variance">variance</code></td>
<td>
<p>The variance (second central moment) of the target Standard Beta probability density distribution.</p>
</td></tr>
<tr><td><code id="UABMSL_+3A_l">l</code></td>
<td>
<p>The lower-bound of the Beta distribution. Default is NULL (i.e., does not take a specified l-parameter into account).</p>
</td></tr>
<tr><td><code id="UABMSL_+3A_sd">sd</code></td>
<td>
<p>Optional alternative to specifying <code>var</code>. The standard deviation of the target Standard Beta probability density distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the required value for the Beta upper location-parameter (<code>u</code>) in order to produce a Beta probability density distribution with the target moments and parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some fictional data.
set.seed(1234)
testdata &lt;- rBeta.4P(100000, 0.25, 0.75, 5, 3)
hist(testdata, xlim = c(0, 1), freq = FALSE)

# Suppose you know three of the four necessary parameters to fit a four-
# parameter Beta distribution (i. e., l = 0.25, alpha = 5, beta = 3) to this
# data. To find the value for the necessary u parameter, estimate the mean
# and variance of the distribution:
M &lt;- mean(testdata)
S2 &lt;- var(testdata)

# To find the l parameter necessary to produce a four-parameter Beta
# distribution with the target mean, variance, and u, alpha, and beta
# parameters using the LMSBAU() function:
(u &lt;- UABMSL(alpha = 5, beta = 3, mean = M, variance = S2, l = 0.25))
curve(dBeta.4P(x, 0.25, u, 5, 3), add = TRUE, lwd = 2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
