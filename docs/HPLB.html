<!DOCTYPE html><html lang="en"><head><title>Help for package HPLB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HPLB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#boundingOperation'><p>Bounding Operation</p></a></li>
<li><a href='#empiricalBF'><p>Empirical Bounding Functions</p></a></li>
<li><a href='#HPLB'><p>High Probability Lower Bounds (HPLB) for the Total Variation Distance (TV) Based on Finite Samples</p></a></li>
<li><a href='#HPLBmatrix'><p>Pairwise Total Variation Distance Lower Bound Matrix for the Multi-Class Setting</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>High-Probability Lower Bounds for the Total Variance Distance</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Loris Michel, Jeffrey Naef</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Loris Michel &lt;michel@stat.math.ethz.ch&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of high-probability lower bounds for the total variance distance 
             as introduced in Michel &amp; Naef &amp; Meinshausen (2020) &lt;<a href="https://doi.org/10.48550/arXiv.2005.06006">doi:10.48550/arXiv.2005.06006</a>&gt;. An estimated 
             lower-bound (with high-probability) on the total variation distance between two probability distributions from which
             samples are observed can be obtained with the function HPLB.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>data.table, stats, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, fields, ranger, distrEx</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-06-05 13:03:40 UTC; michello</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-09 12:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='boundingOperation'>Bounding Operation</h2><span id='topic+boundingOperation'></span>

<h3>Description</h3>

<p>Bounding Operation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boundingOperation(v, left, right, m, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boundingOperation_+3A_v">v</code></td>
<td>
<p>a a numeric value giving an ordering permutation of 1 to m+n.</p>
</td></tr>
<tr><td><code id="boundingOperation_+3A_left">left</code></td>
<td>
<p>a numeric value giving the number of witnesses left.</p>
</td></tr>
<tr><td><code id="boundingOperation_+3A_right">right</code></td>
<td>
<p>a numeric value giving the number of witnesses right.</p>
</td></tr>
<tr><td><code id="boundingOperation_+3A_m">m</code></td>
<td>
<p>a numeric value, the number of observations left.</p>
</td></tr>
<tr><td><code id="boundingOperation_+3A_n">n</code></td>
<td>
<p>a numeric value, the number of observations right.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a cumulative counting function represented as a numeric vector.
</p>

<hr>
<h2 id='empiricalBF'>Empirical Bounding Functions</h2><span id='topic+empiricalBF'></span>

<h3>Description</h3>

<p>Empirical Bounding Functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empiricalBF(tv.seq, nsim = 1000, m = 100, n = 100, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="empiricalBF_+3A_tv.seq">tv.seq</code></td>
<td>
<p>a vector of total variation values between 0 and 1.</p>
</td></tr>
<tr><td><code id="empiricalBF_+3A_nsim">nsim</code></td>
<td>
<p>a numeric value giving the number of repetitions.</p>
</td></tr>
<tr><td><code id="empiricalBF_+3A_m">m</code></td>
<td>
<p>a numeric value, the number of observations left.</p>
</td></tr>
<tr><td><code id="empiricalBF_+3A_n">n</code></td>
<td>
<p>a numeric value, the number of observations right.</p>
</td></tr>
<tr><td><code id="empiricalBF_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value giving the type-I error level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of empirical bounding functions indexed by the tv.seq (in the respective order).
</p>

<hr>
<h2 id='HPLB'>High Probability Lower Bounds (HPLB) for the Total Variation Distance (TV) Based on Finite Samples</h2><span id='topic+HPLB'></span>

<h3>Description</h3>

<p>Implementations of different HPLBs for TV as described in (Michel et al., 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HPLB(
  t,
  rho,
  s = 0.5,
  estimator.type = "adapt",
  alpha = 0.05,
  tv.seq = seq(from = 0, to = 1, by = 1/length(t)),
  custom.bounding.seq = NULL,
  direction = rep("left", length(s)),
  cutoff = 0.5,
  verbose.plot = FALSE,
  seed = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HPLB_+3A_t">t</code></td>
<td>
<p>a numeric vector value corresponding to a natural ordering of the observations. For a two-sample
test 0-1 numeric values values should be provided.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_rho">rho</code></td>
<td>
<p>a numeric vector value providing an ordering. This could be
a binary classifier, a regressor, a witness function from a MMD kernel or anything else that would witness a distributional difference.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_s">s</code></td>
<td>
<p>a numeric vector value giving split points on t.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_estimator.type">estimator.type</code></td>
<td>
<p>a character value indicating which estimator to use. One option out of:
</p>

<ul>
<li><p><code>adapt</code>:adaptive binary classification estimator (asymptotic bounding function)
</p>
</li>
<li><p><code>bayes</code>:binary classification estimator
</p>
</li>
<li><p><code>bayes_finite_sample</code>:binary classification finite sample estimator
</p>
</li>
<li><p><code>adapt_empirical</code>:adaptive binary classification estimator (simulation-based bounding function)
</p>
</li>
<li><p><code>adapt_custom</code>:adaptive binary classificatrion estimator (user-defined bounding function)
</p>
</li>
<li><p><code>adapt_dwit</code>:adaptive binary classificatrion estimator (for distributional witnesses estimation)
</p>
</li></ul>
</td></tr>
<tr><td><code id="HPLB_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value giving the overall type-I error control level.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_tv.seq">tv.seq</code></td>
<td>
<p>a sequence of values between 0 and 1 used as the grid search for the total variation distance in case of tv-search.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_custom.bounding.seq">custom.bounding.seq</code></td>
<td>
<p>a list of bounding functions respecting the order of tv.seq used in case of estimator.type &quot;custom-tv-search&quot;.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_direction">direction</code></td>
<td>
<p>a character vector value made of &quot;left&quot; or &quot;right&quot; giving which distribution witness count to estimate (t&lt;=s or t&gt;s?).</p>
</td></tr>
<tr><td><code id="HPLB_+3A_cutoff">cutoff</code></td>
<td>
<p>a numeric value. This is the cutoff used if bayes estimators are used. The theory suggests to use 1/2 but this can be changed.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_verbose.plot">verbose.plot</code></td>
<td>
<p>a boolean value for additional plots.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_seed">seed</code></td>
<td>
<p>an integer value. The seed for reproducibility.</p>
</td></tr>
<tr><td><code id="HPLB_+3A_...">...</code></td>
<td>
<p>additional parameters for the function <code>empiricalBF</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code> containing the relevant lower bounds estimates. For the total variation distance the relevant entry is <code>tvhat</code>.
</p>


<h3>Author(s)</h3>

<p>Loris Michel, Jeffrey Naef
</p>


<h3>References</h3>

<p>L. Michel, J. Naef and N. Meinshausen (2020). High-Probability Lower Bounds for the Total Variation Distance <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## libs
library(HPLB)
library(ranger)
library(distrEx)

## reproducibility
set.seed(0)

## Example 1: TV lower bound based on two samples (bayes estimator), Gaussian mean-shift example

n &lt;- 100
means &lt;- rep(c(0,2), each = n / 2)
x &lt;- stats::rnorm(n, mean = means)
t &lt;- rep(c(0,1), each = n / 2)

bayesRate &lt;- function(x) {
  return(stats::dnorm(x, mean = 2) /
    (stats::dnorm(x, mean = 2) + stats::dnorm(x, mean = 0)))
}

# estimated HPLB
tvhat &lt;- HPLB(t = t, rho = bayesRate(x), estimator.type = "bayes")
# true TV
TotalVarDist(e1 = Norm(2,1), e2 = Norm(0,1))

## Example 2: optimal mixture detection (adapt estimator), Gaussian mean-shift example

n &lt;- 100
mean.shift &lt;- 2
t.train &lt;- runif(n, 0 ,1)
x.train &lt;- ifelse(t.train&gt;0.5, stats::rnorm(n, mean.shift), stats::rnorm(n))
rf &lt;- ranger::ranger(t~x, data.frame(t=t.train,x=x.train))

n &lt;- 100
t.test &lt;- runif(n, 0 ,1)
x.test &lt;- ifelse(t.test&gt;0.5, stats::rnorm(n, mean.shift), stats::rnorm(n))
rho &lt;- predict(rf, data.frame(t=t.test,x=x.test))$predictions

## out-of-sample
tv.oos &lt;- HPLB(t = t.test, rho = rho, s = seq(0.1,0.9,0.1), estimator.type = "adapt")


## total variation values
tv &lt;- c()
for (s in seq(0.1,0.9,0.1)) {

 if (s&lt;=0.5) {

   D.left &lt;- Norm(0,1)
 } else {

   D.left &lt;- UnivarMixingDistribution(Dlist = list(Norm(0,1),Norm(mean.shift,1)),
               mixCoeff = c(ifelse(s&lt;=0.5, 1, 0.5/s), ifelse(s&lt;=0.5, 0, (s-0.5)/s)))
 }
 if (s &lt; 0.5) {

   D.right &lt;- UnivarMixingDistribution(Dlist = list(Norm(0,1),Norm(mean.shift,1)),
               mixCoeff = c(ifelse(s&lt;=0.5, (0.5-s)/(1-s), 0), ifelse(s&lt;=0.5, (0.5/(1-s)), 1)))
 } else {

   D.right &lt;- Norm(mean.shift,1)
 }
tv &lt;- c(tv, TotalVarDist(e1 = D.left, e2 = D.right))
}

## plot
oldpar &lt;- par(no.readonly =TRUE)
par(mfrow=c(2,1))
plot(t.test,x.test,pch=19,xlab="t",ylab="x")
plot(seq(0.1,0.9,0.1), tv.oos$tvhat,type="l",ylim=c(0,1),xlab="t", ylab="TV")
lines(seq(0.1,0.9,0.1), tv, col="red",type="l")
par(oldpar)

</code></pre>

<hr>
<h2 id='HPLBmatrix'>Pairwise Total Variation Distance Lower Bound Matrix for the Multi-Class Setting</h2><span id='topic+HPLBmatrix'></span>

<h3>Description</h3>

<p>Pairwise Total Variation Distance Lower Bound Matrix for the Multi-Class Setting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HPLBmatrix(
  labels,
  ordering.array,
  alpha = 0.05,
  computation.type = "non-optimized",
  seed = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HPLBmatrix_+3A_labels">labels</code></td>
<td>
<p>a numeric vector value. The labels of the classes, should be encoded in [0,nclass-1].</p>
</td></tr>
<tr><td><code id="HPLBmatrix_+3A_ordering.array">ordering.array</code></td>
<td>
<p>a numeric array of size (nclass, nclass, nobs) such that the value (i,j,k) represents a propensity of being of class j instead of i for observation k.</p>
</td></tr>
<tr><td><code id="HPLBmatrix_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value. The type-I error level.</p>
</td></tr>
<tr><td><code id="HPLBmatrix_+3A_computation.type">computation.type</code></td>
<td>
<p>a character value. For the moment only &quot;non-optimized&quot; (default) available.</p>
</td></tr>
<tr><td><code id="HPLBmatrix_+3A_seed">seed</code></td>
<td>
<p>an integer value. The seed for reproducility.</p>
</td></tr>
<tr><td><code id="HPLBmatrix_+3A_...">...</code></td>
<td>
<p>additional parameters to be passed to the HPLB function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric matrix of size (nclass, nclass) giving the matrix of pairwise total variation lower bounds.
</p>


<h3>Author(s)</h3>

<p>Loris Michel, Jeffrey Naef
</p>


<h3>References</h3>

<p>L. Michel, J. Naef and N. Meinshausen (2020). High-Probability Lower Bounds for the Total Variation Distance <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # iris example
 require(HPLB)
 require(ranger)

 # training a multi-class classifier on iris and getting tv lower bounds between classes
 data("iris")

 ind.train &lt;- sample(1:nrow(iris), size = nrow(iris)/2, replace = FALSE)

 rf &lt;- ranger(Species~., data = iris[ind.train, ], probability = TRUE)
 preds &lt;- predict(rf, iris[-ind.train,])$predictions

 # creating the ordering array based on prediction differences
 ar &lt;- array(dim = c(3, 3, nrow(preds)))
 for (i in 1:3) {
   for (j in 1:3) {
    ar[i,j,] &lt;- preds[,j] - preds[,i]
   }
 }

 # encoding the class response
 y &lt;- factor(iris$Species)
 levels(y) &lt;- c(0,1,2)
 y &lt;- as.numeric(y)-1

 # getting the lower bound matrix
 tvhat.iris &lt;- HPLBmatrix(labels = y[-ind.train], ordering.array = ar)
 tvhat.iris
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
