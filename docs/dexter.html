<!DOCTYPE html><html lang="en"><head><title>Help for package dexter</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dexter}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dexter-package'><p>Dexter: data analyses for educational and psychological tests.</p></a></li>
<li><a href='#ability'><p>Estimate abilities</p></a></li>
<li><a href='#add_booklet'><p>Add response data to a project</p></a></li>
<li><a href='#add_item_properties'><p>Add item properties to a project</p></a></li>
<li><a href='#add_person_properties'><p>Add person properties to a project</p></a></li>
<li><a href='#close_project'><p>Close a project</p></a></li>
<li><a href='#coef.p2pass'><p>extract equating information</p></a></li>
<li><a href='#coef.prms'><p>extract enorm item parameters</p></a></li>
<li><a href='#design_info'><p>Information about the design</p></a></li>
<li><a href='#DIF'><p>Exploratory test for Differential Item Functioning</p></a></li>
<li><a href='#distractor_plot'><p>Distractor plot</p></a></li>
<li><a href='#fit_domains'><p>Estimate the Rasch and the Interaction model per domain</p></a></li>
<li><a href='#fit_enorm'><p>Fit the extended nominal response model</p></a></li>
<li><a href='#fit_inter'><p>Estimate the Interaction and the Rasch model</p></a></li>
<li><a href='#get_booklets'><p>Booklets entered in a project</p></a></li>
<li><a href='#get_design'><p>Test design</p></a></li>
<li><a href='#get_items'><p>Items in a project</p></a></li>
<li><a href='#get_persons'><p>Persons in a project</p></a></li>
<li><a href='#get_resp_data'><p>Functions for developers</p></a></li>
<li><a href='#get_responses'><p>Selecting data</p></a></li>
<li><a href='#get_rules'><p>Get scoring rules</p></a></li>
<li><a href='#get_testscores'><p>Get test scores</p></a></li>
<li><a href='#get_variables'><p>Variables that are defined in the project</p></a></li>
<li><a href='#individual_differences'><p>Test individual differences</p></a></li>
<li><a href='#information'><p>Functions of theta</p></a></li>
<li><a href='#keys_to_rules'><p>Derive scoring rules from keys</p></a></li>
<li><a href='#latent_cor'><p>Latent correlations</p></a></li>
<li><a href='#open_project'><p>Open an existing project</p></a></li>
<li><a href='#plausible_scores'><p>Draw plausible test scores</p></a></li>
<li><a href='#plausible_values'><p>Draw plausible values</p></a></li>
<li><a href='#plot.DIF_stats'><p>plot method for pairwise DIF statistics</p></a></li>
<li><a href='#plot.p2pass'><p>A plot method for probability_to_pass</p></a></li>
<li><a href='#plot.prms'><p>Plot for the extended nominal Response model</p></a></li>
<li><a href='#plot.rim'><p>A plot method for the interaction model</p></a></li>
<li><a href='#probability_to_pass'><p>The probability to pass on a reference test given a score on a new booklet</p></a></li>
<li><a href='#profile_plot'><p>Profile plot</p></a></li>
<li><a href='#profile_tables'><p>Profile analysis</p></a></li>
<li><a href='#r_score_IM'><p>Simulation from the interaction model</p></a></li>
<li><a href='#ratedData'><p>Rated data</p></a></li>
<li><a href='#ratedDataProperties'><p>Item properties in the rated data</p></a></li>
<li><a href='#ratedDataRules'><p>Scoring rules for the rated data</p></a></li>
<li><a href='#read_oplm_par'><p>Read item parameters from oplm PAR or CML files</p></a></li>
<li><a href='#standards_3dc'><p>Standard setting</p></a></li>
<li><a href='#standards_db'><p>Export a standard setting database for use by the free 3DC application</p></a></li>
<li><a href='#start_new_project'><p>Start a new project</p></a></li>
<li><a href='#start_new_project_from_oplm'><p>Start a new project from oplm files</p></a></li>
<li><a href='#tia_tables'><p>Simple test-item analysis</p></a></li>
<li><a href='#touch_rules'><p>Add or modify scoring rules</p></a></li>
<li><a href='#verbAggrData'><p>Verbal aggression data</p></a></li>
<li><a href='#verbAggrProperties'><p>Item properties in the verbal aggression data</p></a></li>
<li><a href='#verbAggrRules'><p>Scoring rules for the verbal aggression data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Management and Analysis of Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jesse Koops &lt;jesse.koops@cito.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A system for the management, assessment, and psychometric analysis of data from educational and psychological tests. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://dexter-psychometrics.github.io/dexter/">https://dexter-psychometrics.github.io/dexter/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/dexter-psychometrics/dexter/issues">https://github.com/dexter-psychometrics/dexter/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RSQLite (&ge; 2.2.7), DBI (&ge; 1.0.0), MASS (&ge; 7.3), tidyr (&ge;
1.2.0), rlang (&ge; 1.0.0), dplyr (&ge; 1.1.0), Rcpp (&ge; 1.0.1),
RcppArmadillo (&ge; 0.12.6.6.0), graphics, grDevices, methods,
utils</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo (&ge; 0.12.6.6.0), dqrng, BH, sitmo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, latticeExtra, testthat, ggplot2, Cairo</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-05 09:05:51 UTC; jessek</td>
</tr>
<tr>
<td>Author:</td>
<td>Gunter Maris [aut],
  Timo Bechger [aut],
  Jesse Koops [aut, cre],
  Ivailo Partchev [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-05 09:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dexter-package'>Dexter: data analyses for educational and psychological tests.</h2><span id='topic+dexter'></span><span id='topic+dexter-package'></span>

<h3>Description</h3>

<p>Dexter provides a comprehensive solution for managing and analyzing educational test data.
</p>


<h3>Details</h3>

<p>The main features are:
</p>

<ul>
<li><p> project databases providing a structure for storing data about persons, items, responses and booklets.
</p>
</li>
<li><p> methods to assess data quality using Classical test theory and plots.
</p>
</li>
<li><p> CML calibration of the extended nominal response model and interaction model.
</p>
</li></ul>

<p>To learn more about dexter, start with the vignettes: 'browseVignettes(package=&quot;dexter&quot;)'  
</p>
<p>Dexter uses the following global options
</p>

<ul>
<li><p> 'dexter.use_tibble' return tibbles instead of data.frames, defaults to FALSE
</p>
</li>
<li><p> 'dexter.progress' show progress bars, defaults to TRUE in interactive sessions
</p>
</li>
<li><p> 'dexter.max_cores' set a maximum number of cores that dexter will use, defaults to the minimum of 'Sys.getenv(&quot;OMP_THREAD_LIMIT&quot;)' and
'getOption(&quot;Ncpus&quot;)', otherwise unlimited.
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jesse Koops <a href="mailto:jesse.koops@cito.nl">jesse.koops@cito.nl</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Gunter Maris
</p>
</li>
<li><p> Timo Bechger
</p>
</li>
<li><p> Ivailo Partchev
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://dexter-psychometrics.github.io/dexter/">https://dexter-psychometrics.github.io/dexter/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/dexter-psychometrics/dexter/issues">https://github.com/dexter-psychometrics/dexter/issues</a>
</p>
</li></ul>


<hr>
<h2 id='ability'>Estimate abilities</h2><span id='topic+ability'></span><span id='topic+ability_tables'></span>

<h3>Description</h3>

<p>Computes estimates of ability for persons or for booklet scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ability(
  dataSrc,
  parms,
  predicate = NULL,
  method = c("MLE", "EAP", "WLE"),
  prior = c("normal", "Jeffreys"),
  parms_draw = "average",
  mu = 0,
  sigma = 4,
  merge_within_persons = FALSE
)

ability_tables(
  parms,
  design = NULL,
  method = c("MLE", "EAP", "WLE"),
  prior = c("normal", "Jeffreys"),
  parms_draw = "average",
  mu = 0,
  sigma = 4
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ability_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="ability_+3A_parms">parms</code></td>
<td>
<p>object produced by <code><a href="#topic+fit_enorm">fit_enorm</a></code> or a data.frame with columns item_id, item_score and, 
depending on parametrization, a column named either beta/delta, eta or b</p>
</td></tr>
<tr><td><code id="ability_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
<tr><td><code id="ability_+3A_method">method</code></td>
<td>
<p>Maximum Likelihood (MLE), Expected A posteriori (EAP) or Weighted Likelihood (WLE)</p>
</td></tr>
<tr><td><code id="ability_+3A_prior">prior</code></td>
<td>
<p>If an EAP estimate is produced one can choose a normal prior or
Jeffreys prior; i.e., a prior proportional to the square root of test information.</p>
</td></tr>
<tr><td><code id="ability_+3A_parms_draw">parms_draw</code></td>
<td>
<p>When parms is Bayesian, parms_draw can be the index of the posterior sample of the item 
parameters that will be used for generating abilities. If parms_draw='average', the posterior mean is used.</p>
</td></tr>
<tr><td><code id="ability_+3A_mu">mu</code></td>
<td>
<p>Mean of the normal prior</p>
</td></tr>
<tr><td><code id="ability_+3A_sigma">sigma</code></td>
<td>
<p>Standard deviation of the normal prior</p>
</td></tr>
<tr><td><code id="ability_+3A_merge_within_persons">merge_within_persons</code></td>
<td>
<p>for persons who were administered multiple booklets, 
whether to provide just one ability value (TRUE) or one per booklet(FALSE)</p>
</td></tr>
<tr><td><code id="ability_+3A_design">design</code></td>
<td>
<p>A data.frame with columns item_id and optionally booklet_id. If the column booklet_id is not included, the score 
transformation table will be based on all items found in the design. If design is NULL
and parms is an enorm fit object the score transformation table will be computed based on the test design 
that was used to fit the items.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MLE estimates of ability will produce -Inf and Inf estimates for
the minimum (=0) and the maximum score on a booklet. If this is undesirable, 
we advise to use WLE. The WLE was proposed by Warm (1989) to reduce bias in the MLE and is also known
as the Warm estimator.
</p>


<h3>Value</h3>


<dl>
<dt>ability</dt><dd><p>a data.frame with columns: booklet_id, person_id, booklet_score, theta and optionally se (standard error) </p>
</dd>
<dt>ability_tables</dt><dd><p>a data.frame with columns: booklet_id, booklet_score, theta and optionally se (standard error)</p>
</dd>
</dl>



<h3>References</h3>

<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. 
Psychometrika, 54(3), 427-450.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules, ":memory:")
add_booklet(db, verbAggrData, "agg")

f = fit_enorm(db)

mle = ability_tables(f, method="MLE")
eap = ability_tables(f, method="EAP", mu=0, sigma=1)
wle = ability_tables(f, method="WLE")

plot(wle$booklet_score, wle$theta, xlab="test-score", ylab="ability est.", pch=19)
points(mle$booklet_score, mle$theta, col="red", pch=19,)
points(eap$booklet_score, eap$theta, col="blue", pch=19)
legend("topleft", legend = c("WLE", "MLE", "EAP N(0,1)"), 
        col = c("black", "red", "blue"), bty = "n",pch = 19)

close_project(db)



</code></pre>

<hr>
<h2 id='add_booklet'>Add response data to a project</h2><span id='topic+add_booklet'></span><span id='topic+add_response_data'></span>

<h3>Description</h3>

<p>Add item response data in long or wide format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_booklet(db, x, booklet_id, auto_add_unknown_rules = FALSE)

add_response_data(
  db,
  data,
  design = NULL,
  missing_value = "NA",
  auto_add_unknown_rules = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_booklet_+3A_db">db</code></td>
<td>
<p>a connection to a dexter database, i.e. the output of <code>start_new_project</code>
or <code>open_project</code></p>
</td></tr>
<tr><td><code id="add_booklet_+3A_x">x</code></td>
<td>
<p>A data frame containing the responses and, optionally,
person_properties. The data.frame should have one row per respondent and the column names should 
correspond to the item_id's in the rules or the names of the person_properties. See details.</p>
</td></tr>
<tr><td><code id="add_booklet_+3A_booklet_id">booklet_id</code></td>
<td>
<p>A (short) string identifying the test form (booklet)</p>
</td></tr>
<tr><td><code id="add_booklet_+3A_auto_add_unknown_rules">auto_add_unknown_rules</code></td>
<td>
<p>If FALSE (the default), an error will be generated if 
one or more responses do not appear in the scoring rules. If TRUE, unknown responses will be
assumed to have a score of 0 and will be added to your scoring rules</p>
</td></tr>
<tr><td><code id="add_booklet_+3A_data">data</code></td>
<td>
<p>response data in normalized (long) format. Must contain columns <code>person_id</code>, <code>booklet_id</code>,
<code>item_id</code> and <code>response</code> and optionally <code>item_position</code> 
(useful if your data contains new booklets, see details)</p>
</td></tr>
<tr><td><code id="add_booklet_+3A_design">design</code></td>
<td>
<p>data.frame with columns booklet_id, item_id and optionally item_position specifying the design of any 
_new_ booklets in your data.</p>
</td></tr>
<tr><td><code id="add_booklet_+3A_missing_value">missing_value</code></td>
<td>
<p>value to use for responses in missing rows in your data, see details</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is a common practice to keep response data in tables where each row 
contains the responses from a single person. <code>add_booklet</code> is provided to input
data in that form, one booklet at a time. 
</p>
<p>If the dataframe <code>x</code> contains a variable named <code>person_id</code> this variable 
will be used to identify unique persons. It is assumed that a single person will only 
make a single booklet once, otherwise an error will be generated. 
</p>
<p>If a person_id is not supplied, dexter will generate unique person_id's for each row of data.  
</p>
<p>Any column whose name has an exact match in the scoring rules inputted with
function <code>start_new_project</code> will be treated as an item; any column whose name has an 
exact match in the person_properties will be treated as a person property. If a name matches both
a person_property and an item_id, the item takes precedence. Columns other than items, person properties 
and person_id will be ignored.
</p>
<p><code>add_response_data</code> can be used to add data that is already normalized. This function takes a 
data.frame in long format with columns <code>person_id</code>, <code>booklet_id</code>, 
<code>item_id</code> and <code>response</code> such as can usually be found in databases for example. 
For booklets that are not already known in your project, you need to specify the design via the <code>design</code> argument.
Failure to do so will result in an error. Responses to items that should be there according to the design but which do not have a corresponding
row in <code>data</code> will be added with <code>missing_value</code> used for the response. If this missing value is not defined in your scoring rules 
and <code>auto_add_unknown_rules</code> is set to FALSE, this will lead to an error message.
</p>
<p>Note that responses are always treated as strings (in both functions), and <code>NA</code>
values are transformed to the string <code>"NA"</code>.
</p>


<h3>Value</h3>

<p>A list with information about the recent import.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>db = start_new_project(verbAggrRules, ":memory:", 
                       person_properties=list(gender="unknown"))
head(verbAggrData)
add_booklet(db, verbAggrData, "agg")      

close_project(db)

</code></pre>

<hr>
<h2 id='add_item_properties'>Add item properties to a project</h2><span id='topic+add_item_properties'></span>

<h3>Description</h3>

<p>Add, change or define item properties in a dexter project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_item_properties(db, item_properties = NULL, default_values = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_item_properties_+3A_db">db</code></td>
<td>
<p>a connection to a dexter database, e.g. the output of <code>start_new_project</code>
or <code>open_project</code></p>
</td></tr>
<tr><td><code id="add_item_properties_+3A_item_properties">item_properties</code></td>
<td>
<p>A data frame containing a column item_id (matching item_id's already defined in the project)
and 1 or more other columns with item properties (e.g. item_type, subject)</p>
</td></tr>
<tr><td><code id="add_item_properties_+3A_default_values">default_values</code></td>
<td>
<p>a list where the names are item_properties and the values are defaults.
The defaults will be used wherever the item property is unknown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When entering response data in the form of a rectangular person x item
table, it is easy to provide person properties but practically impossible
to provide item properties. This function provides a possibility to do so.
</p>
<p>Note that is is not possible to add new items with this function, 
use <code><a href="#topic+touch_rules">touch_rules</a></code> if you want to add new items to your project.
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_domains">fit_domains</a></code>, <code><a href="#topic+profile_plot">profile_plot</a></code> for
possible uses of item_properties
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: \donttest{
db = start_new_project(verbAggrRules, "verbAggression.db")
head(verbAggrProperties)
add_item_properties(db, verbAggrProperties)
get_items(db) 

close_project(db)
}
## End(Not run)

</code></pre>

<hr>
<h2 id='add_person_properties'>Add person properties to a project</h2><span id='topic+add_person_properties'></span>

<h3>Description</h3>

<p>Add, change or define person properties in a dexter project. Person properties defined here will 
also be automatically imported with <code><a href="#topic+add_booklet">add_booklet</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_person_properties(db, person_properties = NULL, default_values = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_person_properties_+3A_db">db</code></td>
<td>
<p>a connection to a dexter database, e.g. the output of <code>start_new_project</code>
or <code>open_project</code></p>
</td></tr>
<tr><td><code id="add_person_properties_+3A_person_properties">person_properties</code></td>
<td>
<p>A data frame containing a column person_id and 1 or more other columns with 
person properties (e.g. education_type, birthdate)</p>
</td></tr>
<tr><td><code id="add_person_properties_+3A_default_values">default_values</code></td>
<td>
<p>a list where the names are person_properties and the values are defaults.
The defaults will be used wherever the person property is unknown.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to limitations in the sqlite database backend that we use, the default values for a person property 
can only be defined once for each person_property
</p>


<h3>Value</h3>

<p>nothing
</p>

<hr>
<h2 id='close_project'>Close a project</h2><span id='topic+close_project'></span>

<h3>Description</h3>

<p>This is just an alias for <code>DBI::dbDisconnect(db)</code>, included for completeness
</p>


<h3>Usage</h3>

<pre><code class='language-R'>close_project(db)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="close_project_+3A_db">db</code></td>
<td>
<p>connection to a dexter database</p>
</td></tr>
</table>

<hr>
<h2 id='coef.p2pass'>extract equating information</h2><span id='topic+coef.p2pass'></span>

<h3>Description</h3>

<p>extract equating information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'p2pass'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.p2pass_+3A_object">object</code></td>
<td>
<p>an p2pass object, generated by <code><a href="#topic+probability_to_pass">probability_to_pass</a></code></p>
</td></tr>
<tr><td><code id="coef.p2pass_+3A_...">...</code></td>
<td>
<p>further arguments are currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with columns:
</p>

<dl>
<dt>booklet_id</dt><dd><p>id of the target booklet</p>
</dd>
<dt>score_new</dt><dd><p>score on the target booklet</p>
</dd>
<dt>probability_to_pass</dt><dd><p>probability to pass on the reference test given score_new</p>
</dd>
<dt>true_positive</dt><dd><p>proportion that correctly passes</p>
</dd>
<dt>sensitivity</dt><dd><p>The proportion of positives that are correctly identified as such</p>
</dd>
<dt>specificity</dt><dd><p>The proportion of negatives that are correctly identified as such</p>
</dd>
<dt>proportion</dt><dd><p>proportion in sample with score_new</p>
</dd></dl>


<hr>
<h2 id='coef.prms'>extract enorm item parameters</h2><span id='topic+coef.prms'></span>

<h3>Description</h3>

<p>extract enorm item parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'prms'
coef(object, hpd = 0.95, what = c("items", "var", "posterior"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.prms_+3A_object">object</code></td>
<td>
<p>an enorm parameters object, generated by the function <code><a href="#topic+fit_enorm">fit_enorm</a></code></p>
</td></tr>
<tr><td><code id="coef.prms_+3A_hpd">hpd</code></td>
<td>
<p>width of Bayesian highest posterior density interval around mean_beta, 
value must be between 0 and 1, default is 0.95</p>
</td></tr>
<tr><td><code id="coef.prms_+3A_what">what</code></td>
<td>
<p>which coefficients to return. Defaults to <code>items</code> (the item parameters). Can also be <code>var</code> for the 
variance-covariance matrix (CML only) or <code>posterior</code> for all draws of the item parameters (Bayes only)</p>
</td></tr>
<tr><td><code id="coef.prms_+3A_...">...</code></td>
<td>
<p>further arguments to coef are ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parametrisation of IRT models is far from uniform and depends on the author. Dexter uses the following parametrisation for the 
extended Nominal Response Model (NRM):
</p>
<p style="text-align: center;"><code class="reqn">
P(X=a_j|\beta,\theta) = \frac{\exp\left(a_j\theta-\sum_{g=1}^{j}\beta_g(a_g-a_{g-1})\right)}{1+\sum_h \exp\left(a_h\theta-\sum_{g=1}^{h}\beta_g(a_g-a_{g-1})\right)}
</code>
</p>
 
<p>where <code class="reqn">a_j</code> is a shorthand for the integer score belonging to the j-th category of an item. 
</p>
<p>For dichotomous items with <code class="reqn">a_1=1</code> (i.e. the only possible scores are 0 and 1)
this formula simplifies to the standard Rasch model: <code class="reqn">P(x=1|\beta,\theta)=\frac{\exp(\theta-\beta)}{1+\exp(\theta-\beta)}</code>. For polytomous items, 
when all scores are equal to the categories (i.e. <code class="reqn">a_j=j</code> for all <code class="reqn">j</code>) 
the NRM is equal to the Partial Credit Model, although with a different parametrisation than is commonly used. 
For dichotomous items and for all polytomous items where <code class="reqn">a_j-a_{j-1}</code> is constant, the formulation is equal to the OPLM.
</p>


<h3>Value</h3>

<p>Depends on the calibration method and the value of 'what'. For <code>what="items"</code>: 
</p>

<dl>
<dt>CML calibration</dt><dd><p>a data.frame with columns: item_id, item_score, beta, SE_beta</p>
</dd>
<dt>Bayesian calibration</dt><dd><p>a data.frame with columns: item_id, item_score, mean_beta, SD_beta, &lt;hpd_b_left&gt;, &lt;hpd_b_right&gt;</p>
</dd>
</dl>

<p>If <code>what="var"</code> or <code>what="posterior"</code> then  a matrix is returned with the variance-covariance matrix or the posterior draws 
respectively.
</p>

<hr>
<h2 id='design_info'>Information about the design</h2><span id='topic+design_info'></span>

<h3>Description</h3>

<p>This function is useful to inspect incomplete designs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>design_info(dataSrc, predicate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="design_info_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="design_info_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following components
</p>

<dl>
<dt>design</dt><dd><p>a data.frame with columns booklet_id, item_id, item_position, n_persons</p>
</dd> 
<dt>connected_booklets</dt><dd><p>a data.frame with columns booklet_id, group; 
booklets with the same 'group' are connected to each other.</p>
</dd> 
<dt>connected</dt><dd><p>TRUE/FALSE indicating whether the design is connected or not</p>
</dd> 
<dt>testlets</dt><dd><p>a data.frame with columns item_id and testlet; items within the same testlet 
always occur together in a booklet</p>
</dd> 
<dt>adj_matrix</dt><dd><p>list of two adjacency matrices: *weighted_by_items* and *weighted_by_persons*; These matrices can be 
useful in visually inspecting the design using a package like *igraph*</p>
</dd>
</dl>


<hr>
<h2 id='DIF'>Exploratory test for Differential Item Functioning</h2><span id='topic+DIF'></span>

<h3>Description</h3>

<p>Exploratory test for Differential Item Functioning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DIF(dataSrc, person_property, predicate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DIF_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="DIF_+3A_person_property">person_property</code></td>
<td>
<p>Defines groups of persons to calculate DIF</p>
</td></tr>
<tr><td><code id="DIF_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tests for equality of relative item/category difficulties across groups.
Supplements the confirmatory approach of the profile plot.
</p>


<h3>Value</h3>

<p>An object of class <code>DIF_stats</code> holding statistics for
overall-DIF and a matrix of statistics for DIF in the relative position of
item-category parameters in the beta-parameterization where they represent 
locations on the ability scale where adjacent categories are equally likely. 
If there is DIF, the function 'plot' can be used to produce an image of the pairwise DIF statistics.
</p>


<h3>References</h3>

<p>Bechger, T. M. and Maris, G (2015); A Statistical Test for Differential Item Pair Functioning. 
Psychometrika. Vol. 80, no. 2, 317-340.
</p>


<h3>See Also</h3>

<p>A plot of the result is produced by the function <code><a href="#topic+plot.DIF_stats">plot.DIF_stats</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules, ":memory:", person_properties=list(gender='unknown'))
add_booklet(db, verbAggrData, "agg")
dd = DIF(db,person_property="gender")
print(dd)
plot(dd)
str(dd)

close_project(db)



</code></pre>

<hr>
<h2 id='distractor_plot'>Distractor plot</h2><span id='topic+distractor_plot'></span>

<h3>Description</h3>

<p>Produce a diagnostic distractor plot for an item
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distractor_plot(
  dataSrc,
  item_id,
  predicate = NULL,
  legend = TRUE,
  curtains = 10,
  adjust = 1,
  col = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distractor_plot_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database or a data.frame with columns: person_id, item_id, response, item_score
and optionally booklet_id</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_item_id">item_id</code></td>
<td>
<p>The ID of the item to plot. A separate plot will be produced
for each booklet that contains the item, or an error message if the item_id
is not known. Each plot contains a non-parametric regression of each possible
response on the total score.</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_legend">legend</code></td>
<td>
<p>logical, whether to include the legend. default is TRUE</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_curtains">curtains</code></td>
<td>
<p>100*the tail probability of the sum scores to be shaded. Default is 10.
Set to 0 to have no curtains shown at all.</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_adjust">adjust</code></td>
<td>
<p>factor to adjust the smoothing bandwidth respective to the default value</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_col">col</code></td>
<td>
<p>vector of colors to use for plotting. The names of the vector can be responses. If the vector is not named, 
colors are assigned to the most frequent responses first.</p>
</td></tr>
<tr><td><code id="distractor_plot_+3A_...">...</code></td>
<td>
<p>further arguments to plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Customization of title and subtitle can be done by using the arguments main and sub. 
These arguments can contain references to the variables item_id, booklet_id, item_position(if available),
pvalue, rit and rir. References are made by prefixing these variables with a dollar sign. Variable names may be postfixed 
with a sprintf style format string, e.g. 
<code>distractor_plot(db, main='item: $item_id', sub='Item rest correlation: $rir:.2f')</code>
</p>


<h3>Value</h3>

<p>Silently, a data.frame of response categories and colors used. Potentially useful if you want to customize the legend or 
print it separately
</p>

<hr>
<h2 id='fit_domains'>Estimate the Rasch and the Interaction model per domain</h2><span id='topic+fit_domains'></span>

<h3>Description</h3>

<p>Estimate the parameters of the Rasch model and the Interaction model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_domains(dataSrc, item_property, predicate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_domains_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="fit_domains_+3A_item_property">item_property</code></td>
<td>
<p>The item property defining the
domains (subtests)</p>
</td></tr>
<tr><td><code id="fit_domains_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We have generalised the interaction model for items having more than two (potentially, a largish number) 
of response categories. This function represents scores on subtests as 
super-items and analyses these as normal items.
</p>


<h3>Value</h3>

<p>An object of class <code>imp</code> holding results
for the Rasch model and the interaction model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.rim">plot.rim</a></code>, <code><a href="#topic+fit_inter">fit_inter</a></code>, <code><a href="#topic+add_item_properties">add_item_properties</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules, ":memory:")
add_booklet(db, verbAggrData, "agg")
add_item_properties(db, verbAggrProperties)
mSit = fit_domains(db, item_property= "situation")
plot(mSit)

close_project(db)



</code></pre>

<hr>
<h2 id='fit_enorm'>Fit the extended nominal response model</h2><span id='topic+fit_enorm'></span>

<h3>Description</h3>

<p>Fits an Extended NOminal Response Model (ENORM) using conditional maximum likelihood (CML)
or a Gibbs sampler for Bayesian estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_enorm(
  dataSrc,
  predicate = NULL,
  fixed_params = NULL,
  method = c("CML", "Bayes"),
  nDraws = 1000,
  merge_within_persons = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_enorm_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="fit_enorm_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
<tr><td><code id="fit_enorm_+3A_fixed_params">fixed_params</code></td>
<td>
<p>Optionally, a prms object from a previous analysis or 
a data.frame with parameters, see details.</p>
</td></tr>
<tr><td><code id="fit_enorm_+3A_method">method</code></td>
<td>
<p>If CML, the estimation method will be Conditional Maximum Likelihood;
otherwise, a Gibbs sampler will be used to produce a sample from the posterior</p>
</td></tr>
<tr><td><code id="fit_enorm_+3A_ndraws">nDraws</code></td>
<td>
<p>Number of Gibbs samples when estimation method is Bayes.</p>
</td></tr>
<tr><td><code id="fit_enorm_+3A_merge_within_persons">merge_within_persons</code></td>
<td>
<p>whether to merge different booklets administered to the same person, enabling linking over persons as well as booklets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To support some flexibility in fixing parameters, fixed_params can be a dexter prms object or a data.frame.
If a data.frame, it should contain the columns item_id, item_score and a difficulty parameter. Three types of parameters are supported:
</p>

<dl>
<dt>delta/beta</dt><dd><p> thresholds between subsequent item categories </p>
</dd>
<dt>eta</dt><dd><p>item-category parameters</p>
</dd> 
<dt>b</dt><dd><p>exp(-eta)</p>
</dd>
</dl>

<p>Each type corresponds to a different parametrization of the model.
</p>


<h3>Value</h3>

<p>An object of type <code>prms</code>. The prms object can be cast to a data.frame of item parameters 
using function <code>coef</code> or used directly as input for other Dexter functions.
</p>


<h3>References</h3>

<p>Maris, G., Bechger, T.M. and San-Martin, E. (2015) A Gibbs sampler for the (extended) marginal Rasch model. 
Psychometrika. 80(4), 859-879. 
</p>
<p>Koops, J. and Bechger, T.M. and Maris, G. (in press); Bayesian inference for multistage and other 
incomplete designs. In Research for Practical Issues and Solutions in Computerized Multistage Testing.
Routledge, London.
</p>


<h3>See Also</h3>

<p>functions that accept a prms object as input: <code><a href="#topic+ability">ability</a></code>, <code><a href="#topic+plausible_values">plausible_values</a></code>, 
<code><a href="#topic+plot.prms">plot.prms</a></code>, and <code><a href="#topic+plausible_scores">plausible_scores</a></code>
</p>

<hr>
<h2 id='fit_inter'>Estimate the Interaction and the Rasch model</h2><span id='topic+fit_inter'></span>

<h3>Description</h3>

<p>Estimate the parameters of the Interaction model and the Rasch model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_inter(dataSrc, predicate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_inter_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="fit_inter_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike the Rasch model, the interaction model cannot be computed
concurrently for a whole design of test forms. This function therefore fits the
Rasch model and the interaction model on complete data. 
This typically consist of responses to items in one booklet but can also consist of
the intersection (common items) in two or more booklets. If the intersection is empty
(no common items for all persons), the function will exit with an error message.
</p>


<h3>Value</h3>

<p>An object of class <code>rim</code> holding results
for the Rasch model and the interaction model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.rim">plot.rim</a></code>, <code><a href="#topic+fit_domains">fit_domains</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules, ":memory:")
add_booklet(db, verbAggrData, "agg")

m = fit_inter(db, booklet_id=='agg')
plot(m, "S1DoScold", show.observed=TRUE)

close_project(db)



</code></pre>

<hr>
<h2 id='get_booklets'>Booklets entered in a project</h2><span id='topic+get_booklets'></span>

<h3>Description</h3>

<p>Retrieve information about the booklets entered in the db so far
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_booklets(db)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_booklets_+3A_db">db</code></td>
<td>
<p>a connection to a dexter database, i.e. the output of <code>start_new_project</code>
or <code>open_project</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with columns: booklet_id, n_persons, n_items and booklet_max_score. 
booklet_max_score gives the maximum theoretically possible score according to the scoring rules
</p>

<hr>
<h2 id='get_design'>Test design</h2><span id='topic+get_design'></span>

<h3>Description</h3>

<p>Retrieve all items that have been entered in the db
so far by booklet and position in the booklet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_design(
  dataSrc,
  format = c("long", "wide"),
  rows = c("booklet_id", "item_id", "item_position"),
  columns = c("item_id", "booklet_id", "item_position"),
  fill = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_design_+3A_datasrc">dataSrc</code></td>
<td>
<p>a dexter database or any object form which a design can be inferred</p>
</td></tr>
<tr><td><code id="get_design_+3A_format">format</code></td>
<td>
<p>return format, see below</p>
</td></tr>
<tr><td><code id="get_design_+3A_rows">rows</code></td>
<td>
<p>variable that defines the rows, ignored if format='long'</p>
</td></tr>
<tr><td><code id="get_design_+3A_columns">columns</code></td>
<td>
<p>variable that defines the columns, ignored if format='long'</p>
</td></tr>
<tr><td><code id="get_design_+3A_fill">fill</code></td>
<td>
<p>If set, missing values will be replaced with this value, ignored if format='long'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the design. The contents depend on the rows, columns and format parameters
if <code>format</code> is <code>'long'</code> a data.frame with columns: booklet_id, item_id, item_position (if available)
if <code>format</code> is <code>'wide'</code> a data.frame with the rows defined by the <code>rows</code> parameter and 
the columns by the <code>columns</code> parameter, with the remaining variable (i.e. item_id, booklet_id or item_position)
making up the cells
</p>

<hr>
<h2 id='get_items'>Items in a project</h2><span id='topic+get_items'></span>

<h3>Description</h3>

<p>Retrieve all items that have been entered in the db
so far together with the item properties
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_items(db)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_items_+3A_db">db</code></td>
<td>
<p>a connection to a dexter database, e.g. the output of <code>start_new_project</code>
or <code>open_project</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with column item_id and a column for each item property
</p>

<hr>
<h2 id='get_persons'>Persons in a project</h2><span id='topic+get_persons'></span>

<h3>Description</h3>

<p>Retrieve all persons/respondents that have been entered in the db
so far together with their properties
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_persons(db)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_persons_+3A_db">db</code></td>
<td>
<p>a connection to a dexter database, e.g. the output of <code>start_new_project</code>
or <code>open_project</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with columns person_id and columns for each person_property
</p>

<hr>
<h2 id='get_resp_data'>Functions for developers</h2><span id='topic+get_resp_data'></span><span id='topic+get_resp_matrix'></span>

<h3>Description</h3>

<p>These functions are meant for people who want to develop their own models based
on the data management structure of dexter. The benefit is some extra speed and less memory usage 
compared to using <code>get_responses</code> or <code>get_testscores</code>.
The return value of get_resp_data can be used as the 'dataSrc' argument in analysis functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_resp_data(
  dataSrc,
  qtpredicate = NULL,
  extra_columns = NULL,
  summarised = FALSE,
  env = NULL,
  protect_x = TRUE,
  retain_person_id = TRUE,
  merge_within_persons = FALSE,
  parms_check = NULL,
  raw = FALSE
)

get_resp_matrix(dataSrc, qtpredicate = NULL, env = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_resp_data_+3A_datasrc">dataSrc</code></td>
<td>
<p>data.frame, integer matrix, dexter database or 'dx_resp_data' object</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_qtpredicate">qtpredicate</code></td>
<td>
<p>quoted predicate, e.g. <code>quote(booklet_id=='bk01')</code></p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_extra_columns">extra_columns</code></td>
<td>
<p>to be returned in addition to person_id, booklet_id, item_score, item_id</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_summarised">summarised</code></td>
<td>
<p>if TRUE, no item scores are returned, just booklet scores</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_env">env</code></td>
<td>
<p>environment for evaluation of qtpredicate, defaults to caller environment</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_protect_x">protect_x</code></td>
<td>
<p>best set TRUE (default)</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_retain_person_id">retain_person_id</code></td>
<td>
<p>whether to retain the original person_id levels or just use arbitrary integers</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_merge_within_persons">merge_within_persons</code></td>
<td>
<p>merge different booklets for the same person together</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_parms_check">parms_check</code></td>
<td>
<p>data.frame of item_id, item_score to check for coverage of data</p>
</td></tr>
<tr><td><code id="get_resp_data_+3A_raw">raw</code></td>
<td>
<p>if raw is TRUE, no sum scores, booklets, or design is provided and arguments, 'parms_check' and 'summarised' are ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regular users are advised not to use these functions 
as incorrect use can crash your R-session or lead to unexpected results.
</p>


<h3>Value</h3>


<dl>
<dt>get_resp_data</dt><dd><p> returns a list with class 'dx_resp_data' with elements
</p>

<dl>
<dt>x</dt><dd>
<p>when summarised is FALSE, a tibble(person_id, booklet_id, item_id, item_score, booklet_score [, extra_columns]), sorted in such a way that
all rows pertaining to the same person-booklet are together
</p>
<p>when summarised is TRUE, a tibble(person_id, booklet_id, booklet_score [, extra_columns])</p>
</dd>
<dt>design</dt><dd>
<p>tibble(booklet_id, item_id), sorted
</p>
</dd></dl>
</dd>
<dt>get_resp_matrix</dt><dd><p>returns a matrix of item scores as commonly used in other IRT packages, facilitating
easy connection of your own package to the data management capabilities of dexter</p>
</dd>
</dl>


<hr>
<h2 id='get_responses'>Selecting data</h2><span id='topic+get_responses'></span>

<h3>Description</h3>

<p>Extract data from a dexter database
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_responses(
  dataSrc,
  predicate = NULL,
  columns = c("person_id", "item_id", "item_score")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_responses_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="get_responses_+3A_predicate">predicate</code></td>
<td>
<p>an expression to select data on</p>
</td></tr>
<tr><td><code id="get_responses_+3A_columns">columns</code></td>
<td>
<p>the columns you wish to select, can include any column in the project, see: <code><a href="#topic+get_variables">get_variables</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many functions in Dexter accept a data source and a predicate. Predicates are extremely flexible 
but they have a few limitations because they work on the individual response level. It is therefore not possible
for example, to remove complete person cases from an analysis based on responses to a single item 
by using just a predicate expression.
</p>
<p>For such cases, Dexter supports selecting the data and manipulating it before passing it back to a Dexter function 
or possibly doing something else with it. The following example will hopefully clarify this.
</p>


<h3>Value</h3>

<p>a data.frame of responses
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# goal: fit the extended nominal response model using only persons 
# without any missing responses
library(dplyr)

# the following would not work since it will omit only the missing 
# responses, not the persons; which is not what we want in this case
wrong = fit_enorm(db, response != 'NA')

# to select on an aggregate level, we need to gather the data and 
# manipulate it ourselves
data = get_responses(db, 
   columns=c('person_id','item_id','item_score','response')) |&gt;
   group_by(person_id) |&gt;
   mutate(any_missing = any(response=='NA')) |&gt;
   filter(!any_missing)

correct = fit_enorm(data)


## End(Not run)
</code></pre>

<hr>
<h2 id='get_rules'>Get scoring rules</h2><span id='topic+get_rules'></span>

<h3>Description</h3>

<p>Retrieve the scoring rules currently present in the dexter project db
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_rules(db)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_rules_+3A_db">db</code></td>
<td>
<p>a connection to a Dexter database</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame of scoring rules containing columns: item_id, response, item_score
</p>

<hr>
<h2 id='get_testscores'>Get test scores</h2><span id='topic+get_testscores'></span>

<h3>Description</h3>

<p>Supplies the sum of item scores for each person selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_testscores(dataSrc, predicate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_testscores_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="get_testscores_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to filter data, if NULL all data is used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with columns person_id, item_id, booklet_score
</p>

<hr>
<h2 id='get_variables'>Variables that are defined in the project</h2><span id='topic+get_variables'></span>

<h3>Description</h3>

<p>Inspect the variables defined in your dexter project and their datatypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_variables(db)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_variables_+3A_db">db</code></td>
<td>
<p>a dexter project database</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variables in Dexter consist of the item properties and person properties you specified
and a number of reserved variables that are automatically defined like <code>response</code> and <code>booklet_id</code>.
</p>
<p>Variables in Dexter are most useful when used in predicate expressions. A number of functions can 
take a dataSrc argument and an optional predicate. Predicates are 
a concise and flexible way to filter data for the different psychometric functions in Dexter.
</p>
<p>The variables can also be used to retrieve data in <code><a href="#topic+get_responses">get_responses</a></code>
</p>


<h3>Value</h3>

<p>a data.frame with name and type of the variables defined in your dexter project
</p>

<hr>
<h2 id='individual_differences'>Test individual differences</h2><span id='topic+individual_differences'></span>

<h3>Description</h3>

<p>Test individual differences
</p>


<h3>Usage</h3>

<pre><code class='language-R'>individual_differences(dataSrc, predicate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="individual_differences_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="individual_differences_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses a score distribution to test whether there are individual 
differences in ability. First, it estimates ability based on the score distribution. Then, 
the observed distribution is compared to the one expected from the single estimated ability.
The data are typically from one booklet but can also consist of 
the intersection (i.e., the common items) of two or more booklets. If the intersection is empty
(i.e., no common items for all persons), the function will exit with an error message.
</p>


<h3>Value</h3>

<p>An object of type tind. Printing the object will show test results. 
Plotting it will produce a plot of expected and observed score frequencies. 
The former under the hypothesis that there are no individual differences.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

db = start_new_project(verbAggrRules, ":memory:")
add_booklet(db, verbAggrData, "agg")

dd = individual_differences(db)
print(dd)
plot(dd)

close_project(db)



</code></pre>

<hr>
<h2 id='information'>Functions of theta</h2><span id='topic+information'></span><span id='topic+expected_score'></span><span id='topic+r_score'></span><span id='topic+p_score'></span>

<h3>Description</h3>

<p>returns information function, expected score function, score simulation function, or score distribution 
for a single item, an arbitrary group of items or all items
</p>


<h3>Usage</h3>

<pre><code class='language-R'>information(
  parms,
  items = NULL,
  booklet_id = NULL,
  parms_draw = c("average", "sample")
)

expected_score(
  parms,
  items = NULL,
  booklet_id = NULL,
  parms_draw = c("average", "sample")
)

r_score(
  parms,
  items = NULL,
  booklet_id = NULL,
  parms_draw = c("average", "sample")
)

p_score(
  parms,
  items = NULL,
  booklet_id = NULL,
  parms_draw = c("average", "sample")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="information_+3A_parms">parms</code></td>
<td>
<p>object produced by <code><a href="#topic+fit_enorm">fit_enorm</a></code> or a data.frame with columns item_id, item_score and, 
depending on parametrization, a column named either beta/delta, eta or b</p>
</td></tr>
<tr><td><code id="information_+3A_items">items</code></td>
<td>
<p>vector of one or more item_id's. If NULL and booklet_id is also NULL, all items in parms are used</p>
</td></tr>
<tr><td><code id="information_+3A_booklet_id">booklet_id</code></td>
<td>
<p>id of a single booklet (e.g. the test information function), if items is not NULL this is ignored</p>
</td></tr>
<tr><td><code id="information_+3A_parms_draw">parms_draw</code></td>
<td>
<p>when the item parameters are estimated with method &quot;Bayes&quot; (see: <code><a href="#topic+fit_enorm">fit_enorm</a></code>), 
parms_draw specifies whether to use a sample (a different item parameter draw for each output column) or the posterior mean
of the item draws. Alternatively, it can be an integer specifying a specific draw. It is ignored when parms is not estimated Bayesianly.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Each function returns a new function which accepts a vector of theta's. These return the following values: 
</p>

<dl>
<dt>information</dt><dd><p>an equal length vector with the information estimate at each value of theta.</p>
</dd>
<dt>expected_score</dt><dd><p>an equal length vector with the expected score at each value of theta</p>
</dd>
<dt>r_score</dt><dd><p>a matrix with length(theta) rows and one column for each item containing simulated scores based on theta. 
To obtain test scores, use rowSums on this matrix</p>
</dd>
<dt>p_score</dt><dd><p>a matrix with length(theta) rows and one column for each possible sumscore containing the probability of 
the score given theta</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules,':memory:')
add_booklet(db,verbAggrData, "agg")
p = fit_enorm(db)

# plot information function for single item

ifun = information(p, "S1DoScold")

plot(ifun,from=-4,to=4)

# compare test information function to the population ability distribution

ifun = information(p, booklet="agg")

pv = plausible_values(db,p)

op = par(no.readonly=TRUE)
par(mar = c(5,4,2,4))

plot(ifun,from=-4,to=4, xlab='theta', ylab='test information')

par(new=TRUE)

plot(density(pv$PV1), col='green', axes=FALSE, xlab=NA, ylab=NA, main=NA)
axis(side=4)
mtext(side = 4, line = 2.5, 'population density (green)')

par(op)
close_project(db)



</code></pre>

<hr>
<h2 id='keys_to_rules'>Derive scoring rules from keys</h2><span id='topic+keys_to_rules'></span>

<h3>Description</h3>

<p>For multiple choice items that will be scored as 0/1, derive the
scoring rules from the keys to the correct responses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keys_to_rules(keys, include_NA_rule = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="keys_to_rules_+3A_keys">keys</code></td>
<td>
<p>A data frame containing columns <code>item_id</code>, <code>noptions</code>, and
<code>key</code> See details.</p>
</td></tr>
<tr><td><code id="keys_to_rules_+3A_include_na_rule">include_NA_rule</code></td>
<td>
<p>whether to add an option 'NA' (which is scored 0) to each item</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function might be useful in setting up the scoring rules when all items
are multiple-choice and scored as 0/1. 
</p>
<p>The input data frame must contain the exact id of each item, the number
of options, and the key. If the keys are all integers, it will be assumed that
responses are coded as 1 through noptions. If they are all  letters,
it is assumed that responses are coded as A,B,C,... All other cases result
in an error.
</p>


<h3>Value</h3>

<p>A data frame that can be used as input to <code>start_new_project</code>
</p>

<hr>
<h2 id='latent_cor'>Latent correlations</h2><span id='topic+latent_cor'></span>

<h3>Description</h3>

<p>Estimates correlations between latent traits using plausible values as described in Marsman, et al. (2022). 
An item_property is used to distinguish the different scales.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>latent_cor(
  dataSrc,
  item_property,
  predicate = NULL,
  nDraws = 500,
  hpd = 0.95,
  use = "complete.obs"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="latent_cor_+3A_datasrc">dataSrc</code></td>
<td>
<p>A connection to a dexter database or a data.frame with columns: person_id, item_id, item_score and 
the item_property</p>
</td></tr>
<tr><td><code id="latent_cor_+3A_item_property">item_property</code></td>
<td>
<p>The name of the item property used to define the domains. If <code>dataSrc</code> is a dexter db then the
item_property must match a known item property. If datasrc is a data.frame, item_property must be equal to
one of its column names.</p>
</td></tr>
<tr><td><code id="latent_cor_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
<tr><td><code id="latent_cor_+3A_ndraws">nDraws</code></td>
<td>
<p>Number of draws for plausible values</p>
</td></tr>
<tr><td><code id="latent_cor_+3A_hpd">hpd</code></td>
<td>
<p>width of Bayesian highest posterior density interval around the correlations, 
value must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="latent_cor_+3A_use">use</code></td>
<td>
<p>Only complete.obs at this time. Respondents who don't have a score for one or more scales are removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses plausible values so results may differ slightly between calls.
</p>


<h3>Value</h3>

<p>List containing a estimated correlation matrix, the corresponding standard deviations, 
and the lower and upper limits of the highest posterior density interval
</p>


<h3>References</h3>

<p>Marsman, M., Bechger, T. M., &amp; Maris, G. K. (2022). Composition algorithms for conditional distributions. 
In Essays on Contemporary Psychometrics (pp. 219-250). Cham: Springer International Publishing.
</p>

<hr>
<h2 id='open_project'>Open an existing project</h2><span id='topic+open_project'></span>

<h3>Description</h3>

<p>Opens a database created by function <code>start_new_project</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>open_project(db_name = "dexter.db")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="open_project_+3A_db_name">db_name</code></td>
<td>
<p>The name of the database to be opened.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a database connection object
</p>

<hr>
<h2 id='plausible_scores'>Draw plausible test scores</h2><span id='topic+plausible_scores'></span>

<h3>Description</h3>

<p>Draw plausible, i.e. posterior predictive sumscores on a set of items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plausible_scores(
  dataSrc,
  parms = NULL,
  predicate = NULL,
  items = NULL,
  parms_draw = c("sample", "average"),
  covariates = NULL,
  nPS = 1,
  prior_dist = c("normal", "mixture"),
  keep.observed = TRUE,
  by_item = FALSE,
  merge_within_persons = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plausible_scores_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_parms">parms</code></td>
<td>
<p>An object returned by function <code>fit_enorm</code> and containing
parameter estimates. If parms is given the function provides plausible scores conditional on the 
item parameters. These are considered known. If <code>parms</code> is <code>NULL</code>, Bayesian parameters are calculated from the datasrc</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_predicate">predicate</code></td>
<td>
<p>an expression to filter data. If missing, the function will use 
all data in dataSrc</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_items">items</code></td>
<td>
<p>vector of item_id's, this specifies the itemset to generate the testscores for. If <code>items</code> is <code>NULL</code> 
all items occurring in <code>dataSrc</code> are used.</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_parms_draw">parms_draw</code></td>
<td>
<p>when the item parameters are estimated Bayesianly (see: <code><a href="#topic+fit_enorm">fit_enorm</a></code>), 
parms_draw specifies whether to use a sample(a different item parameter draw for each plausible values draw) or the posterior mean
of the item draws. Alternatively, it can be an integer specifying a specific draw. Ignored when parms is not estimated Bayesianly.</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_covariates">covariates</code></td>
<td>
<p>name or a vector of names of the variables to group the population, used to update the prior.
A covariate must be a discrete person covariate that indicates nominal categories, e.g. gender or school
If dataSrc is a data.frame, it must contain the covariate.</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_nps">nPS</code></td>
<td>
<p>Number of plausible testscores to generate per person.</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_prior_dist">prior_dist</code></td>
<td>
<p>use a normal prior for the plausible values or a mixture of two normals. 
A mixture is only possible when there are no covariates.</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_keep.observed">keep.observed</code></td>
<td>
<p>If responses to one or more of the items have been observed,
the user can choose to keep these observations or generate new ones.</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_by_item">by_item</code></td>
<td>
<p>return scores per item instead of sumscores</p>
</td></tr>
<tr><td><code id="plausible_scores_+3A_merge_within_persons">merge_within_persons</code></td>
<td>
<p>If a person took multiple booklets, this indicates
whether plausible scores are generated per person (TRUE) or per booklet (FALSE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A typical use of this function is to generate plausible scores on
a complete item bank when data is collected using an incomplete design
</p>


<h3>Value</h3>

<p>A data.frame with columns booklet_id, person_id, booklet_score and nPS plausible scores
named PS1...PSn.
</p>

<hr>
<h2 id='plausible_values'>Draw plausible values</h2><span id='topic+plausible_values'></span>

<h3>Description</h3>

<p>Draws plausible values based on test scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plausible_values(
  dataSrc,
  parms = NULL,
  predicate = NULL,
  covariates = NULL,
  nPV = 1,
  parms_draw = c("sample", "average"),
  prior_dist = c("normal", "mixture"),
  merge_within_persons = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plausible_values_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_parms">parms</code></td>
<td>
<p>An object returned by function <code>fit_enorm</code> containing parameter estimates. If parms are provided, item parameters are considered known. 
If parms = NULL, they will be estimated Bayesianly.</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_predicate">predicate</code></td>
<td>
<p>an expression to filter data. If missing, the function will use 
all data in dataSrc</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_covariates">covariates</code></td>
<td>
<p>name or a vector of names of the variables to group the populations used to improve the prior.
A covariate must be a discrete person property (e.g. not a float) that indicates nominal categories, e.g. gender or school.
If dataSrc is a data.frame, it must contain the covariate.</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_npv">nPV</code></td>
<td>
<p>Number of plausible values to draw per person.</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_parms_draw">parms_draw</code></td>
<td>
<p>when the item parameters are estimated with method &quot;Bayes&quot; (see: <code><a href="#topic+fit_enorm">fit_enorm</a></code>), 
parms_draw specifies whether to use a sample (a different item parameter draw for each plausible values draw) or the posterior mean
of the item draws. Alternatively, it can be an integer specifying a specific draw. It is ignored when parms is not estimated Bayesianly.</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_prior_dist">prior_dist</code></td>
<td>
<p>use a normal prior for the plausible values or a mixture of two normals. 
A mixture is only possible when there are no covariates.</p>
</td></tr>
<tr><td><code id="plausible_values_+3A_merge_within_persons">merge_within_persons</code></td>
<td>
<p>If a person took multiple booklets, this indicates
whether plausible values are generated per person (TRUE) or per booklet (FALSE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the item parameters are estimated using <code>fit_enorm(..., method='Bayes')</code> and parms_draw = 'sample', the uncertainty 
of the item parameters estimates is taken into account when drawing multiple plausible values. 
</p>
<p>In there are covariates, the prior distribution is a hierarchical normal with equal variances across groups. When there is only
one group this becomes a regular normal distribution. When there are no covariates and prior_dist = &quot;mixture&quot;, the prior is a mixture
distribution of two normal distributions which gives a little more flexibility than a normal prior.
</p>


<h3>Value</h3>

<p>A data.frame with columns booklet_id, person_id, booklet_score, any covariate columns, and nPV plausible values
named PV1...PVn.
</p>


<h3>References</h3>

<p>Marsman, M., Maris, G., Bechger, T. M., and Glas, C.A.C. (2016) What can we learn from plausible values? 
Psychometrika. 2016; 81: 274-289. See also the vignette.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules, ":memory:", 
   person_properties=list(gender="&lt;unknown&gt;"))
add_booklet(db, verbAggrData, "agg")
add_item_properties(db, verbAggrProperties)

f=fit_enorm(db)
pv_M=plausible_values(db,f,(mode=="Do")&amp;(gender=="Male"))
pv_F=plausible_values(db,f,(mode=="Do")&amp;(gender=="Female"))

par(mfrow=c(1,2))

plot(ecdf(pv_M$PV1), 
   main="Do: males versus females", xlab="Ability", col="red")
lines(ecdf(pv_F$PV1), col="green")
legend(-2.2,0.9, c("female", "male") , 
   lty=1, col=c('green', 'red'), bty='n', cex=.75)

pv_M=plausible_values(db,f,(mode=="Want")&amp;(gender=="Male"))
pv_F=plausible_values(db,f,(mode=="Want")&amp;(gender=="Female"))

plot(ecdf(pv_M$PV1), 
   main="Want: males versus females", xlab=" Ability", col="red")
lines(ecdf(pv_F$PV1),col="green")
legend(-2.2,0.9, c("female", "male") , 
   lty=1, col=c('green', 'red'), bty='n', cex=.75)
   
   
close_project(db)    



</code></pre>

<hr>
<h2 id='plot.DIF_stats'>plot method for pairwise DIF statistics</h2><span id='topic+plot.DIF_stats'></span>

<h3>Description</h3>

<p>plot method for pairwise DIF statistics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DIF_stats'
plot(x, items = NULL, itemsX = items, itemsY = items, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.DIF_stats_+3A_x">x</code></td>
<td>
<p>object produced by <code><a href="#topic+DIF">DIF</a></code></p>
</td></tr>
<tr><td><code id="plot.DIF_stats_+3A_items">items</code></td>
<td>
<p>character vector of item id's for a subset of the plot. Useful if you have many items. 
If NULL all items are plotted.</p>
</td></tr>
<tr><td><code id="plot.DIF_stats_+3A_itemsx">itemsX</code></td>
<td>
<p>character vector of item id's for the X axis</p>
</td></tr>
<tr><td><code id="plot.DIF_stats_+3A_itemsy">itemsY</code></td>
<td>
<p>character vector of item id's for the Y axis</p>
</td></tr>
<tr><td><code id="plot.DIF_stats_+3A_alpha">alpha</code></td>
<td>
<p>significance level used to color the plot (two sided)</p>
</td></tr>
<tr><td><code id="plot.DIF_stats_+3A_...">...</code></td>
<td>
<p>further arguments to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plotting produces an image of the matrix of pairwise DIF statistics. 
The statistics are standard normal deviates and colored to distinguish significant from non-significant values.
If there is no DIF, a proportion alpha off the cells will be colored significant by chance alone.
</p>


<h3>References</h3>

<p>Feskens, R., Fox, J. P., &amp; Zwitser, R. (2019). Differential item functioning in PISA due to mode effects. 
In Theoretical and Practical Advances in Computer-based Educational Measurement (pp. 231-247). Springer, Cham.
</p>

<hr>
<h2 id='plot.p2pass'>A plot method for probability_to_pass</h2><span id='topic+plot.p2pass'></span>

<h3>Description</h3>

<p>Plot equating information from probability_to_pass
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'p2pass'
plot(
  x,
  what = c("all", "equating", "sens/spec", "roc"),
  booklet_id = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.p2pass_+3A_x">x</code></td>
<td>
<p>An object produced by function <code><a href="#topic+probability_to_pass">probability_to_pass</a></code></p>
</td></tr>
<tr><td><code id="plot.p2pass_+3A_what">what</code></td>
<td>
<p>information to plot, 'equating', 'sens/spec', 'roc, or 'all'</p>
</td></tr>
<tr><td><code id="plot.p2pass_+3A_booklet_id">booklet_id</code></td>
<td>
<p>vector of booklet_id's to plot, if NULL all booklets are plotted</p>
</td></tr>
<tr><td><code id="plot.p2pass_+3A_...">...</code></td>
<td>
<p>Any additional plotting parameters; e.g., cex = 0.7.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.prms'>Plot for the extended nominal Response model</h2><span id='topic+plot.prms'></span>

<h3>Description</h3>

<p>The plot shows 'fit' by comparing the expected score based on the model (grey line)
with the average scores based on the data (black line with dots) for groups of students
with similar estimated ability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'prms'
plot(
  x,
  item_id = NULL,
  dataSrc = NULL,
  predicate = NULL,
  nbins = 5,
  ci = 0.95,
  add = FALSE,
  col = "black",
  col.model = "grey80",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.prms_+3A_x">x</code></td>
<td>
<p>object produced by fit_enorm</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_item_id">item_id</code></td>
<td>
<p>which item to plot, if NULL, one plot for each item is made</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_datasrc">dataSrc</code></td>
<td>
<p>data source, see details</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_predicate">predicate</code></td>
<td>
<p>an expression to subset data in dataSrc</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_nbins">nbins</code></td>
<td>
<p>number of ability groups</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_ci">ci</code></td>
<td>
<p>confidence interval for the error bars, between 0 and 1. Use 0 to suppress the error bars.
Default = 0.95 for a 95% confidence interval</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_add">add</code></td>
<td>
<p>logical; if TRUE add to an already existing plot</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_col">col</code></td>
<td>
<p>color for the observed score average</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_col.model">col.model</code></td>
<td>
<p>color for the expected score based on the model</p>
</td></tr>
<tr><td><code id="plot.prms_+3A_...">...</code></td>
<td>
<p>further arguments to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard plot shows the fit against the sample on which the parameters were fitted. If
dataSrc is provided, the fit is shown against the observed data in dataSrc. This may be useful 
for plotting the fit in different subgroups as a visual test for item level DIF. The confidence 
intervals denote the uncertainty about the predicted pvalues within the ability groups for the 
sample size in dataSrc (if not NULL) or the original data on which the model was fit.
</p>


<h3>Value</h3>

<p>Silently, a data.frame with observed and expected values possibly useful to create a numerical fit measure.
</p>

<hr>
<h2 id='plot.rim'>A plot method for the interaction model</h2><span id='topic+plot.rim'></span>

<h3>Description</h3>

<p>Plot the item-total regressions fit by the interaction (or Rasch) model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rim'
plot(
  x,
  items = NULL,
  summate = TRUE,
  overlay = FALSE,
  curtains = 10,
  show.observed = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.rim_+3A_x">x</code></td>
<td>
<p>An object produced by function <code>fit_inter</code></p>
</td></tr>
<tr><td><code id="plot.rim_+3A_items">items</code></td>
<td>
<p>The items to plot (item_id's). If NULL, all items will be plotted</p>
</td></tr>
<tr><td><code id="plot.rim_+3A_summate">summate</code></td>
<td>
<p>If FALSE, regressions for polytomous items will be shown for each
response option separately; default is TRUE.</p>
</td></tr>
<tr><td><code id="plot.rim_+3A_overlay">overlay</code></td>
<td>
<p>If TRUE and more than one item is specified, there will be two plots,
one for the Rasch model and the other for the interaction model, with all items
overlayed; otherwise, one plot for each item with the two models overlayed. Ignored
if summate is FALSE. Default is FALSE</p>
</td></tr>
<tr><td><code id="plot.rim_+3A_curtains">curtains</code></td>
<td>
<p>100*the tail probability of the sum scores to be shaded. Default is 10.
Set to 0 to have no curtains shown at all.</p>
</td></tr>
<tr><td><code id="plot.rim_+3A_show.observed">show.observed</code></td>
<td>
<p>If TRUE, the observed proportion correct at each sum score
will be shown as dots. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.rim_+3A_...">...</code></td>
<td>
<p>Any additional plotting parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Customization of title and subtitle can be done by using the arguments main and sub.
These arguments can contain references to the variables item_id (if overlay=FALSE) or model (if overlay=TRUE)
by prefixing them with a dollar sign, e.g. plot(m, main='item: $item_id')
</p>

<hr>
<h2 id='probability_to_pass'>The probability to pass on a reference test given a score on a new booklet</h2><span id='topic+probability_to_pass'></span>

<h3>Description</h3>

<p>Given response data that form a connected design,
compute the probability to pass on the reference set conditional on each score on one or more target tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probability_to_pass(
  dataSrc,
  parms,
  ref_items,
  pass_fail,
  predicate = NULL,
  target_booklets = NULL,
  nDraws = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probability_to_pass_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="probability_to_pass_+3A_parms">parms</code></td>
<td>
<p>object produced by <code><a href="#topic+fit_enorm">fit_enorm</a></code> or a data.frame with columns item_id, item_score and  beta. 
If uncertainty about parameter estimation should be included
in the computations, use a &lsquo;parms' object computed with 'method=&rsquo;Bayes'' and nDraws equal or larger than nDraws in probability_to_pass</p>
</td></tr>
<tr><td><code id="probability_to_pass_+3A_ref_items">ref_items</code></td>
<td>
<p>vector with id's of items in the reference set, they must all occur in dataSrc</p>
</td></tr>
<tr><td><code id="probability_to_pass_+3A_pass_fail">pass_fail</code></td>
<td>
<p>pass-fail score on the reference set, the lowest score with which one passes</p>
</td></tr>
<tr><td><code id="probability_to_pass_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data in dataSrc, if NULL all data is used</p>
</td></tr>
<tr><td><code id="probability_to_pass_+3A_target_booklets">target_booklets</code></td>
<td>
<p>The target test booklet(s). A data.frame with columns booklet_id (if multiple booklets) and item_id, 
if NULL (default) this will be derived from the dataSrc and the probability to pass will be computed 
for each test score for each booklet in your data.</p>
</td></tr>
<tr><td><code id="probability_to_pass_+3A_ndraws">nDraws</code></td>
<td>
<p>The function uses an Markov-Chain Monte-Carlo method to calculate the probability to pass and this is the number of Monte-Carlo samples used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function is computationally intensive and can take some time to run, especially when computing the
probability to pass for multiple target booklets. Further technical details can be found in a vignette.
</p>


<h3>Value</h3>

<p>An object of type <code>p2pass</code>. Use <code>coef()</code> to extract the 
probablity to pass for each booklet and score. Use <code>plot()</code> to plot 
the probabilities, sensitivity and specificity or a ROC-curve.
</p>


<h3>See Also</h3>

<p>The function used to plot the results: <code><a href="#topic+plot.p2pass">plot.p2pass</a></code>
</p>

<hr>
<h2 id='profile_plot'>Profile plot</h2><span id='topic+profile_plot'></span>

<h3>Description</h3>

<p>Profile plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>profile_plot(
  dataSrc,
  item_property,
  covariate,
  predicate = NULL,
  model = c("IM", "RM"),
  x = NULL,
  col = NULL,
  col.diagonal = "lightgray",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="profile_plot_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database or a data.frame with columns: 
person_id, item_id, item_score and the item_property and the covariate of interest.</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_item_property">item_property</code></td>
<td>
<p>The name of the item property defining the domains. 
The item property should have exactly two distinct values in your data</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_covariate">covariate</code></td>
<td>
<p>name of the person property used to create the groups. 
There will be one line for each distinct value.</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to filter data, if NULL all data is used</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_model">model</code></td>
<td>
<p>&quot;IM&quot; (default) or &quot;RM&quot; where &quot;IM&quot; is the interaction model and 
&quot;RM&quot; the Rasch model. The interaction model is the default as it fits 
the data better or at least as good as the Rasch model.</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_x">x</code></td>
<td>
<p>Which category of the item_property to draw on the x axis, if NULL, one is chosen automatically</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_col">col</code></td>
<td>
<p>vector of colors to use for plotting</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_col.diagonal">col.diagonal</code></td>
<td>
<p>color of the diagonal lines representing the testscores</p>
</td></tr>
<tr><td><code id="profile_plot_+3A_...">...</code></td>
<td>
<p>further graphical arguments to plot. Graphical parameters for the legend can be postfixed with <code>.legend</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Profile plots can be used to investigate whether two (or more) groups of respondents 
attain the same test score in the same way. The user must provide a  
(meaningful) classification of the items in two non-overlapping subsets such that 
the test score is the sum of the scores on the subsets. 
The plot shows the probabilities to obtain 
any combinations of subset scores with thin gray lines indicating the combinations 
that give the same test score. The thick lines connect the most likely 
combination for each test score in each group.
When applied to educational test data, the plots can be used to detect differences in the 
relative difficulty of (sets of) items for respondents that belong to different 
groups and are matched on the test score. This provides a content-driven way to 
investigate differential item functioning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


db = start_new_project(verbAggrRules, ":memory:", 
                         person_properties=list(gender="unknown"))
add_booklet(db, verbAggrData, "agg")
add_item_properties(db, verbAggrProperties)
profile_plot(db, item_property='mode', covariate='gender')

close_project(db)



</code></pre>

<hr>
<h2 id='profile_tables'>Profile analysis</h2><span id='topic+profile_tables'></span><span id='topic+profiles'></span>

<h3>Description</h3>

<p>Expected and observed domain scores, conditional on the test score, per person or test score. 
Domains are specified as categories of items using item_properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>profile_tables(parms, domains, item_property, design = NULL)

profiles(
  dataSrc,
  parms,
  item_property,
  predicate = NULL,
  merge_within_persons = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="profile_tables_+3A_parms">parms</code></td>
<td>
<p>An object returned by <code><a href="#topic+fit_enorm">fit_enorm</a></code> or a data.frame of item parameters</p>
</td></tr>
<tr><td><code id="profile_tables_+3A_domains">domains</code></td>
<td>
<p>data.frame with column item_id and a column with name equal to <code>item_property</code></p>
</td></tr>
<tr><td><code id="profile_tables_+3A_item_property">item_property</code></td>
<td>
<p>the name of the item property used to define the domains. If <code>dataSrc</code> is a dexter db then the
item_property must match a known item property. If datasrc is a data.frame, item_property must be equal to
one of its column names. For profile_tables item_property must match a column name in <code>domains</code>.</p>
</td></tr>
<tr><td><code id="profile_tables_+3A_design">design</code></td>
<td>
<p>data.frame with columns item_id and optionally booklet_id</p>
</td></tr>
<tr><td><code id="profile_tables_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database or a data.frame with columns: person_id, item_id, item_score, 
an arbitrarily named column containing an item property and optionally booklet_id</p>
</td></tr>
<tr><td><code id="profile_tables_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data in dataSrc, if NULL all data is used</p>
</td></tr>
<tr><td><code id="profile_tables_+3A_merge_within_persons">merge_within_persons</code></td>
<td>
<p>whether to merge different booklets administered to the same person.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using a unidimensional IRT Model like the extended nominal response model in 
dexter (see: <code><a href="#topic+fit_enorm">fit_enorm</a></code>), the model is as a rule to simple to catch all the relevant dimensions in a test.
Nevertheless, a simple model is quite useful in practice. Profile analysis can complement the model
in this case by indicating how a test-taker, conditional on her/his test score, 
performs on a number of pre-specified domains, e.g. in case of a mathematics test 
the domains could be numbers, algebra and geometry or in case of a digital test the domains could be animated versus
non-animated items. This can be done by comparing the achieved score on a domain with the expected score, given the test score.
</p>


<h3>Value</h3>


<dl>
<dt>profiles</dt><dd><p>a data.frame with columns person_id, booklet_id, booklet_score, 
&lt;item_property&gt;, domain_score, expected_domain_score</p>
</dd>
<dt>profile_tables</dt><dd><p>a data.frame with columns booklet_id, booklet_score, 
&lt;item_property&gt;, expected_domain_score </p>
</dd>
</dl>



<h3>References</h3>

<p>Verhelst, N. D. (2012). Profile analysis: a closer look at the PISA 2000 reading data. 
Scandinavian Journal of Educational Research, 56 (3), 315-332.
</p>

<hr>
<h2 id='r_score_IM'>Simulation from the interaction model</h2><span id='topic+r_score_IM'></span>

<h3>Description</h3>

<p>Simulate item scores conditional on test scores using the interaction model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r_score_IM(m, scores)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r_score_IM_+3A_m">m</code></td>
<td>
<p>an object produced by function <code>fit_inter</code></p>
</td></tr>
<tr><td><code id="r_score_IM_+3A_scores">scores</code></td>
<td>
<p>vector of test scores</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with item scores, one column per item and one row per test score. Row order
equal to scores
</p>

<hr>
<h2 id='ratedData'>Rated data</h2><span id='topic+ratedData'></span>

<h3>Description</h3>

<p>A data set with rated data. A number of student performances are rated twice on several
aspects by independent judges. The ratings are binary and have been summed following
the theory discussed by Maris and Bechger (2006, Handbook of Statistics). Data are a
small subset of data collected on the State Exam Dutch as a second language for Speaking.
</p>


<h3>Format</h3>

<p>A data set with 75 rows and 15 columns.
</p>

<hr>
<h2 id='ratedDataProperties'>Item properties in the rated data</h2><span id='topic+ratedDataProperties'></span>

<h3>Description</h3>

<p>A data set of item properties related to the rated data. These are the aspects: 
IH = content, WZ = word choice and phrasing, and WK = vocabulary.
</p>


<h3>Format</h3>

<p>A data set with 14 rows and 2 columns: item_id and aspect
</p>

<hr>
<h2 id='ratedDataRules'>Scoring rules for the rated data</h2><span id='topic+ratedDataRules'></span>

<h3>Description</h3>

<p>A set of (trivial) scoring rules for the rated data set
</p>


<h3>Format</h3>

<p>A data set with 42 rows and 3 columns (item_id, response, item_score).
</p>

<hr>
<h2 id='read_oplm_par'>Read item parameters from oplm PAR or CML files</h2><span id='topic+read_oplm_par'></span>

<h3>Description</h3>

<p>Read item parameters from oplm PAR or CML files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_oplm_par(par_path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_oplm_par_+3A_par_path">par_path</code></td>
<td>
<p>path to a file in the (binary) OPLM PAR format or the human readable CML format</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is very occasionally useful to calibrate new items on an existing scale. This
function offers the possibility to read parameters from the proprietary oplm format 
so that they can be used to fix a new calibration in Dexter on an existing scale of items
that were calibrated in oplm.
</p>


<h3>Value</h3>

<p>depends on the input. For .PAR files a data.frame with columns: item_id, item_score, beta, nbr,
for .CML files also several statistics columns that are outputted by OPLM as part of the calibration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
\donttest{
par = read_oplm_par('/parameters.PAR')
f = fit_enorm(db, fixed_params=par)
}
## End(Not run)
</code></pre>

<hr>
<h2 id='standards_3dc'>Standard setting</h2><span id='topic+standards_3dc'></span><span id='topic+coef.sts_par'></span><span id='topic+plot.sts_par'></span>

<h3>Description</h3>

<p>Set performance standards on one or more test forms using the data driven direct consensus (3DC) method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standards_3dc(parms, design)

## S3 method for class 'sts_par'
coef(object, ...)

## S3 method for class 'sts_par'
plot(x, booklet_id = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standards_3dc_+3A_parms">parms</code></td>
<td>
<p>parameters object returned from fit_enorm</p>
</td></tr>
<tr><td><code id="standards_3dc_+3A_design">design</code></td>
<td>
<p>a data.frame with columns 'cluster_id', 'item_id' and optionally 'booklet_id'</p>
</td></tr>
<tr><td><code id="standards_3dc_+3A_object">object</code></td>
<td>
<p>an object containing parameters for the 3DC standard setting procedure</p>
</td></tr>
<tr><td><code id="standards_3dc_+3A_...">...</code></td>
<td>
<p>ignored
Optionally you can include a column 'booklet_id' to specify multiple test forms for standard setting and/or
columns 'cluster_nbr' and 'item_nbr' to specify ordering of clusters and items in the forms and application.</p>
</td></tr>
<tr><td><code id="standards_3dc_+3A_x">x</code></td>
<td>
<p>an object containing parameters for the 3DC standard setting procedure</p>
</td></tr>
<tr><td><code id="standards_3dc_+3A_booklet_id">booklet_id</code></td>
<td>
<p>which test form to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data driven direct consensus (3DC) method of standard setting was invented by Gunter Maris and described in Keuning et. al. (2017).
To easily apply this procedure, we advise to use the free digital 3DC application. This application 
can be downloaded from the Cito website, see the 
<a href="https://www.cito.com/our-expertise/implementation/3dc">3DC application download page</a>. 
If you want to apply the 3DC method using paper forms instead, you can use the plot method to generate the forms
from the sts_par object.
</p>
<p>Although the 3DC method is used as explained in Keuning et. al., the method we use for computing the forms is a simple
maximum likelihood scaling from an IRT model, described in Moe and Verhelst (2017)
</p>


<h3>Value</h3>

<p>an object of type 'sts_par'
</p>


<h3>References</h3>

<p>Keuning J., Straat J.H., Feskens R.C.W. (2017) The Data-Driven Direct Consensus (3DC) Procedure: A New Approach to Standard Setting. 
In: Blomeke S., Gustafsson JE. (eds) Standard Setting in Education. 
Methodology of Educational Measurement and Assessment. Springer, Cham
</p>
<p>Moe E., Verhelst N. (2017) Setting Standards for Multistage Tests of Norwegian for Adult Immigrants 
In: Blomeke S., Gustafsson JE. (eds) Standard Setting in Education. 
Methodology of Educational Measurement and Assessment. Springer, Cham
</p>


<h3>See Also</h3>

<p>how to make a database for the 3DC standard setting application: <code><a href="#topic+standards_db">standards_db</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


library(dplyr)
db = start_new_project(verbAggrRules, ":memory:")
            
add_booklet(db, verbAggrData, "agg")
add_item_properties(db, verbAggrProperties)

design = get_items(db) |&gt;
  rename(cluster_id='behavior')

f = fit_enorm(db)

sts_par = standards_3dc(f, design)

plot(sts_par)


# db_sts = standards_db(sts_par,'test.db',c('mildly aggressive','dangerously aggressive'))



</code></pre>

<hr>
<h2 id='standards_db'>Export a standard setting database for use by the free 3DC application</h2><span id='topic+standards_db'></span>

<h3>Description</h3>

<p>This function creates an export (an sqlite database file) which can be used by the 3DC application. This is a free application with which
a standard setting session can be facilitated through a LAN network using the Chrome browser.
The 3DC application can be downloaded from <a href="https://www.cito.com/our-expertise/implementation/3dc">3DC application download page</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standards_db(
  par.sts,
  file_name,
  standards,
  population = NULL,
  group_leader = "admin"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standards_db_+3A_par.sts">par.sts</code></td>
<td>
<p>an object containing parameters for the 3DC standard setting procedure produced by
<code><a href="#topic+standards_3dc">standards_3dc</a></code></p>
</td></tr>
<tr><td><code id="standards_db_+3A_file_name">file_name</code></td>
<td>
<p>name of the exported database file</p>
</td></tr>
<tr><td><code id="standards_db_+3A_standards">standards</code></td>
<td>
<p>vector of 1 or more standards. In case there are multiple test forms and
they should use different performance standards, a list of such vectors. 
The names of this list should correspond to the names of the testforms</p>
</td></tr>
<tr><td><code id="standards_db_+3A_population">population</code></td>
<td>
<p>optional, a data.frame with three columns: 'booklet_id','booklet_score','n' (where n is a count)</p>
</td></tr>
<tr><td><code id="standards_db_+3A_group_leader">group_leader</code></td>
<td>
<p>login name of the group leader. The login password will always be 'admin' 
but can be changed in the 3DC application</p>
</td></tr>
</table>

<hr>
<h2 id='start_new_project'>Start a new project</h2><span id='topic+start_new_project'></span>

<h3>Description</h3>

<p>Imports a complete set of scoring rules and starts a new project (database)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>start_new_project(rules, db_name = "dexter.db", person_properties = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="start_new_project_+3A_rules">rules</code></td>
<td>
<p>A data frame with columns <code>item_id</code>, <code>response</code>, and <code>item_score</code>.
The order is not important but spelling is. Any other columns will be ignored.</p>
</td></tr>
<tr><td><code id="start_new_project_+3A_db_name">db_name</code></td>
<td>
<p>A string specifying a filename
for a new sqlite database to be created. If this name does not
contain a path, the file will be created in the work
directory. Any existing file with the same name will be overwritten. For an in-memory database
you can use the string <code>":memory:"</code>. A connection object is also allowed.</p>
</td></tr>
<tr><td><code id="start_new_project_+3A_person_properties">person_properties</code></td>
<td>
<p>An optional list of person properties. Names should correspond to person_properties intended to be used in the project.
Values are used as default (missing) values. The datatype will also be inferred from the values.
Known person_properties will be automatically imported when adding response data with <code><a href="#topic+add_booklet">add_booklet</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This package only works with closed items (e.g. likert, MC or possibly short answer)
it does not score any open items.
The first step to creating a project is to import an exhaustive list of all items and
all admissible responses, along with the score that any of the latter will be given.
Responses may be integers or strings but they will always be treated as strings.
Scores must be integers, and the minimum score for an item must be 0.
When inputting data, all responses not specified in the rules can optionally be treated as
missing and ultimately scored 0, but it is good style to include the missing
responses in the list. NA values will be treated as the string &quot;NA&quot;'.
</p>


<h3>Value</h3>

<p>a database connection object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
head(verbAggrRules)
db_name = tempfile(fileext='.db')
db = start_new_project(verbAggrRules, db_name, 
                       person_properties = list(gender = "unknown"))


</code></pre>

<hr>
<h2 id='start_new_project_from_oplm'>Start a new project from oplm files</h2><span id='topic+start_new_project_from_oplm'></span>

<h3>Description</h3>

<p>Creates a dexter project database and fills it with response data based on a .dat and .scr file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>start_new_project_from_oplm(
  dbname,
  scr_path,
  dat_path,
  booklet_position = NULL,
  responses_start = NULL,
  response_length = 1,
  person_id = NULL,
  missing_character = c(" ", "9"),
  use_discrim = FALSE,
  format = "compressed"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="start_new_project_from_oplm_+3A_dbname">dbname</code></td>
<td>
<p>filename/path of new dexter project database (will be overwritten if already exists)</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_scr_path">scr_path</code></td>
<td>
<p>path to the .scr file</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_dat_path">dat_path</code></td>
<td>
<p>path to the .dat file</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_booklet_position">booklet_position</code></td>
<td>
<p>vector of start and end of booklet position in the dat file, e.g. c(1,4), 
all positions are counted from 1, start and end are both inclusive. If NULL, this is read from the scr file.</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_responses_start">responses_start</code></td>
<td>
<p>start position of responses in the .dat file. If NULL, this is read from the scr file.</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_response_length">response_length</code></td>
<td>
<p>length of individual responses, default=1</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_person_id">person_id</code></td>
<td>
<p>optionally, a vector of start and end position of person_id in the .dat file.
If NULL, person id's will be auto-generated.</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_missing_character">missing_character</code></td>
<td>
<p>vector of character(s) used to indicate missing in .dat file, 
default is to use both a space and a 9 as missing characters.</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_use_discrim">use_discrim</code></td>
<td>
<p>if TRUE, the scores for the responses will be multiplied by the
discrimination parameters of the items</p>
</td></tr>
<tr><td><code id="start_new_project_from_oplm_+3A_format">format</code></td>
<td>
<p>not used, at the moment only the compressed format is supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>start_new_project_from_oplm builds a complete dexter database from a .dat and .scr file in
the proprietary oplm format. Four custom variables are added to the database: 
booklet_on_off, oplm_marginal, item_local_on_off, item_global_on_off. These are taken from the .scr file
and can be used in predicates in the various dexter functions.
</p>
<p>Booklet_position and responses_start are usually inferred from the scr file but since they
are sometimes misspecified in the scr file they can be overridden. Response_length is not 
inferred from the scr file since anything other than 1 is most often a mistake.
</p>


<h3>Value</h3>

<p>a database connection object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: \donttest{
db = start_new_project_from_oplm('test.db',
   'path_to_scr_file', 'path_to_dat_file', 
   booklet_position=c(1,3), responses_start=101,
   person_id=c(50,62))

prms = fit_enorm(db, 
   item_global_on_off==1 &amp; item_local_on_off==1 &amp; booklet_on_off==1)


}
## End(Not run)
</code></pre>

<hr>
<h2 id='tia_tables'>Simple test-item analysis</h2><span id='topic+tia_tables'></span>

<h3>Description</h3>

<p>Show simple Classical Test Analysis statistics
at item and test level
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tia_tables(
  dataSrc,
  predicate = NULL,
  type = c("raw", "averaged", "compared"),
  max_scores = c("observed", "theoretical"),
  distractor = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tia_tables_+3A_datasrc">dataSrc</code></td>
<td>
<p>a connection to a dexter database, a matrix, or a data.frame with columns: person_id, item_id, item_score</p>
</td></tr>
<tr><td><code id="tia_tables_+3A_predicate">predicate</code></td>
<td>
<p>An optional expression to subset data, if NULL all data is used</p>
</td></tr>
<tr><td><code id="tia_tables_+3A_type">type</code></td>
<td>
<p>How to present the item level statistics: <code>raw</code> for each test booklet 
separately, <code>averaged</code> booklets are ignored, with the exception of rit and rir which are averaged over the test booklets,
with the number of persons as weights, or <code>compared</code>, in which case the pvalues, 
correlations with the sum score (rit), and correlations with the rest score (rit) are 
shown in separate tables and compared across booklets</p>
</td></tr>
<tr><td><code id="tia_tables_+3A_max_scores">max_scores</code></td>
<td>
<p>use the observed maximum item score or the theoretical maximum item score 
according to the scoring rules in the database to determine pvalues and maximum scores</p>
</td></tr>
<tr><td><code id="tia_tables_+3A_distractor">distractor</code></td>
<td>
<p>add a tia for distractors, only useful for selected response (MC) items</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>booklets</code></td>
<td>
<p>a data.frame of statistics at booklet level</p>
</td></tr> 
<tr><td><code>items</code></td>
<td>
<p>a data.frame (or list if type='compared') of statistics at item level</p>
</td></tr>
<tr><td><code>distractors</code></td>
<td>
<p>a data.frame of statistics at the response level (if distractor==TRUE), i.e. 
rvalue (pvalue for response) and rar (rest-alternative correlation)</p>
</td></tr>
</table>

<hr>
<h2 id='touch_rules'>Add or modify scoring rules</h2><span id='topic+touch_rules'></span>

<h3>Description</h3>

<p>It is occasionally necessary to alter or add a scoring rule, e.g. in case of a key error. 
This function offers the possibility to do so and also allows you to add new items to your project
</p>


<h3>Usage</h3>

<pre><code class='language-R'>touch_rules(db, rules)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="touch_rules_+3A_db">db</code></td>
<td>
<p>a connection to a dexter project database</p>
</td></tr>
<tr><td><code id="touch_rules_+3A_rules">rules</code></td>
<td>
<p>A data frame with columns <code>item_id</code>, <code>response</code>, and <code>item_score</code>.
The order is not important but spelling is. Any other columns will be ignored. See details</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rules should contain all rules that you want to change or add. This means that in case of a key error
in a single multiple choice question, you typically have to change two rules.
</p>


<h3>Value</h3>

<p>If the scoring rules pass a sanity check, a small summary of changes is printed and nothing is returned.
Otherwise this function returns a data frame listing the problems found, with 4 columns:
</p>

<dl>
<dt>item_id</dt><dd><p>id of the problematic item</p>
</dd>
<dt>less_than_two_scores</dt><dd><p>if TRUE, the item has only one distinct score</p>
</dd>
<dt>duplicated_responses</dt><dd><p>if TRUE, the item contains two or more identical response categories</p>
</dd>
<dt>min_score_not_zero</dt><dd><p>if TRUE, the minimum score of the item was not 0</p>
</dd></dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: \donttest{
# given that in your dexter project there is an mc item with id 'itm_01', 
# which currently has key 'A' but you want to change it to 'C'.

new_rules = data.frame(item_id='itm_01', response=c('A','C'), item_score=c(0,1))
touch_rules(db, new_rules)
}
## End(Not run)

</code></pre>

<hr>
<h2 id='verbAggrData'>Verbal aggression data</h2><span id='topic+verbAggrData'></span>

<h3>Description</h3>

<p>A data set of self-reported verbal behaviour in different frustrating
situations (Vansteelandt, 2000). The dataset also contains participants reported gender and scores on the 'anger' questionnaire.
</p>


<h3>Format</h3>

<p>A data set with 316 rows and 26 columns.
</p>

<hr>
<h2 id='verbAggrProperties'>Item properties in the verbal aggression data</h2><span id='topic+verbAggrProperties'></span>

<h3>Description</h3>

<p>A data set of item properties related to the verbal
aggression data
</p>


<h3>Format</h3>

<p>A data set with 24 rows and 5 columns.
</p>

<hr>
<h2 id='verbAggrRules'>Scoring rules for the verbal aggression data</h2><span id='topic+verbAggrRules'></span>

<h3>Description</h3>

<p>A set of (trivial) scoring rules for the verbal 
aggression data set
</p>


<h3>Format</h3>

<p>A data set with 72 rows and 3 columns (item_id, response, item_score).
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
