<!DOCTYPE html><html lang="en-US"><head><title>Help for package FACT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FACT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ClustPredictor'><p>Clustering Predictor Object</p></a></li>
<li><a href='#create_predict_fun'><p>Create a generic prediction function</p></a></li>
<li><a href='#evaluate_class'><p>Evaluate Class</p></a></li>
<li><a href='#IDEA'><p>Idea - Isolated Effect on Assignment</p></a></li>
<li><a href='#SMART'><p><code>SMART</code> - Scoring Metric after Permutation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Feature Attributions for ClusTering</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>We present 'FACT' (Feature Attributions for ClusTering), a
  framework for unsupervised interpretation methods that can be used with an 
  arbitrary clustering algorithm. The package is capable of re-assigning instances to
  clusters (algorithm agnostic), preserves the integrity of the data and does
  not introduce additional models. 'FACT' is inspired by the principles of
  model-agnostic interpretation in supervised learning. Therefore, some of the
  methods presented are based on 'iml', a R Package for Interpretable Machine
  Learning by Christoph Molnar, Giuseppe Casalicchio, and Bernd Bischl (2018)
  &lt;<a href="https://doi.org/10.21105%2Fjoss.00786">doi:10.21105/joss.00786</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/henrifnk/FACT/issues">https://github.com/henrifnk/FACT/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate, data.table, ggplot2, gridExtra, R6, iml</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), caret, covr, knitr, mlr3, mlr3cluster,
rmarkdown, FuzzyDBScan, factoextra, patchwork, spelling</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-25 10:28:15 UTC; henri_funk</td>
</tr>
<tr>
<td>Author:</td>
<td>Henri Funk [aut, cre],
  Christian Scholbeck [aut, ctb],
  Giuseppe Casalicchio [aut, ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Henri Funk &lt;Henri.Funk@stat.uni-muenchen.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-25 10:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ClustPredictor'>Clustering Predictor Object</h2><span id='topic+ClustPredictor'></span>

<h3>Description</h3>

<p>A <code>ClustPredictor</code> object holds any unsupervised clustering algorithm
and the data to be used for analyzing the model. The interpretation methods
in the <code>FACT</code> package need the clustering algorithm to be wrapped in a
<code>ClustPredictor</code> object.
</p>


<h3>Details</h3>

<p>A Cluster Predictor object is a container for the unsupervised prediction
model and the data.
This ensures that the clustering algorithm can be analyzed in a robust way.
The Model inherits from <a href="iml.html#topic+Predictor">iml::Predictor</a> Object and adjusts this Object to
contain unsupervised Methods.
</p>


<h3>Super class</h3>

<p><code><a href="iml.html#topic+Predictor">iml::Predictor</a></code> -&gt; <code>ClustPredictor</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>type</code></dt><dd><p><code>character(1)</code><br />
Either partition for cluster assignments or prob
for soft labels. Can be decided by chosen by the
user when initializing the object. If <code>NULL</code>,
it checks the the dimensions of <code>y</code>.</p>
</dd>
<dt><code>cnames</code></dt><dd><p><code>character</code><br />
Is <code>NULL</code>, if hard labeling is used. If soft
labels are used, column names of <code>y</code> are being
transferred.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ClustPredictor-new"><code>ClustPredictor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ClustPredictor-clone"><code>ClustPredictor$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="Predictor" data-id="predict"><a href='../../iml/html/Predictor.html#method-Predictor-predict'><code>iml::Predictor$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="Predictor" data-id="print"><a href='../../iml/html/Predictor.html#method-Predictor-print'><code>iml::Predictor$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-ClustPredictor-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a ClustPredictor object
</p>


<h5>Usage</h5>

<div class="r"><pre>ClustPredictor$new(
  model = NULL,
  data = NULL,
  predict.function = NULL,
  y = NULL,
  batch.size = 1000,
  type = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model</code></dt><dd><p>any<br />
The trained clustering algorithm. Recommended
are models from <code>mlr3cluster</code>. For other
clustering algorithms predict functions need to
be specified.</p>
</dd>
<dt><code>data</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
The data to be used for analyzing the prediction model. Allowed column
classes are: <a href="base.html#topic+numeric">numeric</a>, <a href="base.html#topic+factor">factor</a>, <a href="base.html#topic+integer">integer</a>, <a href="base.html#topic+ordered">ordered</a> and <a href="base.html#topic+character">character</a></p>
</dd>
<dt><code>predict.function</code></dt><dd><p><a href="base.html#topic+function">function</a><br />
The function to assign newdata. Only needed if
<code>model</code> is not a model from <code>mlr3cluster</code>. The
first argument of <code>predict.fun</code> has to be the
model, the second the <code>newdata</code>:
</p>
<div class="sourceCode"><pre>function(model, newdata)
</pre></div></dd>
<dt><code>y</code></dt><dd><p>any<br />
A <a href="base.html#topic+integer">integer</a> vector representing the assigned
clusters or a <a href="base.html#topic+data.frame">data.frame</a> representing the
soft labels per cluster assigned in columns.</p>
</dd>
<dt><code>batch.size</code></dt><dd><p><code>numeric(1)</code><br />
The maximum number of rows to be input the model for prediction at once.
Currently only respected for <a href="#topic+SMART">SMART</a>.</p>
</dd>
<dt><code>type</code></dt><dd><p><code>character(1)</code>)<br />
This argument is passed to the prediction
function of the model. For soft label
predictions, use <code>type="prob"</code>. For hard label
predictions, use <code>type="partition"</code>. Consult
the documentation or definition of the
clustering algorithm you use to find which type
options you have.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ClustPredictor-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>ClustPredictor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>require(factoextra)
require(FuzzyDBScan)
multishapes &lt;- as.data.frame(multishapes[, 1:2])
eps = c(0, 0.2)
pts = c(3, 15)
res &lt;- FuzzyDBScan$new(multishapes, eps, pts)
res$plot("x", "y")
# create hard label predictor
predict_part = function(model, newdata) model$predict(new_data = newdata, cmatrix = FALSE)$cluster
ClustPredictor$new(res, as.data.frame(multishapes), y = res$clusters,
                       predict.function = predict_part, type = "partition")
# create soft label predictor
predict_prob = function(model, newdata) model$predict(new_data = newdata)
ClustPredictor$new(res, as.data.frame(multishapes), y = res$results,
                               predict.function = predict_prob, type = "prob")
</code></pre>

<hr>
<h2 id='create_predict_fun'>Create a generic prediction function</h2><span id='topic+create_predict_fun'></span><span id='topic+create_predict_fun.Learner'></span>

<h3>Description</h3>

<p>Create the algorithms prediction function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_predict_fun(model, task, predict.fun = NULL, type = NULL)

## S3 method for class 'Learner'
create_predict_fun(model, task, predict.fun = NULL, type = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_predict_fun_+3A_model">model</code></td>
<td>
<p>any <br />
An arbitrary trained clustering algorithm.</p>
</td></tr>
<tr><td><code id="create_predict_fun_+3A_task">task</code></td>
<td>
<p><code>character(1)</code> <br />
Should be clustering in this case. To be extended...</p>
</td></tr>
<tr><td><code id="create_predict_fun_+3A_predict.fun">predict.fun</code></td>
<td>
<p><code>function</code> <br />
The function to assign newdata. Only needed if <code>model</code> is not a model from
<code>mlr3cluster</code>. The first argument of <code>predict.fun</code> has to be the model, the
second the <code>newdata</code>:
</p>
<div class="sourceCode"><pre>function(model, newdata)
</pre></div>
<p>To be extended for more methods.</p>
</td></tr>
<tr><td><code id="create_predict_fun_+3A_type">type</code></td>
<td>
<p><code>character(1)</code> <br />
For soft label predictions, <code>type="prob"</code>. For hard label predictions,
<code>type="partition"</code>. Consult the documentation or definition of the
clustering algorithm you use to find which type options you have.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A unified cluster assignment function for either hard or soft labels.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>create_predict_fun(Learner)</code>: Create a predict function for algorithms from
<code>mlr3cluster</code>
</p>
</li></ul>

<hr>
<h2 id='evaluate_class'>Evaluate Class</h2><span id='topic+evaluate_class'></span><span id='topic+calculate_confusion'></span>

<h3>Description</h3>

<p>Calculation of binary similarity metric based on confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate_class(actual, predicted, metric = "f1")

calculate_confusion(actual, predicted)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evaluate_class_+3A_actual">actual</code></td>
<td>
<p><code>numeric</code> <br />
initial cluster assignments</p>
</td></tr>
<tr><td><code id="evaluate_class_+3A_predicted">predicted</code></td>
<td>
<p><code>numeric</code> <br />
cluster assignments of permuted data</p>
</td></tr>
<tr><td><code id="evaluate_class_+3A_metric">metric</code></td>
<td>
<p><code>character(1)</code> <br />
binary score metric</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A binary score for each of the clusters and the number of instances.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>calculate_confusion()</code>: Calculate confusion matrix
</p>
</li></ul>

<hr>
<h2 id='IDEA'>Idea - Isolated Effect on Assignment</h2><span id='topic+IDEA'></span>

<h3>Description</h3>

<p><code>IDEA</code> with a soft label predictor (sIDEA) <br />
tacks changes the soft label of being assigned to each existing cluster
throughout a (multidimensional) feature space
<code>IDEA</code> with a hard label predictor (hIDEA) <br />
tacks changes the soft label of being assigned to each existing cluster
throughout a (multidimensional) feature space
</p>


<h3>Details</h3>

<p><code>IDEA</code> for soft labeling algorithms (sIDEA) indicates the soft label that an
observation <code class="reqn">\textbf{x}</code> with replaced values <code class="reqn">\tilde{\textbf{x}}_S</code> is assigned to
the k-th cluster. <code>IDEA</code> for hard labeling algorithms (hIDEA) indicates
the cluster assignment of an observation <code class="reqn">\textbf{x}</code> with replaced values
<code class="reqn">\tilde{\textbf{x}}_S</code>. <br />
</p>
<p>The global <code>IDEA</code> is denoted by the corresponding data set X:
</p>
<p style="text-align: center;"><code class="reqn">
\text{sIDEA}_X(\tilde{\textbf{x}}_S) = \left(\frac{1}{n} \sum_{i = 1}^n
\text{sIDEA}^{(1)}_{\textbf{x}^{(i)}}(\tilde{\textbf{x}}_S), \dots, \frac{1}{n}
\sum_{i = 1}^n \text{sIDEA}^{(k)}_{\textbf{x}^{(i)}}(\tilde{\textbf{x}}_S) \right)
</code>
</p>

<p>where the c-th vector element is the average c-th vector element of local
sIDEA functions. The global hIDEA corresponds to:
</p>
<p style="text-align: center;"><code class="reqn">
\text{hIDEA}_X(\tilde{\textbf{x}}_S) =  \left(\frac{1}{n}\sum_{i = 1}^n
\mathbb{1}_{1}(\text{hIDEA}_{\textbf{x}^{(i)}}(\tilde{\textbf{x}}_S)), \dots,
\frac{1}{n}\sum_{i = 1}^n \mathbb{1}_{k}(\text{hIDEA}_{\textbf{x}^{(i)}}(\tilde{\textbf{x}}_S))\right)
</code>
</p>

<p>where the c-th vector element is the fraction of hard label
reassignments to the c-th cluster.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+ClustPredictor">ClustPredictor</a><br />
The object (created with <code>ClustPredictor$new()</code>) holding
the cluster algorithm and the data.</p>
</dd>
<dt><code>feature</code></dt><dd><p>(<code style="white-space: pre;">&#8288;character or list&#8288;</code>)<br />
Features/ feature sets to calculate the effect curves.</p>
</dd>
<dt><code>method</code></dt><dd><p><code>character(1)</code><br />
The <code>IDEA</code> method to be used.</p>
</dd>
<dt><code>mg</code></dt><dd><p><code>DataGenerator</code><br />
A <code>MarginalGenerator</code> object to sample and generate
the pseudo instances.</p>
</dd>
<dt><code>results</code></dt><dd><p><code>data.table</code><br />
The <code>IDEA</code> results.</p>
</dd>
<dt><code>noise.out</code></dt><dd><p>any <br />
Indicator for the noise variable.</p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>type</code></dt><dd><p>function <br />
Detect the type in the predictor</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-IDEA-new"><code>IDEA$new()</code></a>
</p>
</li>
<li> <p><a href="#method-IDEA-plot"><code>IDEA$plot()</code></a>
</p>
</li>
<li> <p><a href="#method-IDEA-plot_globals"><code>IDEA$plot_globals()</code></a>
</p>
</li>
<li> <p><a href="#method-IDEA-clone"><code>IDEA$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-IDEA-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create an <a href="#topic+IDEA">IDEA</a> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>IDEA$new(predictor, feature, method = "g+l", grid.size = 20L, noise.out = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+ClustPredictor">ClustPredictor</a><br />
The object (created with <code>ClustPredictor$new()</code>) holding
the cluster algorithm and the data.</p>
</dd>
<dt><code>feature</code></dt><dd><p>(<code style="white-space: pre;">&#8288;character or list&#8288;</code>)<br />
For which features do you want importance scores calculated. The default
value of <code>NULL</code> implies all features. Use a named list of character vectors
to define groups of features for which joint importance will be calculated.</p>
</dd>
<dt><code>method</code></dt><dd><p><code>character(1)</code><br />
The <code>IDEA</code> method to be used. Possible choices for the method are:<br />
<code>"g+l"</code> (default): store global and local <code>IDEA</code> results
</p>
<p><code>"local"</code>: store only local <code>IDEA</code> results
</p>
<p><code>"global"</code>: store only global <code>IDEA</code> results
</p>
<p><code>"init_local"</code>: store only local <code>IDEA</code> results and
additional reference for the observations initial
assigned cluster.
</p>
<p><code>"init_g+l"</code> store global and local <code>IDEA</code> results and
additional reference for the observations initial
assigned cluster.</p>
</dd>
<dt><code>grid.size</code></dt><dd><p><code style="white-space: pre;">&#8288;(numeric(1) or NULL)&#8288;</code> <br />
size of the grid to replace values. If grid size is
given, an equidistant grid is create. If <code>NULL</code>, values
are calculated at all present combinations of feature values.</p>
</dd>
<dt><code>noise.out</code></dt><dd><p>any <br />
Indicator for the noise variable. If not NULL, noise will
be excluded from the effect estimation.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(data.frame)<br />
Values for the effect curves: <br />
One row per grid per instance for each local idea
estimation. If <code>method</code> includes global estimation, one
additional row per grid point.
</p>


<hr>
<a id="method-IDEA-plot"></a>



<h4>Method <code>plot()</code></h4>

<p>Plot an <a href="#topic+IDEA">IDEA</a> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>IDEA$plot(c = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>c</code></dt><dd><p>indicator for the cluster to plot. If <code>NULL</code>,
all clusters are plotted.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(ggplot)<br />
A ggplot object that depends on the <code>method</code> chosen.
</p>


<hr>
<a id="method-IDEA-plot_globals"></a>



<h4>Method <code>plot_globals()</code></h4>

<p>Plot the global sIDEA curves of all clusters.
</p>


<h5>Usage</h5>

<div class="r"><pre>IDEA$plot_globals(mass = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>mass</code></dt><dd><p>between 0 and 1. The percentage of local <code>IDEA</code>
curves to plot a certainty interval.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(ggplot)<br />
A ggplot object.
</p>


<hr>
<a id="method-IDEA-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>IDEA$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><a href="iml.html#topic+FeatureEffects">iml::FeatureEffects</a>, <a href="iml.html#topic+FeatureEffects">iml::FeatureEffects</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data and packages
require(factoextra)
require(FuzzyDBScan)
multishapes = as.data.frame(multishapes[, 1:2])
# Set up an train FuzzyDBScan
eps = c(0, 0.2)
pts = c(3, 15)
res = FuzzyDBScan$new(multishapes, eps, pts)
res$plot("x", "y")
# create soft label predictor
predict_prob = function(model, newdata) model$predict(new_data = newdata)
predictor = ClustPredictor$new(res, as.data.frame(multishapes), y = res$results,
                                    predict.function = predict_prob, type = "prob")
# Calculate `IDEA` global and local for feature "x"
idea_x = IDEA$new(predictor = predictor, feature = "x", grid.size = 5)
idea_x$plot_globals(0.5) # plot global effect of all clusters with 50 percent of local mass.

</code></pre>

<hr>
<h2 id='SMART'><code>SMART</code> - Scoring Metric after Permutation</h2><span id='topic+SMART'></span>

<h3>Description</h3>

<p><code>SMART</code> estimates the importance of a feature to the clustering algorithm
by measuring changes in cluster assignments by scoring functions after
permuting selected feature. Cluster-specific <code>SMART</code> indicates the importance
of specific clusters versus the remaining ones, measured by a binary scoring
metric. Global <code>SMART</code> assigns importance scores across all clusters, measured
by a multi-class scoring metric. Currently, <code>SMART</code> can only be used for hard
label predictors.
</p>


<h3>Details</h3>

<p>Let <code class="reqn">M \in \mathbb{N}_0^{k \times k}</code> denote the multi-cluster
confusion matrix and <code class="reqn">M_c \in \mathbb{N}_0^{2 \times 2}</code> the binary
confusion matrix for cluster c versus the remaining clusters. <code>SMART</code> for
feature set S corresponds to:
</p>
<p style="text-align: center;"><code class="reqn">
\text{Multi-cluster scoring:} \quad \text{SMART}(X, \tilde{X}_S) = h_{\text{multi}}(M) \\
\text{Binary scoring:} \quad \text{SMART}(X, \tilde{X}_S) = \text{AVE}(h_{\text{binary}}(M_1), \dots, h_{\text{binary}}(M_k))
</code>
</p>

<p>where <code class="reqn">\text{AVE}</code> averages a vector of binary scores, e.g., via micro or
macro averaging.
In order to reduce variance in the estimate from shuffling the data, one can
shuffle t times and evaluate the distribution of scores. Let <code class="reqn">\tilde{X}_S^{(t)}</code>
denote the t-th shuffling iteration for feature set S. The <code>SMART</code> point
estimate is given by: <br />
</p>
<p style="text-align: center;"><code class="reqn">
\overline{\text{SMART}}(X, \tilde{X}_S) = \psi\left(\text{SMART}(X, \tilde{X}_S^{(1)}),
 \dots, \text{SMART}(X, \tilde{X}_S^{(t)})\right)
</code>
</p>

<p>where <code class="reqn">\psi</code> extracts a sample statistic such as the mean or median or quantile.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>avg</code></dt><dd><p>(<code>character(1)</code> or <code>NULL</code>)<br />
<code>NULL</code> is calculating cluster-specific (binary)
metrics. <code>"micro"</code> summarizes binary scores to a global
score that treats each instance in the data set with equal
importance. <code>"macro"</code> summarizes binary scores to a global
score that treats each cluster with equal importance.</p>
</dd>
<dt><code>metric</code></dt><dd><p><code>character(1)</code><br />
The binary similarity metric used.</p>
</dd>
<dt><code>predictor</code></dt><dd><p><a href="#topic+ClustPredictor">ClustPredictor</a><br />
The object (created with <code>ClustPredictor$new()</code>) holding
the cluster algorithm and the data.</p>
</dd>
<dt><code>data.sample</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
The data, including features and cluster soft/ hard labels.</p>
</dd>
<dt><code>sampler</code></dt><dd><p>any<br />
Sampler from the <code>predictor</code> object.</p>
</dd>
<dt><code>features</code></dt><dd><p>(<code style="white-space: pre;">&#8288;character or list&#8288;</code>)<br />
Features/ feature sets to calculate importance scores.</p>
</dd>
<dt><code>n.repetitions</code></dt><dd><p>(<code>numeric(1)</code>)<br />
How often is the shuffling of the feature repeated?</p>
</dd>
<dt><code>results</code></dt><dd><p>(<code>data.table</code>)<br />
A data.table containing the results from <code>SMART</code> procedure.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-SMART-new"><code>SMART$new()</code></a>
</p>
</li>
<li> <p><a href="#method-SMART-print"><code>SMART$print()</code></a>
</p>
</li>
<li> <p><a href="#method-SMART-plot"><code>SMART$plot()</code></a>
</p>
</li>
<li> <p><a href="#method-SMART-clone"><code>SMART$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-SMART-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a <a href="#topic+SMART">SMART</a> object
</p>


<h5>Usage</h5>

<div class="r"><pre>SMART$new(
  predictor,
  features = NULL,
  metric = "f1",
  avg = NULL,
  n.repetitions = 5
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+ClustPredictor">ClustPredictor</a><br />
The object (created with <code>ClustPredictor$new()</code>) holding
the cluster algorithm and the data.</p>
</dd>
<dt><code>features</code></dt><dd><p>(<code style="white-space: pre;">&#8288;character or list&#8288;</code>)<br />
For which features do you want importance scores calculated. The default
value of <code>NULL</code> implies all features. Use a named list of character vectors
to define groups of features for which joint importance will be calculated.</p>
</dd>
<dt><code>metric</code></dt><dd><p><code>character(1)</code><br />
The binary similarity metric used. Defaults to <code>f1</code>,
where F1 Score is used. Other possible binary scores are
<code>"precision"</code>, <code>"recall"</code>, <code>"jaccard"</code>, <code>"folkes_mallows"</code>
and <code>"accuracy"</code>.</p>
</dd>
<dt><code>avg</code></dt><dd><p>(<code>character(1)</code> or <code>NULL</code>)<br />
Either <code>NULL</code>, <code>"micro"</code> or <code>"macro"</code>.
Defaults to <code>NULL</code> is calculating cluster-specific (binary)
metrics. <code>"micro"</code> summarizes binary scores to a global
score that treats each instance in the data set with equal
importance. <code>"macro"</code> summarizes binary scores to a global
score that treats each cluster with equal importance.
For unbalanced clusters, <code>"macro"</code> is more recommendable.</p>
</dd>
<dt><code>n.repetitions</code></dt><dd><p>(<code>numeric(1)</code>)<br />
How often should the shuffling of the feature be repeated?
The higher the number of repetitions the more stable and
accurate the results become.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(data.frame)<br />
data.frame with the results of the feature importance computation.
One row per feature with the following columns:
For global scores:
</p>

<ul>
<li><p> importance.05 (5% quantile of importance values from the repetitions)
</p>
</li>
<li><p> importance (median importance)
</p>
</li>
<li><p> importance.95 (95% quantile) and the permutation.error (median error
over all repetitions).
For cluster specific scores each column indicates for a different cluster.
</p>
</li></ul>



<hr>
<a id="method-SMART-print"></a>



<h4>Method <code>print()</code></h4>

<p>Print a <code>SMART</code> object
</p>


<h5>Usage</h5>

<div class="r"><pre>SMART$print()</pre></div>



<h5>Returns</h5>

<p><code>character</code> <br />
Information about <code>predictor</code>, <code>data</code>, <code>metric</code>, and <code>avg</code>
and head of the <code>results</code>.
</p>


<hr>
<a id="method-SMART-plot"></a>



<h4>Method <code>plot()</code></h4>

<p>plots the similarity score results of a <code>SMART</code>
object.
</p>


<h5>Usage</h5>

<div class="r"><pre>SMART$plot(log = FALSE, single_cl = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>log</code></dt><dd><p><code>logical(1)</code> <br />
Indicator weather results should be logged. This can be
useful to distinguish the importance if similarity scores
are all close to 1.</p>
</dd>
<dt><code>single_cl</code></dt><dd><p><code>character(1)</code> <br />
Only used for cluster-specific scores (<code>avg = NULL</code>).
Should match one of the cluster names.
In this case, importance scores for a single cluster are
plotted.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>The plot shows the similarity per feature.
For global scores:
When <code>n.repetitions</code> in <code>SMART$new</code> was larger than 1, then we get
multiple similarity estimates per feature. The similarity are aggregated and
the plot shows the median similarity per feature (as dots) and also the
90%-quantile, which helps to understand how much variance the computation has
per feature.
For cluster-specific scores:
Stacks the similarity estimates of all clusters per feature.
Can be used to achieve a global estimate as a sum of
cluster-wise similarities.
</p>



<h5>Returns</h5>

<p>ggplot2 plot object
</p>


<hr>
<a id="method-SMART-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>SMART$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><a href="iml.html#topic+FeatureImp">iml::FeatureImp</a>
</p>
<p><a href="#topic+SMART">SMART</a>
</p>
<p><a href="#topic+SMART">SMART</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data and packages
require(factoextra)
require(FuzzyDBScan)
multishapes = as.data.frame(multishapes[, 1:2])
# Set up an train FuzzyDBScan
eps = c(0, 0.2)
pts = c(3, 15)
res = FuzzyDBScan$new(multishapes, eps, pts)
res$plot("x", "y")
# create hard label predictor
predict_part = function(model, newdata) model$predict(new_data = newdata, cmatrix = FALSE)$cluster
predictor = ClustPredictor$new(res, as.data.frame(multishapes), y = res$clusters,
                               predict.function = predict_part, type = "partition")
# Run SMART globally
macro_f1 = SMART$new(predictor, n.repetitions = 50, metric = "f1", avg = "macro")
macro_f1 # print global SMART
macro_f1$plot(log = TRUE) # plot global SMART
# Run cluster specific SMART
classwise_f1 = SMART$new(predictor, n.repetitions = 50, metric = "f1")
macro_f1 # print regional SMART
macro_f1$plot(log = TRUE) # plot regional SMART

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
