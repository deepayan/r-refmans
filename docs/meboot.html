<!DOCTYPE html><html><head><title>Help for package meboot</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {meboot}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checkConv'><p>Check Convergence</p></a></li>
<li><a href='#elapsedtime'><p>Internal Function</p></a></li>
<li><a href='#expand.sd'><p>Expand the Standard Deviation of Resamples</p></a></li>
<li><a href='#flexMeboot'><p>Flexible Extension of the Maximum Entropy Bootstrap Procedure</p></a></li>
<li><a href='#force.clt'><p>Enforce Central Limit Theorem</p></a></li>
<li><a href='#meboot'><p>Generate Maximum Entropy Bootstrapped Time Series Ensemble</p></a></li>
<li><a href='#meboot.part'><p>meboot Internal Function</p></a></li>
<li><a href='#meboot.pdata.frame'><p>Maximum Entropy Bootstrap for Panel Time Series Data</p></a></li>
<li><a href='#mebootSpear'><p>Generate Maximum Entropy Bootstrapped Time Series Ensemble Specifying Rank Correlation</p></a></li>
<li><a href='#null.ci'><p>Get Confidence Interval Around Specified NullZero Total</p></a></li>
<li><a href='#olsHALL.b'><p>OLS regression model for consumption</p></a></li>
<li><a href='#ullwan'><p>Data about Some of the S&amp;P 500 Stock Prices</p></a></li>
<li><a href='#USconsum'><p>Consumption and Disposable Income Data (Annual 1948-1998)</p></a></li>
<li><a href='#USfygt'><p>Long-term Treasury Bond Rates and Deficit Data Set (Annual 1948-200)</p></a></li>
<li><a href='#zero.ci'><p>Get Confidence Interval Around Zero</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.4-9.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-22</td>
</tr>
<tr>
<td>Title:</td>
<td>Maximum Entropy Bootstrap for Time Series</td>
</tr>
<tr>
<td>Author:</td>
<td>Hrishikesh D. Vinod &lt;Vinod@fordham.edu&gt;, Javier
        LÃ³pez-de-Lacalle &lt;javlacalle@yahoo.es&gt;, and Fred Viole</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fred Viole &lt;fviole@fordham.edu&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), dynlm, nlme, tdigest, hdrcde</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, car, ConvergenceConcepts, geepack, lmtest, strucchange,
plm, zoo</td>
</tr>
<tr>
<td>Description:</td>
<td>Maximum entropy density based dependent data bootstrap. 
  An algorithm is provided to create a population of time series (ensemble) 
  without assuming stationarity. The reference paper (Vinod, H.D., 2004 &lt;<a href="https://doi.org/10.1016%2Fj.jempfin.2003.06.002">doi:10.1016/j.jempfin.2003.06.002</a>&gt;) explains
  how the algorithm satisfies the ergodic theorem and the central limit theorem.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-22 19:51:55 UTC; fredv</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-22 20:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='checkConv'>Check Convergence</h2><span id='topic+checkConv'></span>

<h3>Description</h3>

<p>This function generates a 3D array giving (Xn-X) in the notation of
the <code>ConvergenceConcepts</code> package by Lafaye de Micheaux and Liquet for sample paths
with dimensions <code class="reqn">=</code> <code>n999</code> as first dimension, <code>nover</code> <code class="reqn">=</code> range of n
values as second dimension and number of items in <code>key</code> as the third
dimension.  It is intended to be used for checking convergence of <code>meboot</code> in the context 
of a specific real world time series regression problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkConv (y, bigx, trueb = 1, n999 = 999, nover = 5, 
  seed1 = 294, key = 0, trace = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkConv_+3A_y">y</code></td>
<td>
<p>vector of data containing the dependent variable.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_bigx">bigx</code></td>
<td>
<p>vector of data for all regressor variables in a regression or <code>ts</code> object.
<code>bigx</code> should not include column of ones for the intercept.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_trueb">trueb</code></td>
<td>
<p>true values of regressor coefficients for simulation. If <code>trueb=0</code> then use OLS 
coefficient values rounded to 2 digits as true values of beta for simulation purposes, to be close 
to but not exactly equal to OLS.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_n999">n999</code></td>
<td>
<p>number of replicates to generate in a simulation.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_nover">nover</code></td>
<td>
<p>number of values of n over which convergence calculated.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_seed1">seed1</code></td>
<td>
<p>seed for the random number generator.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_key">key</code></td>
<td>
<p>the subset of key regression coefficient whose convergence is studied
if <code>key=0</code> all coefficients are studied for convergence.</p>
</td></tr>
<tr><td><code id="checkConv_+3A_trace">trace</code></td>
<td>
<p>logical. If <code>TRUE</code>, tracing information on the process is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use this only when lagged dependent variable is absent.
</p>
<p>Warning: <code>key=0</code> might use up too much memory for large regression problems.
</p>
<p>The algorithm first creates data on the dependent variable for a simulation using known 
true values denoted by trueb.  It proceeds to create <code>n999</code> regression problems using the 
seven-step algorithm in <code><a href="#topic+meboot">meboot</a></code> creating <code>n999</code> time series for all variable 
in the simulated regression.  It then creates sample paths over a range of n values for 
coefficients of interest denoted as <code>key</code> (usually a subset of original coefficients). 
For each key coefficient there are <code>n999</code> paths as n increases. If <code>meboot</code> algorithm 
is converging to true values, the value of (Xn-X) based criteria for 
&quot;convergence in probability&quot; and &quot;almost sure convergence&quot; in the notation of the 
<code>ConvergenceConcepts</code> package should decline. 
The decline can be plotted and/or tested to check if it is statistically significant 
as sample size increases. This function permits the user of <code>meboot</code> working with a short 
time series to see if the <code>meboot</code> algorithm is working in his or her particular situation.
</p>


<h3>Value</h3>

<p>A 3 dimensional array giving (Xn-X) for sample paths with dimensions <code class="reqn">=</code> <code>n999</code> 
as first dimension, <code>nover</code> <code class="reqn">=</code> range of n values as second dimension
and number of items in <code>key</code> as the third dimension ready for use in 
<code>ConvergenceConcepts</code> package.
</p>


<h3>References</h3>

<p>Lafaye de Micheaux, P. and Liquet, B. (2009), Understanding Convergence Concepts: 
a Visual-Minded and Graphical Simulation-Based Approach,
<em>The American Statistician</em>, <b>63</b>(2) pp. 173-178.
</p>
<p>Vinod, H.D. (2006), Maximum Entropy Ensembles for Time Series Inference in Economics,
<em>Journal of Asian Economics</em>, <b>17</b>(6), pp. 955-978
</p>
<p>Vinod, H.D. (2004), Ranking mutual funds using unconventional utility theory 
and stochastic dominance, <em>Journal of Empirical Finance</em>, <b>11</b>(3), pp. 353-377.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meboot">meboot</a></code>, <code><a href="ConvergenceConcepts.html#topic+criterion">criterion</a></code>.</p>

<hr>
<h2 id='elapsedtime'>Internal Function</h2><span id='topic+elapsedtime'></span>

<h3>Description</h3>

<p>Internal function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  elapsedtime(ptm1, ptm2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elapsedtime_+3A_ptm1">ptm1</code></td>
<td>
<p><code><a href="base.html#topic+proc.time">proc.time</a></code> object.</p>
</td></tr>
<tr><td><code id="elapsedtime_+3A_ptm2">ptm2</code></td>
<td>
<p><code><a href="base.html#topic+proc.time">proc.time</a></code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List giving the elapsed time between <code>ptm1</code> and <code>ptm2</code>.
</p>

<hr>
<h2 id='expand.sd'>Expand the Standard Deviation of Resamples</h2><span id='topic+expand.sd'></span>

<h3>Description</h3>

<p>This function expands the standard deviation of the simulated data. Expansion is needed since some of the ratios of the actual standard deviation to that of the original data are lower than 1 due to attenuation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    expand.sd (x, ensemble, fiv=5)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expand.sd_+3A_x">x</code></td>
<td>
<p>a vector of data or a time series object.</p>
</td></tr>
<tr><td><code id="expand.sd_+3A_ensemble">ensemble</code></td>
<td>
<p>a matrix or <code>mts</code> object containing resamples of the original data <code>x</code>.</p>
</td></tr>
<tr><td><code id="expand.sd_+3A_fiv">fiv</code></td>
<td>
<p>reference value for the upper limit of a uniform distribution used in expansion. For example, if equal to 5 the standard deviation of each resample is expanded through a value from a uniform random distribution with lower limit equal to 1 and upper limit equal to 1+(5/100)=1.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Resamples (by columns) with expanded standard deviations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    
    set.seed(345)
    out &lt;- meboot(x=AirPassengers, reps=100, trim=0.10, reachbnd=FALSE, elaps=TRUE) 
    exp.ens &lt;- expand.sd(x=AirPassengers, out$ensemble)
  </code></pre>

<hr>
<h2 id='flexMeboot'>Flexible Extension of the Maximum Entropy Bootstrap Procedure</h2><span id='topic+flexMeboot'></span>

<h3>Description</h3>

<p>This function extends the maximum entropy bootstrap procedure
implemented in <code><a href="#topic+meboot">meboot</a></code>
to allow for for a flexible trend up, flat or down.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  flexMeboot (x, reps = 9, segment = 5, forc = FALSE, myseq = seq(-1, 1, by = 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flexMeboot_+3A_x">x</code></td>
<td>
<p>vector of data, <code>ts</code> object.</p>
</td></tr>
<tr><td><code id="flexMeboot_+3A_reps">reps</code></td>
<td>
<p>number of replicates to generate.</p>
</td></tr>
<tr><td><code id="flexMeboot_+3A_segment">segment</code></td>
<td>
<p>block size.</p>
</td></tr>
<tr><td><code id="flexMeboot_+3A_forc">forc</code></td>
<td>
<p>logical. If TRUE the ensemble is forced to satisfy the central limit theorem.
See <code><a href="#topic+force.clt">force.clt</a></code>.</p>
</td></tr>
<tr><td><code id="flexMeboot_+3A_myseq">myseq</code></td>
<td>
<p>directions for trend within a block of data is chosen randomly with the user's choice
limited by the range of values given by myseq. For example, <code>myseq=seq(-1,1,by=0.5)</code>
provides five options for direction changes. If the user specifies any single number
instead of a sequence, (e.g., <code>myseq=1</code>) then <code>flexMeboot</code> will not change the directions
of trends at all, but will modify the original <code>meboot</code> function to resample separately
within several non-overlapping blocks, before joining them into resampled time series.
This may be desirable for long series and for some applications.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>flexMeboot</code> uses non-overlapping blocks having only m observations.
A trend <code class="reqn">a + bt</code> is replaced by <code class="reqn">a + Bt</code>,
where <code>B = sample(myseq) * b</code>.
</p>
<p>Its steps are as follows:
</p>

<ol>
<li><p> Choose block size <code>segment</code> denoted here as <code class="reqn">m</code>
(default equal to <code class="reqn">m=5</code>)
and divide the original time series <code>x</code> of length <code class="reqn">T</code>
into <code class="reqn">k = floor(T/m)</code> blocks or subsets. Note that when
<code class="reqn">T/m</code> is not an integer the <code class="reqn">k</code>-th block will have a few more than
<code class="reqn">m</code> items. Hence let us denote the number of observations in each block as
<code class="reqn">m</code> which equals <code class="reqn">m</code> for most blocks, except the <code class="reqn">k</code>-th.
</p>
</li>
<li><p> Regress each block having m observations as subsets of <code>x</code> on the set
<code class="reqn">\tau = 1, 2,..., m</code>, and store the intercept <code class="reqn">b0</code>,
the slope <code class="reqn">b1</code> of <code class="reqn">\tau</code> and the residuals <code class="reqn">r</code>.
</p>
</li>
<li><p> Note that the positive (negative) sign of the slope <code class="reqn">b1</code> in this regression
determines the up (down) direction of the time series in that block.
Hence the next step of the algorithm replaces <code class="reqn">b1</code> by <code class="reqn">B1 = b1 * w</code>, defined
by a randomly chosen weight <code class="reqn">w in (-1, 0, 1)</code>.
For example, when the random choice yields <code class="reqn">w = -1</code>, the sign of <code class="reqn">b1</code> is
reversed. Our weighting independently injects some limited flexibility
to the directions of values block segments of the original time series.
</p>
</li>
<li><p> Reconstruct all time series blocks as: <code class="reqn">b0 + b1 * w * \tau + r</code>,
by adding back the residual <code class="reqn">r</code> of the regression on <code class="reqn">\tau</code>.
</p>
</li>
<li><p> The next step applies the function <code><a href="#topic+meboot">meboot</a></code> to each
block of time serie-now having a modified trend-and create a large
number, <code class="reqn">J</code>, of resampled time series for each of the <code class="reqn">k</code> blocks.
</p>
</li>
<li><p> Sequentially join the <code class="reqn">J</code> replicates of all <code class="reqn">k</code> blocks or subsets together.
</p>
</li></ol>



<h3>Value</h3>

<p>A matrix containing by columns
the bootstrapped replicated of the original data <code>x</code>.
</p>


<h3>References</h3>

<p>Vinod, H.D. (2012), Constructing Scenarios of Time Heterogeneous Series for Stress Testing,
Available at SSRN: <a href="https://www.ssrn.com/abstract=1987879">https://www.ssrn.com/abstract=1987879</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meboot">meboot</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(235)
myseq &lt;- seq(-1, 1, by = 0.5)
xx &lt;- flexMeboot(x = AirPassengers, myseq = myseq, reps = 3)
matplot(cbind(AirPassengers, xx), type = "l")
</code></pre>

<hr>
<h2 id='force.clt'>Enforce Central Limit Theorem</h2><span id='topic+force.clt'></span>

<h3>Description</h3>

<p>Function to enforce the maximum entropy bootstrap resamples to satisfy the central limit theorem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    force.clt (x, ensemble)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="force.clt_+3A_x">x</code></td>
<td>
<p>a vector of data or a time series object.</p>
</td></tr>
<tr><td><code id="force.clt_+3A_ensemble">ensemble</code></td>
<td>
<p>a matrix or <code>mts</code> object containing resamples of the original data <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Revised matrix satisfying the central limit theorem.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    set.seed(345)
    out &lt;- meboot(x=AirPassengers, reps=100, trim=0.10, reachbnd=FALSE, elaps=TRUE)
    cm1 &lt;- colMeans(out$ensemb)
    # Note that the column means are somewhat non-normal
    qqnorm(cm1)

    clt.ens &lt;- force.clt(x=AirPassengers, ensemble=out$ensemble) 
    cm2 &lt;- colMeans(clt.ens)
    # Note that the columns are closer to being normal
    qqnorm(cm2)

  </code></pre>

<hr>
<h2 id='meboot'>Generate Maximum Entropy Bootstrapped Time Series Ensemble</h2><span id='topic+meboot'></span><span id='topic+meboot-package'></span>

<h3>Description</h3>

<p>Generates maximum entropy bootstrap replicates for dependent data. (See details.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    meboot (x, reps=999, trim=list(trim=0.10, xmin=NULL, xmax=NULL), reachbnd=TRUE,
  expand.sd=TRUE, force.clt=TRUE, scl.adjustment = FALSE, sym = FALSE,
  elaps=FALSE, colsubj, coldata, coltimes, ...)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meboot_+3A_x">x</code></td>
<td>
<p>vector of data, <code>ts</code> object or <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="meboot_+3A_reps">reps</code></td>
<td>
<p>number of replicates to generate.</p>
</td></tr>
<tr><td><code id="meboot_+3A_trim">trim</code></td>
<td>
<p>a list object containing the elements: <code>trim</code>, the trimming proportion;
<code>xmin</code>, the lower limit for left tail and <code>xmax</code>, the upper limit for right tail.</p>
</td></tr>
<tr><td><code id="meboot_+3A_reachbnd">reachbnd</code></td>
<td>
<p>logical. If <code>TRUE</code> potentially reached bounds (xmin = smallest value - trimmed mean and xmax=largest value + trimmed mean) are given when the random draw happens to be equal to 0 and 1, respectively.</p>
</td></tr>
<tr><td><code id="meboot_+3A_expand.sd">expand.sd</code></td>
<td>
<p>logical. If <code>TRUE</code> the standard deviation in the ensemble in expanded. See <code><a href="#topic+expand.sd">expand.sd</a></code>.</p>
</td></tr>
<tr><td><code id="meboot_+3A_force.clt">force.clt</code></td>
<td>
<p>logical. If <code>TRUE</code> the ensemble is forced to satisfy the central limit theorem. See <code><a href="#topic+force.clt">force.clt</a></code>.</p>
</td></tr>
<tr><td><code id="meboot_+3A_scl.adjustment">scl.adjustment</code></td>
<td>
<p>logical. If <code>TRUE</code> scale adjustment is performed
to ensure that the population variance of the transformed series equals the variance of the data.</p>
</td></tr>
<tr><td><code id="meboot_+3A_sym">sym</code></td>
<td>
<p>logical. If <code>TRUE</code> an adjustment is peformed to ensure that the ME density is symmetric.</p>
</td></tr>
<tr><td><code id="meboot_+3A_elaps">elaps</code></td>
<td>
<p>logical. If <code>TRUE</code> elapsed time during computations is displayed.</p>
</td></tr>
<tr><td><code id="meboot_+3A_colsubj">colsubj</code></td>
<td>
<p>the column in <code>x</code> that contains the individual index. It is ignored if the input data <code>x</code> is not a <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="meboot_+3A_coldata">coldata</code></td>
<td>
<p>the column in <code>x</code> that contains the data of the variable to create the ensemble. It is ignored if the input data <code>x</code> is not a <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="meboot_+3A_coltimes">coltimes</code></td>
<td>
<p>an optional argument indicating the column that contains the times at which the observations for each individual are observed. It is ignored if the input data <code>x</code> is not a <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="meboot_+3A_...">...</code></td>
<td>
<p>possible argument <code>fiv</code> to be passed to <code><a href="#topic+expand.sd">expand.sd</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Seven-steps algorithm:
</p>

<ol>
<li><p> Sort the original data in increasing order and store the ordering index vector.
</p>
</li>
<li><p> Compute intermediate points on the sorted series.
</p>
</li>
<li><p> Compute lower limit for left tail (<code>xmin</code>) and upper limit for right tail (<code>xmax</code>). This is done by computing the <code>trim</code> (e.g. 10
</p>
</li>
<li><p> Compute the mean of the maximum entropy density within each interval in such a way that the <em>mean preserving constraint</em> is satisfied. (Denoted as <code class="reqn">m_t</code> in the reference paper.) The first and last interval means have distinct formulas. See Theil and Laitinen (1980) for details.
</p>
</li>
<li><p> Generate random numbers from the [0,1] uniform interval and compute sample quantiles at those points.
</p>
</li>
<li><p> Apply to the sample quantiles the correct order to keep the dependence relationships of the observed data.
</p>
</li>
<li><p> Repeat the previous steps several times (e.g. 999).
</p>
</li></ol>

<p>The scale and symmetry adjustments are described in Vinod (2013) referenced below.
</p>
<p>In some applications, the ensembles must be ensured to be non-negative.
Setting <code>trim$xmin = 0</code> ensures positive values of the ensembles. It also
requires <code>force.clt = FALSE</code> and <code>expand.sd = FALSE</code>. These arguments are
set to <code>FALSE</code> if <code>trim$xmin = 0</code> is defined and a warning is returned
to inform that the value of those arguments were overwritten.
Note: The choice of <code>xmin</code> and <code>xmax</code> cannot be arbitrary and should be
cognizant of <code>range(x)</code> in data. Otherwise, if there are observations outside those
bounds, the limits set by these arguments may not be met.
If the user is concerned only with the trimming proportion, then it can be passed as argument
simply <code>trim = 0.1</code> and the default values for <code>xmin</code> and <code>xmax</code> will be used.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>original data provided as input.</p>
</td></tr>
<tr><td><code>ensemble</code></td>
<td>
<p>maximum entropy bootstrap replicates.</p>
</td></tr>
<tr><td><code>xx</code></td>
<td>
<p>sorted order stats (xx[1] is minimum value).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>class intervals limits.</p>
</td></tr>
<tr><td><code>dv</code></td>
<td>
<p>deviations of consecutive data values.</p>
</td></tr>
<tr><td><code>dvtrim</code></td>
<td>
<p>trimmed mean of dv.</p>
</td></tr>
<tr><td><code>xmin</code></td>
<td>
<p>data minimum for ensemble=xx[1]-dvtrim.</p>
</td></tr>
<tr><td><code>xmax</code></td>
<td>
<p>data x maximum for ensemble=xx[n]+dvtrim.</p>
</td></tr>
<tr><td><code>desintxb</code></td>
<td>
<p>desired interval means.</p>
</td></tr>
<tr><td><code>ordxx</code></td>
<td>
<p>ordered x values.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>scale adjustment to the variance of ME density.</p>
</td></tr>
<tr><td><code>elaps</code></td>
<td>
<p>elapsed time.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Vinod, H.D. (2013), Maximum Entropy Bootstrap Algorithm Enhancements.
<a href="https://www.ssrn.com/abstract=2285041">https://www.ssrn.com/abstract=2285041</a>.
</p>
<p>Vinod, H.D. (2006), Maximum Entropy Ensembles for Time Series Inference in Economics,
<em>Journal of Asian Economics</em>, <b>17</b>(6), pp. 955-978
</p>
<p>Vinod, H.D. (2004), Ranking mutual funds using unconventional utility theory and stochastic dominance, <em>Journal of Empirical Finance</em>, <b>11</b>(3), pp. 353-377.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Ensemble for the AirPassenger time series data
    set.seed(345)
    out &lt;- meboot(x=AirPassengers, reps=100, trim=0.10, elaps=TRUE)

    ## Ensemble for T=5 toy time series used in Vinod (2004)
    set.seed(345)
    out &lt;- meboot(x=c(4, 12, 36, 20, 8), reps=999, trim=0.25, elaps=TRUE)
    mean(out$ens)  # ensemble mean should be close to sample mean 16
  </code></pre>

<hr>
<h2 id='meboot.part'>meboot Internal Function</h2><span id='topic+meboot.part'></span>

<h3>Description</h3>

<p>Internal function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  meboot.part (x, n, z, xmin, xmax, desintxb, reachbnd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meboot.part_+3A_x">x</code></td>
<td>
<p>vector of data, <code>ts</code> object or <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="meboot.part_+3A_n">n</code></td>
<td>
<p>length of <code>x</code>.</p>
</td></tr>
<tr><td><code id="meboot.part_+3A_z">z</code></td>
<td>
<p>class intervals limits.</p>
</td></tr>
<tr><td><code id="meboot.part_+3A_xmin">xmin</code></td>
<td>
<p>lower limit in the left tail.</p>
</td></tr>
<tr><td><code id="meboot.part_+3A_xmax">xmax</code></td>
<td>
<p>upper limit in the left tail</p>
</td></tr>
<tr><td><code id="meboot.part_+3A_desintxb">desintxb</code></td>
<td>
<p>desired inteval means.</p>
</td></tr>
<tr><td><code id="meboot.part_+3A_reachbnd">reachbnd</code></td>
<td>
<p>logical. If TRUE potentially reached bounds (xmin = smallest value - trimmed mean and xmax=largest value + trimmed mean) are given when the random draw happens to be equal to 0 and 1, respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of resampled data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meboot">meboot</a></code>.</p>

<hr>
<h2 id='meboot.pdata.frame'>Maximum Entropy Bootstrap for Panel Time Series Data</h2><span id='topic+meboot.pdata.frame'></span>

<h3>Description</h3>

<p>This function applies the maximum entropy bootstraped in a panel of time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    meboot.pdata.frame (x, reps=999, trim=0.10, reachbnd=TRUE,
      expand.sd=TRUE, force.clt=TRUE, scl.adjustment = FALSE, sym = FALSE, elaps=FALSE,
      colsubj, coldata, coltimes, ...)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meboot.pdata.frame_+3A_x">x</code></td>
<td>
<p>a <code>pdata.frame</code> object containing by columns: the individual index, an optional time index and a panel of time series data.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_reps">reps</code></td>
<td>
<p>number of replicates to generate for each subject in the panel.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_trim">trim</code></td>
<td>
<p>the trimming proportion.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_reachbnd">reachbnd</code></td>
<td>
<p>logical. If <code>TRUE</code> potentially reached bounds (xmin = smallest value - trimmed mean and xmax=largest value + trimmed mean) are given when the random draw happens to be equal to 0 and 1, respectively.
</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_expand.sd">expand.sd</code></td>
<td>
<p>logical. If TRUE the standard deviation in the ensemble in expanded. See <code><a href="#topic+expand.sd">expand.sd</a></code>.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_force.clt">force.clt</code></td>
<td>
<p>logical.If TRUE the ensemble is forced to satisfy the central limit theorem. See <code><a href="#topic+force.clt">force.clt</a></code>.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_scl.adjustment">scl.adjustment</code></td>
<td>
<p>logical. If <code>TRUE</code> scale adjustment is performed 
to ensure that the population variance of the transformed series equals the variance of the data.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_sym">sym</code></td>
<td>
<p>logical. If <code>TRUE</code> an adjustment is peformed to ensure that the ME density is symmetric.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_elaps">elaps</code></td>
<td>
<p>logical. If TRUE elapsed time during computations is displayed.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_colsubj">colsubj</code></td>
<td>
<p>the column in <code>x</code> that contains the individual index.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_coldata">coldata</code></td>
<td>
<p>the column in <code>x</code> that contains the data of the variable to create the ensemble.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_coltimes">coltimes</code></td>
<td>
<p>an optional argument indicating the column that contains the times at which the observations for each individual are observed.</p>
</td></tr>
<tr><td><code id="meboot.pdata.frame_+3A_...">...</code></td>
<td>
<p>possible argument <code>fiv</code> to be passed to <code><a href="#topic+expand.sd">expand.sd</a></code>.</p>
</td></tr>    
</table>


<h3>Details</h3>

<p>The observations in <code>x</code> should be arranged by individuals. The observations for each individual must be sorted by time.
</p>
<p>The argument <code>colsubj</code> can be either a numeric or a character index indicating the individual or the time series to which each observation is related.
</p>
<p>Only one variable can be replicated at a time, <code>coldata</code> must be of length one.
</p>
<p>If the times at which observations are observed is provided specifying the column with the times through the argument <code>coltimes</code>, these times are used only to label the rows of the data.frame returned as output.
</p>


<h3>Value</h3>

<p>A data.frame object of dimension: number of rows of <code>x</code> times number of replicates indicated in <code>reps</code>. The replicates for the panel of data are arranged by columns. Each replicate in each column is sorted with the same order stablished in the input <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meboot">meboot</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Ensemble for a panel of series of stock prices  
    data("ullwan")
    out &lt;- meboot(ullwan, reps=99, colsubj=2, coldata=4)
  </code></pre>

<hr>
<h2 id='mebootSpear'>Generate Maximum Entropy Bootstrapped Time Series Ensemble Specifying Rank Correlation</h2><span id='topic+mebootSpear'></span>

<h3>Description</h3>

<p>Generates maximum entropy bootstrap replicates for dependent data
specifying Spearman rank correlation coefficient between replicates series. (See details.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    mebootSpear (x, reps=999, setSpearman=1, drift=TRUE, trim=0.10,
    xmin=NULL, xmax=NULL, reachbnd=TRUE, expand.sd=TRUE, force.clt=TRUE,
    scl.adjustment = FALSE, sym = FALSE, elaps=FALSE, colsubj, coldata, coltimes,...)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mebootSpear_+3A_x">x</code></td>
<td>
<p>vector of data, <code>ts</code> object or <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_reps">reps</code></td>
<td>
<p>number of replicates to generate.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_setspearman">setSpearman</code></td>
<td>
<p> The default setting <code>setSpearman=1</code> assumes that
the user wants to generate replicates that are perfectly dependent on
original time series.  <code>setSpearman&lt;1</code> admits less perfect
(more realistic for some purposes) dependence.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_drift">drift</code></td>
<td>
<p>logical; <code>TRUE</code> default preserves the drift of the original series.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_trim">trim</code></td>
<td>
<p>the trimming proportion.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_xmin">xmin</code></td>
<td>
<p>the lower limit for left tail.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_xmax">xmax</code></td>
<td>
<p>the upper limit for right tail.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_reachbnd">reachbnd</code></td>
<td>
<p>logical. If <code>TRUE</code> potentially reached bounds (xmin = smallest value - trimmed mean and xmax=largest value + trimmed mean) are given when the random draw happens to be equal to 0 and 1, respectively.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_expand.sd">expand.sd</code></td>
<td>
<p>logical. If <code>TRUE</code> the standard deviation in the ensemble in expanded. See <code><a href="#topic+expand.sd">expand.sd</a></code>.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_force.clt">force.clt</code></td>
<td>
<p>logical. If <code>TRUE</code> the ensemble is forced to satisfy the central limit theorem. See <code><a href="#topic+force.clt">force.clt</a></code>.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_scl.adjustment">scl.adjustment</code></td>
<td>
<p>logical. If <code>TRUE</code> scale adjustment is performed
to ensure that the population variance of the transformed series equals the variance of the data.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_sym">sym</code></td>
<td>
<p>logical. If <code>TRUE</code> an adjustment is peformed to ensure that the ME density is symmetric.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_elaps">elaps</code></td>
<td>
<p>logical. If <code>TRUE</code> elapsed time during computations is displayed.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_colsubj">colsubj</code></td>
<td>
<p>the column in <code>x</code> that contains the individual index. It is ignored if the input data <code>x</code> is not a <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_coldata">coldata</code></td>
<td>
<p>the column in <code>x</code> that contains the data of the variable to create the ensemble. It is ignored if the input data <code>x</code> is not a <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_coltimes">coltimes</code></td>
<td>
<p>an optional argument indicating the column that contains the times at which the observations for each individual are observed. It is ignored if the input data <code>x</code> is not a <code>pdata.frame</code> object.</p>
</td></tr>
<tr><td><code id="mebootSpear_+3A_...">...</code></td>
<td>
<p>possible argument <code>fiv</code> to be passed to <code><a href="#topic+expand.sd">expand.sd</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Seven-steps algorithm:
</p>

<ol>
<li><p> Sort the original data in increasing order and store the ordering index vector.
</p>
</li>
<li><p> Compute intermediate points on the sorted series.
</p>
</li>
<li><p> Compute lower limit for left tail (<code>xmin</code>) and upper limit for right tail (<code>xmax</code>). This is done by computing the <code>trim</code> (e.g. 10
</p>
</li>
<li><p> Compute the mean of the maximum entropy density within each interval in such a way that the <em>mean preserving constraint</em> is satisfied. (Denoted as <code class="reqn">m_t</code> in the reference paper.) The first and last interval means have distinct formulas. See Theil and Laitinen (1980) for details.
</p>
</li>
<li><p> Generate random numbers from the [0,1] uniform interval and compute sample quantiles at those points.
</p>
</li>
<li><p> Apply to the sample quantiles the correct order to keep the dependence relationships of the observed data.
</p>
</li>
<li><p> Repeat the previous steps several times (e.g. 999).
</p>
</li></ol>

<p>The scale and symmetry adjustments are described in Vinod (2013) referenced below.
</p>
<p>In some applications, the ensembles must be ensured to be non-negative.
Setting <code>trim$xmin = 0</code> ensures positive values of the ensembles. It also
requires <code>force.clt = FALSE</code> and <code>expand.sd = FALSE</code>. These arguments are
set to <code>FALSE</code> if <code>trim$xmin = 0</code> is defined and a warning is returned
to inform that the value of those arguments were overwritten.
Note: The choice of <code>xmin</code> and <code>xmax</code> cannot be arbitrary and should be
cognizant of <code>range(x)</code> in data. Otherwise, if there are observations outside those
bounds, the limits set by these arguments may not be met.
If the user is concerned only with the trimming proportion, then it can be passed as argument
simply <code>trim = 0.1</code> and the default values for <code>xmin</code> and <code>xmax</code> will be used.
</p>
<p><code>setSpearman&lt;1</code> is implemented with grid search near the
desired value of the rank correlation coefficient, suggested by Fred Viole, a
Ph.D. student at Fordham University and author of an R package NNS.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>original data provided as input.</p>
</td></tr>
<tr><td><code>ensemble</code></td>
<td>
<p>maximum entropy bootstrap replicates.</p>
</td></tr>
<tr><td><code>xx</code></td>
<td>
<p>sorted order stats (xx[1] is minimum value).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>class intervals limits.</p>
</td></tr>
<tr><td><code>dv</code></td>
<td>
<p>deviations of consecutive data values.</p>
</td></tr>
<tr><td><code>dvtrim</code></td>
<td>
<p>trimmed mean of dv.</p>
</td></tr>
<tr><td><code>xmin</code></td>
<td>
<p>data minimum for ensemble=xx[1]-dvtrim.</p>
</td></tr>
<tr><td><code>xmax</code></td>
<td>
<p>data x maximum for ensemble=xx[n]+dvtrim.</p>
</td></tr>
<tr><td><code>desintxb</code></td>
<td>
<p>desired interval means.</p>
</td></tr>
<tr><td><code>ordxx</code></td>
<td>
<p>ordered x values.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>scale adjustment to the variance of ME density.</p>
</td></tr>
<tr><td><code>elaps</code></td>
<td>
<p>elapsed time.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Vinod, H.D. and Viole, F. (2020), Maximum Entropy Bootstrap and Improved Monte Carlo Simulations.
<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3621614">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3621614</a>.
</p>
<p>Vinod, H.D. (2013), Maximum Entropy Bootstrap Algorithm Enhancements.
<a href="https://www.ssrn.com/abstract=2285041">https://www.ssrn.com/abstract=2285041</a>.
</p>
<p>Vinod, H.D. (2006), Maximum Entropy Ensembles for Time Series Inference in Economics,
<em>Journal of Asian Economics</em>, <b>17</b>(6), pp. 955-978
</p>
<p>Vinod, H.D. (2004), Ranking mutual funds using unconventional utility theory and stochastic dominance, <em>Journal of Empirical Finance</em>, <b>11</b>(3), pp. 353-377.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Ensemble for the AirPassenger time series data
    set.seed(345)
    out &lt;- mebootSpear(x=AirPassengers, reps=100, xmin=0, setSpearman = 0)
    cor(out$rowAvg, AirPassengers, method = "spearman") # rank-correlation should be close to 0
  </code></pre>

<hr>
<h2 id='null.ci'>Get Confidence Interval Around Specified NullZero Total</h2><span id='topic+null.ci'></span>

<h3>Description</h3>

<p>Function to get two sided confidence interval around zero as the true value. Confidence interval is adjusted so that it covers the true zero (1-'level')*100 times. Symmetry is not assumed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    null.ci (x, level=0.95, null.value=0, type=8, ...)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="null.ci_+3A_x">x</code></td>
<td>
<p>a vector of data.</p>
</td></tr>
<tr><td><code id="null.ci_+3A_level">level</code></td>
<td>
<p>confidence level.</p>
</td></tr>
<tr><td><code id="null.ci_+3A_null.value">null.value</code></td>
<td>
<p>a specified value of the null, e.g., 0.</p>
</td></tr>
<tr><td><code id="null.ci_+3A_type">type</code></td>
<td>
<p>type of quantile, a number between 1 and 9. See <code><a href="stats.html#topic+quantile">quantile</a></code>.</p>
</td></tr>
<tr><td><code id="null.ci_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lower limit and upper limit of the confidence interval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    x &lt;- runif(25, 0, 1)
    null.ci(x)
  </code></pre>

<hr>
<h2 id='olsHALL.b'>OLS regression model for consumption</h2><span id='topic+olsHALL.b'></span>

<h3>Description</h3>

<p>Compute OLS coefficients in a regression model for the consumption variable. 
See details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    olsHALL.b (y, x)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="olsHALL.b_+3A_y">y</code></td>
<td>
<p>dependent variable (consumption).</p>
</td></tr>
<tr><td><code id="olsHALL.b_+3A_x">x</code></td>
<td>
<p>regressor variable (disposable income).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The regression model is: c(t) = b1 + b2*c(t) + b3*y(t-1) + u(t), where
'c' is consumption and 'y' is disposable income.
</p>
<p>This function is intended to speed up the ME bootstrap procedure
for inference. Instead of using the <code>lm</code> or <code>dynlm</code> interfaces the 
function calls directly to the Fortran procedure 'dqrls'.
</p>


<h3>Value</h3>

<p>Coeffient estimates by OLS.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    data("USconsum")
    USconsum &lt;- log(USconsum)

    # lm interface 
    lmcf1 &lt;- lm(USconsum[-1,1] ~ USconsum[-51,1] + USconsum[-51,2])
    coefficients(lmcf1)
 
    # dynlm interface 
    library("dynlm")
    lmcf2 &lt;- dynlm(consum ~ L(consum, 1) + L(dispinc, 1), data=USconsum)
    coefficients(lmcf2)

    # olsHALL.b
    olsHALL.b(y=USconsum[,1], x=USconsum[,2])
  </code></pre>

<hr>
<h2 id='ullwan'>Data about Some of the S&amp;P 500 Stock Prices</h2><span id='topic+ullwan'></span>

<h3>Description</h3>

<p>This data set collects information about seven S&amp;P 500 stocks whose market capitalizaiton exceeds $27 billion. The seven companies are labelled as ABT, AEG, ATI, ALD, ALL, AOL and AXP. For each company data from May 1993 to November 1997 are available (469 observations).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>      data (ullwan)
   </code></pre>


<h3>Format</h3>

<p>The data are stored in an object of classes <code>pdata.frame</code> (a data.frame class with further attributes useful for panel data from the <code>plm</code> package) and <code>data.frame</code>.
</p>


<h3>Details</h3>

<p>The following information is contained by columns:
</p>

<ul>
<li> <p><code>Subj</code>: Company index.
</p>
</li>
<li> <p><code>Tim</code>: Times at which the data where observed (on a monthly basis).
</p>
</li>
<li> <p><code>MktVal</code>: Market capitalization.
</p>
</li>
<li> <p><code>Price</code>: Stock prices.
</p>
</li>
<li> <p><code>Pupdn</code>: Binary variable, takes the value 1 if there is a turning point (a switch from a bull to a bear market or vice versa) and 0 otherwise.
</p>
</li>
<li> <p><code>Tb3</code>: Interest on 3-month Treasury bills.
</p>
</li></ul>



<h3>Source</h3>

<p>Compustat database.</p>


<h3>References</h3>

<p>Yves Croissant (2005). plm: Linear models for panel data. R package version 0.1-2.
</p>

<hr>
<h2 id='USconsum'>Consumption and Disposable Income Data (Annual 1948-1998)</h2><span id='topic+USconsum'></span>

<h3>Description</h3>

<p>Data set employed in Murray (2006, pp.46-47, 799-801) to discuss the Keynesian consumption function on the basis of the Friedman's permanent income hypothesis and Robert Hall's model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>      data (USconsum)
   </code></pre>


<h3>Format</h3>

<p>A .rda file storing the data as an <code>mts</code> object.</p>


<h3>Details</h3>

<p>Annual data. Available time series: (Each corresponding label in the list object appears in quotes.)
</p>

<ul>
<li> <p><code>consum</code>: consumption per capita in thousands of dollars (1948-1998). Log of this variable is the dependent variable and its lagged value is a regressor in Murray's Table 18.1. 
</p>
</li>
<li> <p><code>dispinc</code>: disposable income per capita in thousands of dollars (1948-1998).  Lagged value of the Log of this variable is the second regressor (proxy for permanent income) in Murray's Table 18.1.
</p>
</li></ul>



<h3>Source</h3>

<p>Robert Hall's data for 1948 to 1977 extended by Murray to 1998 by using standard sources for US macroeconomic data from government publications (U.S. Bureau of Labor Statistics for population data, U.S. Bureau of Economic Analysis for income data, U.S. Bureau of Labor Statistics for consumption data).
</p>


<h3>References</h3>

<p>Murray, M.P. (2006), <em>Econometrics. A modern introduction</em>, New York: Pearson Addison Wesley.
</p>

<hr>
<h2 id='USfygt'>Long-term Treasury Bond Rates and Deficit Data Set (Annual 1948-200)</h2><span id='topic+USfygt'></span>

<h3>Description</h3>

<p>Data set employed in Murray (2006, pp.795-797) to test the null hypothesis that per capita federal deficits explain long-term Treasury bond interest rates based on the Stock and Watson's dynamic OLS model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>      data (USfygt)
   </code></pre>


<h3>Format</h3>

<p>A .rda file storing the data as an <code>mts</code> object.</p>


<h3>Details</h3>

<p>Annual data. Available time series: (Each corresponding label in the list object appears in quotes.)
</p>

<ul>
<li><p> &quot;dy&quot;: mean changes in real per capita income (1949-1998).
</p>
</li>
<li><p> &quot;fygt1&quot;: shorth-term (one-year) Treasury bond interest rates (1953-1998).
</p>
</li>
<li><p> &quot;fygt10&quot;: long-term (ten-year) Treasury bond interest rates (1953-2000).
</p>
</li>
<li><p> &quot;infl&quot;: inflation (1949-2000).
</p>
</li>
<li><p> &quot;usdef&quot;: per capita real federal deficit (1948-2000).
</p>
</li>
<li><p> &quot;reallir&quot;: real long term interest rates (not used in Murray's Table 18.12).
</p>
</li>
<li><p> &quot;realsir&quot;: real short term interest rates (not used in Murray's Table 18.12).
</p>
</li></ul>



<h3>Source</h3>

<p>Data was made available by James Stock and Mark Watson to readers of their famous Econometrica paper, 1993, 61, pp 783-820, who in turn used standard sources for US macroeconomic data from government publications.
</p>


<h3>References</h3>

<p>Murray, M.P. (2006), <em>Econometrics. A modern introduction</em>, New York: Pearson Addison Wesley.
</p>

<hr>
<h2 id='zero.ci'>Get Confidence Interval Around Zero</h2><span id='topic+zero.ci'></span>

<h3>Description</h3>

<p>Function to get two sided confidence interval around zero as the true value. Confidence interval is adjusted so that it covers the true zero (1-'confl')*100 times. Symmetry is not assumed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    zero.ci (x, confl=0.05)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zero.ci_+3A_x">x</code></td>
<td>
<p>a vector of data.</p>
</td></tr>
<tr><td><code id="zero.ci_+3A_confl">confl</code></td>
<td>
<p>confidence level.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>bnlo</code></td>
<td>
<p>count of number of items below lower limit.</p>
</td></tr>
<tr><td><code>bnup</code></td>
<td>
<p>count of number of items above upper limit.</p>
</td></tr>
<tr><td><code>lolim</code></td>
<td>
<p>lower limit of the confidence interval.</p>
</td></tr>
<tr><td><code>uplim</code></td>
<td>
<p>upper limit of the confidence interval.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>    x &lt;- runif(25, 0, 1)
    zero.ci(x)
  </code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
