<!DOCTYPE html><html><head><title>Help for package Markovchart</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Markovchart}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#diabetes'>
<p>Pseudonymised and randomised time series dataset of diabetes patients for control chart applications</p></a></li>
<li><a href='#LDL'>
<p>Aggregated low-density-lipoprotein patient data for control chart applications</p></a></li>
<li><a href='#Markovchart'>
<p>Cost-efficient X-bar control charts with fixed/random shift size, random repair and random sampling time.</p></a></li>
<li><a href='#Markovsim'>
<p>Progression and monitoring simulation of a process with random shift size, random repair and random sampling time.</p></a></li>
<li><a href='#Markovstat'>
<p>Stationary distribution calculation for processes with fixed/random shift size, random repair and random sampling time.</p></a></li>
<li><a href='#plot.Markov_grid'>
<p>Contour plot for <code>Markov_grid</code> control chart results.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Markov Chain-Based Cost-Optimal Control Charts</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.5</td>
</tr>
<tr>
<td>Author:</td>
<td>Balazs Dobi &amp; Andras Zempleni</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Balazs Dobi &lt;dobibalazs@inf.elte.hu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for cost-optimal control charts with a focus on health care applications. Compared to assumptions in traditional control chart theory, here, we allow random shift sizes, random repair and random sampling times. The package focuses on X-bar charts with a sample size of 1 (representing the monitoring of a single patient at a time). The methods are described in Zempleni et al. (2004) &lt;<a href="https://doi.org/10.1002%2Fasmb.521">doi:10.1002/asmb.521</a>&gt;, Dobi and Zempleni (2019) &lt;<a href="https://doi.org/10.1002%2Fqre.2518">doi:10.1002/qre.2518</a>&gt; and Dobi and Zempleni (2019) <a href="http://ac.inf.elte.hu/Vol_049_2019/129_49.pdf">http://ac.inf.elte.hu/Vol_049_2019/129_49.pdf</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, kableExtra, gridExtra, reshape2, zoo</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, parallel, doParallel, optimParallel, foreach, ggplot2,
metR</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-09 16:43:31 UTC; Bazsi</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-09 23:22:36 UTC</td>
</tr>
</table>
<hr>
<h2 id='diabetes'>
Pseudonymised and randomised time series dataset of diabetes patients for control chart applications
</h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>Pseudonymised and randomised time series data of 800 patients. The patients are divided into two main groups by therapy type: insulin analogues (artificial insulins) and glucagon-like peptides (GLP, promotes insulin secretion). The patients' well-being is indicated by the blood sugar (more accurately, the glicated haemoglobin - HbA1c) level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("diabetes")</code></pre>


<h3>Format</h3>

<p>A data frame with 87598 observations on the following 11 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>Patient ID</p>
</dd>
<dt><code>DATE</code></dt><dd><p>Date of the sampling/observation</p>
</dd>
<dt><code>AGE</code></dt><dd><p>Age of the patient</p>
</dd>
<dt><code>THERAPY</code></dt><dd><p>Therapy type</p>
</dd>
<dt><code>THERAPY_COST_EUR</code></dt><dd><p>Therapy cost</p>
</dd>
<dt><code>HEALTHCARE_BURDEN_EUR</code></dt><dd><p>Event (e.g. heart attack) cost for the health care provider</p>
</dd>
<dt><code>HBA1C_AVG</code></dt><dd><p>Blood sugar average for the 30-day sampling cycle</p>
</dd>
<dt><code>HBA1C_SD</code></dt><dd><p>Blood sugar standard deviation for the 30-day sampling cycle</p>
</dd>
<dt><code>SAMPLING_IN_MONTH</code></dt><dd><p>Number of sampling for the 30-day sampling cycle</p>
</dd>
<dt><code>ICD</code></dt><dd><p>Diabetes diagnosis type (International Classification of Diseases)</p>
</dd>
<dt><code>THERAPY_VECTOR</code></dt><dd><p>Therapy vector of the patient, i.e. taking into account the time the therapy lasts after initiation</p>
</dd>
</dl>



<h3>Details</h3>

<p>The example data focuses on two therapy types: insulin analogues (artificial insulins) and glucagon-like peptides (GLP, promotes insulin secretion). Of course there are more treatment types, the database also lists oral antidiabetics (OAD) and human insulins, but we choose to make the data simpler by focusing on GLP and analogue therapies. For the sake of comparison the therapies are grouped in this way: the first group is insulin analogues with possible parallel OAD therapies but human insulin and GLP excluded. The second group is GLP therapies with possible parallel OAD and insulin analogue therapies but human insulin excluded. Essentially we are comparing the effect and cost of insulin analogues with the effect and cost of additional GLP therapies. For cost calculations, the 2021 March 21 EUR-HUF exchange rate was used (1 EUR = 369.05 HUF).
</p>
<p>The example below contains a lengthy code which exemplifies the process of gathering useful data for control chart use. Detailed application of this data can be found in the package's vignette.
</p>


<h3>Source</h3>

<p>The original dataset is based on a month-aggregated time series data of diabetic patients from Hungary which was gathered from the period of 2007 September - 2017 September. The data came from two sources: the National Health Insurance Fund of Hungary and the South-Pest Central Hospital. The first source provided information about diagnoses, treatments, health care event and related costs while the latter provided laboratory data regarding blood sugar level. Patients with International Classification of Diseases (ICD) codes (diagnosis) of E10, E11 and E14, and at least one blood sugar measurement were included initially. Only the data of patients with at least one E11 (type II diabetes) diagnosis in the study period was kept. An additional homogenising filter was the requirement of age above 40 at the time of the first diagnosis. Disease progression and therapy effectiveness estimation required at least two blood sugar (HbA1c) measurements with simultaneous therapy data. A total of 4434 patients satisfied all conditions out of which 2151 had at least two HbA1c measurements.
</p>


<h3>References</h3>

<p>https://ecmiindmath.org/2019/08/19/markov-chain-based-cost-optimal-control-charts/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("diabetes")
str(diabetes)

## Not run: 
##### Example of data assessment for control chart use #####
### Packages
require(zoo)
require(reshape2)

RANDOMISED_DATA &lt;- diabetes

### Functions
weighted.var &lt;- function(x, w, na.rm = FALSE) {
    if (na.rm) {
        w &lt;- w[i &lt;- !is.na(x)]
        x &lt;- x[i]
    }
    sum.w &lt;- sum(w)
    sum.w2 &lt;- sum(w^2)
    mean.w &lt;- sum(x * w) / sum(w)
    (sum.w / (sum.w^2 - sum.w2)) * sum(w * (x - mean.w)^2, na.rm =
na.rm)
}

estBetaParams &lt;- function(mu, var) {
  alpha &lt;- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta &lt;- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}

### Setting up data
# Way too high HbA1C levels are discarded as outliers
RANDOMISED_DATA$HBA1C_AVG[RANDOMISED_DATA$HBA1C_AVG&gt;20 &amp; !is.na(RANDOMISED_DATA$HBA1C_AVG)] &lt;- NA

# Lowest HbA1c level taken into account
lowest &lt;- 4

### Gathering data for several estimates
RANDOMISED_DATA &lt;- RANDOMISED_DATA[RANDOMISED_DATA$ID %in%
RANDOMISED_DATA$ID[grepl("E11",RANDOMISED_DATA$ICD)],]

# Process standard deviation
sigma_param &lt;- sigma &lt;- sqrt(weighted.mean((RANDOMISED_DATA$HBA1C_SD[
RANDOMISED_DATA$SAMPLING_IN_MONTH&gt;=2 &amp; !is.na(RANDOMISED_DATA$SAMPLING_IN_MONTH)])^2,
RANDOMISED_DATA$SAMPLING_IN_MONTH[RANDOMISED_DATA$SAMPLING_IN_MONTH&gt;=2 &amp;
!is.na(RANDOMISED_DATA$SAMPLING_IN_MONTH)]))

IDLIST &lt;- unique(RANDOMISED_DATA$ID[!is.na(RANDOMISED_DATA$HBA1C_AVG)][
duplicated(RANDOMISED_DATA$ID[!is.na(RANDOMISED_DATA$HBA1C_AVG)])])
IDLIST &lt;- unique(RANDOMISED_DATA$ID[(RANDOMISED_DATA$ID %in% IDLIST) &amp; RANDOMISED_DATA$AGE&gt;39])

shiftdat &lt;- NULL
stimedat &lt;- NULL
repaidat &lt;- NULL
deltats  &lt;- NULL
deltaATC &lt;- NULL
for(i in IDLIST)
{
	smalldat    &lt;- RANDOMISED_DATA[RANDOMISED_DATA$ID==i,c("DATE","HBA1C_AVG","THERAPY_VECTOR")]
	smalldat    &lt;- smalldat[!is.na(smalldat$DATE) &amp; !is.na(smalldat$HBA1C_AVG),]
	patshiftdat &lt;- as.data.frame(cbind(i,smalldat$DATE[2:dim(smalldat)[1]],diff(smalldat$DATE),
	diff(smalldat$HBA1C_AVG))[diff(smalldat$HBA1C_AVG)&gt;2*sigma,,drop=FALSE])
	if(dim(patshiftdat)[1]&gt;1) stimedat &lt;- rbind(stimedat,cbind(i,diff(as.Date(patshiftdat$V2))))
	patrepaidat &lt;- as.data.frame(cbind(i,diff(smalldat$DATE),(smalldat$HBA1C_AVG-lowest)[2:
    length(smalldat$HBA1C_AVG)]/(smalldat$HBA1C_AVG-lowest)[1:(length(smalldat$HBA1C_AVG)-1)],
		as.character(smalldat$THERAPY_VECTOR[1:(length(smalldat$THERAPY_VECTOR)-1)]))[
		(which(diff(smalldat$HBA1C_AVG)&lt;(-2*sigma) &amp;
		smalldat$HBA1C_AVG[1:(length(smalldat$HBA1C_AVG)-1)]&gt;6 &amp;
		smalldat$HBA1C_AVG[1:(length(smalldat$HBA1C_AVG)-1)]&lt;=20)),,drop=FALSE])

	shiftdat &lt;- rbind(shiftdat,patshiftdat)
	repaidat &lt;- rbind(repaidat,patrepaidat)
	deltats  &lt;- rbind(deltats,cbind(i,diff(as.Date(RANDOMISED_DATA$DATE[
	!is.na(RANDOMISED_DATA$HBA1C_AVG) &amp; RANDOMISED_DATA$ID==i]))))
	try(deltaATC &lt;- rbind(deltaATC,cbind(i,diff(as.Date(RANDOMISED_DATA$DATE[
	!is.na(RANDOMISED_DATA$THERAPY) &amp; RANDOMISED_DATA$ID==i])))), silent=TRUE)
}
colnames(shiftdat) &lt;- c("ID","TIME","TIMEDIFF","SHIFTSIZE")
colnames(deltats)  &lt;- c("ID","DeltaT")
colnames(deltaATC) &lt;- c("ID","deltaATC")

# delta: expected shift size
delta_param &lt;- mean(shiftdat$SHIFTSIZE[shiftdat$TIMEDIFF&gt;=90 &amp; shiftdat$TIMEDIFF&lt;184])

# Empirical distribution of elapsed times (between samplings)
summary(deltats[,2])
mean(deltats[,2])
median(deltats[,2])
sd(deltats[,2])

# s: expected number of shifts per unit time
stimedat           &lt;- as.data.frame(stimedat)
colnames(stimedat) &lt;- c("ID","TIMEDIFF")
s_param            &lt;- 1/mean(stimedat$TIMEDIFF[stimedat$TIMEDIFF&lt;367])

# alphas, betas: therapy effectiveness parameters
colnames(repaidat) &lt;- c("ID","TIMEDIFF","REMAIN","THERAP")
repaidat$REMAIN    &lt;- as.numeric(as.character(repaidat$REMAIN))
repaidat$TIMEDIFF  &lt;- as.numeric(as.character(repaidat$TIMEDIFF))
repaidat$THERAP    &lt;- as.character(repaidat$THERAP)
repaidat           &lt;- repaidat[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184,]
repaidat$REMAIN[repaidat$REMAIN&lt;0] &lt;- 0

ther_eff &lt;- as.data.frame(rbind(
cbind("ANALOGUE",repaidat$REMAIN[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184 &amp;
grepl("ANALOGUE",repaidat$THERAP) &amp; !grepl("-H",repaidat$THERAP) &amp; !grepl("GLP",repaidat$THERAP)]),
cbind("GLP",repaidat$REMAIN[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184 &amp;
grepl("GLP",repaidat$THERAP) &amp; !grepl("-H",repaidat$THERAP)])))
ther_eff[,1]       &lt;- factor(ther_eff[,1], levels = c("ANALOGUE", "GLP"))
ther_eff[,2]       &lt;- as.numeric(as.character(ther_eff[,2]))
colnames(ther_eff) &lt;- c("Type","Effectiveness")

ANALOGUE &lt;- estBetaParams(mean(repaidat$REMAIN[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184 &amp;
grepl("ANALOGUE",repaidat$THERAP) &amp; !grepl("-H",repaidat$THERAP) &amp; !grepl("GLP",repaidat$THERAP)]),
			 var(repaidat$REMAIN[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184 &amp;
			 grepl("ANALOGUE",repaidat$THERAP) &amp; !grepl("-H",repaidat$THERAP) &amp;
			 !grepl("GLP",repaidat$THERAP)]))
GLP &lt;- estBetaParams(mean(repaidat$REMAIN[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184 &amp;
                       grepl("GLP",repaidat$THERAP) &amp; !grepl("-H",repaidat$THERAP)]),
                     var(repaidat$REMAIN[repaidat$TIMEDIFF&gt;=90 &amp; repaidat$TIMEDIFF&lt;184 &amp;
                       grepl("GLP",repaidat$THERAP) &amp; !grepl("-H",repaidat$THERAP)]))

### Repair cost
HBA1C_fill &lt;- NULL
for (i in unique(RANDOMISED_DATA$ID[!is.na(RANDOMISED_DATA$HBA1C_AVG)]))
{
  vec &lt;- RANDOMISED_DATA$HBA1C_AVG[RANDOMISED_DATA$ID==i]
  vec[which(is.na(vec))[which(is.na(vec))&lt;which(!is.na(vec))[1]]] &lt;- vec[which(!is.na(vec))[1]]
  vec[which(is.na(vec))[which(is.na(vec))&gt;which(!is.na(vec))[length(which(!is.na(vec)))]]] &lt;-
    vec[which(!is.na(vec))[length(which(!is.na(vec)))]]
  vec &lt;- na.approx(vec)
  HBA1C_fill &lt;- rbind(HBA1C_fill,cbind(i,vec))

  smaldat &lt;- RANDOMISED_DATA[RANDOMISED_DATA$ID==i,]
  smaldat$THERAPY_COST_EUR[smaldat$THERAPY_COST_EUR==0 &amp; smaldat$THERAPY_VECTOR!=""] &lt;- NA
  if(is.na(smaldat$THERAPY_COST_EUR[1])) smaldat$THERAPY_COST_EUR[1]                 &lt;- 0
  new_burden &lt;- na.locf(smaldat$THERAPY_COST_EUR)

  seged                     &lt;- cbind(rle(is.na(smaldat$THERAPY_COST_EUR))[[2]],
                                     rle(is.na(smaldat$THERAPY_COST_EUR))[[1]])
  seged[,2][seged[,1]==0]   &lt;- seged[,2][seged[,1]==0]-1
  seged[,2][seged[,1]==1]   &lt;- seged[,2][seged[,1]==1]+1
  if(seged[length(seged[,1]),1]==0) seged[length(seged[,2]),2] &lt;- seged[length(seged[,2]),2]+1
  seged2                    &lt;- cbind(rep(seged[,1], seged[,2]),rep(seged[,2], seged[,2]))
  new_burden[seged2[,1]==1] &lt;- new_burden[seged2[,1]==1]/seged2[,2][seged2[,1]==1]

  RANDOMISED_DATA$THERAPY_COST_EUR[RANDOMISED_DATA$ID==i]	&lt;-	new_burden
}

RANDOMISED_DATA$HBA1C_fill &lt;- NA
RANDOMISED_DATA$HBA1C_fill[RANDOMISED_DATA$ID%in%HBA1C_fill[,1]] &lt;- HBA1C_fill[,2]
RANDOMISED_DATA$HBA1C_fill_filter &lt;- RANDOMISED_DATA$HBA1C_fill
RANDOMISED_DATA$HBA1C_fill_filter[RANDOMISED_DATA$HBA1C_fill_filter&gt;=10] &lt;- NA

discparam    &lt;-	150
cutHBA1C_AVG &lt;-	cut(na.omit(RANDOMISED_DATA$HBA1C_fill_filter),breaks=discparam)
newlvls      &lt;-	seq(min(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)),
                    max(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)),
                    (max(na.omit(RANDOMISED_DATA$HBA1C_fill_filter))-
                      min(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)))/discparam)[1:discparam] +
                    (max(na.omit(RANDOMISED_DATA$HBA1C_fill_filter))-
                      min(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)))/discparam/2
levels(cutHBA1C_AVG) &lt;- newlvls
costs                &lt;- cbind(as.numeric(as.character(cutHBA1C_AVG)),
                               RANDOMISED_DATA$THERAPY_COST_EUR[!is.na(
                               RANDOMISED_DATA$HBA1C_fill_filter)]/30,
                               as.character(RANDOMISED_DATA$THERAPY[
                               !is.na(RANDOMISED_DATA$HBA1C_fill_filter)]))
costs           &lt;- as.data.frame(costs)
colnames(costs)	&lt;- c("HBA1C","HC_BURDEN","THERAP")
costs$HBA1C     &lt;- as.numeric(as.character(costs$HBA1C))
costs$HC_BURDEN	&lt;- as.numeric(as.character(costs$HC_BURDEN))
costs$THERAP    &lt;- as.character(costs$THERAP)

costs$THERAP[grepl("ANALOGUE", costs$THERAP) &amp; !grepl("GLP", costs$THERAP)] &lt;- "ANALOGUE"
costs$THERAP[grepl("GLP",costs$THERAP)]                                     &lt;- "GLP"

cost.ANALOGUE &lt;- as.data.frame(cbind(sort(unique(costs$HBA1C[costs$THERAP=="ANALOGUE"])),
                                as.numeric(tapply(costs$HC_BURDEN[costs$THERAP=="ANALOGUE"],
                                  costs$HBA1C[costs$THERAP=="ANALOGUE"],mean))))
colnames(cost.ANALOGUE) &lt;- c("HBA1C","HC_BURDEN")

cost.GLP &lt;-	as.data.frame(cbind(sort(unique(costs$HBA1C[costs$THERAP=="GLP"])),
                            as.numeric(tapply(costs$HC_BURDEN[costs$THERAP=="GLP"],
                              costs$HBA1C[costs$THERAP=="GLP"],mean))))
colnames(cost.GLP) &lt;-	c("HBA1C","HC_BURDEN")

## ANALOGUE therapy
# Mean
cost.ANALOGUE           &lt;- na.omit(as.data.frame(cbind(as.numeric(
                                     costs$HBA1C[costs$THERAP=="ANALOGUE"]),
                                     costs$HC_BURDEN[costs$THERAP=="ANALOGUE"])))
colnames(cost.ANALOGUE) &lt;- c("HBA1C","HC_BURDEN")
cost.ANALOGUE           &lt;- cost.ANALOGUE[order(cost.ANALOGUE$HBA1C),]
cost.ANALOGUE           &lt;- cost.ANALOGUE[cost.ANALOGUE$HBA1C&gt;lowest,]
cost.ANALOGUE$HBA1C     &lt;- cost.ANALOGUE$HBA1C-min(lowest)

# Fit non-linear model
mod.ANALOGUE &lt;- nls(HC_BURDEN ~  a + b/(HBA1C + c),
                    start = list(a = 5, b = -5, c = 1), cost.ANALOGUE,
                    control = list(maxiter = 50000, minFactor = 0.000000000000001))

cost_ANALOGUE_plotdat &lt;- cbind("ANALOGUE",as.data.frame(cbind(seq(0,6,6/99),
                                predict(mod.ANALOGUE,
                                 newdata=data.frame(HBA1C = seq(0,6,6/99))))))

# Variance
cost_var.ANALOGUE  &lt;- na.omit(as.data.frame(cbind(sort(unique(
                               costs$HBA1C[costs$THERAP=="ANALOGUE"])),
                               as.numeric(tapply(costs$HC_BURDEN[costs$THERAP=="ANALOGUE"],
                               costs$HBA1C[costs$THERAP=="ANALOGUE"],var)))))
colnames(cost_var.ANALOGUE)	&lt;- c("HBA1C","HC_BURDEN")
cost_var.ANALOGUE           &lt;- cost_var.ANALOGUE[cost_var.ANALOGUE$HBA1C&gt;lowest,]
cost_var.ANALOGUE$HBA1C     &lt;- cost_var.ANALOGUE$HBA1C-min(lowest)

# Fit non-linear model
mod_var.ANALOGUE &lt;- nls(HC_BURDEN ~  a + b/(HBA1C + c),
                        start = list(a = 5, b = -3, c = 0.1),
                        cost_var.ANALOGUE[cost_var.ANALOGUE$HBA1C&lt;10-lowest,],
                        control = list(maxiter = 50000, minFactor = 0.000000000000001))

cost_ANALOGUE_plotdat &lt;- cbind(cost_ANALOGUE_plotdat,
                               cost_ANALOGUE_plotdat[,3] -
                                 sqrt(predict(mod_var.ANALOGUE,
                                   newdata=data.frame(HBA1C = seq(0,6,6/99)))),
                               cost_ANALOGUE_plotdat[,3] +
                                 sqrt(predict(mod_var.ANALOGUE,
                                   newdata=data.frame(HBA1C = seq(0,6,6/99)))))
colnames(cost_ANALOGUE_plotdat) &lt;- c("Data","HbA1c","Therapy cost","low","high")

## GLP
# Mean
cost.GLP           &lt;- na.omit(as.data.frame(cbind(as.numeric(
                                costs$HBA1C[costs$THERAP=="GLP"]),
                                costs$HC_BURDEN[costs$THERAP=="GLP"])))
colnames(cost.GLP) &lt;- c("HBA1C","HC_BURDEN")
cost.GLP           &lt;- cost.GLP[order(cost.GLP$HBA1C),]
cost.GLP           &lt;- cost.GLP[cost.GLP$HBA1C&gt;lowest,]
cost.GLP$HBA1C     &lt;- cost.GLP$HBA1C-min(lowest)

# Simple linear
mod.GLP &lt;- nls(HC_BURDEN ~ a + b * HBA1C,
               start = list(a = 1, b = 1), cost.GLP,
               control = list(maxiter = 50000, minFactor = 0.000000000000001))

cost_GLP_plotdat &lt;-	cbind("GLP",as.data.frame(cbind(seq(0,6,6/99),
                     predict(mod.GLP, newdata=data.frame(HBA1C = seq(0,6,6/99))))))

# Variance
cost_var.GLP           &lt;- na.omit(as.data.frame(cbind(sort(unique(
                                   costs$HBA1C[costs$THERAP=="GLP"])),
                                   as.numeric(tapply(costs$HC_BURDEN[costs$THERAP=="GLP"],
                                   costs$HBA1C[costs$THERAP=="GLP"],var)))))
colnames(cost_var.GLP) &lt;- c("HBA1C","HC_BURDEN")
cost_var.GLP           &lt;- cost_var.GLP[cost_var.GLP$HBA1C&gt;lowest,]
cost_var.GLP$HBA1C     &lt;- cost_var.GLP$HBA1C-min(lowest)

# Simple linear
mod_var.GLP &lt;- nls(HC_BURDEN ~  a + b*(HBA1C),
                   start = list(a = 5, b = -3), cost_var.GLP,
                   control = list(maxiter = 50000, minFactor = 0.000000000000001))

cost_GLP_plotdat &lt;- cbind(cost_GLP_plotdat,
                          cost_GLP_plotdat[,3] -
                           sqrt(predict(mod_var.GLP, newdata=data.frame(HBA1C = seq(0,6,6/99)))),
                          cost_GLP_plotdat[,3] +
                           sqrt(predict(mod_var.GLP, newdata=data.frame(HBA1C = seq(0,6,6/99)))))
colnames(cost_GLP_plotdat) &lt;- c("Data","HbA1c","Therapy cost","low","high")

### Out-of-control cost
COST_CUMU&lt;-NULL
for (i in unique(RANDOMISED_DATA$ID[!is.na(RANDOMISED_DATA$HEALTHCARE_BURDEN_EUR)]))
{
	vec       &lt;- RANDOMISED_DATA$HEALTHCARE_BURDEN_EUR[RANDOMISED_DATA$ID==i]
	vec2      &lt;- rollapply(vec,min(6,length(vec)),
	              sum,align="left",partial=TRUE)/
	               (pmin(length(vec)-(1:length(vec))+1,6)*30)
	COST_CUMU &lt;- rbind(COST_CUMU,cbind(i,vec2))
}

RANDOMISED_DATA$COST_CUMU &lt;- NA
RANDOMISED_DATA$COST_CUMU[RANDOMISED_DATA$ID%in%COST_CUMU[,1]] &lt;- COST_CUMU[,2]

discparam    &lt;- 150
cutHBA1C_AVG &lt;- cut(na.omit(RANDOMISED_DATA$HBA1C_fill_filter),breaks=discparam)
newlvls      &lt;- seq(min(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)),
                    max(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)),
                    (max(na.omit(RANDOMISED_DATA$HBA1C_fill_filter))-
                      min(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)))/discparam)[1:discparam] +
                      (max(na.omit(RANDOMISED_DATA$HBA1C_fill_filter))-
                        min(na.omit(RANDOMISED_DATA$HBA1C_fill_filter)))/discparam/2
levels(cutHBA1C_AVG) &lt;- newlvls
ooc_costs &lt;- cbind(round(as.numeric(as.character(cutHBA1C_AVG)),1),
              RANDOMISED_DATA$COST_CUMU[!is.na(RANDOMISED_DATA$HBA1C_fill_filter)])
ooc_costs &lt;- as.data.frame(ooc_costs)

# Mean
disc_ooc_cost           &lt;- as.data.frame(cbind(as.numeric(ooc_costs[,1]),ooc_costs[,2]))
colnames(disc_ooc_cost)	&lt;- c("HBA1C","COST")
disc_ooc_cost           &lt;- disc_ooc_cost[order(disc_ooc_cost$HBA1C),]
disc_ooc_cost           &lt;- disc_ooc_cost[disc_ooc_cost$HBA1C &gt;= lowest,]
disc_ooc_cost$HBA1C     &lt;- disc_ooc_cost$HBA1C - lowest

mod.COST &lt;- nls(COST ~ a + c*HBA1C^2, start = list(a = 1, c = 1), disc_ooc_cost)

cost_COST_plotdat &lt;- cbind("Complications",as.data.frame(cbind(seq(0, 6, 6/99),
                           predict(mod.COST, newdata=data.frame(HBA1C = seq(0, 6, 6/99))))))

# Variance
disc_ooc_cost_var           &lt;- as.data.frame(cbind(sort(unique(ooc_costs[,1])),
                                as.numeric(tapply(ooc_costs[,2],ooc_costs[,1],var))))
colnames(disc_ooc_cost_var) &lt;- c("HBA1C","COST")

disc_ooc_cost_var       &lt;- disc_ooc_cost_var[disc_ooc_cost_var$HBA1C&gt;=lowest,]
disc_ooc_cost_var$HBA1C &lt;- disc_ooc_cost_var$HBA1C-lowest

mod_var.COST &lt;- nls(COST ~ a + c*HBA1C^2,
                    start = list(a = 0.5, c = 0.5), disc_ooc_cost_var,
                    control = list(maxiter = 50000, minFactor = 0.000000000000001))

cost_COST_plotdat &lt;- cbind(cost_COST_plotdat,
                           cost_COST_plotdat[,3] -
                             sqrt(predict(mod_var.COST,
                               newdata=data.frame(HBA1C = seq(0,6,6/99)))),
                           cost_COST_plotdat[,3] +
                             sqrt(predict(mod_var.COST,
                               newdata=data.frame(HBA1C = seq(0,6,6/99)))))
colnames(cost_COST_plotdat) &lt;- c("Data","HbA1c","Therapy cost","low","high")

cost_plots       &lt;- rbind(cost_ANALOGUE_plotdat,cost_GLP_plotdat,cost_COST_plotdat)
cost_plots$HbA1c &lt;- cost_plots$HbA1c + lowest
cost_plots[,"Therapy cost"]               &lt;- cost_plots[,"Therapy cost"]/1
cost_plots[,"low"]                        &lt;- cost_plots[,"low"]/1
cost_plots[,"low"][cost_plots[,"low"]&lt;0]  &lt;- 0
cost_plots[,"high"]                       &lt;- cost_plots[,"high"]/1

cost_plots &lt;- cost_plots

### Sampling cost: official, government-regulated prices related to sampling
### converted from HUF to EUR
sampling_cost=2875/369.05

### Empirical costs for comparison
# GLP
mean(RANDOMISED_DATA[grepl("GLP", RANDOMISED_DATA$THERAPY),]$THERAPY_COST_EUR)/30 +
mean(RANDOMISED_DATA[grepl("GLP", RANDOMISED_DATA$THERAPY),]$COST_CUMU) +
sampling_cost/mean(deltats[,2])

sd(RANDOMISED_DATA[grepl("GLP", RANDOMISED_DATA$THERAPY),]$THERAPY_COST_EUR/30 +
RANDOMISED_DATA[grepl("GLP", RANDOMISED_DATA$THERAPY),]$COST_CUMU +
sampling_cost/mean(deltats[,2]))

# ANALOGUE
mean(RANDOMISED_DATA[grepl("ANALOGUE", RANDOMISED_DATA$THERAPY) &amp;
 !grepl("GLP", RANDOMISED_DATA$THERAPY),]$THERAPY_COST_EUR)/30 +
mean(RANDOMISED_DATA[grepl("ANALOGUE", RANDOMISED_DATA$THERAPY) &amp;
 !grepl("GLP", RANDOMISED_DATA$THERAPY),]$COST_CUMU) +
sampling_cost/mean(deltats[,2])

sd(RANDOMISED_DATA[grepl("ANALOGUE", RANDOMISED_DATA$THERAPY) &amp;
 !grepl("GLP", RANDOMISED_DATA$THERAPY),]$THERAPY_COST_EUR/30 +
RANDOMISED_DATA[grepl("ANALOGUE", RANDOMISED_DATA$THERAPY) &amp;
 !grepl("GLP", RANDOMISED_DATA$THERAPY),]$COST_CUMU +
sampling_cost/mean(deltats[,2]))

### Empirical HbA1c distribution
# GLP
empi.GLP  &lt;- RANDOMISED_DATA$HBA1C_fill[grepl("GLP", RANDOMISED_DATA$THERAPY) &amp;
               RANDOMISED_DATA$HBA1C_fill&gt;=4 &amp; RANDOMISED_DATA$HBA1C_fill&lt;=20]
cutHBA1C  &lt;- cut(na.omit(empi.GLP),breaks=100)
newlvls   &lt;- seq(min(na.omit(empi.GLP)),max(na.omit(empi.GLP)),
                     (max(na.omit(empi.GLP))-min(na.omit(empi.GLP)))/100)[1:100] +
                      (max(na.omit(empi.GLP))-min(na.omit(empi.GLP)))/100/2
levels(cutHBA1C)    &lt;- newlvls
empi.GLP            &lt;- as.data.frame(table(cutHBA1C)/sum(table(cutHBA1C)))
empi.GLP$cutHBA1C   &lt;- as.numeric(as.character(empi.GLP$cutHBA1C))
empi.GLP            &lt;- cbind("GLP", empi.GLP)
colnames(empi.GLP)  &lt;- c("Therapy", "HbA1c", "Probability")

# ANALOGUE
empi.ANALOGUE   &lt;- RANDOMISED_DATA$HBA1C_fill[grepl("ANALOGUE", RANDOMISED_DATA$THERAPY) &amp;
                    !grepl("GLP", RANDOMISED_DATA$THERAPY) &amp;
                      RANDOMISED_DATA$HBA1C_fill&gt;=4 &amp; RANDOMISED_DATA$HBA1C_fill&lt;=20]
cutHBA1C        &lt;- cut(na.omit(empi.ANALOGUE),breaks=100)
newlvls         &lt;- seq(min(na.omit(empi.ANALOGUE)),
                       max(na.omit(empi.ANALOGUE)),
                       (max(na.omit(empi.ANALOGUE))-
                         min(na.omit(empi.ANALOGUE)))/100)[1:100] +
                          (max(na.omit(empi.ANALOGUE))-
                            min(na.omit(empi.ANALOGUE)))/100/2
levels(cutHBA1C)        &lt;- newlvls
empi.ANALOGUE           &lt;- as.data.frame(table(cutHBA1C)/sum(table(cutHBA1C)))
empi.ANALOGUE$cutHBA1C  &lt;- as.numeric(as.character(empi.ANALOGUE$cutHBA1C))
empi.ANALOGUE           &lt;- cbind("ANALOGUE", empi.ANALOGUE)
colnames(empi.ANALOGUE)	&lt;- c("Therapy", "HbA1c", "Probability")

# Merging datasets
hba1c_empir &lt;- rbind(empi.ANALOGUE, empi.GLP)

# The list of gathered data and statistics:
# sigma_param, s_param, delta_param, ANALOGUE
# GLP, mod.ANALOGUE, mod_var.ANALOGUE
# mod.GLP, mod_var.GLP, mod.COST, mod_var.COST
# cost_plots, sampling_cost, hba1c_empir


## End(Not run)
</code></pre>

<hr>
<h2 id='LDL'>
Aggregated low-density-lipoprotein patient data for control chart applications
</h2><span id='topic+LDL'></span>

<h3>Description</h3>

<p>A data frame  containing aggregated low-density-lipoprotein (LDL) patient data gathered from various sources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("LDL")</code></pre>


<h3>Format</h3>

<p>A data frame with 1 observation on the following 12 variables.
</p>

<dl>
<dt><code>target_value</code></dt><dd><p>Target LDL value.  Set according to the European guideline for patients at risk. Garmendia et al. (2000)</p>
</dd>
<dt><code>standard_deviation</code></dt><dd><p>Process standard deviation. Estimated using real life data from Hungary, namely registry data through Healthware Consulting Ltd. (Budapest, Hungary).</p>
</dd>
<dt><code>expected_shift_size</code></dt><dd><p>Expected shift size, around 0.8 increase in LDL per year on average, due to the expected number of shifts per year. Estimated with the help of a health care professional from the Healthware Consulting Ltd.</p>
</dd>
<dt><code>num_exp_daily_shifts</code></dt><dd><p>We expect around 3 shifts per year on average. Estimated with the help of a health professional from the Healthware Consulting Ltd.</p>
</dd>
<dt><code>rep_size_first</code></dt><dd><p>First repair size distribution parameter. Estimated using an international study which included Hungary. Garmendia et al. (2000)</p>
</dd>
<dt><code>rep_size_second</code></dt><dd><p>Second repair size distribution parameter.</p>
</dd>
<dt><code>samp_prob_first</code></dt><dd><p>First sampling probability parameter. Patient non-compliance in LDL controlling medicine is quite high, and this is represented through the parametrisation of the logistic function. Lardizabal
and Deedwania (2010)</p>
</dd>
<dt><code>samp_prob_second</code></dt><dd><p>Second sampling probability parameter.</p>
</dd>
<dt><code>sampling_cost</code></dt><dd><p>Sampling cost in Euro. Estimated using the official LDL testing cost and visit cost in Hungary.</p>
</dd>
<dt><code>OOC_cost</code></dt><dd><p>Out-of-control operation (health care event) cost in Euro. Estimated using real world data of cardiovascular event costs from Hungary</p>
</dd>
<dt><code>base_rep_cost</code></dt><dd><p>Base repair (treatment) cost in Euro. Estimated using the simvastatin therapy costs in Hungary</p>
</dd>
<dt><code>prop_rep_cost</code></dt><dd><p>Shift-proportional (illness-proportional) repair cost in Euro. Estimated using the simvastatin therapy costs in Hungary.</p>
</dd>
</dl>



<h3>Details</h3>

<p>It is very difficult to give a good estimate for the type and parameters of a distribution that properly models the non-compliance (sampling probability), thus the data here can at best be regarded as close approximations to a real-life situation. This is not a limiting factor, as patients themselves can have vast differences in their behaviour, so evaluation of different scenarios are often required. Since high LDL levels rarely produce noticeable symptoms, the sampling probability should only depend on the time between samplings (Institute for Quality and Efficiency in Health Care, 2017). Thus, the sampling probability parameters assume the use of a logistic function and not a beta distribution in the <code>Markovstat</code> function. It is important to note that the proportional costs usually assumed to increase according to a Taguchi-type loss function (squared loss), thus huge expenses can be generated if the patient’s health is highly out-of-control. For cost calculations, the 2021 March 21 EUR-HUF exchange rate was used (1 EUR = 369.05 HUF).
</p>


<h3>Source</h3>

<p>Dobi, B. and Zempléni, A. Markov chain-based cost-optimal control charts for health care data. Quality and Reliability Engineering International, 2019;35(5):1379–1395. https://doi.org/10.1002/qre.2518
</p>


<h3>References</h3>

<p>Boekholdt SM, Arsenault BJ, Mora S, et al. Association of LDL cholesterol, non–HDL cholesterol, and apolipoprotein B levels with risk of cardiovascular events among patients treated with statins: a meta-analysis. J Am Med Assoc. 2012;307(12):1302-1309. https://doi.org/10. 1001/jama.2012.366
</p>
<p>Garmendia F, Brown AS, Reiber I, Adams PC. Attaining United States and European guideline LDL-cholesterol levels with simvastatin in patients with coronary heart disease (the GOALLS study). Curr Med Res Opin. 2000;16(3):208-219. PMID: 11191012.
</p>
<p>Lardizabal JA, Deedwania PC. Benefits of statin therapy and compliance in high risk cardiovascular patients. Vasc Health Risk Manag. 2010;6:843-853. https://doi/org/10.2147/VHRM.S9474
</p>
<p>High cholesterol: Overview. Institute for Quality and Efficiency in Health Care. https://www.ncbi.nlm.nih.gov/books/NBK279318/ [10 September 2021] Bookshelf ID: NBK279318.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Print data
data("LDL")
LDL

###

# Run analysis from Dobi &amp; Zempleni 2019.
# Note that the code below is generated with updated HUF-EUR rate and
# a more accurate R implementation than in the original paper.

stat_LDL_cost &lt;- Markovstat(
  shiftfun = 'exp', h = 50, k = 3.15-LDL$target_value,
  sigma = LDL$standard_deviation,
  s = LDL$num_exp_daily_shifts,
  delta = LDL$expected_shift_size,
  RanRep = TRUE, alpha = LDL$rep_size_first, beta = LDL$rep_size_second,
  RanSam = TRUE, q = LDL$samp_prob_first, z = LDL$samp_prob_second,
  Vd = 100, V = 6-LDL$target_value)

#Defining parallel_opt parallel settings.
#parallel_opt can also be left empty to be defined automatically by the function.
require(parallel)
num_workers &lt;- min(c(detectCores(),2))
parall &lt;- list(cl=makeCluster(num_workers), forward=FALSE, loginfo=TRUE)
res_LDL_cost &lt;- Markovchart(
  statdist = stat_LDL_cost,
  OPTIM = TRUE, p = 1,
  cs = LDL$sampling_cost,
  cf = LDL$base_rep_cost,
  coparams = c(0,LDL$OOC_cost),
  crparams = c(LDL$base_rep_cost,LDL$prop_rep_cost),
  parallel_opt = parall)

num_workers &lt;-  min(c(detectCores(),2))
parall      &lt;-  list(cl=makeCluster(num_workers), forward=FALSE, loginfo=TRUE)
res_LDL_cost_grid &lt;- Markovchart(
  statdist = stat_LDL_cost,
  h=seq(50,75,2.5),
  k=seq(0.05,0.25,0.02),
  p = 1,
  cs = LDL$sampling_cost,
  cf = LDL$base_rep_cost,
  coparams = c(0,LDL$OOC_cost),
  crparams = c(LDL$base_rep_cost,LDL$prop_rep_cost),
  parallel_opt = parall)

require(ggplot2)
plot(res_LDL_cost_grid,
     y = 'Expected \ndaily cost',
     mid = '#ff9494',
     high = '#800000',
     xlab = 'Days between samplings',
     ylab = 'Critical LDL increase') +
     geom_point(aes(x = res_LDL_cost$Parameters[[1]],
                    y = res_LDL_cost$Parameters[[2]]))

</code></pre>

<hr>
<h2 id='Markovchart'>
Cost-efficient X-bar control charts with fixed/random shift size, random repair and random sampling time.
</h2><span id='topic+Markovchart'></span>

<h3>Description</h3>

<p>Wrapper for Markov chain-based cost optimal control charts. Includes cost calculation methods for different shift size distributions and optimisation with respect to the average cost and cost standard deviation where the free parameters are the sampling interval (<code>h</code>) and the control limit/critical value (<code>k</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Markovchart(statdist, h = NULL, k = NULL,
            OPTIM = FALSE, p = 1, constantr = FALSE,
            ooc_rep = 0, cs = NULL, cofun = cofun_default,
            coparams = NULL, crfun = crfun_default, crparams = NULL,
            cf = crparams, vcofun = vcofun_default,
            vcoparams = c(0, 0), vcrfun = vcrfun_default,
            vcrparams = c(0, 0), method = c("L-BFGS-B", "Nelder-Mead",
            "BFGS", "CG", "SANN", "Brent"), parallel_opt = NULL,
            silent = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Markovchart_+3A_statdist">statdist</code></td>
<td>

<p>The stationary distribution of the Markov chain. Must be an object of class <code>Markov_stationary</code>, preferably created by <code>Markovstat</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_h">h</code></td>
<td>

<p>The time between samplings. Must be a positive value, can be a numeric vector. For optimisation, this is the initial value. Inherited from <code>statdist</code> if not given.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_k">k</code></td>
<td>

<p>The control limit (critical value). Must be a positive value, can be a numeric vector. For optimisation, this is the initial value. Only one sided shifts are allowed, thus there is only one control limit. Inherited from <code>statdist</code> if not given.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_optim">OPTIM</code></td>
<td>

<p>Logical. Should the resulting <code>G-value</code> (weighted average of the expected cost and cost standard deviation) be optimised by finding the adequate value of <code>h</code> and <code>k</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_p">p</code></td>
<td>

<p>The weight of the cost expectation in the calculation of the <code>G-value</code>; should be
between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_constantr">constantr</code></td>
<td>

<p>Logical. Should the repair cost be assumed to constantly occur over time (<code>TRUE</code>) or assumed to only occur when there is a repair due to an alarm (<code>FALSE</code>, default)? If <code>TRUE</code>, then the repair cost should be given per unit time.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_ooc_rep">ooc_rep</code></td>
<td>

<p>Numeric value between 0 and 1. The percentage of repair cost ocurring during out-of-control operation. Default is 0. If a value greater than 0 is set, then <code>constantr</code> should be <code>TRUE</code>, but it is not forced.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_cs">cs</code></td>
<td>

<p>Sampling cost per sampling.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_cofun">cofun</code></td>
<td>

<p>A function describing the relationship between the distance from the target value and the resulting out-of-control costs. Default is calculated using a base and a distance-scaling out-of-control parameter. See &quot;Details&quot;.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_coparams">coparams</code></td>
<td>

<p>Numeric vector. Parameters of <code>cofun</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_crfun">crfun</code></td>
<td>

<p>A function describing the relationship between the distance from the target value and the resulting repair costs. The default function assumes a linear relationship between the repair cost and the distance, and uses a base and a distance-scaling repair cost parameter. See &quot;Details&quot;.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_crparams">crparams</code></td>
<td>

<p>Numeric vector. Parameters of <code>crfun</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_cf">cf</code></td>
<td>

<p>Numeric. The false alarm cost. Only relevant when <code>statdist</code> was created using <code>shiftfun="deg"</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_vcofun">vcofun</code></td>
<td>

<p>A function describing the relationship between the distance from the target value and the resulting out-of-control cost variance. For the default function see &quot;Details&quot;.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_vcoparams">vcoparams</code></td>
<td>

<p>Numeric vector. Parameters of <code>vcofun</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_vcrfun">vcrfun</code></td>
<td>

<p>A function describing the relationship between the distance from the target value and the resulting repair cost variance. For the default function see &quot;Details&quot;.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_vcrparams">vcrparams</code></td>
<td>

<p>Numeric vector. Parameters of <code>vcrfun</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_method">method</code></td>
<td>

<p>Method used for optimisation. Same as the argument of <code>optim</code>, but the default here is <code>"L-BFGS-B"</code>, because it turned out to be more robust in testing.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_parallel_opt">parallel_opt</code></td>
<td>

<p>A list of parallel options. See e.g. the argument <code>parallel</code> in the documentation of <code><a href="optimParallel.html#topic+optimParallel">optimParallel</a></code>. Can be left empty, in this case the number of cores (threads) is automatically detected and all but one is used. (Single-core computers simply use one core.)
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_silent">silent</code></td>
<td>

<p>Should the call be returned? Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="Markovchart_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed down to <code>optimParallel</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>constantr</code> parameter is used for different repair assumptions. In traditional control chart theory, repair cost only occurs in case of an alarm signal. This is represented by <code>constantr=FALSE</code>, which is the default. In this case the repair is just a momentary cost, occurring at the time of the sampling. However this model is inappropriate in several cases in healthcare. For example there are chronic diseases that require constant medication (repair in the sense of the model). In this approach (<code>constantr=TRUE</code>) the repair cost still depends on the state of the process during sampling, but occurs even if there is no alarm and is divided by <code>h</code> to represent the constant repair through the whole sampling interval. Thus the repair cost should be given in a way which corresponds to the model used.
</p>
<p>The default <code>cofun</code> calculates the out-of-control (OOC) cost using a base and a distance-scaling OOC parameter:
</p>
<p style="text-align: center;"><code class="reqn">c_{o} = c_{ob} + c_{os} A^2(v),</code>
</p>

<p>where <code class="reqn">c_{o}</code> is the total OOC cost, <code class="reqn"> c_{ob}</code> is the base OOC cost (even without shift), <code class="reqn">c_{os}</code> is the shift-scaling cost and <code class="reqn">A^2(v)</code> is the squared distance from the target value. This latter part is defined like this because a Taguchi-type loss function is used. This <code class="reqn">A^2(v)</code> incorporates the distances (the base of the losses) incurred not just at the time of the sampling, but also between samplings (hence it dependens on h). Even if the user defines a custom cost function for the OOC cost, this <code class="reqn">A^2(v)</code> term must be included, as a closed form solution has been developed for the calculation of the squared distances in case of exponential shifts, considerably decreasing run times. Thus the arguments of the OOC cost function should look like this: function(<code class="reqn">A^2(v)</code>, other parameters contained in a vector). <code class="reqn">A^2(v)</code> is fed to the cost function as a vector, thus the function should vectorised with respect to this argument. The default function looks like this:
</p>
<pre>
cofun_default	&lt;-	function(sqmudist,coparams)
{
  sqmudist=sqmudist
  cob=coparams[1]
  cos=coparams[2]
  co		&lt;-	cob + cos*sqmudist
  return(co)
}
</pre>
<p>The default <code>vcofun</code> also uses a Taguchi-type loss function and has identical parts and requirements as <code>cofun</code>. The final standard deviation itself is calculated using the law of total variance. The default <code>vcofun</code> is:
</p>
<pre>
vcofun_default	&lt;-	function(sqmudist,vcoparams)
{
  sqmudist=sqmudist
  vcob=vcoparams[1]
  vcos=vcoparams[2]
  vco		&lt;-	vcob + vcos*sqmudist
  return(vco)
}
</pre>
<p>The defaults for the repair cost and cost variance are simple linear functions. For <code>crfun</code> it is
</p>
<p style="text-align: center;"><code class="reqn">c_{r} = c_{rb} + c_{rs} v,</code>
</p>

<p>where the notation are the same as before and &quot;r&quot; denotes repair. A custom function can be defined more freely here, but the first argument should be <code class="reqn">v</code> and the second a vector of further parameters.
</p>
<p>The default function are:
</p>
<pre>
crfun_default	&lt;-	function(mudist,crparams)
{
  mudist=mudist
  crb=crparams[1]
  crs=crparams[2]
  cr		&lt;-	crb + crs*mudist
  return(cr)
}
</pre>
<pre>
vcrfun_default	&lt;-	function(mudist,vcrparams)
{
  mudist=mudist
  vcrb=vcrparams[1]
  vcrs=vcrparams[2]
  vcr		&lt;-	vcrb + vcrs*mudist;
  return(vcr)
}
</pre>


<h3>Value</h3>

<p>The value depends on the parameters:
</p>
<p>If either <code>h</code> or <code>k</code> have length greater than 1, then the <code>G-value</code> (weighted average of average cost and cost standard deviation) is calculated for all given values without optimisation. The value of the function in this case is a data frame of class codeMarkov_grid with <code>length(h)*length(k)</code> number of rows and three columns for <code>h</code>, <code>k</code> and the <code>G-value</code>.
</p>
<p>If <code>h</code> and <code>k</code> are both of length 1 (they may be inherited from <code>statdist</code>), then the value of the function is a <code>Markov_chart</code> object, which is a list of length 4, detailing the properties of the control chart setup.
</p>
<table>
<tr><td><code>Results</code></td>
<td>
<p>Vector of <code>G-value</code>, expected cost, cost standard deviation and further process moments. Note that these further moments only take into account the process variation (i.e. the standard deviation of the process itself), while the &quot;Total cost std. dev.&quot; takes into account all sources of variance (e.g. the different costs that can occur due to being out-of-control). The &quot;Total cost std. dev.&quot; is only relevant and calculated for non-degenerate distributions.</p>
</td></tr>
<tr><td><code>Subcosts</code></td>
<td>
<p>Vector of sub-costs that are parts of the total expected cost.</p>
</td></tr>
<tr><td><code>Parameters</code></td>
<td>
<p>A vector that contains the time between samplings (<code>h</code>) and critical value (<code>k</code>) which was used in the control chart setup.</p>
</td></tr>
<tr><td><code>Stationary_distribution</code></td>
<td>
<p>The stationary distribution of the Markov chain. Further information about the stationary distribution can be calculated using the <code><a href="#topic+Markovstat">Markovstat</a></code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Balazs Dobi and Andras Zempleni
</p>


<h3>References</h3>

<p>Zempleni A, Veber M, Duarte B and Saraiva P. (2004) Control charts: a cost-optimization approach for processes with random shifts. <em>Applied Stochastic Models in Business and Industry</em>, 20(3), 185-200.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts for health care data. <em>Quality and Reliability Engineering
International</em>, 35(5), 1379-1395.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts with different shift size distributions. <em>Annales Univ. Sci.
Budapest., Sect. Comp.</em>, 49, 129-146.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Defining parallel_opt parallel settings.
#parallel_opt can also be left empty to be defined automatically by the function.
require(parallel)
num_workers &lt;-  min(c(detectCores(),2))
parall	    &lt;-  list(cl=makeCluster(num_workers), forward=FALSE, loginfo=TRUE)


#Fixed shift size (essentially Duncan's cycle model) - no optimisation.
stat_deg &lt;- Markovstat(shiftfun="deg", h=1, k=1, sigma=1, s=0.2, delta=2.5)
res1     &lt;- Markovchart(statdist=stat_deg, cs=1, crparams=20, coparams=50)
res1

#Fixed shift size (essentially Duncan's cycle model) - with optimisation.
res2 &lt;-  Markovchart(statdist=stat_deg, OPTIM=TRUE, cs=1, crparams=20, coparams=50,
                    lower = c(0.01,0.01), upper = c(5,5),
                    parallel_opt=parall)
res2

#Exponential shift - no optimisation - default cost functions.
stat_exp &lt;- Markovstat(shiftfun="exp", h=0.5, k=2, sigma=1, s=0.2, delta=2,
                       RanRep=FALSE, Vd=30, V=18)
res3     &lt;- Markovchart(stat_exp, p=0.9, cs=1, coparams=c(10,3), crparams=c(1,2))
res3

#Exponential shift - with optimisation - default cost functions.
stat_exp2 &lt;- Markovstat(shiftfun="exp", h=1, k=1, sigma=1, s=0.2, delta=2,
                        RanRep=TRUE, alpha=1, beta=3, Vd=30, V=18)
parall    &lt;- list(cl=makeCluster(num_workers), forward=FALSE, loginfo=TRUE)
res4      &lt;- Markovchart(statdist=stat_exp2, OPTIM=TRUE, p=0.9, cs=1,
                         coparams=c(10,3), crparams=c(1,2), vcoparams=c(8,1.5),
                         vcrparams=c(5,2), parallel_opt=parall)
res4

#Exponential-geometric mixture shift - no optimisation -
#random sampling - custom repair variance function.
stat_expgeo &lt;- Markovstat(shiftfun="exp-geo",h=1.5, k=2, sigma=1,
                          s=0.2, delta=1.2, probmix=0.7, probnbin=0.8,
                          disj=2, RanRep=TRUE, alpha=1, beta=3, RanSam=TRUE,
                          StateDep=TRUE, a=1, b=15, Vd=100, V=8)

vcrfun_new	&lt;-	function(mudist,vcrparams)
{
  mudist=mudist
  vcrb=vcrparams[1]
  vcrs=vcrparams[2]
  vcrs2=vcrparams[3]

  vcr		&lt;-	vcrb + vcrs/(mudist + vcrs2)
  return(vcr)
}

res5 &lt;- Markovchart(statdist=stat_expgeo, p=0.9, cs=1,
                   coparams=c(10,6), crparams=c(20,3),
                   vcoparams=c(10000,100), vcrfun=vcrfun_new,
                   vcrparams=c(50000,-600000,1.5))
res5

#Exponential shift - no optimisation  - vectorised.
parall &lt;- list(cl=makeCluster(num_workers), forward=FALSE, loginfo=TRUE)
Gmtx   &lt;-	Markovchart(statdist=stat_exp2, h=seq(1,10,by=(10-1)/5),
                      k=seq(0.1,5,by=(5-0.1)/5), p=0.9, cs=1,
                      coparams=c(10,3), crparams=c(1,2),
                      vcoparams=c(8,1.5), vcrparams=c(5,2),
                      V=18, parallel_opt=parall)
Gmtx

</code></pre>

<hr>
<h2 id='Markovsim'>
Progression and monitoring simulation of a process with random shift size, random repair and random sampling time.
</h2><span id='topic+Markovsim'></span>

<h3>Description</h3>

<p>Wrapper for simulation of processes with a Markov chain-based control chart setup. Includes methods for different shift size distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Markovsim(shiftfun = c("exp", "exp-geo"), num = 100, h, k, sigma,
          s, delta, probmix = 0, probnbin = 0.5, disj=1,
          RanRep = FALSE, alpha = NULL, beta = NULL, RanSam = FALSE,
          StateDep = FALSE, a = NULL, b = NULL, q = NULL,
          z = NULL, detail = 100, Vd = 50, V, burnin = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Markovsim_+3A_shiftfun">shiftfun</code></td>
<td>

<p>A string defining the shift size distribution to be used. Must be either &quot;exp&quot;, &quot;exp-geo&quot;.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_num">num</code></td>
<td>

<p>Integer. The number of sampling intervals simulated. This means that the time elapsed in the simulation is <code>num*h</code>.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_h">h</code></td>
<td>

<p>The time between samplings. Must be a positive value.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_k">k</code></td>
<td>

<p>The control limit (critical value). Must be a positive value. Only one sided shifts are allowed, thus there is only one control limit.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_sigma">sigma</code></td>
<td>

<p>Process standard deviation (the distribution is normal).
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_s">s</code></td>
<td>

<p>Expected number of shifts in an unit time interval.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_delta">delta</code></td>
<td>

<p>Expected shift size.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_probmix">probmix</code></td>
<td>

<p>The weight of the geometric distribution in case of exponential-geometric mixture shift distribution and should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_probnbin">probnbin</code></td>
<td>

<p>The probability parameter of the geometric distribution in case of exponential-geometric mixture shift distribution and should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_disj">disj</code></td>
<td>

<p>The size of a discrete jump in case of exponential-geometric mixture shift distribution, must be a positive number.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_ranrep">RanRep</code></td>
<td>

<p>Logical. Should the repair be random? Default is FALSE (no).
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_alpha">alpha</code></td>
<td>

<p>First shape parameter for the random repair beta distribution.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_beta">beta</code></td>
<td>

<p>Second shape parameter for the random repair beta distribution.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_ransam">RanSam</code></td>
<td>

<p>Logical. Should the sampling be random? Default is FALSE (no).
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_statedep">StateDep</code></td>
<td>

<p>Logical. Should the sampling probability also depend on the distance from the target value (state dependency)? (If TRUE, a beta distribution is used for the sampling probability, if FALSE then a logistic function.)
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_a">a</code></td>
<td>

<p>First parameter*<code>h</code>  for the random sampling time beta distribution. The first shape parameter is <code>a/h</code> to create dependency on the time between samplings.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_b">b</code></td>
<td>

<p>Second shape parameter for the random sampling time beta distribution.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_q">q</code></td>
<td>

<p>The steepness of the curve of the random sampling time logistic function.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_z">z</code></td>
<td>

<p>The logistic sigmoid's midpoint of the random sampling time logistic function.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_detail">detail</code></td>
<td>

<p>The detail of the simulation, i.e. how many data points (including the moment of the sampling itself) should be simulated within a unit time. Should be a positive integer greater than 1, and the user should consider the length of the sampling interval <code>h</code>, as a shorter interval leads to less datapoints.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_vd">Vd</code></td>
<td>

<p>Integer discretisation parameter: the number of states after the equidistant discretisation of the state space. Should be an integer value greater than 2. This parameter is needed to calculate a stationary distibution that can be compared to results of the <code>Markovchart</code> function.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_v">V</code></td>
<td>

<p>Numeric discretisation parameter: the maximum (positive) distance from the target value taken into account. This parameter is needed to calculate a stationary distibution that can be compared to results of the <code>Markovchart</code> function and for the calculation of sampling probabilities in the case of random sampling.
</p>
</td></tr>
<tr><td><code id="Markovsim_+3A_burnin">burnin</code></td>
<td>

<p>Numeric burn-in parameter: the number of samplings deemed as a burn-in period. Should be an integer greater than one.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation only includes the more complicated process and control chart cases and is meant for model checking and for situations when the exact calculation is problematic (such as low probabilities in the stationary distribution leading to rounding errors).
</p>


<h3>Value</h3>

<p>A <code>Markov_sim</code> object which is a list of length 4.
</p>
<table>
<tr><td><code>Value_at_samplings</code></td>
<td>
<p>The process value at sampling.</p>
</td></tr>
<tr><td><code>Sampling_event</code></td>
<td>
<p>The event at sampling, each can either be success (there was a sampling but no alarm), alarm (sampling with alarm) or failure (no sampling occurred).</p>
</td></tr>
<tr><td><code>Simulation_data</code></td>
<td>
<p>The simulated data (distances from the target value).</p>
</td></tr>
<tr><td><code>Stationary_distribution</code></td>
<td>
<p>The stationary distribution of the Markov chain, created by discretising the simulated data. See the documentaion of the <code><a href="#topic+Markovchart">Markovchart</a></code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Balazs Dobi and Andras Zempleni
</p>


<h3>References</h3>

<p>Zempleni A, Veber M, Duarte B and Saraiva P. (2004) Control charts: a cost-optimization approach for processes with random shifts. <em>Applied Stochastic Models in Business and Industry</em>, 20(3), 185-200.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts for health care data. <em>Quality and Reliability Engineering
International</em>, 35(5), 1379-1395.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts with different shift size distributions. <em>Annales Univ. Sci.
Budapest., Sect. Comp.</em>, 49, 129-146.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Markovstat">Markovstat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulation using exponential shifts, random repair and random samling.
simres1	&lt;-	Markovsim(shiftfun="exp", num=500, h=1, k=1, sigma=1, s=0.2, delta=2,
                          RanRep=TRUE, alpha=1, beta=3, RanSam=TRUE, StateDep=TRUE,
                          a=0.1, b=1, V=10)
simres1
hist(simres1[[1]], 20, freq=FALSE)

#Simulation using exponential-geometric mixture shifts, random repair and random samling.
simres2	&lt;-	Markovsim(shiftfun="exp-geo", num=500, h=1, k=1, sigma=1, s=0.2, delta=2,
                          probmix=0.9, probnbin=0.6, RanRep=TRUE, alpha=1, beta=3, RanSam=TRUE,
                          StateDep=TRUE, a=0.1, b=1, V=10)
simres2
hist(simres2[[1]], 20, freq=FALSE)
</code></pre>

<hr>
<h2 id='Markovstat'>
Stationary distribution calculation for processes with fixed/random shift size, random repair and random sampling time.
</h2><span id='topic+Markovstat'></span>

<h3>Description</h3>

<p>Calculates the stationary distribution of a process described by a discrete state, discrete time Markov chain. The process is described by a degradation-repair cycle type model. The user must give parameters describing both the degradation and the repair. The process is not repaired until the problem is discovered by sampling, hence the control chart setup. The same, single element is monitored (i.e. the sample size is always 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Markovstat(shiftfun = c("exp", "exp-geo", "deg"), h, k, sigma,
           s, delta, probmix = 0, probnbin = 0.5, disj = 1,
           RanRep = FALSE, alpha = NULL, beta = NULL,
           RanSam = FALSE, StateDep = FALSE, a = NULL,
           b = NULL, q = NULL, z = NULL, Vd = 100, V,
           Qparam = 30)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Markovstat_+3A_shiftfun">shiftfun</code></td>
<td>

<p>A string defining the shift size distribution to be used. Must be either <code>"exp"</code> (exponential), <code>"exp-geo"</code> (exponential-geometric mixture) or <code>"deg"</code> (degenerate). Use <code>"deg"</code> for fixed shift size with perfect repair and guaranteed sampling, i.e. Duncan&quot;s traditional cycle model.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_h">h</code></td>
<td>

<p>The time between samplings. Must be a positive value.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_k">k</code></td>
<td>

<p>The control limit (critical value). Must be a positive value. Only one sided shifts are allowed, thus there is only one control limit.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_sigma">sigma</code></td>
<td>

<p>Process standard deviation (the distribution is assumed to be normal).
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_s">s</code></td>
<td>

<p>Expected number of shifts in an unit time interval.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_delta">delta</code></td>
<td>

<p>Expected shift size. Used as the parameter of the exponential distribution (<code>shiftfun="exp"</code> or <code>"exp-geo"</code>), or simply as the size of the shift (<code>shiftfun="deg"</code>).
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_probmix">probmix</code></td>
<td>

<p>The weight of the geometric distribution in case of exponential-geometric mixture shift distribution; should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_probnbin">probnbin</code></td>
<td>

<p>The probability parameter of the geometric distribution in case of exponential-geometric mixture shift distribution; should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_disj">disj</code></td>
<td>

<p>The size of a discrete jump in case of exponential-geometric mixture shift distribution, must be a positive number.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_ranrep">RanRep</code></td>
<td>

<p>Logical. Should the repair be random? Default is <code>FALSE</code> (the repair is perfect, the process is always repaired to the target value). The repair is always perfect (non-random) for <code>shiftfun="deg"</code>.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_alpha">alpha</code></td>
<td>

<p>First shape parameter for the random repair beta distribution.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_beta">beta</code></td>
<td>

<p>Second shape parameter for the random repair beta distribution.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_ransam">RanSam</code></td>
<td>

<p>Logical. Should the sampling be random? Default is <code>FALSE</code> (no). The sampling is never random for <code>shiftfun="deg"</code>.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_statedep">StateDep</code></td>
<td>

<p>Logical. Should the sampling probability also depend on the distance from the target value (state dependency)? (If TRUE, a beta distribution is used for the sampling probability, if <code>FALSE</code> then a logistic function.)
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_a">a</code></td>
<td>

<p>First parameter*<code>h</code> for the random sampling time beta distribution. The first shape parameter is <code>a/h</code> to create dependency on the time between samplings as described at the <code>StateDep</code> parameter.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_b">b</code></td>
<td>

<p>Second shape parameter for the random sampling time beta distribution.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_q">q</code></td>
<td>

<p>The steepness of the curve of the random sampling time logistic function.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_z">z</code></td>
<td>

<p>The logistic sigmoid&quot;s midpoint of the random sampling time logistic function.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_vd">Vd</code></td>
<td>

<p>Integer discretisation parameter: the number of states in the equidistant discretisation of the state space. Should be an integer value greater than 2.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_v">V</code></td>
<td>

<p>Numeric discretisation parameter: the maximum (positive) distance from the target value taken into account.
</p>
</td></tr>
<tr><td><code id="Markovstat_+3A_qparam">Qparam</code></td>
<td>

<p>Integer discretisation parameter: the number of maximum events taken into account within a sampling interval.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function return a list object of class <code>Markov_stationary</code>. The list is of length 3:
</p>
<table>
<tr><td><code>Stationary_distribution</code></td>
<td>
<p>Stationary distribution of the Markov chain. The probabilities in the stationary distribution are labeled. If <code>shiftfun</code> is &quot;deg&quot; then the stationary distribution is always of length 4. If <code>shiftfun</code> is not &quot;deg&quot; then there are multiple out-of-control (OOC) and true alarm states. These are labeled with an index and the value the state represents. If <code>shiftfun</code> is &quot;deg&quot; then the out-of-control and true alarm states are at a distance <code>delta</code> from the target value, and the in-control and the false alarm state are always at the target value.</p>
</td></tr>
<tr><td><code>Transition_matrix</code></td>
<td>
<p>The transition matrix of the Markov chain. Not printed.</p>
</td></tr>
<tr><td><code>Param_list</code></td>
<td>
<p>Parameters given to the function and various technical results used by the <code><a href="#topic+Markovchart">Markovchart</a></code> function. Not printed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Balazs Dobi and Andras Zempleni
</p>


<h3>References</h3>

<p>Zempleni A, Veber M, Duarte B and Saraiva P. (2004) Control charts: a cost-optimization approach for processes with random shifts. <em>Applied Stochastic Models in Business and Industry</em>, 20(3), 185-200.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts for health care data. <em>Quality and Reliability Engineering
International</em>, 35(5), 1379-1395.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts with different shift size distributions. <em>Annales Univ. Sci.
Budapest., Sect. Comp.</em>, 49, 129-146.</p>


<h3>See Also</h3>

<p><code><a href="#topic+Markovchart">Markovchart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Fixed shift size (essentially Duncan's cycle model).
res1 &lt;- Markovstat(shiftfun="deg", h=1, k=1, sigma=1, s=0.2, delta=2.5)
res1

#Exponential shift - perfect repair - deterministic sampling
res2 &lt;- Markovstat(shiftfun="exp", h=1, k=1, sigma=1, s=0.2, delta=2, Vd=30, V=18)
res2
#Notice how the In-control and the False-alarm states have non-zero probabilities.
#If the repair would be random (RanRep=TRUE), then these states would have zero probability.

#Exponential-geometric mixture shift - random repair - random sampling.
res3 &lt;- Markovstat(shiftfun='exp-geo', h=1.5, k=2, sigma=1, s=0.2,
                   delta=1.2, probmix=0.7, probnbin=0.8, disj=2,
                   RanRep=TRUE, alpha=1, beta=3, RanSam=TRUE,
                   StateDep=TRUE, a=1, b=15, Vd=40, V=8)
res3
</code></pre>

<hr>
<h2 id='plot.Markov_grid'>
Contour plot for <code>Markov_grid</code> control chart results.
</h2><span id='topic+plot.Markov_grid'></span>

<h3>Description</h3>

<p>Convenience function for plotting G-values in a contour plot as the function of the time between samplings and the critical value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Markov_grid'
plot(
     x, y = expression(atop(italic("G")*-value~per, unit~time)),
     xlab = "Time between samplings", ylab = "Critical value",
     low = "white", mid = "#999999", high = "black",
     colour = "white", nbreaks = 16, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Markov_grid_+3A_x">x</code></td>
<td>

<p>A <code>Markov_grid</code> data.frame with three columns (preferably created by the Markovchart function): time between samplings, critical value and the weighted mean of the expected cost and the cost standard deviation (G-values).
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_y">y</code></td>
<td>

<p>The name of the scale.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_xlab">xlab</code></td>
<td>

<p>A title for the x axis.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_ylab">ylab</code></td>
<td>

<p>A title for the x axis.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_low">low</code></td>
<td>

<p>Colour for the low end of the gradient.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_mid">mid</code></td>
<td>

<p>Colour for the midpoint.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_high">high</code></td>
<td>

<p>Colour for the high end of the gradient.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_colour">colour</code></td>
<td>

<p>Colour of the contour lines.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_nbreaks">nbreaks</code></td>
<td>

<p>Number of contour breaks. Uses <code>pretty()</code>, thus actual, plotted number of breaks may differ.
</p>
</td></tr>
<tr><td><code id="plot.Markov_grid_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed down to <code>plot</code>. Mostly kept due to S3 method compatibility.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object of class <code>gg</code> and <code>ggplot</code> produced using the <code>ggplot2</code> package.
</p>


<h3>Note</h3>

<p>The plot itself is made using the package <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code> by Hadley Wickham et al. The text on the contour lines is added with the <code><a href="metR.html#topic+geom_text_contour">geom_text_contour</a></code> function from the package <code>metR</code> by Elio Campitelli.
</p>


<h3>Author(s)</h3>

<p>Balazs Dobi and Andras Zempleni
</p>


<h3>References</h3>

<p>Zempleni A, Veber M, Duarte B and Saraiva P. (2004) Control charts: a cost-optimization approach for processes with random shifts. <em>Applied Stochastic Models in Business and Industry</em>, 20(3), 185-200.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts for health care data. <em>Quality and Reliability Engineering
International</em>, 35(5), 1379-1395.
</p>
<p>Dobi B and Zempleni A. (2019) Markov chain-based cost-optimal
control charts with different shift size distributions. <em>Annales Univ. Sci.
Budapest., Sect. Comp.</em>, 49, 129-146.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Markovchart">Markovchart</a></code>
<code><a href="#topic+Markovstat">Markovstat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Defining parallel_opt parallel settings.
#parallel_opt can also be left empty to be defined automatically by the function.
require(parallel)
num_workers &lt;- min(c(detectCores(),2))

#Exponential shift - default cost functions.
stat_exp &lt;- Markovstat(shiftfun="exp", h=1, k=1, sigma=1, s=0.2, delta=2,
                        RanRep=TRUE, alpha=1, beta=3, Vd=30, V=18)

parall &lt;- list(cl=makeCluster(num_workers), forward=FALSE, loginfo=TRUE)
Gmtx   &lt;-	Markovchart(statdist=stat_exp, h=seq(1,10,by=(10-1)/5),
                      k=seq(0.1,5,by=(5-0.1)/5), p=0.9, cs=1,
                      coparams=c(10,3), crparams=c(1,2),
                      vcoparams=c(8,1.5), vcrparams=c(5,2),
                      V=18, parallel_opt=parall)
plot(Gmtx)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
