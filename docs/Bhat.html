<!DOCTYPE html><html><head><title>Help for package Bhat</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Bhat}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Bhat-package'><p>Bhat: General likelihood exploration</p></a></li>
<li><a href='#btrf'><p>Generalized inverse-logit transform</p></a></li>
<li><a href='#dfp'><p>Function minimization with box-constraints</p></a></li>
<li><a href='#dqstep'><p>step size generator</p></a></li>
<li><a href='#ftrf'><p>Generalized logit transform</p></a></li>
<li><a href='#global'><p>Random search for a global function minimum</p></a></li>
<li><a href='#logit.hessian'><p>Hessian (curvature matrix)</p></a></li>
<li><a href='#mymcmc'><p>Adaptive Multivariate MCMC sampler</p></a></li>
<li><a href='#newton'><p>Function minimization with box-constraints</p></a></li>
<li><a href='#plkhci'><p>Profile-likelihood based confidence intervals</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>General Likelihood Exploration</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9-12</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for Maximum Likelihood
             Estimation, Markov Chain Monte Carlo, finding confidence
             intervals.  The implementation is heavily based on the
             original Fortran source code translated to R.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, MASS, stats</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-10 13:13:10 UTC; galexv</td>
</tr>
<tr>
<td>Author:</td>
<td>Georg Luebeck <a href="https://orcid.org/0000-0002-4378-2829"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Rafael Meza <a href="https://orcid.org/0000-0002-1076-5037"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Alexander Gaenko <a href="https://orcid.org/0000-0002-1901-0394"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rafael Meza &lt;rmeza@umich.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-10 13:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Bhat-package'>Bhat: General likelihood exploration</h2><span id='topic+Bhat'></span><span id='topic+Bhat-package'></span>

<h3>Description</h3>

<p>This package provides functions for Maximum Likelihood Estimation, Markov Chain Monte Carlo, finding confidence intervals. This implementation is heavily based on the original Fortran source code translated to R.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Rafael Meza <a href="mailto:rmeza@umich.edu">rmeza@umich.edu</a> (<a href="https://orcid.org/0000-0002-1076-5037">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Georg Luebeck <a href="mailto:gluebeck@fhcrc.org">gluebeck@fhcrc.org</a> (<a href="https://orcid.org/0000-0002-4378-2829">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Alexander Gaenko <a href="mailto:galexv@umich.edu">galexv@umich.edu</a> (<a href="https://orcid.org/0000-0002-1901-0394">ORCID</a>) [contributor]
</p>
</li></ul>


<hr>
<h2 id='btrf'>Generalized inverse-logit transform</h2><span id='topic+btrf'></span>

<h3>Description</h3>

<p>maps real line onto open interval (xl, xu) using the transform y = (exp(xt)
* xu + xl)/(1.+exp(xt)) where xt is a numeric vector with -Inf &lt; xt &lt; Inf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>btrf(xt, xl, xu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="btrf_+3A_xt">xt</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
<tr><td><code id="btrf_+3A_xl">xl</code></td>
<td>
<p>a numeric vector of same length as x</p>
</td></tr>
<tr><td><code id="btrf_+3A_xu">xu</code></td>
<td>
<p>a numeric vector of same length as x, and xu &gt; xl</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the inverse-logit transform (numeric) of xt
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftrf">ftrf</a></code>
</p>

<hr>
<h2 id='dfp'>Function minimization with box-constraints</h2><span id='topic+dfp'></span>

<h3>Description</h3>

<p>This Davidon-Fletcher-Powell optimization algorithm has been &lsquo;hand-tuned&rsquo;
for minimal setup configuration and for efficency. It uses an internal
logit-type transformation based on the pre-specified box-constraints.
Therefore, it usually does not require rescaling (see help for the R optim
function). <code>dfp</code> automatically computes step sizes for each parameter
to operate with sufficient sensitivity in the functional output.
Performance is comparable to the BFGS algorithm in the R function
<code>optim</code>. <code>dfp</code> interfaces with <code>newton</code> to ascertain
convergence, compute the eigenvalues of the Hessian, and provide 95%
confidence intervals when the function to be minimized is a negative
log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfp(x, f, tol = 1e-05, nfcn = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfp_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="dfp_+3A_f">f</code></td>
<td>
<p>the function that is to be minimized over the parameter vector
defined by the list <code>x</code></p>
</td></tr>
<tr><td><code id="dfp_+3A_tol">tol</code></td>
<td>
<p>a tolerance used to determine when convergence should be
indicated</p>
</td></tr>
<tr><td><code id="dfp_+3A_nfcn">nfcn</code></td>
<td>
<p>number of function calls</p>
</td></tr>
<tr><td><code id="dfp_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to 'f'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dfp function minimizes a function <code>f</code> over the parameters
specified in the input list <code>x</code>. The algorithm is based on Fletcher's
&quot;Switching Method&quot; (Comp.J. 13,317 (1970))
</p>
<p>the code has been 'transcribed' from Fortran source code into R
</p>


<h3>Value</h3>

<p>list with the following components: </p>
<table>
<tr><td><code>fmin</code></td>
<td>
<p> the function
value f at the minimum </p>
</td></tr> <tr><td><code>label</code></td>
<td>
<p> the labels taken from list <code>x</code>
</p>
</td></tr> <tr><td><code>est</code></td>
<td>
<p> a vector of the estimates at the minimum. dfp does not
overwrite <code>x</code> </p>
</td></tr> <tr><td><code>status</code></td>
<td>
<p> 0 indicates convergence, 1 indicates
non-convergence </p>
</td></tr> <tr><td><code>nfcn</code></td>
<td>
<p> no. of function calls </p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is part of the Bhat exploration tool
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>References</h3>

<p>Fletcher's Switching Method (Comp.J. 13,317, 1970)
</p>


<h3>See Also</h3>

<p>optim, <code><a href="#topic+newton">newton</a></code>, <code><a href="#topic+ftrf">ftrf</a></code>,
<code><a href="#topic+btrf">btrf</a></code>, <code><a href="#topic+logit.hessian">logit.hessian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
        # generate some Poisson counts on the fly
          dose &lt;- c(rep(0,50),rep(1,50),rep(5,50),rep(10,50))
          data &lt;- cbind(dose,rpois(200,20*(1+dose*.5*(1-dose*0.05))))

        # neg. log-likelihood of Poisson model with 'linear-quadratic' mean: 
          lkh &lt;- function (x) { 
          ds &lt;- data[, 1]
          y  &lt;- data[, 2]
          g &lt;- x[1] * (1 + ds * x[2] * (1 - x[3] * ds)) 
          return(sum(g - y * log(g)))
          }

	# for example define
          x &lt;- list(label=c("a","b","c"),est=c(10.,10.,.01),low=c(0,0,0),upp=c(100,20,.1))

	# call:
	  results &lt;- dfp(x,f=lkh)

</code></pre>

<hr>
<h2 id='dqstep'>step size generator</h2><span id='topic+dqstep'></span>

<h3>Description</h3>

<p><code>dqstep</code> determines the smallest steps ds from s so that
abs(f(s+ds)-f(s)) equals a pre-specified sensitivity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dqstep(x, f, sens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dqstep_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="dqstep_+3A_f">f</code></td>
<td>
<p>the function that is to be minimized over the parameter vector
defined by the list <code>x</code></p>
</td></tr>
<tr><td><code id="dqstep_+3A_sens">sens</code></td>
<td>
<p>target sensitivity (i.e. the value of f(s+ds)-f(s))</p>
</td></tr>
</table>


<h3>Details</h3>

<p>uses simple quadratic interpolation
</p>


<h3>Value</h3>

<p>returns a vector with the desired step sizes
</p>


<h3>Note</h3>

<p>This function is part of the Bhat exploration tool
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfp">dfp</a></code>, <code><a href="#topic+newton">newton</a></code>,
<code><a href="#topic+logit.hessian">logit.hessian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ## Rosenbrock Banana function
   fr &lt;- function(x) {
         x1 &lt;- x[1]
         x2 &lt;- x[2]
         100 * (x2 - x1 * x1)^2 + (1 - x1)^2
    }
  ## define
   x &lt;- list(label=c("a","b"),est=c(1,1),low=c(0,0),upp=c(100,100))
   dqstep(x,fr,sens=1)

</code></pre>

<hr>
<h2 id='ftrf'>Generalized logit transform</h2><span id='topic+ftrf'></span>

<h3>Description</h3>

<p>maps a bounded parameter x onto the real line according to
y=log((x-xl)/(xu-x))), with xl &lt; x &lt; xu. If this constraint is violated, an
error occurs. x may be vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftrf(x, xl, xu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ftrf_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
<tr><td><code id="ftrf_+3A_xl">xl</code></td>
<td>
<p>a numeric vector of same length as x with x &gt; xl</p>
</td></tr>
<tr><td><code id="ftrf_+3A_xu">xu</code></td>
<td>
<p>a numeric vector of same length as x with x &lt; xu</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns numerical vector of transforms
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+btrf">btrf</a></code>
</p>

<hr>
<h2 id='global'>Random search for a global function minimum</h2><span id='topic+global'></span>

<h3>Description</h3>

<p>This function generates MCMC samples from a (posterior) density function f
(not necessarily normalized) in search of a global minimum of f.  It uses a
simple Metropolis algorithm to generate the samples.  Global monitors the
mcmc samples and returns the minimum value of f, as well as a sample
covariance (covm) that can be used as input for the Bhat function mymcmc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>global(
  x,
  nlogf,
  beta = 1,
  mc = 1000,
  scl = 2,
  skip = 1,
  nfcn = 0,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="global_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="global_+3A_nlogf">nlogf</code></td>
<td>
<p>negative log of the density function (not necessarily
normalized)</p>
</td></tr>
<tr><td><code id="global_+3A_beta">beta</code></td>
<td>
<p>'inverse temperature' parameter</p>
</td></tr>
<tr><td><code id="global_+3A_mc">mc</code></td>
<td>
<p>length of MCMC search run</p>
</td></tr>
<tr><td><code id="global_+3A_scl">scl</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="global_+3A_skip">skip</code></td>
<td>
<p>number of cycles skipped for graphical output</p>
</td></tr>
<tr><td><code id="global_+3A_nfcn">nfcn</code></td>
<td>
<p>number of function calls</p>
</td></tr>
<tr><td><code id="global_+3A_plot">plot</code></td>
<td>
<p>logical variable. If TRUE the chain and the negative log
density (nlogf) is plotted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>standard output reports a summary of the acceptance fraction, the current
values of nlogf and the parameters for every (100*skip) th cycle. Plotted
chains show values only for every (skip) th cycle.
</p>


<h3>Value</h3>

<p>list with the following components: </p>
<table>
<tr><td><code>fmin</code></td>
<td>
<p> minimum value of
nlogf for the samples obtained </p>
</td></tr> <tr><td><code>xmin</code></td>
<td>
<p> parameter values at fmin </p>
</td></tr>
<tr><td><code>covm</code></td>
<td>
<p> covariance matrix of differences between consecutive samples
in chain </p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is part of the Bhat package
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>References</h3>

<p>too numerous to be listed here
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfp">dfp</a></code>, <code><a href="#topic+newton">newton</a></code>,
<code><a href="#topic+logit.hessian">logit.hessian</a></code> <code><a href="#topic+mymcmc">mymcmc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate some Poisson counts on the fly
  dose &lt;- c(rep(0,50),rep(1,50),rep(5,50),rep(10,50))
  data &lt;- cbind(dose,rpois(200,20*(1+dose*.5*(1-dose*0.05))))

# neg. log-likelihood of Poisson model with 'linear-quadratic' mean: 
  nlogf &lt;- function (x) { 
  ds &lt;- data[, 1]
  y  &lt;- data[, 2]
  g &lt;- x[1] * (1 + ds * x[2] * (1 - x[3] * ds)) 
  return(sum(g - y * log(g)))
  }

# initialize global search
  x &lt;- list(label=c("a","b","c"), est=c(10, 0.25, 0.05), low=c(0,0,0), upp=c(100,10,.1))
# samples from posterior density (~exp(-nlogf))) with non-informative
# (random uniform) priors for "a", "b" and "c".
out &lt;- global(x, nlogf, beta = 1., mc=1000, scl=2, skip=1, nfcn = 0, plot=TRUE)
# start MCMC from some other point: e.g. try x$est &lt;- c(16,.2,.02)

</code></pre>

<hr>
<h2 id='logit.hessian'>Hessian (curvature matrix)</h2><span id='topic+logit.hessian'></span>

<h3>Description</h3>

<p>Numerical evaluation of the Hessian of a real function f: <code class="reqn">R^n </code><code class="reqn"> \rightarrow R</code> on a generalized logit scale, i.e. using
transformed parameters according to x'=log((x-xl)/(xu-x))), with xl &lt; x &lt;
xu.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit.hessian(
  x = x,
  f = f,
  del = rep(0.002, length(x$est)),
  dapprox = FALSE,
  nfcn = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit.hessian_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="logit.hessian_+3A_f">f</code></td>
<td>
<p>the function for which the Hessian is to be computed at point x</p>
</td></tr>
<tr><td><code id="logit.hessian_+3A_del">del</code></td>
<td>
<p>step size on logit scale (numeric)</p>
</td></tr>
<tr><td><code id="logit.hessian_+3A_dapprox">dapprox</code></td>
<td>
<p>logical variable. If TRUE the off-diagonal elements are set
to zero. If FALSE (default) the full Hessian is computed</p>
</td></tr>
<tr><td><code id="logit.hessian_+3A_nfcn">nfcn</code></td>
<td>
<p>number of function calls</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This version uses a symmetric grid for the numerical evaluation computation
of first and second derivatives.
</p>


<h3>Value</h3>

<p>returns list with </p>
<table>
<tr><td><code>df</code></td>
<td>
<p> first derivatives (logit scale) </p>
</td></tr>
<tr><td><code>ddf</code></td>
<td>
<p> Hessian (logit scale) </p>
</td></tr> <tr><td><code>nfcn</code></td>
<td>
<p> number of function calls
</p>
</td></tr> <tr><td><code>eigen</code></td>
<td>
<p> eigen values (logit scale) </p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is part of the Bhat exploration tool
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfp">dfp</a></code>, <code><a href="#topic+newton">newton</a></code>, <code><a href="#topic+ftrf">ftrf</a></code>,
<code><a href="#topic+btrf">btrf</a></code>, <code><a href="#topic+dqstep">dqstep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ## Rosenbrock Banana function
   fr &lt;- function(x) {
         x1 &lt;- x[1]
         x2 &lt;- x[2]
         100 * (x2 - x1 * x1)^2 + (1 - x1)^2
    }
  ## define
   x &lt;- list(label=c("a","b"),est=c(1,1),low=c(-100,-100),upp=c(100,100))
   logit.hessian(x,f=fr,del=dqstep(x,f=fr,sens=0.01))
  ## shows the differences in curvature at the minimum of the Banana
  ## function along principal axis (in a logit-transformed coordinate system)

</code></pre>

<hr>
<h2 id='mymcmc'>Adaptive Multivariate MCMC sampler</h2><span id='topic+mymcmc'></span>

<h3>Description</h3>

<p>This function generates MCMC-based samples from a (posterior) density f
(not necessarily normalized). It uses a Metropolis algorithm in conjunction
with a multivariate normal proposal distribution which is updated
adaptively by monitoring the correlations of succesive increments of at
least 2 pilot chains. The method is described in De Gunst, Dewanji and
Luebeck (submitted). The adaptive method is similar to the one proposed in
Gelfand and Sahu (JCGS 3:261&ndash;276, 1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mymcmc(
  x,
  nlogf,
  m1,
  m2 = m1,
  m3,
  scl1 = 0.5,
  scl2 = 2,
  skip = 1,
  covm = 0,
  nfcn = 0,
  plot = FALSE,
  plot.range = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mymcmc_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_nlogf">nlogf</code></td>
<td>
<p>negative log of the density function (not necessarily
normalized) for which samples are to be obtained</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_m1">m1</code></td>
<td>
<p>length of first pilot run (not used when covm supplied)</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_m2">m2</code></td>
<td>
<p>length of second pilot run (not used when covm supplied )</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_m3">m3</code></td>
<td>
<p>length of final run</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_scl1">scl1</code></td>
<td>
<p>scale for covariance of mv normal proposal (second pilot run)</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_scl2">scl2</code></td>
<td>
<p>scale for covariance of mv normal proposal (final run)</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_skip">skip</code></td>
<td>
<p>number of cycles skipped for graphical output</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_covm">covm</code></td>
<td>
<p>covariance matrix for multivariate normal proposal
distribution. If supplied, all pilot runs will be skipped and a run of
length m3 will be produced. Useful to continue a simulation from a given
point with specified covm</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_nfcn">nfcn</code></td>
<td>
<p>number of function calls</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_plot">plot</code></td>
<td>
<p>logical variable. If TRUE the chain and the negative log
density (nlogf) is plotted. The first m1+m2 cycles are shown in green,
other cycles in red</p>
</td></tr>
<tr><td><code id="mymcmc_+3A_plot.range">plot.range</code></td>
<td>
<p>[Not documented. Leave as default]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>standard output reports a summary of the acceptance fraction, the current
values of nlogf and the parameters for every (100*skip) th cycle. Plotted
chains show values only for every (skip) th cycle.
</p>


<h3>Value</h3>

<p>list with the following components: </p>
<table>
<tr><td><code>f</code></td>
<td>
<p> values of nlogf for
the samples obtained </p>
</td></tr> <tr><td><code>mcmc</code></td>
<td>
<p> the chain (samples obtained) </p>
</td></tr>
<tr><td><code>covm</code></td>
<td>
<p> current covariance matrix for mv normal proposal
distribution</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is part of the Bhat exploration tool
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>References</h3>

<p>too numerous to be listed here
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfp">dfp</a></code>, <code><a href="#topic+newton">newton</a></code>,
<code><a href="#topic+logit.hessian">logit.hessian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate some Poisson counts on the fly
  dose &lt;- c(rep(0,50),rep(1,50),rep(5,50),rep(10,50))
  data &lt;- cbind(dose,rpois(200,20*(1+dose*.5*(1-dose*0.05))))

# neg. log-likelihood of Poisson model with 'linear-quadratic' mean: 
  nlogf &lt;- function (x) { 
  ds &lt;- data[, 1]
  y  &lt;- data[, 2]
  g &lt;- x[1] * (1 + ds * x[2] * (1 - x[3] * ds)) 
  return(sum(g - y * log(g)))
  }

# start MCMC near mle
  x &lt;- list(label=c("a","b","c"), est=c(20, 0.5, 0.05), low=c(0,0,0), upp=c(100,10,.1))
# samples from posterior density (~exp(-nlogf))) with non-informative
# (random uniform) priors for "a", "b" and "c".
out &lt;- mymcmc(x, nlogf, m1=2000, m2=2000, m3=10000, scl1=0.5, scl2=2, skip=10, plot=TRUE)
# start MCMC from some other point: e.g. try x$est &lt;- c(16,.2,.02)

</code></pre>

<hr>
<h2 id='newton'>Function minimization with box-constraints</h2><span id='topic+newton'></span>

<h3>Description</h3>

<p>Newton-Raphson algorithm for minimizing a function <code>f</code> over the
parameters specified in the input list <code>x</code>. Note, a Newton-Raphson
search is very efficient in the 'quadratic region' near the optimum. In
higher dimensions it tends to be rather unstable and may behave
chaotically. Therefore, a (local or global) minimum should be available to
begin with. Use the <code>optim</code> or <code>dfp</code> functions to search for
optima.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newton(x, f, eps = 0.1, itmax = 10, relax = 0, nfcn = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newton_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="newton_+3A_f">f</code></td>
<td>
<p>the function that is to be minimized over the parameter vector
defined by the list <code>x</code></p>
</td></tr>
<tr><td><code id="newton_+3A_eps">eps</code></td>
<td>
<p>converges when all (logit-transformed) derivatives are smaller
<code>eps</code></p>
</td></tr>
<tr><td><code id="newton_+3A_itmax">itmax</code></td>
<td>
<p>maximum number of Newton-Raphson iterations</p>
</td></tr>
<tr><td><code id="newton_+3A_relax">relax</code></td>
<td>
<p>numeric. If 0, take full Newton step, otherwise 'relax' step
incrementally until a better value is found</p>
</td></tr>
<tr><td><code id="newton_+3A_nfcn">nfcn</code></td>
<td>
<p>number of function calls</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components: </p>
<table>
<tr><td><code>fmin</code></td>
<td>
<p> the function
value f at the minimum </p>
</td></tr> <tr><td><code>label</code></td>
<td>
<p> the labels </p>
</td></tr> <tr><td><code>est</code></td>
<td>
<p> a vector
of the parameter estimates at the minimum. newton does not overwrite
<code>x</code> </p>
</td></tr> <tr><td><code>low</code></td>
<td>
<p> lower 95% (Wald) confidence bound </p>
</td></tr> <tr><td><code>upp</code></td>
<td>

<p>upper 95% (Wald) confidence bound </p>
</td></tr></table>
<p> The confidence bounds assume that the
function <code>f</code> is a negative log-likelihood
</p>


<h3>Note</h3>

<p><code>newton</code> computes the (logit-transformed) Hessian of <code>f</code>
(using logit.hessian). This function is part of the Bhat exploration tool
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfp">dfp</a></code>, <code><a href="#topic+ftrf">ftrf</a></code>, <code><a href="#topic+btrf">btrf</a></code>,
<code><a href="#topic+logit.hessian">logit.hessian</a></code>, <code><a href="#topic+plkhci">plkhci</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
        # generate some Poisson counts on the fly
          dose &lt;- c(rep(0,100),rep(1,100),rep(5,100),rep(10,100))
          data &lt;- cbind(dose,rpois(400,20*(1+dose*.5*(1-dose*0.05))))

        # neg. log-likelihood of Poisson model with 'linear-quadratic' mean: 
          lkh &lt;- function (x) { 
          ds &lt;- data[, 1]
          y  &lt;- data[, 2]
          g &lt;- x[1] * (1 + ds * x[2] * (1 - x[3] * ds)) 
          return(sum(g - y * log(g)))
          }

	# for example define
          x &lt;- list(label=c("a","b","c"),est=c(10.,10.,.01),low=c(0,0,0),upp=c(100,20,.1))

	# calls:
	  r &lt;- dfp(x,f=lkh)
          x$est &lt;- r$est
          results &lt;- newton(x,lkh)

</code></pre>

<hr>
<h2 id='plkhci'>Profile-likelihood based confidence intervals</h2><span id='topic+plkhci'></span>

<h3>Description</h3>

<p>function to find <code>prob</code>*100% confidence intervals using
profile-likelihood. Numerical solutions are obtained via a modified
Newton-Raphson algorithm. The method is described in Venzon and Moolgavkar,
Journal of the Royal Statistical Society, Series C vol 37, no.1, 1988, pp.
87-94.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plkhci(x, nlogf, label, prob = 0.95, eps = 0.001, nmax = 10, nfcn = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plkhci_+3A_x">x</code></td>
<td>
<p>a list with components 'label' (of mode character), 'est' (the
parameter vector with the initial guess), 'low' (vector with lower bounds),
and 'upp' (vector with upper bounds)</p>
</td></tr>
<tr><td><code id="plkhci_+3A_nlogf">nlogf</code></td>
<td>
<p>the negative log of the density function (not necessarily
normalized) for which samples are to be obtained</p>
</td></tr>
<tr><td><code id="plkhci_+3A_label">label</code></td>
<td>
<p>parameter for which confidence bounds are computed</p>
</td></tr>
<tr><td><code id="plkhci_+3A_prob">prob</code></td>
<td>
<p>probability associated with the confidence interval</p>
</td></tr>
<tr><td><code id="plkhci_+3A_eps">eps</code></td>
<td>
<p>a numerical value. Convergence results when all
(logit-transformed) derivatives are smaller <code>eps</code></p>
</td></tr>
<tr><td><code id="plkhci_+3A_nmax">nmax</code></td>
<td>
<p>maximum number of Newton-Raphson iterations in each direction</p>
</td></tr>
<tr><td><code id="plkhci_+3A_nfcn">nfcn</code></td>
<td>
<p>number of function calls</p>
</td></tr>
</table>


<h3>Value</h3>

<p>2 component vector giving lower and upper p% confidence bounds
</p>


<h3>Note</h3>

<p>At this point, only a single parameter label can be passed to plkhci.
This function is part of the Bhat exploration tool
</p>


<h3>Author(s)</h3>

<p>E. Georg Luebeck (FHCRC)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfp">dfp</a></code>, <code><a href="#topic+newton">newton</a></code>,
<code><a href="#topic+logit.hessian">logit.hessian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
        # generate some Poisson counts on the fly
          dose &lt;- c(rep(0,50),rep(1,50),rep(5,50),rep(10,50))
          data &lt;- cbind(dose,rpois(200,20*(1+dose*.5*(1-dose*0.05))))

        # neg. log-likelihood of Poisson model with 'linear-quadratic' mean: 
          nlogf &lt;- function (x) { 
          ds &lt;- data[, 1]
          y  &lt;- data[, 2]
          g &lt;- x[1] * (1 + ds * x[2] * (1 - x[3] * ds)) 
          return(sum(g - y * log(g)))
          }

	# for example define
          x &lt;- list(label=c("a","b","c"),est=c(10.,10.,.01),low=c(0,0,0),upp=c(100,20,.1))

	# get MLEs using dfp:
	  r &lt;- dfp(x,f=nlogf)
          x$est &lt;- r$est
          plkhci(x,nlogf,"a")
          plkhci(x,nlogf,"b")
          plkhci(x,nlogf,"c")
	# e.g. 90% confidence bounds for "c" 
          plkhci(x,nlogf,"c",prob=0.9)
        

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
