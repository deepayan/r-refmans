<!DOCTYPE html><html lang="en"><head><title>Help for package TMB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TMB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.list.sdreport'><p>Convert estimates to original list format.</p></a></li>
<li><a href='#benchmark'><p>Benchmark parallel templates</p></a></li>
<li><a href='#checkConsistency'><p>Check consistency and Laplace accuracy</p></a></li>
<li><a href='#compile'><p>Compile a C++ template to DLL suitable for MakeADFun.</p></a></li>
<li><a href='#config'><p>Get or set internal configuration variables</p></a></li>
<li><a href='#confint.tmbprofile'><p>Profile based confidence intervals.</p></a></li>
<li><a href='#dynlib'><p>Add dynlib extension</p></a></li>
<li><a href='#FreeADFun'><p>Free memory allocated on the C++ side by <code>MakeADFun</code>.</p></a></li>
<li><a href='#gdbsource'><p>Source R-script through gdb to get backtrace.</p></a></li>
<li><a href='#GK'><p>Gauss Kronrod configuration</p></a></li>
<li><a href='#MakeADFun'><p>Construct objective functions with derivatives based on a compiled C++ template.</p></a></li>
<li><a href='#newton'><p>Generalized newton optimizer.</p></a></li>
<li><a href='#newtonOption'><p>Set newton options for a model object.</p></a></li>
<li><a href='#normalize'><p>Normalize process likelihood using the Laplace approximation.</p></a></li>
<li><a href='#oneStepPredict'><p>Calculate one-step-ahead (OSA) residuals for a latent variable model.</p></a></li>
<li><a href='#openmp'><p>Control number of OpenMP threads used by a TMB model.</p></a></li>
<li><a href='#plot.tmbprofile'><p>Plot likelihood profile.</p></a></li>
<li><a href='#precompile'><p>Precompile the TMB library in order to speed up compilation of templates.</p></a></li>
<li><a href='#print.checkConsistency'><p>Print output from <code>checkConsistency</code></p></a></li>
<li><a href='#print.sdreport'><p>Print brief model summary</p></a></li>
<li><a href='#Rinterface'><p>Create minimal R-code corresponding to a cpp template.</p></a></li>
<li><a href='#runExample'><p>Run one of the test examples.</p></a></li>
<li><a href='#runSymbolicAnalysis'><p>Run symbolic analysis on sparse Hessian</p></a></li>
<li><a href='#sdreport'><p>General sdreport function.</p></a></li>
<li><a href='#SR'><p>Sequential reduction configuration</p></a></li>
<li><a href='#summary.checkConsistency'><p>Summarize output from <code>checkConsistency</code></p></a></li>
<li><a href='#summary.sdreport'><p>summary tables of model parameters</p></a></li>
<li><a href='#template'><p>Create cpp template to get started.</p></a></li>
<li><a href='#TMB.Version'><p>Version information on API and ABI.</p></a></li>
<li><a href='#tmbprofile'><p>Adaptive likelihood profiling.</p></a></li>
<li><a href='#tmbroot'><p>Compute likelihood profile confidence intervals of a TMB object by root-finding</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Template Model Builder: A General Random Effect Tool Inspired by
'ADMB'</td>
</tr>
<tr>
<td>Version:</td>
<td>1.9.17</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-08</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kasper Kristensen &lt;kaskr@dtu.dk&gt;</td>
</tr>
<tr>
<td>Author:</td>
<td>Kasper Kristensen [aut, cre, cph],
  Brad Bell [cph],
  Hans Skaug [ctb],
  Arni Magnusson [ctb],
  Casper Berg [ctb],
  Anders Nielsen [ctb],
  Martin Maechler [ctb],
  Theo Michelot [ctb],
  Mollie Brooks [ctb],
  Alex Forrence [ctb],
  Christoffer Moesgaard Albertsen [ctb],
  Cole Monnahan [ctb]</td>
</tr>
<tr>
<td>Copyright:</td>
<td>See the file COPYRIGHTS</td>
</tr>
<tr>
<td>Description:</td>
<td>With this tool, a user should be able to quickly implement
    complex random effect models through simple C++ templates. The package combines
    'CppAD' (C++ automatic differentiation), 'Eigen' (templated matrix-vector
    library) and 'CHOLMOD' (sparse matrix routines available from R) to obtain
    an efficient implementation of the applied Laplace approximation with exact
    derivatives. Key features are: Automatic sparseness detection, parallelism
    through 'BLAS' and parallel user templates.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kaskr/adcomp/wiki">https://github.com/kaskr/adcomp/wiki</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kaskr/adcomp/issues">https://github.com/kaskr/adcomp/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, methods, stats, utils, Matrix (&ge; 1.0-12)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Matrix, RcppEigen</td>
</tr>
<tr>
<td>Suggests:</td>
<td>numDeriv, parallel</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-08 10:47:07 UTC; kaskr</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-10 08:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.list.sdreport'>Convert estimates to original list format.</h2><span id='topic+as.list.sdreport'></span>

<h3>Description</h3>

<p>Get estimated parameters or standard errors in the same shape as
the original parameter list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdreport'
as.list(x, what = "", report = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.list.sdreport_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+sdreport">sdreport</a></code>.</p>
</td></tr>
<tr><td><code id="as.list.sdreport_+3A_what">what</code></td>
<td>
<p>Select what to convert (Estimate / Std. Error).</p>
</td></tr>
<tr><td><code id="as.list.sdreport_+3A_report">report</code></td>
<td>
<p>Get AD reported variables rather than model parameters ?</p>
</td></tr>
<tr><td><code id="as.list.sdreport_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="#topic+summary.sdreport">summary.sdreport</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts the selected column <code>what</code> of
<code>summary(x, select = c("fixed", "random"), ...)</code> to the same
format as the original parameter list (re-ordered as the template
parameter order). The argument <code>what</code> is partially matched
among the column names of the summary table. The actual match is
added as an attribute to the output.
</p>


<h3>Value</h3>

<p>List of same shape as original parameter list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
example(sdreport)

## Estimates as a parameter list:
as.list(rep, "Est")

## Std Errors in the same list format:
as.list(rep, "Std")

## p-values in the same list format:
as.list(rep, "Pr", p.value=TRUE)

## AD reported variables as a list:
as.list(rep, "Estimate", report=TRUE)

## Bias corrected AD reported variables as a list:
as.list(rep, "Est. (bias.correct)", report=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='benchmark'>Benchmark parallel templates</h2><span id='topic+benchmark'></span><span id='topic+plot.parallelBenchmark'></span>

<h3>Description</h3>

<p>Benchmark parallel templates
</p>
<p>Plot result of parallel benchmark
</p>


<h3>Usage</h3>

<pre><code class='language-R'>benchmark(obj, n = 10, expr = NULL, cores = NULL)

## S3 method for class 'parallelBenchmark'
plot(x, type = "b", ..., show = c("speedup", "time"), legendpos = "topleft")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="benchmark_+3A_obj">obj</code></td>
<td>
<p>Object from <code>MakeADFun</code></p>
</td></tr>
<tr><td><code id="benchmark_+3A_n">n</code></td>
<td>
<p>Number of replicates to obtain reliable results.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_expr">expr</code></td>
<td>
<p>Optional expression to benchmark instead of default.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_cores">cores</code></td>
<td>
<p>Optional vector of cores.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_x">x</code></td>
<td>
<p>Object to plot</p>
</td></tr>
<tr><td><code id="benchmark_+3A_type">type</code></td>
<td>
<p>Plot type</p>
</td></tr>
<tr><td><code id="benchmark_+3A_...">...</code></td>
<td>
<p>Further plot arguments</p>
</td></tr>
<tr><td><code id="benchmark_+3A_show">show</code></td>
<td>
<p>Plot relative speedup or relative time?</p>
</td></tr>
<tr><td><code id="benchmark_+3A_legendpos">legendpos</code></td>
<td>
<p>Position of legend</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default this function will perform timings of the most critical
parts of an AD model, specifically
</p>

<ol>
<li><p> Objective function of evaluated template.
</p>
</li>
<li><p> Gradient of evaluated template.
</p>
</li>
<li><p> Sparse hessian of evaluated template.
</p>
</li>
<li><p> Cholesky factorization of sparse hessian.
</p>
</li></ol>

<p>(for pure fixed effect models only the first two).
Expressions to time can be overwritten by the user (<code>expr</code>).
A <code>plot</code> method is available for Parallel benchmarks.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
runExample("linreg_parallel",thisR=TRUE)  ## Create obj
ben &lt;- benchmark(obj,n=100,cores=1:4)
plot(ben)
ben &lt;- benchmark(obj,n=10,cores=1:4,expr=expression(do.call("optim",obj)))
plot(ben)

## End(Not run)
</code></pre>

<hr>
<h2 id='checkConsistency'>Check consistency and Laplace accuracy</h2><span id='topic+checkConsistency'></span>

<h3>Description</h3>

<p>Check consistency of various parts of a TMB implementation.
Requires that user has implemented simulation code for the data and
optionally random effects. (<em>Beta version; may change without
notice</em>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkConsistency(
  obj,
  par = NULL,
  hessian = FALSE,
  estimate = FALSE,
  n = 100,
  observation.name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkConsistency_+3A_obj">obj</code></td>
<td>
<p>Object from <code>MakeADFun</code></p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_par">par</code></td>
<td>
<p>Parameter vector (<code class="reqn">\theta</code>) for simulation. If
unspecified use the best encountered parameter of the object.</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_hessian">hessian</code></td>
<td>
<p>Calculate the hessian matrix for each replicate ?</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_estimate">estimate</code></td>
<td>
<p>Estimate parameters for each replicate ?</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_n">n</code></td>
<td>
<p>Number of simulations</p>
</td></tr>
<tr><td><code id="checkConsistency_+3A_observation.name">observation.name</code></td>
<td>
<p>Optional; Name of simulated observation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function checks that the simulation code of random effects and
data is consistent with the implemented negative log-likelihood
function. It also checks whether the approximate <em>marginal</em>
score function is central indicating whether the Laplace
approximation is suitable for parameter estimation.
</p>
<p>Denote by <code class="reqn">u</code> the random effects, <code class="reqn">\theta</code> the parameters
and by <code class="reqn">x</code> the data.  The main assumption is that the user has
implemented the joint negative log likelihood <code class="reqn">f_{\theta}(u,x)</code>
satisfying
</p>
<p style="text-align: center;"><code class="reqn">\int \int \exp( -f_{\theta}(u,x) ) \:du\:dx = 1</code>
</p>

<p>It follows that the joint and marginal score functions are central:
</p>

<ol>
<li> <p><code class="reqn">E_{u,x}\left[\nabla_{\theta}f_{\theta}(u,x)\right]=0</code>
</p>
</li>
<li> <p><code class="reqn">E_{x}\left[\nabla_{\theta}-\log\left( \int \exp(-f_{\theta}(u,x))\:du \right) \right]=0</code>
</p>
</li></ol>

<p>For each replicate of <code class="reqn">u</code> and <code class="reqn">x</code> joint and marginal
gradients are calculated. Appropriate centrality tests are carried
out by <code><a href="#topic+summary.checkConsistency">summary.checkConsistency</a></code>.  An asymptotic
<code class="reqn">\chi^2</code> test is used to verify the first identity. Power of
this test increases with the number of simulations <code>n</code>.  The
second identity holds <em>approximately</em> when replacing the
marginal likelihood with its Laplace approximation. A formal test
would thus fail eventually for large <code>n</code>. Rather, the gradient
bias is transformed to parameter scale (using the estimated
information matrix) to provide an estimate of parameter bias caused
by the Laplace approximation.
</p>


<h3>Value</h3>

<p>List with gradient simulations (joint and marginal)
</p>


<h3>Simulation/re-estimation</h3>

<p>A full simulation/re-estimation study is performed when <code>estimate=TRUE</code>.
By default <a href="stats.html#topic+nlminb">nlminb</a> will be used to perform the minimization, and output is stored in a separate list component 'estimate' for each replicate.
Should a custom optimizer be needed, it can be passed as a user function via the same argument (<code>estimate</code>).
The function (<code>estimate</code>) will be called for each simulation as <code>estimate(obj)</code> where <code>obj</code> is the simulated model object.
Current default corresponds to <code>estimate = function(obj) nlminb(obj$par,obj$fn,obj$gr)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.checkConsistency">summary.checkConsistency</a></code>, <code><a href="#topic+print.checkConsistency">print.checkConsistency</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
runExample("simple")
chk &lt;- checkConsistency(obj)
chk
## Get more details
s &lt;- summary(chk)
s$marginal$p.value  ## Laplace exact for Gaussian models 
## End(Not run)
</code></pre>

<hr>
<h2 id='compile'>Compile a C++ template to DLL suitable for MakeADFun.</h2><span id='topic+compile'></span>

<h3>Description</h3>

<p>Compile a C++ template into a shared object file. OpenMP flag is set if the template is detected to be parallel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compile(
  file,
  flags = "",
  safebounds = TRUE,
  safeunload = TRUE,
  openmp = isParallelTemplate(file[1]),
  libtmb = TRUE,
  libinit = TRUE,
  tracesweep = FALSE,
  framework = getOption("tmb.ad.framework"),
  supernodal = FALSE,
  longint = FALSE,
  eigen.disable.warnings = TRUE,
  max.order = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compile_+3A_file">file</code></td>
<td>
<p>C++ file.</p>
</td></tr>
<tr><td><code id="compile_+3A_flags">flags</code></td>
<td>
<p>Character with compile flags.</p>
</td></tr>
<tr><td><code id="compile_+3A_safebounds">safebounds</code></td>
<td>
<p>Turn on preprocessor flag for bound checking?</p>
</td></tr>
<tr><td><code id="compile_+3A_safeunload">safeunload</code></td>
<td>
<p>Turn on preprocessor flag for safe DLL unloading?</p>
</td></tr>
<tr><td><code id="compile_+3A_openmp">openmp</code></td>
<td>
<p>Turn on openmp flag? Auto detected for parallel templates.</p>
</td></tr>
<tr><td><code id="compile_+3A_libtmb">libtmb</code></td>
<td>
<p>Use precompiled TMB library if available (to speed up compilation)?</p>
</td></tr>
<tr><td><code id="compile_+3A_libinit">libinit</code></td>
<td>
<p>Turn on preprocessor flag to register native routines?</p>
</td></tr>
<tr><td><code id="compile_+3A_tracesweep">tracesweep</code></td>
<td>
<p>Turn on preprocessor flag to trace AD sweeps? (Silently disables <code>libtmb</code>)</p>
</td></tr>
<tr><td><code id="compile_+3A_framework">framework</code></td>
<td>
<p>Which AD framework to use ('TMBad' or 'CppAD')</p>
</td></tr>
<tr><td><code id="compile_+3A_supernodal">supernodal</code></td>
<td>
<p>Turn on preprocessor flag to use supernodal sparse Cholesky/Inverse from system wide suitesparse library</p>
</td></tr>
<tr><td><code id="compile_+3A_longint">longint</code></td>
<td>
<p>Turn on preprocessor flag to use long integers for Eigen's SparseMatrix StorageIndex</p>
</td></tr>
<tr><td><code id="compile_+3A_eigen.disable.warnings">eigen.disable.warnings</code></td>
<td>
<p>Turn on preprocessor flag to disable nuisance warnings. Note that this is not allowed for code to be compiled on CRAN.</p>
</td></tr>
<tr><td><code id="compile_+3A_max.order">max.order</code></td>
<td>
<p>Maximum derivative order of compiler generated atomic special functions - see details.</p>
</td></tr>
<tr><td><code id="compile_+3A_...">...</code></td>
<td>
<p>Passed as Makeconf variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TMB relies on R's built in functionality to create shared libraries independent of the platform.
A template is compiled by <code>compile("template.cpp")</code>, which will call R's makefile with appropriate
preprocessor flags.
Compiler and compiler flags can be stored in a configuration file. In order of precedence either via
the file pointed at by R_MAKEVARS_USER or the file ~/.R/Makevars if it exists.
Additional configuration variables can be set with the <code>flags</code> and <code>...</code> arguments, which will override any
previous selections.
</p>


<h3>Using a custom SuiteSparse installation</h3>

<p>Sparse matrix calculations play an important role in TMB. By default TMB uses a small subset of <code>SuiteSparse</code> available through the R package <code>Matrix</code>. This is sufficient for most use cases, however for some very large models the following extra features are worth considering:
</p>

<ul>
<li><p> Some large models benefit from an extended set of graph reordering algorithms (especially METIS) not part of <code>Matrix</code>. It is common that these orderings can provide quite big speedups.
</p>
</li>
<li><p> Some large models need sparse matrices with number of nonzeros exceeding the current 32 bit limitation of <code>Matrix</code>. Normally such cases will result in the cholmod error 'problem too large'. <code>SuiteSparse</code> includes 64 bit integer routines to address this problem.
</p>
</li></ul>

<p>Experimental support for linking to a <em>custom</em> <code>SuiteSparse</code> installation is available through two arguments to the <code><a href="#topic+compile">compile</a></code> function. The first argument <code>supernodal=TRUE</code> tells TMB to use the supernodal Cholesky factorization from the system wide <code>SuiteSparse</code> on the C++ side. This will affect the speed of the Laplace approximation when run internally (using arguments <code>intern</code> or <code>integrate</code> to <code><a href="#topic+MakeADFun">MakeADFun</a></code>).
</p>
<p>The second argument <code>longint=TRUE</code> tells TMB to use 64 bit integers for sparse matrices on the C++ side. This works in combination with <code>supernodal=TRUE</code> from Eigen version 3.4.
</p>
<p>On Windows a <code>SuiteSparse</code> installation can be obtained using the <code>Rtools</code> package manager. Start 'Rtools Bash' terminal and run:
</p>
<pre>
  pacman -Sy
  pacman -S mingw-w64-{i686,x86_64}-suitesparse
</pre>
<p>On Linux one should look for the package <code>libsuitesparse-dev</code>.
</p>


<h3>Selecting the AD framework</h3>

<p>TMB supports two different AD libraries 'CppAD' and 'TMBad' selected via the argument <code>framework</code> which works as a switch to set one of two C++ preprocessor flags: 'CPPAD_FRAMEWORK' or 'TMBAD_FRAMEWORK'. The default value of <code>framework</code> can be set from R by <code>options("tmb.ad.framework")</code> or alternatively from the shell via the environment variable 'TMB_AD_FRAMEWORK'. Packages linking to TMB should set one of the two C++ preprocessor flags in Makevars.
</p>


<h3>Order of compiler generated atomic functions</h3>

<p>The argument <code>max.order</code> controls the maximum derivative order of special functions (e.g. <code>pbeta</code>) generated by the compiler. By default the value is set to 3 which is sufficient to obtain the Laplace approximation (order 2) and its derivatives (order 3). However, sometimes a higher value may be needed. For example <code>framework='TMBad'</code> allows one to calculate the Hessian of the Laplace approximation, but that requires 4th order derivatives of special functions in use. A too small value will cause the runtime error 'increase TMB_MAX_ORDER'. Note that compilation time and binary size increases with <code>max.order</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+precompile">precompile</a></code>
</p>

<hr>
<h2 id='config'>Get or set internal configuration variables</h2><span id='topic+config'></span>

<h3>Description</h3>

<p>Get or set internal configuration variables of user's DLL.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config(..., DLL = getUserDLL())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="config_+3A_...">...</code></td>
<td>
<p>Variables to set</p>
</td></tr>
<tr><td><code id="config_+3A_dll">DLL</code></td>
<td>
<p>Name of user's DLL. Auto-detected if missing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A model compiled with the <code>TMB</code> C++ library has several
configuration variables set by default. The variables can be read
and modified using this function. The meaning of the variables can
be found in the Doxygen documentation.
</p>


<h3>Value</h3>

<p>List with current configuration
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Load library
dyn.load(dynlib("mymodel"))
## Read the current settings
config(DLL="mymodel")
## Reduce memory peak of a parallel model by creating tapes in serial
config(tape.parallel=0, DLL="mymodel")
obj &lt;- MakeADFun(..., DLL="mymodel")

## End(Not run)
</code></pre>

<hr>
<h2 id='confint.tmbprofile'>Profile based confidence intervals.</h2><span id='topic+confint.tmbprofile'></span>

<h3>Description</h3>

<p>Calculate confidence interval from a likelihood profile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tmbprofile'
confint(object, parm, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.tmbprofile_+3A_object">object</code></td>
<td>
<p>Output from <code><a href="#topic+tmbprofile">tmbprofile</a></code>.</p>
</td></tr>
<tr><td><code id="confint.tmbprofile_+3A_parm">parm</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="confint.tmbprofile_+3A_level">level</code></td>
<td>
<p>Confidence level.</p>
</td></tr>
<tr><td><code id="confint.tmbprofile_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lower and upper limit as a matrix.
</p>

<hr>
<h2 id='dynlib'>Add dynlib extension</h2><span id='topic+dynlib'></span>

<h3>Description</h3>

<p>Add the platform dependent dynlib extension. In order for examples
to work across platforms DLLs should be loaded by
<code>dyn.load(dynlib("name"))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynlib(name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dynlib_+3A_name">name</code></td>
<td>
<p>Library name without extension</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character
</p>

<hr>
<h2 id='FreeADFun'>Free memory allocated on the C++ side by <code>MakeADFun</code>.</h2><span id='topic+FreeADFun'></span>

<h3>Description</h3>

<p>Free memory allocated on the C++ side by <code>MakeADFun</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FreeADFun(obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FreeADFun_+3A_obj">obj</code></td>
<td>
<p>Object returned by <code>MakeADFun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>An object returned by <code>MakeADFun</code> contains pointers to
structures allocated on the C++ side. These are managed by R's
garbage collector which for the most cases is sufficient. However,
because the garbage collector is unaware of the C++ object sizes,
it may fail to release memory to the system as frequently as
necessary. In such cases one can manually call
<code>FreeADFun(obj)</code> to release the resources.
</p>


<h3>Memory management</h3>

<p>Memory allocated on the C++ side by <code>MakeADFun</code> is
represented by external pointers. Each such pointer has an
associated 'finalizer' (see <code>reg.finalizer</code>) that deallocates
the external pointer when <code>gc()</code> decides the pointer is no
longer needed.  Deallocated pointers are recognized on the R
side as external null pointers <code>&lt;pointer: (nil)&gt;</code>. This is
important as it provides a way to prevent the finalizers from
freeing pointers that have already been deallocated <em>even if
the deallocation C-code has been unloaded</em>.
The user DLL maintains a list of all external pointers on the C
side. Three events can reduce the list:
</p>

<ul>
<li><p> Garbage collection of an external pointer that is no longer needed (triggers corresponding finalizer).
</p>
</li>
<li><p> Explicit deallocation of external pointers using <code>FreeADFun()</code> (corresponding finalizers are untriggered but harmless).
</p>
</li>
<li><p> Unload/reload of the user's DLL deallocates all external pointers (corresponding finalizers are untriggered but harmless).
</p>
</li></ul>



<h3>Note</h3>

<p>This function is normally not needed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>runExample("simple", thisR = TRUE)          ## Create 'obj'
FreeADFun(obj)                              ## Free external pointers
obj$fn()                                    ## Re-allocate external pointers
</code></pre>

<hr>
<h2 id='gdbsource'>Source R-script through gdb to get backtrace.</h2><span id='topic+gdbsource'></span><span id='topic+print.backtrace'></span>

<h3>Description</h3>

<p>Source R-script through gdb to get backtrace.
</p>
<p>If <code>gdbsource</code> is run non-interactively (the default) only
the relevant information will be printed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gdbsource(file, interactive = FALSE)

## S3 method for class 'backtrace'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gdbsource_+3A_file">file</code></td>
<td>
<p>Your R script</p>
</td></tr>
<tr><td><code id="gdbsource_+3A_interactive">interactive</code></td>
<td>
<p>Run interactive gdb session?</p>
</td></tr>
<tr><td><code id="gdbsource_+3A_x">x</code></td>
<td>
<p>Backtrace from <code>gdbsource</code></p>
</td></tr>
<tr><td><code id="gdbsource_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is useful for debugging templates.
If a script aborts e.g. due to an out-of-bound index operation
it should be fast to locate the line that caused the problem by
running <code>gdbsource(file)</code>.
Alternatively, If more detailed debugging is required,  then
<code>gdbsource(file,TRUE)</code> will provide the full backtrace followed
by an interactive gdb session where the individual frames can be inspected.
Note that templates should be compiled without optimization and with debug
information in order to provide correct line numbers:
</p>

<ul>
<li><p> On Linux/OS X use <code>compile(cppfile,"-O0 -g")</code>.
</p>
</li>
<li><p> On Windows use <code>compile(cppfile,"-O1 -g",DLLFLAGS="")</code> (lower
optimization level will cause errors).
</p>
</li></ul>



<h3>Value</h3>

<p>Object of class <code>backtrace</code>
</p>

<hr>
<h2 id='GK'>Gauss Kronrod configuration</h2><span id='topic+GK'></span>

<h3>Description</h3>

<p>Helper function to specify parameters used by the Gauss Kronrod
integration available through the argument <code>integrate</code> to
<code>MakeADFun</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GK(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GK_+3A_...">...</code></td>
<td>
<p>See source code</p>
</td></tr>
</table>

<hr>
<h2 id='MakeADFun'>Construct objective functions with derivatives based on a compiled C++ template.</h2><span id='topic+MakeADFun'></span>

<h3>Description</h3>

<p>Construct objective functions with derivatives based on the users C++ template.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeADFun(
  data,
  parameters,
  map = list(),
  type = c("ADFun", "Fun", "ADGrad"[!intern &amp;&amp; (!is.null(random) || !is.null(profile))]),
  random = NULL,
  profile = NULL,
  random.start = expression(last.par.best[random]),
  hessian = FALSE,
  method = "BFGS",
  inner.method = "newton",
  inner.control = list(maxit = 1000),
  MCcontrol = list(doMC = FALSE, seed = 123, n = 100),
  ADreport = FALSE,
  atomic = TRUE,
  LaplaceNonZeroGradient = FALSE,
  DLL = getUserDLL(),
  checkParameterOrder = TRUE,
  regexp = FALSE,
  silent = FALSE,
  intern = FALSE,
  integrate = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeADFun_+3A_data">data</code></td>
<td>
<p>List of data objects (vectors, matrices, arrays, factors, sparse matrices) required by the user template (order does not matter and un-used components are allowed).</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_parameters">parameters</code></td>
<td>
<p>List of all parameter objects required by the user template (both random and fixed effects).</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_map">map</code></td>
<td>
<p>List defining how to optionally collect and fix parameters - see details.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_type">type</code></td>
<td>
<p>Character vector defining which operation stacks are generated from the users template - see details.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_random">random</code></td>
<td>
<p>Character vector defining the random effect parameters. See also <code>regexp</code>.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_profile">profile</code></td>
<td>
<p>Parameters to profile out of the likelihood (this subset will be appended to <code>random</code> with Laplace approximation disabled).</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_random.start">random.start</code></td>
<td>
<p>Expression defining the strategy for choosing random effect initial values as function of previous function evaluations - see details.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_hessian">hessian</code></td>
<td>
<p>Calculate Hessian at optimum?</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_method">method</code></td>
<td>
<p>Outer optimization method.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_inner.method">inner.method</code></td>
<td>
<p>Inner optimization method (see function &quot;newton&quot;).</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_inner.control">inner.control</code></td>
<td>
<p>List controlling inner optimization.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_mccontrol">MCcontrol</code></td>
<td>
<p>List controlling importance sampler (turned off by default).</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_adreport">ADreport</code></td>
<td>
<p>Calculate derivatives of macro ADREPORT(vector) instead of objective_function return value?</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_atomic">atomic</code></td>
<td>
<p>Allow tape to contain atomic functions?</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_laplacenonzerogradient">LaplaceNonZeroGradient</code></td>
<td>
<p>Allow Taylor expansion around non-stationary point?</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_dll">DLL</code></td>
<td>
<p>Name of shared object file compiled by user (without the conventional extension, &lsquo;<span class="file">.so</span>&rsquo;, &lsquo;<span class="file">.dll</span>&rsquo;, ...).</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_checkparameterorder">checkParameterOrder</code></td>
<td>
<p>Optional check for correct parameter order.</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_regexp">regexp</code></td>
<td>
<p>Match random effects by regular expressions?</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_silent">silent</code></td>
<td>
<p>Disable all tracing information?</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_intern">intern</code></td>
<td>
<p>Do Laplace approximation on C++ side ? See details (Experimental - may change without notice)</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_integrate">integrate</code></td>
<td>
<p>Specify alternative integration method(s) for random effects (see details)</p>
</td></tr>
<tr><td><code id="MakeADFun_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A call to <code>MakeADFun</code> will return an object that, based on the users DLL code (specified through <code>DLL</code>), contains functions to calculate the objective function
and its gradient. The object contains the following components:
</p>

<ul>
<li> <p><code>par</code> A default parameter.
</p>
</li>
<li> <p><code>fn</code> The likelihood function.
</p>
</li>
<li> <p><code>gr</code> The gradient function.
</p>
</li>
<li> <p><code>report</code> A function to report all variables reported with the REPORT() macro in the user template.
</p>
</li>
<li> <p><code>env</code> Environment with access to all parts of the structure.
</p>
</li></ul>

<p>and is thus ready for a call to an R optimizer, such as <code>nlminb</code> or <code>optim</code>.
Data (<code>data</code>) and parameters (<code>parameters</code>) are directly read by the user template via the macros beginning with DATA_
and PARAMETER_. The order of the PARAMETER_ macros defines the order of parameters in the final objective function.
There are no restrictions on the order of random parameters, fixed parameters or data in the template.
</p>


<h3>Value</h3>

<p>List with components (fn, gr, etc) suitable for calling an R optimizer, such as <code>nlminb</code> or <code>optim</code>.
</p>


<h3>Parameter mapping</h3>

<p>Optionally, a simple mechanism for collecting and fixing parameters from R is available through the <code>map</code> argument. A map is a named list
of factors with the following properties:
</p>

<ul>
<li><p> names(map) is a subset of names(parameters).
</p>
</li>
<li><p> For a parameter &quot;p&quot; length(map$p) equals length(parameters$p).
</p>
</li>
<li><p> Parameter entries with NAs in the factor are fixed.
</p>
</li>
<li><p> Parameter entries with equal factor level are collected to a common value.
</p>
</li></ul>

<p>More advanced parameter mapping, such as collecting parameters between different vectors etc., must be implemented from the template.
</p>


<h3>Specifying random effects</h3>

<p>Random effects are specified via the argument <code>random</code>: A component of the parameter list is marked as random if its name is matched
by any of the characters of the vector <code>random</code> (Regular expression match is performed if <code>regexp=TRUE</code>).
If some parameters are specified as random effects, these will
be integrated out of the objective function via the Laplace approximation. In this situation the functions <code>fn</code> and <code>gr</code>
automatically perform an optimization of random effects for each function evaluation. This is referred to as
the 'inner optimization'. Strategies for choosing initial values of the inner optimization can be controlled
via the argument <code>random.start</code>. The default is <code>expression(last.par.best[random])</code>
where <code>last.par.best</code> is an internal full parameter vector corresponding to the currently best
likelihood. An alternative choice could be <code>expression(last.par[random])</code> i.e. the random effect optimum of
the most recent - not necessarily best - likelihood evaluation. Further control of the inner optimization can
be obtained by the argument <code>inner.control</code> which is a list of control parameters for the inner optimizer
<code>newton</code>. Depending of the inner optimization problem type the following settings are recommended:
</p>

<ol>
<li><p> Quasi-convex: <code>smartsearch=TRUE</code> (the default).
</p>
</li>
<li><p> Strictly-convex: <code>smartsearch=FALSE</code> and <code>maxit=20</code>.
</p>
</li>
<li><p> Quadratic: <code>smartsearch=FALSE</code> and <code>maxit=1</code>.
</p>
</li></ol>



<h3>The model environment <code>env</code></h3>

<p>Technically, the user template is processed several times by inserting
different types as template parameter, selected by argument <code>type</code>:
</p>

<ul>
<li> <p><code>"ADFun"</code> Run through the template with AD-types and produce a stack of operations representing the objective function.
</p>
</li>
<li> <p><code>"Fun"</code> Run through the template with ordinary double-types.
</p>
</li>
<li> <p><code>"ADGrad"</code> Run through the template with nested AD-types and produce a stack of operations representing the objective function gradient.
</p>
</li></ul>

<p>Each of these are represented by external pointers to C++ structures available in the environment <code>env</code>.
</p>
<p>Further objects in the environment <code>env</code>:
</p>

<ul>
<li> <p><code>validpar</code> Function defining the valid parameter region (by default no restrictions). If an invalid
parameter is inserted <code>fn</code> immediately return NaN.
</p>
</li>
<li> <p><code>parList</code> Function to get the full parameter vector of random and fixed effects in a convenient
list format.
</p>
</li>
<li> <p><code>random</code> An index vector of random effect positions in the full parameter vector.
</p>
</li>
<li> <p><code>last.par</code> Full parameter of the latest likelihood evaluation.
</p>
</li>
<li> <p><code>last.par.best</code> Full parameter of the best likelihood evaluation.
</p>
</li>
<li> <p><code>tracepar</code> Trace every likelihood evaluation ?
</p>
</li>
<li> <p><code>tracemgc</code> Trace maximum gradient component of every gradient evaluation ?
</p>
</li>
<li> <p><code>silent</code> Pass 'silent=TRUE' to all try-calls ?
</p>
</li></ul>



<h3>The argument <code>intern</code></h3>

<p>By passing <code>intern=TRUE</code> the entire Laplace approximation (including sparse matrix calculations) is done within the AD machinery on the C++ side. This requires the model to be compiled using the 'TMBad framework' - see <code><a href="#topic+compile">compile</a></code>. For any serious use of this option one should consider compiling with <code>supernodal=TRUE</code> - again see <code><a href="#topic+compile">compile</a></code> - in order to get performance comparable to R's matrix calculations. The benefit of the 'intern' LA is that it may be faster in some cases and that it provides an autodiff hessian (<code>obj$he</code>) wrt. the fixed effects which would otherwise not work for random effect models. Another benefit is that it gives access to fast computations with certain hessian structures that do not meet the usual sparsity requirement. A detailed list of options are found in the online doxygen documentation in the 'newton' namespace under the 'newton_config' struct. All these options can be passed from R via the 'inner.control' argument. However, there are some drawbacks of running the LA on the C++ side. Notably, random effects are no longer visible in the model environment which may break assumptions on the layout of internal vectors ('par', 'last.par', etc). In addition, model debugging becomes harder when calculations are moved to C++.
</p>


<h3>Controlling tracing</h3>

<p>A high level of tracing information will be output by default when evaluating the objective function and gradient.
This is useful while developing a model, but may eventually become annoying. Disable all tracing by passing
<code>silent=TRUE</code> to the <code>MakeADFun</code> call.
</p>


<h3>Note</h3>

<p>Do not rely upon the default arguments of any of the functions in the model object <code>obj$fn</code>, <code>obj$gr</code>, <code>obj$he</code>, <code>obj$report</code>. I.e. always use the explicit form <code>obj$fn(obj$par)</code> rather than <code>obj$fn()</code>.
</p>

<hr>
<h2 id='newton'>Generalized newton optimizer.</h2><span id='topic+newton'></span>

<h3>Description</h3>

<p>Generalized newton optimizer used for the inner optimization problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newton(
  par,
  fn,
  gr,
  he,
  trace = 1,
  maxit = 100,
  tol = 1e-08,
  alpha = 1,
  smartsearch = TRUE,
  mgcmax = 1e+60,
  super = TRUE,
  silent = TRUE,
  ustep = 1,
  power = 0.5,
  u0 = 1e-04,
  grad.tol = tol,
  step.tol = tol,
  tol10 = 0.001,
  env = environment(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newton_+3A_par">par</code></td>
<td>
<p>Initial parameter.</p>
</td></tr>
<tr><td><code id="newton_+3A_fn">fn</code></td>
<td>
<p>Objective function.</p>
</td></tr>
<tr><td><code id="newton_+3A_gr">gr</code></td>
<td>
<p>Gradient function.</p>
</td></tr>
<tr><td><code id="newton_+3A_he">he</code></td>
<td>
<p>Sparse hessian function.</p>
</td></tr>
<tr><td><code id="newton_+3A_trace">trace</code></td>
<td>
<p>Print tracing information?</p>
</td></tr>
<tr><td><code id="newton_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="newton_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance.</p>
</td></tr>
<tr><td><code id="newton_+3A_alpha">alpha</code></td>
<td>
<p>Newton stepsize in the fixed stepsize case.</p>
</td></tr>
<tr><td><code id="newton_+3A_smartsearch">smartsearch</code></td>
<td>
<p>Turn on adaptive stepsize algorithm for non-convex problems?</p>
</td></tr>
<tr><td><code id="newton_+3A_mgcmax">mgcmax</code></td>
<td>
<p>Refuse to optimize if the maximum gradient component is too steep.</p>
</td></tr>
<tr><td><code id="newton_+3A_super">super</code></td>
<td>
<p>Supernodal Cholesky?</p>
</td></tr>
<tr><td><code id="newton_+3A_silent">silent</code></td>
<td>
<p>Be silent?</p>
</td></tr>
<tr><td><code id="newton_+3A_ustep">ustep</code></td>
<td>
<p>Adaptive stepsize initial guess between 0 and 1.</p>
</td></tr>
<tr><td><code id="newton_+3A_power">power</code></td>
<td>
<p>Parameter controlling adaptive stepsize.</p>
</td></tr>
<tr><td><code id="newton_+3A_u0">u0</code></td>
<td>
<p>Parameter controlling adaptive stepsize.</p>
</td></tr>
<tr><td><code id="newton_+3A_grad.tol">grad.tol</code></td>
<td>
<p>Gradient convergence tolerance.</p>
</td></tr>
<tr><td><code id="newton_+3A_step.tol">step.tol</code></td>
<td>
<p>Stepsize convergence tolerance.</p>
</td></tr>
<tr><td><code id="newton_+3A_tol10">tol10</code></td>
<td>
<p>Try to exit if last 10 iterations not improved more than this.</p>
</td></tr>
<tr><td><code id="newton_+3A_env">env</code></td>
<td>
<p>Environment for cached Cholesky factor.</p>
</td></tr>
<tr><td><code id="newton_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>smartsearch=FALSE</code> this function performs an ordinary newton optimization
on the function <code>fn</code> using an exact sparse hessian function.
A fixed stepsize may be controlled by <code>alpha</code> so that the iterations are
given by:
</p>
<p style="text-align: center;"><code class="reqn">u_{n+1} = u_n - \alpha f''(u_n)^{-1}f'(u_n)</code>
</p>

<p>If <code>smartsearch=TRUE</code> the hessian is allowed to become negative definite
preventing ordinary newton iterations. In this situation the newton iterations are performed on
a modified objective function defined by adding a quadratic penalty around the expansion point <code class="reqn">u_0</code>:
</p>
<p style="text-align: center;"><code class="reqn">f_{t}(u) = f(u) + \frac{t}{2} \|u-u_0\|^2</code>
</p>

<p>This function's hessian ( <code class="reqn">f''(u)+t I</code> ) is positive definite for <code class="reqn">t</code> sufficiently
large. The value <code class="reqn">t</code> is updated at every iteration: If the hessian is positive definite <code class="reqn">t</code> is
decreased, otherwise increased. Detailed control of the update process can be obtained with the
arguments <code>ustep</code>, <code>power</code> and <code>u0</code>.
</p>


<h3>Value</h3>

<p>List with solution similar to <code>optim</code> output.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newtonOption">newtonOption</a></code>
</p>

<hr>
<h2 id='newtonOption'>Set newton options for a model object.</h2><span id='topic+newtonOption'></span>

<h3>Description</h3>

<p>Inner-problem options can be set for a model object using this
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newtonOption(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newtonOption_+3A_obj">obj</code></td>
<td>
<p>Object from <code><a href="#topic+MakeADFun">MakeADFun</a></code> for which to change settings.</p>
</td></tr>
<tr><td><code id="newtonOption_+3A_...">...</code></td>
<td>
<p>Parameters for the <code><a href="#topic+newton">newton</a></code> optimizer to set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of updated parameters.
</p>

<hr>
<h2 id='normalize'>Normalize process likelihood using the Laplace approximation.</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>If the random effect likelihood contribution of a model has been
implemented without proper normalization (i.e. lacks the normalizing
constant), then this function can perform the adjustment
automatically. In order for this to work, the model must include a
flag that disables the data term so that the un-normalized random effect
(negative log) density is returned from the model template.
Automatic process normalization may be useful if either the
normalizing constant is difficult to implement, or if its calulation
involves so many operations that it becomes infeasible to include in
the AD machinery.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(obj, flag, value = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_obj">obj</code></td>
<td>
<p>Model object from <code>MakeADFun</code> without proper normalization of the random effect likelihood.</p>
</td></tr>
<tr><td><code id="normalize_+3A_flag">flag</code></td>
<td>
<p>Flag to disable the data term from the model.</p>
</td></tr>
<tr><td><code id="normalize_+3A_value">value</code></td>
<td>
<p>Value of 'flag' that signifies to not include the data term.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified model object that can be passed to an optimizer.
</p>

<hr>
<h2 id='oneStepPredict'>Calculate one-step-ahead (OSA) residuals for a latent variable model.</h2><span id='topic+oneStepPredict'></span>

<h3>Description</h3>

<p>Calculate one-step-ahead (OSA) residuals for a latent variable
model. (<em>Beta version; may change without notice</em>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oneStepPredict(
  obj,
  observation.name = NULL,
  data.term.indicator = NULL,
  method = c("oneStepGaussianOffMode", "fullGaussian", "oneStepGeneric",
    "oneStepGaussian", "cdf"),
  subset = NULL,
  conditional = NULL,
  discrete = NULL,
  discreteSupport = NULL,
  range = c(-Inf, Inf),
  seed = 123,
  parallel = FALSE,
  trace = TRUE,
  reverse = (method == "oneStepGaussianOffMode"),
  splineApprox = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="oneStepPredict_+3A_obj">obj</code></td>
<td>
<p>Output from <code>MakeADFun</code>.</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_observation.name">observation.name</code></td>
<td>
<p>Character naming the observation in the template.</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_data.term.indicator">data.term.indicator</code></td>
<td>
<p>Character naming an indicator data variable in the template (not required by all methods - see details).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_method">method</code></td>
<td>
<p>Method to calculate OSA (see details).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_subset">subset</code></td>
<td>
<p>Index vector of observations that will be added one by one during OSA. By default <code>1:length(observations)</code> (with <code>conditional</code> subtracted).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_conditional">conditional</code></td>
<td>
<p>Index vector of observations that are fixed during OSA. By default the empty set.</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_discrete">discrete</code></td>
<td>
<p>Logical; Are observations discrete? (assumed FALSE by default).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_discretesupport">discreteSupport</code></td>
<td>
<p>Possible outcomes of discrete part of the distribution (<code>method="oneStepGeneric"</code> and <code>method="cdf"</code> only).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_range">range</code></td>
<td>
<p>Possible range of continuous part of the distribution (<code>method="oneStepGeneric"</code> only).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_seed">seed</code></td>
<td>
<p>Randomization seed (discrete case only). If <code>NULL</code> the RNG seed is untouched by this routine (recommended for simulation studies).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_parallel">parallel</code></td>
<td>
<p>Run in parallel using the <code>parallel</code> package?</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_trace">trace</code></td>
<td>
<p>Logical; Trace progress? More options available for <code>method="oneStepGeneric"</code> - see details.</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_reverse">reverse</code></td>
<td>
<p>Do calculations in opposite order to improve stability? (currently enabled by default for <code>oneStepGaussianOffMode</code> method only)</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_splineapprox">splineApprox</code></td>
<td>
<p>Represent one-step conditional distribution by a spline to reduce number of density evaluations? (<code>method="oneStepGeneric"</code> only).</p>
</td></tr>
<tr><td><code id="oneStepPredict_+3A_...">...</code></td>
<td>
<p>Control parameters for OSA method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a TMB latent variable model this function calculates OSA
standardized residuals that can be used for goodness-of-fit
assessment. The approach is based on a factorization of the joint
distribution of the <em>observations</em> <code class="reqn">X_1,...,X_n</code> into
successive conditional distributions.
Denote by
</p>
<p style="text-align: center;"><code class="reqn">F_n(x_n) = P(X_n \leq x_n | X_1 = x_1,...,X_{n-1}=x_{n-1} )</code>
</p>

<p>the one-step-ahead CDF, and by
</p>
<p style="text-align: center;"><code class="reqn">p_n(x_n) = P(X_n = x_n | X_1 = x_1,...,X_{n-1}=x_{n-1} )</code>
</p>

<p>the corresponding point probabilities (zero for continuous distributions).
In case of continuous observations the sequence
</p>
<p style="text-align: center;"><code class="reqn">\Phi^{-1}(F_1(X_1))\:,...,\:\Phi^{-1}(F_n(X_n))</code>
</p>

<p>will be iid standard normal. These are referred to as the OSA residuals.
In case of discrete observations draw (unit) uniform variables
<code class="reqn">U_1,...,U_n</code> and construct the randomized OSA residuals
</p>
<p style="text-align: center;"><code class="reqn">\Phi^{-1}(F_1(X_1)-U_1 p_1(X_1))\:,...,\:\Phi^{-1}(F_n(X_n)-U_n p_n(X_n))</code>
</p>

<p>These are also iid standard normal.
</p>


<h3>Value</h3>

<p><code>data.frame</code> with OSA <em>standardized</em> residuals
in column <code>residual</code>. In addition, depending on the method, the output
includes selected characteristics of the predictive distribution (current row) given past observations (past rows), notably the <em>conditional</em>
</p>

<dl>
<dt>mean</dt><dd><p>Expectation of the current observation</p>
</dd>
<dt>sd</dt><dd><p>Standard deviation of the current observation</p>
</dd>
<dt>Fx</dt><dd><p>CDF at current observation</p>
</dd>
<dt>px</dt><dd><p>Density at current observation</p>
</dd>
<dt>nll</dt><dd><p>Negative log density at current observation</p>
</dd>
<dt>nlcdf.lower</dt><dd><p>Negative log of the lower CDF at current observation</p>
</dd>
<dt>nlcdf.upper</dt><dd><p>Negative log of the upper CDF at current observation</p>
</dd>
</dl>

<p><em>given past observations</em>.
If column <code>randomize</code> is present, it indicates that randomization has been applied for the row.
</p>


<h3>Choosing the method</h3>

<p>The user must specify the method used to calculate the residuals - see detailed list of method descriptions below.
We note that all the methods are based on approximations. While the default 'oneStepGaussianoffMode' often represents a good compromise between accuracy and speed, it cannot be assumed to work well for all model classes.
As a rule of thumb, if in doubt whether a method is accurate enough, you should always compare with the 'oneStepGeneric' which is considered the most accurate of the available methods.
</p>

<dl>
<dt>method=&quot;fullGaussian&quot;</dt><dd>
<p>This method assumes that the joint distribution of data <em>and</em>
random effects is Gaussian (or well approximated by a
Gaussian). It does not require any changes to the user
template. However, if used in conjunction with <code>subset</code>
and/or <code>conditional</code> a <code>data.term.indicator</code> is required
- see the next method.
</p>
</dd>
<dt>method=&quot;oneStepGeneric&quot;</dt><dd>
<p>This method calculates the one-step conditional probability
density as a ratio of Laplace approximations. The approximation is
integrated (and re-normalized for improved accuracy) using 1D
numerical quadrature to obtain the one-step CDF evaluated at each
data point. The method works in the continuous case as well as the
discrete case (<code>discrete=TRUE</code>).
</p>
<p>It requires a specification of a <code>data.term.indicator</code>
explained in the following. Suppose the template for the
observations given the random effects (<code class="reqn">u</code>) looks like
</p>
<pre>
    DATA_VECTOR(x);
    ...
    nll -= dnorm(x(i), u(i), sd(i), true);
    ...
</pre>
<p>Then this template can be augmented with a
<code>data.term.indicator = "keep"</code> by changing the template to
</p>
<pre>
    DATA_VECTOR(x);
    DATA_VECTOR_INDICATOR(keep, x);
    ...
    nll -= keep(i) * dnorm(x(i), u(i), sd(i), true);
    ...
</pre>
<p>The new data vector (<code>keep</code>) need not be passed from <span class="rlang"><b>R</b></span>. It
automatically becomes a copy of <code>x</code> filled with ones.
</p>
<p>Some extra parameters are essential for the method.
Pay special attention to the integration domain which must be set either via <code>range</code> (continuous case) or <code>discreteSupport</code> (discrete case). Both of these can be set simultanously to specify a mixed continuous/discrete distribution. For example, a non-negative distribution with a point mass at zero (e.g. the Tweedie distribution) should have <code>range=c(0,Inf)</code> and <code>discreteSupport=0</code>.
Several parameters control accuracy and appropriate settings are case specific. By default, a spline is fitted to the one-step density before integration (<code>splineApprox=TRUE</code>) to reduce the number of density evaluations. However, this setting may have negative impact on accuracy. The spline approximation can then either be disabled or improved by noting that <code>...</code> arguments are passed to <a href="#topic+tmbprofile">tmbprofile</a>: Pass e.g. <code>ystep=20, ytol=0.1</code>.
Finally, it may be useful to look at the one step predictive distributions on either log scale (<code>trace=2</code>) or natural scale (<code>trace=3</code>) to determine which alternative methods might be appropriate.
</p>
</dd>
<dt>method=&quot;oneStepGaussian&quot;</dt><dd>
<p>This is a special case of the generic method where the one step
conditional distribution is approximated by a Gaussian (and can
therefore be handled more efficiently).
</p>
</dd>
<dt>method=&quot;oneStepGaussianOffMode&quot;</dt><dd>
<p>This is an approximation of the &quot;oneStepGaussian&quot; method that
avoids locating the mode of the one-step conditional density.
</p>
</dd>
<dt>method=&quot;cdf&quot;</dt><dd>
<p>The generic method can be slow due to the many function
evaluations used during the 1D integration (or summation in the
discrete case). The present method can speed up this process but
requires more changes to the user template. The above template
must be expanded with information about how to calculate the
negative log of the lower and upper CDF:
</p>
<pre>
    DATA_VECTOR(x);
    DATA_VECTOR_INDICATOR(keep, x);
    ...
    nll -= keep(i) * dnorm(x(i), u(i), sd(i), true);
    nll -= keep.cdf_lower(i) * log( pnorm(x(i), u(i), sd(i)) );
    nll -= keep.cdf_upper(i) * log( 1.0 - pnorm(x(i), u(i), sd(i)) );
    ...
</pre>
<p>The specialized members <code>keep.cdf_lower</code> and
<code>keep.cdf_upper</code> automatically become copies of <code>x</code>
filled with zeros.
</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>######################## Gaussian case
runExample("simple")
osa.simple &lt;- oneStepPredict(obj, observation.name = "x", method="fullGaussian")
qqnorm(osa.simple$residual); abline(0,1)

## Not run: 
######################## Poisson case (First 100 observations)
runExample("ar1xar1")
osa.ar1xar1 &lt;- oneStepPredict(obj, "N", "keep", method="cdf", discrete=TRUE, subset=1:100)
qqnorm(osa.ar1xar1$residual); abline(0,1)

## End(Not run)
</code></pre>

<hr>
<h2 id='openmp'>Control number of OpenMP threads used by a TMB model.</h2><span id='topic+openmp'></span>

<h3>Description</h3>

<p>Control number of OpenMP threads used by a TMB model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>openmp(n = NULL, max = FALSE, autopar = NULL, DLL = getUserDLL())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="openmp_+3A_n">n</code></td>
<td>
<p>Requested number of threads, or <code>NULL</code> to just read the current value.</p>
</td></tr>
<tr><td><code id="openmp_+3A_max">max</code></td>
<td>
<p>Logical; Set n to OpenMP runtime value 'omp_get_max_threads()'?</p>
</td></tr>
<tr><td><code id="openmp_+3A_autopar">autopar</code></td>
<td>
<p>Logical; use automatic parallelization - see details.</p>
</td></tr>
<tr><td><code id="openmp_+3A_dll">DLL</code></td>
<td>
<p>DLL of a TMB model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function controls the number of parallel threads used by a TMB model compiled with OpenMP.
The number of threads is part of the configuration list <code>config()</code> of the DLL.
The value only affects parallelization of the DLL. It does <em>not</em> affect BLAS/LAPACK specific parallelization which has to be specified elsewhere.
</p>
<p>When a DLL is loaded, the number of threads is set to 1 by default.
To activate parallelization you have to explicitly call <code>openmp(nthreads)</code> after loading the DLL. Calling <code>openmp(max=TRUE)</code> should normally pick up the environment variable <code>OMP_NUM_THREADS</code>, but this may be platform dependent.
</p>
<p>An experimental option <code>autopar=TRUE</code> can be set to parallelize models automatically. This requires the model to be compiled with <code>framework="TMBad"</code> and <code>openmp=TRUE</code> without further requirements on the C++ code. If the C++ code already has explicit parallel constructs these will be ignored if automatic parallelization is enabled.
</p>


<h3>Value</h3>

<p>Number of threads.
</p>

<hr>
<h2 id='plot.tmbprofile'>Plot likelihood profile.</h2><span id='topic+plot.tmbprofile'></span>

<h3>Description</h3>

<p>Plot (negative log) likelihood profile with confidence interval added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tmbprofile'
plot(x, type = "l", level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.tmbprofile_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+tmbprofile">tmbprofile</a></code>.</p>
</td></tr>
<tr><td><code id="plot.tmbprofile_+3A_type">type</code></td>
<td>
<p>Plot type.</p>
</td></tr>
<tr><td><code id="plot.tmbprofile_+3A_level">level</code></td>
<td>
<p>Add horizontal and vertical lines depicting this confidence level (<code>NULL</code> disables the lines).</p>
</td></tr>
<tr><td><code id="plot.tmbprofile_+3A_...">...</code></td>
<td>
<p>Additional plot arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='precompile'>Precompile the TMB library in order to speed up compilation of templates.</h2><span id='topic+precompile'></span>

<h3>Description</h3>

<p>Precompile the TMB library
</p>


<h3>Usage</h3>

<pre><code class='language-R'>precompile(all = TRUE, clean = FALSE, trace = TRUE, get.header = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="precompile_+3A_all">all</code></td>
<td>
<p>Precompile all or just the core parts of TMB ?</p>
</td></tr>
<tr><td><code id="precompile_+3A_clean">clean</code></td>
<td>
<p>Remove precompiled libraries ?</p>
</td></tr>
<tr><td><code id="precompile_+3A_trace">trace</code></td>
<td>
<p>Trace precompilation process ?</p>
</td></tr>
<tr><td><code id="precompile_+3A_get.header">get.header</code></td>
<td>
<p>Create files 'TMB.h' and 'TMB.cpp' in current working directory to be used as part of a project?</p>
</td></tr>
<tr><td><code id="precompile_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Precompilation can be used to speed up compilation of
templates. It is only necessary to run <code>precompile()</code> once,
typically right after installation of TMB. The function
<em>prepares</em> TMB for precompilation, while the actual
pre-compilation takes place the first time you compile a model
after running <code>precompile()</code>.
</p>
<p>Note that the precompilation requires write access to the TMB
package folder. Three versions of the library will be prepared:
Normal, parallel and a debugable version.
</p>
<p>Precompilation works the same way on all platforms. The only known
side-effect of precompilation is that it increases the file size
of the generated binaries.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Prepare precompilation
precompile()
## Perform precompilation by running a model
runExample(all = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.checkConsistency'>Print output from <code><a href="#topic+checkConsistency">checkConsistency</a></code></h2><span id='topic+print.checkConsistency'></span>

<h3>Description</h3>

<p>Print diagnostics output from <code><a href="#topic+checkConsistency">checkConsistency</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'checkConsistency'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.checkConsistency_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+checkConsistency">checkConsistency</a></code></p>
</td></tr>
<tr><td><code id="print.checkConsistency_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>

<hr>
<h2 id='print.sdreport'>Print brief model summary</h2><span id='topic+print.sdreport'></span>

<h3>Description</h3>

<p>Print parameter estimates and give convergence diagnostic based on
gradient and Hessian.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdreport'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.sdreport_+3A_x">x</code></td>
<td>
<p>Output from <code><a href="#topic+sdreport">sdreport</a></code></p>
</td></tr>
<tr><td><code id="print.sdreport_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>

<hr>
<h2 id='Rinterface'>Create minimal R-code corresponding to a cpp template.</h2><span id='topic+Rinterface'></span>

<h3>Description</h3>

<p>Create a skeleton of required R-code once the cpp template is ready.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rinterface(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Rinterface_+3A_file">file</code></td>
<td>
<p>cpp template file.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>file &lt;- system.file("examples/simple.cpp", package = "TMB")
Rinterface(file)
</code></pre>

<hr>
<h2 id='runExample'>Run one of the test examples.</h2><span id='topic+runExample'></span>

<h3>Description</h3>

<p>Compile and run a test example (<code>runExample()</code> shows all available examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runExample(
  name = NULL,
  all = FALSE,
  thisR = TRUE,
  clean = FALSE,
  exfolder = NULL,
  dontrun = FALSE,
  subarch = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runExample_+3A_name">name</code></td>
<td>
<p>Character name of example.</p>
</td></tr>
<tr><td><code id="runExample_+3A_all">all</code></td>
<td>
<p>Run all the test examples?</p>
</td></tr>
<tr><td><code id="runExample_+3A_thisr">thisR</code></td>
<td>
<p>Run inside this R?</p>
</td></tr>
<tr><td><code id="runExample_+3A_clean">clean</code></td>
<td>
<p>Cleanup before compile?</p>
</td></tr>
<tr><td><code id="runExample_+3A_exfolder">exfolder</code></td>
<td>
<p>Alternative folder with examples.</p>
</td></tr>
<tr><td><code id="runExample_+3A_dontrun">dontrun</code></td>
<td>
<p>Build only (don't run) and remove temporary object files ?</p>
</td></tr>
<tr><td><code id="runExample_+3A_subarch">subarch</code></td>
<td>
<p>Build in sub-architecture specific folder ?</p>
</td></tr>
<tr><td><code id="runExample_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="#topic+compile">compile</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='runSymbolicAnalysis'>Run symbolic analysis on sparse Hessian</h2><span id='topic+runSymbolicAnalysis'></span>

<h3>Description</h3>

<p>Aggressively tries to reduce fill-in of sparse Cholesky factor by
running a full suite of ordering algorithms. NOTE: requires a
specialized installation of the package. More information is
available at the package URL.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runSymbolicAnalysis(obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runSymbolicAnalysis_+3A_obj">obj</code></td>
<td>
<p>Output from <code>MakeADFun</code></p>
</td></tr>
</table>

<hr>
<h2 id='sdreport'>General sdreport function.</h2><span id='topic+sdreport'></span>

<h3>Description</h3>

<p>After optimization of an AD model, <code>sdreport</code> is used to
calculate standard deviations of all model parameters, including
non linear functions of random effects and parameters specified
through the ADREPORT() macro from the user template.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdreport(
  obj,
  par.fixed = NULL,
  hessian.fixed = NULL,
  getJointPrecision = FALSE,
  bias.correct = FALSE,
  bias.correct.control = list(sd = FALSE, split = NULL, nsplit = NULL),
  ignore.parm.uncertainty = FALSE,
  getReportCovariance = TRUE,
  skip.delta.method = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sdreport_+3A_obj">obj</code></td>
<td>
<p>Object returned by <code>MakeADFun</code></p>
</td></tr>
<tr><td><code id="sdreport_+3A_par.fixed">par.fixed</code></td>
<td>
<p>Optional. Parameter estimate (will be known to <code>obj</code> when an optimization has been carried out).</p>
</td></tr>
<tr><td><code id="sdreport_+3A_hessian.fixed">hessian.fixed</code></td>
<td>
<p>Optional. Hessian wrt. parameters (will be calculated from <code>obj</code> if missing).</p>
</td></tr>
<tr><td><code id="sdreport_+3A_getjointprecision">getJointPrecision</code></td>
<td>
<p>Optional. Return full joint precision matrix of random effects and parameters?</p>
</td></tr>
<tr><td><code id="sdreport_+3A_bias.correct">bias.correct</code></td>
<td>
<p>logical indicating if bias correction should be applied</p>
</td></tr>
<tr><td><code id="sdreport_+3A_bias.correct.control">bias.correct.control</code></td>
<td>
<p>a <code>list</code> of bias correction options; currently <code>sd</code>, <code>split</code> and <code>nsplit</code> are used - see details.</p>
</td></tr>
<tr><td><code id="sdreport_+3A_ignore.parm.uncertainty">ignore.parm.uncertainty</code></td>
<td>
<p>Optional. Ignore estimation variance of parameters?</p>
</td></tr>
<tr><td><code id="sdreport_+3A_getreportcovariance">getReportCovariance</code></td>
<td>
<p>Get full covariance matrix of ADREPORTed variables?</p>
</td></tr>
<tr><td><code id="sdreport_+3A_skip.delta.method">skip.delta.method</code></td>
<td>
<p>Skip the delta method? (<code>FALSE</code> by default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, the Hessian wrt. the parameter vector (<code class="reqn">\theta</code>) is
calculated.  The parameter covariance matrix is approximated by
</p>
<p style="text-align: center;"><code class="reqn">V(\hat\theta)=-\nabla^2 l(\hat\theta)^{-1}</code>
</p>
<p> where <code class="reqn">l</code>
denotes the log likelihood function (i.e. <code>-obj$fn</code>).  If
<code>ignore.parm.uncertainty=TRUE</code> then the Hessian calculation
is omitted and a zero-matrix is used in place of
<code class="reqn">V(\hat\theta)</code>.
</p>
<p>For non-random effect models the standard delta-method is used to
calculate the covariance matrix of transformed parameters. Let
<code class="reqn">\phi(\theta)</code> denote some non-linear function of
<code class="reqn">\theta</code>. Then </p>
<p style="text-align: center;"><code class="reqn">V(\phi(\hat\theta))\approx \nabla\phi
V(\hat\theta) \nabla\phi'</code>
</p>

<p>The covariance matrix of reported variables
<code class="reqn">V(\phi(\hat\theta))</code> is returned by default. This can cause
high memory usage if many variables are ADREPORTed. Use
<code>getReportCovariance=FALSE</code> to only return standard errors.
In case standard deviations are not required one can completely skip
the delta method using <code>skip.delta.method=TRUE</code>.
</p>
<p>For random effect models a generalized delta-method is used. First
the joint covariance of random effect and parameter estimation error is approximated
by
</p>
<p style="text-align: center;"><code class="reqn">V \left( \begin{array}{cc} \hat u - u \cr \hat\theta - \theta \end{array} \right) \approx
\left( \begin{array}{cc} H_{uu}^{-1} &amp; 0 \cr 0 &amp; 0 \end{array} \right) +
J V(\hat\theta) J'
</code>
</p>

<p>where <code class="reqn">H_{uu}</code> denotes random effect block of the full joint
Hessian of <code>obj$env$f</code> and <code class="reqn">J</code> denotes the Jacobian of
<code class="reqn">\left( \begin{array}{cc}\hat u(\theta) \cr \theta \end{array} \right)</code> wrt. <code class="reqn">\theta</code>.
Here, the first term represents the expected conditional variance
of the estimation error given the data and the second term represents the variance
of the conditional mean of the estimation error given the data.
</p>
<p>Now the delta method can be applied on a general non-linear
function <code class="reqn">\phi(u,\theta)</code> of random effects <code class="reqn">u</code> and
parameters <code class="reqn">\theta</code>:
</p>
<p style="text-align: center;"><code class="reqn">V\left(\phi(\hat u,\hat\theta) - \phi(u,\theta) \right)\approx \nabla\phi V \left( \begin{array}{cc}
\hat u - u \cr \hat\theta - \theta \end{array} \right) \nabla\phi'</code>
</p>

<p>The full joint covariance is not returned by default, because it
may require large amounts of memory.  It may be obtained by
specifying <code>getJointPrecision=TRUE</code>, in which case <code class="reqn">V
\left( \begin{array}{cc} \hat u - u \cr \hat\theta - \theta \end{array} \right) ^{-1} </code> will be part of the
output. This matrix must be manually inverted using
<code>solve(jointPrecision)</code> in order to get the joint covariance
matrix. Note, that the parameter order will follow the original
order (i.e. <code>obj$env$par</code>).
</p>
<p>Using <code class="reqn">\phi(\hat u,\theta)</code> as estimator of
<code class="reqn">\phi(u,\theta)</code> may result in substantial bias. This may be
the case if either <code class="reqn">\phi</code> is non-linear or if the distribution
of <code class="reqn">u</code> given <code class="reqn">x</code> (data) is sufficiently non-symmetric.  A
generic correction is enabled with <code>bias.correct=TRUE</code>. It is
based on the identity
</p>
<p style="text-align: center;"><code class="reqn">E_{\theta}[\phi(u,\theta)|x] =
\partial_\varepsilon\left(\log \int \exp(-f(u,\theta) +
\varepsilon \phi(u,\theta))\:du\right)_{|\varepsilon=0}</code>
</p>

<p>stating that the conditional expectation can be written as a
marginal likelihood gradient wrt. a nuisance parameter
<code class="reqn">\varepsilon</code>.
The marginal likelihood is replaced by its Laplace approximation.
</p>
<p>If <code>bias.correct.control$sd=TRUE</code> the variance of the
estimator is calculated using
</p>
<p style="text-align: center;"><code class="reqn">V_{\theta}[\phi(u,\theta)|x] =
\partial_\varepsilon^2\left(\log \int \exp(-f(u,\theta) +
\varepsilon \phi(u,\theta))\:du\right)_{|\varepsilon=0}</code>
</p>

<p>A further correction is added to this variance to account for the
effect of replacing <code class="reqn">\theta</code> by the MLE <code class="reqn">\hat\theta</code>
(unless <code>ignore.parm.uncertainty=TRUE</code>).
</p>
<p>Bias correction can be be performed in chunks in order to reduce
memory usage or in order to only bias correct a subset of
variables. First option is to pass a list of indices as
<code>bias.correct.control$split</code>. E.g. a list
<code>list(1:2,3:4)</code> calculates the first four ADREPORTed
variables in two chunks.
The internal function <code>obj$env$ADreportIndex()</code>
gives an overview of the possible indices of ADREPORTed variables.
</p>
<p>Second option is to pass the number of
chunks as <code>bias.correct.control$nsplit</code> in which case all
ADREPORTed variables are bias corrected in the specified number of
chunks.
Also note that <code>skip.delta.method</code> may be necessary when bias
correcting a large number of variables.
</p>


<h3>Value</h3>

<p>Object of class <code>sdreport</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.sdreport">summary.sdreport</a></code>, <code><a href="#topic+print.sdreport">print.sdreport</a></code>, <code><a href="#topic+as.list.sdreport">as.list.sdreport</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
runExample("linreg_parallel", thisR = TRUE) ## Non-random effect example
sdreport(obj) 
## End(Not run)

runExample("simple", thisR = TRUE)          ## Random effect example
rep &lt;- sdreport(obj)
summary(rep, "random")                      ## Only random effects
summary(rep, "fixed", p.value = TRUE)       ## Only non-random effects
summary(rep, "report")                      ## Only report

## Bias correction
rep &lt;- sdreport(obj, bias.correct = TRUE)
summary(rep, "report")                      ## Include bias correction
</code></pre>

<hr>
<h2 id='SR'>Sequential reduction configuration</h2><span id='topic+SR'></span>

<h3>Description</h3>

<p>Helper function to specify an integration grid used by the
sequential reduction algorithm available through the argument
<code>integrate</code> to <code>MakeADFun</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SR(x, discrete = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SR_+3A_x">x</code></td>
<td>
<p>Breaks defining the domain of integration</p>
</td></tr>
<tr><td><code id="SR_+3A_discrete">discrete</code></td>
<td>
<p>Boolean defining integration wrt Lebesgue measure (<code>discrete=FALSE</code>) or counting measure <code>discrete=TRUE</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.checkConsistency'>Summarize output from <code><a href="#topic+checkConsistency">checkConsistency</a></code></h2><span id='topic+summary.checkConsistency'></span>

<h3>Description</h3>

<p>Summarize output from <code><a href="#topic+checkConsistency">checkConsistency</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'checkConsistency'
summary(object, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.checkConsistency_+3A_object">object</code></td>
<td>
<p>Output from <code><a href="#topic+checkConsistency">checkConsistency</a></code></p>
</td></tr>
<tr><td><code id="summary.checkConsistency_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical; Remove failed simulations ?</p>
</td></tr>
<tr><td><code id="summary.checkConsistency_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of diagnostics
</p>

<hr>
<h2 id='summary.sdreport'>summary tables of model parameters</h2><span id='topic+summary.sdreport'></span>

<h3>Description</h3>

<p>Extract parameters, random effects and reported variables along
with uncertainties and optionally Chi-square statistics. Bias
corrected quantities are added as additional columns if available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdreport'
summary(
  object,
  select = c("all", "fixed", "random", "report"),
  p.value = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.sdreport_+3A_object">object</code></td>
<td>
<p>Output from <code><a href="#topic+sdreport">sdreport</a></code></p>
</td></tr>
<tr><td><code id="summary.sdreport_+3A_select">select</code></td>
<td>
<p>Parameter classes to select. Can be any subset of
<code>"fixed"</code> (<code class="reqn">\hat\theta</code>), <code>"random"</code> (<code class="reqn">\hat u</code>) or
<code>"report"</code> (<code class="reqn">\phi(\hat u,\hat\theta)</code>) using notation as
<code><a href="#topic+sdreport">sdreport</a></code>.</p>
</td></tr>
<tr><td><code id="summary.sdreport_+3A_p.value">p.value</code></td>
<td>
<p>Add column with approximate p-values</p>
</td></tr>
<tr><td><code id="summary.sdreport_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>

<hr>
<h2 id='template'>Create cpp template to get started.</h2><span id='topic+template'></span>

<h3>Description</h3>

<p>Create a cpp template to get started.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>template(file = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="template_+3A_file">file</code></td>
<td>
<p>Optional name of cpp file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates a C++ template with a header and include
statement. Here is a brief overview of the C++ syntax used to code
the objective function. For a full reference see the Doxygen
documentation (more information at the package URL).
</p>
<p>Macros to read data and declare parameters:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <b>Template Syntax</b>    </td><td style="text-align: left;">     <b>C++ type</b>            </td><td style="text-align: left;">    <b>R type</b> </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_VECTOR(name)         </td><td style="text-align: left;">     vector&lt;Type&gt;               </td><td style="text-align: left;">    vector        </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_MATRIX(name)         </td><td style="text-align: left;">     matrix&lt;Type&gt;               </td><td style="text-align: left;">    matrix        </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_SCALAR(name)         </td><td style="text-align: left;">     Type                       </td><td style="text-align: left;">    numeric(1)    </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_INTEGER(name)        </td><td style="text-align: left;">     int                        </td><td style="text-align: left;">    integer(1)    </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_FACTOR(name)         </td><td style="text-align: left;">     vector&lt;int&gt;                </td><td style="text-align: left;">    factor        </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_IVECTOR(name)        </td><td style="text-align: left;">     vector&lt;int&gt;                </td><td style="text-align: left;">    integer       </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_SPARSE_MATRIX(name)  </td><td style="text-align: left;">     Eigen::SparseMatrix&lt;Type&gt;  </td><td style="text-align: left;">    dgTMatrix     </td>
</tr>
<tr>
 <td style="text-align: left;">
    DATA_ARRAY(name)          </td><td style="text-align: left;">     array&lt;Type&gt;                </td><td style="text-align: left;">    array         </td>
</tr>
<tr>
 <td style="text-align: left;">
    PARAMETER_MATRIX(name)    </td><td style="text-align: left;">     matrix&lt;Type&gt;               </td><td style="text-align: left;">    matrix        </td>
</tr>
<tr>
 <td style="text-align: left;">
    PARAMETER_VECTOR(name)    </td><td style="text-align: left;">     vector&lt;Type&gt;               </td><td style="text-align: left;">    vector        </td>
</tr>
<tr>
 <td style="text-align: left;">
    PARAMETER_ARRAY(name)     </td><td style="text-align: left;">     array&lt;Type&gt;                </td><td style="text-align: left;">    array         </td>
</tr>
<tr>
 <td style="text-align: left;">
    PARAMETER(name)           </td><td style="text-align: left;">     Type                       </td><td style="text-align: left;">    numeric(1)    </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>

<p>Basic calculations:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <b>Template Syntax</b>    </td><td style="text-align: left;">   <b>Explanation</b>                     </td>
</tr>
<tr>
 <td style="text-align: left;">
    REPORT(x)                 </td><td style="text-align: left;">   Report x back to R                     </td>
</tr>
<tr>
 <td style="text-align: left;">
    ADREPORT(x)               </td><td style="text-align: left;">   Report x back to R with derivatives    </td>
</tr>
<tr>
 <td style="text-align: left;">
    vector&lt;Type&gt; v(n1);       </td><td style="text-align: left;">   R equivalent of v=numeric(n1)          </td>
</tr>
<tr>
 <td style="text-align: left;">
    matrix&lt;Type&gt; m(n1,n2);    </td><td style="text-align: left;">   R equivalent of m=matrix(0,n1,n2)      </td>
</tr>
<tr>
 <td style="text-align: left;">
    array&lt;Type&gt; a(n1,n2,n3);  </td><td style="text-align: left;">   R equivalent of a=array(0,c(n1,n2,n3)) </td>
</tr>
<tr>
 <td style="text-align: left;">
    v+v,v-v,v*v,v/v           </td><td style="text-align: left;">   Pointwise binary operations            </td>
</tr>
<tr>
 <td style="text-align: left;">
    m*v                       </td><td style="text-align: left;">   Matrix-vector multiply                 </td>
</tr>
<tr>
 <td style="text-align: left;">
    a.col(i)                  </td><td style="text-align: left;">   R equivalent of a[,,i]                 </td>
</tr>
<tr>
 <td style="text-align: left;">
    a.col(i).col(j)           </td><td style="text-align: left;">   R equivalent of a[,j,i]                </td>
</tr>
<tr>
 <td style="text-align: left;">
    a(i,j,k)                  </td><td style="text-align: left;">   R equivalent of a[i,j,k]               </td>
</tr>
<tr>
 <td style="text-align: left;">
    exp(v)                    </td><td style="text-align: left;">   Pointwise math                         </td>
</tr>
<tr>
 <td style="text-align: left;">
    m(i,j)                    </td><td style="text-align: left;">   R equivalent of m[i,j]                 </td>
</tr>
<tr>
 <td style="text-align: left;">
    v.sum()                   </td><td style="text-align: left;">   R equivalent of sum(v)                 </td>
</tr>
<tr>
 <td style="text-align: left;">
    m.transpose()             </td><td style="text-align: left;">   R equivalent of t(m)                   </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>

<p>Some distributions are available as C++ templates with syntax close to R's distributions:
</p>

<table>
<tr>
 <td style="text-align: left;">
   <b>Function header</b>                </td><td style="text-align: left;"> <b>Distribution</b>                      </td>
</tr>
<tr>
 <td style="text-align: left;">
   dnbinom2(x,mu,var,int give_log=0)     </td><td style="text-align: left;"> Negative binomial with mean and variance </td>
</tr>
<tr>
 <td style="text-align: left;">
   dpois(x,lambda,int give_log=0)        </td><td style="text-align: left;"> Poisson distribution as in R             </td>
</tr>
<tr>
 <td style="text-align: left;">
   dlgamma(y,shape,scale,int give_log=0) </td><td style="text-align: left;"> log-gamma distribution                   </td>
</tr>
<tr>
 <td style="text-align: left;">
   dnorm(x,mean,sd,int give_log=0)       </td><td style="text-align: left;"> Normal distribution as in R              </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>template()
</code></pre>

<hr>
<h2 id='TMB.Version'>Version information on API and ABI.</h2><span id='topic+TMB.Version'></span>

<h3>Description</h3>

<p>The R interface to <code>TMB</code> roughly consists of two components: (1) The 'API' i.e. R functions documented in this manual and (2) C-level entry points, here referred to as the 'ABI', which controls the C++ code. The latter can be shown by <code>getDLLRegisteredRoutines(DLL)</code> where <code>DLL</code> is the shared library generated by the <a href="#topic+compile">compile</a> function (or by a package linking to <code>TMB</code>).
A DLL compiled with one version of <code>TMB</code> can be used with another version of <code>TMB</code> provided that the 'ABI' is the same. We therefore define the 'ABI version' as the oldest ABI compatible version. This number can then be used to tell if re-compilation of a DLL is necessary after updating <code>TMB</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TMB.Version()
</code></pre>


<h3>Value</h3>

<p>List with components <code>package</code> (API version) and <code>abi</code> (ABI version) inspired by corresponding function in the <code>Matrix</code> package.
</p>

<hr>
<h2 id='tmbprofile'>Adaptive likelihood profiling.</h2><span id='topic+tmbprofile'></span>

<h3>Description</h3>

<p>Calculate 1D likelihood profiles wrt. single parameters or more
generally, wrt. arbitrary linear combinations of parameters
(e.g. contrasts).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tmbprofile(
  obj,
  name,
  lincomb,
  h = 1e-04,
  ytol = 2,
  ystep = 0.1,
  maxit = ceiling(5 * ytol/ystep),
  parm.range = c(-Inf, Inf),
  slice = FALSE,
  adaptive = TRUE,
  trace = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tmbprofile_+3A_obj">obj</code></td>
<td>
<p>Object from <code>MakeADFun</code> that has been optimized.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_name">name</code></td>
<td>
<p>Name or index of a parameter to profile.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_lincomb">lincomb</code></td>
<td>
<p>Optional linear combination of parameters to
profile. By default a unit vector corresponding to <code>name</code>.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_h">h</code></td>
<td>
<p>Initial adaptive stepsize on parameter axis.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_ytol">ytol</code></td>
<td>
<p>Adjusts the range of the likelihood values.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_ystep">ystep</code></td>
<td>
<p>Adjusts the resolution of the likelihood profile.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_maxit">maxit</code></td>
<td>
<p>Max number of iterations for adaptive algorithm.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_parm.range">parm.range</code></td>
<td>
<p>Valid parameter range.</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_slice">slice</code></td>
<td>
<p>Do slicing rather than profiling?</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_adaptive">adaptive</code></td>
<td>
<p>Logical; Use adaptive step size?</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_trace">trace</code></td>
<td>
<p>Trace progress? (TRUE, or a numeric value of 1,
gives basic tracing: numeric values &gt; 1 give more information)</p>
</td></tr>
<tr><td><code id="tmbprofile_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a linear combination </p>
<p style="text-align: center;"><code class="reqn"> t = \sum_{i=1}^n v_i \theta_i </code>
</p>
<p> of
the parameter vector <code class="reqn">\theta</code>, this function calculates the
likelihood profile of <code class="reqn">t</code>. By default <code class="reqn">v</code> is a unit vector
determined from <code>name</code>. Alternatively the linear combination
may be given directly (<code>lincomb</code>).
</p>


<h3>Value</h3>

<p>data.frame with parameter and function values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.tmbprofile">plot.tmbprofile</a></code>, <code><a href="#topic+confint.tmbprofile">confint.tmbprofile</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
runExample("simple",thisR=TRUE)
## Parameter names for this model:
## beta   beta   logsdu   logsd0

## Profile wrt. sigma0:
prof &lt;- tmbprofile(obj,"logsd0")
plot(prof)
confint(prof)

## Profile the difference between the beta parameters (name is optional):
prof2 &lt;- tmbprofile(obj,name="beta1 - beta2",lincomb = c(1,-1,0,0))
plot(prof2)
confint(prof2)

## End(Not run)
</code></pre>

<hr>
<h2 id='tmbroot'>Compute likelihood profile confidence intervals of a TMB object by root-finding</h2><span id='topic+tmbroot'></span>

<h3>Description</h3>

<p>Compute likelihood profile confidence intervals of a TMB object by root-finding
in contrast to <code><a href="#topic+tmbprofile">tmbprofile</a></code>, which tries to compute
somewhat equally spaced values along the likelihood profile (which
is useful for visualizing the shape of the likelihood surface),
and then (via <code><a href="#topic+confint.tmbprofile">confint.tmbprofile</a></code>) extracting a
critical value by linear interpolation,
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tmbroot(
  obj,
  name,
  target = 0.5 * qchisq(0.95, df = 1),
  lincomb,
  parm.range = c(NA, NA),
  sd.range = 7,
  trace = FALSE,
  continuation = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tmbroot_+3A_obj">obj</code></td>
<td>
<p>Object from <code>MakeADFun</code> that has been optimized.</p>
</td></tr>
<tr><td><code id="tmbroot_+3A_name">name</code></td>
<td>
<p>Name or index of a parameter to profile.</p>
</td></tr>
<tr><td><code id="tmbroot_+3A_target">target</code></td>
<td>
<p>desired deviation from minimum log-likelihood. Default
is set to retrieve the 95
if the objective function is a negative log-likelihood function</p>
</td></tr>
<tr><td><code id="tmbroot_+3A_lincomb">lincomb</code></td>
<td>
<p>Optional linear combination of parameters to
profile. By default a unit vector corresponding to <code>name</code>.</p>
</td></tr>
<tr><td><code id="tmbroot_+3A_parm.range">parm.range</code></td>
<td>
<p>lower and upper limits; if <code>NA</code>,
a value will be guessed based on the parameter value and <code>sd.range</code></p>
</td></tr>
<tr><td><code id="tmbroot_+3A_sd.range">sd.range</code></td>
<td>
<p>in the absence of explicit <code>parm.range</code> values,
the range chosen will be the parameter value plus or minus <code>sd.range</code>
times the corresponding standard deviation.
May be specified as a two-element vector for different ranges below and
above the parameter value.</p>
</td></tr>
<tr><td><code id="tmbroot_+3A_trace">trace</code></td>
<td>
<p>report information?</p>
</td></tr>
<tr><td><code id="tmbroot_+3A_continuation">continuation</code></td>
<td>
<p>use continuation method, i.e. set starting parameters for non-focal parameters to solutions from previous fits?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a two-element numeric vector containing the lower and upper limits (or <code>NA</code> if the target is not achieved in the range), with an attribute giving the total number of function iterations used
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
runExample("simple",thisR=TRUE)
logsd0.ci &lt;- tmbroot(obj,"logsd0")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
