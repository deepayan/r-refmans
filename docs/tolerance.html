<!DOCTYPE html><html><head><title>Help for package tolerance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tolerance}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#tolerance-package'>
<p>Statistical Tolerance Intervals and Regions</p></a></li>
<li><a href='#acc.samp'><p>Acceptance Sampling</p></a></li>
<li><a href='#anovatol.int'><p>Tolerance Intervals for ANOVA</p></a></li>
<li><a href='#bayesnormtol.int'><p>Bayesian Normal Tolerance Intervals</p></a></li>
<li><a href='#bintol.int'><p>Binomial Tolerance Intervals</p></a></li>
<li><a href='#bonftol.int'><p>Approximate 2-Sided Tolerance Intervals that Control the Tails Using Bonferroni's Inequality</p></a></li>
<li><a href='#cautol.int'><p>Cauchy Tolerance Intervals</p></a></li>
<li><a href='#diffnormtol.int'><p>1-Sided Tolerance Limits for the Distribution of the Difference Between Two Independent Normal Random Variables</p></a></li>
<li><a href='#DiffProp'>
<p>Difference Between Two Proportions Distribution</p></a></li>
<li><a href='#DiscretePareto'>
<p>Discrete Pareto Distribution</p></a></li>
<li><a href='#distfree.est'><p>Estimating Various Quantities for Distribution-Free Tolerance Intervals</p></a></li>
<li><a href='#dpareto.ll'>
<p>Maximum Likelihood Estimation for the Discrete Pareto Distribution</p></a></li>
<li><a href='#dparetotol.int'>
<p>Discrete Pareto Tolerance Intervals</p></a></li>
<li><a href='#exp2tol.int'><p>2-Parameter Exponential Tolerance Intervals</p></a></li>
<li><a href='#exptol.int'><p>Exponential Tolerance Intervals</p></a></li>
<li><a href='#exttol.int'><p>Weibull (or Extreme-Value) Tolerance Intervals</p></a></li>
<li><a href='#F1'><p>Appell's F1 Hypergeometric Function</p></a></li>
<li><a href='#fidbintol.int'>
<p>Fiducial-Based Tolerance Intervals for the Function of Two Binomial Proportions</p></a></li>
<li><a href='#fidnegbintol.int'>
<p>Fiducial-Based Tolerance Intervals for the Function of Two Negative Binomial Proportions</p></a></li>
<li><a href='#fidpoistol.int'>
<p>Fiducial-Based Tolerance Intervals for the Function of Two Poisson Rates</p></a></li>
<li><a href='#gamtol.int'><p>Gamma (or Log-Gamma) Tolerance Intervals</p></a></li>
<li><a href='#hypertol.int'><p>Hypergeometric Tolerance Intervals</p></a></li>
<li><a href='#K.factor'><p>Estimating K-factors for Tolerance Intervals Based on Normality</p></a></li>
<li><a href='#K.factor.sim'><p>Estimating K-factors for Simultaneous Tolerance Intervals Based on Normality</p></a></li>
<li><a href='#K.table'><p>Tables of K-factors for Tolerance Intervals Based on Normality</p></a></li>
<li><a href='#laptol.int'><p>Laplace Tolerance Intervals</p></a></li>
<li><a href='#logistol.int'><p>Logistic (or Log-Logistic) Tolerance Intervals</p></a></li>
<li><a href='#mvregtol.region'><p>Multivariate (Multiple) Linear Regression Tolerance Regions</p></a></li>
<li><a href='#mvtol.region'><p>Multivariate Normal Tolerance Regions</p></a></li>
<li><a href='#negbintol.int'><p>Negative Binomial Tolerance Intervals</p></a></li>
<li><a href='#NegHypergeometric'><p>The Negative Hypergeometric Distribution</p></a></li>
<li><a href='#neghypertol.int'><p>Negative Hypergeometric Tolerance Intervals</p></a></li>
<li><a href='#nlregtol.int'><p>Nonlinear Regression Tolerance Bounds</p></a></li>
<li><a href='#norm.OC'><p>Operating Characteristic (OC) Curves for K-Factors for Tolerance Intervals Based on Normality</p></a></li>
<li><a href='#norm.ss'><p>Sample Size Determination for Normal Tolerance Intervals</p></a></li>
<li><a href='#normtol.int'><p>Normal (or Log-Normal) Tolerance Intervals</p></a></li>
<li><a href='#np.order'><p>Sample Size Determination for Tolerance Limits Based on Order Statistics</p></a></li>
<li><a href='#npbetol.int'><p>Nonparametric Beta-Expectation Tolerance Intervals</p></a></li>
<li><a href='#npmvtol.region'><p>Nonparametric Multivariate Hyperrectangular Tolerance Regions</p></a></li>
<li><a href='#npregtol.int'><p>Nonparametric Regression Tolerance Bounds</p></a></li>
<li><a href='#nptol.int'><p>Nonparametric Tolerance Intervals</p></a></li>
<li><a href='#paretotol.int'><p>Pareto (or Power Distribution) Tolerance Intervals</p></a></li>
<li><a href='#plottol'><p>Plotting Capabilities for Tolerance Intervals</p></a></li>
<li><a href='#poislind.ll'>
<p>Maximum Likelihood Estimation for the Discrete Poisson-Lindley Distribution</p></a></li>
<li><a href='#poislindtol.int'>
<p>Poisson-Lindley Tolerance Intervals</p></a></li>
<li><a href='#PoissonLindley'>
<p>Discrete Poisson-Lindley Distribution</p></a></li>
<li><a href='#poistol.int'><p>Poisson Tolerance Intervals</p></a></li>
<li><a href='#regtol.int'><p>(Multiple) Linear Regression Tolerance Bounds</p></a></li>
<li><a href='#simnormtol.int'><p>Simultaneous Normal (or Log-Normal) Tolerance Intervals</p></a></li>
<li><a href='#tolerance-internal'><p>Internal Functions</p></a></li>
<li><a href='#TwoParExponential'><p>The 2-Parameter Exponential Distribution</p></a></li>
<li><a href='#umatol.int'><p>Uniformly Most Accurate Upper Tolerance Limits for Certain Discrete Distributions</p></a></li>
<li><a href='#uniftol.int'><p>Uniform Tolerance Intervals</p></a></li>
<li><a href='#ZipfMandelbrot'>
<p>Zipf-Mandelbrot Distributions</p></a></li>
<li><a href='#zipftol.int'>
<p>Zipf-Mandelbrot Tolerance Intervals</p></a></li>
<li><a href='#zm.ll'>
<p>Maximum Likelihood Estimation for Zipf-Mandelbrot Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Tolerance Intervals and Regions</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-02-04</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, rgl, stats4</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical tolerance limits provide the limits between which we can expect to find a specified proportion of a sampled population with a given level of confidence.  This package provides functions for estimating tolerance limits (intervals) for various univariate distributions (binomial, Cauchy, discrete Pareto, exponential, two-parameter exponential, extreme value, hypergeometric, Laplace, logistic, negative binomial, negative hypergeometric, normal, Pareto, Poisson-Lindley, Poisson, uniform, and Zipf-Mandelbrot), Bayesian normal tolerance limits, multivariate normal tolerance regions, nonparametric tolerance intervals, tolerance bands for regression settings (linear regression, nonlinear regression, nonparametric regression, and multivariate regression), and analysis of variance tolerance intervals.  Visualizations are also available for most of these settings.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-04 20:12:27 UTC; derekyoung</td>
</tr>
<tr>
<td>Author:</td>
<td>Derek S. Young [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Derek S. Young &lt;derek.young@uky.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-05 13:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='tolerance-package'>
Statistical Tolerance Intervals and Regions
</h2><span id='topic+tolerance-package'></span><span id='topic+tolerance'></span>

<h3>Description</h3>

<p>Statistical tolerance limits provide the limits between which we can expect to find a specified proportion of a sampled population with a given level of confidence.  This package provides functions for estimating tolerance limits (intervals) for various univariate distributions (binomial, Cauchy, discrete Pareto, exponential, two-parameter exponential, extreme value, hypergeometric, Laplace, logistic, negative binomial, negative hypergeometric, normal, Pareto, Poisson-Lindley, Poisson, uniform, and Zipf-Mandelbrot), Bayesian normal tolerance limits, multivariate normal tolerance regions, nonparametric tolerance intervals, tolerance bands for regression settings (linear regression, nonlinear regression, nonparametric regression, and multivariate regression), and analysis of variance tolerance intervals.  Visualizations are also available for most of these settings.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> tolerance</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.0.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2020-02-04</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> MASS, rgl, stats4</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Derek S. Young, Ph.D.
</p>
<p>Maintainer: Derek S. Young &lt;derek.young@uky.edu&gt;
</p>


<h3>References</h3>

<p>Hahn, G. J. and Meeker, W. Q. (1991), <em>Statistical Intervals: A Guide for Practitioners</em>, Wiley-Interscience.
</p>
<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>
<p>Patel, J. K. (1986), Tolerance Intervals - A Review, <em>Communications in Statistics - Theory and Methodology</em>,
<b>15</b>, 2719&ndash;2762.
</p>
<p>Young, D. S. (2010), <code>tolerance:</code> An <code>R</code> Package for Estimating Tolerance Intervals, <em>Journal of Statistical Software</em>, <b>36</b>(5), 1&ndash;39.
</p>
<p>Young, D. S. (2014), Computing Tolerance Intervals and Regions in <code>R</code>. In M. B. Rao and C. R. Rao (eds.), <em>Handbook of Statistics, Volume 32: Computational Statistics with <code>R</code></em>, 309&ndash;338. North-Holland, Amsterdam.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+confint">confint</a></code>
</p>

<hr>
<h2 id='acc.samp'>Acceptance Sampling</h2><span id='topic+acc.samp'></span>

<h3>Description</h3>

<p>Provides an upper bound on the number of acceptable rejects or nonconformities in a process.  This is similar
to a 1-sided upper tolerance bound for a hypergeometric random variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acc.samp(n, N, alpha = 0.05, P = 0.99, AQL = 0.01, RQL = 0.02)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acc.samp_+3A_n">n</code></td>
<td>
<p>The sample size to be drawn from the inventory.</p>
</td></tr>
<tr><td><code id="acc.samp_+3A_n">N</code></td>
<td>
<p>The total inventory (or lot) size.</p>
</td></tr>
<tr><td><code id="acc.samp_+3A_alpha">alpha</code></td>
<td>
<p><code>1-alpha</code> is the confidence level for bounding the probability of accepting the inventory.</p>
</td></tr>
<tr><td><code id="acc.samp_+3A_p">P</code></td>
<td>
<p>The proportion of items in the inventory which are to be accountable.</p>
</td></tr>
<tr><td><code id="acc.samp_+3A_aql">AQL</code></td>
<td>
<p>The acceptable quality level, which is the largest proportion of defects in a process considered
acceptable. Note that <code>0 &lt; AQL &lt; 1</code>.</p>
</td></tr>
<tr><td><code id="acc.samp_+3A_rql">RQL</code></td>
<td>
<p>The rejectable quality level, which is the largest proportion of defects in an independent lot
that one is willing to tolerate. Note that <code>AQL &lt; RQL &lt; 1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>acc.samp</code> returns a matrix with the following quantities:
</p>
<table>
<tr><td><code>acceptance.limit</code></td>
<td>
<p>The number of items in the sample which may be unaccountable, yet still be able to 
attain the desired confidence level <code>1-alpha</code>.</p>
</td></tr>
<tr><td><code>lot.size</code></td>
<td>
<p>The total inventory (or lot) size <code>N</code>.</p>
</td></tr>
<tr><td><code>confidence</code></td>
<td>
<p>The confidence level <code>1-alpha</code>.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of accountable items specified by the user.</p>
</td></tr>
<tr><td><code>AQL</code></td>
<td>
<p>The acceptable quality level as specified by the user.  If the sampling were to be repeated numerous times as a process, then
this quantity specifies the proportion of missing items considered acceptable from the process as a whole.  Conditioning on the
calculated value for <code>acceptance.limit</code>, the <code>AQL</code> is used to estimate the producer's risk (see <code>prod.risk</code> below).</p>
</td></tr>
<tr><td><code>RQL</code></td>
<td>
<p>The rejectable quality level as specified by the user.  This is the proportion of individual items in a sample one is willing
to tolerate missing. Conditioning on the calculated value for <code>acceptance.limit</code>, the <code>RQL</code> is used to estimate the consumer's risk (see <code>cons.risk</code> below).</p>
</td></tr>
<tr><td><code>sample.size</code></td>
<td>
<p>The sample size drawn as specified by <code>n</code>.</p>
</td></tr>
<tr><td><code>prod.risk</code></td>
<td>
<p>The producer's risk at the specified <code>AQL</code>.  This is the probability of rejecting an audit of a good inventory (also
called the Type I error).  A good inventory can be rejected if an unfortunate random sample is selected (e.g.,
most of the missing items happened to be selected for the audit).  <code>1-prod.risk</code> gives the confidence level of this 
sampling plan for the specified <code>AQL</code> and <code>RQL</code>.  If it is lower than the confidence level desired (e.g., because the <code>AQL</code> is too high), then a warning message will be displayed.</p>
</td></tr>
<tr><td><code>cons.risk</code></td>
<td>
<p>The consumer's risk at the specified <code>RQL</code>.  This is the probability of accepting an audit of a bad inventory (also
called the Type II error).  A bad inventory can be accepted if a fortunate random sample is selected (e.g., most of the missing
items happened to not be selected for the audit).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Montgomery, D. C. (2005), <em>Introduction to Statistical Quality Control</em>, Fifth Edition, John Wiley &amp; Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Hypergeometric">Hypergeometric</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## A 90%/90% acceptance sampling plan for a sample of 450 
## drawn from a lot size of 960.

acc.samp(n = 450, N = 960, alpha = 0.10, P = 0.90, AQL = 0.07,
         RQL = 0.10)
 </code></pre>

<hr>
<h2 id='anovatol.int'>Tolerance Intervals for ANOVA</h2><span id='topic+anovatol.int'></span>

<h3>Description</h3>

<p>Tolerance intervals for each factor level in a balanced (or nearly-balanced) ANOVA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anovatol.int(lm.out, data, alpha = 0.05, P = 0.99, side = 1,
             method = c("HE", "HE2", "WBE", "ELL", "KM", 
             "EXACT", "OCT"), m = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anovatol.int_+3A_lm.out">lm.out</code></td>
<td>
<p>An object of class <code>lm</code> (i.e., the results from the linear model fitting routine such that
the <code>anova</code> function can act upon).</p>
</td></tr>
<tr><td><code id="anovatol.int_+3A_data">data</code></td>
<td>
<p>A data frame consisting of the data fitted in <code>lm.out</code>.  Note that <code>data</code> must have one
column for each main effect (i.e., factor) that is analyzed in <code>lm.out</code> and that these columns must be of
class <code>factor</code>.</p>
</td></tr>
<tr><td><code id="anovatol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="anovatol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="anovatol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="anovatol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="anovatol.int_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code> and <code>method = "OCT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>anovatol.int</code> returns a list where each element is a data frame corresponding to each main effect (i.e.,
factor) tested in the ANOVA and the rows of each data frame are the levels of that factor.  The columns of each data
frame report the following:
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>The mean for that factor level.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The effective sample size for that factor level.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>The k-factor for constructing the respective factor level's tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Howe, W. G. (1969), Two-Sided Tolerance Limits for Normal Populations - Some Improvements, <em>Journal of the
American Statistical Association</em>, <b>64</b>, 610&ndash;620.
</p>
<p>Weissberg, A. and Beatty, G. (1969), Tables of Tolerance Limit Factors for Normal Distributions, <em>Technometrics</em>,
<b>2</b>, 483&ndash;500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+K.factor">K.factor</a></code>, <code><a href="#topic+normtol.int">normtol.int</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+anova">anova</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/95% 2-sided tolerance intervals for a 2-way ANOVA 
## using the "warpbreaks" data.

attach(warpbreaks)

lm.out &lt;- lm(breaks ~ wool + tension)
out &lt;- anovatol.int(lm.out, data = warpbreaks, alpha = 0.10,
                    P = 0.95, side = 2, method = "HE")
out

plottol(out, x = warpbreaks)
</code></pre>

<hr>
<h2 id='bayesnormtol.int'>Bayesian Normal Tolerance Intervals</h2><span id='topic+bayesnormtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided Bayesian tolerance intervals under the conjugate prior for data distributed according to a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayesnormtol.int(x = NULL, norm.stats = list(x.bar = NA, 
                 s = NA, n = NA), alpha = 0.05, P = 0.99, 
                 side = 1, method = c("HE", "HE2", "WBE", 
                 "ELL", "KM", "EXACT", "OCT"), m = 50,
                 hyper.par = list(mu.0 = NULL, 
                 sig2.0 = NULL, m.0 = NULL, n.0 = NULL))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayesnormtol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to a normal distribution.</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_norm.stats">norm.stats</code></td>
<td>
<p>An optional list of statistics that can be provided in-lieu of the full dataset.  If provided, the user must specify all three components: the sample mean (<code>x.bar</code>), the sample standard deviation (<code>s</code>), and the sample size (<code>n</code>).</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code> and <code>method = "OCT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
<tr><td><code id="bayesnormtol.int_+3A_hyper.par">hyper.par</code></td>
<td>
<p>A list consisting of the hyperparameters for the conjugate prior: the hyperparameters for the mean (<code>mu.0</code> and <code>n.0</code>) and the hyperparameters for the variance (<code>sig2.0</code> and <code>m.0</code>).</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Note that if one considers the non-informative prior distribution, then the Bayesian tolerance intervals are the same as the classical solution, which can be obtained by using <code><a href="#topic+normtol.int">normtol.int</a></code>.
</p>


<h3>Value</h3>

<p><code>bayesnormtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>x.bar</code></td>
<td>
<p>The sample mean.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower Bayesian tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper Bayesian tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower Bayesian tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper Bayesian tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Aitchison, J. (1964), Bayesian Tolerance Regions, <em>Journal of the
Royal Statistical Society, Series B</em>, <b>26</b>, 161&ndash;175.
</p>
<p>Guttman, I. (1970), <em>Statistical Tolerance Regions: Classical and Bayesian</em>,
Charles Griffin and Company.
</p>
<p>Young, D. S., Gordon, C. M., Zhu, S., and Olin, B. D. (2016), Sample Size Determination Strategies for Normal Tolerance Intervals Using Historical Data, <em>Quality Engineering</em>, <b>28</b>, 337&ndash;351.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">Normal</a></code>, <code><a href="#topic+normtol.int">normtol.int</a></code>, <code><a href="#topic+K.factor">K.factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/85% 1-sided Bayesian normal tolerance limits for 
## a sample of size 100. 

set.seed(100)
x &lt;- rnorm(100)
out &lt;- bayesnormtol.int(x = x, alpha = 0.05, P = 0.85, 
                        side = 1, method = "EXACT", 
                        hyper.par = list(mu.0 = 0, 
                        sig2.0 = 1, n.0 = 10, m.0 = 10))
out

plottol(out, x, plot.type = "both", side = "upper", 
        x.lab = "Normal Data")
</code></pre>

<hr>
<h2 id='bintol.int'>Binomial Tolerance Intervals</h2><span id='topic+bintol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for binomial random variables.  From a statistical quality control
perspective, these limits use the proportion of defective (or acceptable) items in a sample to bound the number
of defective (or acceptable) items in future productions of a specified quantity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bintol.int(x, n, m = NULL, alpha = 0.05, P = 0.99, side = 1, 
           method = c("LS", "WS", "AC", "JF", "CP", "AS", 
           "LO", "PR", "PO", "CL", "CC", "CWS"), 
           a1 = 0.5, a2 = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bintol.int_+3A_x">x</code></td>
<td>
<p>The number of defective (or acceptable) units in the sample. Can be a vector of length <code>n</code>, in which case the sum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_n">n</code></td>
<td>
<p>The size of the random sample of units selected for inspection.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_m">m</code></td>
<td>
<p>The quantity produced in future groups. If <code>m = NULL</code>, then the tolerance limits will be constructed assuming <code>n</code> for this quantity.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the defective (or acceptable) units in future samples of size <code>m</code> 
to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the lower and upper confidence bounds, which are used in the calculation
of the tolerance bounds.  The default method is <code>"LS"</code>, which is the large-sample method.  <code>"WS"</code> is Wilson's method, which is just the score confidence interval.  <code>"AC"</code> gives the Agresti-Coull method,
which is also appropriate when the sample size is large.  <code>"JF"</code> is Jeffreys' method, which is a Bayesian approach
to the estimation.  <code>"CP"</code> is the Clopper-Pearson (exact) method, which is based on beta percentiles and provides a more conservative interval.  <code>"AS"</code> is
the arcsine method, which is appropriate when the sample proportion is not too close to 0 or 1.  <code>"LO"</code> is the logit
method, which also is appropriate when the sample proportion is not too close to 0 or 1, but yields a more conservative interval.  <code>"PR"</code> uses a probit transformation and is accurate for large sample sizes.  <code>"PO"</code> is based on a Poisson parameterization, but it tends to be more erratic compared to the other methods.  <code>"CL"</code> is the complementary log transformation and also tends to perform well for large sample sizes.  <code>"CC"</code> gives a continuity-corrected version of the large-sample method.  <code>"CWS"</code> gives a continuity-corrected version of Wilson's method.
More information on these methods can be found in the &quot;References&quot;.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_a1">a1</code></td>
<td>
<p>This specifies the first shape hyperparameter when using Jeffreys' method.</p>
</td></tr>
<tr><td><code id="bintol.int_+3A_a2">a2</code></td>
<td>
<p>This specifies the second shape hyperparameter when using Jeffreys' method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bintol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of defective (or acceptable) units in future samples of size <code>m</code>.</p>
</td></tr>
<tr><td><code>p.hat</code></td>
<td>
<p>The proportion of defective (or acceptable) units in the sample, calculated by <code>x/n</code>.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brown, L. D., Cai, T. T., and DasGupta, A. (2001), Interval Estimation for a Binomial Proportion, 
<em>Statistical Science</em>, <b>16</b>, 101&ndash;133.
</p>
<p>Hahn, G. J. and Chandra, R. (1981), Tolerance Intervals for Poisson and Binomial Variables,
<em>Journal of Quality Technology</em>, <b>13</b>, 100&ndash;110.
</p>
<p>Newcombe, R. G. (1998), Two-Sided Confidence Intervals for the Single Proportion: Comparison of Seven Methods, <em>Statistics in Medicine</em>, <b>17</b>, 857&ndash;872.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Binomial">Binomial</a></code>, <code><a href="#topic+umatol.int">umatol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 85%/90% 2-sided binomial tolerance intervals for a future 
## lot of 2500 when a sample of 230 were drawn from a lot of 
## 1000.  All methods but Jeffreys' method are compared
## below.

bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "LS")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "WS")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "AC")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "CP")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "AS")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "LO")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "PR")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "PO")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "CL")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "CC")
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 2, method = "CWS")
           
## Using Jeffreys' method to construct the 85%/90% 1-sided 
## binomial tolerance limits.  The first calculation assumes 
## a prior on the proportion of defects which places greater
## density on values near 0.  The second calculation assumes
## a prior on the proportion of defects which places greater
## density on values near 1.

bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 1, method = "JF", a1 = 2, a2 = 10)
bintol.int(x = 230, n = 1000, m = 2500, alpha = 0.15, P = 0.90,
           side = 1, method = "JF", a1 = 5, a2 = 1)


 </code></pre>

<hr>
<h2 id='bonftol.int'>Approximate 2-Sided Tolerance Intervals that Control the Tails Using Bonferroni's Inequality</h2><span id='topic+bonftol.int'></span>

<h3>Description</h3>

<p>This function allows the user to control what proportion of the population is to be in the tails of the given distribution for
a 2-sided tolerance interval.  The result is a conservative approximation based on Bonferroni's inequality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bonftol.int(fn, P1 = 0.005, P2 = 0.005, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bonftol.int_+3A_fn">fn</code></td>
<td>
<p>The function name for the 2-sided tolerance interval to be calculated.</p>
</td></tr>
<tr><td><code id="bonftol.int_+3A_p1">P1</code></td>
<td>
<p>The proportion of the population not covered in the lower tail of the distribution.</p>
</td></tr>
<tr><td><code id="bonftol.int_+3A_p2">P2</code></td>
<td>
<p>The proportion of the population not covered in the upper tail of the distribution.</p>
</td></tr>
<tr><td><code id="bonftol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="bonftol.int_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>fn</code>, including the data.  All arguments that would be specified in <code>fn</code> must
also be specified here.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The results for the 2-sided tolerance interval procedure are reported.  See the corresponding help file for <code>fn</code> about
specific output.  Note that the (minimum) proportion of the population to be covered by this interval is <code>1 - (P1 + P2)</code>.
</p>


<h3>Note</h3>

<p>This function can be used with any 2-sided tolerance interval function, including the regression tolerance interval functions.
</p>


<h3>References</h3>

<p>Jensen, W. A. (2009), Approximations of Tolerance Intervals for Normally Distributed Data, <em>Quality and Reliability
Engineering International</em>, <b>25</b>, 571&ndash;580.
</p>
<p>Patel, J. K. (1986), Tolerance Intervals - A Review, <em>Communications in Statistics - Theory and Methodology</em>,
<b>15</b>, 2719&ndash;2762.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/97% tolerance interval for normally distributed
## data controlling 1% of the data is in the lower tail
## and 2% of the data in the upper tail.

set.seed(100)
x &lt;- rnorm(100, 0, 0.2)
bonftol.int(normtol.int, x = x, P1 = 0.01, P2 = 0.02,
            alpha = 0.05, method = "HE")

</code></pre>

<hr>
<h2 id='cautol.int'>Cauchy Tolerance Intervals</h2><span id='topic+cautol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for Cauchy distributed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cautol.int(x, alpha = 0.05, P = 0.99, side = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cautol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is Cauchy distributed.</p>
</td></tr>
<tr><td><code id="cautol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="cautol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="cautol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>cautol.int</code> returns a data.frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bain, L. J. (1978), <em>Statistical Analysis of Reliability and Life-Testing Models</em>, Marcel Dekker, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Cauchy">Cauchy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/90% 2-sided Cauchy tolerance interval for a sample 
## of size 1000. 

set.seed(100)
x &lt;- rcauchy(1000, 100000, 10)
out &lt;- cautol.int(x = x, alpha = 0.05, P = 0.90, side = 2)
out

plottol(out, x, plot.type = "both", x.lab = "Cauchy Data")
</code></pre>

<hr>
<h2 id='diffnormtol.int'>1-Sided Tolerance Limits for the Distribution of the Difference Between Two Independent Normal Random Variables</h2><span id='topic+diffnormtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided tolerance limits for the difference between two independent normal random variables.  If the ratio of the variances is known,
then an exact calculation is performed.  Otherwise, approximation methods are implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffnormtol.int(x1, x2, var.ratio = NULL, alpha = 0.05, 
                P = 0.99, method = c("HALL", "GK", "RG"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffnormtol.int_+3A_x1">x1</code></td>
<td>
<p>A vector of sample data which is distributed according to a normal distribution (sample 1).</p>
</td></tr>
<tr><td><code id="diffnormtol.int_+3A_x2">x2</code></td>
<td>
<p>Another vector of sample data which is distributed according to a normal distribution (sample 2).  It can be of a different sample size than
the sample specified by <code>x1</code>.</p>
</td></tr>
<tr><td><code id="diffnormtol.int_+3A_var.ratio">var.ratio</code></td>
<td>
<p>A specified, known value of the variance ratio (i.e., the ratio of the variance for population 1 to the variance of population 2).
If <code>NULL</code>, then the variance ratio is estimated according to one of the three methods specified in the <code>method</code> argument.</p>
</td></tr>
<tr><td><code id="diffnormtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="diffnormtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by the tolerance limits.</p>
</td></tr>
<tr><td><code id="diffnormtol.int_+3A_method">method</code></td>
<td>
<p>The method for estimating the variance ratio.  This only needs to be specified in the case when
<code>var.ratio</code> is not <code>NULL</code>.  <code>"HALL"</code> is Hall's method, which takes a bias-corrected version of the ratio between the sample variance for sample 1 to
the sample variance for sample 2.  <code>"GK"</code> is the Guo-Krishnamoorthy method, which first calculates a bias-corrected version of the ratio between the sample variance for sample 2
to the sample variance for sample 1.  The resulting limit is then compared to the limit from Hall's method and the most conservative limit is chosen.  <code>"RG"</code> is
the Reiser-Guttman method, which is a biased version of the variance ratio that is calculated by taking the sample variance for sample 1 to the sample variance for sample 2.  
Typically, Hall's method or the Guo-Krishnamoorthy method are preferred to the Reiser-Guttman method. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Satterthwaite's approximation for the degrees of freedom is used when the variance ratio is unknown.
</p>


<h3>Value</h3>

<p><code>diffnormtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>diff.bar</code></td>
<td>
<p>The difference between the sample means.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Unlike other tolerance interval functions, the output from <code>diffnormtol.int</code> cannot be passed to <code>plottol</code>.
</p>


<h3>References</h3>

<p>Guo, H. and Krishnamoorthy, K. (2004), New Approximate Inferential Methods for the Reliability Parameter in a Stress-Strength Model: The
Normal Case, <em>Communications in Statistics - Theory and Methods</em>, <b>33</b>, 1715&ndash;1731.
</p>
<p>Hall, I. J. (1984), Approximate One-Sided Tolerance Limits for the Difference or Sum of Two Independent Normal Variates, <em>Journal of Quality
Technology</em>, <b>16</b>, 15&ndash;19.
</p>
<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>
<p>Reiser, B. J. and Guttman, I. (1986), Statistical Inference for Pr(Y &lt; X): The Normal Case, <em>Technometrics</em>,
<b>28</b>, 253&ndash;257.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">Normal</a></code>, <code><a href="#topic+K.factor">K.factor</a></code>, <code><a href="#topic+normtol.int">normtol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/99% tolerance limits for the difference between two
## simulated normal data sets.  This data is taken from
## Krishnamoorthy and Mathew (2009).  Note that there is a
## calculational error in their example, which yields different
## results with the output below. 

x1 &lt;- c(10.166, 5.889, 8.258, 7.303, 8.757)
x2 &lt;- c(-0.204, 2.578, 1.182, 1.892, 0.786, -0.517, 1.156,
        0.980, 0.323, 0.437, 0.397, 0.050, 0.812, 0.720)

diffnormtol.int(x1, x2, alpha = 0.10, P = 0.99, method = "HALL")
diffnormtol.int(x1, x2, alpha = 0.10, P = 0.99, method = "GK")
diffnormtol.int(x1, x2, alpha = 0.10, P = 0.99, method = "RG")
diffnormtol.int(x1, x2, var.ratio = 3.8, alpha = 0.10, P = 0.99)
</code></pre>

<hr>
<h2 id='DiffProp'>
Difference Between Two Proportions Distribution
</h2><span id='topic+DiffProp'></span><span id='topic+ddiffprop'></span><span id='topic+pdiffprop'></span><span id='topic+qdiffprop'></span><span id='topic+rdiffprop'></span>

<h3>Description</h3>

<p>Density (mass), distribution function, quantile function, and random generation for the difference between two proportions.  This is determined by taking the difference between two independent beta distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddiffprop(x, k1, k2, n1, n2, a1 = 0.5, a2 = 0.5,
          log = FALSE, ...)
pdiffprop(q, k1, k2, n1, n2, a1 = 0.5, a2 = 0.5,
          lower.tail = TRUE, log.p = FALSE, ...)
qdiffprop(p, k1, k2, n1, n2, a1 = 0.5, a2 = 0.5,
          lower.tail = TRUE, log.p = FALSE, ...)
rdiffprop(n, k1, k2, n1, n2, a1 = 0.5, a2 = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DiffProp_+3A_x">x</code>, <code id="DiffProp_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_n">n</code></td>
<td>
<p>The number of observations.  If <code>length&gt;1</code>, then the length is taken to be the number
required.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_k1">k1</code>, <code id="DiffProp_+3A_k2">k2</code></td>
<td>
<p>The number of successes drawn from groups 1 and 2, respectively.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_n1">n1</code>, <code id="DiffProp_+3A_n2">n2</code></td>
<td>
<p>The sample sizes for groups 1 and 2, respectively.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_a1">a1</code>, <code id="DiffProp_+3A_a2">a2</code></td>
<td>
<p>The shift parameters for the beta distributions.  For the fiducial approach, we know that the lower and upper limits are set at <code>a1 = a2 = 0</code> and <code>a1 = a2 = 1</code>, respectively, for the true <code>p1</code> and <code>p2</code>.  While computations can be performed on real values outside the unit interval, a <code>warning</code> message will be returned if such values are specified. For practical purposes, the default value of 0.5 should be used for each parameter.</p>
</td></tr>  
<tr><td><code id="DiffProp_+3A_log">log</code>, <code id="DiffProp_+3A_log.p">log.p</code></td>
<td>
<p>Logical vectors.  If <code>TRUE</code>, then the probabilities are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical vector.  If <code>TRUE</code>, then probabilities are <code class="reqn">P[X\le x]</code>, else <code class="reqn">P[X&gt;x]</code>.</p>
</td></tr>
<tr><td><code id="DiffProp_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the Appell <code>F1</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The difference between two proportions distribution has a fairly complicated functional form.  Please see the article by Chen and Luo (2011), who corrected a typo in the article by Nadarajah and Kotz (2007), for the functional form of this distribution.
</p>


<h3>Value</h3>

<p><code>ddiffprop</code> gives the density (mass), <code>pdiffprop</code> gives the distribution function, <code>qdiffprop</code> gives the quantile function, and <code>rdiffprop</code> generates random deviates. 
</p>


<h3>References</h3>

<p>Chen, Y. and Luo, S. (2011), A Few Remarks on 'Statistical Distribution of the Difference of Two Proportions', <em>Statistics in Medicine</em>, <b>30</b>, 1913&ndash;1915. 
</p>
<p>Nadarajah, S. and Kotz, S. (2007), Statistical Distribution of the Difference of Two Proportions, <em>Statistics in Medicine</em>, <b>26</b>, 3518&ndash;3523. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> about random number generation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data from the difference between
## two proportions distribution.

set.seed(100)
x &lt;- rdiffprop(n = 100, k1 = 2, k2 = 10, n1 = 17, n2 = 13)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 &lt;- sort(x)
y &lt;- ddiffprop(x = x.1, k1 = 2, k2 = 10, n1 = 17, n2 = 13)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, pdiffprop(q = x.1, k1 = 2, k2 = 10, n1 = 17, 
     n2 = 13), type = "l", xlab = "x", 
     ylab = "Cumulative Probabilities")

qdiffprop(p = 0.20, k1 = 2, k2 = 10, n1 = 17, n2 = 13, 
          lower.tail = FALSE)
qdiffprop(p = 0.80, k1 = 2, k2 = 10, n1 = 17, n2 = 13)
</code></pre>

<hr>
<h2 id='DiscretePareto'>
Discrete Pareto Distribution
</h2><span id='topic+DiscretePareto'></span><span id='topic+ddpareto'></span><span id='topic+pdpareto'></span><span id='topic+qdpareto'></span><span id='topic+rdpareto'></span>

<h3>Description</h3>

<p>Density (mass), distribution function, quantile function, and random generation for the discrete Pareto distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddpareto(x, theta, log = FALSE)
pdpareto(q, theta, lower.tail = TRUE, log.p = FALSE)
qdpareto(p, theta, lower.tail = TRUE, log.p = FALSE)
rdpareto(n, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DiscretePareto_+3A_x">x</code>, <code id="DiscretePareto_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="DiscretePareto_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="DiscretePareto_+3A_n">n</code></td>
<td>
<p>The number of observations.  If <code>length&gt;1</code>, then the length is taken to be the number
required.</p>
</td></tr>
<tr><td><code id="DiscretePareto_+3A_theta">theta</code></td>
<td>
<p>The shape parameter, which must be greater than 0 and less than 1.</p>
</td></tr>
<tr><td><code id="DiscretePareto_+3A_log">log</code>, <code id="DiscretePareto_+3A_log.p">log.p</code></td>
<td>
<p>Logical vectors.  If <code>TRUE</code>, then the probabilities are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="DiscretePareto_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical vector.  If <code>TRUE</code>, then probabilities are <code class="reqn">P[X\le x]</code>, else <code class="reqn">P[X&gt;x]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete Pareto distribution has mass
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \theta^{\log(1+x)}-\theta^{\log(2+x)},</code>
</p>

<p>where <code class="reqn">x=0,1,\ldots</code> and <code class="reqn">0&lt;\theta&lt;1</code> is the shape parameter. 
</p>


<h3>Value</h3>

<p><code>ddpareto</code> gives the density (mass), <code>pdpareto</code> gives the distribution function, <code>qdpareto</code> gives the quantile function, and <code>rdpareto</code> generates random deviates for the specified distribution. 
</p>


<h3>References</h3>

<p>Krishna, H. and Pundir, P. S. (2009), Discrete Burr and Discrete Pareto Distributions, 
<em>Statistical Methodology</em>, <b>6</b>, 177&ndash;188.
</p>
<p>Young, D. S., Naghizadeh Qomi, M., and Kiapour, A. (2019), Approximate Discrete Pareto Tolerance Limits for Characterizing Extremes in Count Data, <em>Statistica Neerlandica</em>, <b>73</b>, 4&ndash;21. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> about random number generation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data from the discrete Pareto
## distribution.

set.seed(100)
x &lt;- rdpareto(n = 150, theta = 0.2)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 &lt;- sort(x)
y &lt;- ddpareto(x = x.1, theta = 0.2)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, pdpareto(q = x.1, theta = 0.2), type = "l", 
     xlab = "x", ylab = "Cumulative Probabilities")

qdpareto(p = 0.80, theta = 0.2, lower.tail = FALSE)
qdpareto(p = 0.95, theta = 0.2)
</code></pre>

<hr>
<h2 id='distfree.est'>Estimating Various Quantities for Distribution-Free Tolerance Intervals</h2><span id='topic+distfree.est'></span>

<h3>Description</h3>

<p>When providing two of the three quantities <code>n</code>, <code>alpha</code>, and <code>P</code>, this function solves for the 
third quantity in the context of distribution-free tolerance intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distfree.est(n = NULL, alpha = NULL, P = NULL, side = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distfree.est_+3A_n">n</code></td>
<td>
<p>The necessary sample size to cover a proportion <code>P</code> of the population with
confidence <code>1-alpha</code>.  Can be a vector.</p>
</td></tr>
<tr><td><code id="distfree.est_+3A_alpha">alpha</code></td>
<td>
<p>1 minus the confidence level attained when it is desired to cover a proportion <code>P</code>
of the population and a sample size <code>n</code> is provided.  Can be a vector.</p>
</td></tr>
<tr><td><code id="distfree.est_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered with confidence <code>1-alpha</code> when a sample size <code>n</code>
is provided.  Can be a vector.</p>
</td></tr>
<tr><td><code id="distfree.est_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is assumed (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>When providing two of the three quantities <code>n</code>, <code>alpha</code>, and <code>P</code>, <code>distfree.est</code> returns the
third quantity.  If more than one value of a certain quantity is specified, then a table will be returned.
</p>


<h3>References</h3>

<p>Natrella, M. G. (1963), <em>Experimental Statistics: National Bureau of Standards - Handbook No. 91</em>,
United States Government Printing Office, Washington, D.C. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nptol.int">nptol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Solving for 1 minus the confidence level.

distfree.est(n = 59, P = 0.95, side = 1)

## Solving for the sample size.

distfree.est(alpha = 0.05, P = 0.95, side = 1)

## Solving for the proportion of the population to cover.

distfree.est(n = 59, alpha = 0.05, side = 1)

## Solving for sample sizes for many tolerance specifications.

distfree.est(alpha = seq(0.01, 0.05, 0.01), 
             P = seq(0.80, 0.99, 0.01), side = 2)


</code></pre>

<hr>
<h2 id='dpareto.ll'>
Maximum Likelihood Estimation for the Discrete Pareto Distribution
</h2><span id='topic+dpareto.ll'></span>

<h3>Description</h3>

<p>Performs maximum likelihood estimation for the parameter of the discrete Pareto distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpareto.ll(x, theta = NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpareto.ll_+3A_x">x</code></td>
<td>
<p>A vector of raw data which is distributed according to a Poisson-Lindley distribution.</p>
</td></tr>
<tr><td><code id="dpareto.ll_+3A_theta">theta</code></td>
<td>
<p>Optional starting value for the parameter.  If <code>NULL</code>, then the method of moments estimator is used.</p>
</td></tr>
<tr><td><code id="dpareto.ll_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>mle</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete Pareto distribution is a discretized of the continuous Type II Pareto distribution (also called the Lomax distribution).
</p>


<h3>Value</h3>

<p>See the help file for <code>mle</code> to see how the output is structured.				
</p>


<h3>References</h3>

<p>Krishna, H. and Pundir, P. S. (2009), Discrete Burr and Discrete Pareto Distributions, 
<em>Statistical Methodology</em>, <b>6</b>, 177&ndash;188.
</p>
<p>Young, D. S., Naghizadeh Qomi, M., and Kiapour, A. (2019), Approximate Discrete Pareto Tolerance Limits for Characterizing Extremes in Count Data, <em>Statistica Neerlandica</em>, <b>73</b>, 4&ndash;21. 
</p>


<h3>See Also</h3>

<p><code><a href="stats4.html#topic+mle">mle</a></code>, <code><a href="#topic+DiscretePareto">DiscretePareto</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Maximum likelihood estimation for randomly generated data
## from the discrete Pareto distribution. 

set.seed(100)

dp.data &lt;- rdpareto(n = 500, theta = 0.2)
out.dp &lt;- dpareto.ll(dp.data)
stats4::coef(out.dp)
stats4::vcov(out.dp)
</code></pre>

<hr>
<h2 id='dparetotol.int'>
Discrete Pareto Tolerance Intervals
</h2><span id='topic+dparetotol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to the discrete Pareto distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dparetotol.int(x, m = NULL, alpha = 0.05, P = 0.99, side = 1, 
                ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dparetotol.int_+3A_x">x</code></td>
<td>
<p>A vector of raw data which is distributed according to a discrete Pareto distribution.</p>
</td></tr>
<tr><td><code id="dparetotol.int_+3A_m">m</code></td>
<td>
<p>The number of observations in a future sample for which the tolerance limits will be calculated.  By default, <code>m = NULL</code> and, thus, <code>m</code> will be set equal to the original sample size.</p>
</td></tr>
<tr><td><code id="dparetotol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that 1-alpha is the confidence level.</p>
</td></tr>
<tr><td><code id="dparetotol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="dparetotol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="dparetotol.int_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>dpareto.ll</code> function, which is used for maximum likelihood estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete Pareto is a discretized of the continuous Type II Pareto distribution (also called the Lomax distribution). Discrete Pareto distributions are heavily right-skewed distributions and potentially good models for discrete lifetime data and extremes in count data.  For most practical applications, one will typically be interested in 1-sided upper bounds.
</p>


<h3>Value</h3>

<p><code>dparetotol.int</code> returns a data frame with the following items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr> 
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr> 
<tr><td><code>theta</code></td>
<td>
<p>MLE for the shape parameter <code>theta</code>.</p>
</td></tr> 
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 				
</table>


<h3>References</h3>

<p>Young, D. S., Naghizadeh Qomi, M., and Kiapour, A. (2019), Approximate Discrete Pareto Tolerance Limits for Characterizing Extremes in Count Data, <em>Statistica Neerlandica</em>, <b>73</b>, 4&ndash;21. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DiscretePareto">DiscretePareto</a></code>, <code><a href="#topic+dpareto.ll">dpareto.ll</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 95%/95% 1-sided tolerance intervals for data assuming 
## the discrete Pareto distribution.

set.seed(100)

x &lt;- rdpareto(n = 500, theta = 0.5)
out &lt;- dparetotol.int(x, alpha = 0.05, P = 0.95, side = 1)
out
</code></pre>

<hr>
<h2 id='exp2tol.int'>2-Parameter Exponential Tolerance Intervals</h2><span id='topic+exp2tol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to a 2-parameter
exponential distribution.  Data with Type II censoring is permitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp2tol.int(x, alpha = 0.05, P = 0.99, side = 1,
            method = c("GPU", "DUN", "KM"), type.2 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp2tol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to the 2-parameter exponential distribution.</p>
</td></tr>
<tr><td><code id="exp2tol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="exp2tol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="exp2tol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="exp2tol.int_+3A_method">method</code></td>
<td>
<p>The method for how the upper tolerance bound is approximated.  <code>"GPU"</code> is the
Guenther-Patil-Upppuluri method. <code>"DUN"</code> is the Dunsmore method, which has been empirically shown to be an improvement
for samples greater than or equal to 8.  <code>"KM"</code> is the Krishnamoorthy-Mathew method, which is typically more liberal than the other methods. More information on these methods can be found in the &quot;References&quot;, which also highlight general sample size conditions as to when these different methods should be used.</p>
</td></tr>
<tr><td><code id="exp2tol.int_+3A_type.2">type.2</code></td>
<td>
<p>Select <code>TRUE</code> if Type II censoring is present (i.e., the data set is censored at the maximum
value present).  The default is <code>FALSE</code>.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>exp2tol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dunsmore, I. R. (1978), Some Approximations for Tolerance Factors for the Two Parameter Exponential Distribution,
<em>Technometrics</em>, <b>20</b>, 317&ndash;318.
</p>
<p>Engelhardt, M. and Bain, L. J. (1978), Tolerance Limits and Confidence Limits on Reliability for the Two-Parameter
Exponential Distribution, <em>Technometrics</em>, <b>20</b>, 37&ndash;39.
</p>
<p>Guenther, W. C., Patil, S. A., and Uppuluri, V. R. R. (1976), One-Sided <code class="reqn">\beta</code>-Content Tolerance Factors
for the Two Parameter Exponential Distribution, <em>Technometrics</em>, <b>18</b>, 333&ndash;340.  
</p>
<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TwoParExponential">TwoParExponential</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/90% 1-sided 2-parameter exponential tolerance intervals
## for a sample of size 50. 

set.seed(100)
x &lt;- r2exp(50, 6, shift = 55)
out &lt;- exp2tol.int(x = x, alpha = 0.05, P = 0.90, side = 1,
                   method = "DUN", type.2 = FALSE)
out

plottol(out, x, plot.type = "both", side = "upper", 
        x.lab = "2-Parameter Exponential Data")
</code></pre>

<hr>
<h2 id='exptol.int'>Exponential Tolerance Intervals</h2><span id='topic+exptol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to an
exponential distribution.  Data with Type II censoring is permitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exptol.int(x, alpha = 0.05, P = 0.99, side = 1, type.2 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exptol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to an exponential distribution.</p>
</td></tr>
<tr><td><code id="exptol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="exptol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="exptol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="exptol.int_+3A_type.2">type.2</code></td>
<td>
<p>Select <code>TRUE</code> if Type II censoring is present (i.e., the data set is censored at the maximum
value present).  The default is <code>FALSE</code>.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>exptol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>lambda.hat</code></td>
<td>
<p>The mean of the data (i.e., <code>1/rate</code>).</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Blischke, W. R. and Murthy, D. N. P. (2000), <em>Reliability: Modeling, Prediction, and Optimization</em>,
John Wiley &amp; Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Exponential">Exponential</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/99% 1-sided exponential tolerance intervals for a
## sample of size 50. 

set.seed(100)
x &lt;- rexp(100, 0.004)
out &lt;- exptol.int(x = x, alpha = 0.05, P = 0.99, side = 1,
                  type.2 = FALSE)
out

plottol(out, x, plot.type = "both", side = "lower", 
        x.lab = "Exponential Data")
</code></pre>

<hr>
<h2 id='exttol.int'>Weibull (or Extreme-Value) Tolerance Intervals</h2><span id='topic+exttol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to either a Weibull distribution or
extreme-value (also called Gumbel) distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exttol.int(x, alpha = 0.05, P = 0.99, side = 1,
           dist = c("Weibull", "Gumbel"), ext = c("min", "max"), 
           NR.delta = 1e-8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exttol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to either a Weibull distribution or an extreme-value
distribution.</p>
</td></tr>
<tr><td><code id="exttol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="exttol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="exttol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="exttol.int_+3A_dist">dist</code></td>
<td>
<p>Select either <code>dist = "Weibull"</code> or <code>dist = "Gumbel"</code> if the data is distributed according
to the Weibull or extreme-value distribution, respectively.</p>
</td></tr>
<tr><td><code id="exttol.int_+3A_ext">ext</code></td>
<td>
<p>If <code>dist = "Gumbel"</code>, then select which extreme is to be modeled for the Gumbel distribution.  The
Gumbel distribution for the minimum (i.e., <code>ext = "min"</code>) corresponds to a left-skewed distribution and the
Gumbel distribution for the maximum (i.e., <code>ext = "max"</code>) corresponds to a right-skewed distribution</p>
</td></tr>
<tr><td><code id="exttol.int_+3A_nr.delta">NR.delta</code></td>
<td>
<p>The stopping criterion used for the Newton-Raphson algorithm when finding the maximum likelihood
estimates of the Weibull or extreme-value distribution.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Recall that the relationship between the Weibull distribution and the extreme-value distribution for the minimum is that if the
random variable <code class="reqn">X</code> is distributed according to a Weibull distribution, then the random variable <code class="reqn">Y = ln(X)</code> is
distributed according to an extreme-value distribution for the minimum.
</p>
<p>If <code>dist = "Weibull"</code>, then the natural logarithm of the data are taken so that a Newton-Raphson algorithm can
be employed to find the MLEs of the extreme-value distribution for the minimum and then the data and MLEs are transformed back appropriately.
No transformation is performed if <code>dist = "Gumbel"</code>.  The Newton-Raphson algorithm is initialized by the method of moments
estimators for the parameters.
</p>


<h3>Value</h3>

<p><code>exttol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>shape.1</code></td>
<td>
<p>MLE for the shape parameter if <code>dist = "Weibull"</code> or for the location parameter if
<code>dist = "Gumbel"</code>.</p>
</td></tr>
<tr><td><code>shape.2</code></td>
<td>
<p>MLE for the scale parameter if <code>dist = "Weibull"</code> or <code>dist = "Gumbel"</code>.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bain, L. J. and Engelhardt, M. (1981), Simple Approximate Distributional Results for Confidence and Tolerance Limits
for the Weibull Distribution Based on Maximum Likelihood Estimators, <em>Technometrics</em>, <b>23</b>, 15&ndash;20.
</p>
<p>Coles, S. (2001), <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Weibull">Weibull</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 85%/90% 1-sided Weibull tolerance intervals for a sample
## of size 150. 

set.seed(100)
x &lt;- rweibull(150, 3, 75)
out &lt;- exttol.int(x = x, alpha = 0.15, P = 0.90, side = 1,
                  dist = "Weibull")
out

plottol(out, x, plot.type = "both", side = "lower", 
        x.lab = "Weibull Data")
</code></pre>

<hr>
<h2 id='F1'>Appell's F1 Hypergeometric Function</h2><span id='topic+F1'></span>

<h3>Description</h3>

<p>The Appell function of the first kind, which is a two variable extension of the hypergeometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F1(a, b, b.prime, c, x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F1_+3A_a">a</code>, <code id="F1_+3A_b">b</code>, <code id="F1_+3A_b.prime">b.prime</code>, <code id="F1_+3A_c">c</code></td>
<td>
<p>Appropriate parameters for this function.</p>
</td></tr>
<tr><td><code id="F1_+3A_x">x</code>, <code id="F1_+3A_y">y</code></td>
<td>
<p>The inputted values to evaluate this function such that each is less than 1 in absolute value.</p>
</td></tr>
<tr><td><code id="F1_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>integrate</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>F1</code> returns the simple integral result for the Appell function of the first kind with the arguments specified above.
</p>


<h3>Note</h3>

<p>This function is solved by using a simple integral representation for real numbers.  While all four of the Appell functions can be extended to the complex plane, this is not an option for this code.
</p>


<h3>References</h3>

<p>Bailey, W. N. (1935), <em>Generalised Hypergeometric Series</em>, Cambridge University Press.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DiffProp">DiffProp</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Sample calculation.

F1(a = 3, b = 4, b.prime = 5, c = 13, x = 0.2, y = 0.4)
</code></pre>

<hr>
<h2 id='fidbintol.int'>
Fiducial-Based Tolerance Intervals for the Function of Two Binomial Proportions
</h2><span id='topic+fidbintol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for the function of two binomial proportions using fiducial quantities. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fidbintol.int(x1, x2, n1, n2, m1 = NULL, m2 = NULL, FUN, 
              alpha = 0.05, P = 0.99, side = 1, K = 1000, 
              B = 1000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fidbintol.int_+3A_x1">x1</code></td>
<td>
<p>A value of observed &quot;successes&quot; from group 1.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_x2">x2</code></td>
<td>
<p>A value of observed &quot;successes&quot; from group 2.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_n1">n1</code></td>
<td>
<p>The total number of trials for group 1.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_n2">n2</code></td>
<td>
<p>The total number of trials for group 2.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_m1">m1</code></td>
<td>
<p>The total number of future trials for group 1. If <code>NULL</code>, then it is set to <code>n1</code>.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_m2">m2</code></td>
<td>
<p>The total number of future trials for group 2. If <code>NULL</code>, then it is set to <code>n2</code>.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_fun">FUN</code></td>
<td>
<p>Any reasonable (and meaningful) function taking exactly two arguments that we are interested in constructing a tolerance interval on.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that 1-alpha is the confidence level.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_k">K</code></td>
<td>
<p>The number of fiducial quantities to be generated.  The number of iterations should be at least as large as the default value of 1000. See <code>Details</code> for the definition of the fiducial quantity for a binomial proportion.</p>
</td></tr>
<tr><td><code id="fidbintol.int_+3A_b">B</code></td>
<td>
<p>The number of iterations used for the Monte Carlo algorithm which determines the tolerance limits. The number of iterations should be at least as large as the default value of 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">X</code> is observed from a <code class="reqn">Bin(n,p)</code> distribution, then the fiducial quantity for <code class="reqn">p</code> is <code class="reqn">Beta(X+0.5,n-X+0.5)</code>.
</p>


<h3>Value</h3>

<p><code>fidbintol.int</code> returns a list with two items.  The first item (<code>tol.limits</code>) is a data frame with the following items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr> 
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr> 
<tr><td><code>fn.est</code></td>
<td>
<p>A point estimate of the functional form of interest using the maximum likelihood estimates calculated with the inputted values of <code>x1</code>, <code>x2</code>, <code>n1</code>, and <code>n2</code>.</p>
</td></tr> 
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr>
</table>
<p>The second item (<code>fn</code>) simply returns the functional form specified by <code>FUN</code>. 				
</p>


<h3>References</h3>

<p>Clopper, C. J. and Pearson, E. S. (1934), The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial, <em>Biometrika</em>, <b>26</b>, 404&ndash;413.
</p>
<p>Krishnamoorthy, K. and Lee, M. (2010), Inference for Functions of Parameters in Discrete Distributions Based on Fiducial Approach: Binomial and Poisson Cases, <em>Journal of Statistical Planning and Inference</em>, <b>140</b>, 1182&ndash;1192.
</p>
<p>Mathew, T. and Young, D. S. (2013), Fiducial-Based Tolerance Intervals for Some Discrete Distributions, <em>Computational Statistics and Data Analysis</em>, <b>61</b>, 38&ndash;49.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fidnegbintol.int">fidnegbintol.int</a></code>, <code><a href="#topic+fidpoistol.int">fidpoistol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 95%/99% 1-sided and 2-sided tolerance intervals for 
## the difference between binomial proportions.

set.seed(100)

p1 &lt;- 0.2
p2 &lt;- 0.4
n1 &lt;- n2 &lt;- 200
x1 &lt;- rbinom(1, n1, p1)
x2 &lt;- rbinom(1, n2, p2)
fun.ti &lt;- function(x, y) x - y

fidbintol.int(x1, x2, n1, n2, m1 = 500, m2 = 500, FUN = fun.ti,
              alpha = 0.05, P = 0.99, side = 1)
fidbintol.int(x1, x2, n1, n2, m1 = 500, m2 = 500, FUN = fun.ti,
              alpha = 0.05, P = 0.99, side = 2)
              
</code></pre>

<hr>
<h2 id='fidnegbintol.int'>
Fiducial-Based Tolerance Intervals for the Function of Two Negative Binomial Proportions
</h2><span id='topic+fidnegbintol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for the function of two negative binomial proportions using fiducial quantities. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fidnegbintol.int(x1, x2, n1, n2, m1 = NULL, m2 = NULL, FUN, 
                 alpha = 0.05, P = 0.99, side = 1, K = 1000, 
                 B = 1000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fidnegbintol.int_+3A_x1">x1</code></td>
<td>
<p>A value of observed &quot;failures&quot; from group 1.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_x2">x2</code></td>
<td>
<p>A value of observed &quot;failures&quot; from group 2.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_n1">n1</code></td>
<td>
<p>The target number of successes for group 1.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_n2">n2</code></td>
<td>
<p>The target number of successes for group 2.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_m1">m1</code></td>
<td>
<p>The total number of future trials for group 1. If <code>NULL</code>, then it is set to <code>n1</code>.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_m2">m2</code></td>
<td>
<p>The total number of future trials for group 2. If <code>NULL</code>, then it is set to <code>n2</code>.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_fun">FUN</code></td>
<td>
<p>Any reasonable (and meaningful) function taking exactly two arguments that we are interested in constructing a tolerance interval on.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that 1-alpha is the confidence level.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_k">K</code></td>
<td>
<p>The number of fiducial quantities to be generated.  The number of iterations should be at least as large as the default value of 1000. See <code>Details</code> for the definition of the fiducial quantity for a negative binomial proportion.</p>
</td></tr>
<tr><td><code id="fidnegbintol.int_+3A_b">B</code></td>
<td>
<p>The number of iterations used for the Monte Carlo algorithm which determines the tolerance limits. The number of iterations should be at least as large as the default value of 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">X</code> is observed from a <code class="reqn">NegBin(n,p)</code> distribution, then the fiducial quantity for <code class="reqn">p</code> is <code class="reqn">Beta(n,X+0.5)</code>.
</p>


<h3>Value</h3>

<p><code>fidnegbintol.int</code> returns a list with two items.  The first item (<code>tol.limits</code>) is a data frame with the following items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr> 
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr> 
<tr><td><code>fn.est</code></td>
<td>
<p>A point estimate of the functional form of interest using the maximum likelihood estimates calculated with the inputted values of <code>x1</code>, <code>x2</code>, <code>n1</code>, and <code>n2</code>.</p>
</td></tr> 
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr>
</table>
<p>The second item (<code>fn</code>) simply returns the functional form specified by <code>FUN</code>. 				
</p>


<h3>References</h3>

<p>Cai, Y. and Krishnamoorthy, K. (2005), A Simple Improved Inferential Method for Some Discrete Distributions, <em>Computational Statistics and Data Analysis</em>, <b>48</b>, 605&ndash;621.
</p>
<p>Clopper, C. J. and Pearson, E. S. (1934), The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial, <em>Biometrika</em>, <b>26</b>, 404&ndash;413.
</p>
<p>Krishnamoorthy, K. and Lee, M. (2010), Inference for Functions of Parameters in Discrete Distributions Based on Fiducial Approach: Binomial and Poisson Cases, <em>Journal of Statistical Planning and Inference</em>, <b>140</b>, 1182&ndash;1192.
</p>
<p>Mathew, T. and Young, D. S. (2013), Fiducial-Based Tolerance Intervals for Some Discrete Distributions, <em>Computational Statistics and Data Analysis</em>, <b>61</b>, 38&ndash;49.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fidbintol.int">fidbintol.int</a></code>, <code><a href="#topic+fidpoistol.int">fidpoistol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 95%/99% 1-sided and 2-sided tolerance intervals for 
## the ratio of odds ratios for negative binomial proportions.

set.seed(100)

p1 &lt;- 0.6
p2 &lt;- 0.2
n1 &lt;- n2 &lt;- 50
x1 &lt;- rnbinom(1, n1, p1)
x2 &lt;- rnbinom(1, n2, p2)
fun.ti &lt;- function(x, y) x * (1 - y) / (y * (1 - x))

fidnegbintol.int(x1, x2, n1, n2, m1 = 50, m2 = 50, FUN = fun.ti, 
                 alpha = 0.05, P = 0.99, side = 1)
fidnegbintol.int(x1, x2, n1, n2, m1 = 50, m2 = 50, FUN = fun.ti, 
                 alpha = 0.05, P = 0.99, side = 2)
              
</code></pre>

<hr>
<h2 id='fidpoistol.int'>
Fiducial-Based Tolerance Intervals for the Function of Two Poisson Rates
</h2><span id='topic+fidpoistol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for the function of two Poisson rates using fiducial quantities. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fidpoistol.int(x1, x2, n1, n2, m1 = NULL, m2 = NULL, FUN, 
               alpha = 0.05, P = 0.99, side = 1, K = 1000, 
               B = 1000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fidpoistol.int_+3A_x1">x1</code></td>
<td>
<p>A value of observed counts from group 1.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_x2">x2</code></td>
<td>
<p>A value of observed counts from group 2.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_n1">n1</code></td>
<td>
<p>The length of time that <code>x1</code> was recorded over.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_n2">n2</code></td>
<td>
<p>The length of time that <code>x2</code> was recorded over.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_m1">m1</code></td>
<td>
<p>The total number of future trials for group 1. If <code>NULL</code>, then it is set to <code>n1</code>.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_m2">m2</code></td>
<td>
<p>The total number of future trials for group 2. If <code>NULL</code>, then it is set to <code>n2</code>.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_fun">FUN</code></td>
<td>
<p>Any reasonable (and meaningful) function taking exactly two arguments that we are interested in constructing a tolerance interval on.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that 1-alpha is the confidence level.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_k">K</code></td>
<td>
<p>The number of fiducial quantities to be generated.  The number of iterations should be at least as large as the default value of 1000. See <code>Details</code> for the definition of the fiducial quantity for a Poisson rate.</p>
</td></tr>
<tr><td><code id="fidpoistol.int_+3A_b">B</code></td>
<td>
<p>The number of iterations used for the Monte Carlo algorithm which determines the tolerance limits. The number of iterations should be at least as large as the default value of 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">X</code> is observed from a <code class="reqn">Poi(n*\lambda)</code> distribution, then the fiducial quantity for <code class="reqn">\lambda</code> is <code class="reqn">\chi^{2}_{2*x+1}/(2*n)</code>.
</p>


<h3>Value</h3>

<p><code>fidpoistol.int</code> returns a list with two items.  The first item (<code>tol.limits</code>) is a data frame with the following items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr> 
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr> 
<tr><td><code>fn.est</code></td>
<td>
<p>A point estimate of the functional form of interest using the maximum likelihood estimates calculated with the inputted values of <code>x1</code>, <code>x2</code>, <code>n1</code>, and <code>n2</code>.</p>
</td></tr> 
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr>
</table>
<p>The second item (<code>fn</code>) simply returns the functional form specified by <code>FUN</code>. 				
</p>


<h3>References</h3>

<p>Cox, D. R. (1953), Some Simple Approximate Tests for Poisson Variates, <em>Biometrika</em>, <b>40</b>, 354&ndash;360.
</p>
<p>Krishnamoorthy, K. and Lee, M. (2010), Inference for Functions of Parameters in Discrete Distributions Based on Fiducial Approach: Binomial and Poisson Cases, <em>Journal of Statistical Planning and Inference</em>, <b>140</b>, 1182&ndash;1192.
</p>
<p>Mathew, T. and Young, D. S. (2013), Fiducial-Based Tolerance Intervals for Some Discrete Distributions, <em>Computational Statistics and Data Analysis</em>, <b>61</b>, 38&ndash;49.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fidbintol.int">fidbintol.int</a></code>, <code><a href="#topic+fidnegbintol.int">fidnegbintol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 95%/99% 1-sided and 2-sided tolerance intervals for 
## the ratio of two Poisson rates.

set.seed(100)

lambda1 &lt;- 10
lambda2 &lt;- 2
n1 &lt;- 3000
n2 &lt;- 3250
x1 &lt;- rpois(1, n1 * lambda1)
x2 &lt;- rpois(1, n2 * lambda2)
fun.ti &lt;- function(x, y) x / y

fidpoistol.int(x1, x2, n1, n2, m1 = 2000, m2 = 2500, 
               FUN = fun.ti, alpha = 0.05, P = 0.99, side = 1)
fidpoistol.int(x1, x2, n1, n2, m1 = 2000, m2 = 2500, 
               FUN = fun.ti, alpha = 0.05, P = 0.99, side = 2)
              
</code></pre>

<hr>
<h2 id='gamtol.int'>Gamma (or Log-Gamma) Tolerance Intervals</h2><span id='topic+gamtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to either a gamma
distribution or log-gamma distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamtol.int(x, alpha = 0.05, P = 0.99, side = 1, 
           method = c("HE", "HE2", "WBE", "ELL", "KM", "EXACT", 
           "OCT"), m = 50, log.gamma = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamtol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to either a gamma distribution or a log-gamma distribution.</p>
</td></tr>
<tr><td><code id="gamtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="gamtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="gamtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="gamtol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="gamtol.int_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code> and <code>method = "OCT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
<tr><td><code id="gamtol.int_+3A_log.gamma">log.gamma</code></td>
<td>
<p>If <code>TRUE</code>, then the data is considered to be from a log-gamma distribution, in which
case the output gives tolerance intervals for the log-gamma distribution.  The default is <code>FALSE</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Recall that if the random variable <code class="reqn">X</code> is distributed according to a log-gamma distribution, then the random variable <code class="reqn">Y = ln(X)</code> is
distributed according to a gamma distribution.
</p>


<h3>Value</h3>

<p><code>gamtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Krishnamoorthy, K., Mathew, T., and Mukherjee, S. (2008), Normal-Based Methods for a Gamma Distribution:
Prediction and Tolerance Intervals and Stress-Strength Reliability, <em>Technometrics</em>, <b>50</b>, 69&ndash;78.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+GammaDist">GammaDist</a></code>, <code><a href="#topic+K.factor">K.factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 99%/99% 1-sided gamma tolerance intervals for a sample
## of size 50. 

set.seed(100)
x &lt;- rgamma(50, 0.30, scale = 2)
out &lt;- gamtol.int(x = x, alpha = 0.01, P = 0.99, side = 1,
                  method = "HE")
out

plottol(out, x, plot.type = "both", side = "upper", 
        x.lab = "Gamma Data")
</code></pre>

<hr>
<h2 id='hypertol.int'>Hypergeometric Tolerance Intervals</h2><span id='topic+hypertol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for hypergeometric random variables.  From a sampling without replacement
perspective, these limits use the proportion of units from group A (e.g., &quot;black balls&quot; in an urn) in a sample to bound the number
of potential units drawn from group A in a future sample taken from the universe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypertol.int(x, n, N, m = NULL, alpha = 0.05, P = 0.99, 
             side = 1, method = c("EX", "LS", "CC"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hypertol.int_+3A_x">x</code></td>
<td>
<p>The number of units from group A in the sample. Can be a vector, in which case the sum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_n">n</code></td>
<td>
<p>The size of the random sample of units selected.</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_n">N</code></td>
<td>
<p>The population size.</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_m">m</code></td>
<td>
<p>The quantity of units to be sampled from the universe for a future study. If <code>m = NULL</code>, then the tolerance limits will be constructed assuming <code>n</code> for this quantity.</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_p">P</code></td>
<td>
<p>The proportion of units from group A in future samples of size <code>m</code> 
to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="hypertol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the lower and upper confidence bounds, which are used in the calculation
of the tolerance bounds.  The default method is <code>"EX"</code>, which is an exact-based method.  <code>"LS"</code> is the large-sample method.  <code>"CC"</code> gives a continuity-corrected version of the large-sample method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>hypertol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of units from group A in future samples of size <code>m</code>.</p>
</td></tr>
<tr><td><code>rate</code></td>
<td>
<p>The sampling rate determined by <code>n/N</code>.</p>
</td></tr>
<tr><td><code>p.hat</code></td>
<td>
<p>The proportion of units in the sample from group A, calculated by <code>x/n</code>.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>As this methodology is built using large-sample theory, if the sampling rate is less than 0.05, then a warning is generated stating that the results are not reliable.  Also, compare the functionality of this procedure with the <code><a href="#topic+acc.samp">acc.samp</a></code> procedure, which is to determine a minimal acceptance limit for a particular sampling plan.
</p>


<h3>References</h3>

<p>Brown, L. D., Cai, T. T., and DasGupta, A. (2001), Interval Estimation for a Binomial Proportion, 
<em>Statistical Science</em>, <b>16</b>, 101&ndash;133.
</p>
<p>Eichenberger, P., Hulliger, B., and Potterat, J. (2011), Two Measures for Sample Size Determination,
<em>Survey Research Methods</em>, <b>5</b>, 27&ndash;37.
</p>
<p>Young, D. S. (2014), Tolerance Intervals for Hypergeometric and Negative Hypergeometric Variables,
<em>Sankhya: The Indian Journal of Statistics, Series B</em>, <b>77</b>(1), 114&ndash;140.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acc.samp">acc.samp</a></code>, <code><a href="stats.html#topic+Hypergeometric">Hypergeometric</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/95% 1-sided and 2-sided hypergeometric tolerance 
## intervals for a future sample of 30 when the universe
## is of size 100.

hypertol.int(x = 15, n = 50, N = 100, m = 30, alpha = 0.10, 
             P = 0.95, side = 1, method = "LS")
hypertol.int(x = 15, n = 50, N = 100, m = 30, alpha = 0.10, 
             P = 0.95, side = 1, method = "CC")
hypertol.int(x = 15, n = 50, N = 100, m = 30, alpha = 0.10, 
             P = 0.95, side = 2, method = "LS")
hypertol.int(x = 15, n = 50, N = 100, m = 30, alpha = 0.10, 
             P = 0.95, side = 2, method = "CC")
 </code></pre>

<hr>
<h2 id='K.factor'>Estimating K-factors for Tolerance Intervals Based on Normality</h2><span id='topic+K.factor'></span>

<h3>Description</h3>

<p>Estimates k-factors for tolerance intervals based on normality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>K.factor(n, f = NULL, alpha = 0.05, P = 0.99, side = 1, 
         method = c("HE", "HE2", "WBE", "ELL", "KM", "EXACT", 
         "OCT"), m = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="K.factor_+3A_n">n</code></td>
<td>
<p>The (effective) sample size.</p>
</td></tr>
<tr><td><code id="K.factor_+3A_f">f</code></td>
<td>
<p>The number of degrees of freedom associated with calculating the estimate of the population standard deviation.
If <code>NULL</code>, then <code>f</code> is taken to be <code>n-1</code>.</p>
</td></tr>
<tr><td><code id="K.factor_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="K.factor_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by the tolerance interval.</p>
</td></tr>
<tr><td><code id="K.factor_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="K.factor_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="K.factor_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code> and <code>method = "OCT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>K.factor</code> returns the k-factor for tolerance intervals based on normality with the arguments specified above.
</p>


<h3>Note</h3>

<p>For larger sample sizes, there may be some accuracy issues with the 1-sided calculation since it depends on the noncentral t-distribution.  
The code is primarily intended to be used for moderate values of the noncentrality parameter. It will not be highly accurate, especially in the tails, for large values.
See <code><a href="stats.html#topic+TDist">TDist</a></code> for further details.
</p>


<h3>References</h3>

<p>Ellison, B. E. (1964), On Two-Sided Tolerance Intervals for a Normal Distribution, <em>Annals of Mathematical
Statistics</em>, <b>35</b>, 762&ndash;772.
</p>
<p>Howe, W. G. (1969), Two-Sided Tolerance Limits for Normal Populations - Some Improvements, <em>Journal of the
American Statistical Association</em>, <b>64</b>, 610&ndash;620.
</p>
<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>
<p>Odeh, R. E. and Owen, D. B. (1980), <em>Tables for Normal Tolerance Limits, Sampling Plans, and Screening</em>, Marcel-Dekker.
</p>
<p>Owen, D. B. (1964), Controls of Percentages in Both Tails of the Normal Distribution, <em>Technometrics</em>, <b>6</b>, 377-387.
</p>
<p>Wald, A. and Wolfowitz, J. (1946), Tolerance Limits for a Normal Distribution, <em>Annals of the Mathematical Statistics</em>,
<b>17</b>, 208&ndash;215.  
</p>
<p>Weissberg, A. and Beatty, G. (1969), Tables of Tolerance Limit Factors for Normal Distributions, <em>Technometrics</em>,
<b>2</b>, 483&ndash;500.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+K.table">K.table</a></code>, <code><a href="#topic+normtol.int">normtol.int</a></code>, <code><a href="stats.html#topic+TDist">TDist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Showing the effect of the Howe, Weissberg-Beatty, 
## and exact estimation methods as the sample size increases.

K.factor(10, P = 0.95, side = 2, method = "HE")
K.factor(10, P = 0.95, side = 2, method = "WBE")
K.factor(10, P = 0.95, side = 2, method = "EXACT", m = 50)

K.factor(100, P = 0.95, side = 2, method = "HE")
K.factor(100, P = 0.95, side = 2, method = "WBE")
K.factor(100, P = 0.95, side = 2, method = "EXACT", m = 50)

</code></pre>

<hr>
<h2 id='K.factor.sim'>Estimating K-factors for Simultaneous Tolerance Intervals Based on Normality</h2><span id='topic+K.factor.sim'></span>

<h3>Description</h3>

<p>Estimates k-factors for simultaneous tolerance intervals based on normality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>K.factor.sim(n, l = NULL, alpha = 0.05, P = 0.99, side = 1, 
         method = c("EXACT", "BONF"), m = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="K.factor.sim_+3A_n">n</code></td>
<td>
<p>If <code>method = "EXACT"</code>, this is the sample size of each of the <code>l</code> groups. If <code>method = "BONF"</code>, then <code>n</code> can be a vector of different sample sizes for the <code>l</code> groups.</p>
</td></tr>
<tr><td><code id="K.factor.sim_+3A_l">l</code></td>
<td>
<p>The number of normal populations for which the k-factors will be constructed simultaneously.
If <code>NULL</code>, then it is taken to be the length of <code>n</code>.</p>
</td></tr>
<tr><td><code id="K.factor.sim_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="K.factor.sim_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by the tolerance interval.</p>
</td></tr>
<tr><td><code id="K.factor.sim_+3A_side">side</code></td>
<td>
<p>Whether a k-factor for a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="K.factor.sim_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  <code>"EXACT"</code> is an exact method that can be used when all <code>l</code> groups have the same sample size. <code>"BONF"</code> is an approximate method using the Bonferroni inequality, which can be used when the <code>l</code> groups have different sample sizes.</p>
</td></tr>
<tr><td><code id="K.factor.sim_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>K.factor</code> returns the k-factor for simultaneous tolerance intervals based on normality with the arguments specified above.
</p>


<h3>Note</h3>

<p>For larger combinations of <code>n</code> and <code>l</code> when <code>side = 2</code> and <code>method = "EXACT"</code>, the calculation can be slow. For larger sample sizes when <code>side = "BONF"</code>, there may be some accuracy issues with the 1-sided calculation since it depends on the noncentral t-distribution.  
The code is primarily intended to be used for moderate values of the noncentrality parameter. It will not be highly accurate, especially in the tails, for large values.
See <code><a href="stats.html#topic+TDist">TDist</a></code> for further details.
</p>
<p>Thanks to Andrew Landgraf for providing the basic code for the <code>method = "EXACT"</code> procedure.
</p>


<h3>References</h3>

<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>
<p>Mee, R. W. (1990), Simultaneous Tolerance Intervals for Normal Populations with Common Variance, <em>Technometrics</em>, <b>32</b>, 83-92.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+K.factor">K.factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Reproducing part of Table B5 from Krishnamoorthy and 
## Mathew (2009).

n_sizes &lt;- c(2:20, seq(30, 100, 10))
l_sizes &lt;- 2:10
KM_table &lt;- sapply(1:length(l_sizes), function(i)
                   sapply(1:length(n_sizes), function(j)
                   round(K.factor.sim(n = n_sizes[j], 
                   l = l_sizes[i], side=1, alpha = 0.1, 
                   P = 0.9),3)))
dimnames(KM_table) &lt;- list(n = n_sizes, l = l_sizes)
KM_table

</code></pre>

<hr>
<h2 id='K.table'>Tables of K-factors for Tolerance Intervals Based on Normality</h2><span id='topic+K.table'></span>

<h3>Description</h3>

<p>Tabulated summary of k-factors for tolerance intervals based on normality.  The user can specify multiple values
for each of the three inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>K.table(n, alpha, P, side = 1, f = NULL, method = c("HE", 
        "HE2", "WBE", "ELL", "KM", "EXACT", "OCT"), m = 50,
        by.arg = c("n", "alpha", "P")) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="K.table_+3A_n">n</code></td>
<td>
<p>A vector of (effective) sample sizes.</p>
</td></tr>
<tr><td><code id="K.table_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.  Can be a vector.</p>
</td></tr>
<tr><td><code id="K.table_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.  Can be a vector.</p>
</td></tr>
<tr><td><code id="K.table_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="K.table_+3A_f">f</code></td>
<td>
<p>The number of degrees of freedom associated with calculating the estimate of the population standard deviation.
If <code>NULL</code>, then <code>f</code> is taken to be <code>n-1</code>.  Only a single value can be specified for <code>f</code>.</p>
</td></tr>
<tr><td><code id="K.table_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="K.table_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code> and <code>method = "OCT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
<tr><td><code id="K.table_+3A_by.arg">by.arg</code></td>
<td>
<p>How you would like the output organized.  If <code>by.arg = "n"</code>, then the output provides a list of matrices
sorted by the values specified in <code>n</code>.  The matrices have rows corresponding to the values specified by <code>1-alpha</code> and columns
corresponding to the values specified by <code>P</code>.  If <code>by.arg = "alpha"</code>, then the output provides a list of matrices
sorted by the values specified in <code>1-alpha</code>.  The matrices have rows corresponding to the values specified by <code>n</code> and columns
corresponding to the values specified by <code>P</code>.  If <code>by.arg = "P"</code>, then the output provides a list of matrices
sorted by the values specified in <code>P</code>.  The matrices have rows corresponding to the values specified by <code>1-alpha</code> and columns
corresponding to the values specified by <code>n</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method used for estimating the k-factors is that due to Howe as it is generally viewed as more accurate than the Weissberg-Beatty method.
</p>


<h3>Value</h3>

<p><code>K.table</code> returns a list with a structure determined by the argument <code>by.arg</code> described above.
</p>


<h3>References</h3>

<p>Howe, W. G. (1969), Two-Sided Tolerance Limits for Normal Populations - Some Improvements, <em>Journal of the
American Statistical Association</em>, <b>64</b>, 610&ndash;620.
</p>
<p>Weissberg, A. and Beatty, G. (1969), Tables of Tolerance Limit Factors for Normal Distributions, <em>Technometrics</em>,
<b>2</b>, 483&ndash;500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+K.factor">K.factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Tables generated for each value of the sample size.

K.table(n = seq(50, 100, 10), alpha = c(0.01, 0.05, 0.10), 
        P = c(0.90, 0.95, 0.99), by.arg = "n")

## Tables generated for each value of the confidence level.

K.table(n = seq(50, 100, 10), alpha = c(0.01, 0.05, 0.10), 
        P = c(0.90, 0.95, 0.99), by.arg = "alpha")

## Tables generated for each value of the coverage proportion.

K.table(n = seq(50, 100, 10), alpha = c(0.01, 0.05, 0.10), 
        P = c(0.90, 0.95, 0.99), by.arg = "P")
        
</code></pre>

<hr>
<h2 id='laptol.int'>Laplace Tolerance Intervals</h2><span id='topic+laptol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to a Laplace distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laptol.int(x, alpha = 0.05, P = 0.99, side = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laptol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to a Laplace distribution.</p>
</td></tr>
<tr><td><code id="laptol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="laptol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="laptol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>laptol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bain, L. J. and Engelhardt, M. (1973), Interval Estimation for the Two Parameter Double Exponential Distribution, 
<em>Technometrics</em>, <b>15</b>, 875&ndash;887.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## First generate data from a Laplace distribution with location
## parameter 70 and scale parameter 3.

set.seed(100)
tmp &lt;- runif(40)
x &lt;- rep(70, 40) - sign(tmp - 0.5)*rep(3, 40)*
              log(2*ifelse(tmp &lt; 0.5, tmp, 1-tmp))

## 95%/90% 1-sided Laplace tolerance intervals for the sample
## of size 40 generated above. 

out &lt;- laptol.int(x = x, alpha = 0.05, P = 0.90, side = 1) 
out

plottol(out, x, plot.type = "hist", side = "two", 
        x.lab = "Laplace Data")
</code></pre>

<hr>
<h2 id='logistol.int'>Logistic (or Log-Logistic) Tolerance Intervals</h2><span id='topic+logistol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to a logistic or log-logistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistol.int(x, alpha = 0.05, P = 0.99, log.log = FALSE,
             side = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to a logistic or log-logistic distribution.</p>
</td></tr>
<tr><td><code id="logistol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="logistol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="logistol.int_+3A_log.log">log.log</code></td>
<td>
<p>If <code>TRUE</code>, then the data is considered to be from a log-logistic distribution, in which
case the output gives tolerance intervals for the log-logistic distribution.  The default is <code>FALSE</code>.</p>
</td></tr> 
<tr><td><code id="logistol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recall that if the random variable <code class="reqn">X</code> is distributed according to a log-logistic distribution, then the random variable <code class="reqn">Y = ln(X)</code> is
distributed according to a logistic distribution.
</p>


<h3>Value</h3>

<p><code>logistol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Balakrishnan, N. (1992), <em>Handbook of the Logistic Distribution</em>, Marcel Dekker, Inc.
</p>
<p>Hall, I. J. (1975), One-Sided Tolerance Limits for a Logistic Distribution Based on Censored Samples, <em>Biometrics</em>,
<b>31</b>, 873&ndash;880.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Logistic">Logistic</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/95% 1-sided logistic tolerance intervals for a sample
## of size 20. 

set.seed(100)
x &lt;- rlogis(20, 5, 1)
out &lt;- logistol.int(x = x, alpha = 0.10, P = 0.95, 
                    log.log = FALSE, side = 1) 
out

plottol(out, x, plot.type = "control", side = "two", 
        x.lab = "Logistic Data")
</code></pre>

<hr>
<h2 id='mvregtol.region'>Multivariate (Multiple) Linear Regression Tolerance Regions</h2><span id='topic+mvregtol.region'></span>

<h3>Description</h3>

<p>Determines the appropriate tolerance factor for computing multivariate (multiple) linear regression tolerance regions based on Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvregtol.region(mvreg, new.x = NULL, alpha = 0.05, P = 0.99, 
                B = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvregtol.region_+3A_mvreg">mvreg</code></td>
<td>
<p>A multivariate (multiple) linear regression fit, having class <code>mlm</code>.</p>
</td></tr>
<tr><td><code id="mvregtol.region_+3A_new.x">new.x</code></td>
<td>
<p>An optional data frame of new values for which to approximate k-factors. This must be a data frame with named columns that match those in the data frame used for the <code>mvreg</code> fitted object.</p>
</td></tr>
<tr><td><code id="mvregtol.region_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="mvregtol.region_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance region.</p>
</td></tr>
<tr><td><code id="mvregtol.region_+3A_b">B</code></td>
<td>
<p>The number of iterations used for the Monte Carlo algorithm which determines the tolerance factor.  The number of
iterations should be at least as large as the default value of 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A basic sketch of how the algorithm works is as follows:
</p>
<p>(1) Generate independent chi-square random variables and Wishart random matrices.
</p>
<p>(2) Compute the eigenvalues of the randomly generated Wishart matrices.
</p>
<p>(3) Iterate the above steps to generate a set of <code>B</code> sample values such that the <code>100(1-alpha)</code>-th percentile is an approximate tolerance factor.
</p>


<h3>Value</h3>

<p><code>mvregtol.region</code> returns a matrix where the first column is the k-factor, the next <code>q</code> columns are the estimated responses
from the least squares fit, and the final <code>m</code> columns are the predictor values.  The first <code>n</code> rows of the matrix pertain to the raw data
as specified by <code>y</code> and <code>x</code>.  If values for <code>new.x</code> are specified, then there is one additional row appended to this output for each
row in the matrix <code>new.x</code>.
</p>


<h3>Note</h3>

<p>As of tolerance version 2.0.0, the arguments to this function have changed.  This function no longer depends on inputted <code>y</code> and <code>x</code> matrices or an <code>int</code> argument.  Instead, the function requires <code>mvreg</code>, which is of class &quot;mlm&quot;, and provides all of the necessary components for the way the output is formatted.  Also, <code>new.x</code> must now be a data frame with columns matching those from the data frame used in the <code>mvreg</code> fitted object.  
</p>


<h3>References</h3>

<p>Anderson, T. W. (2003) <em>An Introduction to Multivariate Statistical Analysis</em>, Third Edition, Wiley.
</p>
<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>
<p>Krishnamoorthy, K. and Mondal, S. (2008), Tolerance Factors in Multiple and Multivariate Linear Regressions, 
<em>Communications in Statistics - Simulation and Computation</em>, <b>37</b>, 546&ndash;559.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/95% multivariate regression tolerance factors using
## a fertilizer data set presented in Anderson (2003, p. 374). 

grain &lt;- c(40, 17, 9, 15, 6, 12, 5, 9)
straw &lt;- c(53, 19, 10, 29, 13, 27, 19, 30)
fert &lt;- c(24, 11, 5, 12, 7, 14, 11, 18)
DF &lt;- data.frame(grain,straw,fert)
new.x &lt;- data.frame(fert = c(10, 15, 20))
mvreg &lt;- lm(cbind(grain, straw) ~ fert + I(fert^2), data = DF)

set.seed(100)
out &lt;- mvregtol.region(mvreg, new.x = new.x, alpha = 0.05,
                       P = 0.95, B = 5000)
out
</code></pre>

<hr>
<h2 id='mvtol.region'>Multivariate Normal Tolerance Regions</h2><span id='topic+mvtol.region'></span>

<h3>Description</h3>

<p>Determines the appropriate tolerance factor for computing multivariate normal tolerance regions based on Monte Carlo methods or other approximations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvtol.region(x, alpha = 0.05, P = 0.99, B = 1000, M = 1000,
             method = c("KM", "AM", "GM", "HM", "MHM", "V11", 
             "HM.V11", "MC")) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvtol.region_+3A_x">x</code></td>
<td>
<p>An <code>n</code>x<code>p</code> matrix of data assumed to be drawn from a <code>p</code>-dimensional multivariate normal
distribution.  <code>n</code> pertains to the sample size.</p>
</td></tr>
<tr><td><code id="mvtol.region_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.  A vector of <code>alpha</code> values
may be specified.</p>
</td></tr>
<tr><td><code id="mvtol.region_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance region.  A vector of <code>P</code> values may be
specified.</p>
</td></tr>
<tr><td><code id="mvtol.region_+3A_b">B</code></td>
<td>
<p>The number of iterations used for the Monte Carlo algorithms (i.e., when <code>method = "KM"</code> or <code>"MC"</code>), which determines the tolerance factor.  The number of
iterations should be at least as large as the default value of 1000.</p>
</td></tr>
<tr><td><code id="mvtol.region_+3A_m">M</code></td>
<td>
<p>The number of iterations used for the inner loop of the Monte Carlo algorithm specified through <code>method = "MC"</code>.  The number of
iterations should be at least as large as the default value of 1000.  Note that this is not required for <code>method = "KM"</code> since that algorithm handles the eigenvalues
differently in the estimation of the tolerance factor.</p>
</td></tr>
<tr><td><code id="mvtol.region_+3A_method">method</code></td>
<td>
<p>The method for estimating the tolerance factors. <code>"KM"</code> is the Krishnamoorthy-Mondal method, which is the method implemented in previous versions of the <code>tolerance</code>
package.  It is one of the more accurate methods available.  <code>"AM"</code> is an approximation method based on the arithmetic mean.  <code>"GM"</code> is an approximation method based on the geometric
mean.  <code>"HM"</code> is an approximation method based on the harmonic mean.  <code>"MHM"</code> is a modified approach based on the harmonic mean.  <code>"V11"</code> is a method that utilizes a certain
partitioning of a Wishart random matrix for deriving an approximate tolerance factor.  <code>"HM.V11"</code> is a hybrid method of the <code>"HM"</code> and <code>"V11"</code> methods.  <code>"MC"</code> is a simple Monte
Carlo approach to estimating the tolerance factor, which is computationally expensive as the values of <code>B</code> and <code>M</code> increase.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All of the methods are outlined in the references that we provided.  In practice, we recommend using the Krishnamoorthy-Mondal approach.  A basic sketch of how the Krishnamoorthy-Mondal algorithm works is as follows:
</p>
<p>(1) Generate independent chi-square random variables and Wishart random matrices.
</p>
<p>(2) Compute the eigenvalues of the randomly generated Wishart matrices.
</p>
<p>(3) Iterate the above steps to generate a set of <code>B</code> sample values such that the <code>100(1-alpha)</code>-th percentile is an approximate tolerance factor.
</p>


<h3>Value</h3>

<p><code>mvtol.region</code> returns a matrix where the rows pertain to each confidence level <code>1-alpha</code> specified and the columns
pertain to each proportion level <code>P</code> specified.
</p>


<h3>References</h3>

<p>Krishnamoorthy, K. and Mathew, T. (1999), Comparison of Approximation Methods for Computing Tolerance Factors for a Multivariate Normal Population, 
<em>Technometrics</em>, <b>41</b>, 234&ndash;249.
</p>
<p>Krishnamoorthy, K. and Mondal, S. (2006), Improved Tolerance Factors for Multivariate Normal Distributions, 
<em>Communications in Statistics - Simulation and Computation</em>, <b>35</b>, 461&ndash;478.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/90% bivariate normal tolerance region. 

set.seed(100)
x1 &lt;- rnorm(100, 0, 0.2)
x2 &lt;- rnorm(100, 0, 0.5)
x &lt;- cbind(x1, x2)

out1 &lt;- mvtol.region(x = x, alpha = 0.10, P = 0.90, B = 1000,
                     method = "KM")
out1
plottol(out1, x)

## 90%/90% trivariate normal tolerance region. 

set.seed(100)
x1 &lt;- rnorm(100, 0, 0.2)
x2 &lt;- rnorm(100, 0, 0.5)
x3 &lt;- rnorm(100, 5, 1)
x &lt;- cbind(x1, x2, x3)
mvtol.region(x = x, alpha = c(0.10, 0.05, 0.01), 
             P = c(0.90, 0.95, 0.99), B = 1000, method = "KM") 

out2 &lt;- mvtol.region(x = x, alpha = 0.10, P = 0.90, B = 1000, 
                     method = "KM")
out2
plottol(out2, x)
</code></pre>

<hr>
<h2 id='negbintol.int'>Negative Binomial Tolerance Intervals</h2><span id='topic+negbintol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for negative binomial random variables. From a statistical quality control perspective, these limits use the number of failures that occur to reach <code>n</code> successes to bound the number of failures for a specified amount of future successes (<code>m</code>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negbintol.int(x, n, m = NULL, alpha = 0.05, P = 0.99, 
              side = 1, method = c("LS", "WU", "CB", 
              "CS", "SC", "LR", "SP", "CC"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negbintol.int_+3A_x">x</code></td>
<td>
<p>The total number of failures that occur from a sample of size <code>n</code>.  Can be a vector of length <code>n</code>, in which case the sum of <code>x</code> is computed.</p>
</td></tr>
<tr><td><code id="negbintol.int_+3A_n">n</code></td>
<td>
<p>The target number of successes (sometimes called size) for each trial.</p>
</td></tr>
<tr><td><code id="negbintol.int_+3A_m">m</code></td>
<td>
<p>The target number of successes in a future lot for which the tolerance limits will be calculated. If <code>m = NULL</code>, then the tolerance limits will be constructed assuming <code>n</code> for the target number of future successes.</p>
</td></tr>
<tr><td><code id="negbintol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="negbintol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the defective (or acceptable) units in future samples of size <code>m</code> 
to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="negbintol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="negbintol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the lower and upper confidence bounds, which are used in the calculation
of the tolerance bounds.  The default method is <code>"LS"</code>, which is the large-sample method based on the MLE.  <code>"WU"</code> is a Wald-type interval based on the UMVUE of the negative binomial proportion. <code>"CB"</code> is the Casella-Berger exact method.  <code>"CS"</code> is a method based on chi-square percentiles.  <code>"SC"</code> is the score method.  <code>"LR"</code> is a likelihood ratio-based method.  <code>"SP"</code> is a method using a saddlepoint approximation for the confidence intervals.  <code>"CC"</code> gives a continuity-corrected version of the large-sample method and is appropriate when <code>n</code> is large.  More information on these methods can be found in the &quot;References&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes the approach for Poisson and binomial random variables developed in Hahn and Chandra (1981) and applies it to the negative binomial case.
</p>


<h3>Value</h3>

<p><code>negbintol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of defective (or acceptable) units in future samples of size <code>m</code>.</p>
</td></tr>
<tr><td><code>pi.hat</code></td>
<td>
<p>The probability of success in each trial, calculated by <code>n/(n+x)</code>.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Recall that the geometric distribution is the negative binomial distribution where the size is 1. Therefore, the case when <code>n = m = 1</code> will provide tolerance limits for a geometric distribution.
</p>


<h3>References</h3>

<p>Casella, G. and Berger, R. L. (1990), <em>Statistical Inference</em>, Duxbury Press.
</p>
<p>Hahn, G. J. and Chandra, R. (1981), Tolerance Intervals for Poisson and Binomial Variables,
<em>Journal of Quality Technology</em>, <b>13</b>, 100&ndash;110.
</p>
<p>Tian, M., Tang, M. L., Ng, H. K. T., and Chan, P. S. (2009), A Comparative Study of Confidence Intervals for Negative Binomial Proportions,
<em>Journal of Statistical Computation and Simulation</em>, <b>79</b>, 241&ndash;249.
</p>
<p>Young, D. S. (2014), A Procedure for Approximate Negative Binomial Tolerance Intervals, <em>Journal of Statistical Computation and Simulation</em>, <b>84</b>, 438&ndash;450.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code>, <code><a href="#topic+umatol.int">umatol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Comparison of 95%/99% 1-sided tolerance limits with
## 50 failures before 10 successes are reached.

negbintol.int(x = 50, n = 10, side = 1, method = "LS")
negbintol.int(x = 50, n = 10, side = 1, method = "WU")
negbintol.int(x = 50, n = 10, side = 1, method = "CB")
negbintol.int(x = 50, n = 10, side = 1, method = "CS")
negbintol.int(x = 50, n = 10, side = 1, method = "SC")
negbintol.int(x = 50, n = 10, side = 1, method = "LR")
negbintol.int(x = 50, n = 10, side = 1, method = "SP")
negbintol.int(x = 50, n = 10, side = 1, method = "CC")

## 95%/99% 1-sided tolerance limits and 2-sided tolerance 
## interval for the same setting above, but when we are 
## interested in a future experiment that requires 20 successes 
## be reached for each trial.

negbintol.int(x = 50, n = 10, m = 20, side = 1)
negbintol.int(x = 50, n = 10, m = 20, side = 2)
</code></pre>

<hr>
<h2 id='NegHypergeometric'>The Negative Hypergeometric Distribution</h2><span id='topic+NegHypergeometric'></span><span id='topic+dnhyper'></span><span id='topic+pnhyper'></span><span id='topic+qnhyper'></span><span id='topic+rnhyper'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation for the negative hypergeometric distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnhyper(x, m, n, k, log = FALSE)
pnhyper(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
qnhyper(p, m, n, k, lower.tail = TRUE, log.p = FALSE)
rnhyper(nn, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NegHypergeometric_+3A_x">x</code>, <code id="NegHypergeometric_+3A_q">q</code></td>
<td>
<p>Vector of quantiles representing the number of trials until <code>k</code> successes have occurred (e.g., until <code>k</code> white balls have been drawn from an urn without replacement).</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_m">m</code></td>
<td>
<p>The number of successes in the population (e.g., the number of white balls in the urn).</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_n">n</code></td>
<td>
<p>The population size (e.g., the total number of balls in the urn).</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_k">k</code></td>
<td>
<p>The number of successes (e.g., white balls) to achieve with the sample.</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_p">p</code></td>
<td>
<p>Vector of probabilities, which must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_nn">nn</code></td>
<td>
<p>The number of observations.  If <code>length&gt;1</code>, then the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_log">log</code>, <code id="NegHypergeometric_+3A_log.p">log.p</code></td>
<td>
<p>Logical vectors.  If <code>TRUE</code>, then probabilities are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="NegHypergeometric_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical vector.  If <code>TRUE</code>, then probabilities are <code class="reqn">P[X\le x]</code>, else <code class="reqn">P[X&gt;x]</code>.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>A negative hypergeometric distribution (sometimes called the inverse hypergeometric distribution) models the total number of trials until <code>k</code> successes occur.  Compare this to the negative binomial distribution, which models the number of failures that occur until a specified number of successes has been reached.  The negative hypergeometric distribution has density
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \frac{{x-1 \choose k-1}{n-x \choose m-k}}{{n \choose m}}</code>
</p>

<p>for <code class="reqn">x=k,k+1,...,n-m+k</code>.
</p>


<h3>Value</h3>

<p><code>dnhyper</code> gives the density, <code>pnhyper</code> gives the distribution function, <code>qnhyper</code> gives the quantile
function, and <code>rnhyper</code> generates random deviates.
</p>
<p>Invalid arguments will return value <code>NaN</code>, with a warning.
</p>


<h3>References</h3>

<p>Wilks, S. S. (1963), <em>Mathematical Statistics</em>, Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> about random number generation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data from the negative hypergeometric 
## distribution.

set.seed(100)
x &lt;- rnhyper(nn = 1000, m = 15, n = 40, k = 10)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 = sort(x)
y &lt;- dnhyper(x = x.1, m = 15, n = 40, k = 10)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, pnhyper(q = x.1, m = 15, n = 40, k = 10),             
     type = "l", xlab = "x", ylab = "Cumulative Probabilities")

qnhyper(p = 0.20, m = 15, n = 40, k = 10, lower.tail = FALSE)
qnhyper(p = 0.80, m = 15, n = 40, k = 10)
</code></pre>

<hr>
<h2 id='neghypertol.int'>Negative Hypergeometric Tolerance Intervals</h2><span id='topic+neghypertol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for negative hypergeometric random variables.  When sampling without replacement, these limits are on the total number of expected draws in a future sample in order to achieve a certain number from group A (e.g., &quot;black balls&quot; in an urn).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neghypertol.int(x, n, N, m = NULL, alpha = 0.05, P = 0.99,
                side = 1, method = c("EX", "LS", "CC"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neghypertol.int_+3A_x">x</code></td>
<td>
<p>The number of units drawn in order to achieve <code>n</code> successes. Can be a vector, in which case the sum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_n">n</code></td>
<td>
<p>The target number of successes in the sample drawn (e.g., the number of &quot;black balls&quot; you are to draw in the sample).</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_n">N</code></td>
<td>
<p>The population size (e.g., the total number of balls in the urn).</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_m">m</code></td>
<td>
<p>The target number of successes to be sampled from the universe for a future study. If <code>m = NULL</code>, then the tolerance limits will be constructed assuming <code>n</code> for this quantity.</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_p">P</code></td>
<td>
<p>The proportion of units from group A in future samples of size <code>m</code> 
to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="neghypertol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the lower and upper confidence bounds, which are used in the calculation
of the tolerance bounds.  The default method is <code>"EX"</code>, which is an exact-based method.  <code>"LS"</code> is the large-sample method.  <code>"CC"</code> gives a continuity-corrected version of the large-sample method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>neghypertol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of units from group A in future samples of size <code>m</code>.</p>
</td></tr>
<tr><td><code>rate</code></td>
<td>
<p>The sampling rate determined by <code>x/N</code>.</p>
</td></tr>
<tr><td><code>p.hat</code></td>
<td>
<p>The proportion of units in the sample from group A, calculated by <code>n/x</code>.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>As this methodology is built using large-sample theory, if the sampling rate is less than 0.05, then a warning is generated stating that the results are not reliable.
</p>


<h3>References</h3>

<p>Khan, R. A. (1994), A Note on the Generating Function of a Negative Hypergeometric Distribution,
<em>Sankhya: The Indian Journal of Statistics, Series B</em>, <b>56</b>, 309&ndash;313.
</p>
<p>Young, D. S. (2014), Tolerance Intervals for Hypergeometric and Negative Hypergeometric Variables,
<em>Sankhya: The Indian Journal of Statistics, Series B</em>, <b>77</b>(1), 114&ndash;140.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acc.samp">acc.samp</a></code>, <code><a href="#topic+NegHypergeometric">NegHypergeometric</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 90%/95% 2-sided negative hypergeometric tolerance
## intervals for a future number of 20 successes when
## the universe is of size 100.  The estimates are 
## based on having drawn 50 in another sample to achieve 
## 20 successes.

neghypertol.int(50, 20, 100, m = 20, alpha = 0.05, 
                P = 0.95, side = 2, method = "LS")
</code></pre>

<hr>
<h2 id='nlregtol.int'>Nonlinear Regression Tolerance Bounds</h2><span id='topic+nlregtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided nonlinear regression tolerance bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlregtol.int(formula, xy.data = data.frame(), x.new = NULL,
             side = 1, alpha = 0.05, P = 0.99, maxiter = 50, 
             ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlregtol.int_+3A_formula">formula</code></td>
<td>
<p>A nonlinear model formula including variables and parameters.</p>
</td></tr>
<tr><td><code id="nlregtol.int_+3A_xy.data">xy.data</code></td>
<td>
<p>A data frame in which to evaluate the formulas in <code>formula</code>.  The first column
of <code>xy.data</code> must be the response variable.</p>
</td></tr>
<tr><td><code id="nlregtol.int_+3A_x.new">x.new</code></td>
<td>
<p>Any new levels of the predictor(s) for which to report the tolerance bounds.  The number of columns must be
1 less than the number of columns for <code>xy.data</code>.</p>
</td></tr>
<tr><td><code id="nlregtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance bound is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr> 
<tr><td><code id="nlregtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="nlregtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by the tolerance bound(s).</p>
</td></tr>
<tr><td><code id="nlregtol.int_+3A_maxiter">maxiter</code></td>
<td>
<p>A positive integer specifying the maximum number of iterations that the nonlinear least squares routine (<code>nls</code>)
should run.</p>
</td></tr>
<tr><td><code id="nlregtol.int_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to <code>nls</code> when estimating the nonlinear regression equation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is highly recommended that the user specify starting values for the <code>nls</code> routine.
</p>


<h3>Value</h3>

<p><code>nlregtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by the tolerance bound(s).</p>
</td></tr>
<tr><td><code>y.hat</code></td>
<td>
<p>The predicted value of the response for the fitted nonlinear regression model.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The value of the response given in the first column of <code>xy.data</code>.  This data frame is sorted by
this value.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr></table>


<h3>References</h3>

<p>Wallis, W. A. (1951), Tolerance Intervals for Linear Regression, in <em>Second Berkeley Symposium on Mathematical
Statistics and Probability</em>, ed. J. Neyman, Berkeley: University of CA Press, 43&ndash;51.
</p>
<p>Young, D. S. (2013), Regression Tolerance Intervals, <em>Communications in Statistics - Simulation and Computation</em>, <b>42</b>, 2040&ndash;2055.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nls">nls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/95% 2-sided nonlinear regression tolerance bounds
## for a sample of size 50. 

set.seed(100)
x &lt;- runif(50, 5, 45)
f1 &lt;- function(x, b1, b2) b1 + (0.49 - b1)*exp(-b2*(x - 8)) +
               rnorm(50, sd = 0.01) 
y &lt;- f1(x, 0.39, 0.11)
formula &lt;- as.formula(y ~ b1 + (0.49 - b1)*exp(-b2*(x - 8)))
out &lt;- nlregtol.int(formula = formula, 
                    xy.data = data.frame(cbind(y, x)), 
                    x.new=cbind(c(10, 20)), side = 2, 
                    alpha = 0.05, P = 0.95)
out

plottol(out, x = x, y = y, side = "two", x.lab = "X", 
         y.lab = "Y")
</code></pre>

<hr>
<h2 id='norm.OC'>Operating Characteristic (OC) Curves for K-Factors for Tolerance Intervals Based on Normality</h2><span id='topic+norm.OC'></span>

<h3>Description</h3>

<p>Provides OC-type curves to illustrate how values of the k-factors for normal tolerance intervals, confidence levels, and content levels change as a function of the sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.OC(k = NULL, alpha = NULL, P = NULL, n, side = 1,
        method = c("HE", "HE2", "WBE", "ELL", "KM", "EXACT", 
        "OCT"), m = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm.OC_+3A_k">k</code></td>
<td>
<p>If wanting OC curves where the confidence level or content level is on the y-axis, then a single positive value of <code>k</code> must be specified.  This would be the target k-factor for the desired tolerance interval.  If <code>k = NULL</code>, then OC curves will be constructed where the k-factor value is found for given levels of <code>alpha</code>, <code>P</code>, and <code>n</code>.</p>
</td></tr>
<tr><td><code id="norm.OC_+3A_alpha">alpha</code></td>
<td>
<p>The set of levels chosen such that <code>1-alpha</code> are confidence levels.  If wanting OC curves where the content level is being calculated, then each curve will correspond to a level in the set of <code>alpha</code>.  If a set of <code>P</code> values is specified, then OC curves will be constructed where the k-factor is found and each curve will correspond to each combination of <code>alpha</code> and <code>P</code>.  If <code>alpha = NULL</code>, then OC curves will be constructed to find the confidence level for given levels of <code>k</code>, <code>P</code>, and <code>n</code>.</p>
</td></tr>
<tr><td><code id="norm.OC_+3A_p">P</code></td>
<td>
<p>The set of content levels to be considered.  If wanting OC curves where the confidence level is being calculated, then each curve will correspond to a level in the set of <code>P</code>.  If a set of <code>alpha</code> values is specified, then OC curves will be constructed where the k-factor is found and each curve will correspond to each combination of <code>alpha</code> and <code>P</code>.  If <code>P = NULL</code>, then OC curves will be constructed to find the content level for given levels of <code>k</code>, <code>alpha</code>, and <code>n</code>.</p>
</td></tr>
<tr><td><code id="norm.OC_+3A_n">n</code></td>
<td>
<p>A sequence of sample sizes to consider.  This must be a vector of at least length 2 since all OC curves are constructed as functions of <code>n</code>.</p>
</td></tr>
<tr><td><code id="norm.OC_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="norm.OC_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="norm.OC_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function, which is used for the underlying exact method for calculating the normal tolerance intervals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>norm.OC</code> returns a figure with the OC curves constructed using the specifications in the arguments.
</p>


<h3>References</h3>

<p>Young, D. S. (2016), Normal Tolerance Interval Procedures in the tolerance Package, <em>The R Journal</em>, <b>8</b>, 200&ndash;212.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+K.factor">K.factor</a></code>, <code><a href="#topic+normtol.int">normtol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## The three types of OC-curves that can be constructed
## with the norm.OC function.
 
norm.OC(k = 4, alpha = NULL, P = c(0.90, 0.95, 0.99), 
        n = 10:20, side = 1)

norm.OC(k = 4, alpha = c(0.01, 0.05, 0.10), P = NULL, 
        n = 10:20, side = 1)

norm.OC(k = NULL, P = c(0.90, 0.95, 0.99), 
        alpha=c(0.01,0.05,0.10), n = 10:20, side = 1) 
</code></pre>

<hr>
<h2 id='norm.ss'>Sample Size Determination for Normal Tolerance Intervals</h2><span id='topic+norm.ss'></span>

<h3>Description</h3>

<p>Provides minimum sample sizes for a future sample size when constructing normal tolerance intervals.  Various strategies are available for determining the sample size, including strategies that incorporate known specification limits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.ss(x = NULL, alpha = 0.05, P = 0.99, delta = NULL,
        P.prime = NULL, side = 1, m = 50, spec = c(NA, NA),
        hyper.par = list(mu.0 = NULL, sig2.0 = NULL, 
        m.0 = NULL, n.0 = NULL), method = c("DIR", 
        "FW", "YGZO"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm.ss_+3A_x">x</code></td>
<td>
<p>A vector of current data that is distributed according to a normal distribution.  This is only required for <code>method = "YGZO"</code>.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_delta">delta</code></td>
<td>
<p>The precision measure for the future tolerance interval as specified under the Faulkenberry-Weeks method.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_p.prime">P.prime</code></td>
<td>
<p>The proportion of the population (greater than <code>P</code>) such that the tolerance interval of interest will only exceed <code>P.prime</code> by the probability given by <code>delta</code>.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function, which is used for the underlying exact method for calculating the normal tolerance intervals.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_spec">spec</code></td>
<td>
<p>A vector of length 2 given known specification limits.  These are required when <code>method = "DIR"</code> or <code>method = "YGZO"</code>.  By default, the values are <code>NA</code>.  The two elements of the vector are for the lower and upper specification limits, respectively.  If <code>side = 1</code>, then only one of the specification limits must be specified.  If <code>side = 2</code>, then both specification limits must be specified.</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_hyper.par">hyper.par</code></td>
<td>
<p>Necessary parameter values for the different methods.  If <code>method = "DIR"</code> or <code>method = "YGZO"</code>, then <code>mu.0</code> and <code>sig2.0</code> must be specified, which correspond to the assumed population mean and variance of the underlying normal distribution, which further pertains to the historical data for <code>method = "YGZO"</code>.  If <code>method = "YGZO"</code> and the sample size is to be determined using Bayesian normal tolerance intervals, then this is a required list consisting of the hyperparameters for the conjugate prior &ndash; the hyperparameters for the mean (<code>mu.0 and n.0</code>) and the hyperparameters for the variance (<code>sig2.0</code> and <code>m.0</code>).</p>
</td></tr>
<tr><td><code id="norm.ss_+3A_method">method</code></td>
<td>
<p>The method for performing the sample size determination.   <code>"DIR"</code> is the direct method (intended as a simple calculation for planning purposes) where the mean and standard deviation are taken as truth and the sample size is determined with respect to the given specification limits.  <code>"FW"</code> is for the traditional Faulkenberry-Weeks approach for sample size determination. <code>"YGZO"</code> is for the Young-Gordon-Zhu-Olin approach, which incorporates historical data and specification limits for determining the value of <code>delta</code> and/or <code>P.prime</code> in the Faulkenberry-Weeks approach.  Note that for <code>"YGZO"</code>, at least one of <code>delta</code> and <code>P.prime</code> must be <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>norm.ss</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>The user-specified or calculated precision measure.  Not returned if <code>method = "DIR"</code>.</p>
</td></tr>
<tr><td><code>P.prime</code></td>
<td>
<p>The user-specified or calculated closeness measure.  Not returned if <code>method = "DIR"</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The minimum sample size determined using the conditions specified for this function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Faulkenberry, G. D. and Weeks, D. L. (1968), Sample Size Determination for Tolerance Limits, <em>Technometrics</em>, <b>10</b>, 343&ndash;348.
</p>
<p>Young, D. S., Gordon, C. M., Zhu, S., and Olin, B. D. (2016), Sample Size Determination Strategies for Normal Tolerance Intervals Using Historical Data, <em>Quality Engineering</em>, <b>28</b>, 337&ndash;351.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bayesnormtol.int">bayesnormtol.int</a></code>, <code><a href="stats.html#topic+Normal">Normal</a></code>, <code><a href="#topic+normtol.int">normtol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Sample size determination for 95%/95% 2-sided normal 
## tolerance intervals using the direct method.
 
set.seed(100)
norm.ss(alpha = 0.05, P = 0.95, side = 2, spec = c(-3, 3), 
        method = "DIR", hyper.par = list(mu.0 = 0, 
        sig2.0 = 1))

</code></pre>

<hr>
<h2 id='normtol.int'>Normal (or Log-Normal) Tolerance Intervals</h2><span id='topic+normtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to either a normal
distribution or log-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normtol.int(x, alpha = 0.05, P = 0.99, side = 1,
            method = c("HE", "HE2", "WBE", "ELL", "KM", 
            "EXACT", "OCT"), m = 50, log.norm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normtol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to either a normal distribution or a log-normal distribution.</p>
</td></tr>
<tr><td><code id="normtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="normtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="normtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="normtol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  The k-factor for the 1-sided tolerance intervals
is performed exactly and thus is the same for the chosen method.  <code>"HE"</code> is the
Howe method and is often viewed as being extremely accurate, even for small sample sizes. <code>"HE2"</code> is a second method due to Howe, which performs similarly to the Weissberg-Beatty method, but is computationally simpler.  <code>"WBE"</code> is the 
Weissberg-Beatty method (also called the Wald-Wolfowitz method), which performs similarly to the first Howe method for larger sample sizes. <code>"ELL"</code> is
the Ellison correction to the Weissberg-Beatty method when <code>f</code> is appreciably larger than <code>n^2</code>. A warning
message is displayed if <code>f</code> is not larger than <code>n^2</code>. <code>"KM"</code> is the Krishnamoorthy-Mathew approximation to the exact solution, which works well for larger sample sizes. <code>"EXACT"</code> computes the 
k-factor exactly by finding the integral solution to the problem via the <code>integrate</code> function.  Note the computation time of this method is largely determined by <code>m</code>. <code>"OCT"</code> is the Owen approach 
to compute the k-factor when controlling the tails so that there is not more than (1-P)/2  of the data in each tail of the distribution.</p>
</td></tr>
<tr><td><code id="normtol.int_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code> and <code>method = "OCT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
<tr><td><code id="normtol.int_+3A_log.norm">log.norm</code></td>
<td>
<p>If <code>TRUE</code>, then the data is considered to be from a log-normal distribution, in which
case the output gives tolerance intervals for the log-normal distribution.  The default is <code>FALSE</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Recall that if the random variable <code class="reqn">X</code> is distributed according to a log-normal distribution, then the random variable <code class="reqn">Y = ln(X)</code> is
distributed according to a normal distribution.
</p>


<h3>Value</h3>

<p><code>normtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>x.bar</code></td>
<td>
<p>The sample mean.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Howe, W. G. (1969), Two-Sided Tolerance Limits for Normal Populations - Some Improvements, <em>Journal of the
American Statistical Association</em>, <b>64</b>, 610&ndash;620.
</p>
<p>Wald, A. and Wolfowitz, J. (1946), Tolerance Limits for a Normal Distribution, <em>Annals of Mathematical Statistics</em>,
<b>17</b>, 208&ndash;215.
</p>
<p>Weissberg, A. and Beatty, G. (1969), Tables of Tolerance Limit Factors for Normal Distributions, <em>Technometrics</em>,
<b>2</b>, 483&ndash;500.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">Normal</a></code>, <code><a href="#topic+K.factor">K.factor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/95% 2-sided normal tolerance intervals for a sample
## of size 100. 

set.seed(100)
x &lt;- rnorm(100, 0, 0.2)
out &lt;- normtol.int(x = x, alpha = 0.05, P = 0.95, side = 2,
                   method = "HE", log.norm = FALSE)
out

plottol(out, x, plot.type = "both", side = "two", 
        x.lab = "Normal Data")
</code></pre>

<hr>
<h2 id='np.order'>Sample Size Determination for Tolerance Limits Based on Order Statistics</h2><span id='topic+np.order'></span>

<h3>Description</h3>

<p>For given values of <code>m</code>, <code>alpha</code>, and <code>P</code>, this function solves the necessary sample size such that the
<code>r</code>-th (or (<code>n-s+1</code>)-th) order statistic is the <code>[100(1-alpha)%, 100(P)%]</code> lower (or upper) tolerance
limit (see the Details section below for further explanation).  This function can also report all combinations of order
statistics for 2-sided intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>np.order(m, alpha = 0.05, P = 0.99, indices = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="np.order_+3A_m">m</code></td>
<td>
<p>See the Details section below for how <code>m</code> is defined.</p>
</td></tr>
<tr><td><code id="np.order_+3A_alpha">alpha</code></td>
<td>
<p>1 minus the confidence level attained when it is desired to cover a proportion <code>P</code>
of the population with the order statistics.</p>
</td></tr>
<tr><td><code id="np.order_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered with confidence <code>1-alpha</code> with the order statistics.</p>
</td></tr>
<tr><td><code id="np.order_+3A_indices">indices</code></td>
<td>
<p>An optional argument to report all combinations of order statistics indices for the upper and lower limits
of the 2-sided intervals.  Note that this can only be calculated when <code>m&gt;1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the 1-sided tolerance limits, <code>m=s+r</code> such that the probability is at least <code>1-alpha</code> that at least the 
proportion <code>P</code> of the population is below the (<code>n-s+1</code>)-th order statistic for the upper limit or above the <code>r</code>-th order statistic
for the lower limit.  This means for the 1-sided upper limit that <code>r=1</code>, while for the 1-sided lower limit it means that <code>s=1</code>. 
For the 2-sided tolerance intervals, <code>m=s+r</code> such that the probability is at least <code>1-alpha</code> that at least the 
proportion <code>P</code> of the population is between the <code>r</code>-th and (<code>n-s+1</code>)-th order statistics. Thus, all combinations of r&gt;0 and
s&gt;0 such that <code>m=s+r</code> are considered.
</p>


<h3>Value</h3>

<p>If <code>indices = FALSE</code>, then a single number is returned for the necessary sample size such that the
<code>r</code>-th (or (<code>n-s+1</code>)-th) order statistic is the <code>[100(1-alpha)%, 100(P)%]</code> lower (or upper) tolerance
limit.  If <code>indices = TRUE</code>, then a list is returned with a single number for the necessary sample size and a matrix
with 2 columns where each row gives the pairs of indices for the order statistics for all permissible <code>[100(1-alpha)%, 100(P)%]</code>
2-sided tolerance intervals. 
</p>


<h3>References</h3>

<p>Hanson, D. L. and Owen, D. B. (1963), Distribution-Free Tolerance Limits Elimination of the Requirement That
Cumulative Distribution Functions Be Continuous, <em>Technometrics</em>, <b>5</b>, 518&ndash;522. 
</p>
<p>Scheffe, H. and Tukey, J. W. (1945), Non-Parametric Estimation I. Validation of Order Statistics, 
<em>Annals of Mathematical Statistics</em>, <b>16</b>, 187&ndash;192. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nptol.int">nptol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Only requesting the sample size.

np.order(m = 5, alpha = 0.05, P = 0.95)

## Requesting the order statistics indices as well.

np.order(m = 5, alpha = 0.05, P = 0.95, indices = TRUE)

</code></pre>

<hr>
<h2 id='npbetol.int'>Nonparametric Beta-Expectation Tolerance Intervals</h2><span id='topic+npbetol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided nonparametric (i.e., distribution-free) beta-expectation tolerance intervals for any continuous
data set.  These are equivalent to nonparametric prediction intervals based on order statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npbetol.int(x, Beta = 0.95, side = 1, upper = NULL, lower = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npbetol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which no distributional assumptions are made.  The data is only assumed to come from a continuous
distribution.</p>
</td></tr>
<tr><td><code id="npbetol.int_+3A_beta">Beta</code></td>
<td>
<p>The confidence level.</p>
</td></tr>
<tr><td><code id="npbetol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="npbetol.int_+3A_upper">upper</code></td>
<td>
<p>The upper bound of the data.  When <code>NULL</code>, then the maximum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="npbetol.int_+3A_lower">lower</code></td>
<td>
<p>The lower bound of the data.  When <code>NULL</code>, then the minimum of <code>x</code> is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>nptol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>Beta</code></td>
<td>
<p>The specified confidence level.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Beran, R. and Hall, P (1993), Interpolated Nonparametric Prediction Intervals and Confidence Intervals, <em>Journal of the Royal Statistical Society, Series B</em>, <b>55</b>, 643&ndash;652.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+distfree.est">distfree.est</a></code>, <code><a href="#topic+npregtol.int">npregtol.int</a></code>, <code><a href="#topic+nptol.int">nptol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Nonparametric 90%-expectation tolerance intervals 
## for a sample of size 100. 

set.seed(100)
x &lt;- rexp(100, 5)
out &lt;- npbetol.int(x = x, Beta = 0.90, side = 2,
                   upper = NULL, lower = NULL)
out
</code></pre>

<hr>
<h2 id='npmvtol.region'>Nonparametric Multivariate Hyperrectangular Tolerance Regions</h2><span id='topic+npmvtol.region'></span>

<h3>Description</h3>

<p>Provides depth-based multivariate central or semi-space nonparametric tolerance regions.  These can be calculated for any continuous multivariate data set.  Either (P, 1-alpha) tolerance regions or beta-expectation tolerance regions can be specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npmvtol.region(x, alpha = NULL, P = NULL, Beta = NULL, depth.fn, 
               adjust = c("no", "floor", "ceiling"), 
               type = c("central", "semispace"), 
               semi.order = list(lower = NULL, center = NULL, upper = NULL), 
               L = -Inf, U = Inf, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npmvtol.region_+3A_x">x</code></td>
<td>
<p>An <code>n</code>x<code>p</code> matrix of data assumed to be drawn from a <code>p</code>-dimensional multivariate distribution.  <code>n</code> pertains to the sample size.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level. Note that if a (P, 1-alpha) tolerance region is required, then both <code>alpha</code> and <code>P</code> must be specified, but <code>Beta</code> must be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.  Note that if a (P, 1-alpha) tolerance region is required, then both <code>alpha</code> and <code>P</code> must be specified, but <code>Beta</code> must be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_beta">Beta</code></td>
<td>
<p>The confidence level for a beta-expectation tolerance region. Note that if a beta-expectation tolerance region is required, then <code>Beta</code> must be specified, but both <code>alpha</code> and <code>P</code> must be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_depth.fn">depth.fn</code></td>
<td>
<p>The data depth function used to perform the ordering of the multivariate data.  Thus function must be coded in such a way that the first argument is multivariate data for which to calculate the depth values and the second argument is the original multivariate sample, <code>x</code>.  For the purpose of this tolerance region calculation, these two arguments should both be the original multivariate sample.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_adjust">adjust</code></td>
<td>
<p>Whether an adjustment should be made during an intermediate calculation for determining the number of points that need to be included in the multivariate region.  If <code>adjust = "no"</code>, the default, then no adjustment is made during the intermediate calculation.  If <code>adjust = "floor"</code>, then the intermediate calculation is rounded down to the next nearest integer.  If <code>adjust = "ceiling"</code>, then the intermediate calculation is rounded up to the next nearest integer.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_type">type</code></td>
<td>
<p>The type of multivariate hyperrectangular region to calculate.  If <code>type = "central"</code>, then two-sided intervals are reported for each dimension of the data <code>x</code>.  If <code>type = "semispace"</code>, then a combination of one-sided intervals and two-sided intervals are reported for the dimensions of <code>x</code>.  Which interval is calculated for each dimension in this latter setting is dictated by the <code>semi.order</code> argument.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_semi.order">semi.order</code></td>
<td>
<p>If <code>type = "semispace"</code>, then this argument must be specified.  This argument is a list of length 3, such that each element gives the indices of the dimensions of <code>x</code> for which the type of interval should be calculated.  Indices specified for the element of <code>lower</code> will return one-sided lower limits for those dimensions, indices specified for the element of <code>center</code> will return two-sided intervals for those dimensions, and indices specified for the element of <code>upper</code> will return one-sided upper limits for those dimensions.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_l">L</code></td>
<td>
<p>If <code>type = "semispace"</code>, these are the lower limits for any dimensions for which one requests one-sided upper limits.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_u">U</code></td>
<td>
<p>If <code>type = "semispace"</code>, these are the upper limits for any dimensions for which one requests one-sided lower limits.</p>
</td></tr>
<tr><td><code id="npmvtol.region_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>depth.fn</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>npmvtol.region</code> returns a <code>p</code>x<code>2</code> matrix where the columns give the lower and upper limits, respectively, of the multivariate hyperrectangular tolerance region.
</p>


<h3>References</h3>

<p>Young, D. S. and Mathew, T. (2020+), Nonparametric Hyperrectangular Tolerance
and Prediction Regions for Setting Multivariate Reference Regions in Laboratory
Medicine, <em>Submitted</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+distfree.est">distfree.est</a></code>, <code><a href="#topic+mvtol.region">mvtol.region</a></code>, <code><a href="#topic+npregtol.int">npregtol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/95% semi-space tolerance region for a sample
## of size 20 generated from a multivariate normal
## distribution. The mdepth function below is not 
## a true depth function, but used only for
## illustrative purposes.

mdepth &lt;- function(pts, x){
          mahalanobis(pts, center = rep(0, 3),
                      cov = diag(1, 3))
          }

set.seed(100)
x &lt;- cbind(rnorm(100), rnorm(100), rnorm(100))
out &lt;-npmvtol.region(x = x, alpha = 0.10, P = 0.95, depth.fn = mdepth,
                     type = "semispace", semi.order = list(lower = 2, 
                     center = 3, upper = 1))
out
</code></pre>

<hr>
<h2 id='npregtol.int'>Nonparametric Regression Tolerance Bounds</h2><span id='topic+npregtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided nonparametric regression tolerance bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npregtol.int(x, y, y.hat, side = 1, alpha = 0.05, P = 0.99,
             method = c("WILKS", "WALD", "HM"), upper = NULL, 
             lower = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npregtol.int_+3A_x">x</code></td>
<td>
<p>A vector of values for the predictor variable.  Currently, this function is only capable of handling
a single predictor.</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_y">y</code></td>
<td>
<p>A vector of values for the response variable.</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_y.hat">y.hat</code></td>
<td>
<p>A vector of fitted values extracted from a nonparametric smoothing routine.</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance bound is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr> 
<tr><td><code id="npregtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by the tolerance bound(s).</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_method">method</code></td>
<td>
<p>The method for determining which indices of the ordered residuals will be used for the tolerance bounds.  
<code>"WILKS"</code>, <code>"WALD"</code>, and <code>"HM"</code> are each described in <code><a href="#topic+nptol.int">nptol.int</a></code>.  However, since only one tolerance
bound can actually be reported for this procedure, only the first tolerance bound will be returned.  Note that this is not
an issue when <code>method = "WILKS"</code> is used as it only produces one set of tolerance bounds.</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_upper">upper</code></td>
<td>
<p>The upper bound of the data.  When <code>NULL</code>, then the maximum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="npregtol.int_+3A_lower">lower</code></td>
<td>
<p>The lower bound of the data.  When <code>NULL</code>, then the minimum of <code>x</code> is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>npregtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by the tolerance bound(s).</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The values of the predictor variable.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The values of the response variable.</p>
</td></tr>
<tr><td><code>y.hat</code></td>
<td>
<p>The predicted value of the response for the fitted nonparametric smoothing routine.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr></table>


<h3>References</h3>

<p>Young, D. S. (2013), Regression Tolerance Intervals, <em>Communications in Statistics - Simulation and Computation</em>, <b>42</b>, 2040&ndash;2055.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+loess">loess</a></code>, <code><a href="#topic+nptol.int">nptol.int</a></code>, <code><a href="stats.html#topic+spline">spline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/95% 2-sided nonparametric regression tolerance bounds
## for a sample of size 50. 

set.seed(100)
x &lt;- runif(50, 5, 45)
f1 &lt;- function(x, b1, b2) b1 + (0.49 - b1)*exp(-b2*(x - 8)) +
               rnorm(50, sd = 0.01) 
y &lt;- f1(x, 0.39, 0.11)
y.hat &lt;- loess(y~x)$fit
out &lt;- npregtol.int(x = x, y = y, y.hat = y.hat, side = 2, 
                    alpha = 0.05, P = 0.95, method = "WILKS")
out

plottol(out, x = x, y = y, y.hat = y.hat, side = "two", 
        x.lab = "X", y.lab = "Y")
</code></pre>

<hr>
<h2 id='nptol.int'>Nonparametric Tolerance Intervals</h2><span id='topic+nptol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided nonparametric (i.e., distribution-free) tolerance intervals for any continuous
data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nptol.int(x, alpha = 0.05, P = 0.99, side = 1,
          method = c("WILKS", "WALD", "HM", "YM"), 
          upper = NULL, lower = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nptol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which no distributional assumptions are made.  The data is only assumed to come from a continuous
distribution.</p>
</td></tr>
<tr><td><code id="nptol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="nptol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="nptol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="nptol.int_+3A_method">method</code></td>
<td>
<p>The method for determining which indices of the ordered observations will be used for the tolerance intervals.  
<code>"WILKS"</code> is the Wilks method, which produces tolerance bounds symmetric about the observed center of the data by using
the beta distribution.  <code>"WALD"</code> is the Wald method, which produces (possibly) multiple tolerance bounds for <code>side = 2</code> (each
having at least the specified confidence level), but is the same as <code>method = "WILKS"</code> for <code>side = 1</code>.  <code>"HM"</code> is
the Hahn-Meeker method, which is based on the binomial distribution, but the upper and lower bounds may exceed the minimum and maximum
of the sample data.  For <code>side = 2</code>, this method will yield two intervals if an odd number of observations are to be trimmed from each side.  <code>"YM"</code> is the Young-Mathew method for performing interpolation or extrapolation based on the order statistics.  See below for more information on this method.</p>
</td></tr>
<tr><td><code id="nptol.int_+3A_upper">upper</code></td>
<td>
<p>The upper bound of the data.  When <code>NULL</code>, then the maximum of <code>x</code> is used. If <code>method = "YM"</code> and extrapolation is performed, then <code>upper</code> will be greater than the maximum.</p>
</td></tr>
<tr><td><code id="nptol.int_+3A_lower">lower</code></td>
<td>
<p>The lower bound of the data.  When <code>NULL</code>, then the minimum of <code>x</code> is used. If <code>method = "YM"</code> and extrapolation is performed, then <code>lower</code> will be less than the minimum.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the Young-Mathew method, interpolation or extrapolation is performed.  When <code>side = 1</code>, two intervals are given: one based on linear interpolation/extrapolation of order statistics (<code>OS-Based</code>) and one based on fractional order statistics (<code>FOS-Based</code>).  When <code>side = 2</code>, only an interval based on linear interpolation/extrapolation of order statistics is given.
</p>


<h3>Value</h3>

<p><code>nptol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bury, K. (1999), <em>Statistical Distributions in Engineering</em>, Cambridge University Press.
</p>
<p>Hahn, G. J. and Meeker, W. Q. (1991), <em>Statistical Intervals: A Guide for Practitioners</em>, Wiley-Interscience.
</p>
<p>Wald, A. (1943), An Extension of Wilks' Method for Setting Tolerance Limits, <em>The Annals of Mathematical Statistics</em>,
<b>14</b>, 45&ndash;55.
</p>
<p>Wilks, S. S. (1941), Determination of Sample Sizes for Setting Tolerance Limits, <em>The Annals of Mathematical Statistics</em>,
<b>12</b>, 91&ndash;96.
</p>
<p>Young, D. S. and Mathew, T. (2014), Improved Nonparametric Tolerance Intervals Based on Interpolated and Extrapolated Order Statistics,
<em>Journal of Nonparametric Statistics</em>, <b>26</b>, 415&ndash;432.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+distfree.est">distfree.est</a></code>, <code><a href="#topic+npregtol.int">npregtol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/95% 2-sided nonparametric tolerance intervals for a 
## sample of size 20. 

set.seed(100)
x &lt;- rlogis(20, 5, 1)
out &lt;- nptol.int(x = x, alpha = 0.10, P = 0.95, side = 1,
                 method = "WILKS", upper = NULL, lower = NULL)
out

plottol(out, x, plot.type = "both", side = "two", x.lab = "X")
</code></pre>

<hr>
<h2 id='paretotol.int'>Pareto (or Power Distribution) Tolerance Intervals</h2><span id='topic+paretotol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to either a Pareto distribution or 
a power distribution (i.e., the inverse Pareto distribution).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paretotol.int(x, alpha = 0.05, P = 0.99, side = 1,
              method = c("GPU", "DUN"), power.dist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paretotol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to either a Pareto distribution or a power distribution.</p>
</td></tr>
<tr><td><code id="paretotol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="paretotol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="paretotol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="paretotol.int_+3A_method">method</code></td>
<td>
<p>The method for how the upper tolerance bound is approximated when transforming to utilize the relationship with the 2-parameter
exponential distribution.  <code>"GPU"</code> is the Guenther-Patil-Upppuluri method. <code>"DUN"</code> is the Dunsmore method, which was empirically shown to be an improvement
for samples greater than or equal to 8.  More information on these methods can be found in the &quot;References&quot;.</p>
</td></tr>
<tr><td><code id="paretotol.int_+3A_power.dist">power.dist</code></td>
<td>
<p>If <code>TRUE</code>, then the data is considered to be from a power distribution, in which
case the output gives tolerance intervals for the power distribution.  The default is <code>FALSE</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p> Recall that if the random variable <code class="reqn">X</code> is distributed 
according to a Pareto distribution, then the random variable <code class="reqn">Y 
= ln(X)</code> is distributed according to a 2-parameter exponential 
distribution. Moreover, if the random variable <code class="reqn">W</code> is 
distributed according to a power distribution, then the random 
variable <code class="reqn">X = 1/W</code> is distributed according to a Pareto 
distribution, which in turn means that the random variable <code class="reqn">Y = 
ln(1/W)</code> is distributed according to a 2-parameter exponential 
distribution.</p>


<h3>Value</h3>

<p><code>paretotol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dunsmore, I. R. (1978), Some Approximations for Tolerance Factors for the Two Parameter Exponential Distribution,
<em>Technometrics</em>, <b>20</b>, 317&ndash;318.
</p>
<p>Engelhardt, M. and Bain, L. J. (1978), Tolerance Limits and Confidence Limits on Reliability for the Two-Parameter
Exponential Distribution, <em>Technometrics</em>, <b>20</b>, 37&ndash;39.
</p>
<p>Guenther, W. C., Patil, S. A., and Uppuluri, V. R. R. (1976), One-Sided <code class="reqn">\beta</code>-Content Tolerance Factors
for the Two Parameter Exponential Distribution, <em>Technometrics</em>, <b>18</b>, 333&ndash;340.  
</p>
<p>Krishnamoorthy, K., Mathew, T., and Mukherjee, S. (2008), Normal-Based Methods for a Gamma Distribution:
Prediction and Tolerance Intervals and Stress-Strength Reliability, <em>Technometrics</em>, <b>50</b>, 69&ndash;78.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TwoParExponential">TwoParExponential</a></code>, <code><a href="#topic+exp2tol.int">exp2tol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/99% 2-sided Pareto tolerance intervals 
## for a sample of size 500. 

set.seed(100)
x &lt;- exp(r2exp(500, rate = 0.15, shift = 2))
out &lt;- paretotol.int(x = x, alpha = 0.05, P = 0.99, side = 2,
                     method = "DUN", power.dist = FALSE)
out

plottol(out, x, plot.type = "both", side = "two", 
        x.lab = "Pareto Data")
</code></pre>

<hr>
<h2 id='plottol'>Plotting Capabilities for Tolerance Intervals</h2><span id='topic+plottol'></span>

<h3>Description</h3>

<p>Provides control charts and/or histograms for tolerance bounds on continuous data as well as tolerance ellipses
for data distributed according to bivariate and trivariate normal distributions.  Scatterplots with regression tolerance bounds
and interval plots for ANOVA tolerance intervals may also be produced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plottol(tol.out, x, y = NULL, y.hat = NULL, 
        side = c("two", "upper", "lower"), 
        plot.type = c("control", "hist", "both"), 
        x.lab = NULL, y.lab = NULL, z.lab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plottol_+3A_tol.out">tol.out</code></td>
<td>
<p>Output from any continuous (including ANOVA) tolerance interval procedure or from a regression tolerance bound procedure.</p>
</td></tr>
<tr><td><code id="plottol_+3A_x">x</code></td>
<td>
<p>Either data from a continuous distribution or the predictors for a regression model.  If this is a design matrix
for a linear regression model, then it must be in matrix form AND include a column of 1's if there is to be an intercept.  Note
that multiple predictors are only allowed if considering polynomial regression.  If the output for <code>tol.out</code> concerns
ANOVA tolerance intervals, then <code>x</code> must be a data frame.</p>
</td></tr>
<tr><td><code id="plottol_+3A_y">y</code></td>
<td>
<p>The response vector for a regression setting.  Leave as <code>NULL</code> if not doing regression tolerance bounds.</p>
</td></tr>
<tr><td><code id="plottol_+3A_y.hat">y.hat</code></td>
<td>
<p>The fitted values from a nonparametric smoothing routine if plotting nonparametric regression tolerance bounds.  Otherwise,
leave as <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plottol_+3A_side">side</code></td>
<td>
<p><code>side = "two"</code> produces plots for either the two-sided tolerance intervals or both one-sided tolerance intervals.
This will be determined by the output in <code>tol.out</code>.  <code>side = "upper"</code> produces plots showing the upper tolerance
bounds.  <code>side = "lower"</code> produces plots showing the lower tolerance bounds.</p>
</td></tr>
<tr><td><code id="plottol_+3A_plot.type">plot.type</code></td>
<td>
<p><code>plot.type = "control"</code> produces a control chart of the data along with the tolerance bounds specified
by <code>side</code>.  <code>plot.type = "hist"</code> produces a histogram of the data along with the tolerance bounds specified by
<code>side</code>.  <code>plot.type = "both"</code> produces both the control chart and histogram.  This argument is ignored
when plotting regression data.</p>
</td></tr>
<tr><td><code id="plottol_+3A_x.lab">x.lab</code></td>
<td>
<p>Specify the label for the x-axis.</p>
</td></tr>
<tr><td><code id="plottol_+3A_y.lab">y.lab</code></td>
<td>
<p>Specify the label for the y-axis.</p>
</td></tr>
<tr><td><code id="plottol_+3A_z.lab">z.lab</code></td>
<td>
<p>Specify the label for the z-axis.</p>
</td></tr>
<tr><td><code id="plottol_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the plotting function used for the control charts or regression scatterplots.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plottol</code> can return a control chart, histogram, or both for continuous data along with the calculated tolerance intervals.
For regression data, <code>plottol</code> returns a scatterplot along with the regression tolerance bounds.  For ANOVA output, <code>plottol</code>
returns an interval plot for each factor.
</p>


<h3>References</h3>

<p>Montgomery, D. C. (2005), <em>Introduction to Statistical Quality Control</em>, Fifth Edition, John Wiley &amp; Sons, Inc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/90% 1-sided Weibull tolerance intervals for a sample
## of size 150. 

set.seed(100)
x &lt;- rweibull(150, 3, 75)
out &lt;- exttol.int(x = x, alpha = 0.15, P = 0.90, 
                  dist = "Weibull")
out

plottol(out, x, plot.type = "both", side = "lower", 
        x.lab = "Weibull Data")

## 90%/90% trivariate normal tolerance region. 

set.seed(100)
x1 &lt;- rnorm(100, 0, 0.2)
x2 &lt;- rnorm(100, 0, 0.5)
x3 &lt;- rnorm(100, 5, 1)
x &lt;- cbind(x1, x2, x3)
mvtol.region(x = x, alpha = c(0.10, 0.05, 0.01), 
             P = c(0.90, 0.95, 0.99), B = 1000) 

out2 &lt;- mvtol.region(x = x, alpha = 0.10, P = 0.90, B = 1000) 
out2
plottol(out2, x)

## 95%/95% 2-sided linear regression tolerance bounds
## for a sample of size 100. 

set.seed(100)
x &lt;- runif(100, 0, 10)
y &lt;- 20 + 5*x + rnorm(100, 0, 3)
out3 &lt;- regtol.int(reg = lm(y ~ x), new.x = data.frame(x = c(3, 6, 9)), 
                   side = 2, alpha = 0.05, P = 0.95)
plottol(out3, x = cbind(1, x), y = y, side = "two", x.lab = "X", 
        y.lab = "Y")

</code></pre>

<hr>
<h2 id='poislind.ll'>
Maximum Likelihood Estimation for the Discrete Poisson-Lindley Distribution
</h2><span id='topic+poislind.ll'></span>

<h3>Description</h3>

<p>Performs maximum likelihood estimation for the parameter of the Poisson-Lindley distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poislind.ll(x, theta = NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poislind.ll_+3A_x">x</code></td>
<td>
<p>A vector of raw data which is distributed according to a Poisson-Lindley distribution.</p>
</td></tr>
<tr><td><code id="poislind.ll_+3A_theta">theta</code></td>
<td>
<p>Optional starting value for the parameter.  If <code>NULL</code>, then the method of moments estimator is used.</p>
</td></tr>
<tr><td><code id="poislind.ll_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>mle</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete Poisson-Lindley distribution is a compound distribution that, potentially, provides a better fit for count data relative to the traditional Poisson and negative binomial distributions.
</p>


<h3>Value</h3>

<p>See the help file for <code>mle</code> to see how the output is structured.				
</p>


<h3>References</h3>

<p>Ghitany, M. E. and Al-Mutairi, D. K. (2009), Estimation Methods for the Discrete Poisson-Lindley Distribution, 
<em>Journal of Statistical Computation and Simulation</em>, <b>79</b>, 1&ndash;9.
</p>
<p>Sankaran, M. (1970), The Discrete Poisson-Lindley Distribution, <em>Biometrics</em>, <b>26</b>, 145&ndash;149. 
</p>


<h3>See Also</h3>

<p><code><a href="stats4.html#topic+mle">mle</a></code>, <code><a href="#topic+PoissonLindley">PoissonLindley</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Maximum likelihood estimation for randomly generated data
## from the Poisson-Lindley distribution. 

set.seed(100)

pl.data &lt;- rpoislind(n = 500, theta = 0.5)
out.pl &lt;- poislind.ll(pl.data)
stats4::coef(out.pl)
stats4::vcov(out.pl)
</code></pre>

<hr>
<h2 id='poislindtol.int'>
Poisson-Lindley Tolerance Intervals
</h2><span id='topic+poislindtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to the Poisson-Lindley distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poislindtol.int(x, m = NULL, alpha = 0.05, P = 0.99, side = 1, 
                ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poislindtol.int_+3A_x">x</code></td>
<td>
<p>A vector of raw data which is distributed according to a Poisson-Lindley distribution.</p>
</td></tr>
<tr><td><code id="poislindtol.int_+3A_m">m</code></td>
<td>
<p>The number of observations in a future sample for which the tolerance limits will be calculated.  By default, <code>m = NULL</code> and, thus, <code>m</code> will be set equal to the original sample size.</p>
</td></tr>
<tr><td><code id="poislindtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that 1-alpha is the confidence level.</p>
</td></tr>
<tr><td><code id="poislindtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="poislindtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="poislindtol.int_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>poislind.ll</code> function, which is used for maximum likelihood estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The discrete Poisson-Lindley distribution is a compound distribution that, potentially, provides a better fit for count data relative to the traditional Poisson and negative binomial distributions. Poisson-Lindley distributions are heavily right-skewed distributions.  For most practical applications, one will typically be interested in 1-sided upper bounds.
</p>


<h3>Value</h3>

<p><code>poislindtol.int</code> returns a data frame with the following items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr> 
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr> 
<tr><td><code>theta</code></td>
<td>
<p>MLE for the shape parameter <code>theta</code>.</p>
</td></tr> 
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 				
</table>


<h3>References</h3>

<p>Naghizadeh Qomi, M., Kiapour, A., and Young, D. S. (2015), Approximate Tolerance Intervals for the Discrete Poisson-Lindley Distribution, 
<em>Journal of Statistical Computation and Simulation</em>, <b>86</b>, 841&ndash;854.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PoissonLindley">PoissonLindley</a></code>, <code><a href="#topic+poislind.ll">poislind.ll</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 90%/90% 1-sided tolerance intervals for data assuming 
## the Poisson-Lindley distribution.

x &lt;- c(rep(0, 447), rep(1, 132), rep(2, 42), rep(3, 21), 
       rep(4, 3), rep(5, 2))
out &lt;- poislindtol.int(x, alpha = 0.10, P = 0.90, side = 1)
out
</code></pre>

<hr>
<h2 id='PoissonLindley'>
Discrete Poisson-Lindley Distribution
</h2><span id='topic+PoissonLindley'></span><span id='topic+dpoislind'></span><span id='topic+ppoislind'></span><span id='topic+qpoislind'></span><span id='topic+rpoislind'></span>

<h3>Description</h3>

<p>Density (mass), distribution function, quantile function, and random generation for the Poisson-Lindley distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpoislind(x, theta, log = FALSE)
ppoislind(q, theta, lower.tail = TRUE, log.p = FALSE)
qpoislind(p, theta, lower.tail = TRUE, log.p = FALSE)
rpoislind(n, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoissonLindley_+3A_x">x</code>, <code id="PoissonLindley_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="PoissonLindley_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="PoissonLindley_+3A_n">n</code></td>
<td>
<p>The number of observations.  If <code>length&gt;1</code>, then the length is taken to be the number
required.</p>
</td></tr>
<tr><td><code id="PoissonLindley_+3A_theta">theta</code></td>
<td>
<p>The shape parameter, which must be greater than 0.</p>
</td></tr>
<tr><td><code id="PoissonLindley_+3A_log">log</code>, <code id="PoissonLindley_+3A_log.p">log.p</code></td>
<td>
<p>Logical vectors.  If <code>TRUE</code>, then the probabilities are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="PoissonLindley_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical vector.  If <code>TRUE</code>, then probabilities are <code class="reqn">P[X\le x]</code>, else <code class="reqn">P[X&gt;x]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Poisson-Lindley distribution has mass
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \frac{\theta^{2}(x + \theta + 2)}{(\theta + 1)^{x+3}},</code>
</p>

<p>where <code class="reqn">x=0,1,\ldots</code> and <code class="reqn">\theta&gt;0</code> is the shape parameter. 
</p>


<h3>Value</h3>

<p><code>dpoislind</code> gives the density (mass), <code>ppoislind</code> gives the distribution function, <code>qpoislind</code> gives the quantile function, and <code>rpoislind</code> generates random deviates for the specified distribution. 
</p>


<h3>References</h3>

<p>Ghitany, M. E. and Al-Mutairi, D. K. (2009), Estimation Methods for the Discrete Poisson-Lindley Distribution, 
<em>Journal of Statistical Computation and Simulation</em>, <b>79</b>, 1&ndash;9.
</p>
<p>Sankaran, M. (1970), The Discrete Poisson-Lindley Distribution, <em>Biometrics</em>, <b>26</b>, 145&ndash;149. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> about random number generation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data from the Poisson-Lindley
## distribution.

set.seed(100)
x &lt;- rpoislind(n = 150, theta = 0.5)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 &lt;- sort(x)
y &lt;- dpoislind(x = x.1, theta = 0.5)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, ppoislind(q = x.1, theta = 0.5), type = "l", 
     xlab = "x", ylab = "Cumulative Probabilities")

qpoislind(p = 0.20, theta = 0.5, lower.tail = FALSE)
qpoislind(p = 0.80, theta = 0.5)
</code></pre>

<hr>
<h2 id='poistol.int'>Poisson Tolerance Intervals</h2><span id='topic+poistol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for Poisson random variables.  From a statistical quality control
perspective, these limits bound the number of occurrences (which follow a Poisson distribution) in a specified future time period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poistol.int(x, n, m = NULL, alpha = 0.05, P = 0.99, side = 1, 
            method = c("TAB", "LS", "SC", "CC", "VS", "RVS",
            "FT", "CSC"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poistol.int_+3A_x">x</code></td>
<td>
<p>The number of occurrences of the event in time period <code>n</code>. Can be a vector of length <code>n</code>, in which case the sum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="poistol.int_+3A_n">n</code></td>
<td>
<p>The time period of the original measurements.</p>
</td></tr>
<tr><td><code id="poistol.int_+3A_m">m</code></td>
<td>
<p>The specified future length of time. If <code>m = NULL</code>, then the tolerance limits will be constructed assuming <code>n</code> for the future length of time.</p>
</td></tr>
<tr><td><code id="poistol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="poistol.int_+3A_p">P</code></td>
<td>
<p>The proportion of occurrences in future time lengths of size <code>m</code> 
to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="poistol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="poistol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the lower and upper confidence bounds, which are used in the calculation
of the tolerance bounds.  The default method is <code>"TAB"</code>, which is the tabular method and is usually preferred for a smaller
number of occurrences.  <code>"LS"</code> gives the large-sample (Wald) method, which is usually preferred when the number of occurrences is
<code>x&gt;20</code>. <code>"SC"</code> gives the score method, which again is usually used when the number of occurrences is relatively large. <code>"CC"</code> gives a continuity-corrected version of the large-sample method.  <code>"VS"</code> gives a variance-stabilized version of the large-sample method.  <code>"RVS"</code> is a recentered version of the variance-stabilization method.  <code>"FT"</code> is the Freeman-Tukey method.  <code>"CSC"</code> is the continuity-corrected version of the score method. More information on these methods can be found in the &quot;References&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>poistol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of occurrences in future time periods of length <code>m</code>.</p>
</td></tr>
<tr><td><code>lambda.hat</code></td>
<td>
<p>The mean occurrence rate per unit time, calculated by <code>x/n</code>.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Barker, L. (2002), A Comparison of Nine Confidence Intervals for a Poisson Parameter When the Expected Number of Events Is <code class="reqn">\le 5</code>, <em>The American Statistician</em>, <b>56</b>, 85&ndash;89.
</p>
<p>Freeman, M. F. and Tukey, J. W. (1950), Transformations Related to the Angular and the Square Root,
<em>Annals of Mathematical Statistics</em>, <b>21</b>, 607&ndash;611.
</p>
<p>Hahn, G. J. and Chandra, R. (1981), Tolerance Intervals for Poisson and Binomial Variables,
<em>Journal of Quality Technology</em>, <b>13</b>, 100&ndash;110.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Poisson">Poisson</a></code>, <code><a href="#topic+umatol.int">umatol.int</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/90% 1-sided Poisson tolerance limits for future 
## occurrences in a period of length 3.  All seven methods
## are presented for comparison.

poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "TAB")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "LS")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "SC")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "CC")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "VS")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "RVS")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "FT")
poistol.int(x = 45, n = 9, m = 3, alpha = 0.05, P = 0.90,
            side = 1, method = "CSC")
            
## 95%/90% 2-sided Poisson tolerance intervals for future 
## occurrences in a period of length 15.  All seven methods
## are presented for comparison.

poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "TAB")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "LS")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "SC")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "CC")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "VS")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "RVS")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "FT")
poistol.int(x = 45, n = 9, m = 15, alpha = 0.05, P = 0.90,
            side = 2, method = "CSC")
</code></pre>

<hr>
<h2 id='regtol.int'>(Multiple) Linear Regression Tolerance Bounds</h2><span id='topic+regtol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided (multiple) linear regression tolerance bounds.  It is also possible to fit a 
regression through the origin model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regtol.int(reg, new.x = NULL, side = 1, alpha = 0.05, P = 0.99) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regtol.int_+3A_reg">reg</code></td>
<td>
<p>An object of class <code>lm</code> (i.e., the results from a linear regression routine).</p>
</td></tr>
<tr><td><code id="regtol.int_+3A_new.x">new.x</code></td>
<td>
<p>An optional data frame in which to look for variables with which to predict. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="regtol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance bound is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr> 
<tr><td><code id="regtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="regtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by the tolerance bound(s).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>regtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by the tolerance bound(s).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The value of the response given on the left-hand side of the model in <code>reg</code>.</p>
</td></tr>
<tr><td><code>y.hat</code></td>
<td>
<p>The predicted value of the response for the fitted linear regression model.  This data frame is sorted by
this value.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr></table>


<h3>References</h3>

<p>Wallis, W. A. (1951), Tolerance Intervals for Linear Regression, in <em>Second Berkeley Symposium on Mathematical
Statistics and Probability</em>, ed. J. Neyman, Berkeley: University of CA Press, 43&ndash;51.
</p>
<p>Young, D. S. (2013), Regression Tolerance Intervals, <em>Communications in Statistics - Simulation and Computation</em>, <b>42</b>, 2040&ndash;2055.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/95% 2-sided linear regression tolerance bounds
## for a sample of size 100. 

set.seed(100)
x &lt;- runif(100, 0, 10)
y &lt;- 20 + 5*x + rnorm(100, 0, 3)
out &lt;- regtol.int(reg = lm(y ~ x), new.x = data.frame(x = c(3, 6, 9)), 
                  side = 2, alpha = 0.05, P = 0.95)
out

plottol(out, x = cbind(1, x), y = y, side = "two", x.lab = "X", 
        y.lab = "Y")

</code></pre>

<hr>
<h2 id='simnormtol.int'>Simultaneous Normal (or Log-Normal) Tolerance Intervals</h2><span id='topic+simnormtol.int'></span>

<h3>Description</h3>

<p>Provides simultaneous 1-sided or 2-sided tolerance intervals for data distributed according to either a normal
distribution or log-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simnormtol.int(x, alpha = 0.05, P = 0.99, side = 1,
               method = c("EXACT", "BONF"), m = 50, log.norm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simnormtol.int_+3A_x">x</code></td>
<td>
<p>Either a matrix or list of vectors of the data.  If a matrix, then the columns are the samples from the different normal (or log-normal) populations.  If <code>method = "EXACT"</code>, then <code>x</code> must be a matrix.</p>
</td></tr>
<tr><td><code id="simnormtol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="simnormtol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="simnormtol.int_+3A_side">side</code></td>
<td>
<p>Whether simultaneous 1-sided or 2-sided tolerance intervals are required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
<tr><td><code id="simnormtol.int_+3A_method">method</code></td>
<td>
<p>The method for calculating the k-factors.  <code>"EXACT"</code> is an exact method that can be used when all <code>l</code> groups have the same sample size. <code>"BONF"</code> is an approximate method using the Bonferroni inequality, which can be used when the <code>l</code> groups have different sample sizes.</p>
</td></tr>
<tr><td><code id="simnormtol.int_+3A_m">m</code></td>
<td>
<p>The maximum number of subintervals to be used in the <code>integrate</code> function.  This is necessary only for <code>method = "EXACT"</code>.  The larger
the number, the more accurate the solution.  Too low of a value can result in an error. A large value can also cause the function to be slow for <code>method = "EXACT"</code>.</p>
</td></tr>
<tr><td><code id="simnormtol.int_+3A_log.norm">log.norm</code></td>
<td>
<p>If <code>TRUE</code>, then the data is considered to be from a log-normal distribution, in which
case the output gives tolerance intervals for the log-normal distribution.  The default is <code>FALSE</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Recall that if the random variable <code class="reqn">X</code> is distributed according to a log-normal distribution, then the random variable <code class="reqn">Y = ln(X)</code> is
distributed according to a normal distribution.
</p>


<h3>Value</h3>

<p><code>normtol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>x.bar</code></td>
<td>
<p>The sample means.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The simultaneous 1-sided lower tolerance bounds.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The simultaneous 1-sided upper tolerance bounds.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The simultaneous 2-sided lower tolerance bounds.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The simultaneous 2-sided upper tolerance bounds.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The code for this functions is built upon code provided by Andrew Landgraf.</p>


<h3>References</h3>

<p>Krishnamoorthy, K. and Mathew, T. (2009), <em>Statistical Tolerance Regions: Theory, Applications, and Computation</em>, Wiley.
</p>
<p>Mee, R. W. (1990), Simultaneous Tolerance Intervals for Normal Populations with Common Variance, <em>Technometrics</em>, <b>32</b>, 83-92.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">Normal</a></code>, <code><a href="#topic+K.factor.sim">K.factor.sim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 95%/95% simultaneous 2-sided normal tolerance 
## intervals for three samples of unequal size. 

set.seed(100)
x &lt;- list(rnorm(20),rnorm(10,1),rnorm(12,1,2))
out &lt;- simnormtol.int(x = x, alpha = 0.05, P = 0.95, 
                      side = 2, method = "BONF")
out
</code></pre>

<hr>
<h2 id='tolerance-internal'>Internal Functions</h2><span id='topic+extrap'></span><span id='topic+interp'></span><span id='topic+rFUN'></span><span id='topic+rwishart'></span><span id='topic+two.sided'></span><span id='topic+zeta.fun'></span>

<h3>Description</h3>

<p>Internal functions for the package <code>tolerance</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extrap(x, alpha, P)
interp(x, alpha, P)
rFUN(FUN, r1 = "1", r2 = "2")
rwishart(df, p)
two.sided(x, alpha, P)
zeta.fun(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tolerance-internal_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="tolerance-internal_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="tolerance-internal_+3A_fun">FUN</code></td>
<td>
<p>A function that takes exactly two arguments: <code>r1</code> and <code>r2</code>.</p>
</td></tr>
<tr><td><code id="tolerance-internal_+3A_r1">r1</code>, <code id="tolerance-internal_+3A_r2">r2</code></td>
<td>
<p>The two arguments to <code>FUN</code>.</p>
</td></tr>
<tr><td><code id="tolerance-internal_+3A_df">df</code></td>
<td>
<p>The degrees of freedom for the Wishart matrix to be generated.</p>
</td></tr>
<tr><td><code id="tolerance-internal_+3A_p">p</code></td>
<td>
<p>The dimension of the random Wishart matrix.</p>
</td></tr>
<tr><td><code id="tolerance-internal_+3A_x">x</code></td>
<td>
<p>For <code>zeta.fun</code>, a vector or matrix whose real values must be greater than or equal to 1.
For <code>extrap</code>, <code>interp</code>, and <code>two.sided</code>, it is a vector of data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are not intended to be called by the user.  <code>extrap</code>, <code>interp</code>, and <code>two.sided</code> are functions used for the Young-Mathew approach to improving nonparametric tolerance intervals. <code>rFUN</code> is a way to extract the character expression for <code>FUN</code> with the two arguments <code>r1</code> and <code>r2</code>. <code>rwishart</code> performs random generation of Wishart matrices.  <code>zeta.fun</code> is a condensed version of the Riemann's zeta function given in the VGAM package.  Please use that reference if looking to directly implement Riemann's zeta function.  The function we have included is done so out of convenience.  
</p>


<h3>References</h3>

<p>Yee, T. (2010), The VGAM Package for Categorical Data Analysis, <em>Journal of Statistical Software</em>, <b>32</b>, 1&ndash;34.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvtol.region">mvtol.region</a></code>, <code><a href="#topic+nptol.int">nptol.int</a></code>
</p>

<hr>
<h2 id='TwoParExponential'>The 2-Parameter Exponential Distribution</h2><span id='topic+TwoParExponential'></span><span id='topic+d2exp'></span><span id='topic+p2exp'></span><span id='topic+q2exp'></span><span id='topic+r2exp'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation for the 2-parameter 
exponential distribution with rate equal to <code>rate</code> and shift equal to <code>shift</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d2exp(x, rate = 1, shift = 0, log = FALSE)
p2exp(q, rate = 1, shift = 0, lower.tail = TRUE, log.p = FALSE)
q2exp(p, rate = 1, shift = 0, lower.tail = TRUE, log.p = FALSE)
r2exp(n, rate = 1, shift = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TwoParExponential_+3A_x">x</code>, <code id="TwoParExponential_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="TwoParExponential_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="TwoParExponential_+3A_n">n</code></td>
<td>
<p>The number of observations.  If <code>length&gt;1</code>, then the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="TwoParExponential_+3A_rate">rate</code></td>
<td>
<p>Vector of rates.</p>
</td></tr>
<tr><td><code id="TwoParExponential_+3A_shift">shift</code></td>
<td>
<p>Vector of shifts.</p>
</td></tr>
<tr><td><code id="TwoParExponential_+3A_log">log</code>, <code id="TwoParExponential_+3A_log.p">log.p</code></td>
<td>
<p>Logical vectors.  If <code>TRUE</code>, then probabilities are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="TwoParExponential_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical vector.  If <code>TRUE</code>, then probabilities are <code class="reqn">P[X\le x]</code>, else <code class="reqn">P[X&gt;x]</code>.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>If <code>rate</code> or <code>shift</code> are not specified, then they assume the default values of 1 and 0, respectively.
</p>
<p>The 2-parameter exponential distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{1}{\beta}e^{(x-\mu)/ \beta}</code>
</p>

<p>where <code class="reqn">x\ge\mu</code>, <code class="reqn">\mu</code> is the shift parameter, and <code class="reqn">\beta&gt;0</code> is the scale parameter.
</p>


<h3>Value</h3>

<p><code>d2exp</code> gives the density, <code>p2exp</code> gives the distribution function, <code>q2exp</code> gives the quantile
function, and <code>r2exp</code> generates random deviates.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> about random number generation.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data from the 2-parameter exponential 
## distribution.

set.seed(100)
x &lt;- r2exp(n = 500, rate = 3, shift = -10)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 = sort(x)
y &lt;- d2exp(x = x.1, rate = 3, shift = -10)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, p2exp(q = x.1, rate = 3, shift = -10), type = "l", 
     xlab = "x", ylab = "Cumulative Probabilities")

q2exp(p = 0.20, rate = 3, shift = -10, lower.tail = FALSE)
q2exp(p = 0.80, rate = 3, shift = -10)
</code></pre>

<hr>
<h2 id='umatol.int'>Uniformly Most Accurate Upper Tolerance Limits for Certain Discrete Distributions</h2><span id='topic+umatol.int'></span>

<h3>Description</h3>

<p>Provides uniformly most accurate upper tolerance limits for the binomial, negative binomial, and Poisson distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>umatol.int(x, n = NULL, dist = c("Bin", "NegBin", "Pois"), N, 
           alpha = 0.05, P = 0.99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="umatol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to one of the binomial, negative binomial, or Poisson distributions.
If the length of <code>x</code> is 1, then it is assumed that this number is the sum of iid values from the assumed distribution.</p>
</td></tr>
<tr><td><code id="umatol.int_+3A_n">n</code></td>
<td>
<p>The sample size of the data.  If <code>null</code>, then <code>n</code> is calculated as the length of <code>x</code>.</p>
</td></tr>
<tr><td><code id="umatol.int_+3A_dist">dist</code></td>
<td>
<p>The distribution for the data given by <code>x</code>.  The options are <code>"Bin"</code> for the binomial distribution,
<code>"NegBin"</code> for the negative binomial distribution, and <code>"Pois"</code> for the Poisson distribution.</p>
</td></tr>
<tr><td><code id="umatol.int_+3A_n">N</code></td>
<td>
<p>Must be specified for the binomial and negative binomial distributions.  If <code>dist = "Bin"</code>, then <code>N</code>
is the number of Bernoulli trials and must be a positive integer.  If <code>dist = "NegBin"</code>, then <code>N</code> is the total number
of successful trials (or dispersion parameter) and must be strictly positive.</p>
</td></tr>
<tr><td><code id="umatol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="umatol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>umatol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>p.hat</code></td>
<td>
<p>The maximum likelihood estimate for the probability of success in each trial; reported if <code>dist = "Bin"</code>.</p>
</td></tr>
<tr><td><code>nu.hat</code></td>
<td>
<p>The maximum likelihood estimate for the probability of success in each trial; reported if <code>dist = "NegBin"</code>.</p>
</td></tr>
<tr><td><code>lambda.hat</code></td>
<td>
<p>The maximum likelihood estimate for the rate of success; reported if <code>dist = "Pois"</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zacks, S. (1970), Uniformly Most Accurate Tolerance Limits for Monotone Likelihood Ratio Families of Discrete Distributions,
<em>Journal of the American Statistical Association</em>, <b>65</b>, 307&ndash;316.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Binomial">Binomial</a></code>, <code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code>, <code><a href="stats.html#topic+Poisson">Poisson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Examples from Zacks (1970).

umatol.int(25, n = 4, dist = "Bin", N = 10, alpha = 0.10, 
           P = 0.95)
umatol.int(13, n = 10, dist = "NegBin", N = 2, alpha = 0.10,
           P = 0.95)
umatol.int(37, n = 10, dist = "Pois", alpha = 0.10, P = 0.95)
</code></pre>

<hr>
<h2 id='uniftol.int'>Uniform Tolerance Intervals</h2><span id='topic+uniftol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to a uniform distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniftol.int(x, alpha = 0.05, P = 0.99, upper = NULL,
            lower = NULL, side = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uniftol.int_+3A_x">x</code></td>
<td>
<p>A vector of data which is distributed according to a uniform distribution.</p>
</td></tr>
<tr><td><code id="uniftol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that <code>1-alpha</code> is the confidence level.</p>
</td></tr>
<tr><td><code id="uniftol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="uniftol.int_+3A_upper">upper</code></td>
<td>
<p>The upper bound of the data.  When <code>NULL</code>, then the maximum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="uniftol.int_+3A_lower">lower</code></td>
<td>
<p>The lower bound of the data.  When <code>NULL</code>, then the minimum of <code>x</code> is used.</p>
</td></tr>
<tr><td><code id="uniftol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>,
respectively).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>uniftol.int</code> returns a data frame with items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr>
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound.  This is given only if <code>side = 1</code>.</p>
</td></tr>
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound.  This is given only if <code>side = 2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Faulkenberry, G. D. and Weeks, D. L. (1968), Sample Size Determination for Tolerance Limits,
<em>Technometrics</em>, <b>10</b>, 343&ndash;348.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## 90%/90% 1-sided uniform tolerance intervals for a sample
## of size 50 with a known lower bound of 0. 

set.seed(100)
x &lt;- runif(50, 0, 50)
out &lt;- uniftol.int(x = x, alpha = 0.10, P = 0.90, lower = 0,
                   side = 1) 
out

plottol(out, x, plot.type = "hist", side = "two", 
        x.lab = "Uniform Data")
</code></pre>

<hr>
<h2 id='ZipfMandelbrot'>
Zipf-Mandelbrot Distributions
</h2><span id='topic+ZipfMandelbrot'></span><span id='topic+dzipfman'></span><span id='topic+pzipfman'></span><span id='topic+qzipfman'></span><span id='topic+rzipfman'></span>

<h3>Description</h3>

<p>Density (mass), distribution function, quantile function, and random generation for the Zipf, Zipf-Mandelbrot, and zeta distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzipfman(x, s, b = NULL, N = NULL, log = FALSE)
pzipfman(q, s, b = NULL, N = NULL, lower.tail = TRUE, 
         log.p = FALSE)
qzipfman(p, s, b = NULL, N = NULL, lower.tail = TRUE, 
         log.p = FALSE)
rzipfman(n, s, b = NULL, N = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ZipfMandelbrot_+3A_x">x</code>, <code id="ZipfMandelbrot_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="ZipfMandelbrot_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="ZipfMandelbrot_+3A_n">n</code></td>
<td>
<p>The number of observations.  If <code>length&gt;1</code>, then the length is taken to be the number
required.</p>
</td></tr>
<tr><td><code id="ZipfMandelbrot_+3A_s">s</code>, <code id="ZipfMandelbrot_+3A_b">b</code></td>
<td>
<p>The shape parameters, both of which must be greater than 0.  <code>b</code> must be specified for Zipf-Mandelbrot distributions.</p>
</td></tr>
<tr><td><code id="ZipfMandelbrot_+3A_n">N</code></td>
<td>
<p>The number of categories, which must be integer-valued for Zipf and Zipf-Mandelbrot distributions. For a zeta distribution, <code>N = Inf</code> must be used.</p>
</td></tr>
<tr><td><code id="ZipfMandelbrot_+3A_log">log</code>, <code id="ZipfMandelbrot_+3A_log.p">log.p</code></td>
<td>
<p>Logical vectors.  If <code>TRUE</code>, then the probabilities are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="ZipfMandelbrot_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical vector.  If <code>TRUE</code>, then probabilities are <code class="reqn">P[X\le x]</code>, else <code class="reqn">P[X&gt;x]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Zipf-Mandelbrot distribution has mass
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \frac{(x + b)^{-s}}{\sum_{i=1}^{N}(i + b)^{-s}},</code>
</p>
	
<p>where <code class="reqn">x=1,\ldots,N</code>, <code>s,b&gt;0</code> are shape parameters, and <code>N</code> is the number of distinct categories. The Zipf distribution is just a special case of the Zipf-Mandelbrot distribution where the second shape parameter <code>b=0</code>.  The zeta distribution has mass
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \frac{x^{-s}}{\zeta(s)},</code>
</p>
	
<p>where <code class="reqn">x=1,2,\ldots</code>, <code>s&gt;1</code> is the shape parameter, and <code class="reqn">\zeta()</code> is the Riemann zeta function given by:
</p>
<p style="text-align: center;"><code class="reqn">\zeta(t) = \sum_{i=1}^{\infty}\frac{1}{i^{t}}&lt;\infty.</code>
</p>

<p>Note that the zeta distribution is just a special case of the Zipf distribution where <code>s&gt;1</code> and <code>N</code> goes to infinity.
</p>


<h3>Value</h3>

<p><code>dzipfman</code> gives the density (mass), <code>pzipfman</code> gives the distribution function, <code>qzipfman</code> gives the quantile function, and <code>rzipfman</code> generates random deviates for the specified distribution. 
</p>


<h3>Note</h3>

<p>These functions may be updated in a future version of the package so as to allow greater flexibility with the inputs.
</p>


<h3>References</h3>

<p>Mandelbrot, B. B. (1965), Information Theory and Psycholinguistics. In B. B. Wolman and E. Nagel, editors. <em>Scientific Psychology</em>, Basic Books.
</p>
<p>Young, D. S. (2013), Approximate Tolerance Limits for Zipf-Mandelbrot Distributions, <em>Physica A: Statistical Mechanics and its Applications</em>, <b>392</b>, 1702&ndash;1711. 
</p>
<p>Zipf, G. K. (1949), <em>Human Behavior and the Principle of Least Effort</em>, Hafner.
</p>
<p>Zornig, P. and Altmann, G. (1995), Unified Representation of Zipf Distributions, <em>Computational Statistics and Data Analysis</em>, <b>19</b>, 461&ndash;473. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code> and <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> about random number generation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data from the Zipf distribution.

set.seed(100)
x &lt;- rzipfman(n = 150, s = 2, N = 100)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 &lt;- sort(x)
y &lt;- dzipfman(x = x.1, s = 2, N = 100)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, pzipfman(q = x.1, s = 2, N = 100), type = "l", 
     xlab = "x", ylab = "Cumulative Probabilities")

qzipfman(p = 0.20, s = 2, N = 100, lower.tail = FALSE)
qzipfman(p = 0.80, s = 2, N = 100)

## Randomly generated data from the Zipf-Mandelbrot distribution.

set.seed(100)
x &lt;- rzipfman(n = 150, s = 2, b = 3, N = 100)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 &lt;- sort(x)
y &lt;- dzipfman(x = x.1, s = 2, b = 3, N = 100)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, pzipfman(q = x.1, s = 2, b = 3, N = 100), type = "l", 
     xlab = "x", ylab = "Cumulative Probabilities")

qzipfman(p = 0.20, s = 2, b = 3, N = 100, lower.tail = FALSE)
qzipfman(p = 0.80, s = 2, b = 3, N = 100)

## Randomly generated data from the zeta distribution.

set.seed(100)
x &lt;- rzipfman(n = 100, s = 1.3, N = Inf)
hist(x, main = "Randomly Generated Data", prob = TRUE)

x.1 &lt;- sort(x)
y &lt;- dzipfman(x = x.1, s = 1.3, N = Inf)
lines(x.1, y, col = 2, lwd = 2)

plot(x.1, pzipfman(q = x.1, s = 1.3, N = Inf), type = "l", 
     xlab = "x", ylab = "Cumulative Probabilities")

qzipfman(p = 0.20, s = 1.3, lower.tail = FALSE, N = Inf)
qzipfman(p = 0.80, s = 1.3, N = Inf)
</code></pre>

<hr>
<h2 id='zipftol.int'>
Zipf-Mandelbrot Tolerance Intervals
</h2><span id='topic+zipftol.int'></span>

<h3>Description</h3>

<p>Provides 1-sided or 2-sided tolerance intervals for data distributed according to Zipf, Zipf-Mandelbrot, and zeta distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zipftol.int(x, m = NULL, N = NULL, alpha = 0.05, P = 0.99, 
            side = 1, s = 1, b = 1, dist = c("Zipf", 
            "Zipf-Man", "Zeta"), ties = FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zipftol.int_+3A_x">x</code></td>
<td>
<p>A vector of raw data or a table of counts which is distributed according to a Zipf, Zipf-Mandelbrot, or zeta distribution. Do not supply a vector of counts!</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_m">m</code></td>
<td>
<p>The number of observations in a future sample for which the tolerance limits will be calculated.  By default, <code>m = NULL</code> and, thus, <code>m</code> will be set equal to the original sample size.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_n">N</code></td>
<td>
<p>The number of categories when <code>dist = "Zipf"</code> or <code>dist = "Zipf-Man"</code>.  This is not used when <code>dist = "Zeta"</code>.  If <code>N = NULL</code>, then <code>N</code> is estimated based on the number of categories observed in the data.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_alpha">alpha</code></td>
<td>
<p>The level chosen such that 1-alpha is the confidence level.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_p">P</code></td>
<td>
<p>The proportion of the population to be covered by this tolerance interval.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_side">side</code></td>
<td>
<p>Whether a 1-sided or 2-sided tolerance interval is required (determined by <code>side = 1</code> or <code>side = 2</code>, respectively).</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_s">s</code></td>
<td>
<p>The initial value to estimate the shape parameter in the <code>zm.ll</code> function.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_b">b</code></td>
<td>
<p>The initial value to estimate the second shape parameter in the <code>zm.ll</code> function when <code>dist = "Zipf-Man"</code>.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_dist">dist</code></td>
<td>
<p>Options are <code>dist = "Zipf"</code>, <code>dist = "Zipf-Man"</code>, or <code>dist = "Zeta"</code> if the data is distributed according to the Zipf, Zipf-Mandelbrot, or zeta distribution, respectively.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_ties">ties</code></td>
<td>
<p>How to handle if there are other categories with the same frequency as the category at the estimated tolerance limit.  The default is <code>FALSE</code>, which does no correction.  If <code>TRUE</code>, then the highest ranked (i.e., lowest number) of the tied categories is selected for the lower limit and the lowest ranked (i.e., highest number) of the tied categories is selected for the upper limit.</p>
</td></tr>
<tr><td><code id="zipftol.int_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>zm.ll</code> function, which is used for maximum likelihood estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Zipf-Mandelbrot models are commonly used to model phenomena where the frequencies of categorical data are approximately inversely proportional to its rank in the frequency table. Zipf-Mandelbrot distributions are heavily right-skewed distributions with a (relatively) large mass placed on the first category.  For most practical applications, one will typically be interested in 1-sided upper bounds.
</p>


<h3>Value</h3>

<p><code>zipftol.int</code> returns a data frame with the following items:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The specified significance level.</p>
</td></tr> 
<tr><td><code>P</code></td>
<td>
<p>The proportion of the population covered by this tolerance interval.</p>
</td></tr> 
<tr><td><code>s.hat</code></td>
<td>
<p>MLE for the shape parameter <code>s</code>.</p>
</td></tr> 
<tr><td><code>b.hat</code></td>
<td>
<p>MLE for the shape parameter <code>b</code> when <code>dist = "Zipf-Man"</code>.</p>
</td></tr> 	
<tr><td><code>1-sided.lower</code></td>
<td>
<p>The 1-sided lower tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>1-sided.upper</code></td>
<td>
<p>The 1-sided upper tolerance bound. This is given only if <code>side = 1.</code></p>
</td></tr> 
<tr><td><code>2-sided.lower</code></td>
<td>
<p>The 2-sided lower tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 
<tr><td><code>2-sided.upper</code></td>
<td>
<p>The 2-sided upper tolerance bound. This is given only if <code>side = 2.</code></p>
</td></tr> 				
</table>


<h3>Note</h3>

<p>This function may be updated in a future version of the package so as to allow greater flexibility with the inputs.
</p>


<h3>References</h3>

<p>Mandelbrot, B. B. (1965), Information Theory and Psycholinguistics. In B. B. Wolman and E. Nagel, editors. <em>Scientific Psychology</em>, Basic Books.
</p>
<p>Young, D. S. (2013), Approximate Tolerance Limits for Zipf-Mandelbrot Distributions, <em>Physica A: Statistical Mechanics and its Applications</em>, <b>392</b>, 1702&ndash;1711. 
</p>
<p>Zipf, G. K. (1949), <em>Human Behavior and the Principle of Least Effort</em>, Hafner.
</p>
<p>Zornig, P. and Altmann, G. (1995), Unified Representation of Zipf Distributions, <em>Computational Statistics and Data Analysis</em>, <b>19</b>, 461&ndash;473. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ZipfMandelbrot">ZipfMandelbrot</a></code>, <code><a href="#topic+zm.ll">zm.ll</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 95%/99% 1-sided tolerance intervals for the Zipf, 
## Zipf-Mandelbrot, and zeta distributions. 

set.seed(100)

s &lt;- 2
b &lt;- 5
N &lt;- 50

zipf.data &lt;- rzipfman(n = 150, s = s, N = N)
zipfman.data &lt;- rzipfman(n = 150, s = s, b = b, N = N)
zeta.data &lt;- rzipfman(n = 150, s = s, N = Inf)

out.zipf &lt;- zipftol.int(zipf.data, dist = "Zipf")
out.zipfman &lt;- zipftol.int(zipfman.data, dist = "Zipf-Man")
out.zeta &lt;- zipftol.int(zeta.data, N = Inf, dist = "Zeta")

out.zipf
out.zipfman
out.zeta
</code></pre>

<hr>
<h2 id='zm.ll'>
Maximum Likelihood Estimation for Zipf-Mandelbrot Models
</h2><span id='topic+zm.ll'></span>

<h3>Description</h3>

<p>Performs maximum likelihood estimation for the parameters of the Zipf, Zipf-Mandelbrot, and zeta distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zm.ll(x, N = NULL, s = 1, b = 1, dist = c("Zipf", "Zipf-Man", 
      "Zeta"), ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zm.ll_+3A_x">x</code></td>
<td>
<p>A vector of raw data or a table of counts which is distributed according to a Zipf, Zipf-Mandelbrot, or zeta distribution. Do not supply a vector of counts!</p>
</td></tr>
<tr><td><code id="zm.ll_+3A_n">N</code></td>
<td>
<p>The number of categories when <code>dist = "Zipf"</code> or <code>dist = "Zipf-Man"</code>.  This is not used when <code>dist = "Zeta"</code>.  If <code>N = NULL</code>, then <code>N</code> is estimated based on the number of categories observed in the data.</p>
</td></tr>
<tr><td><code id="zm.ll_+3A_s">s</code></td>
<td>
<p>The initial value to estimate the shape parameter, which is set to 1 by default.  If a poor initial value is specified, then a <code>WARNING</code> message is returned.</p>
</td></tr>
<tr><td><code id="zm.ll_+3A_b">b</code></td>
<td>
<p>The initial value to estimate the second shape parameter when <code>dist = "Zipf-Man"</code>, which is set to 1 by default. If a poor initial value is specified, then a <code>WARNING</code> message is returned.</p>
</td></tr>
<tr><td><code id="zm.ll_+3A_dist">dist</code></td>
<td>
<p>Options are <code>dist = "Zipf"</code>, <code>dist = "Zipf-Man"</code>, or <code>dist = "Zeta"</code> if the data is distributed according to the Zipf, Zipf-Mandelbrot, or zeta distribution, respectively.</p>
</td></tr>
<tr><td><code id="zm.ll_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>mle</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Zipf-Mandelbrot models are commonly used to model phenomena where the frequencies of categorical data are approximately inversely proportional to its rank in the frequency table.
</p>


<h3>Value</h3>

<p>See the help file for <code>mle</code> to see how the output is structured.				
</p>


<h3>Note</h3>

<p>This function may be updated in a future version of the package so as to allow greater flexibility with the inputs.
</p>


<h3>References</h3>

<p>Mandelbrot, B. B. (1965), Information Theory and Psycholinguistics. In B. B. Wolman and E. Nagel, editors. <em>Scientific Psychology</em>, Basic Books.
</p>
<p>Zipf, G. K. (1949), <em>Human Behavior and the Principle of Least Effort</em>, Hafner.
</p>
<p>Zornig, P. and Altmann, G. (1995), Unified Representation of Zipf Distributions, <em>Computational Statistics and Data Analysis</em>, <b>19</b>, 461&ndash;473. 
</p>


<h3>See Also</h3>

<p><code><a href="stats4.html#topic+mle">mle</a></code>, <code><a href="#topic+ZipfMandelbrot">ZipfMandelbrot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Maximum likelihood estimation for randomly generated data
## from the Zipf, Zipf-Mandelbrot, and zeta distributions. 

set.seed(100)

s &lt;- 2
b &lt;- 5
N &lt;- 50

zipf.data &lt;- rzipfman(n = 500, s = s, N = N)
out.zipf &lt;- zm.ll(zipf.data, N = N, dist = "Zipf")
stats4::coef(out.zipf)
stats4::vcov(out.zipf)

zipfman.data &lt;- rzipfman(n = 500, s = s, b = b, N = N)
out.zipfman &lt;- zm.ll(zipfman.data, N = N, dist = "Zipf-Man")
stats4::coef(out.zipfman)
diag(stats4::vcov(out.zipfman))

zeta.data &lt;- rzipfman(n = 200, s = s, N = Inf)
out.zeta &lt;- zm.ll(zeta.data, N = Inf, dist = "Zeta")
stats4::coef(out.zeta)
stats4::vcov(out.zeta)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
