<!DOCTYPE html><html lang="en"><head><title>Help for package MSinference</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MSinference}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MSinference-package'><p>Multiscale Inference for Nonparametric Time Trend(s)</p></a></li>
<li><a href='#ar_coef'><p>Computes estimator of the AR(p) coefficients by the procedure from</p>
Khismatullina and Vogt (2020).</a></li>
<li><a href='#compute_minimal_intervals'><p>Computes the set of minimal intervals as described in Duembgen (2002)</p></a></li>
<li><a href='#compute_quantiles'><p>Computes quantiles of the gaussian multiscale statistics.</p></a></li>
<li><a href='#compute_quantiles_2'><p>Computes quantiles of the gaussian multiscale statistics.</p></a></li>
<li><a href='#compute_statistics'><p>Calculates the value of the test statistics both for single time series</p>
analysis and multiple time series analysis.</a></li>
<li><a href='#construct_grid'><p>Computes the location-bandwidth grid for the multiscale test.</p></a></li>
<li><a href='#construct_weekly_grid'><p>Computes the location-bandwidth weekly grid for the multiscale test.</p></a></li>
<li><a href='#corrections'><p>Computes vector of correction terms for second-stage estimator</p>
of AR parameters as described in Khismatullina, Vogt (2019).</a></li>
<li><a href='#covid'><p>Number of daily new cases of infections of COVID-19 per country.</p></a></li>
<li><a href='#emp_acf'><p>Computes autocovariances at lags 0 to p for the ell-th differences of data.</p></a></li>
<li><a href='#estimate_lrv'><p>Computes estimator of the long-run variance of the error terms.</p></a></li>
<li><a href='#multiscale_test'><p>Carries out the multiscale test given that the values the estimatates of</p>
long-run variance have already been computed.</a></li>
<li><a href='#plot_sizer_map'><p>Plots SiZer map from the test results of the multiscale testing procedure.</p></a></li>
<li><a href='#select_order'><p>Calculates different information criterions for a single time series</p>
or multiple time series with AR(<code class="reqn">p</code>) errors
based on the long-run variance estimator(s) for a range of tuning
parameters and different orders <code class="reqn">p</code>.</a></li>
<li><a href='#temperature'><p>Hadley Centre Central England Temperature (HadCET) dataset,</p>
Monthly Mean Central England Temperature (Degrees C)</a></li>
<li><a href='#variance_eta'><p>Computes variance of AR(p) innovation terms eta.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multiscale Inference for Nonparametric Time Trend(s)</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-08-20</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marina Khismatullina &lt;khismatullina@ese.eur.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs a multiscale analysis of a nonparametric
  regression or nonparametric regressions with time series errors. In case
  of one regression, with the help of this package it is possible to detect
  the regions where the trend function is increasing or decreasing.
  In case of multiple regressions, the test identifies regions where
  the trend functions are different from each other. See
  Khismatullina and Vogt (2020) &lt;<a href="https://doi.org/10.1111%2Frssb.12347">doi:10.1111/rssb.12347</a>&gt;,
  Khismatullina and Vogt (2022) &lt;<a href="https://doi.org/10.48550%2FarXiv.2209.10841">doi:10.48550/arXiv.2209.10841</a>&gt; and
  Khismatullina and Vogt (2023) &lt;<a href="https://doi.org/10.1016%2Fj.jeconom.2021.04.010">doi:10.1016/j.jeconom.2021.04.010</a>&gt;
  for more details on theory and applications.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.9), Rdpack, foreach, parallel, doParallel</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-20 22:55:26 UTC; missius</td>
</tr>
<tr>
<td>Author:</td>
<td>Marina Khismatullina [aut, cre],
  Michael Vogt [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-21 09:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='MSinference-package'>Multiscale Inference for Nonparametric Time Trend(s)</h2><span id='topic+MSinference-package'></span><span id='topic+MSinference'></span>

<h3>Description</h3>

<p>This package performs a multiscale analysis of a single nonparametric 
time trends (Khismatullina and Vogt (2020)) or multiple nonparametric 
time trends (Khismatullina and Vogt (2022), Khismatullina and Vogt (2023)).
</p>
<p>In case of a single nonparametric regression, the multiscale method to
test qualitative hypotheses about the nonparametric time trend <code class="reqn">m</code>
in the model <code class="reqn">Y_t = m(t/T) + \epsilon_t</code> with time series errors
<code class="reqn">\epsilon_t</code> is provided. The method was first proposed in
Khismatullina and Vogt (2020). It allows to test for shape properties
(areas of monotonic decrease or increase) of the trend <code class="reqn">m</code>.
</p>
<p>This method require an estimator of the long-run error variance
<code class="reqn">\sigma^2 = \sum_{l=-\infty}^{\infty} Cov(\epsilon_0, \epsilon_l)</code>.
Hence, the package also provides the difference-based
estimator for the case that the errors belong to the class of
<code class="reqn">AR(\infty)</code> processes. The estimator was also proposed in
Khismatullina and Vogt (2020).
</p>
<p>In case of multiple nonparametric regressions, we provide
the multiscale method to test qualitative hypotheses about
the nonparametric time trends in the context of epidemic modelling.
Specifically, we assume that the we observe a sample of the count data
<code class="reqn">\{\mathcal{X}_i = \{ X_{it}: 1 \le 1 \le T \}\}</code>, where <code class="reqn">X_{it}</code>
are quasi-Poisson distributed with time-varying intensity parameter
<code class="reqn">\lambda_i(t/T)</code>. The multiscale method allows to test whether
intenisty parameters are different or not, and if they are, it detects
with a prespicified significance level the regions where these differences
most probably occur. The method was introduced in
Khismatullina and Vogt (2023) and can be used for comparing the rates of
infection of COVID-19 across countries.
</p>


<h3>References</h3>

<p>Khismatullina M, Vogt M (2020).
&ldquo;Multiscale inference and long-run variance estimation in nonparametric regression with time series errors.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>.
</p>
<p>Khismatullina M, Vogt M (2023).
&ldquo;Nonparametric comparison of epidemic time trends: The case of COVID-19.&rdquo;
<em>Journal of Econometrics</em>, <b>232</b>(1), 87-108.
ISSN 0304-4076, <a href="https://doi.org/10.1016/j.jeconom.2021.04.010">doi:10.1016/j.jeconom.2021.04.010</a>.
</p>

<hr>
<h2 id='ar_coef'>Computes estimator of the AR(p) coefficients by the procedure from
Khismatullina and Vogt (2020).</h2><span id='topic+ar_coef'></span>

<h3>Description</h3>

<p>Computes estimator of the AR(p) coefficients by the procedure from
Khismatullina and Vogt (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ar_coef(data, l1, l2, correct, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ar_coef_+3A_data">data</code></td>
<td>
<p>Time series.</p>
</td></tr>
<tr><td><code id="ar_coef_+3A_l1">l1</code>, <code id="ar_coef_+3A_l2">l2</code></td>
<td>
<p>Tuning parameters.</p>
</td></tr>
<tr><td><code id="ar_coef_+3A_correct">correct</code></td>
<td>
<p>Vector of the corrections, either zero or calculated by
the function <code><a href="#topic+corrections">corrections</a></code>.</p>
</td></tr>
<tr><td><code id="ar_coef_+3A_p">p</code></td>
<td>
<p>AR order of the time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.         Vector of length p  of estimated AR coefficients.
</p>

<hr>
<h2 id='compute_minimal_intervals'>Computes the set of minimal intervals as described in Duembgen (2002)</h2><span id='topic+compute_minimal_intervals'></span>

<h3>Description</h3>

<p>Given a set of intervals, this function computes
the corresponding subset of minimal intervals which are defined
as follows. For a given set of intervals <code class="reqn">\mathcal{K}</code>,
all intervals <code class="reqn">\mathcal{I}_k \in \mathcal{K}</code>
such that  <code class="reqn">\mathcal{K}</code> does not contain a proper subset of
<code class="reqn">\mathcal{I}_k</code> are called minimal.
</p>
<p>This function is needed for illustrative purposes.
The set of all the intervals where our test rejects the null
hypothesis may be quite large, hence, we would like to focus
our attention on the smaller subset, for which we are still
able to make simultaneous confidence intervals. This subset
is the subset of minimal intervals, and it helps us to
to precisely locate the intervals of further interest.
</p>
<p>More details can be found in Duembgen (2002) and
Khismatullina and Vogt (2019, 2020)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_minimal_intervals(dataset)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_minimal_intervals_+3A_dataset">dataset</code></td>
<td>
<p>Set of the intervals.
It needs to contain the following columns:
&quot;startpoint&quot; - left end of the interval;
&quot;endpoint&quot;   - right end of the interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Subset of minimal intervals
</p>


<h3>Examples</h3>

<pre><code class='language-R'>startpoint   &lt;- c(0, 0.5, 1)
endpoint     &lt;- c(2, 2, 2)
dataset      &lt;- data.frame(startpoint, endpoint)
minimal_ints &lt;- compute_minimal_intervals(dataset)
</code></pre>

<hr>
<h2 id='compute_quantiles'>Computes quantiles of the gaussian multiscale statistics.</h2><span id='topic+compute_quantiles'></span>

<h3>Description</h3>

<p>Quantiles from the gaussian version of the test
statistics which are used to approximate
the critical values for the multiscale test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_quantiles(
  t_len,
  n_ts = 1,
  grid = NULL,
  ijset = NULL,
  sigma = 1,
  deriv_order = 0,
  sim_runs = 1000,
  probs = seq(0.5, 0.995, by = 0.005),
  correction = TRUE,
  epidem = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_quantiles_+3A_t_len">t_len</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_n_ts">n_ts</code></td>
<td>
<p>Number of time series analyzed. Default is 1.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_grid">grid</code></td>
<td>
<p>Grid of location-bandwidth points as produced by
the function <code><a href="#topic+construct_grid">construct_grid</a></code> or
<code><a href="#topic+construct_weekly_grid">construct_weekly_grid</a></code>, list with
the elements 'gset', 'bws', 'gtype'. If not provided,
then the defalt grid is produced and used.
For the construction of the default grid,
see <code><a href="#topic+construct_grid">construct_grid</a></code>.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_ijset">ijset</code></td>
<td>
<p>A matrix of integers. In case of multiple time series,
we need to know which pairwise comparisons to perform.
This matrix consists of all pairs of indices <code class="reqn">(i, j)</code>
that we want to compare. If not provided, then all
possible pairwise comparison are performed.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_sigma">sigma</code></td>
<td>
<p>Value of <code class="reqn">\sqrt{\sigma^2}</code>. In case of n_ts = 1,
<code class="reqn">\sigma^2</code> denotes the long-run error variance, and
in case of n_ts &gt; 1, <code class="reqn">\sigma^2</code> denotes the
overdispersion parameter.
If not given, then the default is 1.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_deriv_order">deriv_order</code></td>
<td>
<p>In case of a single time series analysed, this parameter
denotes the order of the derivative of the trend
function that is being estimated. Default is 0.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_sim_runs">sim_runs</code></td>
<td>
<p>Number of simulation runs to produce quantiles.
Default is 1000.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_probs">probs</code></td>
<td>
<p>A numeric vector of probability levels <code class="reqn">(1-\alpha)</code>
for which the quantiles are computed.
Default is <code class="reqn">(0.5, 0.505, 0.51, \ldots, 0.995)</code>.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_correction">correction</code></td>
<td>
<p>Logical variable, TRUE (by default) if we are using
<code class="reqn">a_k</code> and <code class="reqn">b_k</code>.</p>
</td></tr>
<tr><td><code id="compute_quantiles_+3A_epidem">epidem</code></td>
<td>
<p>Logical variable, TRUE if we are using
dealing with epidemic time trends. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with 2 rows where the first row contains
the vector of probabilities (probs) and the second
contains corresponding quantiles of the gaussian
statistics distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>compute_quantiles(100)
</code></pre>

<hr>
<h2 id='compute_quantiles_2'>Computes quantiles of the gaussian multiscale statistics.</h2><span id='topic+compute_quantiles_2'></span>

<h3>Description</h3>

<p>Quantiles from the gaussian version of the test
statistics which are used to approximate
the critical values for the multiscale test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_quantiles_2(
  t_len,
  n_ts = 1,
  grid = NULL,
  ijset = NULL,
  sigma = 1,
  deriv_order = 0,
  sim_runs = 1000,
  probs = seq(0.5, 0.995, by = 0.005),
  correction = TRUE,
  epidem = FALSE,
  numCores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_quantiles_2_+3A_t_len">t_len</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_n_ts">n_ts</code></td>
<td>
<p>Number of time series analyzed. Default is 1.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_grid">grid</code></td>
<td>
<p>Grid of location-bandwidth points as produced by
the function <code><a href="#topic+construct_grid">construct_grid</a></code> or
<code><a href="#topic+construct_weekly_grid">construct_weekly_grid</a></code>, list with
the elements 'gset', 'bws', 'gtype'. If not provided,
then the defalt grid is produced and used.
For the construction of the default grid,
see <code><a href="#topic+construct_grid">construct_grid</a></code>.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_ijset">ijset</code></td>
<td>
<p>A matrix of integers. In case of multiple time series,
we need to know which pairwise comparisons to perform.
This matrix consists of all pairs of indices <code class="reqn">(i, j)</code>
that we want to compare. If not provided, then all
possible pairwise comparison are performed.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_sigma">sigma</code></td>
<td>
<p>Value of <code class="reqn">\sqrt{\sigma^2}</code>. In case of n_ts = 1,
<code class="reqn">\sigma^2</code> denotes the long-run error variance, and
in case of n_ts &gt; 1, <code class="reqn">\sigma^2</code> denotes the
overdispersion parameter.
If not given, then the default is 1.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_deriv_order">deriv_order</code></td>
<td>
<p>In case of a single time series analysed, this parameter
denotes the order of the derivative of the trend
function that is being estimated. Default is 0.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_sim_runs">sim_runs</code></td>
<td>
<p>Number of simulation runs to produce quantiles.
Default is 1000.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_probs">probs</code></td>
<td>
<p>A numeric vector of probability levels <code class="reqn">(1-\alpha)</code>
for which the quantiles are computed.
Default is <code class="reqn">(0.5, 0.505, 0.51, \ldots, 0.995)</code>.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_correction">correction</code></td>
<td>
<p>Logical variable, TRUE (by default) if we are using
<code class="reqn">a_k</code> and <code class="reqn">b_k</code>.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_epidem">epidem</code></td>
<td>
<p>Logical variable, TRUE if we are using
dealing with epidemic time trends. Default is FALSE.</p>
</td></tr>
<tr><td><code id="compute_quantiles_2_+3A_numcores">numCores</code></td>
<td>
<p>Integer value used to indicate how many cores are used
while calculating the critical value. Default is NULL,
then the formula used is
<code>round(detectCores() * .70)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with 2 rows where the first row contains
the vector of probabilities (probs) and the second
contains corresponding quantiles of the gaussian
statistics distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>compute_quantiles_2(100, numCores = 2)
</code></pre>

<hr>
<h2 id='compute_statistics'>Calculates the value of the test statistics both for single time series
analysis and multiple time series analysis.</h2><span id='topic+compute_statistics'></span>

<h3>Description</h3>

<p>Calculates the value of the test statistics both for single time series
analysis and multiple time series analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_statistics(
  data,
  sigma = 1,
  sigma_vec = 1,
  n_ts = 1,
  grid = NULL,
  ijset = NULL,
  deriv_order = 0,
  epidem = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_statistics_+3A_data">data</code></td>
<td>
<p>Vector (in case of n_ts = 1) or matrix (in case of
n_ts &gt; 1) that contains (a number of) time series
that needs to be analyzed. In the latter case,
each column of the matrix must contain one time series.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_sigma">sigma</code></td>
<td>
<p>The estimator of the square root of the long-run
variance <code class="reqn">\sigma</code> in case of n_ts = 1,
or the estimator of the overdispersion parameter
<code class="reqn">\sigma</code> in case of n_ts &gt; 1 and epidemic = TRUE.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_sigma_vec">sigma_vec</code></td>
<td>
<p>Vector that consists of estimators of the square root
of the long-run variances <code class="reqn">\sigma_i</code> in case of
n_ts &gt; 1 and epidemic = FALSE.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_n_ts">n_ts</code></td>
<td>
<p>Number of time series analysed. Default is 1.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_grid">grid</code></td>
<td>
<p>Grid of location-bandwidth points as produced by
the functions <code><a href="#topic+construct_grid">construct_grid</a></code> or
<code><a href="#topic+construct_weekly_grid">construct_weekly_grid</a></code>, it is a list with
the elements 'gset', 'bws', 'gtype'. If not provided,
then the defalt grid is used.
For the construction of the default grid,
see <code><a href="#topic+construct_grid">construct_grid</a></code>.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_ijset">ijset</code></td>
<td>
<p>In case of multiple time series (n_ts &gt; 1),
we need to know which pairs of time series to compare.
This matrix consists of all pairs of indices <code class="reqn">(i, j)</code>
that we want to compare. If not provided, then all
possible pairwise comparison are performed.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_deriv_order">deriv_order</code></td>
<td>
<p>In case of a single time series, this denotes the order of
the derivative of the trend that we estimate.
Default is 0.</p>
</td></tr>
<tr><td><code id="compute_statistics_+3A_epidem">epidem</code></td>
<td>
<p>Logical variable, TRUE if we are using
dealing with epidemic time trends. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>In case of n_ts = 1, the function returns a list
with the following elements:
</p>
<table role = "presentation">
<tr><td><code>stat</code></td>
<td>
<p>Value of the multiscale statistics.</p>
</td></tr>
<tr><td><code>gset_with_vals</code></td>
<td>
<p>A matrix that contains the values of the normalised 
kernel averages for each pair of location-bandwidth
with the corresponding location and bandwidth.</p>
</td></tr>
</table>
<p>In case of n_ts &gt; 1, the function returns a list
with the following elements:
</p>
<table role = "presentation">
<tr><td><code>stat</code></td>
<td>
<p>Value of the multiscale statistics.</p>
</td></tr>
<tr><td><code>stat_pairwise</code></td>
<td>
<p>Matrix of the values of the pairwise statistics.</p>
</td></tr>
<tr><td><code>ijset</code></td>
<td>
<p>The matrix that  consists of all pairs of indices
<code class="reqn">(i, j)</code> that we compared. The order of these
pairs corresponds to the order in the list
gset_with_vals.</p>
</td></tr>
<tr><td><code>gset_with_vals</code></td>
<td>
<p>A list of matrices, each matrix corresponding to a 
specific pairwise comparison. The order of the list 
is determined by ijset. Each matrix contains
the values of the normalisedkernel averages
for each pair of location-bandwidth
with the corresponding location and bandwidth.</p>
</td></tr>
</table>

<hr>
<h2 id='construct_grid'>Computes the location-bandwidth grid for the multiscale test.</h2><span id='topic+construct_grid'></span>

<h3>Description</h3>

<p>Computes the location-bandwidth grid for the multiscale test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>construct_grid(t, u_grid = NULL, h_grid = NULL, deletions = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="construct_grid_+3A_t">t</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="construct_grid_+3A_u_grid">u_grid</code></td>
<td>
<p>Vector of location points in the unit interval
<code class="reqn">[0,1]</code>. If NULL, a default grid is used.</p>
</td></tr>
<tr><td><code id="construct_grid_+3A_h_grid">h_grid</code></td>
<td>
<p>Vector of bandwidths, each bandwidth is supposed to lie
in <code class="reqn">(0, 0.5)</code>. If NULL, a default grid is used.</p>
</td></tr>
<tr><td><code id="construct_grid_+3A_deletions">deletions</code></td>
<td>
<p>Logical vector of the length len(u.grid) * len(h.grid).
Each element is either TRUE, which means that
the corresponding location-bandwidth point <code class="reqn">(u, h)</code>
is NOT deleted from the grid, or FALSE, which means that
the corresponding location-bandwidth point <code class="reqn">(u, h)</code>
IS deleted from the grid. Default is NULL
in which case nothing is deleted.
See vignette for the use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table role = "presentation">
<tr><td><code>gset</code></td>
<td>
<p>Matrix of location-bandwidth points <code class="reqn">(u, h)</code>
that remains after deletions, the i-th row gset[i,]
corresponds to the i-th point <code class="reqn">(u,h)</code>.</p>
</td></tr>
<tr><td><code>bws</code></td>
<td>
<p>Vector of bandwidths (after deletions).</p>
</td></tr>
<tr><td><code>lens</code></td>
<td>
<p>Vector of length = length(bws), lens[i] gives
the number of locations in the grid for
the i-th bandwidth level.</p>
</td></tr>
<tr><td><code>gtype</code></td>
<td>
<p>Type of grid that is used, either 'default' or
'non-default'.</p>
</td></tr>
<tr><td><code>gset_full</code></td>
<td>
<p>Matrix of all location-bandwidth pairs <code class="reqn">(u, h)</code>
including deleted ones.</p>
</td></tr>
<tr><td><code>pos_full</code></td>
<td>
<p>Logical vector indicating which points <code class="reqn">(u, h)</code>
have been deleted.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>construct_grid(100)
construct_grid(100, u_grid = seq(from = 0.05, to = 1, by = 0.05),
               h_grid = c(0.1, 0.2, 0.3, 0.4))
</code></pre>

<hr>
<h2 id='construct_weekly_grid'>Computes the location-bandwidth weekly grid for the multiscale test.</h2><span id='topic+construct_weekly_grid'></span>

<h3>Description</h3>

<p>Computes the location-bandwidth weekly grid for the multiscale test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>construct_weekly_grid(t, min_len = 7, nmbr_of_wks = 4)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="construct_weekly_grid_+3A_t">t</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="construct_weekly_grid_+3A_min_len">min_len</code></td>
<td>
<p>Minimal length of the interval considered. The grid then
consists of intervals with lengths min_len,
2 * min_len, 3 * min_len, ... Default is 7, i.e. a week.</p>
</td></tr>
<tr><td><code id="construct_weekly_grid_+3A_nmbr_of_wks">nmbr_of_wks</code></td>
<td>
<p>Number that determines the longest intervals in the grid:
the length of this interval is calculated then as 
min_len * nmbr_of_wks. Default is 4.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table role = "presentation">
<tr><td><code>gset</code></td>
<td>
<p>Matrix of location-bandwidth points <code class="reqn">(u, h)</code>
the i-th row gset[i,] corresponds to the i-th point
<code class="reqn">(u,h)</code>.</p>
</td></tr>
<tr><td><code>bws</code></td>
<td>
<p>Vector of bandwidths.</p>
</td></tr>
<tr><td><code>lens</code></td>
<td>
<p>Vector of length = length(bws), lens[i] gives
the number of locations in the grid for
the i-th bandwidth level.</p>
</td></tr>
<tr><td><code>gtype</code></td>
<td>
<p>Type of grid that is used, always 'default'.</p>
</td></tr>
<tr><td><code>gset_full</code></td>
<td>
<p>Matrix of all location-bandwidth pairs <code class="reqn">(u, h)</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>construct_weekly_grid(100)
construct_weekly_grid(100, min_len = 7, nmbr_of_wks = 2)
</code></pre>

<hr>
<h2 id='corrections'>Computes vector of correction terms for second-stage estimator
of AR parameters as described in Khismatullina, Vogt (2019).</h2><span id='topic+corrections'></span>

<h3>Description</h3>

<p>Computes vector of correction terms for second-stage estimator
of AR parameters as described in Khismatullina, Vogt (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corrections(coefs, var_eta, len)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corrections_+3A_coefs">coefs</code></td>
<td>
<p>Given (estimated) coefficients of the AR time series.</p>
</td></tr>
<tr><td><code id="corrections_+3A_var_eta">var_eta</code></td>
<td>
<p>Variance of the innovation term</p>
</td></tr>
<tr><td><code id="corrections_+3A_len">len</code></td>
<td>
<p>Length of the vector of the corrections</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.         Vector of the corrections terms of length len.
</p>

<hr>
<h2 id='covid'>Number of daily new cases of infections of COVID-19 per country.</h2><span id='topic+covid'></span>

<h3>Description</h3>

<p>Data on the geographic distribution of COVID-19 cases worldwide
(© ECDC [2005-2019])
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("covid")
</code></pre>


<h3>Format</h3>

<p>A matrix with 99 rows and 41 columns. Each column corresponds to
one coutnry, with the name of the country (denoted by three letter) being
the name of the column.
</p>


<h3>Details</h3>

<p>Each entry in the dataset denotes the number of new cases of infection
per day and per country. In order to make the data comparable across
countries, we take the day of the 100th confirmed case in each country as
the starting date t = 1. This way of “normalizing” the data is
common practice (Cohen and Kupferschmidt (2020)).
</p>


<h3>Source</h3>

<p><a href="https://www.ecdc.europa.eu/en">https://www.ecdc.europa.eu/en</a>
</p>

<hr>
<h2 id='emp_acf'>Computes autocovariances at lags 0 to p for the ell-th differences of data.</h2><span id='topic+emp_acf'></span>

<h3>Description</h3>

<p>Computes autocovariances at lags 0 to p for the ell-th differences of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emp_acf(data, ell, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emp_acf_+3A_data">data</code></td>
<td>
<p>Time series for which we calculate autocovariances.</p>
</td></tr>
<tr><td><code id="emp_acf_+3A_ell">ell</code></td>
<td>
<p>Order of differences used.</p>
</td></tr>
<tr><td><code id="emp_acf_+3A_p">p</code></td>
<td>
<p>Maximum lag for the autocovariances</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length (p + 1) that consists of empirical
autocoavariances for the corresponding lag - 1.
</p>

<hr>
<h2 id='estimate_lrv'>Computes estimator of the long-run variance of the error terms.</h2><span id='topic+estimate_lrv'></span>

<h3>Description</h3>

<p>A difference based estimator for the coefficients and
long-run variance in case of a nonparametric regression
model are AR(p).
</p>
<p>Specifically, we assume that we observe <code class="reqn">Y(t)</code> that satisfy
the following equation: </p>
<p style="text-align: center;"><code class="reqn">Y(t) = m(t/T) + \epsilon_t.</code>
</p>

<p>Here, <code class="reqn">m(\cdot)</code> is an unknown function, and the errors
<code class="reqn">\epsilon_t</code> are AR(p) with p known. Specifically, we ler
<code class="reqn">\{\epsilon_t\}</code> be a process of the form
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_t = \sum_{j=1}^p a_j \epsilon_{t-j} + \eta_t,</code>
</p>
 
<p>where <code class="reqn">a_1,a_2,\ldots, a_p</code> are unknown coefficients and
<code class="reqn">\eta_t</code> are i.i.d.\ with <code class="reqn">E[\eta_t] = 0</code> and
<code class="reqn">E[\eta_t^2] = \nu^2</code>.
</p>
<p>This function produces an estimator <code class="reqn">\widehat{\sigma}^2</code>
of the long-run variance 
</p>
<p style="text-align: center;"><code class="reqn">\sigma^2 = \sum_{l=-\infty}^{\infty} cov(\epsilon_0,\epsilon_{l})</code>
</p>

<p>of the error terms, as well as estimators
<code class="reqn">\widehat{a}_1, \ldots, \widehat{a}_p</code> of the coefficients
<code class="reqn">a_1,a_2,\ldots, a_p</code> and an estimator <code class="reqn">\widehat{\nu}^2</code> of 
the innovation variance <code class="reqn">\nu^2</code>.
</p>
<p>The exact estimation procedure as well as description of 
the tuning parameters needed for this estimation can be found
in Khismatullina and Vogt (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_lrv(data, q, r_bar, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_lrv_+3A_data">data</code></td>
<td>
<p>A vector of <code class="reqn">Y(1), Y(2), \ldots, Y(T)</code>.</p>
</td></tr>
<tr><td><code id="estimate_lrv_+3A_q">q</code>, <code id="estimate_lrv_+3A_r_bar">r_bar</code></td>
<td>
<p>Tuning parameters.</p>
</td></tr>
<tr><td><code id="estimate_lrv_+3A_p">p</code></td>
<td>
<p>AR order of the error terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table role = "presentation">
<tr><td><code>lrv</code></td>
<td>
<p>Estimator of the long run variance of the error terms
<code class="reqn">\sigma^2</code>.</p>
</td></tr>
<tr><td><code>ahat</code></td>
<td>
<p>Vector of length p of estimated AR coefficients
<code class="reqn">a_1,a_2,\ldots, a_p</code>.</p>
</td></tr>
<tr><td><code>vareta</code></td>
<td>
<p>Estimator of the variance of the innovation term <code class="reqn">\nu^2</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Khismatullina M., Vogt M. Multiscale inference and long-run
variance estimation in non-parametric regression with
time series errors //Journal of the Royal Statistical Society:
Series B (Statistical Methodology). - 2020.
</p>

<hr>
<h2 id='multiscale_test'>Carries out the multiscale test given that the values the estimatates of
long-run variance have already been computed.</h2><span id='topic+multiscale_test'></span>

<h3>Description</h3>

<p>Carries out the multiscale test given that the values the estimatates of
long-run variance have already been computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiscale_test(
  data,
  sigma = 1,
  sigma_vec = 1,
  n_ts = 1,
  grid = NULL,
  ijset = NULL,
  alpha = 0.05,
  sim_runs = 1000,
  deriv_order = 0,
  correction = TRUE,
  epidem = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiscale_test_+3A_data">data</code></td>
<td>
<p>Vector (in case of n_ts = 1) or matrix (in case of
n_ts &gt; 1) that contains (a number of) time series
that needs to be analyzed. In the latter case,
each column of the matrix must contain one time series.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_sigma">sigma</code></td>
<td>
<p>The estimator of the square root of the long-run
variance <code class="reqn">\sigma</code> in case of n_ts = 1,
or the estimator of the overdispersion parameter
<code class="reqn">\sigma</code> in case of n_ts &gt; 1 and epidemic = TRUE.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_sigma_vec">sigma_vec</code></td>
<td>
<p>Vector that consists of estimators of the square root
of the long-run variances <code class="reqn">\sigma_i</code> in case of
n_ts &gt; 1 and epidemic = FALSE.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_n_ts">n_ts</code></td>
<td>
<p>Number of time series analysed. Default is 1.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_grid">grid</code></td>
<td>
<p>Grid of location-bandwidth points as produced by
the functions <code><a href="#topic+construct_grid">construct_grid</a></code> or
<code><a href="#topic+construct_weekly_grid">construct_weekly_grid</a></code>, it is a list with
the elements 'gset', 'bws', 'gtype'. If not provided,
then the defalt grid is used.
For the construction of the default grid,
see <code><a href="#topic+construct_grid">construct_grid</a></code>.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_ijset">ijset</code></td>
<td>
<p>In case of multiple time series (n_ts &gt; 1),
we need to know which pairs of time series to compare.
This matrix consists of all pairs of indices <code class="reqn">(i, j)</code>
that we want to compare. If not provided, then all
possible pairwise comparison are performed.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_alpha">alpha</code></td>
<td>
<p>Significance level. Default is <code class="reqn">0.05</code>.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_sim_runs">sim_runs</code></td>
<td>
<p>Number of simulation runs to produce quantiles.
Default is 1000.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_deriv_order">deriv_order</code></td>
<td>
<p>In case of a single time series, this denotes the order of
the derivative of the trend that we estimate.
Default is 0.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_correction">correction</code></td>
<td>
<p>Logical variable, TRUE (by default) is we are using
<code class="reqn">a_k</code> and <code class="reqn">b_k</code>.</p>
</td></tr>
<tr><td><code id="multiscale_test_+3A_epidem">epidem</code></td>
<td>
<p>Logical variable, TRUE if we are using
dealing with epidemic time trends. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>In case of n_ts = 1, the function returns a list
with the following elements:
</p>
<table role = "presentation">
<tr><td><code>testing_result</code></td>
<td>
<p>A string that contains the result of the testing:
either the null hypothesis is rejected or not,
what is the confidence level and what is value of
the test statistic.</p>
</td></tr>
<tr><td><code>quant</code></td>
<td>
<p>Quantile that was used for testing calculated from
the Gaussian distribution.</p>
</td></tr>
<tr><td><code>statistics</code></td>
<td>
<p>Value of the multiscale statistics.</p>
</td></tr>
<tr><td><code>test_matrix</code></td>
<td>
<p>Matrix of the test results for the multiscale test
defined in Khismatullina and Vogt (2019).
The matrix is coded as follows:
</p>

<ul>
<li><p> test_matrix[i,j] = -1: test rejects the null for the
j-th location <code class="reqn">u</code> and the i-th bandwidth <code class="reqn">h</code> and
indicates a decrease in the trend;
</p>
</li>
<li><p> test_matrix[i,j] = 0: test does not reject the null
for the j-th location <code class="reqn">u</code> and the i-th
bandwidth <code class="reqn">h</code>;
</p>
</li>
<li><p> test_matrix[i,j] = 1:  test rejects the null for the
j-th location <code class="reqn">u</code> and the i-th bandwidth <code class="reqn">h</code> and
indicates an increase in the trend;
</p>
</li>
<li><p> test_matrix[i,j] = 2: no test is carried out at j-th
location <code class="reqn">u</code> and i-th bandwidth <code class="reqn">h</code> (because
the point <code class="reqn">(u, h)</code> is excluded from the grid
as specified by the 'deletions' option
in the function <code><a href="#topic+construct_grid">construct_grid</a></code>)</p>
</li></ul>
<p>.
</p>
</td></tr>
<tr><td><code>gset_with_vals</code></td>
<td>
<p>A matrix that contains the values of the normalised 
kernel averages and test results for each pair
of location-bandwidth
with the corresponding location and bandwidth.</p>
</td></tr>
</table>
<p>In case of n_ts &gt; 1, the function returns a list
with the following elements:
</p>
<table role = "presentation">
<tr><td><code>quant</code></td>
<td>
<p>Quantile that was used for testing calculated from
the gaussian distribution.</p>
</td></tr>
<tr><td><code>statistics</code></td>
<td>
<p>Value of the multiscale statistics.</p>
</td></tr>
<tr><td><code>stat_pairwise</code></td>
<td>
<p>Matrix of the values of the pairwise statistics.</p>
</td></tr>
<tr><td><code>ijset</code></td>
<td>
<p>The matrix that  consists of all pairs of indices
<code class="reqn">(i, j)</code> that we compared. The order of these
pairs corresponds to the order in the list
gset_with_vals.</p>
</td></tr>
<tr><td><code>gset_with_vals</code></td>
<td>
<p>A list of matrices, each matrix corresponding to a 
specific pairwise comparison. The order of the list 
is determined by ijset. Each matrix contains
the values of the normalisedkernel averages
for each pair of location-bandwidth
with the corresponding location and bandwidth.</p>
</td></tr>
</table>

<hr>
<h2 id='plot_sizer_map'>Plots SiZer map from the test results of the multiscale testing procedure.</h2><span id='topic+plot_sizer_map'></span>

<h3>Description</h3>

<p>Plots SiZer map from the test results of the multiscale testing procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_sizer_map(
  u_grid,
  h_grid,
  test_results,
  plot_title = NA,
  greyscale = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_sizer_map_+3A_u_grid">u_grid</code></td>
<td>
<p>Vector of location points in the unit interval <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="plot_sizer_map_+3A_h_grid">h_grid</code></td>
<td>
<p>Vector of bandwidths from <code class="reqn">(0,0.5)</code>.</p>
</td></tr>
<tr><td><code id="plot_sizer_map_+3A_test_results">test_results</code></td>
<td>
<p>Matrix of test results created by
<code><a href="#topic+multiscale_test">multiscale_test</a></code>.</p>
</td></tr>
<tr><td><code id="plot_sizer_map_+3A_plot_title">plot_title</code></td>
<td>
<p>Title of the plot. Default is NA and no title is written.</p>
</td></tr>
<tr><td><code id="plot_sizer_map_+3A_greyscale">greyscale</code></td>
<td>
<p>Whether SiZer map is plotted in grey scale.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot_sizer_map_+3A_...">...</code></td>
<td>
<p>Any further options to be passed to the image function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for plotting a SiZer map.
</p>

<hr>
<h2 id='select_order'>Calculates different information criterions for a single time series
or multiple time series with AR(<code class="reqn">p</code>) errors
based on the long-run variance estimator(s) for a range of tuning
parameters and different orders <code class="reqn">p</code>.</h2><span id='topic+select_order'></span>

<h3>Description</h3>

<p>This function fits AR(1), ... AR(9) models for all
given time series and calculates different information
criterions (FPE, AIC, AICC, SIC, HQ) for each of these fits.
The result is the best fit in terms of minimizing
the infromation criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_order(data, q = NULL, r = 5:15)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_order_+3A_data">data</code></td>
<td>
<p>One or a number of time series in a matrix. Column names
of the matrix should be reasonable</p>
</td></tr>
<tr><td><code id="select_order_+3A_q">q</code></td>
<td>
<p>A vector of integers that consisits of different tuning
parameters to analyse. If not supplied, q is taken to be
<code class="reqn">[2\log{T}]:([2\sqrt{T}] + 1)</code>.</p>
</td></tr>
<tr><td><code id="select_order_+3A_r">r</code></td>
<td>
<p>A vector of integers that consisits of different tuning
parameters r_bar for <code><a href="#topic+estimate_lrv">estimate_lrv</a></code>.
If not supplied, <code class="reqn">r = 5, \ldots, 15</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with a number of elements:
</p>
<table role = "presentation">
<tr><td><code>orders</code></td>
<td>
<p>A vector of chosen orders of length equal to the number
of time series.
For each time series the order is calculated as
<code class="reqn">\max(which.min(FPE), ... which.min(HQ))</code></p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Matrices with the orders that were selected
(among <code class="reqn">1, \ldots, 9</code>) for each information criterion.
One matrix for each time series.</p>
</td></tr>
</table>

<hr>
<h2 id='temperature'>Hadley Centre Central England Temperature (HadCET) dataset,
Monthly Mean Central England Temperature (Degrees C)</h2><span id='topic+temperature'></span>

<h3>Description</h3>

<p>The CET dataset is the longest instrumental record of temperature
in the world. It contains the mean monthly surface air temperatures
(in degrees Celsius) from the year 1659 to the present. These monthly
temperatures are representative of a roughly triangular area of
the United Kingdom enclosed by Lancashire, London and Bristol.
Manley (1953, 1974) compiled most of the monthly series,
covering 1659 to 1973.  These data were updated to 1991 by
Parker et al (1992). It is now kept up to date by
the Climate Data Monitoring section of the Hadley Centre, Met Office.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("temperature")
</code></pre>


<h3>Format</h3>

<p>A numeric vector of length 359.
</p>


<h3>Details</h3>

<p>Since 1974 the data have been adjusted to allow for urban warming:
currently a correction of -0.2 C is applied to mean temperatures.
CET datasets are freely available for use under Open Government License.
</p>


<h3>Source</h3>

<p><a href="https://www.metoffice.gov.uk/hadobs/hadcet/">https://www.metoffice.gov.uk/hadobs/hadcet/</a>
</p>

<hr>
<h2 id='variance_eta'>Computes variance of AR(p) innovation terms eta.</h2><span id='topic+variance_eta'></span>

<h3>Description</h3>

<p>Computes variance of AR(p) innovation terms eta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variance_eta(data, coefs, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variance_eta_+3A_data">data</code></td>
<td>
<p>Time series.</p>
</td></tr>
<tr><td><code id="variance_eta_+3A_coefs">coefs</code></td>
<td>
<p>Estimated coefficients.</p>
</td></tr>
<tr><td><code id="variance_eta_+3A_p">p</code></td>
<td>
<p>AR order of the time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Variance of the innovation term
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
