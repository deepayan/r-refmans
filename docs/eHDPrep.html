<!DOCTYPE html><html><head><title>Help for package eHDPrep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {eHDPrep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#eHDPrep-package'><p>'eHDPrep': Quality Control and Semantic Enrichment of Datasets</p></a></li>
<li><a href='#apply_quality_ctrl'><p>Apply quality control measures to a dataset</p></a></li>
<li><a href='#assess_completeness'><p>Assess completeness of a dataset</p></a></li>
<li><a href='#assess_quality'><p>Assess quality of a dataset</p></a></li>
<li><a href='#assume_var_classes'><p>Assume variable classes in data</p></a></li>
<li><a href='#cellspec_lgl'><p>Kable logical data highlighting</p></a></li>
<li><a href='#compare_completeness'><p>Compare Completeness between Datasets</p></a></li>
<li><a href='#compare_info_content'><p>Information Content Comparison Table</p></a></li>
<li><a href='#compare_info_content_plt'><p>Information Content Comparison Plot</p></a></li>
<li><a href='#completeness_heatmap'><p>Completeness Heatmap</p></a></li>
<li><a href='#count_compare'><p>Compare unique values before and after data modification</p></a></li>
<li><a href='#discrete.mi'><p>Calculate mutual information of a matrix of discrete values</p></a></li>
<li><a href='#distant_neg_val'><p>Find highly distant value for data frame</p></a></li>
<li><a href='#edge_tbl_to_graph'><p>Convert edge table to tidygraph graph</p></a></li>
<li><a href='#encode_as_num_mat'><p>Convert data frame to numeric matrix</p></a></li>
<li><a href='#encode_bin_cat_vec'><p>Encode a categorical vector with binary categories</p></a></li>
<li><a href='#encode_binary_cats'><p>Encode categorical variables as binary factors</p></a></li>
<li><a href='#encode_cats'><p>Encode categorical variables using one-hot encoding.</p></a></li>
<li><a href='#encode_genotype_vec'><p>Encode a genotype/SNP vector</p></a></li>
<li><a href='#encode_genotypes'><p>Encode genotype/SNP variables in data frame</p></a></li>
<li><a href='#encode_ordinals'><p>Encode ordinal variables</p></a></li>
<li><a href='#entropy'><p>Calculate Entropy of a Vector</p></a></li>
<li><a href='#exact.kde'><p>Exact kernel density estimation</p></a></li>
<li><a href='#example_data'><p>Example data for eHDPrep</p></a></li>
<li><a href='#example_edge_tbl'><p>Example ontology as an edge table for semantic enrichment</p></a></li>
<li><a href='#example_mapping_file'><p>Example mapping file for semantic enrichment</p></a></li>
<li><a href='#example_ontology'><p>Example ontology as a network graph for semantic enrichment</p></a></li>
<li><a href='#export_dataset'><p>Export data to delimited file</p></a></li>
<li><a href='#extract_freetext'><p>Extract information from free text</p></a></li>
<li><a href='#geometric.mean'><p>Geometric mean</p></a></li>
<li><a href='#identify_inconsistency'><p>Identify inconsistencies in a dataset</p></a></li>
<li><a href='#import_dataset'><p>Import data into 'R'</p></a></li>
<li><a href='#import_var_classes'><p>Import corrected variable classes</p></a></li>
<li><a href='#information_content_contin'><p>Calculate Information Content (Continuous Variable)</p></a></li>
<li><a href='#information_content_discrete'><p>Calculate Information Content (Discrete Variable)</p></a></li>
<li><a href='#join_vars_to_ontol'><p>Join Mapping Table to Ontology Network Graph</p></a></li>
<li><a href='#max_catchNAs'><p>Find maximum of vector safely</p></a></li>
<li><a href='#mean_catchNAs'><p>Find mean of vector safely</p></a></li>
<li><a href='#merge_cols'><p>Merge columns in data frame</p></a></li>
<li><a href='#metavariable_agg'><p>Aggregate Data by Metavariable</p></a></li>
<li><a href='#metavariable_info'><p>Compute Metavariable Information</p></a></li>
<li><a href='#metavariable_variable_descendants'><p>Extract metavariables' descendant variables</p></a></li>
<li><a href='#mi_content_discrete'><p>Calculate Mutual Information Content</p></a></li>
<li><a href='#min_catchNAs'><p>Find minimum of vector safely</p></a></li>
<li><a href='#mod_track'><p>Data modification tracking</p></a></li>
<li><a href='#node_IC_zhou'><p>Calculate Node Information Content (Zhou et al 2008 method)</p></a></li>
<li><a href='#normalize'><p>Min max normalization</p></a></li>
<li><a href='#nums_to_NA'><p>Replace numeric values in numeric columns with NA</p></a></li>
<li><a href='#onehot_vec'><p>One hot encode a vector</p></a></li>
<li><a href='#ordinal_label_levels'><p>Extract labels and levels of ordinal variables in a dataset</p></a></li>
<li><a href='#plot_completeness'><p>Plot Completeness of a Dataset</p></a></li>
<li><a href='#prod_catchNAs'><p>Find product of vector safely</p></a></li>
<li><a href='#report_var_mods'><p>Track changes to dataset variables</p></a></li>
<li><a href='#review_quality_ctrl'><p>Review Quality Control</p></a></li>
<li><a href='#row_completeness'><p>Calculate Row Completeness in a Data Frame</p></a></li>
<li><a href='#semantic_enrichment'><p>Semantic enrichment</p></a></li>
<li><a href='#skipgram_append'><p>Append Skipgram Presence Variables to Dataset</p></a></li>
<li><a href='#skipgram_freq'><p>Report Skipgram Frequency</p></a></li>
<li><a href='#skipgram_identify'><p>Identify Neighbouring Words (Skipgrams) in a free-text vector</p></a></li>
<li><a href='#strings_to_NA'><p>Replace values in non-numeric columns with NA</p></a></li>
<li><a href='#sum_catchNAs'><p>Sum vector safely for semantic enrichment</p></a></li>
<li><a href='#validate_consistency_tbl'><p>Validate internal consistency table</p></a></li>
<li><a href='#validate_mapping_tbl'><p>Validate mapping table for semantic enrichment</p></a></li>
<li><a href='#validate_ontol_nw'><p>Validate ontology network for semantic enrichment</p></a></li>
<li><a href='#variable_completeness'><p>Calculate Variable Completeness in a Data Frame</p></a></li>
<li><a href='#variable_entropy'><p>Calculate Entropy of Each Variable in Data Frame</p></a></li>
<li><a href='#variable.bw.kde'><p>Variable bandwidth Kernel Density Estimation</p></a></li>
<li><a href='#warn_missing_dots'><p>Missing dots warning</p></a></li>
<li><a href='#zero_entropy_variables'><p>Identify variables with zero entropy</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Quality Control and Semantic Enrichment of Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ian Overton &lt;I.Overton@qub.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A tool for the preparation and enrichment of health datasets for analysis (Toner et al. (2023) &lt;<a href="https://doi.org/10.1093%2Fgigascience%2Fgiad030">doi:10.1093/gigascience/giad030</a>&gt;). Provides functionality for assessing data quality and for improving the reliability and machine interpretability of a dataset. 
     'eHDPrep' also enables semantic enrichment of a dataset where metavariables are discovered from the relationships between input variables determined from user-provided ontologies.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/overton-group/eHDPrep">https://github.com/overton-group/eHDPrep</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/overton-group/eHDPrep/issues">https://github.com/overton-group/eHDPrep/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2 (&ge; 3.3.3), dplyr (&ge; 1.1.0), forcats (&ge; 0.5.0),
stringr (&ge; 1.4.0), purrr (&ge; 0.3.4), tidyr (&ge; 1.1.2),
kableExtra (&ge; 1.3.1), magrittr (&ge; 2.0.1), tibble (&ge; 3.0.5),
scales (&ge; 1.1.1), rlang (&ge; 0.4.10), quanteda (&ge; 2.1.2), tm
(&ge; 0.7-8), pheatmap (&ge; 1.0.12), igraph (&ge; 1.2.6), tidygraph
(&ge; 1.2.0), readr (&ge; 1.4.0), readxl (&ge; 1.3.1), knitr (&ge;
1.31)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.1.0), ggraph (&ge; 2.0.5)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-05 11:55:44 UTC; tom</td>
</tr>
<tr>
<td>Author:</td>
<td>Tom Toner <a href="https://orcid.org/0000-0001-8059-5822"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Ian Overton <a href="https://orcid.org/0000-0003-1158-8527"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-05 18:20:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='eHDPrep-package'>'eHDPrep': Quality Control and Semantic Enrichment of Datasets</h2><span id='topic+eHDPrep'></span><span id='topic+eHDPrep-package'></span>

<h3>Description</h3>

<p>A tool for the preparation and enrichment of health datasets for analysis
(Toner <em>et al.</em> (2023) &lt;<a href="https://doi.org/10.1093/gigascience/giad030">doi:10.1093/gigascience/giad030</a>&gt;). Provides
functionality for assessing data quality and for improving the reliability
and machine interpretability of a dataset. 'eHDPrep' also enables semantic
enrichment of a dataset where metavariables are discovered from the
relationships between input variables determined from user-provided
ontologies.
</p>


<h3>Maintainer</h3>

<p>Ian Overton <a href="mailto:I.Overton@qub.ac.uk">I.Overton@qub.ac.uk</a>
(<a href="https://orcid.org/0000-0003-1158-8527">https://orcid.org/0000-0003-1158-8527</a>)
</p>


<h3>Author(s)</h3>

<p>Tom Toner <a href="mailto:ttoner03@qub.ac.uk">ttoner03@qub.ac.uk</a>
(<a href="https://orcid.org/0000-0001-8059-5822">https://orcid.org/0000-0001-8059-5822</a>), Ian Overton
<a href="mailto:I.Overton@qub.ac.uk">I.Overton@qub.ac.uk</a> (<a href="https://orcid.org/0000-0003-1158-8527">https://orcid.org/0000-0003-1158-8527</a>)
</p>


<h3>References</h3>

<p>Tom M Toner and others, Strategies and techniques for quality
control and semantic enrichment with multimodal data: a case study in
colorectal cancer with eHDPrep, GigaScience, Volume 12, 2023, giad030,
<a href="https://doi.org/10.1093/gigascience/giad030">doi:10.1093/gigascience/giad030</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/overton-group/eHDPrep">https://github.com/overton-group/eHDPrep</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/overton-group/eHDPrep/issues">https://github.com/overton-group/eHDPrep/issues</a>
</p>
</li></ul>


<hr>
<h2 id='apply_quality_ctrl'>Apply quality control measures to a dataset</h2><span id='topic+apply_quality_ctrl'></span>

<h3>Description</h3>

<p>The primary high level function for quality control. Applies several quality
control functions in sequence to input data frame (see Details for individual
functions).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply_quality_ctrl(
  data,
  id_var,
  class_tbl,
  bin_cats = NULL,
  min_freq = 1,
  to_numeric_matrix = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply_quality_ctrl_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="apply_quality_ctrl_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted  expression which corresponds to a variable (column) in
<code>data</code> which identifies each row (sample).</p>
</td></tr>
<tr><td><code id="apply_quality_ctrl_+3A_class_tbl">class_tbl</code></td>
<td>
<p>data frame such as the output tibble from
<code><a href="#topic+assume_var_classes">assume_var_classes</a></code> followed by
<code><a href="#topic+import_var_classes">import_var_classes</a></code>.</p>
</td></tr>
<tr><td><code id="apply_quality_ctrl_+3A_bin_cats">bin_cats</code></td>
<td>
<p>Optional named vector of user-defined values for binary
values using <code>binary_label_1 = binary_label_2</code> syntax (e.g.
<code>c("No" = "Yes")</code> would assign level 1 to &quot;No&quot; and 2 to &quot;Yes&quot;). See
<code><a href="#topic+encode_binary_cats">encode_binary_cats</a></code> for defaults. Applied to variables (columns)
labelled &quot;character&quot; or &quot;factor&quot; in <code>class_tbl</code>.</p>
</td></tr>
<tr><td><code id="apply_quality_ctrl_+3A_min_freq">min_freq</code></td>
<td>
<p>Minimum frequency of occurrence
<code><a href="#topic+extract_freetext">extract_freetext</a></code> will use to extract groups of proximal
words in free-text from variables (columns) labelled &quot;freetext&quot; in <code>class_tbl</code>.</p>
</td></tr>
<tr><td><code id="apply_quality_ctrl_+3A_to_numeric_matrix">to_numeric_matrix</code></td>
<td>
<p>Should QC'ed data be converted to a numeric matrix?
Default: FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The wrapped functions are applied in the following order:
</p>

<ol>
<li><p> Standardise missing values (<code><a href="#topic+strings_to_NA">strings_to_NA</a></code>)
</p>
</li>
<li><p> Encode binary categorical variables (columns) (<code><a href="#topic+encode_binary_cats">encode_binary_cats</a></code>)
</p>
</li>
<li><p> Encode (specific) ordinal variables (columns)(<code><a href="#topic+encode_ordinals">encode_ordinals</a></code>)
</p>
</li>
<li><p> Encode genotype variables (<code><a href="#topic+encode_genotypes">encode_genotypes</a></code>)
</p>
</li>
<li><p> Extract information from free text variables (columns) (<code><a href="#topic+extract_freetext">extract_freetext</a></code>)
</p>
</li>
<li><p> Encode non-binary categorical variables (columns) (<code><a href="#topic+encode_cats">encode_cats</a></code>)
</p>
</li>
<li><p> Encode output as numeric matrix (optional, <code><a href="#topic+encode_as_num_mat">encode_as_num_mat</a></code>)
</p>
</li></ol>

<p><code>class_tbl</code> is used to apply the above functions to the appropriate variables (columns).
</p>


<h3>Value</h3>

<p><code>data</code> with several QC measures applied.
</p>


<h3>See Also</h3>

<p>Other high level functionality: 
<code><a href="#topic+assess_quality">assess_quality</a>()</code>,
<code><a href="#topic+review_quality_ctrl">review_quality_ctrl</a>()</code>,
<code><a href="#topic+semantic_enrichment">semantic_enrichment</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
require(tibble)

# create an example class_tbl object
# note that diabetes_type is classes as ordinal and is not modified as its
# levels are not pre-coded
tibble::tribble(~"var", ~"datatype",
"patient_id", "id",
"tumoursize", "numeric",
"t_stage", "ordinal_tstage",
"n_stage", "ordinal_nstage",
"diabetes", "factor",
"diabetes_type", "ordinal",
"hypertension", "factor",
"rural_urban", "factor",
"marital_status", "factor",
"SNP_a", "genotype",
"SNP_b", "genotype",
"free_text", "freetext") -&gt; data_types

data_QC &lt;- apply_quality_ctrl(example_data, patient_id, data_types, 
   bin_cats =c("No" = "Yes", "rural" = "urban"),  min_freq = 0.6)
</code></pre>

<hr>
<h2 id='assess_completeness'>Assess completeness of a dataset</h2><span id='topic+assess_completeness'></span>

<h3>Description</h3>

<p>Assesses and visualises completeness of the input data across both rows (samples)
and columns (variables).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assess_completeness(data, id_var, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assess_completeness_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="assess_completeness_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted  expression which corresponds to a variable (column) in
<code>data</code> which identifies each row (sample).</p>
</td></tr>
<tr><td><code id="assess_completeness_+3A_plot">plot</code></td>
<td>
<p>Should plots be rendered when function is run? (Default: TRUE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a list of completeness assessments:
</p>

<dl>
<dt>variable_completeness</dt><dd><p>A tibble detailing completeness of variables (columns)
(via <code><a href="#topic+variable_completeness">variable_completeness</a></code>).</p>
</dd>
<dt>row_completeness</dt><dd><p>A tibble detailing completeness of rows (via
<code><a href="#topic+row_completeness">row_completeness</a></code>).</p>
</dd>
<dt>completeness_plot</dt><dd><p>A plot of row and variable (column) completeness (via
<code><a href="#topic+plot_completeness">plot_completeness</a></code>).</p>
</dd>
<dt>completeness_heatmap</dt><dd><p>A clustered heatmap of cell completeness (via
<code><a href="#topic+completeness_heatmap">completeness_heatmap</a></code>).</p>
</dd>
<dt>plot_completeness_heatmap</dt><dd><p>A function which creates a clean canvas before 
plotting the completeness heatmap.</p>
</dd>
</dl>



<h3>Value</h3>

<p>list of completeness tibbles and plots
</p>


<h3>See Also</h3>

<p>Other measures of completeness: 
<code><a href="#topic+compare_completeness">compare_completeness</a>()</code>,
<code><a href="#topic+completeness_heatmap">completeness_heatmap</a>()</code>,
<code><a href="#topic+plot_completeness">plot_completeness</a>()</code>,
<code><a href="#topic+row_completeness">row_completeness</a>()</code>,
<code><a href="#topic+variable_completeness">variable_completeness</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
res &lt;- assess_completeness(example_data, patient_id)

# variable completeness table
res$variable_completeness

# row completeness table
res$row_completeness

# show completeness of rows and variables as a bar plot
res$completeness_plot

# show dataset completeness in a clustered heatmap
# (this is similar to res$completeness_heatmap but ensures a blank canvas is first created)
res$plot_completeness_heatmap(res)

</code></pre>

<hr>
<h2 id='assess_quality'>Assess quality of a dataset</h2><span id='topic+assess_quality'></span>

<h3>Description</h3>

<p>Provides information on the quality of a dataset. Assesses dataset's
completeness, internal consistency, and entropy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assess_quality(data, id_var, consis_tbl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assess_quality_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="assess_quality_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted  expression which corresponds to a variable (column) in
<code>data</code> which identifies each row (sample).</p>
</td></tr>
<tr><td><code id="assess_quality_+3A_consis_tbl">consis_tbl</code></td>
<td>
<p>data frame or tibble containing information on internal
consistency rules (see &quot;Consistency Table Requirements&quot; section)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wraps several quality assessment functions from <code>eHDPrep</code>
and returns a nested list with the following structure:
</p>

<dl>
<dt>completeness</dt><dd><p>- A list of completeness assessments:
</p>

<ol>
<li><p> Tibble of variable (column) completeness (via <code><a href="#topic+variable_completeness">variable_completeness</a></code>)
</p>
</li>
<li><p> Tibble of row (sample) completeness (via <code><a href="#topic+row_completeness">row_completeness</a></code>)
</p>
</li>
<li><p> Plot of row and variable completeness (via <code><a href="#topic+plot_completeness">plot_completeness</a></code>)
</p>
</li>
<li><p> Completeness heatmap (via <code><a href="#topic+completeness_heatmap">completeness_heatmap</a></code>)
</p>
</li>
<li><p> A function which creates a clean canvas before  plotting the completeness heatmap.
</p>
</li></ol>

</dd>
<dt>internal_inconsistency</dt><dd><p>- Tibble of internal inconsistencies, if any
are present and if a consistency table is supplied (via
<code><a href="#topic+identify_inconsistency">identify_inconsistency</a></code>).</p>
</dd>
<dt>vars_with_zero_entropy</dt><dd><p>- Names of variables (columns) with zero entropy (via
<code><a href="#topic+zero_entropy_variables">zero_entropy_variables</a></code>)</p>
</dd>
</dl>



<h3>Value</h3>

<p>Nested list of quality measurements
</p>


<h3>Consistency Table Requirements</h3>

<p>Table must have exactly five character columns.
The columns should be ordered according to the list below which describes the
values of each column:
</p>

<ol>
<li><p> First column name of data values that will be subject to 
consistency checking. String. Required.
</p>
</li>
<li><p> Second column name of data values that will be subject to 
consistency checking. String. Required.
</p>
</li>
<li><p> Logical test to compare columns one and two. One of: &quot;&gt;&quot;,&quot;&gt;=&quot;,
&quot;&lt;&quot;,&quot;&lt;=&quot;,&quot;==&quot;, &quot;!=&quot;. String. Optional if columns 4 and 5 have non-<code>NA</code> values.
</p>
</li>
<li><p> Either a single character string or a colon-separated range of
numbers which should only appear in column A. Optional if column 3 has a
non-<code>NA</code> value.
</p>
</li>
<li><p> Either a single character string or a colon-separated range of
numbers which should only appear in column B given the value/range
specified in column 4. Optional if column 3 has a non-<code>NA</code> value.
</p>
</li></ol>

<p>Each row should detail one test to make.
Therefore, either column 3 or columns 4 and 5 must contain non-<code>NA</code>
values.
</p>


<h3>See Also</h3>

<p>Other high level functionality: 
<code><a href="#topic+apply_quality_ctrl">apply_quality_ctrl</a>()</code>,
<code><a href="#topic+review_quality_ctrl">review_quality_ctrl</a>()</code>,
<code><a href="#topic+semantic_enrichment">semantic_enrichment</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># general example
data(example_data)
res &lt;- assess_quality(example_data, patient_id)

# example of internal consistency checks on more simple dataset
# describing bean counts
require(tibble)

# creating `data`:
beans &lt;- tibble::tibble(red_beans = 1:15,
blue_beans = 1:15,
total_beans = 1:15*2,
red_bean_summary = c(rep("few_beans",9), rep("many_beans",6)))

# creating `consis_tbl`
bean_rules &lt;- tibble::tribble(~varA, ~varB, ~lgl_test, ~varA_boundaries, ~varB_boundaries,
"red_beans", "blue_beans", "==", NA, NA,
"red_beans", "total_beans", "&lt;=", NA,NA,
"red_beans", "red_bean_summary", NA, "1:9", "few_beans",
"red_beans", "red_bean_summary", NA, "10:15", "many_beans")

# add some inconsistencies
beans[1, "red_bean_summary"] &lt;- "many_beans"
beans[1, "red_beans"] &lt;- 10

res &lt;- assess_quality(beans, consis_tbl = bean_rules)

# variable completeness table
res$completeness$variable_completeness

# row completeness table
res$completeness$row_completeness

# show completeness of rows and variables as a bar plot
res$completeness$completeness_plot

# show dataset completeness in a clustered heatmap
res$completeness$plot_completeness_heatmap(res$completeness)

# show any internal inconsistencies
res$internal_inconsistency

# show any variables with zero entropy
res$vars_with_zero_entropy
</code></pre>

<hr>
<h2 id='assume_var_classes'>Assume variable classes in data</h2><span id='topic+assume_var_classes'></span>

<h3>Description</h3>

<p>Classes/data types of data variables are assumed with this function and
exported to a .csv file for amendment. Any incorrect classes can then be
corrected and imported using <code><a href="#topic+import_var_classes">import_var_classes</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assume_var_classes(data, out_file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assume_var_classes_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="assume_var_classes_+3A_out_file">out_file</code></td>
<td>
<p>file where variables and their assumed classes are stored for
user verification.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Writes a .csv file containing the variables and their assumed 
data types / classes.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+import_var_classes">import_var_classes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example below assumes incorrectly for several variables
tmp = tempfile(fileext = ".csv")
data(example_data)
assume_var_classes(example_data, tmp)
</code></pre>

<hr>
<h2 id='cellspec_lgl'>Kable logical data highlighting</h2><span id='topic+cellspec_lgl'></span>

<h3>Description</h3>

<p>Adds colour highlighting to cell values if they are encoded as logical
values. Output should then be passed to <code>knitr</code>'s <code>kable</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cellspec_lgl(.data, rg = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cellspec_lgl_+3A_.data">.data</code></td>
<td>
<p>Table to be highlighted.</p>
</td></tr>
<tr><td><code id="cellspec_lgl_+3A_rg">rg</code></td>
<td>
<p>Should red and green be used for <code>TRUE</code> and <code>FALSE</code> values, respectively? If FALSE (default), colour-blind-friendly colours are applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is useful for identifying the encoding used in a value (e.g. the
difference between the string &quot;TRUE&quot; and truth value of logic <code>TRUE</code>).
This highlighting can also be useful when visually assessing cell values in
a table. The colour naming format (HTML or LaTeX) is automatically detected.
There are four cell types considered:
</p>

<ol>
<li><p> non-logical cells are coloured black)
</p>
</li>
<li><p><code>TRUE</code> cells are coloured red (default) or green if <code>rg</code>
is <code>TRUE</code>
</p>
</li>
<li><p><code>FALSE</code> cells are coloured cyan (default) or red if <code>rg</code>
is <code>TRUE</code>
</p>
</li>
<li><p><code>NA</code> cells are coloured gray
</p>
</li></ol>

<p>Note: When passed to <code>kable()</code>, the <code>escape</code> parameter should be
<code>FALSE</code> for colours to be rendered correctly.
</p>


<h3>Value</h3>

<p>Table with cell colours specified.
</p>


<h3>See Also</h3>

<p><code><a href="knitr.html#topic+kable">kable</a></code> <code><a href="kableExtra.html#topic+cell_spec">cell_spec</a></code>
</p>

<hr>
<h2 id='compare_completeness'>Compare Completeness between Datasets</h2><span id='topic+compare_completeness'></span>

<h3>Description</h3>

<p>Produces a density plot comparing the completeness of two datasets
(<code>tbl_a</code> and <code>tbl_b</code>) for variables (if <code>dim</code> == 2, default)
or row (if <code>dim</code> == 1). The label used to identify the dataset's density
curve can be specified using <code>tbl_a_lab</code> and <code>tbl_b_lab</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_completeness(tbl_a, tbl_b, dim = 2, tbl_a_lab = NULL, tbl_b_lab = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_completeness_+3A_tbl_a">tbl_a</code></td>
<td>
<p>Data frame of the first data frame to compare.</p>
</td></tr>
<tr><td><code id="compare_completeness_+3A_tbl_b">tbl_b</code></td>
<td>
<p>Data frame of the second data frame to compare.</p>
</td></tr>
<tr><td><code id="compare_completeness_+3A_dim">dim</code></td>
<td>
<p>Integer. Dimension to measure completeness on. 2 (Default)
measures completeness by variable. 1 measures completeness by row.</p>
</td></tr>
<tr><td><code id="compare_completeness_+3A_tbl_a_lab">tbl_a_lab</code></td>
<td>
<p>String to be used to label <code>tbl_a</code> on the output plot.</p>
</td></tr>
<tr><td><code id="compare_completeness_+3A_tbl_b_lab">tbl_b_lab</code></td>
<td>
<p>String to be used to label <code>tbl_b</code> on the output plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plot showing densities of completeness across both datasets.
</p>


<h3>See Also</h3>

<p>Other measures of completeness: 
<code><a href="#topic+assess_completeness">assess_completeness</a>()</code>,
<code><a href="#topic+completeness_heatmap">completeness_heatmap</a>()</code>,
<code><a href="#topic+plot_completeness">plot_completeness</a>()</code>,
<code><a href="#topic+row_completeness">row_completeness</a>()</code>,
<code><a href="#topic+variable_completeness">variable_completeness</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
compare_completeness(example_data, strings_to_NA(example_data), dim = 2,
                     "raw", "cleaned")

</code></pre>

<hr>
<h2 id='compare_info_content'>Information Content Comparison Table</h2><span id='topic+compare_info_content'></span>

<h3>Description</h3>

<p>Used to quantify the amount of information loss, if any, which has occurred
in a merging procedure between two discrete variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_info_content(input1, input2, composite)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_info_content_+3A_input1">input1</code></td>
<td>
<p>Character vector. First variable to compare</p>
</td></tr>
<tr><td><code id="compare_info_content_+3A_input2">input2</code></td>
<td>
<p>Character vector. Second variable to compare</p>
</td></tr>
<tr><td><code id="compare_info_content_+3A_composite">composite</code></td>
<td>
<p>Character vector. Composite variable, resultant of merging
<code>input1</code> and <code>input2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function requires the two discrete variables which have been
merged (<code>input1</code> and <code>input2</code>) and the composite variable
(<code>output</code>). For each input, information content is calculated using
<code><a href="#topic+information_content_discrete">information_content_discrete</a></code> along with each input's mutual
information content with the composite variable using
<code><a href="#topic+mi_content_discrete">mi_content_discrete</a></code>. The function returns a table describing
these measures.
</p>
<p>If the mutual information content between an input variable and the
composite variable is equal to the information content of the input
variable, it is confirmed that all information in the input variable has
been incorporated into the composite variable. However, if one or both
input variables' information content is not equal to their mutual
information with the composite variables, information loss has occurred.
</p>


<h3>Value</h3>

<p>Table containing information content for <code>input1</code> and
<code>input2</code> and their mutual information content with <code>composite</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare_info_content_plt">compare_info_content_plt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
require(dplyr)
require(magrittr)
example_data %&gt;%
   mutate(diabetes_merged = coalesce(diabetes_type, diabetes)) %&gt;%
   select(starts_with("diabetes")) -&gt;
   merged_data
   
compare_info_content(merged_data$diabetes,
                     merged_data$diabetes_type,
                     merged_data$diabetes_merged)
</code></pre>

<hr>
<h2 id='compare_info_content_plt'>Information Content Comparison Plot</h2><span id='topic+compare_info_content_plt'></span>

<h3>Description</h3>

<p>This function requires the output from <code><a href="#topic+compare_info_content">compare_info_content</a></code>.
It is used to visualise the amount of information loss, if any, which has
occurred in a merging procedure between two discrete variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_info_content_plt(compare_info_content_res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_info_content_plt_+3A_compare_info_content_res">compare_info_content_res</code></td>
<td>
<p>Output from
<code><a href="#topic+compare_info_content">compare_info_content</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the mutual information content between an input variable and the
composite variable is equal to the information content of the input
variable, it is confirmed that all information in the input variable has
been incorporated into the composite variable.
</p>


<h3>Value</h3>

<p>Plot of measures calculated in <code><a href="#topic+compare_info_content">compare_info_content</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare_info_content">compare_info_content</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
require(dplyr)
require(magrittr)
example_data %&gt;%
   mutate(diabetes_merged = coalesce(diabetes_type, diabetes)) %&gt;%
   select(starts_with("diabetes")) -&gt;
   merged_data

compare_info_content(merged_data$diabetes,
                     merged_data$diabetes_type,
                     merged_data$diabetes_merged) %&gt;%
                     compare_info_content_plt()
</code></pre>

<hr>
<h2 id='completeness_heatmap'>Completeness Heatmap</h2><span id='topic+completeness_heatmap'></span>

<h3>Description</h3>

<p>Produces a heatmap visualising completeness across a dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>completeness_heatmap(
  data,
  id_var,
  annotation_tbl = NULL,
  method = 1,
  show_rownames = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="completeness_heatmap_+3A_data">data</code></td>
<td>
<p>Data frame to be analysed.</p>
</td></tr>
<tr><td><code id="completeness_heatmap_+3A_id_var">id_var</code></td>
<td>
<p>Character constant of row identifier variable name.</p>
</td></tr>
<tr><td><code id="completeness_heatmap_+3A_annotation_tbl">annotation_tbl</code></td>
<td>
<p>Data frame containing variable annotation data. Column
1 should contain variable names, column 2 should contain an annotation
label.</p>
</td></tr>
<tr><td><code id="completeness_heatmap_+3A_method">method</code></td>
<td>
<p>Integer between 1 and 3. Default: 1. See Details for more
information.</p>
</td></tr>
<tr><td><code id="completeness_heatmap_+3A_show_rownames">show_rownames</code></td>
<td>
<p>Boolean. Should rownames be shown. Default: False.</p>
</td></tr>
<tr><td><code id="completeness_heatmap_+3A_...">...</code></td>
<td>
<p>Parameters to be passed to <code><a href="pheatmap.html#topic+pheatmap">pheatmap</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

 <ul>
<li><p> Method 1: Missing values are numerically encoded with a
highly negative number, numerically distant from all values in <code>data</code>,
using <code><a href="#topic+distant_neg_val">distant_neg_val</a></code>. Values in categorical variables
are replaced with the number of unique values in the variable. Clustering
uses these values. Cells are coloured by presence (yellow = missing; blue =
present). </p>
</li>
<li><p> Method 2: Same as Method 1 but cells are coloured by values
used to cluster. </p>
</li>
<li><p> Method 3: Values in <code>data</code> are encoded as Boolean
values for clustering (present values = 1; missing values = 0). Cells are
coloured by presence (yellow = missing; blue = present). </p>
</li></ul>



<h3>Value</h3>

<p>completeness heatmap
</p>


<h3>Note</h3>

<p>See examples of how to plot using plot.new(). This is ensure a new plot
is created for the heatmap
</p>


<h3>References</h3>

<p>Kolde R (2019). _pheatmap: Pretty Heatmaps_. R package version 1.0.12,
&lt;https://CRAN.R-project.org/package=pheatmap&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="pheatmap.html#topic+pheatmap">pheatmap</a></code>
</p>
<p>Other measures of completeness: 
<code><a href="#topic+assess_completeness">assess_completeness</a>()</code>,
<code><a href="#topic+compare_completeness">compare_completeness</a>()</code>,
<code><a href="#topic+plot_completeness">plot_completeness</a>()</code>,
<code><a href="#topic+row_completeness">row_completeness</a>()</code>,
<code><a href="#topic+variable_completeness">variable_completeness</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)

# heatmap without variable category annotations:
hm &lt;- completeness_heatmap(example_data,patient_id)
plot.new() # ensure new plot is created
hm


# heatmap with variable category annotations:
## create a dataframe containing variable annotations
tibble::tribble(~"var", ~"datatype",
"patient_id", "id",
"tumoursize", "numeric",
"t_stage", "ordinal_tstage",
"n_stage", "ordinal_nstage",
"diabetes", "factor",
"diabetes_type", "ordinal",
"hypertension", "factor",
"rural_urban", "factor",
"marital_status", "factor",
"SNP_a", "genotype",
"SNP_b", "genotype",
"free_text", "freetext") -&gt; data_types

hm &lt;- completeness_heatmap(example_data,patient_id, annotation_tbl = data_types)
plot.new() # ensure new plot is created
hm
</code></pre>

<hr>
<h2 id='count_compare'>Compare unique values before and after data modification</h2><span id='topic+count_compare'></span>

<h3>Description</h3>

<p>Performs comparison of variables before and after a change has been applied
in order to allow manual inspection and review of modifications made during
the dataset preparation process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_compare(
  cols2compare,
  before_tbl = NULL,
  after_tbl = NULL,
  only_diff = FALSE,
  kableout = TRUE,
  caption = NULL,
  latex_wrap = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_compare_+3A_cols2compare">cols2compare</code></td>
<td>
<p>Variables to compare between tables.</p>
</td></tr>
<tr><td><code id="count_compare_+3A_before_tbl">before_tbl</code></td>
<td>
<p>Data frame from before modification was made.</p>
</td></tr>
<tr><td><code id="count_compare_+3A_after_tbl">after_tbl</code></td>
<td>
<p>Data frame from after modification was made.</p>
</td></tr>
<tr><td><code id="count_compare_+3A_only_diff">only_diff</code></td>
<td>
<p>Keep only rows which differ between the tables (good for
variables with many unique values, such as numeric variables).</p>
</td></tr>
<tr><td><code id="count_compare_+3A_kableout">kableout</code></td>
<td>
<p>Should output be a <code>kable</code> from <code>knitr</code>? If not,
returns a <code>tibble</code>. (Default: TRUE)</p>
</td></tr>
<tr><td><code id="count_compare_+3A_caption">caption</code></td>
<td>
<p>Caption for <code>kable</code>'s <code>caption</code> parameter.</p>
</td></tr>
<tr><td><code id="count_compare_+3A_latex_wrap">latex_wrap</code></td>
<td>
<p>Should tables be aligned vertically rather than
horizontally? Useful for wide table which would otherwise run off a page
in LaTeX format.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The purpose of this function is to summarise individual alterations in a
dataset and works best with categorical variables. The output contains two
tables derived from the parameters <code>before_tbl</code> and <code>after_tbl</code>.
Each table shows the unique combinations of values in variables specified in
the parameter <code>cols2compare</code> if the variable is present. The tables are
presented as two sub-tables and therefore share a single table caption. This
caption is automatically generated describing the content of the two
sub-tables when the parameter <code>caption</code> is not specified. The
default output is a <code>kable</code> containing two sub-kables however if the
parameter <code>kableout</code> is <code>FALSE</code>, a list containing the two
<code>tibble</code>s are returned. This may preferable for further analysis on the
tables' contents.
</p>


<h3>Value</h3>

<p>Returns list of two tibbles or a kable (see <code>kableout</code>
argument), each tallying unique values in specified columns in each input
table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># merge data as the example modification
example_data_merged &lt;- merge_cols(example_data, diabetes_type, diabetes, 
"diabetes_merged", rm_in_vars = TRUE)

# review the differences between the input and output of the variable merging step above:
count_compare(before_tbl = example_data,
              after_tbl = example_data_merged,
                            cols2compare = c("diabetes", "diabetes_type", "diabetes_merged"),
                            kableout = FALSE)
</code></pre>

<hr>
<h2 id='discrete.mi'>Calculate mutual information of a matrix of discrete values</h2><span id='topic+discrete.mi'></span>

<h3>Description</h3>

<p>Compute mutual information between all rows of a matrix containing discrete
outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrete.mi(mat, progress.bar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discrete.mi_+3A_mat">mat</code></td>
<td>
<p>A matrix of discrete values</p>
</td></tr>
<tr><td><code id="discrete.mi_+3A_progress.bar">progress.bar</code></td>
<td>
<p>Outputs status to terminal when set to 'text', or no
status updates are output when set to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that only the lower triangle of the matrix is populated for speed, as
the result is symmetric. Takes a matrix as input.
</p>


<h3>Value</h3>

<p>A lower triangular matrix where element [i,j] contains the mutual
information in bits between row i and row j of the input matrix
</p>


<h3>Author(s)</h3>

<p>Alexander Lyulph Robert Lubbock, Ian Overton
</p>

<hr>
<h2 id='distant_neg_val'>Find highly distant value for data frame</h2><span id='topic+distant_neg_val'></span>

<h3>Description</h3>

<p>Returns a numeric value which is distant from the values in <code>data</code> using
the following equation: </p>
<p style="text-align: center;"><code class="reqn">output = -2 * (max(data)-min(data)))</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>distant_neg_val(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distant_neg_val_+3A_data">data</code></td>
<td>
<p>data frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector of length 1
</p>

<hr>
<h2 id='edge_tbl_to_graph'>Convert edge table to tidygraph graph</h2><span id='topic+edge_tbl_to_graph'></span>

<h3>Description</h3>

<p>A edge table, as a data frame, is converted to a directed tidygraph
<code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code>. Column 1 of the edge table is
interpreted as a &quot;from&quot; column, Column 2 is interpreted as a &quot;to&quot; column, and
any further columns are interpreted as attributes of the entity/node recorded
in column 1. Incomplete cases are removed from the edge table (rows) to avoid
redundancy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edge_tbl_to_graph(edge_tbl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="edge_tbl_to_graph_+3A_edge_tbl">edge_tbl</code></td>
<td>
<p>data frame containing 'from' nodes in column 1 and 'to' nodes
in column 2 so that all nodes go 'towards' the root node</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> representation of the edge table
</p>


<h3>Examples</h3>

<pre><code class='language-R'># basic edge table
edge_tbl &lt;- tibble::tribble(~from, ~to,
"Nstage", "TNM",
"Tstage", "TNM",
"Tumoursize", "property_of_tumour",
"Tstage", "property_of_tumour",
"property_of_tumour", "property_of_cancer",
"TNM", "property_of_cancer",
"property_of_cancer", "disease",
"disease", "root",
"root", NA)

graph &lt;- edge_tbl_to_graph(edge_tbl)

graph

plot(graph)


# edge table with node attributes
## note that root node is included in final row to include its label
edge_tbl &lt;- tibble::tribble(~from, ~to, ~label,
"Nstage", "TNM", "N stage",
"Tstage", "TNM", "T stage",
"Tumoursize", "property_of_tumour", "Tumour size",
"Tstage", "property_of_tumour", "T stage",
"property_of_tumour", "property_of_cancer", "Property of tumour",
"TNM", "property_of_cancer", "TNM",
"property_of_cancer", "disease", "Property of cancer",
"disease", "root", "Disease",
"root", NA, "Ontology Root")
graph &lt;- edge_tbl_to_graph(edge_tbl)

graph

plot(graph)

</code></pre>

<hr>
<h2 id='encode_as_num_mat'>Convert data frame to numeric matrix</h2><span id='topic+encode_as_num_mat'></span>

<h3>Description</h3>

<p>Converts all columns to numeric and uses the row identifier column
(<code>id_var</code>) as row names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_as_num_mat(data, id_var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_as_num_mat_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="encode_as_num_mat_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted  expression which corresponds to a variable in
<code>data</code> which identifies each row.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric matrix with <code>id_var</code> values as row names
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(dplyr)
require(magrittr)
mtcars %&gt;%
  dplyr::as_tibble(rownames = "id") %&gt;%
  encode_as_num_mat(id)
</code></pre>

<hr>
<h2 id='encode_bin_cat_vec'>Encode a categorical vector with binary categories</h2><span id='topic+encode_bin_cat_vec'></span>

<h3>Description</h3>

<p>In a character vector, converts binary categories to factor levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_bin_cat_vec(x, values = NULL, numeric_out = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_bin_cat_vec_+3A_x">x</code></td>
<td>
<p>non-numeric input vector</p>
</td></tr>
<tr><td><code id="encode_bin_cat_vec_+3A_values">values</code></td>
<td>
<p>Optional named vector of user-defined values for binary values
using <code>binary_label_1 = binary_label_2</code> syntax (e.g. <code>c("No" =
"Yes")</code> would assign level 1 to &quot;No&quot; and 2 to &quot;Yes&quot;).</p>
</td></tr>
<tr><td><code id="encode_bin_cat_vec_+3A_numeric_out">numeric_out</code></td>
<td>
<p>If true, numeric vector is returned. If false, factor is
returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Binary categories to convert can be specified with a named character vector,
specified in <code>values</code>. The syntax of the named vector is:
<code>negative_finding = positive_finding</code>.  If <code>values</code> is not
provided, the default list will be used: <code>"No"="Yes", "No/unknown" =
"Yes", "no/unknown" = "Yes", "Non-user" = "User", "Never" = "Ever", "WT" =
"MT"</code>.
</p>


<h3>Value</h3>

<p>Factor with false finding encoded as 1 and true finding encoded as
2. Alternatively, numeric vector if <code>numeric_out</code> parameter is
<code>TRUE</code>.
</p>

<hr>
<h2 id='encode_binary_cats'>Encode categorical variables as binary factors</h2><span id='topic+encode_binary_cats'></span>

<h3>Description</h3>

<p>In a data frame, converts binary categories to factors. Ordering of levels is
standardised to: <code>negative_finding, positive_finding</code>. This embeds a
standardised numeric relationship between the binary categories while
preserving value labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_binary_cats(data, ..., values = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_binary_cats_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="encode_binary_cats_+3A_...">...</code></td>
<td>
<p>&lt;<code><a href="dplyr.html#topic+dplyr_tidy_select">tidy-select</a></code>&gt; One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like <code>x:y</code> can
be used to select a range of variables.</p>
</td></tr>
<tr><td><code id="encode_binary_cats_+3A_values">values</code></td>
<td>
<p>Optional named vector of user-defined values for binary values
using <code>binary_label_1 = binary_label_2</code> syntax (e.g. <code>c("No" =
"Yes")</code> would assign level 1 to &quot;No&quot; and 2 to &quot;Yes&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Binary categories to convert can be specified with a named character vector,
specified in <code>values</code>. The syntax of the named vector is:
<code>negative_finding = positive_finding</code>. If <code>values</code> is not
provided, the default list will be used: <code>"No"="Yes", "No/unknown" =
"Yes", "no/unknown" = "Yes", "Non-user" = "User", "Never" = "Ever", "WT" =
"MT"</code>.
</p>


<h3>Value</h3>

<p>dataset with specified binary categories converted to factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use built-in values. Note: rural_urban is not modified
# Note: diabetes is not modified because "missing" is interpreted as a third category.
# strings_to_NA() should be applied first
encode_binary_cats(example_data, hypertension, rural_urban)

# use custom values. Note: rural_urban is now modified as well.
encoded_data &lt;- encode_binary_cats(example_data, hypertension, rural_urban,
                   values = c("No"= "Yes", "rural" = "urban"))

# to demonstrate the new numeric encoding:
dplyr::mutate(encoded_data, hypertension_num = as.numeric(hypertension), .keep = "used") 
</code></pre>

<hr>
<h2 id='encode_cats'>Encode categorical variables using one-hot encoding.</h2><span id='topic+encode_cats'></span>

<h3>Description</h3>

<p>Variables specified in <code>...</code> are replaced with new variables describing
the presence of each unique category. Generated variable names have space
characters replaced with &quot;_&quot; and commas are removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_cats(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_cats_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="encode_cats_+3A_...">...</code></td>
<td>
<p>&lt;<code><a href="dplyr.html#topic+dplyr_tidy_select">tidy-select</a></code>&gt; One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like <code>x:y</code> can
be used to select a range of variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble with converted variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(magrittr)
require(dplyr)

data(example_data)

# encode one variable
encode_cats(example_data, marital_status) %&gt;%
select(starts_with("marital_status"))

# encode multiple variables
encoded &lt;- encode_cats(example_data, diabetes, marital_status)

select(encoded, starts_with("marital_status"))
# diabetes_type included below but was not modified:
select(encoded, starts_with("diabetes")) 
</code></pre>

<hr>
<h2 id='encode_genotype_vec'>Encode a genotype/SNP vector</h2><span id='topic+encode_genotype_vec'></span>

<h3>Description</h3>

<p>Standardises homozygous SNP alleles (e.g. recorded as 'A') to two character
form (e.g. 'A/A') and orders heterozygous SNP alleles alphabetically (e.g.
&quot;GA&quot; becomes &quot;A/G&quot;). The SNP values are then converted from a character
vector to an ordered factor, ordered by SNP allele frequency (e.g. most
frequent SNP allele is 1, second most frequent value is 2, and least frequent
values is 3). This method embeds the numeric relationship between the SNP
allele frequencies while preserving value labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_genotype_vec(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_genotype_vec_+3A_x">x</code></td>
<td>
<p>input vector containing genotype data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ordered factor, ordered by allele frequency in variable
</p>

<hr>
<h2 id='encode_genotypes'>Encode genotype/SNP variables in data frame</h2><span id='topic+encode_genotypes'></span>

<h3>Description</h3>

<p>Standardises homozygous SNPs (e.g. recorded as &quot;A&quot;) to two character
form (e.g. &quot;A/A&quot;) and orders heterozygous SNPs alphabetically (e.g.
&quot;GA&quot; becomes &quot;A/G&quot;). The SNP values are then converted from a character
vector to an ordered factor, ordered by observed allele frequency (in the supplied cohort). The most
frequent allele is assigned level 1, the second most frequent value is assigned level 2, and the least frequent
values is assigned level 3). This method embeds the numeric relationship between the
allele frequencies while preserving value labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_genotypes(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_genotypes_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="encode_genotypes_+3A_...">...</code></td>
<td>
<p>&lt;<code><a href="dplyr.html#topic+dplyr_tidy_select">tidy-select</a></code>&gt; One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like <code>x:y</code> can
be used to select a range of variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>'data' with variables (<code>...</code>) encoded as standardised genotypes
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
require(dplyr)
require(magrittr)

# one variable
encode_genotypes(example_data, SNP_a) %&gt;%
select(SNP_a)

# multiple variables
encode_genotypes(example_data, SNP_a, SNP_b) %&gt;%
select(SNP_a, SNP_b)

# using tidyselect helpers
encode_genotypes(example_data, dplyr::starts_with("SNP")) %&gt;%
select(starts_with("SNP"))

</code></pre>

<hr>
<h2 id='encode_ordinals'>Encode ordinal variables</h2><span id='topic+encode_ordinals'></span>

<h3>Description</h3>

<p>Converts character or factor variables in the input data frame to ordered factors
embedding numeric relationship between values while preserving value labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_ordinals(data, ord_levels, ..., strict_levels = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_ordinals_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="encode_ordinals_+3A_ord_levels">ord_levels</code></td>
<td>
<p>character vector containing values in desired order
(lowest to highest).</p>
</td></tr>
<tr><td><code id="encode_ordinals_+3A_...">...</code></td>
<td>
<p>&lt;<code><a href="dplyr.html#topic+dplyr_tidy_select">tidy-select</a></code>&gt; One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like <code>x:y</code> can
be used to select a range of variables.</p>
</td></tr>
<tr><td><code id="encode_ordinals_+3A_strict_levels">strict_levels</code></td>
<td>
<p>logical constant. If <code>TRUE</code>, variables in
<code>...</code> which contain values other than <code>ord_levels</code> (including
<code>NA</code>) are not modified and a warning is given. If <code>FALSE</code>,
values not in <code>ord_levels</code> are converted to <code>NA</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe with specified variables encoded as ordered factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
require(dplyr)
require(magrittr)
encode_ordinals(example_data, ord_levels = c("N0","N1","N2"), n_stage)

# Note: "unequivocal" is present in  t_stage but not in `ord_levels`.
# with `strict_levels` TRUE, t_stage is unmodified and a warning message is given:

encode_ordinals(example_data,
   ord_levels = c("T1","T2","T3a", "T3b", "T4"), strict_levels = TRUE, t_stage) %&gt;%
   select(t_stage)
   
# with `strict_levels` FALSE, it is replaced with NA:

encode_ordinals(example_data,
   ord_levels = c("T1","T2","T3a", "T3b", "T4"), strict_levels = FALSE, t_stage) %&gt;%
   select(t_stage)
</code></pre>

<hr>
<h2 id='entropy'>Calculate Entropy of a Vector</h2><span id='topic+entropy'></span>

<h3>Description</h3>

<p>Calculates Shannon Entropy of a vector in bits (default) or natural units.
Missing values are omitted from the calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy(x, unit = c("bits"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="entropy_+3A_x">x</code></td>
<td>
<p>Input vector</p>
</td></tr>
<tr><td><code id="entropy_+3A_unit">unit</code></td>
<td>
<p>Unit to measure entropy. Either &quot;bits&quot; (default) or &quot;nats&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Entropy of input variable
</p>


<h3>References</h3>

<p>Shannon, C. E. A mathematical theory of communication. The Bell
System Technical Journal 27, 379423 (1948).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># no entropy:
vec &lt;- c(1,1,1,1,1,1)
entropy(vec)

# entropy
vec &lt;- c(1,2,3,4,5,6)
entropy(vec)
</code></pre>

<hr>
<h2 id='exact.kde'>Exact kernel density estimation</h2><span id='topic+exact.kde'></span>

<h3>Description</h3>

<p>Calculates KDE for a set of points exactly, rather than an approximation as
per the density() core function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exact.kde(x, bw, output.domain = x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exact.kde_+3A_x">x</code></td>
<td>
<p>A numeric vector of values</p>
</td></tr>
<tr><td><code id="exact.kde_+3A_bw">bw</code></td>
<td>
<p>The bandwidth to use - either a single value, or a vector of
values the same length as <code>x</code> if using adaptive bandwidth estimation
(with each value giving the bandwidth at the corresponding data point).</p>
</td></tr>
<tr><td><code id="exact.kde_+3A_output.domain">output.domain</code></td>
<td>
<p>The domain of values over which to estimate the
density. Defaults to <code>x</code>. To use the same domain of <code>x</code> values
as <span class="rlang"><b>R</b></span>'s <code>density</code>, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="exact.kde_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove missing values if <code>TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only tractable for around 10,000 data points or less - otherwise consider
using the density() core function for a close approximation.
</p>
<p>The density() core function approximation is normally a very good approximation, but
some small values close to zero may become zero rather than just very small.
This makes it less suitable for mutual information estimation.
</p>


<h3>Value</h3>

<p>The exact kernel density estimate as a <code>density</code> object,
compatible with <span class="rlang"><b>R</b></span>'s <code>density</code> function.
</p>


<h3>Author(s)</h3>

<p>Alexander Lyulph Robert Lubbock, Ian Overton
</p>

<hr>
<h2 id='example_data'>Example data for eHDPrep</h2><span id='topic+example_data'></span>

<h3>Description</h3>

<p>A dataset containing synthetic example values to demonstrate functionality of
'eHDprep'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 1,000 rows and 10 variables: </p>

<dl>
<dt>patient_id</dt><dd><p>1 to 1000, effictively row numbers</p>
</dd>
<dt>tumoursize</dt><dd><p>double. random values with a mean of 50 and SD of 20</p>
</dd>
<dt>t_stage</dt><dd><p>character. T stage random values</p>
</dd> <dt>n_stage</dt><dd><p>character.
N stage random values</p>
</dd> <dt>diabetes</dt><dd><p>character. Patient diabetes
category</p>
</dd> <dt>diabetes_type</dt><dd><p>character. Patient diabetes type category</p>
</dd>
<dt>hypertension</dt><dd><p>character. Patient hypertension category</p>
</dd>
<dt>rural_urban</dt><dd><p>character. Patient domestic address category</p>
</dd>
<dt>marital_status</dt><dd><p>character. Patient marital status category</p>
</dd>
<dt>SNP_a</dt><dd><p>character. Single Nucleotide Polymorphism (SNP) of the
patient</p>
</dd> <dt>SNP_b</dt><dd><p>character. Another SNP of the patient</p>
</dd>
<dt>free_text</dt><dd><p>character. sentences from the 'stringr' package as an
example of short free text variables</p>
</dd> </dl>



<h3>Source</h3>

<p>synthetic
</p>

<hr>
<h2 id='example_edge_tbl'>Example ontology as an edge table for semantic enrichment</h2><span id='topic+example_edge_tbl'></span>

<h3>Description</h3>

<p>A data frame describing semantic links (edges) between entities in
'example_ontology'. Used to demonstrate semantic enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_edge_tbl
</code></pre>


<h3>Format</h3>

<p>A data frame: </p>

<dl>
<dt>from</dt><dd><p>character. Names of semantic concepts which have a directed relationship to concepts in 'to' column.</p>
</dd>
<dt>to</dt><dd><p>character. Names of semantic concepts which have a directed relationship to concepts in 'from' column.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Used in documentation and creation of &lsquo;example_ontology' in &rsquo;eHDPrep'.
</p>


<h3>Source</h3>

<p>synthetic
</p>

<hr>
<h2 id='example_mapping_file'>Example mapping file for semantic enrichment</h2><span id='topic+example_mapping_file'></span>

<h3>Description</h3>

<p>A data frame containing mappings between variables in 'example_data' and
'example_onto'. Used to demonstrate semantic enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_mapping_file
</code></pre>


<h3>Format</h3>

<p>A data frame: </p>

<dl>
<dt>variable</dt><dd><p>character. names of variables in post-QC 'example_data'.</p>
</dd>
<dt>onto_entity</dt><dd><p>character. names of mapped entities in 'example_ontology'.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Maps variables in &lsquo;example_data' to 'example_ontology' in &rsquo;eHDPrep'.
</p>


<h3>Source</h3>

<p>synthetic
</p>

<hr>
<h2 id='example_ontology'>Example ontology as a network graph for semantic enrichment</h2><span id='topic+example_ontology'></span>

<h3>Description</h3>

<p>A small custom network graph to demonstrate semantic enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_ontology
</code></pre>


<h3>Format</h3>

<p>tidygraph graph
</p>


<h3>Details</h3>

<p>Contains semantic links of variables in 'eHDPrep&rdquo;s 'example_data' following
quality control.
</p>


<h3>Source</h3>

<p>synthetic
</p>

<hr>
<h2 id='export_dataset'>Export data to delimited file</h2><span id='topic+export_dataset'></span>

<h3>Description</h3>

<p>Save dataset in .csv or .tsv format. A wrapper function for <code>readr</code>'s
<code><a href="readr.html#topic+write_csv">write_csv</a></code> and <code><a href="readr.html#topic+write_tsv">write_tsv</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>export_dataset(x, file, format = "csv", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="export_dataset_+3A_x">x</code></td>
<td>
<p>A data frame or tibble to write to disk.</p>
</td></tr>
<tr><td><code id="export_dataset_+3A_file">file</code></td>
<td>
<p>File or connection to write to.</p>
</td></tr>
<tr><td><code id="export_dataset_+3A_format">format</code></td>
<td>
<p>Character constant. &quot;csv&quot; (default) or &quot;tsv&quot;</p>
</td></tr>
<tr><td><code id="export_dataset_+3A_...">...</code></td>
<td>
<p>parameters to pass to <code><a href="readr.html#topic+write_csv">write_csv</a></code> or <code><a href="readr.html#topic+write_tsv">write_tsv</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>x</code> saved to <code>file</code> in selected <code>format</code>
</p>


<h3>See Also</h3>

<p><code><a href="readr.html#topic+write_csv">write_csv</a></code> and <code><a href="readr.html#topic+write_tsv">write_tsv</a></code>
</p>
<p>Other import to/export from 'R' functions: 
<code><a href="#topic+import_dataset">import_dataset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
tmp = tempfile(fileext = ".csv")
export_dataset(example_data, tmp)
</code></pre>

<hr>
<h2 id='extract_freetext'>Extract information from free text</h2><span id='topic+extract_freetext'></span>

<h3>Description</h3>

<p>Extracts information from specified free text variables (<code>...</code>) which
occur in a minimum amount of rows (<code>min_freq</code>) and appends new variables
to <code>data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_freetext(data, id_var, min_freq = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_freetext_+3A_data">data</code></td>
<td>
<p>Data frame to append skipgram variables to.</p>
</td></tr>
<tr><td><code id="extract_freetext_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted  expression which corresponds to a variable in
<code>data</code> which identifies each row.</p>
</td></tr>
<tr><td><code id="extract_freetext_+3A_min_freq">min_freq</code></td>
<td>
<p>Minimum percentage frequency of skipgram occurrence to
return. Default = 1.</p>
</td></tr>
<tr><td><code id="extract_freetext_+3A_...">...</code></td>
<td>
<p>Unquoted expressions of free text variable names from which to
extract information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>New variables report the presence of skipgrams (proximal words in the text)
with a minimum frequency (<code>min_freq</code>, default = 1%)).
</p>


<h3>Value</h3>

<p><code>data</code> with additional Boolean variables describing skipgrams in
<code>...</code>
</p>


<h3>References</h3>

<p>Guthrie, D., Allison, B., Liu, W., Guthrie, L. &amp; Wilks, Y. A
Closer Look at Skip-gram Modelling. in Proceedings of the Fifth
International Conference on Language Resources and Evaluation (LREC06)
(European Language Resources Association (ELRA), 2006).
</p>
<p>Benoit K, Watanabe K, Wang H, Nulty P, Obeng A, Mller S, Matsuo A (2018).
quanteda: An R package for the quantitative analysis of textual data. _Journal
of Open Source Software_, *3*(30), 774. doi:10.21105/joss.00774
&lt;https://doi.org/10.21105/joss.00774&gt;, &lt;https://quanteda.io&gt;.
</p>
<p>Feinerer I, Hornik K (2020). _tm: Text Mining Package_. R package version 0.7-8,
&lt;https://CRAN.R-project.org/package=tm&gt;.
</p>
<p>Ingo Feinerer, Kurt Hornik, and David Meyer (2008). Text Mining Infrastructure in
R. Journal of Statistical Software 25(5): 1-54. URL:
https://www.jstatsoft.org/v25/i05/.
</p>


<h3>See Also</h3>

<p>Principle underlying function: <code><a href="quanteda.html#topic+tokens_ngrams">tokens_ngrams</a></code>
</p>
<p>Other free text functions: 
<code><a href="#topic+skipgram_append">skipgram_append</a>()</code>,
<code><a href="#topic+skipgram_freq">skipgram_freq</a>()</code>,
<code><a href="#topic+skipgram_identify">skipgram_identify</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
extract_freetext(example_data, patient_id, min_freq = 0.6, free_text)
</code></pre>

<hr>
<h2 id='geometric.mean'>Geometric mean</h2><span id='topic+geometric.mean'></span>

<h3>Description</h3>

<p>Calculates the geometric mean of a vector. Used for variable bandwidth
kernel density estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geometric.mean(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geometric.mean_+3A_x">x</code></td>
<td>
<p>A numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The geometric mean of x
</p>


<h3>Author(s)</h3>

<p>Alexander Lyulph Robert Lubbock, Ian Overton
</p>

<hr>
<h2 id='identify_inconsistency'>Identify inconsistencies in a dataset</h2><span id='topic+identify_inconsistency'></span>

<h3>Description</h3>

<p>Tests pairs of variables for consistency between their values according to
a table of rules or 'consistency table'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identify_inconsistency(data = NULL, consis_tbl = NULL, id_var = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identify_inconsistency_+3A_data">data</code></td>
<td>
<p>data frame which will be checked for internal consistency</p>
</td></tr>
<tr><td><code id="identify_inconsistency_+3A_consis_tbl">consis_tbl</code></td>
<td>
<p>data frame or tibble containing information on internal
consistency rules (see &quot;Consistency Table Requirements&quot; section)</p>
</td></tr>
<tr><td><code id="identify_inconsistency_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted expression which corresponds to a variable in
<code>data</code> which identifies each row.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiple types of checks for inconsistency are supported:
</p>

<ol>
<li><p> Comparing by logical operators (&lt;, &lt;=, ==, !=, &gt;=, &gt;)
</p>
</li>
<li><p> Comparing permitted categories (e.g. cat1 in varA only if cat2 in varB)
</p>
</li>
<li><p> Comparing permitted numeric ranges (e.g. 20-25 in varC only if 10-20 in
varD)
</p>
</li>
<li><p> Mixtures of 2 and 3 (e.g. cat1 in varA only if 20-25 in varC) 
</p>
</li></ol>

<p>The consistency tests rely on such rules being specified in a
separate data frame (<code>consis_tbl</code>; see section &quot;Consistency Table Requirements&quot;).
</p>
<p>Variable A is given higher priority than Variable B when A is a category. If A
(as char) is not equal to the value in col 4, the check is not made. This is
to account for one way dependencies (i.e. VarA is fruit, VarB is apple)
</p>


<h3>Value</h3>

<p>tibble detailing any identified internal inconsistencies in
<code>data</code>, if any are found. If no inconsistencies are found, <code>data</code>
is returned invisibly.
</p>


<h3>Consistency Table Requirements</h3>

<p>Table must have exactly five character columns.
The columns should be ordered according to the list below which describes the
values of each column:
</p>

<ol>
<li><p> First column name of data values that will be subject to 
consistency checking. String. Required.
</p>
</li>
<li><p> Second column name of data values that will be subject to 
consistency checking. String. Required.
</p>
</li>
<li><p> Logical test to compare columns one and two. One of: &quot;&gt;&quot;,&quot;&gt;=&quot;,
&quot;&lt;&quot;,&quot;&lt;=&quot;,&quot;==&quot;, &quot;!=&quot;. String. Optional if columns 4 and 5 have non-<code>NA</code> values.
</p>
</li>
<li><p> Either a single character string or a colon-separated range of
numbers which should only appear in column A. Optional if column 3 has a
non-<code>NA</code> value.
</p>
</li>
<li><p> Either a single character string or a colon-separated range of
numbers which should only appear in column B given the value/range
specified in column 4. Optional if column 3 has a non-<code>NA</code> value.
</p>
</li></ol>

<p>Each row should detail one test to make.
Therefore, either column 3 or columns 4 and 5 must contain non-<code>NA</code>
values.
</p>


<h3>See Also</h3>

<p>Other internal consistency functions: 
<code><a href="#topic+validate_consistency_tbl">validate_consistency_tbl</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tibble)
# example with synthetic dataset on number of bean counts
# there is a lot going on in the function so a simple dataset aids this example
#
# creating `data`:
beans &lt;- tibble::tibble(red_beans = 1:15,
blue_beans = 1:15,
total_beans = 1:15*2,
red_bean_summary = c(rep("few_beans",9), rep("many_beans",6)))
#
# creating `consis_tbl`
bean_rules &lt;- tibble::tribble(~varA, ~varB, ~lgl_test, ~varA_boundaries, ~varB_boundaries,
"red_beans", "blue_beans", "==", NA, NA,
"red_beans", "total_beans", "&lt;=", NA,NA,
"red_beans", "red_bean_summary", NA, "1:9", "few_beans",
"red_beans", "red_bean_summary", NA, "10:15", "many_beans")

identify_inconsistency(beans, bean_rules)

# creating some inconsistencies as examples
beans[1, "red_bean_summary"] &lt;- "many_beans"
beans[1, "red_beans"] &lt;- 10

identify_inconsistency(beans, bean_rules)

</code></pre>

<hr>
<h2 id='import_dataset'>Import data into 'R'</h2><span id='topic+import_dataset'></span>

<h3>Description</h3>

<p>Imports a rectangular single table into <span class="rlang"><b>R</b></span> from a .xls, .xlsx, .csv, or .tsv file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_dataset(file, format = "excel", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_dataset_+3A_file">file</code></td>
<td>
<p>Character constant. Path to file.</p>
</td></tr>
<tr><td><code id="import_dataset_+3A_format">format</code></td>
<td>
<p>Character constant. &quot;excel&quot; (default, for .xls or.xlsx files),
csv&quot;, or &quot;tsv&quot;.</p>
</td></tr>
<tr><td><code id="import_dataset_+3A_...">...</code></td>
<td>
<p>Parameters to pass to <code><a href="readxl.html#topic+read_excel">read_excel</a></code>,
<code><a href="readr.html#topic+read_csv">read_csv</a></code> or <code><a href="readr.html#topic+read_tsv">read_tsv</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>First row is interpreted as column headers by default. For more details see
<code><a href="readxl.html#topic+read_excel">read_excel</a></code> (.xlsx/.xls), <code><a href="readr.html#topic+read_csv">read_csv</a></code> (.csv), or
<code><a href="readr.html#topic+read_tsv">read_tsv</a></code> (.tsv).
</p>


<h3>Value</h3>

<p>data as a <code>tibble</code>
</p>


<h3>See Also</h3>

<p><code><a href="readxl.html#topic+read_excel">read_excel</a></code> for additional parameters for
importing .xls or .xlsx files, <code><a href="readr.html#topic+read_csv">read_csv</a></code> for .csv
files, <code><a href="readr.html#topic+read_tsv">read_tsv</a></code> for .tsv files
</p>
<p>Other import to/export from 'R' functions: 
<code><a href="#topic+export_dataset">export_dataset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
   # This code will not run as it requires an xlsx file
   # ./dataset.xlsx should be replaced with path to user's dataset
   
   # excel
   import_dataset(file = "./dataset.xlsx", format = "excel")
   #csv
   import_dataset(file = "./dataset.csv", format = "csv")
   #tsv
   import_dataset(file = "./dataset.tsv", format = "tsv")

## End(Not run)

</code></pre>

<hr>
<h2 id='import_var_classes'>Import corrected variable classes</h2><span id='topic+import_var_classes'></span>

<h3>Description</h3>

<p>Reads in output of <code><a href="#topic+assume_var_classes">assume_var_classes</a></code>, ensures all specified
datatypes are one of (&quot;id&quot;, &quot;numeric&quot;, &quot;double&quot;, &quot;integer&quot;, &quot;character&quot;,
&quot;factor&quot;,&quot;ordinal&quot;, &quot;genotype&quot;, &quot;freetext&quot;, &quot;logical&quot;) as required for high
level 'eHDPrep' functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_var_classes(file = "./datatypes.csv")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_var_classes_+3A_file">file</code></td>
<td>
<p>character string. Path to output of
<code><a href="#topic+assume_var_classes">assume_var_classes</a></code> which should be manually verified outside
of <span class="rlang"><b>R</b></span> and corrected where any data type is incorrect.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame containing the data type values of variables, as described
in <code>file</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+assume_var_classes">assume_var_classes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmp = tempfile(fileext = ".csv")
data(example_data)
assume_var_classes(example_data, tmp)
import_var_classes(tmp)

</code></pre>

<hr>
<h2 id='information_content_contin'>Calculate Information Content (Continuous Variable)</h2><span id='topic+information_content_contin'></span>

<h3>Description</h3>

<p>Calculates information content of a continuous (numeric) vector in bits
(default) or natural units. Missing values are omitted from the calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>information_content_contin(x, unit = c("bits"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="information_content_contin_+3A_x">x</code></td>
<td>
<p>Input vector</p>
</td></tr>
<tr><td><code id="information_content_contin_+3A_unit">unit</code></td>
<td>
<p>Unit to measure entropy. Either &quot;bits&quot; (default) of &quot;nats&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Information content of input variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
information_content_contin(example_data$tumoursize)
</code></pre>

<hr>
<h2 id='information_content_discrete'>Calculate Information Content (Discrete Variable)</h2><span id='topic+information_content_discrete'></span>

<h3>Description</h3>

<p>Calculates information content of a discrete (categorical or ordinal) vector
in bits (default) or natural units. Missing values are omitted from the
calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>information_content_discrete(x, unit = c("bits"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="information_content_discrete_+3A_x">x</code></td>
<td>
<p>Input vector</p>
</td></tr>
<tr><td><code id="information_content_discrete_+3A_unit">unit</code></td>
<td>
<p>Unit to measure entropy. Either &quot;bits&quot; (default) or &quot;nats&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Information content of input variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
information_content_discrete(example_data$marital_status)
</code></pre>

<hr>
<h2 id='join_vars_to_ontol'>Join Mapping Table to Ontology Network Graph</h2><span id='topic+join_vars_to_ontol'></span>

<h3>Description</h3>

<p>This function creates new nodes representing dataset variables and joins them
to an input ontology network using a mapping file. Prior to joining, the
information content of all nodes is calculated using <code><a href="#topic+node_IC_zhou">node_IC_zhou</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>join_vars_to_ontol(ontol_graph, var2entity_tbl, mode = "in", root, k = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="join_vars_to_ontol_+3A_ontol_graph">ontol_graph</code></td>
<td>
<p>Graph containing the chosen ontology. Must be in
<code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> format or coercible to this format.</p>
</td></tr>
<tr><td><code id="join_vars_to_ontol_+3A_var2entity_tbl">var2entity_tbl</code></td>
<td>
<p>Edge table containing dataset variable names in first
column and entities in ontologies to which they are mapped in the second
column.</p>
</td></tr>
<tr><td><code id="join_vars_to_ontol_+3A_mode">mode</code></td>
<td>
<p>Character constant specifying the directionality of the edges.
One of &quot;in&quot; or &quot;out&quot;.</p>
</td></tr>
<tr><td><code id="join_vars_to_ontol_+3A_root">root</code></td>
<td>
<p>name of root node identifier in column 1 to calculate node depth
from.</p>
</td></tr>
<tr><td><code id="join_vars_to_ontol_+3A_k">k</code></td>
<td>
<p>numeric value to adjust the weight of the two items of information
content equation (relative number of hyponyms/descendants and relative node
depth). Default = 0.5</p>
</td></tr>
</table>


<h3>Details</h3>

 <ul>
<li><p> The user-defined mappings between variables in a dataset and
entities/terms in an ontology are provided in an edge table
(<code>var2entity_tbl</code>). </p>
</li>
<li><p> A node attribute column, <code>node_category</code> is
generated to describe if a node is one of &quot;Dataset Variable&quot;, &quot;Annotation&quot;, or
&quot;Annotation Ancestor&quot;.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> resulting from the joining of <code>var2entity_tbl</code>
and <code>ontol_graph</code>.
</p>


<h3>See Also</h3>

<p>node_IC_zhou
</p>
<p>Other semantic enrichment functions: 
<code><a href="#topic+metavariable_agg">metavariable_agg</a>()</code>,
<code><a href="#topic+metavariable_info">metavariable_info</a>()</code>,
<code><a href="#topic+metavariable_variable_descendants">metavariable_variable_descendants</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_ontology)
join_vars_to_ontol(example_ontology, example_mapping_file, root = "root", mode = "in")
</code></pre>

<hr>
<h2 id='max_catchNAs'>Find maximum of vector safely</h2><span id='topic+max_catchNAs'></span>

<h3>Description</h3>

<p>This low-level function is deployed as part of the semantic enrichment
process.Calculates maximum of values in numeric vector (ignoring NAs). If all
values in input vector are <code>NA</code>, returns <code>NA</code> (rather than -Inf),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_catchNAs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_catchNAs_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>maximum value of <code>x</code>
</p>

<hr>
<h2 id='mean_catchNAs'>Find mean of vector safely</h2><span id='topic+mean_catchNAs'></span>

<h3>Description</h3>

<p>This low-level function is deployed as part of the semantic enrichment
process. Averages values in numeric vector (ignoring NAs). If all values in
numeric vector are <code>NA</code>, returns <code>NA</code> (rather than NaN),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_catchNAs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean_catchNAs_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mean of <code>x</code>
</p>

<hr>
<h2 id='merge_cols'>Merge columns in data frame</h2><span id='topic+merge_cols'></span>

<h3>Description</h3>

<p>Merges two columns in a single data frame. The merging draws on the
functionality of <code>'dplyr'</code>'s <code><a href="dplyr.html#topic+coalesce">coalesce</a></code> where missing
values from one vector are replaced by corresponding values in a second
variable. The name of the merged variable is specified in
<code>merge_var_name</code>. <code>primary_var</code> and <code>secondary_var</code> can be
removed with <code>rm_in_vars</code>. Variables must be combinable (i.e. not a
combination of numeric and character).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_cols(
  data,
  primary_var,
  secondary_var,
  merge_var_name = NULL,
  rm_in_vars = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_cols_+3A_data">data</code></td>
<td>
<p>data frame containing <code>primary_var</code> and
<code>secondary_var</code>.</p>
</td></tr>
<tr><td><code id="merge_cols_+3A_primary_var">primary_var</code></td>
<td>
<p>Data variable
which contains the best quality / most detailed information. Missing values
will be supplied by values in corresponding rows from <code>secondary_var</code>.</p>
</td></tr>
<tr><td><code id="merge_cols_+3A_secondary_var">secondary_var</code></td>
<td>
<p>Data variable
which will be used to fill missing values in <code>primary_var</code>.</p>
</td></tr>
<tr><td><code id="merge_cols_+3A_merge_var_name">merge_var_name</code></td>
<td>
<p>character constant. Name for merged variable. Default:
[<code>primary_var</code>]_[<code>secondary_var</code>]_merged</p>
</td></tr>
<tr><td><code id="merge_cols_+3A_rm_in_vars">rm_in_vars</code></td>
<td>
<p>logical constant. Should <code>primary_var</code> and
<code>secondary_var</code> be removed? Default = FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame with coalesced <code>primary_var</code> and <code>secondary_var</code>
</p>


<h3>See Also</h3>

<p><code><a href="dplyr.html#topic+coalesce">coalesce</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)

# preserve input variables (default)
res &lt;- merge_cols(example_data, diabetes_type, diabetes)
dplyr::select(res, dplyr::starts_with("diabetes"))

# remove input variables
res &lt;- merge_cols(example_data, diabetes_type, diabetes, rm_in_vars = TRUE)
dplyr::select(res, dplyr::starts_with("diabetes"))

</code></pre>

<hr>
<h2 id='metavariable_agg'>Aggregate Data by Metavariable</h2><span id='topic+metavariable_agg'></span>

<h3>Description</h3>

<p>Variables in a numeric data frame are aggregated into metavariables via
their most informative common ancestors identified in an ontological graph
object (see <code><a href="#topic+metavariable_info">metavariable_info</a></code>). Metavariables are appended to
the data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metavariable_agg(graph, data, label_attr = "name", normalize_vals = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metavariable_agg_+3A_graph">graph</code></td>
<td>
<p>Graph containing ontological and dataset nodes. Must be in
<code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> format or coercible to this format. Must have been
processed using <code><a href="#topic+metavariable_info">metavariable_info</a></code>.</p>
</td></tr>
<tr><td><code id="metavariable_agg_+3A_data">data</code></td>
<td>
<p>Numeric data frame or matrix containing variables which are also
in <code>graph</code>.</p>
</td></tr>
<tr><td><code id="metavariable_agg_+3A_label_attr">label_attr</code></td>
<td>
<p>Node attribute containing labels used for column names when
creating metavariable aggregations. Default: &quot;name&quot;</p>
</td></tr>
<tr><td><code id="metavariable_agg_+3A_normalize_vals">normalize_vals</code></td>
<td>
<p>Should values be normalized before aggregation?
Default: TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Metavariables are created from the aggregation of data variables via their
most informative common ancestor (expected to have been calculated in
<code><a href="#topic+metavariable_info">metavariable_info</a></code>). Metavariables are labelled using the
syntax: <code>MV_[label_attr]_[Aggregation function]</code>. The data variables are
aggregated row-wise by their maximum, minimum, mean, sum, and product.
Metavariables with zero entropy (no information) are not appended to the
data. See examples for where this function should be applied in the semantic
enrichment workflow.
</p>


<h3>Value</h3>

<p><code>data</code> with semantic aggregations derived from common
ontological ancestry (metavariables) appended as new columns, each
prefixed with &quot;MV_&quot; and suffixed by their aggregation function (e.g. &quot;_SUM&quot;).
</p>


<h3>Note</h3>

<p>A warning may be shown regarding the '.add' argument being deprecated,
this is believed to be an issue with
<code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> which may be resolved in a
future release: &lt;https://github.com/thomasp85/tidygraph/issues/131&gt;.
Another warning may be shown regarding the 'neimode' argument being
deprecated, this is believed to be an issue with
<code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> which may be resolved in a
future release: &lt;https://github.com/thomasp85/tidygraph/issues/156&gt;. These
warning messages are not believed to have an effect on the functionality of
'eHDPrep'.
</p>


<h3>See Also</h3>

<p>Other semantic enrichment functions: 
<code><a href="#topic+join_vars_to_ontol">join_vars_to_ontol</a>()</code>,
<code><a href="#topic+metavariable_info">metavariable_info</a>()</code>,
<code><a href="#topic+metavariable_variable_descendants">metavariable_variable_descendants</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(magrittr)
require(dplyr)
data(example_ontology)
data(example_mapping_file)
data(example_data)

#' # define datatypes
tibble::tribble(~"var", ~"datatype",
"patient_id", "id",
"tumoursize", "numeric",
"t_stage", "ordinal_tstage",
"n_stage", "ordinal_nstage",
"diabetes_merged", "character",
"hypertension", "factor",
"rural_urban", "factor",
"marital_status", "factor",
"SNP_a", "genotype",
"SNP_b", "genotype",
"free_text", "freetext") -&gt; data_types

# create post-QC data
example_data %&gt;%
  merge_cols(diabetes_type, diabetes, "diabetes_merged", rm_in_vars = TRUE) %&gt;%
  apply_quality_ctrl(patient_id, data_types,
                     bin_cats =c("No" = "Yes", "rural" = "urban"),
                     to_numeric_matrix = TRUE) %&gt;%
                     suppressMessages() -&gt;
                     post_qc_data

# minimal example on first four coloums of example data:
dplyr::slice(example_ontology, 1:7,24) %&gt;%
   join_vars_to_ontol(example_mapping_file[1:3,], root = "root") %&gt;%
   metavariable_info() %&gt;%
   metavariable_agg(post_qc_data[1:10,1:4]) -&gt; res
# see Note section of documentation for information on possible warnings.

# summary of result:
tibble::glimpse(res)


# full example:
example_ontology %&gt;%
   join_vars_to_ontol(example_mapping_file, root = "root") %&gt;%
   metavariable_info() %&gt;%
   metavariable_agg(post_qc_data) -&gt; res
 # see Note section of documentation for information on possible warnings.

# summary of result:
tibble::glimpse(res)

</code></pre>

<hr>
<h2 id='metavariable_info'>Compute Metavariable Information</h2><span id='topic+metavariable_info'></span>

<h3>Description</h3>

<p>Calculates attributes for each node in a graph object pertaining to their
suitability and rank as metavariables; primarily if they are the most
informative common ancestor (see <code><a href="#topic+node_IC_zhou">node_IC_zhou</a></code>) of a set of
nodes representing a dataset variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metavariable_info(graph, mode = "in", IC_threshold = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metavariable_info_+3A_graph">graph</code></td>
<td>
<p>Graph containing ontological and dataset nodes. Must be in
<code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> format or coercible to this format.</p>
</td></tr>
<tr><td><code id="metavariable_info_+3A_mode">mode</code></td>
<td>
<p>Character constant specifying the directionality of the edges.
One of: &quot;in&quot; or &quot;out&quot;.</p>
</td></tr>
<tr><td><code id="metavariable_info_+3A_ic_threshold">IC_threshold</code></td>
<td>
<p>Metavariables with IC less than this value will be
omitted from output. Default = 0 (no omission).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The added attributes are:
</p>
<dl>
<dt>min_dist_to_var</dt><dd><p>Integer. The minimum distance of an ontology
node in the graph to a node representing a dataset variable.</p>
</dd>
<dt>is_metavariable</dt><dd><p>Logical. If the node has at least two descendants in
the graph which represent dataset variables.</p>
</dd>
<dt>variable_descendants</dt><dd><p>List. The names of variables of which a node is
an ancestor.</p>
</dd>
<dt>variable_set</dt><dd><p>Integer. An identifier for the unique set of descendants
in the graph which represent dataset variables. The assigned
number corresponds to the order in which a unique set was identified when
scanning through the node table.</p>
</dd>
<dt>highest_IC</dt><dd><p>Logical. If the node possesses the highest information
content of all other nodes which are common ancestors of the same variable
set. Information content is expected to have been calculated in
<code><a href="#topic+join_vars_to_ontol">join_vars_to_ontol</a></code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A modified graph object with additional node attributes pertaining to their
status as a metavariable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+node_IC_zhou">node_IC_zhou</a></code>
</p>
<p>Other semantic enrichment functions: 
<code><a href="#topic+join_vars_to_ontol">join_vars_to_ontol</a>()</code>,
<code><a href="#topic+metavariable_agg">metavariable_agg</a>()</code>,
<code><a href="#topic+metavariable_variable_descendants">metavariable_variable_descendants</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_ontology)
require(magrittr)
example_ontology %&gt;%
join_vars_to_ontol(example_mapping_file, root = "root") -&gt; joined_ontol

metavariable_info(joined_ontol)
</code></pre>

<hr>
<h2 id='metavariable_variable_descendants'>Extract metavariables' descendant variables</h2><span id='topic+metavariable_variable_descendants'></span>

<h3>Description</h3>

<p>Formats the output of <code><a href="#topic+metavariable_info">metavariable_info</a></code> for easier
interpretation of each metavariable's descendant variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metavariable_variable_descendants(metavariable_info_output)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metavariable_variable_descendants_+3A_metavariable_info_output">metavariable_info_output</code></td>
<td>
<p>Output tibble of
<code><a href="#topic+metavariable_info">metavariable_info</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not part of the standard semantic enrichment pipeline as this function just
produces a simplified version of the output of <code><a href="#topic+metavariable_info">metavariable_info</a></code>.
</p>
<p>The output of <code><a href="#topic+metavariable_info">metavariable_info</a></code> is converted to a tibble,
filtered to only include metavariables with highest information content for
the variable set. The tibble has three columns describing a metavariable, its
information content, and its descendant variables.
</p>


<h3>Value</h3>

<p>A tibble describing each metavariable, its
information content, and its descendant variables
</p>


<h3>See Also</h3>

<p><code><a href="#topic+node_IC_zhou">node_IC_zhou</a></code>
</p>
<p>Other semantic enrichment functions: 
<code><a href="#topic+join_vars_to_ontol">join_vars_to_ontol</a>()</code>,
<code><a href="#topic+metavariable_agg">metavariable_agg</a>()</code>,
<code><a href="#topic+metavariable_info">metavariable_info</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_ontology)
require(magrittr)
example_ontology %&gt;%
join_vars_to_ontol(example_mapping_file, root = "root") -&gt; joined_ontol

mv_info &lt;- metavariable_info(joined_ontol)
metavariable_variable_descendants(mv_info)
</code></pre>

<hr>
<h2 id='mi_content_discrete'>Calculate Mutual Information Content</h2><span id='topic+mi_content_discrete'></span>

<h3>Description</h3>

<p>Calculates mutual information content between two variables in bits. Missing
values are omitted from the calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi_content_discrete(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mi_content_discrete_+3A_x">x</code></td>
<td>
<p>First variable</p>
</td></tr>
<tr><td><code id="mi_content_discrete_+3A_y">y</code></td>
<td>
<p>Second variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Mutual information content of <code>x</code> and <code>y</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
mi_content_discrete(example_data$diabetes, example_data$diabetes_type)
</code></pre>

<hr>
<h2 id='min_catchNAs'>Find minimum of vector safely</h2><span id='topic+min_catchNAs'></span>

<h3>Description</h3>

<p>This low-level function is deployed as part of the semantic enrichment
process. Calculates minimum of values in numeric vector (ignoring NAs). If
all values in numeric vector are <code>NA</code>, returns <code>NA</code> (rather than
Inf),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>min_catchNAs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="min_catchNAs_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>minimum value of <code>x</code>
</p>

<hr>
<h2 id='mod_track'>Data modification tracking</h2><span id='topic+mod_track'></span>

<h3>Description</h3>

<p>This function produces a table
where each row represents a value in a variable which is present in the
cleaned dataset and which has been modified. The identifier, original and
modified value, modification type, and variable names in the original and
modified datasets are recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_track(before_tbl, after_tbl, id_var, plot = FALSE, vars2compare)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_track_+3A_before_tbl">before_tbl</code></td>
<td>
<p>Data frame from before modifications were made.</p>
</td></tr>
<tr><td><code id="mod_track_+3A_after_tbl">after_tbl</code></td>
<td>
<p>Data frame from after modifications were made.</p>
</td></tr>
<tr><td><code id="mod_track_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted expression which corresponds to a variable in both
<code>before_tbl</code> and <code>after_tbl</code> which identifies each row. Required.</p>
</td></tr>
<tr><td><code id="mod_track_+3A_plot">plot</code></td>
<td>
<p>Should a plot be returned instead of a table of results? Default:
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mod_track_+3A_vars2compare">vars2compare</code></td>
<td>
<p>Character vectors of variable names to compare.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Table containing row-level modification records or plot summarising
modifications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># merge data as the example modification

require(magrittr)

 # example with one modification type (removal)
 # return table
  mod_track(example_data, strings_to_NA(example_data), patient_id)
 
 # return plot
  mod_track(example_data, strings_to_NA(example_data), patient_id, plot = TRUE)

 # example with multiple modification types (removal, substitution and addition)
example_data %&gt;%
   strings_to_NA() %&gt;%
   merge_cols(diabetes_type, diabetes) -&gt;
   modded_data

# return table
mod_track(example_data, modded_data, patient_id, vars2compare = c("t_stage",
"diabetes_type_diabetes_merged" = "diabetes", "diabetes_type_diabetes_merged"
= "diabetes_type"), plot = FALSE)

# return plot
mod_track(example_data, modded_data, patient_id, vars2compare = c("t_stage",
"diabetes_type_diabetes_merged" = "diabetes", "diabetes_type_diabetes_merged"
= "diabetes_type"), plot = TRUE)
</code></pre>

<hr>
<h2 id='node_IC_zhou'>Calculate Node Information Content (Zhou et al 2008 method)</h2><span id='topic+node_IC_zhou'></span>

<h3>Description</h3>

<p>Computes the information content for each node in a directed graph according
to the equation developed by Zhou <em>et al.</em> (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>node_IC_zhou(graph, mode = "in", root, k = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="node_IC_zhou_+3A_graph">graph</code></td>
<td>
<p><code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> directed graph.</p>
</td></tr>
<tr><td><code id="node_IC_zhou_+3A_mode">mode</code></td>
<td>
<p>Character constant specifying the directionality of the edges.
One of &quot;in&quot; or &quot;out&quot;.</p>
</td></tr>
<tr><td><code id="node_IC_zhou_+3A_root">root</code></td>
<td>
<p>name of root node identifier in column 1 to calculate node depth
from.</p>
</td></tr>
<tr><td><code id="node_IC_zhou_+3A_k">k</code></td>
<td>
<p>numeric value to adjust the weight of the two items of information
content equation (relative number of hyponyms/descendants and relative node
depth). Default = 0.5</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tidygraph with additional node attribute &quot;information_content&quot;
</p>


<h3>Note</h3>

<p>For use in semantic enrichment, this should be applied before joining
an ontology with nodes representing data variables (i.e. before applying
<code><a href="#topic+join_vars_to_ontol">join_vars_to_ontol</a></code>.
</p>


<h3>References</h3>

<p>Zhou, Z., Wang, Y. &amp; Gu, J. A New Model of Information Content
for Semantic Similarity in WordNet. in 2008 Second International Conference
on Future Generation Communication and Networking Symposia vol. 3 8589
(2008).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_ontology)
node_IC_zhou(example_ontology, mode = "in", root = "root")
</code></pre>

<hr>
<h2 id='normalize'>Min max normalization</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Normalizes values in <code>x</code> to be between 0 and 1 using min-max
normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="normalize_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical indicating whether missing values should be removed. Default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>normalised <code>x</code>
</p>

<hr>
<h2 id='nums_to_NA'>Replace numeric values in numeric columns with NA</h2><span id='topic+nums_to_NA'></span>

<h3>Description</h3>

<p>Replaces specified numbers in numeric columns with <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nums_to_NA(data, ..., nums_to_replace = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nums_to_NA_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="nums_to_NA_+3A_...">...</code></td>
<td>
<p>&lt;<code><a href="dplyr.html#topic+dplyr_tidy_select">tidy-select</a></code>&gt; One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like <code>x:y</code> can
be used to select a range of variables.</p>
</td></tr>
<tr><td><code id="nums_to_NA_+3A_nums_to_replace">nums_to_replace</code></td>
<td>
<p>numeric vector of values to be replaced with
<code>NA</code>. Case is ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Columns to process can be specified in <code>...</code> or the function will be
applied to all numeric columns.
</p>


<h3>Value</h3>

<p><code>data</code> with specified values replaced with NA
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)

# replace all 1,2, and 3 from tumoursize and patient_id with NA.
nums_to_NA(data = example_data, tumoursize, patient_id, nums_to_replace = c(1,2,3))
</code></pre>

<hr>
<h2 id='onehot_vec'>One hot encode a vector</h2><span id='topic+onehot_vec'></span>

<h3>Description</h3>

<p>Uses one-hot encoding to convert nominal vectors to a tibble containing
variables for each of the unique values in input vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onehot_vec(x, prefix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="onehot_vec_+3A_x">x</code></td>
<td>
<p>non-numeric vector</p>
</td></tr>
<tr><td><code id="onehot_vec_+3A_prefix">prefix</code></td>
<td>
<p>prefix to append to output variable names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tibble
</p>

<hr>
<h2 id='ordinal_label_levels'>Extract labels and levels of ordinal variables in a dataset</h2><span id='topic+ordinal_label_levels'></span>

<h3>Description</h3>

<p>This function enables preservation of the text labels for ordinal variables in
a dataset in preparation for conversion to a numeric matrix. A table is produced
which retains the mappings between the text labels and the
numerical labels for future reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordinal_label_levels(data, out_path = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordinal_label_levels_+3A_data">data</code></td>
<td>
<p>data frame with ordinal variables with labels and levels to be
extracted.</p>
</td></tr>
<tr><td><code id="ordinal_label_levels_+3A_out_path">out_path</code></td>
<td>
<p>Optional string. Path to write output to. If not supplied, <span class="rlang"><b>R</b></span>
object will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble of text label and (numerical) level mappings
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(magrittr)  # for %&gt;%

# create an example class_tbl object
# note that diabetes_type is classed as ordinal yet is not modified as its
# levels are not pre-coded. It should instead be encoded with encode_ordinals().
tibble::tribble(~"var", ~"datatype",
"patient_id", "id",
"tumoursize", "numeric",
"t_stage", "ordinal_tstage",
"n_stage", "ordinal_nstage",
"diabetes", "factor",
"diabetes_type", "ordinal",
"hypertension", "factor",
"rural_urban", "factor",
"marital_status", "factor",
"SNP_a", "genotype",
"SNP_b", "genotype",
"free_text", "freetext") -&gt; data_types

# show unqiue values for t_stage in pre-QC example_data 
unique(example_data$t_stage)

# apply quality control to example_data
apply_quality_ctrl(example_data, patient_id, data_types,
bin_cats =c("No" = "Yes", "rural" = "urban"),  min_freq = 0.6) %&gt;%
ordinal_label_levels -&gt; res

# examine the labels and levels of t_stage in post-QC example_data
dplyr::filter(res, variable == "t_stage")

</code></pre>

<hr>
<h2 id='plot_completeness'>Plot Completeness of a Dataset</h2><span id='topic+plot_completeness'></span>

<h3>Description</h3>

<p>Generates a bar plot of percentage completeness for one or both data frame
dimensions (rows/columns).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_completeness(data, id_var, plot = c("variables", "rows"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_completeness_+3A_data">data</code></td>
<td>
<p>Data frame in tidy format (see <a href="https://tidyr.tidyverse.org/">https://tidyr.tidyverse.org/</a>).</p>
</td></tr>
<tr><td><code id="plot_completeness_+3A_id_var">id_var</code></td>
<td>
<p>Row identifier variable name.</p>
</td></tr>
<tr><td><code id="plot_completeness_+3A_plot">plot</code></td>
<td>
<p>Character vector containing one or both of <code>variables</code> and
<code>rows</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Completeness bar plot.
</p>


<h3>See Also</h3>

<p>Other measures of completeness: 
<code><a href="#topic+assess_completeness">assess_completeness</a>()</code>,
<code><a href="#topic+compare_completeness">compare_completeness</a>()</code>,
<code><a href="#topic+completeness_heatmap">completeness_heatmap</a>()</code>,
<code><a href="#topic+row_completeness">row_completeness</a>()</code>,
<code><a href="#topic+variable_completeness">variable_completeness</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
plot_completeness(example_data, patient_id, "variables")
</code></pre>

<hr>
<h2 id='prod_catchNAs'>Find product of vector safely</h2><span id='topic+prod_catchNAs'></span>

<h3>Description</h3>

<p>This low-level function is deployed as part of the semantic enrichment
process. Calculates product of values in numeric vector (ignoring NAs). If
all values in numeric vector are <code>NA</code>, returns <code>NA</code> (rather than
Inf),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prod_catchNAs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prod_catchNAs_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>product of <code>x</code>
</p>

<hr>
<h2 id='report_var_mods'>Track changes to dataset variables</h2><span id='topic+report_var_mods'></span>

<h3>Description</h3>

<p>Reports if variables have been added, removed, or are preserved between two
data frames. Intended to be used to review quality control / data
preparation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>report_var_mods(before_tbl = NULL, after_tbl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="report_var_mods_+3A_before_tbl">before_tbl</code></td>
<td>
<p>Data frame from before modifications were made.</p>
</td></tr>
<tr><td><code id="report_var_mods_+3A_after_tbl">after_tbl</code></td>
<td>
<p>Data frame from after modifications were made.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble containing two columns. 'variable' contains name of each
variable. 'presence' contains the presence of the variable in
<code>after_tbl</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_data_merged &lt;- merge_cols(example_data, diabetes_type,
diabetes, "diabetes_merged", rm_in_vars = TRUE)

report_var_mods(example_data, example_data_merged)
</code></pre>

<hr>
<h2 id='review_quality_ctrl'>Review Quality Control</h2><span id='topic+review_quality_ctrl'></span>

<h3>Description</h3>

<p>Provides information on modifications made to a dataset at both variable
(column) and value (sample) levels, designed for review of quality control
measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>review_quality_ctrl(before_tbl, after_tbl, id_var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="review_quality_ctrl_+3A_before_tbl">before_tbl</code></td>
<td>
<p>Data frame from before modifications were made.</p>
</td></tr>
<tr><td><code id="review_quality_ctrl_+3A_after_tbl">after_tbl</code></td>
<td>
<p>Data frame from after modifications were made.</p>
</td></tr>
<tr><td><code id="review_quality_ctrl_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted expression which corresponds to a variable in both
<code>before_tbl</code> and <code>after_tbl</code> which identifies each row. Required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Modifications are identified by comparing the original and modified dataset.
</p>
<p>QC review functions are applied in the following order:
</p>

<ol>
<li><p> Variable-level modifications (<code><a href="#topic+report_var_mods">report_var_mods</a></code>)
</p>
</li>
<li><p> Value-level modifications (<code><a href="#topic+mod_track">mod_track</a></code>)
</p>
</li>
<li><p> Value-level modifications (plot) (<code><a href="#topic+mod_track">mod_track</a></code>)
</p>
</li></ol>

<p>A list containing each of these functions' outputs is returned.
</p>


<h3>Value</h3>

<p>List containing data for review of quality control
</p>


<h3>See Also</h3>

<p>Other high level functionality: 
<code><a href="#topic+apply_quality_ctrl">apply_quality_ctrl</a>()</code>,
<code><a href="#topic+assess_quality">assess_quality</a>()</code>,
<code><a href="#topic+semantic_enrichment">semantic_enrichment</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
require(tibble)

tibble::tribble(~"var", ~"datatype",
"patient_id", "id",
"tumoursize", "numeric",
"t_stage", "ordinal_tstage",
"n_stage", "ordinal_nstage",
"diabetes", "factor",
"diabetes_type", "ordinal",
"hypertension", "factor",
"rural_urban", "factor",
"marital_status", "factor",
"SNP_a", "genotype",
"SNP_b", "genotype",
"free_text", "freetext") -&gt; data_types

   
# create QC'ed dataset
post_QC_example_data &lt;- apply_quality_ctrl(example_data,
                                           patient_id,
                                           data_types,
                                           bin_cats =c("No" = "Yes",
                                                       "rural" = "urban"),
                                           min_freq = 0.6)

# review QC
QC_review &lt;- review_quality_ctrl(before_tbl = example_data,
                    after_tbl = post_QC_example_data,
                    id_var = patient_id)

# view variable level changes
QC_review$variable_level_changes

# view value level changes
QC_review$value_level_changes

# view value level changes as a plot
QC_review$value_level_changes_plt

</code></pre>

<hr>
<h2 id='row_completeness'>Calculate Row Completeness in a Data Frame</h2><span id='topic+row_completeness'></span>

<h3>Description</h3>

<p>Calculates the completeness of each row/observation in a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>row_completeness(data, id_var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="row_completeness_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="row_completeness_+3A_id_var">id_var</code></td>
<td>
<p>Row identifier variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Row completeness is measured by comparing the number of <code>NA</code> to
non-<code>NA</code> values. Returns the count of <code>NA</code> as well as the
percentage of <code>NA</code> values and the percentage completeness.
</p>


<h3>Value</h3>

<p>Tibble detailing completeness statistics for each row in input data.
</p>


<h3>See Also</h3>

<p>Other measures of completeness: 
<code><a href="#topic+assess_completeness">assess_completeness</a>()</code>,
<code><a href="#topic+compare_completeness">compare_completeness</a>()</code>,
<code><a href="#topic+completeness_heatmap">completeness_heatmap</a>()</code>,
<code><a href="#topic+plot_completeness">plot_completeness</a>()</code>,
<code><a href="#topic+variable_completeness">variable_completeness</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
row_completeness(example_data, patient_id)
</code></pre>

<hr>
<h2 id='semantic_enrichment'>Semantic enrichment</h2><span id='topic+semantic_enrichment'></span>

<h3>Description</h3>

<p>Enriches a dataset with additional (meta-)variables derived from the semantic
commonalities between variables (columns).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semantic_enrichment(
  data,
  ontology,
  mapping_file,
  mode = "in",
  root,
  label_attr = "name",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semantic_enrichment_+3A_data">data</code></td>
<td>
<p>Required. Numeric data frame or matrix containing variables present in
the mapping file.</p>
</td></tr>
<tr><td><code id="semantic_enrichment_+3A_ontology">ontology</code></td>
<td>
<p>Required. One of: </p>
<ul>
<li><p> Path to ontology edge table in .csv format (String)</p>
</li>
<li><p> Edge
table in data frame format </p>
</li>
<li><p> Graph containing the chosen ontology -
must be in <code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> format or coercible
to this format.</p>
</li></ul>
<p>.</p>
</td></tr>
<tr><td><code id="semantic_enrichment_+3A_mapping_file">mapping_file</code></td>
<td>
<p>Required. Path to csv file or data frame containing mapping
information. Should contain two columns only. The first column should
contain column names, present in the data frame. The second column should
contain the name of entities present in the ontology object.</p>
</td></tr>
<tr><td><code id="semantic_enrichment_+3A_mode">mode</code></td>
<td>
<p>Character constant specifying the directionality of the edges.
One of: &quot;in&quot; or &quot;out&quot;.</p>
</td></tr>
<tr><td><code id="semantic_enrichment_+3A_root">root</code></td>
<td>
<p>Required. Name of root node identifier in column 1 to calculate node depth
from.</p>
</td></tr>
<tr><td><code id="semantic_enrichment_+3A_label_attr">label_attr</code></td>
<td>
<p>Node attribute containing labels used for column names when
creating metavariable aggregations. Default: &quot;name&quot;</p>
</td></tr>
<tr><td><code id="semantic_enrichment_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="readr.html#topic+read_csv">read_csv</a></code> when reading 'mapping_file'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Semantic enrichment generates meta-variables from the aggregation of data
variables (columns) via their most informative common ancestor. Meta-variables are
labelled using the syntax: <code>MV_[label_attr]_[Aggregation function]</code>. The
data variables are aggregated row-wise by their maximum, minimum, mean, sum,
and product. Meta-variables with zero entropy (no information) are not
appended to the data.
See the &quot;Semantic Enrichment&quot; section in the vignette of 'eHDPrep' for more
information: <code>vignette("Introduction_to_eHDPrep", package = "eHDPrep")</code>
</p>


<h3>Value</h3>

<p>Semantically enriched dataset
</p>


<h3>Note</h3>

<p>A warning may be shown regarding the '.add' argument being deprecated, this is
believed to be an issue with 'tidygraph' which may be resolved in a future release: 
&lt;https://github.com/thomasp85/tidygraph/issues/131&gt;. Another warning may be shown regarding the 'neimode' argument being deprecated, this is
believed to be an issue with 'tidygraph' which may be resolved in a future release: 
&lt;https://github.com/thomasp85/tidygraph/issues/156&gt;. These warning messages are not believed to have
an effect on the functionality of 'eHDPrep'.
</p>


<h3>See Also</h3>

<p>Other high level functionality: 
<code><a href="#topic+apply_quality_ctrl">apply_quality_ctrl</a>()</code>,
<code><a href="#topic+assess_quality">assess_quality</a>()</code>,
<code><a href="#topic+review_quality_ctrl">review_quality_ctrl</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(magrittr)
require(dplyr)
data(example_ontology)
data(example_mapping_file)
data(example_data)

#' # define datatypes
tibble::tribble(~"var", ~"datatype",
"patient_id", "id",
"tumoursize", "numeric",
"t_stage", "ordinal_tstage",
"n_stage", "ordinal_nstage",
"diabetes_merged", "character",
"hypertension", "factor",
"rural_urban", "factor",
"marital_status", "factor",
"SNP_a", "genotype",
"SNP_b", "genotype",
"free_text", "freetext") -&gt; data_types

# create post-QC data
example_data %&gt;%
  merge_cols(diabetes_type, diabetes, "diabetes_merged", rm_in_vars = TRUE) %&gt;%
  apply_quality_ctrl(patient_id, data_types,
                     bin_cats =c("No" = "Yes", "rural" = "urban"),
                     to_numeric_matrix = TRUE) %&gt;%
                     suppressMessages() -&gt;
                     post_qc_data

# minimal example on first four coloums of example data:
semantic_enrichment(post_qc_data[1:10,1:4],
                    dplyr::slice(example_ontology, 1:7,24),
                    example_mapping_file[1:3,], root = "root") -&gt; res
# see Note section of documentation for information on possible warnings.

# summary of result:
tibble::glimpse(res)


# full example:
 res &lt;- semantic_enrichment(post_qc_data, example_ontology,
 example_mapping_file, root = "root")
 # see Note section of documentation for information on possible warnings.

</code></pre>

<hr>
<h2 id='skipgram_append'>Append Skipgram Presence Variables to Dataset</h2><span id='topic+skipgram_append'></span>

<h3>Description</h3>

<p>Adds new variables to <code>data</code> which report the presence of skipgrams
(either those specified in <code>skipgrams2append</code> or, if not specified,
skipgrams with a minimum frequency (<code>min_freq</code>, default = 1)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skipgram_append(skipgram_tokens, skipgrams2append, data, id_var, min_freq = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skipgram_append_+3A_skipgram_tokens">skipgram_tokens</code></td>
<td>
<p>Output of <code><a href="#topic+skipgram_identify">skipgram_identify</a></code>.</p>
</td></tr>
<tr><td><code id="skipgram_append_+3A_skipgrams2append">skipgrams2append</code></td>
<td>
<p>Which skipgrams in <code>skipgram_tokens</code> to append
to dataset.</p>
</td></tr>
<tr><td><code id="skipgram_append_+3A_data">data</code></td>
<td>
<p>Data frame to append skipgram variables to.</p>
</td></tr>
<tr><td><code id="skipgram_append_+3A_id_var">id_var</code></td>
<td>
<p>An unquoted  expression which corresponds to a variable in
<code>data</code> which identifies each row.</p>
</td></tr>
<tr><td><code id="skipgram_append_+3A_min_freq">min_freq</code></td>
<td>
<p>Minimum percentage frequency of skipgram occurrence to
return. Default = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data</code> with additional variables describing presence of
skipgrams
</p>


<h3>References</h3>

<p>Guthrie, D., Allison, B., Liu, W., Guthrie, L. &amp; Wilks, Y. A
Closer Look at Skip-gram Modelling. in Proceedings of the Fifth
International Conference on Language Resources and Evaluation (LREC06)
(European Language Resources Association (ELRA), 2006).
</p>
<p>Benoit K, Watanabe K, Wang H, Nulty P, Obeng A, Mller S, Matsuo A (2018).
quanteda: An R package for the quantitative analysis of textual data. _Journal
of Open Source Software_, *3*(30), 774. doi:10.21105/joss.00774
&lt;https://doi.org/10.21105/joss.00774&gt;, &lt;https://quanteda.io&gt;.
</p>
<p>Feinerer I, Hornik K (2020). _tm: Text Mining Package_. R package version 0.7-8,
&lt;https://CRAN.R-project.org/package=tm&gt;.
</p>
<p>Ingo Feinerer, Kurt Hornik, and David Meyer (2008). Text Mining Infrastructure in
R. Journal of Statistical Software 25(5): 1-54. URL:
https://www.jstatsoft.org/v25/i05/.
</p>


<h3>See Also</h3>

<p>Principle underlying function: <code><a href="quanteda.html#topic+tokens_ngrams">tokens_ngrams</a></code>
</p>
<p>Other free text functions: 
<code><a href="#topic+extract_freetext">extract_freetext</a>()</code>,
<code><a href="#topic+skipgram_freq">skipgram_freq</a>()</code>,
<code><a href="#topic+skipgram_identify">skipgram_identify</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
# identify skipgrams
toks_m &lt;- skipgram_identify(x = example_data$free_text,
                            ids = example_data$patient_id,
                            max_interrupt_words = 5)
# add skipgrams by minimum frequency
skipgram_append(toks_m,
                id_var = patient_id,
                min_freq = 0.6,
                data = example_data)
# add specific skipgrams
skipgram_append(toks_m,
                id_var = patient_id,
                skipgrams2append = c("sixteen_week", "bad_strain"),
                data = example_data)
</code></pre>

<hr>
<h2 id='skipgram_freq'>Report Skipgram Frequency</h2><span id='topic+skipgram_freq'></span>

<h3>Description</h3>

<p>Measures the frequency of skipgrams (non-contiguous words in free text), reported in a
tibble. Frequency is reported as both counts and percentages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skipgram_freq(skipgram_tokens, min_freq = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skipgram_freq_+3A_skipgram_tokens">skipgram_tokens</code></td>
<td>
<p>Output of <code><a href="#topic+skipgram_identify">skipgram_identify</a></code>.</p>
</td></tr>
<tr><td><code id="skipgram_freq_+3A_min_freq">min_freq</code></td>
<td>
<p>Minimum skipgram percentage frequency of occurrence to
retain. Default = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing frequency of skipgrams in absolute count and
relative to the length of input variable.
</p>


<h3>References</h3>

<p>Guthrie, D., Allison, B., Liu, W., Guthrie, L. &amp; Wilks, Y. A
Closer Look at Skip-gram Modelling. in Proceedings of the Fifth
International Conference on Language Resources and Evaluation (LREC06)
(European Language Resources Association (ELRA), 2006).
</p>
<p>Benoit K, Watanabe K, Wang H, Nulty P, Obeng A, Mller S, Matsuo A (2018).
quanteda: An R package for the quantitative analysis of textual data. _Journal
of Open Source Software_, *3*(30), 774. doi:10.21105/joss.00774
&lt;https://doi.org/10.21105/joss.00774&gt;, &lt;https://quanteda.io&gt;.
</p>
<p>Feinerer I, Hornik K (2020). _tm: Text Mining Package_. R package version 0.7-8,
&lt;https://CRAN.R-project.org/package=tm&gt;.
</p>
<p>Ingo Feinerer, Kurt Hornik, and David Meyer (2008). Text Mining Infrastructure in
R. Journal of Statistical Software 25(5): 1-54. URL:
https://www.jstatsoft.org/v25/i05/.
</p>


<h3>See Also</h3>

<p>Principle underlying function: <code><a href="quanteda.html#topic+tokens_ngrams">tokens_ngrams</a></code>
</p>
<p>Other free text functions: 
<code><a href="#topic+extract_freetext">extract_freetext</a>()</code>,
<code><a href="#topic+skipgram_append">skipgram_append</a>()</code>,
<code><a href="#topic+skipgram_identify">skipgram_identify</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
toks_m &lt;- skipgram_identify(x = example_data$free_text,
                            ids = example_data$patient_id,
                            max_interrupt_words = 5)
skipgram_freq(toks_m, min_freq = 0.5)
</code></pre>

<hr>
<h2 id='skipgram_identify'>Identify Neighbouring Words (Skipgrams) in a free-text vector</h2><span id='topic+skipgram_identify'></span>

<h3>Description</h3>

<p>Identifies words which appear near each other in the free-text variable
(<code>var</code>), referred to as &quot;Skipgrams&quot;. Supported languages for stop words
and stemming are <code>danish</code>, <code>dutch</code>, <code>english</code>, <code>finnish</code>,
<code>french</code>, <code>german</code>, <code>hungarian</code>, <code>italian</code>,
<code>norwegian</code>, <code>portuguese</code>, <code>russian</code>, <code>spanish</code>, and
<code>swedish</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skipgram_identify(
  x,
  ids,
  num_of_words = 2,
  max_interrupt_words = 2,
  words_to_rm = NULL,
  lan = "english"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skipgram_identify_+3A_x">x</code></td>
<td>
<p>Free-text character vector to query.</p>
</td></tr>
<tr><td><code id="skipgram_identify_+3A_ids">ids</code></td>
<td>
<p>Character vector containing IDs for each element of <code>var</code>.</p>
</td></tr>
<tr><td><code id="skipgram_identify_+3A_num_of_words">num_of_words</code></td>
<td>
<p>Number of words to consider for each returned skipgram.
Default = 2.</p>
</td></tr>
<tr><td><code id="skipgram_identify_+3A_max_interrupt_words">max_interrupt_words</code></td>
<td>
<p>Maximum number of words which can interrupt
proximal words. Default = 2.</p>
</td></tr>
<tr><td><code id="skipgram_identify_+3A_words_to_rm">words_to_rm</code></td>
<td>
<p>Character vector of words which should not be considered.</p>
</td></tr>
<tr><td><code id="skipgram_identify_+3A_lan">lan</code></td>
<td>
<p>Language of <code>var</code>. Default: <code>english</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble containing skipgrams as variables and patient values as rows.
</p>


<h3>References</h3>

<p>Guthrie, D., Allison, B., Liu, W., Guthrie, L. &amp; Wilks, Y. A
Closer Look at Skip-gram Modelling. in Proceedings of the Fifth
International Conference on Language Resources and Evaluation (LREC06)
(European Language Resources Association (ELRA), 2006).
</p>
<p>Benoit K, Watanabe K, Wang H, Nulty P, Obeng A, Mller S, Matsuo A (2018).
quanteda: An R package for the quantitative analysis of textual data. _Journal
of Open Source Software_, *3*(30), 774. doi:10.21105/joss.00774
&lt;https://doi.org/10.21105/joss.00774&gt;, &lt;https://quanteda.io&gt;.
</p>
<p>Feinerer I, Hornik K (2020). _tm: Text Mining Package_. R package version 0.7-8,
&lt;https://CRAN.R-project.org/package=tm&gt;.
</p>
<p>Ingo Feinerer, Kurt Hornik, and David Meyer (2008). Text Mining Infrastructure in
R. Journal of Statistical Software 25(5): 1-54. URL:
https://www.jstatsoft.org/v25/i05/.
</p>


<h3>See Also</h3>

<p>Principle underlying function: <code><a href="quanteda.html#topic+tokens_ngrams">tokens_ngrams</a></code>
</p>
<p>Other free text functions: 
<code><a href="#topic+extract_freetext">extract_freetext</a>()</code>,
<code><a href="#topic+skipgram_append">skipgram_append</a>()</code>,
<code><a href="#topic+skipgram_freq">skipgram_freq</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
skipgram_identify(x = example_data$free_text,
                  ids = example_data$patient_id,
                  max_interrupt_words = 5)
</code></pre>

<hr>
<h2 id='strings_to_NA'>Replace values in non-numeric columns with NA</h2><span id='topic+strings_to_NA'></span>

<h3>Description</h3>

<p>Replaces specified or pre-defined strings in non-numeric columns with
<code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strings_to_NA(data, ..., strings_to_replace = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strings_to_NA_+3A_data">data</code></td>
<td>
<p>A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr).</p>
</td></tr>
<tr><td><code id="strings_to_NA_+3A_...">...</code></td>
<td>
<p>&lt;<code><a href="dplyr.html#topic+dplyr_tidy_select">tidy-select</a></code>&gt; One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like <code>x:y</code> can
be used to select a range of variables.</p>
</td></tr>
<tr><td><code id="strings_to_NA_+3A_strings_to_replace">strings_to_replace</code></td>
<td>
<p>character vector of values to be replaced with
<code>NA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Columns to process can be specified in custom arguments (<code>...</code>) or will
be applied to all non-numeric columns.
Default strings which will be replaced with <code>NA</code> are as follows:
&quot;Undetermined&quot;, &quot;unknown&quot;, &quot;missing&quot;, &quot;fail&quot;, &quot;fail / unknown&quot;, 
&quot;equivocal&quot;, &quot;equivocal / unknown&quot;, &quot;*&quot;.
String search is made using <code><a href="base.html#topic+grepl">grepl</a></code> and supports
<code><a href="base.html#topic+regex">regex</a></code> so metacharacters (<code>. \ | ( ) [ ] {  } ^ $ * + ? $</code>)
should be escaped with a &quot;<code>\</code>&quot; prefix.
Matches are case sensitive by default but can ignore case with the parameter: 
<code>ignore.case = TRUE</code> in <code>...</code>).
</p>


<h3>Value</h3>

<p>data with specified values replaced with NA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)

# original unique values in diabetes column:
unique(example_data$diabetes)
# Using default values
res &lt;- strings_to_NA(example_data)
unique(res$diabetes)


# original unique values in diabetes_type column:
unique(example_data$diabetes_type)
# Using custom values
res &lt;- strings_to_NA(example_data, strings_to_replace = "Type I")
unique(res$diabetes_type)

</code></pre>

<hr>
<h2 id='sum_catchNAs'>Sum vector safely for semantic enrichment</h2><span id='topic+sum_catchNAs'></span>

<h3>Description</h3>

<p>sums values in x (ignoring NAs). If all values in x are <code>NA</code>, returns
<code>NA</code> (rather than 0),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sum_catchNAs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sum_catchNAs_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sum of <code>x</code>
</p>

<hr>
<h2 id='validate_consistency_tbl'>Validate internal consistency table</h2><span id='topic+validate_consistency_tbl'></span>

<h3>Description</h3>

<p>Runs a series of checks on a table of internal consistency rules
(see Consistency Table Requirements) in preparation for <code><a href="#topic+identify_inconsistency">identify_inconsistency</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_consistency_tbl(data, consis_tbl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_consistency_tbl_+3A_data">data</code></td>
<td>
<p>data frame which will be checked for internal consistency</p>
</td></tr>
<tr><td><code id="validate_consistency_tbl_+3A_consis_tbl">consis_tbl</code></td>
<td>
<p>data frame or tibble containing information on internal
consistency rules (see &quot;Consistency Table Requirements&quot; section)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Error message or successful validation message is printed.
The dataset is returned invisibly.
</p>


<h3>Consistency Table Requirements</h3>

<p>Table must have exactly five character columns.
The columns should be ordered according to the list below which describes the
values of each column:
</p>

<ol>
<li><p> First column name of data values that will be subject to 
consistency checking. String. Required.
</p>
</li>
<li><p> Second column name of data values that will be subject to 
consistency checking. String. Required.
</p>
</li>
<li><p> Logical test to compare columns one and two. One of: &quot;&gt;&quot;,&quot;&gt;=&quot;,
&quot;&lt;&quot;,&quot;&lt;=&quot;,&quot;==&quot;, &quot;!=&quot;. String. Optional if columns 4 and 5 have non-<code>NA</code> values.
</p>
</li>
<li><p> Either a single character string or a colon-separated range of
numbers which should only appear in column A. Optional if column 3 has a
non-<code>NA</code> value.
</p>
</li>
<li><p> Either a single character string or a colon-separated range of
numbers which should only appear in column B given the value/range
specified in column 4. Optional if column 3 has a non-<code>NA</code> value.
</p>
</li></ol>

<p>Each row should detail one test to make.
Therefore, either column 3 or columns 4 and 5 must contain non-<code>NA</code>
values.
</p>


<h3>See Also</h3>

<p>Other internal consistency functions: 
<code><a href="#topic+identify_inconsistency">identify_inconsistency</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(tibble)
# example with synthetic dataset on number of bean counters
# there is a lot going on in the function so a simple dataset aids this example
#
# creating `data`:
beans &lt;- tibble::tibble(red_beans = 1:15,
blue_beans = 1:15,
total_beans = 1:15*2,
red_bean_summary = c(rep("few_beans",9), rep("many_beans",6)))
#
# creating `consis_tbl`
bean_rules &lt;- tibble::tribble(~varA, ~varB, ~lgl_test, ~varA_boundaries, ~varB_boundaries,
"red_beans", "blue_beans", "==", NA, NA,
"red_beans", "total_beans", "&lt;=", NA,NA,
"red_beans", "red_bean_summary", NA, "1:9", "few_beans",
"red_beans", "red_bean_summary", NA, "10:15", "many_beans")

validate_consistency_tbl(beans, bean_rules)
</code></pre>

<hr>
<h2 id='validate_mapping_tbl'>Validate mapping table for semantic enrichment</h2><span id='topic+validate_mapping_tbl'></span>

<h3>Description</h3>

<p>Applies tests to a mapping table to ensure it is valid for use with
the data frame and ontological graph, in preparation for semantic enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_mapping_tbl(mapping_tbl, data, ontol_graph)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_mapping_tbl_+3A_mapping_tbl">mapping_tbl</code></td>
<td>
<p>data frame. Contains two columns. First column contains
variable names of a primary dataset. Second column contains entities in
an ontological graph to which the primary dataset's variable names are mapped.</p>
</td></tr>
<tr><td><code id="validate_mapping_tbl_+3A_data">data</code></td>
<td>
<p>data frame. Primary dataset which contains variable names
referred to in first column of the mapping table</p>
</td></tr>
<tr><td><code id="validate_mapping_tbl_+3A_ontol_graph">ontol_graph</code></td>
<td>
<p>ontological graph which contains entity names/IDs referred
to in second column of the mapping table</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Any warnings and the mapping table returned invisibly
</p>

<hr>
<h2 id='validate_ontol_nw'>Validate ontology network for semantic enrichment</h2><span id='topic+validate_ontol_nw'></span>

<h3>Description</h3>

<p>Performs tests on a graph object in preparation for semantic enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_ontol_nw(graph)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_ontol_nw_+3A_graph">graph</code></td>
<td>
<p>graph object to validate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tests are:
</p>

<ol>
<li><p> Is graph coercible to <code><a href="tidygraph.html#topic+tidygraph">tidygraph</a></code> format?
</p>
</li>
<li><p> Is graph directed?
</p>
</li>
<li><p> Does graph contains one component (is one ontology)?
</p>
</li></ol>



<h3>Value</h3>

<p>input graph or validation errors
</p>

<hr>
<h2 id='variable_completeness'>Calculate Variable Completeness in a Data Frame</h2><span id='topic+variable_completeness'></span>

<h3>Description</h3>

<p>Calculates the completeness of each variable in a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_completeness(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable_completeness_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is achieved by comparing the number of <code>NA</code> to non-<code>NA</code>
values. Returns the count of <code>NA</code> as well as the percentage of <code>NA</code>
values and the percentage completeness.
</p>


<h3>Value</h3>

<p><code>Tibble</code> detailing completeness statistics for each variable.
</p>


<h3>See Also</h3>

<p>Other measures of completeness: 
<code><a href="#topic+assess_completeness">assess_completeness</a>()</code>,
<code><a href="#topic+compare_completeness">compare_completeness</a>()</code>,
<code><a href="#topic+completeness_heatmap">completeness_heatmap</a>()</code>,
<code><a href="#topic+plot_completeness">plot_completeness</a>()</code>,
<code><a href="#topic+row_completeness">row_completeness</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
variable_completeness(example_data)
</code></pre>

<hr>
<h2 id='variable_entropy'>Calculate Entropy of Each Variable in Data Frame</h2><span id='topic+variable_entropy'></span>

<h3>Description</h3>

<p>Calculates Shannon entropy of all variables in a data frame in bits (default) or
natural units. Missing values are omitted from the calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_entropy(data, unit = "bits")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable_entropy_+3A_data">data</code></td>
<td>
<p>Data Frame to compute on</p>
</td></tr>
<tr><td><code id="variable_entropy_+3A_unit">unit</code></td>
<td>
<p>Unit to measure entropy. Either &quot;bits&quot; (default) or &quot;nats&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named numeric vector containing entropy values
</p>


<h3>References</h3>

<p>Shannon, C. E. A mathematical theory of communication. The Bell
System Technical Journal 27, 379423 (1948).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix(c(c(1,1,1,1,1,1, 1,2,3,4,5,6)),ncol = 2, dimnames =
list(seq(1,6), c("no_entropy","entropy")))
variable_entropy(as.data.frame(a))
</code></pre>

<hr>
<h2 id='variable.bw.kde'>Variable bandwidth Kernel Density Estimation</h2><span id='topic+variable.bw.kde'></span>

<h3>Description</h3>

<p>Calculates variable bandwidth KDE using Abramson's two stage estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable.bw.kde(x, output.domain = x, na.rm = FALSE, adjust.factor = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable.bw.kde_+3A_x">x</code></td>
<td>
<p>A numeric vector of values for estimating density</p>
</td></tr>
<tr><td><code id="variable.bw.kde_+3A_output.domain">output.domain</code></td>
<td>
<p>The domain of values over which to estimate the
density. Defaults to <code>x</code>. To use the same domain of <code>x</code> values
as <span class="rlang"><b>R</b></span>'s <code>density</code>, set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="variable.bw.kde_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove missing values if TRUE</p>
</td></tr>
<tr><td><code id="variable.bw.kde_+3A_adjust.factor">adjust.factor</code></td>
<td>
<p>A scaling factor (exponent) applied to the variable
bandwidth calculation. Larger factors result in greater deviation from the
fixed bandwidth (a value of 0 gives the fixed bandwidth case).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bandwidth is first calculated using Silverman's estimator, then refined in a
second stage to allow local bandwidth variations in the data based on the
initial estimate.
</p>


<h3>Value</h3>

<p>The kernel density estimate as a <code>density</code> object, compatible
with <span class="rlang"><b>R</b></span>'s <code>density</code> function.
</p>


<h3>Author(s)</h3>

<p>Alexander Lyulph Robert Lubbock, Ian Overton
</p>


<h3>References</h3>

<p>Abramson, I. S. On Bandwidth Variation in Kernel Estimates-A
Square Root Law. Ann. Statist. 10, 1217-1223 (1982).
</p>

<hr>
<h2 id='warn_missing_dots'>Missing dots warning</h2><span id='topic+warn_missing_dots'></span>

<h3>Description</h3>

<p>Internal function. Warns if dots (...) argument have not been supplied
</p>


<h3>Usage</h3>

<pre><code class='language-R'>warn_missing_dots(test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="warn_missing_dots_+3A_test">test</code></td>
<td>
<p>expression to test.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>warning to user that no values were modified
</p>

<hr>
<h2 id='zero_entropy_variables'>Identify variables with zero entropy</h2><span id='topic+zero_entropy_variables'></span>

<h3>Description</h3>

<p>Calculates Shannon entropy of variables in a data frame in bits (default) or
natural units. Missing values are omitted from the calculation.
Names of variables with zero entropy are returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zero_entropy_variables(data, unit = "bits")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zero_entropy_variables_+3A_data">data</code></td>
<td>
<p>Data Frame to compute on</p>
</td></tr>
<tr><td><code id="zero_entropy_variables_+3A_unit">unit</code></td>
<td>
<p>Unit to measure entropy. Either &quot;bits&quot; (default) or &quot;nats&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector of variable names with zero entropy
</p>


<h3>References</h3>

<p>Shannon, C. E. A mathematical theory of communication. The Bell
System Technical Journal 27, 379423 (1948).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data)
zero_entropy_variables(example_data)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
