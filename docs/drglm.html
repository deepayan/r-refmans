<!DOCTYPE html><html><head><title>Help for package drglm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {drglm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#big.drglm'><p>Fitting Linear and Generalized Linear Models to out of the memory data sets in &quot;Divide and Recombine&quot; approach</p></a></li>
<li><a href='#drglm'><p>Fitting Linear and Generalized Linear Model in &quot;Divide and Recombine&quot; approach to Large Data Sets</p></a></li>
<li><a href='#drglm.multinom'><p>Fitting Multinomial Logistic Regression model in &quot;Divide and Recombine&quot; approach to Large Data Sets</p></a></li>
<li><a href='#make.data'><p>Reading Data File Larger than Memory for Fitting GLMs Using <code>big.drglm</code> Function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fitting Linear and Generalized Linear Models in "Divide and
Recombine" Approach to Large Data Sets</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Md. Mahadi Hassan Nayem &lt;mhnayem.cu.stat@outlook.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>nnet, speedglm, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>To overcome the memory limitations for fitting linear (LM) and Generalized Linear Models (GLMs) to large data sets, this package implements the Divide and Recombine (D&amp;R) strategy. It basically divides the entire large data set into suitable subsets manageable in size and then fits model to each subset. Finally, results from each subset are aggregated to obtain the final estimate. This package also supports fitting GLMs to data sets that cannot fit into memory and provides methods for fitting GLMs under linear regression, binomial regression, Poisson regression, and multinomial logistic regression settings. Respective models are fitted using different D&amp;R strategies as described by: Xi, Lin, and Chen (2009) &lt;<a href="https://doi.org/10.1109%2FTKDE.2008.186">doi:10.1109/TKDE.2008.186</a>&gt;, Xi, Lin and Chen (2006) &lt;<a href="https://doi.org/10.1109%2FTKDE.2006.196">doi:10.1109/TKDE.2006.196</a>&gt;, Zuo and Li (2018) &lt;<a href="https://doi.org/10.4236%2Fojs.2018.81003">doi:10.4236/ojs.2018.81003</a>&gt;, Karim, M.R., Islam, M.A. (2019) &lt;<a href="https://doi.org/10.1007%2F978-981-13-9776-9">doi:10.1007/978-981-13-9776-9</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://nayemmh.github.io/drglm/">https://nayemmh.github.io/drglm/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-10 14:27:38 UTC; mhnay</td>
</tr>
<tr>
<td>Author:</td>
<td>Md. Mahadi Hassan Nayem [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-12 11:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='big.drglm'>Fitting Linear and Generalized Linear Models to out of the memory data sets in &quot;Divide and Recombine&quot; approach</h2><span id='topic+big.drglm'></span>

<h3>Description</h3>

<p>Function <code>big.drglm</code> aimed to fit GLMs to datasets larger in size that can not be  stored in memory. It uses popular divide and recombine technique to handle large data sets efficiently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big.drglm(data.generator, formula, chunks, family)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big.drglm_+3A_data.generator">data.generator</code></td>
<td>
<p>Using the function <code><a href="#topic+make.data">make.data</a></code> to initialize the data reading function with the data set path and chunk size, then the data.generate is used directly as data source for the <code><a href="#topic+big.drglm">big.drglm</a></code> function.</p>
</td></tr>
<tr><td><code id="big.drglm_+3A_formula">formula</code></td>
<td>
<p>An entity belonging to the &quot;formula&quot; class (or one that can be transformed into that class) represents a symbolic representation of the model that needs to be adjusted. Specifics about how the model is defined can be found in the 'Details' section.</p>
</td></tr>
<tr><td><code id="big.drglm_+3A_chunks">chunks</code></td>
<td>
<p>Number of subsets to be divided.</p>
</td></tr>
<tr><td><code id="big.drglm_+3A_family">family</code></td>
<td>
<p>An explanation of the error distribution that will be implemented in the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Generalized Linear Model is fitted in &quot;Divide &amp; Recombine&quot; approach using preferred number of chunks to data set. A list of model coefficients is estimated using divide and recombine method with the respective standard error of estimates.
</p>


<h3>Author(s)</h3>

<p>MH Nayem
</p>


<h3>References</h3>


<ul>
<li><p> Xi, R., Lin, N., &amp; Chen, Y. (2009). Compression and aggregation for logistic regression analysis in data cubes. IEEE Transactions on Knowledge and Data Engineering, 21(4).
</p>
</li>
<li><p> Chen, Y., Dong, G., Han, J., Pei, J., Wah, B. W., &amp; Wang, J. (2006). Regression cubes with losseless compression and aggregation. IEEE Transactions on Knowledge and Data Engineering, 18(12).
</p>
</li>
<li><p> Zuo, W., &amp; Li, Y. (2018). A New Stochastic Restricted Liu Estimator for the Logistic Regression Model. Open Journal of Statistics, 08(01).
</p>
</li>
<li><p> Karim, M. R., &amp; Islam, M. A. (2019). Reliability and Survival Analysis. In Reliability and Survival Analysis.
</p>
</li>
<li><p> Enea, M. (2009) Fitting Linear Models and Generalized Linear Models with large data sets in R.
</p>
</li>
<li><p> Bates, D. (2009) Technical Report on Least Square Calculations.
</p>
</li>
<li><p> Lumley, T. (2009) <em>biglm</em> package documentation.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+drglm">drglm</a></code>, <code><a href="#topic+drglm.multinom">drglm.multinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a toy dataset
set.seed(123)
# Number of rows to be generated
n &lt;- 10000

# Creating dataset
dataset &lt;- data.frame(
  Var_1 = round(rnorm(n, mean = 50, sd = 10)),
  Var_2 = round(rnorm(n, mean = 7.5, sd = 2.1)),
  Var_3 = as.factor(sample(c("0", "1"), n, replace = TRUE)),
  Var_4 = as.factor(sample(c("0", "1", "2"), n, replace = TRUE)),
  Var_5 = as.factor(sample(0:15, n, replace = TRUE)),
  Var_6 = round(rnorm(n, mean = 60, sd = 5))
)

# Save the dataset to a temporary file
temp_file &lt;- tempfile(fileext = ".csv")
write.csv(dataset, file = temp_file, row.names = FALSE)

# Path to the temporary file
dataset_path &lt;- temp_file
dataset_path  # Display the path to the temporary file

# Initialize the data reading function with the data set path and chunk size
da &lt;- drglm::make.data(dataset_path, chunksize = 1000)
# Fitting MLR Models
nmodel &lt;- drglm::big.drglm(da,
formula = Var_1 ~ Var_2+ factor(Var_3)+factor(Var_4)+ factor(Var_5)+ Var_6,
10, family="gaussian")
# View the results table
print(nmodel)
# Fitting logistic Regression Model
bmodel &lt;- drglm::big.drglm(da,
formula = factor(Var_3) ~ Var_1+ Var_2+ factor(Var_4)+ factor(Var_5)+ Var_6,
10, family="binomial")
# View the results table
print(bmodel)
# Fitting Poisson Regression Model
pmodel &lt;- drglm::big.drglm(da,
formula = Var_5 ~ Var_1+ Var_2+ factor(Var_3)+ factor(Var_4)+ Var_6,
10, family="poisson")
# View the results table
print(pmodel)
</code></pre>

<hr>
<h2 id='drglm'>Fitting Linear and Generalized Linear Model in &quot;Divide and Recombine&quot; approach to Large Data Sets</h2><span id='topic+drglm'></span>

<h3>Description</h3>

<p>Function <code>drglm</code> aimed to fit GLMs to datasets larger in size that can be stored in memory. It uses popular divide and recombine technique to handle large data sets efficiently.Function <code>drglm</code> optimizes performance when linked with optimized BLAS libraries like ATLAS.The function <code>drglm</code> requires defining the number of chunks K and the fitfunction.The rest of the arguments are almost identical with the speedglm or biglm package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drglm(formula, family, data, k, fitfunction)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drglm_+3A_formula">formula</code></td>
<td>
<p>An entity belonging to the &quot;formula&quot; class (or one that can be transformed into that class) represents a symbolic representation of the model that needs to be adjusted. Specifics about how the model is defined can be found in the 'Details' section.</p>
</td></tr>
<tr><td><code id="drglm_+3A_family">family</code></td>
<td>
<p>An explanation of the error distribution that will be implemented in the model.</p>
</td></tr>
<tr><td><code id="drglm_+3A_data">data</code></td>
<td>
<p>A data frame, list, or environment that is not required but can be provided if available.</p>
</td></tr>
<tr><td><code id="drglm_+3A_k">k</code></td>
<td>
<p>Number of subsets to be used.</p>
</td></tr>
<tr><td><code id="drglm_+3A_fitfunction">fitfunction</code></td>
<td>
<p>The function to be utilized for model fitting. <code>glm</code> or <code>speedglm</code> should be used.For Multinomial models, <code>multinom</code> function is preferred.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Generalized Linear Model is fitted in &quot;Divide &amp; Recombine&quot; approach using &quot;k&quot; chunks to data set. A list of model coefficients is estimated using divide and recombine method with the respective standard error of estimates.
</p>


<h3>Author(s)</h3>

<p>MH Nayem
</p>


<h3>References</h3>


<ul>
<li><p> Xi, R., Lin, N., &amp; Chen, Y. (2009). Compression and aggregation for logistic regression analysis in data cubes. IEEE Transactions on Knowledge and Data Engineering, 21(4).
</p>
</li>
<li><p> Chen, Y., Dong, G., Han, J., Pei, J., Wah, B. W., &amp; Wang, J. (2006). Regression cubes with lossless compression and aggregation. IEEE Transactions on Knowledge and Data Engineering, 18(12).
</p>
</li>
<li><p> Zuo, W., &amp; Li, Y. (2018). A New Stochastic Restricted Liu Estimator for the Logistic Regression Model. Open Journal of Statistics, 08(01).
</p>
</li>
<li><p> Karim, M. R., &amp; Islam, M. A. (2019). Reliability and Survival Analysis. In Reliability and Survival Analysis.
</p>
</li>
<li><p> Enea, M. (2009) Fitting Linear Models and Generalized Linear Models with large data sets in R.
</p>
</li>
<li><p> Bates, D. (2009) Technical Report on Least Square Calculations.
</p>
</li>
<li><p> Lumley, T. (2009) <em>biglm</em> package documentation.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+big.drglm">big.drglm</a></code>, <code><a href="#topic+drglm.multinom">drglm.multinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
#Number of rows to be generated
n &lt;- 10000
#creating dataset
dataset &lt;- data.frame( pred_1 = round(rnorm(n, mean = 50, sd = 10)),
pred_2 = round(rnorm(n, mean = 7.5, sd = 2.1)),
pred_3 = as.factor(sample(c("0", "1"), n, replace = TRUE)),
pred_4 = as.factor(sample(c("0", "1", "2"), n, replace = TRUE)),
pred_5 = as.factor(sample(0:15, n, replace = TRUE)),
pred_6 = round(rnorm(n, mean = 60, sd = 5)))
#fitting MLRM
nmodel= drglm::drglm(pred_1 ~ pred_2+ pred_3+ pred_4+ pred_5+ pred_6,
data=dataset, family="gaussian", fitfunction="speedglm", k=10)
#Output
nmodel
#fitting simple logistic regression model
bmodel=drglm::drglm(pred_3~ pred_1+ pred_2+ pred_4+ pred_5+ pred_6,
data=dataset, family="binomial", fitfunction="speedglm", k=10)
#Output
bmodel
#fitting poisson regression model
pmodel=drglm::drglm(pred_5~ pred_1+ pred_2+ pred_3+ pred_4+ pred_6,
data=dataset, family="binomial", fitfunction="speedglm", k=10)
#Output
pmodel
#fitting multinomial logistic regression model
mmodel=drglm::drglm(pred_4~ pred_1+ pred_2+ pred_3+ pred_5+ pred_6,
data=dataset, family="multinomial", fitfunction="multinom", k=10)
#Output
mmodel
</code></pre>

<hr>
<h2 id='drglm.multinom'>Fitting Multinomial Logistic Regression model in &quot;Divide and Recombine&quot; approach to Large Data Sets</h2><span id='topic+drglm.multinom'></span>

<h3>Description</h3>

<p>Function <code>drglm.multinom</code> fits multinomial logistic regressiosn model to big data sets in divide and recombine approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drglm.multinom(formula, data, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drglm.multinom_+3A_formula">formula</code></td>
<td>
<p>An entity belonging to the &quot;formula&quot; class (or one that can be transformed into that class) represents a symbolic representation of the model that needs to be adjusted. Specifics about how the model is defined can be found in the 'Details' section.</p>
</td></tr>
<tr><td><code id="drglm.multinom_+3A_data">data</code></td>
<td>
<p>A data frame, list, or environment that is not required but can be provided if available.</p>
</td></tr>
<tr><td><code id="drglm.multinom_+3A_k">k</code></td>
<td>
<p>Number of subsets to be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;Multinomial (Polytomous) Logistic Regression  Model&quot; is fitted in &quot;Divide and Recombine&quot; approach.
</p>


<h3>Author(s)</h3>

<p>MH Nayem
</p>


<h3>References</h3>

<p>Karim, M. R., &amp; Islam, M. A. (2019). Reliability and Survival Analysis. In Reliability and Survival Analysis.
Venables WN, Ripley BD (2002). Modern Applied Statistics with S, Fourth edition. Springer, New York. ISBN 0-387-95457-0, https://www.stats.ox.ac.uk/pub/MASS4/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+big.drglm">big.drglm</a></code>, <code><a href="#topic+drglm">drglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
#Number of rows to be generated
n &lt;- 10000
#creating dataset
dataset &lt;- data.frame( pred_1 = round(rnorm(n, mean = 50, sd = 10)),
pred_2 = round(rnorm(n, mean = 7.5, sd = 2.1)),
pred_3 = as.factor(sample(c("0", "1"), n, replace = TRUE)),
pred_4 = as.factor(sample(c("0", "1", "2"), n, replace = TRUE)),
pred_5 = as.factor(sample(0:15, n, replace = TRUE)),
pred_6 = round(rnorm(n, mean = 60, sd = 5)))
#fitting multinomial logistic regression model
mmodel=drglm::drglm.multinom(
pred_4~ pred_1+ pred_2+ pred_3+ pred_5+ pred_6, data=dataset, k=10)
#Output
mmodel
</code></pre>

<hr>
<h2 id='make.data'>Reading Data File Larger than Memory for Fitting GLMs Using <code>big.drglm</code> Function</h2><span id='topic+make.data'></span>

<h3>Description</h3>

<p>Reading Data File Larger than Memory for Fitting GLMs Using <code>big.drglm</code> Function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.data(filename, chunksize, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.data_+3A_filename">filename</code></td>
<td>
<p>Path to the data set on disk.</p>
</td></tr>
<tr><td><code id="make.data_+3A_chunksize">chunksize</code></td>
<td>
<p>Size of the chunk or subset to be read from the large file for fitting GLMs.</p>
</td></tr>
<tr><td><code id="make.data_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code>read.csv</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that reads chunks of the data set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a toy dataset
set.seed(123)
# Number of rows to be generated
n &lt;- 10000

# Creating dataset
dataset &lt;- data.frame(
  Var_1 = round(rnorm(n, mean = 50, sd = 10)),
  Var_2 = round(rnorm(n, mean = 7.5, sd = 2.1)),
  Var_3 = as.factor(sample(c("0", "1"), n, replace = TRUE)),
  Var_4 = as.factor(sample(c("0", "1", "2"), n, replace = TRUE)),
  Var_5 = as.factor(sample(0:15, n, replace = TRUE)),
  Var_6 = round(rnorm(n, mean = 60, sd = 5))
)

# Save the dataset to a temporary file
temp_file &lt;- tempfile(fileext = ".csv")
write.csv(dataset, file = temp_file, row.names = FALSE)

# Path to the temporary file
dataset_path &lt;- temp_file
dataset_path  # Display the path to the temporary file

# Initialize the data reading function with the data set path and chunk size
da &lt;- drglm::make.data(dataset_path, chunksize = 1000)

# Fitting MLR Models
nmodel &lt;- drglm::big.drglm(da,
formula = Var_1 ~ Var_2 + factor(Var_3) + factor(Var_4) + factor(Var_5) + Var_6,
10, family = "gaussian")
# View the results table
print(nmodel)

# Fitting logistic Regression Model
bmodel &lt;- drglm::big.drglm(da,
formula = factor(Var_3) ~ Var_1 + Var_2 + factor(Var_4) + factor(Var_5) + Var_6,
10, family = "binomial")
# View the results table
print(bmodel)

# Fitting Poisson Regression Model
pmodel &lt;- drglm::big.drglm(da,
formula = Var_5 ~ Var_1 + Var_2 + factor(Var_3) + factor(Var_4) + Var_6,
10, family = "poisson")
# View the results table
print(pmodel)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
