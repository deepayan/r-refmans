<!DOCTYPE html><html lang="en"><head><title>Help for package Rdta</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Rdta}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Rdta'><p>Data Transforming Augmentation for Linear Mixed Models</p></a></li>
<li><a href='#lmm'><p>Fitting univariate and multiviarate linear mixed models via data transforming augmentation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-1-26</td>
</tr>
<tr>
<td>Title:</td>
<td>Data Transforming Augmentation for Linear Mixed Models</td>
</tr>
<tr>
<td>Author:</td>
<td>Hyungsuk Tak, Kisung You, Sujit K. Ghosh, and Bingyue Su</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hyungsuk Tak &lt;hyungsuk.tak@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MCMCpack(&ge; 1.4-4), mvtnorm(&ge; 1.0-11), Rdpack, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>We provide a toolbox to fit univariate and multivariate linear mixed models via data transforming augmentation. Users can also fit these models via typical data augmentation for a comparison. It returns either maximum likelihood estimates of unknown model parameters (hyper-parameters) via an EM algorithm or posterior samples of those parameters via MCMC. Also see Tak et al. (2019) &lt;<a href="https://doi.org/10.1080%2F10618600.2019.1704295">doi:10.1080/10618600.2019.1704295</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-26 21:41:54 UTC; hyungsuktak</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-27 07:30:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='Rdta'>Data Transforming Augmentation for Linear Mixed Models</h2><span id='topic+Rdta-package'></span>

<h3>Description</h3>

<p>The R package <span class="pkg">Rdta</span> provides a toolbox to fit univariate and multivariate linear mixed models via data transforming augmentation. Users can also fit these models via typical data augmentation for a comparison. It returns either maximum likelihood estimates of unknown model parameters (hyper-parameters) via an EM algorithm or posterior samples of those parameters via a Markov chain Monte Carlo method.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Rdta</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-1-26</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
Main functions: </td><td style="text-align: left;"> <code><a href="#topic+lmm">lmm</a></code></td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Hyungsuk Tak (maintainer), Kisung You, Sujit K. Ghosh, and Bingyue Su
</p>


<h3>References</h3>

<p>Tak, You, Ghosh, Su, Kelly (2019), &quot;Data Transforming Augmentation for Heteroscedastic Models&quot; &lt;<a href="https://doi.org/10.1080/10618600.2019.1704295">doi:10.1080/10618600.2019.1704295</a>&gt;
</p>

<hr>
<h2 id='lmm'>Fitting univariate and multiviarate linear mixed models via data transforming augmentation</h2><span id='topic+lmm'></span>

<h3>Description</h3>

<p>The function <code>lmm</code> fits univariate and multivariate linear mixed models
(also called two-level Gaussian hierarchical models) whose first-level hierarchy is about
a distribution of observed data and second-level hierarchy is about a prior distribution of random effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmm(y, v, x = 1, n.burn, n.sample, tol = 1e-10,
  method = "em", dta = TRUE, print.time = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lmm_+3A_y">y</code></td>
<td>
<p>Response variable. In a univariate case, it is a vector of length <code class="reqn">k</code> for the observed data. In a multivariate case, it is a (<code class="reqn">k</code> by <code class="reqn">p</code>) matrix, where <code class="reqn">k</code> is the number of observations and <code class="reqn">p</code> denotes the dimensionality.</p>
</td></tr>
<tr><td><code id="lmm_+3A_v">v</code></td>
<td>
<p>Known measurement error variance. In a univariate case, it is a vector of length <code class="reqn">k</code>. In a multivariate case, it is a (<code class="reqn">p</code>, <code class="reqn">p</code>, <code class="reqn">k</code>) array of known measurement error covariance matrices, i.e., each of the <code class="reqn">k</code> array components is a (<code class="reqn">p</code> by <code class="reqn">p</code>) covariance matrix.</p>
</td></tr>
<tr><td><code id="lmm_+3A_x">x</code></td>
<td>
<p>(Optional) Covariate information. If there is one covariate for each object, e.g., weight, it is a  vector of length <code class="reqn">k</code> for the weight. If there are two covariates for each object, e.g., weight and height, it is a (<code class="reqn">k</code> by 2) matrix, where each column contains a covariate variable. Default is no covariate (<code>x = 1</code>).</p>
</td></tr>
<tr><td><code id="lmm_+3A_n.burn">n.burn</code></td>
<td>
<p>Number of warming-up iterations for a Markov chain Monte Carlo method. It must be specified for <code>method = "mcmc"</code></p>
</td></tr>
<tr><td><code id="lmm_+3A_n.sample">n.sample</code></td>
<td>
<p>Number of iterations (size of a posterior sample for each parameter) for a Markov chain Monte Carlo method. It must be specified for <code>method = "mcmc"</code></p>
</td></tr>
<tr><td><code id="lmm_+3A_tol">tol</code></td>
<td>
<p>Tolerance that determines the stopping rule of the EM algorithm. The EM algorithm iterates until the change of log-likelihood function is within the tolerance. Default is 1e-10.</p>
</td></tr>
<tr><td><code id="lmm_+3A_method">method</code></td>
<td>
<p><code>"em"</code> will return maximum likelihood estimates of the unknown hyper-parameters and <code>"mcmc"</code> returns posterior samples of those parameters.</p>
</td></tr>
<tr><td><code id="lmm_+3A_dta">dta</code></td>
<td>
<p>A logical; Data transforming augmentation is used if <code>dta = TRUE</code>, and typical data augmentation is used if <code>dta = FALSE</code>.</p>
</td></tr>
<tr><td><code id="lmm_+3A_print.time">print.time</code></td>
<td>
<p>A logical; <code>TRUE</code> to display two time stamps for initiation and termination, <code>FALSE</code> otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each group <code class="reqn">i</code>, let <code class="reqn">y_{i}</code> be an unbiased estimate of random effect <code class="reqn">\theta_{i}</code>,
and <code class="reqn">V_{i}</code> be a known measurement error variance. The linear mixed model of interest is specified as follows:
</p>
<p style="text-align: center;"><code class="reqn">[y_{i} \mid \theta_{i}] \sim N(\theta_{i}, V_{i})</code>
</p>

<p style="text-align: center;"><code class="reqn">[\theta_{i} \mid \mu_{0i}, A) \sim N(\mu_{0i}, A)</code>
</p>

<p style="text-align: center;"><code class="reqn">\mu_{0i} = x_{i}'\beta</code>
</p>
 
<p>independently for <code class="reqn">i = 1, \ldots, k</code>, where <em>k</em> is the number of groups (units) and dimension of each element is appropriately adjusted in a multivariate case.
</p>
<p>The function <code>lmm</code> produces maximum likelihood estimates of hyper-parameters, <code class="reqn">A</code> and <code class="reqn">\beta</code>, their update histories of EM iterations, and the number of EM iterations if <code>method</code> is <code>"em"</code>. 
</p>
<p>For a Bayesian implementation, we put a jointly uniform prior distribution on <code class="reqn">A</code> and <code class="reqn">\beta</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">f(A, \beta) \propto 1,</code>
</p>

<p>which is known to have good frequency properties. This joint prior distribution is improper, but their resulting posterior distribution is proper if <code class="reqn">k\ge m+p+2</code>, where <code class="reqn">k</code> is the number of groups, <code class="reqn">m</code> is the number of regression coefficients, and <code class="reqn">p</code> is the dimension of <code class="reqn">y_{i}</code>. We note that an R package <code>Rgbp</code> also fits this model in a univariate case (<code class="reqn">p=1</code>) via ADM (approximation for density maximization). <code>lmm</code> produces the posterior samples through a Gibbs sampler if <code>method</code> is <code>"bayes"</code>.
</p>


<h3>Value</h3>

<p>The outcome of <code>lmm</code> is composed of:
</p>

<dl>
<dt>A</dt><dd><p>If <code>method</code> is &quot;mcmc&quot;. It contains the posterior sample of <code class="reqn">A</code>.</p>
</dd>
<dt>beta</dt><dd><p>If <code>method</code> is &quot;mcmc&quot;. It contains the posterior sample of <code class="reqn">\beta</code>.</p>
</dd>
<dt>A.mle</dt><dd><p>If <code>method</code> is &quot;em&quot;. It contains the maximum likelihood estimate of <code class="reqn">A</code>.</p>
</dd>
<dt>beta.mle</dt><dd><p>If <code>method</code> is &quot;em&quot;. It contains the maximum likelihood estimate of <code class="reqn">beta</code>.</p>
</dd>
<dt>A.trace</dt><dd><p>If <code>method</code> is &quot;em&quot;. It contains the update history of <code class="reqn">A</code> at each iteration.</p>
</dd>
<dt>beta.trace</dt><dd><p>If <code>method</code> is &quot;em&quot;. It contains the update history of <code class="reqn">beta</code> at each iteration.</p>
</dd>
<dt>n.iter</dt><dd><p>If <code>method</code> is &quot;em&quot;. It contains the number of EM iterations.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Hyungsuk Tak (maintainer), Kisung You, Sujit K. Ghosh, and Bingyue Su
</p>


<h3>References</h3>

<p>Tak, You, Ghosh, Su, Kelly (2019), &quot;Data Transforming Augmentation for Heteroscedastic Models&quot; &lt;<a href="https://doi.org/10.1080/10618600.2019.1704295">doi:10.1080/10618600.2019.1704295</a>&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Univariate linear mixed model

# response variable for 10 objects
y &lt;- c(5.42, -1.91, 2.82, -0.14, -1.83, 3.44, 6.18, -1.20, 2.68, 1.12)
# corresponding measurement error standard deviations
se &lt;- c(1.05, 1.15, 1.22, 1.45, 1.30, 1.29, 1.31, 1.10, 1.23, 1.11)
# one covariate information for 10 objects
x &lt;- c(2, 3, 0, 2, 3, 0, 1, 1, 0, 0)

## Fitting without covariate information
# (DTA) maximum likelihood estimates of A and beta via an EM algorithm
res &lt;- lmm(y = y, v = se^2, method = "em", dta = TRUE)
# (DTA) posterior samples of A and beta via an MCMC method
res &lt;- lmm(y = y, v = se^2, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = TRUE)
# (DA) maximum likelihood estimates of A and beta via an EM algorithm
res &lt;- lmm(y = y, v = se^2, method = "em", dta = FALSE)
# (DA) posterior samples of A and beta via an MCMC method
res &lt;- lmm(y = y, v = se^2, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = FALSE)

## Fitting with the covariate information
# (DTA) maximum likelihood estimates of A and beta via an EM algorithm
res &lt;- lmm(y = y, v = se^2, x = x, method = "em", dta = TRUE)
# (DTA) posterior samples of A and beta via an MCMC method
res &lt;- lmm(y = y, v = se^2, x = x, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = TRUE)
# (DA) maximum likelihood estimates of A and beta via an EM algorithm
res &lt;- lmm(y = y, v = se^2, x = x, method = "em", dta = FALSE)
# (DA) posterior samples of A and beta via an MCMC method
res &lt;- lmm(y = y, v = se^2, x = x, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = FALSE)


### Multivariate linear mixed model

# (arbitrary) 10 hospital profiling data (two response variables)
y1 &lt;- c(10.19, 11.53, 16.28, 12.32, 12.84, 11.85, 14.81, 13.24, 14.43, 9.35)
y2 &lt;- c(12.06, 14.97, 11.50, 17.88, 19.21, 14.69, 13.96, 11.07, 12.71, 9.63)
y &lt;- cbind(y1, y2)

# making measurement error covariance matrices for 10 hospitals
n &lt;- c(24, 34, 38, 42, 49, 50, 79, 84, 96, 102) # number of patients
v0 &lt;- matrix(c(186.87, 120.43, 120.43, 250.60), nrow = 2) # common cov matrix
temp &lt;- sapply(1 : length(n), function(j) { v0 / n[j] })
v &lt;- array(temp, dim = c(2, 2, length(n)))

# covariate information (severity measure)
severity &lt;- c(0.45, 0.67, 0.46, 0.56, 0.86, 0.24, 0.34, 0.58, 0.35, 0.17)

## Fitting without covariate information
# (DTA) maximum likelihood estimates of A and beta via an EM algorithm

res &lt;- lmm(y = y, v = v, method = "em", dta = TRUE)

# (DTA) posterior samples of A and beta via an MCMC method

res &lt;- lmm(y = y, v = v, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = TRUE)

# (DA) maximum likelihood estimates of A and beta via an EM algorithm

res &lt;- lmm(y = y, v = v, method = "em", dta = FALSE)

# (DA) posterior samples of A and beta via an MCMC method

res &lt;- lmm(y = y, v = v, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = FALSE)


## Fitting with the covariate information
# (DTA) maximum likelihood estimates of A and beta via an EM algorithm

res &lt;- lmm(y = y, v = v, x = severity, method = "em", dta = TRUE)

# (DTA) posterior samples of A and beta via an MCMC method

res &lt;- lmm(y = y, v = v, x = severity, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = TRUE)

# (DA) maximum likelihood estimates of A and beta via an EM algorithm

res &lt;- lmm(y = y, v = v, x = severity, method = "em", dta = FALSE)

# (DA) posterior samples of A and beta via an MCMC method

res &lt;- lmm(y = y, v = v, x = severity, n.burn = 1e1, n.sample = 1e1,
           method = "mcmc", dta = FALSE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
