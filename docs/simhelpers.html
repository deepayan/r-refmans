<!DOCTYPE html><html lang="en"><head><title>Help for package simhelpers</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {simhelpers}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#alpha_res'><p>Cronbach's alpha simulation results</p></a></li>
<li><a href='#bootstrap_CIs'><p>Calculate one or multiple bootstrap confidence intervals</p></a></li>
<li><a href='#bootstrap_pvals'><p>Calculate one or multiple bootstrap p-values</p></a></li>
<li><a href='#bundle_sim'><p>Bundle functions into a simulation driver function</p></a></li>
<li><a href='#calc_absolute'><p>Calculate absolute performance criteria and MCSE</p></a></li>
<li><a href='#calc_coverage'><p>Calculate confidence interval coverage, width and MCSE</p></a></li>
<li><a href='#calc_rejection'><p>Calculate rejection rate and MCSE</p></a></li>
<li><a href='#calc_relative'><p>Calculate relative performance criteria and MCSE</p></a></li>
<li><a href='#calc_relative_var'><p>Calculate jack-knife Monte Carlo SE for variance estimators</p></a></li>
<li><a href='#create_skeleton'><p>Open a simulation skeleton</p></a></li>
<li><a href='#evaluate_by_row'><p>Evaluate a simulation function on each row of a data frame or tibble</p></a></li>
<li><a href='#extrapolate_coverage'><p>Extrapolate coverage and width using sub-sampled bootstrap confidence</p>
intervals.</a></li>
<li><a href='#extrapolate_rejection'><p>Extrapolate coverage and width using sub-sampled bootstrap confidence</p>
intervals.</a></li>
<li><a href='#repeat_and_stack'><p>Repeat an expression multiple times and (optionally) stack the results.</p></a></li>
<li><a href='#t_res'><p>t-test simulation results</p></a></li>
<li><a href='#Tipton_Pusto'><p>Results for Figure 2 of Tipton &amp; Pustejovsky (2015)</p></a></li>
<li><a href='#welch_res'><p>Welch t-test simulation results</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Helper Functions for Simulation Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates performance criteria measures and associated Monte Carlo standard errors for simulation results. Includes functions to help run simulation studies, following a general simulation workflow that closely aligns with the approach described by Morris, White, and Crowther (2019) &lt;<a href="https://doi.org/10.1002%2Fsim.8086">doi:10.1002/sim.8086</a>&gt;. Also includes functions for calculating bootstrap confidence intervals (including normal, basic, studentized, percentile, bias-corrected, and bias-corrected-and-accelerated) with tidy output, as well as for extrapolating confidence interval coverage rates and hypothesis test rejection rates following techniques suggested by Boos and Zhang (2000) &lt;<a href="https://doi.org/10.1080%2F01621459.2000.10474226">doi:10.1080/01621459.2000.10474226</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://meghapsimatrix.github.io/simhelpers/">https://meghapsimatrix.github.io/simhelpers/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/meghapsimatrix/simhelpers/issues">https://github.com/meghapsimatrix/simhelpers/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>RStudio</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, furrr, tidyr, rstudioapi, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dplyr, tibble, purrr, future, knitr, rmarkdown, pkgdown,
covr, testthat, kableExtra, ggplot2, broom, boot</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-10 18:03:35 UTC; meghajoshi</td>
</tr>
<tr>
<td>Author:</td>
<td>Megha Joshi <a href="https://orcid.org/0000-0001-7936-076X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  James Pustejovsky <a href="https://orcid.org/0000-0003-0591-9465"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Megha Joshi &lt;megha.j456@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-10 21:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='alpha_res'>Cronbach's alpha simulation results</h2><span id='topic+alpha_res'></span>

<h3>Description</h3>

<p>A dataset containing simulation results from estimating Cronbach's alpha and its variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alpha_res
</code></pre>


<h3>Format</h3>

<p>A tibble with 1,000 rows and 3 variables:
</p>

<dl>
<dt>A</dt><dd><p>estimate of alpha.</p>
</dd>
<dt>Var_A</dt><dd><p>estimate of the variance of alpha.</p>
</dd>
<dt>true_param</dt><dd><p>true alpha used to generate the data.</p>
</dd>
</dl>


<hr>
<h2 id='bootstrap_CIs'>Calculate one or multiple bootstrap confidence intervals</h2><span id='topic+bootstrap_CIs'></span>

<h3>Description</h3>

<p>Calculate one or multiple bootstrap confidence intervals, given
a sample of bootstrap replications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_CIs(
  boot_est,
  boot_se = NULL,
  est = NULL,
  se = NULL,
  influence = NULL,
  CI_type = "percentile",
  level = 0.95,
  B_vals = length(boot_est),
  reps = 1L,
  format = "wide",
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrap_CIs_+3A_boot_est">boot_est</code></td>
<td>
<p>vector of bootstrap replications of an estimator.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_boot_se">boot_se</code></td>
<td>
<p>vector of estimated standard errors from each bootstrap
replication.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_est">est</code></td>
<td>
<p>numeric value of the estimate based on the original sample.
Required for <code>CI_type = "normal"</code>, <code>CI_type = "basic"</code>,
<code>CI_type = "student"</code>, and <code>CI_type = "bias-corrected"</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_se">se</code></td>
<td>
<p>numeric value of the estimated standard error based on the original
sample. Required for <code>CI_type = "student"</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_influence">influence</code></td>
<td>
<p>vector of empirical influence values for the estimator. Required for <code>CI_type = "BCa"</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_ci_type">CI_type</code></td>
<td>
<p>Character string or vector of character strings indicating
types of confidence intervals to calculate. Options are <code>"normal"</code>,
<code>"basic"</code>, <code>"student"</code>, <code>"percentile"</code> (the default), <code>"bias-corrected"</code>, or <code>"BCa"</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_level">level</code></td>
<td>
<p>numeric value between 0 and 1 for the desired coverage level,
with a default of <code>0.95</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_b_vals">B_vals</code></td>
<td>
<p>vector of sub-sample sizes for which to calculate confidence
intervals. Setting <code>B_vals = length(boot_est)</code> (the default) will
return bootstrap confidence intervals calculated on the full set of
bootstrap replications. For <code>B_vals &lt; length(boot_est)</code>, confidence
intervals will be calculated after sub-sampling (without replacement) the
bootstrap replications.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_reps">reps</code></td>
<td>
<p>integer value for the number of sub-sample confidence intervals
to generate when <code>B_vals &lt; length(boot_est)</code>, with a default of
<code>reps = 1</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_format">format</code></td>
<td>
<p>character string controlling the format of the output. If
<code>format = "wide"</code> (the default), then different types of confidence
intervals will be returned in separate columns. If <code>format = "long"</code>,
then confidence intervals of different types will appear on different rows
of dataset. If <code>format = "wide-list"</code>, then different types of
confidence intervals will be returned in separate columns and the result
will be wrapped in an unnamed list.</p>
</td></tr>
<tr><td><code id="bootstrap_CIs_+3A_seed">seed</code></td>
<td>
<p>Single numeric value to which the random number generator seed
will be set. Default is <code>NULL</code>, which does not set a seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Confidence intervals are calculated following the methods described
in Chapter 5 of Davison and Hinkley (1997). For basic non-parametric
bootstraps, the methods are nearly identical to the implementation in
<code><a href="boot.html#topic+boot.ci">boot.ci</a></code> from the <code>boot</code> package.
</p>


<h3>Value</h3>

<p>If <code>format = "wide"</code>, the function returns a <code>data.frame</code>
with <code>reps</code> rows per entry of <code>B_vals</code>, where each row contains
confidence intervals for one sub-sample replication.
</p>
<p>If <code>format = "long"</code>, the function returns a <code>data.frame</code> with
one row for each <code>CI_type</code>, each replication, and each entry of
<code>B_vals</code>, where each row contains a single confidence interval for one
sub-sample replication.
</p>
<p>If <code>format = "wide-list"</code>, then the output will be structured as in
<code>format = "wide"</code> but will be wrapped in an unnamed list, which makes
it easier to sore the output in a tibble, and will be assigned the class
<code>"bootstrap_CIs"</code>.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997). _Bootstrap Methods and
Their Application_, Chapter 5. Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate t-distributed data
N &lt;- 50
mu &lt;- 2
nu &lt;- 5
dat &lt;- mu + rt(N, df = nu)

# create bootstrap replications
f &lt;- \(x) {
 c(
   M = mean(x, trim = 0.1),
   SE = sd(x) / sqrt(length(x))
 )
}

booties &lt;- replicate(399, {
  sample(dat, replace = TRUE, size = N) |&gt;
  f()
})

res &lt;- f(dat)

# calculate bootstrap CIs from full set of bootstrap replicates
bootstrap_CIs(
  boot_est = booties[1,],
  boot_se = booties[2,],
  est = res[1],
  se = res[2],
  CI_type = c("normal","basic","student","percentile","bias-corrected"),
  format = "long"
)

# Calculate bias-corrected-and-accelerated CIs
inf_vals &lt;- res[1] - sapply(seq_along(dat), \(i) f(dat[-i])[1])
bootstrap_CIs(
  boot_est = booties[1,],
  est = res[1],
  influence = inf_vals,
  CI_type = c("percentile","bias-corrected","BCa"),
  format = "long"
)

# calculate multiple bootstrap CIs using sub-sampling of replicates
bootstrap_CIs(
  boot_est = booties[1,],
  boot_se = booties[2,],
  est = res[1],
  se = res[2],
  CI_type = c("normal","basic","student","percentile","bias-corrected"),
  B_vals = 199,
  reps = 4L,
  format = "long"
)

# calculate multiple bootstrap CIs using sub-sampling of replicates,
# for each of several sub-sample sizes.
bootstrap_CIs(
  boot_est = booties[1,],
  boot_se = booties[2,],
  est = res[1],
  se = res[2],
  CI_type = c("normal","basic","student","percentile"),
  B_vals = c(49,99,199),
  reps = 4L,
  format = "long"
)

</code></pre>

<hr>
<h2 id='bootstrap_pvals'>Calculate one or multiple bootstrap p-values</h2><span id='topic+bootstrap_pvals'></span>

<h3>Description</h3>

<p>Calculate one or multiple bootstrap p-values, given a bootstrap
sample of test statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_pvals(
  boot_stat,
  stat,
  alternative = "two-sided",
  B_vals = length(boot_stat),
  reps = 1L,
  enlist = FALSE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrap_pvals_+3A_boot_stat">boot_stat</code></td>
<td>
<p>vector of bootstrap replications of a test statistic.</p>
</td></tr>
<tr><td><code id="bootstrap_pvals_+3A_stat">stat</code></td>
<td>
<p>numeric value of the test statistic based on the original sample.</p>
</td></tr>
<tr><td><code id="bootstrap_pvals_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two-sided"</code> (the default), <code>"greater"</code> or
<code>"less"</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_pvals_+3A_b_vals">B_vals</code></td>
<td>
<p>vector of sub-sample sizes for which to calculate p-values.
Setting <code>B_vals = length(boot_stat)</code> (the default) will return a
single p-value calculated on the full set of bootstrap replications. For
<code>B_vals &lt; length(boot_stat)</code>, p-values will be calculated after
sub-sampling (without replacement) the bootstrap replications.</p>
</td></tr>
<tr><td><code id="bootstrap_pvals_+3A_reps">reps</code></td>
<td>
<p>integer value for the number of sub-sample p-values to generate
when <code>B_vals &lt; length(boot_stat)</code>, with a default of <code>reps = 1</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_pvals_+3A_enlist">enlist</code></td>
<td>
<p>logical indicating whether to wrap the returned values in an
unnamed list, with a default of <code>FALSE</code>. Setting <code>enlist = TRUE</code>
makes it easier to store the output as a single entry in a <code>tibble</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_pvals_+3A_seed">seed</code></td>
<td>
<p>Single numeric value to which the random number generator seed
will be set. Default is <code>NULL</code>, which does not set a seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>p-values are calculated by comparing <code>stat</code> to the distribution
of <code>boot_stat</code>, which is taken to represent the null distribution of
the test statistic. If <code>alternative = "two-sided"</code> (the default), then
the p-value is the proportion of the bootstrap sample where the absolute
value of the bootstrapped statistic exceeds the absolute value of the
original statistic. If <code>alternative = "greater"</code>, then the p-value is
the proportion of the bootstrap sample where the value of the bootstrapped
statistic is larger than the original statistic. If <code>alternative =
  "less"</code>, then the p-value is the proportion of the bootstrap sample where
the value of the bootstrapped statistic is less than the original
statistic.
</p>


<h3>Value</h3>

<p>The format of the output depends on several contingencies. If only a
single value of <code>B_vals</code> is specified and <code>reps = 1</code>, then the
function returns a vector with a single p-value. If only a single value of
<code>B_vals</code> is specified but <code>B_vals &lt; length(boot_stat)</code> and
<code>reps &gt; 1</code>, then the function returns a vector p-values, with an entry
for each sub-sample replication. If <code>B_vals</code> is a vector of multiple
values, then the function returns a list with one entry per entry of
<code>B_vals</code>, where each entry is a vector of length <code>reps</code> with
entries for each sub-sample replication.
</p>
<p>If <code>enlist = TRUE</code>, then results will be wrapped in an unnamed list,
which makes it easier to sore the output in a tibble.
</p>


<h3>References</h3>

<p>Davison, A.C. and Hinkley, D.V. (1997). _Bootstrap Methods and
Their Application_, Chapter 4. Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate data from two distinct populations
dat &lt;- data.frame(
  group = rep(c("A","B"), c(40, 50)),
  y = c(
    rgamma(40, shape = 7, scale = 2),
    rgamma(50, shape = 3, scale = 4)
  )
)
stat &lt;- t.test(y ~ group, data = dat)$statistic

# create bootstrap replications under the null of no difference
boot_dat &lt;- dat
booties &lt;- replicate(399, {
  boot_dat$group &lt;- sample(dat$group)
  t.test(y ~ group, data = boot_dat)$statistic
})

# calculate bootstrap p-values from full set of bootstrap replicates
bootstrap_pvals(boot_stat = booties, stat = stat)

# calculate multiple bootstrap p-values using sub-sampling of replicates
bootstrap_pvals(
  boot_stat = booties, stat = stat,
  B_vals = 199,
  reps = 4L
)

# calculate multiple bootstrap p-values using sub-sampling of replicates,
# for each of several sub-sample sizes.
bootstrap_pvals(
  boot_stat = booties, stat = stat,
  B_vals = c(49,99,199),
  reps = 4L
)

</code></pre>

<hr>
<h2 id='bundle_sim'>Bundle functions into a simulation driver function</h2><span id='topic+bundle_sim'></span>

<h3>Description</h3>

<p>Bundle a data-generation function, a data-analysis function, and
(optionally) a performance summary function into a simulation driver.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bundle_sim(
  f_generate,
  f_analyze,
  f_summarize = NULL,
  reps_name = "reps",
  seed_name = "seed",
  summarize_opt_name = "summarize",
  row_bind_reps = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bundle_sim_+3A_f_generate">f_generate</code></td>
<td>
<p>function for data-generation</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_f_analyze">f_analyze</code></td>
<td>
<p>function for data-analysis. The first argument must be the
data, in the format generated by <code>f_analyze()</code>.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_f_summarize">f_summarize</code></td>
<td>
<p>function for calculating performance summaries across
replications. The first argument must be the replicated data analysis
results. Default is <code>NULL</code>, so that no summary function is used.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_reps_name">reps_name</code></td>
<td>
<p>character string to set the name of the argument for the
number of replications, with a default value of <code>"reps"</code>.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_seed_name">seed_name</code></td>
<td>
<p>character string to set the name of the argument for the
seed option, with a default value of <code>"seed"</code>. Set to <code>NULL</code> to
remove the argument from the simulation driver.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_summarize_opt_name">summarize_opt_name</code></td>
<td>
<p>character string to set the name of the argument
for where to apply <code>f_summarize</code> to the simulation results, with a
default value of <code>"summarize"</code>. Ignored if no <code>f_summarize</code> function is
specified. Set to <code>NULL</code> to remove the argument from the simulation
driver.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_row_bind_reps">row_bind_reps</code></td>
<td>
<p>logical indicating whether to combine the simulation
results into a data frame using <code>rbind()</code>, with a default value of
<code>TRUE</code>. If <code>FALSE</code>, then the function will return replications in
a list and so <code>f_summarize</code> must be able to take a list as its first
argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function to repeatedly run the 'f_generate' and 'f_analyze'
functions and (optionally) apply 'f_summarize' to the resulting
replications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f_G &lt;- rnorm
f_A &lt;- function(x, trim = 0) data.frame(y_bar = mean(x, trim = trim))
f_S &lt;- function(x, calc_sd = FALSE) {
  if (calc_sd) {
    res_SD &lt;- apply(x, 2, sd)
    res &lt;- data.frame(M = colMeans(x), SD = res_SD)
  } else {
    res &lt;- data.frame(M = colMeans(x))
  }
  res
}

# bundle data-generation and data-analysis functions
sim1 &lt;- bundle_sim(f_generate = f_G, f_analyze = f_A)
args(sim1)
res1 &lt;- sim1(4, n = 70, mean = 0.5, sd = 1, trim = 0.2)
res1

# bundle data-generation, data-analysis, and performance summary functions
sim2 &lt;- bundle_sim(f_generate = f_G, f_analyze = f_A, f_summarize = f_S)
args(sim2)
res2 &lt;- sim2(24, n = 7, mean = 0, sd = 1, trim = 0.2, calc_sd = TRUE)
res2

# bundle data-generation and data-analysis functions, returning results as a list
sim3 &lt;- bundle_sim(f_generate = f_G, f_analyze = f_A, row_bind_reps = FALSE)
args(sim3)
res3 &lt;- sim3(4, n = 70, mean = 0.5, sd = 3, trim = 0.2)
res3

</code></pre>

<hr>
<h2 id='calc_absolute'>Calculate absolute performance criteria and MCSE</h2><span id='topic+calc_absolute'></span>

<h3>Description</h3>

<p>Calculates absolute bias, variance, mean squared error (mse) and
root mean squared error (rmse). The function also calculates the associated
Monte Carlo standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_absolute(
  data,
  estimates,
  true_param,
  criteria = c("bias", "variance", "stddev", "mse", "rmse"),
  winz = Inf
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_absolute_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_estimates">estimates</code></td>
<td>
<p>vector or name of column from <code>data</code> containing point
estimates.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_true_param">true_param</code></td>
<td>
<p>vector or name of column from <code>data</code> containing
corresponding true parameters.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance
criteria to be calculated, with possible options <code>"bias"</code>,
<code>"variance"</code>, <code>"stddev"</code>, <code>"mse"</code>, and <code>"rmse"</code>.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_winz">winz</code></td>
<td>
<p>numeric value for winsorization constant. If set to a finite
value, estimates will be winsorized at the constant multiple of the
inter-quartile range below the 25th percentile or above the 75th percentile
of the distribution. For instance, setting <code>winz = 3</code> will
truncate estimates that fall below P25 - 3 * IQR or above P75 + 3 * IQR.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance
criteria estimate(s) and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_absolute(data = t_res, estimates = est, true_param = true_param)

</code></pre>

<hr>
<h2 id='calc_coverage'>Calculate confidence interval coverage, width and MCSE</h2><span id='topic+calc_coverage'></span>

<h3>Description</h3>

<p>Calculates confidence interval coverage and width. The function also calculates the associated
Monte Carlo standard errors. The confidence interval percentage is based on how you calculated the lower
and upper bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_coverage(
  data,
  lower_bound,
  upper_bound,
  true_param,
  criteria = c("coverage", "width"),
  winz = Inf
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_coverage_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_lower_bound">lower_bound</code></td>
<td>
<p>vector or name of column from <code>data</code> containing lower bounds of confidence intervals.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_upper_bound">upper_bound</code></td>
<td>
<p>vector or name of column from <code>data</code> containing upper bounds of confidence intervals.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_true_param">true_param</code></td>
<td>
<p>vector or name of column from <code>data</code> containing
corresponding true parameters.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance
criteria to be calculated, with possible options <code>"coverage"</code> and <code>"width"</code>.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_winz">winz</code></td>
<td>
<p>numeric value for winsorization constant. If set to a finite
value, estimates will be winsorized at the constant multiple of the
inter-quartile range below the 25th percentile or above the 75th percentile
of the distribution. For instance, setting <code>winz = 3</code> will
truncate estimates that fall below P25 - 3 * IQR or above P75 + 3 * IQR.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance criteria estimate(s)
and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_coverage(data = t_res, lower_bound = lower_bound,
              upper_bound = upper_bound, true_param = true_param)


</code></pre>

<hr>
<h2 id='calc_rejection'>Calculate rejection rate and MCSE</h2><span id='topic+calc_rejection'></span>

<h3>Description</h3>

<p>Calculates rejection rate. The function also calculates the
associated Monte Carlo standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_rejection(data, p_values, alpha = 0.05, format = "wide")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_rejection_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_rejection_+3A_p_values">p_values</code></td>
<td>
<p>vector or name of column from <code>data</code> containing
p-values.</p>
</td></tr>
<tr><td><code id="calc_rejection_+3A_alpha">alpha</code></td>
<td>
<p>scalar or vector indicating the nominal alpha level(s). Default
value is set to the conventional .05.</p>
</td></tr>
<tr><td><code id="calc_rejection_+3A_format">format</code></td>
<td>
<p>option <code>"wide"</code> (the default) will produce a tibble with
one row, with separate variables for each specified <code>alpha</code>. Option
<code>"long"</code> will produce a tibble with one row per specified
<code>alpha</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance
criteria estimate and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_rejection(data = t_res, p_values = p_val)


</code></pre>

<hr>
<h2 id='calc_relative'>Calculate relative performance criteria and MCSE</h2><span id='topic+calc_relative'></span>

<h3>Description</h3>

<p>Calculates relative bias, mean squared error (relative mse), and root mean squared error (relative rmse).
The function also calculates the associated
Monte Carlo standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative(
  data,
  estimates,
  true_param,
  criteria = c("relative bias", "relative mse", "relative rmse"),
  winz = Inf
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_relative_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_estimates">estimates</code></td>
<td>
<p>vector or name of column from <code>data</code> containing point
estimates.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_true_param">true_param</code></td>
<td>
<p>vector or name of column from <code>data</code> containing
corresponding true parameters.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance
criteria to be calculated, with possible options <code>"relative bias"</code>,
<code>"relative mse"</code>, and <code>"relative rmse"</code>.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_winz">winz</code></td>
<td>
<p>numeric value for winsorization constant. If set to a finite
value, estimates will be winsorized at the constant multiple of the
inter-quartile range below the 25th percentile or above the 75th percentile
of the distribution. For instance, setting <code>winz = 3</code> will
truncate estimates that fall below P25 - 3 * IQR or above P75 + 3 * IQR.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance criteria estimate(s)
and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_relative(data = t_res, estimates = est, true_param = true_param)


</code></pre>

<hr>
<h2 id='calc_relative_var'>Calculate jack-knife Monte Carlo SE for variance estimators</h2><span id='topic+calc_relative_var'></span>

<h3>Description</h3>

<p>Calculates relative bias, mean squared error (relative mse), and
root mean squared error (relative rmse)  of variance estimators. The
function also calculates the associated jack-knife Monte Carlo standard
errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative_var(
  data,
  estimates,
  var_estimates,
  criteria = c("relative bias", "relative mse", "relative rmse"),
  winz = Inf,
  var_winz = winz
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_relative_var_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_estimates">estimates</code></td>
<td>
<p>vector or name of column from <code>data</code> containing point
estimates.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_var_estimates">var_estimates</code></td>
<td>
<p>vector or name of column from <code>data</code> containing
variance estimates for point estimator in <code>estimates</code>.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance
criteria to be calculated, with possible options <code>"relative bias"</code>,
<code>"relative mse"</code>, and <code>"relative rmse"</code>.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_winz">winz</code></td>
<td>
<p>numeric value for winsorization constant. If set to a finite
value, estimates will be winsorized at the constant multiple of the
inter-quartile range below the 25th percentile or above the 75th percentile
of the distribution. For instance, setting <code>winz = 3</code> will
truncate estimates that fall below P25 - 3 * IQR or above P75 + 3 * IQR.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_var_winz">var_winz</code></td>
<td>
<p>numeric value for winsorization constant for the
variance estimates. If set to a finite value, variance estimates will be
winsorized at the constant multiple of the inter-quartile range below the
25th percentile or above the 75th percentile of the distribution. For
instance, setting <code>var_winz = 3</code> will truncate variance estimates
that fall below P25 - 3 * IQR or above P75 + 3 * IQR. By default
<code>var_winz</code> is set to the same constant as <code>winsorize</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance
criteria estimate(s) and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_relative_var(data = alpha_res, estimates = A, var_estimates = Var_A)

</code></pre>

<hr>
<h2 id='create_skeleton'>Open a simulation skeleton</h2><span id='topic+create_skeleton'></span>

<h3>Description</h3>

<p>Creates and opens a .R file containing a skeleton for writing a Monte Carlo simulation study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_skeleton()
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
create_skeleton()

## End(Not run)
</code></pre>

<hr>
<h2 id='evaluate_by_row'>Evaluate a simulation function on each row of a data frame or tibble</h2><span id='topic+evaluate_by_row'></span>

<h3>Description</h3>

<p>Evaluates a simulation function on each row of a data frame or tibble
containing parameter values. Returns a single tibble with parameters
and simulation results. The function uses <code>furrr::future_pmap</code>, which
allows for easy parallelization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate_by_row(
  params,
  sim_function,
  ...,
  results_name = ".results",
  .progress = FALSE,
  .options = furrr::furrr_options(),
  system_time = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evaluate_by_row_+3A_params">params</code></td>
<td>
<p>data frame or tibble containing simulation parameter values. Each row should
represent a separate set of parameter values.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_sim_function">sim_function</code></td>
<td>
<p>function to be evaluated, with argument names matching
the variable names in <code>params</code>. The function must return a
<code>data.frame</code>, <code>tibble</code>, or vector.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>sim_function</code>.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_results_name">results_name</code></td>
<td>
<p>character string to set the name of the column storing the results of the simulation. Default is <code>".results"</code>.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_.progress">.progress</code></td>
<td>
<p>A single logical. Should a progress bar be displayed?
Only works with multisession, multicore, and multiprocess futures. Note
that if a multicore/multisession future falls back to sequential, then
a progress bar will not be displayed.
</p>
<p><strong>Warning:</strong> The <code>.progress</code> argument will be deprecated and removed
in a future version of furrr in favor of using the more robust
<a href="https://CRAN.R-project.org/package=progressr">progressr</a>
package.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_.options">.options</code></td>
<td>
<p>The <code>future</code> specific options to use with the workers. This
must be the result from a call to <code><a href="furrr.html#topic+furrr_options">furrr_options()</a></code>.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_system_time">system_time</code></td>
<td>
<p>logical indicating whether to print computation time.
<code>TRUE</code> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing parameter values and simulation results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  n = 3:5,
  lambda = seq(8, 16, 4)
)

evaluate_by_row(df, rpois)

</code></pre>

<hr>
<h2 id='extrapolate_coverage'>Extrapolate coverage and width using sub-sampled bootstrap confidence
intervals.</h2><span id='topic+extrapolate_coverage'></span>

<h3>Description</h3>

<p>Given a set of bootstrap confidence intervals calculated across
sub-samples with different numbers of replications, extrapolates confidence
interval coverage and width of bootstrap confidence intervals to a
specified (larger) number of bootstraps. The function also calculates the
associated Monte Carlo standard errors. The confidence interval percentage
is based on how you calculated the lower and upper bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extrapolate_coverage(
  data,
  CI_subsamples,
  true_param,
  B_target = Inf,
  criteria = c("coverage", "width"),
  winz = Inf,
  nested = FALSE,
  format = "wide",
  width_trim = 0,
  cover_na_val = NA,
  width_na_val = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extrapolate_coverage_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_ci_subsamples">CI_subsamples</code></td>
<td>
<p>list or name of column from <code>data</code> containing list
of confidence intervals calculated based on sub-samples with different
numbers of replications.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_true_param">true_param</code></td>
<td>
<p>vector or name of column from <code>data</code> containing
corresponding true parameters.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_b_target">B_target</code></td>
<td>
<p>number of bootstrap replications to which the criteria should
be extrapolated, with a default of <code>B = Inf</code>.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance
criteria to be calculated, with possible options <code>"coverage"</code> and
<code>"width"</code>.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_winz">winz</code></td>
<td>
<p>numeric value for winsorization constant. If set to a finite
value, estimates will be winsorized at the constant multiple of the
inter-quartile range below the 25th percentile or above the 75th percentile
of the distribution. For instance, setting <code>winz = 3</code> will
truncate estimates that fall below P25 - 3 * IQR or above P75 + 3 * IQR.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_nested">nested</code></td>
<td>
<p>logical value controlling the format of the output. If
<code>FALSE</code> (the default), then the results will be returned as a data
frame with rows for each distinct number of bootstraps. If <code>TRUE</code>,
then the results will be returned as a data frame with a single row, with
each performance criterion containing a nested data frame.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_format">format</code></td>
<td>
<p>character string controlling the format of the output when
<code>CI_subsamples</code> has results for more than one type of confidence
interval. If <code>"wide"</code> (the default), then each performance criterion
will have a separate column for each CI type. If <code>"long"</code>, then each
performance criterion will be a single variable, with separate rows for
each CI type.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_width_trim">width_trim</code></td>
<td>
<p>numeric value specifying the trimming percentage to use
when summarizing CI widths across replications from a single set of
bootstraps, with a default of 0.0 (i.e., use the regular arithmetic mean).</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_cover_na_val">cover_na_val</code></td>
<td>
<p>numeric value to use for calculating coverage if bootstrap CI end-points are missing. Default is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="extrapolate_coverage_+3A_width_na_val">width_na_val</code></td>
<td>
<p>numeric value to use for calculating width if bootstrap CI end-points are missing. Default is <code>NA</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance
criteria estimate(s) and the associated MCSE.
</p>


<h3>References</h3>

<p>Boos DD, Zhang J (2000).
&ldquo;Monte Carlo evaluation of resampling-based hypothesis tests.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>95</b>(450), 486&ndash;492.
<a href="https://doi.org/10.1080/01621459.2000.10474226">doi:10.1080/01621459.2000.10474226</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dgp &lt;- function(N, mu, nu) {
  mu + rt(N, df = nu)
}

estimator &lt;- function(
   dat,
    B_vals = c(49,59,89,99),
    m = 4,
    trim = 0.1
) {


  # compute estimate and standard error
  N &lt;- length(dat)
  est &lt;- mean(dat, trim = trim)
  se &lt;- sd(dat) / sqrt(N)

  # compute booties
  booties &lt;- replicate(max(B_vals), {
    x &lt;- sample(dat, size = N, replace = TRUE)
    data.frame(
      M = mean(x, trim = trim),
      SE = sd(x) / sqrt(N)
    )
  }, simplify = FALSE) |&gt;
    dplyr::bind_rows()

  # confidence intervals for each B_vals
  CIs &lt;- bootstrap_CIs(
    boot_est = booties$M,
    boot_se = booties$SE,
    est = est,
    se = se,
    CI_type = c("normal","basic","student","percentile"),
    B_vals = B_vals,
    reps = m,
    format = "wide-list"
  )

  res &lt;- data.frame(
    est = est,
    se = se
  )
  res$CIs &lt;- CIs

  res
}

#' build a simulation driver function
simulate_bootCIs &lt;- bundle_sim(
  f_generate = dgp,
  f_analyze = estimator
)

boot_results &lt;- simulate_bootCIs(
  reps = 50, N = 20, mu = 2, nu = 3,
  B_vals = seq(49, 199, 50),
)

extrapolate_coverage(
  data = boot_results,
  CI_subsamples = CIs,
  true_param = 2
)

extrapolate_coverage(
  data = boot_results,
  CI_subsamples = CIs,
  true_param = 2,
  B_target = 999,
  format = "long"
)

</code></pre>

<hr>
<h2 id='extrapolate_rejection'>Extrapolate coverage and width using sub-sampled bootstrap confidence
intervals.</h2><span id='topic+extrapolate_rejection'></span>

<h3>Description</h3>

<p>Given a set of bootstrap confidence intervals calculated across
sub-samples with different numbers of replications, extrapolates confidence
interval coverage and width of bootstrap confidence intervals to a
specified (larger) number of bootstraps. The function also calculates the
associated Monte Carlo standard errors. The confidence interval percentage
is based on how you calculated the lower and upper bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extrapolate_rejection(
  data,
  pvalue_subsamples,
  B_target = Inf,
  alpha = 0.05,
  nested = FALSE,
  format = "wide"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extrapolate_rejection_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="extrapolate_rejection_+3A_pvalue_subsamples">pvalue_subsamples</code></td>
<td>
<p>list or name of column from <code>data</code> containing list
of confidence intervals calculated based on sub-samples with different
numbers of replications.</p>
</td></tr>
<tr><td><code id="extrapolate_rejection_+3A_b_target">B_target</code></td>
<td>
<p>number of bootstrap replications to which the criteria should
be extrapolated, with a default of <code>B = Inf</code>.</p>
</td></tr>
<tr><td><code id="extrapolate_rejection_+3A_alpha">alpha</code></td>
<td>
<p>scalar or vector indicating the nominal alpha level(s). Default
value is set to the conventional .05.</p>
</td></tr>
<tr><td><code id="extrapolate_rejection_+3A_nested">nested</code></td>
<td>
<p>logical value controlling the format of the output. If
<code>FALSE</code> (the default), then the results will be returned as a data
frame with rows for each distinct number of bootstraps. If <code>TRUE</code>,
then the results will be returned as a data frame with a single row, with
each performance criterion containing a nested data frame.</p>
</td></tr>
<tr><td><code id="extrapolate_rejection_+3A_format">format</code></td>
<td>
<p>character string controlling the format of the output when
<code>CI_subsamples</code> has results for more than one type of confidence
interval. If <code>"wide"</code> (the default), then each performance criterion
will have a separate column for each CI type. If <code>"long"</code>, then each
performance criterion will be a single variable, with separate rows for
each CI type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance
criteria estimate(s) and the associated MCSE.
</p>


<h3>References</h3>

<p>Boos DD, Zhang J (2000).
&ldquo;Monte Carlo evaluation of resampling-based hypothesis tests.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>95</b>(450), 486&ndash;492.
<a href="https://doi.org/10.1080/01621459.2000.10474226">doi:10.1080/01621459.2000.10474226</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# function to generate data from two distinct populations
dgp &lt;- function(N_A, N_B, shape_A, scale_A, shape_B, scale_B) {
  data.frame(
    group = rep(c("A","B"), c(N_A, N_B)),
      y = c(
        rgamma(N_A, shape = shape_A, scale = scale_A),
        rgamma(N_B, shape = shape_B, scale = scale_B)
      )
  )
}

# function to do a bootstrap t-test
estimator &lt;- function(
    dat,
    B_vals = c(49,59,89,99), # number of booties to evaluate
    pval_reps = 4L
) {
  stat &lt;- t.test(y ~ group, data = dat)$statistic

  # create bootstrap replications under the null of no difference
  boot_dat &lt;- dat
  booties &lt;- replicate(max(B_vals), {
    boot_dat$group &lt;- sample(dat$group)
    t.test(y ~ group, data = boot_dat)$statistic
  })

  # calculate multiple bootstrap p-values using sub-sampling of replicates
  res &lt;- data.frame(stat = stat)

  res$pvalue_subsamples &lt;- bootstrap_pvals(
    boot_stat = booties,
    stat = stat,
    B_vals = B_vals,
    reps = pval_reps,
    enlist = TRUE
  )

  res
}

# create simulation driver
simulate_boot_pvals &lt;- bundle_sim(
  f_generate = dgp,
  f_analyze = estimator
)

# replicate the bootstrap process
x &lt;- simulate_boot_pvals(
  reps = 50L,
  N_A = 20, N_B = 25,
  shape_A = 7, scale_A = 2,
  shape_B = 4, scale_B = 3,
  B_vals = c(49, 99, 149, 199),
  pval_reps = 2L
)

extrapolate_rejection(
  data = x,
  pvalue_subsamples = pvalue_subsamples,
  B_target = 1999,
  alpha = c(.01, .05, .10)
)

extrapolate_rejection(
  data = x,
  pvalue_subsamples = pvalue_subsamples,
  B_target = Inf,
  alpha = c(.01, .05, .10),
  nested = TRUE
)

</code></pre>

<hr>
<h2 id='repeat_and_stack'>Repeat an expression multiple times and (optionally) stack the results.</h2><span id='topic+repeat_and_stack'></span>

<h3>Description</h3>

<p>Repeat an expression (usually involving random number
generation) multiple times. Optionally, organize the results into a
<code>data.frame</code> that stacks the output from all replications of the
expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repeat_and_stack(n, expr, stack = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="repeat_and_stack_+3A_n">n</code></td>
<td>
<p>Number of times to repeat the expression</p>
</td></tr>
<tr><td><code id="repeat_and_stack_+3A_expr">expr</code></td>
<td>
<p>An expression to be evaluated.</p>
</td></tr>
<tr><td><code id="repeat_and_stack_+3A_stack">stack</code></td>
<td>
<p>Logical value indicating whether to organize the results into a
<code>data.frame</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>stack = TRUE</code> (the default), the results of each evaluation
of <code>expr</code> will be stacked together using <code>rbind</code>. If <code>stack
  = FALSE</code>, a list of length <code>n</code> with entries corresponding to the
output of each replication of <code>expr</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>repeat_and_stack(n = 3, data.frame(x = rexp(2)))

repeat_and_stack(n = 3, data.frame(x = rexp(2)), stack = FALSE)

</code></pre>

<hr>
<h2 id='t_res'>t-test simulation results</h2><span id='topic+t_res'></span>

<h3>Description</h3>

<p>A dataset containing simulation results from a study that just runs a t-test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_res
</code></pre>


<h3>Format</h3>

<p>A tibble with 1,000 rows and 5 variables:
</p>

<dl>
<dt>est</dt><dd><p>estimate of the mean difference.</p>
</dd>
<dt>p_val</dt><dd><p>p-value from the t-test.</p>
</dd>
<dt>lower_bound</dt><dd><p>lower bound of the confidence interval.</p>
</dd>
<dt>upper_bound</dt><dd><p>upper bound of the confidence interval.</p>
</dd>
<dt>true_param</dt><dd><p>true mean difference used to generate the data.</p>
</dd>
</dl>


<hr>
<h2 id='Tipton_Pusto'>Results for Figure 2 of Tipton &amp; Pustejovsky (2015)</h2><span id='topic+Tipton_Pusto'></span>

<h3>Description</h3>

<p>A dataset containing simulation results comparing small sample correction
methods for cluster robust variance estimation in meta-analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tipton_Pusto
</code></pre>


<h3>Format</h3>

<p>A tibble with 15,300 rows and 8 variables:
</p>

<dl>
<dt>num_studies</dt><dd><p>the number of studies included in the meta-analysis.</p>
</dd>
<dt>r</dt><dd><p>correlation between outcomes.</p>
</dd>
<dt>Isq</dt><dd><p>measure of heterogeneity of true effects.</p>
</dd>
<dt>contrast</dt><dd><p>type of contrast that was tested.</p>
</dd>
<dt>test</dt><dd><p>small sample method used.</p>
</dd>
<dt>q</dt><dd><p>the number of parameters in the hypothesis test.</p>
</dd>
<dt>rej_rate</dt><dd><p>the Type 1 error rate.</p>
</dd>
<dt>mcse</dt><dd><p>the Monte Carlo standard error for the estimate of the Type 1 error rate.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Tipton E, Pustejovsky JE (2015).
&ldquo;Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression.&rdquo;
<em>Journal of Educational and Behavioral Statistics</em>, <b>40</b>(6), 604&ndash;634.
<a href="https://doi.org/10.3102/1076998615606099">doi:10.3102/1076998615606099</a>.
</p>

<hr>
<h2 id='welch_res'>Welch t-test simulation results</h2><span id='topic+welch_res'></span>

<h3>Description</h3>

<p>A dataset containing simulation results from a study comparing Welch t-test to the conventional t-test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>welch_res
</code></pre>


<h3>Format</h3>

<p>A tibble with 16,000 rows and 11 variables:
</p>

<dl>
<dt>n1</dt><dd><p>sample size for Group 1.</p>
</dd>
<dt>n2</dt><dd><p>sample size for Group 2.</p>
</dd>
<dt>mean_diff</dt><dd><p>true difference in means of two groups used to generate the data.</p>
</dd>
<dt>iterations</dt><dd><p>number of iterations.</p>
</dd>
<dt>seed</dt><dd><p>seed used to generate data.</p>
</dd>
<dt>method</dt><dd><p>indicates whether Welch or conventional t-test was used.</p>
</dd>
<dt>est</dt><dd><p>estimate of the mean difference.</p>
</dd>
<dt>var</dt><dd><p>variance of the estimate.</p>
</dd>
<dt>p_val</dt><dd><p>p-value from the t-test.</p>
</dd>
<dt>lower_bound</dt><dd><p>lower bound of the confidence interval.</p>
</dd>
<dt>upper_bound</dt><dd><p>upper bound of the confidence interval.</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
