<!DOCTYPE html><html><head><title>Help for package simhelpers</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {simhelpers}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#alpha_res'><p>Cronbach's alpha simulation results</p></a></li>
<li><a href='#bundle_sim'><p>Bundle functions into a simulation driver function</p></a></li>
<li><a href='#calc_absolute'><p>Calculate absolute performance criteria and MCSE</p></a></li>
<li><a href='#calc_coverage'><p>Calculate confidence interval coverage, width and MCSE</p></a></li>
<li><a href='#calc_rejection'><p>Calculate rejection rate and MCSE</p></a></li>
<li><a href='#calc_relative'><p>Calculate relative performance criteria and MCSE</p></a></li>
<li><a href='#calc_relative_var'><p>Calculate jack-knife Monte Carlo SE for variance estimators</p></a></li>
<li><a href='#create_skeleton'><p>Open a simulation skeleton</p></a></li>
<li><a href='#evaluate_by_row'><p>Evaluate a simulation function on each row of a data frame or tibble</p></a></li>
<li><a href='#t_res'><p>t-test simulation results</p></a></li>
<li><a href='#Tipton_Pusto'><p>Results for Figure 2 of Tipton &amp; Pustejovsky (2015)</p></a></li>
<li><a href='#welch_res'><p>Welch t-test simulation results</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Helper Functions for Simulation Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Megha Joshi &lt;megha.j456@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates performance criteria measures and associated Monte Carlo standard errors for simulation results. Includes functions to help run simulation studies. Our derivation and explanation of formulas and our general simulation workflow is closely aligned with the approach described by Morris, White, and Crowther (2019) &lt;<a href="https://doi.org/10.1002%2Fsim.8086">doi:10.1002/sim.8086</a>&gt;. </td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://meghapsimatrix.github.io/simhelpers/index.html">https://meghapsimatrix.github.io/simhelpers/index.html</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/meghapsimatrix/simhelpers/issues">https://github.com/meghapsimatrix/simhelpers/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>RStudio</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, furrr, tidyr, tibble, rstudioapi, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dplyr, plyr, purrr, future, knitr, rmarkdown, pkgdown, covr,
testthat, kableExtra, ggplot2, broom</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-28 17:36:11 UTC; meghajoshi</td>
</tr>
<tr>
<td>Author:</td>
<td>Megha Joshi <a href="https://orcid.org/0000-0001-7936-076X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  James Pustejovsky <a href="https://orcid.org/0000-0003-0591-9465"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-29 21:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='alpha_res'>Cronbach's alpha simulation results</h2><span id='topic+alpha_res'></span>

<h3>Description</h3>

<p>A dataset containing simulation results from estimating Cronbach's alpha and its variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alpha_res
</code></pre>


<h3>Format</h3>

<p>A tibble with 1,000 rows and 3 variables:
</p>

<dl>
<dt>A</dt><dd><p>estimate of alpha.</p>
</dd>
<dt>Var_A</dt><dd><p>estimate of the variance of alpha.</p>
</dd>
<dt>true_param</dt><dd><p>true alpha used to generate the data.</p>
</dd>
</dl>


<hr>
<h2 id='bundle_sim'>Bundle functions into a simulation driver function</h2><span id='topic+bundle_sim'></span>

<h3>Description</h3>

<p>Bundle a data-generation function, a data-analysis function, and
(optionally) a performance summary function into a simulation driver.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bundle_sim(
  f_generate,
  f_analyze,
  f_summarize = NULL,
  reps_name = "reps",
  seed_name = "seed",
  summarize_opt_name = "summarize",
  row_bind_reps = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bundle_sim_+3A_f_generate">f_generate</code></td>
<td>
<p>function for data-generation</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_f_analyze">f_analyze</code></td>
<td>
<p>function for data-analysis. The first argument must be the
data, in the format generated by <code>f_analyze()</code>.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_f_summarize">f_summarize</code></td>
<td>
<p>function for calculating performance summaries across
replications. The first argument must be the replicated data analysis
results. Default is <code>NULL</code>, so that no summary function is used.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_reps_name">reps_name</code></td>
<td>
<p>character string to set the name of the argument for the
number of replications, with a default value of <code>"reps"</code>.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_seed_name">seed_name</code></td>
<td>
<p>character string to set the name of the argument for the
seed option, with a default value of <code>"seed"</code>. Set to <code>NULL</code> to
remove the argument from the simulation driver.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_summarize_opt_name">summarize_opt_name</code></td>
<td>
<p>character string to set the name of the argument
for where to apply <code>f_summarize</code> to the simulation results, with a
default value of <code>TRUE</code>. Ignored if no <code>f_summarize</code> function is
specified. Set to <code>NULL</code> to remove the argument from the simulation
driver.</p>
</td></tr>
<tr><td><code id="bundle_sim_+3A_row_bind_reps">row_bind_reps</code></td>
<td>
<p>logical indicating whether to combine the simulation
results into a data frame using <code>rbind()</code>, with a default value of
<code>TRUE</code>. If <code>FALSE</code>, then the function will return replications in
a list and so <code>f_summarize</code> must be able to take a list as its first
argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function to repeatedly run the 'f_generate' and 'f_analyze'
functions and (optionally) apply 'f_summarize' to the resulting
replications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f_G &lt;- rnorm
f_A &lt;- function(x, trim = 0) data.frame(y_bar = mean(x, trim = trim))
f_S &lt;- function(x, calc_sd = FALSE) {
  if (calc_sd) {
    res_SD &lt;- apply(x, 2, sd)
    res &lt;- data.frame(M = colMeans(x), SD = res_SD)
  } else {
    res &lt;- data.frame(M = colMeans(x))
  }
  res
}

# bundle data-generation and data-analysis functions
sim1 &lt;- bundle_sim(f_generate = f_G, f_analyze = f_A)
args(sim1)
res1 &lt;- sim1(4, n = 70, mean = 0.5, sd = 1, trim = 0.2)
res1

# bundle data-generation, data-analysis, and performance summary functions
sim2 &lt;- bundle_sim(f_generate = f_G, f_analyze = f_A, f_summarize = f_S)
args(sim2)
res2 &lt;- sim2(24, n = 7, mean = 0, sd = 1, trim = 0.2, calc_sd = TRUE)
res2

# bundle data-generation and data-analysis functions, returning results as a list
sim3 &lt;- bundle_sim(f_generate = f_G, f_analyze = f_A, row_bind_reps = FALSE)
args(sim3)
res3 &lt;- sim3(4, n = 70, mean = 0.5, sd = 3, trim = 0.2)
res3

</code></pre>

<hr>
<h2 id='calc_absolute'>Calculate absolute performance criteria and MCSE</h2><span id='topic+calc_absolute'></span>

<h3>Description</h3>

<p>Calculates absolute bias, variance, mean squared error (mse)
and root mean squared error (rmse). The function also calculates the associated
Monte Carlo standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_absolute(
  data,
  estimates,
  true_param,
  criteria = c("bias", "variance", "mse", "rmse")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_absolute_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_estimates">estimates</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing point estimates.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_true_param">true_param</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing corresponding true parameters.</p>
</td></tr>
<tr><td><code id="calc_absolute_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance criteria to be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance criteria estimate(s)
and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_absolute(data = t_res, estimates = est, true_param = true_param)

</code></pre>

<hr>
<h2 id='calc_coverage'>Calculate confidence interval coverage, width and MCSE</h2><span id='topic+calc_coverage'></span>

<h3>Description</h3>

<p>Calculates confidence interval coverage and width. The function also calculates the associated
Monte Carlo standard errors. The confidence interval percentage is based on how you calculated the lower
and upper bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_coverage(
  data,
  lower_bound,
  upper_bound,
  true_param,
  criteria = c("coverage", "width")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_coverage_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_lower_bound">lower_bound</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing lower bounds of confidence intervals.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_upper_bound">upper_bound</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing upper bounds of confidence intervals.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_true_param">true_param</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing corresponding true parameters.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance criteria to be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance criteria estimate(s)
and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_coverage(data = t_res, lower_bound = lower_bound,
              upper_bound = upper_bound, true_param = true_param)


</code></pre>

<hr>
<h2 id='calc_rejection'>Calculate rejection rate and MCSE</h2><span id='topic+calc_rejection'></span>

<h3>Description</h3>

<p>Calculates rejection rate. The function also calculates the
associated Monte Carlo standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_rejection(data, p_values, alpha = 0.05, format = "wide")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_rejection_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_rejection_+3A_p_values">p_values</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing
p-values.</p>
</td></tr>
<tr><td><code id="calc_rejection_+3A_alpha">alpha</code></td>
<td>
<p>Scalar or vector indicating the nominal alpha level(s). Default
value is set to the conventional .05.</p>
</td></tr>
<tr><td><code id="calc_rejection_+3A_format">format</code></td>
<td>
<p>Option <code>"wide"</code> (the default) will produce a tibble with
one row, with separate variables for each specified <code>alpha</code>. Option
<code>"long"</code> will produce a tibble with one row per specified
<code>alpha</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance
criteria estimate and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_rejection(data = t_res, p_values = p_val)


</code></pre>

<hr>
<h2 id='calc_relative'>Calculate relative performance criteria and MCSE</h2><span id='topic+calc_relative'></span>

<h3>Description</h3>

<p>Calculates relative bias, mean squared error (relative mse), and root mean squared error (relative rmse).
The function also calculates the associated
Monte Carlo standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative(
  data,
  estimates,
  true_param,
  criteria = c("relative bias", "relative mse", "relative rmse")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_relative_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_estimates">estimates</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing point estimates.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_true_param">true_param</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing corresponding true parameters.</p>
</td></tr>
<tr><td><code id="calc_relative_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance criteria to be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance criteria estimate(s)
and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_relative(data = t_res, estimates = est, true_param = true_param)


</code></pre>

<hr>
<h2 id='calc_relative_var'>Calculate jack-knife Monte Carlo SE for variance estimators</h2><span id='topic+calc_relative_var'></span>

<h3>Description</h3>

<p>Calculates relative bias, mean squared error (relative mse), and root mean
squared error (relative rmse)  of variance estimators.
The function also calculates the associated jack-knife Monte Carlo standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative_var(
  data,
  estimates,
  var_estimates,
  criteria = c("relative bias", "relative mse", "relative rmse")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc_relative_var_+3A_data">data</code></td>
<td>
<p>data frame or tibble containing the simulation results.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_estimates">estimates</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing point estimates.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_var_estimates">var_estimates</code></td>
<td>
<p>Vector or name of column from <code>data</code> containing variance estimates for point estimator in <code>estimates</code>.</p>
</td></tr>
<tr><td><code id="calc_relative_var_+3A_criteria">criteria</code></td>
<td>
<p>character or character vector indicating the performance criteria to be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the number of simulation iterations, performance criteria estimate(s)
and the associated MCSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_relative_var(data = alpha_res, estimates = A, var_estimates = Var_A)

</code></pre>

<hr>
<h2 id='create_skeleton'>Open a simulation skeleton</h2><span id='topic+create_skeleton'></span>

<h3>Description</h3>

<p>Creates and opens a .R file containing a skeleton for writing a Monte Carlo simulation study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_skeleton()
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
create_skeleton()

## End(Not run)
</code></pre>

<hr>
<h2 id='evaluate_by_row'>Evaluate a simulation function on each row of a data frame or tibble</h2><span id='topic+evaluate_by_row'></span>

<h3>Description</h3>

<p>Evaluates a simulation function on each row of a data frame or tibble
containing parameter values. Returns a single tibble with parameters
and simulation results. The function uses <code>furrr::future_pmap</code>, which
allows for easy parallelization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate_by_row(
  params,
  sim_function,
  ...,
  results_name = ".results",
  .progress = FALSE,
  .options = furrr::furrr_options(),
  system_time = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate_by_row_+3A_params">params</code></td>
<td>
<p>data frame or tibble containing simulation parameter values. Each row should
represent a separate set of parameter values.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_sim_function">sim_function</code></td>
<td>
<p>function to be evaluated, with argument names matching
the variable names in <code>params</code>. The function must return a
<code>data.frame</code>, <code>tibble</code>, or vector.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>sim_function</code>.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_results_name">results_name</code></td>
<td>
<p>character string to set the name of the column storing the results of the simulation. Default is <code>".results"</code>.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_.progress">.progress</code></td>
<td>
<p>A single logical. Should a progress bar be displayed?
Only works with multisession, multicore, and multiprocess futures. Note
that if a multicore/multisession future falls back to sequential, then
a progress bar will not be displayed.
</p>
<p><strong>Warning:</strong> The <code>.progress</code> argument will be deprecated and removed
in a future version of furrr in favor of using the more robust
<a href="https://CRAN.R-project.org/package=progressr">progressr</a>
package.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_.options">.options</code></td>
<td>
<p>The <code>future</code> specific options to use with the workers. This
must be the result from a call to <code><a href="furrr.html#topic+furrr_options">furrr_options()</a></code>.</p>
</td></tr>
<tr><td><code id="evaluate_by_row_+3A_system_time">system_time</code></td>
<td>
<p>logical indicating whether to print computation time.
<code>TRUE</code> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing parameter values and simulation results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  n = 3:5,
  lambda = seq(8, 16, 4)
)

evaluate_by_row(df, rpois)

</code></pre>

<hr>
<h2 id='t_res'>t-test simulation results</h2><span id='topic+t_res'></span>

<h3>Description</h3>

<p>A dataset containing simulation results from a study that just runs a t-test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_res
</code></pre>


<h3>Format</h3>

<p>A tibble with 1,000 rows and 5 variables:
</p>

<dl>
<dt>est</dt><dd><p>estimate of the mean difference.</p>
</dd>
<dt>p_val</dt><dd><p>p-value from the t-test.</p>
</dd>
<dt>lower_bound</dt><dd><p>lower bound of the confidence interval.</p>
</dd>
<dt>upper_bound</dt><dd><p>upper bound of the confidence interval.</p>
</dd>
<dt>true_param</dt><dd><p>true mean difference used to generate the data.</p>
</dd>
</dl>


<hr>
<h2 id='Tipton_Pusto'>Results for Figure 2 of Tipton &amp; Pustejovsky (2015)</h2><span id='topic+Tipton_Pusto'></span>

<h3>Description</h3>

<p>A dataset containing simulation results comparing small sample correction
methods for cluster robust variance estimation in meta-analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tipton_Pusto
</code></pre>


<h3>Format</h3>

<p>A tibble with 15,300 rows and 8 variables:
</p>

<dl>
<dt>num_studies</dt><dd><p>the number of studies included in the meta-analysis.</p>
</dd>
<dt>r</dt><dd><p>correlation between outcomes.</p>
</dd>
<dt>Isq</dt><dd><p>measure of heterogeneity of true effects.</p>
</dd>
<dt>contrast</dt><dd><p>type of contrast that was tested.</p>
</dd>
<dt>test</dt><dd><p>small sample method used.</p>
</dd>
<dt>q</dt><dd><p>the number of parameters in the hypothesis test.</p>
</dd>
<dt>rej_rate</dt><dd><p>the Type 1 error rate.</p>
</dd>
<dt>mcse</dt><dd><p>the Monte Carlo standard error for the estimate of the Type 1 error rate.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Tipton E, Pustejovsky JE (2015).
&ldquo;Small-Sample Adjustments for Tests of Moderators and Model Fit Using Robust Variance Estimation in Meta-Regression.&rdquo;
<em>Journal of Educational and Behavioral Statistics</em>, <b>40</b>(6), 604&ndash;634.
ISSN 1076-9986, 1935-1054, <a href="https://doi.org/10.3102/1076998615606099">doi:10.3102/1076998615606099</a>, <a href="https://journals.sagepub.com/doi/10.3102/1076998615606099">https://journals.sagepub.com/doi/10.3102/1076998615606099</a>.
</p>

<hr>
<h2 id='welch_res'>Welch t-test simulation results</h2><span id='topic+welch_res'></span>

<h3>Description</h3>

<p>A dataset containing simulation results from a study comparing Welch t-test to the conventional t-test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>welch_res
</code></pre>


<h3>Format</h3>

<p>A tibble with 16,000 rows and 11 variables:
</p>

<dl>
<dt>n1</dt><dd><p>sample size for Group 1.</p>
</dd>
<dt>n2</dt><dd><p>sample size for Group 2.</p>
</dd>
<dt>mean_diff</dt><dd><p>true difference in means of two groups used to generate the data.</p>
</dd>
<dt>iterations</dt><dd><p>number of iterations.</p>
</dd>
<dt>seed</dt><dd><p>seed used to generate data.</p>
</dd>
<dt>method</dt><dd><p>indicates whether Welch or conventional t-test was used.</p>
</dd>
<dt>est</dt><dd><p>estimate of the mean difference.</p>
</dd>
<dt>var</dt><dd><p>variance of the estimate.</p>
</dd>
<dt>p_val</dt><dd><p>p-value from the t-test.</p>
</dd>
<dt>lower_bound</dt><dd><p>lower bound of the confidence interval.</p>
</dd>
<dt>upper_bound</dt><dd><p>upper bound of the confidence interval.</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
