<!DOCTYPE html><html lang="en"><head><title>Help for package EvoPhylo</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EvoPhylo}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#characters'>
<p>A morphological phylogenetic data matrix</p></a></li>
<li><a href='#clock_reshape'>
<p>Convert clock rate tables from wide to long format</p></a></li>
<li><a href='#clockrate_dens_plot'>
<p>Plot clock rate distributions</p></a></li>
<li><a href='#clockrate_reg_plot'>
<p>Plot regression lines between sets of rates</p></a></li>
<li><a href='#clockrate_summary'>
<p>Compute rate summary statistics across clades and clocks</p></a></li>
<li><a href='#cluster_to_nexus'>
<p>Export character partitions to a Nexus file</p></a></li>
<li><a href='#combine_log'>
<p>Combine and filter (.p) log files from Mr.Bayes</p></a></li>
<li><a href='#drop.dummy.beast'><p>Remove dummy tip from beast summary trees, accounting for metadata on the tips</p></a></li>
<li><a href='#drop.dummy.mb'><p>Remove dummy tip from Mr. Bayes summary trees, accounting for metadata on the tips</p></a></li>
<li><a href='#FBD_dens_plot'>
<p>Density plots for each FBD parameter</p></a></li>
<li><a href='#FBD_normality_plot'>
<p>Inspect FBD parameter distributions visually</p></a></li>
<li><a href='#FBD_reshape'>
<p>Convert an FBD posterior parameter table from wide to long format</p></a></li>
<li><a href='#FBD_summary'>
<p>Summarize FBD posterior parameter estimates</p></a></li>
<li><a href='#FBD_tests1'>
<p>Test assumptions of normality and homoscedasticity for FBD posterior parameters</p></a></li>
<li><a href='#FBD_tests2'>
<p>Test for differences in FBD parameter values</p></a></li>
<li><a href='#get_clockrate_table_BEAST2'><p>Extract evolutionary rates from Bayesian clock trees produced by BEAST2</p></a></li>
<li><a href='#get_clockrate_table_MrBayes'>
<p>Extract evolutionary rates from a Bayesian clock tree produced by Mr. Bayes</p></a></li>
<li><a href='#get_gower_dist'>
<p>Compute Gower distances between characters</p></a></li>
<li><a href='#get_pwt_rates_BEAST2'>
<p>Conduct pairwise t-tests between node rates and clock base rates from a BEAST2 output.</p></a></li>
<li><a href='#get_pwt_rates_MrBayes'>
<p>Conduct pairwise t-tests between node rates and clock base rate from a Mr.Bayes output.</p></a></li>
<li><a href='#get_sil_widths'>
<p>Calculate silhouette widths index for various numbers of partitions</p></a></li>
<li><a href='#make_clusters'>
<p>Estimate and plot character partitions</p></a></li>
<li><a href='#offset.to.dummy'><p>Convert trees produced by a BEAST2 FBD analysis with offset to trees with correct ages.</p></a></li>
<li><a href='#offset.to.dummy.metadata'><p>Convert trees produced by a BEAST2 FBD analysis with offset to trees with correct ages,</p>
accounting for possible metadata on the tips.</a></li>
<li><a href='#plot_back_rates'>
<p>Plots distribution of background rates extracted from posterior log files.</p></a></li>
<li><a href='#plot_treerates_sgn'>
<p>Plot Bayesian evolutionary tree with rate thresholds for selection mode</p></a></li>
<li><a href='#post_trees'>
<p>Multiple phylogenetic clock trees</p></a></li>
<li><a href='#posterior1p'>
<p>Posterior parameter samples (single clock)</p></a></li>
<li><a href='#posterior3p'>
<p>Posterior parameter samples (3 clock partions)</p></a></li>
<li><a href='#RateTable_Means_1p_Clades'>
<p>Mean clock rates by node and clade (single clock)</p></a></li>
<li><a href='#RateTable_Means_3p_Clades'>
<p>Mean clock rates by node and clade (3 clock partitions)</p></a></li>
<li><a href='#tree_clock1'>
<p>BEAST2 phylogenetic tree with clock rates from partition 1</p></a></li>
<li><a href='#tree_clock2'>
<p>BEAST2 phylogenetic tree with clock rates from partition 2</p></a></li>
<li><a href='#tree1p'>
<p>Phylogenetic tree with a single clock partition</p></a></li>
<li><a href='#tree3p'>
<p>Phylogenetic tree with 3 clock partitions</p></a></li>
<li><a href='#write_partitioned_alignments'><p>Write character partitions as separate Nexus files (for use in BEAUti)</p></a></li>
<li><a href='#write.beast.treedata'>
<p>Export multiple treedata objects (S4 class tree files) to BEAST NEXUS file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Title:</td>
<td>Pre- And Postprocessing of Morphological Data from Relaxed Clock
Bayesian Phylogenetics</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs automated morphological character partitioning for 
             phylogenetic analyses and analyze macroevolutionary parameter 
             outputs from clock (time-calibrated) Bayesian inference analyses, following 
             concepts introduced by Simões and Pierce (2021) &lt;<a href="https://doi.org/10.1038%2Fs41559-021-01532-x">doi:10.1038/s41559-021-01532-x</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ape (&ge; 1.16.2), dplyr (&ge; 1.0.8), cluster (&ge; 2.1.2),
deeptime (&ge; 0.2.0), ggplot2 (&ge; 3.3.5), ggrepel (&ge; 0.9.1),
ggtree (&ge; 3.1.5.902), patchwork, treeio (&ge; 1.16.2), Rtsne (&ge;
0.15), unglue (&ge; 0.1.0), devtools (&ge; 2.4.3)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>kableExtra, knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tiago-simoes/EvoPhylo">https://github.com/tiago-simoes/EvoPhylo</a>,
<a href="https://tiago-simoes.github.io/EvoPhylo/">https://tiago-simoes.github.io/EvoPhylo/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tiago-simoes/EvoPhylo/issues">https://github.com/tiago-simoes/EvoPhylo/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-03 16:33:02 UTC; tiago</td>
</tr>
<tr>
<td>Author:</td>
<td>Tiago Simoes <a href="https://orcid.org/0000-0003-4716-649X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Noah Greifer <a href="https://orcid.org/0000-0003-3067-7154"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Joelle Barido-Sottani
    <a href="https://orcid.org/0000-0002-5220-5468"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Stephanie Pierce <a href="https://orcid.org/0000-0003-0717-1841"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tiago Simoes &lt;trsimoes87@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-03 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='characters'>
A morphological phylogenetic data matrix
</h2><span id='topic+characters'></span>

<h3>Description</h3>

<p>An example dataset of morphological characters for early tetrapodomorphs from Simões &amp; Pierce (2021). This type of data would be used as input to <code><a href="#topic+get_gower_dist">get_gower_dist</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("characters")</code></pre>


<h3>Format</h3>

<p>A data frame with 178 observations (characters) on 43 columns (taxa).
</p>


<h3>References</h3>

<p>Simões, T. R. and S. E. Pierce (2021). Sustained High Rates of Morphological Evolution During the Rise of Tetrapods. <em>Nature Ecology &amp; Evolution</em> 5: 1403–1414.
</p>

<hr>
<h2 id='clock_reshape'>
Convert clock rate tables from wide to long format
</h2><span id='topic+clock_reshape'></span>

<h3>Description</h3>

<p>Converts clock rate tables, such as those produced by <code><a href="#topic+clockrate_summary">clockrate_summary</a></code> and imported back after including clade names, from wide to long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clock_reshape(rate_table)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clock_reshape_+3A_rate_table">rate_table</code></td>
<td>

<p>A data frame of clock rates, such as from the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> with an extra &quot;clade&quot; column.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will convert clock rate tables from wide to long format, with a new column &quot;clock&quot; containing the clock partition from where each rate estimate was obtained as a factor. The long format is necessary for downstream analyses of selection strength (mode), as similarly done by <code><a href="#topic+FBD_reshape">FBD_reshape</a></code> for posterior parameter log files.
</p>


<h3>Value</h3>

<p>A data frame containing a single &quot;value&quot; column (for all rate values) and one column for the &quot;clock&quot; variable (indicating to which clock partition each rate values refers to)
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, <code><a href="#topic+clockrate_summary">clockrate_summary</a></code>, <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

## The example dataset rate_table_clades_means3
## has clades and 3 clock rate columns:
data("rate_table_clades_means3")

## Reshape a clock rate table with clade names to long format
## Not run: 
rates_by_clade &lt;- clock_reshape(rate_table_clades_means3)

## End(Not run)</code></pre>

<hr>
<h2 id='clockrate_dens_plot'>
Plot clock rate distributions
</h2><span id='topic+clockrate_dens_plot'></span>

<h3>Description</h3>

<p>Plots the distribution density of clock rates by clock and clade. The input must have a &quot;clade&quot; column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clockrate_dens_plot(rate_table, clock = NULL,
                    stack = FALSE, nrow = 1,
                    scales = "fixed")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clockrate_dens_plot_+3A_rate_table">rate_table</code></td>
<td>

<p>A data frame of clock rates, such as from the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> with an extra &quot;clade&quot; column.
</p>
</td></tr>
<tr><td><code id="clockrate_dens_plot_+3A_clock">clock</code></td>
<td>

<p>Which clock rates will be plotted. If unspecified, all clocks are plotted.
</p>
</td></tr>
<tr><td><code id="clockrate_dens_plot_+3A_stack">stack</code></td>
<td>

<p>Whether to display stacked density plots (<code>TRUE</code>) or overlapping density plots (<code>FALSE</code>).
</p>
</td></tr>
<tr><td><code id="clockrate_dens_plot_+3A_nrow">nrow</code></td>
<td>

<p>When plotting rates for more than one clock, how many rows should be filled by the plots. This is passed to <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.
</p>
</td></tr>
<tr><td><code id="clockrate_dens_plot_+3A_scales">scales</code></td>
<td>

<p>When plotting rates for more than one clock, whether the axis scales should be &quot;fixed&quot; (default) across clocks or allowed to vary (&quot;free&quot;, &quot;free_x&quot;, or &quot;free_y&quot;). This is passed to <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user must manually add clades to the rate table produced by <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> before it can be used with this function. This can be doen manually with in R, such as by using a graphical user interface for editing data like the <span class="pkg">DataEditR</span> package, or by writing the rate table to a spreadsheet and reading it back in after adding the clades. The example below uses a table that has had the clades added.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object, which can be modified using <span class="pkg">ggplot2</span> functions.
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code>, <code><a href="ggplot2.html#topic+geom_density">geom_density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

data("RateTable_Means_3p_Clades")

# Overlapping plots
clockrate_dens_plot(RateTable_Means_3p_Clades, stack = FALSE,
                    nrow = 1, scales = "fixed")

# Stacked density for all three clocks, changing the color
# palette to viridis using ggplot2 functions
clockrate_dens_plot(RateTable_Means_3p_Clades,
                    clock = 1:3, nrow = 1, stack = TRUE,
                    scales = "fixed") +
  ggplot2::scale_color_viridis_d() +
  ggplot2::scale_fill_viridis_d()
</code></pre>

<hr>
<h2 id='clockrate_reg_plot'>
Plot regression lines between sets of rates
</h2><span id='topic+clockrate_reg_plot'></span>

<h3>Description</h3>

<p>Displays a scatterplot and fits regression line of one set of clock rates against another, optionally displaying their Pearson correlation coefficient (r) and R-squared values (R^2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clockrate_reg_plot(rate_table, clock_x, clock_y,
                   method = "lm", show_lm = TRUE,
                   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clockrate_reg_plot_+3A_rate_table">rate_table</code></td>
<td>

<p>A table of clock rates, such as from the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code>.
</p>
</td></tr>
<tr><td><code id="clockrate_reg_plot_+3A_clock_x">clock_x</code>, <code id="clockrate_reg_plot_+3A_clock_y">clock_y</code></td>
<td>

<p>The clock rates that should go on the x- and y-axes, respectively.
</p>
</td></tr>
<tr><td><code id="clockrate_reg_plot_+3A_method">method</code></td>
<td>

<p>The method (function) used fit the regression of one clock on the other. Check the <code>method</code> argument in the to <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code> function of <span class="pkg">ggplot2</span> for all options. Default is <code>"lm"</code> for a linear regression model. <code>"glm"</code> and <code>"loess"</code> are alternative options.
</p>
</td></tr>
<tr><td><code id="clockrate_reg_plot_+3A_show_lm">show_lm</code></td>
<td>

<p>Whether to display the Pearson correlation coefficient (r) and R-squared values (R^2) between two sets of clock rates.
</p>
</td></tr>
<tr><td><code id="clockrate_reg_plot_+3A_...">...</code></td>
<td>

<p>Other arguments passed to <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>clockrate_reg_plot()</code> can only be used when multiple clocks are present in the clock rate table. Unlike <code><a href="#topic+clockrate_summary">clockrate_summary</a></code> and <code><a href="#topic+clockrate_dens_plot">clockrate_dens_plot</a></code>, no &quot;clade&quot; column is required.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object, which can be modified using <span class="pkg">ggplot2</span> functions.
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="ggplot2.html#topic+geom_point">geom_point</a></code>, <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

data("RateTable_Means_3p_Clades")

#Plot correlations between clocks 1 and 3
clockrate_reg_plot(RateTable_Means_3p_Clades,
                   clock_x = 1, clock_y = 3)

#Use arguments supplied to geom_smooth():
clockrate_reg_plot(RateTable_Means_3p_Clades,
                   clock_x = 1, clock_y = 3,
                   color = "red", se = FALSE)
</code></pre>

<hr>
<h2 id='clockrate_summary'>
Compute rate summary statistics across clades and clocks
</h2><span id='topic+clockrate_summary'></span>

<h3>Description</h3>

<p>Computes summary statistics for each clade and/or each clock partition. The input must have a &quot;clade&quot; column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clockrate_summary(rate_table, file = NULL, digits = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clockrate_summary_+3A_rate_table">rate_table</code></td>
<td>

<p>A data frame of clock rates, such as from the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> with an extra <code>"clade"</code> column.
</p>
</td></tr>
<tr><td><code id="clockrate_summary_+3A_file">file</code></td>
<td>

<p>An optional file path where the resulting table will be stored using <code><a href="utils.html#topic+write.csv">write.csv</a></code>.
</p>
</td></tr>
<tr><td><code id="clockrate_summary_+3A_digits">digits</code></td>
<td>

<p>The number of digits to round the summary results to. Default is 3. See <code><a href="base.html#topic+round">round</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user must manually add clades to the rate table produced by <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> before it can be used with this function. This can be doen manually within R, such as by using a graphical user interface for editing data like the <span class="pkg">DataEditR</span> package, or by writing the rate table to a spreadsheet and reading it back in after adding the clades. The example below uses a table that has had the clades added.
</p>


<h3>Value</h3>

<p>A data frame containing a row for each clade and each clock with summary statistics (n, mean, standard deviation, minimum, 1st quartile, median, third quartile, maximum).
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code>, <code><a href="base.html#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

data("RateTable_Means_3p_Clades")

clockrate_summary(RateTable_Means_3p_Clades)
</code></pre>

<hr>
<h2 id='cluster_to_nexus'>
Export character partitions to a Nexus file
</h2><span id='topic+cluster_to_nexus'></span>

<h3>Description</h3>

<p>Creates and exports a Nexus file with a list of characters and their respective partitions as inferred by the <code><a href="#topic+make_clusters">make_clusters</a></code> function. The contents can be copied and pasted directly into a Mr. Bayes commands block for a partitioned clock Bayesian inference analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_to_nexus(cluster_df, file = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster_to_nexus_+3A_cluster_df">cluster_df</code></td>
<td>

<p>A <code>cluster_df</code> object; the output of a call to <code><a href="#topic+make_clusters">make_clusters</a></code>.
</p>
</td></tr>
<tr><td><code id="cluster_to_nexus_+3A_file">file</code></td>
<td>

<p>The path of the text file to be created containing the partitioning information in Nexus format. If <code>NULL</code> (the default), no file will be written and the output will be returned as a string. If <code>""</code>, the text will be printed to the console. Passed directly to the <code>file</code> argument of <code><a href="base.html#topic+cat">cat</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The text as a string, returned invisibly if <code>file</code> is not <code>NULL</code>. Use <code><a href="base.html#topic+cat">cat</a></code> on the resulting output to format it correctly (i.e., to turn <code>"\n"</code> into line breaks).
</p>


<h3>See Also</h3>

<p><code>vignette("char-part")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+make_clusters">make_clusters</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("char-part") for how to use this
# function as part of an analysis pipeline

# Load example phylogenetic data matrix
data("characters")

# Create distance matrix
Dmatrix &lt;- get_gower_dist(characters)

# Find optimal partitioning scheme using PAM under k=3
# partitions
cluster_df &lt;- make_clusters(Dmatrix, k = 3)

# Write to Nexus file and export to .txt file:
file &lt;- tempfile(fileext = ".txt")

# You would set, e.g.,
# file &lt;- "path/to/file.txt"

cluster_to_nexus(cluster_df, file = file)
</code></pre>

<hr>
<h2 id='combine_log'>
Combine and filter (.p) log files from Mr.Bayes
</h2><span id='topic+combine_log'></span>

<h3>Description</h3>

<p>Imports parameter (.p) log files from Mr. Bayes and combines them into a single data frame. Samples can be dropped from the start of each log file (i.e., discarded as burn-in) and/or downsampled to reduce the size of the output object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_log(path = ".", burnin = 0.25, downsample = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combine_log_+3A_path">path</code></td>
<td>

<p>The path to a folder containing (.p) log files or a character vector of log files to be read.
</p>
</td></tr>
<tr><td><code id="combine_log_+3A_burnin">burnin</code></td>
<td>

<p>Either the number or a proportion of generations to drop from the beginning of each log file.
</p>
</td></tr>
<tr><td><code id="combine_log_+3A_downsample">downsample</code></td>
<td>

<p>Either the number or the proportion of generations the user wants to keep after downsampling for the final (combined) log file. Generations will be dropped in approximately equally-spaced intervals.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>combine_log()</code> imports log files produced by Mr.Bayes, ignoring the first row of the file (which contains an ID number). The files are appended together, optionally after removing burn-in generations from the beginning and/or by further filtering throughout the rest of each file. When <code>burnin</code> is greater than 0, the number or propotion of generations corresponding to the supplied value will be dropped from the beginning of each file as it is read in. For example, setting <code>burnin = .25</code> (the default) will drop the first 25% of generations from each file. When <code>downsample</code> is greater than 0, the file will be downsampled until the number or proportion of generations corresponding to the supplied value is reached. For example, if <code>downsample = 10000</code> generations (the default) for log files from 4 independent runs (i.e., 4 (.p) files), each log file will be downsampled to 2500 generations, and the final combined data frame will contain 10000 samples, selected in approximately equally spaced intervals from the original data.
</p>
<p>The output can be supplied to <code><a href="#topic+get_pwt_rates_MrBayes">get_pwt_rates_MrBayes</a></code> and to <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>. The latter will convert the log data frame from my wide to long format, which is necessary to be used as input for downstream analyses using <code><a href="#topic+FBD_summary">FBD_summary</a></code>, <code><a href="#topic+FBD_dens_plot">FBD_dens_plot</a></code>, <code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code>, <code><a href="#topic+FBD_tests1">FBD_tests1</a></code>, or <code><a href="#topic+FBD_tests2">FBD_tests2</a></code>.
</p>


<h3>Value</h3>

<p>A data frame with columns corresponding to the columns in the supplied log files and rows containing the sampled parameter values. Examples of the kind of output produced can be accessed using <code><a href="#topic+posterior1p">data(&quot;posterior1p&quot;)</a></code> and <code><a href="#topic+posterior3p">data(&quot;posterior3p&quot;)</a></code>.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+FBD_reshape">FBD_reshape</a></code>, which reshapes a combined parameter log file for use in some other package functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline
## Not run: 
posterior &lt;- combine_log("path/to/folder", burnin = .25,
                         downsample = 10000)

## End(Not run)
</code></pre>

<hr>
<h2 id='drop.dummy.beast'>Remove dummy tip from beast summary trees, accounting for metadata on the tips</h2><span id='topic+drop.dummy.beast'></span>

<h3>Description</h3>

<p>This method is designed to remove the dummy tip added on offset trees once postprocessing is
complete (for instance once the summary tree has been built using TreeAnnotator).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop.dummy.beast(
  tree.file,
  output.file = NULL,
  dummy.name = "dummy",
  convert.heights = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drop.dummy.beast_+3A_tree.file">tree.file</code></td>
<td>
<p>path to file containing the tree with dummy tip</p>
</td></tr>
<tr><td><code id="drop.dummy.beast_+3A_output.file">output.file</code></td>
<td>
<p>path to file to write converted tree. If <code>NULL</code> (default), the tree is simply returned.</p>
</td></tr>
<tr><td><code id="drop.dummy.beast_+3A_dummy.name">dummy.name</code></td>
<td>
<p>name of the added dummy tip, default <code>dummy</code>.</p>
</td></tr>
<tr><td><code id="drop.dummy.beast_+3A_convert.heights">convert.heights</code></td>
<td>
<p>whether height metadata should be converted to height - offset (required to plot e.g. HPD intervals correctly). Default TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of <code>tree</code> converted tree (as treedata) ; and <code>offset</code> age of the youngest tip in the final tree
</p>


<h3>See Also</h3>

<p><code><a href="#topic+drop.dummy.mb">drop.dummy.mb()</a></code> for the same function using summary trees with a &quot;dummy&quot; extant from Mr. Bayes
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Analyze the trees with dummy tips - for instance, calculate the MCC summary tree
# Then remove the dummy tip from the MCC tree
final_tree &lt;- drop.dummy.beast(system.file("extdata", "ex_offset.MCC.tre", package = "EvoPhylo"))

</code></pre>

<hr>
<h2 id='drop.dummy.mb'>Remove dummy tip from Mr. Bayes summary trees, accounting for metadata on the tips</h2><span id='topic+drop.dummy.mb'></span>

<h3>Description</h3>

<p>This method is designed to remove the dummy tip added to a dataset before running with Mr. Bayes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop.dummy.mb(
  tree.file,
  output.file = NULL,
  dummy.name = "dummy",
  convert.ages = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drop.dummy.mb_+3A_tree.file">tree.file</code></td>
<td>
<p>path to file containing the tree with dummy tip</p>
</td></tr>
<tr><td><code id="drop.dummy.mb_+3A_output.file">output.file</code></td>
<td>
<p>path to file to write converted tree. If <code>NULL</code> (default), the tree is simply returned.</p>
</td></tr>
<tr><td><code id="drop.dummy.mb_+3A_dummy.name">dummy.name</code></td>
<td>
<p>name of the added dummy tip, default <code>dummy</code>.</p>
</td></tr>
<tr><td><code id="drop.dummy.mb_+3A_convert.ages">convert.ages</code></td>
<td>
<p>whether height metadata should be converted to height - offset (required to plot e.g. HPD intervals correctly). Default TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of <code>tree</code> converted tree (as treedata) ; and <code>offset</code> age of the youngest tip in the final tree
</p>


<h3>See Also</h3>

<p><code><a href="#topic+drop.dummy.beast">drop.dummy.beast()</a></code> for the same function using summary trees with a &quot;dummy&quot; extant from BEAST2
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Remove the dummy tip from the summary tree
final_tree &lt;- drop.dummy.mb(system.file("extdata", "tree_mb_dummy.tre", package = "EvoPhylo"))

</code></pre>

<hr>
<h2 id='FBD_dens_plot'>
Density plots for each FBD parameter
</h2><span id='topic+FBD_dens_plot'></span>

<h3>Description</h3>

<p>Produces a density or violin plot displaying the distribution of FBD parameter samples by time bin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBD_dens_plot(posterior, parameter, type = "density",
              stack = FALSE, color = "red")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FBD_dens_plot_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates containing a single &quot;Time_bin&quot; column and one column for each FBD parameter value. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> followed by <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>.
</p>
</td></tr>
<tr><td><code id="FBD_dens_plot_+3A_parameter">parameter</code></td>
<td>

<p>A string containing the name of an FBD parameter in the data frame; abbreviations allowed.
</p>
</td></tr>
<tr><td><code id="FBD_dens_plot_+3A_type">type</code></td>
<td>

<p>The type of plot; either <code>"density"</code> for a density plot or <code>"violin"</code> for violin plots. Abbreviations allowed.
</p>
</td></tr>
<tr><td><code id="FBD_dens_plot_+3A_stack">stack</code></td>
<td>

<p>When <code>type = "density"</code>, whether to produce stacked densities (<code>TRUE</code>) or overlapping densities (<code>FALSE</code>, the default). Ignored otherwise.
</p>
</td></tr>
<tr><td><code id="FBD_dens_plot_+3A_color">color</code></td>
<td>

<p>When <code>type = "violin"</code>, the color of the plotted densities.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Density plots are produced using <code><a href="ggplot2.html#topic+stat_density">ggplot2::stat_density</a></code>, and violin plots are produced using <code><a href="ggplot2.html#topic+geom_violin">ggplot2::geom_violin</a></code>. On violin plots, a horizontal line indicates the median (of the density), and the black dot indicates the mean.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object, which can be modified using <span class="pkg">ggplot2</span> functions.
</p>


<h3>Note</h3>

<p>When setting <code>type = "violin"</code>, a warning may appear saying something like &quot;In regularize.values(x, y, ties, missing(ties), na.rm = na.rm) : collapsing to unique 'x' values&quot;. This warning can be ignored.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="ggplot2.html#topic+stat_density">ggplot2::stat_density</a></code>, <code><a href="ggplot2.html#topic+geom_violin">ggplot2::geom_violin</a></code> for the underlying functions to produce the plots.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code> for producing a single data frame of FBD parameter posterior samples from multiple log files.
</p>
<p><code><a href="#topic+FBD_reshape">FBD_reshape</a></code> for converting a single data frame of FBD parameter estimates, such as those imported using <code><a href="#topic+combine_log">combine_log</a></code>, from wide to long format.
</p>
<p><code><a href="#topic+FBD_summary">FBD_summary</a></code>, <code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code>, <code><a href="#topic+FBD_tests1">FBD_tests1</a></code>, and <code><a href="#topic+FBD_tests2">FBD_tests2</a></code> for other functions used to summarize and display the distributions of the parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline

data("posterior3p")

posterior3p_long &lt;- FBD_reshape(posterior3p)

FBD_dens_plot(posterior3p_long, parameter = "net_speciation",
              type = "density", stack = FALSE)

FBD_dens_plot(posterior3p_long, parameter = "net_speciation",
              type = "density", stack = TRUE)

FBD_dens_plot(posterior3p_long, parameter = "net_speciation",
              type = "violin", color = "red")
</code></pre>

<hr>
<h2 id='FBD_normality_plot'>
Inspect FBD parameter distributions visually
</h2><span id='topic+FBD_normality_plot'></span>

<h3>Description</h3>

<p>Produces plots of the distributions of fossilized birth–death process (FBD) parameters to facilitate the assessment of the assumptions of normality within time bins and homogeneity of variance across time bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBD_normality_plot(posterior)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FBD_normality_plot_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates containing a single &quot;Time_bin&quot; column and one column for each FBD parameter value. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> followed by <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plots produced include density plots for each parameter within each time bin (residualized to have a mean of zero), scaled so that the top of the density is at a value of one (in <em>black</em>). Superimposed onto these densitys are the densities of a normal distribution with the same mean and variance (and scaled by the same amount) (in <em>red</em>). Deviations between the normal density in <em>red</em> and the density of the parameters in <em>black</em> indiciate deviations from normality. The standard deviation of each parameter is also displayed for each time bin to facilitate assessing homogenity of variance.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object, which can be modified using <span class="pkg">ggplot2</span> functions.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code> for producing a single data set of parameter posterior samples from individual parameter log files.
</p>
<p><code><a href="#topic+FBD_reshape">FBD_reshape</a></code> for converting posterior parameter table from wide to long format.
</p>
<p><code><a href="#topic+FBD_tests1">FBD_tests1</a></code> for statistical tests of normality and homogeneity of variance.
</p>
<p><code><a href="#topic+FBD_tests2">FBD_tests2</a></code> for tests of differences in parameter means.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline

data("posterior3p")

posterior3p_long &lt;- FBD_reshape(posterior3p)

FBD_normality_plot(posterior3p_long)
</code></pre>

<hr>
<h2 id='FBD_reshape'>
Convert an FBD posterior parameter table from wide to long format
</h2><span id='topic+FBD_reshape'></span>

<h3>Description</h3>

<p>Converts FBD posterior parameter table, such as those imported using <code><a href="#topic+combine_log">combine_log</a></code>, from wide to long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBD_reshape(posterior, variables = NULL, log.type = c("MrBayes", "BEAST2"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FBD_reshape_+3A_posterior">posterior</code></td>
<td>

<p>Single posterior parameter sample dataset with skyline FBD parameters produced with <code><a href="#topic+combine_log">combine_log</a></code>.
</p>
</td></tr>
<tr><td><code id="FBD_reshape_+3A_variables">variables</code></td>
<td>

<p>Names of FBD rate variables in the log. If NULL (default), will attempt to auto-detect the names and log type.
</p>
</td></tr>
<tr><td><code id="FBD_reshape_+3A_log.type">log.type</code></td>
<td>

<p>Name of the software which produced the log (currently supported: MrBayes or BEAST2). Has to be set if <code>variables</code> is not NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior parameters log files produced by Bayesian evolutionary analyses using skyline birth-death tree models, including the skyline FBD model, result into two or more estimates for each FBD parameter, one for each time bin. This function will convert a table of parameters with skyline FBD parameters from wide to long format, with one row per generation per time bin and a new column &quot;Time_bin&quot; containing the respective time bins as a factor. The long format is necessary for downstream analyses using <code><a href="#topic+FBD_summary">FBD_summary</a></code>, <code><a href="#topic+FBD_dens_plot">FBD_dens_plot</a></code>, <code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code>, <code><a href="#topic+FBD_tests1">FBD_tests1</a></code>, or <code><a href="#topic+FBD_tests2">FBD_tests2</a></code>, as similarly done by <code><a href="#topic+clock_reshape">clock_reshape</a></code> for clock rate tables.
</p>
<p>The format of the log files can either be specified using the <code>variables</code> and <code>log.type</code> or auto-detected by the function.
The &quot;posterior&quot; data frame can be obtained by reading in a log file directly (e.g. using the <code>read.table</code> function) or by combining several output log files from Mr. Bayes using <code><a href="#topic+combine_log">combine_log</a></code>.
</p>


<h3>Value</h3>

<p>A data frame of posterior parameter estimates containing a single &quot;Time_bin&quot; column and one column for each FBD parameter value.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code>, <code><a href="stats.html#topic+reshape">reshape</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline

data("posterior3p")

head(posterior3p)

## Reshape FBD table to long format
posterior3p_long &lt;- FBD_reshape(posterior3p)

head(posterior3p_long)
</code></pre>

<hr>
<h2 id='FBD_summary'>
Summarize FBD posterior parameter estimates
</h2><span id='topic+FBD_summary'></span>

<h3>Description</h3>

<p>Produces numerical summaries of each fossilized birth–death process (FBD) posterior parameter by time bin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBD_summary(posterior, file = NULL, digits = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FBD_summary_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates containing a single &quot;Time_bin&quot; column and one column for each FBD parameter value. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> followed by <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>.
</p>
</td></tr>
<tr><td><code id="FBD_summary_+3A_file">file</code></td>
<td>

<p>An optional file path where the resulting table will be stored using <code><a href="utils.html#topic+write.csv">write.csv</a></code>.
</p>
</td></tr>
<tr><td><code id="FBD_summary_+3A_digits">digits</code></td>
<td>

<p>The number of digitis to round the summary results to. Default is 3. See <code><a href="base.html#topic+round">round</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with a row for each paramater and time bin, and columns for different summary statistics. These include the number of data points (<code>n</code>) and the mean, standard deviation (<code>sd</code>), minimum value (<code>min</code>), first quartile (<code>Q1</code>), median, third quartile (<code>Q3</code>), and maximum value (<code>max</code>). When <code>file</code> is not <code>NULL</code>, a .csv file containing this data frame will be saved to the filepath specified in <code>file</code> and the output will be returned invisibly.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code> for producing a single data set of parameter posterior samples from individual parameter log files.
</p>
<p><code><a href="#topic+FBD_reshape">FBD_reshape</a></code> for converting posterior parameter table from wide to long format.
</p>
<p><code><a href="#topic+FBD_dens_plot">FBD_dens_plot</a></code>, <code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code>, <code><a href="#topic+FBD_tests1">FBD_tests1</a></code>, and <code><a href="#topic+FBD_tests2">FBD_tests2</a></code> for other functions used to summarize and display the distributions of the parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline

data("posterior3p")

posterior3p_long &lt;- FBD_reshape(posterior3p)

FBD_summary(posterior3p_long)
</code></pre>

<hr>
<h2 id='FBD_tests1'>
Test assumptions of normality and homoscedasticity for FBD posterior parameters
</h2><span id='topic+FBD_tests1'></span>

<h3>Description</h3>

<p>Produces tests of normality (within time bin, ignoring time bin, and pooling within-time bin values) and homoscedasticity (homogeneity of variances) for each fossilized birth–death process (FBD) parameter in the posterior parameter log file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBD_tests1(posterior, downsample = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FBD_tests1_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates containing a single &quot;Time_bin&quot; column and one column for each FBD parameter value. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> followed by <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>.
</p>
</td></tr>
<tr><td><code id="FBD_tests1_+3A_downsample">downsample</code></td>
<td>

<p>Whether to downsample the observations to ensure Shapiro-Wilk normality tests can be run. If <code>TRUE</code>, observations will be dropped so that no more than 5000 observations are used for the tests on the full dataset, as required by <code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code>. They will be dropped in evenly spaced intervals. If <code>FALSE</code> and there are more than 5000 observations for any test, that test will not be run.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>FBD_tests1()</code> performs several tests on the posterior distributions of parameter values within and across time bins. It produces the Shapiro-Wilk test for normality using <code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> and the Bartlett and Fligner tests for homogeneity of variance using <code><a href="stats.html#topic+bartlett.test">bartlett.test</a></code> and <code><a href="stats.html#topic+fligner.test">fligner.test</a></code>, respectively. Note that these tests are likely to be significant even if the observations are approximately normally distributed or have approximately equal variance; therefore, they should be supplemented with visual inspection using <code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code>.
</p>


<h3>Value</h3>

<p>A list containing the results of the three tests with the following elements:
</p>
<table role = "presentation">
<tr><td><code>shapiro</code></td>
<td>
<p>A list with an element for each parameter. Each element is a data frame with a row for each time bin and the test statistic and p-value for the Shapiro-Wilk test for normality. In addition, there will be a row for an overall test, combining all observations ignoring time bin, and a test of the residuals, which combines the group-mean-centered observations (equivalent to the residuals in a regression of the parameter on time bin).</p>
</td></tr>
<tr><td><code>bartlett</code></td>
<td>
<p>A data frame of the Bartlett test for homogeneity of variance across time bins with a row for each parameter and the test statistic and p-value for the test.</p>
</td></tr>
<tr><td><code>fligner</code></td>
<td>
<p>A data frame of the Fligner test for homogeneity of variance across time bins with a row for each parameter and the test statistic and p-value for the test.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code> for producing a single data set of parameter posterior samples from individual parameter log files.
</p>
<p><code><a href="#topic+FBD_reshape">FBD_reshape</a></code> for converting posterior parameter table from wide to long format.
</p>
<p><code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code> for visual assessments.
</p>
<p><code><a href="#topic+FBD_tests2">FBD_tests2</a></code> for tests of differences between parameter means.
</p>
<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code>, <code><a href="stats.html#topic+bartlett.test">bartlett.test</a></code>, and <code><a href="stats.html#topic+fligner.test">fligner.test</a></code> for the statistical tests used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline

data("posterior3p")

posterior3p_long &lt;- FBD_reshape(posterior3p)

FBD_tests1(posterior3p_long)
</code></pre>

<hr>
<h2 id='FBD_tests2'>
Test for differences in FBD parameter values
</h2><span id='topic+FBD_tests2'></span>

<h3>Description</h3>

<p><code>FBD_tests2()</code> performs t-tests and Mann-Whitney U-tests to compare the average value of fossilized birth–death process (FBD) parameters between time bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FBD_tests2(posterior, p.adjust.method = "fdr")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FBD_tests2_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates containing a single &quot;Time_bin&quot; column and one column for each FBD parameter value. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> followed by <code><a href="#topic+FBD_reshape">FBD_reshape</a></code>.
</p>
</td></tr>
<tr><td><code id="FBD_tests2_+3A_p.adjust.method">p.adjust.method</code></td>
<td>

<p>The method use to adjust the p-values for multiple testing. See <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> for details and options. Default if <code>"fdr"</code> for the Benjamini-Hochberg false discovery rate correction.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code> and <code><a href="stats.html#topic+pairwise.wilcox.test">pairwise.wilcox.test</a></code> are used to calculate, respectively, the t-test and Mann-Whitney U-tests statistics and p-values. Because the power of these tests depends on the number of posterior samples, it can be helpful to examine the distributions of FBD parameter posteriors using <code><a href="#topic+FBD_dens_plot">FBD_dens_plot</a></code> instead of relying heavily on the tests.
</p>


<h3>Value</h3>

<p>A list with an element for each test, each of which contains a list of test results for each parameter. The results are in the form of a data frame containing the sample sizes and unadjusted and adjusted p-values for each comparison.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code> for producing a single data set of parameter posterior samples from individual parameter log files.
</p>
<p><code><a href="#topic+FBD_reshape">FBD_reshape</a></code> for converting posterior parameter table from wide to long format.
</p>
<p><code><a href="#topic+FBD_dens_plot">FBD_dens_plot</a></code>, <code><a href="#topic+FBD_normality_plot">FBD_normality_plot</a></code>, <code><a href="#topic+FBD_tests1">FBD_tests1</a></code>, and <code><a href="#topic+FBD_tests2">FBD_tests2</a></code> for other functions used to summarize and display the distributions of the parameter posteriors.
</p>
<p><code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code> and <code><a href="stats.html#topic+pairwise.wilcox.test">pairwise.wilcox.test</a></code> for the tests used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline

data("posterior3p")

posterior3p_long &lt;- FBD_reshape(posterior3p)

FBD_tests2(posterior3p_long)
</code></pre>

<hr>
<h2 id='get_clockrate_table_BEAST2'>Extract evolutionary rates from Bayesian clock trees produced by BEAST2</h2><span id='topic+get_clockrate_table_BEAST2'></span>

<h3>Description</h3>

<p>BEAST2 stores the rates for each clock in a separate file. All trees need to be loaded using <code>treeio::read.beast</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_clockrate_table_BEAST2(..., summary = "median", drop_dummy = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_clockrate_table_BEAST2_+3A_...">...</code></td>
<td>
<p><code>treedata</code> objects containing the summary trees with associated data on the rates for each separate clock.</p>
</td></tr>
<tr><td><code id="get_clockrate_table_BEAST2_+3A_summary">summary</code></td>
<td>
<p>summary metric used for the rates. Currently supported: <code>"mean"</code> or <code>"median"</code>, default <code>"median"</code>.</p>
</td></tr>
<tr><td><code id="get_clockrate_table_BEAST2_+3A_drop_dummy">drop_dummy</code></td>
<td>
<p>if not <code>NULL</code>, will drop the dummy extant tip with the given label from the BEAST2 summary trees prior to extracting the clock rates (when present). Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with a column containing the node identifier (<code>node</code>) and one column containing the clock rates for each tree provided, in the same order as the trees.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes()</a></code> for the equivalent function for MrBayes output files.
</p>
<p><code><a href="#topic+clockrate_summary">clockrate_summary()</a></code> for summarizing and examining properties of the resulting rate table. Note that clade membership for each node must be customized (manually added) before these functions can be used, since this is tree and dataset dependent.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Import all clock summary trees produced by BEAST2 from your local directory
## Not run: 
tree_clock1 &lt;- treeio::read.beast("tree_file_clock1.tre")
tree_clock2 &lt;- treeio::read.beast("tree_file_clock2.tre")

## End(Not run)

#Or use the example BEAST2 multiple clock trees that accompany EvoPhylo.
data(tree_clock1)
data(tree_clock2)

# obtain the rate table from BEAST2 trees
rate_table &lt;- get_clockrate_table_BEAST2(tree_clock1, tree_clock2, summary = "mean")

</code></pre>

<hr>
<h2 id='get_clockrate_table_MrBayes'>
Extract evolutionary rates from a Bayesian clock tree produced by Mr. Bayes
</h2><span id='topic+get_clockrate_table_MrBayes'></span>

<h3>Description</h3>

<p>Extract evolutionary rate summary statistics for each node from a Bayesian clock summary tree produced by Mr. Bayes and stores them in a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_clockrate_table_MrBayes(tree, summary = "median",
                    drop_dummy = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_clockrate_table_MrBayes_+3A_tree">tree</code></td>
<td>

<p>An S4 class object of type <code>treedata</code>; a Bayesian clock tree imported using <code><a href="treeio.html#topic+read.mrbayes">treeio::read.mrbayes</a></code> for Mr. Bayes summary trees.
</p>
</td></tr>
<tr><td><code id="get_clockrate_table_MrBayes_+3A_summary">summary</code></td>
<td>

<p>The name of the rate summary. Should be one of <code>"mean"</code> or <code>"median"</code>.
</p>
</td></tr>
<tr><td><code id="get_clockrate_table_MrBayes_+3A_drop_dummy">drop_dummy</code></td>
<td>

<p>if not <code>NULL</code>, will drop the dummy extant tip with the given label from the Mr. Bayes summary tree prior to extracting the clock rates (when present). Default is <code>NULL</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with a column containing the node identifier (<code>node</code>) and one column for each relaxed clock partition in the tree object containing clock rates.
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
<code><a href="#topic+get_clockrate_table_BEAST2">get_clockrate_table_BEAST2</a></code> for the equivalent function for BEAST2 output files.
<code><a href="#topic+clockrate_summary">clockrate_summary</a></code> for summarizing and examining properties of the resulting rate table. Note that clade membership for each node must be customized (manually added) before these functions can be used, since this is tree and dataset dependent.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

## Import summary tree with three clock partitions produced by
## Mr. Bayes (.t or .tre files) from your local directory
## Not run: 
tree3p &lt;- treeio::read.mrbayes("Tree3p.t")

## End(Not run)

#Or use the example Mr.Bayes multi-clock tree file (\code{tree3p})
data("tree3p")

# obtain the rate table from MrBayes tree
rate_table &lt;- get_clockrate_table_MrBayes(tree3p)

head(rate_table)
</code></pre>

<hr>
<h2 id='get_gower_dist'>
Compute Gower distances between characters
</h2><span id='topic+get_gower_dist'></span>

<h3>Description</h3>

<p>Computes Gower distance between characters from a phylogenetic data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_gower_dist(x, numeric = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_gower_dist_+3A_x">x</code></td>
<td>

<p>A phylogenetic data matrix in Nexus (.nex) format, or in any other data frame or matrix format with a column for each character and terminal taxa as rows, which will be read using <code><a href="ape.html#topic+read.nexus.data">ape::read.nexus.data</a></code>. The data cannot include polymorphisms.
</p>
</td></tr>
<tr><td><code id="get_gower_dist_+3A_numeric">numeric</code></td>
<td>

<p>Whether to treat the values contained in the <code>x</code> as numeric or categorical. If <code>FALSE</code> (default), features will be considered categorical; if <code>TRUE</code>, they will be considered numeric.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Gower distance matrix.
</p>


<h3>Author(s)</h3>

<p>This function uses code adapted from <code>StatMatch::gower.dist()</code> written by Marcello D'Orazio.
</p>


<h3>See Also</h3>

<p><code>vignette("char-part")</code> for the use of this function as part of an analysis pipeline.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("char-part") for how to use this
# function as part of an analysis pipeline

# Load example phylogenetic data matrix
data("characters")

# Create distance matrix
Dmatrix &lt;- get_gower_dist(characters)

# Reading data matrix as numeric data
Dmatrix &lt;- get_gower_dist(characters, numeric = TRUE)
</code></pre>

<hr>
<h2 id='get_pwt_rates_BEAST2'>
Conduct pairwise t-tests between node rates and clock base rates from a BEAST2 output.
</h2><span id='topic+get_pwt_rates_BEAST2'></span>

<h3>Description</h3>

<p>Produces a data frame containing the results of 1-sample t-tests for the mean of posterior clock rates against each node's absolute clock rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pwt_rates_BEAST2(rate_table, posterior)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pwt_rates_BEAST2_+3A_rate_table">rate_table</code></td>
<td>

<p>A data frame containing a single &quot;value&quot; column (for all rate values) and one column for the &quot;clock&quot; variable (indicating to which clock partition each rate values refers to), such as from the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> with an extra <code>clade</code> column added, and followed by <code><a href="#topic+clock_reshape">clock_reshape</a></code>.
</p>
</td></tr>
<tr><td><code id="get_pwt_rates_BEAST2_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates including a &quot;clockrate&quot; column indicating the base of the clock rate estimate for each generation that will be used for pairwise t-tests. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> (no need to reshape from wide to long). See the <code><a href="#topic+posterior1p">posterior1p</a></code> or <code><a href="#topic+posterior3p">posterior3p</a></code> datasets for an examples of how the input file should look.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>get_pwt_rates_BEAST2()</code> first transforms relative clock rates to absolute rate values for each node and each clock, by multiplying these by the mean posterior clock rate base value. Then, for each node and clock, a one-sample t-test is performed with the null hypothesis that the mean of the posterior clockrates is equal to that node and clock's absolute clock rate.
</p>


<h3>Value</h3>

<p>A long data frame with one row per node per clock and the following columns:
</p>
<table role = "presentation">
<tr><td><code>clade</code></td>
<td>
<p>The name of the clade, taken from the &quot;clade&quot; column of <code>rate_table</code></p>
</td></tr>
<tr><td><code>nodes</code></td>
<td>
<p>The node number, taken from the &quot;node&quot; column of <code>rate_table</code></p>
</td></tr>
<tr><td><code>clock</code></td>
<td>
<p>The clock partition number</p>
</td></tr>
<tr><td><code>background.rate(mean)</code></td>
<td>
<p>The absolute background clock rate (mean clock rate for the whole tree) sampled from the posterior log file</p>
</td></tr>
<tr><td><code>relative.rate(mean)</code></td>
<td>
<p>The relative mean clock rate per branch, taken from the &quot;rates&quot; columns of <code>rate_table</code></p>
</td></tr>
<tr><td><code>absolute.rate(mean)</code></td>
<td>
<p>The absolute mean clock rate per branch; the relative clock rate multiplied by the mean of the posterior clock rates</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p-value of the test comparing the mean ofthe posterior clockrates to each absolute clockrate</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

# Load example rate table and posterior data sets
RateTable_Means_Clades &lt;- system.file("extdata", "RateTable_Means_Clades.csv", package = "EvoPhylo")
RateTable_Means_Clades &lt;- read.csv(RateTable_Means_Clades, header = TRUE)

posterior &lt;- system.file("extdata", "Penguins_log.log", package = "EvoPhylo")
posterior &lt;- read.table(posterior, header = TRUE)

get_pwt_rates_BEAST2(RateTable_Means_Clades, posterior)

## End(Not run)</code></pre>

<hr>
<h2 id='get_pwt_rates_MrBayes'>
Conduct pairwise t-tests between node rates and clock base rate from a Mr.Bayes output.
</h2><span id='topic+get_pwt_rates_MrBayes'></span>

<h3>Description</h3>

<p>Produces a data frame containing the results of 1-sample t-tests for the mean of posterior clock rates against each node's absolute clock rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pwt_rates_MrBayes(rate_table, posterior)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pwt_rates_MrBayes_+3A_rate_table">rate_table</code></td>
<td>

<p>A data frame containing a single &quot;value&quot; column (for all rate values) and one column for the &quot;clock&quot; variable (indicating to which clock partition each rate values refers to), such as from the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> with an extra <code>clade</code> column added, and followed by <code><a href="#topic+clock_reshape">clock_reshape</a></code>.
</p>
</td></tr>
<tr><td><code id="get_pwt_rates_MrBayes_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates including a &quot;clockrate&quot; column indicating the base of the clock rate estimate for each generation that will be used for pairwise t-tests. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> (no need to reshape from wide to long). See the <code><a href="#topic+posterior1p">posterior1p</a></code> or <code><a href="#topic+posterior3p">posterior3p</a></code> datasets for an examples of how the input file should look.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>get_pwt_rates_MrBayes()</code> first transforms relative clock rates to absolute rate values for each node and each clock, by multiplying these by the mean posterior clock rate base value. Then, for each node and clock, a one-sample t-test is performed with the null hypothesis that the mean of the posterior clockrates is equal to that node and clock's absolute clock rate.
</p>


<h3>Value</h3>

<p>A long data frame with one row per node per clock and the following columns:
</p>
<table role = "presentation">
<tr><td><code>clade</code></td>
<td>
<p>The name of the clade, taken from the &quot;clade&quot; column of <code>rate_table</code></p>
</td></tr>
<tr><td><code>nodes</code></td>
<td>
<p>The node number, taken from the &quot;node&quot; column of <code>rate_table</code></p>
</td></tr>
<tr><td><code>clock</code></td>
<td>
<p>The clock partition number</p>
</td></tr>
<tr><td><code>relative.rate</code></td>
<td>
<p>The relative mean clock rate per node, taken from the &quot;rates&quot; columns of <code>rate_table</code></p>
</td></tr>
<tr><td><code>absolute.rate(mean)</code></td>
<td>
<p>The absolute mean clock rate per node; the relative clock rate multiplied by the mean of the posterior clock rates</p>
</td></tr>
<tr><td><code>null</code></td>
<td>
<p>The absolute clock rate used as the null value in the t-test</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p-value of the test comparing the mean ofthe posterior clockrates to each absolute clockrate</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+combine_log">combine_log</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

# Load example rate table and posterior data sets
data("RateTable_Means_3p_Clades")
data("posterior3p")

get_pwt_rates_MrBayes(RateTable_Means_3p_Clades, posterior3p)
</code></pre>

<hr>
<h2 id='get_sil_widths'>
Calculate silhouette widths index for various numbers of partitions
</h2><span id='topic+get_sil_widths'></span><span id='topic+plot.sil_width_df'></span>

<h3>Description</h3>

<p>Computes silhouette widths index for several possible numbers of clusters(partitions) <code>k</code>, which determines how well an object falls within their cluster compared to other clusters. The best number of clusters <code>k</code> is the one with the highest silhouette width.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_sil_widths(dist_mat, max.k = 10)

## S3 method for class 'sil_width_df'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_sil_widths_+3A_dist_mat">dist_mat</code></td>
<td>

<p>A Gower distance matrix, the output of a call to <code><a href="#topic+get_gower_dist">get_gower_dist</a></code>.
</p>
</td></tr>
<tr><td><code id="get_sil_widths_+3A_max.k">max.k</code></td>
<td>

<p>The maximum number of clusters(partitions) to search across.
</p>
</td></tr>
<tr><td><code id="get_sil_widths_+3A_x">x</code></td>
<td>

<p>A <code>sil_width_df</code> object; the output of a call to <code>get_sil_widths()</code>.
</p>
</td></tr>
<tr><td><code id="get_sil_widths_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="ggplot2.html#topic+geom_path">ggplot2::geom_line</a></code> to control the appearance of the plot.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>get_sil_widths</code> calls <code><a href="cluster.html#topic+pam">cluster::pam</a></code> on the supplied Gower distance matrix with each number of clusters (partitions) up to <code>max.k</code> and stores the average silhouette widths across the clustered characters. When <code>plot = TRUE</code>, a plot of the sillhouette widths against the number of clusters is produced, though this can also be produced seperately on the resulting data frame using <code>plot.sil_width_df()</code>. The number of clusters with the greatest silhouette width should be selected for use in the final clustering specification.
</p>


<h3>Value</h3>

<p>For <code>get_sil_widths()</code>, it produces a data frame, inheriting from class <code>"sil_width_df"</code>, with two columns: <code>k</code> is the number of clusters, and <code>sil_width</code> is the silhouette widths for each number of clusters. If <code>plot = TRUE</code>, the output is returned invisibly.
</p>
<p>For <code>plot()</code> on a <code>get_sil_widths()</code> object, it produces a <code>ggplot</code> object that can be manipulated using <span class="pkg">ggplot2</span> syntax (e.g., to change the <code>theme</code> or labels).
</p>


<h3>See Also</h3>

<p><code>vignette("char-part")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+get_gower_dist">get_gower_dist</a></code>, <code><a href="cluster.html#topic+pam">cluster::pam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("char-part") for how to use this
# function as part of an analysis pipeline

data("characters")

#Reading example file as categorical data
Dmatrix &lt;- get_gower_dist(characters)

#Get silhouette widths for k=7
sw &lt;- get_sil_widths(Dmatrix, max.k = 7)

sw

plot(sw, color = "red", size =2)
</code></pre>

<hr>
<h2 id='make_clusters'>
Estimate and plot character partitions
</h2><span id='topic+make_clusters'></span><span id='topic+plot.cluster_df'></span>

<h3>Description</h3>

<p>Determines cluster (partition) membership for phylogenetic morphological characters from the supplied Gower distance matrix and requested number of clusters using partitioning around medoids (PAM, or K-medoids). For further and independently testing the quality of the chosen partitioning scheme, users may also poduce graphic clustering (tSNEs), coloring data points according to PAM clusters, to verify PAM clustering results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_clusters(dist_mat, k, tsne = FALSE,
              tsne_dim = 2, tsne_theta = 0,
              ...)

## S3 method for class 'cluster_df'
plot(x, seed = NA, nrow = 1,
              ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_clusters_+3A_dist_mat">dist_mat</code></td>
<td>

<p>A Gower distance matrix, the output of a call to <code><a href="#topic+get_gower_dist">get_gower_dist</a></code>.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_k">k</code></td>
<td>

<p>The desired number of clusters (or character partitions), the output from <code><a href="#topic+get_sil_widths">get_sil_widths</a></code>.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_tsne">tsne</code></td>
<td>

<p>Whether to perform Barnes-Hut t-distributed stochastic neighbor embedding (tSNE) to produce a multi-dimensional representation of the distance matrix using <code><a href="Rtsne.html#topic+Rtsne">Rtsne::Rtsne</a></code>. The number of dimensions is controlled by the <code>tsne_dim</code> argument. See Details. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_tsne_dim">tsne_dim</code></td>
<td>

<p>When <code>tsne = TRUE</code>, the number of dimensions for the tSNE multidimensional scaling plots. This is passed to the <code>dims</code> argument of <code><a href="Rtsne.html#topic+Rtsne">Rtsne::Rtsne</a></code>. Default is 2.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_tsne_theta">tsne_theta</code></td>
<td>

<p>When <code>tsne = TRUE</code>, a parameter controlling the speed/accuracy trade-off (increase for faster but less accurate results). This is passed to the <code>theta</code> argument of <code><a href="Rtsne.html#topic+Rtsne">Rtsne::Rtsne</a></code>. Default is 0 for exact tSNE.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_...">...</code></td>
<td>

<p>For <code>make_clusters()</code>, other arguments passed to <code><a href="Rtsne.html#topic+Rtsne">Rtsne::Rtsne</a></code> when <code>tsne = TRUE</code>.
</p>
<p>For <code>plot()</code>, when plotting a <code>cluster_df</code> object, other arguments passed to <code><a href="ggrepel.html#topic+geom_label_repel">ggrepel::geom_text_repel</a></code> to control display of the observation labels.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_x">x</code></td>
<td>

<p>For <code>plot()</code>, a <code>cluster_df</code> object; the output of a call to <code>make_clusters()</code>.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_seed">seed</code></td>
<td>

<p>For <code>plot()</code>, the seed used to control the placement of the labels and the jittering of the points. Jittering only occurs when <code>tsne = FALSE</code> in the call to <code>make_clusters()</code>. Using a non-<code>NA</code> seed ensure replicability across uses.
</p>
</td></tr>
<tr><td><code id="make_clusters_+3A_nrow">nrow</code></td>
<td>

<p>For <code>plot()</code>, when <code>tsne = TRUE</code> in the call to <code>make_clusters()</code> and <code>tsne_dim</code> is greater than 2, the number of rows used to display the resulting 2-dimensional plots. Default is 1 for side-by-side plots.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>make_clusters</code> calls <code><a href="cluster.html#topic+pam">cluster::pam</a></code> on the supplied Gower distance matrix with the specified number of clusters to determine cluster membership for each character. PAM is analogous to K-means, but it has its clusters centered around medoids instead of centered around centroids, which are less prone to the impact from outliers and heterogeneous cluster sizes. PAM also has the advantage over k-means of utilizing Gower distance matrices instead of Euclidean distance matrices only.
</p>
<p>When <code>tsne = TRUE</code>, a Barnes-Hut t-distributed stochastic neighbor embedding is used to compute a multi-dimensional embedding of the distance matrix, coloring data points according to the PAM-defined clusters, as estimated by the function <code>make_clusters</code>. This graphic clustering allows users to independently test the quality of the chosen partitioning scheme from PAM, and can help in visualizing the resulting clusters. <code><a href="Rtsne.html#topic+Rtsne">Rtsne::Rtsne</a></code> is used to do this. The resulting dimensions will be included in the output; see Value below.
</p>
<p><code>plot()</code> plots all morphological characters in a scatterplot with points colored based on cluster membership. When <code>tsne = TRUE</code> in the call to <code>make_clusters()</code>, the x- and y-axes will correspond to requested tSNE dimensions. With more than 2 dimensions, several plots will be produced, one for each pair of tSNE dimensions. These are displayed together using <code><a href="patchwork.html#topic+plot_layout">patchwork::plot_layout</a></code>. When <code>tsne = FALSE</code>, the points will be arrange horizontally by cluster membership and randomly placed vertically.
</p>


<h3>Value</h3>

<p>A data frame, inheriting from class <code>"cluster_df"</code>, with a row for each character with its number (<code>character_number</code>) and cluster membership (<code>cluster</code>). When <code>tsne = TRUE</code>, additional columns  will be included, one for each requested tSNE dimension, labeled <code>tSNE_Dim1</code>, <code>tSNE_Dim2</code>, etc., containing the values on the dimensions computed using <code>Rtsne()</code>.
</p>
<p>The <code>pam</code> fit resulting from <code>cluster::pam</code> is returned in the <code>"pam.fit"</code> attribute of the outut object.
</p>


<h3>Note</h3>

<p>When using <code>plot()</code> on a <code>cluster_df</code> object, warnings may appear from <code>ggrepel</code> saying something along the lines of &quot;unlabeled data points (too many overlaps). Consider increasing max.overlaps&quot;. See <code><a href="ggrepel.html#topic+geom_label_repel">ggrepel::geom_text_repel</a></code> for details; the <code>max.overlaps</code> argument can be supplied to <code>plot()</code> to increase the maximum number of element overlap in the plot. Alternatively, users can increase the size of the plot when exporting it, as it will increase the plot area and reduce the number of elements overlap. This warning can generally be ignored, though.
</p>


<h3>See Also</h3>

<p><code>vignette("char-part")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code><a href="#topic+get_gower_dist">get_gower_dist</a></code>, <code><a href="#topic+get_sil_widths">get_sil_widths</a></code>, <code><a href="#topic+cluster_to_nexus">cluster_to_nexus</a></code>
</p>
<p><code><a href="cluster.html#topic+pam">cluster::pam</a></code>, <code><a href="Rtsne.html#topic+Rtsne">Rtsne::Rtsne</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("char-part") for how to use this
# function as part of an analysis pipeline

data("characters")

# Reading example file as categorical data
Dmatrix &lt;- get_gower_dist(characters)

sil_widths &lt;- get_sil_widths(Dmatrix, max.k = 7)

sil_widths
# 3 clusters yields the highest silhouette width

# Create clusters with PAM under k=3 partitions
cluster_df &lt;- make_clusters(Dmatrix, k = 3)

# Simple plot of clusters
plot(cluster_df, seed = 12345)

# Create clusters with PAM under k=3 partitions and perform
# tSNE (3 dimensions; default is 2)
cluster_df_tsne &lt;- make_clusters(Dmatrix, k = 3, tsne = TRUE,
                                 tsne_dim = 2)

# Plot clusters, plots divided into 2 rows, and increasing
# overlap of text labels (default = 10)
plot(cluster_df_tsne, nrow = 2, max.overlaps = 20)
</code></pre>

<hr>
<h2 id='offset.to.dummy'>Convert trees produced by a BEAST2 FBD analysis with offset to trees with correct ages.</h2><span id='topic+offset.to.dummy'></span>

<h3>Description</h3>

<p>This method adds a dummy tip at the present (t = 0) to fully extinct trees with offsets,
in order to have correct ages (otherwise the most recent tip is assumed to be at 0).
This is a workaround to get the proper ages of the trees into other tools such as TreeAnnotator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>offset.to.dummy(trees.file, log.file, output.file = NULL, dummy.name = "dummy")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="offset.to.dummy_+3A_trees.file">trees.file</code></td>
<td>
<p>path to BEAST2 output file containing posterior trees</p>
</td></tr>
<tr><td><code id="offset.to.dummy_+3A_log.file">log.file</code></td>
<td>
<p>path to BEAST2 trace log file containing offset values</p>
</td></tr>
<tr><td><code id="offset.to.dummy_+3A_output.file">output.file</code></td>
<td>
<p>path to file to write converted trees. If <code>NULL</code> (default), trees are simply returned.</p>
</td></tr>
<tr><td><code id="offset.to.dummy_+3A_dummy.name">dummy.name</code></td>
<td>
<p>name of the added dummy tip, default <code>dummy</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>NB:</strong> Any metadata present on the tips will be discarded. If you want to keep metadata (such as clock rate values),
use <code>offset.to.dummy.metadata</code> instead.
</p>


<h3>Value</h3>

<p>list of converted trees (as treedata)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+offset.to.dummy.metadata">offset.to.dummy.metadata()</a></code> (slower version, keeping metadata)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Convert trees with offset to trees with dummy tip
trees_file &lt;- system.file("extdata", "ex_offset.trees", package = "EvoPhylo")
log_file &lt;- system.file("extdata", "ex_offset.log", package = "EvoPhylo")
converted_trees &lt;- offset.to.dummy.metadata(trees_file, log_file)

# Do something with the converted trees - for instance, calculate the MCC summary tree
# Then remove the dummy tip from the MCC tree
final_tree &lt;- drop.dummy.beast(system.file("extdata", "ex_offset.MCC.tre", package = "EvoPhylo"))

</code></pre>

<hr>
<h2 id='offset.to.dummy.metadata'>Convert trees produced by a BEAST2 FBD analysis with offset to trees with correct ages,
accounting for possible metadata on the tips.</h2><span id='topic+offset.to.dummy.metadata'></span>

<h3>Description</h3>

<p>This method adds a dummy tip at the present (t = 0) to fully extinct trees with offsets,
in order to have correct ages (otherwise the most recent tip is assumed to be at 0).
This is a workaround to get the proper ages of the trees into other tools such as TreeAnnotator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>offset.to.dummy.metadata(
  trees.file,
  log.file,
  output.file = NULL,
  dummy.name = "dummy"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="offset.to.dummy.metadata_+3A_trees.file">trees.file</code></td>
<td>
<p>path to BEAST2 output file containing posterior trees</p>
</td></tr>
<tr><td><code id="offset.to.dummy.metadata_+3A_log.file">log.file</code></td>
<td>
<p>path to BEAST2 trace log file containing offset values</p>
</td></tr>
<tr><td><code id="offset.to.dummy.metadata_+3A_output.file">output.file</code></td>
<td>
<p>path to file to write converted trees. If <code>NULL</code> (default), trees are simply returned.</p>
</td></tr>
<tr><td><code id="offset.to.dummy.metadata_+3A_dummy.name">dummy.name</code></td>
<td>
<p>name of the added dummy tip, default <code>dummy</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of converted trees (as treedata)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+offset.to.dummy">offset.to.dummy()</a></code> (faster version discarding metadata)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Convert trees with offset to trees with dummy tip
trees_file &lt;- system.file("extdata", "ex_offset.trees", package = "EvoPhylo")
log_file &lt;- system.file("extdata", "ex_offset.log", package = "EvoPhylo")
converted_trees &lt;- offset.to.dummy.metadata(trees_file, log_file)

# Do something with the converted trees - for instance, calculate the MCC summary tree
# Then remove the dummy tip from the MCC tree
final_tree &lt;- drop.dummy.beast(system.file("extdata", "ex_offset.MCC.tre", package = "EvoPhylo"))

</code></pre>

<hr>
<h2 id='plot_back_rates'>
Plots distribution of background rates extracted from posterior log files.
</h2><span id='topic+plot_back_rates'></span>

<h3>Description</h3>

<p>Plots The distribution of background rates extracted from the posterior log files from Mr. Bayes or BEAST2, as well as the distribution of background rates if log transformed to test for normality of data distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_back_rates(type = c("MrBayes", "BEAST2"),
                           posterior,
                           clock = 1,
                           trans = c("none", "log", "log10"),
                           size = 12, quantile = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_back_rates_+3A_type">type</code></td>
<td>

<p>Whether to use data output from &quot;Mr.Bayes&quot; or &quot;BEAST2&quot;.
</p>
</td></tr>
<tr><td><code id="plot_back_rates_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates (log file). From Mr.Bayes, it includes a &quot;clockrate&quot; column indicating the mean (background) clock rate estimate for each generation that will be used for pairwise t-tests. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> (no need to reshape from wide to long). See the <code><a href="#topic+posterior1p">posterior1p</a></code> or <code><a href="#topic+posterior3p">posterior3p</a></code> datasets for an examples of how the input file should look.
From BEAST2, it will include at least one &quot;rate&lt;filename&gt;.mean&quot; column indicating the mean (background) clock rate estimate for each generation. If there are &quot;P&quot; unlinked clock partitions in BEAST2, there will be P x &quot;rate&lt;filename&gt;.mean&quot; columns (one for each partition) in the posterior log file.
</p>
</td></tr>
<tr><td><code id="plot_back_rates_+3A_clock">clock</code></td>
<td>

<p>The clock partition number to calculate selection mode. Ignored if only one clock is available.
</p>
</td></tr>
<tr><td><code id="plot_back_rates_+3A_trans">trans</code></td>
<td>

<p>Type of data transformation to perform on background rates extracted from the posterior log file from Mr. Bayes or BEAST2. Options include &quot;none&quot; (if rates are normally distributed), natural log transformation &quot;log&quot;, and log of base 10 transformation &quot;log10&quot;. The necessity of using data transformation can be tested using the function <code><a href="#topic+plot_back_rates">plot_back_rates</a></code>.
</p>
</td></tr>
<tr><td><code id="plot_back_rates_+3A_size">size</code></td>
<td>

<p>Font size for title of plot
</p>
</td></tr>
<tr><td><code id="plot_back_rates_+3A_quantile">quantile</code></td>
<td>

<p>Upper limit for X axis (passed on to 'xlim') to remove outliers from histogram. The quantile can be any value between &quot;0&quot; and &quot;1&quot;, but values equal or above &quot;0.95&quot; provide good results in most cases in which the data distribution is right skewed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots The distribution of background rates extracted from the posterior log files from Mr. Bayes or BEAST2, as well as the distribution of background rates if log transformed.  Background rates should be normally distributed for meeting the assumptions of t-tests and other tests passed on by downstream functions, including <code><a href="#topic+get_pwt_rates_MrBayes">get_pwt_rates_MrBayes</a></code>, <code><a href="#topic+get_pwt_rates_BEAST2">get_pwt_rates_BEAST2</a></code>, and <code><a href="#topic+plot_treerates_sgn">plot_treerates_sgn</a></code>.
</p>


<h3>Value</h3>

<p>It produces a <code>ggplot</code> object that can be manipulated using <span class="pkg">ggplot2</span> syntax (e.g., to change the <code>theme</code> or labels).
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

## MrBayes example
# Load example tree and posterior

data("posterior3p")

P &lt;- plot_back_rates (type = "MrBayes", posterior3p, clock = 1,
                      trans = "log10", size = 10, quantile = 0.95)
P
</code></pre>

<hr>
<h2 id='plot_treerates_sgn'>
Plot Bayesian evolutionary tree with rate thresholds for selection mode
</h2><span id='topic+plot_treerates_sgn'></span>

<h3>Description</h3>

<p>Plots the summary Bayesian evolutionary tree with branches, according to user-defined thresholds (in units of standard deviations) used to infer the strength and mode of selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_treerates_sgn(type = c("MrBayes", "BEAST2"),
                  tree, posterior,
                  trans = c("none", "log", "log10"),
                  summary = "mean", drop.dummyextant = TRUE,
                  clock = 1, threshold = c("1 SD", "2 SD"),
                  low = "blue", mid = "gray90", high = "red",
                  branch_size = 2, tip_size = 2,
                  xlim = NULL, nbreaks = 10, geo_size = list(2, 3),
                  geo_skip = c("Quaternary", "Holocene", "Late Pleistocene"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_treerates_sgn_+3A_type">type</code></td>
<td>

<p>Whether to use data output from &quot;Mr.Bayes&quot; or &quot;BEAST2&quot;.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_tree">tree</code></td>
<td>

<p>A <code>tidytree</code> object; the output of a call to <code><a href="treeio.html#topic+read.beast">treeio::read.beast</a></code>. Summary trees from Mr. Bayes will include branch specific rates for all clock partitions, and the partition to be plotted will be specified using the &quot;clock&quot; argument. On the other hand, BEAST2 will output one separate summary tree file for each clock partition. For the latter, the tree file for the partition of interest should be provided for plotting.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_posterior">posterior</code></td>
<td>

<p>A data frame of posterior parameter estimates (log file). From Mr.Bayes, it includes a &quot;clockrate&quot; column indicating the mean (background) clock rate estimate for each generation that will be used for pairwise t-tests. Such data frame can be imported using <code><a href="#topic+combine_log">combine_log</a></code> (no need to reshape from wide to long). See the <code><a href="#topic+posterior1p">posterior1p</a></code> or <code><a href="#topic+posterior3p">posterior3p</a></code> datasets for an examples of how the input file should look.
From BEAST2, it will include at least one &quot;rate&lt;filename&gt;.mean&quot; column indicating the mean (background) clock rate estimate for each generation. If there are &quot;P&quot; unlinked clock partitions in BEAST2, there will be P x &quot;rate&lt;filename&gt;.mean&quot; columns (one for each partition) in the posterior log file.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_trans">trans</code></td>
<td>

<p>Type of data transformation to perform on background rates extracted from the posterior log file from Mr. Bayes or BEAST2. Options include &quot;none&quot; (if rates are normally distributed), natural log transformation &quot;log&quot;, and log of base 10 transformation &quot;log10&quot;. The necessity of using data transformation can be tested using the function <code><a href="#topic+plot_back_rates">plot_back_rates</a></code>.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_summary">summary</code></td>
<td>

<p>Only when using Mr. Bayes trees. The rate summary stats chosen to calculate selection mode. Only rates &quot;mean&quot; and &quot;median&quot; are allowed. Default is &quot;mean&quot;.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_drop.dummyextant">drop.dummyextant</code></td>
<td>

<p><code>logical</code>; Only when using Mr. Bayes trees. Whether to drop the &quot;Dummyextant&quot; tip (if present) from the tree before plotting the tree. Default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_clock">clock</code></td>
<td>

<p>The clock partition number to calculate selection mode. Ignored if only one clock is available.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_threshold">threshold</code></td>
<td>

<p>A vector of threshold values. Default is to display thresholds of ±1 relative standard deviation (SD) of the relative posterior clock rates. Should be specified as a number of standard deviations (e.g., <code>"1 SD"</code>) or the confidence level for a confidence interal around the mean relative posterior clockrate (e.g., <code>"95%"</code>). Multiple values are allowed to produce a plot with multiple thresholds. Set to <code>NULL</code> to omit thresholds.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_low">low</code>, <code id="plot_treerates_sgn_+3A_mid">mid</code>, <code id="plot_treerates_sgn_+3A_high">high</code></td>
<td>

<p>Colors passed to <code><a href="ggplot2.html#topic+scale_color_steps2">scale_color_steps2</a></code> to control the colors of the branches based on which thresholds are exceeded. When no thresholds are supplied, use <code>mid</code> to control the color of the tree.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_branch_size">branch_size</code></td>
<td>

<p>The thickness of the lines that form the tree.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_tip_size">tip_size</code></td>
<td>

<p>The font size for the tips of the tree.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_xlim">xlim</code></td>
<td>

<p>The x-axis limits. Should be two negative numbers (though the axis labels will be in absolute value, i.e., Ma).
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_nbreaks">nbreaks</code></td>
<td>

<p>The number of interval breaks in the geological timescale.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_geo_size">geo_size</code></td>
<td>

<p>The font size for the labels in the geological scale. The first value in <code>list()</code> is the font size for geological epochs and the second value is for geological periods. Passed directly to the <code>size</code> argument of <code><a href="deeptime.html#topic+coord_geo">deeptime::coord_geo</a></code>.
</p>
</td></tr>
<tr><td><code id="plot_treerates_sgn_+3A_geo_skip">geo_skip</code></td>
<td>

<p>A vector of interval names indicating which intervals should not be labeled. Passed directly to the <code>skip</code> argument of <code><a href="deeptime.html#topic+coord_geo">deeptime::coord_geo</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots the phylogentic tree contained in <code>tree</code> using <code><a href="ggtree.html#topic+ggtree">ggtree::ggtree</a></code>. Branches undergoing accelerating evolutionary rates (e.g., &gt;<code>"1 SD"</code>, <code>"3 SD"</code>, or <code>"5 SD"</code> relative to the background rate) for each morphological clock partition suggest directional (or positive) selection for that morphological partition in that branch of the tree. Branches undergoing decelerating evolutionary rates (e.g., &lt;<code>"1 SD"</code>, <code>"3 SD"</code>, or <code>"5 SD"</code> relative to the background rate) for each morphological clock partition suggest stabilizing selection for that morphological partition in that branch of the tree. For details on rationale, see Simões &amp; Pierce (2021).
</p>
<p>Please double check that the distribution of background rates (mean rates for the tree) sampled from the posterior follow the assumptions of a normal distribution (e.g., check for normality of distribution in Tracer). Otherwise, displayed results may not have a valid interpretation.
</p>


<h3>Value</h3>

<p>A <code>ggtree</code> object, which inherits from <code>ggplot</code>.
</p>


<h3>References</h3>

<p>Simões, T. R. and S. E. Pierce (2021). Sustained High Rates of Morphological Evolution During the Rise of Tetrapods. <em>Nature Ecology &amp; Evolution</em> 5: 1403–1414.
</p>


<h3>See Also</h3>

<p><code>vignette("rates-selection")</code> for the use of this function as part of an analysis pipeline.
<code><a href="ggtree.html#topic+ggtree">ggtree::ggtree</a></code>, <code><a href="deeptime.html#topic+coord_geo">deeptime::coord_geo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See vignette("rates-selection") for how to use this
# function as part of an analysis pipeline

## MrBayes example
# Load example tree and posterior
data("tree3p")
data("posterior3p")

plot_treerates_sgn(
  type = "MrBayes",
  tree3p, posterior3p,          #MrBayes tree file with data for all partitions
  trans = "none",
  summary = "mean",             #MrBayes specific argument
  drop.dummyextant = TRUE,      #MrBayes specific argument
  clock = 1,                           #Show rates for clock partition 1
  threshold = c("1 SD", "3 SD"),       #sets background rate threshold for selection mode
  branch_size = 1.5, tip_size = 3,                          #sets size for tree elements
  xlim = c(-450, -260), nbreaks = 8, geo_size = list(3, 3)) #sets limits and breaks for geoscale

## Not run: 
## BEAST2 example
tree_clock1 &lt;- system.file("extdata", "Penguins_MCC_morpho_part1", package = "EvoPhylo")
tree_clock1 &lt;- treeio::read.beast(tree_clock1)
posterior &lt;- system.file("extdata", "Penguins_log.log", package = "EvoPhylo")
posterior &lt;- read.table(posterior, header = TRUE)

plot_treerates_sgn(
  type = "BEAST2",
  tree_clock1, posterior,                 #BEAST2 tree file with data for partition 1
  trans = "log10",
  clock = 1,                              #Show rates for clock partition 1
  threshold = c("1 SD", "3 SD"),          #sets background rate threshold for selection mode
  branch_size = 1.5, tip_size = 3,                        #sets size for tree elements
  xlim = c(-70, 30), nbreaks = 8, geo_size = list(3, 3))  #sets limits and breaks for geoscale

## End(Not run)</code></pre>

<hr>
<h2 id='post_trees'>
Multiple phylogenetic clock trees
</h2><span id='topic+post_trees'></span>

<h3>Description</h3>

<p>Multiple clock Bayesian phylogenetic tree, imported as an S4 class object using <code>treeio::read.beast()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("post_trees")</code></pre>


<h3>Format</h3>

<p>A <code>tidytree</code> object.
</p>


<h3>Details</h3>

<p>Example tree file for function <code><a href="#topic+write.beast.treedata">write.beast.treedata</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.beast.treedata">write.beast.treedata</a></code> for using this file in context.
</p>

<hr>
<h2 id='posterior1p'>
Posterior parameter samples (single clock)
</h2><span id='topic+posterior1p'></span>

<h3>Description</h3>

<p>An example dataset of posterior parameter samples resulting from a clock-based Bayesian inference analysis using the skyline fossilized birth–death process (FBD) tree model with Mr. Bayes after combining all parameter (.p) files into a single data frame with the <code><a href="#topic+combine_log">combine_log</a></code> function. This particular example was produced by analyzing the data set with a single morphological partition from Simões &amp; Pierce (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("posterior1p")</code></pre>


<h3>Format</h3>

<p>A data frame with 4000 observations on several variables estimated for each generation during analysis:
</p>

<dl>
<dt>Gen</dt><dd><p>A numeric vector for the generation number</p>
</dd>
<dt><code>LnL</code></dt><dd><p>A numeric vector for the natural log likelihood of the cold chain</p>
</dd>
<dt><code>LnPr</code></dt><dd><p>A numeric vector for the natural log likelihood of the priors</p>
</dd>
<dt><code>TH</code></dt><dd><p>A numeric vector for the total tree height (sum of all branch durations, as chronological units)</p>
</dd>
<dt><code>TL</code></dt><dd><p>A numeric vector for total tree length (sum of all branch lengths, as accumulated substitutions/changes)</p>
</dd>
<dt><code>prop_ancfossil</code></dt><dd><p>A numeric vector indicating the proportion of fossils recovered as ancestors</p>
</dd>
<dt><code>sigma</code></dt><dd><p>A numeric vector for the standard deviation of the lognormal distribution governing how much rates vary across characters.</p>
</dd>
<dt><code>net_speciation_1</code>, <code>net_speciation_2</code>, <code>net_speciation_3</code>, <code>net_speciation_4</code></dt><dd><p>A numeric vector for net speciation estimates for each time bin</p>
</dd>
<dt><code>relative_extinction_1</code>, <code>relative_extinction_2</code>, <code>relative_extinction_3</code>, <code>relative_extinction_4</code></dt><dd><p>A numeric vector for relative extinction estimates for each time bin</p>
</dd>
<dt><code>relative_fossilization_1</code>, <code>relative_fossilization_2</code>, <code>relative_fossilization_3</code>, <code>relative_fossilization_4</code></dt><dd><p>A numeric vector for relative fossilization estimates for each time bin</p>
</dd>
<dt><code>tk02var</code></dt><dd><p>A numeric vector for the variance on the base of the clock rate</p>
</dd>
<dt><code>clockrate</code></dt><dd><p>A numeric vector for the base of the clock rate</p>
</dd>
</dl>



<h3>Details</h3>

<p>Datasets like this one can be produced from parameter log (.p) files using <code><a href="#topic+combine_log">combine_log</a></code>. The number of variables depends on parameter set up, but for clock analyses with Mr. Bayes, will typically include the ones above, possibly also including <code>alpha</code>, which contains the shape of the gamma distribution governing how much rates vary across characters. When using the traditional FBD model rather than the skyline FBD model used to produce this dataset, there will be only one column for each of <code>net_speciation</code>, <code>relative_extinction</code> and <code>relative_fossilization</code>. When using more than one morphological partition, different columns may be present; see <code><a href="#topic+posterior3p">posterior3p</a></code> for an example with 3 partitions.
</p>


<h3>References</h3>

<p>Simões, T. R. and S. E. Pierce (2021). Sustained High Rates of Morphological Evolution During the Rise of Tetrapods. <em>Nature Ecology &amp; Evolution</em> 5: 1403–1414.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posterior3p">posterior3p</a></code> for an example dataset of posterior parameter samples resulting from an analysis with 3 partitions rather than 1.
</p>

<hr>
<h2 id='posterior3p'>
Posterior parameter samples (3 clock partions)
</h2><span id='topic+posterior3p'></span>

<h3>Description</h3>

<p>An example dataset of posterior parameter samples resulting from a clock-based Bayesian inference analysis using the skyline fossilized birth–death process (FBD) tree model with Mr. Bayes after combining all parameter (.p) files into a single data frame with the <code><a href="#topic+combine_log">combine_log</a></code> function. This particular example was produced by analyzing the data set with three morphological partitions from Simões &amp; Pierce (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("posterior3p")</code></pre>


<h3>Format</h3>

<p>A data frame with 4000 observations on several variables estimated for each generation during analysis. The number of variables depends on parameter set up, but for clock analyses with Mr. Bayes, will typically include the following:
</p>

<dl>
<dt><code>Gen</code></dt><dd><p>A numeric vector for the generation number</p>
</dd>
<dt><code>LnL</code></dt><dd><p>A numeric vector for the natural log likelihood of the cold chain</p>
</dd>
<dt><code>LnPr</code></dt><dd><p>A numeric vector for the natural log likelihood of the priors</p>
</dd>
<dt><code>TH.all.</code></dt><dd><p>A numeric vector for the total tree height (sum of all branch durations, as chronological units)</p>
</dd>
<dt><code>TL.all.</code></dt><dd><p>A numeric vector for total tree length (sum of all branch lengths, as accumulated substitutions/changes)</p>
</dd>
<dt><code>prop_ancfossil.all.</code></dt><dd><p>A numeric vector indicating the proportion of fossils recovered as ancestors</p>
</dd>
<dt><code>sigma.1.</code>, <code>sigma.2.</code>, <code>sigma.3.</code></dt><dd><p>A numeric vector for the standard deviation of the lognormal distribution governing how much rates vary across characters for each data partition</p>
</dd>
<dt><code>m.1.</code>, <code>m.2.</code>, <code>m.3.</code></dt><dd><p>A numeric vector for the rate multiplier parameter for each data partition</p>
</dd>
<dt><code>net_speciation_1.all.</code>, <code>net_speciation_2.all.</code>, <code>net_speciation_3.all.</code>, <code>net_speciation_4.all.</code></dt><dd><p>A numeric vector for net speciation estimates for each time bin</p>
</dd>
<dt><code>relative_extinction_1.all.</code>, <code>relative_extinction_2.all.</code>, <code>relative_extinction_3.all.</code>, <code>relative_extinction_4.all.</code></dt><dd><p>A numeric vector for relative extinction estimates for each time bin</p>
</dd>
<dt><code>relative_fossilization_1.all.</code>, <code>relative_fossilization_2.all.</code>, <code>relative_fossilization_3.all.</code>, <code>relative_fossilization_4.all.</code></dt><dd><p>A numeric vector for relative fossilization estimates for each time bin</p>
</dd>
<dt><code>tk02var.1.</code>, <code>tk02var.2.</code>, <code>tk02var.3.</code></dt><dd><p>A numeric vector for the variance on the base of the clock rate for each clock partition</p>
</dd>
<dt><code>clockrate.all.</code></dt><dd><p>A numeric vector for the base of the clock rate</p>
</dd>
</dl>



<h3>Details</h3>

<p>Datasets like this one can be produced from parameter log (.p) files using <code><a href="#topic+combine_log">combine_log</a></code>. The number of variables depends on parameter set up, but for clock analyses with Mr. Bayes, will typically include the ones above, possibly also including an <code>alpha</code> for each partition, which contains the shape of the gamma distribution governing how much rates vary across characters (when shape of the distribution is unlinked across partitions). When using the traditional FBD model rather than the skyline FBD model used to produce this dataset, there will be only one column for each of <code>net_speciation</code>, <code>relative_extinction</code> and <code>relative_fossilization</code>. When using a single morphological partition, different columns may be present; see <code><a href="#topic+posterior1p">posterior1p</a></code> for an example with just one partition.
</p>


<h3>References</h3>

<p>Simões, T. R. and S. E. Pierce (2021). Sustained High Rates of Morphological Evolution During the Rise of Tetrapods. <em>Nature Ecology &amp; Evolution</em> 5: 1403–1414.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posterior1p">posterior1p</a></code> for an example dataset of posterior parameter samples resulting from an analysis with 1 partition rather than 3.
</p>

<hr>
<h2 id='RateTable_Means_1p_Clades'>
Mean clock rates by node and clade (single clock)
</h2><span id='topic+RateTable_Means_1p_Clades'></span>

<h3>Description</h3>

<p>A data set containing the mean clock rates for a tree with 1 clock partition, such as the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> but with an additional &quot;clade&quot; column added, which is required for use in <code><a href="#topic+clockrate_summary">clockrate_summary</a></code> and <code><a href="#topic+clockrate_dens_plot">clockrate_dens_plot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("RateTable_Means_1p_Clades")</code></pre>


<h3>Format</h3>

<p>A data frame with 79 observations on the following 3 variables.
</p>

<dl>
<dt><code>clade</code></dt><dd><p>A character vector containing the clade names for each corresponding node</p>
</dd>
<dt><code>nodes</code></dt><dd><p>A numeric vector for the node numbers in the summary tree</p>
</dd>
<dt><code>rates</code></dt><dd><p>A numeric vector containing the mean posterior clock rate for each node</p>
</dd>
</dl>



<h3>Details</h3>

<p><code>RateTable_Means_1p_Clades</code> was created by running <code>get_clockrate_table_MrBayes(tree1p)</code> and then adding a &quot;clade&quot; column. It can be produced by using the following procedure:
</p>
<p>1) Import tree file:
</p>
<pre>data("tree1p")</pre>
<p>2) Produce clock rate table with, for instance, mean rate values from each branch in the tree:
</p>
<pre>rate_table &lt;- get_clockrate_table_MrBayes(tree1p, summary = "mean")</pre>
<pre>write.csv(rate_table, file = "rate_table.csv", row.names = FALSE)</pre>
<p>3) Now, manually add clades using, e.g., Excel:
</p>
<p>3.1) Manually edit rate_table.csv, adding a &quot;clade&quot; column. This introduces customized clade names to individual nodes in the tree.
</p>
<p>3.2) Save the edited rate table with a different name to differentiate from the original output (e.g., rate_table_clades_means.csv).
</p>
<p>4) Read the file back in:
</p>
<pre>RateTable_Means_1p_Clades &lt;- read.csv("rate_table_clades_means.csv")</pre>
<pre>head(RateTable_Means_1p_Clades)</pre>


<h3>See Also</h3>

<p><code><a href="#topic+tree1p">tree1p</a></code> for the tree from which the clock rates were extracted.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> for extracting a clock rate table from a tree.
</p>
<p><code><a href="#topic+clockrate_summary">clockrate_summary</a></code>, <code><a href="#topic+clockrate_dens_plot">clockrate_dens_plot</a></code>, and <code><a href="#topic+clockrate_reg_plot">clockrate_reg_plot</a></code> for examples of using a clockrate table.
</p>

<hr>
<h2 id='RateTable_Means_3p_Clades'>
Mean clock rates by node and clade (3 clock partitions)
</h2><span id='topic+RateTable_Means_3p_Clades'></span>

<h3>Description</h3>

<p>A data set containing the mean clock rates for a tree with 3 clock partitions, such as the output of <code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> but with an additional &quot;clade&quot; column added, which is required for use in <code><a href="#topic+clockrate_summary">clockrate_summary</a></code> and <code><a href="#topic+clockrate_dens_plot">clockrate_dens_plot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("RateTable_Means_3p_Clades")</code></pre>


<h3>Format</h3>

<p>A data frame with 79 observations on the following 5 variables.
</p>

<dl>
<dt><code>clade</code></dt><dd><p>A character vector containing the clade names for each corresponding node</p>
</dd>
<dt><code>nodes</code></dt><dd><p>A numeric vector for the node numbers in the summary tree</p>
</dd>
<dt><code>rates1</code></dt><dd><p>A numeric vector containing the mean posterior clock rate for each node for the first partition</p>
</dd>
<dt><code>rates2</code></dt><dd><p>A numeric vector containing the mean posterior clock rate for each node for the second partition</p>
</dd>
<dt><code>rates3</code></dt><dd><p>A numeric vector containing the mean posterior clock rate for each node for the third partition</p>
</dd>
</dl>



<h3>Details</h3>

<p><code>RateTable_Means_3p_Clades</code> was created by running <code>get_clockrate_table_MrBayes(tree3p)</code> and then adding a &quot;clade&quot; column. It can be produced by using the following procedure:
</p>
<p>1) Import tree file:
</p>
<pre>data("tree3p")</pre>
<p>2) Produce clock rate table with, for instance, mean rate values from each branch in the tree:
</p>
<pre>rate_table &lt;- get_clockrate_table_MrBayes(tree3p, summary = "mean")</pre>
<pre>write.csv(rate_table, file = "rate_table.csv", row.names = FALSE)</pre>
<p>3) Now, manually add clades using, e.g., Excel:
</p>
<p>3.1) Manually edit rate_table.csv, adding a &quot;clade&quot; column. This introduces customized clade names to individual nodes in the tree.
</p>
<p>3.2) Save the edited rate table with a different name to differentiate from the original output (e.g., rate_table_clades_means.csv).
</p>
<p>4) Read the file back in:
</p>
<pre>RateTable_Means_3p_Clades &lt;- read.csv("rate_table_clades_means.csv")</pre>
<pre>head(RateTable_Means_3p_Clades)</pre>


<h3>See Also</h3>

<p><code><a href="#topic+tree3p">tree3p</a></code> for the tree from which the clock rates were extracted.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> for extracting a clock rate table from a tree.
</p>
<p><code><a href="#topic+clockrate_summary">clockrate_summary</a></code>, <code><a href="#topic+clockrate_dens_plot">clockrate_dens_plot</a></code>, and <code><a href="#topic+clockrate_reg_plot">clockrate_reg_plot</a></code> for examples of using a clockrate table.
</p>

<hr>
<h2 id='tree_clock1'>
BEAST2 phylogenetic tree with clock rates from partition 1
</h2><span id='topic+tree_clock1'></span>

<h3>Description</h3>

<p>A clock Bayesian phylogenetic tree with clock rates from a single clock partition (partition 1 here), imported as an S4 class object using <code>treeio::read.beast()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tree_clock1")</code></pre>


<h3>Format</h3>

<p>A <code>tidytree</code> object.
</p>


<h3>Details</h3>

<p>This example tree file was produced by analyzing the data set with a single morphological partition from
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tree_clock2">tree_clock2</a></code> for another BEAST2 tree object with  clock rates from partition 2 for this same dataset.
</p>
<p><code><a href="#topic+tree3p">tree3p</a></code> for another tree object with 3 clock partitions from Mr.Bayes.
</p>
<p><code><a href="#topic+tree1p">tree1p</a></code> for another tree object with a single clock from Mr.Bayes.
</p>
<p><code><a href="#topic+get_clockrate_table_BEAST2">get_clockrate_table_BEAST2</a></code> for extratcing the poserior clock rates from BEAST2 tree objects.
</p>

<hr>
<h2 id='tree_clock2'>
BEAST2 phylogenetic tree with clock rates from partition 2
</h2><span id='topic+tree_clock2'></span>

<h3>Description</h3>

<p>A clock Bayesian phylogenetic tree with clock rates from a single clock partition (partition 2 here), imported as an S4 class object using <code>treeio::read.beast()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tree_clock2")</code></pre>


<h3>Format</h3>

<p>A <code>tidytree</code> object.
</p>


<h3>Details</h3>

<p>This example tree file was produced by analyzing the data set with a single morphological partition from
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tree_clock1">tree_clock1</a></code> for another BEAST2 tree object with  clock rates from partition 1 for this same dataset.
</p>
<p><code><a href="#topic+tree3p">tree3p</a></code> for another tree object with 3 clock partitions from Mr.Bayes.
</p>
<p><code><a href="#topic+tree1p">tree1p</a></code> for another tree object with a single clock from Mr.Bayes.
</p>
<p><code><a href="#topic+get_clockrate_table_BEAST2">get_clockrate_table_BEAST2</a></code> for extratcing the poserior clock rates from BEAST2 tree objects.
</p>

<hr>
<h2 id='tree1p'>
Phylogenetic tree with a single clock partition
</h2><span id='topic+tree1p'></span>

<h3>Description</h3>

<p>A clock Bayesian phylogenetic tree, imported as an S4 class object using <code>treeio::read.mrbayes()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tree1p")</code></pre>


<h3>Format</h3>

<p>A <code>tidytree</code> object.
</p>


<h3>Details</h3>

<p>This example tree file was produced by analyzing the data set with a single morphological partition from Simões &amp; Pierce (2021).
</p>


<h3>References</h3>

<p>Simões, T. R. and S. E. Pierce (2021). Sustained High Rates of Morphological Evolution During the Rise of Tetrapods. <em>Nature Ecology &amp; Evolution</em> 5: 1403–1414.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tree3p">tree3p</a></code> for another tree object with 3 clock partitions.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> for extratcing the poserior clockrates from a tree object.
</p>

<hr>
<h2 id='tree3p'>
Phylogenetic tree with 3 clock partitions
</h2><span id='topic+tree3p'></span>

<h3>Description</h3>

<p>A clock Bayesian phylogenetic tree, imported as an S4 class object using <code>treeio::read.mrbayes()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tree3p")</code></pre>


<h3>Format</h3>

<p>A <code>tidytree</code> object.
</p>


<h3>Details</h3>

<p>This example tree file was produced by analyzing the data set with 3 morphological clock partitions from Simões &amp; Pierce (2021).
</p>


<h3>References</h3>

<p>Simões, T. R. and S. E. Pierce (2021). Sustained High Rates of Morphological Evolution During the Rise of Tetrapods. <em>Nature Ecology &amp; Evolution</em> 5: 1403–1414.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tree1p">tree1p</a></code> for another tree object with a single clock partition.
</p>
<p><code><a href="#topic+get_clockrate_table_MrBayes">get_clockrate_table_MrBayes</a></code> for extratcing the poserior clockrates from a tree object.
</p>

<hr>
<h2 id='write_partitioned_alignments'>Write character partitions as separate Nexus files (for use in BEAUti)</h2><span id='topic+write_partitioned_alignments'></span>

<h3>Description</h3>

<p>Write character partitions as separate Nexus files (for use in BEAUti)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_partitioned_alignments(x, cluster_df, file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_partitioned_alignments_+3A_x">x</code></td>
<td>
<p>character data matrix as Nexus file (.nex) or data frame (with taxa as rows and characters as columns) read directly from local directory</p>
</td></tr>
<tr><td><code id="write_partitioned_alignments_+3A_cluster_df">cluster_df</code></td>
<td>
<p>cluster partitions as outputted by <code>make.clusters</code></p>
</td></tr>
<tr><td><code id="write_partitioned_alignments_+3A_file">file</code></td>
<td>
<p>path to save the alignments. If <code>file = "example.nex"</code>, alignments will be saved to files <code>"example_part1.nex"</code>, <code>"example_part2.nex"</code>, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no return value
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example phylogenetic data matrix
data("characters")

# Create distance matrix
Dmatrix &lt;- get_gower_dist(characters)

# Find optimal partitioning scheme using PAM under k=3 partitions
cluster_df &lt;- make_clusters(Dmatrix, k = 3)

# Write to Nexus files
## Not run: write_partitioned_alignments(characters, cluster_df, "example.nex")
</code></pre>

<hr>
<h2 id='write.beast.treedata'>
Export multiple treedata objects (S4 class tree files) to BEAST NEXUS file
</h2><span id='topic+write.beast.treedata'></span>

<h3>Description</h3>

<p>This function was adopted and modified from treeio::write.beast to export a list of trees instead of a single tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.beast.treedata(treedata, file = "",
                    translate = TRUE, tree.name = "STATE")

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.beast.treedata_+3A_treedata">treedata</code></td>
<td>

<p>An S4 class object of type <code>treedata</code> containing multiple trees; e.g. a Bayesian clock tree distribution imported using <code><a href="treeio.html#topic+read.beast">treeio::read.beast</a></code> or <code><a href="treeio.html#topic+read.mrbayes">treeio::read.mrbayes</a></code>.
</p>
</td></tr>
<tr><td><code id="write.beast.treedata_+3A_file">file</code></td>
<td>

<p>Output file. If <code>file = ""</code>, prints the output content on screen.
</p>
</td></tr>
<tr><td><code id="write.beast.treedata_+3A_translate">translate</code></td>
<td>

<p>Whether to translate taxa labels.
</p>
</td></tr>
<tr><td><code id="write.beast.treedata_+3A_tree.name">tree.name</code></td>
<td>

<p>Name of the trees, default <code>"STATE"</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Writes object type <code>treedata</code> containing multiple trees to a file or file content on screen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Load file with multiple trees
## Not run: 
trees_file = system.file("extdata", "ex_offset.trees", package = "EvoPhylo")
posterior_trees_offset = treeio::read.beast(trees_file)

#Write multiple trees to screen
write.beast.treedata(posterior_trees_offset)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
