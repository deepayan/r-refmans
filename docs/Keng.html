<!DOCTYPE html><html lang="en-US"><head><title>Help for package Keng</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Keng}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calc_PRE'><p>Calculate PRE from Cohen's f, f_squared, or partial correlation</p></a></li>
<li><a href='#compare_lm'><p>Compare lm()'s fitted outputs using PRE and R-squared.</p></a></li>
<li><a href='#cut_r'><p>Cut-off values of Pearson's correlation r with known sample size n.</p></a></li>
<li><a href='#depress'><p>Depression and Coping</p></a></li>
<li><a href='#plot.Keng_power'><p>Plot the power against the sample size for the Keng_power class</p></a></li>
<li><a href='#power_lm'><p>Conduct post-hoc and prior power analysis, and plan the sample size for regression analysis</p></a></li>
<li><a href='#power_r'><p>Conduct post-hoc and prior power analysis, and plan the sample size for r.</p></a></li>
<li><a href='#print.Keng_power'><p>Print primary but not all contents of the Keng_power class</p></a></li>
<li><a href='#Scale'><p>Scale a vector</p></a></li>
<li><a href='#test_r'><p>Test the significance, analyze the power, and plan the sample size for r.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Knock Errors Off Nice Guesses</td>
</tr>
<tr>
<td>Version:</td>
<td>2024.12.15</td>
</tr>
<tr>
<td>Description:</td>
<td>Miscellaneous functions and data used in psychological research and teaching. Keng 
    currently has a built-in dataset depress, and could (1) scale a vector; (2) compute the cut-off 
    values of Pearson's r with known sample size; (3) test the significance and compute the post-hoc
    power for Pearson's r with known sample size; (4) conduct prior power analysis and plan the 
    sample size for Pearson's r; (5) compare lm()'s fitted outputs using R-squared, f_squared, 
    post-hoc power, and PRE (Proportional Reduction in Error, also called partial R-squared or 
    partial Eta-squared); (6) calculate PRE from partial correlation, Cohen's f, or f_squared; 
    (7) conduct prior power analysis and plan the sample size for one or a set of predictors in 
    regression analysis; (8) conduct post-hoc power analysis for one or a set of predictors in 
    regression analysis with known sample size.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, car, effectsize, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/qyaozh/Keng">https://github.com/qyaozh/Keng</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/qyaozh/Keng/issues">https://github.com/qyaozh/Keng/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-12-15 14:32:23 UTC; Yao</td>
</tr>
<tr>
<td>Author:</td>
<td>Qingyao Zhang <a href="https://orcid.org/0000-0002-6891-5982"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Qingyao Zhang &lt;qingyaozhang@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-15 14:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calc_PRE'>Calculate PRE from Cohen's f, f_squared, or partial correlation</h2><span id='topic+calc_PRE'></span>

<h3>Description</h3>

<p>Calculate PRE from Cohen's f, f_squared, or partial correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_PRE(f = NULL, f_squared = NULL, r_p = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_PRE_+3A_f">f</code></td>
<td>
<p>Cohen's f. Cohen (1988) suggested &gt;=0.1, &gt;=0.25, and &gt;=0.40 as cut-off values of f for small,
medium, and large effect sizes, respectively.</p>
</td></tr>
<tr><td><code id="calc_PRE_+3A_f_squared">f_squared</code></td>
<td>
<p>Cohen's f_squared. Cohen (1988) suggested &gt;=0.02, &gt;=0.15, and &gt;=0.35 as cut-off values of f for small,
medium, and large effect sizes, respectively.</p>
</td></tr>
<tr><td><code id="calc_PRE_+3A_r_p">r_p</code></td>
<td>
<p>Partial correlation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including PRE, the absolute value of r_p (partial correlation), Cohen's f_squared, and f.
</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>calc_PRE(f = 0.1)
calc_PRE(f_squared = 0.02)
calc_PRE(r_p = 0.2)
</code></pre>

<hr>
<h2 id='compare_lm'>Compare lm()'s fitted outputs using PRE and R-squared.</h2><span id='topic+compare_lm'></span>

<h3>Description</h3>

<p>Compare lm()'s fitted outputs using PRE and R-squared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_lm(
  fitC = NULL,
  fitA = NULL,
  n = NULL,
  PC = NULL,
  PA = NULL,
  SSEC = NULL,
  SSEA = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_lm_+3A_fitc">fitC</code></td>
<td>
<p>The result of <code>lm()</code> of the Compact model (model C).</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_fita">fitA</code></td>
<td>
<p>The result of <code>lm()</code> of the Augmented model (model A).</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_n">n</code></td>
<td>
<p>Sample size of the model C or model A.
Model C and model A must use the same sample, and hence have the same sample size.
Non-integer <code>n</code> would be converted to be an integer using <code>as.integer()</code>.</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_pc">PC</code></td>
<td>
<p>The number of parameters in model C.
Non-integer <code>PC</code> would be converted to be an integer using <code>as.integer()</code>.</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_pa">PA</code></td>
<td>
<p>The number of parameters in model A.
Non-integer <code>PA</code> would be converted to be an integer using <code>as.integer()</code>.
<code>as.integer(PA)</code> should be larger than <code>as.integer(PC)</code>.</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_ssec">SSEC</code></td>
<td>
<p>The Sum of Squared Errors (SSE) of model C.</p>
</td></tr>
<tr><td><code id="compare_lm_+3A_ssea">SSEA</code></td>
<td>
<p>The Sum of Squared Errors of model A.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>compare_lm()</code> compares model A with model C using PRE (Proportional Reduction in Error) , R-squared, f_squared, and post-hoc power.
PRE is partial R-squared (called partial Eta-squared in Anova).
There are two ways of using <code>compare_lm()</code>.
The 1st is giving <code>compare_lm()</code> <code>fitC</code> and <code>fitA</code>.
The 2nd is giving <code>n</code>, <code>PC</code>, <code>PA</code>, <code>SSEC</code>, and <code>SSEA</code>.
The 1st way is more convenient, and it minimizes precision loss by omitting copying-and-pasting.
Note that the F-tests for PRE and that for R-squared change are equivalent.
Please refer to Judd et al. (2017) for more details about PRE, and refer to Aberson (2019) for more details about f_squared and post-hoc power.
</p>


<h3>Value</h3>

<p>A matrix with 12 rows and 4 columns.
The 1st column reports information for the baseline model (intercept-only model).
the 2nd for model C, the third for model A, and the fourth for the change (model A vs. model C).
SSE (Sum of Squared Errors), sample size n, df of SSE, and the number of parameters for baseline model, model C,
model A, and change (model A vs. model C) are reported in rows 1-3.
The information in the 4th column are all for the change; put differently,
these results could quantify the effect of one or a set of new parameters model A has but model C doesn't.
If fitC and fitA are not inferior to the intercept-only model,
R-squared, Adjusted R-squared, PRE, PRE_adjusted, and f_squared for the full model
(compared with the baseline model) are reported for model C and model A.
If model C or model A has at least one predictor, F-test with p,
and post-hoc power would be computed for the corresponding full model.
</p>


<h3>References</h3>

<p>Aberson, C. L. (2019). <em>Applied power analysis for the behavioral sciences</em>. Routledge.
</p>
<p>Judd, C. M., McClelland, G. H., &amp; Ryan, C. S. (2017). <em>Data analysis: A model Comparison approach to regression, ANOVA, and beyond</em>. Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(193)
x2 &lt;- rnorm(193)
y &lt;- 0.3 + 0.2*x1 + 0.1*x2 + rnorm(193)
dat &lt;- data.frame(y, x1, x2)
# Fix the intercept to constant 1 using I().
fit1 &lt;- lm(I(y - 1) ~ 0, dat)
# Free the intercept.
fit2 &lt;- lm(y ~ 1, dat)
compare_lm(fit1, fit2)
# One predictor.
fit3 &lt;- lm(y ~ x1, dat)
compare_lm(fit2, fit3)
# Fix the intercept to 0.3 using offset().
intercept &lt;- rep(0.3, 193)
fit4 &lt;- lm(y ~ 0 + x1 + offset(intercept), dat)
compare_lm(fit4, fit3)
# Two predictors.
fit5 &lt;- lm(y ~ x1 + x2, dat)
compare_lm(fit2, fit5)
compare_lm(fit3, fit5)
# Fix the slope of x2 to 0.05 using offset().
fit6 &lt;- lm(y ~ x1 + offset(0.05*x2), dat)
compare_lm(fit6, fit5)
</code></pre>

<hr>
<h2 id='cut_r'>Cut-off values of Pearson's correlation r with known sample size n.</h2><span id='topic+cut_r'></span>

<h3>Description</h3>

<p>Cut-off values of Pearson's correlation r with known sample size n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cut_r(n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cut_r_+3A_n">n</code></td>
<td>
<p>Sample size of Pearson's correlation r. <code>n</code> should be larger than</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given n and p, t and then r could be determined. The formula used could be found in <code>test_r()</code>'s documentation.
</p>


<h3>Value</h3>

<p>A data.frame including the cut-off values of r at the significance levels of p = 0.1, 0.05, 0.01, 0.001.  r with the absolute value larger than the cut-off value is significant at the corresponding significance level.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cut_r(193)
</code></pre>

<hr>
<h2 id='depress'>Depression and Coping</h2><span id='topic+depress'></span>

<h3>Description</h3>

<p>A subset of data from research about depression and coping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>depress
</code></pre>


<h3>Format</h3>



<h4><code>depress</code></h4>

<p>A data frame with 94 rows and 237 columns:
</p>

<dl>
<dt>id</dt><dd><p>Participant id</p>
</dd>
<dt>class</dt><dd><p>Class</p>
</dd>
<dt>grade</dt><dd><p>Grade</p>
</dd>
<dt>elite</dt><dd><p>Elite classes</p>
</dd>
<dt>intervene</dt><dd><p>0 = Control group, 1 = Intervention group</p>
</dd>
<dt>gender</dt><dd><p>0 = girl, 1 = boy</p>
</dd>
<dt>age</dt><dd><p>Age in year</p>
</dd>
<dt>cope1i1p</dt><dd><p>Cope scale, Time1, Item1, Problem-focused coping, 1 = very seldom, 5 = very often</p>
</dd>
<dt>cope1i3a</dt><dd><p>Cope scale, Time1, Item3, Avoidance coping</p>
</dd>
<dt>cope1i5e</dt><dd><p>cope scale, Time1, Item5, Emotion-focused coping</p>
</dd>
<dt>cope2i1p</dt><dd><p>Cope scale, Time2, Item1, Problem-focused coping</p>
</dd>
<dt>depr1i1</dt><dd><p>Depression scale, Time1, Item1, 1 = very seldom, 5 = always</p>
</dd>
<dt>ecr1avo</dt><dd><p>ECR-RS scale, Item1, attachment avoidance, 1 = very disagree, 7 = very agree</p>
</dd>
<dt>ecr2anx</dt><dd><p>ECR-RS scale, Item2, attachment anxiety</p>
</dd>
<dt>dm1</dt><dd><p>Depression, Mean, Time1</p>
</dd>
<dt>pm1</dt><dd><p>Problem-focused coping, Mean, Time1</p>
</dd>
<dt>em1</dt><dd><p>Emotion-focused coping, Mean, Time1</p>
</dd>
<dt>am1</dt><dd><p>Avoidance coping, Mean, Time1</p>
</dd>
<dt>avo</dt><dd><p>Attachment avoidance, Mean</p>
</dd>
<dt>anx</dt><dd><p>Attachment anxiety, Mean</p>
</dd>
</dl>




<h3>Source</h3>

<p>Keng package.
</p>

<hr>
<h2 id='plot.Keng_power'>Plot the power against the sample size for the Keng_power class</h2><span id='topic+plot.Keng_power'></span>

<h3>Description</h3>

<p>Plot the power against the sample size for the Keng_power class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Keng_power'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.Keng_power_+3A_x">x</code></td>
<td>
<p>The output object of <code>power_r()</code> or <code>power_lm()</code>.</p>
</td></tr>
<tr><td><code id="plot.Keng_power_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of power against sample size.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(power_lm())
out &lt;- power_r(0.2, n = 193)
plot(out)
</code></pre>

<hr>
<h2 id='power_lm'>Conduct post-hoc and prior power analysis, and plan the sample size for regression analysis</h2><span id='topic+power_lm'></span>

<h3>Description</h3>

<p>Conduct post-hoc and prior power analysis, and plan the sample size for regression analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_lm(
  PRE = 0.02,
  PC = 1,
  PA = 2,
  sig_level = 0.05,
  power = 0.8,
  power_ul = 1,
  n_ul = 1.45e+09,
  n = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power_lm_+3A_pre">PRE</code></td>
<td>
<p>Proportional Reduction in Error.
PRE = The square of partial correlation.
Cohen (1988) suggested &gt;=0.02, &gt;=0.13, and &gt;=0.26 as cut-off values of PRE for small,
medium, and large effect sizes, respectively.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_pc">PC</code></td>
<td>
<p>Number of parameters of model C (compact model) without focal predictors of interest.
Non-integer <code>PC</code> would be converted to be an integer using <code>as.integer()</code>.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_pa">PA</code></td>
<td>
<p>Number of parameters of model A (augmented model) with focal predictors of interest.
Non-integer <code>PA</code> would be converted to be an integer using <code>as.integer()</code>.
<code>as.integer(PA)</code> should be larger than <code>as.integer(PC)</code>.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_sig_level">sig_level</code></td>
<td>
<p>Expected significance level for effects of focal predictors.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_power">power</code></td>
<td>
<p>Expected statistical power for effects of focal predictors.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_power_ul">power_ul</code></td>
<td>
<p>The upper limit of power below which the minimum sample size is searched.
<code>power_ul</code> should be larger than <code>power</code>, and the maximum <code>power_ul</code> is 1.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_n_ul">n_ul</code></td>
<td>
<p>The upper limit of sample size below which the minimum required sample size is searched.
Non-integer <code>n_ul</code> would be converted to be an integer using <code>as.integer()</code>.
<code>as.integer(n_ul)</code> should be at least <code>as.integer(PA) + 1</code>.</p>
</td></tr>
<tr><td><code id="power_lm_+3A_n">n</code></td>
<td>
<p>The current sample size. Non-integer <code>n</code> would be converted to be an integer using <code>as.integer()</code>.
Non-NULL <code>as.integer(n)</code> should be at least <code>as.integer(PA) + 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>power_ul</code> and <code>n_ul</code> determine the total times of power_lm()'s attempts searching for the minimum required sample size,
hence the number of rows of the returned power table <code>prior</code> and the right limit of the horizontal axis of the returned power plot.
<code>power_lm()</code> will keep running and gradually raise the sample size to <code>n_ul</code> until the sample size pushes the power level to <code>power_ul</code>.
When PRE is very small (e.g., less than 0.001) and power is larger than 0.8,
a huge increase in sample size only brings about a trivial increase in power, which is cost-ineffective.
To make <code>power_lm()</code> omit unnecessary attempts, you could set <code>power_ul</code> to be a value less than 1 (e.g., 0.90),
and/or set <code>n_ul</code> to be a value less than 1.45e+09 (e.g., 10000).
</p>


<h3>Value</h3>

<p>A Keng_power class, also a list. If sample size <code>n</code> is not given, the following results would be returned:
<code style="white-space: pre;">&#8288;[[1]]&#8288;</code> <code>PRE</code>;
<code style="white-space: pre;">&#8288;[[2]]&#8288;</code> <code>f_squared</code>, Cohen's f_squared derived from PRE;
<code style="white-space: pre;">&#8288;[[3]]&#8288;</code> <code>PC</code>;
<code style="white-space: pre;">&#8288;[[4]]&#8288;</code> <code>PA</code>;
<code style="white-space: pre;">&#8288;[[5]]&#8288;</code> <code>sig_level</code>, expected significance level for effects of focal predictors;
<code style="white-space: pre;">&#8288;[[6]]&#8288;</code> <code>power</code>, expected statistical power for effects of focal predictors;
<code style="white-space: pre;">&#8288;[[7]]&#8288;</code> <code>power_ul</code>, the upper limit of power;
<code style="white-space: pre;">&#8288;[[8]]&#8288;</code> <code>n_ul</code>, the upper limit of sample size;
<code style="white-space: pre;">&#8288;[[9]]&#8288;</code> <code>minimum</code>, the minimum sample size <code>n_i</code> required for focal predictors to reach the
expected statistical power and significance level, and corresponding
<code>df_A_C</code>(the df of the numerator of the F-test, i.e., the difference of the dfs between model C and model A),
<code>df_A_i</code>(the df of the denominator of the F-test, i.e., the df of the model A at the sample size <code>n_i</code>),
<code>F_i</code>(the <em>F</em>-test of <code>PRE</code> at the sample size <code>n_i</code>),
<code>p_i</code>(the p-value of <code>F_i</code>),
<code>lambda_i</code>(the non-centrality parameter of the F-distribution for the alternative hypothesis, given <code>PRE</code> and <code>n_i</code>),
<code>power_i</code>(the actual power of <code>PRE</code> at the sample size <code>n_i</code>);
<code style="white-space: pre;">&#8288;[[10]]&#8288;</code> <code>prior</code>, a prior power table with increasing sample sizes (<code>n_i</code>) and power(<code>power_i</code>).
</p>
<p>If sample size <code>n</code> is given, the following results would also be returned:
Integer <code>n</code>, the F_test of <code>PRE</code> at the sample size <code>n</code> with
<code>df_A_C</code>,
<code>df_A</code> (the df of the model A at the sample size <code>n</code>),
<code>F</code> (the F-test of <code>PRE</code> at the sample size <code>n</code>),
<code>p</code> (the p-value of F-test at the sample size <code>n</code>), and the post-hoc power analysis with
<code>lambda_post</code> (the non-centrality parameter of <code>F</code> at the sample size <code>n</code>),
and <code>power_post</code> (the post-hoc power at the sample size <code>n</code>).
</p>
<p>By default, <code>print()</code> prints the primary but not all contents of the <code>Keng_power</code> class.
To inspect more contents, use <code>print.AsIs()</code> or list extracting.
</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>power_lm()
print(power_lm())
plot(power_lm())
</code></pre>

<hr>
<h2 id='power_r'>Conduct post-hoc and prior power analysis, and plan the sample size for r.</h2><span id='topic+power_r'></span>

<h3>Description</h3>

<p>Conduct post-hoc and prior power analysis, and plan the sample size for r.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_r(
  r = 0.2,
  sig_level = 0.05,
  power = 0.8,
  power_ul = 1,
  n_ul = 1.45e+09,
  n = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power_r_+3A_r">r</code></td>
<td>
<p>Pearson's correlation. Cohen(1988) suggested &gt;=0.1, &gt;=0.3, and &gt;=0.5 as cut-off values
of Pearson's correlation r for small, medium, and large effect sizes, respectively.</p>
</td></tr>
<tr><td><code id="power_r_+3A_sig_level">sig_level</code></td>
<td>
<p>Expected significance level.</p>
</td></tr>
<tr><td><code id="power_r_+3A_power">power</code></td>
<td>
<p>Expected statistical power.</p>
</td></tr>
<tr><td><code id="power_r_+3A_power_ul">power_ul</code></td>
<td>
<p>The upper limit of power. <code>power_ul</code> should be larger than <code>power</code>, and the maximum <code>power_ul</code> is 1.</p>
</td></tr>
<tr><td><code id="power_r_+3A_n_ul">n_ul</code></td>
<td>
<p>The upper limit of sample size below which the minimum required sample size is searched.
Non-integer <code>n_ul</code> would be converted to be an integer using <code>as.integer()</code>.
<code>n_ul</code> should be at least 3.</p>
</td></tr>
<tr><td><code id="power_r_+3A_n">n</code></td>
<td>
<p>The current sample size. Non-integer <code>n</code> would be converted to be an integer using <code>as.integer()</code>.
<code>n</code> should be at least 3.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Power_r()</code> follows Aberson (2019) approach to conduct power analysis. <code>power_ul</code> and <code>n_ul</code> determine the total times of power_r()'s attempts searching for the minimum required sample size,
hence the number of rows of the returned power table <code>prior</code> and the right limit of the horizontal axis of the returned power plot.
<code>power_r()</code> will keep running and gradually raise the sample size to <code>n_ul</code> until the sample size pushes the power level to <code>power_ul</code>.
When <code>r</code> is very small and power is larger than 0.8, a huge increase of sample size only brings about a trivial increase in power,
which is cost-ineffective. To make <code>power_r()</code> omit unnecessary attempts, you could set <code>power_ul</code> to be a value less than 1 (e.g., 0.90),
and/or set <code>n_ul</code> to be a value less than 1.45e+09 (e.g., 10000).
</p>


<h3>Value</h3>

<p>A Keng_power class, also a list. If <code>n</code> is not given, the following results would be returned:
<code style="white-space: pre;">&#8288;[[1]]&#8288;</code> <code>r</code>, the given r;
<code style="white-space: pre;">&#8288;[[2]]&#8288;</code> <code>d</code>, Cohen's d derived from <code>r</code>;  Cohen (1988) suggested &gt;=0.2, &gt;=0.5, and &gt;=0.8
as cut-off values of <code>d</code> for small, medium, and large effect sizes, respectively;
<code style="white-space: pre;">&#8288;[[3]]&#8288;</code> <code>sig_level</code>, the expected significance level;
<code style="white-space: pre;">&#8288;[[4]]&#8288;</code> <code>power</code>, the expected power;
<code style="white-space: pre;">&#8288;[[5]]&#8288;</code> <code>power_ul</code>, The upper limit of power;
<code style="white-space: pre;">&#8288;[[6]]&#8288;</code> <code>n_ul</code>, the upper limit of sample size;
<code style="white-space: pre;">&#8288;[[7]]&#8288;</code> <code>minimum</code>, the minimum planned sample size <code>n_i</code> and corresponding
<code>df_i</code> (the <code>df</code> of t-test at the sample size <code>n_i</code>, <code>df_i</code> = <code>n_i</code> - 2),
<code>SE_i</code> (the SE of <code>r</code> at the sample size <code>n_i</code>),
<code>t_i</code> (the t-test of <code>r</code>),
<code>p_i</code> (the p-value of <code>t_i</code>),
<code>delta_i</code> (the non-centrality parameter of the t-distribution for the alternative hypothesis, given <code>r</code> and <code>n_i</code>),
<code>power_i</code> (the actual power of <code>r</code> at the sample size <code>n_i</code>);
<code style="white-space: pre;">&#8288;[[8]]&#8288;</code> <code>prior</code>, a prior power table with increasing sample sizes (<code>n_i</code>) and power(<code>power_i</code>).
<code style="white-space: pre;">&#8288;[[9]]&#8288;</code>  A plot of power against sample size n.
</p>
<p>If sample size <code>n</code> is given, the following results would also be returned:
Integer <code>n</code>, the t_test of <code>r</code> at the sample size <code>n</code> with
<code>df</code>, <code>SE</code> of <code>r</code>, <code>p</code> (the p-value of t-test), and the post-hoc power analysis with
<code>delta_post</code> (the non-centrality parameter of the t-distribution for the alternative hypothesis),
and <code>power_post</code> (the post-hoc power of <code>r</code> at the sample size <code>n</code>).
</p>
<p>By default, <code>print()</code> prints the primary but not all contents of the <code>Keng_power</code> class.
To inspect more contents, use <code>print.AsIs()</code> or list extracting.
</p>


<h3>References</h3>

<p>Aberson, C. L. (2019). <em>Applied power analysis for the behavioral sciences</em>. Routledge.
</p>
<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>power_r(0.2)
print(power_r(0.04))
plot(power_r(0.04))
</code></pre>

<hr>
<h2 id='print.Keng_power'>Print primary but not all contents of the Keng_power class</h2><span id='topic+print.Keng_power'></span>

<h3>Description</h3>

<p>Print primary but not all contents of the Keng_power class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Keng_power'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.Keng_power_+3A_x">x</code></td>
<td>
<p>The output object of <code>power_r()</code> or <code>power_lm()</code>.</p>
</td></tr>
<tr><td><code id="print.Keng_power_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None (invisible NULL).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>power_lm()
power_lm(n = 200)
print(power_lm(n = 200))
x &lt;- power_r(0.2, n = 193)
x
</code></pre>

<hr>
<h2 id='Scale'>Scale a vector</h2><span id='topic+Scale'></span>

<h3>Description</h3>

<p>Scale a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Scale(x, m = NULL, sd = NULL, oadvances = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Scale_+3A_x">x</code></td>
<td>
<p>The original vector.</p>
</td></tr>
<tr><td><code id="Scale_+3A_m">m</code></td>
<td>
<p>The expected Mean of the scaled vector.</p>
</td></tr>
<tr><td><code id="Scale_+3A_sd">sd</code></td>
<td>
<p>The expected Standard Deviation (unit) of the scaled vector.</p>
</td></tr>
<tr><td><code id="Scale_+3A_oadvances">oadvances</code></td>
<td>
<p>The distance the Origin of x advances by.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To scale <code>x</code>, its origin, or unit (sd), or both, could be changed.
</p>
<p>If <code>m</code> = 0 or <code>NULL</code>, and <code>sd</code> = <code>NULL</code>, <code>x</code> would be mean-centered.
</p>
<p>If <code>m</code> is a non-zero number, and <code>sd</code> = <code>NULL</code>, the mean of <code>x</code> would be transformed to m.
</p>
<p>If <code>m</code> = 0 or <code>NULL</code>, and <code>sd</code> = 1, <code>x</code> would be standardized to be its z-score with m = 0 and m = 1.
</p>
<p>The standardized score is not necessarily the z-score. If neither <code>m</code> nor <code>sd</code> is <code>NULL</code>,
<code>x</code> would be standardized to be a vector whose mean and standard deviation would be <code>m</code> and <code>sd</code>, respectively.
To standardize <code>x</code>, the mean and standard deviation of <code>x</code> are needed and computed,
for which the missing values of <code>x</code> are removed if any.
</p>
<p>If <code>oadvances</code> is not <code>NULL</code>,  the origin of <code>x</code> will advance with the standard deviation being unchanged.
In this case, <code>Scale()</code> could be used to pick points in simple slope analysis for moderation models.
Note that when <code>oadvances</code> is not <code>NULL</code>, <code>m</code> and <code>sd</code> must be NULL.
</p>


<h3>Value</h3>

<p>The scaled vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(x &lt;- rnorm(10, 5, 2))
# Mean-center x.
Scale(x)
# Transform the mean of x to 3.
Scale(x, m = 3)
# Transform x to its z-score.
Scale(x, sd = 1)
# Standardize x with m = 100 and sd = 15.
Scale(x, m = 100, sd = 15)
# The origin of x advances by 3.
Scale(x, oadvances = 3)
</code></pre>

<hr>
<h2 id='test_r'>Test the significance, analyze the power, and plan the sample size for r.</h2><span id='topic+test_r'></span>

<h3>Description</h3>

<p>Test the significance, analyze the power, and plan the sample size for r.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_r(r = NULL, n = NULL, sig_level = 0.05, power = 0.8)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_r_+3A_r">r</code></td>
<td>
<p>Pearson's correlation. Cohen(1988) suggested &gt;=0.1, &gt;=0.3, and &gt;=0.5 as cut-off values
of Pearson's correlation r for small, medium, and large effect sizes, respectively.</p>
</td></tr>
<tr><td><code id="test_r_+3A_n">n</code></td>
<td>
<p>Sample size of r. Non-integer <code>n</code> would be converted to be a integer using <code>as.integer()</code>.
<code>n</code> should be at least 3.</p>
</td></tr>
<tr><td><code id="test_r_+3A_sig_level">sig_level</code></td>
<td>
<p>Expected significance level.</p>
</td></tr>
<tr><td><code id="test_r_+3A_power">power</code></td>
<td>
<p>Expected statistical power.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To test the significance of the r using the one-sample t-test,
the SE of <code>r</code> is determined by the following formula: <code>SE = sqrt((1 - r^2)/(n - 2))</code>.
Another way is transforming <code>r</code> to Fisher's z using the following formula:
<code>fz = atanh(r)</code> with the SE of <code>fz</code> being <code>sqrt(n - 3)</code>.
Fisher's z is commonly used to compare two Pearson's correlations from independent samples.
Fisher's transformation is presented here only to satisfy the curiosity of users who are
interested in the difference between t-test and Fisher's transformation.
</p>
<p>The post-hoc power of <code>r</code>'s t-test is computed through the way of Aberson (2019).
Other software and R packages like SPSS and <code>pwr</code> give different power estimates due to
underlying different formulas. <code>Keng</code> adopts Aberson's approach because this approach guarantees
the equivalence of r and PRE.
</p>


<h3>Value</h3>

<p>A list with the following results:
<code style="white-space: pre;">&#8288;[[1]]&#8288;</code> <code>r</code>, the given r;
<code style="white-space: pre;">&#8288;[[2]]&#8288;</code> <code>d</code>, Cohen's d derived from <code>r</code>; Cohen (1988) suggested &gt;=0.2, &gt;=0.5, and &gt;=0.8
as cut-off values of <code>d</code> for small, medium, and large effect sizes, respectively.
<code style="white-space: pre;">&#8288;[[3]]&#8288;</code> Integer <code>n</code>;
<code style="white-space: pre;">&#8288;[[4]]&#8288;</code> t-test of <code>r</code> (incl., <code>r</code>, <code>df</code> of r, <code>SE_r</code>, <code>t</code>, <code>p_r</code>),
95% CI of <code>r</code> based on t -test (<code>LLCI_r_t</code>, <code>ULCI_r_t</code>),
and post-hoc power of <code>r</code> (incl., <code>delta_post</code>, <code>power_post</code>);
<code style="white-space: pre;">&#8288;[[5]]&#8288;</code> Fisher's z transformation (incl., <code>fz</code> of <code>r</code>, z-test of <code>fz</code> [<code>SE_fz</code>, <code>z</code>, <code>p_fz</code>],
and 95% CI of <code>r</code> derived from <code>fz</code>.
</p>
<p>Note that the returned CI of <code>r</code> may be out of r's valid range [-1, 1].
This &quot;error&quot; is deliberately left to users, who should correct the CI manually in reports.
</p>


<h3>References</h3>

<p>Aberson, C. L. (2019). <em>Applied power analysis for the behavioral sciences</em>. Routledge.
</p>
<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Routledge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_r(0.2, 193)

# compare the p-values of t-test and Fisher's transformation
for (i in seq(30, 200, 10)) {
cat(c("n = ", i, ", difference between ps = ",
       format(
        abs(test_r(0.2, i)[["t_test"]]["p_r"] - test_r(0.2, i)[["Fisher_z"]]["p_fz"]),
        nsmall = 12,
        scientific = FALSE)),
      sep = "",
      fill = TRUE)
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
