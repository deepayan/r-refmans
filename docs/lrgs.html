<!DOCTYPE html><html><head><title>Help for package lrgs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lrgs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lrgs-package'>
<p>Linear Regression by Gibbs Sampling</p></a></li>
<li><a href='#Gibbs.post2dataframe'>
<p>Linear Regression by Gibbs Sampling</p></a></li>
<li><a href='#Gibbs.regression'>
<p>Linear Regression by Gibbs Sampling</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Linear Regression by Gibbs Sampling</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-08-10</td>
</tr>
<tr>
<td>Author:</td>
<td>Adam Mantz</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adam Mantz &lt;amantz@slac.stanford.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements a Gibbs sampler to do linear regression with multiple covariates, multiple responses, Gaussian measurement errors on covariates and responses, Gaussian intrinsic scatter, and a covariate prior distribution which is given by either a Gaussian mixture of specified size or a Dirichlet process with a Gaussian base distribution. Described further in Mantz (2016) &lt;<a href="https://doi.org/10.1093%2Fmnras%2Fstv3008">doi:10.1093/mnras/stv3008</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/abmantz/lrgs">https://github.com/abmantz/lrgs</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-08-10 22:22:10 UTC; amantz</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-08-11 14:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='lrgs-package'>
Linear Regression by Gibbs Sampling
</h2><span id='topic+lrgs-package'></span><span id='topic+lrgs'></span>

<h3>Description</h3>

<p>Implements a Gibbs sampler to do linear regression with multiple covariates, multiple responses, Gaussian measurement errors on covariates and responses, Gaussian intrinsic scatter, and a covariate prior distribution which is given by either a Gaussian mixture of specified size or a Dirichlet process with a Gaussian base distribution.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> lrgs</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.5.4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2018-05-17</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> MIT</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>See help for Gibbs.regression
</p>


<h3>Author(s)</h3>

<p>Adam Mantz &lt;amantz@slac.stanford.edu&gt;
</p>

<hr>
<h2 id='Gibbs.post2dataframe'>
Linear Regression by Gibbs Sampling
</h2><span id='topic+Gibbs.post2dataframe'></span>

<h3>Description</h3>

<p>Transforms a set of posterior samples produced by Gibbs.regression into a data frame for more straightforward analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gibbs.post2dataframe(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gibbs.post2dataframe_+3A_p">p</code></td>
<td>

<p>an object returned from Gibbs.regression.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with one column corresponding to each parameter stored in post.
</p>


<h3>Author(s)</h3>

<p>Adam Mantz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gibbs.regression">Gibbs.regression</a></code>
</p>

<hr>
<h2 id='Gibbs.regression'>
Linear Regression by Gibbs Sampling
</h2><span id='topic+Gibbs.regression'></span>

<h3>Description</h3>

<p>Runs a Gibbs sampler to simulate the posterior distribution of a linear model with (potentially) multiple covariates and response variables. Throughout this help file, we use the following notation: there are n data points, m response variables and p covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gibbs.regression(x.in, y.in, M, Nsamples, Ngauss = 1, dirichlet=FALSE,
 M.inv = NULL, intercept = TRUE, trace = "bs", fix = "", start = list(),
 B.prior.mean=NULL, B.prior.cov=NULL, Sigma.prior.scale=NULL,
 Sigma.prior.dof=-1, dp.prior.alpha=NULL, dp.prior.beta=NULL,
 mention.every=NA, save.every=NA, save.to=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gibbs.regression_+3A_x.in">x.in</code></td>
<td>

<p>the measured covariates. Either an n*p matrix, a vector (if p=1) or NULL (if p=0, i.e. a the model is constant).
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_y.in">y.in</code></td>
<td>

<p>the measured responses. Either an n*m matrix or a vector (if m=1).
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_m">M</code></td>
<td>

<p>a (p+m)*(p+m)*n array holding the n measurement covariance matrices, with covariates ordered before responses within each matrix. If both M and M.inv are NULL, all measurement errors are taken to be zero.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_nsamples">Nsamples</code></td>
<td>

<p>the number of iterations of the Gibbs sampler to run.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_ngauss">Ngauss</code></td>
<td>

<p>number of Gaussian mixture components describing the distribution of covariates. Pass 0 for the special case of a uniform distribution.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_dirichlet">dirichlet</code></td>
<td>

<p>if TRUE, the prior on covariates is given not by a Gaussian mixture of size Ngauss, but by a Dirichlet process with a Gaussian base distribution (see details). This can be thought of as a Gaussian mixture where Ngauss is learned from the data and marginalized over.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_m.inv">M.inv</code></td>
<td>

<p>as an alternative to M, the inverses of the n measurement covariance matrices in the same format. Note that the M argument takes precedence; pass M=NULL to use M.inv. If both M and M.inv are NULL, all measurement errors are taken to be zero.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_intercept">intercept</code></td>
<td>

<p>if TRUE, the model includes constant (intercept) terms for each response. Otherwise, the intercepts are fixed to zero.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_trace">trace</code></td>
<td>

<p>determines which variables are returned at the end of the call. See details.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_fix">fix</code></td>
<td>

<p>determines which parameters are NOT varied. See details.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_start">start</code></td>
<td>

<p>a list containing starting values for any of the model parameters. These are optional, with the exception of Sigma and Tau if they are fixed. See details.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_b.prior.mean">B.prior.mean</code></td>
<td>

<p>optional vector giving the mean of a Gaussian prior to be applied to the coefficients. The order is B11, B21, ..., B12, B22, ..., where the first index refers to the covariate and the second to the response. Assumed to be zero if it is not specified but B.prior.cov is.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_b.prior.cov">B.prior.cov</code></td>
<td>

<p>optional matrix giving the covariance of a Gaussian prior to be applied to the coefficients. The parameter order is the same as in B.prior.mean. If not specified, an improper uniform prior is used.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_sigma.prior.scale">Sigma.prior.scale</code></td>
<td>

<p>optional matrix giving the scale parameter of an inverse-Wishart prior to be applied to the intrinsic covariance. Default is zero.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_sigma.prior.dof">Sigma.prior.dof</code></td>
<td>

<p>number of degrees of freedom for the inverse-Wishart prior on the intrinsic covariance. Default is -1, which corresponds to the Jeffreys (i.e. minimally informative) prior when the default scale matrix is used. Using -(m+1) degrees of freedom with the default scale matrix corresponds to a prior that is uniform in det(Sigma).
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_dp.prior.alpha">dp.prior.alpha</code></td>
<td>

<p>shape paramerer of a Gamma prior to be applied to the Dirichlet process concentration parameter, if dirichlet=TRUE.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_dp.prior.beta">dp.prior.beta</code></td>
<td>

<p>rate paramerer of a Gamma prior to be applied to the Dirichlet process concentration parameter, if dirichlet=TRUE.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_mention.every">mention.every</code></td>
<td>

<p>if set to a positive integer N, a message will be printed after every N iterations to confirm that something is happening.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_save.every">save.every</code></td>
<td>

<p>if set to a positive integer N, the result will be saved as an object named &quot;res&quot; to the file named in the save.to argument every N iterations.
</p>
</td></tr>
<tr><td><code id="Gibbs.regression_+3A_save.to">save.to</code></td>
<td>

<p>the name of a file to periodically save the results to.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An in-depth description of the model and algorithm can be found in the references below. The full set of parameters is
</p>
<p>X: true values of all covariates, arranged as a design matrix
</p>
<p>Y: true values of all responses
</p>
<p>B: matrix of intercepts and coefficients
</p>
<p>Sigma: intrisic covariance matrix of the responses
</p>
<p>G: vector encoding which Gaussian mixture component of the covariate 
distribution model each data point belongs to
</p>
<p>pi: vector of relative proportions of the mixture components
</p>
<p>mu: matrix holding the mean of each mixture component
</p>
<p>Tau: covariance matrices for each mixture component
</p>
<p>mu0: mean of the Gaussian hyper-prior applied to mu
</p>
<p>U: covariance matrix of the hyper-prior for mu
</p>
<p>W: matrix defining the Wishart hyper-prior for Tau
</p>
<p>alpha: the Dirichlet process concentration parameter
</p>
<p>Note that mu0, U and W are meaningful only if Ngauss&gt;1. If Ngauss=0 these, as well as G, pi, mu and Tau, are ignored.
</p>
<p>If a Dirichlet process prior on the covariates is used instead of a Gaussian mixture, then mu and Tau represent the hyperparameters of the Gaussian base distribution of the process. In this case, pi mu0, U and W are not sampled, but G can still be interpretted as giving which cluster each data point belongs to. alpha is only meaningful if the Dirichlet process is being used.
</p>
<p>In the trace and fix arguments, these parameters (in the order above) are indicated by the characters &quot;xybsgpmtzuwa&quot;. So, for example, the default value trace=&quot;bs&quot; means that only the coefficients and intrisic scatter are returned to the user, while fix=&quot;x&quot; would fix the values of X (typically to the measured input values, x.in).
</p>
<p>The contents of the list optionally passed to start should be similar to those returned by this function, with one fewer dimension (corresponding to the multiple samples returned). That is, if the $X item returned by this function has dimension c(n,p+1,Nsamples), a valid value for start$X has dimensions c(n,p+1).
</p>


<h3>Value</h3>

<p>A list containing samples of the model parameters specified by the trace argument. The parameters are defined above; the dimensionality of the result will be
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>n,p+1,Nsamples</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>n,m,Nsamples</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>p+1,m,Nsamples</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>m,m,Nsamples</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>n,Nsamples</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>Ngauss,Nsamples</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Ngauss,p,Nsamples</p>
</td></tr>
<tr><td><code>Tau</code></td>
<td>
<p>p,p,Ngauss,Nsamples</p>
</td></tr>
<tr><td><code>mu0</code></td>
<td>
<p>p,Nsamples</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>p,p,Nsamples</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>p,p,Nsamples</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Nsamples</p>
</td></tr>
</table>
<p>This assumes intercept=TRUE; otherwise, replace p+1 with p everywhere. This list can be transformed into a data frame using the Gibbs.post2dataframe function.
</p>


<h3>Note</h3>

<p>The output is a Monte Carlo Markov Chain, and therefore may take some time to converge to the true posterior distribution. Traces of the parameters of interest should be examined in order to identify and remove this &quot;burn-in&quot; period.
</p>
<p>If your data set is missing the occasional covariate or response measurement, it should be sufficient to set the corresponding variance in M to a very large number. (Alternatively, this case can be handled exactly by passing the inverse-covariances through M.inv, and setting the appropriate elements to zero.) Similarly, if a subset of values are measured with no error, use a very small number for the variance (but do not attempt to pass zero covariance or Inf in the inverse-covariance).
</p>


<h3>Author(s)</h3>

<p>Adam Mantz
</p>


<h3>References</h3>

<p>Mantz (2016; MNRAS 457:1279; arXiv:1509.00908; doi:10.1093/mnras/stv3008) for this function, Kelly (2007, ApJ 665:1489; arXiv:0705.2774; doi:10.1086/519947) for the same approach with a single response variable and a Gaussian mixture of covariates, Neal (2000, Journal of Computational and Graphical Statistics 9:249) for the Dirichlet process algorithm employed.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code> for classical linear regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example using the default Ngauss=1 with no measurement errors
x &lt;- rnorm(500, 0, 5)
y &lt;- pi*x + rnorm(length(x), 0, 0.1)
post &lt;- Gibbs.regression(x, y, NULL, 50, trace='bsmt', fix='xy')
m &lt;- lm(y~x)
plot(post$B[1,1,-(1:10)], col=4); abline(h=m$coefficients[1], lty=2, col=2)
plot(post$B[2,1,-(1:10)], col=4); abline(h=m$coefficients[2], lty=2, col=2)
plot(post$Sigma[1,1,-(1:10)], col=4); abline(h=var(m$residuals), lty=2, col=2)
plot(post$mu[1,1,-(1:10)], col=4); abline(h=mean(x), lty=2, col=2)
plot(post$Tau[1,1,1,-(1:10)], col=4); abline(h=var(x), lty=2, col=2)

## verbose example using a Dirichlet process, including measurement errors
## in practice, you would would want a longer chain, i.e. larger nmc
xx &lt;- rnorm(100, c(-15,0,15), 1)
yy &lt;- xx + rnorm(length(xx)) + rnorm(length(xx), 0, 3)
xx &lt;- xx + rnorm(length(xx))
M &lt;- array(0, dim=c(2,2,length(xx)))
M[1,1,] &lt;- 1
M[2,2,] &lt;- 1
nmc &lt;- 10
post &lt;- Gibbs.regression(xx, yy, M, nmc, dirichlet=TRUE, trace='bsgmta', mention.every=1)
plot(xx, yy, col=post$G[,nmc]) # plot clusters at the last iteration
m &lt;- lm(yy~xx)
plot(post$B[1,1,-1], col=4); abline(h=m$coefficients[1], lty=2, col=2)
plot(post$B[2,1,-1], col=4); abline(h=m$coefficients[2], lty=2, col=2)
plot(post$Sigma[1,1,-1], col=4); abline(h=var(m$residuals), lty=2, col=2)
plot(post$mu[1,1,-1], col=4); abline(h=mean(xx), lty=2, col=2)
plot(post$Tau[1,1,1,-1], col=4); abline(h=var(xx), lty=2, col=2)
plot(post$alpha[-1], col=4)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
