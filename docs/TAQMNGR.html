<!DOCTYPE html><html lang="en"><head><title>Help for package TAQMNGR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TAQMNGR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#TAQ'>
<p>TAQ Manager</p></a></li>
<li><a href='#TAQMNGR'>
<p>TAQ Manager</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>2018.5-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-05-12</td>
</tr>
<tr>
<td>Title:</td>
<td>Manage Tick-by-Tick Transaction Data</td>
</tr>
<tr>
<td>Author:</td>
<td>Francesco Calvori, Fabrizio Cipollini, Giampiero M. Gallo and 'gzstream' authors.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fabrizio Cipollini &lt;cipollini.fabrizio@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0-2)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp (&ge; 0.11.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>zlib headers and library</td>
</tr>
<tr>
<td>Description:</td>
<td>Manager of tick-by-tick transaction data that performs 'cleaning', 'aggregation' and 'import' in an efficient and fast way. The package engine, written in C++, exploits the 'zlib' and 'gzstream' libraries to handle gzipped data without need to uncompress them. 'Cleaning' and 'aggregation' are performed according to Brownlees and Gallo (2006) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2006.09.030">doi:10.1016/j.csda.2006.09.030</a>&gt;. Currently, TAQMNGR processes raw data from WRDS (Wharton Research Data Service, <a href="https://wrds-web.wharton.upenn.edu/wrds/">https://wrds-web.wharton.upenn.edu/wrds/</a>).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://cran.r-project.org/package=TAQMNGR">https://cran.r-project.org/package=TAQMNGR</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-05-20 05:32:34 UTC; cipollini</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-05-20 06:37:40 UTC</td>
</tr>
</table>
<hr>
<h2 id='TAQ'>
TAQ Manager
</h2><span id='topic+TAQ.CleanTickByTick'></span><span id='topic+TAQ.Aggregate'></span><span id='topic+TAQ.Report'></span><span id='topic+TAQ.Read'></span>

<h3>Description</h3>

<p>Manage tick-by-tick transaction data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
  TAQ.CleanTickByTick(dirInput, dirOutput, 
  
    window = 80, deltaTrimmed = 0.10, granularity = 0.04, useCleaned = TRUE)
  
  TAQ.Aggregate(dirInput, symbol, bin, useAggregated = TRUE)
  
  TAQ.Report(dirInput, symbol)

  TAQ.Read(dirInput, symbol, import = NULL, startDate, endDate, bin)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TAQ_+3A_dirinput">dirInput</code></td>
<td>
<p>A <em>character</em> scalar: the input directory.<br />
For the function <code>CleanTickByTick()</code>, <code>dirInput</code> is the name of the folder containing the raw data files. 
In this case it is important that <code>dirInput</code> includes only <code>.gz</code> files to be cleaned.
For the remaining functions, <code>dirInput</code> is the name of the folder including the previously cleaned/aggregated data (appearing as <code>dirOutput</code> in the function <code>CleanTickByTick()</code>).</p>
</td></tr>
<tr><td><code id="TAQ_+3A_diroutput">dirOutput</code></td>
<td>
<p>A <em>character</em> scalar: the output directory. 
It must be different from <code>dirInput</code>.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_window">window</code></td>
<td>
<p>A <em>numeric</em> integer scalar: the window size for the trimming procedure of data clean (see Details).</p>
</td></tr>
<tr><td><code id="TAQ_+3A_deltatrimmed">deltaTrimmed</code></td>
<td>
<p>A <em>numeric</em> scalar into $(0,1)$: the trimming proportion (see Details).</p>
</td></tr>
<tr><td><code id="TAQ_+3A_granularity">granularity</code></td>
<td>
<p>A <em>numeric</em> positive scalar: the granularity parameter (see Details).</p>
</td></tr>
<tr><td><code id="TAQ_+3A_usecleaned">useCleaned</code></td>
<td>
<p>A <em>logical</em> scalar: if <code>TRUE</code>, previously cleaned files (if any) are not cleaned again.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_useaggregated">useAggregated</code></td>
<td>
<p>A <em>logical</em> scalar: if <code>TRUE</code>, previously aggregated data (if any) are not aggregated again.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_symbol">symbol</code></td>
<td>
<p>A <em>character</em> (vector in <code>TAQ.Aggregate()</code>; scalar in <code>TAQ.Report()</code> and <code>TAQ.Read()</code>): the ticker symbols of interest.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_startdate">startDate</code></td>
<td>
<p>A <em>numeric</em> integer scalar: the start date in the <em>yyyymmdd</em> format.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_enddate">endDate</code></td>
<td>
<p>A <em>numeric</em> integer scalar: the end date in the <em>yyyymmdd</em> format.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_bin">bin</code></td>
<td>
<p>A <em>numeric</em> integer scalar: the bin size (in seconds) for aggregating data.</p>
</td></tr>
<tr><td><code id="TAQ_+3A_import">import</code></td>
<td>
<p>A <em>character</em>: the list of fields to be imported. One or more among:<br />
<code>"FIRST"</code>: First price in the bin.<br />
<code>"MIN"</code>: Min price in the bin.<br />
<code>"MAX"</code>: Max price in the bin.<br />
<code>"LAST"</code>: Last price in the bin.<br />
<code>"SIZE"</code>: First price in the bin.<br />
<code>"#TRADES"</code>: Number of trades in the bin.<br />
<code>"VWAP"</code>: Volume Weighted Average Price in the bin.<br />
If <code>NULL</code>, all fields are imported.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The meaning of the arguments <code>window</code>, <code>deltaTrimmed</code>, and <code>granularity</code> is detailed in the reference below.
</p>


<h3>References</h3>

<p>Brownlees, C. T., and Gallo, G. M. (2006). Financial Econometric Analysis at Ultra&ndash;High Frequency: Data Handling Concerns, <em>Computational Statistics and Data Analysis</em> <b>51</b>, 2232&ndash;2245.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  #### A fake dataset for running the example can be downloaded at 
  #### 'http://local.disia.unifi.it/cipollini/webpage-new/data/data_sample.txt.gz' 
  ## Input
  # dirInput  &lt;- "path of the input folder" 
  # dirOutput &lt;- "path of the output folder" ## Must be different from 'dirInput' 
  ## Clean
  # TAQ.CleanTickByTick(dirInput = dirInput, dirOutput = dirInput)
  ## Make the report (1 at a time)
  # TAQ.Report(dirInput = dirOutput, symbol = c("DOG")) ## A scalar symbol
  # TAQ.Report(dirInput = dirOutput, symbol = c("GNU")) ## A scalar symbol
  ## Aggregate
  # TAQ.Aggregate(dirInput = dirOutput, symbol = c("DOG", "GNU"), bin = 300, 
  #   useAggregated = TRUE)
  ## Import data
  # dog &lt;- TAQ.Read(dirInput = dirOutput, symbol = "DOG", 
  #   startDate = 00010101, endDate = 20141231, bin = 300)
</code></pre>

<hr>
<h2 id='TAQMNGR'>
TAQ Manager
</h2><span id='topic+TAQMNGR'></span>

<h3>Description</h3>

<p>The package manages tick-by-tick transaction data, performing <em>cleaning</em>, <em>aggregation</em> and <em>import</em>. 
</p>


<h3>Details</h3>

<p>The package manages tick-by-tick transaction data, performing <em>cleaning</em>, <em>aggregation</em> and <em>import</em> in an efficient and fast way (the package engine is developed in <code>C++</code>).<br />
Cleaning and Aggregation are performed according to Brownlees and Gallo (2006).
</p>

<table>
<tr>
 <td style="text-align: left;">
 Package: </td><td style="text-align: left;"> TAQMNGR</td>
</tr>
<tr>
 <td style="text-align: left;">
 Type:    </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
 Version: </td><td style="text-align: left;"> 2015.2-1</td>
</tr>
<tr>
 <td style="text-align: left;">
 Date:    </td><td style="text-align: left;"> 2015-02-21</td>
</tr>
<tr>
 <td style="text-align: left;">
 License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>Note</h3>

<p>Currently, the package processes raw data from WRDS (Wharton Research Data Service).<br />
They have to satisfy the following requirements:<br />
</p>

<ul>
<li><p> all fields have to be included (select the '<code>Check All</code>' button at the WRDS downloading page);<br />
</p>
</li>
<li><p> select the fixed-width text and '<code>G zip</code>' as output format and compression type, respectively, at the WRDS downloading page.
</p>
</li></ul>

<p>An example with fake raw data can be downloaded at <a href="http://local.disia.unifi.it/cipollini/webpage-new/data/data_sample.txt.gz">http://local.disia.unifi.it/cipollini/webpage-new/data/data_sample.txt.gz</a>.<br />
The package uses the following libraries: 'Gzstream' (available at 'http://www.cs.unc.edu/Research/compgeom/gzstream/' under LGPL license), and 'zlib' (freely available at 'http://www.zlib.net/').
</p>


<h3>Author(s)</h3>

<p>Francesco Calvori &lt;francesco.calvori@gmail.com&gt;, 
</p>
<p>Fabrizio Cipollini &lt;cipollini.fabrizio@gmail.com&gt;, 
</p>
<p>Giampiero M. Gallo &lt;giampiero.gallo@gmail.com&gt;.
</p>
<p><strong>Maintainer</strong>: &lt;fabrizio.cipollini@gmail.com&gt;
</p>


<h3>References</h3>

<p>Brownlees, C. T., and Gallo, G. M. (2006). Financial Econometric Analysis at Ultra&ndash;High Frequency: Data Handling Concerns, <em>Computational Statistics and Data Analysis</em> <b>51</b>, 2232&ndash;2245.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
