<!DOCTYPE html><html><head><title>Help for package aTSA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {aTSA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#accurate'><p>Accurate Computation</p></a></li>
<li><a href='#adf.test'><p>Augmented Dickey-Fuller Test</p></a></li>
<li><a href='#arch.test'><p>ARCH Engle's Test for Residual Heteroscedasticity</p></a></li>
<li><a href='#aTSA'>
<p>Alternative Time Series Analysis</p></a></li>
<li><a href='#coint.test'><p>Cointegration Test</p></a></li>
<li><a href='#ecm'><p>Error Correction Model</p></a></li>
<li><a href='#estimate'><p>Estimate an ARIMA Model</p></a></li>
<li><a href='#expsmooth'><p>Simple Exponential Smoothing</p></a></li>
<li><a href='#forecast'><p>Forecast From ARIMA Fits</p></a></li>
<li><a href='#Holt'><p>Holt's Two-parameter Exponential Smoothing</p></a></li>
<li><a href='#identify'><p>Identify a Time Series Model</p></a></li>
<li><a href='#kpss.test'><p>Kwiatkowski-Phillips-Schmidt-Shin Test</p></a></li>
<li><a href='#MA'><p>Moving Average Filter</p></a></li>
<li><a href='#pp.test'><p>Phillips-Perron Test</p></a></li>
<li><a href='#stationary.test'><p>Stationary Test for Univariate Time Series</p></a></li>
<li><a href='#stepar'><p>Stepwise Autoregressive Model</p></a></li>
<li><a href='#trend.test'><p>Trend Test</p></a></li>
<li><a href='#ts.diag'><p>Diagnostics for ARIMA fits</p></a></li>
<li><a href='#Winters'><p>Winters Three-parameter Smoothing</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Alternative Time Series Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>3.1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-06-19</td>
</tr>
<tr>
<td>Author:</td>
<td>Debin Qiu</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Debin Qiu &lt;debinqiu@uga.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains some tools for testing, analyzing time series data and
    fitting popular time series models such as ARIMA, Moving Average and Holt
    Winters, etc. Most functions also provide nice and clear outputs like SAS
    does, such as identify, estimate and forecast, which are the same statements
    in PROC ARIMA in SAS.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-21 07:54:50 UTC; hornik</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-21 07:59:33 UTC</td>
</tr>
</table>
<hr>
<h2 id='accurate'>Accurate Computation</h2><span id='topic+accurate'></span>

<h3>Description</h3>

<p>Computes the accurate criterion of smoothed (fitted) values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accurate(x, x.hat, k, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accurate_+3A_x">x</code></td>
<td>
<p>a numeric vector of original values.</p>
</td></tr>
<tr><td><code id="accurate_+3A_x.hat">x.hat</code></td>
<td>
<p>a numeric vector of smoothed (fitted) values.</p>
</td></tr>
<tr><td><code id="accurate_+3A_k">k</code></td>
<td>
<p>the number of parameters in obtaining the smoothed (fitted) values.</p>
</td></tr>
<tr><td><code id="accurate_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console. The default is
<code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="http://www.dms.umontreal.ca/~duchesne/chap12.pdf">http://www.dms.umontreal.ca/~duchesne/chap12.pdf</a> in page 616 - 617 for
the details of calculations for each criterion.
</p>


<h3>Value</h3>

<p>A vector containing the following components:
</p>
<table>
<tr><td><code>SST</code></td>
<td>
<p>the total sum of squares.</p>
</td></tr>
<tr><td><code>SSE</code></td>
<td>
<p>the sum of the squared residuals.</p>
</td></tr>
<tr><td><code>MSE</code></td>
<td>
<p>the mean squared error.</p>
</td></tr>
<tr><td><code>RMSE</code></td>
<td>
<p>the root mean square error.</p>
</td></tr>
<tr><td><code>MAPE</code></td>
<td>
<p>the mean absolute percent error.</p>
</td></tr>
<tr><td><code>MPE</code></td>
<td>
<p>the mean percent error.</p>
</td></tr>
<tr><td><code>MAE</code></td>
<td>
<p>the mean absolute error.</p>
</td></tr>
<tr><td><code>ME</code></td>
<td>
<p>the mean error.</p>
</td></tr>
<tr><td><code>R.squared</code></td>
<td>
<p>R^2 = 1 - SSE/SST.</p>
</td></tr>
<tr><td><code>R.adj.squared</code></td>
<td>
<p>the adjusted R^2.</p>
</td></tr>
<tr><td><code>RW.R.squared</code></td>
<td>
<p>the random walk R^2.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>the Akaike's information criterion.</p>
</td></tr>
<tr><td><code>SBC</code></td>
<td>
<p>the Schwarz's Bayesian criterion.</p>
</td></tr>
<tr><td><code>APC</code></td>
<td>
<p>the Amemiya's prediction criterion</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the model fits the series badly, the model error sum of squares <code>SSE</code>
may be larger than <code>SST</code> and the <code>R.squared</code> or <code>RW.R.squared</code> statistics
will be negative. The <code>RW.R.squared</code> uses the random walk model for the purpose of
comparison.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(200),100,2)
y &lt;- 0.1*X[,1] + 2*X[,2] + rnorm(100)
y.hat &lt;- fitted(lm(y ~ X))
accurate(y,y.hat,2)
</code></pre>

<hr>
<h2 id='adf.test'>Augmented Dickey-Fuller Test</h2><span id='topic+adf.test'></span>

<h3>Description</h3>

<p>Performs the Augmented Dickey-Fuller test for the null hypothesis
of a unit root of a univarate time series <code>x</code> (equivalently, <code>x</code> is a
non-stationary time series).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adf.test(x, nlag = NULL, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adf.test_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="adf.test_+3A_nlag">nlag</code></td>
<td>
<p>the lag order with default to calculate the test statistic. See details for
the default.</p>
</td></tr>
<tr><td><code id="adf.test_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the test results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Augmented Dickey-Fuller test incorporates
three types of linear regression models. The first type (<code>type1</code>) is a linear model
with no drift and linear trend with respect to time:
</p>
<p style="text-align: center;"><code class="reqn">dx[t] = \rho*x[t-1] + \beta[1]*dx[t-1] + ... + \beta[nlag - 1]*dx[t - nlag + 1]
+e[t],</code>
</p>

<p>where <code class="reqn">d</code> is an operator of first order difference, i.e.,
<code class="reqn">dx[t] = x[t] - x[t-1]</code>, and <code class="reqn">e[t]</code> is an error term.
</p>
<p>The second type (<code>type2</code>) is a linear model with drift but no linear trend:
</p>
<p style="text-align: center;"><code class="reqn">dx[t] = \mu  + \rho*x[t-1] + \beta[1]*dx[t-1] + ... +
\beta[nlag - 1]*dx[t - nlag + 1] +e[t].</code>
</p>

<p>The third type (<code>type3</code>) is a linear model with both drift and linear trend:
</p>
<p style="text-align: center;"><code class="reqn">dx[t] = \mu + \beta*t + \rho*x[t-1] + \beta[1]*dx[t-1] + ... +
\beta[nlag - 1]*dx[t - nlag + 1] +e[t].</code>
</p>

<p>We use the default <code>nlag = floor(4*(length(x)/100)^(2/9))</code> to
calcuate the test statistic.
The Augmented Dickey-Fuller test statistic is defined as
</p>
<p style="text-align: center;"><code class="reqn">ADF = \rho.hat/S.E(\rho.hat),</code>
</p>

<p>where <code class="reqn">\rho.hat</code> is the coefficient estimation
and <code class="reqn">S.E(\rho.hat)</code> is its corresponding estimation of standard error for each
type of linear model. The p.value is
calculated by interpolating the test statistics from the corresponding critical values
tables (see Table 10.A.2 in Fuller (1996)) for each type of linear models with given
sample size <code class="reqn">n</code> = length(<code>x</code>).
The Dickey-Fuller test is a special case of Augmented Dickey-Fuller test
when <code>nlag</code> = 2.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>type1</code></td>
<td>
<p>a matrix with three columns: <code>lag</code>, <code>ADF</code>, <code>p.value</code>,
where <code>ADF</code> is the Augmented Dickey-Fuller test statistic.</p>
</td></tr>
<tr><td><code>type2</code></td>
<td>
<p>same as above for the second type of linear model.</p>
</td></tr>
<tr><td><code>type3</code></td>
<td>
<p>same as above for the third type of linear model.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Missing values are removed.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Fuller, W. A. (1996). Introduction to Statistical Time Series, second ed., New York:
John Wiley and Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pp.test">pp.test</a></code>, <code><a href="#topic+kpss.test">kpss.test</a></code>, <code><a href="#topic+stationary.test">stationary.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ADF test for AR(1) process
x &lt;- arima.sim(list(order = c(1,0,0),ar = 0.2),n = 100)
adf.test(x)
# ADF test for co2 data
adf.test(co2)
</code></pre>

<hr>
<h2 id='arch.test'>ARCH Engle's Test for Residual Heteroscedasticity</h2><span id='topic+arch.test'></span>

<h3>Description</h3>

<p>Performs Portmanteau Q and Lagrange Multiplier tests for the null
hypothesis that the residuals of a ARIMA model are homoscedastic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arch.test(object, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arch.test_+3A_object">object</code></td>
<td>
<p>an object from arima model estimated by
<code><a href="stats.html#topic+arima">arima</a></code> or <code><a href="#topic+estimate">estimate</a></code> function.</p>
</td></tr>
<tr><td><code id="arch.test_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console, including the
plots. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ARCH Engle's test is constructed based on the fact that if the residuals
(defined as <code class="reqn">e[t]</code>) are heteroscedastic, the squared residuals (<code class="reqn">e^2[t]</code>) are
autocorrelated. The
first type of test is to examine whether the squares of residuals are a sequence of white
noise, which is called Portmanteau Q test and similar to the Ljung-Box test on the squared
residuals. The second type of test proposed by Engle (1982) is the Lagrange Multiplier
test which is to fit a linear regression model for the squared residuals and examine
whether the fitted model
is significant. So the null hypothesis is that the squared residuals are a sequence
of white noise, namely, the residuals are homoscedastic. The lag parameter
to calculate the test statistics is taken from an integer sequence of <code class="reqn">1:min(24,n)</code> with
step 4 if <code class="reqn">n &gt; 25</code>, otherwise 2, where <code class="reqn">n</code> is the number of nonmissing observations.
</p>
<p>The plots of residuals, squared residuals, p.values of PQ and LM tests will be drawn if
<code>output = TRUE</code>.
</p>


<h3>Value</h3>

<p>A matrix with the following five columns:
</p>
<table>
<tr><td><code>order</code></td>
<td>
<p>the lag parameter to calculate the test statistics.</p>
</td></tr>
<tr><td><code>PQ</code></td>
<td>
<p>the Portmanteau Q test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p.value for PQ test.</p>
</td></tr>
<tr><td><code>LM</code></td>
<td>
<p>the Lagrange Multiplier test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p.value for LM test.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Missing values are removed before analysis.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Engle, Robert F. (1982). Autoregressive Conditional Heteroscedasticity with Estimates
of the Variance of United Kingdom Inflation. <em>Econometrica</em>, 50 (4): 987-1007.
</p>
<p>McLeod, A. I. and W. K. Li. Diagnostic Checking ARMA Time Series Models Using
Squared-Residual Autocorrelations. <em>Journal of Time Series Analysis</em>.
Vol. 4, 1983, pp. 269-273.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
mod &lt;- estimate(x,p = 1) # or mod &lt;- arima(x,order = c(1,0,0))
arch.test(mod)
</code></pre>

<hr>
<h2 id='aTSA'>
Alternative Time Series Analysis
</h2><span id='topic+aTSA'></span><span id='topic+aTSA'></span>

<h3>Description</h3>

<p>This is an alternative package to analyze the time series data, especially the univariate time series. Compared with other existing functions for time series analysis, most functions in this package provide nice outputs like SAS does for time series. Several functions are exactly the same names as 'arima' procedure in SAS, such as <code><a href="#topic+identify">identify</a></code>, <code><a href="#topic+estimate">estimate</a></code>, and <code><a href="#topic+forecast">forecast</a></code>, etc. They also have the similar outputs.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> aTSA</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 3.1.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2015-06-19</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2 | GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>For a complete list of functions and dataset, use <code>library(help = aTSA)</code>.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>
<p>Maintainer: Debin Qiu &lt;debinqiu@uga.edu&gt;
</p>


<h3>References</h3>

<p>Engle, Robert F.; Granger, Clive W. J. (1987). Co-integration and error correction: Representation, estimation and testing. <em>Econometrica</em>, 55 (2): 251-276.
</p>
<p>Engle, Robert F. (1982). Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of United Kingdom Inflation. <em>Econometrica</em>, 50 (4): 987-1007.
</p>
<p>Fuller, W. A. (1976). Introduction to Statistical Time Series. New York: John Wiley and Sons.
</p>
<p>Hobijn B, Franses PH and Ooms M (2004). Generalization of the KPSS-test for stationarity. <em>Statistica Neerlandica</em>, vol. 58, p. 482-502.
</p>
<p>Kwiatkowski, D.; Phillips, P. C. B.; Schmidt, P.; Shin, Y. (1992). 
Testing the null hypothesis of stationarity against the alternative of a unit root. <em>Journal of Econometrics</em>, 54 (1-3): 159-178.
</p>
<p>McLeod, A. I. and W. K. Li. Diagnostic Checking ARMA Time Series Models Using Squared-Residual Autocorrelations. <em>Journal of Time Series Analysis</em>. Vol. 4, 1983, pp. 269-27.
</p>
<p>Phillips, P. C. B.; Perron, P. (1988). Testing for a Unit Root in Time Series Regression. <em>Biometrika</em>, 75 (2): 335-346.
</p>

<hr>
<h2 id='coint.test'>Cointegration Test</h2><span id='topic+coint.test'></span>

<h3>Description</h3>

<p>Performs Engle-Granger(or EG) tests for the null hypothesis that two or more
time series, each of which is I(1), are not cointegrated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coint.test(y, X, d = 0, nlag = NULL, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coint.test_+3A_y">y</code></td>
<td>
<p>the response</p>
</td></tr>
<tr><td><code id="coint.test_+3A_x">X</code></td>
<td>
<p>the exogenous input variable of a numeric vector or a matrix.</p>
</td></tr>
<tr><td><code id="coint.test_+3A_d">d</code></td>
<td>
<p>difference operator for both <code>y</code> and <code>X</code>. The default is 0.</p>
</td></tr>
<tr><td><code id="coint.test_+3A_nlag">nlag</code></td>
<td>
<p>the lag order to calculate the test statistics. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="coint.test_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To implement the original EG tests, one first has to fit the linear regression
</p>
<p style="text-align: center;"><code class="reqn">y[t] = \mu + B*X[t] + e[t],</code>
</p>

<p>where <code class="reqn">B</code> is the coefficient vector and <code class="reqn">e[t]</code> is an error term.
With the fitted model, the residuals are obtained, i.e., <code class="reqn">z[t] = y[t] - hat{y}[t]</code>
and a Augmented Dickey-Fuller test is utilized to examine whether the sequence of
residuals <code class="reqn">z[t]</code> is white noise. The null hypothesis of non-cointegration
is equivalent to the null hypothesis that <code class="reqn">z[t]</code> is white noise. See <code><a href="#topic+adf.test">adf.test</a></code>
for more details of Augmented Dickey-Fuller test, as well as the default <code>nlag</code>.
</p>


<h3>Value</h3>

<p>A matrix for test results with three columns (<code>lag</code>, <code>EG</code>, <code>p.value</code>)
and three rows (<code>type1</code>, <code>type2</code>, <code>type3</code>).
Each row is the test results (including lag parameter,
test statistic and p.value) for each type of linear regression models of residuals
<code class="reqn">z[t]</code>. See <code><a href="#topic+adf.test">adf.test</a></code> for more details of three types of linear models.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>MacKinnon, J. G. (1991). Critical values for cointegration tests, Ch. 13 in Long-run
Economic Relationships: Readings in Cointegration, eds. R. F. Engle and C. W. J.
Granger, Oxford, Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adf.test">adf.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(200),100,2)
y &lt;- 0.3*X[,1] + 1.2*X[,2] + rnorm(100)
# test for original y and X
coint.test(y,X)

# test for response = diff(y,differences = 1) and
# input = apply(X, diff, differences = 1)
coint.test(y,X,d = 1)
</code></pre>

<hr>
<h2 id='ecm'>Error Correction Model</h2><span id='topic+ecm'></span>

<h3>Description</h3>

<p>Fits an error correction model for univriate response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecm(y, X, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecm_+3A_y">y</code></td>
<td>
<p>a response of a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="ecm_+3A_x">X</code></td>
<td>
<p>an exogenous input of a numeric vector or a matrix for multivariate time series.</p>
</td></tr>
<tr><td><code id="ecm_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An error correction model captures the short term relationship between the
response <code>y</code> and the exogenous input variable <code>X</code>. The model is defined as
</p>
<p style="text-align: center;"><code class="reqn">dy[t] = bold{\beta}[0]*dX[t] + \beta[1]*ECM[t-1] + e[t],</code>
</p>

<p>where <code class="reqn">d</code> is an operator of the first order difference, i.e.,
<code class="reqn">dy[t] = y[t] - y[t-1]</code>, and <code class="reqn">bold{\beta}[0]</code> is a coefficient vector with the
number of elements being the number of columns of <code>X</code> (i.e., the number
of exogenous input variables), and<code class="reqn"> ECM[t-1] = y[t-1] - hat{y}[t-1]</code> which is the
main term in the sense that its coefficient <code class="reqn">\beta[1]</code> explains the short term
dynamic relationship between <code>y</code> and <code>X</code>
in this model, in which <code class="reqn">hat{y}[t]</code> is estimated from the linear regression model
<code class="reqn">y[t] = bold{\alpha}*X[t] + u[t]</code>. Here, <code class="reqn">e[t]</code> and <code class="reqn">u[t]</code> are both error terms
but from different linear models.
</p>


<h3>Value</h3>

<p>An object with class &quot;<code>lm</code>&quot;, which is the same results of <code><a href="stats.html#topic+lm">lm</a></code> for
fitting linear regression.
</p>


<h3>Note</h3>

<p>Missing values are removed before the analysis. In the results, <code>dX</code> or
<code>dX1</code>, <code>dX2</code>, ... represents the first difference of each exogenous input
variable <code>X</code>, and <code>dy</code> is the first difference of response <code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Engle, Robert F.; Granger, Clive W. J. (1987). Co-integration and error correction:
Representation, estimation and testing. <em>Econometrica</em>, 55 (2): 251-276.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(200),100,2)
y &lt;- 0.1*X[,1] + 2*X[,2] + rnorm(100)
ecm(y,X)
</code></pre>

<hr>
<h2 id='estimate'>Estimate an ARIMA Model</h2><span id='topic+estimate'></span>

<h3>Description</h3>

<p>Estimates an ARIMA model for a univariate time series, including a sparse
ARIMA model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate(x, p = 0, d = 0, q = 0, PDQ = c(0, 0, 0), S = NA,
  method = c("CSS-ML", "ML", "CSS"), intercept = TRUE, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_+3A_x">x</code></td>
<td>
<p>a univariate time series.</p>
</td></tr>
<tr><td><code id="estimate_+3A_p">p</code></td>
<td>
<p>the AR order, can be a positive integer or a vector with several positive
integers. The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_d">d</code></td>
<td>
<p>the degree of differencing. The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_q">q</code></td>
<td>
<p>the MA order, can be a positive integer or a vector with several positive
integers. The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_pdq">PDQ</code></td>
<td>
<p>a vector with three non-negative integers for specification of the seasonal
part of the ARIMA model. The default is <code>c(0,0,0)</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_s">S</code></td>
<td>
<p>the period of seasonal ARIMA model. The default is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_method">method</code></td>
<td>
<p>fitting method. The default is <code>CSS-ML</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_intercept">intercept</code></td>
<td>
<p>a logical value indicating to include the intercept in ARIMA model. The
default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console. The default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="estimate_+3A_...">...</code></td>
<td>
<p>optional arguments to <code><a href="stats.html#topic+arima">arima</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is similar to the ESTIMATE statement in ARIMA procedure of SAS,
except that it does not fit a transfer function model for a univariate time series. The
fitting method is inherited from <code><a href="stats.html#topic+arima">arima</a></code> in <code>stats</code> package. To be
specific, the pure ARIMA(p,q) is defined as
</p>
<p style="text-align: center;"><code class="reqn">X[t] = \mu + \phi[1]*X[t-1] + ... + \phi[p]*X[p] +
             e[t] - \theta[1]*e[t-1] - ... - \theta[q]*e[t-q].</code>
</p>

<p>The <code>p</code> and <code>q</code> can be a vector for fitting a sparse ARIMA model. For example,
<code>p = c(1,3),q = c(1,3)</code> means the ARMA((1,3),(1,3)) model defined as
</p>
<p style="text-align: center;"><code class="reqn">X[t] = \mu + \phi[1]*X[t-1] + \phi[3]*X[t-3] + e[t]
- \theta[1]*e[t-1] - \theta[3]*e[t-3].</code>
</p>
<p> The <code>PDQ</code> controls the
order of seasonal ARIMA model, i.e., ARIMA(p,d,q)x(P,D,Q)(S), where S is the seasonal
period. Note that the difference operators <code>d</code> and D = <code>PDQ</code>[2] are different.
The <code>d</code> is equivalent to <code>diff(x,differences = d)</code> and D is
<code>diff(x,lag = D,differences = S)</code>, where the default seasonal period is
<code>S = frequency(x)</code>.
</p>
<p>The residual diagnostics plots will be drawn.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>estimate</code>&quot; and the same results as
<code><a href="stats.html#topic+arima">arima</a></code>. See <code><a href="stats.html#topic+arima">arima</a></code> for
more details.
</p>


<h3>Note</h3>

<p>Missing values are removed before the estimate. Sparse seasonal
ARIMA(p,d,q)x(P,D,Q)(S) model is not allowed.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Brockwell, P. J. and Davis, R. A. (1996). Introduction to Time Series and Forecasting.
Springer, New York. Sections 3.3 and 8.3.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+arima">arima</a></code>,  <code><a href="#topic+identify">identify</a></code>,  <code><a href="#topic+forecast">forecast</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimate(lh, p = 1) # AR(1) process
estimate(lh, p = 1, q = 1) # ARMA(1,1) process
estimate(lh, p = c(1,3)) # sparse AR((1,3)) process

# seasonal ARIMA(0,1,1)x(0,1,1)(12) model
estimate(USAccDeaths, p = 1, d = 1, PDQ = c(0,1,1))
</code></pre>

<hr>
<h2 id='expsmooth'>Simple Exponential Smoothing</h2><span id='topic+expsmooth'></span>

<h3>Description</h3>

<p>Performs a simple exponential smoothing for univariate time series
with no trend or seasonal pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expsmooth(x, trend = 1, alpha = 0.2, beta = 0.10557, gamma = 0.07168,
  lead = 0, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expsmooth_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="expsmooth_+3A_trend">trend</code></td>
<td>
<p>the type of trend. See details.</p>
</td></tr>
<tr><td><code id="expsmooth_+3A_alpha">alpha</code></td>
<td>
<p>the smoothing parameter for constant component. The default is <code>0.2</code>.</p>
</td></tr>
<tr><td><code id="expsmooth_+3A_beta">beta</code></td>
<td>
<p>the smoothing parameter for linear component. The default is <code>0.10557</code>.</p>
</td></tr>
<tr><td><code id="expsmooth_+3A_gamma">gamma</code></td>
<td>
<p>the smoothing parameter for quadratic component. The default is <code>0.07168</code>.</p>
</td></tr>
<tr><td><code id="expsmooth_+3A_lead">lead</code></td>
<td>
<p>the number of steps ahead for which prediction is required.
The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="expsmooth_+3A_plot">plot</code></td>
<td>
<p>a logical value indicating to print the plot of original data v.s smoothed
data. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simple exponential smoothing is a weighted average between the most recent
observation and the most recent forecasting, with weights <code class="reqn">\alpha</code> and
<code class="reqn">1 - \alpha</code>, respectively. To be precise, the smoothing equation of single exponential
smoothing (constant model, <code>trend = 1</code>) is given by
</p>
<p style="text-align: center;"><code class="reqn">level[t] = \alpha *x[t] + (1 - \alpha)*level[t-1],</code>
</p>

<p>and the forecasting equation is
</p>
<p style="text-align: center;"><code class="reqn">hat{x}[t+1|t] = level[t],</code>
</p>

<p>for <code class="reqn">t = 1,...,n</code>.
The initial value <code class="reqn">level[0] = x[1]</code>. For example, <code class="reqn">hat{x}[1|0] = level[0]</code>,
<code class="reqn">hat{x}[2|1] = level[1]</code>,..., etc.
</p>
<p>Let <code class="reqn">x1[t]</code> be the smoothed values of single exponential smoothing. The double
exponential smoothing (<code>trend = 2</code>, a linear model) is to apply a single
exponential smoothing again to the smoothed sequence <code class="reqn">x1[t]</code>, with a new smoothing
parameter <code>beta</code>. Similarly, we denote the smoothed values of double
exponential smoothing to be <code class="reqn">x2[t]</code>. The triple exponential smoothing
(<code>trend = 3</code>, a quadratic model) is to apply the single exponential smoothing
to the smoothed sequence <code class="reqn">x2[t]</code> with a new smoothing parameter <code>gamma</code>. The
default smoothing parameters (weights) <code>alpha</code>, <code>beta</code>, <code>gamma</code> are
taken from the equation <code>1 - 0.8^{1/trend}</code> respectively, which is similar
to the FORECAST procedure in SAS.
</p>


<h3>Value</h3>

<p>A list with class <code>"es"</code> containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the smoothed values.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>the predicted values when <code>lead</code> &gt; 0.</p>
</td></tr>
<tr><td><code>accurate</code></td>
<td>
<p>the accurate measurements.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Missing values are removed before the analysis.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Winters">Winters</a></code>, <code><a href="#topic+Holt">Holt</a></code>, <code><a href="#topic+MA">MA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
es &lt;- expsmooth(x) # trend = 1: a constant model
plot(x,type = "l")
lines(es$estimate,col = 2)
expsmooth(x,trend = 2) # trend = 2: a linear model
expsmooth(x,trend = 3) # trend = 3: a quadratic model
</code></pre>

<hr>
<h2 id='forecast'>Forecast From ARIMA Fits</h2><span id='topic+forecast'></span>

<h3>Description</h3>

<p>Forecasts from models fitted by <code><a href="stats.html#topic+arima">arima</a></code> or <code><a href="#topic+estimate">estimate</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forecast(object, lead = 1, id = NULL, alpha = 0.05, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forecast_+3A_object">object</code></td>
<td>
<p>the result of an <code>arima</code> or <code>estimate</code> fit.</p>
</td></tr>
<tr><td><code id="forecast_+3A_lead">lead</code></td>
<td>
<p>the number of steps ahead for which prediction is required. The default is
<code>1</code>.</p>
</td></tr>
<tr><td><code id="forecast_+3A_id">id</code></td>
<td>
<p>the id of the observation which is the time. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="forecast_+3A_alpha">alpha</code></td>
<td>
<p>the significant level for constructing the confidence interval of prediction.
The default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="forecast_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is originally from <code><a href="stats.html#topic+predict.Arima">predict.Arima</a></code> in <code>stats</code> package,
but has a nice output
including 100*(1 - <code class="reqn">\alpha</code>)% confidence interval and a prediction plot. It is
similar to FORECAST statement in PROC ARIMA of SAS.
</p>


<h3>Value</h3>

<p>A matrix with <code>lead</code> rows and five columns. Each column represents the number
of steps ahead (<code>Lead</code>), the predicted values (<code>Forecast</code>), the standard errors
(<code>S.E</code>) and the 100*(1 - <code class="reqn">\alpha</code>)% lower bound (<code>Lower</code>) and upper bound
(<code>Upper</code>) of confidence interval.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict.Arima">predict.Arima</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(order = c(3,0,0),ar = c(0.2,0.4,-0.15)),n = 100)
fit &lt;- estimate(x,p = 3) # same as fit &lt;- arima(x,order = c(3,0,0))
forecast(fit,lead = 4)

# forecast with id
t &lt;- as.Date("2014-03-25") + 1:100
forecast(fit,lead = 4, id = t)
</code></pre>

<hr>
<h2 id='Holt'>Holt's Two-parameter Exponential Smoothing</h2><span id='topic+Holt'></span>

<h3>Description</h3>

<p>Performs Holt's two-parameter exponential smoothing for linear
trend or damped trend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Holt(x, type = c("additive", "multiplicative"), alpha = 0.2,
  beta = 0.1057, lead = 0, damped = FALSE, phi = 0.98, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Holt_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="Holt_+3A_type">type</code></td>
<td>
<p>the type of interaction between the level and the linear trend. See
details.</p>
</td></tr>
<tr><td><code id="Holt_+3A_alpha">alpha</code></td>
<td>
<p>the parameter for the level smoothing. The default is <code>0.2</code>.</p>
</td></tr>
<tr><td><code id="Holt_+3A_beta">beta</code></td>
<td>
<p>the parameter for the trend smoothing. The default is <code>0.1057</code>.</p>
</td></tr>
<tr><td><code id="Holt_+3A_lead">lead</code></td>
<td>
<p>the number of steps ahead for which prediction is required.
The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="Holt_+3A_damped">damped</code></td>
<td>
<p>a logical value indicating a damped trend. See details. The default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="Holt_+3A_phi">phi</code></td>
<td>
<p>a smoothing parameter for damped trend. The default is <code>0.98</code>, only valid
for <code>damped = TRUE</code>.</p>
</td></tr>
<tr><td><code id="Holt_+3A_plot">plot</code></td>
<td>
<p>a logical value indicating to print the plot of original data v.s smoothed
data. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Holt's two parameter is used to forecast a time series with trend, but
wihtout seasonal pattern. For the additive model (<code>type = "additive"</code>), the
<code class="reqn">h</code>-step-ahead forecast is given by <code class="reqn">hat{x}[t+h|t] = level[t] + h*b[t]</code>,
where
</p>
<p style="text-align: center;"><code class="reqn">level[t] = \alpha *x[t] + (1-\alpha)*(b[t-1] + level[t-1]),</code>
</p>

<p style="text-align: center;"><code class="reqn">b[t] = \beta*(level[t] - level[t-1]) + (1-\beta)*b[t-1],</code>
</p>

<p>in which <code class="reqn">b[t]</code> is the trend component.
For the multiplicative (<code>type = "multiplicative"</code>) model, the
<code class="reqn">h</code>-step-ahead forecast is given by <code class="reqn">hat{x}[t+h|t] = level[t] + h*b[t]</code>,
where
</p>
<p style="text-align: center;"><code class="reqn">level[t] = \alpha *x[t] + (1-\alpha)*(b[t-1] * level[t-1]),</code>
</p>

<p style="text-align: center;"><code class="reqn">b[t] = \beta*(level[t] / level[t-1]) + (1-\beta)*b[t-1].</code>
</p>

<p>Compared with the Holt's linear trend that displays a constant increasing or
decreasing, the damped trend generated by exponential smoothing method shows a
exponential growth or decline, which is a situation between simple exponential
smoothing (with 0 increasing or decreasing rate) and Holt's two-parameter smoothing.
If <code>damped = TRUE</code>, the additive model becomes
</p>
<p style="text-align: center;"><code class="reqn">hat{x}[t+h|t] = level[t] + (\phi + \phi^{2} + ... + \phi^{h})*b[t],</code>
</p>

<p style="text-align: center;"><code class="reqn">level[t] = \alpha *x[t] + (1-\alpha)*(\phi*b[t-1] + level[t-1]),</code>
</p>

<p style="text-align: center;"><code class="reqn">b[t] = \beta*(level[t] - level[t-1]) + (1-\beta)*\phi*b[t-1].</code>
</p>

<p>The multiplicative model becomes
</p>
<p style="text-align: center;"><code class="reqn">hat{x}[t+h|t] = level[t] *b[t]^(\phi + \phi^{2} + ... + \phi^{h}),</code>
</p>

<p style="text-align: center;"><code class="reqn">level[t] = \alpha *x[t] + (1-\alpha)*(b[t-1]^{\phi} * level[t-1]),</code>
</p>

<p style="text-align: center;"><code class="reqn">b[t] = \beta*(level[t] / level[t-1]) + (1-\beta)*b[t-1]^{\phi}.</code>
</p>

<p>See Chapter 7.4 for more details in R. J. Hyndman and G. Athanasopoulos (2013).
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>Holt</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the estimate values.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the smoothing parameter used for level.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the smoothing parameter used for trend.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>the smoothing parameter used for damped trend.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>the predicted values, only available for <code>lead</code> &gt; 0.</p>
</td></tr>
<tr><td><code>accurate</code></td>
<td>
<p>the accurate measurements.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Missing values are removed before analysis.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>R. J. Hyndman and G. Athanasopoulos, &quot;Forecasting: principles and
practice,&quot; 2013. [Online]. Available: <a href="http://otexts.org/fpp/">http://otexts.org/fpp/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+HoltWinters">HoltWinters</a></code>, <code><a href="#topic+expsmooth">expsmooth</a></code>, <code><a href="#topic+Winters">Winters</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- (1:100)/100
y &lt;- 2 + 1.2*x + rnorm(100)

ho0 &lt;- Holt(y) # with additive interaction
ho1 &lt;- Holt(y,damped = TRUE) # with damped trend

# multiplicative model for AirPassengers data,
# although seasonal pattern exists.
ho2 &lt;- Holt(AirPassengers,type = "multiplicative")
</code></pre>

<hr>
<h2 id='identify'>Identify a Time Series Model</h2><span id='topic+identify'></span>

<h3>Description</h3>

<p>Checks the white noise and stationarity of a univariate time series,
and also identifies an appropriate ARIMA model using AICC criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identify(x, p = NULL, q = NULL, nlag = 6, intercept = TRUE,
  stat.test = FALSE, method = c("adf", "pp", "kpss"), output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identify_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="identify_+3A_p">p</code></td>
<td>
<p>the maximum lag order for AR process. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="identify_+3A_q">q</code></td>
<td>
<p>the maximum lag order for MA process. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="identify_+3A_nlag">nlag</code></td>
<td>
<p>the lag parameter to calculate the Ljung-Box test statistic.
The default is <code>6</code>.</p>
</td></tr>
<tr><td><code id="identify_+3A_intercept">intercept</code></td>
<td>
<p>an intercept to be included in ARIMA model, only valid for
<code>p</code> &gt; 0 or <code>q</code> &gt; 0. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="identify_+3A_stat.test">stat.test</code></td>
<td>
<p>the stationary test for time series, see <code><a href="#topic+stationary.test">stationary.test</a></code> for
more details. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="identify_+3A_method">method</code></td>
<td>
<p>the method of stationary test, only valid for <code>stat.test = TRUE</code>.</p>
</td></tr>
<tr><td><code id="identify_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is similar to IDENTIFY statement in ARIMA procedure of SAS software,
which is to check the white noise and stationarity for a univariate time
series. The white noise check is accomplished by using <code><a href="stats.html#topic+Box.test">Box.test</a></code>
in <code>stats</code> package, with the default method <code>type = "Ljung-Box"</code>.
The stationary check uses the <code><a href="#topic+stationary.test">stationary.test</a></code> implemented in this package.
</p>
<p>The AICC criterion (Burnham and Anderson (2002)) is used to identify an optimal
model which has the minimum AICC value. The AICC is defined as
</p>
<p style="text-align: center;"><code class="reqn">AICC = AIC + 2k(k+1)/(n-k-1),</code>
</p>

<p>where <code class="reqn">AIC = 2k - 2log(Loglik)</code> which is called Akaike information criterion
(Akaike (1974)). Here,
<code class="reqn">k,n</code> are the number of estimated parameters and observations, respectively.
<code class="reqn">Loglik</code> is the maximized value of the likelihood function for the model.
</p>
<p>Four plots are made: plot of original data, ACF plot, PACF plot and p.value of white
noise check.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>identify</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>WNcheck</code></td>
<td>
<p>a matrix with three columns for results of white noise check for each lag.</p>
</td></tr>
<tr><td><code>aicc</code></td>
<td>
<p>the minimum AICC value, only available for <code>p &gt; 0</code> or <code>q &gt; 0</code>.</p>
</td></tr>
<tr><td><code>min.p</code></td>
<td>
<p>the optimal order <code>p</code> for AR process, only available for
<code>p &gt; 0</code> or <code>q &gt; 0</code>.</p>
</td></tr>
<tr><td><code>min.q</code></td>
<td>
<p>the optimal order <code>q</code> for AR process, only available for
<code>p &gt; 0</code> or <code>q &gt; 0</code>.</p>
</td></tr>
<tr><td><code>stnt.test</code></td>
<td>
<p>a list of stationary test results with three components. See
<code><a href="#topic+stationary.test">stationary.test</a></code> for more details.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Missing values are removed before the analysis.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Akaike, H. (1974), &quot;A new look at the statistical model identification&quot;, <em>IEEE
Transactions on Automatic Control</em>, 19 (6): 716-723.
</p>
<p>Box, G. E. P. and Pierce, D. A. (1970), Distribution of residual correlations
in autoregressive-integrated moving average time series models. <em>Journal
of the American Statistical Association</em>, 65, 1509-1526.
</p>
<p>Burnham, K. P.; Anderson, D. R. (2002), Model Selection and Multimodel Inference:
A Practical Information-Theoretic Approach (2nd ed.), Springer-Verlag
</p>
<p>Ljung, G. M. and Box, G. E. P. (1978). On a measure of lack of fit in time series
models. <em>Biometrika</em> 65, 297-303.
</p>
<p>Harvey, A. C. (1993) Time Series Models. 2nd Edition, Harvester Wheatsheaf,
NY, pp. 44, 45.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(order = c(2,0,0),ar = c(0.2,0.4)),n = 100)
identify(x) # white noise check
identify(x,stat.test = TRUE) # white noise and stationarity check
identify(x,p = 3,q = 2) # white noise check and optimal model identification.
</code></pre>

<hr>
<h2 id='kpss.test'>Kwiatkowski-Phillips-Schmidt-Shin Test</h2><span id='topic+kpss.test'></span>

<h3>Description</h3>

<p>Performs Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test for the null
hypothesis that <code>x</code> is a stationary univariate time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kpss.test(x, lag.short = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kpss.test_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="kpss.test_+3A_lag.short">lag.short</code></td>
<td>
<p>a logical value indicating whether the parameter of lag to calculate
the test statistic is a short or long term. The default is a short term. See details.</p>
</td></tr>
<tr><td><code id="kpss.test_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print out the results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test tends to decompose the time
series into the sum of a deterministic trend, a random walk, and a stationary error:
</p>
<p style="text-align: center;"><code class="reqn">x[t] = \alpha*t + u[t] + e[t],</code>
</p>

<p>where <code class="reqn">u[t]</code> satisfies <code class="reqn">u[t] = u[t-1] + a[t]</code>, and <code class="reqn">a[t]</code> are i.i.d
<code class="reqn">(0,\sigma^2)</code>. The null hypothesis is that <code class="reqn">\sigma^2 = 0</code>, which implies
<code>x</code> is a stationary time series. In order to calculate the test statistic,
we consider three types of linear regression models.
The first type (<code>type1</code>) is the one with no drift and deterministic trend,
defined as </p>
<p style="text-align: center;"><code class="reqn">x[t] = u[t] + e[t].</code>
</p>

<p>The second type (<code>type2</code>) is the one with drift but no trend:
</p>
<p style="text-align: center;"><code class="reqn">x[t] = \mu + u[t] + e[t].</code>
</p>

<p>The third type (<code>type3</code>) is the one with both drift and trend:
</p>
<p style="text-align: center;"><code class="reqn">x[t] = \mu + \alpha*t + u[t] + e[t].</code>
</p>

<p>The details of calculation of test statistic (<code>kpss</code>) can be seen in the references
below. The default parameter of lag to calculate the test statistic is
<code class="reqn">max(1,floor(3*sqrt(n)/13)</code> for short term effect, otherwise,
<code class="reqn">max(1,floor(10*sqrt(n)/13)</code> for long term effect.
The p.value is calculated by the interpolation of test statistic from tables of
critical values (Table 5, Hobijn B., Franses PH. and Ooms M (2004)) for a given
sample size <code class="reqn">n</code> = length(<code>x</code>).
</p>


<h3>Value</h3>

<p>A matrix for test results with three columns (<code>lag</code>, <code>kpss</code>,
<code>p.value</code>) and three rows (<code>type1</code>, <code>type2</code>, <code>type3</code>).
Each row is the test results (including lag parameter, test statistic and p.value) for
each type of linear regression models.
</p>


<h3>Note</h3>

<p>Missing values are removed.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Hobijn B, Franses PH and Ooms M (2004). Generalization of the KPSS-test for stationarity.
<em>Statistica Neerlandica</em>, vol. 58, p. 482-502.
</p>
<p>Kwiatkowski, D.; Phillips, P. C. B.; Schmidt, P.; Shin, Y. (1992).
Testing the null hypothesis of stationarity against the alternative of a unit root.
<em>Journal of Econometrics</em>, 54 (1-3): 159-178.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adf.test">adf.test</a></code>, <code><a href="#topic+pp.test">pp.test</a></code>, <code><a href="#topic+stationary.test">stationary.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># KPSS test for AR(1) process
x &lt;- arima.sim(list(order = c(1,0,0),ar = 0.2),n = 100)
kpss.test(x)

# KPSS test for co2 data
kpss.test(co2)
</code></pre>

<hr>
<h2 id='MA'>Moving Average Filter</h2><span id='topic+MA'></span>

<h3>Description</h3>

<p>Applies moving average filter to estimate the linear trend or
nonseasonal pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MA(x, nlag = NULL, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MA_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="MA_+3A_nlag">nlag</code></td>
<td>
<p>the number of period to calculate the average. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="MA_+3A_plot">plot</code></td>
<td>
<p>a logical value indicating to print out the plot. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The moving average filter uses the unweight mean of (2*<code>nlag</code> + 1) adjacent
observations. That is,
</p>
<p style="text-align: center;"><code class="reqn">hat{X}[t] = (X[t - nlag] + ... + X[t] + ...+ X[t + nlag])/(2*nlag + 1)</code>
</p>

<p>for <code class="reqn">nlag &lt; t &lt; n - nlag</code>.
For the values at the boundary <code class="reqn">t \le nlag</code> or <code class="reqn">n - nlag \le t \le n</code>, you can
refer to Equation (7) in Qiu <em>et al.,</em> (2013) for details of calculations.
The default method for choosing the optimal <code>nlag</code> uses the rule-of-thumb
criterion proposed by Qiu, <em>et al</em>., (2013), in which they showed that the moving
average
is a special case of local linear estimator in the sense that the kernel function is the
uniform one, and the moving average period <code>nlag</code> is a function of bandwidth. Thus,
choosing the optimal <code>nlag</code> is equivalent to choosing the optimal bandwidth in local
linear regression.
</p>
<p>The plot of original values v.s fitted values will be displayed if <code>plot = TRUE</code>.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>MA</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the smoothed values.</p>
</td></tr>
<tr><td><code>nlag</code></td>
<td>
<p>the period used to compute the average.</p>
</td></tr>
<tr><td><code>accurate</code></td>
<td>
<p>the accurate measurements.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>D. Qiu, Q. Shao, and L. Yang (2013), Efficient inference for autoregressive
coefficient in the presence of trend. <em>Journal of Multivariate Analysis</em>
114, 40-53.
</p>
<p>P.J. Brockwell, R.A. Davis, Time Series: Theory and Methods, second ed.,
Springer, New York, 1991.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(order = c(1,0,0),ar = 0.4),n = 100)
y &lt;- 5*(1:100)/100 + x
MA(y)

# moving average filter for co2 data
MA(co2)
</code></pre>

<hr>
<h2 id='pp.test'>Phillips-Perron Test</h2><span id='topic+pp.test'></span>

<h3>Description</h3>

<p>Performs the Phillips-Perron test for the null hypothesis of a unit root of
a univariate time series <code>x</code> (equivalently, <code>x</code> is a non-stationary time series).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.test(x, type = c("Z_rho", "Z_tau"), lag.short = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp.test_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="pp.test_+3A_type">type</code></td>
<td>
<p>the type of Phillips-Perron test. The default is <code>Z_rho</code>.</p>
</td></tr>
<tr><td><code id="pp.test_+3A_lag.short">lag.short</code></td>
<td>
<p>a logical value indicating whether the parameter of lag to calculate the
statistic is a short or long term. The default is a short term.</p>
</td></tr>
<tr><td><code id="pp.test_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console. The default
is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compared with the Augmented Dickey-Fuller test, Phillips-Perron test makes
correction to the test statistics and is robust to the unspecified autocorrelation
and heteroscedasticity in the errors. There are two types of test statistics,
<code class="reqn">Z_{\rho}</code> and <code class="reqn">Z_{\tau}</code>, which have the same asymptotic distributions
as Augmented Dickey-Fuller test statistic, <code>ADF</code>. The calculations of each type
of the Phillips-Perron test can be see in the reference below. If the
<code>lag.short = TRUE</code>, we use the default number of Newey-West lags
<code class="reqn">floor(4*(length(x)/100)^0.25)</code>,
otherwise <code class="reqn">floor(12*(length(x)/100)^0.25)</code> to calculate the test statistics.
In order to calculate the test statistic, we consider
three types of linear regression models. The first type (<code>type1</code>) is the one
with no drift and linear trend with respect to time:
</p>
<p style="text-align: center;"><code class="reqn">x[t] = \rho*x[t-1] + e[t],</code>
</p>

<p>where <code class="reqn">e[t]</code> is an error term.
The second type (<code>type2</code>) is the one with drift but no linear trend:
</p>
<p style="text-align: center;"><code class="reqn">x[t] = \mu + \rho*x[t-1] + e[t].</code>
</p>

<p>The third type (type3) is the one with both drift and linear trend:
</p>
<p style="text-align: center;"><code class="reqn">x[t] = \mu + \alpha*t + \rho*x[t-1] + e[t].</code>
</p>

<p>The p.value is calculated by the interpolation of test statistics from the critical values
tables (Table 10.A.1 for <code>Z_rho</code> and 10.A.2 for <code>Z_tau</code> in Fuller (1996))
with a given sample size <code class="reqn">n</code> = length(<code>x</code>).
</p>


<h3>Value</h3>

<p>A matrix for test results with three columns (<code>lag</code>,<code>Z_rho</code>
or <code>Z_tau</code>, <code>p.value</code>) and three rows (<code>type1</code>, <code>type2</code>, <code>type3</code>).
Each row is the test results (including lag parameter, test statistic and p.value) for
each type of linear equation.
</p>


<h3>Note</h3>

<p>Missing values are removed.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>Phillips, P. C. B.; Perron, P. (1988). Testing for a Unit Root in Time Series Regression.
<em>Biometrika</em>, 75 (2): 335-346.
</p>
<p>Fuller, W. A. (1996). Introduction to statistical time series, second ed., Wiley, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adf.test">adf.test</a></code>, <code><a href="#topic+kpss.test">kpss.test</a></code>, <code><a href="#topic+stationary.test">stationary.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># PP test for ar(1) process
x &lt;- arima.sim(list(order = c(1,0,0),ar = 0.2),n = 100)
pp.test(x)

# PP test for co2 data
pp.test(co2)
</code></pre>

<hr>
<h2 id='stationary.test'>Stationary Test for Univariate Time Series</h2><span id='topic+stationary.test'></span>

<h3>Description</h3>

<p>Performs stationary test for a univariate time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stationary.test(x, method = c("adf", "pp", "kpss"), nlag = NULL,
  type = c("Z_rho", "Z_tau"), lag.short = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stationary.test_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="stationary.test_+3A_method">method</code></td>
<td>
<p>a character indicating which test to use. The default is
<code>"adf"</code> by Augmented Dickey-Fuller test.</p>
</td></tr>
<tr><td><code id="stationary.test_+3A_nlag">nlag</code></td>
<td>
<p>the lag order to calculate the test statistic, only valid for
<code>method = "adf"</code>. See <code><a href="#topic+adf.test">adf.test</a></code> for more details.</p>
</td></tr>
<tr><td><code id="stationary.test_+3A_type">type</code></td>
<td>
<p>the test type, only valid for <code>method = "pp"</code>.
See <code><a href="#topic+pp.test">pp.test</a></code> for more details.</p>
</td></tr>
<tr><td><code id="stationary.test_+3A_lag.short">lag.short</code></td>
<td>
<p>a logical value, only valid for <code>method = "pp"</code> or <code>"kpss"</code>.
See <code><a href="#topic+pp.test">pp.test</a></code> and <code><a href="#topic+kpss.test">kpss.test</a></code> for more details.</p>
</td></tr>
<tr><td><code id="stationary.test_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console.
The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function combines the existing functions <code><a href="#topic+adf.test">adf.test</a></code>,
<code><a href="#topic+pp.test">pp.test</a></code> and
<code><a href="#topic+kpss.test">kpss.test</a></code> for testing the stationarity of a univariate time series <code>x</code>.
</p>


<h3>Value</h3>

<p>The results are the same as one of the <code><a href="#topic+adf.test">adf.test</a></code>, <code><a href="#topic+pp.test">pp.test</a></code>,
<code><a href="#topic+kpss.test">kpss.test</a></code>, depending on which test are used.
</p>


<h3>Note</h3>

<p>Missing values are removed.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(order = c(1,0,0),ar = 0.2),n = 100)
stationary.test(x)  # same as adf.test(x)
stationary.test(x, method = "pp") # same as pp.test(x)
stationary.test(x, method = "kpss") # same as kpss.test(x)
</code></pre>

<hr>
<h2 id='stepar'>Stepwise Autoregressive Model</h2><span id='topic+stepar'></span>

<h3>Description</h3>

<p>Fit a stepwise autoregressive model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepar(y, xreg = NULL, trend = c("linear", "quadratic", "constant"),
  order = NULL, lead = 0, newx = NULL, output = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepar_+3A_y">y</code></td>
<td>
<p>a numeric vector of response</p>
</td></tr>
<tr><td><code id="stepar_+3A_xreg">xreg</code></td>
<td>
<p>a numeric vector or matrix of exogenous input variables. The default is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="stepar_+3A_trend">trend</code></td>
<td>
<p>the type of trend with respective to time. The default is <code>linear</code>.</p>
</td></tr>
<tr><td><code id="stepar_+3A_order">order</code></td>
<td>
<p>the order to fit the AR model for residuals. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="stepar_+3A_lead">lead</code></td>
<td>
<p>the number of steps ahead for which prediction is required.
The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="stepar_+3A_newx">newx</code></td>
<td>
<p>a matrix of new data of <code>xreg</code> for predictions. The default is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="stepar_+3A_output">output</code></td>
<td>
<p>a logical value indicating to print the results in R console. The default is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="stepar_+3A_...">...</code></td>
<td>
<p>additional arguments for <code><a href="stats.html#topic+ar">ar</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The stewise autoregressive model uses a two-stage procedure to fit time series.
The first stage is to fit a (<code>constant</code>,<code>linear</code>,<code>quadratic</code>)
model with respective to time sequence:
<code class="reqn">t = (1:n)/n</code>, where <code class="reqn">n = length(y)</code>. If <code>xreg</code> is supplied,
the fitted model is updated by
</p>
<p style="text-align: center;"><code class="reqn">y = \mu + \beta*xreg + e[t] </code>
</p>

<p>for <code>trend = "constant"</code>, and
</p>
<p style="text-align: center;"><code class="reqn">y = \mu + \beta*xreg + \alpha*t + e[t]</code>
</p>

<p>for <code>trend = "linear"</code>, and
</p>
<p style="text-align: center;"><code class="reqn">y = \mu + \beta*xreg + \alpha[1]*t + \alpha[2]*t^2 + e[t]</code>
</p>

<p>for <code>trend = "quadratic"</code>.
The second stage is to fit an autoregressive process to the residuals of the fitted
model obtained in the first stage, which is accomplished by using <code><a href="stats.html#topic+ar">ar</a></code> function
in <code>stats</code> package.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>stepar</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>coef</code></td>
<td>
<p>a estimated coefficient matrix including the t-test results.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the square root of the estimated variance of the random error.</p>
</td></tr>
<tr><td><code>R.squared</code></td>
<td>
<p>the R^2 for fitted model in the first stage.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>the predictions, only available for <code>lead</code> &gt; 0.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If <code>lead</code> &gt; 0 and <code>xreg</code> is supplied, <code>newx</code> must also be
supplied in order to make a prediction. The <code>newx</code> must be a matrix with
the same number of columns as <code>xreg</code> and the number of rows being
equal to <code>lead</code>. The predictions should be used with cautions.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 5*(1:100)/100
x &lt;- x + arima.sim(list(order = c(1,0,0),ar = 0.4),n = 100)
stepar(x)
stepar(x,order = 1)

# with xreg supplied
X &lt;- matrix(rnorm(200),100,2)
y &lt;- 0.1*X[,1] + 1.2*X[,2] + rnorm(100)
stepar(y,X)
# make a prediction with lead = 1; used with caution.
newdat1 &lt;- matrix(rnorm(2),nrow = 1)
fit1 &lt;- stepar(y,X,lead = 1,newx = newdat1,output = FALSE)
# make a prediction with lead = 2; used with caution.
newdat2 &lt;- matrix(rnorm(4),nrow = 2)
fit2 &lt;- stepar(y,X,lead = 2,newx = newdat2,output = FALSE)
</code></pre>

<hr>
<h2 id='trend.test'>Trend Test</h2><span id='topic+trend.test'></span>

<h3>Description</h3>

<p>Performs an approximate Cox-Stuart or Difference-Sign trend test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trend.test(x, method = c("cox.stuart", "diff.sign"), plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trend.test_+3A_x">x</code></td>
<td>
<p>a numeric vector or univariate time series.</p>
</td></tr>
<tr><td><code id="trend.test_+3A_method">method</code></td>
<td>
<p>test method. The default is <code>method = "cox.stuart"</code>.</p>
</td></tr>
<tr><td><code id="trend.test_+3A_plot">plot</code></td>
<td>
<p>a logical value indicating to display the plot of data.
The default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cox-Stuart or Difference-Sign test is used to test whether the data have a
increasing or decreasing trend. They are useful to detect the linear or nonlinear trend.
The Cox-Stuart test is constructed as follows.
For the given data <code class="reqn">x[1],...,x[t]</code>, one can divide them into two sequences with
equal number of observations cutted in the midpoint and then take the paired difference,
i.e., <code class="reqn">D = x[i] - x[i+c], i = 1, ..., floor(n/2)</code>, where <code class="reqn">c</code> is the index of
midpoint. Let <code class="reqn">S</code> be the number of positive or negative values in <code class="reqn">D</code>. Under the
null hypothesis that data have no trend, for large <code class="reqn">n</code> = length(x), <code class="reqn">S</code> is
approximately distributed as <code class="reqn">N(n/2,n/4)</code>, such that one can immediately obtain
the p value. The exact Cox-Stuart trend test can be seen in <code>cs.test</code> of
<code>snpar</code> package.
</p>
<p>The Difference-Sign test is constructed as the similar way as Cox-Stuart test. We first
let <code class="reqn">D = x[i] - x[i - 1]</code> for <code class="reqn">i = 2, ..., n</code> and then
count the number of positive or negative values in <code class="reqn">D</code>, defined as <code class="reqn">S</code>.
Under the null hypothesis, <code class="reqn">S</code> is approximately distributed as
<code class="reqn">N((n-1)/2,(n+1)/12)</code>. Thus, p-value can be calculated based on the null distribution.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>htest</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the type of test applied.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic with a name describing it.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Missing values are removed.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>D.R. Cox and A. Stuart (1955). Some quick sign tests for trend in location
and dispersion. <em>Biometrika</em>, Vol. 42, pp. 80-95.
</p>
<p>P.J. Brockwell, R.A. Davis, Time Series: Theory and Methods, second ed.,
Springer, New York, 1991. (p. 37)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
trend.test(x,plot = TRUE) # no trend

x &lt;- 5*(1:100)/100
x &lt;- x + arima.sim(list(order = c(1,0,0),ar = 0.4),n = 100)
trend.test(x,plot = TRUE) # increasing trend
</code></pre>

<hr>
<h2 id='ts.diag'>Diagnostics for ARIMA fits</h2><span id='topic+ts.diag'></span>

<h3>Description</h3>

<p>Performs diagnostics for ARIMA model fitted by <code><a href="stats.html#topic+arima">arima</a></code> or
<code><a href="#topic+estimate">estimate</a></code> with output of diagnostic plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ts.diag(object, lag.seq = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ts.diag_+3A_object">object</code></td>
<td>
<p>the result of an <code>arima</code> or <code>estimate</code> fit.</p>
</td></tr>
<tr><td><code id="ts.diag_+3A_lag.seq">lag.seq</code></td>
<td>
<p>the sequence of lag to calculate the Ljung-Box test statistics. The default
is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is similar to <code><a href="#topic+ts.diag">ts.diag</a></code> in <code>stats</code> package, but with
one more diagnostic plot for the normality of residuals. Also, the default sequence of lags
for a Ljung-Box test is set to be <code>seq(4,24,by = 4)</code> if sample size <code class="reqn">n &gt; 24</code>,
otherwise <code>seq(1,n,4)</code>. This function has been automatically implemented in
<code><a href="#topic+estimate">estimate</a></code> function.
</p>
<p>Diagnostics are plotted, including the ACF plot, PACF plot, p.value of
white noise checking plot, and Q-Q plot for residuals.
</p>


<h3>Value</h3>

<p>A matrix for the result of white noise checking by Ljung-Box test.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- arima.sim(list(order = c(3,0,0),ar = c(0.2,0.4,-0.15)),n = 100)
fit &lt;- estimate(x,p = 3) # same as fit &lt;- arima(x,order = c(3,0,0))
ts.diag(fit)
</code></pre>

<hr>
<h2 id='Winters'>Winters Three-parameter Smoothing</h2><span id='topic+Winters'></span>

<h3>Description</h3>

<p>Performs Winters three-parameter smoothing for a univariate time series
with seasonal pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Winters(x, period = NULL, trend = 2, lead = 0, plot = TRUE,
  seasonal = c("additive", "multiplicative"), damped = FALSE, alpha = 0.2,
  beta = 0.1057, gamma = 0.07168, phi = 0.98, a.start = NA,
  b.start = NA, c.start = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Winters_+3A_x">x</code></td>
<td>
<p>a univariate time series.</p>
</td></tr>
<tr><td><code id="Winters_+3A_period">period</code></td>
<td>
<p>seasonal period. The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_trend">trend</code></td>
<td>
<p>the type of trend component, can be one of 1,2,3 which represents constant,
linear and quadratic trend, respectively. The default is <code>trend = 2</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_lead">lead</code></td>
<td>
<p>the number of steps ahead for which prediction is required.
The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_plot">plot</code></td>
<td>
<p>a logical value indicating to display the smoothed graph. The default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_seasonal">seasonal</code></td>
<td>
<p>character string to select an &quot;<code>additive</code>&quot; or &quot;<code>multiplicative</code>&quot;
seasonal model. The default is &quot;<code>additive</code>&quot;.</p>
</td></tr>
<tr><td><code id="Winters_+3A_damped">damped</code></td>
<td>
<p>a logical value indicating to include the damped trend, only valid for
<code>trend = 2</code>. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_alpha">alpha</code></td>
<td>
<p>the parameter of level smoothing. The default is <code>0.2</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_beta">beta</code></td>
<td>
<p>the parameter of trend smoothing. The default is <code>0.1057</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_gamma">gamma</code></td>
<td>
<p>the parameter of season smoothing. The default is <code>0.07168</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_phi">phi</code></td>
<td>
<p>the parameter of damped trend smoothing, only valid for <code>damped = TRUE</code>.
The default is <code>0.98</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_a.start">a.start</code></td>
<td>
<p>the starting value for level smoothing. The default is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_b.start">b.start</code></td>
<td>
<p>the starting value for trend smoothing. The default is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="Winters_+3A_c.start">c.start</code></td>
<td>
<p>the starting value for season smoothing. The default is <code>NA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Winters filter is used to decompose the trend and seasonal components by
updating equations. This is similar to the function <code><a href="stats.html#topic+HoltWinters">HoltWinters</a></code> in
<code>stats</code> package but may be in different perspective. To be precise, it uses the
updating equations similar to exponential
smoothing to fit the parameters for the following models when
<code>seasonal = "additive"</code>.
If the trend is constant (<code>trend = 1</code>):
</p>
<p style="text-align: center;"><code class="reqn">x[t] = a[t] + s[t] + e[t].</code>
</p>

<p>If the trend is linear (<code>trend = 2</code>):
</p>
<p style="text-align: center;"><code class="reqn">x[t] = (a[t] + b[t]*t) + s[t] + e[t].</code>
</p>

<p>If the trend is quadratic (<code>trend = 3</code>):
</p>
<p style="text-align: center;"><code class="reqn">x[t] = (a[t] + b[t]*t + c[t]*t^2) + s[t] + e[t].</code>
</p>

<p>Here <code class="reqn">a[t],b[t],c[t]</code> are the trend parameters, <code class="reqn">s[t]</code> is the seasonal
parameter for the
season corresponding to time <code class="reqn">t</code>.
For the multiplicative season, the models are as follows.
If the trend is constant (<code>trend = 1</code>):
</p>
<p style="text-align: center;"><code class="reqn">x[t] = a[t] * s[t] + e[t].</code>
</p>

<p>If the trend is linear (<code>trend = 2</code>):
</p>
<p style="text-align: center;"><code class="reqn">x[t] = (a[t] + b[t]*t) * s[t] + e[t].</code>
</p>

<p>If the trend is quadratic (<code>trend = 3</code>):
</p>
<p style="text-align: center;"><code class="reqn">x[t] = (a[t] + b[t]*t + c[t]*t^2) * s[t] + e[t].</code>
</p>

<p>When <code>seasonal = "multiplicative"</code>, the updating equations for each parameter can
be seen in page 606-607 of PROC FORECAST document of SAS. Similarly, for the
additive seasonal model, the 'division' (/) for <code class="reqn">a[t]</code> and <code class="reqn">s[t]</code> in page 606-607
is changed to 'minus' (-).
</p>
<p>The default starting values for <code class="reqn">a,b,c</code> are computed by a time-trend regression over
the first cycle of time series. The default starting values for the seasonal factors are
computed from seasonal averages. The default smoothing parameters (weights) <code>alpha,
beta, gamma</code> are taken from the equation <code>1 - 0.8^{1/trend}</code> respectively. You can
also use the <code><a href="stats.html#topic+HoltWinters">HoltWinters</a></code> function to get the optimal smoothing parameters
and plug them back in this function.
</p>
<p>The prediction equation is <code class="reqn">x[t+h] = (a[t] + b[t]*t)*s[t+h]</code> for <code>trend = 2</code> and
<code>seasonal = "additive"</code>. Similar equations can be derived for the other options. When
the <code>damped = TRUE</code>, the prediction equation is
<code class="reqn">x[t+h] = (a[t] + (\phi + ... + \phi^(h))*b[t]*t)*s[t+h]</code>. More details can be
referred to R. J. Hyndman and G. Athanasopoulos (2013).
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>Winters</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>season</code></td>
<td>
<p>the seasonal factors.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the smoothed values.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>the prediction, only available with <code>lead</code> &gt; 0.</p>
</td></tr>
<tr><td><code>accurate</code></td>
<td>
<p>the accurate measurements.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The sum of seasonal factors is equal to the seasonal period. This restriction is
to ensure the identifiability of seasonality in the models above.
</p>


<h3>Author(s)</h3>

<p>Debin Qiu
</p>


<h3>References</h3>

<p>P. R. Winters (1960) Forecasting sales by exponentially weighted moving averages,
<em>Management Science</em> 6, 324-342.
</p>
<p>R. J. Hyndman and G. Athanasopoulos, &quot;Forecasting: principles and practice,&quot; 2013.
[Online]. Available: <a href="http://otexts.org/fpp/">http://otexts.org/fpp/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+HoltWinters">HoltWinters</a></code>, <code><a href="#topic+Holt">Holt</a></code>, <code><a href="#topic+expsmooth">expsmooth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Winters(co2)

Winters(AirPassengers, seasonal = "multiplicative")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
