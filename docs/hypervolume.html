<!DOCTYPE html><html lang="en"><head><title>Help for package hypervolume</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hypervolume}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#hypervolume-package'>
<p>High Dimensional Geometry, Set Operations, Projection, and</p>
Inference Using Kernel Density Estimation, Support Vector
Machines, and Convex Hulls</a></li>
<li><a href='#acacia_pinus'>
<p>Data for Acacia and Pinus tree distributions</p></a></li>
<li><a href='#circles'>
<p>Circles simulated dataset</p></a></li>
<li><a href='#copy_param_hypervolume'>
<p>Generate hypervolumes using pre-existing parameters</p></a></li>
<li><a href='#estimate_bandwidth'>
<p>Kernel bandwidth estimators for hypervolumes</p></a></li>
<li><a href='#expectation_ball'>
<p>Hypersphere expectation</p></a></li>
<li><a href='#expectation_box'>
<p>Hyperbox expectation</p></a></li>
<li><a href='#expectation_convex'>
<p>Convex expectation</p></a></li>
<li><a href='#expectation_maximal'>
<p>Maximal expectation</p></a></li>
<li><a href='#find_optimal_occupancy_thin'>
<p>Find optimal parameters to calculate occupancy</p></a></li>
<li><a href='#get_centroid'>
<p>Get centroid of hypervolume or hypervolume list</p></a></li>
<li><a href='#get_centroid_weighted'>
<p>Get weighted centroid of hypervolume or hypervolume list</p></a></li>
<li><a href='#get_occupancy_intersection_bootstrap'>
<p>Volume of the intersection of a bootstrapped occupancy object</p></a></li>
<li><a href='#get_occupancy_stats'>
<p>Stats from occupancy objects</p></a></li>
<li><a href='#get_occupancy_unshared_bootstrap'>
<p>Volume of the unshared fraction of a bootstrapped occupancy object</p></a></li>
<li><a href='#get_occupancy_volume_bootstrap'>
<p>Extract the volume from occupancy bootstrap objects</p></a></li>
<li><a href='#get_relative_volume'>
<p>Extract the relative volume</p></a></li>
<li><a href='#get_volume'>
<p>Extract volume</p></a></li>
<li><a href='#hypervolume'>
<p>Hypervolume construction methods</p></a></li>
<li><a href='#hypervolume_box'>
<p>Hypervolume construction via hyperbox kernel density estimation</p></a></li>
<li><a href='#hypervolume_distance'>
<p>Distance between two hypervolumes</p></a></li>
<li><a href='#hypervolume_distance_point'>
<p>Distance from a point to the margin of a hypervolume.</p></a></li>
<li><a href='#hypervolume_estimate_probability'>
<p>Estimate probability a given location</p></a></li>
<li><a href='#hypervolume_funnel'>
<p>Hypervolumes at different sample sizes</p></a></li>
<li><a href='#hypervolume_gaussian'>
<p>Hypervolume construction via Gaussian kernel density estimation</p></a></li>
<li><a href='#hypervolume_general_model'>
<p>Generates hypervolume by sampling from arbitrary model object.</p></a></li>
<li><a href='#hypervolume_holes'>
<p>Hole detection</p></a></li>
<li><a href='#hypervolume_inclusion_test'>
<p>Inclusion test</p></a></li>
<li><a href='#hypervolume_join'>
<p>Concatenate hypervolumes</p></a></li>
<li><a href='#hypervolume_n_occupancy'>
<p>Operations for groups of hypervolumes</p></a></li>
<li><a href='#hypervolume_n_occupancy_permute'>
<p>Hypervolumes through permuting labels of n pairwise groups of hypervolumes</p></a></li>
<li><a href='#hypervolume_n_occupancy_test'>
<p>Significance of random points occupancy</p></a></li>
<li><a href='#hypervolume_n_resample'>
<p>Bootstrap n hypervolumes</p></a></li>
<li><a href='#hypervolume_overlap_confidence'>
<p>Confidence intervals for overlap statistics</p></a></li>
<li><a href='#hypervolume_overlap_statistics'>
<p>Overlap statistics for set operations (Sorensen, Jaccard, etc.)</p></a></li>
<li><a href='#hypervolume_overlap_test'>
<p>Null distribution for overlap statistics</p></a></li>
<li><a href='#hypervolume_permute'>
<p>Hypervolumes through permuting data of two hypervolumes</p></a></li>
<li><a href='#hypervolume_project'>
<p>Geographical projection of hypervolume for species distribution modeling, using the hypervolume as the environmental niche model.</p></a></li>
<li><a href='#hypervolume_prune'>
<p>Removes small hypervolumes from a HypervolumeList</p></a></li>
<li><a href='#hypervolume_redundancy'>
<p>Redundancy of a point in a hypervolume</p></a></li>
<li><a href='#hypervolume_resample'>
<p>Hypervolume resampling methods</p></a></li>
<li><a href='#hypervolume_save_animated_gif'>
<p>Saves animated GIF of three-dimensional hypervolume plot.</p></a></li>
<li><a href='#hypervolume_segment'>
<p>Segments a hypervolume into multiple separate hypervolumes.</p></a></li>
<li><a href='#hypervolume_set'>
<p>Set operations (intersection / union / unique components)</p></a></li>
<li><a href='#hypervolume_set_n_intersection'>
<p>Multi-way set intersection</p></a></li>
<li><a href='#hypervolume_set_n_union'>
<p>Multi-way set union</p></a></li>
<li><a href='#hypervolume_svm'>
<p>Hypervolume construction via one-class support vector machine (SVM) learning model</p></a></li>
<li><a href='#hypervolume_thin'>
<p>Reduces the number of random points in a hypervolume</p></a></li>
<li><a href='#hypervolume_threshold'>
<p>Thresholds hypervolume and calculates volume quantile statistics (empirical cumulative distribution function)</p></a></li>
<li><a href='#hypervolume_to_data_frame'>
<p>Convert hypervolumes to <code>data.frame</code></p></a></li>
<li><a href='#hypervolume_variable_importance'>
<p>Hypervolume variable importance</p></a></li>
<li><a href='#Hypervolume-class'><p>Class <code>"Hypervolume"</code></p></a></li>
<li><a href='#HypervolumeList-class'><p>Class <code>"HypervolumeList"</code></p></a></li>
<li><a href='#morphSnodgrassHeller'>
<p>Morphological data for Darwin's finches</p></a></li>
<li><a href='#occupancy_bootstrap_gof'>
<p>Goodness of fit metrics for bootstrapped occupancy objects</p></a></li>
<li><a href='#occupancy_filter'>
<p>Subset occupancy hypervolumes</p></a></li>
<li><a href='#occupancy_to_intersection'>
<p>Get the intersection of an occupancy object</p></a></li>
<li><a href='#occupancy_to_union'>
<p>Union of hypervolumes from an occupancy object</p></a></li>
<li><a href='#occupancy_to_unshared'>
<p>Unshared fraction from an occupancy object</p></a></li>
<li><a href='#padded_range'>
<p>Generates axis-wise range limits with padding</p></a></li>
<li><a href='#plot.HypervolumeList'>
<p>Plot a hypervolume or list of hypervolumes</p></a></li>
<li><a href='#print.Hypervolume'>
<p>Print summary of hypervolume</p></a></li>
<li><a href='#quercus'>
<p>Data and demo for Quercus (oak) tree distributions</p></a></li>
<li><a href='#summary.Hypervolume'>
<p>Summary of hypervolume</p></a></li>
<li><a href='#to_hv_list'>
<p>Read hypervolumes from directory</p></a></li>
<li><a href='#weight_data'>
<p>Abundance weighting and prior  of data for hypervolume input</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>High Dimensional Geometry, Set Operations, Projection, and
Inference Using Kernel Density Estimation, Support Vector
Machines, and Convex Hulls</td>
</tr>
<tr>
<td>Version:</td>
<td>3.1.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-17</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimates the shape and volume of high-dimensional datasets and performs set operations: intersection / overlap, union, unique components, inclusion test, and hole detection. Uses stochastic geometry approach to high-dimensional kernel density estimation, support vector machine delineation, and convex hull generation. Applications include modeling trait and niche hypervolumes and species distribution modeling.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>Rcpp, methods, R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, progress</td>
</tr>
<tr>
<td>Imports:</td>
<td>raster, maps, MASS, geometry, ks, hitandrun, pdist,
fastcluster, compiler, e1071, progress, mvtnorm, data.table,
terra, sp, foreach, doParallel, parallel, ggplot2, pbapply,
palmerpenguins, purrr, dplyr, caret</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rgl, magick, alphahull, knitr, rmarkdown, gridExtra</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bblonder/hypervolume">https://github.com/bblonder/hypervolume</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bblonder/hypervolume/issues">https://github.com/bblonder/hypervolume/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-17 19:48:18 UTC; benjaminblonder</td>
</tr>
<tr>
<td>Author:</td>
<td>Benjamin Blonder [aut, cre],
  Cecina Babich Morrow [aut],
  Stuart Brown [aut],
  Gregoire Butruille [aut],
  Daniel Chen [aut],
  Alex Laini [aut],
  David J. Harris [aut],
  Clement Violet [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Benjamin Blonder &lt;benjamin.blonder@berkeley.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-17 20:50:16 UTC</td>
</tr>
</table>
<hr>
<h2 id='hypervolume-package'>
High Dimensional Geometry, Set Operations, Projection, and
Inference Using Kernel Density Estimation, Support Vector
Machines, and Convex Hulls
</h2><span id='topic+hypervolume-package'></span>

<h3>Description</h3>

<p>Estimates the shape and volume of high-dimensional datasets and performs set operations: intersection / overlap, union, unique components, inclusion test, and hole detection. Uses stochastic geometry approach to high-dimensional kernel density estimation, support vector machine delineation, and convex hull generation. Applications include modeling trait and niche hypervolumes and species distribution modeling.
</p>


<h3>Details</h3>

<p>A frequently asked questions document (FAQ) can be found at http://www.benjaminblonder.org/hypervolume_faq.html. More details are also available in a user guide within our 2018 paper (see reference below).
</p>


<h3>Author(s)</h3>

<p>Benjamin Blonder [aut, cre],
  Cecina Babich Morrow [aut],
  Stuart Brown [aut],
  Gregoire Butruille [aut],
  Daniel Chen [aut],
  Alex Laini [aut],
  David J. Harris [aut],
  Clement Violet [aut]
</p>
<p>Maintainer: Benjamin Blonder &lt;benjamin.blonder@berkeley.edu&gt;
</p>


<h3>References</h3>

<p>Blonder, B., Lamanna, C., Violle, C. and Enquist, B. J. (2014), The n-dimensional hypervolume. Global Ecology and Biogeography, 23: 595-609. doi: 10.1111/geb.12146
</p>
<p>Blonder, B. Do Hypervolumes Have Holes?, The American Naturalist, 187(4) E93-E105. doi: 10.1086/685444
</p>
<p>Blonder, B., Morrow, C.B., Maitner, B., et al. New approaches for delineating n-dimensional hypervolumes. Methods Ecol Evol. 2018;9:305-319. doi: 10.1111/2041-210X.12865
</p>

<hr>
<h2 id='acacia_pinus'>
Data for Acacia and Pinus tree distributions
</h2><span id='topic+acacia_pinus'></span>

<h3>Description</h3>

<p>Data for occurrences of Acacia and Pinus species based on geographic observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(acacia_pinus)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 37845 observations on the following 3 variables.
</p>

<dl>
<dt><code>Species</code></dt><dd><p>a <code>character</code> containing 139 unique values</p>
</dd>
<dt><code>Latitude</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Longitude</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Occurrence data come from the BIEN database (<code>https://biendata.org/</code>).
</p>


<h3>References</h3>

<p>Blonder, B., Lamanna, C., Violle, C., Enquist, B. The n-dimensional hypervolume. Global Ecology and Biogeography (2014).
</p>

<hr>
<h2 id='circles'>
Circles simulated dataset
</h2><span id='topic+circles'></span>

<h3>Description</h3>

<p>Data generated by picking 100 points randomly within a circle of radius 1. See the vignette on occupancy for information about its usage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(circles)</code></pre>


<h3>Format</h3>

<p>A <code>list</code> with 20 objects of class <code>matrix</code>. Each <code>matrix</code> contains 100 rows and 2 columns.
</p>

<dl>
<dt><code>[,1]</code></dt><dd><p>x coordinate</p>
</dd>
<dt><code>[,2]</code></dt><dd><p>y coordinate</p>
</dd>
</dl>


<hr>
<h2 id='copy_param_hypervolume'>
Generate hypervolumes using pre-existing parameters
</h2><span id='topic+copy_param_hypervolume'></span>

<h3>Description</h3>

<p><code>copy_param_hypervolume</code> takes in a hypervolume and data. After detecting the method used to generate the input hypervolume, the function returns a new hypervolume generated from the data using the same method and parameters as the input hypervolume. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copy_param_hypervolume(hv, data, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copy_param_hypervolume_+3A_hv">hv</code></td>
<td>

<p>hypervolume object
</p>
</td></tr>
<tr><td><code id="copy_param_hypervolume_+3A_data">data</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="copy_param_hypervolume_+3A_name">name</code></td>
<td>

<p>String name of hypervolume
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>copy_param_hypervolume</code> only works if the input hypervolume was generated using <code>method = "box"</code>, <code>method = "gaussian"</code>, or <code>method = "svm"</code>. Calling this function on hypervolumes generated from <code>hypervolume_set</code> will result in an error. 
Note that <code>kde.bandwidth</code> is affected by size of the data and will be re-estimated using whichever method was used to generate the original bandwidth if <code>method = "gaussian"</code> or <code>method = "box"</code>.
Use <code>hv@Parameters</code> to see what parameters are copied from the input hypervolume.
</p>


<h3>Value</h3>

<p>hypervolume object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(palmerpenguins)
data("penguins")
bill_data = na.omit(penguins[,3:4])
hv = hypervolume(data = bill_data, 
                  method = "gaussian", 
                  quantile.requested = .9, 
                  quantile.requested.type = "volume")

# Generates a new hypervolume using the same hypervolume and data
hv_copy = copy_param_hypervolume(hv, hv@Data)
# Check to see that the information of the two hypervolumes is the same
print(hv)
print(hv_copy)

## End(Not run)
</code></pre>

<hr>
<h2 id='estimate_bandwidth'>
Kernel bandwidth estimators for hypervolumes
</h2><span id='topic+estimate_bandwidth'></span>

<h3>Description</h3>

<p>Estimates bandwidth vector from data using multiple approaches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_bandwidth(data,method="silverman",value=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_bandwidth_+3A_data">data</code></td>
<td>

<p>m x n matrix or data frame, where m is the number of observations and n the number of dimensions.
</p>
</td></tr>
<tr><td><code id="estimate_bandwidth_+3A_method">method</code></td>
<td>

<p>One of <code>"fixed"</code>, <code>"silverman"</code>, <code>"silverman-1d"</code>, <code>"plug-in"</code>, or <code>"cross-validation"</code> - see 'details' section.
</p>
</td></tr>
<tr><td><code id="estimate_bandwidth_+3A_value">value</code></td>
<td>

<p>If <code>method="fixed"</code>, a scalar or vector value to be used. Otherwise ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fixed (<code>"fixed"</code>) is a constant value (scalar or vector of length equal to the dimensionality of the data). The value can be set via the <code>value</code> argument. If the input has length 1, the value will be repeated for all dimensions.
</p>
<p>The Silverman (<code>"silverman"</code>) estimator is defined as (4/(n+2))^(1/(n+4)) * m^(-1/(n+4))*sd(X) where m is the number of observations, n is the dimensionality, and X is the data vector in each dimension. This corresponds to the Silverman rule of thumb for multivariate data and is chosen as the default for computational speed, though other more advanced algorithms may perform better.
</p>
<p>The Silverman (<code>"silverman-1d"</code>) estimator is defined as 1.06 * sd(X) * m^(-1/5) where m is the number of observations and X is the data vector in each dimension. Minimizes mean integrated square error under the assumption the data are univariate normal. This was the default behavior in versions 1.x and 2.x of the package.
</p>
<p>The plug-in (<code>"plug-in"</code>) estimator is defined using a diagonal plug-in estimator with a 2-stage pilot estimation and a pre-scaling transformation (in <code>ks::Hpi.diag</code>). The resulting diagonal variances are then transformed to standard deviations and multiplied by two to be consistent for the box kernels used here. Available only in n&lt;7 dimensions. Minimizes sum of asymptotic mean squared error.
</p>
<p>The cross-validation (<code>"cross-validation"</code>) estimator is defined using a diagonal smoothed cross validation estimator with a 2-stage pilot estimation and a pre-scaling transformation (in <code>ks::Hscv.diag</code>). The resulting diagonal variances are then transformed to standard deviations and multiplied by two to be consistent for the box kernels used here. Available only in n&lt;7 dimensions.  Minimizes sum of asymptotic mean squared error.
</p>
<p>Note that all estimators are optimal only for normal kernels, whereas the hypervolume algorithms use box kernels - as the number of data points increases, this difference will become increasingly less important.
</p>
<p>Computational run-times for the plug-in and cross-validation estimators may become infeasibly large in n&gt;=4 dimensions. 
</p>


<h3>Value</h3>

<p>Vector of length n with each entry corresponding to the estimated bandwidth along each axis. An attribute <code>method</code> is also set indicating the algorithm used.
</p>


<h3>References</h3>

<p>Duong, T. (2007) ks: Kernel Density Estimation and Kernel Discriminant Analysis for Multivariate Data in R. Journal of Statistical Software 21, (7)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
                    
estimate_bandwidth(penguins_adelie,method="fixed",value=c(2,1,2))
estimate_bandwidth(penguins_adelie,method="silverman")
estimate_bandwidth(penguins_adelie,method="plug-in") # may be quite slow to run
estimate_bandwidth(penguins_adelie,method="cross-validation") # may be quite slow to run

## End(Not run)
</code></pre>

<hr>
<h2 id='expectation_ball'>
Hypersphere expectation
</h2><span id='topic+expectation_ball'></span>

<h3>Description</h3>

<p>Generates expectation hypervolume corresponding to a hypersphere that minimally encloses the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_ball(input, point.density = NULL, num.samples = NULL,
                 use.random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectation_ball_+3A_input">input</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="expectation_ball_+3A_point.density">point.density</code></td>
<td>

<p>The point density of the output expectation. If <code>NULL</code>, defaults to <code>v / num.points</code> where <code>d</code> is the dimensionality of the input and v is the volume of the hypersphere.
</p>
</td></tr>
<tr><td><code id="expectation_ball_+3A_num.samples">num.samples</code></td>
<td>

<p>The number of points in the output expectation. If <code>NULL</code>, defaults to <code>10^(3+sqrt(ncol(d)))</code> where <code>d</code> is the dimensionality of the input. <code>num.points</code> has priority over <code>point.density</code>; both cannot be specified.
</p>
</td></tr>
<tr><td><code id="expectation_ball_+3A_use.random">use.random</code></td>
<td>

<p>If <code>TRUE</code> and the <code>input</code> is of class <code>Hypervolume</code>, sets boundaries based on the <code>@RandomPoints</code> slot; otherwise uses <code>@Data</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>Hypervolume-class</code> object corresponding to the expectation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
e_ball &lt;- expectation_ball(penguins_adelie)
</code></pre>

<hr>
<h2 id='expectation_box'>
Hyperbox expectation
</h2><span id='topic+expectation_box'></span>

<h3>Description</h3>

<p>Generates expectation hypervolume corresponding to an axis-aligned hyperbox that minimally encloses the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_box(input, point.density = NULL, num.samples = NULL, use.random = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectation_box_+3A_input">input</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="expectation_box_+3A_point.density">point.density</code></td>
<td>

<p>The point density of the output expectation. If <code>NULL</code>, defaults to <code>v / num.points</code> where <code>d</code> is the dimensionality of the input and v is the volume of the hypersphere.
</p>
</td></tr>
<tr><td><code id="expectation_box_+3A_num.samples">num.samples</code></td>
<td>

<p>The number of points in the output expectation. If <code>NULL</code>, defaults to <code>10^(3+sqrt(ncol(d)))</code> where <code>d</code> is the dimensionality of the input. <code>num.points</code> has priority over <code>point.density</code>; both cannot be specified.
</p>
</td></tr>
<tr><td><code id="expectation_box_+3A_use.random">use.random</code></td>
<td>

<p>If <code>TRUE</code> and the <code>input</code> is of class <code>Hypervolume</code>, sets boundaries based on the <code>@RandomPoints</code> slot; otherwise uses <code>@Data</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>Hypervolume-class</code> object corresponding to the expectation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
e_box &lt;- expectation_box(penguins_adelie)
</code></pre>

<hr>
<h2 id='expectation_convex'>
Convex expectation
</h2><span id='topic+expectation_convex'></span>

<h3>Description</h3>

<p>Generates expectation hypervolume corresponding to a convex hull (polytope) that minimally encloses the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_convex(input, point.density = NULL, num.samples = NULL,
                 num.points.on.hull = NULL, check.memory = TRUE,
                 verbose = TRUE, use.random = FALSE, method =
                 "hitandrun", chunksize = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectation_convex_+3A_input">input</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_point.density">point.density</code></td>
<td>

<p>The point density of the output expectation. If <code>NULL</code>, defaults to <code>v / num.points</code> where <code>d</code> is the dimensionality of the input and v is the volume of the hypersphere.
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_num.samples">num.samples</code></td>
<td>

<p>The number of points in the output expectation. If <code>NULL</code>, defaults to <code>10^(3+sqrt(ncol(d)))</code> where <code>d</code> is the dimensionality of the input. <code>num.points</code> has priority over <code>point.density</code>; both cannot be specified.
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_num.points.on.hull">num.points.on.hull</code></td>
<td>

<p>Number of points of the input used to calculate the convex hull. Larger values are more accurate but may lead to slower runtimes. If <code>NULL</code>, defaults to using all of the data (most accurate).
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_check.memory">check.memory</code></td>
<td>

<p>If <code>TRUE</code>, reports expected number of convex hull simplices required for calculation and stops further memory allocation. Also warns if dimensionality is high.
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic progress messages.
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_use.random">use.random</code></td>
<td>

<p>If <code>TRUE</code> and the <code>input</code> is of class <code>Hypervolume</code>, sets boundaries based on the <code>@RandomPoints</code> slot; otherwise uses <code>@Data</code>.
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_method">method</code></td>
<td>

<p>One of <code>"rejection"</code> (rejection sampling) or <code>"hitandrun"</code> (adaptive hit and run Monte Carlo sampling)
</p>
</td></tr>
<tr><td><code id="expectation_convex_+3A_chunksize">chunksize</code></td>
<td>

<p>Number of random points to process per internal step. Larger values may have better performance on machines with large amounts of free memory. Changing this parameter does not change the output of the function; only how this output is internally assembled.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rejection sampling algorithm generates random points within a hyperbox enclosing the points, then sequentially tests whether each is in or out of the convex polytope based on a dot product test. It becomes exponentially inefficient in high dimensionalities. The hit-and-run sampling algorithm generates a Markov chain of samples that eventually converges to the true distribution of points within the convex polytope. It performs better in high dimensionalities but may not converge quickly. It will also be slow if the number of simplices on the convex polytope is large.
</p>
<p>Both algorithms may become impracticably slow in &gt;= 6 or 7 dimensions.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> object corresponding to the expectation hypervolume.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
e_convex &lt;- expectation_convex(penguins_adelie, check.memory=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='expectation_maximal'>
Maximal expectation
</h2><span id='topic+expectation_maximal'></span>

<h3>Description</h3>

<p>Creates a hypervolume from a set of points reflecting the maximal expectation. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectation_maximal(input, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectation_maximal_+3A_input">input</code></td>
<td>

<p>A dataset to be used as input to the <code>hypervolume</code> function
</p>
</td></tr>
<tr><td><code id="expectation_maximal_+3A_...">...</code></td>
<td>

<p>Arguments to the <code>hypervolume</code> function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is effectively an alias for the <code>hypervolume</code> function. You must decide what the maximal expectation is yourself!
</p>


<h3>Value</h3>

<p>A Hypervolume object.
</p>

<hr>
<h2 id='find_optimal_occupancy_thin'>
Find optimal parameters to calculate occupancy
</h2><span id='topic+find_optimal_occupancy_thin'></span>

<h3>Description</h3>

<p>The <code>find_optimal_occupancy_thin()</code> function is used to find the optimal parameters for
<code>hypervolume_n_occupancy()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_optimal_occupancy_thin(..., 
                            verbose = TRUE, 
                            sequence = seq(0, 1, 0.1), 
                            n = 10, 
                            res_type = "raw")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_optimal_occupancy_thin_+3A_...">...</code></td>
<td>

<p>Parameters to be used to run <code>hypervolume_n_occupancy()</code>.
</p>
</td></tr>
<tr><td><code id="find_optimal_occupancy_thin_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="find_optimal_occupancy_thin_+3A_sequence">sequence</code></td>
<td>

<p>Quantiles to be tested.
</p>
</td></tr>
<tr><td><code id="find_optimal_occupancy_thin_+3A_n">n</code></td>
<td>

<p>Number of seeds to be tested.
</p>
</td></tr>
<tr><td><code id="find_optimal_occupancy_thin_+3A_res_type">res_type</code></td>
<td>

<p>If <code>raw</code> print all the seeds and quantiles tested together with the resulting root mean square error (RMSE). If <code>summary</code> print RMSE mean and standard deviation for each quantile.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>find_optimal_occupancy_thin()</code> function searches for the optimal parameters for running <code>hypervolume_n_occupancy()</code>. It works by testing different quantiles and <code>n</code> seeds for random number generation (the same set of n seeds is tested for each quantile). RMSE is returned as the measure of the goodness of fit and results are ordered by increasing RMSE when <code>res_type = "raw"</code>. Quantile equal to 0 correspond to no thin. The obtained parameters can be used to feed arguments <code>quant.thin</code> and <code>seed</code> within the function <code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy()</a></code>.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
                             paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
  x = penguins_no_na_split, 
  y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# find optimal parameters
opt_par = find_optimal_occupancy_thin(hv_list, 
                                       classification = rep(c("female", "male"), 3),
                                       n = 20)

head(opt_par)

unoptimized_hv_occ = hypervolume_n_occupancy(hv_list, 
                        classification = rep(c("female", "male"), 3))

optimized_hv_occ = hypervolume_n_occupancy(hv_list, 
                        classification = rep(c("female", "male"), 3), 
                        quant.thin = opt_par[1, 2], seed = opt_par[1, 1])


## End(Not run)
</code></pre>

<hr>
<h2 id='get_centroid'>
Get centroid of hypervolume or hypervolume list
</h2><span id='topic+get_centroid'></span>

<h3>Description</h3>

<p>Returns the column mean of the random points in each hypervolume.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_centroid(hv)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_centroid_+3A_hv">hv</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either a vector or a matrix of column of centroid values along each axis. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
hv = hypervolume_gaussian(penguins_adelie)
get_centroid(hv)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_centroid_weighted'>
Get weighted centroid of hypervolume or hypervolume list
</h2><span id='topic+get_centroid_weighted'></span>

<h3>Description</h3>

<p>Returns the column weighted mean of the random points in each hypervolume. Useful for hypervolumes generated with <code>hypervolume_n_occupancy()</code>
or <code>hypervolume_n_occupancy_test()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_centroid_weighted(hv)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_centroid_weighted_+3A_hv">hv</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>get_centroid_weighted()</code> differs from <code>get_centroid()</code> because it uses occupancy values to weight random points for evaluating centroids position.
</p>


<h3>Value</h3>

<p>Either a vector or a matrix of column of centroid values along each axis. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))


penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))


hv_list = lapply(penguins_no_na_split, function(x) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
  samples.per.point=100))

hv_list = hypervolume_join(hv_list)
hv_occupancy = hypervolume_n_occupancy(hv_list)

# unweighted centroids
get_centroid(hv_occupancy)

# weighted centroids
get_centroid_weighted(hv_occupancy)


## End(Not run)
</code></pre>

<hr>
<h2 id='get_occupancy_intersection_bootstrap'>
Volume of the intersection of a bootstrapped occupancy object
</h2><span id='topic+get_occupancy_intersection_bootstrap'></span>

<h3>Description</h3>

<p>The <code>get_occupancy_intersection_bootstrap()</code> function is used to get the volume of the intersection of objects generated with <code>hypervolume_n_occupancy_bootstrap()</code>. It provides raw values or summary statistics for all the hypervolumes or their n_wise combinations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_occupancy_intersection_bootstrap(path,
                                     method = "n_wise",
                                     res_type = "summary",
                                     m = 2, 
                                     relative = FALSE,
                                     tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_occupancy_intersection_bootstrap_+3A_path">path</code></td>
<td>

<p>A path to a directory of bootstrapped occupancy objects obtained with <br />
<code>hypervolume_n_occupancy_bootstrap()</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_intersection_bootstrap_+3A_method">method</code></td>
<td>

<p>If <code>all</code> compute the volume of the intersection among all the hypervolumes for each bootstrapped occupancy object found in <code>path</code>. If <code>n_wise</code> compute the volume of the intersection for each n_wise combination of hypervolumes within the bootstrapped occupancy objects found in <code>path</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_intersection_bootstrap_+3A_res_type">res_type</code></td>
<td>

<p>It can be <code>raw</code> or <code>pairwise</code>. See details.
</p>
</td></tr>
<tr><td><code id="get_occupancy_intersection_bootstrap_+3A_m">m</code></td>
<td>

<p>Number of elements to choose. Default to 2 (pairwise comparisons). This argument is ignored when <code>method</code> is set to <code>all</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_intersection_bootstrap_+3A_relative">relative</code></td>
<td>

<p>If <code>TRUE</code> it computes relative instead of absolute volumes.
</p>
</td></tr>
<tr><td><code id="get_occupancy_intersection_bootstrap_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>get_occupancy_intersection_bootstrap()</code> returns the volume of the intersection for each bootstrapped occupancy object if <code>res_type = "raw"</code> and <code>method = "all"</code>. When <code>res_type = "summary"</code> and <code>method = "all"</code> this function returns the mean volume as well as the standard deviation, median, minimum, maximum, 2.5% and 97.5% quantiles, skewness and kurtosis of the intersection. The same summary statistics are calculated for each n_wise combination of hypervolumes when <code>res_type = "summary"</code> and <code>method = "n_wise"</code>. The number of elements of n_wise combinations is set with the argument <code>m</code>. The intersection is calculated by finding the set of random points shared by all or n_wise combinations of hypervolumes in each of the bootstrapped occupancy objects. More details on how the intersection is computed in <code><a href="#topic+occupancy_to_intersection">occupancy_to_intersection()</a></code>. <br />
The <code>get_occupancy_intersection_bootstrap()</code> function attempts to reconstruct the volume of the intersection from each bootstrapped occupancy object. At first, the volume of the union of hypervolumes is calculated for each hypervolume of the jth bootstrapped occupancy object as the ratio between the total number of random points and the number of random points of the ith hypervolume of the jth bootstrapped occupancy object, multiplied by the volume of the ith hypervolume of the jth bootstrapped occupancy object. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated using the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned. The volume of the intersection is then calculated as the ratio between the number of random points of the intersection and the total number of random points, multiplied by the volume of the union of hypervolumes. <br />
When <code>relative = TRUE</code> relative instead of absolute volumes are returned. The relative volume is calculated as the ratio between the volume of the intersection and the volume of the union of all the hypervolumes (or combination of hypervolumes when <code>method = "n_wise"</code>). The same approach described above is used to reconstruct the volume of the union of hypervolumes.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> with bootstrapped volumes or summary statistics of the intersection.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_bootstrap">hypervolume_n_occupancy_bootstrap</a></code>, <code><a href="#topic+occupancy_to_intersection">occupancy_to_intersection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# bootstrap the hypervolumes
hv_list_boot = hypervolume_n_resample(name = "example", hv_list)

# calculate occupancy on bootstrapped hypervolumes
hv_occupancy_boot_sex = hypervolume_n_occupancy_bootstrap(path = hv_list_boot,
                                    name = "example_occ",
                                    classification = rep(c("female", "male"), 3))

# get the intersection
get_occupancy_intersection_bootstrap(hv_occupancy_boot_sex)


## End(Not run)
</code></pre>

<hr>
<h2 id='get_occupancy_stats'>
Stats from occupancy objects
</h2><span id='topic+get_occupancy_stats'></span><span id='topic+get_occupancy_stats_bootstrap'></span>

<h3>Description</h3>

<p>Functions <code>get_occupancy_stats()</code> and <code>get_occupancy_stats_bootstrap()</code> return the results of a function applied to hypervolumes generated with <code>hypervolume_n_occupancy()</code>,
<code>hypervolume_n_occupancy_bootstrap()</code>, <code>hypervolume_n_occupancy_permute()</code> or <code>hypervolume_n_occupancy_test()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_occupancy_stats(hv, FUN, remove_zeroes = TRUE)

get_occupancy_stats_bootstrap(path,
                              FUN,
                              remove_zeroes = TRUE,
                              method = "pairwise",
                              res_type = "summary",
                              verbose = TRUE,
                              cores = 1)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_occupancy_stats_+3A_hv">hv</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object generated with <code>hypervolume_n_occupancy()</code>, <code>hypervolume_n_occupancy_bootstrap()</code>, <code>hypervolume_n_occupancy_permute()</code> or <code>hypervolume_n_occupancy_test()</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_fun">FUN</code></td>
<td>

<p>The function to be applied.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_remove_zeroes">remove_zeroes</code></td>
<td>

<p>Remove zeroes before the calculation. See Details.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_path">path</code></td>
<td>

<p>A path to a directory of bootstrapped hypervolumes obtained with
<code>hypervolume_n_occupancy_bootstrap()</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_method">method</code></td>
<td>

<p>If <code>all</code> returns the results for each hypervolume. If <code>pairwise</code> returns the results for all the pairwise comparisons of individual hypervolumes.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_res_type">res_type</code></td>
<td>

<p>It can be <code>raw</code> or <code>pairwise</code>. See details.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_stats_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating permuted hypervolumes. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in <code>cores</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>get_occupancy_stats()</code> and <code>get_occupancy_stats_bootstrap()</code> functions take <code>ValueAtRandomPoints</code> of each hypervolume as input to <code>FUN</code> (e.g. mean, median). <br />
The <code>get_occupancy_stats_bootstrap()</code> function applies the function to bootstrapped occupancy objects generated with <code>hypervolume_n_occupancy_bootstrap()</code>. If <code>res_type = "raw"</code> raw values of the applied functions are returned for each occupancy object in <code>path</code>, only when <code>method = "all"</code>. If <code>res_type = "summary"</code> the mean value as well as the standard deviation, median, minimum, maximum, 2.5% and 97.5% quantiles, skewness and kurtosis are returned either for individual hypervolumes (<code>method = "all"</code>) or pairwise comparisons (<code>method = "pairwise"</code>). <br />
The <code>get_occupancy_stats()</code> and <code>get_occupancy_stats_bootstrap()</code> functions remove occupancy values equal to 0 by default. These values are generated during the occupancy routine when a random point is included in some groups of hypervolumes but not in others. A tipical usage of
<code>get_occupancy_stats()</code> or <code>get_occupancy_stats_bootstrap()</code> should remove zeroes before applying a function (the default).
</p>


<h3>Value</h3>

<p>Either a <code>vector</code>, a <code>matrix</code> or a <code>data.frame</code> with the results of the applied function. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_bootstrap">hypervolume_n_occupancy_bootstrap</a></code>,
<code><a href="#topic+hypervolume_n_occupancy_permute">hypervolume_n_occupancy_permute</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##### single occupancy object #####
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# calculate occupancy based on sex
hv_occupancy_list_sex = hypervolume_n_occupancy(hv_list, 
                          classification = rep(c("female", "male"), 3))


# calculate the mean occupancy value
get_occupancy_stats(hv_occupancy_list_sex, mean)

##### bootstrapped occupancy objects #####

# bootstrap input hypervolumes
hv_boot = hypervolume_n_resample(name = "example", hv_list = hv_list,  n = 9)

# calculate occupancy on bootstrapped hypervolumes
hv_boot_occ = hypervolume_n_occupancy_bootstrap(hv_boot, name = "example_occ",
                                  classification = rep(c("female", "male"), 3))

# calculate summary statistics for pairwise comparisons
get_occupancy_stats_bootstrap(hv_boot_occ, FUN = mean)


## End(Not run)
</code></pre>

<hr>
<h2 id='get_occupancy_unshared_bootstrap'>
Volume of the unshared fraction of a bootstrapped occupancy object
</h2><span id='topic+get_occupancy_unshared_bootstrap'></span>

<h3>Description</h3>

<p>The <code>get_occupancy_unshared_bootstrap()</code> function is used to get the volume of the unshared fraction of an object generated with <code>hypervolume_n_occupancy_bootstrap()</code>. It provides raw values or summary statistics for both individual hypervolumes or their pairwise comparisons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_occupancy_unshared_bootstrap(path,
                                 method = "pairwise",
                                 res_type = "summary",
                                 relative = FALSE,
                                 tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_occupancy_unshared_bootstrap_+3A_path">path</code></td>
<td>

<p>A path to a directory of bootstrapped occupancy objects obtained with <br />
<code>hypervolume_n_occupancy_bootstrap()</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_unshared_bootstrap_+3A_method">method</code></td>
<td>

<p>If <code>all</code> compute the volume of the unique fraction of each hypervolume compared to all the hypervolumes for each occupancy object in <code>path</code>. If <code>pairwise</code> compute the difference of the volume of the unshared fraction for each pairwise combination of hypervolumes within the bootstrapped occupancy objects found in <code>path</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_unshared_bootstrap_+3A_res_type">res_type</code></td>
<td>

<p>It can be <code>raw</code> or <code>pairwise</code>. See details.
</p>
</td></tr>
<tr><td><code id="get_occupancy_unshared_bootstrap_+3A_relative">relative</code></td>
<td>

<p>If <code>TRUE</code> it computes relative instead of absolute volumes.
</p>
</td></tr>
<tr><td><code id="get_occupancy_unshared_bootstrap_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>get_occupancy_unshared_bootstrap()</code> returns the volume of the unshared fraction for each hypervolume in the bootstrapped occupancy object if <code>res_type = "raw"</code> and <code>method = "all"</code>. When <code>res_type = "summary"</code> and <code>method = "all"</code> this function returns the mean volume as well as the standard deviation, median, minimum, maximum, 2.5% and 97.5% quantiles, skewness and kurtosis of the unshared fraction for each hypervolume. The same summary statistics are calculated for the difference of volume of the unshared fraction for each pairwise combination of hypervolumes when <code>res_type = "summary"</code> and <code>method = "pairwise"</code>. The unshared fraction is calculated by finding the set of random points that are not shared with other hypervolumes or pairwise combinations of hypervolumes in each bootstrapped occupancy object. More details on how the unshared fraction is computed in <code><a href="#topic+occupancy_to_unshared">occupancy_to_unshared()</a></code>.<br />
The <code>get_occupancy_unshared_bootstrap()</code> function attempts to reconstruct the volume of the unshared fraction from each bootstrapped occupancy object. At first, the volume of the union of hypervolumes is calculated for each hypervolume of the jth bootstrapped occupancy object as the ratio between the total number of random points and the number of random points of the ith hypervolume of the jth bootstrapped occupancy object, multiplied by the volume of the ith hypervolume of the jth bootstrapped occupancy object. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned. The volume of the unshared fraction is then calculated as the ratio between the number of random points of the unshared fraction and the total number of random points, multiplied by the volume of the union of hypervolumes. <br />
When <code>relative = TRUE</code> relative instead of absolute volumes are returned. The relative volume is calculated as the ratio between the volume of the unshared fraction and the volume of the union of all the hypervolumes (or combination of hypervolumes when <code>method = "pairwise"</code>). The same approach described above is used to reconstruct the volume of the union of hypervolumes.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> with bootstrapped volumes or summary statistics of the unshared fraction.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_bootstrap">hypervolume_n_occupancy_bootstrap</a></code>
<code><a href="#topic+occupancy_to_unshared">occupancy_to_unshared</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# bootstrap the hypervolumes
hv_list_boot = hypervolume_n_resample(name = "example", hv_list)

# calculate occupancy on bootstrapped hypervolumes
hv_occupancy_boot_sex = hypervolume_n_occupancy_bootstrap(path = hv_list_boot,
                                    name = "example_occ",
                                    classification = rep(c("female", "male"), 3))

# get the unshared fraction
get_occupancy_unshared_bootstrap(hv_occupancy_boot_sex)


## End(Not run)
</code></pre>

<hr>
<h2 id='get_occupancy_volume_bootstrap'>
Extract the volume from occupancy bootstrap objects
</h2><span id='topic+get_occupancy_volume_bootstrap'></span>

<h3>Description</h3>

<p>The function <code>get_occupancy_volume_bootstrap()</code> extract the volume from objects generated with <code>hypervolume_n_occupancy_bootstrap()</code>. It provides raw values or summary statistics for both single hypervolumes or their pairwise comparisons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_occupancy_volume_bootstrap(path,
                               method = "all",
                               res_type = "raw",
                               relative = FALSE,
                               tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_occupancy_volume_bootstrap_+3A_path">path</code></td>
<td>

<p>A path to a directory containing bootstrapped occupancy objects generated with <code>hypervolume_n_occupancy_bootstrap()</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_volume_bootstrap_+3A_method">method</code></td>
<td>

<p>If <code>all</code> the function returns the volume of each bootstrapped hypervolume for each bootstrapped occupancy object in <code>path</code>. If <code>pairwise</code> returns the volume difference for each pairwise combination of hypervolumes within the bootstrapped occupancy objects found in <code>path</code>.
</p>
</td></tr>
<tr><td><code id="get_occupancy_volume_bootstrap_+3A_res_type">res_type</code></td>
<td>

<p>It can be <code>raw</code> or <code>pairwise</code>. See details.
</p>
</td></tr>
<tr><td><code id="get_occupancy_volume_bootstrap_+3A_relative">relative</code></td>
<td>

<p>If <code>TRUE</code> it computes relative instead of absolute volumes.
</p>
</td></tr>
<tr><td><code id="get_occupancy_volume_bootstrap_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>get_occupancy_volume_bootstrap()</code> returns the volume for each bootstrapped hypervolume if <code>res_type = "raw"</code> and <code>method = "all"</code>. When <code>res_type = "summary"</code> and <code>method = "all"</code> this function returns the mean volume as well as the standard deviation, median, minimum, maximum, 2.5% and 97.5% quantiles, skewness and kurtosis for each of hypervolume. The same summary statistics are calculated for the difference of volume for each pairwise combination of hypervolumes when <code>res_type = "summary"</code> and <code>method = "pairwise"</code>. <br />
When <code>relative = TRUE</code> relative instead of absolute volumes are returned. The relative volume is calculated as the ratio between the volume of an hypervolume and the volume of the union of all the hypervolumes. The <code>get_occupancy_volume_bootstrap()</code> function attempts to reconstruct the volume of the union of all the hypervolumes from each bootstrapped hypervolume. At first, the volume of the union of hypervolumes is calculated for each hypervolume of the jth bootstrapped occupancy_object as the the ratio between the total number of random points and the number of random points of the ith hypervolume of the jth bootstrapped occupancy_object, multiplied by the volume of the ith hypervolume of the jth bootstrapped occupancy_object. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy_object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> with bootstrapped volumes or summary statistics for single hypervolumes or their pairwise comparisons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_bootstrap">hypervolume_n_occupancy_bootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# bootstrap the hypervolumes
hv_list_boot = hypervolume_n_resample(name = "example", hv_list)

# calculate occupancy on bootstrapped hypervolumes
hv_occupancy_boot_sex = hypervolume_n_occupancy_bootstrap(path = hv_list_boot,
                                    name = "example_occ",
                                    classification = rep(c("female", "male"), 3))

# get the volume of the bootstrapped hypervolumes
get_occupancy_volume_bootstrap(hv_occupancy_boot_sex)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_relative_volume'>
Extract the relative volume
</h2><span id='topic+get_relative_volume'></span>

<h3>Description</h3>

<p>The function <code>get_relative_volume()</code> computes the relative volume from objects generated with the occupancy routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_relative_volume(hv_list, tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_relative_volume_+3A_hv_list">hv_list</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object generated with <code>hypervolume_n_occupancy()</code>, <code>hypervolume_n_occupancy_permute()</code>, <code>hypervolume_n_occupancy_test()</code>, <code>occupancy_to_union()</code>, <code>occupancy_to_intersection()</code>, <code>occupancy_to_unshared()</code>, or <code>occupancy_filter()</code>.
</p>
</td></tr>
<tr><td><code id="get_relative_volume_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relative volume is calculated as the ratio between hypervolumes of an <code>HypervolumeList</code> and the volume resulting from the union of hypervolumes in the same <code>HypervolumeList</code>. Relative volumes can be calculated only for <code>HypervolumeList</code> generated with functions <code>hypervolume_n_occupancy()</code>, <code>hypervolume_n_occupancy_test()</code>, <code>hypervolume_n_occupancy_permute()</code>, <code>occupancy_to_union()</code>, <code>occupancy_to_ushared()</code>, <code>occupancy_to_intersection()</code> or <code>occupancy_filter()</code>. <br />
The <code>get_relative_volume()</code> function attempts to reconstruct the volume of the union of hypervolumes from <code>hv_list</code>. At first, the volume of the union of hypervolumes is calculated for each hypervolume of <code>hv_list</code> as the the ratio between the total number of random points and the number of random points of the ith hypervolume of <code>hv_list</code>, multiplied by the volume of the ith hypervolume <code>hv_list</code>. This step results in a number of reconstructed volumes equal to the number of hypervolumes in <code>hv_list</code>. Reconstructed volumes are then compared to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned.
</p>


<h3>Value</h3>

<p>A named numeric vector with the relative volume of each input hypervolume
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_permute">hypervolume_n_occupancy_permute</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>, <code><a href="#topic+occupancy_to_union">occupancy_to_union</a></code>,
<code><a href="#topic+occupancy_to_unshared">occupancy_to_unshared</a></code>, <code><a href="#topic+occupancy_to_intersection">occupancy_to_intersection</a></code>,
<code><a href="#topic+occupancy_filter">occupancy_filter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# calculate occupancy based on sex
hv_occupancy_list_sex = hypervolume_n_occupancy(hv_list, 
                          classification = rep(c("female", "male"), 3))


# get the relative volume
get_relative_volume(hv_occupancy_list_sex)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_volume'>
Extract volume
</h2><span id='topic+get_volume'></span><span id='topic+get_volume.Hypervolume'></span><span id='topic+get_volume.HypervolumeList'></span><span id='topic+get_volume+2CHypervolume-method'></span><span id='topic+get_volume+2CHypervolumeList-method'></span>

<h3>Description</h3>

<p>Extract volume from Hypervolume or HypervolumeList object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Hypervolume'
get_volume(object)
## S3 method for class 'HypervolumeList'
get_volume(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_volume_+3A_object">object</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named numeric vector with the volume of each input hypervolume
</p>

<hr>
<h2 id='hypervolume'>
Hypervolume construction methods
</h2><span id='topic+hypervolume'></span>

<h3>Description</h3>

<p>Constructs hypervolumes using one of several possible methods after error-checking input data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume(data, method = "gaussian", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_+3A_data">data</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="hypervolume_+3A_method">method</code></td>
<td>

<p>One of <code>"box"</code> (box kernel density estimation), <code>"gaussian"</code> (Gaussian kernel density estimation), or <code>"svm"</code> (one-class support vector machine). See respective functions for details.
</p>
</td></tr>
<tr><td><code id="hypervolume_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="#topic+hypervolume_box">hypervolume_box</a></code>, <code><a href="#topic+hypervolume_gaussian">hypervolume_gaussian</a></code>, or <code><a href="#topic+hypervolume_svm">hypervolume_svm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Checks for collinearity,  missingness of input data, and appropriate random point coverage. Generates warning/errors as appropriate.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> object corresponding to the inferred hypervolume.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+weight_data">weight_data</a></code>, <code><a href="#topic+estimate_bandwidth">estimate_bandwidth</a></code>, <code><a href="#topic+expectation_convex">expectation_convex</a></code>, <code><a href="#topic+expectation_ball">expectation_ball</a></code>, <code><a href="#topic+expectation_box">expectation_box</a></code>, <code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
hv = hypervolume(penguins_adelie,method='box')
</code></pre>

<hr>
<h2 id='hypervolume_box'>
Hypervolume construction via hyperbox kernel density estimation
</h2><span id='topic+hypervolume_box'></span>

<h3>Description</h3>

<p>Constructs a hypervolume from a set of observations via thresholding a kernel density estimate of the observations. Assumes an axis-aligned hyperbox kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_box(data, name = NULL, verbose = TRUE, samples.per.point =
                 ceiling((10^(3 + sqrt(ncol(data))))/nrow(data)),
                 kde.bandwidth = 2*estimate_bandwidth(data),
                 tree.chunksize = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_box_+3A_data">data</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="hypervolume_box_+3A_name">name</code></td>
<td>

<p>A string to assign to the hypervolume for later output and plotting. Defaults to the name of the variable if NULL.
</p>
</td></tr>
<tr><td><code id="hypervolume_box_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_box_+3A_samples.per.point">samples.per.point</code></td>
<td>

<p>Number of random points to be evaluated per data point in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_box_+3A_kde.bandwidth">kde.bandwidth</code></td>
<td>

<p>A scalar or a n x 1 vector corresponding to the half-width of the box kernel in each dimension. If a scalar input, the single value is used for all dimensions. Several esimation methods are available in <code><a href="#topic+estimate_bandwidth">estimate_bandwidth</a></code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_box_+3A_tree.chunksize">tree.chunksize</code></td>
<td>

<p>Number of random points to process per internal step. Larger values may have better performance on machines with large amounts of free memory. Changing this parameter does not change the output of the function; only how this output is internally assembled.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Constructs a kernel density estimate by overlaying hyperbox kernels on each datapoint, then sampling uniformly random points from each kernel. Kernel density at each point is then determined by a range query on a recursive partitioning tree and used to resample these random points to a uniform density and fixed number, from which a volume can be inferred.
</p>
<p>Note that when comparing among hypervolumes constructed with fixed bandwidth, volume will be approximately a an approximately linear function of the number of input data points.
</p>
<p>Note that this function returns an unthresholded hypervolume. To assign a quantile threshold, use <code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> object corresponding to the inferred hypervolume.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>, <code><a href="#topic+estimate_bandwidth">estimate_bandwidth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
hv = hypervolume_box(penguins_adelie,name='Adelie')
summary(hv)
</code></pre>

<hr>
<h2 id='hypervolume_distance'>
Distance between two hypervolumes
</h2><span id='topic+hypervolume_distance'></span>

<h3>Description</h3>

<p>Calculates the distance between two hypervolumes either defined as the Euclidean distance between centroids or as the minimum Euclidean distance between the random points comprising either hypervolume.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_distance(hv1, hv2, type = "centroid", 
  num.points.max = 1000, check.memory = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_distance_+3A_hv1">hv1</code></td>
<td>

<p>A <code>Hypervolume</code> object.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_+3A_hv2">hv2</code></td>
<td>

<p>A <code>Hypervolume</code> object.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_+3A_type">type</code></td>
<td>

<p>If 'centroid', the centroid distance; if 'minimum', the minimum distance.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_+3A_num.points.max">num.points.max</code></td>
<td>

<p>The number of random points to subsample from each input hypervolume. Ignored if <code>type='centroid'</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_+3A_check.memory">check.memory</code></td>
<td>

<p>If <code>TRUE</code>, prints expected memory usage and returns an error before allocating memory. Ignored if <code>type='centroid'</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Minimum distance calculations scale quadratically with <code>npmax</code> and may be computationally costly.
</p>


<h3>Value</h3>

<p>The distance between the two hypervolumes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
penguins_chinstrap = penguins_no_na[penguins_no_na$species=="Chinstrap",
                      c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv1 = hypervolume_gaussian(penguins_adelie)
hv2 = hypervolume_gaussian(penguins_chinstrap)

# note that minimum distance is smaller than centroid distance as expected
hypervolume_distance(hv1, hv2, type='centroid')
hypervolume_distance(hv1, hv2, type='minimum', num.points.max=500, check.memory=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_distance_point'>
Distance from a point to the margin of a hypervolume.
</h2><span id='topic+hypervolume_distance_point'></span>

<h3>Description</h3>

<p>Calculates the distance between two hypervolumes either defined as the Euclidean distance between centroids or as the minimum Euclidean distance between the random points comprising either hypervolume.
</p>
<p>Code by Clement Violet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_distance_point(hv1, x, type = "minimum", 
  num.points.max = 1000, check.memory = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_distance_point_+3A_hv1">hv1</code></td>
<td>

<p>A <code>Hypervolume</code> object.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_point_+3A_x">x</code></td>
<td>

<p>An object coercible to a <code>matrix</code> object.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_point_+3A_type">type</code></td>
<td>

<p>If 'minimum', compute the smallest distance to the hypervolume margin; if 'maximum' calculates the greatest distance to the margin of the hypervolume.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_point_+3A_num.points.max">num.points.max</code></td>
<td>

<p>The number of random points to subsample from the input hypervolume.
</p>
</td></tr>
<tr><td><code id="hypervolume_distance_point_+3A_check.memory">check.memory</code></td>
<td>

<p>If <code>TRUE</code>, prints expected memory usage and returns an error before allocating memory. Ignored if <code>type='centroid'</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Distance calculations scale quadratically with <code>npmax</code> and may be computationally costly.
</p>


<h3>Value</h3>

<p>The distance between the two hypervolumes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                                 c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv1 = hypervolume_gaussian(penguins_adelie)

point = penguins_no_na[penguins_no_na$species=="Chinstrap",
                       c("bill_length_mm","bill_depth_mm","flipper_length_mm")][42, ]

# note that minimum distance is smaller than centroid distance as expected
hypervolume_distance_point(hv1, point, type='minimum', num.points.max=500, check.memory=FALSE)
hypervolume_distance_point(hv1, point, type='maximum', num.points.max=500, check.memory=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_estimate_probability'>
Estimate probability a given location
</h2><span id='topic+hypervolume_estimate_probability'></span>

<h3>Description</h3>

<p>Estimates probability density at one or more of points within or outside a hypervolume. The estimation is carried out as the weighted sum of the probability density of all subsampled random points in the input hypervolume, where the weights are proportional to the distance from the test point raised to a certain power. The default power, -1, corresponds to inverse distance weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_estimate_probability(hv, points, 
                reduction.factor = 1, weight.exponent = -1, 
                set.edges.zero = TRUE, edges.zero.distance.factor = 1,
                parallel = FALSE, n.cores = 1,
                verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_estimate_probability_+3A_hv">hv</code></td>
<td>

<p>An input hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_points">points</code></td>
<td>

<p>A m x n matrix of m points of dimensionality n (same as the input hypervolume). These are the points at which the probability is to be estimated.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_reduction.factor">reduction.factor</code></td>
<td>

<p>A value between 0 and 1 corresponding to a thinning factor applied to random points of the input hypervolume. Smaller values result in faster runtimes but lower accuracy.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_weight.exponent">weight.exponent</code></td>
<td>

<p>The exponent of the distance weights. Should be negative and probably does not need to be changed.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_set.edges.zero">set.edges.zero</code></td>
<td>

<p>If <code>TRUE</code>, any test points more than a critical distance (multiplied by <code>edges.zero.distance.factor</code>) away from a random point in the input hypervolume are assumed to have probability zero. Otherwise the weighted sum is used with no further modification.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_edges.zero.distance.factor">edges.zero.distance.factor</code></td>
<td>

<p>Positive number used to multiply the critical distance for <code>set.edges.zero</code>. Larger values lead to more stringent criteria for test points being set to zero.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_parallel">parallel</code></td>
<td>

<p>If <code>TRUE</code>, uses multiple cores.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_n.cores">n.cores</code></td>
<td>

<p>Number of cores to use in parallel operation.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic progress messages.
</p>
</td></tr>
<tr><td><code id="hypervolume_estimate_probability_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to <code>pbsapply</code> for parallelization.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Identifies the uniformly random points enclosed within a hypersphere centered on the point of interest, then averages the probability density at each of these points.
</p>


<h3>Value</h3>

<p>A vector of probability densities of length corresponding to m, the number of input points.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_inclusion_test">hypervolume_inclusion_test</a></code>, <code><a href="#topic+hypervolume_redundancy">hypervolume_redundancy</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
hv = hypervolume_box(penguins_adelie,name='Adelie')

new_points = data.frame(bill_length_mm=c(0,38), bill_depth_mm=c(0,18),flipper_length_mm=c(0,190))

probs &lt;- hypervolume_estimate_probability(hv, points=new_points)
probs
# should give a zero value and a non-zero value

# example for parallel operation
# probs_new &lt;- hypervolume_estimate_probability(hv, points=new_points, parallel=TRUE, n.cores=2)
</code></pre>

<hr>
<h2 id='hypervolume_funnel'>
Hypervolumes at different sample sizes
</h2><span id='topic+hypervolume_funnel'></span>

<h3>Description</h3>

<p>This function takes in hypervolumes bootstrapped at different sample sizes applies a function to each hypervolume. The output of the function can either be a plot of nonparametric confidence intervals or a table of the mean and quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_funnel(input_path, 
                    title = NULL, 
                    func = get_volume, 
                    CI = .95, 
                    as_table = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_funnel_+3A_input_path">input_path</code></td>
<td>

<p>output of <code>resample</code> with method = &quot;bootstrap seq&quot;; path to a sequence of different sample sized bootstraps
</p>
</td></tr>
<tr><td><code id="hypervolume_funnel_+3A_title">title</code></td>
<td>

<p>title of output plot, ignore if outputting as table
</p>
</td></tr>
<tr><td><code id="hypervolume_funnel_+3A_func">func</code></td>
<td>

<p>a function that takes a single parameter which is a hypervolume and returns a numerical value.
</p>
</td></tr>
<tr><td><code id="hypervolume_funnel_+3A_ci">CI</code></td>
<td>

<p>Confidence interval is taken by using the the (1-CI)/2 and (1+CI)/2 quantile
</p>
</td></tr>
<tr><td><code id="hypervolume_funnel_+3A_as_table">as_table</code></td>
<td>

<p>If TRUE, returns a table with columns upper quantile, mean, lower quantile
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used to evaluate the behavior of hypervolumes at different sample sizes and determine bias. Statistics such as volume are affected by sample size especially when the hypervolumes are constructed with method = &quot;gaussian&quot; since the bandwidth estimate is dependent on sample size.
</p>


<h3>Value</h3>

<p>ggplot object, or dataframe object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# 3000 data point hypervolume
data(quercus)
hv_quercus = hypervolume(quercus[,c(2,3)])

# the seq argument is equivalent to a length 30 vector {10, 139, ... , 3649, 3779}
# 6hr sequential runtime
quercus_bootstrap_seq &lt;- resample('quercus_bootstrap_seq', 
                                    hv_quercus, 
                                    method = 'bootstrap seq', 
                                    points_per_resample = "sample_size", 
                                    seq = floor(seq(10, 3779, length.out = 30)),
                                    cores = 20)

# Compatible with ggplot syntax when used with as_table = FALSE
hypervolume_funnel(quercus_bootstrap_seq, 
                    title = 'Resampled volumes of Quercus', 
                    func = get_volume) + 
  geom_line(aes(y = get_volume(hv_quercus))) +
  ylab("Volume")

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_gaussian'>
Hypervolume construction via Gaussian kernel density estimation
</h2><span id='topic+hypervolume_gaussian'></span>

<h3>Description</h3>

<p>Constructs a hypervolume by building a Gaussian kernel density estimate on an adaptive grid of random points wrapping around the original data points. The bandwidth vector reflects the axis-aligned standard deviations of a hyperelliptical kernel. 
</p>
<p>Because Gaussian kernel density estimates do not decay to zero in a finite distance, the algorithm evaluates the kernel density in hyperelliptical regions out to a distance set by <code>sd.count</code>. 
</p>
<p>After delineating the probability density, the function calls <code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code> to determine a boundary. The defaullt behavior ensures that 95 percent of the stimated probability density is enclosed by the chosen boundary. However note that theaccuracy of the total probability density depends on having set a large value of <code>sd.count</code>.
</p>
<p>Most use cases should not require modification of any parameters except <code>kde.bandwidth</code>. 
</p>
<p>Optionally, weighting of the data (e.g. for abundance-weighting) is possible. By default, the function estimates the probability density of the observations via Gaussian kernel functions, assuming each data point contributes equally. By setting a <code>weight</code> parameter, the algorithm can instead take a weighted average the kernel functions centered on each observation. Code for weighting data written by Yuanzhi Li (Yuanzhi.Li@usherbrooke.ca).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_gaussian(data, name = NULL, 
                      weight = NULL,
                      samples.per.point = ceiling((10^(3 + sqrt(ncol(data))))/nrow(data)),
                      kde.bandwidth = estimate_bandwidth(data), 
                      sd.count = 3, 
                      quantile.requested = 0.95, 
                      quantile.requested.type = "probability", 
                      chunk.size = 1000, 
                      verbose = TRUE, 
                      ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_gaussian_+3A_data">data</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_name">name</code></td>
<td>

<p>A string to assign to the hypervolume for later output and plotting. Defaults to the name of the variable if NULL.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_weight">weight</code></td>
<td>

<p>An optional vector of weights for the kernel density estimation. Defaults to even weighting (<code>rep(1/nrow(data),nrow(data))</code>) if <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_samples.per.point">samples.per.point</code></td>
<td>

<p>Number of random points to be evaluated per data point in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_kde.bandwidth">kde.bandwidth</code></td>
<td>

<p>A bandwidth vector obtained by running <code><a href="#topic+estimate_bandwidth">estimate_bandwidth</a></code> Note that previous package version (&lt;3.0.0) allowed inputting a scalar/vector value here - this is now handled through the <code><a href="#topic+estimate_bandwidth">estimate_bandwidth</a></code> interface.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_sd.count">sd.count</code></td>
<td>

<p>The number of standard deviations (converted to actual units by multiplying by <code>kde.bandwidth</code>) at which the 'edge' of the hypervolume should be evaluated. Larger values of <code>threshold.sd.count</code> will come closer to a true estimate of the Gaussian density over a larger region of hyperspace, but require rapidly increasing computational resources (see Details section). It is generally better to use a large/default value for this parameter. Warnings will be generated if chosen to take a value less than 3.</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_quantile.requested">quantile.requested</code></td>
<td>
<p>The quantile value used to delineate the boundary of the kernel density estimate. See <code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>.</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_quantile.requested.type">quantile.requested.type</code></td>
<td>
<p>The type of quantile (volume or probability) used for the boundary delineation. See <code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>.</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_chunk.size">chunk.size</code></td>
<td>

<p>Number of random points to process per internal step. Larger values may have better performance on machines with large amounts of free memory. Changing this parameter does not change the output of the function; only how this output is internally assembled.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_gaussian_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to  <code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> object corresponding to the inferred hypervolume.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
  
# low samples per point for CRAN demo
hv = hypervolume_gaussian(penguins_adelie,name='Adelie',samples.per.point=100)
summary(hv)

</code></pre>

<hr>
<h2 id='hypervolume_general_model'>
Generates hypervolume by sampling from arbitrary model object.
</h2><span id='topic+hypervolume_general_model'></span>

<h3>Description</h3>

<p>Uses rejection sampling to obtain predicted values of a model object at uniformly random points within a range box, then converts output to a hypervolume.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_general_model(model, name = NULL, verbose = TRUE, 
  data = NULL, range.box = NULL, num.samples = ceiling(10^(3 + sqrt(ncol(range.box)))), 
  chunk.size = 10000, min.value = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_general_model_+3A_model">model</code></td>
<td>

<p>Any model object which can be used within a <code>predict(model, newdata, ...) call.</code>
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_name">name</code></td>
<td>

<p>Name of the output hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic output.
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_data">data</code></td>
<td>

<p>If not <code>NULL</code>, used to specify <code>range.box=padded_range(data)</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_range.box">range.box</code></td>
<td>

<p>A 2 x n matrix, where n is the number of dimensions of the data, and the first row corresponds to a lower limit and the second row to an upper limit. Each column is thus the low and high limits of the range box along each axis. Can be generated via <code><a href="#topic+padded_range">padded_range</a></code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_num.samples">num.samples</code></td>
<td>

<p>Number of samples to draw from the range box.
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_chunk.size">chunk.size</code></td>
<td>

<p>Number of samples to process in each <code>predict</code> call. Changing this value may affect the speed of function return but not the returned values.
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_min.value">min.value</code></td>
<td>

<p>If <code>TRUE</code>, discards sampled values below this threshold. Effectively used to set hypervolume boundaries.
</p>
</td></tr>
<tr><td><code id="hypervolume_general_model_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to <code>predict</code>, e.g. <code>type='response'</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>Hypervolume</code>-class object corresponding to retained values within the hyperbox of interest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_no_na$is_adelie = penguins_no_na$species=="Adelie"
penguins_no_na = penguins_no_na[,c("is_adelie","bill_length_mm","bill_depth_mm")]


m_glm = glm(is_adelie~.,data=penguins_no_na)

hv_general_glm = hypervolume_general_model(m_glm, 
  range.box=padded_range(penguins_no_na[,2:3]),type='response')
plot(hv_general_glm)	
	
</code></pre>

<hr>
<h2 id='hypervolume_holes'>
Hole detection
</h2><span id='topic+hypervolume_holes'></span>

<h3>Description</h3>

<p>Detects the holes in an observed hypervolume relative to an expectation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_holes(hv.obs, hv.exp, set.num.points.max = NULL, set.check.memory = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_holes_+3A_hv.obs">hv.obs</code></td>
<td>

<p>The observed hypervolume whose holes are to be detected
</p>
</td></tr>
<tr><td><code id="hypervolume_holes_+3A_hv.exp">hv.exp</code></td>
<td>

<p>The expected hypervolume that provides a baseline expectation geometry
</p>
</td></tr>
<tr><td><code id="hypervolume_holes_+3A_set.num.points.max">set.num.points.max</code></td>
<td>

<p>Maximum number of points to be used for set operations comparing <code>hv_obs</code> to <code>hv_exp</code>. Defaults to 10^(3+sqrt(n)), where n is the dimensionality of the input hypervolumes.
</p>
</td></tr>
<tr><td><code id="hypervolume_holes_+3A_set.check.memory">set.check.memory</code></td>
<td>

<p>If <code>TRUE</code>, estimates the memory usage required to perform set operations, then exits. If <code>FALSE</code>, prints resource usage and continues algorithm. It is useful for preventing crashes to check the estimated memory usage on large or high dimensional datasets before running the full algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm has a good Type I error rate (rarely detects holes that do not actually exist). However it can have a high Type II error rate (failure to find holes when they do exist). To reduce this error rate, make sure to re-run the algorithm with input hypervolumes with higher values of <code>@PointDensity</code>, or increase <code>set.num.points.max</code>.
</p>
<p>The algorithm performs the set difference between the observed and expected hypervolumes, then removes stray points in this hypervolume by deleting any random point whose distance from any other random point is greater than expected.
</p>
<p>A 'rule of thumb' is that algorithm has acceptable statistical performance when log_e(m) &gt; n, where m is the number of data points and n is the dimensionality.
</p>


<h3>Value</h3>

<p>A <code>Hypervolume</code> object containing a uniformly random set of points describing the holes in <code>hv_obs</code>. Note that the point density of this object is likely to be much lower than that of the input hypervolumes due to the stochastic geometry algorithms used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# generate annulus data
data_annulus &lt;- data.frame(matrix(data=runif(4000),ncol=2))
names(data_annulus) &lt;- c("x","y")
data_annulus  &lt;- subset(data_annulus, 
sqrt((x-0.5)^2+(y-0.5)^2) &gt; 0.4 &amp; sqrt((x-0.5)^2+(y-0.5)^2) &lt; 0.5)

# MAKE HYPERVOLUME (low reps for fast execution)
hv_annulus &lt;- hypervolume_gaussian(data_annulus,
                kde.bandwidth=0.05,name='annulus',samples.per.point=1)

# GET CONVEX EXPECTATION
hv_convex &lt;- expectation_convex(hypervolume_thin(hv_annulus,num.samples=500),
                check.memory=FALSE,use.random=TRUE)

# DETECT HOLES (low npoints for fast execution)
features_annulus &lt;- hypervolume_holes(
                      hv.obs=hv_annulus, 
                      hv.exp=hv_convex,
                      set.check.memory=FALSE)

# CLEAN UP RESULTS
features_segmented &lt;- hypervolume_segment(features_annulus, 
                        check.memory=FALSE,distance.factor=2)
features_segmented_pruned &lt;- hypervolume_prune(features_segmented, 
                                volume.min=0.02)

# PLOT RETAINED HOLE(S)
plot(hypervolume_join(hv_annulus, features_segmented_pruned))

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_inclusion_test'>
Inclusion test
</h2><span id='topic+hypervolume_inclusion_test'></span>

<h3>Description</h3>

<p>Determines if a set of points are within a hypervolume. Can operate using a 'fast' algorithm which determines whether at least one random point of the hypervolume is within a critical distance of the test point. This algorithm is very efficient but leads to noisy and error-prone results when the point density slow. A warning is generated if this algorithm is used.
</p>
<p>The function can also operate using an 'accurate' algorithm which estimates the probability density at the test point, and rejects it if it is below the requested threshold value. This is very slow but guarantees good results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_inclusion_test(hv, points, reduction.factor = 1, fast.or.accurate =
                 "fast", fast.method.distance.factor = 1,
                 accurate.method.threshold =
                 quantile(hv@ValueAtRandomPoints,
                 0.5), verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_inclusion_test_+3A_hv">hv</code></td>
<td>

<p>n-dimensional hypervolume to compare against
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_points">points</code></td>
<td>

<p>Candidate points. A m x n matrix or dataframe, where m is the number of candidate points and n is the number of dimensions.
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_reduction.factor">reduction.factor</code></td>
<td>

<p>A number in (0,1] that represents the fraction of random points sampled from the hypervolume for the stochastic inclusion test. Larger values are more accurate but computationally slower.
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_fast.or.accurate">fast.or.accurate</code></td>
<td>

<p>If <code>'fast'</code>, uses the critical distance test. If <code>'accurate'</code>, uses a probability density estimate.
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_fast.method.distance.factor">fast.method.distance.factor</code></td>
<td>

<p>Numeric value; multiplicative factor applied to the critical distance for all inclusion tests (see below). Used only when <code>fast.or.accurate='fast'</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_accurate.method.threshold">accurate.method.threshold</code></td>
<td>

<p>Numeric value; threshold probability value below which the point is determined to be out of the hypervolume. Used only when <code>fast.or.accurate='accurate'</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if true.
</p>
</td></tr>
<tr><td><code id="hypervolume_inclusion_test_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to either <code><a href="#topic+hypervolume_estimate_probability">hypervolume_estimate_probability</a></code> or <code><a href="#topic+hypervolume_inclusion_test">hypervolume_inclusion_test</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A m x 1 logical vector indicating whether each candidate point is in the hypervolume.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# construct a hypervolume of points in the unit square [0,1] x [0,1]
data = data.frame(x=runif(100,min=0,max=1), y=runif(100,min=0,max=1))
hv = hypervolume_gaussian(data)

# test if (0.5,0.5) and (-1,1) are in - should return TRUE FALSE
hypervolume_inclusion_test(hv, points=data.frame(x=c(0.5,-1),y=c(0.5,-1)))

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_join'>
Concatenate hypervolumes
</h2><span id='topic+hypervolume_join'></span>

<h3>Description</h3>

<p>Combines multiple hypervolumes or hypervolume lists into a single HypervolumeList suitable for analysis or plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_join(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_join_+3A_...">...</code></td>
<td>

<p>One or more objects of class <code>Hypervolume</code> or <code>HypervolumeList</code>, or a <code>list()</code> of <code>Hypervolume</code> objects.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>HypervolumeList</code> containing all hypervolumes in all arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
penguins_chinstrap = penguins_no_na[penguins_no_na$species=="Chinstrap",
                      c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv1 = hypervolume_box(penguins_adelie,name='Adelie')
hv2 = hypervolume_box(penguins_chinstrap,name='Chinstrap')

hvs_joined = hypervolume_join(hv1, hv2)
</code></pre>

<hr>
<h2 id='hypervolume_n_occupancy'>
Operations for groups of hypervolumes
</h2><span id='topic+hypervolume_n_occupancy'></span><span id='topic+hypervolume_n_occupancy_bootstrap'></span>

<h3>Description</h3>

<p>Computes the occupancy of hyperspace by one or more groups of hypervolumes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_n_occupancy(hv_list,
                        classification = NULL,
                        method = "subsample",
                        FUN = mean,
                        num.points.max = NULL,
                        verbose = TRUE,
                        distance.factor = 1,
                        check.hyperplane = FALSE,
                        box_density = 5000,
                        thin = FALSE,
                        quant.thin = 0.5,
                        seed = NULL,
                        print_log = FALSE)
                        
hypervolume_n_occupancy_bootstrap(path,
                                  name = NULL,
                                  classification = NULL,
                                  method = "subsample",
                                  FUN = mean,
                                  num.points.max = NULL,
                                  verbose = TRUE,
                                  distance.factor = 1,
                                  check.hyperplane = FALSE,
                                  box_density = 5000,
                                  thin = FALSE,
                                  quant.thin = 0.5,
                                  seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_n_occupancy_+3A_hv_list">hv_list</code></td>
<td>

<p>An <code>HypervolumeList</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_classification">classification</code></td>
<td>

<p>A vector assigning each hypervolume in the <code>HypervolumeList</code> to a group.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_method">method</code></td>
<td>

<p>Can be <code>subsample</code> or <code>box</code>. See details.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_fun">FUN</code></td>
<td>

<p>A function to aggregate points within each group. Default to <code>mean</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_num.points.max">num.points.max</code></td>
<td>

<p>Maximum number of random points to use for set operations. If <code>NULL</code> defaults to 10^(3+sqrt(n)) where n is the dimensionality of the input hypervolumes. Note that this default parameter value has been increased by a factor of 10 since the 1.2 release of this package.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_distance.factor">distance.factor</code></td>
<td>

<p>Numeric value; multiplicative factor applied to the critical distance for all inclusion tests (see below). Recommended to not change this parameter.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_check.hyperplane">check.hyperplane</code></td>
<td>

<p>Check if data is hyperplanar.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_box_density">box_density</code></td>
<td>

<p>Density of random points to fill the hyperbox when method is equal to <code>box</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_thin">thin</code></td>
<td>

<p>Take a subsample of random points to get a more uniform distribution of random points. Intended to be used with <code>method = "subsample"</code>, but can be used with <code>method = "box"</code> too. Can be slow, especially in high dimensions. See details.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_quant.thin">quant.thin</code></td>
<td>

<p>Set quantile for using when <code>thin = TRUE</code>. See details.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_seed">seed</code></td>
<td>

<p>Set seed for random number generation. Useful for having reproducible results and with the use of <code><a href="#topic+find_optimal_occupancy_thin">find_optimal_occupancy_thin()</a></code>
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_print_log">print_log</code></td>
<td>

<p>Save a log file with the volume of each input hypervolume, recomputed volume and the ratio between the original and recomputed hypervolumes. It works for <code>hypervolume_n_occupancy()</code> only.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_path">path</code></td>
<td>

<p>A path to a directory of bootstrapped hypervolumes obtained with <br />
<code>hypervolume_n_resample()</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_+3A_name">name</code></td>
<td>

<p>File name; The function writes hypervolumes to file in &quot;./Objects/&lt;name&gt;&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the inclusion test approach to count how many hypervolumes include each random point. Counts range from 0 (no hypervolumes contain a given random point), to the number of hypervolumes in a group (all the hypervolumes contain a given random point). A function <code>FUN</code>, usually <code>mean</code> or <code>sum</code>, is then applied. A hypervolume is then returned for each group and the occupancy stored in <code>ValueAtRandomPoints</code>. IMPORTANT: random points with 
<code>ValueAtRandomPoints</code> equal to 0 are not removed to ease downstream calculation. <br />
When <code>method = "subsample"</code> the computation is performed on a random sample from input hypervolumes, constraining each to have the same point density given by the minimum of the point density of each input hypervolume and the point density calculated using the volumes of each input hypervolume divided by <code>num.points.max</code>. <br />
Because this algorithm is based on distances calculated between the distributions of random points, the critical distance (point density ^ (-1/n)) can be scaled by a user-specified factor to provide more or less liberal estimates (<code>distance_factor</code> greater than or less than 1). <br />
Two methods can be used for calculating the occupancy. The method <code>subsample</code> is based on a random sample of points from input hypervolumes. Each point is selected with a probability set to the inverse of the number of neighbour points calculated according to the critical distance. This method performs accurately when input hypervolumes have a low degree of overlap. The method <code>box</code> create a bounding box around the union of input hypervolumes. The bounding box is filled with points following a uniform distribution and with a density set with the argument <code>box_density</code>. A greater density usually provides more accurate results. The method <code>box</code> performs better than the method <code>subsample</code> in low dimensions, while in higher dimensions the method <code>box</code> become computationally inefficient as nearly all of the hyperbox sampling space will end up being empty and most of the points will be rejected. <br />
When <code>verbose = TRUE</code> the volume of each input hypervolume will be printed to screen togheter with the recomputed volume and the ratio between the original and recomputed hypervolumes. Mean absolute error (MAE) and root mean square error (RMSE) are also provided as overall measures of the goodness of fit. A log file will be saved in the working directory with the information about the volume of input hypervolumes, the recomputed volume and the ratio between the original and recomputed hypervolumes. <br />
When <code>thin = TRUE</code> an algorithm is applied to try to make the distribution of random points more uniform. Moderate departures from uniform distribution can in fact result from applying <code>hypervolume_n_occupancy()</code> on hypervolumes with a high overlap degree. At first, the algorithm in <code>thin</code> calculates the minimum distance from the neighboor points within the critical distance for each random point. A quantile (set with <code>quant.thin</code>) of these distances is taken and set as the threshold distance. Random points are then subset so that the distance of a point to another is greater than the threshold distance. <br />
The function <code>hypervolume_n_occupancy_bootstrap()</code> takes a path of bootstrapped hypervolumes generated with <code>hypervolume_n_resample()</code> as input. It creates a directory called Objects in the current working directory if a directory of that name doesn't already exist where storing occupancy objects. The function <code>hypervolume_n_occupancy_bootstrap()</code> returns the absolute path to the directory with bootstrapped hypervolumes. It automatically saves a log file with the volume of each input hypervolume, the recomputed volume and the ratio between the original and recomputed hypervolumes. The log file is used with <code>occupancy_bootstrap_gof()</code>.
</p>


<h3>Value</h3>

<p><code>hypervolume_n_occupancy()</code> returns a <code>Hypervolume</code> or <code>HypervolumeList</code> whose number of hypervolumes equals the number of groups in <code>classification</code>. <code>hypervolume_n_occupancy_bootstrap()</code> returns a string containing an absolute path equivalent to ./Objects/&lt;name&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_optimal_occupancy_thin">find_optimal_occupancy_thin</a></code>, <code><a href="#topic+occupancy_bootstrap_gof">occupancy_bootstrap_gof</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
                        paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))


# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
  x = penguins_no_na_split, 
  y = names(penguins_no_na_split))

hv_list &lt;- hypervolume_join(hv_list)

# calculate occupancy without groups
hv_occupancy &lt;- hypervolume_n_occupancy(hv_list)
plot(hv_occupancy, cex.random = 1)

# calculate occupancy with groups
hv_occupancy_list_sex &lt;- hypervolume_n_occupancy(hv_list, 
                          classification = rep(c("female", "male"), each = 3))

plot(hv_occupancy_list_sex, cex.random = 1, show.density = FALSE)


### hypervolume_n_occupancy_bootstrap  ###

# bootstrap the hypervolumes
hv_list_boot = hypervolume_n_resample(name = "example", hv_list)

# calculate occupancy on bootstrapped hypervolumes
hv_occupancy_boot_sex = hypervolume_n_occupancy_bootstrap(path = hv_list_boot,
                                    name = "example_occ",
                                    classification = rep(c("female", "male"), 3))


## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_n_occupancy_permute'>
Hypervolumes through permuting labels of n pairwise groups of hypervolumes
</h2><span id='topic+hypervolume_n_occupancy_permute'></span>

<h3>Description</h3>

<p>Permute labels of an <code>hypervolume_n_occupancy()</code> object and calculate <code>hypervolume_n_occupancy()</code> for the permuted objects. This function is meant for taking a sample of all permutations and does not guarantee that permutations are not repeated. Newly generated hypervolume objects are written to file. This function is to be used within the occupancy routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_n_occupancy_permute(name, 
                                hv_list1,
                                hv_list2,
                                verbose = TRUE,
                                n = 9,
                                cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_n_occupancy_permute_+3A_name">name</code></td>
<td>

<p>File name; The function writes hypervolumes to file in ./Objects/&lt;name&gt;
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_permute_+3A_hv_list1">hv_list1</code></td>
<td>

<p>An hypervolume list generated with <code>hypervolume_n_occupancy()</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_permute_+3A_hv_list2">hv_list2</code></td>
<td>

<p>The hypervolume list used to generate <code>hv_list1</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_permute_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; outputs progress bar in console.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_permute_+3A_n">n</code></td>
<td>

<p>Number of permutations to take.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_permute_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating permuted hypervolumes. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in <code>cores</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hypervolume_n_occupancy_permute()</code> creates a directory called Objects in the current working directory if a directory of that name doesn't already exist. Within this directory, it creates a directory for each pairwise combinations of elements within <code>hv_list1</code>. Group labels are permuted and a new <code>HypervolumeList</code> is saved as a rds file for each pairwise combination. IMPORTANT: only group labels are permuted, random points are kept fixed and will be the same across all the permuted hypervolumes. 
</p>
<p><code>hypervolume_n_occupancy_test()</code> takes in a <code>hypervolume_n_occupuancy_permute()</code> filepath output.
</p>
<p>It is also possible to access the hypervolumes by using readRDS to read the hypervolume objects in one by one.
</p>


<h3>Value</h3>

<p>Returns a string containing an absolute path equivalent to ./Objects/&lt;name&gt;
</p>


<h3>Warning</h3>

<p><code>hypervolume_n_occupancy_permute()</code> requires a lot of disk space especially when building occupancy hypervolumes with <code>method = "box"</code>. Try with a small number of replications and check the folder Objects for memory usage before to proceed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))


# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
                        paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))


# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
  x = penguins_no_na_split, 
  y = names(penguins_no_na_split))
  

names(hv_list) &lt;- names(penguins_no_na_split)
hv_list &lt;- hypervolume_join(hv_list)


hv_occupancy_list_sex &lt;- hypervolume_n_occupancy(hv_list, 
                              classification = rep(c("female", "male"), each = 3))

# takes 9 permutations on 1 core
hypervolume_n_occupancy_permute("permute", hv_occupancy_list_sex,
                                hv_list , n = 9, cores = 1)




## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_n_occupancy_test'>
Significance of random points occupancy
</h2><span id='topic+hypervolume_n_occupancy_test'></span>

<h3>Description</h3>

<p>The function <code>hypervolume_n_occupancy_test()</code> calculates the significance of the difference between occupancy values for each random point and for all the pairwise combinations of groups in objects generated with <code>hypervolume_n_occupancy()</code> and <code>hypervolume_n_occupancy_permute()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_n_occupancy_test(observed,
                             path,
                             alternative = "two_sided",
                             significance = 0.05,
                             cores = 1, 
                             p_adjust = "none",
                             multi_comp_type = "pairwise")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_n_occupancy_test_+3A_observed">observed</code></td>
<td>

<p>An <code>HypervolumeList</code> generated from <code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy()</a></code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_test_+3A_path">path</code></td>
<td>

<p>A path to a directory of permuted hypervolumes generated with <code><a href="#topic+hypervolume_n_occupancy_permute">hypervolume_n_occupancy_permute()</a></code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_test_+3A_alternative">alternative</code></td>
<td>

<p>Alternative hypothesis, can be one of <code>two_sided</code>, <code>more</code> or <code>less</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_test_+3A_significance">significance</code></td>
<td>

<p>Significance values lower than this threshold will be retained.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_test_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating permuted hypervolumes. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in <code>cores</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_test_+3A_p_adjust">p_adjust</code></td>
<td>

<p>Method of correction for multiple comparisons, set to <code>none</code> by default. Otherwise look at <code>p.adjust</code> of the <code>stats</code> package for alternatives.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_occupancy_test_+3A_multi_comp_type">multi_comp_type</code></td>
<td>

<p>Type of multiple comparison. Can be <code>pairwise</code>, for which the number of comparisons is set to the length of <code>ValueAtRandomPoints</code>, <code>all</code>,  for which the number of comparisons is set to the length of <code>ValueAtRandomPoints</code> times the number of groups, or <code>none</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed difference between <code>ValueAtRandomPoints</code> of two groups is compared against null expectations generated with <code>hypervolume_n_occupancy_permute()</code>. 
</p>


<h3>Value</h3>

<p>An <code>HypervolumeList</code> of length equal to the number of pairwise combinations of the observed <code>HypervolumeList</code> elements. <code>ValueAtRandomPoints</code> are calculated as the difference between the <code>ValueAtRandomPoints</code> of the first and the second group for each pairwise combination. Only significant values are retained according to <code>significance</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))


# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
                        paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))


# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
  x = penguins_no_na_split, 
  y = names(penguins_no_na_split))

names(hv_list) &lt;- names(penguins_no_na_split)
hv_list &lt;- hypervolume_join(hv_list)


hv_occupancy_list_sex &lt;- hypervolume_n_occupancy(hv_list, 
                              classification = rep(c("female", "male"), each = 3))

# takes 9 permutations on 1 core
hyper_permuted &lt;- hypervolume_n_occupancy_permute("permute", hv_occupancy_list_sex,
                                hv_list , n = 99, cores = 1)

hypervolume_test &lt;- hypervolume_n_occupancy_test(hv_occupancy_list_sex, hyper_permuted, 
                      alternative = "more", significance = 0.1)



## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_n_resample'>
Bootstrap n hypervolumes
</h2><span id='topic+hypervolume_n_resample'></span>

<h3>Description</h3>

<p>The function <code>hypervolume_n_resample()</code> generates n hypervolumes using data bootstrapped from original data of the input hypervolumes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_n_resample(name,
                       hv_list,
                       n = 10,
                       points_per_resample = 'sample_size',
                       cores = 1,
                       verbose = TRUE,
                       seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_n_resample_+3A_name">name</code></td>
<td>

<p>File name; The function writes hypervolumes to file in &quot;./Objects/&lt;name&gt;&quot;&quot;
</p>
</td></tr>
<tr><td><code id="hypervolume_n_resample_+3A_hv_list">hv_list</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_resample_+3A_n">n</code></td>
<td>

<p>Number of resamples to take.
Used for every method.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_resample_+3A_points_per_resample">points_per_resample</code></td>
<td>

<p>Number of points in each resample. If the input is <code>sample_size</code>, then the same number of points as the original sample is used.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_resample_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating bootstraped hypervolumes. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in <code>cores</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_resample_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; If function is being run sequentially, outputs progress bar in console.
</p>
</td></tr>
<tr><td><code id="hypervolume_n_resample_+3A_seed">seed</code></td>
<td>

<p>Set seed for random number generation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hypervolume_n_resample()</code> creates a directory called Objects in the current working directory if a directory of that name doesn't already exist. A directory is then created for each hypervolume in <code>hv_list</code>. Returns an absolute path to directory with resampled hypervolumes. <br />
It is possible to access the hypervolumes by using readRDS to read the hypervolume objects one by one. <br />
The resampled hypervolumes are generated using the same parameters used to generate the input hypervolume. The only exception is that the bandwidth is re-estimated if <code>method = "gaussian"</code> or <code>method = "box"</code>. See <code><a href="#topic+copy_param_hypervolume">copy_param_hypervolume</a></code> for more details.
</p>


<h3>Value</h3>

<p>Returns a string containing an absolute path equivalent to ./Objects/&lt;name&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy_bootstrap">hypervolume_n_occupancy_bootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

library(palmerpenguins)
data(penguins)
bill_data = na.omit(penguins[,3:4])
hv = hypervolume(bill_data)

# Example 1: get 50 resampled hypervolumes for each input hypervolume
# Use detectCores to see how many cores are availible in current environment
# Set cores = 1 to run sequentially (default)
# bootstrap the hypervolumes
hv_list_boot = hypervolume_n_resample(name = "example", hv_list, n = 50)


## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_overlap_confidence'>
Confidence intervals for overlap statistics
</h2><span id='topic+hypervolume_overlap_confidence'></span>

<h3>Description</h3>

<p>Generates confidence intervals of four different overlap statistics. In order to find the confidence interval for the overlap statistics of two hypervolumes, use <code>hypervolume_resample</code> twice to generate bootstraps. The function takes in paths to two sets of bootstrapped hypervolumes and gets overlap statistics for each possible pair. Confidence interval is calculated by taking a quantile of generated overlap statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_overlap_confidence(path1, path2, CI = .95, cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_overlap_confidence_+3A_path1">path1</code></td>
<td>

<p>A path to a directory of bootstrapped hypervolumes
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_confidence_+3A_path2">path2</code></td>
<td>

<p>A path to a directory of bootstrapped hypervolumes
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_confidence_+3A_ci">CI</code></td>
<td>

<p>Desired confidence interval proportion
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_confidence_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating overlap statistics. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The four overlap statistics are Sorensen, Jaccard, frac_unique_1, frac_unique_2. See <code><a href="#topic+hypervolume_overlap_statistics">hypervolume_overlap_statistics</a></code>
</p>
<p>Each hypervolume from path1 is overlapped with each hypervolume from path2 using <code>hypervolume_set</code>. The four overlap statistics are calculated for each overlap.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>jaccard</code></td>
<td>

<p>Confidence interval for jaccard similarity score
</p>
</td></tr>
<tr><td><code>sorensen</code></td>
<td>

<p>Confidence interval for sorensen similarity score
</p>
</td></tr>
<tr><td><code>frac_unique_1</code></td>
<td>

<p>Confidence interval for fraction of first hypervolume that is unique
</p>
</td></tr>
<tr><td><code>frac_unique_2</code></td>
<td>

<p>Confidence interval for fraction of second hypervolume that is unique
</p>
</td></tr>
<tr><td><code>distribution</code></td>
<td>

<p>a matrix of overlap statistics used to generate the confidence intervals
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_resample">hypervolume_resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Let us overlap two hypervolumes generated from multivariate nomral 
# distributions with different means and same covariance matrices.
sample1 = rmvnorm(150, mean = c(0, 0))
sample2 = rmvnorm(150, mean = c(0.5, 0.5))

hv1 = hypervolume(sample1)
hv2 = hypervolume(sample2)

# generates confidence intervals from quantiles of 20*20 overlaps
path1 = hypervolume_resample("mean_0_0", hv1, n = 20)
path2 = hypervolume_resample("mean_0.5_0.5", hv2, n = 20)

result = hypervolume_overlap_confidence(path1, path2)
# confidence index of Sorensen coefficient
print(result["sorensen"])


## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_overlap_statistics'>
Overlap statistics for set operations (Sorensen, Jaccard, etc.)
</h2><span id='topic+hypervolume_overlap_statistics'></span>

<h3>Description</h3>

<p>Calculates overlap metrics for two hypervolumes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_overlap_statistics(hvlist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_overlap_statistics_+3A_hvlist">hvlist</code></td>
<td>

<p>A set of hypervolumes calculated from <code><a href="#topic+hypervolume_set">hypervolume_set</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A set of multiple metrics
</p>
<table role = "presentation">
<tr><td><code>jaccard</code></td>
<td>
<p>Jaccard similarity (volume of intersection of 1 and 2 divided by volume of union of 1 and 2)</p>
</td></tr>
<tr><td><code>sorensen</code></td>
<td>
<p>Sorensen similarity (twice the volume of intersection of 1 and 2 divided by volume of 1 plus volume of 2)</p>
</td></tr>
<tr><td><code>frac_unique_1</code></td>
<td>
<p>Unique fraction 1 (volume of unique component of 1 divided by volume of 1))</p>
</td></tr>
<tr><td><code>frac_unique_2</code></td>
<td>
<p>Unique fraction 2 (volume of unique component of 2 divided by volume of 2))</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
penguins_chinstrap = penguins_no_na[penguins_no_na$species=="Chinstrap",
                      c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv1 = hypervolume_box(penguins_adelie,name='Adelie')
hv2 = hypervolume_box(penguins_chinstrap,name='Chinstrap')

hv_set &lt;- hypervolume_set(hv1, hv2, check.memory=FALSE)

hypervolume_overlap_statistics(hv_set)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_overlap_test'>
Null distribution for overlap statistics
</h2><span id='topic+hypervolume_overlap_test'></span>

<h3>Description</h3>

<p>Generates null distribution of four different overlap statistics under the null hypothesis that two samples are drawn from the same population.
Observed value of overlap statistic is calculated from inputed hypervolumes.
calculates p value for observed value of each statistic with respect to the generated null distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_overlap_test(hv1, hv2, path, alternative = "one-sided", bins = 100, cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_overlap_test_+3A_hv1">hv1</code></td>
<td>

<p>A hypervolume object
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_test_+3A_hv2">hv2</code></td>
<td>

<p>A hypervolume object
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_test_+3A_path">path</code></td>
<td>

<p>a path to a directory containing permuted hypervolumes, bootstrapped hypervolumes, or a vector of two paths to bootstrapped hypervolumes
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_test_+3A_alternative">alternative</code></td>
<td>

<p>&quot;one-sided&quot; or &quot;two-sided&quot;
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_test_+3A_bins">bins</code></td>
<td>

<p>plotting parameter for histogram of overlap statistics
</p>
</td></tr>
<tr><td><code id="hypervolume_overlap_test_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating overlap statistics. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generating overlap statistics can be parallelized using the <code>cores</code> argument.  
</p>
<p>hypervolume_overlap_test can generate a null distribution from the output of hypervolume_permute, hypervolume_resample with method = &quot;bootstrap&quot;, or a vector of two bootstrap outputs. See examples for how to use each case.
</p>
<p>path should point to hypervolumes generated from the two input hypervolumes. There are three valid choices:
</p>
<p>path is generated from <code>hypervolume_permute(&lt;name&gt;, hv1, hv2, ...)</code>. In this case the null distribution is generated by taking the overlap statistics of every single pair of permutations and turning them into a histogram.
</p>
<p>OR
</p>
<p>path is generated by resampling the hypervolume generated by combining the data of hv1 and hv2
If the number of data points used to generate hv1 is the same as hv2 then the path is <code>hypervolume_resample(&lt;name&gt;, hv_combined, "bootstrap", points_per_resample = nrow(hv1@Data))</code>. In this case, the list bootstrapped hypervolumes is split in half and overlap statistics are taken for every possible pair of hypervolumes from the two halves. A histogram of these overlap statitics represent the null distribution.
</p>
<p>If the number of data points is different between hv1 and hv2 path is a list of two paths generated from <code>hypervolume_resample(&lt;name&gt;, hv_combined, "bootstrap", points_per_resample = nrow(hv1@Data), ...)</code> and <code>hypervolume_resample(&lt;name&gt;, hv_combined, "bootstrap", points_per_resample = nrow(hv2@Data), ...)</code>. Overlap statistics are taken for every possible pair of hypervolumes from each bootstrap. A histogram of these overlap statitics represent the null distribution.
See example for appropriate path inputs. 
</p>
<p>The four overlap statistics are Sorensen, Jaccard, frac_unique_1, frac_unique_2. See <code><a href="#topic+hypervolume_overlap_statistics">hypervolume_overlap_statistics</a></code> for description of the statistics.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>p_values</code></td>
<td>

<p>a list of p_values indexed by the name of the relevant statistic
</p>
</td></tr>
<tr><td><code>plots</code></td>
<td>

<p>a list of ggplot objects indexed by the name of the relevant statistic. The observed value of each statistic is represented as a vertical line on the x axis.
</p>
</td></tr>
<tr><td><code>distribution</code></td>
<td>

<p>a matrix of overlap statistics used to generate the null distribution
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_resample">hypervolume_resample</a></code>, <code><a href="#topic+hypervolume_permute">hypervolume_permute</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# We will use the data in "quercus" as our population in this example
data("quercus")
# Consider taking two samples of size 150 from the population and you want to figure out whether
# the samples are similar by seeing if they occupy the same area in feature space.
qsample1 = quercus[sample(1:nrow(quercus), 150),]
qsample2 = quercus[sample(1:nrow(quercus), 150),]

# Construct two hypervolumes from the samples
hv1 = hypervolume(qsample1[,2:3])
hv2 = hypervolume(qsample2[,2:3])

# Approach 1
# Take 200 permutations of the 300 data points. Using more cores is faster.
perm_path = hypervolume_permute("Quercus_perm_150", hv1, hv2, n = 200, cores = 20)

# hypervolume_overlap_test takes perm_path as an input. 
# Results include p values for the overlap statistics of hv1 and hv2 as well as 
# the corresponding null distributions generated from perm_path.
results1 = hypervolume_overlap_test(hv1, hv2, perm_path, cores = 20)

# Approach 2
# Under our null hypothesis the samples come from the same population. 
# Approximate the original population by combining the data
# then simulate drawing 150 data points 50 times.
hv_combine = hypervolume(rbind(qsample1[,2:3],qsample2[,2:3]))
bootstrap_path = hypervolume_resample("Quercus_boot_150", 
                                        hv_combine, 
                                        method = "bootstrap", 
                                        n = 50, 
                                        points_per_resample = 150, 
                                        cores = 20)

# hypervolume_overlap_test splits the 50 resampled hypervolumes in half and gets
# overlap statistic for each of the 25*25 pairs to generate the null 
# distribution. This method allows us to approximate the null distribution using
# 625 data points while only generating 50 hypervolumes as opposed to 
# hypervolume_permute which uses 400 hypervolumes to generate 200 data points.
results2 = hypervolume_overlap_test(hv1, hv2, bootstrap_path)

# Approach 3
# Suppose we have a size 300 sample and a size 150 sample and we want to know 
# whether they come from the same distribution.
qsample3 = quercus[sample(1:nrow(quercus), 300),]
hv3 = hypervolume(qsample3[,2:3])

# Permutation still works in this case, however we can also use bootstrap by 
# combining the data and drawing size 150 then size 300 samples.
hv_combine = hypervolume(rbind(qsample1[,2:3],qsample3[,2:3]))
b150_path = resample("Quercus_150", 
                      hv_combine, 
                      method = "bootstrap", 
                      n = 25, 
                      points_per_resample = 150, 
                      cores = 20)
b300_path = resample("Quercus_300", 
                      hv_combine, 
                      method = "bootstrap", 
                      n = 25, 
                      points_per_resample = 300, 
                      cores = 20)

# hypervolume_overlap_test generates overlap statistics for each of the 25*25 
# possible pairs of size 150 and size 300 hypervolumes.
results3 = hypervolume_overlap_test(hv1, hv2, c(b150_path, b300_path), cores = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_permute'>
Hypervolumes through permuting data of two hypervolumes
</h2><span id='topic+hypervolume_permute'></span>

<h3>Description</h3>

<p>Takes two data of two hypervolume objects (with the same column labels) and generates pairs of hypervolumes with the original sizes of the input hypervolumes but with permuted data (the rows of the original hypervolumes' data are combined and redistributed to the two new hypervolumes). This function is meant for taking a sample of all permutations and does not guarantee that permutations are not repeated. Newly generated hypervolume objects are written to file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_permute(name, 
                    hv1, 
                    hv2, 
                    n = 50, 
                    cores = 1, 
                    verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_permute_+3A_name">name</code></td>
<td>

<p>File name; The function writes hypervolumes to file in ./Objects/&lt;name&gt;
</p>
</td></tr>
<tr><td><code id="hypervolume_permute_+3A_hv1">hv1</code></td>
<td>

<p>A hypervolume object
</p>
</td></tr>
<tr><td><code id="hypervolume_permute_+3A_hv2">hv2</code></td>
<td>

<p>A hypervolume object
</p>
</td></tr>
<tr><td><code id="hypervolume_permute_+3A_n">n</code></td>
<td>

<p>number of permutations to take
</p>
</td></tr>
<tr><td><code id="hypervolume_permute_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating permuted hypervolumes. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in cores.
</p>
</td></tr>
<tr><td><code id="hypervolume_permute_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; If function is being run sequentially, outputs progress bar in console.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hypervolume_permute</code> creates a directory called Objects in the current working directory if a directory of that name doesn't already exist. Returns an absolute path to directory with permuted hypervolumes. rds files are stored in separate subdirectories for each permutation. Use <code>hypervolume_permute</code> when generating null distribution of overlap statistics. <code><a href="#topic+hypervolume_overlap_test">hypervolume_overlap_test</a></code> takes in a <code>hypervolume_permute</code> filepath output.
</p>
<p>It is also possible to access the hypervolumes by using readRDS to read the hypervolume objects in one by one.
</p>


<h3>Value</h3>

<p>returns a string containing an absolute path equivalent to ./Objects/&lt;name&gt;
</p>


<h3>See Also</h3>

<p><code>hypervolume_overlap_test</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("quercus")
# For this example consider taking two samples of size 150 from the data.
qsample1 = quercus[sample(1:nrow(quercus), 150),]
qsample2 = quercus[sample(1:nrow(quercus), 150),]

# Construct two hypervolumes from the samples
hv1 = hypervolume(qsample1[,2:3])
hv2 = hypervolume(qsample2[,2:3])

# Take 200 permutations of the 300 data points. Using more cores is faster.
perm_path = hypervolume_permute("Quercus_perm_150", hv1, hv2, n = 200, cores = 20)

# hypervolume_overlap_test takes perm_path as an input.
# Results include p value for the overlap statistics of hv1 and hv2 as well as
# null distribution generated from perm_path. The null distribution assumes data
# for hv1 and hv2 are drawn from the same distribution and permuting data will 
# not change the overlap statitsics.
results = hypervolume_overlap_test(hv1, hv2, perm_path)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_project'>
Geographical projection of hypervolume for species distribution modeling, using the hypervolume as the environmental niche model.
</h2><span id='topic+hypervolume_project'></span>

<h3>Description</h3>

<p>Determines a suitability score by calculating the hypervolume value at each of a set of points in an input raster stack based on either a probability density estimation or inclusion test.
</p>
<p>Note that projected values are not normalized and are not necessarily constrained to fall between 0 and 1.
</p>
<p>Note also that additional arguments can be passed to this function to enable parallel operation (see ... below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_project(hv, rasters, type = "probability", verbose = TRUE,
                 ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_project_+3A_hv">hv</code></td>
<td>

<p>An input hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_project_+3A_rasters">rasters</code></td>
<td>

<p>A <code>RasterStack</code> with the same names as the dimension names of the hypervolume.
</p>
</td></tr>
<tr><td><code id="hypervolume_project_+3A_type">type</code></td>
<td>

<p>If <code>'probability'</code>, suitability scores correspond to probability density values estimated using <code><a href="#topic+hypervolume_estimate_probability">hypervolume_estimate_probability</a></code>; if <code>'inclusion'</code>, scores correspond to binary presence/absence values from calling <code><a href="#topic+hypervolume_inclusion_test">hypervolume_inclusion_test</a></code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_project_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to either <code><a href="#topic+hypervolume_estimate_probability">hypervolume_estimate_probability</a></code> or <code><a href="#topic+hypervolume_inclusion_test">hypervolume_inclusion_test</a></code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_project_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic and progress output.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>raster</code> object of same resolution and extent as the input layers corresponding to suitability values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_estimate_probability">hypervolume_estimate_probability</a></code>, <code><a href="#topic+hypervolume_inclusion_test">hypervolume_inclusion_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # load in lat/lon data
  data('quercus') 
  data_alba = subset(quercus, Species=="Quercus alba")[,c("Longitude","Latitude")]
  data_alba = data_alba[sample(1:nrow(data_alba),500),]
   
  # get worldclim data from internet
  require(maps)
  require(raster)
  climatelayers = getData('worldclim', var='bio', res=10, path=tempdir())
    
  # z-transform climate layers to make axes comparable
  climatelayers_ss = climatelayers[[c(1,12)]]
  for (i in 1:nlayers(climatelayers_ss))
  {
    climatelayers_ss[[i]] &lt;- 
    	(climatelayers_ss[[i]] - cellStats(climatelayers_ss[[i]], 'mean')) / 
    	cellStats(climatelayers_ss[[i]], 'sd') 
  }
  climatelayers_ss = crop(climatelayers_ss, extent(-150,-50,15,60))
  
  # extract transformed climate values
  climate_alba = extract(climatelayers_ss, data_alba[1:300,])
  
  # compute hypervolume
  hv_alba &lt;- hypervolume_gaussian(climate_alba)
  
  # do geographical projection
  raster_alba_projected_accurate &lt;- hypervolume_project(hv_alba, 
                                      rasters=climatelayers_ss)
  raster_alba_projected_fast = hypervolume_project(hv_alba, 
                                      rasters=climatelayers_ss, 
                                      type='inclusion',
                                      fast.or.accurate='fast')
  
  # draw map of suitability scores
  plot(raster_alba_projected_accurate,xlim=c(-100,-60),ylim=c(25,55))
  map('usa',add=TRUE)
  
  plot(raster_alba_projected_fast,xlim=c(-100,-60),ylim=c(25,55))
  map('usa',add=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_prune'>
Removes small hypervolumes from a HypervolumeList
</h2><span id='topic+hypervolume_prune'></span>

<h3>Description</h3>

<p>Identifies hypervolumes characterized either by a  number of uniformly random points or a volume below a user-specified value and removes them from a <code>HypervolumeList</code>. 
</p>
<p>This function is useful for removing small features that can occur stochastically during segmentation after set operations or hole detection. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_prune(hvlist, num.points.min = NULL, volume.min = NULL, return.ids=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_prune_+3A_hvlist">hvlist</code></td>
<td>

<p>A <code>HypervolumeList</code> object.
</p>
</td></tr>
<tr><td><code id="hypervolume_prune_+3A_num.points.min">num.points.min</code></td>
<td>

<p>The minimum number of points in each input hypervolume.
</p>
</td></tr>
<tr><td><code id="hypervolume_prune_+3A_volume.min">volume.min</code></td>
<td>

<p>The minimum volume in each input hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_prune_+3A_return.ids">return.ids</code></td>
<td>

<p>If <code>TRUE</code>, returns indices of input list as well as a pruned hypervolume list
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>minnp</code> or <code>minvol</code> (but not both) must be specified.
</p>


<h3>Value</h3>

<p>A <code>HypervolumeList</code> pruned to only those hypervolumes of sizes above the desired value. If <code>returnids=TRUE</code>, instead returns a list structure with first item being the <code>HypervolumeList</code> and the second item being the indices of the retained hypervolumes.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_holes">hypervolume_holes</a></code>, <code><a href="#topic+hypervolume_segment">hypervolume_segment</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv = hypervolume_gaussian(penguins_adelie,name='Adelie')

hv_segmented &lt;- hypervolume_segment(hv, 
                          num.points.max=200, distance.factor=1,
                          check.memory=FALSE) # intentionally under-segment
hv_segmented_pruned &lt;- hypervolume_prune(hv_segmented, 
                          num.points.min=20)
plot(hv_segmented_pruned)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_redundancy'>
Redundancy of a point in a hypervolume
</h2><span id='topic+hypervolume_redundancy'></span>

<h3>Description</h3>

<p>Estimates squared probability density at a given point. This metric is proportional to the number of data points multiplied by the probability density at a point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_redundancy(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_redundancy_+3A_...">...</code></td>
<td>

<p>Arguments to be passed to <code>hypervolume_estimate_probability</code>
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_estimate_probability">hypervolume_estimate_probability</a></code>
</p>

<hr>
<h2 id='hypervolume_resample'>
Hypervolume resampling methods
</h2><span id='topic+hypervolume_resample'></span>

<h3>Description</h3>

<p><code>hypervolume_resample</code> generates new hyperolumes based on the method input. Outputs written to file.
</p>
<p>- <code>"bootstrap"</code>:        Generates n hypervolumes using data bootstrapped from original data
</p>
<p>- <code>"bootstrap seq"</code>:    Generates n hypervolumes for each sample size in sequence specified by user
</p>
<p>- <code>"weighted bootstrap"</code>: Same procedure as bootstrap but with sampling weights applied to data (default weights are normal distributed)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_resample(name, 
                      hv, 
                      method, 
                      n = 10, 
                      points_per_resample = "sample_size", 
                      seq = 3:nrow(hv@Data), 
                      cores = 1,
                      verbose = TRUE,
                      to_file = TRUE,
                      mu = NULL, 
                      sigma = NULL, 
                      cols_to_weigh = 1:ncol(hv@Data), 
                      weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_resample_+3A_name">name</code></td>
<td>

<p>File name; The function writes hypervolumes to file in ./Objects/&lt;name&gt;
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_hv">hv</code></td>
<td>

<p>A hypervolume object
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_method">method</code></td>
<td>

<p>String input; options are <code>"bootstrap"</code>, <code>"bootstrap seq"</code>, and <code>"weighted bootstrap"</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_n">n</code></td>
<td>

<p>Number of resamples to take.
Used for every method.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_points_per_resample">points_per_resample</code></td>
<td>

<p>Number of points in each resample. If the input is &quot;sample_size&quot;, then the same number of points as the original sample is used.
Used for <code>method = "bootstrap"</code> and <code>method = "weighted bootstrap"</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_seq">seq</code></td>
<td>

<p>Sequence of sample sizes. If <code>method = "bootstrap seq"</code> then the function generates n bootstrapped hypervolumes for each sample size in seq.
Used for <code>method = "bootstrap seq"</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_cores">cores</code></td>
<td>

<p>Number of logical cores to use while generating bootstraped hypervolumes. If parallel backend already registered to <code>doParallel</code>, function will use that backend and ignore the argument in cores.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; If function is being run sequentially, outputs progress bar in console.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_to_file">to_file</code></td>
<td>

<p>Logical value; If TRUE, writes resampled hypervolumes to file, otherwise returns an object from <code><a href="#topic+HypervolumeList-class">HypervolumeList-class</a></code>.
Used for <code>method = "bootstrap"</code> and <code>method = "weighted bootstrap"</code>
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_mu">mu</code></td>
<td>

<p>Array of values specifying the mean of multivariate normal weights.
Used for <code>method = "weighted bootstrap"</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_sigma">sigma</code></td>
<td>

<p>Array of values specifying the variance in each dimension. (higher variance corresponds to more even weights)
Used for <code>method = "weighted bootstrap"</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_cols_to_weigh">cols_to_weigh</code></td>
<td>

<p>Array of column indices; must be same length as mu and sigma.  
Used for <code>method = "weighted bootstrap"</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_resample_+3A_weights">weights</code></td>
<td>

<p>Custom weight assigned to each row of data when resampling.
Used for <code>method = "weighted bootstrap"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hypervolume_resample</code> creates a directory called Objects in the current working directory if a directory of that name doesn't already exist. Returns an absolute path to directory with resampled hypervolumes. rds files are stored in different file structures depending on which method is called.
</p>
<p>Use <code>to_hv_list</code> to extract every hypervolume object in a directory into a HypervolumeList object.
It is also possible to access the hypervolumes by using readRDS to read the hypervolume objects in one by one.
</p>
<p>The resampled hypervolumes are generated using the same parameters used to generate the input hypervolume. The only exception is that the bandwidth is re-estimated if <code>method = "gaussian"</code> or <code>method = "box"</code>. See <code><a href="#topic+copy_param_hypervolume">copy_param_hypervolume</a></code> for more details.
</p>


<h3>Value</h3>

<p>returns a string containing an absolute path equivalent to ./Objects/&lt;name&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+to_hv_list">to_hv_list</a></code>, <code><a href="#topic+hypervolume_overlap_test">hypervolume_overlap_test</a></code>, <code><a href="#topic+hypervolume_funnel">hypervolume_funnel</a></code>, <code><a href="#topic+hypervolume_overlap_confidence">hypervolume_overlap_confidence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(palmerpenguins)
data(penguins)
bill_data = na.omit(penguins[,3:4])
hv = hypervolume(bill_data)

# Example 1: Get 50 resampled hypervolumes
# Use detectCores to see how many cores are availible in current environment
# Set cores = 1 to run sequentially (default)
path = hypervolume_resample("example_bootstrap", 
                              hv, 
                              method = "bootstrap", 
                              n = 50, 
                              cores = 12)
hvs = to_hv_list(path)

# Example 2: Get resample with applied weights
# Get maximum bill length
max_bill = max(bill_data$bill_length_mm)
# Make data with larger bill length slightly more likley to be resampled
weighted_path = hypervolume_resample("weighted test", 
                                    hv, 
                                    method = "weighted bootstrap", 
                                    n = 50, 
                                    cores = 12, 
                                    mu = max_bill, 
                                    sigma = 90, 
                                    cols_to_weigh = "bill_length_mm")
hvs_weighted = to_hv_list(weighted_path)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_save_animated_gif'>
Saves animated GIF of three-dimensional hypervolume plot.
</h2><span id='topic+hypervolume_save_animated_gif'></span>

<h3>Description</h3>

<p>Rotates the plot around an axis at a given speed and saves results as a series of GIFs. Requires that the <code>rgl</code> library is installed. Assumes there is an open RGL plot (e.g. from calling <code>plot(hv, show.3d=TRUE)</code>). If the <code>magick</code> package is available, combines these GIFs into a single animation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_save_animated_gif(image.size = 400, 
                              axis = c(0, 0, 1), rpm = 4, duration = 15, fps = 10, 
                              file.name = "movie", directory.output = ".", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_save_animated_gif_+3A_image.size">image.size</code></td>
<td>

<p>Number of pixels on each side of the animated image.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_axis">axis</code></td>
<td>

<p>A three-element vector describing the rotation axis.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_rpm">rpm</code></td>
<td>

<p>Animation speed in rotations per minute.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_duration">duration</code></td>
<td>

<p>Animation duration in seconds.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_fps">fps</code></td>
<td>

<p>Animation speed in frames per second.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_file.name">file.name</code></td>
<td>

<p>A base name (no extension) for the GIFs.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_directory.output">directory.output</code></td>
<td>

<p>The folder in which output should be located.
</p>
</td></tr>
<tr><td><code id="hypervolume_save_animated_gif_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to <code>rgl::movie3d</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None; used for the side-effect of producing files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
  
hv = hypervolume_gaussian(penguins_adelie,name='Adelie')

if(interactive())
{
  plot(hv, show.3d=TRUE)
  hypervolume_save_animated_gif()
  rgl.close()
}

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_segment'>
Segments a hypervolume into multiple separate hypervolumes.
</h2><span id='topic+hypervolume_segment'></span>

<h3>Description</h3>

<p>Performs hierarchical clustering (using the 'single' method described in <code>fastcluster::hclust</code>) on the input hypervolume to determine which sets of points are closest to others, then cuts the resulting tree at a height equal to the characteristic distance between points multiplied by a distance factor. Random points in the input hypervolume corresponding to each distinct cluster are assigned to distinct output hypervolumes.
</p>
<p>Because clustering algorithms scale quadratically with the number of input points, this algorithm can run slowly. Therefore by default, the function can thin the input hypervolume to a reduced number of random points before analysis. This causes some loss of resolution but improves runtimes. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_segment(hv, distance.factor = 1, num.points.max = NULL,
                 verbose = TRUE, check.memory = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_segment_+3A_hv">hv</code></td>
<td>

<p>An input <code>Hypervolume</code> class object.
</p>
</td></tr>
<tr><td><code id="hypervolume_segment_+3A_distance.factor">distance.factor</code></td>
<td>

<p>A numeric value characterizing the distance multiplication factor. Larger values result in fewer distinct output hypervolumes; smaller values result in more.
</p>
</td></tr>
<tr><td><code id="hypervolume_segment_+3A_num.points.max">num.points.max</code></td>
<td>

<p>A numeric value describing the maximum number of random points to be retained in the input; passed to <code>hypervolume_thin</code> before analysis. Set to <code>NULL</code> to disable thinning.
</p>
</td></tr>
<tr><td><code id="hypervolume_segment_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_segment_+3A_check.memory">check.memory</code></td>
<td>

<p>Logical value; returns information about expected memory usage if true.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>HypervolumeList</code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_thin">hypervolume_thin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># low sample sizes to meet CRAN time requirements
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

# intentionally make a holey shape for segmentation example
hv = hypervolume_gaussian(penguins_adelie,name='Adelie',
  kde.bandwidth=estimate_bandwidth(penguins_adelie)/3) 

hv_segmented &lt;- hypervolume_segment(hv, 
                          num.points.max=200, distance.factor=1.25,
                          check.memory=FALSE) # intentionally under-segment
plot(hv_segmented,show.contour=FALSE)
</code></pre>

<hr>
<h2 id='hypervolume_set'>
Set operations (intersection / union / unique components)
</h2><span id='topic+hypervolume_set'></span>

<h3>Description</h3>

<p>Computes the intersection, union, and unique components of two hypervolumes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_set(hv1, hv2, num.points.max = NULL, 
  verbose = TRUE, check.memory = TRUE, distance.factor = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_set_+3A_hv1">hv1</code></td>
<td>

<p>A n-dimensional hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_set_+3A_hv2">hv2</code></td>
<td>

<p>A n-dimensional hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_set_+3A_num.points.max">num.points.max</code></td>
<td>

<p>Maximum number of random points to use for set operations. If <code>NULL</code> defaults to 10^(3+sqrt(n)) where n is the dimensionality of the input hypervolumes. Note that this default parameter value has been increased by a factor of 10 since the 1.2 release of this package.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if true.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_+3A_check.memory">check.memory</code></td>
<td>

<p>Logical value; returns information about expected memory usage if true.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_+3A_distance.factor">distance.factor</code></td>
<td>

<p>Numeric value; multiplicative factor applied to the critical distance for all inclusion tests (see below). Recommended to not change this parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the inclusion test approach to identify points in the first hypervolume that are or are not within the second hypervolume and vice-versa, based on determining whether each random point in each hypervolume is within a critical distance of at least one random point in the other hypervolume.
</p>
<p>The intersection is the points in both hypervolumes, the union those in either hypervolume, and the unique components the points in one hypervolume but not the other. 
</p>
<p>If you have more than two hypervolumes and wish to calculate only an intersection, consider instead using <code><a href="#topic+hypervolume_set_n_intersection">hypervolume_set_n_intersection</a></code> rather than iteratively applying this function.
</p>
<p>By default, the function uses <code>check.memory=TRUE</code> which will provide an estimate of the computational cost of the set operations. The function should then be re-run with <code>check_memory=FALSE</code> if the cost is acceptable. This algorithm's memory and time cost scale quadratically with the number of input points, so large datasets can have disproportionately high costs. This error-checking is intended to prevent the user from large accidental memory allocation. 
</p>
<p>The computation is actually performed on a random sample from both input hypervolumes, constraining each to have the same point density given by the minimum of the point density of each input hypervolume, and the point density calculated using the volumes of each input hypervolume divided by <code>num.points.max</code>.
</p>
<p>Because this algorithm is based on distances calculated between the distributions of random points, the critical distance (point density ^ (-1/n)) can be scaled by a user-specified factor to provide more or less liberal estimates (<code>distance_factor</code> greater than or less than 1).
</p>


<h3>Value</h3>

<p>If <code>check_memory</code> is false, returns a HypervolumeList object, with six items in its HVList slot:
</p>
<table role = "presentation">
<tr><td><code>HV1</code></td>
<td>
<p>The input hypervolume hv1</p>
</td></tr>
<tr><td><code>HV2</code></td>
<td>
<p>The input hypervolume hv2</p>
</td></tr>
<tr><td><code>Intersection</code></td>
<td>
<p>The intersection of hv1 and hv2</p>
</td></tr>
<tr><td><code>Union</code></td>
<td>
<p>The union of hv1 and hv2</p>
</td></tr>
<tr><td><code>Unique_1</code></td>
<td>
<p>The unique component of hv1 relative to hv2</p>
</td></tr>
<tr><td><code>Unique_2</code></td>
<td>
<p>The unique component of hv2 relative to hv1</p>
</td></tr>
</table>
<p>Note that the output hypervolumes will have lower random point densities than the input hypervolumes. 
</p>
<p>You may find it useful to define a Jaccard-type fractional overlap between hv1 and hv2 as <code>hv_set@HVList$Intersection@Volume / hv_set@HVList$Union@Volume</code>.
</p>
<p>If <code>check_memory=TRUE</code>, instead returns a scalar with the expected number of pairwise comparisons.
</p>
<p>If one of the input hypervolumes has no random points, returns <code>NA</code> with a warning.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_set_n_intersection">hypervolume_set_n_intersection</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
penguins_chinstrap = penguins_no_na[penguins_no_na$species=="Chinstrap",
                      c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv1 = hypervolume_box(penguins_adelie,name='Adelie')
hv2 = hypervolume_box(penguins_chinstrap,name='Chinstrap')

hv_set &lt;- hypervolume_set(hv1, hv2, check.memory=FALSE)

hypervolume_overlap_statistics(hv_set)
# examine volumes of each set component
get_volume(hv_set)
</code></pre>

<hr>
<h2 id='hypervolume_set_n_intersection'>
Multi-way set intersection
</h2><span id='topic+hypervolume_set_n_intersection'></span>

<h3>Description</h3>

<p>Intersection of n hypervolumes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_set_n_intersection(hv_list, num.points.max = NULL, 
  verbose = TRUE, distance.factor = 1, check.hyperplane = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_set_n_intersection_+3A_hv_list">hv_list</code></td>
<td>

<p>A list of hypervolumes (HypervolumeList)
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_intersection_+3A_num.points.max">num.points.max</code></td>
<td>

<p>Maximum number of random points to use for the calculation of the intersection. If <code>NULL</code> defaults to 10^(3+sqrt(n)) where n is the dimensionality of the input hypervolumes. Note that this default parameter value has been increased by a factor of 10 since the 1.2 release of this package.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_intersection_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if true.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_intersection_+3A_distance.factor">distance.factor</code></td>
<td>

<p>Numeric value; multiplicative factor applied to the critical distance for all inclusion tests (see below). Recommended to not change this parameter.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_intersection_+3A_check.hyperplane">check.hyperplane</code></td>
<td>

<p>Checks whether data in the input hypervolumes forms a hyperplane (if so, the algorithm is not able to accurately calculate an intersection)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds the intersection of multiple hypervolumes. Using this function is likely faster and more accurate than iteratively applying <code>hypervolume_set</code> to hypervolume pairs, as this function does not iteratively perform downsampling.
</p>
<p>Stores all the points from the input hypervolumes in a single set. Then uses the inclusion test approach to identify and store points from this set that are within each individual resampled hypervolume, successively. All the points that are common to all the tests are grouped, resampled and used to generate the hypervolume corresponding to the intersection.
</p>
<p>The computation is actually performed on a random sample from input hypervolumes, constraining each to have the same point density given by the minimum of the point density of each input hypervolume, and the point density calculated using the volumes of each input hypervolume divided by <code>num.points.max</code>.
Because this algorithm is based on distances calculated between the distributions of random points, the critical distance (point density ^ (-1/n)) can be scaled by a user-specified factor to provide more or less liberal estimates (<code>distance_factor</code> greater than or less than 1).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>The intersection of the input hypervolumes, as a unique hypervolume</p>
</td></tr></table>
<p>.
</p>
<p>Note that the output hypervolumes will have lower random point densities than the input hypervolumes.
</p>
<p>If one of the input hypervolumes has no random points, returns <code>NA</code> with a warning.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_set">hypervolume_set</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
hv1 = hypervolume_gaussian(subset(iris, Species=="setosa")[,1:3],
name='setosa')
hv2 = hypervolume_gaussian(subset(iris, Species=="virginica")[,1:3],
name='virginica')
hv3 = hypervolume_gaussian(subset(iris, Species=="versicolor")[,1:3],
name='versicolor')
    
hv_list = hypervolume_join(hv1,hv2,hv3)
intersection = hv_set_n_intersection(hv_list) 


## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_set_n_union'>
Multi-way set union
</h2><span id='topic+hypervolume_set_n_union'></span>

<h3>Description</h3>

<p>Union of n hypervolumes.
</p>
<p>Code by Clement Violet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_set_n_union(hv_list, num.points.max = NULL, 
  verbose = TRUE, distance.factor = 1, check.hyperplane = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_set_n_union_+3A_hv_list">hv_list</code></td>
<td>

<p>A list of hypervolumes (HypervolumeList)
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_union_+3A_num.points.max">num.points.max</code></td>
<td>

<p>Maximum number of random points to use for the calculation of the union. If <code>NULL</code> defaults to 10^(3+sqrt(n)) where n is the dimensionality of the input hypervolumes. Note that this default parameter value has been increased by a factor of 10 since the 1.2 release of this package.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_union_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if true.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_union_+3A_distance.factor">distance.factor</code></td>
<td>

<p>Numeric value; multiplicative factor applied to the critical distance for all inclusion tests (see below). Recommended to not change this parameter.
</p>
</td></tr>
<tr><td><code id="hypervolume_set_n_union_+3A_check.hyperplane">check.hyperplane</code></td>
<td>

<p>Checks whether data in the input hypervolumes forms a hyperplane (if so, the algorithm is not able to accurately calculate an union)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds the union of multiple hypervolumes. Using this function is likely faster and more accurate than iteratively applying <code>hypervolume_set</code> to hypervolume pairs, as this function does not iteratively perform downsampling.
</p>
<p>Stores all the points from the input hypervolumes in a single set. Then uses the inclusion test approach to identify and store points from this set that are within each individual resampled hypervolume, successively. All the points that are common to all the tests are grouped, resampled and used to generate the hypervolume corresponding to the union.
</p>
<p>The computation is actually performed on a random sample from input hypervolumes, constraining each to have the same point density given by the minimum of the point density of each input hypervolume, and the point density calculated using the volumes of each input hypervolume divided by <code>num.points.max</code>.
Because this algorithm is based on distances calculated between the distributions of random points, the critical distance (point density ^ (-1/n)) can be scaled by a user-specified factor to provide more or less liberal estimates (<code>distance_factor</code> greater than or less than 1).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>The union of the input hypervolumes, as a unique hypervolume</p>
</td></tr></table>
<p>.
</p>
<p>Note that the output hypervolumes will have lower random point densities than the input hypervolumes.
</p>
<p>If one of the input hypervolumes has no random points, returns <code>NA</code> with a warning.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_set">hypervolume_set</a></code>, <code><a href="#topic+hypervolume_set_n_intersection">hypervolume_set_n_intersection</a></code>, <code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
hv1 = hypervolume_gaussian(subset(iris, Species=="setosa")[,1:3],
name='setosa')
hv2 = hypervolume_gaussian(subset(iris, Species=="virginica")[,1:3],
name='virginica')
hv3 = hypervolume_gaussian(subset(iris, Species=="versicolor")[,1:3],
name='versicolor')
    
hv_list = hypervolume_join(hv1,hv2,hv3)
union = hv_set_n_union(hv_list) 


## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_svm'>
Hypervolume construction via one-class support vector machine (SVM) learning model
</h2><span id='topic+hypervolume_svm'></span>

<h3>Description</h3>

<p>Constructs a hypervolume by building a one-class support vector machine that classifies data points as 'in' and other locations as 'out'. This is accomplished by 1) transforming the input data into a high-dimensional nonlinear space in which the data points can be optimally separated from background by a single hyperplane, 2) back-transforming the hyperplane into the original space, 3) delineating an adaptive grid of random points near the original data points, and 4) using the SVM to predict if each of these points is in or out.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_svm(data, name = NULL, 
                  samples.per.point = ceiling((10^(3 + sqrt(ncol(data))))/nrow(data)), 
                  svm.nu = 0.01, svm.gamma = 0.5, 
                  scale.factor = 1,
                  chunk.size = 1000, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_svm_+3A_data">data</code></td>
<td>

<p>A m x n matrix or data frame, where m is the number of observations and n is the dimensionality.
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_name">name</code></td>
<td>

<p>A string to assign to the hypervolume for later output and plotting. Defaults to the name of the variable if NULL.
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_samples.per.point">samples.per.point</code></td>
<td>

<p>Number of random points to be evaluated per data point in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_svm.nu">svm.nu</code></td>
<td>

<p>A SVM parameter determining an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Lower values result in tighter wrapping of the shape to the data (see section 2.2. of https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf). 
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_svm.gamma">svm.gamma</code></td>
<td>

<p>A SVM parameter defining the inverse radius of influence of a single point. Low values yield large influences (smooth less complex wraps around the data) and high values yield small influences (tighter but potentially noiser wraps around the data) (see http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_scale.factor">scale.factor</code></td>
<td>

<p>A multiplicative factor used to determine the boundaries of the hyperelliptical sampling region. Larger values yield larger boundaries and can prevent clipping. Should not need to be changed in almost any situation.
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_chunk.size">chunk.size</code></td>
<td>

<p>Number of random points to process per internal step. Larger values may have better performance on machines with large amounts of free memory. Changing this parameter does not change the output of the function; only how this output is internally assembled.
</p>
</td></tr>
<tr><td><code id="hypervolume_svm_+3A_verbose">verbose</code></td>
<td>

<p>Logical value; print diagnostic output if <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> object corresponding to the inferred hypervolume.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_threshold">hypervolume_threshold</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
  
hv = hypervolume_svm(penguins_adelie,name='Adelie')
summary(hv)
</code></pre>

<hr>
<h2 id='hypervolume_thin'>
Reduces the number of random points in a hypervolume
</h2><span id='topic+hypervolume_thin'></span>

<h3>Description</h3>

<p>Many hypervolume algorithms have computational complexities that scale with the number of random points used to characterize a hypervolume (<code>@RandomPoints</code>). This value can be reduced to improve runtimes at the cost of lower resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_thin(hv, factor = NULL, num.points = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_thin_+3A_hv">hv</code></td>
<td>

<p>An object of class <code>Hypervolume</code>
</p>
</td></tr>
<tr><td><code id="hypervolume_thin_+3A_factor">factor</code></td>
<td>

<p>A number in (0,1) describing the fraction of random points to keep.
</p>
</td></tr>
<tr><td><code id="hypervolume_thin_+3A_num.points">num.points</code></td>
<td>

<p>A number describing the number random points to keep.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>factor</code> or <code>npoints</code> (but not both) must be specified.
</p>


<h3>Value</h3>

<p>A <code>Hypervolume</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
  
hv = hypervolume_box(penguins_adelie,name='Adelie')

# downsample to 1000 random points
hv_thinned = hypervolume_thin(hv, num.points=1000)
hv_thinned
</code></pre>

<hr>
<h2 id='hypervolume_threshold'>
Thresholds hypervolume and calculates volume quantile statistics (empirical cumulative distribution function)
</h2><span id='topic+hypervolume_threshold'></span>

<h3>Description</h3>

<p>Thresholds a hypervolume at a given value that can correspond to a quantile of the hypervolume. All random points below the threshold value are removed and the volume is adjusted accordingly. Provides threshold-quantile plots if multiple thresholds are specified (as by default). 
</p>
<p>Quantiles can be specified to be either of the total volume enclosed by the hypervolume p(proportional to <code>nrow(hv@RandomPoints)</code>), or of the total probability density (proportional to <code>sum(hv@ValueAtRandomPoints)</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_threshold(hv, 
                        thresholds = NULL, 
                        num.thresholds = 20, 
                        quantile.requested = NULL,
                        quantile.requested.type = "volume", 
                        uniform.density = TRUE,
                        plot = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_threshold_+3A_hv">hv</code></td>
<td>

<p>An input hypervolume
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_thresholds">thresholds</code></td>
<td>

<p>A sequence of probability threshold values. If <code>NULL</code>, defaults to a sequence of length <code>num.thresholds</code> spanning the minimum and maximum probability values in the hypervolume.
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_num.thresholds">num.thresholds</code></td>
<td>

<p>The number of threshold values to use if <code>thresholds=NULL</code>. Otherwise ignored.
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_quantile.requested">quantile.requested</code></td>
<td>

<p>If not <code>NULL</code>, selects a single hypervolume correspondong to the threshold value that comes closest to enclosing the requested quantile fraction of the type <code>quantile.requested.type</code>. Using high values of <code>num.thresholds</code> enables more accurate threshold and quantile selection.
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_quantile.requested.type">quantile.requested.type</code></td>
<td>

<p>Determines the quantile type: either <code>"volume"</code> or <code>"probability"</code>. 
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_uniform.density">uniform.density</code></td>
<td>

<p>Logical value. If <code>TRUE</code>, sets all <code>@ValueAtRandomPoints</code> values to 1 in order to represent thresholded hypervolume as a solid geometrical shape. 
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_plot">plot</code></td>
<td>

<p>Plots a threshold-quantile plot if <code>TRUE</code>. Quantiles are shown for both volume and probability density. This plot is similar to an empirical cumulative distribution function.
</p>
</td></tr>
<tr><td><code id="hypervolume_threshold_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic progress messages.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hypervolumes constructed using the <code>hypervolume_box</code> method may not always yield quantiles close to the requested value because of the flat shape of the kernel. 
</p>


<h3>Value</h3>

<p>A list containing two elements: a <code>HypervolumeList</code> or <code>Hypervolume</code> object corresponding to the hypervolumes at each threshold value, and a dataframe <code>Statistics</code> corresponding to the relevant quantiles and thresholds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]
  
hv = hypervolume_box(penguins_adelie,name='Adelie')

# get hypervolumes at multiple thresholds
hvlist = hypervolume_threshold(hv, plot=TRUE)
head(hvlist$Statistics)
plot(hvlist$HypervolumesThresholded[[c(1,5,10,15,20)]],
  show.random=TRUE, show.data=FALSE,show.centroid=FALSE)

# get hypervolume for a single low quantile value
plot(hypervolume_threshold(hv, plot=FALSE, verbose=FALSE,
  quantile.requested=0.1,quantile.requested.type="volume")[[1]])

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_to_data_frame'>
Convert hypervolumes to <code>data.frame</code>
</h2><span id='topic+hypervolume_to_data_frame'></span>

<h3>Description</h3>

<p>Convert objects of class <code>Hypervolume</code> or <code>HypervolumeList</code> to a <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_to_data_frame(hv, remove_zeroes = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_to_data_frame_+3A_hv">hv</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code>.
</p>
</td></tr>
<tr><td><code id="hypervolume_to_data_frame_+3A_remove_zeroes">remove_zeroes</code></td>
<td>

<p>Remove zeroes from <code>ValuesAtRandomPoints</code>. See Details for further information. It works for <code>hypervolume_n_occupancy()</code>, <code>hypervolume_n_occupancy_test()</code>, <code>occupancy_to_union()</code>, <code>occupancy_to_intersection()</code> and <code>occupancy_to_unshared()</code>, otherwise ignored. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Zero values are generated during the occupancy routine when a random point is included in some groups of hypervolumes but not in others. A tipical usage of <code>hypervolume_to_data_frame()</code> with objects generated with the occupancy routine should remove zeroes.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
                        paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))


# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
  x = penguins_no_na_split, 
  y = names(penguins_no_na_split))

hv_list &lt;- hypervolume_join(hv_list)

# get the data.frame
hypervolume_to_data_frame(hv_list)

## End(Not run)
</code></pre>

<hr>
<h2 id='hypervolume_variable_importance'>
Hypervolume variable importance
</h2><span id='topic+hypervolume_variable_importance'></span>

<h3>Description</h3>

<p>Assesses the contribution of each variable to the total hypervolume as a rough metric of variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume_variable_importance(hv, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypervolume_variable_importance_+3A_hv">hv</code></td>
<td>

<p>A hypervolume for which the importance of each variable should be calculated.
</p>
</td></tr>
<tr><td><code id="hypervolume_variable_importance_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic progress messages.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm proceeds by comparing the n-dimensional input hypervolume's volume to all possible n-1 dimensional hypervolumes where each variable of interest has been deleted. The importance score reported is the ratio of the n-dimensional hypervolume relative to each of the n-1 dimensional hypervolumes. Larger values indicate that a variable makes a proportionally higher contribution to the overall volume.
</p>
<p>The algorithm can only be used on Hypervolumes that have a <code>Data</code> and <code>Method</code> value, because the variable deletion process is not well defined for objects that are not associated with a particular set of observations and construction method.
</p>


<h3>Value</h3>

<p>A named vector with importance scores for each axis. Note that these scores are not dimensionless but rather have units corresponding to the original units of each variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># low parameter values for speed
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv = hypervolume_box(penguins_adelie,name='Adelie')

varimp = hypervolume_variable_importance(hv,verbose=FALSE)
barplot(varimp,ylab='Importance',xlab='Variable')
</code></pre>

<hr>
<h2 id='Hypervolume-class'>Class <code>"Hypervolume"</code></h2><span id='topic+Hypervolume-class'></span>

<h3>Description</h3>

<p>Primary storage class for stochastic descriptions of hypervolumes</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("Hypervolume", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Name</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ the name of the hypervolume</p>
</dd>
<dt><code>Method</code>:</dt><dd><p>Object of class <code>"character"</code> ~~ the method used to construct this hypervolume</p>
</dd>
<dt><code>Data</code>:</dt><dd><p>Object of class <code>"matrix"</code> ~~ May be empty if the hypervolume is not associated with data (e.g. convex expectation, set operations)</p>
</dd>
<dt><code>Dimensionality</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ Dimensionality of the hypervolume</p>
</dd>
<dt><code>Volume</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ Volume of the hypervolume</p>
</dd>
<dt><code>PointDensity</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ Number of random points per unit volume</p>
</dd>
<dt><code>Parameters</code>:</dt><dd><p>Object of class <code>"list"</code> ~~ List of parameters that will depend on the method used to construct the hypervolume</p>
</dd>
<dt><code>RandomPoints</code>:</dt><dd><p>Object of class <code>"matrix"</code> ~~ A matrix of uniformly random points distributed within the hypervolume</p>
</dd>
<dt><code>ValueAtRandomPoints</code>:</dt><dd><p>Object of class <code>"numeric"</code> ~~ A vector of positive numbers representing the probabilty density at each random point in <code>@RandomPoints</code></p>
</dd>
</dl>


<hr>
<h2 id='HypervolumeList-class'>Class <code>"HypervolumeList"</code></h2><span id='topic+HypervolumeList-class'></span>

<h3>Description</h3>

<p>A class used for storing more than one hypervolume.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("HypervolumeList", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>HVList</code>:</dt><dd><p>Object of class <code>"list"</code> containing multiple hypervolumes</p>
</dd>
</dl>


<hr>
<h2 id='morphSnodgrassHeller'>
Morphological data for Darwin's finches
</h2><span id='topic+morphSnodgrassHeller'></span>

<h3>Description</h3>

<p>Data for nine morphological traits for species of Darwin's finches occurring on the Galapagos Islands.
</p>
<p>Note that the underlying morphological dataset has been augmented and improved since version 1.3.1 to include more species and islands. Results are not comparable to version 1.3.0 and below. To duplicate results in the Blonder et al. (2014) paper please install an older version of the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("morphSnodgrassHeller")</code></pre>


<h3>Format</h3>

<p>A data frame with 549 observations on the following 20 variables.
</p>

<dl>
<dt><code>Source</code></dt><dd><p>a factor with levels <code>Snodgrass &amp; Heller (1904)</code></p>
</dd>
<dt><code>IslandID</code></dt><dd><p>a factor with levels <code>Balt_SS</code> <code>Drwn_Clp</code> <code>Esp_Hd</code> <code>Flor_Chrl</code> <code>Frn_Nrb</code> <code>Gnov_Twr</code> <code>Isa_Alb</code> <code>Mrch_Bndl</code> <code>Pnt_Abng</code> <code>Pnz_Dnc</code> <code>SCris_Chat</code> <code>SCru_Inde</code> <code>SFe_Brngt</code> <code>Snti_Jams</code> <code>Wlf_Wnm</code></p>
</dd>
<dt><code>TaxonOrig</code></dt><dd><p>a factor with levels <code>Certhidea cinerascens bifasciata</code> <code>Certhidea cinerascens cinerascens</code> <code>Certhidea olivacea becki</code> <code>Certhidea olivacea fusca</code> <code>Certhidea olivacea luteola</code> <code>Certhidea olivacea mentalis</code> <code>Certhidea olivacea olivacea</code> <code>Geospiza affinis </code> <code>Geospiza conirostris conirostris</code> <code>Geospiza conirostris propinqua</code> <code>Geospiza crassirostris </code> <code>Geospiza fortis dubia</code> <code>Geospiza fortis fortis</code> <code>Geospiza fortis fratercula</code> <code>Geospiza fortis platyrhyncha</code> <code>Geospiza fuliginosa acutirostris</code> <code>Geospiza fuliginosa difficilis</code> <code>Geospiza fuliginosa fuliginosa</code> <code>Geospiza fuliginosa minor</code> <code>Geospiza fuliginosa parvula</code> <code>Geospiza habeli </code> <code>Geospiza heliobates </code> <code>Geospiza paupera </code> <code>Geospiza prosthemelas prosthemelas</code> <code>Geospiza prosthemelas salvini</code> <code>Geospiza psittacula psittacula</code> <code>Geospiza scandens abingdoni</code> <code>Geospiza scandens fatigata</code> <code>Geospiza scandens rothschildi</code> <code>Geospiza scandens scandens</code> <code>Geospiza septentrionalis </code> <code>Geospiza strenua </code></p>
</dd>
<dt><code>GenusL69</code></dt><dd><p>a factor with levels <code>Camarhynchus</code> <code>Certhidea</code> <code>Geospiza</code> <code>Platyspiza</code></p>
</dd>
<dt><code>SpeciesL69</code></dt><dd><p>a factor with levels <code>conirostris</code> <code>crassirostris</code> <code>difficilis</code> <code>fortis</code> <code>fuliginosa</code> <code>heliobates</code> <code>magnirostris</code> <code>olivacea</code> <code>parvulus</code> <code>pauper</code> <code>psittacula</code> <code>scandens</code></p>
</dd>
<dt><code>SubspL69</code></dt><dd><p>a factor with levels  <code>abingdoni</code> <code>affinis</code> <code>becki</code> <code>bifasciatus</code> <code>cinerascens</code> <code>conirostris</code> <code>darwini</code> <code>fusca</code> <code>habeli</code> <code>intermedia</code> <code>luteola</code> <code>mentalis</code> <code>olivacea</code> <code>parvulus</code> <code>propinqua</code> <code>psittacula</code> <code>rothschildi</code> <code>salvini</code> <code>scandens</code> <code>septentrionalis</code> <code>strenua</code></p>
</dd>
<dt><code>SpeciesID</code></dt><dd><p>a factor with levels <code>Cam.hel</code> <code>Cam.par</code> <code>Cam.pau</code> <code>Cam.psi</code> <code>Cer.oli</code> <code>Geo.con</code> <code>Geo.dif</code> <code>Geo.for</code> <code>Geo.ful</code> <code>Geo.mag</code> <code>Geo.sca</code> <code>Pla.cra</code></p>
</dd>
<dt><code>SubspID</code></dt><dd><p>a factor with levels <code>Cam.hel</code> <code>Cam.par.par</code> <code>Cam.par.sal</code> <code>Cam.pau</code> <code>Cam.psi.aff</code> <code>Cam.psi.hab</code> <code>Cam.psi.psi</code> <code>Cer.oli.bec</code> <code>Cer.oli.bif</code> <code>Cer.oli.cin</code> <code>Cer.oli.fus</code> <code>Cer.oli.lut</code> <code>Cer.oli.men</code> <code>Cer.oli.oli</code> <code>Geo.con.con</code> <code>Geo.con.dar</code> <code>Geo.con.pro</code> <code>Geo.dif.sep</code> <code>Geo.for</code> <code>Geo.ful</code> <code>Geo.mag.str</code> <code>Geo.sca.abi</code> <code>Geo.sca.int</code> <code>Geo.sca.rot</code> <code>Geo.sca.sca</code> <code>Pla.cra</code></p>
</dd>
<dt><code>Sex</code></dt><dd><p>a factor with levels <code>F</code> <code>M</code></p>
</dd>
<dt><code>Plumage</code></dt><dd><p>a logical vector</p>
</dd>
<dt><code>BodyL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>WingL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TailL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BeakW</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BeakH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>LBeakL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>UBeakL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>N.UBkL</code></dt><dd><p>a factor with levels  <code>10</code> <code>10.3</code> <code>10.5</code> <code>10.7</code> <code>11</code> <code>11.3</code> <code>11.5</code> <code>11.7</code> <code>12</code> <code>12.3</code> <code>12.5</code> <code>12.7</code> <code>13</code> <code>13.3</code> <code>13.5</code> <code>13.7</code> <code>14</code> <code>14.3</code> <code>14.5</code> <code>14.7</code> <code>15</code> <code>15.3</code> <code>15.5</code> <code>15.7</code> <code>16</code> <code>16.3</code> <code>16.5</code> <code>16.7</code> <code>17</code> <code>17.5</code> <code>6.5</code> <code>6.7</code> <code>7</code> <code>7.3</code> <code>7.5</code> <code>7.7</code> <code>8</code> <code>8..3</code> <code>8.3</code> <code>8.5</code> <code>8.7</code> <code>9</code> <code>9.3</code> <code>9.5</code> <code>9.7</code></p>
</dd>
<dt><code>TarsusL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MToeL</code></dt><dd><p>a logical vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Snodgrass RE and Heller E (1904) Papers from the Hopkins-Stanford Galapagos Expedition, 1898-99. XVI. Birds. Proceedings of the Washington Academy of Sciences 5: 231-372. 
</p>
<p>Downloaded from http://datadryad.org/resource/doi:10.5061/dryad.152
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(morphSnodgrassHeller)
finch_isabela &lt;- morphSnodgrassHeller[morphSnodgrassHeller$IslandID=="Isa_Alb",]
</code></pre>

<hr>
<h2 id='occupancy_bootstrap_gof'>
Goodness of fit metrics for bootstrapped occupancy objects
</h2><span id='topic+occupancy_bootstrap_gof'></span>

<h3>Description</h3>

<p>The <code>occupancy_bootstrap_gof()</code> function calculates goodness of fit metrics for objects generated with <code>hypervolume_n_occupancy_bootstrap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_bootstrap_gof(path, FUN)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="occupancy_bootstrap_gof_+3A_path">path</code></td>
<td>

<p>A path to a directory of bootstrapped hypervolumes generated with <code>hypervolume_n_occupancy_bootstrap()</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_bootstrap_gof_+3A_fun">FUN</code></td>
<td>

<p>Function to calculate the goodness of fit. It can be <code>mae</code> for the mean absolute error, <code>rmse</code> for the root mean square error or a function provided by the user.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Goodness of fit metrics are calculated on the difference between input and recomputed volumes for each bootstrapped element (set with <code>n</code> in <code>hypervolume_n_resample()</code>). See <code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy()</a></code> for details on the meaning of input and recomputed hypervolumes. 
</p>


<h3>Value</h3>

<p>A one row <code>data.frame</code> reporting mean, standard deviation, minimum, maximum, median, 2.5%, 25%, 75% ans 97.5% quantiles. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# bootstrap hypervolumes based on sex
hv_resample = hypervolume_n_resample(hv_list, name = "boot_example")

# calculate occupancy for each bootstrap
hv_occupancy_bootstrap = hypervolume_n_occupancy_bootstrap(hv_resample, 
                                    name = "occupancy_example", 
                                    classification = rep(c("female", "male"), 3))
                
                
occupancy_bootstrap_gof(hv_occupancy_bootstrap, FUN = "rmse")


## End(Not run)
</code></pre>

<hr>
<h2 id='occupancy_filter'>
Subset occupancy hypervolumes
</h2><span id='topic+occupancy_filter'></span>

<h3>Description</h3>

<p>The <code>occupancy_filter()</code> function is used to subset an hypervolume generated with <code>hypervolume_n_occupancy()</code> or <code>hypervolume_n_occupancy_test()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_filter(hv, operator = NULL, filter = NULL, tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="occupancy_filter_+3A_hv">hv</code></td>
<td>

<p>A <code>Hypervolume</code> or <code>HypervolumeList</code> object generated with <code>hypervolume_n_occupancy()</code> or <code>hypervolume_n_occupancy_test()</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_filter_+3A_operator">operator</code></td>
<td>

<p>Binary operator which allow the comparison.
</p>
</td></tr>
<tr><td><code id="occupancy_filter_+3A_filter">filter</code></td>
<td>

<p>Threshold value to perform the operation.
</p>
</td></tr>
<tr><td><code id="occupancy_filter_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>occupancy_filter()</code> function set the occupancy values to 0 based on the user-provided operation. Volume of the hypervolumes are changed accordingly.<br />
When <code>hv</code> is an <code>HypervolumeList</code>, the <code>occupancy_filter()</code> function attempts to reconstruct the volume of the union of hypervolumes from <code>hv_list</code>. At first, the volume of the union of hypervolumes is calculated for each element of <code>hv</code> as the the ratio between the total number of random points and the number of random points of the ith element of <code>hv</code>, multiplied by the volume of the ith element <code>hv</code>. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy_object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> or <code><a href="#topic+HypervolumeList-class">HypervolumeList-class</a></code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm","bill_depth_mm","flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# calculate occupancy based on sex
hv_occupancy_list_sex = hypervolume_n_occupancy(hv_list, 
                          classification = rep(c("female", "male"), 3))


# set to 0 values lower than 0.35
occupancy_filter(hv_occupancy_list_sex, operator = "&lt;", filter = "0.35")

## End(Not run)
</code></pre>

<hr>
<h2 id='occupancy_to_intersection'>
Get the intersection of an occupancy object
</h2><span id='topic+occupancy_to_intersection'></span>

<h3>Description</h3>

<p>The <code>occupancy_to_intersection()</code> function is used to get the intersection of hypervolumes of an object generated with the occupancy routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_to_intersection(hv_list, method = "all", m = 2, tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="occupancy_to_intersection_+3A_hv_list">hv_list</code></td>
<td>

<p>A <code>HypervolumeList</code> generated with <code>hypervolume_n_occupancy()</code>,  <code>hypervolume_n_occupancy_test()</code>, <code>occupancy_to_union()</code>, <code>occupancy_to_unshared()</code> or <code>occupancy_filter()</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_intersection_+3A_method">method</code></td>
<td>

<p>If <code>all</code> compute the intersection among all the hypervolumes in <code>hv_list</code>. If <code>n_wise</code> compute the intersection for each n_wise combination of hypervolumes in <code>hv_list</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_intersection_+3A_m">m</code></td>
<td>

<p>Number of elements to choose. Default to 2 (pairwise comparisons). This argument is ignored when <code>method</code> is set to <code>all</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_intersection_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>occupancy_to_intersection()</code> function takes as input a <code>HypervolumeList</code> generated with an occupancy function (check <code>See Also</code>) and returns a <code>Hypervolume</code> or <code>HypervolumeList</code> depending on <code>method</code>. When <code>method = "all"</code> the <code>occupancy_to_intersection()</code> function returns a <code>Hypervolume</code> representing the intersection of all the hypervolumes in <code>hv_list</code>. When <code>method = "n_wise"</code> a <code>HypervolumeList</code> in which each hypervolume represent the intersection of a combination of the hypervolumes in <code>hv_list</code> is returned. The number of hypervolumes for each combination is set with the argument <code>m</code>. Argument <code>m</code> can not be higher than the number of hypervolumes in <code>hv_list</code> and lower than 2. <br />
The <code>occupancy_to_intersection()</code> function attempts to reconstruct the volume of the intersection from the <code>hv_list</code> provided by the user. At first, the volume of the union of hypervolumes is calculated for each hypervolume in <code>hv_list</code> as the the ratio between the total number of random points and the number of random points of the ith hypervolume of <code>hv_list</code>, multiplied by the volume of the ith hypervolume of <code>hv_list</code>. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy_object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned. The volume of the intersection is then calculated as the ratio between the number of random points of the intersection and the total number of random points, multiplied by the volume of the union of hypervolumes.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> or <code><a href="#topic+HypervolumeList-class">HypervolumeList-class</a></code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>, <code><a href="#topic+occupancy_to_union">occupancy_to_union</a></code>,
<code><a href="#topic+occupancy_to_unshared">occupancy_to_unshared</a></code>, <code><a href="#topic+occupancy_filter">occupancy_filter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
                  paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
  x = penguins_no_na_split, 
  y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# calculate occupancy based on sex
hv_occupancy_list_sex = hypervolume_n_occupancy(hv_list, 
                    classification = rep(c("Adelie", "Chinstrap", "Gentoo"), 2))

# get the hypervolume of intersection
hv_occupancy_sex_intersection &lt;- occupancy_to_intersection(hv_occupancy_list_sex)
plot(hv_occupancy_sex_intersection)

# get hypervolumes with the intersection among 3 or 2 combinations of hypervolumes
hv_occ_sex_intersection_3 &lt;- occupancy_to_intersection(hv_occupancy_list_sex,
                                                       method = "n_wise",
                                                       m = 3)
hv_occ_intersection_2 &lt;- occupancy_to_intersection(hv_occupancy_list_sex,
                                                   method = "n_wise",
                                                   m = 2)


## End(Not run)
</code></pre>

<hr>
<h2 id='occupancy_to_union'>
Union of hypervolumes from an occupancy object
</h2><span id='topic+occupancy_to_union'></span>

<h3>Description</h3>

<p>The <code>occupancy_to_union()</code> function is used to get the union of hypervolumes of an object generated with <code>hypervolume_n_occupancy()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_to_union(hv_list, method = "all", m = 2, tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="occupancy_to_union_+3A_hv_list">hv_list</code></td>
<td>

<p>A <code>HypervolumeList</code> object generated with <code>hypervolume_n_occupancy()</code>, <code>hypervolume_n_occupancy_test()</code>, <code>occupancy_to_intersection()</code>, <code>occupancy_to_unshared()</code> or <code>occupancy_filter()</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_union_+3A_method">method</code></td>
<td>

<p>If <code>all</code> compute the union of all the hypervolumes in <code>hv_list</code>. If <code>n_wise</code> compute of the union for each n_wise combination of hypervolumes in <code>hv_list</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_union_+3A_m">m</code></td>
<td>

<p>Number of elements to choose. Default to 2 (pairwise comparisons). This argument is ignored when <code>method</code> is set to <code>all</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_union_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>occupancy_to_union()</code> function takes as input a <code>HypervolumeList</code> generated with an occupancy function (check <code>See Also</code>) and returns a <code>Hypervolume</code> or <code>HypervolumeList</code> depending on <code>method</code>. When <code>method = "all"</code> the <code>occupancy_to_union()</code> function returns a <code>Hypervolume</code> representing the union of all the hypervolumes in <code>hv_list</code>. When <code>method = "n_wise"</code> a <code>HypervolumeList</code> in which each hypervolume represent the union of a combination of the hypervolumes in <code>hv_list</code> is returned. The number of hypervolumes for each combination is set with the argument <code>m</code>. Argument <code>m</code> can not be higher than the number of hypervolumes in <code>hv_list</code> and lower than 2. <br />
The <code>occupancy_to_union()</code> function attempts to reconstruct the volume of the union from the <code>hv_list</code> provided by the user. For each hypervolume in <code>hv_list</code>, it calculates the volume of the union as the ratio between the total number of random points and the number of random points of the ith hypervolume of <code>hv_list</code>, multiplied by the volume of the ith hypervolume of <code>hv_list</code>. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy_object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned.   
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> or <code><a href="#topic+HypervolumeList-class">HypervolumeList-class</a></code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>, <code><a href="#topic+occupancy_to_intersection">occupancy_to_intersection</a></code>, <code><a href="#topic+occupancy_to_unshared">occupancy_to_unshared</a></code>, <code><a href="#topic+occupancy_filter">occupancy_filter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# calculate occupancy based on sex
hv_occupancy_list_sex = hypervolume_n_occupancy(hv_list, 
                          classification = rep(c("female", "male"), 3))
                          
# get the union of all the hypervolumes
hv_occupancy_sex_union &lt;- occupancy_to_union(hv_occupancy_list_sex)
plot(hv_occupancy_sex_union)


## End(Not run)
</code></pre>

<hr>
<h2 id='occupancy_to_unshared'>
Unshared fraction from an occupancy object
</h2><span id='topic+occupancy_to_unshared'></span>

<h3>Description</h3>

<p>The <code>occupancy_to_unshared()</code> function is used to get the unshared fraction of hypervolumes of an object generated with the occupancy routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_to_unshared(hv_list, method = "all", tol = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="occupancy_to_unshared_+3A_hv_list">hv_list</code></td>
<td>

<p>A <code>HypervolumeList</code> object generated with <code>hypervolume_n_occupancy()</code>,  <code>hypervolume_n_occupancy_test()</code>, <code>occupancy_to_union()</code>, <code>occupancy_to_intersection()</code> or <code>occupancy_filter</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_unshared_+3A_method">method</code></td>
<td>

<p>If <code>all</code> compute the unshared fraction of each hypervolume in <code>hv_list</code>. If <code>pairwise</code> compute the unshared fraction for each pairwise combination of hypervolumes in <code>hv_list</code>.
</p>
</td></tr>
<tr><td><code id="occupancy_to_unshared_+3A_tol">tol</code></td>
<td>

<p>Set the tolerance for reconstructing whole volume. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unshared fraction is the fraction of the hypervolume not shared with other hypervolumes. It is calculated from occupancy objects only (check <code>See Also</code>). When <code>method = "all"</code> a <code>HypervolumeList</code> containing the unshared fraction of each hypervolume is returned. When <code>method = "pairwise"</code> an <code>HypervolumeList</code> containing the unshared fraction of the pairwise combination of hypervolumes is returned. Hypervolumes generated when <code>method = "pairwise"</code> include the unshared fraction of both hypervolumes under comparison. The first of the two hypervolumes is assigned with  <code>ValueAtRandomPoints</code> equal to 1 while, the second is assigned with <code>ValueAtRandomPoints</code> equal to -1. This is useful when used in combination with <code>occupancy_filter()</code> or <code>hypervolume_to_data_frame()</code>. <br />
The <code>occupancy_to_unshared()</code> function attempts to reconstruct the volume of the unshared fraction from the <code>hv_list</code> provided by the user. At first, the volume of the union of hypervolumes is calculated for each hypervolume in <code>hv_list</code> as the the ratio between the total number of random points and the number of random points of the ith hypervolume of <code>hv_list</code>, multiplied by the volume of the ith hypervolume of <code>hv_list</code>. This step results in a number of reconstructed volumes equal to the number of hypervolumes in the jth bootstrapped occupancy_object. Reconstructed volumes are then compared among each other to ensure the consistency of the reconstruction. To do this, the distance among reconstructed volumes is calculated with the <code>dist()</code> function of the <code>stats</code> package. If at least one of the distances is greater than <code>tol</code> the computation is stopped and some suggestions are returned. The volume of the unshared fraction is then calculated as the ratio between the number of random points of the unshared fraction and the total number of random points, multiplied by the volume of the union of hypervolumes.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> or <code><a href="#topic+HypervolumeList-class">HypervolumeList-class</a></code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_n_occupancy">hypervolume_n_occupancy</a></code>, <code><a href="#topic+hypervolume_n_occupancy_test">hypervolume_n_occupancy_test</a></code>, <code><a href="#topic+occupancy_to_intersection">occupancy_to_intersection</a></code>,
<code><a href="#topic+occupancy_to_union">occupancy_to_union</a></code>, <code><a href="#topic+occupancy_filter">occupancy_filter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))

# split the dataset on species and sex
penguins_no_na_split = split(penguins_no_na, 
paste(penguins_no_na$species, penguins_no_na$sex, sep = "_"))

# calculate the hypervolume for each element of the splitted dataset
hv_list = mapply(function(x, y) 
  hypervolume_gaussian(x[, c("bill_length_mm", "flipper_length_mm")],
                       samples.per.point=100, name = y), 
                       x = penguins_no_na_split, 
                       y = names(penguins_no_na_split))


# transform the list into an HypervolumeList
hv_list = hypervolume_join(hv_list)

# calculate occupancy based on sex
hv_occupancy_list_sex = hypervolume_n_occupancy(hv_list, 
                          classification = rep(c("female", "male"), 3))
                          
# get hypervolumes with the unshared fraction
hv_occupancy_sex_unshared &lt;- occupancy_to_unshared(hv_occupancy_list_sex)
plot(hv_occupancy_sex_unshared)

# get hypervolumes with the unshared fraction between each pairwise combination of hypervolumes
hv_occupancy_sex_unshared_pw &lt;- occupancy_to_unshared(hv_occupancy_list_sex)

# plot the unshared fraction with ggplot2
require(ggplot2)

# extract data to plot
occupancy_sex_pw_df &lt;- hypervolume_to_data_frame(hv_occupancy_sex_unshared_pw)

ggplot(occupancy_sex_pw_df, aes(bill_length_mm, flipper_length_mm, col = Name)) +
  geom_point() +
  theme_bw()

## End(Not run)
</code></pre>

<hr>
<h2 id='padded_range'>
Generates axis-wise range limits with padding
</h2><span id='topic+padded_range'></span>

<h3>Description</h3>

<p>For each data axis, finds the minimum and maximum values. Then pads this range by a multiplicative factor of the range interval, and pads again by an additive amount.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>padded_range(data, multiply.interval.amount = 0, add.amount = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="padded_range_+3A_data">data</code></td>
<td>

<p>A m x n matrix whose range limits should be found.
</p>
</td></tr>
<tr><td><code id="padded_range_+3A_multiply.interval.amount">multiply.interval.amount</code></td>
<td>

<p>A non-negative factor used to multiply the range interval. Can have either dimensionality 1 or n.
</p>
</td></tr>
<tr><td><code id="padded_range_+3A_add.amount">add.amount</code></td>
<td>

<p>A non-negative factor used to add to the range limits. Can have either dimensionality 1 or n.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 2 x n matrix, whose first row is the low value along each axis and whose second row is the high value along each axis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(morphSnodgrassHeller)
finch_isabela &lt;- na.omit(morphSnodgrassHeller[morphSnodgrassHeller$IslandID=="Isa_Alb",
      c("WingL","TailL","BeakW","BeakH")])

finch_isabela_rangebox_nopadding = padded_range(finch_isabela)
finch_isabela_rangebox_nopadding

finch_isabela_rangebox_padding = padded_range(finch_isabela,
  multiply.interval.amount=0.5, add.amount=0.1)
finch_isabela_rangebox_padding
</code></pre>

<hr>
<h2 id='plot.HypervolumeList'>
Plot a hypervolume or list of hypervolumes
</h2><span id='topic+plot.Hypervolume'></span><span id='topic+plot.HypervolumeList'></span>

<h3>Description</h3>

<p>Plots a single hypervolume or multiple hypervolumes as either a pairs plot (all axes) or a 3D plot (a subset of axes). The hypervolume is drawn as a uniformly random set of points guaranteed to be in the hypervolume.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HypervolumeList'
plot(x, 
   show.3d=FALSE,plot.3d.axes.id=NULL,
   show.axes=TRUE, show.frame=TRUE,
   show.random=TRUE, show.density=TRUE,show.data=TRUE,
   names=NULL, show.legend=TRUE, limits=NULL, 
   show.contour=TRUE, contour.lwd=1.5, 
    contour.type='kde', 
    contour.alphahull.alpha=0.25,
    contour.ball.radius.factor=1, 
    contour.kde.level=1e-04,
    contour.raster.resolution=20,
   show.centroid=TRUE, cex.centroid=2,
   colors=rainbow(floor(length(x@HVList)*1.5),alpha=0.8), 
   point.alpha.min=0.2, point.dark.factor=0.5,
   cex.random=0.5,cex.data=0.75,cex.axis=0.75,cex.names=1.0,cex.legend=0.75,
   num.points.max.data = 1000, num.points.max.random = 2000, reshuffle=TRUE,
   plot.function.additional=NULL,
   verbose=FALSE,
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.HypervolumeList_+3A_x">x</code></td>
<td>

<p>A Hypervolume or HypervolumeList object. The objects to be plotted.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.3d">show.3d</code></td>
<td>

<p>If <code>TRUE</code>, makes a three-dimensional plot of a subset of axes determined by <code>plot.3d.axes.id</code>; otherwise, a pairs plot of all axes. Requires that the <code>rgl</code> library is installed.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_plot.3d.axes.id">plot.3d.axes.id</code></td>
<td>

<p>Numeric identities of axes to plot in three dimensions. Defaults to 1:3 if set to <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.axes">show.axes</code></td>
<td>

<p>If <code>TRUE</code>, draws axes on the plot.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.frame">show.frame</code></td>
<td>

<p>If <code>TRUE</code>, frames the plot with a box.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.random">show.random</code></td>
<td>

<p>If <code>TRUE</code>, shows random points from the hypervolume.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.density">show.density</code></td>
<td>

<p>If <code>TRUE</code>, draws random points with alpha level proportional to their unit-scaled probability density. Note that this has no effect when probability density is not relevant, i.e. for hypervolumes that are the output of set operations.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.data">show.data</code></td>
<td>

<p>If <code>TRUE</code>, draws data points from the hypervolume. Note that this has no effect if the hypervolume is not associated with data points, e.g. for those that are the output of set operations.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_names">names</code></td>
<td>

<p>A vector of strings in the same order as the input hypervolumes. Used to draw the axes labels.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.legend">show.legend</code></td>
<td>

<p>If <code>TRUE</code>, draws a color legend.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_limits">limits</code></td>
<td>

<p>A list of two-element vectors corresponding to the axes limits for each dimension. If a single two-element vector is provided it is re-used for all axes.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.contour">show.contour</code></td>
<td>

<p>If <code>TRUE</code>, draws a boundary line saround each two-dimensional projection. Ignored if <code>show.3d=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_contour.lwd">contour.lwd</code></td>
<td>

<p>Line width used for contour lines. Ignored if <code>show.contour=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_contour.type">contour.type</code></td>
<td>

<p>Type of contour boundary: any of <code>"alphahull"</code> (alpha hull), <code>"ball"</code> (experimental ball covering), <code>"kde"</code> (2D KDE smoothing), or <code>"raster"</code> (grid-based rasterization).
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_contour.alphahull.alpha">contour.alphahull.alpha</code></td>
<td>

<p>Value of the alpha parameter for a  <code>"alphahull"</code> contour. Can be increased to provide smoother contours.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_contour.ball.radius.factor">contour.ball.radius.factor</code></td>
<td>

<p>Factor used to multiply radius of ball surrounding each random point for a <code>"ball"</code> contour.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_contour.kde.level">contour.kde.level</code></td>
<td>

<p>Probability level used to delineate edges for a <code>"kde"</code> contour.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_contour.raster.resolution">contour.raster.resolution</code></td>
<td>

<p>Grid resolution for a <code>"raster"</code> contour.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_show.centroid">show.centroid</code></td>
<td>

<p>If <code>TRUE</code>, draws a colored point indicating the centroid for each hypervolume.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_cex.centroid">cex.centroid</code></td>
<td>

<p>Expansion factor for the centroid symbol.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_colors">colors</code></td>
<td>

<p>A vector of colors to be used to plot each hypervolume, in the same order as the input hypervolumes.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_point.alpha.min">point.alpha.min</code></td>
<td>

<p>Fractional value corresponding to the most transparent value for plotting random points. 0 corresponds to full transparency.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_point.dark.factor">point.dark.factor</code></td>
<td>

<p>Fractional value corresponding to the darkening factor for plotting data points. 0 corresponds to fully black.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_cex.random">cex.random</code></td>
<td>

<p>cex value for uniformly random points.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_cex.data">cex.data</code></td>
<td>

<p>cex value for data points.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_cex.axis">cex.axis</code></td>
<td>

<p>cex value for axes, if pair=T.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_cex.names">cex.names</code></td>
<td>

<p>cex value for variable names printed on the diagonal, if pair=T.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_cex.legend">cex.legend</code></td>
<td>

<p>cex value for the legend text
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_num.points.max.data">num.points.max.data</code></td>
<td>

<p>An integer indicating the maximum number of data points to be sampled from each hypervolume. Lower values result in faster plotting and smaller file sizes but less accuracy.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_num.points.max.random">num.points.max.random</code></td>
<td>

<p>An integer indicating the maximum number of random points to be sampled from each hypervolume. Lower values result in faster plotting and smaller file sizes but less accuracy.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_reshuffle">reshuffle</code></td>
<td>

<p>A logical value relevant when pair=TRUE. If false, each hypervolume is drawn on top of the previous hypervolume; if true, all points of all hypervolumes are randomly shuffled so no hypervolume is given visual preference during plotting.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_plot.function.additional">plot.function.additional</code></td>
<td>

<p>Any <code>function(i,j)</code> that will add additional plotting commands for column <code>i</code> and row <code>j</code> of the pairs plot. Should not create new plots or change <code>par()</code> settings. Has no effect if <code>show.3d=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, prints diagnostic information about the number of points being plotted
</p>
</td></tr>
<tr><td><code id="plot.HypervolumeList_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to <code>rgl::plot3d</code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None; used for the side-effect of producing a plot.
</p>


<h3>Note</h3>

<p>Contour line plotting with <code>alphahull</code> requires the non-FOSS <code>alphahull</code> package to be installed. Please do so in order to use this functionality!
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_save_animated_gif">hypervolume_save_animated_gif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# low parameter values for speed
data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

hv = hypervolume_gaussian(penguins_adelie,name='Adelie')

# 2d plot
plot(hv, show.3d=FALSE)

# 3d plot
if(interactive()) 
{
  plot(hv, show.3d=TRUE)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='print.Hypervolume'>
Print summary of hypervolume
</h2><span id='topic+print.Hypervolume'></span><span id='topic+print.HypervolumeList'></span>

<h3>Description</h3>

<p>Summarizes all slots of <code><a href="#topic+Hypervolume-class">Hypervolume-class</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Hypervolume'
print(x, ...)
## S3 method for class 'HypervolumeList'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.Hypervolume_+3A_x">x</code></td>
<td>

<p>The hypervolume to summarize
</p>
</td></tr>
<tr><td><code id="print.Hypervolume_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to base print function 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None; used for the side-effect of printing.
</p>

<hr>
<h2 id='quercus'>
Data and demo for Quercus (oak) tree distributions
</h2><span id='topic+quercus'></span>

<h3>Description</h3>

<p>Data for occurrences of Quercus alba and Quercus rubra based on geographic observations. Demonstration analysis of how to use hypervolumes for species distribution modeling using WorldClim data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(quercus)</code></pre>


<h3>Format</h3>

<p>A data frame with 3779 observations on the following 3 variables.
</p>

<dl>
<dt><code>Species</code></dt><dd><p>a factor with levels <code>Quercus alba</code> <code>Quercus rubra</code></p>
</dd>
<dt><code>Latitude</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Longitude</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Occurrence data come from the BIEN database (<code>https://biendata.org/</code>). Climate data are from WorldClim.
</p>


<h3>References</h3>

<p>Blonder, B., Lamanna, C., Violle, C., Enquist, B. The n-dimensional hypervolume. Global Ecology and Biogeography (2014).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>demo('quercus', package='hypervolume')
</code></pre>

<hr>
<h2 id='summary.Hypervolume'>
Summary of hypervolume
</h2><span id='topic+summary.Hypervolume'></span><span id='topic+summary.HypervolumeList'></span><span id='topic+show.Hypervolume'></span><span id='topic+show.HypervolumeList'></span>

<h3>Description</h3>

<p>Prints basic information about Hypervolume or HypervolumeList structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Hypervolume'
summary(object, ...)
## S3 method for class 'HypervolumeList'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.Hypervolume_+3A_object">object</code></td>
<td>

<p>The hypervolume to summarize
</p>
</td></tr>
<tr><td><code id="summary.Hypervolume_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to base summary function 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None; used for the side-effect of printing.
</p>

<hr>
<h2 id='to_hv_list'>
Read hypervolumes from directory
</h2><span id='topic+to_hv_list'></span>

<h3>Description</h3>

<p>Takes a path to a directory containing only rds files and reads them into a HypervolumeList object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_hv_list(path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="to_hv_list_+3A_path">path</code></td>
<td>

<p>absolute or relative path to directory containing rds files
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use to_hv_list on the output from <code>hypervolume_resample</code> when method = &quot;bootstrap&quot; to read bootstrapped hypervolumes into memory.
</p>


<h3>Value</h3>

<p><code>HypervolumeList</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(palmerpenguins)
data(penguins)
bill_data = na.omit(penguins[,3:4])
hv = hypervolume(bill_data)

# Use detectCores to see how many cores are availible in current environment
path = hypervolume_resample("example_bootstrap", hv, method = "bootstrap", n = 50, cores = 12)
hvs = to_hv_list(path)

## End(Not run)
</code></pre>

<hr>
<h2 id='weight_data'>
Abundance weighting and prior  of data for hypervolume input
</h2><span id='topic+weight_data'></span>

<h3>Description</h3>

<p>Resamples input data for hypervolume construction, so that some data points can be weighted more strongly than others in kernel density estimation. Also allows a multidimensional normal prior distribution to be placed on each data point to enable simulation of uncertainty or variation within each observed data point. 
</p>
<p>Note that this algorithm will change the number of data points and may thus lead to changes in the inferred hypervolume if the selected algorithm (e.g. for bandwidth selection) depends on sample size.
</p>
<p>A direct weighting approach (which does not artificially change the sample size, and thus the kernel bandwidth estimate) is available for Gaussian hypervolumes within <code><a href="#topic+hypervolume_gaussian">hypervolume_gaussian</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weight_data(data, weights, jitter.sd = matrix(0, nrow = nrow(data), ncol = ncol(data)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weight_data_+3A_data">data</code></td>
<td>

<p>A data frame or matrix of unweighted data. Must only contain numeric values.
</p>
</td></tr>
<tr><td><code id="weight_data_+3A_weights">weights</code></td>
<td>

<p>A vector of weights with the same length as the number of rows in <code>data</code>. All values must take positive integer values.
</p>
</td></tr>
<tr><td><code id="weight_data_+3A_jitter.sd">jitter.sd</code></td>
<td>

<p>A matrix of the same size as <code>data</code> corresponding to the standard deviation of a normal distribution with mean equal to that of the observed data. If a vector of length equal to 1 or the number of columns of <code>data</code>, is repeated for all observations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each data point is jittered a single time. To sample many points from a distribution around each observed data point, multiply all weights by a large number.
</p>


<h3>Value</h3>

<p>A data frame with the rows of <code>data</code> repeated by <code>weights</code>, potentially with noise added. The output has the same columns as the input but <code>sum(weights)</code> total rows.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume_gaussian">hypervolume_gaussian</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins,package='palmerpenguins')
penguins_no_na = as.data.frame(na.omit(penguins))
penguins_adelie = penguins_no_na[penguins_no_na$species=="Adelie",
                    c("bill_length_mm","bill_depth_mm","flipper_length_mm")]

weighted_data &lt;- weight_data(penguins_adelie,
  weights=1+rpois(n=nrow(penguins_adelie),lambda=3))
# color points by alpha to show overlaps
pairs(weighted_data,col=rgb(1,0,0,alpha=0.15)) 

weighted_noisy_data &lt;- weight_data(penguins_adelie,
  weights=1+rpois(n=nrow(penguins_adelie),lambda=3),jitter.sd=0.5)
# color points by alpha to show overlaps
pairs(weighted_noisy_data,col=rgb(1,0,0,alpha=0.15)) 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
