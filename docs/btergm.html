<!DOCTYPE html><html><head><title>Help for package btergm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {btergm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjust'><p>Adjust the dimensions of a source object to the dimensions of a target object</p></a></li>
<li><a href='#alliances'><p>Longitudinal international defense alliance network, 1981&ndash;2000</p></a></li>
<li><a href='#btergm'><p>Estimate a TERGM by MPLE with temporal bootstrapping</p></a></li>
<li><a href='#btergm-class'><p>An S4 class to represent a fitted TERGM by bootstrapped MPLE</p></a></li>
<li><a href='#btergm-package'><p>Temporal Exponential Random Graph Models by Bootstrapped Pseudolikelihood</p></a></li>
<li><a href='#checkdegeneracy'><p>Check for degeneracy in fitted TERGMs</p></a></li>
<li><a href='#chemnet'><p>German Toxic Chemicals Policy Network in the 1980s (Volker Schneider)</p></a></li>
<li><a href='#coauthor'><p>Swiss political science co-authorship network 2013</p></a></li>
<li><a href='#createBtergm'><p>Constructor for btergm objects</p></a></li>
<li><a href='#createMtergm'><p>Constructor for mtergm objects</p></a></li>
<li><a href='#createTbergm'><p>Constructor for tbergm objects</p></a></li>
<li><a href='#edgeprob'><p>Create all predicted tie probabilities using MPLE</p></a></li>
<li><a href='#getformula'><p>Extract the formula from a model</p></a></li>
<li><a href='#gof'><p>Goodness-of-fit diagnostics for ERGMs, TERGMs, SAOMs, and logit models</p></a></li>
<li><a href='#gof-plot'><p>Plot and print methods for GOF output</p></a></li>
<li><a href='#gof-statistics'><p>Statistics for goodness-of-fit assessment of network models</p></a></li>
<li><a href='#handleMissings'><p>Handle missing data in matrices</p></a></li>
<li><a href='#interpret'><p>Micro-Level Interpretation of (T)ERGMs</p></a></li>
<li><a href='#knecht'><p>Longitudinal classroom friendship network and behavior (Andrea Knecht)</p></a></li>
<li><a href='#marginalplot'><p>Plot marginal effects for two-way interactions in (T)ERGMs</p></a></li>
<li><a href='#mtergm'><p>Estimate a TERGM by MCMC-MLE</p></a></li>
<li><a href='#mtergm-class'><p>An S4 Class to represent a fitted TERGM by MCMC-MLE</p></a></li>
<li><a href='#simulate.btergm'><p>Simulate Networks from a <code>btergm</code> Object</p></a></li>
<li><a href='#tbergm'><p>Estimate a TERGM using Bayesian estimation</p></a></li>
<li><a href='#tbergm-class'><p>An S4 class to represent a fitted TERGM using Bayesian estimation</p></a></li>
<li><a href='#tergm-terms'><p>Temporal dependencies for TERGMs</p></a></li>
<li><a href='#tergmprepare'><p>Prepare data structure for TERGM estimation, including composition change</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.10.12</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-31</td>
</tr>
<tr>
<td>Title:</td>
<td>Temporal Exponential Random Graph Models by Bootstrapped
Pseudolikelihood</td>
</tr>
<tr>
<td>Description:</td>
<td>Temporal Exponential Random Graph Models (TERGM) estimated by maximum pseudolikelihood with bootstrapped confidence intervals or Markov Chain Monte Carlo maximum likelihood. Goodness of fit assessment for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs. The methods are described in Leifeld, Cranmer and Desmarais (2018), JStatSoft &lt;<a href="https://doi.org/10.18637%2Fjss.v083.i06">doi:10.18637/jss.v083.i06</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/leifeld/btergm">https://github.com/leifeld/btergm</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, methods, graphics, network (&ge; 1.17.1), sna (&ge;
2.3.2), ergm (&ge; 4.2.1), parallel, Matrix (&ge; 1.3.2), boot (&ge;
1.3.17), coda (&ge; 0.18.1), ROCR (&ge; 1.0.7), igraph (&ge; 0.7.1),
statnet.common (&ge; 4.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>fastglm (&ge; 0.0.1), speedglm (&ge; 0.3.1), testthat, Bergm (&ge;
5.0.2), RSiena (&ge; 1.0.12.232), ggplot2 (&ge; 2.0.0)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-31 21:09:45 UTC; philip</td>
</tr>
<tr>
<td>Author:</td>
<td>Philip Leifeld [aut, cre],
  Skyler J. Cranmer [ctb],
  Bruce A. Desmarais [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Philip Leifeld &lt;philip.leifeld@manchester.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-31 22:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjust'>Adjust the dimensions of a source object to the dimensions of a target object</h2><span id='topic+adjust'></span>

<h3>Description</h3>

<p>Adjust the dimensions of a source object to the dimensions of a target
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust(
  source,
  target,
  remove = TRUE,
  add = TRUE,
  value = NA,
  returnlabels = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust_+3A_source">source</code></td>
<td>
<p>A matrix, network, list or data.frame object or a vector which
should be adjusted.</p>
</td></tr>
<tr><td><code id="adjust_+3A_target">target</code></td>
<td>
<p>A matrix, network, list or data.frame object or a vector to
which the source object is compared with regard to its labels.</p>
</td></tr>
<tr><td><code id="adjust_+3A_remove">remove</code></td>
<td>
<p>Should rows and columns that are not present in the target
object be removed?</p>
</td></tr>
<tr><td><code id="adjust_+3A_add">add</code></td>
<td>
<p>Should rows and columns that are present in the target object but
not in the source object be added to the source object?</p>
</td></tr>
<tr><td><code id="adjust_+3A_value">value</code></td>
<td>
<p>The value to be inserted if a new row or column is added. By
default, new cells are filled with <code>NA</code> values, but other sensible
values may include <code>-Inf</code> or <code>0</code>.</p>
</td></tr>
<tr><td><code id="adjust_+3A_returnlabels">returnlabels</code></td>
<td>
<p>Return a list of added and removed row and column labels
rather than the actual matrix, vector, or network object?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An adjacency matrix (the <code>source</code> matrix) is compared to another
adjacency matrix (the <code>target</code> matrix) by matching the row or column
labels. If the target matrix contains rows/columns which are not present in
the source matrix, new rows and columns with the corresponding labels and
<code>NA</code> values in the cells are inserted into the source matrix. If the
source matrix contains rows/columns which are not present in the target
matrix, these rows and columns are removed from the source matrix. In
addition to adjacency matrices, two-mode matrices, network objects (also with
vertex attributes), and vectors are supported.
</p>
<p>Note that it is not necessary to use this function to preprocess any data
before estimating a TERGM. The estimation functions in the <span class="pkg">btergm</span>
package call this function repeatedly to mutually adjust all data as needed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+handleMissings">handleMissings</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create sociomatrix a with 13 vertices a to m
vertices &lt;- letters[1:13]
a &lt;- matrix(rbinom(length(vertices)^2, 1, 0.1), nrow = length(vertices))
rownames(a) &lt;- colnames(a) &lt;- vertices

# create matrix b with the same vertices except f and k, but additional n
vertices &lt;- c(vertices[-c(6, 11)], "n")
b &lt;- matrix(rbinom(length(vertices)^2, 1, 0.1), nrow = length(vertices))
rownames(b) &lt;- colnames(b) &lt;- vertices

# check dimensions
dim(a)  # 13 x 13
dim(b)  # 12 x 12

# adjust a to b: add n and fill up with NAs; remove f and k
adjust(a, b, add = TRUE, remove = TRUE)

## Not run: 
# more complex example with additional attributes stored in the network
# object; convert a to network object with additional vertex and network
# attributes
nw &lt;- network(a)
vertices &lt;- letters[1:13]
nwattrib1 &lt;- matrix(rbinom(length(vertices)^2, 1, 0.1),
                    nrow = length(vertices))
nwattrib2 &lt;- nwattrib1
rownames(nwattrib1) &lt;- colnames(nwattrib1) &lt;- vertices
set.network.attribute(nw, "nwattrib1", nwattrib1)
set.network.attribute(nw, "nwattrib2", nwattrib2)
set.vertex.attribute(nw, "vattrib", 1:length(vertices))

# check presence of the two attributes
list.network.attributes(nw)  # nwattrib1 and nwattrib2 are listed
get.network.attribute(nw, "nwattrib1")  # returns sociomatrix with labels
get.network.attribute(nw, "nwattrib2")  # returns sociomatrix without labels
list.vertex.attributes(nw)  # vattrib is listed
get.vertex.attribute(nw, "vattrib")  # returns numeric vector 1:13

# adjust the network including the two attributes
nw.adjusted &lt;- adjust(nw, b, add = TRUE, remove = TRUE)
as.matrix(nw.adjusted)  # note that the order of nodes may have changed
get.network.attribute(nw.adjusted, "nwattrib1")  # returns adjusted matrix
get.network.attribute(nw.adjusted, "nwattrib2")  # returns adjusted matrix
get.vertex.attribute(nw.adjusted, "vattrib")  # returns adjusted vector

## End(Not run)

</code></pre>

<hr>
<h2 id='alliances'>Longitudinal international defense alliance network, 1981&ndash;2000</h2><span id='topic+alliances'></span><span id='topic+allyNet'></span><span id='topic+contigMat'></span><span id='topic+lNet'></span><span id='topic+LSP'></span><span id='topic+warNet'></span>

<h3>Description</h3>

<p>Longitudinal international defense alliance network, 1981&ndash;2000.
</p>


<h3>Format</h3>


<dl>
<dt><code>allyNet</code></dt><dd><p>is a list of network objects at 20 time points,
1981&ndash;2000, containing undirected defense alliance networks. In addition to
the alliance ties, each network object contains three vertex attributes.
<code>cinc</code> is the &quot;CINC&quot; or Composite Index of National Capability score
(see
<a href="https://correlatesofwar.org/data-sets/national-material-capabilities/">https://correlatesofwar.org/data-sets/national-material-capabilities/</a>).
<code>polity</code> is the &quot;polity score&quot; of each country in the respective year.
Quoting the online description, &quot;the Polity Score captures this regime
authority spectrum on a 21-point scale ranging from -10 (hereditary
monarchy) to +10 (consolidated democracy),&quot; (see
<a href="https://www.systemicpeace.org/polityproject.html">https://www.systemicpeace.org/polityproject.html</a>). <code>year</code> is
simply the year recorded as a vertex attribute.</p>
</dd>
<dt><code>contigMat</code></dt><dd><p>is a 164 x 164 binary matrix in which a 1 indicates
that two countries share a border.</p>
</dd>
<dt><code>lNet</code></dt><dd><p>is a list of 20 matrices. Each element is the adjacency
matrix from the previous year. This is used to model memory in the ties.</p>
</dd>
<dt><code>LSP</code></dt><dd><p>is a list of 20 matrices. Each element is a matrix
recording the number of shared partners between countries in the alliance
network from the previous year.</p>
</dd>
<dt><code>warNet</code></dt><dd><p>is a list of 20 matrices. Each element is a binary
matrix that indicates whether two states were in a militarized interstate
dispute in the respective year.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The alliances dataset contains the international defense alliance network
among 164 countries, covering the years 1981&ndash;2000. In addition to the
yearly defense alliance network, it contains data on military capabilities,
governing regime type, geographic contiguity and international conflict.
This is an excerpt from a dataset that has been used in two published
analyses. The full dataset (Cranmer, Desmarais and Menninga 2012; Cranmer,
Desmarais and Kirkland 2012) contains a large number of countries and a much
longer time series.
</p>


<h3>Source</h3>

<p>The data were gathered by Skyler Cranmer and Bruce Desmarais in the
process of writing Cranmer, Desmarais and Menninga (2012) and Cranmer,
Desmarais and Kirkland (2012).
</p>
<p>Permission to redistribute this dataset along with this package was granted
by Skyler Cranmer and Bruce Desmarais on December 15, 2015. Questions about
the data should be directed to them.
</p>


<h3>References</h3>

<p>Cranmer, Skyler J., Bruce A. Desmarais, and Justin H. Kirkland
(2012): Toward a Network Theory of Alliance Formation. <em>International
Interactions</em> 38(3): 295&ndash;324. <a href="https://doi.org/10.1080/03050629.2012.677741">doi:10.1080/03050629.2012.677741</a>.
</p>
<p>Cranmer, Skyler J., Bruce A. Desmarais, and Elizabeth Menninga (2012):
Complex Dependencies in the Alliance Network. <em>International
Interactions</em> 29(3): 279&ndash;313. <a href="https://doi.org/10.1177/0738894212443446">doi:10.1177/0738894212443446</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("alliances")

# btergm formulas look very similar to ERGM formulas.
# Note the R argument; usually want R &gt; 1000.
# Here it is set to 50 to limit computation time.
# First, set the seed for replicability.
set.seed(123)
model &lt;- btergm(allyNet ~ edges + gwesp(0, fixed = TRUE)
    + edgecov(lNet) + edgecov(LSP) + edgecov(warNet)
    + nodecov("polity") + nodecov("cinc") + absdiff("polity")
    + absdiff("cinc") + edgecov(contigMat) + nodecov("year"),
    R = 50)

# View estimates and confidence intervals.
summary(model)

# Evaluate model fit. Simulate 100 networks for each time point.
# Calculate edgewise shared partners, degree and geodesic distance
# distance distributions.
alliance_gof &lt;- gof(model, statistics = c(deg, esp, geodesic))

# Plot goodness of fit.
plot(alliance_gof)

## End(Not run)
</code></pre>

<hr>
<h2 id='btergm'>Estimate a TERGM by MPLE with temporal bootstrapping</h2><span id='topic+btergm'></span>

<h3>Description</h3>

<p>Estimate a TERGM by MPLE with temporal bootstrapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>btergm(
  formula,
  R = 500,
  offset = FALSE,
  returndata = FALSE,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  control.ergm = NULL,
  usefastglm = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="btergm_+3A_formula">formula</code></td>
<td>
<p>Formula for the TERGM. Model construction works like in the
<span class="pkg">ergm</span> package with the same model terms etc. (for a list of terms, see
<code>help("<a href="ergm.html#topic+ergm-terms">ergm-terms</a>")</code>). The networks to be modeled on the
left-hand side of the equation must be given either as a list of network
objects with more recent networks last (i.e., chronological order) or as a
list of matrices with more recent matrices at the end. <code>dyadcov</code> and
<code>edgecov</code> terms accept time-independent covariates (as <code>network</code>
or <code>matrix</code> objects) or time-varying covariates (as a list of networks
or matrices with the same length as the list of networks to be modeled).</p>
</td></tr>
<tr><td><code id="btergm_+3A_r">R</code></td>
<td>
<p>Number of bootstrap replications. The higher the number of
replications, the more accurate but also the slower is the estimation.</p>
</td></tr>
<tr><td><code id="btergm_+3A_offset">offset</code></td>
<td>
<p>If <code>offset = TRUE</code> is set, a list of offset matrices
(one for each time step) with structural zeros is handed over to the
pseudolikelihood preparation routine. The offset matrices contain
structural zeros where either the dependent networks or any of the
covariates have missing nodes (if <code>auto.adjust = TRUE</code> is used). All
matrices and network objects are inflated to the dimensions of the largest
object, and the offset matrices inform the estimation preparation routine
which dyads are constrained to be absent. After MPLE data preparation, the
dyads with these structural zeros are removed before the GLM is estimated.
If <code>offset = FALSE</code> is set (the default behavior), all nodes that are
not present across all covariates and networks within a time step are
removed completely from the respective object(s) before estimation begins.</p>
</td></tr>
<tr><td><code id="btergm_+3A_returndata">returndata</code></td>
<td>
<p>Return the processed input data instead of estimating and
returning the model? In the <code>btergm</code> case, this will return a data
frame with the dyads of the dependent variable/network and the change
statistics for all covariates. In the <code>mtergm</code> case, this will return
a list object with the blockdiagonal network object for the dependent
variable and blockdiagonal matrices for all dyadic covariates and the
offset matrix for the structural zeros.</p>
</td></tr>
<tr><td><code id="btergm_+3A_parallel">parallel</code></td>
<td>
<p>Use multiple cores in a computer or nodes in a cluster to
speed up bootstrapping computations. The default value <code>"no"</code> means
parallel computing is switched off. If <code>"multicore"</code> is used, the
<code>mclapply</code> function from the <span class="pkg">parallel</span> package (formerly in the
<span class="pkg">multicore</span> package) is used for parallelization. This should run on
any kind of system except MS Windows because it is based on forking. It is
usually the fastest type of parallelization. If <code>"snow"</code> is used, the
<code>parLapply</code> function from the <span class="pkg">parallel</span> package (formerly in the
<span class="pkg">snow</span> package) is used for parallelization. This should run on any
kind of system including cluster systems and including MS Windows. It is
slightly slower than the former alternative if the same number of cores is
used. However, <code>"snow"</code> provides support for MPI clusters with a large
amount of cores, which <span class="pkg">multicore</span> does not offer (see also the
<code>cl</code> argument). The backend for the bootstrapping procedure is the
<span class="pkg">boot</span> package.</p>
</td></tr>
<tr><td><code id="btergm_+3A_ncpus">ncpus</code></td>
<td>
<p>The number of CPU cores used for parallel computing (only if
<code>parallel</code> is activated). If the number of cores should be detected
automatically on the machine where the code is executed, one can set
<code>ncpus = detectCores()</code> after loading the <span class="pkg">parallel</span> package.
On some HPC clusters, the number of available cores is saved as an
environment variable; for example, if MOAB is used, the number of
available cores can sometimes be accessed using
<code>Sys.getenv("MOAB_PROCCOUNT")</code>, depending on the implementation.</p>
</td></tr>
<tr><td><code id="btergm_+3A_cl">cl</code></td>
<td>
<p>An optional <span class="pkg">parallel</span> or <span class="pkg">snow</span> cluster for use if
<code>parallel = "snow"</code>. If not supplied, a PSOCK cluster is created
temporarily on the local machine.</p>
</td></tr>
<tr><td><code id="btergm_+3A_control.ergm">control.ergm</code></td>
<td>
<p>ergm controls for <code><a href="ergm.html#topic+ergmMPLE">ergmMPLE</a></code> calls. See
<code><a href="ergm.html#topic+control.ergm">control.ergm</a></code> for details.</p>
</td></tr>
<tr><td><code id="btergm_+3A_usefastglm">usefastglm</code></td>
<td>
<p>Controls whether to use the <code><a href="fastglm.html#topic+fastglm">fastglm</a></code>
estimation routine from the <span class="pkg">fastglm</span> package with <code>method = 3</code>.
Defaults to <code>FALSE</code> (and then uses
<code><a href="speedglm.html#topic+speedglm">speedglm.wfit</a></code> instead if available).</p>
</td></tr>
<tr><td><code id="btergm_+3A_verbose">verbose</code></td>
<td>
<p>Print details about data preprocessing and estimation
settings.</p>
</td></tr>
<tr><td><code id="btergm_+3A_...">...</code></td>
<td>
<p>Further arguments to be handed over to the
<code><a href="boot.html#topic+boot">boot</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>btergm</code> function computes temporal exponential random graph models
(TERGM) by bootstrapped pseudolikelihood, as described in Desmarais and
Cranmer (2012). It is faster than MCMC-MLE but only asymptotically unbiased
the longer the time series of networks because it uses temporal bootstrapping
to correct the standard errors.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld, Skyler J. Cranmer, Bruce A. Desmarais
</p>


<h3>References</h3>

<p>Cranmer, Skyler J., Tobias Heinrich and Bruce A. Desmarais
(2014): Reciprocity and the Structural Determinants of the International
Sanctions Network. <em>Social Networks</em> 36(1): 5-22.
<a href="https://doi.org/10.1016/j.socnet.2013.01.001">doi:10.1016/j.socnet.2013.01.001</a>.
</p>
<p>Desmarais, Bruce A. and Skyler J. Cranmer (2012): Statistical Mechanics of
Networks: Estimation and Uncertainty. <em>Physica A</em> 391: 1865&ndash;1876.
<a href="https://doi.org/10.1016/j.physa.2011.10.018">doi:10.1016/j.physa.2011.10.018</a>.
</p>
<p>Desmarais, Bruce A. and Skyler J. Cranmer (2010): Consistent Confidence
Intervals for Maximum Pseudolikelihood Estimators. <em>Neural Information
Processing Systems 2010 Workshop on Computational Social Science and the
Wisdom of Crowds</em>.
</p>
<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2017):
Temporal Exponential Random Graph Models with btergm: Estimation and
Bootstrap Confidence Intervals. <em>Journal of Statistical Software</em>
83(6): 1-36. <a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mtergm">mtergm</a></code> <code><a href="#topic+tbergm">tbergm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(5)

networks &lt;- list()
for (i in 1:10) {              # create 10 random networks with 10 actors
  mat &lt;- matrix(rbinom(100, 1, .25), nrow = 10, ncol = 10)
  diag(mat) &lt;- 0               # loops are excluded
  nw &lt;- network::network(mat)  # create network object
  networks[[i]] &lt;- nw          # add network to the list
}

covariates &lt;- list()
for (i in 1:10) {              # create 10 matrices as covariate
  mat &lt;- matrix(rnorm(100), nrow = 10, ncol = 10)
  covariates[[i]] &lt;- mat       # add matrix to the list
}

fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates), R = 100)
summary(fit)                   # show estimation results

# For examples with real data, see help("knecht") or help("alliances").


# Examples for parallel processing:

# Some preliminaries:
# - "Forking" means running the code on multiple cores in the same
#   computer. It's fast but consumes a lot of memory because all
#   objects are copied for each node. It's also restricted to
#   cores within a physical computer, i.e. no distribution over a
#   network or cluster. Forking does not work on Windows systems.
# - "MPI" is a protocol for distributing computations over many
#   cores, often across multiple physical computers/nodes. MPI
#   is fast and can distribute the work across hundreds of nodes
#   (but remember that R can handle a maximum of 128 connections,
#   which includes file access and parallel connections). However,
#   it requires that the Rmpi package is installed and that an MPI
#   server is running (e.g., OpenMPI).
# - "PSOCK" is a TCP-based protocol. It can also distribute the
#   work to many cores across nodes (like MPI). The advantage of
#   PSOCK is that it can as well make use of multiple nodes within
#   the same node or desktop computer (as with forking) but without
#   consuming too much additional memory. However, the drawback is
#   that it is not as fast as MPI or forking.
# The following code provides examples for these three scenarios.

# btergm works with clusters via the parallel package. That is, the
# user can create a cluster object (of type "PSOCK", "MPI", or
# "FORK") and supply it to the 'cl' argument of the 'btergm'
# function. If no cluster object is provided, btergm will try to
# create a temporary PSOCK cluster (if parallel = "snow") or it
# will use forking (if parallel = "multicore").

## Not run: 
# To use a PSOCK cluster without providing an explicit cluster
# object:
require("parallel")
fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates),
              R = 100, parallel = "snow", ncpus = 25)

# Equivalently, a PSOCK cluster can be provided as follows:
require("parallel")
cores &lt;- 25
cl &lt;- makeCluster(cores, type = "PSOCK")
fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates),
              R = 100, parallel = "snow", ncpus = cores, cl = cl)
stopCluster(cl)

# Forking (without supplying a cluster object) can be used as
# follows.
require("parallel")
cores &lt;- 25
fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates),
              R = 100, parallel = "multicore", ncpus = cores)
stopCluster(cl)

# Forking (by providing a cluster object) works as follows:
require("parallel")
cores &lt;- 25
cl &lt;- makeCluster(cores, type = "FORK")
fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates),
              R = 100, parallel = "snow", ncpus = cores, cl = cl)
stopCluster(cl)

# To use MPI, a cluster object MUST be created beforehand. In
# this example, a MOAB HPC server is used. It stores the number of
# available cores as a system option:
require("parallel")
cores &lt;- as.numeric(Sys.getenv("MOAB_PROCCOUNT"))
cl &lt;- makeCluster(cores, type = "MPI")
fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates),
              R = 100, parallel = "snow", ncpus = cores, cl = cl)
stopCluster(cl)

# In the following example, the Rmpi package is used to create a
# cluster. This may not work on all systems; consult your local
# support staff or the help files on your HPC server to find out how
# to create a cluster object on your system.

# snow/Rmpi start-up
if (!is.loaded("mpi_initialize")) {
  library("Rmpi")
}
library(snow);

mpirank &lt;- mpi.comm.rank (0)
if (mpirank == 0) {
  invisible(makeMPIcluster())
} else {
  sink (file="/dev/null")
  invisible(slaveLoop (makeMPImaster()))
  mpi.finalize()
  q()
}
# End snow/Rmpi start-up

cl &lt;- getMPIcluster()

fit &lt;- btergm(networks ~ edges + istar(2) + edgecov(covariates),
              R = 100, parallel = "snow", ncpus = 25, cl = cl)

## End(Not run)

</code></pre>

<hr>
<h2 id='btergm-class'>An S4 class to represent a fitted TERGM by bootstrapped MPLE</h2><span id='topic+btergm-class'></span><span id='topic+show+2Cbtergm-method'></span><span id='topic+coef+2Cbtergm-method'></span><span id='topic+nobs+2Cbtergm-method'></span><span id='topic+btergm.se'></span><span id='topic+confint+2Cbtergm-method'></span><span id='topic+timesteps.btergm'></span><span id='topic+summary+2Cbtergm-method'></span>

<h3>Description</h3>

<p>An S4 class to represent a fitted TERGM by bootstrapped MPLE.
</p>
<p>Show the coefficients of a <code>btergm</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'btergm'
show(object)

## S4 method for signature 'btergm'
coef(object, invlogit = FALSE, ...)

## S4 method for signature 'btergm'
nobs(object)

btergm.se(object, print = FALSE)

## S4 method for signature 'btergm'
confint(object, parm, level = 0.95, type = "perc", invlogit = FALSE, ...)

timesteps.btergm(object)

## S4 method for signature 'btergm'
summary(object, level = 0.95, type = "perc", invlogit = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="btergm-class_+3A_object">object</code></td>
<td>
<p>A <code>btergm</code> object.</p>
</td></tr>
<tr><td><code id="btergm-class_+3A_invlogit">invlogit</code></td>
<td>
<p>Apply inverse logit transformation to the estimates and/or
confidence intervals? That is, <code class="reqn">\frac{1}{1 + \exp(-x)}</code>, where <code class="reqn">x</code>
is the respective value.</p>
</td></tr>
<tr><td><code id="btergm-class_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed through to the <code>confint</code>
function.</p>
</td></tr>
<tr><td><code id="btergm-class_+3A_print">print</code></td>
<td>
<p>Should the formatted coefficient table be printed to the R
console along with significance stars (<code>print = TRUE</code>), or should the
plain coefficient matrix be returned (<code>print = FALSE</code>)?</p>
</td></tr>
<tr><td><code id="btergm-class_+3A_parm">parm</code></td>
<td>
<p>Parameters (specified by integer position or character string).</p>
</td></tr>
<tr><td><code id="btergm-class_+3A_level">level</code></td>
<td>
<p>The significance level for computation of the confidence
intervals. The default is <code>0.95</code> (that is, an alpha value of 0.05).
Other common values include <code>0.999</code>, <code>0.99</code>, and <code>0.9</code>.</p>
</td></tr>
<tr><td><code id="btergm-class_+3A_type">type</code></td>
<td>
<p>Type of confidence interval, e.g., basic bootstrap interval
(<code>type = "basic"</code>), percentile-based interval (<code>type = "perc"</code>,
which is the default option), or bias-adjusted and accelerated confidence
interval (<code>type = "bca"</code>). All options from the <code>type</code> argument
of the <a href="boot.html#topic+boot.ci">boot.ci</a> function in the boot package can be used to
generate confidence intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>btergm</code> objects result from the estimation of a bootstrapped TERGM via
the <code><a href="#topic+btergm">btergm</a></code> function. <code>btergm</code> objects contain the
coefficients, the bootstrapping samples of the coefficients, the number of
replications, the number of observations, the number of time steps, the
original formula, and the response, effects and weights objects that were fed
into the <code>glm</code> call for estimating the model.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>coef(btergm)</code>: Return the coefficients of a <code>btergm</code> object.
</p>
</li>
<li> <p><code>nobs(btergm)</code>: Return the number of observations saved in a
<code>btergm</code> object.
</p>
</li>
<li> <p><code>btergm.se()</code>: Create a coefficient table from a <code>btergm</code>
object
</p>
<p>Create a coefficient matrix with standard errors and p-values.
</p>
<p>This function can create a coefficient matrix with coefficients, standard
errors, z-scores, and p-values, based on a fitted <code>btergm</code> object.
If the argument <code>print = TRUE</code> is used, the matrix is printed to the R
console as a formatted coefficient matrix with significance stars instead.
Note that confidence intervals are the preferred way of interpretation for
bootstrapped TERGMs; standard errors are only accurate if the bootstrapped
data are normally distributed, which is not always the case. Various methods
for checking for normality for each model term are available, for example
quantile-quantile plots (e.g., <code>qqnorm(x@boot$t[, 1])</code> for the first
model term in the <code>btergm</code> object called <code>x</code>).
</p>
</li>
<li> <p><code>confint(btergm)</code>: Return the confidence intervals for estimates in a
<code>btergm</code> object.
</p>
</li>
<li> <p><code>timesteps.btergm()</code>: Return the number of time steps saved in a
<code>btergm</code> object.
</p>
</li>
<li> <p><code>summary(btergm)</code>: Summary of a fitted <code>btergm</code> object.
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>coef</code></dt><dd><p>Object of class <code>"numeric"</code>. The coefficients.</p>
</dd>
<dt><code>boot</code></dt><dd><p>Object of class <code>"matrix"</code>. The bootstrapping sample.</p>
</dd>
<dt><code>R</code></dt><dd><p>Object of class <code>"numeric"</code>. Number of replications.</p>
</dd>
<dt><code>nobs</code></dt><dd><p>Object of class <code>"numeric"</code>. Number of observations.</p>
</dd>
<dt><code>time.steps</code></dt><dd><p>Object of class <code>"numeric"</code>. Number of time steps.</p>
</dd>
<dt><code>formula</code></dt><dd><p>Object of class <code>"formula"</code>. The original model formula
(without indices for the time steps).</p>
</dd>
<dt><code>formula2</code></dt><dd><p>The revised formula with the object references after applying
the <code><a href="#topic+tergmprepare">tergmprepare</a></code> function.</p>
</dd>
<dt><code>response</code></dt><dd><p>Object of class <code>"integer"</code>. The response variable.</p>
</dd>
<dt><code>effects</code></dt><dd><p>Object of class <code>"data.frame"</code>. The effects that went
into the <code>glm</code> call.</p>
</dd>
<dt><code>weights</code></dt><dd><p>Object of class <code>"integer"</code>. The weights of the
observations.</p>
</dd>
<dt><code>auto.adjust</code></dt><dd><p>Object of class <code>"logical"</code>. Indicates whether
automatic adjustment of dimensions was done before estimation.</p>
</dd>
<dt><code>offset</code></dt><dd><p>Object of class <code>"logical"</code>. Indicates whether an offset
matrix with structural zeros was used.</p>
</dd>
<dt><code>directed</code></dt><dd><p>Object of class <code>"logical"</code>. Are the dependent networks
directed?</p>
</dd>
<dt><code>bipartite</code></dt><dd><p>Object of class <code>"logical"</code>. Are the dependent networks
bipartite?</p>
</dd>
<dt><code>nvertices</code></dt><dd><p>Number of vertices.</p>
</dd>
<dt><code>data</code></dt><dd><p>The data after processing by the <code><a href="#topic+tergmprepare">tergmprepare</a></code>
function.</p>
</dd>
</dl>


<h3>See Also</h3>

<p>Other tergm-classes: 
<code><a href="#topic+createBtergm">createBtergm</a>()</code>,
<code><a href="#topic+createMtergm">createMtergm</a>()</code>,
<code><a href="#topic+createTbergm">createTbergm</a>()</code>,
<code><a href="#topic+mtergm-class">mtergm-class</a></code>,
<code><a href="#topic+tbergm-class">tbergm-class</a></code>
</p>

<hr>
<h2 id='btergm-package'>Temporal Exponential Random Graph Models by Bootstrapped Pseudolikelihood</h2><span id='topic+btergm-package'></span>

<h3>Description</h3>

<p>Temporal Exponential Random Graph Models by Bootstrapped Pseudolikelihood.
</p>


<h3>Details</h3>

<p>Temporal Exponential Random Graph Models (TERGM) estimated by maximum
pseudolikelihood with bootstrapped confidence intervals, Markov Chain Monte
Carlo maximum likelihood, or Bayesian estimation. Goodness of fit assessment
for ERGMs, TERGMs, and SAOMs. Micro-level interpretation of ERGMs and TERGMs.
</p>
<p>The <span class="pkg">btergm</span> package implements TERGMs with MPLE and bootstrapped
confidence intervals (<code><a href="#topic+btergm">btergm</a></code> function), MCMC MLE
(<code><a href="#topic+mtergm">mtergm</a></code> function), or Bayesian estimation (<code><a href="#topic+tbergm">tbergm</a></code>
function). Goodness of fit assessment for ERGMs, TERGMs, SAOMs, and dyadic
independence models is possible with the generic <code><a href="#topic+gof">gof</a></code> function
and its various methods defined here in the <span class="pkg">btergm</span> package. New
networks can be simulated from TERGMs using the <code><a href="#topic+simulate.btergm">simulate.btergm</a></code>
function. The package also implements micro-level interpretation for ERGMs
and TERGMs using the <code><a href="#topic+interpret">interpret</a></code> function. Furthermore, the
package contains the <code><a href="#topic+chemnet">chemnet</a></code> and <code><a href="#topic+knecht">knecht</a></code> (T)ERGM
datasets. To display citation information, type <code>citation("btergm")</code>.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld, Skyler J. Cranmer, Bruce A. Desmarais
</p>


<h3>References</h3>

<p>Cranmer, Skyler J., Tobias Heinrich and Bruce A. Desmarais (2014):
Reciprocity and the Structural Determinants of the International Sanctions
Network. <em>Social Networks</em> 36(1): 5-22.
<a href="https://doi.org/10.1016/j.socnet.2013.01.001">doi:10.1016/j.socnet.2013.01.001</a>.
</p>
<p>Desmarais, Bruce A. and Skyler J. Cranmer (2012): Statistical Mechanics of
Networks: Estimation and Uncertainty. <em>Physica A</em> 391: 1865&ndash;1876.
<a href="https://doi.org/10.1016/j.physa.2011.10.018">doi:10.1016/j.physa.2011.10.018</a>.
</p>
<p>Desmarais, Bruce A. and Skyler J. Cranmer (2010): Consistent Confidence
Intervals for Maximum Pseudolikelihood Estimators. <em>Neural Information
Processing Systems 2010 Workshop on Computational Social Science and the
Wisdom of Crowds</em>.
</p>
<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/leifeld/btergm">https://github.com/leifeld/btergm</a>
</p>
</li></ul>


<hr>
<h2 id='checkdegeneracy'>Check for degeneracy in fitted TERGMs</h2><span id='topic+checkdegeneracy'></span><span id='topic+checkdegeneracy-methods'></span><span id='topic+checkdegeneracy+2Cmtergm-method'></span><span id='topic+checkdegeneracy+2Cbtergm-method'></span><span id='topic+print.degeneracy'></span><span id='topic+plot.degeneracy'></span>

<h3>Description</h3>

<p>Check for degeneracy in fitted TERGMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkdegeneracy(object, ...)

## S4 method for signature 'mtergm'
checkdegeneracy(object, ...)

## S4 method for signature 'btergm'
checkdegeneracy(
  object,
  nsim = 1000,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  verbose = FALSE
)

## S3 method for class 'degeneracy'
print(
  x,
  center = FALSE,
  t = 1:length(x$sim),
  terms = 1:length(x$target.stats[[1]]),
  ...
)

## S3 method for class 'degeneracy'
plot(
  x,
  center = TRUE,
  t = 1:length(x$sim),
  terms = 1:length(x$target.stats[[1]]),
  vbar = TRUE,
  main = NULL,
  xlab = NULL,
  target.col = "red",
  target.lwd = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkdegeneracy_+3A_object">object</code></td>
<td>
<p>A <code>btergm</code> or <code>mtergm</code> object, as estimated using the
<code>btergm</code> or <code>mtergm</code> function.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_...">...</code></td>
<td>
<p>Arbitrary further arguments for subroutines.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_nsim">nsim</code></td>
<td>
<p>The number of networks to be simulated at each time step. This
number should be sufficiently large for a meaningful comparison. If
possible, much more than 1,000 simulations.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_mcmc.interval">MCMC.interval</code></td>
<td>
<p>Internally, this package uses the simulation facilities
of the <span class="pkg">ergm</span> package to create new networks against which to compare
the original network(s) for goodness-of-fit assessment. This argument sets
the MCMC interval to be passed over to the simulation command. The default
value is <code>1000</code>, which means that every 1000th simulation outcome from
the MCMC sequence is used. There is no general rule of thumb on the
selection of this parameter, but if the results look suspicious (e.g., when
the model fit is perfect), increasing this value may be helpful.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_mcmc.burnin">MCMC.burnin</code></td>
<td>
<p>Internally, this package uses the simulation facilities of
the <span class="pkg">ergm</span> package to create new networks against which to compare the
original network(s) for goodness-of-fit assessment. This argument sets the
MCMC burnin to be passed over to the simulation command. The default value
is <code>10000</code>. There is no general rule of thumb on the selection of this
parameter, but if the results look suspicious (e.g., when the model fit is
perfect), increasing this value may be helpful.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_verbose">verbose</code></td>
<td>
<p>Print details?</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_x">x</code></td>
<td>
<p>A <code>degeneracy</code> object created by the <code>checkdegeneracy</code>
function.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_center">center</code></td>
<td>
<p>If <code>TRUE</code>, print/plot the simulated minus the target
statistics, with an expected value of 0 in a non-degenerate model. If
<code>FALSE</code>, print/plot the distribution of simulated statistics and show
the target statistic separately.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_t">t</code></td>
<td>
<p>Time indices to include, e.g., <code>t = 2:4</code> for time steps 2 to 4.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_terms">terms</code></td>
<td>
<p>Indices of the model terms to include, e.g., <code>terms = 1:3</code>
includes the first three statistics.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_vbar">vbar</code></td>
<td>
<p>Show vertical bar for target statistic in histogram.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_main">main</code></td>
<td>
<p>Main title of the plot.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_xlab">xlab</code></td>
<td>
<p>Label on the x-axis. Defaults to the name of the statistic.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_target.col">target.col</code></td>
<td>
<p>Color of the vertical bar for the target statistic.
Defaults to red.</p>
</td></tr>
<tr><td><code id="checkdegeneracy_+3A_target.lwd">target.lwd</code></td>
<td>
<p>Line width of the vertical bar for the target statistic.
Defaults to 3.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods for the generic <code>degeneracy</code> function implement a degeneracy
check for <code>btergm</code> and <code>mtergm</code> objects. For <code>btergm</code>, this
works by comparing the global statistics of simulated networks to those of
the observed networks at each observed time step. If the global statistics
differ significantly, this is indicated by small p-values. If there are many
significant results, this indicates degeneracy. For <code>mtergm</code>, the
<code>mcmc.diagnostics</code> function from the <span class="pkg">ergm</span> package is used.
</p>


<h3>Value</h3>

<p>A list with target statistics and simulations.
</p>


<h3>References</h3>

<p>Hanneke, Steve, Wenjie Fu and Eric P. Xing (2010): Discrete Temporal Models
of Social Networks. <em>Electronic Journal of Statistics</em> 4: 585&ndash;605.
<a href="https://doi.org/10.1214/09-EJS548">doi:10.1214/09-EJS548</a>.
</p>
<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1-36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>

<hr>
<h2 id='chemnet'>German Toxic Chemicals Policy Network in the 1980s (Volker Schneider)</h2><span id='topic+chemnet'></span><span id='topic+pol'></span><span id='topic+scito'></span><span id='topic+scifrom'></span><span id='topic+infrep'></span><span id='topic+committee'></span><span id='topic+types'></span><span id='topic+intpos'></span>

<h3>Description</h3>

<p>German Toxic Chemicals Policy Network in the 1980s (Volker Schneider).
</p>


<h3>Format</h3>


<dl>
<dt><code>pol</code></dt><dd><p>is a directed 30 x 30 adjancency matrix indicating which
row actor sends political/strategic information to which column actor.
<code>1</code> indicates an information exchange tie, and <code>0</code> indicates the
absence of a network tie.</p>
</dd>
<dt><code>scito</code></dt><dd><p>is a directed 30 x 30 adjacency matrix indicating which
row actor sends technical/scientific information to which column actor.
<code>1</code> indicates an information exchange tie, and <code>0</code> indicates the
absence of a network tie. In contrast to political/strategic information
exchange, two separate survey questions were asked about
technical/scientific information exchange: sending information, and
receiving information. The two matrices contain the same relation but one
time from the sender's perspective and one time from the receiver's
perspective. By combining the two matrices, one can create a &quot;confirmed&quot;
technical/scientific information exchange relation. The <code>scito</code> matrix
contains ties from the sender's perspective.</p>
</dd>
<dt><code>scifrom</code></dt><dd><p>is a directed 30 x 30 adjacency matrix indicating
which row actor receives technical/scientific information from which column
actor. <code>1</code> indicates an information exchange tie, and <code>0</code>
indicates the absence of a network tie. In contrast to political/strategic
information exchange, two separate survey questions were asked about
technical/scientific information exchange: sending information, and
receiving information. The two matrices contain the same relation but one
time from the sender's perspective and one time from the receiver's
perspective. By combining the two matrices, one can create a &quot;confirmed&quot;
technical/scientific information exchange relation. The <code>scifrom</code>
matrix contains ties from the receiver's perspective.</p>
</dd>
<dt><code>infrep</code></dt><dd><p>is a directed 30 x 30 adjancency matrix indicating
which row actor deems which column actor &quot;particularly influential&quot;.
<code>1</code> indicates such a tie, and <code>0</code> indicates the absence of an
influence attribution tie.</p>
</dd>
<dt><code>committee</code></dt><dd><p>is a 30 x 20 two-mode (bipartite) network matrix
indicating which row actor is a member of which policy committee/forum (as
indicated by the column labels). <code>1</code> indicates a membership tie, and
<code>0</code> indicates non-membership.</p>
</dd>
<dt><code>types</code></dt><dd><p>is a one-column data.frame where the <code>type</code>
variable contains the actor type of each node. The following values are
possible:</p>
</dd>
</dl>

<ul>
<li> <p><code>gov</code> (government actor, e.g., a federal ministry)
</p>
</li>
<li> <p><code>ig</code> (interest group)
</p>
</li>
<li> <p><code>io</code> (international organization)
</p>
</li>
<li> <p><code>par</code> (political party)
</p>
</li>
<li> <p><code>sci</code> (scientific organization)
</p>
</li></ul>

<dl>
<dt><code>intpos</code></dt><dd><p>is a 30 x 6 matrix containing the interest positions of
the 30 political actors on the six most salient political issues related to a
pending new chemicals law. <code>-1</code> indicates a negative stance, i.e., the
actor rejects the proposal; <code>1</code> indicates a positive stance, i.e., the
actor supports the proposal; and <code>0</code> indicates a neutral or absent
opinion.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The chemnet dataset contains network and attribute data and for the 30 most
influential political actors with regard to toxic chemicals regulation in
Germany in 1983/1984. While the original dataset contains up to 47 actors,
this dataset contains the &quot;complete influence core&quot; of mutually relevant
actors. The data are cross-sectional. There are no missing data; the
response rate was 100 percent. Volker Schneider (University of Konstanz)
collected this dataset for his dissertation (Schneider 1988). The dataset
was later re-used for a journal publication on information exchange in
policy networks (Leifeld and Schneider 2012).
</p>
<p>The chemnet dataset contains network relations on political/strategic and
technical/scientific information exchange, influence attribution, and
membership in policy committees/forums, as well as nodal attributes on the
actor type and opinions about the six most salient issues related to the
political process that was leading to a new chemicals law at the time being.
</p>


<h3>Source</h3>

<p>The data were collected using paper-based questionnaires. The
questionnaires were administered in personal interviews (PAPI).  Further
information, including the actual survey, data on additional actors, the
full names of the policy committees/forums, and the full list of
unabbreviated actor names can be found online at
<a href="http://hdl.handle.net/1902.1/17004">http://hdl.handle.net/1902.1/17004</a> in the replication archive of
Leifeld and Schneider (2012).
</p>

<ul>
<li><p> Replication archive: <a href="http://hdl.handle.net/1902.1/17004">http://hdl.handle.net/1902.1/17004</a>
</p>
</li>
<li><p> AJPS publication: <a href="https://doi.org/10.1111/j.1540-5907.2011.00580.x">doi:10.1111/j.1540-5907.2011.00580.x</a>
</p>
</li></ul>

<p>The dataset is publicly available. Questions about the data or the original
study should be directed to Volker Schneider
&lt;volker.schneider@uni-konstanz.de&gt;, the author of the original study and
person who collected the data.
</p>


<h3>References</h3>

<p>Leifeld, Philip and Volker Schneider (2012): Information Exchange in Policy
Networks. <em>American Journal of Political Science</em> 53(3): 731&ndash;744.
<a href="https://doi.org/10.1111/j.1540-5907.2011.00580.x">doi:10.1111/j.1540-5907.2011.00580.x</a>.
</p>
<p>Schneider, Volker (1988): <em>Politiknetzwerke der Chemikalienkontrolle.
Eine Analyse einer transnationalen Politikentwicklung</em>. Walter de Gruyter:
Berlin/New York.
</p>
<p>Schneider, Volker and Philip Leifeld (2009): Ueberzeugungssysteme,
Diskursnetzwerke und politische Kommunikation: Ein zweiter Blick auf die
deutsche Chemikalienkontrolle der 1980er Jahre. In: Volker Schneider, Frank
Janning, Philip Leifeld and Thomas Malang (editors): <em>Politiknetzwerke.
Modelle, Anwendungen und Visualisierungen</em>. Pages 139&ndash;158. Wiesbaden: VS
Verlag fuer Sozialwissenschaften.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Replication code for Leifeld and Schneider (2012), AJPS.
# Note that the estimates can only be reproduced approximately
# due to internal changes in the statnet package.

# preparatory steps
library("network")
library("sna")
library("ergm")
library("btergm")
library("texreg")
seed &lt;- 12345
set.seed(seed)
data("chemnet")

# create confirmed network relation
sci &lt;- scito * t(scifrom)  # equation 1 in the AJPS paper
prefsim &lt;- dist(intpos, method = "euclidean")  # equation 2
prefsim &lt;- max(prefsim) - prefsim  # equation 3
prefsim &lt;- as.matrix(prefsim)
committee &lt;- committee %*% t(committee)  # equation 4
diag(committee) &lt;- 0 # the diagonal has no meaning
types &lt;- types[, 1]  # convert to vector

# create network objects and store attributes
nw.pol &lt;- network(pol) # political/stratgic information exchange
set.vertex.attribute(nw.pol, "orgtype", types)
set.vertex.attribute(nw.pol, "betweenness",
    betweenness(nw.pol)) # centrality

nw.sci &lt;- network(sci) # technical/scientific information exchange
set.vertex.attribute(nw.sci, "orgtype", types)
set.vertex.attribute(nw.sci, "betweenness",
    betweenness(nw.sci)) # centrality

# ERGM: model 1 in the AJPS paper; only preference similarity
model1 &lt;- ergm(nw.pol ~ edges + edgecov(prefsim),
    control = control.ergm(seed = seed))
summary(model1)

# ERGM: model 2 in the AJPS paper; complete model
model2 &lt;- ergm(nw.pol ~
    edges +
    edgecov(prefsim) +
    mutual +
    nodemix("orgtype", base = -7) +
    nodeifactor("orgtype", base = -1) +
    nodeofactor("orgtype", base = -5) +
    edgecov(committee) +
    edgecov(nw.sci) +
    edgecov(infrep) +
    gwesp(0.1, fixed = TRUE) +
    gwdsp(0.1, fixed = TRUE),
    control = control.ergm(seed = seed)
)
summary(model2)

# ERGM: model 3 in the AJPS paper; only preference similarity
model3 &lt;- ergm(nw.sci ~ edges + edgecov(prefsim),
    control = control.ergm(seed = seed))
summary(model3)

# ERGM: model 4 in the AJPS paper; complete model
model4 &lt;- ergm(nw.sci ~
    edges +
    edgecov(prefsim) +
    mutual +
    nodemix("orgtype", base = -7) +
    nodeifactor("orgtype", base = -1) +
    nodeofactor("orgtype", base = -5) +
    edgecov(committee) +
    edgecov(nw.pol) +
    edgecov(infrep) +
    gwesp(0.1, fixed = TRUE) +
    gwdsp(0.1, fixed = TRUE),
    control = control.ergm(seed = seed)
)
summary(model4)

# regression table using the texreg package
screenreg(list(model1, model2, model3, model4))

# goodness of fit using the btergm package
gof2 &lt;- gof(model2, roc = FALSE, pr = FALSE)
gof2  # print gof output
plot(gof2)  # visual inspection of GOF

gof4 &lt;- gof(model4, roc = FALSE, pr = FALSE)
gof4
plot(gof4)

# MCMC diagnostics
pdf("diagnostics2.pdf")
mcmc.diagnostics(model2)
dev.off()

pdf("diagnostics4.pdf")
mcmc.diagnostics(model4)
dev.off()

## End(Not run)
</code></pre>

<hr>
<h2 id='coauthor'>Swiss political science co-authorship network 2013</h2><span id='topic+coauthor'></span><span id='topic+ch_coauthor'></span><span id='topic+ch_coaut'></span><span id='topic+ch_dist100km'></span><span id='topic+ch_en_article_sim'></span><span id='topic+ch_nodeattr'></span><span id='topic+ch_topicsim'></span>

<h3>Description</h3>

<p>Swiss political science co-authorship network 2013
</p>


<h3>Format</h3>


<dl>
<dt><code>ch_coaut</code></dt><dd><p>is an undirected, weighted 156 x 156 adjancency matrix
indicating how many publications political scientist in Switzerland shared
with each other as reported in late 2013, including only postdoctoral and
professorial political scientists affiliated with research institutes or
universities. The exact edge weight should be treated with caution because
some publications were counted multiple times because they were reported by
multiple co-authors. The diagonal contains the number of publications of
the respective author. Leifeld and Ingold (2016) describe the data collection
process in more detail.</p>
</dd>
<dt><code>ch_nodeattr</code></dt><dd><p>is a data frame with node attributes/variables for
the 156 researchers, in the same alphabetical row order as the network
matrix. The first twelve columns with column labels starting with &quot;inst_&quot; are
affiliations with different institutions (1 = affiliated; 0 = no
affiliation). The next seven columns with column labels starting with &quot;city_&quot;
contain the locations of the researchers' institutional affiliations. The
&quot;phdyear&quot; column contains the self-reported year of obtaining the PhD, and
the &quot;birthyear&quot; column contains the self-reported or publicly available year
of birth; these two variables contain many missing values. The &quot;status&quot;
column indicates whether a researcher was listed as a professor or as having
postdoctoral or other non-professorial status at the time. &quot;chairtitle&quot; is
the name of the chair or research group the researcher reported to be a
member of. &quot;num_publications&quot; is the total number of publications,
&quot;num_articles&quot; the number of journal articles among them, &quot;num_books&quot; the
number of books among them, &quot;share_articles&quot; the percentage of journal
articles among the publications, and &quot;share_books&quot; the percentage of
monographs and edited volumes among the publications. The four columns with
column names starting with &quot;lang_&quot; contain the relative shares of English,
French, German, Italian, and other languages among the publications of the
researcher. The column &quot;share_en_articles&quot; contains the percentage of English
journal articles among all publications of the researcher. &quot;male&quot; is a dummy
variable indicating whether the author is male (1) or female (0). The
variables contained here are described in Leifeld (2018).</p>
</dd>
<dt><code>ch_dist100km</code></dt><dd><p>is a 156 x 156 matrix containing the geographical
distance between any two researchers measured in units of 100km (for a
reasonable scaling of coefficients in a statistical model), computed over the
latitude and longitude of their main institutional affiliations. The measure
is included in Leifeld (2018).</p>
</dd>
<dt><code>ch_en_article_sim</code></dt><dd><p>is a 156 x 156 matrix containing the
similarity between any two researchers in terms of the share of their work
that is published in English and as journal articles. Values closer to 1.0
indicate that two researchers were similar in their language and publication
type portfolio while values closer to 0 indicate that they were relatively
dissimilar. Only extra-dyadic publications were counted in establishing this
similarity. I.e., if researcher A and B co-authored, their joint publications
were not included in establishing their English article share similarity.
This was done to reduce endogeneity/reverse causality when modeling
co-authorship as a function of English article share similarity. The measure
is described in Leifeld (2018).</p>
</dd>
<dt><code>ch_topicsim</code></dt><dd><p>is a 156 x 156 topic similarity matrix for the
researchers. Topic similarities were computed by taking into account all
words in the publication titles of any two researchers, excluding the
publications they published as co-authors (i.e., only extra-dyadic
publications, to reduce endogeneity/reverse causality in modeling
co-authorship ties as a function of topic similarity). Topic similarity was
established by computing the cosine similarity between the tf-idf scores for
the title words of any two researchers (i.e., a vector space model). Leifeld
(2018) contains more details on this procedure.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The Swiss political science co-authorship network 2013 dataset contains the
co-authorship network of all political scientists at Swiss universities and
research institutes in late 2013. The data are described in Leifeld and
Ingold (2016) and Leifeld (2018). The data contained here include
postdoctoral and professorial researchers but not PhD students, as in Leifeld
(2018), without the PhD researchers included in Leifeld and Ingold (2016).
For the full dataset, see the replication archive at DOI
<a href="https://doi.org/10.7910/DVN/85SK1M">doi:10.7910/DVN/85SK1M</a>.
</p>
<p>Leifeld and Ingold (2016) summarize the data collection strategy as follows:
<em>&quot;Data gathering took place between July and December 2013. A single
coder pursued a three-step coding procedure: he first created a list of all
relevant university departments and research institutes that host political
scientists in Switzerland, then he browsed the websites of these institutes
and entered all researchers along with several details about them into a
database, including their seniority status (predoctoral, postdoctoral, or
professor) and the URL of their publication list (either the CV, the
institutional website, a private homepage, or several of those items in order
to get a complete publication profile of each person). After entering all
researchers of an institute, the coder went through the researchers'
publication lists and entered the following pieces of information for each
publication into the database: the reporting author, the names of all
co-authors, the title of the publication, the year, the name of the journal
or book in which the publication appeared (if applicable), the names of all
editors (if applicable), and a classification of the type of publication
(academic journal, book chapter, monograph, edited volume, other). Most
publications are relatively recent, but the earliest publications in the
database date back to the 1960s. After completing these three steps, data
entered at the beginning was double-checked in order to avoid bias due to new
publications that may have shown up during the coding time period. This
procedure is the best one can do in terms of completeness, but it should be
clear that it crucially depends on the accuracy of the self-reported
bibliographic information. For example, if a researcher did not update his or
her CV or list of publications for the previous six months, those most recent
publications only had a chance to enter the database if the co-authors listed
the publication on their website. In some relatively rare cases, all authors
failed to report recent updates, and this may cause minor inaccuracies in the
network dataset, mostly affecting very recent publications in 2013 because
there is, on average, a reporting lag.&quot;</em>
</p>
<p>Based on the collected publication data, a co-authorship network matrix with
156 nodes was created. In addition to this matrix, the dataset here contains
node attribute data (institutional affiliations, location, demographics,
language shares, publication type shares) and relational covariates
(geographical distance, similarity in terms of the share of English articles,
and topic similarity) as described in Leifeld (2018). The dataset can be used
to replicate Leifeld (2018), but only approximately due to changes in the
estimation routine in the <span class="pkg">ergm</span> package since the article was published.
</p>


<h3>Source</h3>

<p>The data were collected from public information online. The full
data collection details are described in Leifeld and Ingold (2016).
</p>


<h3>References</h3>

<p>Leifeld, Philip (2018): Polarization in the Social Sciences: Assortative
Mixing in Social Science Collaboration Networks is Resilient to
Interventions. <em>Physica A: Statistical Mechanics and its Applications</em>
507: 510&ndash;523. <a href="https://doi.org/10.1016/j.physa.2018.05.109">doi:10.1016/j.physa.2018.05.109</a>. Full replication data:
<a href="https://doi.org/10.7910/DVN/85SK1M">doi:10.7910/DVN/85SK1M</a>.
</p>
<p>Leifeld, Philip and Karin Ingold (2016): Co-authorship Networks in Swiss
Political Research. <em>Swiss Political Science Review</em> 22(2): 264&ndash;287.
<a href="https://doi.org/10.1111/spsr.12193">doi:10.1111/spsr.12193</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Replication code for the full Swiss co-authorship ERGM in Leifeld (2018).
# Note that the estimates can only be reproduced approximately due to
# internal changes in the ergm package.

library("network")
library("ergm")

data("ch_coauthor")

# set up network object with node attributes
ch_nw &lt;- network(ch_coaut, directed = FALSE)
set.vertex.attribute(ch_nw, "frequency", ch_nodeattr$num_publications)
set.vertex.attribute(ch_nw, "status", as.character(ch_nodeattr$status))
set.vertex.attribute(ch_nw, "male", ch_nodeattr$male)
set.vertex.attribute(ch_nw, "share_en_articles",
                     ch_nodeattr$share_en_articles)

# create same affiliation matrix
ch_inst_indices &lt;- which(grepl("^inst_.+", colnames(ch_nodeattr)))
ch_same_affiliation &lt;- as.matrix(ch_nodeattr[, ch_inst_indices]) %*%
  t(ch_nodeattr[, ch_inst_indices])

# create same chair matrix
ch_nodeattr$chairtitle[ch_nodeattr$chairtitle == ""] &lt;- NA
ch_same_chair &lt;- matrix(0, nrow = nrow(ch_same_affiliation),
                        ncol = ncol(ch_same_affiliation))
for (i in 1:length(ch_nodeattr$chairtitle)) {
  for (j in 1:length(ch_nodeattr$chairtitle)) {
    if (i != j &amp;&amp;
        !is.na(ch_nodeattr$chairtitle[i]) &amp;&amp;
        !is.na(ch_nodeattr$chairtitle[j]) &amp;&amp;
        ch_nodeattr$chairtitle[i] == ch_nodeattr$chairtitle[j] &amp;&amp;
        ch_same_affiliation[i, j] == TRUE) {
      ch_same_chair[i, j] &lt;- 1
    }
  }
}
rownames(ch_same_chair) &lt;- rownames(ch_same_affiliation)
colnames(ch_same_chair) &lt;- colnames(ch_same_affiliation)

# create supervision matrix (same chair + affiliation + mixed seniority)
ch_supervision &lt;- ch_same_affiliation *
  ch_same_chair *
  matrix(ch_nodeattr$status == "professor",
         nrow = nrow(ch_same_chair),
         ncol = ncol(ch_same_chair),
         byrow = FALSE) *
  matrix(ch_nodeattr$status != "professor",
         nrow = nrow(ch_same_chair),
         ncol = ncol(ch_same_chair),
         byrow = TRUE)

# ERGM estimation
ch_model &lt;- ergm(ch_nw ~
                   edges +
                   gwesp(0.3, fixed = TRUE) +
                   gwdegree(0.4, fixed = TRUE) +
                   nodecov("frequency") +
                   nodefactor("status") +
                   nodefactor("male") +
                   nodematch("male") +
                   edgecov(ch_dist100km) +
                   edgecov(ch_same_affiliation) +
                   edgecov(ch_same_chair) +
                   edgecov(ch_supervision) +
                   edgecov(ch_topicsim) +
                   nodecov("share_en_articles") +
                   edgecov(ch_en_article_sim),
                 control = control.ergm(MCMLE.termination = "Hummel",
                                        MCMLE.effectiveSize = NULL))
summary(ch_model)  # corresponds Column 1 in Table 3 in Leifeld (2018)

## End(Not run)
</code></pre>

<hr>
<h2 id='createBtergm'>Constructor for <a href="#topic+btergm-class">btergm</a> objects</h2><span id='topic+createBtergm'></span>

<h3>Description</h3>

<p>Constructor for <a href="#topic+btergm-class">btergm</a> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBtergm(
  coef,
  boot,
  R,
  nobs,
  time.steps,
  formula,
  formula2,
  response,
  effects,
  weights,
  auto.adjust,
  offset,
  directed,
  bipartite,
  nvertices,
  data
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createBtergm_+3A_coef">coef</code></td>
<td>
<p>Object of class <code>"numeric"</code>. The coefficients.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_boot">boot</code></td>
<td>
<p>Object of class <code>"matrix"</code>. The bootstrapping sample.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_r">R</code></td>
<td>
<p>Object of class <code>"numeric"</code>. Number of replications.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_nobs">nobs</code></td>
<td>
<p>Object of class <code>"numeric"</code>. Number of observations.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_time.steps">time.steps</code></td>
<td>
<p>Object of class <code>"numeric"</code>. Number of time steps.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>"formula"</code>. The original model formula
(without indices for the time steps).</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_formula2">formula2</code></td>
<td>
<p>The revised formula with the object references after applying
the <code><a href="#topic+tergmprepare">tergmprepare</a></code> function.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_response">response</code></td>
<td>
<p>Object of class <code>"integer"</code>. The response variable.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_effects">effects</code></td>
<td>
<p>Object of class <code>"data.frame"</code>. The effects that went
into the <code>glm</code> call.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_weights">weights</code></td>
<td>
<p>Object of class <code>"integer"</code>. The weights of the
observations.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_auto.adjust">auto.adjust</code></td>
<td>
<p>Object of class <code>"logical"</code>. Indicates whether
automatic adjustment of dimensions was done before estimation.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_offset">offset</code></td>
<td>
<p>Object of class <code>"logical"</code>. Indicates whether an offset
matrix with structural zeros was used.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_directed">directed</code></td>
<td>
<p>Object of class <code>"logical"</code>. Are the dependent networks
directed?</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_bipartite">bipartite</code></td>
<td>
<p>Object of class <code>"logical"</code>. Are the dependent networks
bipartite?</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_nvertices">nvertices</code></td>
<td>
<p>Number of vertices.</p>
</td></tr>
<tr><td><code id="createBtergm_+3A_data">data</code></td>
<td>
<p>The data after processing by the <code><a href="#topic+tergmprepare">tergmprepare</a></code>
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create an S4 <a href="#topic+btergm-class">btergm</a> object using this constructor function.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld
</p>


<h3>See Also</h3>

<p>Other tergm-classes: 
<code><a href="#topic+btergm-class">btergm-class</a></code>,
<code><a href="#topic+createMtergm">createMtergm</a>()</code>,
<code><a href="#topic+createTbergm">createTbergm</a>()</code>,
<code><a href="#topic+mtergm-class">mtergm-class</a></code>,
<code><a href="#topic+tbergm-class">tbergm-class</a></code>
</p>

<hr>
<h2 id='createMtergm'>Constructor for <a href="#topic+mtergm-class">mtergm</a> objects</h2><span id='topic+createMtergm'></span>

<h3>Description</h3>

<p>Constructor for <a href="#topic+mtergm-class">mtergm</a> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createMtergm(
  coef,
  se,
  pval,
  nobs,
  time.steps,
  formula,
  formula2,
  auto.adjust,
  offset,
  directed,
  bipartite,
  estimate,
  loglik,
  aic,
  bic,
  ergm,
  nvertices,
  data
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createMtergm_+3A_coef">coef</code></td>
<td>
<p>Object of class <code>"numeric"</code>. The coefficients.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_se">se</code></td>
<td>
<p>Standard errors.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_pval">pval</code></td>
<td>
<p>The p-values.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_nobs">nobs</code></td>
<td>
<p>Object of class <code>"numeric"</code>. Number of observations.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_time.steps">time.steps</code></td>
<td>
<p>Object of class <code>"numeric"</code>. Number of time steps.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>"formula"</code>. The original model formula
(without indices for the time steps).</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_formula2">formula2</code></td>
<td>
<p>The revised formula with the object references after applying
the <code><a href="#topic+tergmprepare">tergmprepare</a></code> function.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_auto.adjust">auto.adjust</code></td>
<td>
<p>Object of class <code>"logical"</code>. Indicates whether
automatic adjustment of dimensions was done before estimation.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_offset">offset</code></td>
<td>
<p>Object of class <code>"logical"</code>. Indicates whether an offset
matrix with structural zeros was used.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_directed">directed</code></td>
<td>
<p>Object of class <code>"logical"</code>. Are the dependent networks
directed?</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_bipartite">bipartite</code></td>
<td>
<p>Object of class <code>"logical"</code>. Are the dependent networks
bipartite?</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_estimate">estimate</code></td>
<td>
<p>Estimate: either MCMC MLE or MPLE.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_loglik">loglik</code></td>
<td>
<p>Log likelihood of the MLE.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_aic">aic</code></td>
<td>
<p>Akaike's Information Criterion.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_bic">bic</code></td>
<td>
<p>Bayesian Information Criterion.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_ergm">ergm</code></td>
<td>
<p>The original <code>ergm</code> object as estimated by the
<code><a href="ergm.html#topic+ergm">ergm</a></code> function in the <span class="pkg">ergm</span> package.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_nvertices">nvertices</code></td>
<td>
<p>Number of vertices.</p>
</td></tr>
<tr><td><code id="createMtergm_+3A_data">data</code></td>
<td>
<p>The data after processing by the <code><a href="#topic+tergmprepare">tergmprepare</a></code>
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create an S4 <a href="#topic+mtergm-class">mtergm</a> object using this constructor function.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld
</p>


<h3>See Also</h3>

<p>Other tergm-classes: 
<code><a href="#topic+btergm-class">btergm-class</a></code>,
<code><a href="#topic+createBtergm">createBtergm</a>()</code>,
<code><a href="#topic+createTbergm">createTbergm</a>()</code>,
<code><a href="#topic+mtergm-class">mtergm-class</a></code>,
<code><a href="#topic+tbergm-class">tbergm-class</a></code>
</p>

<hr>
<h2 id='createTbergm'>Constructor for <a href="#topic+tbergm-class">tbergm</a> objects</h2><span id='topic+createTbergm'></span>

<h3>Description</h3>

<p>Constructor for <a href="#topic+tbergm-class">tbergm</a> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createTbergm(
  time.steps,
  formula,
  formula2,
  auto.adjust,
  offset,
  directed,
  bipartite,
  estimate,
  bergm,
  nvertices,
  data
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createTbergm_+3A_time.steps">time.steps</code></td>
<td>
<p>Object of class <code>"numeric"</code>. Number of time steps.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>"formula"</code>. The original model formula
(without indices for the time steps).</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_formula2">formula2</code></td>
<td>
<p>The revised formula with the object references after applying
the <code><a href="#topic+tergmprepare">tergmprepare</a></code> function.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_auto.adjust">auto.adjust</code></td>
<td>
<p>Object of class <code>"logical"</code>. Indicates whether
automatic adjustment of dimensions was done before estimation.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_offset">offset</code></td>
<td>
<p>Object of class <code>"logical"</code>. Indicates whether an offset
matrix with structural zeros was used.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_directed">directed</code></td>
<td>
<p>Object of class <code>"logical"</code>. Are the dependent networks
directed?</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_bipartite">bipartite</code></td>
<td>
<p>Object of class <code>"logical"</code>. Are the dependent networks
bipartite?</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_estimate">estimate</code></td>
<td>
<p>Estimate: <code>"bergm"</code> for Bayesian estimation.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_bergm">bergm</code></td>
<td>
<p>The original <code>bergm</code> object as estimated by the
<code><a href="Bergm.html#topic+bergm">bergm</a></code> function in the <span class="pkg">Bergm</span> package.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_nvertices">nvertices</code></td>
<td>
<p>Number of vertices.</p>
</td></tr>
<tr><td><code id="createTbergm_+3A_data">data</code></td>
<td>
<p>The data after processing by the <code><a href="#topic+tergmprepare">tergmprepare</a></code>
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Create an S4 <a href="#topic+tbergm-class">tbergm</a> object using this constructor function.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld
</p>


<h3>See Also</h3>

<p>Other tergm-classes: 
<code><a href="#topic+btergm-class">btergm-class</a></code>,
<code><a href="#topic+createBtergm">createBtergm</a>()</code>,
<code><a href="#topic+createMtergm">createMtergm</a>()</code>,
<code><a href="#topic+mtergm-class">mtergm-class</a></code>,
<code><a href="#topic+tbergm-class">tbergm-class</a></code>
</p>

<hr>
<h2 id='edgeprob'>Create all predicted tie probabilities using MPLE</h2><span id='topic+edgeprob'></span>

<h3>Description</h3>

<p>Create all predicted tie probabilities using MPLE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edgeprob(object, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="edgeprob_+3A_object">object</code></td>
<td>
<p>An <code>ergm</code>, <code>btergm</code>, or <code>mtergm</code> object.</p>
</td></tr>
<tr><td><code id="edgeprob_+3A_verbose">verbose</code></td>
<td>
<p>Print details?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a given (T)ERGM, return a data frame with all predicted edge
probabilities along with the design matrix of the MPLE logit model, based
on the estimated coefficients and the design matrix, for all time points,
along with <code>i</code>, <code>j</code>, and <code>t</code> variables indicating where the
respective dyad is located.
</p>
<p><code>edgeprob</code> is a convenience function that creates a data frame with all
dyads in the ERGM or TERGM along with their edge probabilities and their
predictor values (i.e., change statistics). This is useful for creating
marginal effects plots or contrasting multiple groups of dyads. This function
works faster than the <code><a href="#topic+interpret">interpret</a></code> function.
</p>


<h3>Value</h3>

<p>The first variable in the resulting data frame contains the edge
value (i.e., the dependent variable, which is usually binary). The next
variables contain all the predictors from the ERGM or TERGM (i.e., the change
statistics). The next five variables contain the indices of the sender (i),
the receiver (j), the time step (t), the vertex id of i (i.name), and the
vertex id of j (j.name). These five variables serve to identify the dyad. The
last variable contains the computed edge probabilities.
</p>


<h3>See Also</h3>

<p>Other interpretation: 
<code><a href="#topic+interpret">interpret</a>()</code>,
<code><a href="#topic+marginalplot">marginalplot</a>()</code>
</p>

<hr>
<h2 id='getformula'>Extract the formula from a model</h2><span id='topic+getformula'></span><span id='topic+getformula-methods'></span><span id='topic+getformula+2Cergm-method'></span><span id='topic+getformula+2Cbtergm-method'></span><span id='topic+getformula+2Cmtergm-method'></span><span id='topic+getformula+2Ctbergm-method'></span>

<h3>Description</h3>

<p>Extract the model formula from a fitted object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getformula(x)

## S4 method for signature 'ergm'
getformula(x)

## S4 method for signature 'btergm'
getformula(x)

## S4 method for signature 'mtergm'
getformula(x)

## S4 method for signature 'tbergm'
getformula(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getformula_+3A_x">x</code></td>
<td>
<p>A fitted model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>getformula</code> function will extract the formula from a fitted model.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>getformula(ergm)</code>: Extract the formula from an <code>ergm</code> object.
</p>
</li>
<li> <p><code>getformula(btergm)</code>: Extract the formula from a <code>btergm</code> object.
</p>
</li>
<li> <p><code>getformula(mtergm)</code>: Extract the formula from an <code>mtergm</code> object.
</p>
</li>
<li> <p><code>getformula(tbergm)</code>: Extract the formula from a <code>tbergm</code> object.
</p>
</li></ul>

<hr>
<h2 id='gof'>Goodness-of-fit diagnostics for ERGMs, TERGMs, SAOMs, and logit models</h2><span id='topic+gof'></span><span id='topic+gof-methods'></span><span id='topic+gofmethods'></span><span id='topic+createGOF'></span><span id='topic+gof+2Cbtergm-method'></span><span id='topic+gof+2Cergm-method'></span><span id='topic+gof+2Cmtergm-method'></span><span id='topic+gof+2Ctbergm-method'></span><span id='topic+gof+2CsienaFit-method'></span><span id='topic+gof+2Cnetwork-method'></span><span id='topic+gof+2Cmatrix-method'></span>

<h3>Description</h3>

<p>Assess goodness of fit of <code>btergm</code> and other network models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gof(object, ...)

createGOF(
  simulations,
  target,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  parallel = "no",
  ncpus = 1,
  cl = NULL,
  verbose = TRUE,
  ...
)

## S4 method for signature 'btergm'
gof(
  object,
  target = NULL,
  formula = getformula(object),
  nsim = 100,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  verbose = TRUE,
  ...
)

## S4 method for signature 'ergm'
gof(
  object,
  target = NULL,
  formula = getformula(object),
  nsim = 100,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  verbose = TRUE,
  ...
)

## S4 method for signature 'mtergm'
gof(
  object,
  target = NULL,
  formula = getformula(object),
  nsim = 100,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  verbose = TRUE,
  ...
)

## S4 method for signature 'tbergm'
gof(
  object,
  target = NULL,
  formula = getformula(object),
  nsim = 100,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  verbose = TRUE,
  ...
)

## S4 method for signature 'sienaFit'
gof(
  object,
  period = NULL,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  structzero = 10,
  statistics = c(esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  groupName = object$f$groupNames[[1]],
  varName = NULL,
  outofsample = FALSE,
  sienaData = NULL,
  sienaEffects = NULL,
  nsim = NULL,
  verbose = TRUE,
  ...
)

## S4 method for signature 'network'
gof(
  object,
  covariates,
  coef,
  target = NULL,
  nsim = 100,
  mcmc = FALSE,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  verbose = TRUE,
  ...
)

## S4 method for signature 'matrix'
gof(
  object,
  covariates,
  coef,
  target = NULL,
  nsim = 100,
  mcmc = FALSE,
  MCMC.interval = 1000,
  MCMC.burnin = 10000,
  parallel = c("no", "multicore", "snow"),
  ncpus = 1,
  cl = NULL,
  statistics = c(dsp, esp, deg, ideg, geodesic, rocpr, walktrap.modularity),
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gof_+3A_object">object</code></td>
<td>
<p>A <code>btergm</code>, <code>ergm</code>, or <code>sienaFit</code> object (for
the <code>btergm</code>, <code>ergm</code>, and <code>sienaFit</code> methods, respectively).
Or a network object or matrix (for the <code>network</code> and <code>matrix</code>
methods, respectively).</p>
</td></tr>
<tr><td><code id="gof_+3A_...">...</code></td>
<td>
<p>Arbitrary further arguments to be passed on to the statistics. See
also the help page for the <a href="#topic+gof-statistics">gof-statistics</a>.</p>
</td></tr>
<tr><td><code id="gof_+3A_simulations">simulations</code></td>
<td>
<p>A list of <code>network</code> objects or sparse matrices
(generated using the <span class="pkg">Matrix</span> package) representing simulated networks.</p>
</td></tr>
<tr><td><code id="gof_+3A_target">target</code></td>
<td>
<p>In the <code>gof</code> function: A network or list of networks to
which the simulations are compared. If left empty, the original networks
from the <code>btergm</code> object <code>x</code> are used as observed networks. In
the <code>createGOF</code> function: a list of sparse matrices (generated using
the <span class="pkg">Matrix</span> package) or a list of <code>network</code> objects (generated
using the <span class="pkg">network</span> package). The simulations are compared against
these target networks.</p>
</td></tr>
<tr><td><code id="gof_+3A_statistics">statistics</code></td>
<td>
<p>A list of functions used for comparison of observed and
simulated networks. Note that the list should contain the actual functions,
not a character representation of them. See <a href="#topic+gof-statistics">gof-statistics</a> for
details.</p>
</td></tr>
<tr><td><code id="gof_+3A_parallel">parallel</code></td>
<td>
<p>Use multiple cores in a computer or nodes in a cluster to
speed up the simulations. The default value <code>"no"</code> means parallel
computing is switched off. If <code>"multicore"</code> is used (only available
for <code>sienaAlgorithm</code> and <code>sienaModel</code> objects), the
<code>mclapply</code> function from the <span class="pkg">parallel</span> package (formerly in the
<span class="pkg">multicore</span> package) is used for parallelization. This should run on
any kind of system except MS Windows because it is based on forking. It is
usually the fastest type of parallelization. If <code>"snow"</code> is used, the
<code>parLapply</code> function from the <span class="pkg">parallel</span> package (formerly in the
<span class="pkg">snow</span> package) is used for parallelization. This should run on any
kind of system including cluster systems and including MS Windows. It is
slightly slower than the former alternative if the same number of cores is
used. However, <code>"snow"</code> provides support for MPI clusters with a large
amount of cores, which <span class="pkg">multicore</span> does not offer (see also the
<code>cl</code> argument). Note that <code>"multicore"</code> will only work if all
cores are on the same node. For example, if there are three nodes with
eight cores each, a maximum of eight CPUs can be used. Parallel computing
is described in more detail on the help page of <a href="#topic+btergm">btergm</a>.</p>
</td></tr>
<tr><td><code id="gof_+3A_ncpus">ncpus</code></td>
<td>
<p>The number of CPU cores used for parallel GOF assessment (only
if <code>parallel</code> is activated). If the number of cores should be detected
automatically on the machine where the code is executed, one can try the
<code>detectCores()</code> function from the <span class="pkg">parallel</span> package. On some HPC
clusters, the number of available cores is saved as an environment
variable; for example, if MOAB is used, the number of available cores can
sometimes be accessed using <code>Sys.getenv("MOAB_PROCCOUNT")</code>, depending
on the implementation. Note that the maximum number of connections in a
single R session (i.e., to other cores or for opening files etc.) is 128,
so fewer than 128 cores should be used at a time.</p>
</td></tr>
<tr><td><code id="gof_+3A_cl">cl</code></td>
<td>
<p>An optional <span class="pkg">parallel</span> or <span class="pkg">snow</span> cluster for use if
<code>parallel = "snow"</code>. If not supplied, a cluster on the local machine
is created temporarily.</p>
</td></tr>
<tr><td><code id="gof_+3A_verbose">verbose</code></td>
<td>
<p>Print details?</p>
</td></tr>
<tr><td><code id="gof_+3A_formula">formula</code></td>
<td>
<p>A model formula from which networks are simulated for
comparison. By default, the formula from the <code>btergm</code> object <code>x</code>
is used. It is possible to hand over a formula with only a single response
network and/or dyad or edge covariates or with lists of response networks
and/or covariates. It is also possible to use indices like
<code>networks[[4]]</code> or <code>networks[3:5]</code> inside the formula.</p>
</td></tr>
<tr><td><code id="gof_+3A_nsim">nsim</code></td>
<td>
<p>The number of networks to be simulated at each time step.
Example: If there are six time steps in the <code>formula</code> and
<code>nsim = 100</code>, a total of 600 new networks is simulated. The
comparison between simulated and observed networks is only done within time
steps. For example, the first 100 simulations are compared with the first
observed network, simulations 101-200 with the second observed network etc.</p>
</td></tr>
<tr><td><code id="gof_+3A_mcmc.interval">MCMC.interval</code></td>
<td>
<p>Internally, this package uses the simulation facilities
of the <span class="pkg">ergm</span> package to create new networks against which to compare
the original network(s) for goodness-of-fit assessment. This argument sets
the MCMC interval to be passed over to the simulation command. The default
value is <code>1000</code>, which means that every 1000th simulation outcome from
the MCMC sequence is used. There is no general rule of thumb on the
selection of this parameter, but if the results look suspicious (e.g., when
the model fit is perfect), increasing this value may be helpful.</p>
</td></tr>
<tr><td><code id="gof_+3A_mcmc.burnin">MCMC.burnin</code></td>
<td>
<p>Internally, this package uses the simulation facilities of
the <span class="pkg">ergm</span> package to create new networks against which to compare the
original network(s) for goodness-of-fit assessment. This argument sets the
MCMC burnin to be passed over to the simulation command. The default value
is <code>10000</code>. There is no general rule of thumb on the selection of this
parameter, but if the results look suspicious (e.g., when the model fit is
perfect), increasing this value may be helpful.</p>
</td></tr>
<tr><td><code id="gof_+3A_period">period</code></td>
<td>
<p>Which transition between time periods should be used for GOF
assessment? By default, all transitions between all time periods are used.
For example, if there are three consecutive networks, this will extract
simulations from the transitions between 1 and 2 and between 2 and 3,
respectively, and these simulations will be compared to the networks at
time steps 2 and 3, respectively. The time period can be provided as a
numeric, e.g., <code>period = 4</code> for extracting the simulations between
time steps 4 and 5 (= the fourth transition) and predicting the fifth
network. Values lower than 1 or larger than the number of consecutive
networks minus 1 are therefore not permitted. This argument is only used if
out-of-sample prediction is switched off.</p>
</td></tr>
<tr><td><code id="gof_+3A_structzero">structzero</code></td>
<td>
<p>Which value was used for structural zeros (usually nodes
that have dropped out of the network or have not yet joined the network) in
the dependent variable/network? These nodes are removed from the observed
network and the simulations before comparison. Usually, the value <code>10</code>
is used for structural zeros in Siena.</p>
</td></tr>
<tr><td><code id="gof_+3A_groupname">groupName</code></td>
<td>
<p>The group name used in the Siena model.</p>
</td></tr>
<tr><td><code id="gof_+3A_varname">varName</code></td>
<td>
<p>The variable name that denotes the dependent networks in the
Siena model.</p>
</td></tr>
<tr><td><code id="gof_+3A_outofsample">outofsample</code></td>
<td>
<p>Should out-of-sample prediction be attempted? If so, some
additional arguments must be provided: <code>sienaData</code>,
<code>sienaEffects</code>, and <code>nsim</code>. The <code>sienaData</code> object must
contain a base and a target network for out-of-sample prediction. The
<code>sienaEffects</code> must contain the effects to be used for the
simulations. The estimates will be taken from the estimated <code>object</code>,
and they will be injected into a new SAOM and fixed during the sampling
procedure. <code>nsim</code> determines how many simulations are used for the
out-of-sample comparison.</p>
</td></tr>
<tr><td><code id="gof_+3A_sienadata">sienaData</code></td>
<td>
<p>An object of the class <code>siena</code>, which is usually
created using the <code>sienaDataCreate</code> function in the <span class="pkg">RSiena</span>
package. This argument is only used for out-of-sample prediction. The
object must be based on a <code>sienaDependent</code> object that contains two
networks: the base network from which to simulate forward, and the target
network which you want to predict out-of-sample. The object can contain
further objects for storing covariates etc. that are necessary for
estimating new networks. The best practice is to create an object that is
identical to the <code>siena</code> object used for estimating the model, except
that it contains the base and the target network instead of the dependent
variable/networks.</p>
</td></tr>
<tr><td><code id="gof_+3A_sienaeffects">sienaEffects</code></td>
<td>
<p>An object of the class <code>sienaEffects</code>, which is
usually created using the <code>getEffects()</code> and the
<code>includeEffects()</code> functions in the <code>RSiena</code> package. The best
practice is to provide a <code>sienaEffects</code> object that is identical to
the object used to create the original model (that is, it should contain
the same effects), except that it should be based on the <code>siena</code>
object provided through the <code>sienaData</code> argument. In other words, the
<code>sienaEffects</code> object should be based on the base and target network
used for out-of-sample prediction, and it should contain the same effects
as those used for the original estimation. This argument is used only for
out-of-sample prediction.</p>
</td></tr>
<tr><td><code id="gof_+3A_covariates">covariates</code></td>
<td>
<p>A list of matrices or network objects that serve as
covariates for the dependent network. The covariates in this list are
automatically added to the formula as <code>edgecov</code> terms.</p>
</td></tr>
<tr><td><code id="gof_+3A_coef">coef</code></td>
<td>
<p>A vector of coefficients.</p>
</td></tr>
<tr><td><code id="gof_+3A_mcmc">mcmc</code></td>
<td>
<p>Should statnet's MCMC methods be used for simulating new
networks? If <code>mcmc = FALSE</code>, new networks are simulated based on
predicted tie probabilities of the regression equation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generic <code>gof</code> function provides goodness-of-fit measures and
degeneracy checks for <code>btergm</code>, <code>mtergm</code>, <code>tbergm</code>,
<code>ergm</code>, <code>sienaFit</code>, and custom dyadic-independent models. The user
can provide a list of network statistics for comparing simulated networks
based on the estimated model with the observed network(s). See
<code><a href="#topic+gof-statistics">gof-statistics</a></code>. The objects created by these methods can be
displayed using various plot and print methods (see <code><a href="#topic+gof-plot">gof-plot</a></code>).
</p>
<p>In-sample GOF assessment is the default, which means that the same time steps
are used for creating simulations and for comparison with the observed
network(s). It is possible to do out-of-sample prediction by specifying a
(list of) target network(s) using the <code>target</code> argument. If a formula is
provided, the simulations are based on the networks and covariates specified
in the formula. This is helpful in situations where complex out-of-sample
predictions have to be evaluated. A usage scenario could be to simulate from
a network at time <code>t</code> (provided through the <code>formula</code> argument) and
compare to an observed network at time <code>t + 1</code> (the <code>target</code>
argument). This can be done, for example, to assess predictive performance
between time steps of the original networks, or to check whether the model
performs well with regard to a newly measured network given the old data from
the previous time step.
</p>
<p>Predictive fit can also be assessed for stochastic actor-oriented models
(SAOM) as implemented in the <span class="pkg">RSiena</span> package. After compiling the usual
objects (model, data, effects), one of the time steps can be predicted based
on the previous time step and the SAOM using the <code>sienaFit</code> method of
the <code>gof</code> function. By default, however, within-sample fit is used for
SAOMs, just like for (T)ERGMs.
</p>
<p>The <code>gof</code> methods for networks and matrices serve to assess the goodness
of fit of a dyadic-independence model. To do this, the method requires a
vector of coefficients (one coefficient for the intercept or <code>edges</code>
term and one coefficient for each covariate), a list of covariates (in matrix
or network shape), and a dependent network or matrix. This is useful for
assessing the goodness of fit of QAP-adjusted logistic regression models (as
implemented in the <code>netlogit</code> function in the <span class="pkg">sna</span> package) or
other dyadic-independence models, such as models fitted using <code>glm</code>.
Note that this method only works with cross-sectional models and does not
accept lists of networks as input data.
</p>
<p>The <code>createGOF</code> function is used internally by the <code>gof</code> function
in order to create a <code>gof</code> object from a list of simulated networks and
a list of target networks to compare against. It can also be used directly by
the end user if the user wants to supply lists of simulated and target
networks from other sources.
</p>


<h3>References</h3>

<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>
<p>Leifeld, Philip and Skyler J. Cranmer (2019): A Theoretical and Empirical
Comparison of the Temporal Exponential Random Graph Model and the Stochastic
Actor-Oriented Model. Network Science 7(1): 20&ndash;51.
<a href="https://doi.org/10.1017/nws.2018.26">doi:10.1017/nws.2018.26</a>.
</p>

<hr>
<h2 id='gof-plot'>Plot and print methods for GOF output</h2><span id='topic+gof-plot'></span><span id='topic+gofplot'></span><span id='topic+plotgof'></span><span id='topic+plot-gof'></span><span id='topic+print+2Cgof-method'></span><span id='topic+print+2Cunivariate-method'></span><span id='topic+print+2Cboxplot-method'></span><span id='topic+print+2Croc-method'></span><span id='topic+print+2Cpr-method'></span><span id='topic+print+2Crocpr-method'></span><span id='topic+plot+2Cgof-method'></span><span id='topic+plot+2Cunivariate-method'></span><span id='topic+plot+2Cboxplot-method'></span><span id='topic+plot+2Croc-method'></span><span id='topic+plot+2Cpr-method'></span><span id='topic+plot+2Crocpr-method'></span><span id='topic+print.boxplot'></span><span id='topic+print.roc'></span><span id='topic+print.pr'></span><span id='topic+print.rocpr'></span><span id='topic+print.univariate'></span><span id='topic+print.gof'></span><span id='topic+plot.gof'></span><span id='topic+plot.boxplot'></span><span id='topic+plot.roc'></span><span id='topic+plot.pr'></span><span id='topic+plot.rocpr'></span><span id='topic+plot.univariate'></span>

<h3>Description</h3>

<p>Plot and print methods for goodness-of-fit output for network models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boxplot'
print(x, ...)

## S3 method for class 'roc'
print(x, ...)

## S3 method for class 'pr'
print(x, ...)

## S3 method for class 'rocpr'
print(x, ...)

## S3 method for class 'univariate'
print(x, ...)

## S3 method for class 'gof'
print(x, ...)

## S3 method for class 'gof'
plot(x, mfrow = TRUE, ...)

## S3 method for class 'boxplot'
plot(
  x,
  relative = TRUE,
  transform = function(x) x,
  xlim = NULL,
  main = x$label,
  xlab = x$label,
  ylab = "Frequency",
  border = "darkgray",
  boxplot.lwd = 0.8,
  outline = FALSE,
  median = TRUE,
  median.col = "black",
  median.lty = "solid",
  median.lwd = 2,
  mean = TRUE,
  mean.col = "black",
  mean.lty = "dashed",
  mean.lwd = 1,
  ...
)

## S3 method for class 'roc'
plot(
  x,
  add = FALSE,
  main = x$label,
  avg = c("none", "horizontal", "vertical", "threshold"),
  spread.estimate = c("boxplot", "stderror", "stddev"),
  lwd = 3,
  rgraph = FALSE,
  col = "#bd0017",
  random.col = "#bd001744",
  ...
)

## S3 method for class 'pr'
plot(
  x,
  add = FALSE,
  main = x$label,
  avg = c("none", "horizontal", "vertical", "threshold"),
  spread.estimate = c("boxplot", "stderror", "stddev"),
  lwd = 3,
  rgraph = FALSE,
  col = "#5886be",
  random.col = "#5886be44",
  pr.poly = 0,
  ...
)

## S3 method for class 'rocpr'
plot(
  x,
  main = x$label,
  roc.avg = c("none", "horizontal", "vertical", "threshold"),
  roc.spread.estimate = c("boxplot", "stderror", "stddev"),
  roc.lwd = 3,
  roc.rgraph = FALSE,
  roc.col = "#bd0017",
  roc.random.col = "#bd001744",
  pr.avg = c("none", "horizontal", "vertical", "threshold"),
  pr.spread.estimate = c("boxplot", "stderror", "stddev"),
  pr.lwd = 3,
  pr.rgraph = FALSE,
  pr.col = "#5886be",
  pr.random.col = "#5886be44",
  pr.poly = 0,
  ...
)

## S3 method for class 'univariate'
plot(
  x,
  main = x$label,
  sim.hist = TRUE,
  sim.bar = TRUE,
  sim.density = TRUE,
  obs.hist = FALSE,
  obs.bar = TRUE,
  obs.density = TRUE,
  sim.adjust = 1,
  obs.adjust = 1,
  sim.lwd = 2,
  obs.lwd = 2,
  sim.col = "black",
  obs.col = "red",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gof-plot_+3A_x">x</code></td>
<td>
<p>An object created by one of the <code>gof</code> methods.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_...">...</code></td>
<td>
<p>Arbitrary further arguments.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_mfrow">mfrow</code></td>
<td>
<p>Should the GOF plots come out separately (<code>mfrow = FALSE</code>),
or should all statistics be aligned in a single diagram
(<code>mfrow = TRUE</code>)? Returning the plots separately can be helpful if the
output is redirected to a multipage PDF or TIFF file.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_relative">relative</code></td>
<td>
<p>Print relative frequencies (as opposed to absolute
frequencies) of a statistic on the y axis?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_transform">transform</code></td>
<td>
<p>A function which transforms the y values used for the
boxplots. For example, if some of the values become very large and make the
output illegible, <code>transform = function(x) x^0.1</code> or a similar
transformation of the values can be used. Note that logarithmic
transformations often produce infinite values because <code>log(0) = -Inf</code>,
so one should rather use something like
<code>transform = function(x) log1p</code> to avoid infinite values.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_xlim">xlim</code></td>
<td>
<p>Horizontal limit of the boxplots. Only the maximum value must be
provided, e.g., <code>xlim = 8</code>.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_main">main</code></td>
<td>
<p>Main title of a GOF plot.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_xlab">xlab</code></td>
<td>
<p>Label of the x-axis of a GOF plot.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_ylab">ylab</code></td>
<td>
<p>Label of the y-axis of a GOF plot.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_border">border</code></td>
<td>
<p>Color of the borders of the boxplots.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_boxplot.lwd">boxplot.lwd</code></td>
<td>
<p>Line width of boxplot.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_outline">outline</code></td>
<td>
<p>Print outliers in the boxplots?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_median">median</code></td>
<td>
<p>Plot the median curve for the observed network?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_median.col">median.col</code></td>
<td>
<p>Color of the median of the observed network statistic.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_median.lty">median.lty</code></td>
<td>
<p>Line type of median line. For example &quot;dashed&quot; or &quot;solid&quot;.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_median.lwd">median.lwd</code></td>
<td>
<p>Line width of median line.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_mean">mean</code></td>
<td>
<p>Plot the mean curve for the observed network?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_mean.col">mean.col</code></td>
<td>
<p>Color of the mean of the observed network statistic.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_mean.lty">mean.lty</code></td>
<td>
<p>Line type of mean line. For example &quot;dashed&quot; or &quot;solid&quot;.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_mean.lwd">mean.lwd</code></td>
<td>
<p>Line width of mean line.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_add">add</code></td>
<td>
<p>Add the ROC and/or PR curve to an existing plot?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_avg">avg</code></td>
<td>
<p>Averaging pattern for the ROC and PR curve(s) if multiple target
time steps were used. Allowed values are <code>"none"</code> (plot all curves
separately), <code>"horizontal"</code> (horizontal averaging), <code>"vertical"</code>
(vertical averaging), and <code>"threshold"</code> (threshold (= cutoff)
averaging). Note that while threshold averaging is always feasible,
vertical and horizontal averaging are not well-defined if the graph cannot
be represented as a function x-&gt;y and y-&gt;x, respectively. More information
can be obtained from the help pages of the <span class="pkg">ROCR</span> package, the
functions of which are employed here.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_spread.estimate">spread.estimate</code></td>
<td>
<p>When multiple target time steps are used and curve
averaging is enabled, the variation around the average curve can be
visualized as standard error bars (<code>"stderror"</code>), standard deviation
bars (<code>"stddev"</code>), or by using box plots (<code>"boxplot"</code>). Note that
the function plotCI, which is used internally by the <span class="pkg">ROCR</span> package to
draw error bars, might raise a warning if the spread of the curves at
certain positions is 0. More details can be found in the documentation of
the <span class="pkg">ROCR</span> package, the functions of which are employed here.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_lwd">lwd</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_rgraph">rgraph</code></td>
<td>
<p>Should an ROC or PR curve also be drawn for a random graph?
This serves as a baseline against which to compare the actual ROC or PR
curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_col">col</code></td>
<td>
<p>Color of the ROC or PR curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_random.col">random.col</code></td>
<td>
<p>Color of the ROC or PR curve of the random graph
prediction.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.poly">pr.poly</code></td>
<td>
<p>If a value of <code>0</code> is set, nothing special happens. If a
value of <code>1</code> is set, a straight line is fitted through the PR curve
and displayed. Values between <code>2</code> and <code>9</code> fit higher-order
polynomial curves through the PR curve and display the resulting curve.
This argument allows to check whether the imputation of the first precision
value in the PR curve yielded a reasonable result (in case the value had to
be imputed).</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_roc.avg">roc.avg</code></td>
<td>
<p>Averaging pattern for the ROC curve(s) if multiple target time
steps were used. Allowed values are <code>"none"</code> (plot all curves
separately), <code>"horizontal"</code> (horizontal averaging), <code>"vertical"</code>
(vertical averaging), and <code>"threshold"</code> (threshold (= cutoff)
averaging). Note that while threshold averaging is always feasible,
vertical and horizontal averaging are not well-defined if the graph cannot
be represented as a function x-&gt;y and y-&gt;x, respectively. More information
can be obtained from the help pages of the <span class="pkg">ROCR</span> package, the
functions of which are employed here.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_roc.spread.estimate">roc.spread.estimate</code></td>
<td>
<p>When multiple target time steps are used and curve
averaging is enabled, the variation around the average curve can be
visualized as standard error bars (<code>"stderror"</code>), standard deviation
bars (<code>"stddev"</code>), or by using box plots (<code>"boxplot"</code>). Note that
the function plotCI, which is used internally by the <span class="pkg">ROCR</span> package to
draw error bars, might raise a warning if the spread of the curves at
certain positions is 0. More details can be found in the documentation of
the <span class="pkg">ROCR</span> package, the functions of which are employed here.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_roc.lwd">roc.lwd</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_roc.rgraph">roc.rgraph</code></td>
<td>
<p>Should an ROC curve also be drawn for a random graph? This
serves as a baseline against which to compare the actual ROC curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_roc.col">roc.col</code></td>
<td>
<p>Color of the ROC curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_roc.random.col">roc.random.col</code></td>
<td>
<p>Color of the ROC curve of the random graph prediction.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.avg">pr.avg</code></td>
<td>
<p>Averaging pattern for the PR curve(s) if multiple target time
steps were used. Allowed values are <code>"none"</code> (plot all curves
separately), <code>"horizontal"</code> (horizontal averaging), <code>"vertical"</code>
(vertical averaging), and <code>"threshold"</code> (threshold (= cutoff)
averaging). Note that while threshold averaging is always feasible,
vertical and horizontal averaging are not well-defined if the graph cannot
be represented as a function x-&gt;y and y-&gt;x, respectively. More information
can be obtained from the help pages of the <span class="pkg">ROCR</span> package, the
functions of which are employed here.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.spread.estimate">pr.spread.estimate</code></td>
<td>
<p>When multiple target time steps are used and curve
averaging is enabled, the variation around the average curve can be
visualized as standard error bars (<code>"stderror"</code>), standard deviation
bars (<code>"stddev"</code>), or by using box plots (<code>"boxplot"</code>). Note that
the function plotCI, which is used internally by the <span class="pkg">ROCR</span> package to
draw error bars, might raise a warning if the spread of the curves at
certain positions is 0. More details can be found in the documentation of
the <span class="pkg">ROCR</span> package, the functions of which are employed here.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.lwd">pr.lwd</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.rgraph">pr.rgraph</code></td>
<td>
<p>Should an PR curve also be drawn for a random graph? This
serves as a baseline against which to compare the actual PR curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.col">pr.col</code></td>
<td>
<p>Color of the PR curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_pr.random.col">pr.random.col</code></td>
<td>
<p>Color of the PR curve of the random graph prediction.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_sim.hist">sim.hist</code></td>
<td>
<p>Draw a histogram for the simulated networks?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_sim.bar">sim.bar</code></td>
<td>
<p>Draw a bar for the median of the statistic for the simulated
networks?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_sim.density">sim.density</code></td>
<td>
<p>Draw a density curve fot the statistic for the simulated
networks?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_obs.hist">obs.hist</code></td>
<td>
<p>Draw a histogram for the observed networks?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_obs.bar">obs.bar</code></td>
<td>
<p>Draw a bar for the median of the statistic for the observed
networks?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_obs.density">obs.density</code></td>
<td>
<p>Draw a density curve fot the statistic for the observed
networks?</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_sim.adjust">sim.adjust</code></td>
<td>
<p>Bandwidth adjustment parameter for the density curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_obs.adjust">obs.adjust</code></td>
<td>
<p>Bandwidth adjustment parameter for the density curve.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_sim.lwd">sim.lwd</code></td>
<td>
<p>Line width for the simulated networks.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_obs.lwd">obs.lwd</code></td>
<td>
<p>Line width for the observed network(s).</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_sim.col">sim.col</code></td>
<td>
<p>Color for the simulated networks.</p>
</td></tr>
<tr><td><code id="gof-plot_+3A_obs.col">obs.col</code></td>
<td>
<p>Color for the observed network(s).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These plot and print methods serve to display the output generated by the
<code>gof</code> function and its methods. See the help page of
<code><a href="#topic+gof-methods">gof-methods</a></code> for details on how to compute goodness-of-fit
statistics.
</p>


<h3>References</h3>

<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>

<hr>
<h2 id='gof-statistics'>Statistics for goodness-of-fit assessment of network models</h2><span id='topic+gof-statistics'></span><span id='topic+gofstatistics'></span><span id='topic+dsp'></span><span id='topic+esp'></span><span id='topic+nsp'></span><span id='topic+deg'></span><span id='topic+b1deg'></span><span id='topic+b2deg'></span><span id='topic+odeg'></span><span id='topic+ideg'></span><span id='topic+kstar'></span><span id='topic+b1star'></span><span id='topic+b2star'></span><span id='topic+ostar'></span><span id='topic+istar'></span><span id='topic+kcycle'></span><span id='topic+geodesic'></span><span id='topic+triad.directed'></span><span id='topic+triad.undirected'></span><span id='topic+comemb'></span><span id='topic+walktrap.modularity'></span><span id='topic+walktrap.roc'></span><span id='topic+walktrap.pr'></span><span id='topic+fastgreedy.modularity'></span><span id='topic+fastgreedy.roc'></span><span id='topic+fastgreedy.pr'></span><span id='topic+louvain.modularity'></span><span id='topic+louvain.roc'></span><span id='topic+louvain.pr'></span><span id='topic+maxmod.modularity'></span><span id='topic+maxmod.roc'></span><span id='topic+maxmod.pr'></span><span id='topic+edgebetweenness.modularity'></span><span id='topic+edgebetweenness.roc'></span><span id='topic+edgebetweenness.pr'></span><span id='topic+spinglass.modularity'></span><span id='topic+spinglass.roc'></span><span id='topic+spinglass.pr'></span><span id='topic+rocpr'></span>

<h3>Description</h3>

<p>Statistics for goodness-of-fit assessment of network models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsp(mat, ...)

esp(mat, ...)

nsp(mat, ...)

deg(mat, ...)

b1deg(mat, ...)

b2deg(mat, ...)

odeg(mat, ...)

ideg(mat, ...)

kstar(mat, ...)

b1star(mat, ...)

b2star(mat, ...)

ostar(mat, ...)

istar(mat, ...)

kcycle(mat, ...)

geodesic(mat, ...)

triad.directed(mat, ...)

triad.undirected(mat, ...)

comemb(vec)

walktrap.modularity(mat, ...)

walktrap.roc(sim, obs, ...)

walktrap.pr(sim, obs, ...)

fastgreedy.modularity(mat, ...)

fastgreedy.roc(sim, obs, ...)

fastgreedy.pr(sim, obs, ...)

louvain.modularity(mat, ...)

louvain.roc(sim, obs, ...)

louvain.pr(sim, obs, ...)

maxmod.modularity(mat, ...)

maxmod.roc(sim, obs, ...)

maxmod.pr(sim, obs, ...)

edgebetweenness.modularity(mat, ...)

edgebetweenness.roc(sim, obs, ...)

edgebetweenness.pr(sim, obs, ...)

spinglass.modularity(mat, ...)

spinglass.roc(sim, obs, ...)

spinglass.pr(sim, obs, ...)

rocpr(sim, obs, roc = TRUE, pr = TRUE, joint = TRUE, pr.impute = "poly4", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gof-statistics_+3A_mat">mat</code></td>
<td>
<p>A sparse network matrix as created by the <code>Matrix</code> function
in the <span class="pkg">Matrix</span> package.</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_...">...</code></td>
<td>
<p>Additional arguments. This must be present in all auxiliary GOF
statistics.</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_vec">vec</code></td>
<td>
<p>A vector of community memberships in order to create a community
co-membership matrix.</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_sim">sim</code></td>
<td>
<p>A list of simulated networks. Each element in the list should be a
sparse matrix as created by the <code><a href="Matrix.html#topic+Matrix">Matrix</a></code> function in
the <span class="pkg">Matrix</span> package.</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_obs">obs</code></td>
<td>
<p>A list of observed (= target) networks. Each element in the list
should be a sparse matrix as created by the <code><a href="Matrix.html#topic+Matrix">Matrix</a></code>
function in the <span class="pkg">Matrix</span> package.</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_roc">roc</code></td>
<td>
<p>Compute receiver-operating characteristics (ROC)?</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_pr">pr</code></td>
<td>
<p>Compute precision-recall curve (PR)?</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_joint">joint</code></td>
<td>
<p>Merge all time steps into a single big prediction task and
compute predictive fit (instead of computing GOF for all time steps
separately)?</p>
</td></tr>
<tr><td><code id="gof-statistics_+3A_pr.impute">pr.impute</code></td>
<td>
<p>In some cases, the first precision value of the
precision-recall curve is undefined. The <code>pr.impute</code> argument serves
to impute this missing value to ensure that the AUC-PR value is not
severely biased. Possible values are <code>"no"</code> for no imputation,
<code>"one"</code> for using a value of <code>1.0</code>, <code>"second"</code> for using the
next (= adjacent) precision value, <code>"poly1"</code> for fitting a straight
line through the remaining curve to predict the first value, <code>"poly2"</code>
for fitting a second-order polynomial curve etc. until <code>"poly9"</code>.
Warning: this is a pragmatic solution. Please double-check whether the
imputation makes sense. This can be checked by plotting the resulting
object and using the <code>pr.poly</code> argument to plot the predicted curve on
top of the actual PR curve.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions can be plugged into the <code>statistics</code> argument of the
<code>gof</code> methods in order to compare observed with simulated networks (see
the <a href="#topic+gof-methods">gof-methods</a> help page). There are three types of statistics:
</p>

<ol>
<li><p> Univariate statistics, which aggregate a network into a single
quantity. For example, modularity measures or density. The distribution
of statistics can be displayed using histograms, density plots, and
median bars. Univariate statistics take a sparse matrix (<code>mat</code>)
as an argument and return a single numeric value that summarize a network
matrix.
</p>
</li>
<li><p> Multivariate statistics, which aggregate a network into a vector of
quantities. For example, the distribution of geodesic distances, edgewise
shared partners, or indegree. These statistics typically have multiple
values, e.g., esp(1), esp(2), esp(3) etc. The results can be displayed
using multiple boxplots for simulated networks and a black curve for the
observed network(s). Multivariate statistics take a sparse matrix
(<code>mat</code>) as an argument and return a vector of numeric values that
summarize a network matrix.
</p>
</li>
<li><p> Tie prediction statistics, which predict dyad states the observed
network(s) by the dyad states in the simulated networks. For example,
receiver operating characteristics (ROC) or precision-recall curves (PR)
of simulated networks based on the model, or ROC or PR predictions of
community co-membership matrices of the simulated vs. the observed
network(s). Tie prediction statistics take a list of simulated sparse
network matrices and another list of observed sparse network matrices
(possibly containing only a single sparse matrix) as arguments and return
a <code>rocpr</code>, <code>roc</code>, or <code>pr</code> object (as created by the
<a href="#topic+rocpr">rocpr</a> function).
</p>
</li></ol>

<p>Users can create their own statistics for use with the <code>gof</code> methods. To
do so, one needs to write a function that accepts and returns the respective
objects described in the enumeration above. It is advisable to look at the
definitions of some of the existing functions to add custom functions. It is
also possible to add an attribute called <code>label</code> to the return object,
which describes what is being returned by the function. This label will be
used as a descriptive label in the plot and for verbose output during
computations. The examples section contains an example of a custom user
statistic. Note that all statistics <em>must</em> contain the <code>...</code>
argument to ensure that custom arguments of other statistics do not cause an
error.
</p>
<p>To aid the development of custom statistics, the helper function
<code>comemb</code> is available: it accepts a vector of community memberships and
converts it to a co-membership matrix. This function is also used internally
by statistics like <code>walktrap.roc</code> and others.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>dsp()</code>: Multivariate GOF statistic: dyad-wise shared
partner distribution
</p>
</li>
<li> <p><code>esp()</code>: Multivariate GOF statistic: edge-wise shared
partner distribution
</p>
</li>
<li> <p><code>nsp()</code>: Multivariate GOF statistic: non-edge-wise shared
partner distribution
</p>
</li>
<li> <p><code>deg()</code>: Multivariate GOF statistic: degree distribution
</p>
</li>
<li> <p><code>b1deg()</code>: Multivariate GOF statistic: degree distribution
for the first mode
</p>
</li>
<li> <p><code>b2deg()</code>: Multivariate GOF statistic: degree distribution
for the second mode
</p>
</li>
<li> <p><code>odeg()</code>: Multivariate GOF statistic: outdegree distribution
</p>
</li>
<li> <p><code>ideg()</code>: Multivariate GOF statistic: indegree distribution
</p>
</li>
<li> <p><code>kstar()</code>: Multivariate GOF statistic: k-star distribution
</p>
</li>
<li> <p><code>b1star()</code>: Multivariate GOF statistic: k-star distribution
for the first mode
</p>
</li>
<li> <p><code>b2star()</code>: Multivariate GOF statistic: k-star distribution
for the second mode
</p>
</li>
<li> <p><code>ostar()</code>: Multivariate GOF statistic: outgoing k-star
distribution
</p>
</li>
<li> <p><code>istar()</code>: Multivariate GOF statistic: incoming k-star
distribution
</p>
</li>
<li> <p><code>kcycle()</code>: Multivariate GOF statistic: k-cycle distribution
</p>
</li>
<li> <p><code>geodesic()</code>: Multivariate GOF statistic: geodesic distance
distribution
</p>
</li>
<li> <p><code>triad.directed()</code>: Multivariate GOF statistic: triad census in
directed networks
</p>
</li>
<li> <p><code>triad.undirected()</code>: Multivariate GOF statistic: triad census in
undirected networks
</p>
</li>
<li> <p><code>comemb()</code>: Helper function: create community co-membership
matrix
</p>
</li>
<li> <p><code>walktrap.modularity()</code>: Univariate GOF statistic: Walktrap modularity
distribution
</p>
</li>
<li> <p><code>walktrap.roc()</code>: Tie prediction GOF statistic: ROC of Walktrap
community detection. Receiver-operating characteristics of predicting the
community structure in the observed network(s) by the community structure
in the simulated networks, as computed by the Walktrap algorithm.
</p>
</li>
<li> <p><code>walktrap.pr()</code>: Tie prediction GOF statistic: PR of Walktrap
community detection. Precision-recall curve for predicting the community
structure in the observed network(s) by the community structure in the
simulated networks, as computed by the Walktrap algorithm.
</p>
</li>
<li> <p><code>fastgreedy.modularity()</code>: Univariate GOF statistic: fast and greedy
modularity distribution
</p>
</li>
<li> <p><code>fastgreedy.roc()</code>: Tie prediction GOF statistic: ROC of fast and
greedy community detection. Receiver-operating characteristics of
predicting the community structure in the observed network(s) by the
community structure in the simulated networks, as computed by the fast and
greedy algorithm. Only sensible with undirected networks.
</p>
</li>
<li> <p><code>fastgreedy.pr()</code>: Tie prediction GOF statistic: PR of fast and
greedy community detection. Precision-recall curve for predicting the
community structure in the observed network(s) by the community structure
in the simulated networks, as computed by the fast and greedy algorithm.
Only sensible with undirected networks.
</p>
</li>
<li> <p><code>louvain.modularity()</code>: Univariate GOF statistic: Louvain clustering
modularity distribution
</p>
</li>
<li> <p><code>louvain.roc()</code>: Tie prediction GOF statistic: ROC of Louvain
community detection. Receiver-operating characteristics of predicting the
community structure in the observed network(s) by the community structure
in the simulated networks, as computed by the Louvain algorithm.
</p>
</li>
<li> <p><code>louvain.pr()</code>: Tie prediction GOF statistic: PR of Louvain
community detection. Precision-recall curve for predicting the community
structure in the observed network(s) by the community structure in the
simulated networks, as computed by the Louvain algorithm.
</p>
</li>
<li> <p><code>maxmod.modularity()</code>: Univariate GOF statistic: maximal modularity
distribution
</p>
</li>
<li> <p><code>maxmod.roc()</code>: Tie prediction GOF statistic: ROC of maximal
modularity community detection. Receiver-operating characteristics of
predicting the community structure in the observed network(s) by the
community structure in the simulated networks, as computed by the
modularity maximization algorithm.
</p>
</li>
<li> <p><code>maxmod.pr()</code>: Tie prediction GOF statistic: PR of maximal
modularity community detection. Precision-recall curve for predicting the
community structure in the observed network(s) by the community structure
in the simulated networks, as computed by the modularity maximization
algorithm.
</p>
</li>
<li> <p><code>edgebetweenness.modularity()</code>: Univariate GOF statistic: edge betweenness
modularity distribution
</p>
</li>
<li> <p><code>edgebetweenness.roc()</code>: Tie prediction GOF statistic: ROC of edge
betweenness community detection. Receiver-operating characteristics of
predicting the community structure in the observed network(s) by the
community structure in the simulated networks, as computed by the
Girvan-Newman edge betweenness community detection method.
</p>
</li>
<li> <p><code>edgebetweenness.pr()</code>: Tie prediction GOF statistic: PR of edge
betweenness community detection. Precision-recall curve for predicting the
community structure in the observed network(s) by the community structure
in the simulated networks, as computed by the Girvan-Newman edge
betweenness community detection method.
</p>
</li>
<li> <p><code>spinglass.modularity()</code>: Univariate GOF statistic: spinglass modularity
distribution
</p>
</li>
<li> <p><code>spinglass.roc()</code>: Tie prediction GOF statistic: ROC of spinglass
community detection. Receiver-operating characteristics of predicting the
community structure in the observed network(s) by the community structure
in the simulated networks, as computed by the Spinglass algorithm.
</p>
</li>
<li> <p><code>spinglass.pr()</code>: Tie prediction GOF statistic: PR of spinglass
community detection. Precision-recall curve for predicting the community
structure in the observed network(s) by the community structure in the
simulated networks, as computed by the Spinglass algorithm.
</p>
</li>
<li> <p><code>rocpr()</code>: Tie prediction GOF statistic: ROC and PR curves.
Receiver-operating characteristics (ROC) and precision-recall curve (PR).
Prediction of the dyad states of the observed network(s) by the dyad states
of the simulated networks.
</p>
</li></ul>


<h3>References</h3>

<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># To see how these statistics are used, look at the examples section of 
# ?"gof-methods". The following example illustrates how custom 
# statistics can be created. Suppose one is interested in the density 
# of a network. Then a univariate statistic can be created as follows.

dens &lt;- function(mat, ...) {        # univariate: one argument
  mat &lt;- as.matrix(mat)             # sparse matrix -&gt; normal matrix
  d &lt;- sna::gden(mat)               # compute the actual statistic
  attributes(d)$label &lt;- "Density"  # add a descriptive label
  return(d)                         # return the statistic
}

# Note that the '...' argument must be present in all statistics. 
# Now the statistic can be used in the statistics argument of one of 
# the gof methods.

# For illustrative purposes, let us consider an existing statistic, the 
# indegree distribution, a multivariate statistic. It also accepts a 
# single argument. Note that the sparse matrix is converted to a 
# normal matrix object when it is used. First, statnet's summary 
# method is used to compute the statistic. Names are attached to the 
# resulting vector for the different indegree values. Then the vector 
# is returned.

ideg &lt;- function(mat, ...) {
  d &lt;- summary(mat ~ idegree(0:(nrow(mat) - 1)))
  names(d) &lt;- 0:(length(d) - 1)
  attributes(d)$label &lt;- "Indegree"
  return(d)
}

# See the gofstatistics.R file in the package for more complex examples.

</code></pre>

<hr>
<h2 id='handleMissings'>Handle missing data in matrices</h2><span id='topic+handleMissings'></span>

<h3>Description</h3>

<p>Process <code>NA</code> values (= remove nodes with <code>NA</code>s iteratively).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>handleMissings(mat, na = NA, method = "remove", logical = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="handleMissings_+3A_mat">mat</code></td>
<td>
<p>A matrix object.</p>
</td></tr>
<tr><td><code id="handleMissings_+3A_na">na</code></td>
<td>
<p>The value that missing data are coded as. Usually <code>NA</code>,
sometimes <code>9</code> or <code>10</code>.</p>
</td></tr>
<tr><td><code id="handleMissings_+3A_method">method</code></td>
<td>
<p>What should be done with the missing data? If
<code>method = "remove"</code> is set, the function determines how many missing
entries are in each row and column and iteratively removes rows or columns
with the largest amount of missing data until no missing data are left in
the matrix. If <code>method = "fillmode"</code> is set, the modal value of the
matrix is identified (usually <code>0</code> in network matrices) and missing
cells are imputed by filling in this modal value. <code>method = "zero"</code>
replaces NAs by 0s.</p>
</td></tr>
<tr><td><code id="handleMissings_+3A_logical">logical</code></td>
<td>
<p>Return a matrix with logical values indicating which cells
should be removed? By default the manipulated matrix is returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function deals with missing data in matrices or network objects used for
inferential network analysis. It can either remove missing rows and/or
columns iteratively (rows and columns with more <code>NA</code> values first, then
successively rows and columns with fewer <code>NA</code> entries) or replace
missing values by the modal value of the matrix or by <code>0</code>. The function
can return either the manipulated matrix or a matrix with logical values
indicating which of the cells should be removed.
</p>


<h3>Value</h3>

<p>Either a matrix in which missing data were taken care of or a matrix
indicating where missing data are located.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjust">adjust</a></code>
</p>

<hr>
<h2 id='interpret'>Micro-Level Interpretation of (T)ERGMs</h2><span id='topic+interpret'></span><span id='topic+interpret-methods'></span><span id='topic+interpret+2Cergm-method'></span><span id='topic+interpret+2Cbtergm-method'></span><span id='topic+interpret+2Cmtergm-method'></span>

<h3>Description</h3>

<p>Micro-level interpretation of (T)ERGMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret(object, ...)

## S4 method for signature 'ergm'
interpret(
  object,
  formula = getformula(object),
  coefficients = coef(object),
  target = NULL,
  type = "tie",
  i,
  j
)

## S4 method for signature 'btergm'
interpret(
  object,
  formula = getformula(object),
  coefficients = coef(object),
  target = NULL,
  type = "tie",
  i,
  j,
  t = 1:object@time.steps
)

## S4 method for signature 'mtergm'
interpret(
  object,
  formula = getformula(object),
  coefficients = coef(object),
  target = NULL,
  type = "tie",
  i,
  j,
  t = 1:object@time.steps
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interpret_+3A_object">object</code></td>
<td>
<p>An <code>ergm</code>, <code>btergm</code>, or <code>mtergm</code> object.</p>
</td></tr>
<tr><td><code id="interpret_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed on to subroutines.</p>
</td></tr>
<tr><td><code id="interpret_+3A_formula">formula</code></td>
<td>
<p>The formula to be used for computing probabilities. By
default, the formula embedded in the model object is retrieved and used.</p>
</td></tr>
<tr><td><code id="interpret_+3A_coefficients">coefficients</code></td>
<td>
<p>The estimates on which probabilities should be based. By
default, the coefficients from the model object are retrieved and used.
Custom coefficients can be handed over, for example, in order to compare
versions of the model where the reciprocity term is fixed at <code>0</code>
versus versions of the model where the reciprocity term is left as in the
empirical result. This is one of the examples described in Desmarais and
Cranmer (2012).</p>
</td></tr>
<tr><td><code id="interpret_+3A_target">target</code></td>
<td>
<p>The response network on which probabilities are based.
Depending on whether the function is applied to an <code>ergm</code> or
<code>btergm</code>/<code>mtergm</code> object, this can be either a single network or
a list of networks. By default, the (list of) network(s) provided as the
left-hand side of the (T)ERGM formula is used.</p>
</td></tr>
<tr><td><code id="interpret_+3A_type">type</code></td>
<td>
<p>If <code>type = "tie"</code> is used, probabilities at the edge level
are computed. For example, what is the probability of a specific node
<code>i</code> to be connected to a specific node <code>j</code> given the rest of the
network and given the model? If <code>type = "dyad"</code> is used, probabilities
at the dyad level are computed. For example, what is the probability that
node <code>i</code> is connected to node <code>j</code> but not vice-versa, or what is
the probability that nodes <code>i</code> and <code>j</code> and mutually connected in
a directed network? If <code>type = "node"</code> is used, probabilities at the
node level are computed. For example, what is the probability that node
<code>i</code> is connected to a set of three other <code>j</code> nodes given the rest
of the network and the model?</p>
</td></tr>
<tr><td><code id="interpret_+3A_i">i</code></td>
<td>
<p>A single (sender) node <code>i</code> or a set of (sender) nodes <code>i</code>.
If <code>type = "node"</code> is used, this can be more than one node and should
be provided as a vector. The <code>i</code> argument can be either provided as
the index of the node in the sociomatrix (e.g., the fourth node would be
<code>i = 4</code>) or the row name of the node in the sociomatrix (e.g.,
<code>i = "Peter"</code>). If more than one node is provided and
<code>type = "node"</code>, there can be only one (receiver) node <code>j</code>. The
<code>i</code> and <code>j</code> arguments are used to specify for which nodes
probabilities should be computed. For example, what is the probability that
<code>i = 4</code> is connected to <code>j = 7</code>?</p>
</td></tr>
<tr><td><code id="interpret_+3A_j">j</code></td>
<td>
<p>A single (receiver) node <code>j</code> or a set of (receiver) nodes
<code>j</code>. If <code>type = "node"</code> is used, this can be more than one node
and should be provided as a vector. The <code>j</code> argument can be either
provided as the index of the node in the sociomatrix (e.g., the fourth node
would be <code>j = 4</code>) or the column name of the node in the sociomatrix
(e.g., <code>j = "Mary"</code>). If more than one node is provided and
<code>type = "node"</code>, there can be only one (sender) node <code>i</code>. The
<code>i</code> and <code>j</code> arguments are used to specify for which nodes
probabilities should be computed. For example, what is the probability that
<code>i = 4</code> is connected to <code>j = 7</code>?</p>
</td></tr>
<tr><td><code id="interpret_+3A_t">t</code></td>
<td>
<p>A vector of (numerical) time steps for which the probabilities
should be computed. This only applies to <code>btergm</code> amd <code>mtergm</code>
objects because <code>ergm</code> objects are by definition based on a single
time step. By default, all available time steps are used. It is, for
example, possible to compute probabilities only for a single time step by
specifying, e.g., <code>t = 5</code> in order to compute probabilities for the
fifth response network.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>interpret</code> function facilitates interpretation of ERGMs and TERGMs
at the micro level, as described in Desmarais and Cranmer (2012). There are
methods for <code>ergm</code> objects, <code>btergm</code> objects, and <code>mtergm</code>
objects. The function can be used to interpret these models at the tie or
edge level, dyad level, and block level. For example, what is the probability
that two specific nodes <code>i</code> (the sender) and <code>j</code> (the receiver) are
connected given the rest of the network and given the model? Or what is the
probability that any two nodes are tied at <code>t = 2</code> if they were tied (or
disconnected) at <code>t = 1</code> (i.e., what is the amount of tie stability)?
These tie- or edge-level questions can be answered if the <code>type = "tie"</code>
argument is used.
</p>
<p>Another example: What is the probability that node <code>i</code> has a tie to node
<code>j</code> but not vice-versa? Or that <code>i</code> and <code>j</code> maintain a
reciprocal tie? Or that they are disconnected? How much more or less likely
are <code>i</code> and <code>j</code> reciprocally connected if the <code>mutual</code> term in
the model is fixed at <code>0</code> (compared to the model that includes the
estimated parameter for reciprocity)? See example below. These dyad-level
questions can be answered if the <code>type = "dyad"</code> argument is used.
</p>
<p>Or what is the probability that a specific node <code>i</code> is connected to
nodes <code>j1</code> and <code>j2</code> but not to <code>j5</code> and <code>j7</code>? And how
likely is any node <code>i</code> to be connected to exactly four <code>j</code> nodes?
These node-level questions (focusing on the ties of node <code>i</code> or node
<code>j</code>) can be answered by using the <code>type = "node"</code> argument.
</p>
<p>The typical procedure is to manually enumerate all dyads or
sender-receiver-time combinations with certain properties and repeat the same
thing with some alternative properties for contrasting the two groups. Then
apply the <code>interpret</code> function to the two groups of dyads and compute a
measure of central tendency (e.g., mean or median) and possibly some
uncertainy measure (i.e., confidence intervals) from the distribution of
dyadic probabilities in each group. For example, if there is a gender
attribute, one can sample male-male or female-female dyads, compute the
distributions of edge probabilities for the two sets of dyads, and create
boxplots or barplots with confidence intervals for the two types of dyads in
order to contrast edge probabilities for male versus female same-sex dyads.
</p>
<p>See also the <code><a href="#topic+edgeprob">edgeprob</a></code> function for automatic computation of all
dyadic edge probabilities.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>interpret(ergm)</code>: Interpret method for <code>ergm</code> objects
</p>
</li>
<li> <p><code>interpret(btergm)</code>: Interpret method for <code>btergm</code> objects
</p>
</li>
<li> <p><code>interpret(mtergm)</code>: Interpret method for <code>mtergm</code> objects
</p>
</li></ul>


<h3>References</h3>

<p>Desmarais, Bruce A. and Skyler J. Cranmer (2012): Micro-Level Interpretation
of Exponential Random Graph Models with Application to Estuary Networks.
<em>Policy Studies Journal</em> 40(3): 402&ndash;434.
<a href="https://doi.org/10.1111/j.1541-0072.2012.00459.x">doi:10.1111/j.1541-0072.2012.00459.x</a>.
</p>
<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2017): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>
<p>Czarna, Anna Z., Philip Leifeld, Magdalena Smieja, Michael Dufner and Peter
Salovey (2016): Do Narcissism and Emotional Intelligence Win Us Friends?
Modeling Dynamics of Peer Popularity Using Inferential Network Analysis.
<em>Personality and Social Psychology Bulletin</em> 42(11): 1588&ndash;1599.
<a href="https://doi.org/10.1177/0146167216666265">doi:10.1177/0146167216666265</a>.
</p>


<h3>See Also</h3>

<p>Other interpretation: 
<code><a href="#topic+edgeprob">edgeprob</a>()</code>,
<code><a href="#topic+marginalplot">marginalplot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##### The following example is a TERGM adaptation of the #####
##### dyad-level example provided in figure 5(c) on page #####
##### 424 of Desmarais and Cranmer (2012) in the PSJ. At #####
##### each time step, it compares dyadic probabilities   #####
##### (no tie, unidirectional tie, and reciprocal tie    #####
##### probability) between a fitted model and a model    #####
##### where the reciprocity effect is fixed at 0 based   #####
##### on 20 randomly selected dyads per time step. The   #####
##### results are visualized using a grouped bar plot.   #####

## Not run: 
  # create toy dataset and fit a model
  networks &lt;- list()
  for (i in 1:3) {           # create 3 random networks with 10 actors
    mat &lt;- matrix(rbinom(100, 1, 0.25), nrow = 10, ncol = 10)
    diag(mat) &lt;- 0           # loops are excluded
    nw &lt;- network(mat)       # create network object
    networks[[i]] &lt;- nw      # add network to the list
  }
  fit &lt;- btergm(networks ~ edges + istar(2) + mutual, R = 200)

  # extract coefficients and create null hypothesis vector
  null &lt;- coef(fit)  # estimated coefs
  null[3] &lt;- 0       # set mutual term = 0

  # sample 20 dyads per time step and compute probability ratios
  probabilities &lt;- matrix(nrow = 9, ncol = length(networks))
  # nrow = 9 because three probabilities + upper and lower CIs
  colnames(probabilities) &lt;- paste("t =", 1:length(networks))
  for (t in 1:length(networks)) {
    d &lt;- dim(as.matrix(networks[[t]]))  # how many row and column nodes?
    size &lt;- d[1] * d[2]                 # size of the matrix
    nw &lt;- matrix(1:size, nrow = d[1], ncol = d[2])
    nw &lt;- nw[lower.tri(nw)]             # sample only from lower triangle b/c
    samp &lt;- sample(nw, 20)              # dyadic probabilities are symmetric
    prob.est.00 &lt;- numeric(0)
    prob.est.01 &lt;- numeric(0)
    prob.est.11 &lt;- numeric(0)
    prob.null.00 &lt;- numeric(0)
    prob.null.01 &lt;- numeric(0)
    prob.null.11 &lt;- numeric(0)
    for (k in 1:20) {
      i &lt;- arrayInd(samp[k], d)[1, 1]   # recover 'i's and 'j's from sample
      j &lt;- arrayInd(samp[k], d)[1, 2]
      # run interpretation function with estimated coefs and mutual = 0:
      int.est &lt;- interpret(fit, type = "dyad", i = i, j = j, t = t)
      int.null &lt;- interpret(fit, coefficients = null, type = "dyad",
                            i = i, j = j, t = t)
      prob.est.00 &lt;- c(prob.est.00, int.est[[1]][1, 1])
      prob.est.11 &lt;- c(prob.est.11, int.est[[1]][2, 2])
      mean.est.01 &lt;- (int.est[[1]][1, 2] + int.est[[1]][2, 1]) / 2
      prob.est.01 &lt;- c(prob.est.01, mean.est.01)
      prob.null.00 &lt;- c(prob.null.00, int.null[[1]][1, 1])
      prob.null.11 &lt;- c(prob.null.11, int.null[[1]][2, 2])
      mean.null.01 &lt;- (int.null[[1]][1, 2] + int.null[[1]][2, 1]) / 2
      prob.null.01 &lt;- c(prob.null.01, mean.null.01)
    }
    prob.ratio.00 &lt;- prob.est.00 / prob.null.00  # ratio of est. and null hyp
    prob.ratio.01 &lt;- prob.est.01 / prob.null.01
    prob.ratio.11 &lt;- prob.est.11 / prob.null.11
    probabilities[1, t] &lt;- mean(prob.ratio.00)   # mean estimated 00 tie prob
    probabilities[2, t] &lt;- mean(prob.ratio.01)   # mean estimated 01 tie prob
    probabilities[3, t] &lt;- mean(prob.ratio.11)   # mean estimated 11 tie prob
    ci.00 &lt;- t.test(prob.ratio.00, conf.level = 0.99)$conf.int
    ci.01 &lt;- t.test(prob.ratio.01, conf.level = 0.99)$conf.int
    ci.11 &lt;- t.test(prob.ratio.11, conf.level = 0.99)$conf.int
    probabilities[4, t] &lt;- ci.00[1]              # lower 00 conf. interval
    probabilities[5, t] &lt;- ci.01[1]              # lower 01 conf. interval
    probabilities[6, t] &lt;- ci.11[1]              # lower 11 conf. interval
    probabilities[7, t] &lt;- ci.00[2]              # upper 00 conf. interval
    probabilities[8, t] &lt;- ci.01[2]              # upper 01 conf. interval
    probabilities[9, t] &lt;- ci.11[2]              # upper 11 conf. interval
  }

  # create barplots from probability ratios and CIs
  require("gplots")
  bp &lt;- barplot2(probabilities[1:3, ], beside = TRUE, plot.ci = TRUE,
                 ci.l = probabilities[4:6, ], ci.u = probabilities[7:9, ],
                 col = c("tan", "tan2", "tan3"), ci.col = "grey40",
                 xlab = "Dyadic tie values", ylab = "Estimated Prob./Null Prob.")
  mtext(1, at = bp, text = c("(0,0)", "(0,1)", "(1,1)"), line = 0, cex = 0.5)


  ##### The following examples illustrate the behavior of  #####
  ##### the interpret function with undirected and/or      #####
  ##### bipartite graphs with or without structural zeros. #####

  library("statnet")
  library("btergm")

  # micro-level interpretation for undirected network with structural zeros
  set.seed(12345)
  mat &lt;- matrix(rbinom(400, 1, 0.1), nrow = 20, ncol = 20)
  mat[1, 5] &lt;- 1
  mat[10, 7] &lt;- 1
  mat[15, 3] &lt;- 1
  mat[18, 4] &lt; 1
  nw &lt;- network(mat, directed = FALSE, bipartite = FALSE)
  cv &lt;- matrix(rnorm(400), nrow = 20, ncol = 20)
  offsetmat &lt;- matrix(rbinom(400, 1, 0.1), nrow = 20, ncol = 20)
  offsetmat[1, 5] &lt;- 1
  offsetmat[10, 7] &lt;- 1
  offsetmat[15, 3] &lt;- 1
  offsetmat[18, 4] &lt; 1
  model &lt;- ergm(nw ~ edges + kstar(2) + edgecov(cv) + offset(edgecov(offsetmat)),
                offset.coef = -Inf)
  summary(model)

  # tie-level interpretation (note that dyad interpretation would not make any
  # sense in an undirected network):
  interpret(model, type = "tie", i = 1, j = 2)  # 0.28 (= normal dyad)
  interpret(model, type = "tie", i = 1, j = 5)  # 0.00 (= structural zero)

  # node-level interpretation; note the many 0 probabilities due to the
  # structural zeros; also note the warning message that the probabilities may
  # be slightly imprecise because -Inf needs to be approximated by some large
  # negative number (-9e8):
  interpret(model, type = "node", i = 1, j = 3:5)

  # repeat the same exercise for a directed network
  nw &lt;- network(mat, directed = TRUE, bipartite = FALSE)
  model &lt;- ergm(nw ~ edges + istar(2) + edgecov(cv) + offset(edgecov(offsetmat)),
                offset.coef = -Inf)
  interpret(model, type = "tie", i = 1, j = 2)  # 0.13 (= normal dyad)
  interpret(model, type = "tie", i = 1, j = 5)  # 0.00 (= structural zero)
  interpret(model, type = "dyad", i = 1, j = 2)  # results for normal dyad
  interpret(model, type = "dyad", i = 1, j = 5)  # results for i-&gt;j struct. zero
  interpret(model, type = "node", i = 1, j = 3:5)

  # micro-level interpretation for bipartite graph with structural zeros
  set.seed(12345)
  mat &lt;- matrix(rbinom(200, 1, 0.1), nrow = 20, ncol = 10)
  mat[1, 5] &lt;- 1
  mat[10, 7] &lt;- 1
  mat[15, 3] &lt;- 1
  mat[18, 4] &lt; 1
  nw &lt;- network(mat, directed = FALSE, bipartite = TRUE)
  cv &lt;- matrix(rnorm(200), nrow = 20, ncol = 10)  # some covariate
  offsetmat &lt;- matrix(rbinom(200, 1, 0.1), nrow = 20, ncol = 10)
  offsetmat[1, 5] &lt;- 1
  offsetmat[10, 7] &lt;- 1
  offsetmat[15, 3] &lt;- 1
  offsetmat[18, 4] &lt; 1
  model &lt;- ergm(nw ~ edges + b1star(2) + edgecov(cv)
                + offset(edgecov(offsetmat)), offset.coef = -Inf)
  summary(model)

  # tie-level interpretation; note the index for the second mode starts with 21
  interpret(model, type = "tie", i = 1, j = 21)

  # dyad-level interpretation does not make sense because network is undirected;
  # node-level interpretation prints warning due to structural zeros, but
  # computes the correct probabilities (though slightly imprecise because -Inf
  # is approximated by some small number:
  interpret(model, type = "node", i = 1, j = 21:25)

  # compute all dyadic probabilities
  dyads &lt;- edgeprob(model)
  dyads

## End(Not run)

</code></pre>

<hr>
<h2 id='knecht'>Longitudinal classroom friendship network and behavior (Andrea Knecht)</h2><span id='topic+knecht'></span><span id='topic+friendship'></span><span id='topic+demographics'></span><span id='topic+primary'></span><span id='topic+delinquency'></span><span id='topic+alcohol'></span><span id='topic+advice'></span>

<h3>Description</h3>

<p>Longitudinal classroom friendship network and behavior (Andrea Knecht).
</p>


<h3>Format</h3>

<p>Note: the data have to be transformed before they can be used with
<span class="pkg">btergm</span> and related packages (see examples below).
</p>

<dl>
<dt><code>friendship</code></dt><dd><p>is a list of adjacency matrices at four time
points, containing friendship nominations of the column node by the row
node. The following values are used: <code>0</code> = no, <code>1</code> = yes,
<code>NA</code> = missing, <code>10</code> = not a member of the classroom (structural
zero).</p>
</dd>
<dt><code>demographics</code></dt><dd><p>is a data frame with 26 rows (the pupils) and
four demographic variables about the pupils:</p>
</dd> </dl>
 <ul>
<li><p><code>sex</code>
(<code>1</code> = girl, <code>2</code> = boy) </p>
</li>
<li><p><code>age</code> (in years)
</p>
</li>
<li><p><code>ethnicity</code> (<code>1</code> = Dutch, <code>2</code> = other, <code>0</code> =
missing) </p>
</li>
<li><p><code>religion</code> (<code>1</code> = Christian, <code>2</code> =
non-religious, <code>3</code> = non-Christian religion, <code>0</code> = missing) </p>
</li></ul>

<dl>
<dt><code>primary</code></dt><dd><p>is a 26 x 26 matrix indicating whether two pupils
attended the same primary school. <code>0</code> = no, <code>1</code> = yes.</p>
</dd>
<dt><code>delinquency</code></dt><dd><p>is a data frame with 26 rows (the pupils) and
four columns (the four time steps). It contains the rounded average of four
items (stealing, vandalizing, fighting, graffiti).  Categories: frequency
over last three months, <code>1</code> = never, <code>2</code> = once, <code>3</code> = 2&ndash;4
times, <code>4</code> = 5&ndash;10 times, <code>5</code> = more than 10 times; <code>0</code> =
missing.</p>
</dd>
<dt><code>alcohol</code></dt><dd><p>is a data frame with 26 rows (the pupils) and 3
columns (waves 2, 3, and 4). It contains data on alcohol use (&ldquo;How
often did you drink alcohol with friends in the last three months?&rdquo;).
Categories: <code>1</code> = never, <code>2</code> = once, <code>3</code> = 2&ndash;4 times,
<code>4</code> = 5&ndash;10 times, <code>5</code> = more than 10 times; <code>0</code> = missing.</p>
</dd>
<dt><code>advice</code></dt><dd><p>is a data frame with one variable, &ldquo;school
advice&rdquo;, the assessment given at the end of primary school about the school
capabilities of the pupil (<code>4</code> = low, <code>8</code> = high, <code>0</code> =
missing)</p>
</dd>
</dl>



<h3>Details</h3>

<p>The Knecht dataset contains the friendship network of 26 pupils in a Dutch
school class measured at four time points along with several demographic and
behavioral covariates like age, sex, ethnicity, religion, delinquency,
alcohol consumption, primary school co-attendance, and school advice. Some
of these covariates are constant while others vary over time.
</p>
<p>The full dataset (see Knecht 2006 and 2008) contains a large number of
classrooms while the dataset presented here is an excerpt based on one
single classroom. This excerpt was first used in a tutorial for the software
<span class="pkg">Siena</span> and the corresponding R package <span class="pkg">RSiena</span> (Snijders, Steglich
and van de Bunt 2010). The following description was largely copied from the
original data description provided on the homepage of the <span class="pkg">Siena</span>
project (see below for the URL).
</p>
<p>The data were collected between September 2003 and June 2004 by Andrea
Knecht, supervised by Chris Baerveldt, at the Department of Sociology of the
University of Utrecht (NL). The entire study is reported in Knecht (2008).
The project was funded by the Netherlands Organisation for Scientific
Research NWO, grant 401-01-554. The 26 students were followed over their
first year at secondary school during which friendship networks as well as
other data were assessed at four time points at intervals of three months.
There were 17 girls and 9 boys in the class, aged 11&ndash;13 at the beginning of
the school year. Network data were assessed by asking students to indicate
up to twelve classmates which they considered good friends. Delinquency is
defined as a rounded average over four types of minor delinquency (stealing,
vandalism, graffiti, and fighting), measured in each of the four waves of
data collection. The five-point scale ranged from &lsquo;never&rsquo; to 'more than 10
times', and the distribution is highly skewed. In a range of 1&ndash;5, the mode
was 1 at all four waves, the average rose over time from 1.4 to 2.0, and the
value 5 was never observed.
</p>


<h3>Source</h3>

<p>The data were gathered by Andrea Knecht, as part of her PhD
research, building on methods developed by Chris Baerveldt, initiator and
supervisor of the project. The project is funded by the Netherlands
Organisation for Scientific Research NWO, grant 401-01-554, and is part of
the research program &quot;Dynamics of Networks and Behavior&quot; with principle
investigator Tom A. B. Snijders.
</p>

<ul>
<li><p> Complete original data:
<a href="https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:48665">https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:48665</a>
</p>
</li>
<li><p> This excerpt in Siena format:
<a href="http://www.stats.ox.ac.uk/~snijders/siena/klas12b.zip">http://www.stats.ox.ac.uk/~snijders/siena/klas12b.zip</a>
</p>
</li>
<li><p> Siena dataset description:
<a href="http://www.stats.ox.ac.uk/~snijders/siena/tutorial2010_data.htm">http://www.stats.ox.ac.uk/~snijders/siena/tutorial2010_data.htm</a>
</p>
</li></ul>

<p>Permission to redistribute this dataset along with this package was granted
by Andrea Knecht on April 17, 2014. Questions about the data or the original
study should be directed to her.
</p>


<h3>References</h3>

<p>Knecht, Andrea (2006): <em>Networks and Actor Attributes in Early
Adolescence</em> [2003/04]. Utrecht, The Netherlands Research School ICS,
Department of Sociology, Utrecht University. (ICS-Codebook no. 61).
</p>
<p>Knecht, Andrea (2008): <em>Friendship Selection and Friends' Influence.
Dynamics of Networks and Actor Attributes in Early Adolescence</em>. PhD
Dissertation, University of Utrecht. <a href="https://dspace.library.uu.nl/handle/1874/25950">https://dspace.library.uu.nl/handle/1874/25950</a>.
</p>
<p>Knecht, Andrea, Tom A. B. Snijders, Chris Baerveldt, Christian E.  G.
Steglich, and Werner Raub (2010): Friendship and Delinquency: Selection and
Influence Processes in Early Adolescence.  <em>Social Development</em> 19(3):
494&ndash;514. <a href="https://doi.org/10.1111/j.1467-9507.2009.00564.x">doi:10.1111/j.1467-9507.2009.00564.x</a>.
</p>
<p>Leifeld, Philip and Skyler J. Cranmer (2019): A Theoretical and Empirical
Comparison of the Temporal Exponential Random Graph Model and the Stochastic
Actor-Oriented Model. Network Science 7(1): 20&ndash;51.
<a href="https://doi.org/10.1017/nws.2018.26">doi:10.1017/nws.2018.26</a>.
</p>
<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>
<p>Snijders, Tom A. B., Christian E. G. Steglich, and Gerhard G. van de Bunt
(2010): Introduction to Actor-Based Models for Network Dynamics.
<em>Social Networks</em> 32: 44&ndash;60. <a href="https://doi.org/10.1016/j.socnet.2009.02.004">doi:10.1016/j.socnet.2009.02.004</a>.
</p>
<p>Steglich, Christian E. G. and Andrea Knecht (2009): Die statistische Analyse
dynamischer Netzwerkdaten. In: Stegbauer, Christian and Roger Haeussling
(editors), <em>Handbuch der Netzwerkforschung</em>, Wiesbaden: Verlag fuer
Sozialwissenschaften.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# ====================================================================
# The following example was taken from the JSS article about btergm
# that is referenced above (Leifeld, Cranmer and Desmarais 2018).
# ====================================================================

require("texreg")
require("sna")
require("btergm")
require("RSiena")
data("knecht")

# step 1: make sure the network matrices have node labels
for (i in 1:length(friendship)) {
  rownames(friendship[[i]]) &lt;- 1:nrow(friendship[[i]])
  colnames(friendship[[i]]) &lt;- 1:ncol(friendship[[i]])
}
rownames(primary) &lt;- rownames(friendship[[1]])
colnames(primary) &lt;- colnames(friendship[[1]])
sex &lt;- demographics$sex
names(sex) &lt;- 1:length(sex)

# step 2: imputation of NAs and removal of absent nodes:
friendship &lt;- handleMissings(friendship, na = 10, method = "remove")
friendship &lt;- handleMissings(friendship, na = NA, method = "fillmode")

# step 3: add nodal covariates to the networks
for (i in 1:length(friendship)) {
  s &lt;- adjust(sex, friendship[[i]])
  friendship[[i]] &lt;- network(friendship[[i]])
  friendship[[i]] &lt;- set.vertex.attribute(friendship[[i]], "sex", s)
  idegsqrt &lt;- sqrt(degree(friendship[[i]], cmode = "indegree"))
  friendship[[i]] &lt;- set.vertex.attribute(friendship[[i]],
      "idegsqrt", idegsqrt)
  odegsqrt &lt;- sqrt(degree(friendship[[i]], cmode = "outdegree"))
  friendship[[i]] &lt;- set.vertex.attribute(friendship[[i]],
      "odegsqrt", odegsqrt)
}
sapply(friendship, network.size)

# step 4: plot the networks
pdf("knecht.pdf")
par(mfrow = c(2, 2), mar = c(0, 0, 1, 0))
for (i in 1:length(friendship)) {
  plot(network(friendship[[i]]), main = paste("t =", i),
  usearrows = TRUE, edge.col = "grey50")
}
dev.off()

# step 5: estimate TERGMS without and with temporal dependencies
model.2a &lt;- btergm(friendship ~ edges + mutual + ttriple +
    transitiveties + ctriple + nodeicov("idegsqrt") +
    nodeicov("odegsqrt") + nodeocov("odegsqrt") +
    nodeofactor("sex") + nodeifactor("sex") + nodematch("sex") +
    edgecov(primary), R = 100)

model.2b &lt;- btergm(friendship ~ edges + mutual + ttriple +
    transitiveties + ctriple + nodeicov("idegsqrt") +
    nodeicov("odegsqrt") + nodeocov("odegsqrt") +
    nodeofactor("sex") + nodeifactor("sex") + nodematch("sex") +
    edgecov(primary) + delrecip + memory(type = "stability"),
    R = 100)

# step 6: alternatively, estimate via MCMC-MLE:
model.2d &lt;- mtergm(friendship ~ edges + mutual + ttriple +
    transitiveties + ctriple + nodeicov("idegsqrt") +
    nodeicov("odegsqrt") + nodeocov("odegsqrt") +
    nodeofactor("sex") + nodeifactor("sex") + nodematch("sex") +
    edgecov(primary) + delrecip + memory(type = "stability"),
    control = control.ergm(MCMC.samplesize = 5000, MCMC.interval = 2000))

# step 7: GOF assessment with out-of-sample prediction
# (note the commentaries and corrections at
#  https://doi.org/10.1017/nws.2022.7 and
#  https://doi.org/10.1017/nws.2022.6)
model.2e &lt;- btergm(friendship[1:3] ~ edges + mutual + ttriple +
    transitiveties + ctriple + nodeicov("idegsqrt") +
    nodeicov("odegsqrt") + nodeocov("odegsqrt") +
    nodeofactor("sex") + nodeifactor("sex") + nodematch("sex") +
    edgecov(primary) + delrecip + memory(type = "stability"),
    R = 100)

gof.2e &lt;- gof(model.2e, nsim = 100, target = friendship[[4]],
    formula = friendship[3:4] ~ edges + mutual + ttriple +
    transitiveties + ctriple + nodeicov("idegsqrt") +
    nodeicov("odegsqrt") + nodeocov("odegsqrt") +
    nodeofactor("sex") + nodeifactor("sex") + nodematch("sex") +
    edgecov(primary) + delrecip + memory(type = "stability"),
    coef = coef(model.2b), statistics = c(esp, dsp, geodesic,
    deg, triad.undirected, rocpr))
pdf("gof-2e.pdf", width = 8, height = 6)
plot(gof.2e)
dev.off()

## End(Not run)
</code></pre>

<hr>
<h2 id='marginalplot'>Plot marginal effects for two-way interactions in (T)ERGMs</h2><span id='topic+marginalplot'></span>

<h3>Description</h3>

<p>Plot marginal effects for two-way interactions in (T)ERGMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>marginalplot(
  model,
  var1,
  var2,
  inter,
  ci = 0.95,
  rug = FALSE,
  point = FALSE,
  structzeromat = NULL,
  zeroline = TRUE,
  color = "black",
  xlab = NULL,
  ylab = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="marginalplot_+3A_model">model</code></td>
<td>
<p>An <code>ergm</code> object as generated by the <span class="pkg">ergm</span> package.
Note that marginal effects plots cannot be created for <code>btergm</code>
objects because the variance-covariance matrix is not valid. However, it
should be possible to apply the <code>marginalplot</code> function to
MCMC-MLE-estimated TERGMs because the <code>ergm</code> object is stored in the
<code>ergm</code> slot of an <code>mtergm</code> object. To do this, supply the
<code>ergm</code> object instead of the <code>mtergm</code> object (e.g.,
<code>marginalplot(mtergmobject@ergm)</code>).</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_var1">var1</code></td>
<td>
<p>Name of the first main variable. This is the focal variable.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_var2">var2</code></td>
<td>
<p>Name of the second main variable. This is the conditioning
variable.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_inter">inter</code></td>
<td>
<p>Name of the interaction effect.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_ci">ci</code></td>
<td>
<p>Significance level.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_rug">rug</code></td>
<td>
<p>Display the distribution of the conditioning variable at the
bottom of the plot?</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_point">point</code></td>
<td>
<p>Display error bars for the levels of the conditioning variable
(instead of a continuous curve)?</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_structzeromat">structzeromat</code></td>
<td>
<p>An optional matrix object which indicates dyads that
should be deleted prior to the calculation of the confidence interval for
the marginal effect curve. This is useful when such a matrix was used to
indicate structural zeros during estimation. In this event, the dyads
characterized by structural zeros are not allowed to be tied, therefore
they should be removed from the set of dyads used for the calculation of
marginal effects. The matrix should contain ones for structural zeros and
zeros for entries that should be used.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_zeroline">zeroline</code></td>
<td>
<p>Draw a horizontal line to indicate zero for the first main
variable?</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_color">color</code></td>
<td>
<p>Color of the curve, confidence interval, and distribution.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_xlab">xlab</code></td>
<td>
<p>Axis label for the second (conditioning) variable.</p>
</td></tr>
<tr><td><code id="marginalplot_+3A_ylab">ylab</code></td>
<td>
<p>Axis label for the first (focal) variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>marginalplot</code> function creates marginal effects plots for ERGMs
with interaction effects. The user has to supply the <code>ergm</code> object and
the coefficient names of the first main variable, the second main variable,
and the interaction term as stored in the coefficients vector inside the
<code>ergm</code> object. It is possible to draw continuous curves or discrete
error bars depending on the nature of the data (using the <code>point</code>
argument). The distribution of the second (conditioning) variable can be
plotted at the bottom of the viewport using the <code>rug</code> argument.
</p>
<p>The resulting marginal effects plot is a <code>ggplot2</code> plot. This means it
can be extended by plotting additional elements and using themes.
</p>


<h3>See Also</h3>

<p>Other interpretation: 
<code><a href="#topic+edgeprob">edgeprob</a>()</code>,
<code><a href="#topic+interpret">interpret</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# data preparation
data("florentine")
n &lt;- network.size(flobusiness)
wealth &lt;- get.vertex.attribute(flobusiness, "wealth")
priorates &lt;- get.vertex.attribute(flobusiness, "priorates")
wealth.icov &lt;- matrix(rep(wealth, n), ncol = n, byrow = TRUE)
priorates.icov &lt;- matrix(rep(priorates, n), ncol = n, byrow = TRUE)
interac &lt;- wealth.icov * priorates.icov

# estimate model with interaction effect
model &lt;- ergm(flobusiness ~ edges + esp(1) + edgecov(wealth.icov)
                + edgecov(priorates.icov) + edgecov(interac))

# plot the interaction (note the additional optional ggplot2 elements)
marginalplot(model, var1 = "edgecov.wealth.icov",
             var2 = "edgecov.priorates.icov", inter = "edgecov.interac",
             color = "darkred", rug = TRUE, point = FALSE,
             xlab = "Priorates", ylab = "Wealth") +
  ggplot2::theme_bw() +
  ggplot2::ggtitle("Interaction effect")

## End(Not run)

</code></pre>

<hr>
<h2 id='mtergm'>Estimate a TERGM by MCMC-MLE</h2><span id='topic+mtergm'></span>

<h3>Description</h3>

<p>Estimate a TERGM by Markov Chain Monte Carlo Maximum Likelihood Estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtergm(formula, constraints = ~., returndata = FALSE, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtergm_+3A_formula">formula</code></td>
<td>
<p>Formula for the TERGM. Model construction works like in the
<span class="pkg">ergm</span> package with the same model terms etc. (for a list of terms, see
<code>help("<a href="ergm.html#topic+ergm-terms">ergm-terms</a>")</code>). The networks to be modeled on the
left-hand side of the equation must be given either as a list of network
objects with more recent networks last (i.e., chronological order) or as a
list of matrices with more recent matrices at the end. <code>dyadcov</code> and
<code>edgecov</code> terms accept time-independent covariates (as <code>network</code>
or <code>matrix</code> objects) or time-varying covariates (as a list of networks
or matrices with the same length as the list of networks to be modeled).</p>
</td></tr>
<tr><td><code id="mtergm_+3A_constraints">constraints</code></td>
<td>
<p>Constraints of the ERGM. See <code><a href="ergm.html#topic+ergm">ergm</a></code> for
details.</p>
</td></tr>
<tr><td><code id="mtergm_+3A_returndata">returndata</code></td>
<td>
<p>Return the processed input data instead of estimating and
returning the model? In the <code>btergm</code> case, this will return a data
frame with the dyads of the dependent variable/network and the change
statistics for all covariates. In the <code>mtergm</code> case, this will return
a list object with the blockdiagonal network object for the dependent
variable and blockdiagonal matrices for all dyadic covariates and the
offset matrix for the structural zeros.</p>
</td></tr>
<tr><td><code id="mtergm_+3A_verbose">verbose</code></td>
<td>
<p>Print details about data preprocessing and estimation
settings.</p>
</td></tr>
<tr><td><code id="mtergm_+3A_...">...</code></td>
<td>
<p>Further arguments to be handed over to the
<code><a href="ergm.html#topic+ergm">ergm</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>mtergm</code> function computes TERGMs by MCMC MLE (or MPLE with
uncorrected standard errors) via blockdiagonal matrices and structural zeros.
It acts as a wrapper for the <span class="pkg">ergm</span> package. The <code>btergm</code> function
is faster than the <code>mtergm</code> function but is only asymptotically unbiased
the longer the time series. The <code>mtergm</code> function yields unbiased
estimates and standard errors but may suffer from degeneracy if the model is
not specified in good keeping with the true data-generating process.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld, Skyler J. Cranmer, Bruce A. Desmarais
</p>


<h3>References</h3>

<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2017):
Temporal Exponential Random Graph Models with btergm: Estimation and
Bootstrap Confidence Intervals. <em>Journal of Statistical Software</em>
83(6): 1-36. <a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+btergm">btergm</a></code> <code><a href="#topic+tbergm">tbergm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("network")
set.seed(5)

networks &lt;- list()
for (i in 1:10) {              # create 10 random networks with 10 actors
  mat &lt;- matrix(rbinom(100, 1, .25), nrow = 10, ncol = 10)
  diag(mat) &lt;- 0               # loops are excluded
  nw &lt;- network::network(mat)  # create network object
  networks[[i]] &lt;- nw          # add network to the list
}

covariates &lt;- list()
for (i in 1:10) {              # create 10 matrices as covariate
  mat &lt;- matrix(rnorm(100), nrow = 10, ncol = 10)
  covariates[[i]] &lt;- mat       # add matrix to the list
}

## Not run: 
fit2 &lt;- mtergm(networks ~ edges + istar(2) + edgecov(covariates))
summary(fit2)

## End(Not run)

# For examples with real data, see help("knecht") or help("alliances").

</code></pre>

<hr>
<h2 id='mtergm-class'>An S4 Class to represent a fitted TERGM by MCMC-MLE</h2><span id='topic+mtergm-class'></span><span id='topic+show+2Cmtergm-method'></span><span id='topic+coef+2Cmtergm-method'></span><span id='topic+nobs+2Cmtergm-method'></span><span id='topic+timesteps.mtergm'></span><span id='topic+summary+2Cmtergm-method'></span>

<h3>Description</h3>

<p>An S4 class to represent a fitted TERGM by MCMC-MLE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'mtergm'
show(object)

## S4 method for signature 'mtergm'
coef(object, invlogit = FALSE, ...)

## S4 method for signature 'mtergm'
nobs(object)

timesteps.mtergm(object)

## S4 method for signature 'mtergm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtergm-class_+3A_object">object</code></td>
<td>
<p>An <code>mtergm</code> object.</p>
</td></tr>
<tr><td><code id="mtergm-class_+3A_invlogit">invlogit</code></td>
<td>
<p>Apply inverse logit transformation to the estimates and/or
confidence intervals? That is, <code class="reqn">\frac{1}{1 + \exp(-x)}</code>, where <code class="reqn">x</code>
is the respective value.</p>
</td></tr>
<tr><td><code id="mtergm-class_+3A_...">...</code></td>
<td>
<p>Currently not in use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mtergm</code> objects result from MCMC-MLE-based estimation of a TERGM via
the <code><a href="#topic+mtergm">mtergm</a></code> function. They contain the coefficients, standard
errors, and p-values, among other details.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>show(mtergm)</code>: Show the coefficients of an <code>mtergm</code> object.
</p>
</li>
<li> <p><code>coef(mtergm)</code>: Return the coefficients of an <code>mtergm</code> object.
</p>
</li>
<li> <p><code>nobs(mtergm)</code>: Return the coefficients of an <code>mtergm</code> object.
</p>
</li>
<li> <p><code>timesteps.mtergm()</code>: Return the number of time steps saved in an
<code>mtergm</code> object.
</p>
</li>
<li> <p><code>summary(mtergm)</code>: Return the coefficients of an <code>mtergm</code> object.
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>coef</code></dt><dd><p>Object of class <code>"numeric"</code>. The coefficients.</p>
</dd>
<dt><code>se</code></dt><dd><p>Object of class <code>"numeric"</code>. The standard errors.</p>
</dd>
<dt><code>pval</code></dt><dd><p>Object of class <code>"numeric"</code>. The p-values.</p>
</dd>
<dt><code>nobs</code></dt><dd><p>Object of class <code>"numeric"</code>. Number of observations.</p>
</dd>
<dt><code>time.steps</code></dt><dd><p>Object of class <code>"numeric"</code>. Number of time steps.</p>
</dd>
<dt><code>formula</code></dt><dd><p>Object of class <code>"formula"</code>. The original model formula
(without indices for the time steps).</p>
</dd>
<dt><code>formula2</code></dt><dd><p>The revised formula with the object references after applying
the <code><a href="#topic+tergmprepare">tergmprepare</a></code> function.</p>
</dd>
<dt><code>auto.adjust</code></dt><dd><p>Object of class <code>"logical"</code>. Indicates whether
automatic adjustment of dimensions was done before estimation.</p>
</dd>
<dt><code>offset</code></dt><dd><p>Object of class <code>"logical"</code>. Indicates whether an offset
matrix with structural zeros was used.</p>
</dd>
<dt><code>directed</code></dt><dd><p>Object of class <code>"logical"</code>. Are the dependent networks
directed?</p>
</dd>
<dt><code>bipartite</code></dt><dd><p>Object of class <code>"logical"</code>. Are the dependent networks
bipartite?</p>
</dd>
<dt><code>estimate</code></dt><dd><p>Estimate: either MLE or MPLE.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Log likelihood of the MLE.</p>
</dd>
<dt><code>aic</code></dt><dd><p>Akaike's Information Criterion.</p>
</dd>
<dt><code>bic</code></dt><dd><p>Bayesian Information Criterion.</p>
</dd>
<dt><code>ergm</code></dt><dd><p>The original <code>ergm</code> object as estimated by the
<code><a href="ergm.html#topic+ergm">ergm</a></code> function in the <span class="pkg">ergm</span> package.</p>
</dd>
<dt><code>nvertices</code></dt><dd><p>Number of vertices.</p>
</dd>
<dt><code>data</code></dt><dd><p>The data after processing by the <code><a href="#topic+tergmprepare">tergmprepare</a></code>
function.</p>
</dd>
</dl>


<h3>Author(s)</h3>

<p>Philip Leifeld
</p>


<h3>See Also</h3>

<p>Other tergm-classes: 
<code><a href="#topic+btergm-class">btergm-class</a></code>,
<code><a href="#topic+createBtergm">createBtergm</a>()</code>,
<code><a href="#topic+createMtergm">createMtergm</a>()</code>,
<code><a href="#topic+createTbergm">createTbergm</a>()</code>,
<code><a href="#topic+tbergm-class">tbergm-class</a></code>
</p>

<hr>
<h2 id='simulate.btergm'>Simulate Networks from a <code>btergm</code> Object</h2><span id='topic+simulate.btergm'></span><span id='topic+simulate.mtergm'></span>

<h3>Description</h3>

<p>Simulate networks from a <code>btergm</code> object using MCMC sampler.
</p>
<p>Simulate networks from an <code>mtergm</code> object using MCMC sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'btergm'
simulate(
  object,
  nsim = 1,
  seed = NULL,
  index = NULL,
  formula = getformula(object),
  coef = object@coef,
  verbose = TRUE,
  ...
)

## S3 method for class 'mtergm'
simulate(
  object,
  nsim = 1,
  seed = NULL,
  index = NULL,
  formula = getformula(object),
  coef = object@coef,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.btergm_+3A_object">object</code></td>
<td>
<p>A <code>btergm</code> or <code>mtergm</code> object, resulting from a call
of the <code><a href="#topic+btergm">btergm</a></code> or <code><a href="#topic+mtergm">mtergm</a></code> function.</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_nsim">nsim</code></td>
<td>
<p>The number of networks to be simulated. Note that for values
greater than one, a <code>network.list</code> object is returned, which can be
indexed just like a <code>list</code> object, for example <code>mynetworks[[1]]</code>
for the first simulated network in the object <code>mynetworks</code>.</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_seed">seed</code></td>
<td>
<p>Random number integer seed. See <a href="base.html#topic+Random">set.seed</a>.</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_index">index</code></td>
<td>
<p>Index of the network from which the new network(s) should be
simulated. The index refers to the list of response networks on the
left-hand side of the model formula. Note that more recent networks are
located at the end of the list. By default, the last (= most recent)
network is used.</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_formula">formula</code></td>
<td>
<p>A model formula from which the new network(s) should be
simulated. By default, the formula is taken from the <code>btergm</code> object.</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_coef">coef</code></td>
<td>
<p>A vector of parameter estimates. By default, the coefficients are
extracted from the given <code>btergm</code> object.</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_verbose">verbose</code></td>
<td>
<p>Print additional details while running the simulations?</p>
</td></tr>
<tr><td><code id="simulate.btergm_+3A_...">...</code></td>
<td>
<p>Further arguments are handed over to the
<code><a href="ergm.html#topic+simulate_formula">simulate_formula</a></code> function in the <span class="pkg">ergm</span> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>simulate.btergm</code> function is a wrapper for the
<code><a href="ergm.html#topic+simulate_formula">simulate_formula</a></code> function in the <span class="pkg">ergm</span> package (see
<code>help("simulate.ergm")</code>). It can be used to simulate new networks from a
<code>btergm</code> object. The <code>index</code> argument specifies from which of the
original networks the new network(s) should be simulated. For example, if
<code>object</code> is an estimation based on cosponsorship networks from the 99th
to the 107th Congress (as in Desmarais and Cranmer 2012), and the
cosponsorship network in the 108th Congress should be predicted using the
<code>simulate.btergm</code> function, then the argument <code>index = 9</code> should be
passed to the function because the network should be based on the 9th network
in the list (that is, the latest network, which is the cosponsorship network
for the 107th Congress). Note that all relevant objects (the networks and the
covariates) must be present in the workspace (as was the case during the
estimation of the model).
</p>


<h3>References</h3>

<p>Desmarais, Bruce A. and Skyler J. Cranmer (2012): Statistical Mechanics of
Networks: Estimation and Uncertainty. <em>Physica A</em> 391: 1865&ndash;1876.
<a href="https://doi.org/10.1016/j.physa.2011.10.018">doi:10.1016/j.physa.2011.10.018</a>.
</p>
<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2018): Temporal
Exponential Random Graph Models with btergm: Estimation and Bootstrap
Confidence Intervals. <em>Journal of Statistical Software</em> 83(6): 1&ndash;36.
<a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# fit a TERGM to some toy data
library("network")
set.seed(5)
networks &lt;- list()
for(i in 1:10){            # create 10 random networks with 10 actors
  mat &lt;- matrix(rbinom(100, 1, .25), nrow = 10, ncol = 10)
  diag(mat) &lt;- 0           # loops are excluded
  nw &lt;- network(mat)       # create network object
  networks[[i]] &lt;- nw      # add network to the list
}
covariates &lt;- list()
for (i in 1:10) {          # create 10 matrices as covariate
  mat &lt;- matrix(rnorm(100), nrow = 10, ncol = 10)
  covariates[[i]] &lt;- mat   # add matrix to the list
}
fit &lt;- btergm(networks ~ edges + istar(2) +
                edgecov(covariates), R = 100)

# simulate 12 new networks from the last (= 10th) time step
sim1 &lt;- simulate(fit, nsim = 12)

# simulate 1 network from the first time step
sim2 &lt;- simulate(fit, index = 1)

# simulate network from t = 5 with larger covariate coefficient
coefs &lt;- coef(fit)
coefs["edgecov.covariates[[i]]"] &lt;- 0.5
sim3 &lt;- simulate(fit, index = 5, coef = coefs)

## End(Not run)

</code></pre>

<hr>
<h2 id='tbergm'>Estimate a TERGM using Bayesian estimation</h2><span id='topic+tbergm'></span>

<h3>Description</h3>

<p>Estimate a TERGM using Bayesian estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tbergm(formula, returndata = FALSE, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tbergm_+3A_formula">formula</code></td>
<td>
<p>Formula for the TERGM. Model construction works like in the
<span class="pkg">ergm</span> package with the same model terms etc. (for a list of terms, see
<code>help("<a href="ergm.html#topic+ergm-terms">ergm-terms</a>")</code>). The networks to be modeled on the
left-hand side of the equation must be given either as a list of network
objects with more recent networks last (i.e., chronological order) or as a
list of matrices with more recent matrices at the end. <code>dyadcov</code> and
<code>edgecov</code> terms accept time-independent covariates (as <code>network</code>
or <code>matrix</code> objects) or time-varying covariates (as a list of networks
or matrices with the same length as the list of networks to be modeled).</p>
</td></tr>
<tr><td><code id="tbergm_+3A_returndata">returndata</code></td>
<td>
<p>Return the processed input data instead of estimating and
returning the model? In the <code>btergm</code> case, this will return a data
frame with the dyads of the dependent variable/network and the change
statistics for all covariates. In the <code>mtergm</code> case, this will return
a list object with the blockdiagonal network object for the dependent
variable and blockdiagonal matrices for all dyadic covariates and the
offset matrix for the structural zeros.</p>
</td></tr>
<tr><td><code id="tbergm_+3A_verbose">verbose</code></td>
<td>
<p>Print details about data preprocessing and estimation
settings.</p>
</td></tr>
<tr><td><code id="tbergm_+3A_...">...</code></td>
<td>
<p>Further arguments to be handed over to the
<code><a href="Bergm.html#topic+bergm">bergm</a></code> function in the <span class="pkg">Bergm</span> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>tbergm</code> function computes TERGMs by Bayesian estimation via
blockdiagonal matrices and structural zeros. It acts as a wrapper for the
<code><a href="Bergm.html#topic+bergm">bergm</a></code> function in the <span class="pkg">Bergm</span> package.
</p>


<h3>Author(s)</h3>

<p>Philip Leifeld
</p>


<h3>References</h3>

<p>Caimo, Alberto and Nial Friel (2012): Bergm: Bayesian Exponential
Random Graphs in R. <em>Journal of Statistical Software</em> 61(2): 1-25.
<a href="https://doi.org/10.18637/jss.v061.i02">doi:10.18637/jss.v061.i02</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+btergm">btergm</a></code> <code><a href="#topic+mtergm">mtergm</a></code>
</p>

<hr>
<h2 id='tbergm-class'>An S4 class to represent a fitted TERGM using Bayesian estimation</h2><span id='topic+tbergm-class'></span><span id='topic+show+2Ctbergm-method'></span><span id='topic+nobs+2Ctbergm-method'></span><span id='topic+timesteps.tbergm'></span><span id='topic+summary+2Ctbergm-method'></span>

<h3>Description</h3>

<p>An S4 class to represent a fitted TERGM using Bayesian estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'tbergm'
show(object)

## S4 method for signature 'tbergm'
nobs(object)

timesteps.tbergm(object)

## S4 method for signature 'tbergm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tbergm-class_+3A_object">object</code></td>
<td>
<p>A <code>tbergm</code> object.</p>
</td></tr>
<tr><td><code id="tbergm-class_+3A_...">...</code></td>
<td>
<p>Further arguments for the <code>summary</code> function in the
<span class="pkg">Bergm</span> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>tbergm</code> objects result from Bayesian estimation of a TERGM using the
<code><a href="#topic+tbergm">tbergm</a></code> function. They contain the original <code>bergm</code> object
and some additional information.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>show(tbergm)</code>: Show the coefficients of a <code>tbergm</code> object.
</p>
</li>
<li> <p><code>nobs(tbergm)</code>: Return the number of observations saved in a
<code>tbergm</code> object.
</p>
</li>
<li> <p><code>timesteps.tbergm()</code>: Return the number of time steps saved in a
<code>tbergm</code> object.
</p>
</li>
<li> <p><code>summary(tbergm)</code>: Summary of a fitted <code>tbergm</code> object.
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>time.steps</code></dt><dd><p>Object of class <code>"numeric"</code>. Number of time steps.</p>
</dd>
<dt><code>formula</code></dt><dd><p>Object of class <code>"formula"</code>. The original model formula
(without indices for the time steps).</p>
</dd>
<dt><code>formula2</code></dt><dd><p>The revised formula with the object references after applying
the <code><a href="#topic+tergmprepare">tergmprepare</a></code> function.</p>
</dd>
<dt><code>auto.adjust</code></dt><dd><p>Object of class <code>"logical"</code>. Indicates whether
automatic adjustment of dimensions was done before estimation.</p>
</dd>
<dt><code>offset</code></dt><dd><p>Object of class <code>"logical"</code>. Indicates whether an offset
matrix with structural zeros was used.</p>
</dd>
<dt><code>directed</code></dt><dd><p>Object of class <code>"logical"</code>. Are the dependent networks
directed?</p>
</dd>
<dt><code>bipartite</code></dt><dd><p>Object of class <code>"logical"</code>. Are the dependent networks
bipartite?</p>
</dd>
<dt><code>estimate</code></dt><dd><p>Estimate: <code>"bergm"</code> for Bayesian estimation.</p>
</dd>
<dt><code>bergm</code></dt><dd><p>The original <code>bergm</code> object as estimated by the
<code><a href="Bergm.html#topic+bergm">bergm</a></code> function in the <span class="pkg">Bergm</span> package.</p>
</dd>
<dt><code>nvertices</code></dt><dd><p>Number of vertices.</p>
</dd>
<dt><code>data</code></dt><dd><p>The data after processing by the <code><a href="#topic+tergmprepare">tergmprepare</a></code>
function.</p>
</dd>
</dl>


<h3>Author(s)</h3>

<p>Philip Leifeld
</p>


<h3>See Also</h3>

<p>Other tergm-classes: 
<code><a href="#topic+btergm-class">btergm-class</a></code>,
<code><a href="#topic+createBtergm">createBtergm</a>()</code>,
<code><a href="#topic+createMtergm">createMtergm</a>()</code>,
<code><a href="#topic+createTbergm">createTbergm</a>()</code>,
<code><a href="#topic+mtergm-class">mtergm-class</a></code>
</p>

<hr>
<h2 id='tergm-terms'>Temporal dependencies for TERGMs</h2><span id='topic+tergm-terms'></span><span id='topic+memory'></span><span id='topic+timecov'></span><span id='topic+delrecip'></span>

<h3>Description</h3>

<p>Network statistics that span multiple time points.
</p>
<p>Transform a covariate using a function of time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timecov(
  covariate,
  minimum = 1,
  maximum = length(covariate),
  transform = function(t) 1 + (0 * t) + (0 * t^2),
  onlytime = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tergm-terms_+3A_covariate">covariate</code></td>
<td>
<p>The list of networks or matrices for which to create a time
covariate. This can be the list of networks on the left-hand side of the
formula, in which case a time trend is created as a covariate list of
matrices, or it can be a list of networks or matrices that is used as a
dyadic covariate on the right-hand side of the formula, in which case an
interaction effect between the time trend and the covariate is created. If
used as a model term inside a formula, <code>covariate = NULL</code> is
permitted, in which case the networks on the left-hand side will be used to
form a time trend.</p>
</td></tr>
<tr><td><code id="tergm-terms_+3A_minimum">minimum</code>, <code id="tergm-terms_+3A_maximum">maximum</code></td>
<td>
<p>For time steps below the <code>minimum</code> value and
above the <code>maximum</code> value, the time covariate is set to 0. These
arguments can be used to create step-wise, discrete effects, for example to
use a value of 0 up to an external event and 1 from that event onwards in
order to control for influences of external events.</p>
</td></tr>
<tr><td><code id="tergm-terms_+3A_transform">transform</code></td>
<td>
<p>In the default case, edges are modeled as being linearly
increasingly important over time (i.e., a linear time trend). By tweaking
the <code>transform</code> function, arbitrary functional forms of time can be
tested. For example, <code>transform = sqrt</code> (for a geometrically
decreasing time effect), <code>transform = function(x) x^2</code> (for a
geometrically increasing time effect), <code>transform = function(t) t</code>
(for a linear time trend) or polynomial functional forms (e.g.,
<code>transform = function(t) 0 + (1 * t) + (1 * t^2)</code>) can be used.</p>
</td></tr>
<tr><td><code id="tergm-terms_+3A_onlytime">onlytime</code></td>
<td>
<p>If <code>TRUE</code>, return a time trend only. If <code>FALSE</code>,
return an interaction between the time trend and the covariate. Note that
the model term may need to be called twice or more inside a formula: one
time to create the time trend main effect and one time for each
interaction term; you also need to include the main effects for the
covariates separately using <code>edgecov</code> or similar terms.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In addition to the ERGM user terms that can be estimated within a single
network (see <a href="ergm.html#topic+ergm-terms">ergm-terms</a>), the <span class="pkg">btergm</span> package provides
additional model terms that can be used within a formula. These additional
statistics span multiple time periods and are therefore called &quot;temporal
dependencies.&quot; Examples include memory terms (i.e., positive autoregression,
dyadic stability, edge innovation, or edge loss), delayed reciprocity or
mutuality, and time covariates (i.e., functions of time or interactions with
time):
</p>

<dl>
<dt><code>delrecip(mutuality = FALSE, lag = 1)</code></dt><dd><p>The <code>delrecip</code> term
checks for delayed reciprocity. For example, if node <code>j</code> is tied to
node <code>i</code> at <code>t = 1</code>, does this lead to a reciprocation of that
tie back from <code>i</code> to <code>j</code> at <code>t = 2</code>? If
<code>mutuality = TRUE</code> is set, this extends not only to ties, but also
non-ties. That is, if <code>i</code> is not tied to <code>j</code> at <code>t = 1</code>,
will this lead to <code>j</code> not being tied to <code>i</code> at <code>t = 2</code>, in
addition to positively reciprocal patterns over time? The <code>lag</code>
argument controls the size of the temporal lag: with <code>lag = 1</code>,
reciprocity over one consecutive time period is checked. Note that as
<code>lag</code> increases, the number of time steps on the dependent variable
decreases.</p>
</dd>
<dt><code>memory(type = "stability", lag = 1)</code></dt><dd><p>Memory terms control for
the impact of a previous network on the current network. Four different
types of memory terms are available: positive autoregression
(<code>type = "autoregression"</code>) checks whether previous ties are carried
over to the current network; dyadic stability (<code>type = "stability"</code>)
checks whether both edges and non-edges are stable between the previous
and the current network; edge loss (<code>type = "loss"</code>) checks whether
ties in the previous network have been dissolved and no longer exist in
the current network; and edge innovation (<code>type = "innovation"</code>)
checks whether previously unconnected nodes have the tendency to become
tied in the current network. The <code>lag</code> argument accepts integer
values and controls whether the comparison is made with the previous
network (<code>lag = 1</code>), the pre-previous network (<code>lag = 2</code>) etc.
Note that as <code>lag</code> increases, the number of time steps on the
dependent variable decreases.</p>
</dd>
<dt><code>timecov(x = NULL, minimum = 1, maximum = NULL,
    transform = function(t) t)</code></dt><dd><p>The <code>timecov</code> model term checks for
linear or non-linear time trends with regard to edge formation.
Optionally, this can be combined with a covariate to create an
interaction effect between a dyadic covariate and time in order to test
whether the importance of a covariate increases or decreases over time.
In the default case, edges modeled as being linearly increasingly
important over time. By tweaking the <code>transform</code> function,
arbitrary functional forms of time can be tested. For example,
<code>transform = sqrt</code> (for a geometrically decreasing time effect),
<code>transform = function(x) x^2</code> (for a geometrically increasing time
effect), <code>transform = function(t) t</code> (for a linear time trend) or
polynomial functional forms (e.g., <code>0 + (1 * t) + (1 * t^2)</code>) can
be used. For time steps below the <code>minimum</code> value and above the
<code>maximum</code> value, the time covariate is set to 0. These arguments
can be used to create step-wise, discrete effects, for example to use a
value of 0 up to an external event and 1 from that event onwards in
order to control for influences of external events.</p>
</dd>
</dl>

<p>The <code>timecov</code> model term checks for linear or non-linear time trends
with regard to edge formation. Optionally, this can be combined with a
covariate to create an interaction effect between a dyadic covariate and time
in order to test whether the importance of a covariate increases or decreases
over time. The function can either be used in a formula with
<code><a href="#topic+btergm">btergm</a></code>, <code><a href="#topic+mtergm">mtergm</a></code>, or <code><a href="#topic+tbergm">tbergm</a></code>, or it
can be executed directly for manual inclusion of the results as a covariate.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>timecov()</code>: Time trends and temporal covariate interactions
</p>
</li></ul>


<h3>References</h3>

<p>Leifeld, Philip, Skyler J. Cranmer and Bruce A. Desmarais (2017):
Temporal Exponential Random Graph Models with btergm: Estimation and
Bootstrap Confidence Intervals. <em>Journal of Statistical Software</em>
83(6): 1-36. <a href="https://doi.org/10.18637/jss.v083.i06">doi:10.18637/jss.v083.i06</a>.
</p>

<hr>
<h2 id='tergmprepare'>Prepare data structure for TERGM estimation, including composition change</h2><span id='topic+tergmprepare'></span>

<h3>Description</h3>

<p>Prepare data structure for TERGM estimation, including composition change.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tergmprepare(formula, offset = TRUE, blockdiag = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tergmprepare_+3A_formula">formula</code></td>
<td>
<p>The original formula provided by the user, given the data
structures in the workspace.</p>
</td></tr>
<tr><td><code id="tergmprepare_+3A_offset">offset</code></td>
<td>
<p>Indicates whether absent nodes should be added where they are
missing (<code>offset = TRUE</code>) or removed where they are not missing
(<code>offset = FALSE</code>).</p>
</td></tr>
<tr><td><code id="tergmprepare_+3A_blockdiag">blockdiag</code></td>
<td>
<p>Should the time steps be arranged in a blockdiagonal matrix
for use with MCMC-MLE or Bayesian estimation (<code>blockdiag = TRUE</code>), or
should they be kept as items in a list for use with <code><a href="#topic+btergm">btergm</a></code>
(<code>blockdiag = FALSE</code>)?</p>
</td></tr>
<tr><td><code id="tergmprepare_+3A_verbose">verbose</code></td>
<td>
<p>Report details about dimension adjustment?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a helper function that adjusts the dimensions of networks or
covariates within a given time step to each other by removing nodes that are
not present across all objects within a time step or by adding nodes where
they are missing (and simultaneously adding entries to a list of structural
zero matrices to indicate their absence). It is not necessary to have
identical (numbers of) nodes across time steps as long as the dimensions of
the matrices, networks, and vectors match cross-sectionally within time
steps, given that temporal dependency terms like memory are interpreted as
dyadic covariates in a given time step. This helper function also creates
these dyadic covariate data structures for some of the custom temporal model
terms, such as <code>memory</code> and <code>delrecip</code>. Leifeld, Cranmer and
Desmarais (2018) contain additional details on composition change, dimension
adjustment of matrices, and temporal dependencies. Note that this function
should not normally be used by the end user. It is automatically called
internally by the estimation functions to make the dimensions of all objects
conformable to each other for estimation. Use this function only for
diagnostic purposes!
</p>


<h3>Value</h3>

<p>A list with the following slots:
</p>

<dl>
<dt>lhs.original</dt><dd><p>A character object containing the original name of the
object on the left-hand side of the formula provided by the user. This is
saved here because the formula is manipulated such that the left-hand
side of the formula contains a new item <code>networks[[i]]</code>.</p>
</dd>
<dt>networks</dt><dd><p>The list of networks on the left-hand side of the formula
after dimension adjustment, or a blockdiagonal network representing the
left-hand side of the formula after dimension adjustment if argument
<code>blockdiag = TRUE</code> was used.</p>
</dd>
<dt>num.vertices</dt><dd><p>The maximum number of nodes of any time point after
adjustment of dimensions.</p>
</dd>
<dt>directed</dt><dd><p>Are the networks directed?</p>
</dd>
<dt>bipartite</dt><dd><p>Are the networks bipartite?</p>
</dd>
<dt>form</dt><dd><p>The formula after manipulation and adjustment of the data,
including <code>networks[[i]]</code> on the left-hand side and an added offset
covariate on the right-hand side of the formula, in addition to added
indices for the covariate terms.</p>
</dd>
<dt>time.steps</dt><dd><p>The number of time steps of the dataset.</p>
</dd>
<dt>rhs.terms</dt><dd><p>The right-hand side of the formula after adjustment, as
a vector of <code>character</code> objects representing the terms.</p>
</dd>
<dt>covnames</dt><dd><p>A <code>character</code> vector containing the names of the
objects in which the networks and covariates are stored, according to the
manipulated formula. This includes <code>"networks"</code> (for the left-hand
side of the formula) and all objects containing exogenous covariates on
the right-hand side of the formula after manipulation.</p>
</dd>
<dt>...</dt><dd><p>Each of the covariates mentioned in the slot <code>covnames</code> is
stored as an element of the list, either as a list of matrices or
networks (if <code>blockdiag = FALSE</code>) or as a matrix or network object
(if <code>blockdiag = TRUE</code>).</p>
</dd>
<dt>auto.adjust</dt><dd><p>Did the function have to adjust the dimensions of the
networks or covariates at all?</p>
</dd>
<dt>nvertices</dt><dd><p>A matrix containing the number of nodes in the rows and
columns of each object at each time step, after adjustment.</p>
</dd>
<dt>offsmat</dt><dd><p>A list of offset covariate matrices or a large blockdiagonal
offset covariate matrix containing structural zeros. If
<code>offset = FALSE</code>, this matrix or list of matrices will contain only
zeros. If <code>offset = TRUE</code>, they will contain ones where nodes were
absent in the original data.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Philip Leifeld
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
