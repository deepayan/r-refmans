<!DOCTYPE html><html><head><title>Help for package dparser</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dparser}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dparse'><p>Create R-based Dparser tree walking function based on grammar</p></a></li>
<li><a href='#dparser-package'><p>A Scannerless GLR parser/parser generator</p></a></li>
<li><a href='#dparserFunction-class'><p>A S4 class for dparser functions</p></a></li>
<li><a href='#dpDefaultSkip'><p>Default skip function for darsing grammar</p></a></li>
<li><a href='#dpGetFile'><p>Get file for dparser arguments</p></a></li>
<li><a href='#dpIncludeDir'><p>Dparser C headers include directory</p></a></li>
<li><a href='#dpReload'><p>Reload the R dparser dll</p></a></li>
<li><a href='#dpRparse'><p>C code for R parser</p></a></li>
<li><a href='#dpVersion'><p>Version and repository for this dparser package.</p></a></li>
<li><a href='#gc.dparser'><p>Garbage collection for dpaser functions</p></a></li>
<li><a href='#mkdparse'><p>mkdparse dparser grammer c</p></a></li>
<li><a href='#show,dparserFunction-method'><p>Print the s4 object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Port of 'Dparser' Package</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.1-11</td>
</tr>
<tr>
<td>Imports:</td>
<td>digest, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rex, covr, testthat, knitr, devtools</td>
</tr>
<tr>
<td>Description:</td>
<td>A Scannerless GLR parser/parser generator.  Note that GLR standing for "generalized LR", where L stands for "left-to-right" and
   R stands for "rightmost (derivation)".  For more information see <a href="https://en.wikipedia.org/wiki/GLR_parser">https://en.wikipedia.org/wiki/GLR_parser</a>. This parser is based on the Tomita
   (1987) algorithm. (Paper can be found at <a href="https://aclanthology.org/P84-1073.pdf">https://aclanthology.org/P84-1073.pdf</a>).
   The original 'dparser' package documentation can be found at <a href="https://dparser.sourceforge.net/">https://dparser.sourceforge.net/</a>.  This allows you to add mini-languages to R (like
   rxode2's ODE mini-language Wang, Hallow, and James 2015 &lt;<a href="https://doi.org/10.1002%2Fpsp4.12052">doi:10.1002/psp4.12052</a>&gt;) or to parse other languages like 'NONMEM' to automatically translate
   them to R code.   To use this in your code, add a LinkingTo dparser in your DESCRIPTION file and instead of using #include &lt;dparse.h&gt; use
   #include &lt;dparser.h&gt;.  This also provides a R-based port of the make_dparser <a href="https://dparser.sourceforge.net/d/make_dparser.cat">https://dparser.sourceforge.net/d/make_dparser.cat</a> command called
   mkdparser().  Additionally you can parse an arbitrary grammar within R using the dparse() function, which works on most OSes and is mainly for grammar
   testing.  The fastest parsing, of course, occurs at the C level, and is suggested.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nlmixr2/dparser-R/issues/">https://github.com/nlmixr2/dparser-R/issues/</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://nlmixr2.github.io/dparser-R/">https://nlmixr2.github.io/dparser-R/</a>,
<a href="https://github.com/nlmixr2/dparser-R/">https://github.com/nlmixr2/dparser-R/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-07 16:23:25 UTC; matt</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthew Fidler [aut, cre],
  John Plevyak [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthew Fidler &lt;matthew.fidler@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-08 00:20:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='dparse'>Create R-based Dparser tree walking function based on grammar</h2><span id='topic+dparse'></span>

<h3>Description</h3>

<p>Note R-based dparser tree walking works on Windows (with R tools)
Mac, or Linux. Linking to arbitrary c grammars works on any
platform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dparse(
  grammar,
  start_state = 0,
  save_parse_tree = TRUE,
  partial_parses = FALSE,
  compare_stacks = TRUE,
  commit_actions_interval = 100,
  fixup = TRUE,
  fixup_ebnf = FALSE,
  nogreedy = FALSE,
  noheight = FALSE,
  use_file_name = TRUE,
  parse_size = 1024,
  verbose_level = 0,
  children_first = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dparse_+3A_grammar">grammar</code></td>
<td>
<p>Dparser grammar filename (must be a file with a &quot;.g&quot;
extension)</p>
</td></tr>
<tr><td><code id="dparse_+3A_start_state">start_state</code></td>
<td>
<p>Start State (default 0)</p>
</td></tr>
<tr><td><code id="dparse_+3A_save_parse_tree">save_parse_tree</code></td>
<td>
<p>Save Parse Tree (default TRUE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_partial_parses">partial_parses</code></td>
<td>
<p>Partial Parses (default FALSE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_compare_stacks">compare_stacks</code></td>
<td>
<p>Compare Stacks (default TRUE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_commit_actions_interval">commit_actions_interval</code></td>
<td>
<p>Commit Interval (default 100)</p>
</td></tr>
<tr><td><code id="dparse_+3A_fixup">fixup</code></td>
<td>
<p>Fix-up Internal Productions (default FALSE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_fixup_ebnf">fixup_ebnf</code></td>
<td>
<p>Fixup EBNF Productions (default FALSE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_nogreedy">nogreedy</code></td>
<td>
<p>No Greediness for Disambiguation (default FALSE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_noheight">noheight</code></td>
<td>
<p>No Height for Disambiguation (default FALSE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_use_file_name">use_file_name</code></td>
<td>
<p>Use File Name for syntax errors (default
TRUE)</p>
</td></tr>
<tr><td><code id="dparse_+3A_parse_size">parse_size</code></td>
<td>
<p>Parser size (default 1024)</p>
</td></tr>
<tr><td><code id="dparse_+3A_verbose_level">verbose_level</code></td>
<td>
<p>the level of verbosity when creating parser
(default 0)</p>
</td></tr>
<tr><td><code id="dparse_+3A_children_first">children_first</code></td>
<td>
<p>When TRUE, parse the children before the
parent (default TRUE).</p>
</td></tr>
<tr><td><code id="dparse_+3A_...">...</code></td>
<td>
<p>Parameters sent to <code><a href="#topic+mkdparse">mkdparse</a></code>, with the
exception of <code>use_r_header</code> which is forced to be
<code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that allows parsing of a file based on the
grammar supplied. This function would be able to
parse arbitrary grammars the way you may want with your own
user supplied function.
</p>


<h3>Garbage collection</h3>

<p>There are two user options that control if the dlls for the
grammars created by dparser will be deleted upon garbage
collection or R exit if they are not associated with any active
objects.  These are:
</p>

<dl>
<dt><code>dpaser.rm.unnamed.parser.dll</code>:</dt><dd><p>when <code>TRUE</code>, this remove parsers
that are created from strings, or other memory-based items in R.</p>
</dd>
<dt><code>dpaser.rm.unnamed.parser.dll</code>:</dt><dd><p>when <code>TRUE</code>, this
removes parsers created from grammar files.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+mkdparse">mkdparse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## This creates the R based parsing function.  It requires
## compilation and runs on most OSes, with the exception of solaris.
## Windows requires Rtools to be installed.
f &lt;- dparse(system.file("tran.g", package = "dparser"),children_first=FALSE)

## Once created, you may then use this function to parse an
## arbitrary syntax file.  For example:
f("
b       = -1
d/dt(X) = a*X + Y*Z;
d/dt(Y) = b*(Y - Z);
d/dt(Z) = -X*Y + c*Y - Z
if (t &lt; 0.02 | t &gt; 99.98){
    print
}
", function(name, value, pos, depth){
    ## This prints the name, value, position and depth passed to the
    ##parsing function.
    cat(sprintf("name:%s;value:%s;pos:%s;depth:%s\n", name, value, pos,
                 depth));
})

## You could use a better R parsing function; You could also use
## this as a starting place for your own C-based parser

</code></pre>

<hr>
<h2 id='dparser-package'>A Scannerless GLR parser/parser generator</h2><span id='topic+dparser'></span><span id='topic+dparser-package'></span>

<h3>Description</h3>

<p>This package is based on the C dparser
https://github.com/jplevyak/dparser
</p>


<h3>Details</h3>

<p>DParser is an simple but powerful tool for parsing.  You can
specify the form of the text to be parsed using a combination of
regular expressions and grammar productions.  Because of the
parsing technique (technically a scannerless GLR parser based on
the Tomita algorithm) there are no restrictions.  The grammar can
be ambiguous, right or left recursive, have any number of null
productions, and because there is no separate tokenizer, can
include whitespace in terminals and have terminals which are
prefixes of other terminals.  DParser handles not just well formed
computer languages and data files, but just about any wacky
situation that occurs in the real world.
</p>


<h3>Features</h3>


<ul>
<li><p> Powerful GLR parsing
</p>
</li>
<li><p> Simple EBNF-style grammars and regular expression terminals
</p>
</li>
<li><p> Priorities and associativities for token and rules
</p>
</li>
<li><p> Built-in error recovery
</p>
</li>
<li><p> Speculative actions (for semantic disambiguation)
</p>
</li>
<li><p> Auto-building of parse tree (optionally)
</p>
</li>
<li><p> Final actions as you go, or on the complete parse tree
</p>
</li>
<li><p> Tree walkers and default actions (multi-pass compilation support)
</p>
</li>
<li><p> Symbol table built for ambiguous parsing
</p>
</li>
<li><p> Partial parses, recursive parsing, parsing starting with any non-terminal
</p>
</li>
<li><p> Whitespace can be specified as a subgrammar
</p>
</li>
<li><p> External (C call interface) tokenizers and external terminal scanners
</p>
</li>
<li><p> Good asymptotically efficiency
</p>
</li>
<li><p> Comes with ANSI-C, Python and Verilog grammars
</p>
</li>
<li><p> Comes with full source
</p>
</li>
<li><p> Portable C for easy compilation and linking
</p>
</li>
<li><p> BSD license, so you can included it in your application without worrying about licensing
</p>
</li></ul>

<p>The result is natural grammars and powerful parsing.
</p>
<p>The R based tree parsing in <code><a href="#topic+dparse">dparse</a></code> creates dlls on
the fly based on C code. By default the echoing of the compile is
disabled, but you can change this by
<code>options(dparser.echo.compile=FALSE)</code>
</p>


<h3>Garbage collection</h3>

<p>There are two user options that control if the dlls for the
grammars created by dparser will be deleted upon garbage
collection or R exit if they are not associated with any active
objects.  These are:
</p>

<dl>
<dt><code>dpaser.rm.unnamed.parser.dll</code>:</dt><dd><p>when <code>TRUE</code>, this remove parsers
that are created from strings, or other memory-based items in R.</p>
</dd>
<dt><code>dpaser.rm.unnamed.parser.dll</code>:</dt><dd><p>when <code>TRUE</code>, this
removes parsers created from grammar files.</p>
</dd>
</dl>



<h3>Creating a Grammar for Parsing</h3>


<dl>
<dt>Grammar Comments:</dt><dd><p>Grammars can include C/C++ style comments
</p>
<p><b>Example:</b>
</p>
<pre>
// My first grammar
E: E '+' E | "[abc]";
/* is this right? */
</pre></dd>
<dt>Grammar Productions:</dt><dd>
<p>A production is the parts of your language your are trying to parse and are tpyically named.  See https://en.wikipedia.org/wiki/Top-down_parsing
</p>

<ul>
<li><p> The first production is the root of your grammar (what you
will be trying to parse).
</p>
</li>
<li><p> Productions start with the non-terminal being defined
followed by a colon ':', a set of right hand sides separated by
'|' (or) consisting of elements (non-terminals or terminals).
</p>
</li>
<li><p> Elements can be grouped with parens '(', and the normal
regular expression symbols can be used ('+' '*' '?' '|').
</p>
</li>
<li><p> Elements can be grouped with parens '(', and the normal
regular expression symbols can be used ('+' '*' '?' '|').
</p>
</li>
<li><p> Elements can be repeated using '@', for example elem@3 or
elem@1:3 for repeat 3 or between 1 and 3 times respectively.
</p>
</li></ul>

<p><b>Example:</b>
</p>
<pre>
 program: statements+ |  comment* (function |  procedure)?;
</pre>
<p><b>Note:</b> Instead of using '[' ']' for optional elements we
use the more familar and consistent '?' operator.  The square
brackets are reserved for speculative actions (below).
</p>
</dd>
<dt>Global C code in Grammars:</dt><dd>
<p>Since the main parsing of the language grammar is in C, intermixing C code with the grammar can be useful.
</p>
<ul>
<li><p> Global (or static) C code can be intermixed with productions by surrounding the code with brackets '{}'.</p>
</li></ul>

<p><b>Example:</b>
</p>
<pre>
  { void dr_s() { printf("Dr. S\n"); }
   S: 'the' 'cat' 'and' 'the' 'hat' { dr_s(); } | T;
   { void twain() { printf("Mark Twain\n"); }
       T: 'Huck' 'Finn' { twain(); };
</pre>
<p><b>Note:</b> When parsing the grammar using
<code><a href="#topic+mkdparse">mkdparse</a></code>, the option <code>use_r_header = TRUE</code> will
redefine <code>printf</code> to <code>Rprintf</code> to better
comply with R packages.
</p>
</dd>
<dt>Terminals</dt><dd>
<p>The terminals are the peices of the language that are being parsed, like language keywords.
</p>
<ul>
<li><p> Strings terminals are surrounded with single quotes.  For example:</p>
</li></ul>

<pre>
block: '{' statements* '}';
whileblock: 'while' '(' expression ')' block;
</pre>
<ul>
<li><p> Unicode literals can appear in strings or as charaters with U+ or u+.  For example:</p>
</li></ul>

<pre>
U+03c9 { printf("omega\n"); }
</pre>
</dd>
</dl>
<ul>
<li><p>  Regular expressions are surrounded with double quotes.  For example:</p>
</li></ul>

<pre>
hexint: "(0x|0X)[0-9a-fA-F]+[uUlL]?";
</pre>
<p><b>Note:</b>  only the simple regular expression operators are currently supported. This include parens, square parens, ranges, and '*', '+', '?'.
</p>
<ul>
<li><p> Terminal modifiers</p>
</li></ul>

<p>Terminals can contain embbed escape codes.  Including the standard
C escape codes, the codes \x and \d permit inserting hex and
decimal ASCII characters directly.
</p>
<p>Tokens can be given a name by appending the $name option.  This is useful when you have several
tokens which which represent the same string (e.g. ',').   For example,
</p>
<pre>
function_call: function '(' parameter ( ',' $name 'parameter_comma' parameter) ')';
</pre>
<p>It is now possible to use $0.symbol == ${string parameter_comma} to differentiate ParseNode ($0) between
a parameter comma node and say an initialization comma.
</p>
<p>Terminals ending in '/i' are case insensitive.  For example 'hi'/i
matches 'HI', 'Hi' and &quot;hI' in addition to 'hi'.
</p>
<ul>
<li><p> External (C) Scanners</p>
</li></ul>

<p>There are two types of external scanners, those which read a
single terminal, and those which are global (called for every
terminal).  Here is an example of a scanner for a single terminal.
Notice how it can be mixed with regular string terminals.
</p>
<pre>
{
    extern char *ops;
    extern void *ops_cache;
    int ops_scan(char *ops, void *ops_cache, char **as,
                 int *col, int *line, unsigned short *op_assoc, int *op_priority);
}

X: '1' (${scan ops_scan(ops, ops_cache)} '2')*;


The user provides the 'ops_scan' function.  This example is from tests/g4.test.g in the source distribution.

The second type of scanner is a global scanner:
\preformatted{
{
   #include "g7.test.g.d_parser.h"
   int myscanner(char **s, int *col, int *line, unsigned short *symbol,
                 int *term_priority, unsigned short *op_assoc, int *op_priority)
   {
       if (**s == 'a') {
           (*s)++;
           *symbol = A;
           return 1;
       } else if (**s == 'b') {
           (*s)++;
           *symbol = BB;
           return 1;
       } else if (**s == 'c') {
           (*s)++;
           *symbol = CCC;
           return 1;
       } else if (**s == 'd') {
           (*s)++;
           *symbol = DDDD;
           return 1;
       } else
           return 0;
   }
   ${scanner myscanner}
   ${token A BB CCC DDDD}

   S: A (BB CCC)+ SS;
   SS: DDDD;
}

Notice how the you need to include the header file generated by
\code{\link{mkdparse}} which contains the token definitions.

\itemize{\item Tokenizers}

Tokenizers are non-context sensitive global scanners which produce
only one token for any given input string.  Some programming
languages (for example C) are easier to specify using a tokenizer
because (for example) reserved words can be handled simply by
lowering the terminal priority for identifiers.
\preformatted{
S : 'if' '(' S ')' S ';' | 'do' S 'while' '(' S ')' ';' | ident;
ident: "[a-z]+" $term -1;
}

The sentence: \bold{if ( while ) a;} is legal because \bold{while}
cannot appear at the start of \bold{S} and so it doesn't conflict
with the parsing of \bold{while} as an \bold{ident} in that
position.  However, if a tokenizer is specified, all tokens will
be possible at each position and the sentense will produce a
syntax error.

\bold{DParser} provides two ways to specify tokenizers: globally
as an option (-T) to \code{\link{mkdparse}} and locally with a ${declare
tokenize ...} specifier (see the ANSI C grammar for an example).
The ${declare tokenize ...} declartion allows a tokenizer to be
specified over a subset of the parsing states so that (for
example) ANSI C could be a subgrammar of another larger grammar.
Currently the parse states are not split so that the productions
for the substates must be disjoint.

\itemize{\item Longest Match}

 Longest match lexical ambiguity resolution is a technique used by
 separate phase lexers to help decide (along with lexical
 priorities) which single token to select for a given input
 string.  It is used in the definition of ANSI-C, but not in C++
 because of a snafu in the definition of templates whereby
 templates of templates (List&lt;List &lt;Int&gt;&gt;) can end with the right
 shift token
 ('&gt;&gt;').  Since \bold{DParser} does not have a separate lexical phase, it
 does not require longest match disambiguation, but provides it as an option.

There are two ways to specify longest match disabiguation:
globally as an option (-l) to make_dparser or locally with with a
${declare longest_match ...}.  If global longest match
disambiguation is \bold{ON}, it can be locally disabled with {$declare
all_matches ...} .  As with Tokenizers above, local declarations
operate on disjoint subsets of parsing states.
</pre>
<dl>
<dt>Priorities and Associativity:</dt><dd>
<p>Priorities can very from MININT to MAXINT and are specified as integers.  Associativity can take the values:
</p>
<pre>
assoc : '$unary_op_right' | '$unary_op_left' | '$binary_op_right'
| '$binary_op_left' | '$unary_right' | '$unary_left'
| '$binary_right' | '$binary_left' | '$right' | '$left' ;
</pre>
<ul>
<li><p> Token Prioritites</p>
</li></ul>

<p>Termininal priorities apply after the set of matching strings has
been found and the terminal(s) with the highest priority is
selected.
</p>
<p>Terminal priorities are introduced after a terminal by the
specifier <b>$term</b>.  We saw an example of token priorities
with the definition of <b>ident</b>.
</p>
<p><b>Example:</b></p>
<pre>
S : 'if' '(' S ')' S ';' | 'do' S 'while' '(' S ')' ';' | ident;
ident: "[a-z]+" $term -1;
</pre>
<ul>
<li><p> Operator Priorities</p>
</li></ul>

<p>Operator priorities specify the priority of a operator symbol
(either a terminal or a non-terminal).  This corresponds to the
yacc or bison 
doesn't require a global tokenizer, operator priorities and
associativities are specified on the reduction which creates the
token.  Moreover, the associativity includes the operator usage as
well since it cannot be infered from rule context.  Possible
operator associativies are:
</p>
<pre>
operator_assoc : '$unary_op_right' | '$unary_op_left' | '$binary_op_right'
                    | '$binary_op_left' | '$unary_right' | '$unary_left'
                    | '$binary_right' | '$binary_left';
</pre>
<p><b>Example:</b></p>
<pre>
E: ident op ident;
ident: '[a-z]+';
op: '*' $binary_op_left 2 |
    '+' $binary_op_left 1;
</pre>
<ul>
<li><p> Rule Priorities</p>
</li></ul>

<p>Rule priorities specify the priority of the reduction itself and have the possible associativies:
</p>
<pre>
rule_assoc: '$right' | '$left';
</pre>
<p>Rule and operator priorities can be intermixed and are interpreted
at run time (not when the tables are built).  This make it
possible for user-defined scanners to return the associativities
and priorities of tokens.
</p>
</dd>
<dt>Actions: </dt><dd>
<p>Actions are the bits of code which run when a reduction occurs.
Example
</p>
<pre>
 S: this | that;
 this: 'this' { printf("got this\n"); };
 that: 'that' { printf("got that\n"); };
</pre>
<ul>
<li><p> Speculative Action</p>
</li></ul>

<p>Speculative actions occur when the reduction takes place during
the speculative parsing process.  It is possible that the
reduction will not be part of the final parse or that it will
occur a different number of times.  For example:
</p>
<pre>
S: this | that;
this: hi 'mom';
that: ho 'dad';
ho: 'hello' [ printf("ho\n"); ];
hi: 'hello' [ printf("hi\n"); ];
</pre>
<p>Will print both 'hi' and 'ho' when given the input 'hello dad' because at the time hello is reduced, the following token is not known.
</p>
<ul>
<li><p> Final Actions</p>
</li></ul>

<p>Final actions occur only when the reduction must be part of any
legal final parse (committed).  It is possible to do final
actions during parsing or delay them till the entire parse tree
is constructed (see Options).  Final actions are executed in
order and in number according the the single final unambiguous
parse.
</p>
<pre>
 S: A S 'b' | 'x';
 A: [ printf("speculative e-reduce A\n"); ]
    { printf("final e-reduce A\n"); };
</pre>
<p>On input:
</p>
<pre>
 xbbb
</pre>
<p>Will produce:
</p>
<pre>
 speculative e-reduce A
 final e-reduce A
 final e-reduce A
 final e-reduce A
</pre>
<ul>
<li><p> Embedded Actions</p>
</li></ul>

<p>Actions can be embedded into rule. These actions are executed as
if they were replaced with a synthetic production with a single
null rule containing the actions.  For example:
</p>
<pre>
 S: A { printf("X"); } B;
 A: 'a' { printf("a"); };
 B: 'b' { printf("b"); };
</pre>
<p>On input:
</p>
<pre>
ab
</pre>
<p>Will produce:
</p>
<pre>
 aXb
</pre>
<p>Note that in the above example, the print(&quot;X&quot;) is evaluated in a context null rule context while in:
</p>
<pre>
 S: A (A B { printf("X"); }) B;
</pre>
<p>The print is evalated in the context of the &quot;A B&quot; subrule because
it appears at the end of the subrule and is therefor treated as a
normal action for the subrule.
</p>
<ul>
<li><p> Pass Actions</p>
</li></ul>

<p>DParser supports multiple pass compilation.  The passes are
declared at the top of the grammar, and the actions are associated
with individual rules.
</p>
<p><b>Example;</b>
</p>
<pre>
 ${pass sym for_all postorder}
 ${pass gen for_all postorder}

 translation_unit: statement*;

 statement
   : expression ';' {
     d_pass(${parser}, &amp;$n, ${pass sym});
     d_pass(${parser}, &amp;$n, ${pass gen});
   }
   ;

 expression :  integer
   gen: { printf("gen integer\n"); }
   sym: { printf("sym integer\n"); }
   | expression '+' expression $right 2
   sym: { printf("sym +\n"); }
   ;
</pre>
<p>A pass name then a colon indicate that the following action is
associated with a particular pass. Passes can be either for_all or
for_undefined (which means that the automatic traversal only
applies to rules without actions defined for this pass).
Furthermore, passes can be postorder, preorder, and manual (you
have to call d_pass yourself).  Passes can be initiated in the
final action of any rule.
</p>
<ul>
<li><p> Default Actions</p>
</li></ul>

<p>The special production &quot;_&quot; can be defined with a single rule
whose actions become the default when no other action is
specified.  Default actions can be specified for speculative,
final and pass actions and apply to each separately.
</p>
<p><b>Example</b>
</p>
<pre>
 _: { printf("final action"); }
     gen: { printf("default gen action"); }
     sym: { printf("default sym action"); }
     ;
</pre>
</dd>
<dt>Attributes and Action Specifiers</dt><dd>
<p>Each of the language parser can have some global atrributes and actions associated with each part of the parsed code.
</p>
<ul>
<li><p>  Global State ($g)</p>
</li></ul>

<p>Global state is declared by define'ing D_ParseNode_Globals (see the ANSI C grammar for a similar declaration for symbols). Global state can be accessed in any action with $g.  Because DParser handles ambiguous parsing global state can be accessed on different speculative parses.  In the future automatic splitting of global state may be implemented (if there is demand). Currently, the global state can be copied and assigned to $g to ensure that the changes made only effect subsequent speculative parses derived from the particular parse.
</p>
<p><b>Example</b>
</p>
<pre>
  [ $g = copy_globals($g);
  $g-&gt;my_variable = 1;
  ]
</pre>
<p>The symbol table (see below) can be used to manage state information safely for different speculative parses.
</p>
<ul>
<li><p> Parse Node State</p>
</li></ul>

<p>Each parse node includes a set of system state variables and can have a set of user-defined state variables.  User defined parse node state is declared by define'ing D_ParseNodeUser. The size of the parse node state must be passed into new_D_Parser() to ensure that the appropriate amount of space is allocated for parse nodes.   Parse node state is accessed with:
</p>

<dl>
<dt>$# </dt><dd><p>number of child nodes</p>
</dd>
<dt>$$ </dt><dd><p>user parse node state for parent node (non-terminal defined by the production)</p>
</dd>
<dt>$X (where X is a number) </dt><dd><p>the user parse node state of element X of the production</p>
</dd>
<dt>$n </dt><dd><p>the system parse node state of the rule node</p>
</dd>
<dt>$nX </dt><dd><p>the system parse node state of element X of the production</p>
</dd>
</dl>

<p>The system parse node state is defined in dparse.h which is installed with DParser.  It contains such information as the symbol, the location of the parsed string, and pointers to the start and end of the parsed string.
</p>
<ul>
<li><p> Misc</p>
</li></ul>


<dl>
<dt>${scope} </dt><dd><p>the current symbol table scope</p>
</dd>
<dt>${reject} </dt><dd><p>in speculative actions permits the current parse to be rejected</p>
</dd>
</dl>

</dd>
<dt>Symbol Table</dt><dd>
<p>The symbol table can be updated down different speculative paths while sharing the bulk of the data.  It defines the following functions in the file (dsymtab.h):
</p>
<pre>
  struct D_Scope *new_D_Scope(struct D_Scope *st);
  struct D_Scope *enter_D_Scope(struct D_Scope *current, struct D_Scope *scope);
  D_Sym *NEW_D_SYM(struct D_Scope *st, char *name, char *end);
  D_Sym *find_D_Sym(struct D_Scope *st, char *name, char *end);
  D_Sym *UPDATE_D_SYM(struct D_Scope *st, D_Sym *sym);
  D_Sym *current_D_Sym(struct D_Scope *st, D_Sym *sym);
  D_Sym *find_D_Sym_in_Scope(struct D_Scope *st, char *name, char *end);
  </pre>
<p>'new_D_Scope' creates a new scope below 'st' or NULL for a 'top level'
scope.  'enter_D_Scope' returns to a previous scoping level.  NOTE: do
not simply assign ${scope} to a previous scope as any updated symbol
information will be lost.  'commit_D_Scope' can be used in final
actions to compress the update list for the top level scope and
improve efficiency.
</p>
<p>'find_D_Sym' finds the most current version of a symbol in a given
scope.  'UPDATE_D_SYM' updates the value of symbol (creates a
difference record on the current speculative parse path).
'current_D_Sym' is used to retrive the current version of a symbol,
the pointer to which may have been stored in some other attribute or
variable.  Symbols with the same name should not be created in the
same scope.  The function 'find_D_Sym_in_Scope' is provided to detect
this case.
</p>
<p>User data can be attached to symbols by <b>define</b>'ing <b>D_UserSym</b>.  See the ANSI C grammar for an example.
</p>
<p>Here is a full example of scope usage (from tests/g29.test.g):
</p>
<pre>

  #include &lt;stdio.h&gt;

  typedef struct My_Sym {
    int value;
  } My_Sym;
  #define D_UserSym My_Sym
  typedef struct My_ParseNode {
    int value;
    struct D_Scope *scope;
  } My_ParseNode;
  #define D_ParseNode_User My_ParseNode
}

ranslation_unit: statement*;

tatement
: expression ';'
{ printf("
| '{' new_scope statement* '}'
[ ${scope} = enter_D_Scope(${scope}, $n0.scope); ]
{ ${scope} = commit_D_Scope(${scope}); }
;

ew_scope: [ ${scope} = new_D_Scope(${scope}); ];

xpression
: identifier ':' expression
[
_Sym *s;
f (find_D_Sym_in_Scope(${scope}, $n0.start_loc.s, $n0.end))
rintf("duplicate identifier line 
 = NEW_D_SYM(${scope}, $n0.start_loc.s, $n0.end);
-&gt;user.value = $2.value;
$.value = s-&gt;user.value;
]
| identifier '=' expression
[ D_Sym *s = find_D_Sym(${scope}, $n0.start_loc.s, $n0.end);
 = UPDATE_D_SYM(${scope}, s);
-&gt;user.value = $2.value;
$.value = s-&gt;user.value;
]
| integer
[ $$.value = atoi($n0.start_loc.s); ]
| identifier
[ D_Sym *s = find_D_Sym(${scope}, $n0.start_loc.s, $n0.end);
f (s)
$.value = s-&gt;user.value;
]
| expression '+' expression
[ $$.value = $0.value + $1.value; ]
;

nteger: "-?([0-9]|0(x|X))[0-9]*(u|U|b|B|w|W|L|l)*" $term -1;
dentifier: "[a-zA-Z_][a-zA-Z_0-9]*";
</pre></dd>
<dt>Whitespace</dt><dd>
<p>Whitespace can be specified two ways: C function which can be
user-defined, or as a subgrammar.  The default whitespace parser is
compatible with C/C++ #line directives and comments.  It can be
replaced with any user specified function as a parsing option (see
Options).
</p>
<p>Additionally, if the (optionally) reserved production <b>whitespace</b> is
defined, the subgrammar it defines will be used to consume whitespace
for the main grammar.  This subgrammar can include normal actions.
</p>
<p><b>Example</b>
</p>
<pre>
: 'a' 'b' 'c';
hitespace: "[ \t\n]*";
</pre>
<p>Whitespace can be accessed on a per parse node basis using the
unctions: <b>d_ws_before</b> and <b>d_ws_after</b>, which return the
tart of the whitespace before start_loc.s and after end respectively.
</p>
</dd> <dt>Ambiguities</dt><dd>
<p>Ambiguities are resolved automatically based on priorities and
associativities.  In addition, when the other resolution techniques
fail, user defined ambiguity resolution is possible.  The default
ambiguity handler produces a fatal error on an unresolved ambiguity.
This behavior can be replaced with a user defined resolvers the
signature of which is provided in dparse.h.
</p>
<p>If the <b>verbose_level</b> flag is set, the default ambiguity
andler will print out parenthesized versions of the ambiguous parse
rees.  This may be of some assistence in disambiguating a grammar.
</p>
</dd>
<dt>Error Recovery</dt><dd>
<p>DParser implements an error recovery scheme appropriate to scannerless parsers.  I haven't had time to investigate all the prior work in this area, so I am not sure if it is novel.  Suffice for now that it is optional and works well with C/C++ like grammars.
</p>
</dd>
<dt>Parsing Options</dt><dd>
<p>Parser are instantiated with the function new_D_Parser.  The
resulting data structure contains a number of user configurable
options (see dparser.h).  These are provided reasonable default
values and include:
</p>

<ul>
<li> <p><b>initial_globals</b> - the initial global variables accessable through $g
</p>
</li>
<li> <p><b>initial_skip_space_fn</b> - the initial whitespace function
</p>
</li>
<li> <p><b>initial_scope</b> - the initial symbol table scope
</p>
</li>
<li> <p><b>syntax_error_fn</b> - the function called on a syntax error
</p>
</li>
<li> <p><b>ambiguity_fn</b> - the function called on an unresolved ambiguity
</p>
</li>
<li> <p><b>loc</b> - the initial location (set on an error).
</p>
</li></ul>

<p>In addtion, there are the following user configurables:
</p>

<ul>
<li> <p><b>sizeof_user_parse_node</b> - the sizeof D_ParseNodeUser
</p>
</li>
<li> <p><b>save_parse_tree</b> - whether or not the parse tree should be save once the final actions have been executed
</p>
</li>
<li> <p><b>dont_fixup_internal_productions</b> - to not convert the Kleene star into a variable number of children from a tree of reductions
</p>
</li>
<li> <p><b>dont_merge_epsilon_trees</b> - to not automatically remove ambiguities which result from trees of epsilon reductions without actions
</p>
</li>
<li> <p><b>dont_use_greediness_for_disambiguation</b> - do not use the rule that the longest parse which reduces to the same token should be used to disambiguate parses.  This rule is used to handle the case (if then else?) relatively cleanly.
</p>
</li>
<li> <p><b>dont_use_height_for_disambiguation</b> - do not use the rule that the least deep parse which reduces to the same token should be used to disabiguate parses.  This rule is used to handle recursive grammars relatiively cleanly.
</p>
</li>
<li> <p><b>dont_compare_stacks</b> - disables comparing stacks to handle certain exponential cases during ambiguous operator priority resolution.
</p>
</li>
<li> <p><b>commit_actions_interval</b> - how often to commit final actions (0 is immediate, MAXINT is essentially not till the end of parsing)
</p>
</li>
<li> <p><b>error_recovery</b> - whether or not to use error recovery (defaults ON)
</p>
</li></ul>

<p>An the following result values:
</p>

<ul>
<li> <p><b>syntax_errors</b> - how many syntax errors (if <b>error_recovery</b> was
on)
</p>
</li></ul>

<p>This final value should be checked to see if parse was successful.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Matthew Fidler <a href="mailto:matthew.fidler@gmail.com">matthew.fidler@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> John Plevyak <a href="mailto:jplevyak@gmail.com">jplevyak@gmail.com</a> [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://nlmixr2.github.io/dparser-R/">https://nlmixr2.github.io/dparser-R/</a>
</p>
</li>
<li> <p><a href="https://github.com/nlmixr2/dparser-R/">https://github.com/nlmixr2/dparser-R/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/nlmixr2/dparser-R/issues/">https://github.com/nlmixr2/dparser-R/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='dparserFunction-class'>A S4 class for dparser functions</h2><span id='topic+dparserFunction-class'></span>

<h3>Description</h3>

<p>The data here is the function to be called.
</p>


<h3>Slots</h3>


<dl>
<dt><code>env</code></dt><dd><p>contains the environment where the grammar name and dll
files are stored.</p>
</dd>
<dt><code>.Data</code></dt><dd><p>is the function data</p>
</dd>
</dl>

<hr>
<h2 id='dpDefaultSkip'>Default skip function for darsing grammar</h2><span id='topic+dpDefaultSkip'></span>

<h3>Description</h3>

<p>This function is to determine if children are parsed or skipped.
By default, all children are parsed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpDefaultSkip(name, value, pos, depth)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpDefaultSkip_+3A_name">name</code></td>
<td>
<p>Production Name</p>
</td></tr>
<tr><td><code id="dpDefaultSkip_+3A_value">value</code></td>
<td>
<p>Production Value</p>
</td></tr>
<tr><td><code id="dpDefaultSkip_+3A_pos">pos</code></td>
<td>
<p>terminal position.  Negative values are parsed before
children are parsed.  A value of -1 means there are no
children nodes.  A value of -2 means there are children nodes.
Otherwise, the terminal position is numbered starting at 0.</p>
</td></tr>
<tr><td><code id="dpDefaultSkip_+3A_depth">depth</code></td>
<td>
<p>Parsing Depth</p>
</td></tr>
</table>


<h3>Value</h3>

<p>FALSE.  If a comparable function returns TRUE, the
children are not parsed.
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='dpGetFile'>Get file for dparser arguments</h2><span id='topic+dpGetFile'></span>

<h3>Description</h3>

<p>Get file for dparser arguments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpGetFile(file, fileext = "", envir = parent.frame(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpGetFile_+3A_file">file</code></td>
<td>
<p>- File to handle.  This file can be:
</p>

<ul>
<li><p> an actual file.
</p>
</li>
<li><p> a character string.  In this case, a temporary file is
created with the character string.
</p>
</li>
<li><p> A bracket <code>{}</code> enclosed R expression.  In this case
the contents of the expressions is put into a temporary file.
</p>
</li>
<li><p> A function.  In this case the contents of the function body are put into the temporary file.
</p>
</li></ul>
</td></tr>
<tr><td><code id="dpGetFile_+3A_fileext">fileext</code></td>
<td>
<p>file extension of temporary file to create</p>
</td></tr>
<tr><td><code id="dpGetFile_+3A_envir">envir</code></td>
<td>
<p>Environment to deparse variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of three elements:
</p>

<dl>
<dt><code>file</code></dt><dd><p>The file name of either the temporary file or the real file</p>
</dd>
<dt><code>use_file_name</code></dt><dd><p>If the file name was used (<code>TRUE</code>), or a temporary file was created(<code>FALSE</code>)</p>
</dd>
<dt><code>md5</code></dt><dd><p>md5 of the model</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='dpIncludeDir'>Dparser C headers include directory</h2><span id='topic+dpIncludeDir'></span>

<h3>Description</h3>

<p>Return the include directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpIncludeDir(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpIncludeDir_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to file.path</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The include directory has the headers that may be needed to build
functions against the Dparser library.
</p>


<h3>Value</h3>

<p>Dparser include directory
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='dpReload'>Reload the R dparser dll</h2><span id='topic+dpReload'></span>

<h3>Description</h3>

<p>This can be useful if parsing one grammar seems to affect another
grammar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpReload()
</code></pre>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='dpRparse'>C code for R parser</h2><span id='topic+dpRparse'></span>

<h3>Description</h3>

<p>C code for R parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpRparse()
</code></pre>


<h3>Value</h3>

<p>A string for generating C tree walker
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='dpVersion'>Version and repository for this dparser package.</h2><span id='topic+dpVersion'></span>

<h3>Description</h3>

<p>Version and repository for this dparser package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpVersion()
</code></pre>


<h3>Value</h3>

<p>A character vector with the version and repository.
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='gc.dparser'>Garbage collection for dpaser functions</h2><span id='topic+gc.dparser'></span>

<h3>Description</h3>

<p>This will delete the dynamically created dll upon garbage
collection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gc.dparser(env)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gc.dparser_+3A_env">env</code></td>
<td>
<p>Environment that is being garbage collected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing.
</p>


<h3>Garbage collection</h3>

<p>There are two user options that control if the dlls for the
grammars created by dparser will be deleted upon garbage
collection or R exit if they are not associated with any active
objects.  These are:
</p>

<dl>
<dt><code>dpaser.rm.unnamed.parser.dll</code>:</dt><dd><p>when <code>TRUE</code>, this remove parsers
that are created from strings, or other memory-based items in R.</p>
</dd>
<dt><code>dpaser.rm.unnamed.parser.dll</code>:</dt><dd><p>when <code>TRUE</code>, this
removes parsers created from grammar files.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='mkdparse'>mkdparse dparser grammer c</h2><span id='topic+mkdparse'></span>

<h3>Description</h3>

<p>Make a dparser c file based on a grammer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mkdparse(
  file,
  outputFile,
  set_op_priority_from_rule = FALSE,
  right_recursive_BNF = FALSE,
  states_for_whitespace = TRUE,
  states_for_all_nterms = FALSE,
  tokenizer = FALSE,
  token_type = c("#define", "enum"),
  longest_match = FALSE,
  grammar_ident = "gram",
  ident_from_filename = FALSE,
  scanner_blocks = 4,
  write_line_directives = TRUE,
  write_header = c("IfEmpty", TRUE, FALSE),
  rdebug = FALSE,
  verbose = FALSE,
  write_extension = "c",
  use_r_header = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mkdparse_+3A_file">file</code></td>
<td>
<p>File name of grammer to parse.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_outputfile">outputFile</code></td>
<td>
<p>Output file name.  Can be a directory.  If so,
the file name is determined by the input file.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_set_op_priority_from_rule">set_op_priority_from_rule</code></td>
<td>
<p>Toggle setting of operator
priority from rules.  Setting of operator priorities on
operator tokens can increase the size of the tables but can
permit unnecessary parse stacks to be pruned earlier. (FALSE
by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_right_recursive_bnf">right_recursive_BNF</code></td>
<td>
<p>Toggle use of right recursion for EBNF
productions.  Do not change this unless you really know what
you are doing. (FALSE by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_states_for_whitespace">states_for_whitespace</code></td>
<td>
<p>Toggle computing whitespace states.
If 'whitespace' is defined in the grammar, then use it as a
subparser to consume whitespace. (TRUE by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_states_for_all_nterms">states_for_all_nterms</code></td>
<td>
<p>Toggle computing states for all
non-terminals.  Ensures that there is a unique state for each
non-terminal so that a subparsers can be invoked for that
non-terminal. (FALSE by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_tokenizer">tokenizer</code></td>
<td>
<p>Toggle building of a tokenizer for START.  When
TRUE, instead of generating a unique scanner for each state
(i.e. a 'scannerless' parser), generate a single scanner
(tokenizer) for the entire grammar.  This provides an easy way
to build grammars for languages which assume a tokenizer
(e.g. ANSI C). (FALSE by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_token_type">token_type</code></td>
<td>
<p>Token type &quot;#define&quot; or &quot;enum&quot;</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_longest_match">longest_match</code></td>
<td>
<p>Toggle longest match lexical ambiguity
resolution.  When TRUE the scanner only recognizing the
longest matching tokens in a given state. This provides an
easy way to build grammars for languages which use longest
match lexical ambiguity resolution (e.g. ANSI-C, C++). (FALSE
by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_grammar_ident">grammar_ident</code></td>
<td>
<p>Tag for grammar data structures so that
multiple sets of tables can be included in one
file/application. (defaults to 'gram')</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_ident_from_filename">ident_from_filename</code></td>
<td>
<p>Build the grammer tag from the
file-name.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_scanner_blocks">scanner_blocks</code></td>
<td>
<p>Number of blocks to which scanner tables are
broken up into. Larger numbers permit more sharing with more
overhead.  4 seems to be optimal for most grammars. (defaults
to 4) files.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_write_line_directives">write_line_directives</code></td>
<td>
<p>Toggle writing of line numbers.  Used
to debug the parsing table generator itself. (TRUE by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_write_header">write_header</code></td>
<td>
<p>Write header, FALSE : no, TRUE : yes,
&quot;IfEmpty&quot; : only if not empty.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_rdebug">rdebug</code></td>
<td>
<p>Replace all actions in the grammar with actions
printing productions, 1 : during the speculative parsing
process (&lt;-), 2 : when reduction is part of any legal final
parse (&lt;=), 3 : both, 4 : remove all actions from the grammar.
Print the changed grammar to console.  Useful for debugging or
prototyping new, experimental grammars.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_verbose">verbose</code></td>
<td>
<p>Increase verbosity.</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_write_extension">write_extension</code></td>
<td>
<p>Set the extension of the generated code
file.  For C++ programs (for example) the extension can be set
to .cpp with the option <code>write_extension="cpp"</code>.
(<code>write_extension="c"</code> by default)</p>
</td></tr>
<tr><td><code id="mkdparse_+3A_use_r_header">use_r_header</code></td>
<td>
<p>when TRUE, add R headers and swap printf for
Rprintf. By default this is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses a grammer file to create a c file for parsing.
</p>
<p>mkdparser is a scannerless GLR parser generator based on the
Tomita algorithm. It is self-hosted and very easy to
use. Grammars are written in a natural style of EBNF and regular
expressions and support both speculative and final actions.
</p>


<h3>Value</h3>

<p>Nothing. Outputs files instead.
</p>


<h3>Creating a Grammar for Parsing</h3>


<dl>
<dt>Grammar Comments:</dt><dd><p>Grammars can include C/C++ style comments
</p>
<p><b>Example:</b>
</p>
<pre>
// My first grammar
E: E '+' E | "[abc]";
/* is this right? */
</pre></dd>
<dt>Grammar Productions:</dt><dd>
<p>A production is the parts of your language your are trying to parse and are tpyically named.  See https://en.wikipedia.org/wiki/Top-down_parsing
</p>

<ul>
<li><p> The first production is the root of your grammar (what you
will be trying to parse).
</p>
</li>
<li><p> Productions start with the non-terminal being defined
followed by a colon ':', a set of right hand sides separated by
'|' (or) consisting of elements (non-terminals or terminals).
</p>
</li>
<li><p> Elements can be grouped with parens '(', and the normal
regular expression symbols can be used ('+' '*' '?' '|').
</p>
</li>
<li><p> Elements can be grouped with parens '(', and the normal
regular expression symbols can be used ('+' '*' '?' '|').
</p>
</li>
<li><p> Elements can be repeated using '@', for example elem@3 or
elem@1:3 for repeat 3 or between 1 and 3 times respectively.
</p>
</li></ul>

<p><b>Example:</b>
</p>
<pre>
 program: statements+ |  comment* (function |  procedure)?;
</pre>
<p><b>Note:</b> Instead of using '[' ']' for optional elements we
use the more familar and consistent '?' operator.  The square
brackets are reserved for speculative actions (below).
</p>
</dd>
<dt>Global C code in Grammars:</dt><dd>
<p>Since the main parsing of the language grammar is in C, intermixing C code with the grammar can be useful.
</p>
<ul>
<li><p> Global (or static) C code can be intermixed with productions by surrounding the code with brackets '{}'.</p>
</li></ul>

<p><b>Example:</b>
</p>
<pre>
  { void dr_s() { printf("Dr. S\n"); }
   S: 'the' 'cat' 'and' 'the' 'hat' { dr_s(); } | T;
   { void twain() { printf("Mark Twain\n"); }
       T: 'Huck' 'Finn' { twain(); };
</pre>
<p><b>Note:</b> When parsing the grammar using
<code><a href="#topic+mkdparse">mkdparse</a></code>, the option <code>use_r_header = TRUE</code> will
redefine <code>printf</code> to <code>Rprintf</code> to better
comply with R packages.
</p>
</dd>
<dt>Terminals</dt><dd>
<p>The terminals are the peices of the language that are being parsed, like language keywords.
</p>
<ul>
<li><p> Strings terminals are surrounded with single quotes.  For example:</p>
</li></ul>

<pre>
block: '{' statements* '}';
whileblock: 'while' '(' expression ')' block;
</pre>
<ul>
<li><p> Unicode literals can appear in strings or as charaters with U+ or u+.  For example:</p>
</li></ul>

<pre>
U+03c9 { printf("omega\n"); }
</pre>
</dd>
</dl>
<ul>
<li><p>  Regular expressions are surrounded with double quotes.  For example:</p>
</li></ul>

<pre>
hexint: "(0x|0X)[0-9a-fA-F]+[uUlL]?";
</pre>
<p><b>Note:</b>  only the simple regular expression operators are currently supported. This include parens, square parens, ranges, and '*', '+', '?'.
</p>
<ul>
<li><p> Terminal modifiers</p>
</li></ul>

<p>Terminals can contain embbed escape codes.  Including the standard
C escape codes, the codes \x and \d permit inserting hex and
decimal ASCII characters directly.
</p>
<p>Tokens can be given a name by appending the $name option.  This is useful when you have several
tokens which which represent the same string (e.g. ',').   For example,
</p>
<pre>
function_call: function '(' parameter ( ',' $name 'parameter_comma' parameter) ')';
</pre>
<p>It is now possible to use $0.symbol == ${string parameter_comma} to differentiate ParseNode ($0) between
a parameter comma node and say an initialization comma.
</p>
<p>Terminals ending in '/i' are case insensitive.  For example 'hi'/i
matches 'HI', 'Hi' and &quot;hI' in addition to 'hi'.
</p>
<ul>
<li><p> External (C) Scanners</p>
</li></ul>

<p>There are two types of external scanners, those which read a
single terminal, and those which are global (called for every
terminal).  Here is an example of a scanner for a single terminal.
Notice how it can be mixed with regular string terminals.
</p>
<pre>
{
    extern char *ops;
    extern void *ops_cache;
    int ops_scan(char *ops, void *ops_cache, char **as,
                 int *col, int *line, unsigned short *op_assoc, int *op_priority);
}

X: '1' (${scan ops_scan(ops, ops_cache)} '2')*;


The user provides the 'ops_scan' function.  This example is from tests/g4.test.g in the source distribution.

The second type of scanner is a global scanner:
\preformatted{
{
   #include "g7.test.g.d_parser.h"
   int myscanner(char **s, int *col, int *line, unsigned short *symbol,
                 int *term_priority, unsigned short *op_assoc, int *op_priority)
   {
       if (**s == 'a') {
           (*s)++;
           *symbol = A;
           return 1;
       } else if (**s == 'b') {
           (*s)++;
           *symbol = BB;
           return 1;
       } else if (**s == 'c') {
           (*s)++;
           *symbol = CCC;
           return 1;
       } else if (**s == 'd') {
           (*s)++;
           *symbol = DDDD;
           return 1;
       } else
           return 0;
   }
   ${scanner myscanner}
   ${token A BB CCC DDDD}

   S: A (BB CCC)+ SS;
   SS: DDDD;
}

Notice how the you need to include the header file generated by
\code{\link{mkdparse}} which contains the token definitions.

\itemize{\item Tokenizers}

Tokenizers are non-context sensitive global scanners which produce
only one token for any given input string.  Some programming
languages (for example C) are easier to specify using a tokenizer
because (for example) reserved words can be handled simply by
lowering the terminal priority for identifiers.
\preformatted{
S : 'if' '(' S ')' S ';' | 'do' S 'while' '(' S ')' ';' | ident;
ident: "[a-z]+" $term -1;
}

The sentence: \bold{if ( while ) a;} is legal because \bold{while}
cannot appear at the start of \bold{S} and so it doesn't conflict
with the parsing of \bold{while} as an \bold{ident} in that
position.  However, if a tokenizer is specified, all tokens will
be possible at each position and the sentense will produce a
syntax error.

\bold{DParser} provides two ways to specify tokenizers: globally
as an option (-T) to \code{\link{mkdparse}} and locally with a ${declare
tokenize ...} specifier (see the ANSI C grammar for an example).
The ${declare tokenize ...} declartion allows a tokenizer to be
specified over a subset of the parsing states so that (for
example) ANSI C could be a subgrammar of another larger grammar.
Currently the parse states are not split so that the productions
for the substates must be disjoint.

\itemize{\item Longest Match}

 Longest match lexical ambiguity resolution is a technique used by
 separate phase lexers to help decide (along with lexical
 priorities) which single token to select for a given input
 string.  It is used in the definition of ANSI-C, but not in C++
 because of a snafu in the definition of templates whereby
 templates of templates (List&lt;List &lt;Int&gt;&gt;) can end with the right
 shift token
 ('&gt;&gt;').  Since \bold{DParser} does not have a separate lexical phase, it
 does not require longest match disambiguation, but provides it as an option.

There are two ways to specify longest match disabiguation:
globally as an option (-l) to make_dparser or locally with with a
${declare longest_match ...}.  If global longest match
disambiguation is \bold{ON}, it can be locally disabled with {$declare
all_matches ...} .  As with Tokenizers above, local declarations
operate on disjoint subsets of parsing states.
</pre>
<dl>
<dt>Priorities and Associativity:</dt><dd>
<p>Priorities can very from MININT to MAXINT and are specified as integers.  Associativity can take the values:
</p>
<pre>
assoc : '$unary_op_right' | '$unary_op_left' | '$binary_op_right'
| '$binary_op_left' | '$unary_right' | '$unary_left'
| '$binary_right' | '$binary_left' | '$right' | '$left' ;
</pre>
<ul>
<li><p> Token Prioritites</p>
</li></ul>

<p>Termininal priorities apply after the set of matching strings has
been found and the terminal(s) with the highest priority is
selected.
</p>
<p>Terminal priorities are introduced after a terminal by the
specifier <b>$term</b>.  We saw an example of token priorities
with the definition of <b>ident</b>.
</p>
<p><b>Example:</b></p>
<pre>
S : 'if' '(' S ')' S ';' | 'do' S 'while' '(' S ')' ';' | ident;
ident: "[a-z]+" $term -1;
</pre>
<ul>
<li><p> Operator Priorities</p>
</li></ul>

<p>Operator priorities specify the priority of a operator symbol
(either a terminal or a non-terminal).  This corresponds to the
yacc or bison 
doesn't require a global tokenizer, operator priorities and
associativities are specified on the reduction which creates the
token.  Moreover, the associativity includes the operator usage as
well since it cannot be infered from rule context.  Possible
operator associativies are:
</p>
<pre>
operator_assoc : '$unary_op_right' | '$unary_op_left' | '$binary_op_right'
                    | '$binary_op_left' | '$unary_right' | '$unary_left'
                    | '$binary_right' | '$binary_left';
</pre>
<p><b>Example:</b></p>
<pre>
E: ident op ident;
ident: '[a-z]+';
op: '*' $binary_op_left 2 |
    '+' $binary_op_left 1;
</pre>
<ul>
<li><p> Rule Priorities</p>
</li></ul>

<p>Rule priorities specify the priority of the reduction itself and have the possible associativies:
</p>
<pre>
rule_assoc: '$right' | '$left';
</pre>
<p>Rule and operator priorities can be intermixed and are interpreted
at run time (not when the tables are built).  This make it
possible for user-defined scanners to return the associativities
and priorities of tokens.
</p>
</dd>
<dt>Actions: </dt><dd>
<p>Actions are the bits of code which run when a reduction occurs.
Example
</p>
<pre>
 S: this | that;
 this: 'this' { printf("got this\n"); };
 that: 'that' { printf("got that\n"); };
</pre>
<ul>
<li><p> Speculative Action</p>
</li></ul>

<p>Speculative actions occur when the reduction takes place during
the speculative parsing process.  It is possible that the
reduction will not be part of the final parse or that it will
occur a different number of times.  For example:
</p>
<pre>
S: this | that;
this: hi 'mom';
that: ho 'dad';
ho: 'hello' [ printf("ho\n"); ];
hi: 'hello' [ printf("hi\n"); ];
</pre>
<p>Will print both 'hi' and 'ho' when given the input 'hello dad' because at the time hello is reduced, the following token is not known.
</p>
<ul>
<li><p> Final Actions</p>
</li></ul>

<p>Final actions occur only when the reduction must be part of any
legal final parse (committed).  It is possible to do final
actions during parsing or delay them till the entire parse tree
is constructed (see Options).  Final actions are executed in
order and in number according the the single final unambiguous
parse.
</p>
<pre>
 S: A S 'b' | 'x';
 A: [ printf("speculative e-reduce A\n"); ]
    { printf("final e-reduce A\n"); };
</pre>
<p>On input:
</p>
<pre>
 xbbb
</pre>
<p>Will produce:
</p>
<pre>
 speculative e-reduce A
 final e-reduce A
 final e-reduce A
 final e-reduce A
</pre>
<ul>
<li><p> Embedded Actions</p>
</li></ul>

<p>Actions can be embedded into rule. These actions are executed as
if they were replaced with a synthetic production with a single
null rule containing the actions.  For example:
</p>
<pre>
 S: A { printf("X"); } B;
 A: 'a' { printf("a"); };
 B: 'b' { printf("b"); };
</pre>
<p>On input:
</p>
<pre>
ab
</pre>
<p>Will produce:
</p>
<pre>
 aXb
</pre>
<p>Note that in the above example, the print(&quot;X&quot;) is evaluated in a context null rule context while in:
</p>
<pre>
 S: A (A B { printf("X"); }) B;
</pre>
<p>The print is evalated in the context of the &quot;A B&quot; subrule because
it appears at the end of the subrule and is therefor treated as a
normal action for the subrule.
</p>
<ul>
<li><p> Pass Actions</p>
</li></ul>

<p>DParser supports multiple pass compilation.  The passes are
declared at the top of the grammar, and the actions are associated
with individual rules.
</p>
<p><b>Example;</b>
</p>
<pre>
 ${pass sym for_all postorder}
 ${pass gen for_all postorder}

 translation_unit: statement*;

 statement
   : expression ';' {
     d_pass(${parser}, &amp;$n, ${pass sym});
     d_pass(${parser}, &amp;$n, ${pass gen});
   }
   ;

 expression :  integer
   gen: { printf("gen integer\n"); }
   sym: { printf("sym integer\n"); }
   | expression '+' expression $right 2
   sym: { printf("sym +\n"); }
   ;
</pre>
<p>A pass name then a colon indicate that the following action is
associated with a particular pass. Passes can be either for_all or
for_undefined (which means that the automatic traversal only
applies to rules without actions defined for this pass).
Furthermore, passes can be postorder, preorder, and manual (you
have to call d_pass yourself).  Passes can be initiated in the
final action of any rule.
</p>
<ul>
<li><p> Default Actions</p>
</li></ul>

<p>The special production &quot;_&quot; can be defined with a single rule
whose actions become the default when no other action is
specified.  Default actions can be specified for speculative,
final and pass actions and apply to each separately.
</p>
<p><b>Example</b>
</p>
<pre>
 _: { printf("final action"); }
     gen: { printf("default gen action"); }
     sym: { printf("default sym action"); }
     ;
</pre>
</dd>
<dt>Attributes and Action Specifiers</dt><dd>
<p>Each of the language parser can have some global atrributes and actions associated with each part of the parsed code.
</p>
<ul>
<li><p>  Global State ($g)</p>
</li></ul>

<p>Global state is declared by define'ing D_ParseNode_Globals (see the ANSI C grammar for a similar declaration for symbols). Global state can be accessed in any action with $g.  Because DParser handles ambiguous parsing global state can be accessed on different speculative parses.  In the future automatic splitting of global state may be implemented (if there is demand). Currently, the global state can be copied and assigned to $g to ensure that the changes made only effect subsequent speculative parses derived from the particular parse.
</p>
<p><b>Example</b>
</p>
<pre>
  [ $g = copy_globals($g);
  $g-&gt;my_variable = 1;
  ]
</pre>
<p>The symbol table (see below) can be used to manage state information safely for different speculative parses.
</p>
<ul>
<li><p> Parse Node State</p>
</li></ul>

<p>Each parse node includes a set of system state variables and can have a set of user-defined state variables.  User defined parse node state is declared by define'ing D_ParseNodeUser. The size of the parse node state must be passed into new_D_Parser() to ensure that the appropriate amount of space is allocated for parse nodes.   Parse node state is accessed with:
</p>

<dl>
<dt>$# </dt><dd><p>number of child nodes</p>
</dd>
<dt>$$ </dt><dd><p>user parse node state for parent node (non-terminal defined by the production)</p>
</dd>
<dt>$X (where X is a number) </dt><dd><p>the user parse node state of element X of the production</p>
</dd>
<dt>$n </dt><dd><p>the system parse node state of the rule node</p>
</dd>
<dt>$nX </dt><dd><p>the system parse node state of element X of the production</p>
</dd>
</dl>

<p>The system parse node state is defined in dparse.h which is installed with DParser.  It contains such information as the symbol, the location of the parsed string, and pointers to the start and end of the parsed string.
</p>
<ul>
<li><p> Misc</p>
</li></ul>


<dl>
<dt>${scope} </dt><dd><p>the current symbol table scope</p>
</dd>
<dt>${reject} </dt><dd><p>in speculative actions permits the current parse to be rejected</p>
</dd>
</dl>

</dd>
<dt>Symbol Table</dt><dd>
<p>The symbol table can be updated down different speculative paths while sharing the bulk of the data.  It defines the following functions in the file (dsymtab.h):
</p>
<pre>
  struct D_Scope *new_D_Scope(struct D_Scope *st);
  struct D_Scope *enter_D_Scope(struct D_Scope *current, struct D_Scope *scope);
  D_Sym *NEW_D_SYM(struct D_Scope *st, char *name, char *end);
  D_Sym *find_D_Sym(struct D_Scope *st, char *name, char *end);
  D_Sym *UPDATE_D_SYM(struct D_Scope *st, D_Sym *sym);
  D_Sym *current_D_Sym(struct D_Scope *st, D_Sym *sym);
  D_Sym *find_D_Sym_in_Scope(struct D_Scope *st, char *name, char *end);
  </pre>
<p>'new_D_Scope' creates a new scope below 'st' or NULL for a 'top level'
scope.  'enter_D_Scope' returns to a previous scoping level.  NOTE: do
not simply assign ${scope} to a previous scope as any updated symbol
information will be lost.  'commit_D_Scope' can be used in final
actions to compress the update list for the top level scope and
improve efficiency.
</p>
<p>'find_D_Sym' finds the most current version of a symbol in a given
scope.  'UPDATE_D_SYM' updates the value of symbol (creates a
difference record on the current speculative parse path).
'current_D_Sym' is used to retrive the current version of a symbol,
the pointer to which may have been stored in some other attribute or
variable.  Symbols with the same name should not be created in the
same scope.  The function 'find_D_Sym_in_Scope' is provided to detect
this case.
</p>
<p>User data can be attached to symbols by <b>define</b>'ing <b>D_UserSym</b>.  See the ANSI C grammar for an example.
</p>
<p>Here is a full example of scope usage (from tests/g29.test.g):
</p>
<pre>

  #include &lt;stdio.h&gt;

  typedef struct My_Sym {
    int value;
  } My_Sym;
  #define D_UserSym My_Sym
  typedef struct My_ParseNode {
    int value;
    struct D_Scope *scope;
  } My_ParseNode;
  #define D_ParseNode_User My_ParseNode
}

ranslation_unit: statement*;

tatement
: expression ';'
{ printf("
| '{' new_scope statement* '}'
[ ${scope} = enter_D_Scope(${scope}, $n0.scope); ]
{ ${scope} = commit_D_Scope(${scope}); }
;

ew_scope: [ ${scope} = new_D_Scope(${scope}); ];

xpression
: identifier ':' expression
[
_Sym *s;
f (find_D_Sym_in_Scope(${scope}, $n0.start_loc.s, $n0.end))
rintf("duplicate identifier line 
 = NEW_D_SYM(${scope}, $n0.start_loc.s, $n0.end);
-&gt;user.value = $2.value;
$.value = s-&gt;user.value;
]
| identifier '=' expression
[ D_Sym *s = find_D_Sym(${scope}, $n0.start_loc.s, $n0.end);
 = UPDATE_D_SYM(${scope}, s);
-&gt;user.value = $2.value;
$.value = s-&gt;user.value;
]
| integer
[ $$.value = atoi($n0.start_loc.s); ]
| identifier
[ D_Sym *s = find_D_Sym(${scope}, $n0.start_loc.s, $n0.end);
f (s)
$.value = s-&gt;user.value;
]
| expression '+' expression
[ $$.value = $0.value + $1.value; ]
;

nteger: "-?([0-9]|0(x|X))[0-9]*(u|U|b|B|w|W|L|l)*" $term -1;
dentifier: "[a-zA-Z_][a-zA-Z_0-9]*";
</pre></dd>
<dt>Whitespace</dt><dd>
<p>Whitespace can be specified two ways: C function which can be
user-defined, or as a subgrammar.  The default whitespace parser is
compatible with C/C++ #line directives and comments.  It can be
replaced with any user specified function as a parsing option (see
Options).
</p>
<p>Additionally, if the (optionally) reserved production <b>whitespace</b> is
defined, the subgrammar it defines will be used to consume whitespace
for the main grammar.  This subgrammar can include normal actions.
</p>
<p><b>Example</b>
</p>
<pre>
: 'a' 'b' 'c';
hitespace: "[ \t\n]*";
</pre>
<p>Whitespace can be accessed on a per parse node basis using the
unctions: <b>d_ws_before</b> and <b>d_ws_after</b>, which return the
tart of the whitespace before start_loc.s and after end respectively.
</p>
</dd> <dt>Ambiguities</dt><dd>
<p>Ambiguities are resolved automatically based on priorities and
associativities.  In addition, when the other resolution techniques
fail, user defined ambiguity resolution is possible.  The default
ambiguity handler produces a fatal error on an unresolved ambiguity.
This behavior can be replaced with a user defined resolvers the
signature of which is provided in dparse.h.
</p>
<p>If the <b>verbose_level</b> flag is set, the default ambiguity
andler will print out parenthesized versions of the ambiguous parse
rees.  This may be of some assistence in disambiguating a grammar.
</p>
</dd>
<dt>Error Recovery</dt><dd>
<p>DParser implements an error recovery scheme appropriate to scannerless parsers.  I haven't had time to investigate all the prior work in this area, so I am not sure if it is novel.  Suffice for now that it is optional and works well with C/C++ like grammars.
</p>
</dd>
<dt>Parsing Options</dt><dd>
<p>Parser are instantiated with the function new_D_Parser.  The
resulting data structure contains a number of user configurable
options (see dparser.h).  These are provided reasonable default
values and include:
</p>

<ul>
<li> <p><b>initial_globals</b> - the initial global variables accessable through $g
</p>
</li>
<li> <p><b>initial_skip_space_fn</b> - the initial whitespace function
</p>
</li>
<li> <p><b>initial_scope</b> - the initial symbol table scope
</p>
</li>
<li> <p><b>syntax_error_fn</b> - the function called on a syntax error
</p>
</li>
<li> <p><b>ambiguity_fn</b> - the function called on an unresolved ambiguity
</p>
</li>
<li> <p><b>loc</b> - the initial location (set on an error).
</p>
</li></ul>

<p>In addtion, there are the following user configurables:
</p>

<ul>
<li> <p><b>sizeof_user_parse_node</b> - the sizeof D_ParseNodeUser
</p>
</li>
<li> <p><b>save_parse_tree</b> - whether or not the parse tree should be save once the final actions have been executed
</p>
</li>
<li> <p><b>dont_fixup_internal_productions</b> - to not convert the Kleene star into a variable number of children from a tree of reductions
</p>
</li>
<li> <p><b>dont_merge_epsilon_trees</b> - to not automatically remove ambiguities which result from trees of epsilon reductions without actions
</p>
</li>
<li> <p><b>dont_use_greediness_for_disambiguation</b> - do not use the rule that the longest parse which reduces to the same token should be used to disambiguate parses.  This rule is used to handle the case (if then else?) relatively cleanly.
</p>
</li>
<li> <p><b>dont_use_height_for_disambiguation</b> - do not use the rule that the least deep parse which reduces to the same token should be used to disabiguate parses.  This rule is used to handle recursive grammars relatiively cleanly.
</p>
</li>
<li> <p><b>dont_compare_stacks</b> - disables comparing stacks to handle certain exponential cases during ambiguous operator priority resolution.
</p>
</li>
<li> <p><b>commit_actions_interval</b> - how often to commit final actions (0 is immediate, MAXINT is essentially not till the end of parsing)
</p>
</li>
<li> <p><b>error_recovery</b> - whether or not to use error recovery (defaults ON)
</p>
</li></ul>

<p>An the following result values:
</p>

<ul>
<li> <p><b>syntax_errors</b> - how many syntax errors (if <b>error_recovery</b> was
on)
</p>
</li></ul>

<p>This final value should be checked to see if parse was successful.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Matthew L. Fidler for R interface, John Plevyak for
dparser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## This makes the ANSI c grammar file to parse C code:
mkdparse(system.file("ansic.test.g", package = "dparser"),
        file.path(tempdir(), "ansic_gram.c"),
         grammar_ident="ascii_C")
</code></pre>

<hr>
<h2 id='show+2CdparserFunction-method'>Print the s4 object</h2><span id='topic+show+2CdparserFunction-method'></span>

<h3>Description</h3>

<p>Print the s4 object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dparserFunction'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2CdparserFunction-method_+3A_object">object</code></td>
<td>
<p>dparserFunction to print.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
