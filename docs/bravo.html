<!DOCTYPE html><html><head><title>Help for package bravo</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bravo}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bits'><p>Bayesian Iterated Screening (ultra-high, high or low dimensional).</p></a></li>
<li><a href='#mip.sven'><p>Compute marginal inclusion probabilities from a fitted &quot;sven&quot; object.</p></a></li>
<li><a href='#predict.sven'><p>Make predictions from a fitted &quot;sven&quot; object.</p></a></li>
<li><a href='#sven'><p>Selection of variables with embedded screening using Bayesian methods (SVEN)</p>
in Gaussian linear models (ultra-high, high or low dimensional).</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Screening and Variable Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>3.2.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Dongjin Li [aut, cre], Debarshi Chakraborty[aut], Somak Dutta [aut], Vivekananda Roy [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dongjin Li &lt;liyangxiaobei@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Bayesian variable screening and selection for ultra-high dimensional linear regression models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.2), Matrix (&ge; 1.2-17)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-13 17:41:06 UTC; somakd</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-13 19:13:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='bits'>Bayesian Iterated Screening (ultra-high, high or low dimensional).</h2><span id='topic+bits'></span>

<h3>Description</h3>

<p>Perform Bayesian iterated screening in Gaussian regression models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bits(X, y, lam = 1, w = 0.5, pp = FALSE, max.var = nrow(X), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bits_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix. Sparse matrices are supported and every
care is taken not to make copies of this (typically) giant matrix.
No need to center or scale.</p>
</td></tr>
<tr><td><code id="bits_+3A_y">y</code></td>
<td>
<p>The response vector of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="bits_+3A_lam">lam</code></td>
<td>
<p>The slab precision parameter. Default: <code>1</code>.</p>
</td></tr>
<tr><td><code id="bits_+3A_w">w</code></td>
<td>
<p>The prior inclusion probability of each variable. Default: <code>1/2</code>.</p>
</td></tr>
<tr><td><code id="bits_+3A_pp">pp</code></td>
<td>
<p>Boolean: If <code>FALSE</code> (default) the algorithm stops after including <code>max.var</code> many variables.
If true, the posterior probability stopping rule is used.</p>
</td></tr>
<tr><td><code id="bits_+3A_max.var">max.var</code></td>
<td>
<p>The maximum number of variables to be included.</p>
</td></tr>
<tr><td><code id="bits_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> (default) will show the variable index included in each iteration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>model.pp</code></td>
<td>
<p>An integer vector of the screened model.</p>
</td></tr>
<tr><td><code>postprobs</code></td>
<td>
<p>The sequence of posterior probabilities until the last included variable.</p>
</td></tr>
<tr><td><code>lam</code></td>
<td>
<p>The value of lam, the slab precision parameter.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>The value of w, the prior inclusion probability.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wang, R., Dutta, S., Roy, V. (2021) Bayesian iterative screening in ultra-high dimensional 
settings. https://arxiv.org/abs/2107.10175
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=50; p=100;
TrueBeta &lt;- c(rep(5,3),rep(0,p-3))

rho &lt;- 0.6
x1 &lt;- matrix(rnorm(n*p), n, p)
X &lt;- sqrt(1-rho)*x1 + sqrt(rho)*rnorm(n)
y &lt;- 0.5 + X %*% TrueBeta + rnorm(n)
res&lt;-bits(X,y, pp=TRUE)
res$model.pp # the vector of screened model
res$postprobs # the log (unnormalized) posterior probabilities corresponding to the model.pp.
</code></pre>

<hr>
<h2 id='mip.sven'>Compute marginal inclusion probabilities from a fitted &quot;sven&quot; object.</h2><span id='topic+mip.sven'></span>

<h3>Description</h3>

<p>This function computes the marginal inclusion probabilities of all variables from
a fitted &quot;sven&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mip.sven(object, threshold = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mip.sven_+3A_object">object</code></td>
<td>
<p>A fitted &quot;sven&quot; object</p>
</td></tr>
<tr><td><code id="mip.sven_+3A_threshold">threshold</code></td>
<td>
<p>marginal inclusion probabilities above this threshold are stored. Default 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned is a data frame if the <code>sven</code> was run with a single matrix, 
or a list of two data frames if <code>sven</code> was run with a list of two matrices.
The first column are the variable names (or numbers if column names of were absent). 
Only the nonzero marginal inclusion probabilities are stored.
</p>


<h3>Author(s)</h3>

<p>Somak Dutta<br /> Maintainer:
Somak Dutta &lt;somakd@iastate.edu&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 50; p &lt;- 100; nonzero &lt;- 3
trueidx &lt;- 1:3
truebeta &lt;- c(4,5,6)
X &lt;- matrix(rnorm(n*p), n, p) # n x p covariate matrix
y &lt;- 0.5 + X[,trueidx] %*% truebeta + rnorm(n)
res &lt;- sven(X=X, y=y)
res$model.map # the MAP model
mip.sven(res)

Z &lt;- matrix(rnorm(n*p), n, p) # another covariate matrix
y2 = 0.5 + X[,trueidx] %*% truebeta  + Z[,1:2] %*% c(-2,-2) + rnorm(n)
res2 &lt;- sven(X=list(X,Z), y=y2)
mip.sven(res2) # two data frames, one for X and another for Z

</code></pre>

<hr>
<h2 id='predict.sven'>Make predictions from a fitted &quot;sven&quot; object.</h2><span id='topic+predict.sven'></span>

<h3>Description</h3>

<p>This function makes point predictions and computes prediction intervals
from a fitted &quot;sven&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sven'
predict(
  object,
  newdata,
  model = c("WAM", "MAP"),
  interval = c("none", "MC", "Z"),
  return.draws = FALSE,
  Nsim = 10000,
  level = 0.95,
  alpha = 1 - level,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sven_+3A_object">object</code></td>
<td>
<p>A fitted &quot;sven&quot; object</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_newdata">newdata</code></td>
<td>
<p>Matrix of new values for <code>X</code> at which predictions are to be made. Must be a matrix;
can be sparse as in Matrix package.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_model">model</code></td>
<td>
<p>The model to be used to make predictions. Model &quot;MAP&quot; gives the predictions calculated
using the MAP model; model &quot;WAM&quot; gives the predictions calculated using the WAM. Default: &quot;WAM&quot;.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation. If <code>interval</code> = <code>"none"</code>, only point predictions are returned;
if <code>interval</code> = <code>"MC"</code>, Monte Carlo prediction intervals are returned; if <code>interval</code> = <code>"Z"</code>, Z prediction 
intervals are returned.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_return.draws">return.draws</code></td>
<td>
<p>only required if <code>interval</code> = <code>"MC"</code>. if <code>TRUE</code>, the Monte Carlo samples are returned.
Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_nsim">Nsim</code></td>
<td>
<p>only required if <code>interval</code> = <code>"MC"</code>. The Monte Carlo sample size. Default: 10000.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_level">level</code></td>
<td>
<p>Confidence level of the interval. Default: 0.95.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_alpha">alpha</code></td>
<td>
<p>Type one error rate. Default: 1-<code>level</code>.</p>
</td></tr>
<tr><td><code id="predict.sven_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on &quot;interval&quot; argument. If <code>interval</code> = <code>"none"</code>, the object is an 
<code class="reqn">\code{ncol(newdata)}\times 1</code> vector of the point predictions; otherwise, the object is an
<code class="reqn">\code{ncol(newdata)}\times 3</code> matrix with the point predictions in the first column and the lower and upper bounds 
of prediction intervals in the second and third columns, respectively.
</p>
<p>if return.draws is <code>TRUE</code>, a list with the following components is returned:
</p>
<table>
<tr><td><code>prediction</code></td>
<td>
<p>vector or matrix as above</p>
</td></tr>
<tr><td><code>mc.draws</code></td>
<td>
<p>an <code class="reqn">\code{ncol(newdata)} \times \code{Nsim}</code> matrix of the Monte Carlo samples</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongjin Li and Somak Dutta<br /> Maintainer:
Dongjin Li &lt;dongjl@iastate.edu&gt;
</p>


<h3>References</h3>

<p>Li, D., Dutta, S., Roy, V.(2020) Model Based Screening Embedded Bayesian Variable Selection for Ultra-high 
Dimensional Settings http://arxiv.org/abs/2006.07561
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 80; p = 100; nonzero = 5
trueidx &lt;- 1:5
nonzero.value &lt;- c(0.50, 0.75, 1.00, 1.25, 1.50)
TrueBeta = numeric(p)
TrueBeta[trueidx] &lt;- nonzero.value

X &lt;- matrix(rnorm(n*p), n, p)
y &lt;- 0.5 + X %*% TrueBeta + rnorm(n)
res &lt;- sven(X=X, y=y)
newx &lt;- matrix(rnorm(20*p), 20, p)
# predicted values at a new data matrix using MAP model
yhat &lt;- predict(object = res, newdata = newx, model = "MAP", interval = "none")
# 95% Monte Carlo prediction interval using WAM
MC.interval &lt;- predict(object = res, model = "WAM", newdata = newx, interval = "MC", level=0.95)
# 95% Z-prediction interval using MAP model
Z.interval &lt;- predict(object = res, model = "MAP", newdata = newx, interval = "Z", level = 0.95)
</code></pre>

<hr>
<h2 id='sven'>Selection of variables with embedded screening using Bayesian methods (SVEN) 
in Gaussian linear models (ultra-high, high or low dimensional).</h2><span id='topic+sven'></span>

<h3>Description</h3>

<p>SVEN is an approach to selecting variables with embedded screening 
using a Bayesian hierarchical model. It is also a variable selection method in the spirit of 
the stochastic shotgun search algorithm. However, by embedding a unique model 
based screening and using fast Cholesky updates, SVEN produces a highly scalable 
algorithm to explore gigantic model spaces and rapidly identify the regions of 
high posterior probabilities. It outputs the log (unnormalized) posterior 
probability of a set of best (highest probability) models. 
For more details, see Li et al. (2023, https://doi.org/10.1080/10618600.2022.2074428)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sven(
  X,
  y,
  w = NULL,
  lam = NULL,
  Ntemp = 10,
  Tmax = NULL,
  Miter = 50,
  wam.threshold = 0.5,
  log.eps = -16,
  L = 20,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sven_+3A_x">X</code></td>
<td>
<p>The <code class="reqn">n\times p</code> covariate matrix or list of two matrices without intercept. 
The following classes are supported: <code>matrix</code> and <code>dgCMatrix</code>. Every care is taken not to make copies of these (typically)
giant matrices. No need to center or scale these matrices manually. Scaling is performed implicitly and 
regression coefficient are returned on the original scale. Typically, in a combined GWAS-TWAS type 
analysis, <code>X[[1]]</code> should be a sparse matrix and <code>X[[2]]</code> should be a dense matrix.</p>
</td></tr>
<tr><td><code id="sven_+3A_y">y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>. No need to center or scale.</p>
</td></tr>
<tr><td><code id="sven_+3A_w">w</code></td>
<td>
<p>The prior inclusion probability of each variable. Default: NULL, whence it is set as
<code class="reqn">\sqrt{n}/p</code> if <code class="reqn">X</code> is a matrix. Or <code class="reqn">(\sqrt{n}/p_1,\sqrt{n}/p_2)</code> if $X$ is a list of 
two matrices with <code class="reqn">p_1</code> and <code class="reqn">p_2</code> columns.</p>
</td></tr>
<tr><td><code id="sven_+3A_lam">lam</code></td>
<td>
<p>The slab precision parameter. Default: NULL, whence it is set as <code class="reqn">n/p^2</code> for 
as suggested by the theory of Li et al. (2023). Similarly, it's a vector of length two with values
<code class="reqn">\sqrt{n}/P_1^2</code> and <code class="reqn">\sqrt{n}/p_2^2</code> when <code>X</code> is a list.</p>
</td></tr>
<tr><td><code id="sven_+3A_ntemp">Ntemp</code></td>
<td>
<p>The number of temperatures. Default: 10.</p>
</td></tr>
<tr><td><code id="sven_+3A_tmax">Tmax</code></td>
<td>
<p>The maximum temperature. Default: <code class="reqn">\log\log p+\log p</code>.</p>
</td></tr>
<tr><td><code id="sven_+3A_miter">Miter</code></td>
<td>
<p>The number of iterations per temperature. Default: <code>50</code>.</p>
</td></tr>
<tr><td><code id="sven_+3A_wam.threshold">wam.threshold</code></td>
<td>
<p>The threshold probability to select the covariates for WAM.
A covariate will be included in WAM if its corresponding marginal inclusion
probability is greater than the threshold. Default: 0.5.</p>
</td></tr>
<tr><td><code id="sven_+3A_log.eps">log.eps</code></td>
<td>
<p>The tolerance to choose the number of top models. See detail. Default: -16.</p>
</td></tr>
<tr><td><code id="sven_+3A_l">L</code></td>
<td>
<p>The minimum number of neighboring models screened. Default: 20.</p>
</td></tr>
<tr><td><code id="sven_+3A_verbose">verbose</code></td>
<td>
<p>If <code>FALSE</code>, the function prints the current temperature SVEN is at; the default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SVEN is developed based on a hierarchical Gaussian linear model with priors placed 
on the regression coefficients as well as on the model space as follows:
</p>
<p style="text-align: center;"><code class="reqn">y | X, \beta_0,\beta,\gamma,\sigma^2,w,\lambda \sim N(\beta_01 + X_\gamma\beta_\gamma,\sigma^2I_n)</code>
</p>

<p style="text-align: center;"><code class="reqn">\beta_i|\beta_0,\gamma,\sigma^2,w,\lambda \stackrel{indep.}{\sim} N(0, \gamma_i\sigma^2/\lambda),~i=1,\ldots,p,</code>
</p>

<p style="text-align: center;"><code class="reqn">(\beta_0,\sigma^2)|\gamma,w,p \sim p(\beta_0,\sigma^2) \propto 1/\sigma^2</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma_i|w,\lambda \stackrel{iid}{\sim} Bernoulli(w)</code>
</p>

<p>where <code class="reqn">X_\gamma</code> is the <code class="reqn">n \times |\gamma|</code> submatrix of <code class="reqn">X</code> consisting of 
those columns of <code class="reqn">X</code> for which <code class="reqn">\gamma_i=1</code> and similarly, <code class="reqn">\beta_\gamma</code> is the 
<code class="reqn">|\gamma|</code> subvector of <code class="reqn">\beta</code> corresponding to <code class="reqn">\gamma</code>.
Degenerate spike priors on inactive variables and Gaussian slab priors on active 
covariates makes the posterior 
probability (up to a normalizing constant) of a model <code class="reqn">P(\gamma|y)</code> available in 
explicit form (Li et al., 2020).
</p>
<p>The variable selection starts from an empty model and updates the model 
according to the posterior probability of its neighboring models for some pre-specified 
number of iterations. In each iteration, the models with small probabilities are screened 
out in order to quickly identify the regions of high posterior probabilities. A temperature 
schedule is used to facilitate exploration of models separated by valleys in the posterior 
probability function, thus mitigate posterior multimodality associated with variable selection models.
The default maximum temperature is guided by the asymptotic posterior model selection consistency results
in Li et al. (2020).
</p>
<p>SVEN provides the maximum a posteriori (MAP) model as well as the weighted average model 
(WAM). WAM is obtained in the following way: (1) keep the best (highest probability) <code class="reqn">K</code> 
distinct models <code class="reqn">\gamma^{(1)},\ldots,\gamma^{(K)}</code> with 
</p>
<p style="text-align: center;"><code class="reqn">\log P\left(\gamma^{(1)}|y\right) \ge \cdots \ge \log P\left(\gamma^{(K)}|y\right)</code>
</p>

<p>where <code class="reqn">K</code> is chosen so that 
<code class="reqn">\log \left\{P\left(\gamma^{(K)}|y\right)/P\left(\gamma^{(1)}|y\right)\right\} &gt; \code{log.eps}</code>;
(2) assign the weights </p>
<p style="text-align: center;"><code class="reqn">w_i = P(\gamma^{(i)}|y)/\sum_{k=1}^K P(\gamma^{(k)}|y)</code>
</p>

<p>to the model <code class="reqn">\gamma^{(i)}</code>; (3) define the approximate marginal inclusion probabilities 
for the <code class="reqn">j</code>th variable as </p>
<p style="text-align: center;"><code class="reqn">\hat\pi_j = \sum_{k=1}^K w_k I(\gamma^{(k)}_j = 1).</code>
</p>
 
<p>Then, the WAM is defined as the model containing variables <code class="reqn">j</code> with 
<code class="reqn">\hat\pi_j &gt; \code{wam.threshold}</code>. SVEN also provides all the top <code class="reqn">K</code> models which
are stored in an <code class="reqn">p \times K</code> sparse matrix, along with their corresponding log (unnormalized) 
posterior probabilities. 
</p>
<p>When <code>X</code> is a list with two matrices, say, <code>W</code> and <code>Z</code>, the above method is extended 
to <code>ncol(W)+ncol(Z)</code> dimensional regression. However, the hyperparameters <code>lam</code> and <code>w</code>
are chosen separately for the two matrices, the default values being  <code>nrow(W)/ncol(W)^2</code>
and <code>nrow(Z)/ncol(Z)^2</code> for <code>lam</code> and <code>sqrt(nrow(W))/ncol(W)</code> and
<code>sqrt(nrow(Z))/ncol(Z)</code> for <code>w</code>.
</p>
<p>The marginal inclusion probabities can be extracted by using the function <code>mip</code>.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>model.map</code></td>
<td>
<p>A vector of indices corresponding to the selected variables
in the MAP model.</p>
</td></tr>
<tr><td><code>model.wam</code></td>
<td>
<p>A vector of indices corresponding to the selected variables
in the WAM.</p>
</td></tr>
<tr><td><code>model.top</code></td>
<td>
<p>A sparse matrix storing the top models.</p>
</td></tr>
<tr><td><code>beta.map</code></td>
<td>
<p>The ridge estimator of regression coefficients in the MAP model.</p>
</td></tr>
<tr><td><code>beta.wam</code></td>
<td>
<p>The ridge estimator of regression coefficients in the WAM.</p>
</td></tr>
<tr><td><code>mip.map</code></td>
<td>
<p>The marginal inclusion probabilities of the variables in the MAP model.</p>
</td></tr>
<tr><td><code>mip.wam</code></td>
<td>
<p>The marginal inclusion probabilities of the variables in the WAM.</p>
</td></tr>
<tr><td><code>pprob.map</code></td>
<td>
<p>The log (unnormalized) posterior probability corresponding
to the MAP model.</p>
</td></tr>
<tr><td><code>pprob.top</code></td>
<td>
<p>A vector of the log (unnormalized) posterior probabilities
corresponding to the top models.</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>Additional statistics.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dongjin Li, Debarshi Chakraborty, and Somak Dutta<br /> Maintainer:
Dongjin Li &lt;liyangxiaobei@gmail.com&gt;
</p>


<h3>References</h3>

<p>Li, D., Dutta, S., and Roy, V. (2023). Model based screening embedded Bayesian variable 
selection for ultra-high dimensional settings. Journal of Computational and Graphical Statistics, 
32(1), 61-73.
</p>


<h3>See Also</h3>

<p>[mip.sven()] for marginal inclusion probabilities, [predict.sven()](via [predict()]) for prediction for .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 50; p &lt;- 100; nonzero &lt;- 3
trueidx &lt;- 1:3
truebeta &lt;- c(4,5,6)
X &lt;- matrix(rnorm(n*p), n, p) # n x p covariate matrix
y &lt;- 0.5 + X[,trueidx] %*% truebeta + rnorm(n)
res &lt;- sven(X=X, y=y)
res$model.map # the MAP model


Z &lt;- matrix(rnorm(n*p), n, p) # another covariate matrix
y2 = 0.5 + X[,trueidx] %*% truebeta  + Z[,1:2] %*% c(-2,-2) + rnorm(n)
res2 &lt;- sven(X=list(X,Z), y=y2)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
