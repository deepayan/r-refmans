<!DOCTYPE html><html><head><title>Help for package bayesrules</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bayesrules}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#airbnb'><p>Chicago AirBnB Data</p></a></li>
<li><a href='#airbnb_small'><p>Chicago AirBnB Data</p></a></li>
<li><a href='#bald_eagles'><p>Bald Eagle Count Data</p></a></li>
<li><a href='#basketball'><p>WNBA Basketball Data</p></a></li>
<li><a href='#bechdel'><p>Bechdel Test for over 1500 movies</p></a></li>
<li><a href='#big_word_club'><p>Big Word Club (BWC)</p></a></li>
<li><a href='#bike_users'><p>Capital Bikeshare Bike Ridership (Registered and Casual Riders)</p></a></li>
<li><a href='#bikes'><p>Capital Bikeshare Bike Ridership</p></a></li>
<li><a href='#bird_counts'><p>Bird Counts Data</p></a></li>
<li><a href='#book_banning'><p>Book Banning Data</p></a></li>
<li><a href='#cherry_blossom_sample'><p>Cherry Blossom Running Race</p></a></li>
<li><a href='#classification_summary'><p>Posterior Classification Summaries</p></a></li>
<li><a href='#classification_summary_cv'><p>Cross-Validated Posterior Classification Summaries</p></a></li>
<li><a href='#climbers_sub'><p>Himalayan Climber Data</p></a></li>
<li><a href='#coffee_ratings'><p>Coffee Ratings Data</p></a></li>
<li><a href='#coffee_ratings_small'><p>Coffee Ratings Data</p></a></li>
<li><a href='#equality_index'><p>LGBTQ+ Rights Laws by State</p></a></li>
<li><a href='#fake_news'><p>A collection of 150 news articles</p></a></li>
<li><a href='#football'><p>Football Brain Measurements</p></a></li>
<li><a href='#hotel_bookings'><p>Hotel Bookings Data</p></a></li>
<li><a href='#loons'><p>Loon Count Data</p></a></li>
<li><a href='#moma'><p>Museum of Modern Art (MoMA) data</p></a></li>
<li><a href='#moma_sample'><p>Museum of Modern Art (MoMA) data sample</p></a></li>
<li><a href='#naive_classification_summary'><p>Posterior Classification Summaries for a Naive Bayes model</p></a></li>
<li><a href='#naive_classification_summary_cv'><p>Cross-Validated Posterior Classification Summaries for a Naive Bayes model</p></a></li>
<li><a href='#penguins_bayes'><p>Penguins Data</p></a></li>
<li><a href='#plot_beta'><p>Plot a Beta Model for <code class="reqn">\pi</code></p></a></li>
<li><a href='#plot_beta_binomial'><p>Plot a Beta-Binomial Bayesian Model</p></a></li>
<li><a href='#plot_beta_ci'><p>Plot a Beta Model with Credible Interval</p></a></li>
<li><a href='#plot_binomial_likelihood'><p>Plot a Binomial Likelihood Function</p></a></li>
<li><a href='#plot_gamma'><p>Plot a Gamma Model for <code class="reqn">\lambda</code></p></a></li>
<li><a href='#plot_gamma_poisson'><p>Plot a Gamma-Poisson Bayesian Model</p></a></li>
<li><a href='#plot_normal'><p>Plot a Normal Model for <code class="reqn">\mu</code></p></a></li>
<li><a href='#plot_normal_likelihood'><p>Plot a Normal Likelihood Function</p></a></li>
<li><a href='#plot_normal_normal'><p>Plot a Normal-Normal Bayesian model</p></a></li>
<li><a href='#plot_poisson_likelihood'><p>Plot a Poisson Likelihood Function</p></a></li>
<li><a href='#pop_vs_soda'><p>Pop vs Soda vs Coke</p></a></li>
<li><a href='#prediction_summary'><p>Posterior Predictive Summaries</p></a></li>
<li><a href='#prediction_summary_cv'><p>Cross-Validated Posterior Predictive Summaries</p></a></li>
<li><a href='#pulse_of_the_nation'><p>Cards Against Humanity's Pulse of the Nation Survey</p></a></li>
<li><a href='#sample_mode'><p>Sample Mode</p></a></li>
<li><a href='#spotify'><p>Spotify Song Data</p></a></li>
<li><a href='#summarize_beta'><p>Summarize a Beta Model for <code class="reqn">\pi</code></p></a></li>
<li><a href='#summarize_beta_binomial'><p>Summarize a Beta-Binomial Bayesian model</p></a></li>
<li><a href='#summarize_gamma'><p>Summarize a Gamma Model for <code class="reqn">\lambda</code></p></a></li>
<li><a href='#summarize_gamma_poisson'><p>Summarize the Gamma-Poisson Model</p></a></li>
<li><a href='#summarize_normal_normal'><p>Summarize a Normal-Normal Bayesian model</p></a></li>
<li><a href='#voices'><p>Voice Pitch Data</p></a></li>
<li><a href='#weather_australia'><p>Weather Data for 3 Australian Cities</p></a></li>
<li><a href='#weather_perth'><p>Weather Data for Perth, Australia</p></a></li>
<li><a href='#weather_WU'><p>Weather Data for 2 Australian Cities</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Datasets and Supplemental Functions from Bayes Rules! Book</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides datasets and functions used for analysis 
  and visualizations in the Bayes Rules! book (<a href="https://www.bayesrulesbook.com">https://www.bayesrulesbook.com</a>). 
  The package contains a set of functions that summarize and plot Bayesian models from some conjugate families 
  and another set of functions for evaluation of some Bayesian models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, janitor, magrittr, dplyr, stats, purrr, rstanarm,
e1071, groupdata2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bayes-rules.github.io/bayesrules/docs/">https://bayes-rules.github.io/bayesrules/docs/</a>,
<a href="https://github.com/bayes-rules/bayesrules/">https://github.com/bayes-rules/bayesrules/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bayes-rules/bayesrules/issues">https://github.com/bayes-rules/bayesrules/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-25 02:24:11 UTC; minedogucu</td>
</tr>
<tr>
<td>Author:</td>
<td>Mine Dogucu <a href="https://orcid.org/0000-0002-8007-934X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Alicia Johnson [aut],
  Miles Ott <a href="https://orcid.org/0000-0003-4457-6565"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mine Dogucu &lt;mdogucu@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-25 04:30:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='airbnb'>Chicago AirBnB Data</h2><span id='topic+airbnb'></span>

<h3>Description</h3>

<p>The AirBnB data was collated by Trinh and Ameri as part of a course project
at St Olaf College, and distributed with &quot;Broadening Your Statistical Horizons&quot; by Legler and Roback.
This data set includes the prices and features for 1561 AirBnB listings in Chicago, collected in 2016.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>airbnb
</code></pre>


<h3>Format</h3>

<p>A data frame with 1561 rows and 12 variables. Each row represents a single AirBnB listing.
</p>

<dl>
<dt>price</dt><dd><p>the nightly price of the listing (in USD)</p>
</dd>
<dt>rating</dt><dd><p>the listing's average rating, on a scale from 1 to 5</p>
</dd>
<dt>reviews</dt><dd><p>number of user reviews the listing has</p>
</dd>
<dt>room_type</dt><dd><p>the type of listing (eg: Shared room)</p>
</dd>
<dt>accommodates</dt><dd><p>number of guests the listing accommodates</p>
</dd>
<dt>bedrooms</dt><dd><p>the number of bedrooms the listing has</p>
</dd>
<dt>minimum_stay</dt><dd><p>the minimum number of nights to stay in the listing</p>
</dd>
<dt>neighborhood</dt><dd><p>the neighborhood in which the listing is located</p>
</dd>
<dt>district</dt><dd><p>the broader district in which the listing is located</p>
</dd>
<dt>walk_score</dt><dd><p>the neighborhood's rating for walkability (0 - 100)</p>
</dd>
<dt>transit_score</dt><dd><p>the neighborhood's rating for access to public transit (0 - 100)</p>
</dd>
<dt>bike_score</dt><dd><p>the neighborhood's rating for bikeability (0 - 100)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ly Trinh and Pony Ameri (2018). Airbnb Price Determinants: A Multilevel Modeling Approach. Project for Statistics 316-Advanced Statistical Modeling, St. Olaf College.
Julie Legler and Paul Roback (2019). Broadening Your Statistical Horizons: Generalized Linear Models and Multilevel Models. <a href="https://bookdown.org/roback/bookdown-bysh/">https://bookdown.org/roback/bookdown-bysh/</a>.
<a href="https://github.com/proback/BeyondMLR/blob/master/data/airbnb.csv/">https://github.com/proback/BeyondMLR/blob/master/data/airbnb.csv/</a>
</p>

<hr>
<h2 id='airbnb_small'>Chicago AirBnB Data</h2><span id='topic+airbnb_small'></span>

<h3>Description</h3>

<p>The AirBnB data was collated by Trinh and Ameri as part of a course project
at St Olaf College, and distributed with &quot;Broadening Your Statistical Horizons&quot; by Legler and Roback.
This data set, a subset of the airbnb data in the bayesrules package, includes the prices and features for 869 AirBnB listings in Chicago, collected in 2016.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>airbnb_small
</code></pre>


<h3>Format</h3>

<p>A data frame with 869 rows and 12 variables. Each row represents a single AirBnB listing.
</p>

<dl>
<dt>price</dt><dd><p>the nightly price of the listing (in USD)</p>
</dd>
<dt>rating</dt><dd><p>the listing's average rating, on a scale from 1 to 5</p>
</dd>
<dt>reviews</dt><dd><p>number of user reviews the listing has</p>
</dd>
<dt>room_type</dt><dd><p>the type of listing (eg: Shared room)</p>
</dd>
<dt>accommodates</dt><dd><p>number of guests the listing accommodates</p>
</dd>
<dt>bedrooms</dt><dd><p>the number of bedrooms the listing has</p>
</dd>
<dt>minimum_stay</dt><dd><p>the minimum number of nights to stay in the listing</p>
</dd>
<dt>neighborhood</dt><dd><p>the neighborhood in which the listing is located</p>
</dd>
<dt>district</dt><dd><p>the broader district in which the listing is located</p>
</dd>
<dt>walk_score</dt><dd><p>the neighborhood's rating for walkability (0 - 100)</p>
</dd>
<dt>transit_score</dt><dd><p>the neighborhood's rating for access to public transit (0 - 100)</p>
</dd>
<dt>bike_score</dt><dd><p>the neighborhood's rating for bikeability (0 - 100)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ly Trinh and Pony Ameri (2018). Airbnb Price Determinants: A Multilevel Modeling Approach. Project for Statistics 316-Advanced Statistical Modeling, St. Olaf College.
Julie Legler and Paul Roback (2019). Broadening Your Statistical Horizons: Generalized Linear Models and Multilevel Models. <a href="https://bookdown.org/roback/bookdown-bysh/">https://bookdown.org/roback/bookdown-bysh/</a>.
<a href="https://github.com/proback/BeyondMLR/blob/master/data/airbnb.csv/">https://github.com/proback/BeyondMLR/blob/master/data/airbnb.csv/</a>
</p>

<hr>
<h2 id='bald_eagles'>Bald Eagle Count Data</h2><span id='topic+bald_eagles'></span>

<h3>Description</h3>

<p>Bald Eagle count data collected from the year 1981 to 2017, in late December, by birdwatchers in the Ontario, Canada area.
The data was made available by the Bird Studies Canada website and distributed through the R for Data Science TidyTuesday project. 
A more complete data set with a larger selection of birds can be found in the bird_counts data in the bayesrules package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bald_eagles
</code></pre>


<h3>Format</h3>

<p>A data frame with 37 rows and 5 variables. Each row represents Bald Eagle observations in the given year.
</p>

<dl>
<dt>year</dt><dd><p>year of data collection</p>
</dd>
<dt>count</dt><dd><p>number of birds observed</p>
</dd>
<dt>hours</dt><dd><p>total person-hours of observation period</p>
</dd>
<dt>count_per_hour</dt><dd><p>count divided by hours</p>
</dd>
<dt>count_per_week</dt><dd><p>count_per_hour multiplied by 168 hours per week</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv">https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv</a>.
</p>

<hr>
<h2 id='basketball'>WNBA Basketball Data</h2><span id='topic+basketball'></span>

<h3>Description</h3>

<p>The WNBA Basketball Data was scraped from <a href="https://www.basketball-reference.com/wnba/players/">https://www.basketball-reference.com/wnba/players/</a> and contains information on basketball players from the 2019 season.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basketball
</code></pre>


<h3>Format</h3>

<p>A data frame with 146 rows and 30 variables. Each row represents a single WNBA basketball player. The variables on each player are as follows.
</p>

<dl>
<dt>player_name</dt><dd><p>first and last name</p>
</dd>
<dt>height</dt><dd><p>height in inches</p>
</dd>
<dt>weight</dt><dd><p>weight in pounds</p>
</dd>
<dt>year</dt><dd><p>year of the WNBA season</p>
</dd>
<dt>team</dt><dd><p>team that the WNBA player is a member of</p>
</dd>
<dt>age</dt><dd><p>age in years</p>
</dd>
<dt>games_played</dt><dd><p>number of games played by the player in that season</p>
</dd>
<dt>games_started</dt><dd><p>number of games the player started in that season</p>
</dd>
<dt>avg_minutes_played</dt><dd><p>average number of minutes played per game</p>
</dd>
<dt>avg_field_goals</dt><dd><p>average number of field goals per game played</p>
</dd>
<dt>avg_field_goal_attempts</dt><dd><p>average number of field goals attempted per game played</p>
</dd>
<dt>field_goal_pct</dt><dd><p>percent of field goals made throughout the season</p>
</dd>
<dt>avg_three_pointers</dt><dd><p>average number of three pointers per game played</p>
</dd>
<dt>avg_three_pointer_attempts</dt><dd><p>average number of three pointers attempted per game played</p>
</dd>
<dt>three_pointer_pct</dt><dd><p>percent of three pointers made throughout the season</p>
</dd>
<dt>avg_two_pointers</dt><dd><p>average number of two pointers made per game played</p>
</dd>
<dt>avg_two_pointer_attempts</dt><dd><p>average number of two pointers attempted per game played</p>
</dd>
<dt>two_pointer_pct</dt><dd><p>percent of two pointers made throughout the season</p>
</dd>
<dt>avg_free_throws</dt><dd><p>average number of free throws made per game played</p>
</dd>
<dt>avg_free_throw_attempts</dt><dd><p>average number of free throws attempted per game played</p>
</dd>
<dt>free_throw_pct</dt><dd><p>percent of free throws made throughout the season</p>
</dd>
<dt>avg_offensive_rb</dt><dd><p>average number of offensive rebounds per game played</p>
</dd>
<dt>avg_defensive_rb</dt><dd><p>average number of defensive rebounds per game played</p>
</dd>
<dt>avg_rb</dt><dd><p>average number of rebounds (both offensive and defensive) per game played</p>
</dd>
<dt>avg_assists</dt><dd><p>average number of assists per game played</p>
</dd>
<dt>avg_steals</dt><dd><p>average number of steals per game played</p>
</dd>
<dt>avg_blocks</dt><dd><p>average number of blocks per game played</p>
</dd>
<dt>avg_turnovers</dt><dd><p>average number of turnovers per game played</p>
</dd>
<dt>avg_personal_fouls</dt><dd><p>average number of personal fouls per game played. Note: after 5 fouls the player is not allowed to play in that game anymore</p>
</dd>
<dt>avg_points</dt><dd><p>average number of points made per game played</p>
</dd>
<dt>total_minutes</dt><dd><p>total number of minutes played throughout the season</p>
</dd>
<dt>starter</dt><dd><p>whether or not the player started in more than half of the games they played</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.basketball-reference.com/">https://www.basketball-reference.com/</a>
</p>

<hr>
<h2 id='bechdel'>Bechdel Test for over 1500 movies</h2><span id='topic+bechdel'></span>

<h3>Description</h3>

<p>A dataset containing data behind the story
&quot;The Dollar-And-Cents Case Against Hollywood's Exclusion of Women&quot;
<a href="https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/">https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bechdel
</code></pre>


<h3>Format</h3>

<p>A data frame with 1794 rows and 3 variables:
</p>

<dl>
<dt>year</dt><dd><p>The release year of the movie</p>
</dd>
<dt>title</dt><dd><p>The title of the movie</p>
</dd>
<dt>binary</dt><dd><p>Bechdel test result (PASS, FAIL)</p>
</dd>
</dl>



<h3>Source</h3>

<p>&lt;https://github.com/fivethirtyeight/data/tree/master/bechdel/&gt;
</p>

<hr>
<h2 id='big_word_club'>Big Word Club (BWC)</h2><span id='topic+big_word_club'></span>

<h3>Description</h3>

<p>Data on the effectiveness of a digital learning program designed by the Abdul Latif Jameel Poverty Action Lab (J-PAL) to address disparities in vocabulary levels among children from households with different income levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big_word_club
</code></pre>


<h3>Format</h3>

<p>A data frame with 818 student-level observations and 31 variables:
</p>

<dl>
<dt>participant_id</dt><dd><p>unique student id</p>
</dd>
<dt>treat</dt><dd><p>control group (0) or treatment group (1)</p>
</dd>
<dt>age_months</dt><dd><p>age in months</p>
</dd>
<dt>female</dt><dd><p>whether student identifies as female</p>
</dd>
<dt>kindergarten</dt><dd><p>grade level, pre-school (0) or kindergarten (1)</p>
</dd>
<dt>teacher_id</dt><dd><p>unique teacher id</p>
</dd>
<dt>school_id</dt><dd><p>unique school id</p>
</dd>
<dt>private_school</dt><dd><p>whether school is private</p>
</dd>
<dt>title1</dt><dd><p>whether school has Title 1 status</p>
</dd>
<dt>free_reduced_lunch</dt><dd><p>percent of school that receive free / reduced lunch</p>
</dd>
<dt>state</dt><dd><p>school location</p>
</dd>
<dt>esl_observed</dt><dd><p>whether student has ESL status</p>
</dd>
<dt>special_ed_observed</dt><dd><p>whether student has special education status</p>
</dd>
<dt>new_student</dt><dd><p>whether student enrolled after program began</p>
</dd>
<dt>distracted_a1</dt><dd><p>student's distraction level during assessment 1 (0 = not distracted; 1 = mildly distracted; 2 = moderately distracted; 3 = extremely distracted)</p>
</dd>
<dt>distracted_a2</dt><dd><p>same as distracted_a1 but during assessment 2</p>
</dd>
<dt>distracted_ppvt</dt><dd><p>same as distracted_a1 but during standardized assessment</p>
</dd>
<dt>score_a1</dt><dd><p>student score on BWC assessment 1</p>
</dd>
<dt>invalid_a1</dt><dd><p>whether student's score on assessment 1 was invalid</p>
</dd>
<dt>score_a2</dt><dd><p>student score on BWC assessment 2</p>
</dd>
<dt>invalid_a2</dt><dd><p>whether student's score on assessment 2 was invalid</p>
</dd>
<dt>score_ppvt</dt><dd><p>student score on standardized assessment</p>
</dd>
<dt>score_ppvt_age</dt><dd><p>score_ppvt adjusted for age</p>
</dd>
<dt>invalid_ppvt</dt><dd><p>whether student's score on standardized assessment was invalid</p>
</dd>
<dt>t_logins_april</dt><dd><p>number of teacher logins onto BWC system in April</p>
</dd>
<dt>t_logins_total</dt><dd><p>number of teacher logins onto BWC system during entire study</p>
</dd>
<dt>t_weeks_used</dt><dd><p>number of weeks of the BWC program that the classroom has completed</p>
</dd>
<dt>t_words_learned</dt><dd><p>teacher response to the number of words students had learned through BWC (0 = almost none; 1 = 1 to 5; 2 = 6 to 10)</p>
</dd>
<dt>t_financial_struggle</dt><dd><p>teacher response to the number of their students that have families that experience financial struggle</p>
</dd>
<dt>t_misbehavior</dt><dd><p>teacher response to frequency that student misbehavior interferes with teaching (0 = never; 1 = rarely; 2 = occasionally; 3 = frequently)</p>
</dd>
<dt>t_years_experience</dt><dd><p>teacher's number of years of teaching experience</p>
</dd>
<dt>score_pct_change</dt><dd><p>percent change in scores before and after the program</p>
</dd>
</dl>



<h3>Source</h3>

<p>These data correspond to the following study: Ariel Kalil, Susan Mayer, Philip Oreopoulos (2020). Closing the word gap with Big Word Club: Evaluating the Impact of a Tech-Based Early Childhood Vocabulary Program. Data was obtained through the was obtained through the Inter-university Consortium for Political and Social Research (ICPSR) <a href="https://www.openicpsr.org/openicpsr/project/117330/version/V1/view/">https://www.openicpsr.org/openicpsr/project/117330/version/V1/view/</a>.
</p>

<hr>
<h2 id='bike_users'>Capital Bikeshare Bike Ridership (Registered and Casual Riders)</h2><span id='topic+bike_users'></span>

<h3>Description</h3>

<p>Data on ridership among registered members and casual users of the Capital Bikeshare service in Washington, D.C..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bike_users
</code></pre>


<h3>Format</h3>

<p>A data frame with 534 daily observations, 267 each for registered riders and casual riders, and 13 variables:
</p>

<dl>
<dt>date</dt><dd><p>date of observation</p>
</dd>
<dt>season</dt><dd><p>fall, spring, summer, or winter</p>
</dd>
<dt>year</dt><dd><p>the year of the date</p>
</dd>
<dt>month</dt><dd><p>the month of the date</p>
</dd>
<dt>day_of_week</dt><dd><p>the day of the week</p>
</dd>
<dt>weekend</dt><dd><p>whether or not the date falls on a weekend (TRUE or FALSE)</p>
</dd>
<dt>holiday</dt><dd><p>whether or not the date falls on a holiday (yes or no)</p>
</dd>
<dt>temp_actual</dt><dd><p>raw temperature (degrees Fahrenheit)</p>
</dd>
<dt>temp_feel</dt><dd><p>what the temperature feels like (degrees Fahrenheit)</p>
</dd>
<dt>humidity</dt><dd><p>humidity level (percentage)</p>
</dd>
<dt>windspeed</dt><dd><p>wind speed (miles per hour)</p>
</dd>
<dt>weather_cat</dt><dd><p>weather category (categ1 = pleasant, categ2 = moderate, categ3 = severe)</p>
</dd>
<dt>user</dt><dd><p>rider type (casual or registered)</p>
</dd>
<dt>rides</dt><dd><p>number of bikeshare rides</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fanaee-T, Hadi and Gama, Joao (2013). Event labeling combining ensemble detectors and background knowledge. Progress in Artificial Intelligence. <a href="https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset/">https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset/</a>
</p>

<hr>
<h2 id='bikes'>Capital Bikeshare Bike Ridership</h2><span id='topic+bikes'></span>

<h3>Description</h3>

<p>Data on ridership among registered members of the Capital Bikeshare service in Washington, D.C..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bikes
</code></pre>


<h3>Format</h3>

<p>A data frame with 500 daily observations and 13 variables:
</p>

<dl>
<dt>date</dt><dd><p>date of observation</p>
</dd>
<dt>season</dt><dd><p>fall, spring, summer, or winter</p>
</dd>
<dt>year</dt><dd><p>the year of the date</p>
</dd>
<dt>month</dt><dd><p>the month of the date</p>
</dd>
<dt>day_of_week</dt><dd><p>the day of the week</p>
</dd>
<dt>weekend</dt><dd><p>whether or not the date falls on a weekend (TRUE or FALSE)</p>
</dd>
<dt>holiday</dt><dd><p>whether or not the date falls on a holiday (yes or no)</p>
</dd>
<dt>temp_actual</dt><dd><p>raw temperature (degrees Fahrenheit)</p>
</dd>
<dt>temp_feel</dt><dd><p>what the temperature feels like (degrees Fahrenheit)</p>
</dd>
<dt>humidity</dt><dd><p>humidity level (percentage)</p>
</dd>
<dt>windspeed</dt><dd><p>wind speed (miles per hour)</p>
</dd>
<dt>weather_cat</dt><dd><p>weather category (categ1 = pleasant, categ2 = moderate, categ3 = severe)</p>
</dd>
<dt>rides</dt><dd><p>number of bikeshare rides</p>
</dd>
</dl>



<h3>Source</h3>

<p>Fanaee-T, Hadi and Gama, Joao (2013). Event labeling combining ensemble detectors and background knowledge. Progress in Artificial Intelligence. <a href="https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset">https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset</a>
</p>

<hr>
<h2 id='bird_counts'>Bird Counts Data</h2><span id='topic+bird_counts'></span>

<h3>Description</h3>

<p>Bird count data collected between the years 1921 and 2017, in late December, by birdwatchers in the Ontario, Canada area.
The data was made available by the Bird Studies Canada website and distributed through the R for Data Science TidyTuesday project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bird_counts
</code></pre>


<h3>Format</h3>

<p>A data frame with 18706 rows and 7 variables. Each row represents observations for the given bird species in the given year.
</p>

<dl>
<dt>year</dt><dd><p>year of data collection</p>
</dd>
<dt>species</dt><dd><p>scientific name of observed bird species</p>
</dd>
<dt>species_latin</dt><dd><p>latin name of observed bird species</p>
</dd>
<dt>count</dt><dd><p>number of birds observed</p>
</dd>
<dt>hours</dt><dd><p>total person-hours of observation period</p>
</dd>
<dt>count_per_hour</dt><dd><p>count divided by hours</p>
</dd>
<dt>count_per_week</dt><dd><p>count_per_hour multiplied by 168 hours per week</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-06-18/bird_counts.csv/">https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-06-18/bird_counts.csv/</a>.
</p>

<hr>
<h2 id='book_banning'>Book Banning Data</h2><span id='topic+book_banning'></span>

<h3>Description</h3>

<p>The book banning data was collected by Fast and Hegland as part of a course project
at St Olaf College, and distributed with &quot;Broadening Your Statistical Horizons&quot; by Legler and Roback.
This data set includes the features and outcomes for 931 book challenges 
(ie. requests to ban a book) made in the US between 2000 and 2010.
Information on the books being challenged and the characteristics of these books 
were collected from the American Library Society. State-level demographic information and 
political leanings were obtained from the US Census Bureau and Cook Political Report, respectively.
Due to an outlying large number of challenges, book challenges made in the state of Texas 
were omitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>book_banning
</code></pre>


<h3>Format</h3>

<p>A data frame with 931 rows and 17 variables. Each row represents a single book challenge within the given state and date.
</p>

<dl>
<dt>title</dt><dd><p>title of book being challenged</p>
</dd>
<dt>book_id</dt><dd><p>identifier for the book</p>
</dd>
<dt>author</dt><dd><p>author of the book</p>
</dd>
<dt>date</dt><dd><p>date of the challenge</p>
</dd>
<dt>year</dt><dd><p>year of the challenge</p>
</dd>
<dt>removed</dt><dd><p>whether or not the challenge was successful (the book was removed)</p>
</dd>
<dt>explicit</dt><dd><p>whether the book was challenged for sexually explicit material</p>
</dd>
<dt>antifamily</dt><dd><p>whether the book was challenged for anti-family material</p>
</dd>
<dt>occult</dt><dd><p>whether the book was challenged for occult material</p>
</dd>
<dt>language</dt><dd><p>whether the book was challenged for inapropriate language</p>
</dd>
<dt>lgbtq</dt><dd><p>whether the book was challenged for LGBTQ material</p>
</dd>
<dt>violent</dt><dd><p>whether the book was challenged for violent material</p>
</dd>
<dt>state</dt><dd><p>US state in which the challenge was made</p>
</dd>
<dt>political_value_index</dt><dd><p>Political Value Index of the state (negative = leans Republican, 0 = neutral, positive = leans Democrat)</p>
</dd>
<dt>median_income</dt><dd><p>median income in the state, relative to the average state median income</p>
</dd>
<dt>hs_grad_rate</dt><dd><p>high school graduation rate, in percent, relative to the average state high school graduation rate</p>
</dd>
<dt>college_grad_rate</dt><dd><p>college graduation rate, in percent, relative to the average state college graduation rate</p>
</dd>
</dl>



<h3>Source</h3>

<p>Shannon Fast and Thomas Hegland (2011). Book Challenges: A Statistical Examination. Project for Statistics 316-Advanced Statistical Modeling, St. Olaf College.
Julie Legler and Paul Roback (2019). Broadening Your Statistical Horizons: Generalized Linear Models and Multilevel Models. <a href="https://bookdown.org/roback/bookdown-bysh/">https://bookdown.org/roback/bookdown-bysh/</a>.
<a href="https://github.com/proback/BeyondMLR/blob/master/data/bookbanningNoTex.csv/">https://github.com/proback/BeyondMLR/blob/master/data/bookbanningNoTex.csv/</a>
</p>

<hr>
<h2 id='cherry_blossom_sample'>Cherry Blossom Running Race</h2><span id='topic+cherry_blossom_sample'></span>

<h3>Description</h3>

<p>A sub-sample of outcomes for the annual Cherry Blossom Ten Mile race in Washington, D.C.. This sub-sample was taken from the complete Cherry data in the mdsr package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cherry_blossom_sample
</code></pre>


<h3>Format</h3>

<p>A data frame with 252 Cherry Blossom outcomes and 7 variables:
</p>

<dl>
<dt>runner</dt><dd><p>a unique identifier for the runner</p>
</dd>
<dt>age</dt><dd><p>age of the runner</p>
</dd>
<dt>net</dt><dd><p>time to complete the race, from starting line to finish line (minutes)</p>
</dd>
<dt>gun</dt><dd><p>time between the official start of the of race and the finish line (minutes)</p>
</dd>
<dt>year</dt><dd><p>year of the race</p>
</dd>
<dt>previous</dt><dd><p>the number of previous years in which the subject ran in the race</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data in the original Cherry data set were obtained from <a href="https://www.cherryblossom.org/post-race/race-results/">https://www.cherryblossom.org/post-race/race-results/</a>.
</p>

<hr>
<h2 id='classification_summary'>Posterior Classification Summaries</h2><span id='topic+classification_summary'></span>

<h3>Description</h3>

<p>Given a set of observed data including a binary response variable y 
and an rstanreg model of y, 
this function returns summaries of the model's posterior classification quality.
These summaries include a confusion matrix as well as estimates of the model's
sensitivity, specificity, and overall accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classification_summary(model, data, cutoff = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classification_summary_+3A_model">model</code></td>
<td>
<p>an rstanreg model object with binary y</p>
</td></tr>
<tr><td><code id="classification_summary_+3A_data">data</code></td>
<td>
<p>data frame including the variables in the model, both response y and predictors x</p>
</td></tr>
<tr><td><code id="classification_summary_+3A_cutoff">cutoff</code></td>
<td>
<p>probability cutoff to classify a new case as positive (0.5 is the default)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(20)
z &lt;- 3*x
prob &lt;- 1/(1+exp(-z))
y &lt;- rbinom(20, 1, prob)
example_data &lt;- data.frame(x = x, y = y)
example_model &lt;- rstanarm::stan_glm(y ~ x, data = example_data, family = binomial)
classification_summary(model = example_model, data = example_data, cutoff = 0.5)                   
</code></pre>

<hr>
<h2 id='classification_summary_cv'>Cross-Validated Posterior Classification Summaries</h2><span id='topic+classification_summary_cv'></span>

<h3>Description</h3>

<p>Given a set of observed data including a binary response variable y 
and an rstanreg model of y, 
this function returns cross validated estimates of the model's posterior classification quality:
sensitivity, specificity, and overall accuracy.
For hierarchical models of class lmerMod, the folds are comprised by collections of groups, not individual observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classification_summary_cv(model, data, group, k, cutoff = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classification_summary_cv_+3A_model">model</code></td>
<td>
<p>an rstanreg model object with binary y</p>
</td></tr>
<tr><td><code id="classification_summary_cv_+3A_data">data</code></td>
<td>
<p>data frame including the variables in the model, both response y (0 or 1) and predictors x</p>
</td></tr>
<tr><td><code id="classification_summary_cv_+3A_group">group</code></td>
<td>
<p>a character string representing the name of the factor grouping variable, ie. random effect (only used for hierarchical models)</p>
</td></tr>
<tr><td><code id="classification_summary_cv_+3A_k">k</code></td>
<td>
<p>the number of folds to use for cross validation</p>
</td></tr>
<tr><td><code id="classification_summary_cv_+3A_cutoff">cutoff</code></td>
<td>
<p>probability cutoff to classify a new case as positive</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(20)
z &lt;- 3*x
prob &lt;- 1/(1+exp(-z))
y &lt;- rbinom(20, 1, prob)
example_data &lt;- data.frame(x = x, y = y)
example_model &lt;- rstanarm::stan_glm(y ~ x, data = example_data, family = binomial)
classification_summary_cv(model = example_model, data = example_data, k = 2, cutoff = 0.5)                   
</code></pre>

<hr>
<h2 id='climbers_sub'>Himalayan Climber Data</h2><span id='topic+climbers_sub'></span>

<h3>Description</h3>

<p>A sub-sample of the Himalayan Database distributed through the R for Data Science TidyTuesday project. This dataset includes information on the results and conditions for various Himalayan climbing expeditions. Each row corresponds to a single member of a climbing expedition team.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>climbers_sub
</code></pre>


<h3>Format</h3>

<p>A data frame with 2076 observations (1 per climber) and 22 variables:
</p>

<dl>
<dt>expedition_id</dt><dd><p>unique expedition identifier</p>
</dd>
<dt>member_id</dt><dd><p>unique climber identifier</p>
</dd>
<dt>peak_id</dt><dd><p>unique identifier of the expedition's destination peak</p>
</dd>
<dt>peak_name</dt><dd><p>name of the expedition's destination peak</p>
</dd>
<dt>year</dt><dd><p>year of expedition</p>
</dd>
<dt>season</dt><dd><p>season of expedition (Autumn, Spring, Summer, Winter)</p>
</dd>
<dt>sex</dt><dd><p>climber gender identity which the database oversimplifies to a binary category</p>
</dd>
<dt>age</dt><dd><p>climber age</p>
</dd>
<dt>citizenship</dt><dd><p>climber citizenship</p>
</dd>
<dt>expedition_role</dt><dd><p>climber's role in the expedition (eg: Co-Leader)</p>
</dd>
<dt>hired</dt><dd><p>whether the climber was a hired member of the expedition</p>
</dd>
<dt>highpoint_metres</dt><dd><p>the destination peak's highpoint (metres)</p>
</dd>
<dt>success</dt><dd><p>whether the climber successfully reached the destination</p>
</dd>
<dt>solo</dt><dd><p>whether the climber was on a solo expedition</p>
</dd>
<dt>oxygen_used</dt><dd><p>whether the climber utilized supplemental oxygen</p>
</dd>
<dt>died</dt><dd><p>whether the climber died during the expedition</p>
</dd>
<dt>death_cause</dt><dd></dd>
<dt>death_height_metres</dt><dd></dd>
<dt>injured</dt><dd><p>whether the climber was injured on the expedition</p>
</dd>
<dt>injury_type</dt><dd></dd>
<dt>injury_height_metres</dt><dd></dd>
<dt>count</dt><dd><p>number of climbers in the expedition</p>
</dd>
<dt>height_metres</dt><dd><p>height of the peak in meters</p>
</dd>
<dt>first_ascent_year</dt><dd><p>the year of the first recorded summit of the peak (though not necessarily the actual first summit!)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Original source: <a href="https://www.himalayandatabase.com/">https://www.himalayandatabase.com/</a>. Complete dataset distributed by: <a href="https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-09-22/">https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-09-22/</a>.
</p>

<hr>
<h2 id='coffee_ratings'>Coffee Ratings Data</h2><span id='topic+coffee_ratings'></span>

<h3>Description</h3>

<p>A sub-set of data on coffee bean ratings / quality originally collected by James LeDoux (jmzledoux) and distributed through the R for Data Science TidyTuesday project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coffee_ratings
</code></pre>


<h3>Format</h3>

<p>A data frame with 1339 batches of coffee beans and 27 variables on each batch. 
</p>

<dl>
<dt>owner</dt><dd><p>farm owner</p>
</dd>
<dt>farm_name</dt><dd><p>farm where beans were grown</p>
</dd>
<dt>country_of_origin</dt><dd><p>country where farm is</p>
</dd>
<dt>mill</dt><dd><p>where beans were processed</p>
</dd>
<dt>in_country_partner</dt><dd><p>country of coffee partner</p>
</dd>
<dt>altitude_low_meters</dt><dd><p>lowest altitude of the farm</p>
</dd>
<dt>altitude_high_meters</dt><dd><p>highest altitude of the farm</p>
</dd>
<dt>altitude_mean_meters</dt><dd><p>average altitude of the farm</p>
</dd>
<dt>number_of_bags</dt><dd><p>number of bags tested</p>
</dd>
<dt>bag_weight</dt><dd><p>weight of each tested bag</p>
</dd>
<dt>species</dt><dd><p>bean species</p>
</dd>
<dt>variety</dt><dd><p>bean variety</p>
</dd>
<dt>processing_method</dt><dd><p>how beans were processed</p>
</dd>
<dt>aroma</dt><dd><p>bean aroma grade</p>
</dd>
<dt>flavor</dt><dd><p>bean flavor grade</p>
</dd>
<dt>aftertaste</dt><dd><p>bean aftertaste grade</p>
</dd>
<dt>acidity</dt><dd><p>bean acidity grade</p>
</dd>
<dt>body</dt><dd><p>bean body grade</p>
</dd>
<dt>balance</dt><dd><p>bean balance grade</p>
</dd>
<dt>uniformity</dt><dd><p>bean uniformity grade</p>
</dd>
<dt>clean_cup</dt><dd><p>bean clean cup grade</p>
</dd>
<dt>sweetness</dt><dd><p>bean sweetness grade</p>
</dd>
<dt>moisture</dt><dd><p>bean moisture grade</p>
</dd>
<dt>category_one_defects</dt><dd><p>count of category one defects</p>
</dd>
<dt>category_two_defects</dt><dd><p>count of category two defects</p>
</dd>
<dt>color</dt><dd><p>bean color</p>
</dd>
<dt>total_cup_points</dt><dd><p>total bean rating (0 &ndash; 100)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv">https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv</a>.
</p>

<hr>
<h2 id='coffee_ratings_small'>Coffee Ratings Data</h2><span id='topic+coffee_ratings_small'></span>

<h3>Description</h3>

<p>A sub-set of data on coffee bean ratings / quality originally collected by James LeDoux (jmzledoux) and distributed through the R for Data Science TidyTuesday project.
This is a simplified version of the coffee_ratings data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coffee_ratings_small
</code></pre>


<h3>Format</h3>

<p>A data frame with 636 batches of coffee beans and 11 variables on each batch. 
</p>

<dl>
<dt>farm_name</dt><dd><p>farm where beans were grown</p>
</dd>
<dt>total_cup_points</dt><dd><p>total bean rating (0 &ndash; 100)</p>
</dd>
<dt>aroma</dt><dd><p>bean aroma grade</p>
</dd>
<dt>flavor</dt><dd><p>bean flavor grade</p>
</dd>
<dt>aftertaste</dt><dd><p>bean aftertaste grade</p>
</dd>
<dt>acidity</dt><dd><p>bean acidity grade</p>
</dd>
<dt>body</dt><dd><p>bean body grade</p>
</dd>
<dt>balance</dt><dd><p>bean balance grade</p>
</dd>
<dt>uniformity</dt><dd><p>bean uniformity grade</p>
</dd>
<dt>sweetness</dt><dd><p>bean sweetness grade</p>
</dd>
<dt>moisture</dt><dd><p>bean moisture grade</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv">https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv</a>.
</p>

<hr>
<h2 id='equality_index'>LGBTQ+ Rights Laws by State</h2><span id='topic+equality_index'></span>

<h3>Description</h3>

<p>Data on the number of LGBTQ+ equality laws (as of 2019) and demographics in each U.S. state.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equality_index
</code></pre>


<h3>Format</h3>

<p>A data frame with 50 observations, one per state, and 6 variables:
</p>

<dl>
<dt>state</dt><dd><p>state name</p>
</dd>
<dt>region</dt><dd><p>region in which the state falls</p>
</dd>
<dt>gop_2016</dt><dd><p>percent of the 2016 presidential election vote earned by the Republican (&quot;GOP&quot;) candidate</p>
</dd>
<dt>laws</dt><dd><p>number of LGBTQ+ rights laws (as of 2019)</p>
</dd>
<dt>historical</dt><dd><p>political leaning of the state over time (gop = Republican, dem = Democrat, swing = swing state)</p>
</dd>
<dt>percent_urban</dt><dd><p>percent of state's residents that live in urban areas (by the 2010 census)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data on LGBTQ+ laws were obtained from Warbelow, Sarah, Courtnay Avant, and Colin Kutney (2020). 2019 State Equality Index. Washington, DC. Human Rights Campaign Foundation. <a href="https://assets2.hrc.org/files/assets/resources/HRC-SEI-2019-Report.pdf?_ga=2.148925686.1325740687.1594310864-1928808113.1594310864&amp;_gac=1.213124768.1594312278.EAIaIQobChMI9dP2hMzA6gIVkcDACh21GgLEEAAYASAAEgJiJvD_BwE/">https://assets2.hrc.org/files/assets/resources/HRC-SEI-2019-Report.pdf?_ga=2.148925686.1325740687.1594310864-1928808113.1594310864&amp;_gac=1.213124768.1594312278.EAIaIQobChMI9dP2hMzA6gIVkcDACh21GgLEEAAYASAAEgJiJvD_BwE/</a>. Data on urban residency obtained from <a href="https://www.icip.iastate.edu/tables/population/urban-pct-states/">https://www.icip.iastate.edu/tables/population/urban-pct-states/</a>.
</p>

<hr>
<h2 id='fake_news'>A collection of 150 news articles</h2><span id='topic+fake_news'></span>

<h3>Description</h3>

<p>A dataset containing data behind the study
&quot;FakeNewsNet: A Data Repository with News Content, Social Context and Spatialtemporal Information for Studying Fake News on Social Media&quot;
<a href="https://arxiv.org/abs/1809.01286">https://arxiv.org/abs/1809.01286</a>.
The news articles in this dataset were posted to Facebook in September 2016, in the run-up to the U.S. presidential election.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fake_news
</code></pre>


<h3>Format</h3>

<p>A data frame with 150 rows and 6 variables:
</p>

<dl>
<dt>title</dt><dd><p>The title of the news article</p>
</dd>
<dt>text</dt><dd><p>Text of the article</p>
</dd>
<dt>url</dt><dd><p>Hyperlink for the article</p>
</dd>
<dt>authors</dt><dd><p>Authors of the article</p>
</dd>
<dt>type</dt><dd><p>Binary variable indicating whether the article presents fake or real news(fake, real)</p>
</dd>
<dt>title_words</dt><dd><p>Number of words in the title</p>
</dd>
<dt>text_words</dt><dd><p>Number of words in the text</p>
</dd>
<dt>title_char</dt><dd><p>Number of characters in the title</p>
</dd>
<dt>text_char</dt><dd><p>Number of characters in the text</p>
</dd>
<dt>title_caps</dt><dd><p>Number of words that are all capital letters in the title</p>
</dd>
<dt>text_caps</dt><dd><p>Number of words that are all capital letters in the text</p>
</dd>
<dt>title_caps_percent</dt><dd><p>Percent of words that are all capital letters in the title</p>
</dd>
<dt>text_caps_percent</dt><dd><p>Percent of words that are all capital letters in the text</p>
</dd>
<dt>title_excl</dt><dd><p>Number of characters that are exclamation marks in the title</p>
</dd>
<dt>text_excl</dt><dd><p>Number of characters that are exclamation marks in the text</p>
</dd>
<dt>title_excl_percent</dt><dd><p>Percent of characters that are exclamation marks in the title</p>
</dd>
<dt>text_excl_percent</dt><dd><p>Percent of characters that are exclamation marks in the text</p>
</dd>
<dt>title_has_excl</dt><dd><p>Binary variable indicating whether the title of the article includes an exlamation point or not(TRUE, FALSE)</p>
</dd>
<dt>anger</dt><dd><p>Percent of words that are associated with anger</p>
</dd>
<dt>anticipation</dt><dd><p>Percent of words that are associated with anticipation</p>
</dd>
<dt>disgust</dt><dd><p>Percent of words that are associated with disgust</p>
</dd>
<dt>fear</dt><dd><p>Percent of words that are associated with fear</p>
</dd>
<dt>joy</dt><dd><p>Percent of words that are associated with joy</p>
</dd>
<dt>sadness</dt><dd><p>Percent of words that are associated with sadness</p>
</dd>
<dt>surprise</dt><dd><p>Percent of words that are associated with surprise</p>
</dd>
<dt>trust</dt><dd><p>Percent of words that are associated with trust</p>
</dd>
<dt>negative</dt><dd><p>Percent of words that have negative sentiment</p>
</dd>
<dt>positive</dt><dd><p>Percent of words that have positive sentiment</p>
</dd>
<dt>text_syllables</dt><dd><p>Number of syllables in text</p>
</dd>
<dt>text_syllables_per_word</dt><dd><p>Number of syllables per word in text</p>
</dd>
</dl>



<h3>Source</h3>

<p>Shu, K., Mahudeswaran, D., Wang, S., Lee, D. and Liu, H. (2018) FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media
</p>

<hr>
<h2 id='football'>Football Brain Measurements</h2><span id='topic+football'></span>

<h3>Description</h3>

<p>Brain measurements for football and non-football players as provided in the Lock5 package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>football
</code></pre>


<h3>Format</h3>

<p>A data frame with 75 observations and 5 variables:
</p>

<dl>
<dt>group</dt><dd><p>control = no football, 
fb_no_concuss = football player but no concussions, 
fb_concuss = football player with concussion history</p>
</dd>
<dt>years</dt><dd><p>Number of years a person played football</p>
</dd>
<dt>volume</dt><dd><p>Total hippocampus volume, in cubic centimeters</p>
</dd>
</dl>



<h3>Source</h3>

<p>Singh R, Meier T, Kuplicki R, Savitz J, et al., 
&quot;Relationship of Collegiate Football Experience and Concussion 
With Hippocampal Volume and Cognitive Outcome,&quot; JAMA, 311(18), 2014
</p>

<hr>
<h2 id='hotel_bookings'>Hotel Bookings Data</h2><span id='topic+hotel_bookings'></span>

<h3>Description</h3>

<p>A random subset of the data on hotel bookings originally collected by Antonio, Almeida and Nunes (2019) and distributed through the R for Data Science TidyTuesday project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hotel_bookings
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 hotel bookings and 32 variables on each booking. 
</p>

<dl>
<dt>hotel</dt><dd><p>&quot;Resort Hotel&quot; or &quot;City Hotel&quot;</p>
</dd>
<dt>is_canceled</dt><dd><p>whether the booking was cancelled</p>
</dd>
<dt>lead_time</dt><dd><p>number of days between booking and arrival</p>
</dd>
<dt>arrival_date_year</dt><dd><p>year of scheduled arrival</p>
</dd>
<dt>arrival_date_month</dt><dd><p>month of scheduled arrival</p>
</dd>
<dt>arrival_date_week_number</dt><dd><p>week of scheduled arrival</p>
</dd>
<dt>arrival_date_day_of_month</dt><dd><p>day of month of scheduled arrival</p>
</dd>
<dt>stays_in_weekend_nights</dt><dd><p>number of reserved weekend nights</p>
</dd>
<dt>stays_in_week_nights</dt><dd><p>number of reserved week nights</p>
</dd>
<dt>adults</dt><dd><p>number of adults in booking</p>
</dd>
<dt>children</dt><dd><p>number of children</p>
</dd>
<dt>babies</dt><dd><p>number of babies</p>
</dd>
<dt>meal</dt><dd><p>whether the booking includes breakfast (BB = bed &amp; breakfast), breakfast and dinner (HB = half board), or breakfast, lunch, and dinner (FB = full board)</p>
</dd>
<dt>country</dt><dd><p>guest's country of origin</p>
</dd>
<dt>market_segment</dt><dd><p>market segment designation (eg: TA = travel agent, TO = tour operator)</p>
</dd>
<dt>distribution_channel</dt><dd><p>booking distribution channel (eg: TA = travel agent, TO = tour operator)</p>
</dd>
<dt>is_repeated_guest</dt><dd><p>whether or not booking was made by a repeated guest</p>
</dd>
<dt>previous_cancellations</dt><dd><p>guest's number of previous booking cancellations</p>
</dd>
<dt>previous_bookings_not_canceled</dt><dd><p>guest's number of previous bookings that weren't cancelled</p>
</dd>
<dt>reserved_room_type</dt><dd><p>code for type of room reserved by guest</p>
</dd>
<dt>assigned_room_type</dt><dd><p>code for type of room assigned by hotel</p>
</dd>
<dt>booking_changes</dt><dd><p>number of changes made to the booking</p>
</dd>
<dt>deposit_type</dt><dd><p>No Deposit, Non Refund, Refundable</p>
</dd>
<dt>agent</dt><dd><p>booking travel agency</p>
</dd>
<dt>company</dt><dd><p>booking company</p>
</dd>
<dt>days_in_waiting_list</dt><dd><p>number of days the guest waited for booking confirmation</p>
</dd>
<dt>customer_type</dt><dd><p>Contract, Group, Transient, Transient-party (a transient booking tied to another transient booking)</p>
</dd>
<dt>average_daily_rate</dt><dd><p>average hotel cost per day</p>
</dd>
<dt>required_car_parking_spaces</dt><dd><p>number of parking spaces the guest needed</p>
</dd>
<dt>total_of_special_requests</dt><dd><p>number of guest special requests</p>
</dd>
<dt>reservation_status</dt><dd><p>Canceled, Check-Out, No-Show</p>
</dd>
<dt>reservation_status_date</dt><dd><p>when the guest cancelled or checked out</p>
</dd>
</dl>



<h3>Source</h3>

<p>Nuno Antonio, Ana de Almeida, and Luis Nunes (2019). &quot;Hotel booking demand datasets.&quot; Data in Brief (22): 41-49.
<a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/hotels.csv/">https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/hotels.csv/</a>.
</p>

<hr>
<h2 id='loons'>Loon Count Data</h2><span id='topic+loons'></span>

<h3>Description</h3>

<p>Loon count data collected from the year 2000 to 2017, in late December, by birdwatchers in the Ontario, Canada area.
The data was made available by the Bird Studies Canada website and distributed through the R for Data Science TidyTuesday project. 
A more complete data set with a larger selection of birds can be found in the bird_counts data in the bayesrules package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loons
</code></pre>


<h3>Format</h3>

<p>A data frame with 18 rows and 5 variables. Each row represents loon observations in the given year.
</p>

<dl>
<dt>year</dt><dd><p>year of data collection</p>
</dd>
<dt>count</dt><dd><p>number of loons observed</p>
</dd>
<dt>hours</dt><dd><p>total person-hours of observation period</p>
</dd>
<dt>count_per_hour</dt><dd><p>count divided by hours</p>
</dd>
<dt>count_per_100</dt><dd><p>count_per_hour multiplied by 100 hours</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-06-18/bird_counts.csv">https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-06-18/bird_counts.csv</a>.
</p>

<hr>
<h2 id='moma'>Museum of Modern Art (MoMA) data</h2><span id='topic+moma'></span>

<h3>Description</h3>

<p>The Museum of Modern Art data includes information about the individual artists included in the collection of the Museum of Modern Art in New York City.
It does not include information about works for artist collectives or companies.
The data was made available by MoMA itself and downloaded in December 2020.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moma
</code></pre>


<h3>Format</h3>

<p>A data frame with 10964 rows and 11 variables. Each row represents an individual artist in the MoMA collection.
</p>

<dl>
<dt>artist</dt><dd><p>name</p>
</dd>
<dt>country</dt><dd><p>country of origin</p>
</dd>
<dt>birth</dt><dd><p>year of birth</p>
</dd>
<dt>death</dt><dd><p>year of death</p>
</dd>
<dt>alive</dt><dd><p>whether or not the artist was living at the time of data collection (December 2020)</p>
</dd>
<dt>genx</dt><dd><p>whether or not the artist is Gen X or younger, ie. born during 1965 or after</p>
</dd>
<dt>gender</dt><dd><p>gender identity (as perceived by MoMA employees)</p>
</dd>
<dt>department</dt><dd><p>MoMA department in which the artist's works most frequently appear</p>
</dd>
<dt>count</dt><dd><p>number of the artist's works in the MoMA collection</p>
</dd>
<dt>year_acquired_min</dt><dd><p>first year MoMA acquired one of the artist's works</p>
</dd>
<dt>year_acquired_max</dt><dd><p>most recent year MoMA acquired one of the artist's works</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/MuseumofModernArt/collection/blob/master/Artworks.csv/">https://github.com/MuseumofModernArt/collection/blob/master/Artworks.csv/</a>.
</p>

<hr>
<h2 id='moma_sample'>Museum of Modern Art (MoMA) data sample</h2><span id='topic+moma_sample'></span>

<h3>Description</h3>

<p>A random sample of 100 artists represented in the Museum of Modern Art in New York City.
The data was made available by MoMA itself and downloaded in December 2020.
It does not include information about artist collectives or companies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moma_sample
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows and 10 variables. Each row represents an individual artist in the MoMA collection.
</p>

<dl>
<dt>artist</dt><dd><p>name</p>
</dd>
<dt>country</dt><dd><p>country of origin</p>
</dd>
<dt>birth</dt><dd><p>year of birth</p>
</dd>
<dt>death</dt><dd><p>year of death</p>
</dd>
<dt>alive</dt><dd><p>whether or not the artist was living at the time of data collection (December 2020)</p>
</dd>
<dt>genx</dt><dd><p>whether or not the artist is Gen X or younger, ie. born during 1965 or after</p>
</dd>
<dt>gender</dt><dd><p>gender identity (as perceived by MoMA employees)</p>
</dd>
<dt>count</dt><dd><p>number of the artist's works in the MoMA collection</p>
</dd>
<dt>year_acquired_min</dt><dd><p>first year MoMA acquired one of the artist's works</p>
</dd>
<dt>year_acquired_max</dt><dd><p>most recent year MoMA acquired one of the artist's works</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/MuseumofModernArt/collection/blob/master/Artworks.csv/">https://github.com/MuseumofModernArt/collection/blob/master/Artworks.csv/</a>.
</p>

<hr>
<h2 id='naive_classification_summary'>Posterior Classification Summaries for a Naive Bayes model</h2><span id='topic+naive_classification_summary'></span>

<h3>Description</h3>

<p>Given a set of observed data including a categorical response variable y 
and a naiveBayes model of y, 
this function returns summaries of the model's posterior classification quality.
These summaries include a confusion matrix as well as an estimate of the model's
overall accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naive_classification_summary(model, data, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naive_classification_summary_+3A_model">model</code></td>
<td>
<p>a naiveBayes model object with categorical y</p>
</td></tr>
<tr><td><code id="naive_classification_summary_+3A_data">data</code></td>
<td>
<p>data frame including the variables in the model</p>
</td></tr>
<tr><td><code id="naive_classification_summary_+3A_y">y</code></td>
<td>
<p>a character string indicating the y variable in data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins_bayes, package = "bayesrules")
example_model &lt;- e1071::naiveBayes(species ~ bill_length_mm, data = penguins_bayes)
naive_classification_summary(model = example_model, data = penguins_bayes, y = "species")
</code></pre>

<hr>
<h2 id='naive_classification_summary_cv'>Cross-Validated Posterior Classification Summaries for a Naive Bayes model</h2><span id='topic+naive_classification_summary_cv'></span>

<h3>Description</h3>

<p>Given a set of observed data including a categorical response variable y 
and a naiveBayes model of y, 
this function returns a cross validated confusion matrix by which to assess 
the model's posterior classification quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naive_classification_summary_cv(model, data, y, k = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naive_classification_summary_cv_+3A_model">model</code></td>
<td>
<p>a naiveBayes model object with categorical y</p>
</td></tr>
<tr><td><code id="naive_classification_summary_cv_+3A_data">data</code></td>
<td>
<p>data frame including the variables in the model</p>
</td></tr>
<tr><td><code id="naive_classification_summary_cv_+3A_y">y</code></td>
<td>
<p>a character string indicating the y variable in data</p>
</td></tr>
<tr><td><code id="naive_classification_summary_cv_+3A_k">k</code></td>
<td>
<p>the number of folds to use for cross validation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins_bayes, package = "bayesrules")
example_model &lt;- e1071::naiveBayes(species ~ bill_length_mm, data = penguins_bayes)
naive_classification_summary_cv(model = example_model, data = penguins_bayes, y = "species", k = 2)
</code></pre>

<hr>
<h2 id='penguins_bayes'>Penguins Data</h2><span id='topic+penguins_bayes'></span>

<h3>Description</h3>

<p>Data on penguins in the Palmer Archipelago, originally collected by Gordan etal and distributed through the penguins data in the palmerpenguins package.
In addition to the original penguins data is a variable above_average_weight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>penguins_bayes
</code></pre>


<h3>Format</h3>

<p>A data frame with 344 penguins and 9 variables on each. 
</p>

<dl>
<dt>species</dt><dd><p>species (Adelie, Chinstrap, Gentoo)</p>
</dd>
<dt>island</dt><dd><p>home island (Biscoe, Dream, Torgersen)</p>
</dd>
<dt>year</dt><dd><p>year of observation</p>
</dd>
<dt>bill_length_mm</dt><dd><p>length of bill (mm)</p>
</dd>
<dt>bill_depth_mm</dt><dd><p>depth of bill (mm)</p>
</dd>
<dt>flipper_length_mm</dt><dd><p>length of flipper (mm)</p>
</dd>
<dt>body_mass_g</dt><dd><p>body mass (g)</p>
</dd>
<dt>above_average_weight</dt><dd><p>whether or not the body mass exceeds 4200g (TRUE or FALSE)</p>
</dd>
<dt>sex</dt><dd><p>male or female</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gorman KB, Williams TD, and Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of antarctic penguins (Genus Pygoscelis). PLoS ONE, 9(3).
</p>

<hr>
<h2 id='plot_beta'>Plot a Beta Model for <code class="reqn">\pi</code></h2><span id='topic+plot_beta'></span>

<h3>Description</h3>

<p>Plots the probability density function (pdf) for
a Beta(alpha, beta) model of variable <code class="reqn">\pi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_beta(alpha, beta, mean = FALSE, mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_beta_+3A_alpha">alpha</code>, <code id="plot_beta_+3A_beta">beta</code></td>
<td>
<p>positive shape parameters of the Beta model</p>
</td></tr>
<tr><td><code id="plot_beta_+3A_mean">mean</code>, <code id="plot_beta_+3A_mode">mode</code></td>
<td>
<p>a logical value indicating whether to display the model mean and mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A density plot for the Beta model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_beta(alpha = 1, beta = 12, mean = TRUE, mode = TRUE)
</code></pre>

<hr>
<h2 id='plot_beta_binomial'>Plot a Beta-Binomial Bayesian Model</h2><span id='topic+plot_beta_binomial'></span>

<h3>Description</h3>

<p>Consider a Beta-Binomial Bayesian model for parameter <code class="reqn">\pi</code> with 
a Beta(alpha, beta) prior on <code class="reqn">\pi</code> and Binomial likelihood with n trials
and y successes. Given information on the prior (alpha and data) and data (y and n),
this function produces a plot of any combination of the corresponding prior pdf, 
scaled likelihood function, and posterior pdf.  All three are included by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_beta_binomial(
  alpha,
  beta,
  y = NULL,
  n = NULL,
  prior = TRUE,
  likelihood = TRUE,
  posterior = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_beta_binomial_+3A_alpha">alpha</code>, <code id="plot_beta_binomial_+3A_beta">beta</code></td>
<td>
<p>positive shape parameters of the prior Beta model</p>
</td></tr>
<tr><td><code id="plot_beta_binomial_+3A_y">y</code></td>
<td>
<p>observed number of successes</p>
</td></tr>
<tr><td><code id="plot_beta_binomial_+3A_n">n</code></td>
<td>
<p>observed number of trials</p>
</td></tr>
<tr><td><code id="plot_beta_binomial_+3A_prior">prior</code></td>
<td>
<p>a logical value indicating whether the prior model should be plotted</p>
</td></tr>
<tr><td><code id="plot_beta_binomial_+3A_likelihood">likelihood</code></td>
<td>
<p>a logical value indicating whether the scaled likelihood should be plotted</p>
</td></tr>
<tr><td><code id="plot_beta_binomial_+3A_posterior">posterior</code></td>
<td>
<p>a logical value indicating whether posterior model should be plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
plot_beta_binomial(alpha = 1, beta = 13, y = 25, n = 50)
plot_beta_binomial(alpha = 1, beta = 13, y = 25, n = 50, posterior = FALSE)

</code></pre>

<hr>
<h2 id='plot_beta_ci'>Plot a Beta Model with Credible Interval</h2><span id='topic+plot_beta_ci'></span>

<h3>Description</h3>

<p>Plots the probability density function (pdf) for a
Beta(alpha, beta) model of variable <code class="reqn">\pi</code> with markings indicating
a credible interval for <code class="reqn">\pi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_beta_ci(alpha, beta, ci_level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_beta_ci_+3A_alpha">alpha</code>, <code id="plot_beta_ci_+3A_beta">beta</code></td>
<td>
<p>positive shape parameters of the Beta model</p>
</td></tr>
<tr><td><code id="plot_beta_ci_+3A_ci_level">ci_level</code></td>
<td>
<p>credible interval level</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A density plot for the Beta model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_beta_ci(alpha = 7, beta = 12, ci_level = 0.80)
</code></pre>

<hr>
<h2 id='plot_binomial_likelihood'>Plot a Binomial Likelihood Function</h2><span id='topic+plot_binomial_likelihood'></span>

<h3>Description</h3>

<p>Plots the Binomial likelihood function for variable <code class="reqn">\pi</code>
given y observed successes in a series of n Binomial trials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_binomial_likelihood(y, n, mle = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_binomial_likelihood_+3A_y">y</code></td>
<td>
<p>number of successes</p>
</td></tr>
<tr><td><code id="plot_binomial_likelihood_+3A_n">n</code></td>
<td>
<p>number of trials</p>
</td></tr>
<tr><td><code id="plot_binomial_likelihood_+3A_mle">mle</code></td>
<td>
<p>a logical value indicating whether maximum likelihood estimate of <code class="reqn">\pi</code>, y/n, should be plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_binomial_likelihood(y = 3, n = 10, mle = TRUE)
</code></pre>

<hr>
<h2 id='plot_gamma'>Plot a Gamma Model for <code class="reqn">\lambda</code></h2><span id='topic+plot_gamma'></span>

<h3>Description</h3>

<p>Plots the probability density function (pdf) for
a Gamma(shape, rate) model of variable <code class="reqn">\lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_gamma(shape, rate, mean = FALSE, mode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_gamma_+3A_shape">shape</code></td>
<td>
<p>non-negative shape parameter of the Gamma model</p>
</td></tr>
<tr><td><code id="plot_gamma_+3A_rate">rate</code></td>
<td>
<p>non-negative rate parameter of the Gamma model</p>
</td></tr>
<tr><td><code id="plot_gamma_+3A_mean">mean</code>, <code id="plot_gamma_+3A_mode">mode</code></td>
<td>
<p>a logical value indicating whether to display the model mean and mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A density plot for the Gamma model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_gamma(shape = 2, rate = 11, mean = TRUE, mode = TRUE)

</code></pre>

<hr>
<h2 id='plot_gamma_poisson'>Plot a Gamma-Poisson Bayesian Model</h2><span id='topic+plot_gamma_poisson'></span>

<h3>Description</h3>

<p>Consider a Gamma-Poisson Bayesian model for rate parameter <code class="reqn">\lambda</code> with 
a Gamma(shape, rate) prior on <code class="reqn">\lambda</code> and a Poisson likelihood for the data. 
Given information on the prior (shape and rate) 
and data (the sample size n and sum_y),
this function produces a plot of any combination of the corresponding prior pdf, 
scaled likelihood function, and posterior pdf.  All three are included by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_gamma_poisson(
  shape,
  rate,
  sum_y = NULL,
  n = NULL,
  prior = TRUE,
  likelihood = TRUE,
  posterior = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_gamma_poisson_+3A_shape">shape</code></td>
<td>
<p>non-negative shape parameter of the Gamma prior</p>
</td></tr>
<tr><td><code id="plot_gamma_poisson_+3A_rate">rate</code></td>
<td>
<p>non-negative rate parameter of the Gamma prior</p>
</td></tr>
<tr><td><code id="plot_gamma_poisson_+3A_sum_y">sum_y</code></td>
<td>
<p>sum of observed data values for the Poisson likelihood</p>
</td></tr>
<tr><td><code id="plot_gamma_poisson_+3A_n">n</code></td>
<td>
<p>number of observations for the Poisson likelihood</p>
</td></tr>
<tr><td><code id="plot_gamma_poisson_+3A_prior">prior</code></td>
<td>
<p>a logical value indicating whether the prior model should be plotted.</p>
</td></tr>
<tr><td><code id="plot_gamma_poisson_+3A_likelihood">likelihood</code></td>
<td>
<p>a logical value indicating whether the scaled likelihood should be plotted.</p>
</td></tr>
<tr><td><code id="plot_gamma_poisson_+3A_posterior">posterior</code></td>
<td>
<p>a logical value indicating whether posterior model should be plotted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_gamma_poisson(shape = 100, rate = 20, sum_y = 39, n = 6)
plot_gamma_poisson(shape = 100, rate = 20, sum_y = 39, n = 6, posterior = FALSE)
</code></pre>

<hr>
<h2 id='plot_normal'>Plot a Normal Model for <code class="reqn">\mu</code></h2><span id='topic+plot_normal'></span>

<h3>Description</h3>

<p>Plots the probability density function (pdf) for a
Normal(mean, sd^2) model of variable <code class="reqn">\mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_normal(mean, sd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_normal_+3A_mean">mean</code></td>
<td>
<p>mean parameter of the Normal model</p>
</td></tr>
<tr><td><code id="plot_normal_+3A_sd">sd</code></td>
<td>
<p>standard deviation parameter of the Normal model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_normal(mean = 3.5, sd = 0.5)
</code></pre>

<hr>
<h2 id='plot_normal_likelihood'>Plot a Normal Likelihood Function</h2><span id='topic+plot_normal_likelihood'></span>

<h3>Description</h3>

<p>Plots the Normal likelihood function for variable <code class="reqn">\mu</code>
given a vector of Normal data y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_normal_likelihood(y, sigma = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_normal_likelihood_+3A_y">y</code></td>
<td>
<p>vector of observed data</p>
</td></tr>
<tr><td><code id="plot_normal_likelihood_+3A_sigma">sigma</code></td>
<td>
<p>optional value for assumed standard deviation of y. by default, this is calculated by the sample standard deviation of y.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot of Normal likelihood
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_normal_likelihood(y = rnorm(50, mean = 10, sd = 2), sigma = 1.5)
</code></pre>

<hr>
<h2 id='plot_normal_normal'>Plot a Normal-Normal Bayesian model</h2><span id='topic+plot_normal_normal'></span>

<h3>Description</h3>

<p>Consider a Normal-Normal Bayesian model for mean parameter <code class="reqn">\mu</code> with 
a N(mean, sd^2) prior on <code class="reqn">\mu</code> and a Normal likelihood for the data. 
Given information on the prior (mean and sd) 
and data (the sample size n, mean y_bar, and standard deviation sigma),
this function produces a plot of any combination of the corresponding prior pdf, 
scaled likelihood function, and posterior pdf.  All three are included by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_normal_normal(
  mean,
  sd,
  sigma = NULL,
  y_bar = NULL,
  n = NULL,
  prior = TRUE,
  likelihood = TRUE,
  posterior = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_normal_normal_+3A_mean">mean</code></td>
<td>
<p>mean of the Normal prior</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_sd">sd</code></td>
<td>
<p>standard deviation of the Normal prior</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_sigma">sigma</code></td>
<td>
<p>standard deviation of the data, or likelihood standard deviation</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_y_bar">y_bar</code></td>
<td>
<p>sample mean of the data</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_n">n</code></td>
<td>
<p>sample size of the data</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_prior">prior</code></td>
<td>
<p>a logical value indicating whether the prior model should be plotted</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_likelihood">likelihood</code></td>
<td>
<p>a logical value indicating whether the scaled likelihood should be plotted</p>
</td></tr>
<tr><td><code id="plot_normal_normal_+3A_posterior">posterior</code></td>
<td>
<p>a logical value indicating whether posterior model should be plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_normal_normal(mean = 0, sd = 3, sigma= 4, y_bar = 5, n = 3)
plot_normal_normal(mean = 0, sd = 3, sigma= 4, y_bar = 5, n = 3, posterior = FALSE)
</code></pre>

<hr>
<h2 id='plot_poisson_likelihood'>Plot a Poisson Likelihood Function</h2><span id='topic+plot_poisson_likelihood'></span>

<h3>Description</h3>

<p>Plots the Poisson likelihood function for variable <code class="reqn">\lambda</code>
given a vector of Poisson counts y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_poisson_likelihood(y, lambda_upper_bound = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_poisson_likelihood_+3A_y">y</code></td>
<td>
<p>vector of observed Poisson counts</p>
</td></tr>
<tr><td><code id="plot_poisson_likelihood_+3A_lambda_upper_bound">lambda_upper_bound</code></td>
<td>
<p>upper bound for lambda values to display on x-axis</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot of Poisson likelihood
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_poisson_likelihood(y = c(4, 2, 7), lambda_upper_bound = 10)
</code></pre>

<hr>
<h2 id='pop_vs_soda'>Pop vs Soda vs Coke</h2><span id='topic+pop_vs_soda'></span>

<h3>Description</h3>

<p>Results of a volunteer survey on how people around the U.S. refer to fizzy cola drinks. The options are &quot;pop&quot;, &quot;soda&quot;, &quot;coke&quot;, or &quot;other&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pop_vs_soda
</code></pre>


<h3>Format</h3>

<p>A data frame with 374250 observations, one per survey respondent, and 4 variables:
</p>

<dl>
<dt>state</dt><dd><p>the U.S. state in which the respondent resides</p>
</dd>
<dt>region</dt><dd><p>region in which the state falls (as defined by the U.S. Census)</p>
</dd>
<dt>word_for_cola</dt><dd><p>how the respondent refers to fizzy cola drinks</p>
</dd>
<dt>pop</dt><dd><p>whether or not the respondent refers to fizzy cola drinks as &quot;pop&quot;</p>
</dd>
</dl>



<h3>Source</h3>

<p>The survey responses were obtained at <a href="https://popvssoda.com/">https://popvssoda.com/</a> which is maintained by Alan McConchie.
</p>

<hr>
<h2 id='prediction_summary'>Posterior Predictive Summaries</h2><span id='topic+prediction_summary'></span>

<h3>Description</h3>

<p>Given a set of observed data including a quantitative response variable y 
and an rstanreg model of y, 
this function returns 4 measures of the posterior prediction quality.
Median absolute prediction error (mae) measures the typical difference between the observed y values and their posterior predictive medians (stable = TRUE) or means (stable = FALSE).
Scaled mae (mae_scaled) measures the typical number of absolute deviations (stable = TRUE) or standard deviations (stable = FALSE) that observed y values fall from their predictive medians (stable = TRUE) or means (stable = FALSE).
within_50 and within_90 report the proportion of observed y values that fall within their posterior prediction intervals, the probability levels of which are set by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction_summary(
  model,
  data,
  prob_inner = 0.5,
  prob_outer = 0.95,
  stable = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prediction_summary_+3A_model">model</code></td>
<td>
<p>an rstanreg model object with quantitative y</p>
</td></tr>
<tr><td><code id="prediction_summary_+3A_data">data</code></td>
<td>
<p>data frame including the variables in the model, both response y and predictors x</p>
</td></tr>
<tr><td><code id="prediction_summary_+3A_prob_inner">prob_inner</code></td>
<td>
<p>posterior predictive interval probability (a value between 0 and 1)</p>
</td></tr>
<tr><td><code id="prediction_summary_+3A_prob_outer">prob_outer</code></td>
<td>
<p>posterior predictive interval probability (a value between 0 and 1)</p>
</td></tr>
<tr><td><code id="prediction_summary_+3A_stable">stable</code></td>
<td>
<p>TRUE returns the number of absolute deviations and FALSE returns the standard deviations that observed y values fall from their predictive medians</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_data &lt;- data.frame(x = sample(1:100, 20))
example_data$y &lt;- example_data$x*3 + rnorm(20, 0, 5)
example_model &lt;- rstanarm::stan_glm(y ~ x,  data = example_data)
prediction_summary(example_model, example_data, prob_inner = 0.6, prob_outer = 0.80, stable = TRUE)
</code></pre>

<hr>
<h2 id='prediction_summary_cv'>Cross-Validated Posterior Predictive Summaries</h2><span id='topic+prediction_summary_cv'></span>

<h3>Description</h3>

<p>Given a set of observed data including a quantitative response variable y 
and an rstanreg model of y, 
this function returns 4 cross-validated measures of the model's posterior prediction quality: 
Median absolute prediction error (mae) measures the typical difference between the observed y values and their posterior predictive medians (stable = TRUE) or means (stable = FALSE).
Scaled mae (mae_scaled) measures the typical number of absolute deviations (stable = TRUE) or standard deviations (stable = FALSE) that observed y values fall from their predictive medians (stable = TRUE) or means (stable = FALSE).
within_50 and within_90 report the proportion of observed y values that fall within their posterior prediction intervals, the probability levels of which are set by the user.
For hierarchical models of class lmerMod, the folds are comprised by collections of groups, not individual observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction_summary_cv(
  data,
  group,
  model,
  k,
  prob_inner = 0.5,
  prob_outer = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prediction_summary_cv_+3A_data">data</code></td>
<td>
<p>data frame including the variables in the model, both response y and predictors x</p>
</td></tr>
<tr><td><code id="prediction_summary_cv_+3A_group">group</code></td>
<td>
<p>a character string representing the name of the factor grouping variable, ie. random effect (only used for hierarchical models)</p>
</td></tr>
<tr><td><code id="prediction_summary_cv_+3A_model">model</code></td>
<td>
<p>an rstanreg model object with quantitative y</p>
</td></tr>
<tr><td><code id="prediction_summary_cv_+3A_k">k</code></td>
<td>
<p>the number of folds to use for cross validation</p>
</td></tr>
<tr><td><code id="prediction_summary_cv_+3A_prob_inner">prob_inner</code></td>
<td>
<p>posterior predictive interval probability (a value between 0 and 1)</p>
</td></tr>
<tr><td><code id="prediction_summary_cv_+3A_prob_outer">prob_outer</code></td>
<td>
<p>posterior predictive interval probability (a value between 0 and 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_data &lt;- data.frame(x = sample(1:100, 20))
example_data$y &lt;- example_data$x*3 + rnorm(20, 0, 5)
example_model &lt;- rstanarm::stan_glm(y ~ x,  data = example_data)
prediction_summary_cv(model = example_model, data = example_data, k = 2)
</code></pre>

<hr>
<h2 id='pulse_of_the_nation'>Cards Against Humanity's Pulse of the Nation Survey</h2><span id='topic+pulse_of_the_nation'></span>

<h3>Description</h3>

<p>Cards Against Humanity's &quot;Pulse of the Nation&quot; project (<a href="https://thepulseofthenation.com/">https://thepulseofthenation.com/</a>) conducted monthly polls into people's social and political views, as well as some silly things. This data includes responses to a subset of questions included in the poll conducted in September 2017.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pulse_of_the_nation
</code></pre>


<h3>Format</h3>

<p>A data frame with observations on 1000 survey respondents with 15 variables:
</p>

<dl>
<dt>income</dt><dd><p>income in \$1000s</p>
</dd>
<dt>age</dt><dd><p>age in years</p>
</dd>
<dt>party</dt><dd><p>political party affiliation</p>
</dd>
<dt>trump_approval</dt><dd><p>approval level of Donald Trump's job performance</p>
</dd>
<dt>education</dt><dd><p>maximum education level completed</p>
</dd>
<dt>robots</dt><dd><p>opinion of how likely their job is to be replaced by robots within 10 years</p>
</dd>
<dt>climate_change</dt><dd><p>belief in climate change</p>
</dd>
<dt>transformers</dt><dd><p>the number of Transformers film the respondent has seen</p>
</dd>
<dt>science_is_honest</dt><dd><p>opinion of whether scientists are generally honest and serve the public good</p>
</dd>
<dt>vaccines_are_safe</dt><dd><p>opinion of whether vaccines are safe and protect children from disease</p>
</dd>
<dt>books</dt><dd><p>number of books read in the past year</p>
</dd>
<dt>ghosts</dt><dd><p>whether or not they believe in ghosts</p>
</dd>
<dt>fed_sci_budget</dt><dd><p>respondent's estimate of the percentage of the federal budget that is spent on scientific research</p>
</dd>
<dt>earth_sun</dt><dd><p>belief about whether the earth is always farther away from the sun in winter than in summer (TRUE or FALSE)</p>
</dd>
<dt>wise_unwise</dt><dd><p>whether the respondent would rather be wise but unhappy, or unwise but happy</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://thepulseofthenation.com/downloads/201709-CAH_PulseOfTheNation_Raw.csv">https://thepulseofthenation.com/downloads/201709-CAH_PulseOfTheNation_Raw.csv</a>
</p>

<hr>
<h2 id='sample_mode'>Sample Mode</h2><span id='topic+sample_mode'></span>

<h3>Description</h3>

<p>Calculate the sample mode of vector x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_mode(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_mode_+3A_x">x</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sample mode
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample_mode(rbeta(100, 2, 7))
</code></pre>

<hr>
<h2 id='spotify'>Spotify Song Data</h2><span id='topic+spotify'></span>

<h3>Description</h3>

<p>A sub-sample of the Spotify song data originally collected by Kaylin Pavlik (kaylinquest) and distributed through the R for Data Science TidyTuesday project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spotify
</code></pre>


<h3>Format</h3>

<p>A data frame with 350 songs (or tracks) and 23 variables:
</p>

<dl>
<dt>track_id</dt><dd><p>unique song identifier</p>
</dd>
<dt>title</dt><dd><p>song name</p>
</dd>
<dt>artist</dt><dd><p>song artist</p>
</dd>
<dt>popularity</dt><dd><p>song popularity from 0 (low) to 100 (high)</p>
</dd>
<dt>album_id</dt><dd><p>id of the album on which the song appears</p>
</dd>
<dt>album_name</dt><dd><p>name of the album on which the song appears</p>
</dd>
<dt>album_release_date</dt><dd><p>when the album was released</p>
</dd>
<dt>playlist_name</dt><dd><p>Spotify playlist on which the song appears</p>
</dd>
<dt>playlist_id</dt><dd><p>unique playlist identifier</p>
</dd>
<dt>genre</dt><dd><p>genre of the playlist</p>
</dd>
<dt>subgenre</dt><dd><p>subgenre of the playlist</p>
</dd>
<dt>danceability</dt><dd><p>a score from 0 (not danceable) to 100 (danceable) based on features such as tempo, rhythm, etc.</p>
</dd>
<dt>energy</dt><dd><p>a score from 0 (low energy) to 100 (high energy) based on features such as loudness, timbre, entropy, etc.</p>
</dd>
<dt>key</dt><dd><p>song key</p>
</dd>
<dt>loudness</dt><dd><p>song loudness (dB)</p>
</dd>
<dt>mode</dt><dd><p>0 (minor key) or 1 (major key)</p>
</dd>
<dt>speechiness</dt><dd><p>a score from 0 (non-speechy tracks) to 100 (speechy tracks)</p>
</dd>
<dt>acousticness</dt><dd><p>a score from 0 (not acoustic) to 100 (very acoustic)</p>
</dd>
<dt>instrumentalness</dt><dd><p>a score from 0 (not instrumental) to 100 (very instrumental)</p>
</dd>
<dt>liveness</dt><dd><p>a score from 0 (no live audience presence on the song) to 100 (strong live audience presence on the song)</p>
</dd>
<dt>valence</dt><dd><p>a score from 0 (the song is more negative, sad, angry) to 100 (the song is more positive, happy, euphoric)</p>
</dd>
<dt>tempo</dt><dd><p>song tempo (beats per minute)</p>
</dd>
<dt>duration_ms</dt><dd><p>song duration (ms)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/spotify_songs.csv/">https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/spotify_songs.csv/</a>.
</p>

<hr>
<h2 id='summarize_beta'>Summarize a Beta Model for <code class="reqn">\pi</code></h2><span id='topic+summarize_beta'></span>

<h3>Description</h3>

<p>Summarizes the expected value, variance, and mode of 
a Beta(alpha, beta) model for variable <code class="reqn">\pi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_beta(alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_beta_+3A_alpha">alpha</code>, <code id="summarize_beta_+3A_beta">beta</code></td>
<td>
<p>positive shape parameters of the Beta model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a summary table
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarize_beta(alpha = 1, beta = 15)
</code></pre>

<hr>
<h2 id='summarize_beta_binomial'>Summarize a Beta-Binomial Bayesian model</h2><span id='topic+summarize_beta_binomial'></span>

<h3>Description</h3>

<p>Consider a Beta-Binomial Bayesian model for parameter <code class="reqn">\pi</code> with 
a Beta(alpha, beta) prior on <code class="reqn">\pi</code> and Binomial likelihood with n trials
and y successes. Given information on the prior (alpha and data) and data (y and n),
this function summarizes the mean, mode, and variance of the 
prior and posterior Beta models of <code class="reqn">\pi</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_beta_binomial(alpha, beta, y = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_beta_binomial_+3A_alpha">alpha</code>, <code id="summarize_beta_binomial_+3A_beta">beta</code></td>
<td>
<p>positive shape parameters of the prior Beta model</p>
</td></tr>
<tr><td><code id="summarize_beta_binomial_+3A_y">y</code></td>
<td>
<p>number of successes</p>
</td></tr>
<tr><td><code id="summarize_beta_binomial_+3A_n">n</code></td>
<td>
<p>number of trials</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a summary table
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarize_beta_binomial(alpha = 1, beta = 15, y = 25, n = 50)
</code></pre>

<hr>
<h2 id='summarize_gamma'>Summarize a Gamma Model for <code class="reqn">\lambda</code></h2><span id='topic+summarize_gamma'></span>

<h3>Description</h3>

<p>Summarizes the expected value, variance, and mode of 
a Gamma(shape, rate) model for variable <code class="reqn">\lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_gamma(shape, rate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_gamma_+3A_shape">shape</code></td>
<td>
<p>positive shape parameter of the Gamma model</p>
</td></tr>
<tr><td><code id="summarize_gamma_+3A_rate">rate</code></td>
<td>
<p>positive rate parameter of the Gamma model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a summary table
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarize_gamma(shape = 1, rate = 15)

</code></pre>

<hr>
<h2 id='summarize_gamma_poisson'>Summarize the Gamma-Poisson Model</h2><span id='topic+summarize_gamma_poisson'></span>

<h3>Description</h3>

<p>Consider a Gamma-Poisson Bayesian model for rate parameter <code class="reqn">\lambda</code> with 
a Gamma(shape, rate) prior on <code class="reqn">\lambda</code> and a Poisson likelihood for the data. 
Given information on the prior (shape and rate) 
and data (the sample size n and sum_y),
this function summarizes the mean, mode, and variance of the 
prior and posterior Gamma models of <code class="reqn">\lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_gamma_poisson(shape, rate, sum_y = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_gamma_poisson_+3A_shape">shape</code></td>
<td>
<p>positive shape parameter of the Gamma prior</p>
</td></tr>
<tr><td><code id="summarize_gamma_poisson_+3A_rate">rate</code></td>
<td>
<p>positive rate parameter of the Gamma prior</p>
</td></tr>
<tr><td><code id="summarize_gamma_poisson_+3A_sum_y">sum_y</code></td>
<td>
<p>sum of observed data values for the Poisson likelihood</p>
</td></tr>
<tr><td><code id="summarize_gamma_poisson_+3A_n">n</code></td>
<td>
<p>number of observations for the Poisson likelihood</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarize_gamma_poisson(shape = 3, rate = 4, sum_y = 7, n = 12)

</code></pre>

<hr>
<h2 id='summarize_normal_normal'>Summarize a Normal-Normal Bayesian model</h2><span id='topic+summarize_normal_normal'></span>

<h3>Description</h3>

<p>Consider a Normal-Normal Bayesian model for mean parameter <code class="reqn">\mu</code> with 
a N(mean, sd^2) prior on <code class="reqn">\mu</code> and a Normal likelihood for the data. 
Given information on the prior (mean and sd) 
and data (the sample size n, mean y_bar, and standard deviation sigma),
this function summarizes the mean, mode, and variance of the 
prior and posterior Normal models of <code class="reqn">\mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_normal_normal(mean, sd, sigma = NULL, y_bar = NULL, n = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_normal_normal_+3A_mean">mean</code></td>
<td>
<p>mean of the Normal prior</p>
</td></tr>
<tr><td><code id="summarize_normal_normal_+3A_sd">sd</code></td>
<td>
<p>standard deviation of the Normal prior</p>
</td></tr>
<tr><td><code id="summarize_normal_normal_+3A_sigma">sigma</code></td>
<td>
<p>standard deviation of the data, or likelihood standard deviation</p>
</td></tr>
<tr><td><code id="summarize_normal_normal_+3A_y_bar">y_bar</code></td>
<td>
<p>sample mean of the data</p>
</td></tr>
<tr><td><code id="summarize_normal_normal_+3A_n">n</code></td>
<td>
<p>sample size of the data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarize_normal_normal(mean = 2.3, sd = 0.3, sigma = 5.1, y_bar = 128.5, n = 20)
</code></pre>

<hr>
<h2 id='voices'>Voice Pitch Data</h2><span id='topic+voices'></span>

<h3>Description</h3>

<p>Voice pitch data collected by Winter and Grawunder (2012). 
In an experiment, subjects participated in role-playing dialog under various conditions,
while researchers monitored voice pitch (Hz).
The conditions spanned different scenarios (eg: making an appointment, asking for a favor)
and different attitudes to use in the scenario (polite or informal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>voices
</code></pre>


<h3>Format</h3>

<p>A data frame with 84 rows and 4 variables. Each row represents a single observation for the given subject.
</p>

<dl>
<dt>subject</dt><dd><p>subject identifier</p>
</dd>
<dt>scenario</dt><dd><p>context of the dialog (encoded as A, B, ..., G)</p>
</dd>
<dt>attitude</dt><dd><p>whether the attitude to use in dialog was polite or informal</p>
</dd>
<dt>pitch</dt><dd><p>average voice pitch (Hz)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Winter, B., &amp; Grawunder, S. (2012). The Phonetic Profile of Korean Formal and Informal Speech Registers. Journal of Phonetics, 40, 808-815. 
<a href="https://bodo-winter.net/data_and_scripts/POP.csv">https://bodo-winter.net/data_and_scripts/POP.csv</a>.
<a href="https://bodo-winter.net/tutorial/bw_LME_tutorial2.pdf">https://bodo-winter.net/tutorial/bw_LME_tutorial2.pdf</a>.
</p>

<hr>
<h2 id='weather_australia'>Weather Data for 3 Australian Cities</h2><span id='topic+weather_australia'></span>

<h3>Description</h3>

<p>A sub-sample of daily weather information from the weatherAUS data in the rattle package for three Australian cities: Wollongong, Hobart, and Uluru.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weather_australia
</code></pre>


<h3>Format</h3>

<p>A data frame with 300 daily observations and 22 variables from 3 Australian weather stations:
</p>

<dl>
<dt>location</dt><dd><p>one of three weather stations</p>
</dd>
<dt>mintemp</dt><dd><p>minimum temperature (degrees Celsius)</p>
</dd>
<dt>maxtemp</dt><dd><p>maximum temperature (degrees Celsius)</p>
</dd>
<dt>rainfall</dt><dd><p>rainfall (mm)</p>
</dd>
<dt>windgustdir</dt><dd><p>direction of strongest wind gust</p>
</dd>
<dt>windgustspeed</dt><dd><p>speed of strongest wind gust (km/h)</p>
</dd>
<dt>winddir9am</dt><dd><p>direction of wind gust at 9am</p>
</dd>
<dt>winddir3pm</dt><dd><p>direction of wind gust at 3pm</p>
</dd>
<dt>windspeed9am</dt><dd><p>wind speed at 9am (km/h)</p>
</dd>
<dt>windspeed3pm</dt><dd><p>wind speed at 3pm (km/h)</p>
</dd>
<dt>humidity9am</dt><dd><p>humidity level at 9am (percent)</p>
</dd>
<dt>humidity3pm</dt><dd><p>humidity level at 3pm (percent)</p>
</dd>
<dt>pressure9am</dt><dd><p>atmospheric pressure at 9am (hpa)</p>
</dd>
<dt>pressure3pm</dt><dd><p>atmospheric pressure at 3pm (hpa)</p>
</dd>
<dt>temp9am</dt><dd><p>temperature at 9am (degrees Celsius)</p>
</dd>
<dt>temp3pm</dt><dd><p>temperature at 3pm (degrees Celsius)</p>
</dd>
<dt>raintoday</dt><dd><p>whether or not it rained today (Yes or No)</p>
</dd>
<dt>risk_mm</dt><dd><p>the amount of rain today (mm)</p>
</dd>
<dt>raintomorrow</dt><dd><p>whether or not it rained the next day (Yes or No)</p>
</dd>
<dt>year</dt><dd><p>the year of the date</p>
</dd>
<dt>month</dt><dd><p>the month of the date</p>
</dd>
<dt>day_of_year</dt><dd><p>the day of the year</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data in the original weatherAUS data set were obtained from <a href="https://www.bom.gov.au/climate/data/">https://www.bom.gov.au/climate/data/</a>. Copyright Commonwealth of Australia 2010, Bureau of Meteorology.
</p>

<hr>
<h2 id='weather_perth'>Weather Data for Perth, Australia</h2><span id='topic+weather_perth'></span>

<h3>Description</h3>

<p>A sub-sample of daily weather information on Perth, Australia from the weatherAUS data in the rattle package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weather_perth
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 daily observations and 21 variables:
</p>

<dl>
<dt>mintemp</dt><dd><p>minimum temperature (degrees Celsius)</p>
</dd>
<dt>maxtemp</dt><dd><p>maximum temperature (degrees Celsius)</p>
</dd>
<dt>rainfall</dt><dd><p>rainfall (mm)</p>
</dd>
<dt>windgustdir</dt><dd><p>direction of strongest wind gust</p>
</dd>
<dt>windgustspeed</dt><dd><p>speed of strongest wind gust (km/h)</p>
</dd>
<dt>winddir9am</dt><dd><p>direction of wind gust at 9am</p>
</dd>
<dt>winddir3pm</dt><dd><p>direction of wind gust at 3pm</p>
</dd>
<dt>windspeed9am</dt><dd><p>wind speed at 9am (km/h)</p>
</dd>
<dt>windspeed3pm</dt><dd><p>wind speed at 3pm (km/h)</p>
</dd>
<dt>humidity9am</dt><dd><p>humidity level at 9am (percent)</p>
</dd>
<dt>humidity3pm</dt><dd><p>humidity level at 3pm (percent)</p>
</dd>
<dt>pressure9am</dt><dd><p>atmospheric pressure at 9am (hpa)</p>
</dd>
<dt>pressure3pm</dt><dd><p>atmospheric pressure at 3pm (hpa)</p>
</dd>
<dt>temp9am</dt><dd><p>temperature at 9am (degrees Celsius)</p>
</dd>
<dt>temp3pm</dt><dd><p>temperature at 3pm (degrees Celsius)</p>
</dd>
<dt>raintoday</dt><dd><p>whether or not it rained today (Yes or No)</p>
</dd>
<dt>risk_mm</dt><dd><p>the amount of rain today (mm)</p>
</dd>
<dt>raintomorrow</dt><dd><p>whether or not it rained the next day (Yes or No)</p>
</dd>
<dt>year</dt><dd><p>the year of the date</p>
</dd>
<dt>month</dt><dd><p>the month of the date</p>
</dd>
<dt>day_of_year</dt><dd><p>the day of the year</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data in the original weatherAUS data set were obtained from <a href="https://www.bom.gov.au/climate/data/">https://www.bom.gov.au/climate/data/</a>. Copyright Commonwealth of Australia 2010, Bureau of Meteorology.
</p>

<hr>
<h2 id='weather_WU'>Weather Data for 2 Australian Cities</h2><span id='topic+weather_WU'></span>

<h3>Description</h3>

<p>A sub-sample of daily weather information from the weatherAUS data in the rattle package for two Australian cities, Wollongong and Uluru.
The weather_australia data in the bayesrules package combines this data with a third city
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weather_WU
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 daily observations and 22 variables from 2 Australian weather stations:
</p>

<dl>
<dt>location</dt><dd><p>one of two weather stations</p>
</dd>
<dt>mintemp</dt><dd><p>minimum temperature (degrees Celsius)</p>
</dd>
<dt>maxtemp</dt><dd><p>maximum temperature (degrees Celsius)</p>
</dd>
<dt>rainfall</dt><dd><p>rainfall (mm)</p>
</dd>
<dt>windgustdir</dt><dd><p>direction of strongest wind gust</p>
</dd>
<dt>windgustspeed</dt><dd><p>speed of strongest wind gust (km/h)</p>
</dd>
<dt>winddir9am</dt><dd><p>direction of wind gust at 9am</p>
</dd>
<dt>winddir3pm</dt><dd><p>direction of wind gust at 3pm</p>
</dd>
<dt>windspeed9am</dt><dd><p>wind speed at 9am (km/h)</p>
</dd>
<dt>windspeed3pm</dt><dd><p>wind speed at 3pm (km/h)</p>
</dd>
<dt>humidity9am</dt><dd><p>humidity level at 9am (percent)</p>
</dd>
<dt>humidity3pm</dt><dd><p>humidity level at 3pm (percent)</p>
</dd>
<dt>pressure9am</dt><dd><p>atmospheric pressure at 9am (hpa)</p>
</dd>
<dt>pressure3pm</dt><dd><p>atmospheric pressure at 3pm (hpa)</p>
</dd>
<dt>temp9am</dt><dd><p>temperature at 9am (degrees Celsius)</p>
</dd>
<dt>temp3pm</dt><dd><p>temperature at 3pm (degrees Celsius)</p>
</dd>
<dt>raintoday</dt><dd><p>whether or not it rained today (Yes or No)</p>
</dd>
<dt>risk_mm</dt><dd><p>the amount of rain today (mm)</p>
</dd>
<dt>raintomorrow</dt><dd><p>whether or not it rained the next day (Yes or No)</p>
</dd>
<dt>year</dt><dd><p>the year of the date</p>
</dd>
<dt>month</dt><dd><p>the month of the date</p>
</dd>
<dt>day_of_year</dt><dd><p>the day of the year</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data in the original weatherAUS data set were obtained from <a href="https://www.bom.gov.au/climate/data">https://www.bom.gov.au/climate/data</a>. Copyright Commonwealth of Australia 2010, Bureau of Meteorology.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
