<!DOCTYPE html><html><head><title>Help for package cat</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cat}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#belt'><p>Data on driver injury and seat belt use</p></a></li>
<li><a href='#bipf'>
<p>Bayesian Iterative Proportional Fitting (BIPF)</p></a></li>
<li><a href='#crimes'><p>U.S. National Crime Survey</p></a></li>
<li><a href='#da.cat'>
<p>Data Augmentation algorithm for incomplete categorical data</p></a></li>
<li><a href='#dabipf'>
<p>Data augmentation-Bayesian IPF algorithm for incomplete categorical</p>
data</a></li>
<li><a href='#ecm.cat'>
<p>ECM algorithm for incomplete categorical data</p></a></li>
<li><a href='#em.cat'>
<p>EM algorithm for incomplete categorical data</p></a></li>
<li><a href='#imp.cat'>
<p>Impute missing categorical data</p></a></li>
<li><a href='#ipf'>
<p>Iterative Proportional Fitting</p></a></li>
<li><a href='#logpost.cat'>
<p>Log-posterior density for incomplete categorical data</p></a></li>
<li><a href='#mda.cat'>
<p>Monotone Data Augmentation algorithm for incomplete categorical data</p></a></li>
<li><a href='#mi.inference'>
<p>Multiple imputation inference</p></a></li>
<li><a href='#older'><p>Older people dataset</p></a></li>
<li><a href='#prelim.cat'>
<p>Preliminary manipulations on incomplete categorical data</p></a></li>
<li><a href='#rngseed'><p>Initialize random number generator seed</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.0-9</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-02</td>
</tr>
<tr>
<td>Title:</td>
<td>Analysis and Imputation of Categorical-Variable Datasets with
Missing Values</td>
</tr>
<tr>
<td>Author:</td>
<td>Ported to R by Ted Harding and Fernando Tusell. Original by
	Joseph L. Schafer &lt;jls@stat.psu.edu&gt;.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fernando Tusell &lt;fernando.tusell@ehu.es&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs analysis of categorical-variable with missing values. Implements methods from Schafer, JL, Analysis of Incomplete Multivariate Data, Chapman and Hall.</td>
</tr>
<tr>
<td>License:</td>
<td>file LICENSE</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-02 18:41:07 UTC; etptupaf</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-03 13:50:02 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>License_restricts_use:</td>
<td>no</td>
</tr>
<tr>
<td>License_is_FOSS:</td>
<td>yes</td>
</tr>
</table>
<hr>
<h2 id='belt'>Data on driver injury and seat belt use</h2><span id='topic+belt'></span><span id='topic+belt.frame'></span>

<h3>Description</h3>

<p>Data on driver injury and seat belt use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(belt)</code></pre>


<h3>Format</h3>

<p>The data frame <code>belt.frame</code> contains the following columns:
</p>

<dl>
<dt>I</dt><dd><p>Injury to driver (I1=Reported by police, I2=Follow up</p>
</dd>
<dt>B</dt><dd><p>Belt use (B1=Reported by police, B2=Follow up</p>
</dd>
<dt>D</dt><dd><p>Damage to vehicle (high, low)</p>
</dd>
<dt>S</dt><dd><p>Sex: Male or Female</p>
</dd>
<dt>Freq</dt><dd><p>Count</p>
</dd>  </dl>



<h3>Note</h3>

<p>A matrix <code>belt</code> with similarly named columns exists that can be input
directly to functions which do not admit data frames. Both the data
frame and matrix include all complete and incomplete cases, from the
police reports and follow up study.</p>


<h3>Source</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Section 7.4.3, which cites
</p>
<p>Hochberg, Y. (1977) On the use of double sampling schemes in analyzing
categorical data with misclassification errors, <em>JASA</em>, vol. 71,
p. 914-921.
</p>

<hr>
<h2 id='bipf'>
Bayesian Iterative Proportional Fitting (BIPF)
</h2><span id='topic+bipf'></span>

<h3>Description</h3>

<p>Markov-Chain Monte Carlo method for simulating posterior draws of cell
probabilities under a hierarchical loglinear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bipf(table,margins, prior=0.5, start, steps=1, showits=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bipf_+3A_table">table</code></td>
<td>

<p>contingency table (array) to be fitted by a log-linear model. All
elements must be non-negative.
</p>
</td></tr>
<tr><td><code id="bipf_+3A_margins">margins</code></td>
<td>

<p>vector describing the marginal totals to be fitted. A margin
is described by the factors not summed over, and margins are separated
by zeros.  Thus c(1,2,0,2,3,0,1,3) would indicate fitting the (1,2),
(2,3), and (1,3) margins in a three-way table, i.e., the model of no
three-way association.
</p>
</td></tr>
<tr><td><code id="bipf_+3A_prior">prior</code></td>
<td>

<p>optional array of hyperparameters specifying a Dirichlet
prior distribution. The default is the Jeffreys prior (all
hyperparameters = .5). If structural zeros appear in <code>table</code>, a prior
should be supplied with hyperparameters set to <code>NA</code> for those cells.
</p>
</td></tr>
<tr><td><code id="bipf_+3A_start">start</code></td>
<td>

<p>starting value for the algorithm. The default is a uniform table.  If
structural zeros appear in <code>table</code>, <code>start</code> should contain zeros in
those cells and ones elsewhere.
</p>
</td></tr>
<tr><td><code id="bipf_+3A_steps">steps</code></td>
<td>

<p>number of cycles of Bayesian IPF to be performed.
</p>
</td></tr>
<tr><td><code id="bipf_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations so the user can monitor the progress
of the algorithm.
</p>
</td></tr></table>


<h3>Value</h3>

<p>array like <code>table</code>, but containing simulated cell probabilities that
satisfy the loglinear model. If the algorithm has converged, this will
be a draw from the actual posterior distribution of the parameters.
</p>


<h3>Note</h3>

<p>The random number generator seed must be set at least once by the
function <code>rngseed</code> before this function can be used.
</p>
<p>The starting value must lie in the interior of the parameter space.
Hence, caution should be used when using a maximum likelihood 
estimate (e.g., from <code>ipf</code>) as a starting value. Random zeros in a 
table may produce mle's with expected cell counts of zero, and any 
zero in a starting value is interpreted by <code>bipf</code> as a structural 
zero. This difficulty can be overcome by using as a starting value
calculated by <code>ipf</code> after adding a small positive constant (e.g.,
1/2) to each cell.
</p>


<h3>References</h3>

<p>Schafer (1996) <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall,  Chapter 8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ipf">ipf</a></code> and <code><a href="#topic+rngseed">rngseed</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HairEyeColor)                     # load data
m=c(1,2,0,1,3,0,2,3)                   # no three-way interaction
thetahat &lt;- ipf(HairEyeColor,margins=m,
            showits=TRUE)              # fit model
thetahat &lt;- ipf(HairEyeColor+.5,m)     # find an interior starting value 
rngseed(1234567)                       # set random generator seed
theta &lt;- bipf(HairEyeColor,m,
              start=thetahat,prior=0.5,
              steps=50)                # take 50 steps
</code></pre>

<hr>
<h2 id='crimes'>U.S. National Crime Survey</h2><span id='topic+crimes'></span>

<h3>Description</h3>

<p>Victimization status of households on two occasions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(crimes)</code></pre>


<h3>Format</h3>

<p>The matrix <code>crimes</code> contains the following columns:
</p>

<dl>
<dt>V1</dt><dd><p>Victimization status on first occasion (1=No, 2=Yes)</p>
</dd>
<dt>V1</dt><dd><p>Victimization status on second occasion (1=No, 2=Yes)</p>
</dd>
<dt>Freq</dt><dd><p>Count</p>
</dd>  </dl>



<h3>Source</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Section 7.4.3, which cites
</p>
<p>Kadane, J.B. (1985) Is victimization chronic? A Bayesian Analysis of
multinomial missing data, <em>Journal of Econometrics</em>, vol. 29, p. 47-67.
</p>

<hr>
<h2 id='da.cat'>
Data Augmentation algorithm for incomplete categorical data
</h2><span id='topic+da.cat'></span>

<h3>Description</h3>

<p>Markov-Chain Monte Carlo method for simulating draws from the
observed-data posterior distribution of underlying cell probabilities
under a saturated multinomial model. May be used in conjunction with
<code>imp.cat</code> to create proper multiple imputations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>da.cat(s, start, prior=0.5, steps=1, showits=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="da.cat_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset created by the
function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="da.cat_+3A_start">start</code></td>
<td>

<p>starting value of the parameter. This is an array of cell
probabilities of dimension <code>s$d</code>, such as one created by <code>em.cat</code>.
If structural zeros appear in the table, starting values for those
cells should be zero.
</p>
</td></tr>
<tr><td><code id="da.cat_+3A_prior">prior</code></td>
<td>

<p>optional array of hyperparameters specifying a Dirichlet prior
distribution. The default is the Jeffreys prior (all hyperparameters =
supplied with hyperparameters set to <code>NA</code> for those cells.
</p>
</td></tr>
<tr><td><code id="da.cat_+3A_steps">steps</code></td>
<td>

<p>number of data augmentation steps to be taken. Each step consists of an
imputation or I-step followed by a posterior or P-step. 
</p>
</td></tr>
<tr><td><code id="da.cat_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations so the user can monitor the
progress of the algorithm.
</p>
</td></tr></table>


<h3>Details</h3>

<p>At each step, the missing data are randomly imputed under their
predictive distribution given the observed data and the current value
of <code>theta</code> (I-step), and then a new value of <code>theta</code> is drawn from its
Dirichlet posterior distribution given the complete data (P-step).
After a suitable number of steps are taken, the resulting value of the
parameter may be regarded as a random draw from its observed-data
posterior distribution.
</p>
<p>When the pattern of observed data is close to a monotone pattern, then
<code>mda.cat</code> is preferred because it will tend to converge more quickly.
</p>


<h3>Value</h3>

<p>an array like <code>start</code> containing simulated cell probabilities.
</p>


<h3>Note</h3>

<p>IMPORTANT: The random number generator seed must be set at least once
by the function <code>rngseed</code> before this function can be used.
</p>


<h3>References</h3>

<p>Schafer (1996) <em>Analysis of Incomplete Multivariate Data,</em>
Chapman &amp; Hall, Chapter 7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prelim.cat">prelim.cat</a></code>, <code><a href="#topic+rngseed">rngseed</a></code>, <code><a href="#topic+mda.cat">mda.cat</a></code>, <code><a href="#topic+imp.cat">imp.cat</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crimes)
x      &lt;- crimes[,-3]
counts &lt;- crimes[,3]
s &lt;- prelim.cat(x,counts)        # preliminary manipulations
thetahat &lt;- em.cat(s)            # find ML estimate under saturated model
rngseed(7817)                    # set random number generator seed
theta &lt;- da.cat(s,thetahat,50)   # take 50 steps from MLE
ximp  &lt;- imp.cat(s,theta)        # impute once under theta
theta &lt;- da.cat(s,theta,50)      # take another 50 steps
ximp  &lt;- imp.cat(s,theta)        # impute again under new theta
</code></pre>

<hr>
<h2 id='dabipf'>
Data augmentation-Bayesian IPF algorithm for incomplete categorical
data
</h2><span id='topic+dabipf'></span>

<h3>Description</h3>

<p>Markov-Chain Monte Carlo method for simulating draws from the
observed-data posterior distribution of underlying cell probabilities
under hierarchical loglinear models. May be used in conjunction with
<code>imp.cat</code> to create proper multiple imputations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dabipf(s, margins, start, steps=1, prior=0.5, showits=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dabipf_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset created by the
function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="dabipf_+3A_margins">margins</code></td>
<td>

<p>vector describing the marginal totals to be fitted. A margin
is described by the factors not summed over, and margins are separated
by zeros.  Thus c(1,2,0,2,3,0,1,3) would indicate fitting the (1,2),
(2,3), and (1,3) margins in a three-way table, i.e., the model of no
three-way association.
</p>
</td></tr>
<tr><td><code id="dabipf_+3A_start">start</code></td>
<td>

<p>starting value of the parameter. The starting value should lie in the
interior of the parameter space for the given loglinear model. If
structural zeros are present, <code>start</code> should contain zeros in
those positions.
</p>
</td></tr>
<tr><td><code id="dabipf_+3A_steps">steps</code></td>
<td>

<p>number of complete cycles of data augmentation-Bayesian IPF to be
performed.
</p>
</td></tr>
<tr><td><code id="dabipf_+3A_prior">prior</code></td>
<td>

<p>optional array of hyperparameters specifying a Dirichlet
prior distribution. The default is the Jeffreys prior (all
hyperparameters = .5). If structural zeros are present, a prior
should be supplied with hyperparameters set to <code>NA</code> for those cells.
</p>
</td></tr>
<tr><td><code id="dabipf_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations so the user can monitor the
progress of the algorithm.
</p>
</td></tr></table>


<h3>Value</h3>

<p>array of simulated cell probabilities that satisfy the loglinear
model. If the algorithm has converged, this will be a draw from the
actual posterior distribution of the parameters.
</p>


<h3>Note</h3>

<p>The random number generator seed must be set at least once by the
function <code>rngseed</code> before this function can be used.
</p>
<p>The starting value must lie in the interior of the parameter space.
Hence, caution should be used when using a maximum likelihood estimate
(e.g., from <code>ecm.cat</code>) as a starting value. Random zeros in a table
may produce mle's with expected cell counts of zero. This difficulty
can be overcome by using as a starting value a posterior mode
calculated by <code>ecm.cat</code> with prior hyperparameters greater than one.
</p>


<h3>References</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Chapter 8.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
#  Example 1   Based on Schafer's p. 329 and ss. This is a toy version,
#              using a much shorter length of chain than required. To 
#              generate results comparable with those in the book, edit
#              the \dontrun{ } line below and comment the previous one.
#
data(belt)
attach(belt.frame)
EB &lt;- ifelse(B1==B2,1,0)
EI &lt;- ifelse(I1==I2,1,0)
belt.frame &lt;- cbind(belt.frame,EB,EI)
colnames(belt.frame)
a &lt;- xtabs(Freq ~ D + S + B2 + I2 + EB + EI,
                data=belt.frame)
m &lt;- list(c(1,2,3,4),c(3,4,5,6),c(1,5),
           c(1,6),c(2,6))
b &lt;- loglin(a,margin=m)                  # fits (DSB2I2)B2I2EBEI)(DEB)(DEI)(SEI)
                                         # in Schafer's p. 304

a &lt;- xtabs(Freq ~ D + S + B2 + I2 + B1 + I1,
                data=belt.frame)
m &lt;- list(c(1,2,5,6),c(1,2,3,4),c(3,4,5,6),
           c(1,3,5),c(1,4,6),c(2,4,6))
b &lt;- loglin(a,margin=m)                  # fits (DSB1I1)(DSB2I2)(B2I2B1I1)(DB1B2)
                                         #  (DI1I2)(SI1I2) in Schafer's p. 329
s &lt;- prelim.cat(x=belt[,-7],counts=belt[,7])
m &lt;- c(1,2,5,6,0,1,2,3,4,0,3,4,5,6,0,1,3,5,0,1,4,6,0,2,4,6)
theta &lt;- ecm.cat(s,margins=m,            # excruciantingly slow; needs 2558
                   maxits=5000)          # iterations.
rngseed(1234)
#
#   Now ten multiple imputations of the missing variables B2, I2 are
#   generated, by running a chain and taking every 2500th observation.
#   Prior hyperparameter is set at 0.5 as in Shchafer's p. 329
#
imputations &lt;- vector("list",10)

for (i in 1:10) {
cat("Doing imputation ",i,"\n")
  theta &lt;- dabipf(s,m,theta,prior=0.5,   # toy chain; for comparison with
                   steps=25)             # results in Schafer's book the next
                                         # statement should be run,
                                         # rather than this one.
  ## Not run: theta &lt;- dabipf(s,m,theta,prior=0.5,steps=2500)			   
  imputations[[i]] &lt;- imp.cat(s,theta)
}
  

		   
detach(belt.frame)
#
#  Example 2   (reproduces analysis performed in Schafer's p. 327.)
#
#  Caveat! I try to reproduce what has been done in that page, but although
#  the general appearance of the boxplots generated below is quite similar to
#  that of  Schafer's Fig. 8.4 (p. 327), the VALUES of the log odds do not
#  quite fall in line with those reported by said author. It doesn't look like
#  the difference can be traced to decimal vs. natural logs. On the other hand,
#  Fig. 8.4 refers to log odds, while the text near the end of page 327 gives
#  1.74 and 1.50 as the means of the *odds* (not log odds). FT, 22.7.2003.
#
#
data(older)                              # reading data
x      &lt;- older[,1:6]                    # preliminary manipulations
counts &lt;- older[,7]
s &lt;- prelim.cat(x,counts)                
colnames(x)                              # names of columns
rngseed(1234)
m &lt;- c(1,2,3,4,5,0,1,2,3,5,6,0,4,3)      # model (ASPMG)(ASPMD)(GD) in
                                         # Schafer's p. 327
                                         # do analysis with different priors
theta   &lt;- ecm.cat(s,m,prior=1.5)        # Strong pull to uniform table
                                         # for initial estimates
prob1   &lt;- dabipf(s,m,theta,steps=100,   # Burn-in period 
                  prior=0.1)
prob2   &lt;- dabipf(s,m,theta,steps=100,   # Id. with second prior
                  prior=1.5)

lodds   &lt;- matrix(0,5000,2)              # Where to store log odds ratios.

oddsr   &lt;- function(x) {                 # Odds ratio of 2 x 2 table.
            o &lt;- (x[1,1]*x[2,2])/
                   (x[1,2]*x[2,1])
            return(o)
            }

for(i in 1:5000) {                       # Now generate 5000 log odds
prob1  &lt;- dabipf(s,m,prob1, prior=0.1)   
t1   &lt;- apply(prob1,c(1,2),sum)          # Marginal GD table
                                         # Log odds ratio
lodds[i,1] &lt;- log(oddsr(t1))
prob2  &lt;- dabipf(s,m,prob2, prior=1.5)   # Id. with second prior
t2   &lt;- apply(prob2,c(1,2),sum)         
lodds[i,2] &lt;- log(oddsr(t2))
}
lodds  &lt;- as.data.frame(lodds)
colnames(lodds) &lt;- c("0.1","1.5")        # Similar to Schafer's Fig. 8.4.
boxplot(lodds,xlab="Prior hyperparameter")
title(main="Log odds ratio generated with DABIPF (5000 draws)")
summary(lodds)

</code></pre>

<hr>
<h2 id='ecm.cat'>
ECM algorithm for incomplete categorical data
</h2><span id='topic+ecm.cat'></span>

<h3>Description</h3>

<p>Finds ML estimate or posterior mode of cell probabilities under
a hierarchical loglinear model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecm.cat(s, margins, start, prior=1, showits=TRUE, maxits=1000,
eps=0.0001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecm.cat_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset produced by
the function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="ecm.cat_+3A_margins">margins</code></td>
<td>

<p>vector describing the sufficient configurations or margins
in the desired loglinear model. A margin is described by the factors
not summed over, and margins are separated by zeros.  Thus
c(1,2,0,2,3,0,1,3) would indicate the (1,2), (2,3), and (1,3) margins
in a three-way table, i.e., the model of no three-way association.
The integers 1,2,... in the specified margins correspond to the
columns of the original data matrix <code>x</code> that was used to create <code>s</code>.
</p>
</td></tr>
<tr><td><code id="ecm.cat_+3A_start">start</code></td>
<td>

<p>optional starting value of the parameter. This is an array with
dimensions <code>s$d</code> whose elements sum to one. The default starting value
is a uniform array (equal probabilities in all cells). If structural
zeros appear in the table, <code>start</code> should contain zeros in those
positions and nonzero (e.g. uniform) values elsewhere.
</p>
</td></tr>
<tr><td><code id="ecm.cat_+3A_prior">prior</code></td>
<td>

<p>optional vector of hyperparameters for a Dirichlet prior distribution.
The default is a uniform prior distribution (all hyperparameters = 1)
on the cell probabilities, which will result in maximum likelihood
estimation. If structural zeros appear in the table, a prior should be
supplied with <code>NA</code>s in those cells.
</p>
</td></tr>
<tr><td><code id="ecm.cat_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations of ECM so the user can monitor
the progress of the algorithm.
</p>
</td></tr>
<tr><td><code id="ecm.cat_+3A_maxits">maxits</code></td>
<td>

<p>maximum number of iterations performed. The algorithm will stop if the
parameter still has not converged after this many iterations.
</p>
</td></tr>
<tr><td><code id="ecm.cat_+3A_eps">eps</code></td>
<td>

<p>convergence criterion. This is the largest proportional change in an
expected cell count from one iteration to the next.  Any expected
cell count that drops below 1E-07 times the average cell probability
(1/number of non-structural zero cells) is set to zero during the
iterations.
</p>
</td></tr></table>


<h3>Details</h3>

<p>At each iteration, performs an E-step followed by a single cycle of
iterative proportional fitting.
</p>


<h3>Value</h3>

<p>array of dimension <code>s$d</code> containing the ML estimate or posterior mode,
assuming that ECM  has converged by <code>maxits</code> iterations.
</p>


<h3>Note</h3>

<p>If zero cell counts occur in the observed-data tables, the maximum
likelihood estimate may not be unique, and the algorithm may converge
to different stationary values depending on the starting value. Also,
if zero cell counts occur in the observed-data tables, the ML estimate
may lie on the boundary of the parameter space. Supplying a prior with
hyperparameters greater than one will give a unique posterior mode in
the interior of the parameter space. Estimated probabilities for
structural zero cells will always be zero.
</p>


<h3>References</h3>

<p>Schafer (1996), <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Chapter 8 
</p>
<p>X. L. Meng and  D. B. Rubin (1991),
&quot;IPF for contingency tables with missing data via the ECM algorithm,&quot;
Proceedings of the Statistical Computing Section, Amer. Stat. Assoc.,
244&ndash;247.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prelim.cat">prelim.cat</a></code>, <code><a href="#topic+em.cat">em.cat</a></code>, <code><a href="#topic+logpost.cat">logpost.cat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(older)                           # load data
#
#  Example 1
#
older[1:2,]                           # see partial content; older.frame also
                                      # available.
s &lt;- prelim.cat(older[,-7],older[,7]) # preliminary manipulations
m &lt;- c(1,2,5,6,0,3,4)                 # margins for restricted model
try(thetahat1 &lt;- ecm.cat(s,margins=m))# will complain 
thetahat2 &lt;- ecm.cat(s,margins=m,prior=1.1)
                                      # same model with prior information
logpost.cat(s,thetahat2)              # loglikelihood under thetahat2
#
#  Example 2   (reproduces analysis performed in Schafer's p. 327.)
#
m1 &lt;- c(1,2,3,5,6,0,1,2,4,5,6,0,3,4)  # model (ASPMG)(ASPMD)(GD) in
                                      # Schafer's p. 327
theta1 &lt;- ecm.cat(s,margins=m1,
                       prior=1.1)     # Prior to bring MLE away from boundary.
m2     &lt;- c(1,2,3,5,6,0,1,2,4,5,6)    # model (ASPMG)(ASPMD)
theta2 &lt;- ecm.cat(s,margins=m2,
                       prior=1.1)
lik1   &lt;- logpost.cat(s,theta1)       # posterior log likelihood.
lik2   &lt;- logpost.cat(s,theta2)       # id. for restricted model.
lrt    &lt;- -2*(lik2-lik1)              # for testing significance of (GD)
p      &lt;- 1 - pchisq(lrt,1)           # significance level
cat("LRT statistic for \n(ASMPG)(ASMPD) vs. (ASMPG)(ASMPD)(GD): ",lrt," with p-value = ",p)
</code></pre>

<hr>
<h2 id='em.cat'>
EM algorithm for incomplete categorical data
</h2><span id='topic+em.cat'></span>

<h3>Description</h3>

<p>Finds ML estimate or posterior mode of cell probabilities under
the saturated multinomial model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>em.cat(s, start, prior=1, showits=TRUE, maxits=1000,
eps=0.0001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="em.cat_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset produced by
the function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="em.cat_+3A_start">start</code></td>
<td>

<p>optional starting value of the parameter. This is an array with
dimensions <code>s$d</code> whose elements sum to one. The default starting value
is a uniform array (equal probabilities in all cells). If structural
zeros appear in the table, <code>start</code> should contain zeros in those
positions and nonzero (e.g. uniform) values elsewhere. 
</p>
</td></tr>
<tr><td><code id="em.cat_+3A_prior">prior</code></td>
<td>

<p>optional vector of hyperparameters for a Dirichlet prior distribution.
The default is a uniform prior distribution (all hyperparameters = 1)
on the cell probabilities, which will result in maximum likelihood
estimation. If structural zeros appear in the table, a prior should be
supplied with <code>NA</code>s in those cells.
</p>
</td></tr>
<tr><td><code id="em.cat_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations of EM so the user can monitor
the progress of the algorithm.
</p>
</td></tr>
<tr><td><code id="em.cat_+3A_maxits">maxits</code></td>
<td>

<p>maximum number of iterations performed. The algorithm will stop if the
parameter still has not converged after this many iterations.
</p>
</td></tr>
<tr><td><code id="em.cat_+3A_eps">eps</code></td>
<td>

<p>convergence criterion. This is the largest proportional change in an
expected cell count from one iteration to the next.  Any expected
cell count that drops below 1E-07 times the average cell probability
(1/number of non-structural zero cells) is set to zero during the
iterations.
</p>
</td></tr></table>


<h3>Value</h3>

<p>array of dimension <code>s$d</code> containing the ML estimate or posterior mode,
assuming that EM  has converged by <code>maxits</code> iterations.
</p>


<h3>Note</h3>

<p>If zero cell counts occur in the observed-data table, the maximum
likelihood estimate may not be unique, and the algorithm may converge
to different stationary values depending on the starting value. Also,
if zero cell counts occur in the observed-data table, the ML estimate
may lie on the boundary of the parameter space. Supplying a prior with
hyperparameters greater than one will give a unique posterior mode in
the interior of the parameter space. Estimated probabilities for
structural zero cells will always be zero.
</p>


<h3>References</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Section 7.3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prelim.cat">prelim.cat</a></code>, <code><a href="#topic+ecm.cat">ecm.cat</a></code>, <code><a href="#topic+logpost.cat">logpost.cat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crimes)
crimes
s &lt;- prelim.cat(crimes[,1:2],crimes[,3])     # preliminary manipulations
thetahat &lt;- em.cat(s)                        # mle under saturated model
logpost.cat(s,thetahat)                      # loglikelihood at thetahat
</code></pre>

<hr>
<h2 id='imp.cat'>
Impute missing categorical data
</h2><span id='topic+imp.cat'></span>

<h3>Description</h3>

<p>Performs single random imputation of missing values in a categorical
dataset under a user-supplied value of the underlying cell
probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imp.cat(s, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imp.cat_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset created by the
function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="imp.cat_+3A_theta">theta</code></td>
<td>

<p>parameter value under which the missing data are to be imputed.
This is an array of cell probabilities of dimension <code>s$d</code> whose
elements sum to one, such as produced by <code>em.cat</code>, <code>ecm.cat</code>,
<code>da.cat</code>, <code>mda.cat</code> or <code>dabipf</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Missing data are drawn independently for each observational unit from
their conditional predictive distribution given the observed data and
<code>theta</code>. 
</p>


<h3>Value</h3>

<p>If the original incomplete dataset was in ungrouped format
(<code>s$grouped=F</code>), then a matrix like <code>s$x</code> except that all <code>NA</code>s have
been filled in.
</p>
<p>If the original dataset was grouped, then a list with the following
components:
</p>
<table>
<tr><td><code>x</code></td>
<td>

<p>Matrix of levels for categorical variables
</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>

<p>vector of length <code>nrow(x)</code> containing frequencies or counts
corresponding to the levels in <code>x</code>.
</p>
</td></tr></table>


<h3>Note</h3>

<p>IMPORTANT: The random number generator seed must be set by the
function <code>rngseed</code> at least once in the current session before this
function can be used. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prelim.cat">prelim.cat</a></code>, <code><a href="#topic+rngseed">rngseed</a></code>, <code><a href="#topic+em.cat">em.cat</a></code>, <code><a href="#topic+da.cat">da.cat</a></code>, <code><a href="#topic+mda.cat">mda.cat</a></code>, <code><a href="#topic+ecm.cat">ecm.cat</a></code>,
<code><a href="#topic+dabipf">dabipf</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crimes)
x      &lt;- crimes[,-3]
counts &lt;- crimes[,3]
s &lt;- prelim.cat(x,counts)        # preliminary manipulations
thetahat &lt;- em.cat(s)            # find ML estimate under saturated model
rngseed(7817)                    # set random number generator seed
theta &lt;- da.cat(s,thetahat,50)   # take 50 steps from MLE
ximp  &lt;- imp.cat(s,theta)        # impute once under theta
theta &lt;- da.cat(s,theta,50)      # take another 50 steps
ximp  &lt;- imp.cat(s,theta)        # impute again under new theta
</code></pre>

<hr>
<h2 id='ipf'>
Iterative Proportional Fitting
</h2><span id='topic+ipf'></span>

<h3>Description</h3>

<p>ML estimation for hierarchical loglinear models via conventional
iterative proportional fitting (IPF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipf(table, margins, start, eps=0.0001, maxits=50, showits=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ipf_+3A_table">table</code></td>
<td>

<p>contingency table (array) to be fit by a log-linear model. All
elements must be non-negative. 
</p>
</td></tr>
<tr><td><code id="ipf_+3A_margins">margins</code></td>
<td>

<p>vector describing the marginal totals to be fitted. A margin is described
by the factors not summed over, and margins are separated by zeros.
Thus c(1,2,0,2,3,0,1,3) would indicate fitting the (1,2), (2,3), and
(1,3) margins in a three-way table, i.e., the model of no three-way
association.
</p>
</td></tr>
<tr><td><code id="ipf_+3A_start">start</code></td>
<td>

<p>starting value for IPF algorithm. The default is a uniform table.
If structural zeros appear in <code>table</code>, <code>start</code> should contain zeros
in those cells and ones elsewhere.
</p>
</td></tr>
<tr><td><code id="ipf_+3A_eps">eps</code></td>
<td>

<p>convergence criterion. This is the largest proportional change in an
expected cell count from one iteration to the next.  Any expected cell
count that drops below 1E-07 times the average cell probability
(1/number of non-structural zero cells) is set to zero during the
iterations.
</p>
</td></tr>
<tr><td><code id="ipf_+3A_maxits">maxits</code></td>
<td>

<p>maximum number of iterations performed. The algorithm will stop if the
parameter still has not converged after this many iterations.
</p>
</td></tr>
<tr><td><code id="ipf_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations of IPF so the user can monitor the
progress of the algorithm.
</p>
</td></tr></table>


<h3>Value</h3>

<p>array like <code>table</code>, but containing fitted values (expected
frequencies) under the loglinear model. 
</p>


<h3>DETAILS</h3>

<p>This function is usually used to compute ML estimates for a loglinear
model. For ML estimates, the array <code>table</code> should contain the observed
frequencies from a cross-classified contingency table. Because this is
the &quot;cell-means&quot; version of IPF, the resulting fitted values will add
up to equals <code>sum(table)</code>. To obtain estimated cell probabilities,
rescale the fitted values to sum to one.
</p>
<p>This function may also be used to compute the posterior mode of the
multinomial cell probabilities under a Dirichlet prior.  For a
posterior mode, set the elements of <code>table</code> to (observed frequencies +
Dirichlet hyperparameters - 1). Then, after running IPF, rescale the
fitted values to sum to one.
</p>


<h3>Note</h3>

<p>This function is essentially the same as the old S function <code>loglin</code>, but
results are computed to double precision.  See <code>help(loglin)</code> for more
details.
</p>


<h3>References</h3>

<p>Agresti, A. (1990) Categorical Data Analysis. J. Wiley &amp; Sons, New
York.
</p>
<p>Schafer (1996) <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Chapter 8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ecm.cat">ecm.cat</a></code>, <code><a href="#topic+bipf">bipf</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HairEyeColor)                     # load data
m=c(1,2,0,1,3,0,2,3)                   # no three-way interaction
fit1 &lt;- ipf(HairEyeColor,margins=m,
            showits=TRUE)              # fit model
X2 &lt;- sum((HairEyeColor-fit1)^2/fit1)  # Pearson chi square statistic
df &lt;- prod(dim(HairEyeColor)-1)        # Degrees of freedom for this example
1 - pchisq(X2,df)                      # p-value for fit1
</code></pre>

<hr>
<h2 id='logpost.cat'>
Log-posterior density for incomplete categorical data
</h2><span id='topic+logpost.cat'></span>

<h3>Description</h3>

<p>Calculates the observed-data loglikelihood or log-posterior density
for incomplete categorical data under a specified value of the
underlying cell probabilities, e.g. as resulting from em.cat or
ecm.cat.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logpost.cat(s, theta, prior)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logpost.cat_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset created by the
function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="logpost.cat_+3A_theta">theta</code></td>
<td>

<p>an array of cell probabilities of dimension <code>s$d</code>
</p>
</td></tr>
<tr><td><code id="logpost.cat_+3A_prior">prior</code></td>
<td>

<p>optional vector of hyperparameters for a Dirichlet prior
distribution.  The default is a uniform prior distribution (all
hyperparameters = 1) on the cell probabilities, which will result
in evaluation of the loglikelihood. If structural zeros appear in the
table, a prior should be supplied with NAs in those cells and ones
(or other hyperparameters) elsewhere.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This is the loglikelihood or log-posterior density that ignores the
missing-data mechanism.
</p>


<h3>Value</h3>

<p>the value of the observed-data loglikelihood or log-posterior density
function at <code>theta</code> 
</p>


<h3>References</h3>

<p>Schafer (1996) <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall. Section 7.3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prelim.cat">prelim.cat</a></code>, <code><a href="#topic+em.cat">em.cat</a></code>, <code><a href="#topic+ecm.cat">ecm.cat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(older)                            # load data
older[1:2,c(1:4,7)]                    # see partial content; older.frame also
                                       # available.
s &lt;- prelim.cat(older[,1:4],older[,7]) # preliminary manipulations
m &lt;- c(1,2,0,3,4)                      # margins for restricted model
thetahat1 &lt;- ecm.cat(s,margins=m)      # mle 
logpost.cat(s,thetahat1)               # loglikelihood at thetahat1
</code></pre>

<hr>
<h2 id='mda.cat'>
Monotone Data Augmentation algorithm for incomplete categorical data
</h2><span id='topic+mda.cat'></span>

<h3>Description</h3>

<p>Markov-Chain Monte Carlo method for simulating draws from the
observed-data posterior distribution of underlying cell probabilities
under a saturated multinomial model. May be used in conjunction with
<code>imp.cat</code> to create proper multiple imputations. Tends to converge
more quickly than <code>da.cat</code> when the pattern of observed data is nearly
monotone. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mda.cat(s, start, steps=1, prior=0.5, showits=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mda.cat_+3A_s">s</code></td>
<td>

<p>summary list of an incomplete categorical dataset created by the
function <code>prelim.cat</code>.
</p>
</td></tr>
<tr><td><code id="mda.cat_+3A_start">start</code></td>
<td>

<p>starting value of the parameter. This is an array of cell
probabilities of dimension <code>s$d</code>, such as one created by <code>em.cat</code>.
If structural zeros appear in the table, starting values for those
cells should be zero.
</p>
</td></tr>
<tr><td><code id="mda.cat_+3A_steps">steps</code></td>
<td>

<p>number of data augmentation steps to be taken. Each step consists of
an imputation or I-step followed by a posterior or P-step.
</p>
</td></tr>
<tr><td><code id="mda.cat_+3A_prior">prior</code></td>
<td>

<p>optional vector of hyperparameters specifying a Dirichlet prior
distribution. The default is the Jeffreys prior (all hyperparameters =
supplied with hyperparameters set to <code>NA</code> for those cells.
</p>
</td></tr>
<tr><td><code id="mda.cat_+3A_showits">showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations so the user can monitor the
progress of the algorithm.
</p>
</td></tr></table>


<h3>Details</h3>

<p>At each step, the missing data are randomly imputed under their
predictive distribution given the observed data and the current value
of <code>theta</code> (I-step) Unlike <code>da.cat</code>, however, not all of the missing
data are filled in, but only enough to complete a monotone pattern.
Then a new value of <code>theta</code> is drawn from its Dirichlet posterior
distribution given the monotone data (P-step).  After a suitable
number of steps are taken, the resulting value of the parameter may be
regarded as a random draw from its observed-data posterior
distribution.
</p>
<p>For good performance, the variables in the original data matrix <code>x</code>
(which is used to create <code>s</code>) should be ordered according to their
rates of missingness from most observed (in the first columns) to
least observed (in the last columns).
</p>


<h3>Value</h3>

<p>an array like <code>start</code> containing simulated cell probabilities.
</p>


<h3>Note</h3>

<p>IMPORTANT: The random number generator seed must be set at least once
by the function <code>rngseed</code> before this function can be used.
</p>


<h3>References</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall,  Chapter 7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prelim.cat">prelim.cat</a></code>, <code><a href="#topic+rngseed">rngseed</a></code>, <code><a href="#topic+da.cat">da.cat</a></code>, <code><a href="#topic+imp.cat">imp.cat</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(older)
x      &lt;- older[1:80,1:4]               # subset of the data with
counts &lt;- older[1:80,7]                 # monotone pattern.
s &lt;- prelim.cat(x,counts)               # preliminary manipulations
thetahat &lt;- em.cat(s)                   # mle under saturated model
rngseed(7817)                           # set random generator seed
theta &lt;- mda.cat(s,thetahat,50)         # take 50 steps from mle
ximp &lt;- imp.cat(s,theta)                # impute under theta
theta &lt;- mda.cat(s,theta,50)            # take another 50 steps
ximp &lt;- imp.cat(s,theta)                # impute under new theta
</code></pre>

<hr>
<h2 id='mi.inference'>
Multiple imputation inference
</h2><span id='topic+mi.inference'></span>

<h3>Description</h3>

<p>Combines estimates and standard errors from m complete-data analyses
performed on m imputed datasets to produce a single inference.  Uses
the technique described by Rubin (1987) for multiple
imputation inference for a scalar estimand.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi.inference(est, std.err, confidence=0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mi.inference_+3A_est">est</code></td>
<td>

<p>a list of $m$ (at least 2) vectors representing estimates (e.g.,
vectors of estimated regression coefficients) from complete-data
analyses performed on $m$ imputed datasets.
</p>
</td></tr>
<tr><td><code id="mi.inference_+3A_std.err">std.err</code></td>
<td>

<p>a list of $m$ vectors containing standard errors from the
complete-data analyses corresponding to the estimates in <code>est</code>.
</p>
</td></tr>
<tr><td><code id="mi.inference_+3A_confidence">confidence</code></td>
<td>

<p>desired coverage of interval estimates.
</p>
</td></tr></table>


<h3>Value</h3>

<p>a list with the following components, each of which is a vector of the
same length as the components of <code>est</code> and <code>std.err</code>:
</p>
<table>
<tr><td><code>est</code></td>
<td>

<p>the average of the complete-data estimates.
</p>
</td></tr>
<tr><td><code>std.err</code></td>
<td>

<p>standard errors incorporating both the between and the
within-imputation uncertainty (the square root of the &quot;total
variance&quot;).
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>degrees of freedom associated with the t reference distribution used
for interval estimates.
</p>
</td></tr>
<tr><td><code>signif</code></td>
<td>

<p>P-values for the two-tailed hypothesis tests that the estimated
quantities are equal to zero.
</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>

<p>lower limits of the (100*confidence)% interval estimates.
</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>

<p>upper limits of the (100*confidence)% interval estimates.
</p>
</td></tr>
<tr><td><code>r</code></td>
<td>

<p>estimated relative increases in variance due to nonresponse.
</p>
</td></tr>
<tr><td><code>fminf</code></td>
<td>

<p>estimated fractions of missing information.
</p>
</td></tr></table>


<h3>METHOD</h3>

<p>Uses the method described on pp. 76-77 of Rubin (1987) for combining
the complete-data estimates from $m$ imputed datasets
for a scalar estimand. Significance levels and interval estimates are
approximately valid for each one-dimensional estimand, not for all of
them jointly.
</p>


<h3>References</h3>

<p>Fienberg, S.E. (1981) <em>The Analysis of Cross-Classified Categorical
Data</em>, MIT Press, Cambridge.
</p>
<p>Rubin (1987) <em>Multiple Imputation for Nonresponse in
Surveys,</em> Wiley, New York, 
</p>
<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Chapter 8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dabipf">dabipf</a></code>,  <code><a href="#topic+imp.cat">imp.cat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
#  Example 1   Based on Schafer's p. 329 and ss. This is a toy version,
#              using a much shorter length of chain than required. To 
#              generate results comparable with those in the book, edit
#              the \dontrun{ } line below and comment the previous one.
#
data(belt)
attach(belt.frame)

oddsr   &lt;- function(x) {                 # Odds ratio of 2 x 2 table.
            o &lt;- (x[1,1]*x[2,2])/
                   (x[1,2]*x[2,1])
            o.sd &lt;- sqrt(1/x[1,1] +      # large sample S.D. (Fienberg,
                      1/x[1,2] +         # p. 18)
                      1/x[2,1] +
                      1/x[2,2])
            return(list(o=o,sd=o.sd))
            }

colns &lt;- colnames(belt.frame)

a &lt;- xtabs(Freq ~ D + S + B2 + I2 + B1 + I1,
                data=belt.frame)
m &lt;- list(c(1,2,5,6),c(1,2,3,4),c(3,4,5,6),
           c(1,3,5),c(1,4,6),c(2,4,6))
b &lt;- loglin(a,margin=m)                  # fits (DSB1I1)(DSB2I2)(B2I2B1I1)(DB1B2)
                                         #  (DI1I2)(SI1I2) in Schafer's p. 329
s &lt;- prelim.cat(x=belt[,-7],counts=belt[,7])
m &lt;- c(1,2,5,6,0,1,2,3,4,0,3,4,5,6,0,1,3,5,0,1,4,6,0,2,4,6)
theta &lt;- ecm.cat(s,margins=m,            # excruciantingly slow; needs 2558
                   maxits=5000)          # iterations.
rngseed(1234)
#
#   Now ten multiple imputations of the missing variables B2, I2 are
#   generated, by running a chain and taking every 2500th observation.
#   Prior hyperparameter is set at 0.5 as in Schafer's p. 329
#
est &lt;- std.error &lt;- vector("list",10)

for (i in 1:10) {
cat("Doing imputation ",i,"\n")
  theta &lt;- dabipf(s,m,theta,prior=0.5,   # toy chain; for comparison with
                   steps=25)             # results in Schafer's book the next
                                         # statement should be run,
                                         # rather than this one.
  ## Not run: theta &lt;- dabipf(s,m,theta,prior=0.5,steps=2500)			   
  imp&lt;- imp.cat(s,theta)
  imp.frame &lt;- cbind(imp$x,imp$counts)
  colnames(imp.frame) &lt;- colns
  a &lt;- xtabs(Freq ~ B2 + I2,             # 2 x 2 table relating belt use
                    data=imp.frame)      # and injury
  print(a)
  odds &lt;- oddsr(a)                       # odds ratio and std.dev.
  est[[i]] &lt;- odds$o - 1                 # check deviations from 1 of
  std.error[[i]] &lt;- odds$sd              # odds ratio
}
odds &lt;- mi.inference(est,std.error)
print(odds)
detach(belt.frame)
</code></pre>

<hr>
<h2 id='older'>Older people dataset</h2><span id='topic+older'></span><span id='topic+older.frame'></span>

<h3>Description</h3>

<p>Data from the Protective Services Project for Older Persons
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(older)</code></pre>


<h3>Format</h3>

<p>The data frame <code>older.frame</code> contains the following columns:
</p>

<dl>
<dt>M</dt><dd><p>Mental status</p>
</dd>
<dt>P</dt><dd><p>ysical status</p>
</dd>
<dt>D</dt><dd><p>Survival status (deceased or not)</p>
</dd>
<dt>G</dt><dd><p>Group membership: E=experimental, C=control)</p>
</dd>
<dt>A</dt><dd><p>Age: Under75 and 75+</p>
</dd>
<dt>S</dt><dd><p>Sex: Male or Female</p>
</dd>
<dt>Freq</dt><dd><p>Count</p>
</dd>  </dl>



<h3>Note</h3>

<p>A matrix <code>older</code> with similarley named columns exists that can be input
directly to functions which do not admit data frames.</p>


<h3>Source</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Section 7.3.5.
</p>

<hr>
<h2 id='prelim.cat'>
Preliminary manipulations on incomplete categorical data
</h2><span id='topic+prelim.cat'></span>

<h3>Description</h3>

<p>This function performs grouping and sorting operations on 
categorical datasets with missing values. It creates a list that is
needed for input to em.cat, da.cat, imp.cat, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prelim.cat(x, counts, levs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prelim.cat_+3A_x">x</code></td>
<td>

<p>categorical data matrix containing missing values. The data may be
provided either in ungrouped or grouped format. In ungrouped format,
the rows of x correspond to individual observational units, so that
nrow(x) is the total sample size. In grouped format, the rows of x
correspond to distinct covariate patterns; the frequencies are
provided through the <code>counts</code> argument.  In either format, the columns
correspond to variables.  The categories must be coded as consecutive
positive integers beginning with 1 (1,2,...), and missing values are
denoted by <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="prelim.cat_+3A_counts">counts</code></td>
<td>

<p>optional vector of length <code>nrow(x)</code> giving the frequencies corresponding
to the covariate patterns in x. The total sample size is
<code>sum(counts)</code>. If <code>counts</code> is missing, the data are assumed to be
ungrouped; this is equivalent to taking <code>counts</code> equal to
<code>rep(1,nrow(x))</code>.
</p>
</td></tr>
<tr><td><code id="prelim.cat_+3A_levs">levs</code></td>
<td>

<p>optional vector of length <code>ncol(x)</code> indicating the number of levels
for each categorical variable. If missing, <code>levs[j]</code> is taken to be
<code>max(x[,j],na.rm=T)</code>.
</p>
</td></tr></table>


<h3>Value</h3>

<p>a list of seventeen components that summarize various features
of x after the data have been sorted by missingness patterns and
grouped according to the observed values. Components that might
be of interest to the user include:
</p>
<table>
<tr><td><code>nmis</code></td>
<td>

<p>a vector of length <code>ncol(x)</code> containing the number of missing values
for each variable in x.
</p>
</td></tr>
<tr><td><code>r</code></td>
<td>

<p>matrix of response indicators showing the missing data patterns in x.
Dimension is (m,p) where m is number of distinct missingness patterns
in the rows of x, and p is the number of columns in x. Observed values
are indicated by 1 and missing values by 0. The row names give the
number of observations in each pattern, and the columns correspond to
the columns of x.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>vector of length <code>ncol(x)</code> indicating the number of levels for each
variable. The complete-data contingency table would be an array with
these dimensions. Identical to <code>levs</code> if <code>levs</code> was supplied.
</p>
</td></tr>
<tr><td><code>ncells</code></td>
<td>

<p>number of cells in the cross-classified contingency table, equal to
<code>prod(d)</code>.
</p>
</td></tr></table>


<h3>References</h3>

<p>Chapters 7&ndash;8 of Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+em.cat">em.cat</a></code>,  <code><a href="#topic+ecm.cat">ecm.cat</a></code>,  <code><a href="#topic+da.cat">da.cat</a></code>,<code><a href="#topic+mda.cat">mda.cat</a></code>,  <code><a href="#topic+dabipf">dabipf</a></code>,  <code><a href="#topic+imp.cat">imp.cat</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crimes)
crimes
s &lt;- prelim.cat(crimes[,1:2],crimes[,3])   # preliminary manipulations
s$nmis                      # see number of missing observations per variable
s$r                         # look at missing data patterns
</code></pre>

<hr>
<h2 id='rngseed'>Initialize random number generator seed</h2><span id='topic+rngseed'></span>

<h3>Description</h3>

<p>Seeds the random number generator</p>


<h3>Usage</h3>

<pre><code class='language-R'>rngseed(seed)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rngseed_+3A_seed">seed</code></td>
<td>

<p>a positive number, preferably a large integer.
</p>
</td></tr></table>


<h3>Value</h3>

<p><code>NULL</code>.
</p>


<h3>Note</h3>

<p>The random number generator seed must be set at least once
by this function before the simulation or imputation functions
in this package (<code>da.cat</code>, <code>imp.cat</code>, etc.) can be used.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
