<!DOCTYPE html><html><head><title>Help for package GHap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GHap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ghap.anc2plink'>
<p>Convert ancestry tracks to PLINK binary</p></a></li>
<li><a href='#ghap.ancmark'>
<p>Per marker ancestry proportions</p></a></li>
<li><a href='#ghap.ancplot'>
<p>Barplot of predictions of ancestry proportions</p></a></li>
<li><a href='#ghap.ancsmooth'>
<p>Smoothing of haplotype ancestry predictions</p></a></li>
<li><a href='#ghap.ancsvm'>
<p>SVM-based predictions of haplotype ancestry</p></a></li>
<li><a href='#ghap.anctest'>
<p>Prediction of haplotype ancestry</p></a></li>
<li><a href='#ghap.anctrain'>
<p>Construction of prototype alleles</p></a></li>
<li><a href='#ghap.assoc'>
<p>Genome-wide association analysis</p></a></li>
<li><a href='#ghap.blockgen'>
<p>Haplotype block generator</p></a></li>
<li><a href='#ghap.blockstats'>
<p>HapBlock statistics</p></a></li>
<li><a href='#ghap.compress'>
<p>Compress phased genotype data</p></a></li>
<li><a href='#ghap.exfiles'>
<p>Example files</p></a></li>
<li><a href='#ghap.fast2phase'>
<p>Convert fastPHASE data into the GHap phase format</p></a></li>
<li><a href='#ghap.freq'>
<p>Compute marker allele frequencies</p></a></li>
<li><a href='#ghap.froh'>
<p>Calculation of genomic inbreeding (FROH)</p></a></li>
<li><a href='#ghap.fst'>
<p>Haplotype-based Fst</p></a></li>
<li><a href='#ghap.getHinv'>
<p>Compute the inverse of H</p></a></li>
<li><a href='#ghap.hap2plink'>
<p>Convert haplotype allele counts to PLINK binary</p></a></li>
<li><a href='#ghap.haplotyping'>
<p>Haplotype genotypes</p></a></li>
<li><a href='#ghap.hapstats'>
<p>Haplotype allele statistics</p></a></li>
<li><a href='#ghap.ibd'>
<p>Estimation of IBD sharing</p></a></li>
<li><a href='#ghap.inbcoef'>
<p>Compute measures of inbreeding</p></a></li>
<li><a href='#ghap.karyoplot'>
<p>Individual chromosome painting</p></a></li>
<li><a href='#ghap.kinship'>
<p>Relationship matrix based on genomic data</p></a></li>
<li><a href='#ghap.lmm'>
<p>Linear mixed model</p></a></li>
<li><a href='#ghap.loadhaplo'>
<p>Load haplotype genotype data</p></a></li>
<li><a href='#ghap.loadphase'>
<p>Load binary phased genotype data</p></a></li>
<li><a href='#ghap.loadplink'>
<p>Load binary PLINK data</p></a></li>
<li><a href='#ghap.makefile'>
<p>Create example input files</p></a></li>
<li><a href='#ghap.manhattan'>
<p>Manhattan plot</p></a></li>
<li><a href='#ghap.oxford2phase'>
<p>Convert Oxford data into GHap phase</p></a></li>
<li><a href='#ghap.pedcheck'>
<p>Summary statistics for pedigree</p></a></li>
<li><a href='#ghap.phase2plink'>
<p>Export phase object to PLINK binary</p></a></li>
<li><a href='#ghap.predictblup'>
<p>Predict BLUP from reference</p></a></li>
<li><a href='#ghap.profile'>
<p>Genomic profile</p></a></li>
<li><a href='#ghap.relfind'>
<p>Find relatives in IBD estimates</p></a></li>
<li><a href='#ghap.remlci'>
<p>Confidence intervals for functions of variance components</p></a></li>
<li><a href='#ghap.roh'>
<p>Detection of runs of homozygosity (ROH)</p></a></li>
<li><a href='#ghap.simadmix'>
<p>Simulate individuals from specified admixture proportions</p></a></li>
<li><a href='#ghap.simmating'>
<p>Simulate individuals from specified matings</p></a></li>
<li><a href='#ghap.simpheno'>
<p>Quantitative trait simulation using real genotype data</p></a></li>
<li><a href='#ghap.slice'>
<p>Get a slice of a GHap object</p></a></li>
<li><a href='#ghap.subset'>
<p>Subset GHap objects</p></a></li>
<li><a href='#ghap.varblup'>
<p>Convert BLUP of individuals into BLUP of variants</p></a></li>
<li><a href='#ghap.vcf2phase'>
<p>Convert VCF data into GHap phase</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Genome-Wide Haplotyping</td>
</tr>
<tr>
<td>Version:</td>
<td>3.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-06-30</td>
</tr>
<tr>
<td>Author:</td>
<td>Yuri Tani Utsunomiya, Andre Vieira do Nascimento, Marco Milanesi, Mario Barbato</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Haplotype calling from phased marker data. Given user-defined haplotype blocks (HapBlock), the package identifies the different haplotype alleles (HapAllele) present in the data and scores sample haplotype allele genotypes (HapGenotype) based on HapAllele dose (i.e. 0, 1 or 2 copies). The output is not only useful for analyses that can handle multi-allelic markers, but is also conveniently formatted for existing pipelines intended for bi-allelic markers. The package was first described in Bioinformatics by Utsunomiya et al. (2016, &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtw356">doi:10.1093/bioinformatics/btw356</a>&gt;). Since the v2 release, the package provides functions for unsupervised and supervised detection of ancestry tracks. The methods implemented in these functions were described in an article published in Methods in Ecology and Evolution by Utsunomiya et al. (2020, &lt;<a href="https://doi.org/10.1111%2F2041-210X.13467">doi:10.1111/2041-210X.13467</a>&gt;). The source code for v3 was modified for improved performance and inclusion of new functionality, including analysis of unphased data, runs of homozygosity, sampling methods for virtual gamete mating, mixed model fitting and GWAS.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel (&ge; 3.4.4), Matrix (&ge; 1.2-16), methods (&ge; 3.4.4),
pedigreemm (&ge; 0.3-3), sparseinv (&ge; 0.1.3), e1071 (&ge;
1.7-0.1), class (&ge; 7.3-15), data.table (&ge; 1.12.6), stringi
(&ge; 1.7.6)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-30 12:41:55 UTC; yuri</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-01 21:50:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='ghap.anc2plink'>
Convert ancestry tracks to PLINK binary
</h2><span id='topic+ghap.anc2plink'></span>

<h3>Description</h3>

<p>This function takes smoothed ancestry predictions obtained with the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function and converts them to PLINK binary (bed/bim/fam) format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.anc2plink(object, ancsmooth, ancestry, outfile, freq = c(0, 1),
               missingness = 1, only.active.samples = TRUE,
               only.active.markers = TRUE, batchsize = NULL,
               binary = TRUE, ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.anc2plink_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_ancsmooth">ancsmooth</code></td>
<td>

<p>A list containing smoothed ancestry classifications, such as supplied by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_ancestry">ancestry</code></td>
<td>

<p>Character value indicating which ancestry to count at each observed marked site.
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_outfile">outfile</code></td>
<td>

<p>Character value for the output file name.
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_freq">freq</code></td>
<td>

<p>A numeric vector of length 2 specifying the range of ancestry frequency to be included in the output. Default is c(0,1), which includes all marked sites.
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_missingness">missingness</code></td>
<td>

<p>A numeric value providing the missingness threshold to exclude marked sites with poor ancestry assignments (default = 1, with all sites retained).
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used for haplotyping (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of haplotype blocks to be processed and written to output at a time (default = 500).
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_binary">binary</code></td>
<td>

<p>A logical value specfying whether the output file should be binary (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.anc2plink_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned file mimics a standard PLINK (Purcell et al., 2007; Chang et al., 2015) binary file (bed/bim/fam), where counts 0, 1 and 2 represent the number of alleles assigned to the selected ancestry. For compatibility with PLINK, counts are coded as NN, NH and HH genotypes (N = NULL and H = haplotype allele), as if ancestry counts were bi-alelic markers. This codification is acceptable for any given analysis relying on SNP genotype counts, as long as the user specifies that the analysis should be done using the H character as reference for counts. You can specify reference alleles using the .tref file in PLINK with the <em>&ndash;reference-allele</em> command. This is desired for very large datasets, as softwares such as PLINK and GCTA (Yang et al., 2011) have faster implementations for regression, principal components and kinship matrix analyses. Optionally, the user can use binary = FALSE to replace the bed file with a plain txt with ancestry counts.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>C. C. Chang et al. Second-generation PLINK: rising to the challenge of larger and richer datasets. Gigascience. 2015. 4, 7.
</p>
<p>S. Purcell et al. PLINK: a tool set for whole-genome association and population-based linkage analyses. Am. J. Hum. Genet. 2007. 81, 559-575.
</p>
<p>J. Yang et al. GCTA: A tool for genome-wide complex trait analysis. Am. J. Hum. Genet. 2011. 88, 76-82.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# # Unsupervised analysis
# prototypes &lt;- ghap.anctrain(object = phase, K = 2)
# hapadmix &lt;- ghap.anctest(object = phase,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# 
# ### RUN ###
# 
# # Export crossbred data to PLINK binary
# cross &lt;- unique(phase$id[which(phase$pop == "Cross")])
# phase &lt;- ghap.subset(object = phase,
#                     ids = cross,
#                     variants = phase$marker)
# ghap.anc2plink(object = phase, ancsmooth = anctracks,
#                ancestry = "K1", outfile = "cross_K1")

</code></pre>

<hr>
<h2 id='ghap.ancmark'>
Per marker ancestry proportions
</h2><span id='topic+ghap.ancmark'></span>

<h3>Description</h3>

<p>Given smoothed ancestry predictions obtained with the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function, per marker ancestry proportions are calculated across selected individuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.ancmark(object, ancsmooth, ids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.ancmark_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.ancmark_+3A_ancsmooth">ancsmooth</code></td>
<td>

<p>A list containing smoothed ancestry classifications, such as supplied by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.ancmark_+3A_ids">ids</code></td>
<td>

<p>A character vector specifying which individuals to use for the calculations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes smoothed ancestry classifications provided by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function and calculates, for each marker, the proportion of haplotypes carrying each ancestry label. The resulting output serve as a proxy for locus-specific ancestry proportions.
</p>


<h3>Value</h3>

<p>The function returns a dataframes containing the following columns:
</p>
<table>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>MARKER</code></td>
<td>

<p>Marker name.
</p>
</td></tr>
<tr><td><code>BP</code></td>
<td>

<p>Marker position.
</p>
</td></tr>
<tr><td><code>...</code></td>
<td>

<p>A number of columns (one for each ancestry label) giving the proportion of haplotypes carrying the respective ancestry label.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # Supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# prototypes &lt;- ghap.anctrain(object = phase, train = train,
#                             method = "supervised")
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)
# 
# ### RUN ###
# 
# # Get per marker ancestry proportions for 'Pure1'
# pure1 &lt;- unique(phase$id[which(phase$pop == "Pure1")])
# ancmark &lt;- ghap.ancmark(object = phase,
#                         ancsmooth = anctracks,
#                         ids = pure1)
# 
# # Plot 'Pure2' introgression into 'Pure1'
# ghap.manhattan(data = ancmark, chr = "CHR",
#                bp = "BP", y = "Pure2", type = "h")

</code></pre>

<hr>
<h2 id='ghap.ancplot'>
Barplot of predictions of ancestry proportions
</h2><span id='topic+ghap.ancplot'></span>

<h3>Description</h3>

<p>Given smoothed ancestry predictions obtained with the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function, an admixture barplot is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.ancplot(ancsmooth, labels = TRUE,
              pop.ang = 45, group.ang = 0,
              colors = NULL, pop.order = NULL,
              sortby = NULL, use.unk = FALSE,
              legend = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.ancplot_+3A_ancsmooth">ancsmooth</code></td>
<td>

<p>A list containing smoothed ancestry classifications, such as supplied by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_labels">labels</code></td>
<td>

<p>A logic value indicating if population labels should be plotted (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_pop.ang">pop.ang</code></td>
<td>

<p>A numeric value representing the rotation of population labels in degrees (default = 45).
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_group.ang">group.ang</code></td>
<td>

<p>A numeric value representing the rotation of group labels in degrees (default = 0).
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_colors">colors</code></td>
<td>

<p>A character vector of colors to use for each ancestry label.
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_pop.order">pop.order</code></td>
<td>

<p>A single character vector or a list of character vectors specifying the order of populations to plot (see details).
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_sortby">sortby</code></td>
<td>

<p>A character value indicating the ancestry label to use for sorting individuals within populations.
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_use.unk">use.unk</code></td>
<td>

<p>A logical value indicating if the plot should be generated using missing values (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.ancplot_+3A_legend">legend</code></td>
<td>

<p>A logical value indicating if a legend should be included to the plot (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes smoothed ancestry classifications provided by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function and generates a traditional admixture/structure barplot. The argument pop.order allows the user to organize the displaying order of populations through a vector or a list. If a vector is provided, the populations are plotted following the order of elements within the vector. Otherwise, if a named list of vectors is provided, populations are first grouped by list elements and then displayed in the order they appear within their respective group vector.
</p>
<p>The same data could be used to generate a circular barplot, for example with the <span class="pkg">BITE</span> package. 
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>Milanesi, M., Capomaccio, S., Vajana, E., Bomba, L., Garcia, J.F., Ajmone-Marsan, P., Colli, L., 2017. BITE: an R package for biodiversity analyses. bioRxiv 181610. https://doi.org/10.1101/181610
</p>
<p>Y.T. Utsunomiya et al. Unsupervised detection of ancestry tracks with the GHap R package. Methods in Ecology and Evolution. 2020. 11:1448–54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code>, <code><a href="#topic+ghap.ancmark">ghap.ancmark</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # BestK analysis
# bestK &lt;- ghap.anctrain(object = phase, K = 5, tune = TRUE)
# plot(bestK$ssq, type = "b", xlab = "K",
#      ylab = "Within-cluster sum of squares")
# 
# # Unsupervised analysis with best K
# prototypes &lt;- ghap.anctrain(object = phase, K = 2)
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)
# 
# # Supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# prototypes &lt;- ghap.anctrain(object = phase, train = train,
#                             method = "supervised")
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)

</code></pre>

<hr>
<h2 id='ghap.ancsmooth'>
Smoothing of haplotype ancestry predictions
</h2><span id='topic+ghap.ancsmooth'></span>

<h3>Description</h3>

<p>Given ancestry predictions obtained with the <code><a href="#topic+ghap.anctest">ghap.anctest</a></code> or <code><a href="#topic+ghap.ancsvm">ghap.ancsvm</a></code> functions, overlapping classifications are smoothed to refine the boundaries of recombination breakpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.ancsmooth(object, admix,
                ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.ancsmooth_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.ancsmooth_+3A_admix">admix</code></td>
<td>

<p>A data frame containing ancestry classifications, such as supplied by the <code><a href="#topic+ghap.anctest">ghap.anctest</a></code> or <code><a href="#topic+ghap.ancsvm">ghap.ancsvm</a></code> functions.
</p>
</td></tr>
<tr><td><code id="ghap.ancsmooth_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.ancsmooth_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes results from ancestry classifications provided by the <code><a href="#topic+ghap.anctest">ghap.anctest</a></code> or <code><a href="#topic+ghap.ancsvm">ghap.ancsvm</a></code> functions and converts them into runs of ancestry. Since the classifiers assume exactly one ancestry per HapBlock, segments encompassing breakpoints are miss-classified as pertaining to a single origin, as opposed to a recombinant mixture of hybrid ancestry. When <code><a href="#topic+ghap.anctest">ghap.anctest</a></code>/<code><a href="#topic+ghap.ancsvm">ghap.ancsvm</a></code> are ran with overlapping HapBlocks, the smoothing function interrogates the ancestry of each overlapped segment by majority voting of all blocks containing it. After the ancestry of all segments have been resolved, contiguous sites sharing the same classification are converted into runs or segments of ancestry (i.e., ancestry tracks), which comprise the final output ('haplotypes' dataframe). These segments are then used to predict ancestry contributions ('proportions1' and 'proportions2' dataframes).
</p>


<h3>Value</h3>

<p>The function returns three dataframes: 'proportions1', 'proportions2' and 'haplotypes'. The 'proportions1' dataframe contains the following columns:
</p>
<table>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>...</code></td>
<td>

<p>A number of columns giving the predicted ancestry proportions.
</p>
</td></tr>
<tr><td><code>UNK</code></td>
<td>

<p>The proportion of the genome without ancestry assignment.
</p>
</td></tr>
</table>
<p>The 'proportions2' dataframe is similar to 'proportions1', expect that ancestry contributions are re-calibrated using only genome segments with ancestry assignments (therefore does not include the 'UNK' column). The 'haplotypes' dataframe contains the following columns:
</p>
<table>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>HAP</code></td>
<td>

<p>Haplotype number.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Segment start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Segment end position.
</p>
</td></tr>
<tr><td><code>SIZE</code></td>
<td>

<p>Segment size.
</p>
</td></tr>
<tr><td><code>ANCESTRY</code></td>
<td>

<p>Predicted ancestry of the segment.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>Y.T. Utsunomiya et al. Unsupervised detection of ancestry tracks with the GHap R package. Methods in Ecology and Evolution. 2020. 11:1448–54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.anctrain">ghap.anctrain</a></code>, <code><a href="#topic+ghap.ancsvm">ghap.ancsvm</a></code>, <code><a href="#topic+ghap.ancplot">ghap.ancplot</a></code>, <code><a href="#topic+ghap.ancmark">ghap.ancmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # BestK analysis
# bestK &lt;- ghap.anctrain(object = phase, K = 5, tune = TRUE)
# plot(bestK$ssq, type = "b", xlab = "K",
#      ylab = "Within-cluster sum of squares")
# 
# # Unsupervised analysis with best K
# prototypes &lt;- ghap.anctrain(object = phase, K = 2)
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)
# 
# # Supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# prototypes &lt;- ghap.anctrain(object = phase, train = train,
#                             method = "supervised")
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)

</code></pre>

<hr>
<h2 id='ghap.ancsvm'>
SVM-based predictions of haplotype ancestry
</h2><span id='topic+ghap.ancsvm'></span>

<h3>Description</h3>

<p>This function uses Support Vector Machines (SVM) to predict ancestry of haplotype alleles in test samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.ancsvm(object, blocks, test = NULL, train = NULL,
             cost = 1, gamma = NULL, tune = FALSE,
             only.active.samples = TRUE, only.active.markers = TRUE,
             ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.ancsvm_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_blocks">blocks</code></td>
<td>

<p>A data frame containing block boundaries, such as supplied by the <code><a href="#topic+ghap.blockgen">ghap.blockgen</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_test">test</code></td>
<td>

<p>Character vector of individuals to test.
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_train">train</code></td>
<td>

<p>Character vector of individuals to use as reference samples.
</p>
</td></tr> 
<tr><td><code id="ghap.ancsvm_+3A_cost">cost</code></td>
<td>

<p>A numeric value specifying the C constant of the regularization term in the Lagrange formulation.
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_gamma">gamma</code></td>
<td>

<p>A numeric value specifying the gamma parameter of the RBF kernel (default = 1/blocksize).
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_tune">tune</code></td>
<td>

<p>A logical value specfying if a grid search is to be performed for parameters (default = FALSE).
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in predictions (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used for predictions (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.ancsvm_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function predicts haplotype allele ancestry using Support Vector Machines (SVM) together with a Gaussian Radial Basis Function (RBF) kernel. The user is required to specify the C constant of the regularization term in the Lagrange formulation (default cost = 1) and the gamma parameter (default gamma = 1/blocksize) of the RBF kernel. <br />
</p>


<h3>Value</h3>

<p>If ran with tune = FALSE, the function returns a dataframe with the following columns:
</p>
<table>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>HAP1</code></td>
<td>

<p>Predicted ancestry of haplotype 1.
</p>
</td></tr>
<tr><td><code>HAP2</code></td>
<td>

<p>Predicted ancestry of haplotype 2.
</p>
</td></tr>
</table>
<p>If tune = TRUE, the function returns a dataframe with the following columns:
</p>
<table>
<tr><td><code>cost</code></td>
<td>

<p>The candidate value of the C constant.
</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>

<p>The canidate value of the gamma parameter.
</p>
</td></tr>
<tr><td><code>accuracy</code></td>
<td>

<p>The percentage of correctly assigned ancestries.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>R. J. Haasl  et al. Genetic ancestry inference using support vector machines, and the active emergence of a unique American population. Eur J Hum Genet. 2013. 21(5):554-62.
</p>
<p>D. Meyer et al. e1071: Misc Functions of the Department of Statistics, Probability Theory Group (e1071). TU Wien. 2019 R Package Version 1.7-0.1. http://cran.r-project.org/web/packages/e1071/index.html.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code>, <code><a href="#topic+ghap.ancplot">ghap.ancplot</a></code>, <code><a href="#topic+ghap.ancmark">ghap.ancmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # Tune supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# ranblocks &lt;- sample(x = 1:nrow(blocks), size = 5, replace = FALSE)
# tunesvm &lt;- ghap.ancsvm(object = phase, blocks = blocks[ranblocks,],
#                        train = train, gamma = 1/window*c(0.1,1,10),
#                        tune = TRUE)
# 
# # Supervised analysis with default parameters
# hapadmix &lt;- ghap.ancsvm(object = phase, blocks = blocks,
#                         train = train)
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)

</code></pre>

<hr>
<h2 id='ghap.anctest'>
Prediction of haplotype ancestry
</h2><span id='topic+ghap.anctest'></span>

<h3>Description</h3>

<p>This function uses prototype alleles to predict ancestry of haplotypes in test samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.anctest(object, blocks = NULL,
              prototypes, test = NULL,
              only.active.samples = TRUE,
              only.active.markers = TRUE,
              ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.anctest_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_blocks">blocks</code></td>
<td>

<p>A data frame containing block boundaries, such as supplied by the <code><a href="#topic+ghap.blockgen">ghap.blockgen</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_prototypes">prototypes</code></td>
<td>

<p>A data frame containing prototype alleles, such as supplied by the <code><a href="#topic+ghap.anctrain">ghap.anctrain</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_test">test</code></td>
<td>

<p>Character vector of individuals to test. All active individuals are used if this vector is not provided.
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in predictions (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used for predictions (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.anctest_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each interrogated block, tested haplotypes are assigned to their nearest centroids (i.e., the pseudo-lineages with the smallest Euclidean distances). If no blocks are supplied, the function automatically builds blocks compatible with admixture up to 10 generations in the past based on intermarker distances. This has been chosen according to simulation results, where the use of haplotype blocks compatible with recent admixture (~10 generations) retained reasonable accuracy across most scenarios, regardless of the age of admixture.
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the following columns:
</p>
<table>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>HAP1</code></td>
<td>

<p>Predicted ancestry of haplotype 1.
</p>
</td></tr>
<tr><td><code>HAP2</code></td>
<td>

<p>Predicted ancestry of haplotype 2.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>Y.T. Utsunomiya et al. Unsupervised detection of ancestry tracks with the GHap R package. Methods in Ecology and Evolution. 2020. 11:1448–54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.anctrain">ghap.anctrain</a></code>, <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code>, <code><a href="#topic+ghap.ancplot">ghap.ancplot</a></code>, <code><a href="#topic+ghap.ancmark">ghap.ancmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # BestK analysis
# bestK &lt;- ghap.anctrain(object = phase, K = 5, tune = TRUE)
# plot(bestK$ssq, type = "b", xlab = "K",
#      ylab = "Within-cluster sum of squares")
# 
# # Unsupervised analysis with best K
# prototypes &lt;- ghap.anctrain(object = phase, K = 2)
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)
# 
# # Supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# prototypes &lt;- ghap.anctrain(object = phase, train = train,
#                             method = "supervised")
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)

</code></pre>

<hr>
<h2 id='ghap.anctrain'>
Construction of prototype alleles
</h2><span id='topic+ghap.anctrain'></span>

<h3>Description</h3>

<p>This function builds prototype alleles to be used in ancestry predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.anctrain(object, train = NULL,
               method = "unsupervised",
               K = 2, iter.max = 10, nstart = 10,
               nmarkers = 5000, tune = FALSE,
               only.active.samples = TRUE,
               only.active.markers = TRUE,
               batchsize = NULL, ncores = 1,
               verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>The following arguments are used by both the 'supervised' and 'unsupervised' methods:
</p>
<table>
<tr><td><code id="ghap.anctrain_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_train">train</code></td>
<td>

<p>Character vector of individuals to use as reference samples. All active individuals are used if this    vector is not provided.
</p>
</td></tr> 
<tr><td><code id="ghap.anctrain_+3A_method">method</code></td>
<td>

<p>Character value indicating which method to use: 'supervised' or 'unsupervised' (default).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in predictions (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used for predictions (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of markers to be processed at a time (default = nmarkers/10).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>
<p>The following arguments are only used by the 'unsupervised' method:
</p>
<table>
<tr><td><code id="ghap.anctrain_+3A_k">K</code></td>
<td>

<p>A numeric value specifying the number of clusters in K-means (default = 2). Proxy for the number of ancestral populations.
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_iter.max">iter.max</code></td>
<td>

<p>A numeric value specifying the maximum number of iterations of the K-means clustering (default = 10).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_nstart">nstart</code></td>
<td>

<p>A numeric value specifying the number of independent runs of the K-means clustering (default = 10).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_nmarkers">nmarkers</code></td>
<td>

<p>A numeric value specifying the number of seeding markers to be used by the K-means clustering (default = 10).
</p>
</td></tr>
<tr><td><code id="ghap.anctrain_+3A_tune">tune</code></td>
<td>

<p>A logical value specfying if a Best K analysis should be performed (default = FALSE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function builds prototype alleles (i.e., cluster centroids, representing lineage-specific allele frequencies) through two methods: <br />
</p>
<p>The 'unsupervised' method uses the K-means clustering algorithm to group haplotypes into K pseudo-lineages. A random sample of seeding markers (default value of nmarkers = 5000) is used to group all 2*nsamples haplotypes in a user-specified number of clusters (default value of K = 2). Then, for each interrogated block, prototype alleles are built for every cluster using the arithmetic mean of observed haplotypes initially assigned to that cluster. If train = NULL, the function uses all active haplotypes to build prototype alleles. If the user is working with a severely unbalanced data set (ex. one population with a large number of individuals and others with few individuals), it is recommended that a vector of individual names is provided via the train argument such that prototype alleles are built using a more balanced subset of the data.
</p>
<p>The 'supervised' method works in a similar way, but skips the K-means algorithm and uses population labels present in the GHap.phase object as clusters. <br />
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the first column giving marker names and remaining columns containing prototype alleles for each pseudo-lineage. If method 'unsupervised' is ran with tune = TRUE, the function returns the following list:
</p>
<table>
<tr><td><code>ssq</code></td>
<td>

<p>Within-cluster sum of squares for each value of K.
</p>
</td></tr>
<tr><td><code>chindex</code></td>
<td>

<p>Calinski Harabasz Index for consecutive values of K.
</p>
</td></tr>
<tr><td><code>pchange</code></td>
<td>

<p>Percent change in ssq for consecutive values of K.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>Y.T. Utsunomiya et al. Unsupervised detection of ancestry tracks with the GHap R package. Methods in Ecology and Evolution. 2020. 11:1448–54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.anctest">ghap.anctest</a></code>, <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code>, <code><a href="#topic+ghap.ancplot">ghap.ancplot</a></code>, <code><a href="#topic+ghap.ancmark">ghap.ancmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # BestK analysis
# bestK &lt;- ghap.anctrain(object = phase, K = 5, tune = TRUE)
# plot(bestK$ssq, type = "b", xlab = "K",
#      ylab = "Within-cluster sum of squares")
# 
# # Unsupervised analysis with best K
# prototypes &lt;- ghap.anctrain(object = phase, K = 2)
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)
# 
# # Supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# prototypes &lt;- ghap.anctrain(object = phase, train = train,
#                             method = "supervised")
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)


</code></pre>

<hr>
<h2 id='ghap.assoc'>
Genome-wide association analysis
</h2><span id='topic+ghap.assoc'></span>

<h3>Description</h3>

<p>This function performs phenotype-genotype association analysis based on mixed models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.assoc(object, formula, data, covmat,
           ngamma = 100, nlambda = 1000,
           recalibrate = 0.01,
           only.active.variants=TRUE,
           tol = 1e-12, ncores=1,
           verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.assoc_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_formula">formula</code></td>
<td>

<p>Formula describing the model. The synthax is consistent with lme4. The response is declared first, followed by the ~ operator. Predictors are then separated by + operators. Currently only random intercepts are supported, which are distinguished from fixed effects by the notation (1|x). If multiple random effects are specified, the first declared in the formula will be assumed to be the genetic (polygenic) effects.
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_data">data</code></td>
<td>

<p>A dataframe containing the data.
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_covmat">covmat</code></td>
<td>

<p>A list of covariance matrices for each group of random effects. If a matrix is not defined for a given group, an identity matrix will be used. Inverse covariance matrices can also be provided, as long as argument invcov = TRUE is used.
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_ngamma">ngamma</code></td>
<td>

<p>A numeric value for the number of variants to be used in the estimation of the gamma factor (default = 100). The grammar-gamma approximation is turned off if ngamma = 0.
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_nlambda">nlambda</code></td>
<td>

<p>A numeric value for the number of variants to be used in the estimation of the inflation factor (default = 1000).
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_recalibrate">recalibrate</code></td>
<td>

<p>A numeric value for the proportion of top scoring variants to re-analyze without the grammar-gamma approximation (default = 0.01). Not relevant if ngamma = 0.
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_only.active.variants">only.active.variants</code></td>
<td>

<p>A logical value specifying whether only active variants should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_tol">tol</code></td>
<td>

<p>A numeric value specifying the scalar to add to the diagonal of the phenotypic (co)variance matrix if it is not inversible (default = 1e-12).
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specifying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.assoc_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses mixed models and the grammar-gamma approximation for fast genome-wide association analysis. Since mixed models are fit using the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function, the association analysis can be performed using more flexible models than those offered by alternative software, including the use of repeated measurements and other random effects apart from polygenic effects.
</p>


<h3>Value</h3>

<p>The function returns a data frame with results from the genome-wide association analysis. If a GHap.haplo object is used, the first columns of the data frame will be:
</p>
<table>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
</table>
<p>For GHap.phase and GHap.plink objects, the first columns will be:
</p>
<table>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>MARKER</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
</table>
<p>The remaining columns of the data frame will be equal for any class of GHap objects:
</p>
<table>
<tr><td><code>ALLELE</code></td>
<td>

<p>Identity of the counted (A1 or haplotype) allele.
</p>
</td></tr>
<tr><td><code>FREQ</code></td>
<td>

<p>Frequency of the allele.
</p>
</td></tr>
<tr><td><code>N</code></td>
<td>

<p>Number of non-missing observations.
</p>
</td></tr>
<tr><td><code>BETA</code></td>
<td>

<p>Estimated allele substitution effect.
</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>

<p>Standard error for the allele substitution effect.
</p>
</td></tr>
<tr><td><code>CHISQ.EXP</code></td>
<td>

<p>Expected values for the test statistics.
</p>
</td></tr>
<tr><td><code>CHISQ.OBS</code></td>
<td>

<p>Observed value for the test statistics.
</p>
</td></tr>
<tr><td><code>CHISQ.GC</code></td>
<td>

<p>Test statistics scaled by the inflation factor (Genomic Control). Inflation is computed through regression of observed quantiles onto expected quantiles. In order to avoid overestimation by variants rejecting the null hypothesis, a random sample of variants (with size controled via the nlambda argument) is taken within three standard deviations from the mean of the distribution of test statistics.
</p>
</td></tr>
<tr><td><code>LOGP</code></td>
<td>

<p>log10(1/P) or -log10(P) for the allele substitution effect.
</p>
</td></tr>
<tr><td><code>LOGP.GC</code></td>
<td>

<p>log10(1/P) or -log10(P) for the allele substitution effect (scaled by the inflation factor).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>N. Amin et al. A Genomic Background Based Method for Association Analysis in Related Individuals. PLoS ONE. 2007. 2:e1274.
</p>
<p>Y. Da. Multi-allelic haplotype model based on genetic partition for genomic prediction and variance component estimation using SNP markers. BMC Genet. 2015. 16:144.
</p>
<p>B. Devlin and K. Roeder. Genomic control for association studies. Biometrics. 1999. 55:997-1004.
</p>
<p>C. C. Ekine et al. Why breeding values estimated using familial data should not be used for genome-wide association studies. G3. 2014. 4:341-347.
</p>
<p>L. Jiang et al. A resource-efficient tool for mixed model association analysis of large-scale data. Nat. Genet. 2019. 51:1749-1755.
</p>
<p>J. Listgarten et al. Improved linear mixed models for genome-wide association studies. Nat. Methods. 2012. 9:525-526.
</p>
<p>G. R. Svishcheva et al. Rapid variance components-based method for whole-genome association analysis. Nat Genet. 2012. 44:1166-1170.
</p>
<p>J. Yang et al. Advantages and pitfalls in the application of mixed-model association methods. Nat. Genet. 2014. 46: 100-106.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Perform GWAS on repeated measures
# # Use grammar-gama approximation
# # Recalibrate top 1 percent variants
# df$rep &lt;- df$id
# gwas1 &lt;- ghap.assoc(object = plink,
#                     formula = pheno ~ 1 + (1|id) + (1|rep),
#                     data = df,
#                     covmat = list(id = K, rep = NULL),
#                     ngamma = 100, nlambda = 1000, recalibrate = 0.01)
# ghap.manhattan(data = gwas1, chr = "CHR", bp = "BP", y = "LOGP")
# 
# # GWAS with no approximaion (slow)
# gwas2 &lt;- ghap.assoc(object = plink,
#                     formula = pheno ~ 1 + (1|id) + (1|rep),
#                     data = df,
#                     covmat = list(id = K, rep = NULL),
#                     ngamma = 0, nlambda = 1000)
# ghap.manhattan(data = gwas2, chr = "CHR", bp = "BP", y = "LOGP")
# 
# # Correlation between methods
# cor(gwas1$LOGP, gwas2$LOGP)
# plot(gwas1$LOGP, gwas2$LOGP); abline(0,1)

</code></pre>

<hr>
<h2 id='ghap.blockgen'>
Haplotype block generator
</h2><span id='topic+ghap.blockgen'></span>

<h3>Description</h3>

<p>This function generates HapBlocks based on sliding windows. The window and the step size can be specified in markers or kbp. For each window, block coordinates are generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.blockgen(object, windowsize = 10, slide = 5,
               unit = "marker", nsnp = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.blockgen_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.blockgen_+3A_windowsize">windowsize</code></td>
<td>

<p>A numeric value for the size of the window (default = 10).
</p>
</td></tr>
<tr><td><code id="ghap.blockgen_+3A_slide">slide</code></td>
<td>

<p>A numeric value for the step size (default = 5).
</p>
</td></tr>
<tr><td><code id="ghap.blockgen_+3A_unit">unit</code></td>
<td>

<p>A character value for the size unit used for the window and the step. It can be either &quot;marker&quot; or &quot;kbp&quot; (default = &quot;marker&quot;).
</p>
</td></tr>
<tr><td><code id="ghap.blockgen_+3A_nsnp">nsnp</code></td>
<td>

<p>A numeric value for the minimum number of markers per block.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with columns:
</p>
<table>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
<tr><td><code>SIZE</code></td>
<td>

<p>Haplotype size.
</p>
</td></tr>
<tr><td><code>NSNP</code></td>
<td>

<p>Number of marker.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Generate blocks of 5 markers sliding 5 markers at a time
# blocks.mkr &lt;- ghap.blockgen(phase, windowsize = 5,
#                             slide = 5, unit = "marker")
# 
# # Generate blocks of 100 kbp sliding 100 kbp at a time
# blocks.kb &lt;- ghap.blockgen(phase, windowsize = 100,
#                            slide = 100, unit = "kbp")


</code></pre>

<hr>
<h2 id='ghap.blockstats'>
HapBlock statistics
</h2><span id='topic+ghap.blockstats'></span>

<h3>Description</h3>

<p>Generate HapBlock summary statistics from pre-computed HapAlleles statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.blockstats(hapstats, ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.blockstats_+3A_hapstats">hapstats</code></td>
<td>

<p>A data.frame containing HapAllele statistics, as generated by the <code><a href="#topic+ghap.hapstats">ghap.hapstats</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.blockstats_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.blockstats_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each HapBlock, the function counts the number of unique HapAlleles and computes the expected heterozygosity <code class="reqn"> 1 - \sum {p_{i}}^2 </code>, where <code class="reqn">p_{i}</code> is the frequency of HapAllele <em>i</em>. Please notice that when HapAlleles are prunned out by frequency the block statistics can retrieve high expected heterozygosity for blocks with small number of HapAlleles.
</p>


<h3>Value</h3>

<p>A data frame with columns:
</p>
<table>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
<tr><td><code>EXP.H</code></td>
<td>

<p>Block expected heterozygosity.
</p>
</td></tr>
<tr><td><code>N.ALLELES</code></td>
<td>

<p>Number of HapAlleles per block.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# # Generate blocks of 5 markers
# blocks &lt;- ghap.blockgen(phase, windowsize = 5,
#                         slide = 5, unit = "marker")
# 
# # Haplotyping
# ghap.haplotyping(phase = phase, blocks = blocks, outfile = "example",
#                  binary = T, ncores = 1)
# 
# # Load haplotype genotypes using prefix
# haplo &lt;- ghap.loadhaplo("example")
# 
# # Subset
# ids &lt;- which(haplo$pop == "Pure1")
# haplo &lt;- ghap.subset(haplo, ids = ids,
#                      variants = haplo$allele.in,
#                      index = TRUE)
# 
# # Compute haplotype statistics
# hapstats &lt;- ghap.hapstats(haplo)
# 
# ### RUN ###
#
# # Compute block statistics
# blockstats &lt;- ghap.blockstats(hapstats)

</code></pre>

<hr>
<h2 id='ghap.compress'>
Compress phased genotype data
</h2><span id='topic+ghap.compress'></span>

<h3>Description</h3>

<p>This function takes phased genotype data and converts them into a compressed binary format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.compress(input.file = NULL, out.file,
                samples.file = NULL, markers.file = NULL,
                phase.file = NULL, batchsize = NULL,
                ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>If all input files share the same prefix, the user can use the following shortcut options:
</p>
<table>
<tr><td><code id="ghap.compress_+3A_input.file">input.file</code></td>
<td>

<p>Prefix for input files.
</p>
</td></tr>
<tr><td><code id="ghap.compress_+3A_out.file">out.file</code></td>
<td>

<p>Output file name.
</p>
</td></tr>
</table>
<p>For backward compatibility, the user can still point to input files separately:
</p>
<table>
<tr><td><code id="ghap.compress_+3A_samples.file">samples.file</code></td>
<td>

<p>Individual information.
</p>
</td></tr>
<tr><td><code id="ghap.compress_+3A_markers.file">markers.file</code></td>
<td>

<p>Variant map information.
</p>
</td></tr>
<tr><td><code id="ghap.compress_+3A_phase.file">phase.file</code></td>
<td>

<p>Phased genotype matrix.
</p>
</td></tr>
</table>
<p>To turn compression progress-tracking on or off, or to control parallelization of the task please use:
</p>
<table>
<tr><td><code id="ghap.compress_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of markers to be compressed and written to output at a time (default = nmarkers/10).
</p>
</td></tr>
<tr><td><code id="ghap.compress_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.compress_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The supported input format is composed of three files with suffix:
</p>

<ul>
<li> <p><strong>.samples</strong>: space-delimited file without header containing two mandatory columns: Population and ID. Please notice that the Population column serves solely for the purpose of grouping samples, so the user can define any arbitrary family/cluster/subgroup and use as a &quot;population&quot; tag. This file may further contain three additional columns, which are optional: Sire, Dam and Sex (with code 1 = M and 2 = F). Values &quot;0&quot; and &quot;NA&quot; in these additional columns are treated as missing values. 
</p>
</li>
<li> <p><strong>.markers</strong>: space-delimited file without header containing five mandatory columns: Chromosome, Marker, Position (in bp), Reference Allele (A0) and Alternative Allele (A1). Markers should be sorted by chromosome and position. Repeated positions are tolerated, but the user is warned of their presence in the data. Optionally, the user may provide a file containing an additional column with genetic positions (in cM), which has to be placed between the base pair position and the reference allele columns.
</p>
</li>
<li> <p><strong>.phase</strong>: space-delimited file without header containing the phased genotype matrix. The dimension of the matrix is expected to be <em>m x 2n</em>, where <em>m</em> is the number of markers and <em>n</em> is the number of individuals (i.e., two columns per individual, representing the two phased chromosome alleles). Alleles must be coded as 0 or 1. No missing values are allowed, since imputation is assumed to be part of the phasing procedure.
</p>
</li></ul>

<p>The function outputs a binary file with suffix <strong>.phaseb</strong>. Each allele is stored as a bit in that file. Bits for any given marker are arranged in a sequence of bytes. Since each marker requires storage of 2*nsamples bits, the number of bytes consumed by a single marker in the output file is ceiling(2*nsamples). If the number of alleles is not a multiple of 8, bits in the remainder of the last byte are filled with 0. All functions in GHap were carefully designed to decode the bytes of a marker in such a way that trailing bits are ignored if present.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "raw",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Compress phase data using prefix
# ghap.compress(input.file = "example",
#               out.file = "example")
# 
# # Compress phase data using file names
# ghap.compress(samples.file = "example.samples",
#               markers.file = "example.markers",
#               phase.file = "example.phase",
#               out.file = "example")

</code></pre>

<hr>
<h2 id='ghap.exfiles'>
Example files
</h2><span id='topic+ghap.exfiles'></span>

<h3>Description</h3>

<p>This function retrieves the list of example files available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.exfiles()
</code></pre>


<h3>Details</h3>

<p>This function requires internet connection. It returns a data table containing the list of example files in our github repository (<a href="https://github.com/ytutsunomiya/GHap">https://github.com/ytutsunomiya/GHap</a>). To get any of those files, please use <code><a href="#topic+ghap.makefile">ghap.makefile</a></code>.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># # See list of example files
# exlist &lt;- ghap.exfiles()
# View(exlist)
</code></pre>

<hr>
<h2 id='ghap.fast2phase'>
Convert fastPHASE data into the GHap phase format
</h2><span id='topic+ghap.fast2phase'></span>

<h3>Description</h3>

<p>This function takes phased genotype data in fastPHASE format and converts them into a GHap plan and compressed binary format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.fast2phase(input.files = NULL, switchout.files = NULL,
                  map.files = NULL, fam.file = NULL,
                  out.file = NULL, overwrite = FALSE,
                  ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>If all input files share the same prefix, the user can use the following shortcut options:
</p>
<table>
<tr><td><code id="ghap.fast2phase_+3A_input.files">input.files</code></td>
<td>

<p>Character vector with the list of prefixes for input files.
</p>
</td></tr>
<tr><td><code id="ghap.fast2phase_+3A_out.file">out.file</code></td>
<td>

<p>Character value for the output file name.
</p>
</td></tr>
</table>
<p>The user can also opt to point to input files separately:
</p>
<table>
<tr><td><code id="ghap.fast2phase_+3A_switchout.files">switchout.files</code></td>
<td>

<p>Character vector containing the list of fastPHASE files.
</p>
</td></tr>
<tr><td><code id="ghap.fast2phase_+3A_map.files">map.files</code></td>
<td>

<p>Character vector containing the list of map files.
</p>
</td></tr>
<tr><td><code id="ghap.fast2phase_+3A_fam.file">fam.file</code></td>
<td>

<p>Name of the file containing the population and individual ids.
</p>
</td></tr>
</table>
<p>The function avoids overwritting existing files by default. To change this behavior, please use:
</p>
<table>
<tr><td><code id="ghap.fast2phase_+3A_overwrite">overwrite</code></td>
<td>

<p>A logical value controling if existing files with the same name as the selected output should be overwritten (default = FALSE).
</p>
</td></tr>
</table>
<p>To turn conversion progress-tracking on or off or set the number of cores please use:
</p>
<table>
<tr><td><code id="ghap.fast2phase_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specfying the number of cores (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.fast2phase_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently this function handles _switch.out files from fastPHASE v1.4.0 or later. The map files should contain the following 5 space-delimited columns: chromosome, marker, position, allele 0 and allele 1 (no header). The fam file can have an arbitrary number of columns (with no header), but by default only the first two are read and should be space-delimited with the following data: population and individual name.
</p>


<h3>Author(s)</h3>

<p>Mario Barbato &lt;mario.barbato@unicatt.it&gt;
</p>


<h3>References</h3>

<p>Scheet, P., Stephens, M., 2006. A Fast and Flexible Statistical Model for Large-Scale Population Genotype Data: Applications to Inferring Missing Genotypes and Haplotypic Phase. Am. J. Hum. Genet. 78, 629-644. https://doi.org/10.1086/502802.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.compress">ghap.compress</a></code>, <code><a href="#topic+ghap.loadphase">ghap.loadphase</a></code>, <code><a href="#topic+ghap.oxford2phase">ghap.oxford2phase</a></code>, <code><a href="#topic+ghap.vcf2phase">ghap.vcf2phase</a></code>
</p>

<hr>
<h2 id='ghap.freq'>
Compute marker allele frequencies
</h2><span id='topic+ghap.freq'></span>

<h3>Description</h3>

<p>This function takes a GHap.phase object and computes the allele frequency for each marker.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.freq(object, type = "maf",
            only.active.samples = TRUE,
            only.active.markers = TRUE,
            ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.freq_+3A_object">object</code></td>
<td>

<p>A GHap object of type phase or plink.
</p>
</td></tr>
<tr><td><code id="ghap.freq_+3A_type">type</code></td>
<td>

<p>A character value indicating which allele frequency to compute. Valid options are minor allele frequency ('maf', default), frequency of allele 0 ('A0') and frequency of allele 1 ('A1').
</p>
</td></tr>
<tr><td><code id="ghap.freq_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be used for calculations (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.freq_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.freq_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.freq_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function outputs a numeric vector of the same length of active markers containing allele frequencies based on the active samples.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Calculate allele frequency for phase data
# phase &lt;- ghap.loadphase("example")
# q &lt;- ghap.freq(phase, type = 'A0')
# p &lt;- ghap.freq(phase, type = 'A1')
# maf &lt;- ghap.freq(phase, type = 'maf')
# 
# # Calculate allele frequency for plink data
# plink &lt;- ghap.loadplink("example")
# q &lt;- ghap.freq(plink, type = 'A0')
# p &lt;- ghap.freq(plink, type = 'A1')
# maf &lt;- ghap.freq(plink, type = 'maf')

</code></pre>

<hr>
<h2 id='ghap.froh'>
Calculation of genomic inbreeding (FROH)
</h2><span id='topic+ghap.froh'></span>

<h3>Description</h3>

<p>Given runs of homozygosity (ROH) obtained with the <code><a href="#topic+ghap.roh">ghap.roh</a></code> function, this function computes the proportion of the genome covered by ROHs (FROH) of certain lengths.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.froh(object, roh, rohsizes = c(1, 2, 4, 8, 16),
           only.active.markers = TRUE, ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.froh_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase or plink).
</p>
</td></tr>
<tr><td><code id="ghap.froh_+3A_roh">roh</code></td>
<td>

<p>A data frame containing runs of homozygosity, such as supplied by the <code><a href="#topic+ghap.roh">ghap.roh</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.froh_+3A_rohsizes">rohsizes</code></td>
<td>

<p>A numeric vector providing the minimum ROH length (in Mbp) to use in the calculation of ROH (default is 1, 2, 4, 8 and 16). 
</p>
</td></tr>
<tr><td><code id="ghap.froh_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used in the calculation of genome size (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.froh_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes runs of homozygosity obtained with <code><a href="#topic+ghap.roh">ghap.roh</a></code> and returns estimates of genomic inbreeding (FROH). The user can specify the minimum ROH length considered in the calculation using the rohsize argument. A vector of values will cause the function to add an extra column for each specified ROH size. Since the average size (measured in Morgans) of identical-by-descent segments after g generations of the inbreeding event is 1/2g, the default lengths 1, 2, 4, 8 adn 16 are proxies for inbreeding that occurred 50, 25, 13 6 and 3 generations in the past, respectively (assuming an average recombination rate of 1 Mbp ~ cM).
</p>


<h3>Value</h3>

<p>The function returns a dataframe the following columns:
</p>
<table>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>FROH...</code></td>
<td>

<p>A number of columns giving FROH calculated over runs of length greater than each of the sizes informed by the rohsize argument. Default values will return FROH1, FROH2, FROH4, FROH8 and FROH16.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.roh">ghap.roh</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# ### RUN ###
# 
# # Subset pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # ROH via the 'naive' method
# roh1 &lt;- ghap.roh(plink, method = "naive")
# froh1 &lt;- ghap.froh(plink, roh1)
# 
# # ROH via the 'hmm' method
# freq &lt;- ghap.freq(plink, type = 'A1')
# inbcoef &lt;- froh1$FROH1; names(inbcoef) &lt;- froh1$ID
# roh2 &lt;- ghap.roh(plink, method = "hmm", freq = freq,
#                 inbcoef = inbcoef)
# froh2 &lt;- ghap.froh(plink, roh2)
#
# # Method 'hmm' using Fhat3 as starting values
# inbcoef &lt;- ibc$Fhat3; names(inbcoef) &lt;- ibc$ID
# inbcoef[which(inbcoef &lt; 0)] &lt;- 0.01
# roh3 &lt;- ghap.roh(plink, method = "hmm", freq = freq,
#                  inbcoef = inbcoef)
# froh3 &lt;- ghap.froh(plink, roh3)

</code></pre>

<hr>
<h2 id='ghap.fst'>
Haplotype-based Fst
</h2><span id='topic+ghap.fst'></span>

<h3>Description</h3>

<p>Multi-alleleic Fst computed using block summary statistics generated from <code><a href="#topic+ghap.blockstats">ghap.blockstats</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.fst(blockstats.pop1,
          blockstats.pop2,
          blockstats.tot)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.fst_+3A_blockstats.pop1">blockstats.pop1</code></td>
<td>

<p>A data.frame containing block statistics computed on population 1.
</p>
</td></tr>
<tr><td><code id="ghap.fst_+3A_blockstats.pop2">blockstats.pop2</code></td>
<td>

<p>A data.frame containing block statistics computed on population 2.
</p>
</td></tr>
<tr><td><code id="ghap.fst_+3A_blockstats.tot">blockstats.tot</code></td>
<td>

<p>A data.frame containing block statistics computed on population 1 + population 2.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates Fst (Nei, 1973) based on the formula for multi-allelic markers:
</p>
<p style="text-align: center;"><code class="reqn">Fst = (Ht - Hs) / Ht</code>
</p>

<p>where <em>Ht</em> is the total gene diversity (i.e., expected heterozygosity in the population) and <em>Hs</em> is the subpopulation gene diversity (i.e., the average expected heterozygosity in the subpopulations).
</p>


<h3>Value</h3>

<p>The function returns a data.frame with the following columns:
</p>
<table>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
<tr><td><code>EXP.H.pop1</code></td>
<td>

<p>Expected heterozygosity in population 1.
</p>
</td></tr>
<tr><td><code>EXP.H.pop2</code></td>
<td>

<p>Expected heterozygosity in population 2.
</p>
</td></tr>
<tr><td><code>EXP.H.tot</code></td>
<td>

<p>Expected heterozygosity in the total population.
</p>
</td></tr>
<tr><td><code>FST</code></td>
<td>

<p>Fst value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>References</h3>

<p>M. Nei. Analysis of Gene Diversity in Subdivided Populations. PNAS. 1973. 70, 3321-3323.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# # Generate blocks of 5 markers
# blocks &lt;- ghap.blockgen(phase, windowsize = 5,
#                         slide = 5, unit = "marker")
# 
# # Haplotyping
# ghap.haplotyping(phase = phase, blocks = blocks, outfile = "example",
#                  binary = T, ncores = 1)
# 
# # Load haplotype genotypes using prefix
# haplo &lt;- ghap.loadhaplo("example")
# 
# ### RUN ###
# 
# # Compute block statistics for population 1
# ids &lt;- which(haplo$pop == "Pure1")
# haplo &lt;- ghap.subset(haplo, ids = ids,
#                      variants = haplo$allele.in,
#                      index = TRUE)
# hapstats1 &lt;- ghap.hapstats(haplo)
# blockstats1 &lt;- ghap.blockstats(hapstats1)
# 
# # Compute block statistics for population 2
# ids &lt;- which(haplo$pop == "Pure2")
# haplo &lt;- ghap.subset(haplo, ids = ids,
#                      variants = haplo$allele.in,
#                      index = TRUE)
# hapstats2 &lt;- ghap.hapstats(haplo)
# blockstats2 &lt;- ghap.blockstats(hapstats2)
# 
# # Compute block statistics for combined populations
# ids &lt;- which(haplo$pop %in% c("Pure1","Pure2"))
# haplo &lt;- ghap.subset(haplo, ids = ids,
#                      variants = haplo$allele.in,
#                      index = TRUE)
# hapstats12 &lt;- ghap.hapstats(haplo)
# blockstats12 &lt;- ghap.blockstats(hapstats12)
# 
# # Compute FST
# fst &lt;- ghap.fst(blockstats1, blockstats2, blockstats12)
# ghap.manhattan(data = fst, chr = "CHR", bp = "BP1",
#                y = "FST", type = "h")

</code></pre>

<hr>
<h2 id='ghap.getHinv'>
Compute the inverse of H
</h2><span id='topic+ghap.getHinv'></span>

<h3>Description</h3>

<p>This function combines an additive genomic relationship matrix with pedigree data to form the inverse of the H relationship matrix used in single-step GBLUP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.getHinv(K, ped, include = NULL, depth = 3,
             alpha = 0.95, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.getHinv_+3A_k">K</code></td>
<td>

<p>An additive genomic relationship matrix, as provided for example by type=3 in <code><a href="#topic+ghap.kinship">ghap.kinship</a></code>.
</p>
</td></tr>
<tr><td><code id="ghap.getHinv_+3A_ped">ped</code></td>
<td>

<p>A dataframe with columns &quot;id&quot;, &quot;sire&quot; and &quot;dam&quot; containing pedigree data.
</p>
</td></tr>
<tr><td><code id="ghap.getHinv_+3A_include">include</code></td>
<td>

<p>An optional vector of ids to be forced into the output (default = NULL). See details.
</p>
</td></tr>
<tr><td><code id="ghap.getHinv_+3A_depth">depth</code></td>
<td>

<p>A numeric value specifying the pedigree depth in number of generations to be used (default = 3). See details.
</p>
</td></tr>
<tr><td><code id="ghap.getHinv_+3A_alpha">alpha</code></td>
<td>

<p>A numeric value between 0 and 1 specifying the weight of the genomic relationship matrix in the blend alpha*K + (1-alpha)*K. Default = 0.95.
</p>
</td></tr>
<tr><td><code id="ghap.getHinv_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specifying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The pedigree is pruned to include only the number of generations specified by argument &quot;depth&quot;. This prunning starts by seeding the genealogy with all individuals included in the genomic relationship matrix plus all individuals listed in the &quot;include&quot; argument. Then, the genealogy is increased by advancing one generation back at a time up to &quot;depth&quot;. For example, if depth = 3, the genealogical tree will include all individuals listed in K and &quot;include&quot;, plus their parents (depth = 1), grandparents (depth = 2) and great-grandparents (depth = 3). After the pedigree has been pruned, pedigree and genomic relationships are blended to form the inverse of H.
</p>


<h3>Value</h3>

<p>A matrix consisting of the inverse of H.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>A. I. Vazquez. Technical note: An R package for fitting generalized linear mixed models in animal breeding. J. Anim. Sci. 2010. 88, 497-504.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype and pedigree data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# ped &lt;- read.table(file = "example.pedigree", header=T)
# 
# ### RUN ###
# 
# # This analysis emulates a scenario of
# # 100 individuals with genotypes and phenotypes
# # 200 individuals with only phenotypes
# # 400 individuals from pedigree with no data
# 
# # Subset 100 individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# pure1 &lt;- sample(x = pure1, size = 100)
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Exclude pedigree records with missing sire
# ped &lt;- ped[which(is.na(ped$sire) == F),]
# 
# # Make inverse of blended pedigree/genomic matrix
# ids &lt;- unique(c(ped$id, ped$sire, ped$dam, colnames(K)))
# Hinv &lt;- ghap.getHinv(K = K, ped = ped[,-1], include = ids)
# 
# # Run single-step GBLUP
# df$rep &lt;- df$id
# model &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                   data = df,
#                   covmat = list(id = Hinv, rep = NULL),
#                   invcov = T)

</code></pre>

<hr>
<h2 id='ghap.hap2plink'>
Convert haplotype allele counts to PLINK binary
</h2><span id='topic+ghap.hap2plink'></span>

<h3>Description</h3>

<p>This function takes a HapGenotypes matrix (as generated with the <code><a href="#topic+ghap.haplotyping">ghap.haplotyping</a></code> function) and converts it to PLINK binary (bed/bim/fam) format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.hap2plink(object, outfile)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.hap2plink_+3A_object">object</code></td>
<td>

<p>A GHap.haplo object.
</p>
</td></tr>
<tr><td><code id="ghap.hap2plink_+3A_outfile">outfile</code></td>
<td>

<p>A character value specifying the name used for the .bed, .bim and .fam output files.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned file mimics a standard PLINK (Purcell et al., 2007; Chang et al., 2015) binary file (bed/bim/fam), where HapAllele counts 0, 1 and 2 are recoded as NN, NH and HH genotypes (N = NULL and H = haplotype allele), as if HapAlleles were bi-alelic markers. This codification is acceptable for any given analysis relying on SNP genotype counts, as long as the user specifies that the analysis should be done using the H character as reference for counts. You can specify reference alleles using the .tref file in PLINK with the <em>&ndash;reference-allele</em> command. This is desired for very large datasets, as softwares such as PLINK and GCTA (Yang et al., 2011) have faster implementations for regression, principal components and kinship matrix analyses. The name for each pseudo-marker is composed by a concatenation (separated by &quot;_&quot;) of block name, start, end and haplotype allele identity. Pseudo-marker positions are computed as (start+end)/2.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>References</h3>

<p>C. C. Chang et al. Second-generation PLINK: rising to the challenge of larger and richer datasets. Gigascience. 2015. 4, 7.
</p>
<p>S. Purcell et al. PLINK: a tool set for whole-genome association and population-based linkage analyses. Am. J. Hum. Genet. 2007. 81, 559-575.
</p>
<p>J. Yang et al. GCTA: A tool for genome-wide complex trait analysis. Am. J. Hum. Genet. 2011. 88, 76-82.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# # Generate blocks of 5 markers
# blocks &lt;- ghap.blockgen(phase, windowsize = 5,
#                         slide = 5, unit = "marker")
# 
# # Haplotyping
# ghap.haplotyping(phase = phase, blocks = blocks, outfile = "example",
#                  binary = T, ncores = 1)
# 
# # Load haplotype genotypes using prefix
# haplo &lt;- ghap.loadhaplo("example")
# 
# ### RUN ###
# 
# # Convert to plink
# ghap.hap2plink(haplo, outfile = "example")

</code></pre>

<hr>
<h2 id='ghap.haplotyping'>
Haplotype genotypes
</h2><span id='topic+ghap.haplotyping'></span>

<h3>Description</h3>

<p>Generate matrix of HapGenotypes for user-defined blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.haplotyping(object, blocks, outfile,
                 freq = c(0, 1), drop.minor = FALSE,
                 only.active.samples = TRUE,
                 only.active.markers = TRUE,
                 batchsize = NULL, binary = TRUE,
                 ncores = 1, verbose = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.haplotyping_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_blocks">blocks</code></td>
<td>

<p>A data frame containing block boundaries, such as supplied by the <code><a href="#topic+ghap.blockgen">ghap.blockgen</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_outfile">outfile</code></td>
<td>

<p>A character value specifying the name for the output files.
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_freq">freq</code></td>
<td>

<p>A numeric vector of length 2 specifying the range of haplotype allele frequency to be included in the output. Default is c(0,1), which includes all alleles.
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_drop.minor">drop.minor</code></td>
<td>

<p>A logical value specfying whether the minor allele should be excluded from the output (default = FALSE).
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used for haplotyping (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of haplotype blocks to be processed and written to output at a time (default = nblocks/10).
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_binary">binary</code></td>
<td>

<p>A logical value specfying whether the output file should be binary (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.haplotyping_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function outputs three files with suffix:
</p>

<ul>
<li> <p><strong>.hapsamples</strong>: space-delimited file without header containing two columns: Population and Individual ID.
</p>
</li>
<li> <p><strong>.hapalleles</strong>: space-delimited file without header containing five columns: Block Name, Chromosome, Start and End Position (in bp), and HapAllele.
</p>
</li>
<li> <p><strong>.hapgenotypes</strong>: if binary = FALSE, a space-delimited file without header containing the HapGenotype matrix (coded as 0, 1 or 2 copies of the HapAllele). The dimension of the matrix is <em>m x n</em>, where <em>m</em> is the number of HapAlleles and <em>n</em> is the number of individuals.
</p>
</li>
<li> <p><strong>.hapgenotypesb</strong>: if binary = TRUE (default), the same matrix as described above compressed into bits. For seamless compatibility with softwares that use PLINK binary files, the compression is performed using the SNP-major bed format.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>
<p>Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Generate blocks
# blocks &lt;- ghap.blockgen(phase, windowsize = 5,
#                         slide = 5, unit = "marker")
# 
# # Haplotyping
# ghap.haplotyping(phase, blocks = blocks,
#                  outfile = "example",
#                  binary = T, ncores = 1)

</code></pre>

<hr>
<h2 id='ghap.hapstats'>
Haplotype allele statistics
</h2><span id='topic+ghap.hapstats'></span>

<h3>Description</h3>

<p>Summary statistics for HapAlleles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.hapstats(object,
              alpha = c(1, 1),
              batchsize = NULL,
              only.active.samples = TRUE,
              only.active.alleles = TRUE,
              ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.hapstats_+3A_object">object</code></td>
<td>

<p>A GHap.haplo object.
</p>
</td></tr>
<tr><td><code id="ghap.hapstats_+3A_alpha">alpha</code></td>
<td>

<p>A numeric vector of size 2 specifying the shrinkage parameters for the expected-to-observed homozygotes ratio. Default is c(1, 1).
</p>
</td></tr>
<tr><td><code id="ghap.hapstats_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of HapAlleles to be processed at a time (default = nalleles/10).
</p>
</td></tr>
<tr><td><code id="ghap.hapstats_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.hapstats_+3A_only.active.alleles">only.active.alleles</code></td>
<td>

<p>A logical value specifying whether only active haplotype alleles should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.hapstats_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.hapstats_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with columns:
</p>
<table>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
<tr><td><code>ALLELE</code></td>
<td>

<p>Haplotype allele identity.
</p>
</td></tr>
<tr><td><code>N</code></td>
<td>

<p>Number of observations for the haplotype.
</p>
</td></tr>
<tr><td><code>FREQ</code></td>
<td>

<p>Haplotype frequency.
</p>
</td></tr>
<tr><td><code>O.HOM</code></td>
<td>

<p>Observed number of homozygotes.
</p>
</td></tr>
<tr><td><code>O.HET</code></td>
<td>

<p>Observed number of heterozygotes.
</p>
</td></tr>
<tr><td><code>E.HOM</code></td>
<td>

<p>Expected number of homozygotes.
</p>
</td></tr>
<tr><td><code>RATIO</code></td>
<td>

<p>Shrinkage expected-to-observed ratio for the number of homozygotes.
</p>
</td></tr>
<tr><td><code>BIN.logP</code></td>
<td>

<p>log10(1/P) or -log10(P) for Hardy-Weinberg equilibrium assuming number of homozygotes follows a Binomial distribution.
</p>
</td></tr>
<tr><td><code>POI.logP</code></td>
<td>

<p>log10(1/P) or -log10(P) for Hardy-Weinberg equilibrium assuming number of homozygotes follows a Poisson distribution.
</p>
</td></tr>
<tr><td><code>TYPE</code></td>
<td>

<p>Category of the HapAllele: &quot;SINGLETON&quot; = single allele of its block; &quot;ABSENT&quot; = the frequency of the allele is 0; &quot;MINOR&quot; = the least frequent allele of its block (in the case of ties, only the first allele is marked); &quot;MAJOR&quot; = the most frequent allele of its block (ties are also resolved by marking the first allele); &quot;REGULAR&quot; = the allele does not fall in any of the previous categories. Categories &quot;SINGLETON&quot;, &quot;MINOR&quot; and &quot;MAJOR&quot; only apply for blocks where frequencies sum to 1.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# # Generate blocks of 5 markers
# blocks &lt;- ghap.blockgen(phase, windowsize = 5,
#                         slide = 5, unit = "marker")
# 
# # Haplotyping
# ghap.haplotyping(phase = phase, blocks = blocks, outfile = "example",
#                  binary = T, ncores = 1)
# 
# # Load haplotype genotypes using prefix
# haplo &lt;- ghap.loadhaplo("example")
# 
# ### RUN ###
# 
# # Subset
# ids &lt;- which(haplo$pop == "Pure1")
# haplo &lt;- ghap.subset(haplo, ids = ids,
#                      variants = haplo$allele.in,
#                      index = TRUE)
# 
# # Compute haplotype statistics
# hapstats &lt;- ghap.hapstats(haplo)

</code></pre>

<hr>
<h2 id='ghap.ibd'>
Estimation of IBD sharing
</h2><span id='topic+ghap.ibd'></span>

<h3>Description</h3>

<p>This function estimates the same IBD statistics computed by plink's 'genome' option.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.ibd(object, pairlist, freq, mafcut=0.05,
         refsize=10000, batchsize=NULL,
         ncores=1, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.ibd_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase or plink).
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_pairlist">pairlist</code></td>
<td>

<p>A dataframe containing columns ID1 and ID2 specifying the pairs of individual ids to compare.
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_freq">freq</code></td>
<td>

<p>A named numeric vector with (A1) allele frequencies computed in a reference sample.
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_mafcut">mafcut</code></td>
<td>

<p>A numeric value specifying the minor allele frequency threshold for IBD calculations (default = 0.05).
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_refsize">refsize</code></td>
<td>

<p>A numeric value representing the reference sample size used in allele frequncy calculations. If not specified, a large reference sample is assumed (default = 10000)
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of variants to be processed at a time (default = nalleles/10).
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.ibd_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements plink's method-of-moments for IBD estimation. Although not as efficient as plink's implementation, our function allows the user to restrict calculations to specific individual pairs, as well as ground all computations on allele frequencies obtained from a reference population. This is useful for routine pedigree confirmation, since a smaller set of indviduals and comparisons are typically targeted in these situations. The original &ndash;genome flag in plink not only performs all possible comparisons given a set of individuals, but also estimates allele frequencies on-the-fly, which may be unreliable if the number of individuals is small. We still recommend using plink for large problems, such as all pairwise comparisons from thousands of individuals, because it is more efficient. Nevertheless, we offer a more convenient alternative for the validation of smaller pedigrees in routine analyses where a lookup table of allele frequencies is available and maintained from a large reference population.
</p>


<h3>Value</h3>

<p>A dataframe with columns:
POP1 = Population of individual 1<br />
ID1 = Name of individual 1<br />
POP2 = Population of individual 2<br />
ID2 = Name of individual 2<br />
IBS0 = Variant sites where ID1 and ID2 share no identical alleles<br />
IBS1 = Variant sites where ID1 and ID2 share 1 identical allele<br />
IBS2 = Variant sites where ID1 and ID2 share 2 identical alleles<br />
PERC = IBS2/(IBS0+IBS1+IBS2) [proportion of identical genotypes]<br />
DST = (IBS2 + 0.5*IBS1)/(IBS0+IBS1+IBS2) [proportion of shared alleles]<br />
Z0 = Proportion of the genome where ID1 and ID2 share no alleles IBD<br />
Z1 = Proportion of the genome where ID1 and ID2 share 1 allele IBD<br />
Z2 = Proportion of the genome where ID1 and ID2 share 2 alleles IBD<br />
PI_HAT = Z2 + 0.5*Z1 (proportion of IBD alleles shared between ID1 and ID2)
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>C. C. Chang et al. Second-generation PLINK: rising to the challenge of larger and richer datasets. Gigascience. 2015. 4, 7.
S. Purcell et al. PLINK: a tool set for whole-genome association and population-based linkage analyses. Am. J. Hum. Genet. 2007. 81, 559-575.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load pedigree data
# ped &lt;- read.table(file = "example.pedigree", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute A1 allele frequencies
# p &lt;- ghap.freq(plink, type = "A1")
# 
# # Compute IBD statistics for individual 1
# pairlist &lt;- data.frame(ID1 = pure1[1], ID2 = pure1[-1])
# ibd &lt;- ghap.ibd(object = plink, pairlist = pairlist, freq = p,
#                 refsize = length(pure1))
# 
# # Predict relationships for individual 1
# # 1 = parent-offspring
# # 3 = other types of relationship
# # 4 = unrelated
# rel &lt;- ghap.relfind(ibdpairs = ibd)
# table(rel$REL)
# 
# # Confirm with pedigree
# toprel &lt;- rel$ID2[which(rel$REL == 1)]
# ped[which(ped$id %in% toprel &amp; ped$dam == pure1[1]),]

</code></pre>

<hr>
<h2 id='ghap.inbcoef'>
Compute measures of inbreeding
</h2><span id='topic+ghap.inbcoef'></span>

<h3>Description</h3>

<p>This function computes genomic measures of inbreeding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.inbcoef(object, freq, batchsize=NULL,
             only.active.samples=TRUE,
             only.active.variants=TRUE,
             ncores=1, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.inbcoef_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.inbcoef_+3A_freq">freq</code></td>
<td>

<p>A named numeric vector providing allele frequencies.
</p>
</td></tr>
<tr><td><code id="ghap.inbcoef_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of variants to be processed at a time (default = nalleles/10).
</p>
</td></tr>
<tr><td><code id="ghap.inbcoef_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.inbcoef_+3A_only.active.variants">only.active.variants</code></td>
<td>

<p>A logical value specifying whether only active variants should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.inbcoef_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.inbcoef_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inbreeding measures are computed as k + s*sum(f)/d, where k is a constant, s is a sign shifting scalar, f is a per-variant function and d is a scaling denominator. Four different measures of inbreeding are currently available:
</p>
<p>Type = 1 (based on genomic relationship)<br />
k = -1<br />
s = 1<br />
f = ((m - 2*p)^2)/(2*p*(1-p))<br />
d = n<br />
</p>
<p>Type = 2 (excess homozygosity)<br />
k = 1<br />
s = -1<br />
f = m*(2-m)/(2*p*(1-p))<br />
d = n<br />
</p>
<p>Type = 3 (correlation between uniting gametes)<br />
k = 0<br />
s = 1<br />
f = (m^2 - (1+2*p) + 2*p^2)/(2*p*(1-p))<br />
d = n<br />
</p>
<p>Type = 4 (method-of-moments)<br />
k = 1<br />
s = -1<br />
f = length(het)<br />
d = sum(2*p*(1-p))<br />
</p>
<p>In the expressions above, m is the genotype coded as 0, 1 or 2 copies of A1, p is the frequency of A1, n is the number of variants (only non-monomorphic ones are considered), and het is the number of heterozygous genotypes.
</p>


<h3>Value</h3>

<p>The function returns a dataframe containing population name, id and inbreeding measures for each individual.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>J. Yang et al. GCTA: A Tool for Genome-wide Complex Trait Analysis. Am. J. Hum. Genet. 2011. 88:76–82.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute A1 allele frequencies
# p &lt;- ghap.freq(plink, type = "A1")
# 
# # Compute inbreeding coefficients
# ibc &lt;- ghap.inbcoef(object = plink, freq = p)

</code></pre>

<hr>
<h2 id='ghap.karyoplot'>
Individual chromosome painting
</h2><span id='topic+ghap.karyoplot'></span>

<h3>Description</h3>

<p>Given smoothed ancestry predictions obtained with the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function and the name of the indivual, an individual karyotype plot is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.karyoplot(ancsmooth, ids = NULL,
                colors = NULL, chr = NULL, 
                chr.line = 10, plot.line = 25,
                chr.ang = 45, las = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.karyoplot_+3A_ancsmooth">ancsmooth</code></td>
<td>

<p>A list containing smoothed ancestry classifications, such as supplied by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_ids">ids</code></td>
<td>

<p>A character vector of individual(s) to plot. If NULL all the individuals will be plotted (default = NULL).
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_colors">colors</code></td>
<td>

<p>A character vector of colors to use for each ancestry label (default = NULL).
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_chr">chr</code></td>
<td>

<p>A vector with the chromosome(s) to plot. If NULL, all the chromosomes will be plotted (default = NULL).
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_chr.line">chr.line</code></td>
<td>

<p>A numeric value representing the number of chromosomes per plot line (default = 10).
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_plot.line">plot.line</code></td>
<td>

<p>A numeric value representing the distance of horizontal guide (default = 25).
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_chr.ang">chr.ang</code></td>
<td>

<p>A numeric value representing the rotation of chromosome labels in degrees (default = 45).
</p>
</td></tr>
<tr><td><code id="ghap.karyoplot_+3A_las">las</code></td>
<td>

<p>A numeric value representing the las of y-axes (default = 0).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes smoothed ancestry classifications provided by the <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code> function and &quot;paint&quot; the chomosomes of one individual using the ancestry proportions. One or more individuals could be plotted in separated graph. 
</p>


<h3>Author(s)</h3>

<p>Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.anctrain">ghap.anctrain</a></code>, <code><a href="#topic+ghap.anctest">ghap.anctest</a></code>, <code><a href="#topic+ghap.ancsvm">ghap.ancsvm</a></code>, <code><a href="#topic+ghap.ancsmooth">ghap.ancsmooth</a></code>, <code><a href="#topic+ghap.ancmark">ghap.ancmark</a></code>, <code><a href="#topic+ghap.ancplot">ghap.ancplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# 
# phase &lt;- ghap.loadphase("example")
# 
# # Calculate marker density
# mrkdist &lt;- diff(phase$bp)
# mrkdist &lt;- mrkdist[which(mrkdist &gt; 0)]
# density &lt;- mean(mrkdist)
# 
# # Generate blocks for admixture events up to g = 10 generations in the past
# # Assuming mean block size in Morgans of 1/(2*g)
# # Approximating 1 Morgan ~ 100 Mbp
# g &lt;- 10
# window &lt;- (100e+6)/(2*g)
# window &lt;- ceiling(window/density)
# step &lt;- ceiling(window/4)
# blocks &lt;- ghap.blockgen(phase, windowsize = window,
#                         slide = step, unit = "marker")
# 
# # Supervised analysis
# train &lt;- unique(phase$id[which(phase$pop != "Cross")])
# prototypes &lt;- ghap.anctrain(object = phase, train = train,
#                             method = "supervised")
# hapadmix &lt;- ghap.anctest(object = phase,
#                          blocks = blocks,
#                          prototypes = prototypes,
#                          test = unique(phase$id))
# anctracks &lt;- ghap.ancsmooth(object = phase, admix = hapadmix)
# ghap.ancplot(ancsmooth = anctracks)
# 
# ### RUN ###
# 
# # Plot karyoplot
# pure1 &lt;- unique(phase$id[which(phase$pop == "Pure1")])
# pure2 &lt;- unique(phase$id[which(phase$pop == "Pure2")])
# cross &lt;- unique(phase$id[which(phase$pop == "Cross")])
# ghap.karyoplot(ancsmooth = anctracks, ids = pure1[1],
#                chr.line = 11, plot.line = 50, las=1, chr=NULL)
# ghap.karyoplot(ancsmooth = anctracks, ids = pure2[1],
#                chr.line = 11, plot.line = 50, las=1, chr=NULL)
# ghap.karyoplot(ancsmooth = anctracks, ids = cross[1],
#                chr.line = 11, plot.line = 50, las=1, chr=NULL)

</code></pre>

<hr>
<h2 id='ghap.kinship'>
Relationship matrix based on genomic data
</h2><span id='topic+ghap.kinship'></span>

<h3>Description</h3>

<p>This function computes marker-based and HapAllele-based relationship matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.kinship(object, weights = NULL,
             sparsity = NULL,
             type = 1, batchsize = NULL,
             only.active.samples = TRUE,
             only.active.variants = TRUE,
             ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.kinship_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_weights">weights</code></td>
<td>

<p>A numeric vector providing variant-specific weights.
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_sparsity">sparsity</code></td>
<td>

<p>A numeric value specifying a relationship cut-off (default = NULL). All relationships below the specified cut-off will be set to zero, inducing sparsity into the relationship matrix.
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_type">type</code></td>
<td>

<p>A numeric value indicating the type of relationship matrix (see details).
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of variants to be processed at a time (default = nalleles/10).
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_only.active.variants">only.active.variants</code></td>
<td>

<p>A logical value specifying whether only active variants should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.kinship_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\mathbf{M}</code> be the <em>n</em> x <em>m</em> matrix of genotypes, where <em>n</em> is the number of individuals and <em>m</em> is the number of variants (i.e, markers or HapAlleles). Prior to computation, genotypes in matrix <code class="reqn">\mathbf{M}</code> are transformed according to the desired relationship type. After that transformation, the relationship matrix is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{K} = q^{-1}\mathbf{MDM}'</code>
</p>

<p>where <code class="reqn">\mathbf{D} = diag(d_i)</code>, <code class="reqn">d_i</code> is the weight of variant <em>i</em> (default <code class="reqn">d_i = 1</code>), and <code class="reqn">q</code> is a scaling factor. The argument type controls the genotype transformation and the scaling factor, and includes the following option:
<br />
Type = 1 (General additive 1)<br />
Genotype transformation: m - mean(m)<br />
Scaling factor: <code class="reqn">tr(\mathbf{MDM}')^{-1}n</code>
</p>
<p>Type = 2 (General additive 2)<br />
Genotype transformation: (m - mean(m))/sd(m)<br />
Scaling factor: m
</p>
<p>Type = 3 (VanRaden, 2008)<br />
Genotype transformation: m - 2*p[j]<br />
Scaling factor: 2*sum(p*(1-p))
</p>
<p>Type = 4 (GCTA)<br />
Genotype transformation: (m - 2*p[j])/sqrt(2*p[j]*(1-p[j]))<br />
Scaling factor: m
</p>
<p>Type = 5 (Dominance 1)<br />
Genotype transformation:<br />
0 = -2*p[j]^2<br />
1 = 2*p[j]*(1-p[j])<br />
2 = -2*(1-p[j])^2<br />
Scaling factor: 4*sum(p^2*(1-p)^2).
</p>
<p>Type = 6 (Dominance 2)<br />
Genotype transformation:<br />
0 = -2*p[j]^2<br />
1 = 2*p[j]*(1-p[j])<br />
2 = -2*(1-p[j])^2<br />
Scaling factor:<br />
<code class="reqn">tr(\mathbf{MDM}')^{-1}n</code>.
</p>


<h3>Value</h3>

<p>The function returns a <em>n</em> x <em>n</em> relationship matrix, where <em>n</em> is the number of individuals.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>References</h3>

<p>P. M. VanRaden. Efficient methods to compute genomic predictions. J. Dairy. Sci. 2008. 91:4414-4423.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Compute different types of relationship matrices
# K1 &lt;- ghap.kinship(plink, type = 1) # General additive 1
# K2 &lt;- ghap.kinship(plink, type = 2) # General additive 2
# K3 &lt;- ghap.kinship(plink, type = 3) # VanRaden 2008
# K4 &lt;- ghap.kinship(plink, type = 4) # GCTA GRM
# K5 &lt;- ghap.kinship(plink, type = 5) # Dominance 1
# K6 &lt;- ghap.kinship(plink, type = 6) # Dominance 2


</code></pre>

<hr>
<h2 id='ghap.lmm'>
Linear mixed model
</h2><span id='topic+ghap.lmm'></span>

<h3>Description</h3>

<p>Linear mixed model fitting for fixed effects, random effects and variance components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.lmm(formula, data, covmat = NULL,
         weights = NULL, vcp.initial = NULL,
         vcp.estimate = TRUE, vcp.conv = 1e-12,
         errors = TRUE, invcov = FALSE,
         em.reml = 10, tol = 1e-12, extras = NULL,
         verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.lmm_+3A_formula">formula</code></td>
<td>

<p>Formula describing the model. The synthax is consistent with lme4. The response is declared first, followed by the ~ operator. Predictors are then separated by + operators. Currently only random intercepts are supported, which are distinguished from fixed effects by the notation (1|x).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_covmat">covmat</code></td>
<td>

<p>A list of covariance matrices for each group of random effects. If a matrix is not defined for a given group, an identity matrix will be used. Inverse covariance matrices can also be provided, as long as argument invcov = TRUE is used.
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_data">data</code></td>
<td>

<p>A dataframe containing the data.
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_weights">weights</code></td>
<td>

<p>A numeric vector with weights for observations. These weights are treated as diagonal elements of the inverse weight matrix. If not supplied, the analysis is carried out assuming all observations are equally important.
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_vcp.initial">vcp.initial</code></td>
<td>

<p>A list of initial values for variance components. If not provided, the sample variance will be equally divided across the variance components.
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_vcp.estimate">vcp.estimate</code></td>
<td>

<p>A logical value specifying whether variance components should be estimated (default = TRUE). If FALSE, values passed to vcp.initial will be regarded as known variances.
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_vcp.conv">vcp.conv</code></td>
<td>

<p>A numeric value specifying the convergence criterion for variance components (default = 1e-12).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_errors">errors</code></td>
<td>

<p>A logical value specifying whether standard errors should be computed (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_invcov">invcov</code></td>
<td>

<p>A logical value specifying whether the provided covariance matrices are already inverted (default = FALSE).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_em.reml">em.reml</code></td>
<td>

<p>A numeric value specifying the number of EM-REML iterations to carry out before switching to AI-REML (default = 10).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_tol">tol</code></td>
<td>

<p>A numeric value specifying the scalar to add to the diagonal of the left hand side of mixed models equations if it is not inversible (default = 1e-12).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_extras">extras</code></td>
<td>

<p>A character vector indicating extra output to be included in the results list. Currently supported extras are the full inverse of the coefficient matrix (&quot;LHSi&quot;) and the phenotypic (co)variance matrix (&quot;V&quot;).
</p>
</td></tr>
<tr><td><code id="ghap.lmm_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specifying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function fits mixed models using a combination of EM-REML, AI-REML and PCG. Random regression and multivariate analyses are currently not supported.
</p>


<h3>Value</h3>

<p>The returned GHap.lmm object is a list with the following items:
</p>
<table>
<tr><td><code>fixed</code></td>
<td>

<p>A dataframe containing estimates, standard errors, t values and p-values of fixed effects.
</p>
</td></tr>
<tr><td><code>random</code></td>
<td>

<p>A list of dataframes, one for each group of random effects, containing estimates, standard errors and accuracy of random effects.
</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>

<p>A dataframe with fitted values using all effects, only fixed effects and only random effects.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>

<p>A dataframe with residuals from subtracting fitted values using all effects, only fixed effects and only random effects.
</p>
</td></tr>
<tr><td><code>vcp</code></td>
<td>

<p>A dataframe with estimates and standard errors of variance components.
</p>
</td></tr>
<tr><td><code>extras</code></td>
<td>

<p>A list of extra outputs requested by the user (see arguments for possible extras).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>J. Jensen et al. Residual maximum likelihood estimation of (Co)variance components in multivariate mixed linear models using average information. J. Ind. Soc. Ag. Statistics 1997. 49, 215-236.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype and pedigree data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Fit mixed model with variance components estimation
# df$rep &lt;- df$id
# model1 &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                    data = df,
#                    covmat = list(id = K, rep = NULL))
# 
# # Fit mixed model with fixed variance components
# df$rep &lt;- df$id
# model2 &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                    data = df,
#                    covmat = list(id = K, rep = NULL),
#                    vcp.initial = list(id = 0.4, rep = 0.2, Residual = 0.4),
#                    vcp.estimate = F)

</code></pre>

<hr>
<h2 id='ghap.loadhaplo'>
Load haplotype genotype data
</h2><span id='topic+ghap.loadhaplo'></span>

<h3>Description</h3>

<p>This function loads HapGenotypes generated by <code><a href="#topic+ghap.haplotyping">ghap.haplotyping</a></code> and converts them to a native GHap.haplo object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.loadhaplo(input.file = NULL,
                 hapsamples.file = NULL,
                 hapalleles.file = NULL,
                 hapgenotypesb.file = NULL,
                 verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.loadhaplo_+3A_input.file">input.file</code></td>
<td>

<p>Prefix for input files.
</p>
</td></tr>
<tr><td><code id="ghap.loadhaplo_+3A_hapsamples.file">hapsamples.file</code></td>
<td>

<p>Individual information file.
</p>
</td></tr>
<tr><td><code id="ghap.loadhaplo_+3A_hapalleles.file">hapalleles.file</code></td>
<td>

<p>Haplotype alleles information file.
</p>
</td></tr>
<tr><td><code id="ghap.loadhaplo_+3A_hapgenotypesb.file">hapgenotypesb.file</code></td>
<td>

<p>Binary haplotype genotype matrix file.
</p>
</td></tr>
<tr><td><code id="ghap.loadhaplo_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specifying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned GHap.haplo object is a list with components:
</p>
<table>
<tr><td><code>nsamples</code></td>
<td>

<p>An integer value for the sample size.
</p>
</td></tr>
<tr><td><code>nalleles</code></td>
<td>

<p>An integer value for the number of haplotype alleles.
</p>
</td></tr>
<tr><td><code>nsamples.in</code></td>
<td>

<p>An integer value for the number of active samples.
</p>
</td></tr>
<tr><td><code>nalleles.in</code></td>
<td>

<p>An integer value for the number of active haplotype alleles.
</p>
</td></tr>
<tr><td><code>pop</code></td>
<td>

<p>A character vector relating samples to populations. This information is obtained from the first column of the hapsamples file.
</p>
</td></tr>
<tr><td><code>id</code></td>
<td>

<p>A character vector mapping genotypes to samples. This information is obtained from the second column of the hapsamples file.
</p>
</td></tr>
<tr><td><code>id.in</code></td>
<td>

<p>A logical vector indicating active samples. By default, all samples are set to TRUE.
</p>
</td></tr>
<tr><td><code>chr</code></td>
<td>

<p>A character vector mapping haplotype alleles to chromosomes. This information is obtained from the second column of the hapalleles file.
</p>
</td></tr>
<tr><td><code>block</code></td>
<td>

<p>A character vector containing block names. This information is obtained from the first column of the hapalleles file.
</p>
</td></tr>
<tr><td><code>bp1</code></td>
<td>

<p>A numeric vector with haplotype allele start positions. This information is obtained from the third column of the hapalleles file.
</p>
</td></tr>
<tr><td><code>bp2</code></td>
<td>

<p>A numeric vector with haplotype allele end positions. This information is obtained from the fourth column of the hapalleles file.
</p>
</td></tr>
<tr><td><code>allele</code></td>
<td>

<p>A character vector with haplotype allele identity. This information is obtained from the fifth column of the hapalleles file.
</p>
</td></tr>
<tr><td><code>allele.in</code></td>
<td>

<p>A logical vector indicating active haplotype alleles. By default, all alleles are set to TRUE.
</p>
</td></tr>
<tr><td><code>genotypes</code></td>
<td>

<p>A character value giving the pathway to the binary haplotype genotype matrix.
</p>
</td></tr>
</table>
<p>The input format is described in <code><a href="#topic+ghap.haplotyping">ghap.haplotyping</a></code>.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# # Generate blocks of 5 markers sliding 5 markers at a time
# blocks &lt;- ghap.blockgen(phase, windowsize = 5,
#                         slide = 5, unit = "marker")
# 
# # Haplotyping
# ghap.haplotyping(phase = phase, blocks = blocks, outfile = "example",
#                  binary = T, ncores = 1)
# 
# ### RUN ###
# 
# # Load haplotype genotypes using prefix
# haplo &lt;- ghap.loadhaplo("example")
# 
# # Load haplotype genotypes using file names
# haplo &lt;- ghap.loadhaplo(hapsamples.file = "example.hapsamples",
#                         hapalleles.file = "example.hapalleles",
#                         hapgenotypesb.file = "example.hapgenotypesb")

</code></pre>

<hr>
<h2 id='ghap.loadphase'>
Load binary phased genotype data
</h2><span id='topic+ghap.loadphase'></span>

<h3>Description</h3>

<p>This function loads binary phased genotype data and converts them into a native GHap.phase object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.loadphase(input.file = NULL,
                 samples.file = NULL,
                 markers.file = NULL,
                 phaseb.file = NULL,
                 ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>If all input files share the same prefix, the user can use the following shortcut option:
</p>
<table>
<tr><td><code id="ghap.loadphase_+3A_input.file">input.file</code></td>
<td>

<p>Prefix for input files.
</p>
</td></tr>
</table>
<p>For backward compatibility, the user can still point to input files separately:
</p>
<table>
<tr><td><code id="ghap.loadphase_+3A_samples.file">samples.file</code></td>
<td>

<p>Individual information.
</p>
</td></tr>
<tr><td><code id="ghap.loadphase_+3A_markers.file">markers.file</code></td>
<td>

<p>Variant map information.
</p>
</td></tr>
<tr><td><code id="ghap.loadphase_+3A_phaseb.file">phaseb.file</code></td>
<td>

<p>Binary phased genotype matrix, such as supplied by the <code><a href="#topic+ghap.compress">ghap.compress</a></code> function.
</p>
</td></tr>
</table>
<p>To turn loading progress-tracking on or off, or use multiple cores, please use:
</p>
<table>
<tr><td><code id="ghap.loadphase_+3A_ncores">ncores</code></td>
<td>

<p>A numerical value specfying the number of cores to use while loading the input files (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.loadphase_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned GHap.phase object is a list with components:
</p>
<table>
<tr><td><code>nsamples</code></td>
<td>

<p>An integer value for the sample size.
</p>
</td></tr>
<tr><td><code>nmarkers</code></td>
<td>

<p>An integer value for the number of markers.
</p>
</td></tr>
<tr><td><code>nsamples.in</code></td>
<td>

<p>An integer value for the number of active samples.
</p>
</td></tr>
<tr><td><code>nmarkers.in</code></td>
<td>

<p>An integer value for the number of active markers.
</p>
</td></tr>
<tr><td><code>pop</code></td>
<td>

<p>A character vector relating chromosome alleles to populations. This information is obtained from the first column of the sample file.
</p>
</td></tr>
<tr><td><code>id</code></td>
<td>

<p>A character vector mapping chromosome alleles to samples. This information is obtained from the second column of the sample file.
</p>
</td></tr>
<tr><td><code>id.in</code></td>
<td>

<p>A logical vector indicating active chromosome alleles. By default, all chromosomes are set to TRUE.
</p>
</td></tr>
<tr><td><code>sire</code></td>
<td>

<p>A character vector indicating sire names, as provided in the third column of the sample file (optional).
</p>
</td></tr>
<tr><td><code>dam</code></td>
<td>

<p>A character vector indicating dam names, as provided in the fourth column of the sample file (optional).
</p>
</td></tr>
<tr><td><code>sex</code></td>
<td>

<p>A character vector indicating individual sex, as provided in the fifth column of the sample file (optional). Codes are converted as follows: 0 = NA, 1 = Male and 2 = Female.
</p>
</td></tr>
<tr><td><code>chr</code></td>
<td>

<p>A character vector indicating chromosome identity for each marker.
</p>
</td></tr>
<tr><td><code>marker</code></td>
<td>

<p>A character vector containing marker names. This information is obtained from the second column of the marker map file.
</p>
</td></tr>
<tr><td><code>marker.in</code></td>
<td>

<p>A logical vector indicating active markers. By default, all markers are set to TRUE.
</p>
</td></tr>
<tr><td><code>cm</code></td>
<td>

<p>A numeric vector with genetic positions for markers. This information is obtained from the third column of the marker map file if it contains 6 columns. Otherwise, if the map file contains only 5 columns, genetic positions are considered absent and approximated from physical positions (in this case assumed to be the third column) as 1 Mb ~ 1 cM.
</p>
</td></tr>
<tr><td><code>bp</code></td>
<td>

<p>A numeric vector with marker positions. This information is obtained from the third column of the marker map file if it contains 5 columns, or from the fourth column if it contains 6 columns.
</p>
</td></tr>
<tr><td><code>A0</code></td>
<td>

<p>A character vector with reference alleles. This information is obtained from the fourth column of the marker map file in case it contains 5 columns, or from the fifth column if it contains 6 columns.
</p>
</td></tr>
<tr><td><code>A1</code></td>
<td>

<p>A character vector with alternative alleles. This information is obtained from the last column of the marker map file.
</p>
</td></tr>
<tr><td><code>phase</code></td>
<td>

<p>A character value giving the pathway to the binary phased genotype matrix.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Load data using prefix
# phase &lt;- ghap.loadphase(input.file = "example")
# 
# # Load data using file names
# phase &lt;- ghap.loadphase(samples.file = "example.samples",
#                         markers.file = "example.markers",
#                         phaseb.file = "example.phaseb")

</code></pre>

<hr>
<h2 id='ghap.loadplink'>
Load binary PLINK data
</h2><span id='topic+ghap.loadplink'></span>

<h3>Description</h3>

<p>This function loads binary PLINK files (bed/bim/fam) and converts them into a native GHap.plink object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.loadplink(input.file = NULL, bed.file = NULL,
                 bim.file = NULL, fam.file = NULL,
                 ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>If all input files share the same prefix, the user can use the following shortcut option:
</p>
<table>
<tr><td><code id="ghap.loadplink_+3A_input.file">input.file</code></td>
<td>

<p>Prefix for input files.
</p>
</td></tr>
</table>
<p>For backward compatibility, the user can still point to input files separately:
</p>
<table>
<tr><td><code id="ghap.loadplink_+3A_bed.file">bed.file</code></td>
<td>

<p>The binary genotype matrix (in SNP-major format).
</p>
</td></tr>
<tr><td><code id="ghap.loadplink_+3A_bim.file">bim.file</code></td>
<td>

<p>Variant map file.
</p>
</td></tr>
<tr><td><code id="ghap.loadplink_+3A_fam.file">fam.file</code></td>
<td>

<p>Pedigree (family) file.
</p>
</td></tr>
</table>
<p>To turn loading progress-tracking on or off, or engage multiple cores, please use:
</p>
<table>
<tr><td><code id="ghap.loadplink_+3A_ncores">ncores</code></td>
<td>

<p>A numerical value specfying the number of cores to use while loading the input files (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.loadplink_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned GHap.plink object is a list with components:
</p>
<table>
<tr><td><code>nsamples</code></td>
<td>

<p>An integer value for the sample size.
</p>
</td></tr>
<tr><td><code>nmarkers</code></td>
<td>

<p>An integer value for the number of markers.
</p>
</td></tr>
<tr><td><code>nsamples.in</code></td>
<td>

<p>An integer value for the number of active samples.
</p>
</td></tr>
<tr><td><code>nmarkers.in</code></td>
<td>

<p>An integer value for the number of active markers.
</p>
</td></tr>
<tr><td><code>pop</code></td>
<td>

<p>A character vector relating genotypes to populations. This information is obtained from the FID (1st) column in the fam file.
</p>
</td></tr>
<tr><td><code>id</code></td>
<td>

<p>A character vector mapping genotypes to samples. This information is obtained from the IID (2nd) column in the fam file.
</p>
</td></tr>
<tr><td><code>id.in</code></td>
<td>

<p>A logical vector indicating active chromosome alleles. By default, all chromosomes are set to TRUE.
</p>
</td></tr>
<tr><td><code>sire</code></td>
<td>

<p>A character vector indicating sire names, as provided in the SID (3rd) column of the fam file.
</p>
</td></tr>
<tr><td><code>dam</code></td>
<td>

<p>A character vector indicating dam names, as provided in the DID (4th) column of the fam file.
</p>
</td></tr>
<tr><td><code>sex</code></td>
<td>

<p>A character vector indicating individual sex, as provided in the SEX (5th) column of the fam file. Codes are converted as follows: 0 = NA, 1 = Male and 2 = Female.
</p>
</td></tr>
<tr><td><code>chr</code></td>
<td>

<p>A character vector indicating chromosome identity for each marker.
</p>
</td></tr>
<tr><td><code>marker</code></td>
<td>

<p>A character vector containing marker names.
</p>
</td></tr>
<tr><td><code>marker.in</code></td>
<td>

<p>A logical vector indicating active markers. By default, all markers are set to TRUE.
</p>
</td></tr>
<tr><td><code>cm</code></td>
<td>

<p>A numeric vector with genetic positions for markers. This information is obtained from the third column of the bim file. If genetic positions are absent (coded as &quot;0&quot;), they are approximated from physical positions assuming 1 Mb ~ 1 cM.
</p>
</td></tr>
<tr><td><code>bp</code></td>
<td>

<p>A numeric vector with physical positions for markers.
</p>
</td></tr>
<tr><td><code>A0</code></td>
<td>

<p>A character vector with reference alleles. For convenience, this information is obtained from the 6th column of the bim file. If &quot;&ndash;keep-allele-order&quot; is not used while generating the PLINK binary file, A0 will correspond to the major allele.
</p>
</td></tr>
<tr><td><code>A1</code></td>
<td>

<p>A character vector with alternative alleles. As for A0, if &quot;&ndash;keep-allele-order&quot; is not used A1 will correspond to the minor allele.
</p>
</td></tr>
<tr><td><code>plink</code></td>
<td>

<p>A character value giving the pathway to the binary genotype matrix.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Load data using prefix
# plink &lt;- ghap.loadplink("example")
# 
# # Load data using file names
# plink &lt;- ghap.loadplink(bed.file = "example.bed",
#                         bim.file = "example.bim",
#                         fam.file = "example.fam")


</code></pre>

<hr>
<h2 id='ghap.makefile'>
Create example input files
</h2><span id='topic+ghap.makefile'></span>

<h3>Description</h3>

<p>Create example files to test the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.makefile(dataset = "example",
               format = "phase",
               verbose = TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.makefile_+3A_dataset">dataset</code></td>
<td>

<p>A character value specfying the name of the dataset.
</p>
</td></tr>
<tr><td><code id="ghap.makefile_+3A_format">format</code></td>
<td>

<p>A character value specfying the format of the dataset.
</p>
</td></tr>
<tr><td><code id="ghap.makefile_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function downloads example files to the R temporary directory (requires internet connection). The default dataset comprises the following group of files:
</p>
<p><em>example.phaseb</em> <br />
<em>example.markers</em> <br />
<em>example.samples</em> <br />
</p>
<p>For details about the format of these files, see <code><a href="#topic+ghap.compress">ghap.compress</a></code>. The dataset was simulated using the QMSim v1.10 software and contains 450 individuals genotyped for 15,000 markers. These markers were randomly distributed along 10 chromosomes of 100 Mbp each (i.e., 1,500 markers per chromosome). Two divergent lineages were created, namely 'Pure1' (n = 300) and 'Pure2' (n = 100), and gene flow between these two lineages was allowed to produce low levels of admixture. An additional set of 50 crossbred individuals was also included. The same dataset is available in the following formats: raw (equal to the phase format, except that the genotype matrix is not compressed), vcf and oxford. By using format = 'meta', metadata including pedigree and phenotypes for the 'Pure1' population can be downloaded. The pedigree contains 700 records, spanning 5 generations. The records in the phenotypes file are unbalanced repeated measurements (1 to 5 records per individual, with an average of 3) of a trait with heritability of 0.4, repeatability of 0.2, and a major QTL located on chromosome 3.
</p>
<p>Since version 2.1.0, GHap maintains additional example files in its github repository (<a href="https://github.com/ytutsunomiya/GHap">https://github.com/ytutsunomiya/GHap</a>). In order to see which files are available, please see <code><a href="#topic+ghap.exfiles">ghap.exfiles</a></code>.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt; <br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>References</h3>

<p>M. Sargolzaei and F. S. Schenkel. QMSim: A large-scale genome simulator for livestock. Bioinformatics. 2009. 25, 680–681.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># # See list of example files
# exlist &lt;- ghap.exfiles()
# View(exlist)
# 
# # Copy example data in phase format
# exfiles &lt;- ghap.makefile()
# file.copy(from = exfiles, to = "./")
# 
# # Copy example data in plink format
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink", verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy phenotypes and pedigree data
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta", verbose = TRUE)
# file.copy(from = exfiles, to = "./")
</code></pre>

<hr>
<h2 id='ghap.manhattan'>
Manhattan plot
</h2><span id='topic+ghap.manhattan'></span>

<h3>Description</h3>

<p>Generate a Manhattan plot from a dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.manhattan(data, chr, bp, y, colors = NULL, type = "p", pch = 20,
                cex = 1, lwd = 1, ylim = NULL, ylab = "", xlab = "", main = "",
                backcolor = "#F5EFE780", chr.ang = 0, hlines = NULL,
                hcolors = NULL, hlty = 1, hlwd = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.manhattan_+3A_data">data</code></td>
<td>

<p>A data.frame containing the data to be plotted.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_chr">chr</code></td>
<td>

<p>A character value with the name of the column containing chromosome labels.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_bp">bp</code></td>
<td>

<p>A character value with the name of the column containing base pair positions.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_y">y</code></td>
<td>

<p>A character value with the name of the column containing the variable to be plotted in the y axis.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_colors">colors</code></td>
<td>

<p>A character value containing colors to be used for chromosomes.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_type">type</code></td>
<td>

<p>What type of plot should be drawn (default = &quot;p&quot;). See <code><a href="graphics.html#topic+plot">plot</a></code>.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_pch">pch</code></td>
<td>

<p>Either an integer specifying a symbol or a single character to be used as the default in plotting points (default = 20). See <code><a href="graphics.html#topic+points">points</a></code> for possible values and their interpretation. 
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_cex">cex</code></td>
<td>

<p>A numeric value for the relative point size (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_lwd">lwd</code></td>
<td>

<p>A numeric value for the line width (default = 1). Only meaningful for type = &quot;l&quot;.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_ylim">ylim</code></td>
<td>

<p>A numeric vector of size 2 containing the lower and upper limits of the y-axis.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_ylab">ylab</code></td>
<td>

<p>A chracter value for the y-axis label.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_xlab">xlab</code></td>
<td>

<p>A chracter value for the x-axis label.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_main">main</code></td>
<td>

<p>A chracter value for the plot title.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_backcolor">backcolor</code></td>
<td>

<p>The background color.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_chr.ang">chr.ang</code></td>
<td>

<p>A numeric value representing the rotation of chromosome labels in degrees (default = 0).
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_hlines">hlines</code></td>
<td>

<p>A numeric vector containing y-axis positions for horizontal lines.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_hcolors">hcolors</code></td>
<td>

<p>A character vector containing colors for the horizontal lines.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_hlty">hlty</code></td>
<td>

<p>A numeric vector containing types for horizontal lines.
</p>
</td></tr>
<tr><td><code id="ghap.manhattan_+3A_hlwd">hlwd</code></td>
<td>

<p>A numeric vector for the relative width of vertical lines.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a dataframe of genomic positions and generates a Manhattan plot. The chromosome column must be a vector of factors (the order of the chromosomes will be displayed according to the order of the factor levels).
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ### RUN ###
# 
# # Generate some data
# set.seed(1988)
# genome &lt;- c(1:22,"X")
# chr &lt;- rep(genome, each = 1000)
# bp &lt;- rep(1:1000, times = length(genome))
# y &lt;- abs(rnorm(n = length(bp)))
# y &lt;- 1 - (pnorm(y) - pnorm(-y))
# y &lt;- -log10(y)
# y[10300:10350] &lt;- sort(runif(n = 51, min = 0, max = 10))
# mydata &lt;- data.frame(chr,bp,y)
# mydata$chr &lt;- factor(x = mydata$chr, levels = genome, labels = genome)
# 
# # Minimal plot
# ghap.manhattan(data = mydata, chr = "chr", bp = "bp", y = "y")
# 
# # Customization example
# ghap.manhattan(data = mydata, chr = "chr", bp = "bp", y = "y",
#                main = "Genome-wide association analysis", ylab = "-log10(p)",
#                xlab = "Chromosome", chr.ang = 90, backcolor = "white", type = "l",
#                hlines = c(6,8), hlty = c(2,3), hcolors = c(1,2), hlwd = c(1,2))

</code></pre>

<hr>
<h2 id='ghap.oxford2phase'>
Convert Oxford data into GHap phase
</h2><span id='topic+ghap.oxford2phase'></span>

<h3>Description</h3>

<p>This function takes phased genotype data in Oxford HAPS/SAMPLES format and converts them into the GHap phase format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.oxford2phase(input.files = NULL, haps.files = NULL,
                    sample.files = NULL, out.file,
                    ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>If all input files share the same prefix, the user can use the following shortcut options:
</p>
<table>
<tr><td><code id="ghap.oxford2phase_+3A_input.files">input.files</code></td>
<td>

<p>Character vector with the list of prefixes for input files.
</p>
</td></tr>
<tr><td><code id="ghap.oxford2phase_+3A_out.file">out.file</code></td>
<td>

<p>Character value for the output file name.
</p>
</td></tr>
</table>
<p>The user can also opt to point to input files separately:
</p>
<table>
<tr><td><code id="ghap.oxford2phase_+3A_haps.files">haps.files</code></td>
<td>

<p>Character vector containing the list of Oxford HAPS files.
</p>
</td></tr>
<tr><td><code id="ghap.oxford2phase_+3A_sample.files">sample.files</code></td>
<td>

<p>Character vector containing the list of Oxford SAMPLES files.
</p>
</td></tr>
</table>
<p>To turn conversion progress-tracking on or off or use multiple cores please use:
</p>
<table>
<tr><td><code id="ghap.oxford2phase_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specfying the number of cores to use (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.oxford2phase_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Oxford HAPS/SAMPLE format output of widely used phasing software such as SHAPEIT2 (O'Connell et al., 2014) or Eagle (Loh et al., 2106) is here manipulated to obtain the GHap phase format.
</p>


<h3>Author(s)</h3>

<p>Mario Barbato &lt;mario.barbato@unicatt.it&gt;, Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>R-R. Loh P-R et al. Reference-based phasing using the Haplotype Reference Consortium panel. Nat Genet. 2016. 48(11):1443-1448.
J. O'Connell et al. A general approach for haplotype phasing across the full spectrum of relatedness. PLOS Genet. 2014. 10:e1004234.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.compress">ghap.compress</a></code>, <code><a href="#topic+ghap.loadphase">ghap.loadphase</a></code>, <code><a href="#topic+ghap.fast2phase">ghap.fast2phase</a></code>, <code><a href="#topic+ghap.vcf2phase">ghap.vcf2phase</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "oxford",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Convert from a single genome-wide file
# ghap.oxford2phase(input.files = "example",
#                   out.file = "example")
# 
# # Convert from a list of chromosome files
# ghap.oxford2phase(input.files = paste0("example_chr",1:10),
#                   out.file = "example")
# 
# # Convert using separate lists for file extensions
# ghap.oxford2phase(haps.files = paste0("example_chr",1:10,".haps"),
#                   sample.files = paste0("example_chr",1:10,".sample"),
#                   out.file = "example")
# 
# # A more efficient alternative for *nix system users
# # Note: replace "cat" by "zcat" if files are gzipped
# haps.files = paste("example_chr",1:10,".haps",sep="")
# command &lt;- "tail -n+3 example_chr1.sample | cut -d' ' -f1,2 &gt; example.samples"
# system(command)
# for(i in 1:10){
#   command &lt;- paste("cat",haps.files[i],"| cut -d' ' -f1-5 &gt;&gt; example.markers")
#   system(command)
#   command &lt;- paste("cat",haps.files[i],"| cut -d' ' -f1-5 --complement &gt;&gt; example.phase")
#   system(command)
# }

</code></pre>

<hr>
<h2 id='ghap.pedcheck'>
Summary statistics for pedigree
</h2><span id='topic+ghap.pedcheck'></span>

<h3>Description</h3>

<p>This function summarizes pedigree data and calculates inbreeding coefficients and equivalent complete generations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.pedcheck(ped, depth.n.f = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.pedcheck_+3A_ped">ped</code></td>
<td>

<p>A dataframe with columns &quot;id&quot;, &quot;sire&quot; and &quot;dam&quot; containing pedigree data.
</p>
</td></tr>
<tr><td><code id="ghap.pedcheck_+3A_depth.n.f">depth.n.f</code></td>
<td>

<p>A logical indicating if equivalent complete generations (depth) and inbreeding coefficients (f) should be calculated.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing two data frames: stats, which includes the pedigree summary; and ped, consisting of the original pedigree. If depth.n.f = TRUE, three columns are added to the ped data frame: gen (generation number), f (inbreding coefficient) and ecg (equivalent complete generations). The generation number and the inbreeding coefficient are computed with the help of the pedigreemm package.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>A. I. Vazquez. Technical note: An R package for fitting generalized linear mixed models in animal breeding. J. Anim. Sci. 2010. 88, 497-504.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load pedigree data
# ped &lt;- read.table(file = "example.pedigree", header=T)
# 
# ### RUN ###
# 
# # Descriptive statistics for the pedigree
# pedstat &lt;- ghap.pedcheck(ped[,-1])
# print(pedstat$stats)
# 
# # Retrieve inbreeding and pedigree depth
# pedstat &lt;- ghap.pedcheck(ped[,-1], depth.n.f = TRUE)
# print(pedstat$ped)
# hist(pedstat$ped$f)
# hist(pedstat$ped$ecg)

</code></pre>

<hr>
<h2 id='ghap.phase2plink'>
Export phase object to PLINK binary
</h2><span id='topic+ghap.phase2plink'></span>

<h3>Description</h3>

<p>This function takes a phase object and converts it to the PLINK binary (bed/bim/fam) format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.phase2plink(object, out.file,
                 only.active.samples=TRUE,
                 only.active.markers=TRUE,
                 batchsize=NULL, ncores=1,
                 verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.phase2plink_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.phase2plink_+3A_out.file">out.file</code></td>
<td>

<p>A character value specifying the name used for the .bed, .bim and .fam output files.
</p>
</td></tr>
<tr><td><code id="ghap.phase2plink_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.phase2plink_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.phase2plink_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of markers to be processed and written to output at a time (default = nmarkers/10).
</p>
</td></tr>
<tr><td><code id="ghap.phase2plink_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.phase2plink_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned output is a standard set of PLINK (Purcell et al., 2007; Chang et al., 2015) binary file (bed/bim/fam), meaning that phase information will be lost during conversion.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>C. C. Chang et al. Second-generation PLINK: rising to the challenge of larger and richer datasets. Gigascience. 2015. 4, 7.
</p>
<p>S. Purcell et al. PLINK: a tool set for whole-genome association and population-based linkage analyses. Am. J. Hum. Genet. 2007. 81, 559-575.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Convert to plink
# ghap.phase2plink(object = phase, out.file = "example")

</code></pre>

<hr>
<h2 id='ghap.predictblup'>
Predict BLUP from reference
</h2><span id='topic+ghap.predictblup'></span>

<h3>Description</h3>

<p>Prediction of BLUP values in test individuals based on reference individuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.predictblup(refblup, vcp, covmat,
                   errormat = NULL,
                   errorname = "",
                   include.ref = TRUE,
                   diagonals = FALSE,
                   tol = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.predictblup_+3A_refblup">refblup</code></td>
<td>

<p>A named numeric vector of reference BLUP values.
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_vcp">vcp</code></td>
<td>

<p>A numeric value for the variance in BLUP values.
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_covmat">covmat</code></td>
<td>

<p>A square matrix containing correlations among individuals. Both test and reference indiviudals must be present in the matrix.
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_errormat">errormat</code></td>
<td>

<p>A square error matrix for reference individuals. This matrix can be obtained with argument extras = &quot;LHSi&quot; in the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_errorname">errorname</code></td>
<td>

<p>The name used for the random effect in the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function. If the error matrix was imported from somewhere else, this argument can be ignored provided that the names in the error matrix match the ones in the covariance matrix.
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_include.ref">include.ref</code></td>
<td>

<p>A logical value indicating if reference individuals should be included in the output (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_diagonals">diagonals</code></td>
<td>

<p>A logical value indicating if diagonals of the covariance matrix should be used in calculations of accuracy and standard errors (default = FALSE). The default is to set diagonals to 1. For genomic estimated breeding values, using TRUE will account for inbreeding in the computation of accuracies and standard errors.
</p>
</td></tr>
<tr><td><code id="ghap.predictblup_+3A_tol">tol</code></td>
<td>

<p>A numeric value specifying the scalar to add to the diagonal of the covariance matrix if it is not inversible (default = 1e-12).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with predictions of BLUP values. If an error matrix is provided, standard errors and accuracies are also included.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>J.F. Taylor. Implementation and accuracy of genomic selection. Aquaculture 2014. 420, S8-S14.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype and pedigree data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Fit mixed model
# df$rep &lt;- df$id
# model &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                   data = df,
#                   covmat = list(id = K, rep = NULL),
#                   extras = "LHSi")
# refblup &lt;- model$random$id$Estimate
# names(refblup) &lt;- rownames(model$random$id)
# 
# # Predict blup of reference and test individuals
# blup &lt;- ghap.predictblup(refblup, vcp = model$vcp$Estimate[1],
#                          covmat = as.matrix(K),
#                          errormat = model$extras$LHSi,
#                          errorname = "id")
# 
# # Compare predictions
# plot(blup$Estimate, model$random$id$Estimate)
# abline(0,1)
</code></pre>

<hr>
<h2 id='ghap.profile'>
Genomic profile
</h2><span id='topic+ghap.profile'></span>

<h3>Description</h3>

<p>Given a data.frame of user-defined marker or haplotype allele scores, compute individual genomic profiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.profile(object, score, only.active.samples = TRUE,
             batchsize = NULL, ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.profile_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.profile_+3A_score">score</code></td>
<td>

<p>For HapAlleles (to use with GHap.haplo objects), the columns should be: BLOCK, CHR, BP1, BP2, ALLELE, SCORE, CENTER and SCALE. In the case of markers, the columns are: MARKER, CHR, BP, ALLELE, SCORE, CENTER and SCALE.
</p>
</td></tr>
<tr><td><code id="ghap.profile_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether calculations should be reported only for active samples (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.profile_+3A_batchsize">batchsize</code></td>
<td>

<p>A numeric value controlling the number of HapAlleles or markers to be processed at a time (default = n/10).
</p>
</td></tr>
<tr><td><code id="ghap.profile_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.profile_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The profile for each individual is calculated as sum(b*(x-c)/s), where x is a vector of number of copies of a reference allele, c is a constant to center the genotypes (taken from the CENTER column of the score dataframe), s is a constant to scale the genotypes (taken from the SCALE column of the score dataframe), and b is a vector of user-defined scores for each reference allele (taken from the SCORE column of the score dataframe). If no centering or scaling is required, the user can set the CENTER and SCALE columns to 0 and 1, respectively. By default, if scores are provided for only a subset of the HapAlleles or markers, the absent scores will be set to zero. If the input genomic data is a GHap.phase or GHap.plink object, the ALLELE column in the data frame is used as a guide to keep track of the direction of the scores. The default coding in GHap is A0/A0 = 0, A0|A1 = A1|A0 = 1 and A1/A1 = 2. For each marker where the declared allele is A0 instead of A1, that coding is flipped to A0/A0 = 2, A0|A1 = A1|A0 = 1 and A1/A1 = 1 so the profile is computed in the correct direction. Therefore, the user must be careful regarding the allele order, as well as the centering and scaling for each marker, since profiling is allele-oriented. This function has the same spirit as the profiling routine implemented in the <em>score</em> option in PLINK (Purcell et al., 2007; Chang et al., 2015).
</p>


<h3>Value</h3>

<p>The function returns a data.frame with the following columns:
</p>
<table>
<tr><td><code>POP</code></td>
<td>

<p>Population ID.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>PROFILE</code></td>
<td>

<p>Individual profile.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;<br />
Marco Milanesi &lt;marco.milanesi.mm@gmail.com&gt;
</p>


<h3>References</h3>

<p>C. C. Chang et al. Second-generation PLINK: rising to the challenge of larger and richer datasets. Gigascience. 2015. 4, 7.
</p>
<p>S. Purcell et al. PLINK: a tool set for whole-genome association and population-based linkage analyses. Am. J. Hum. Genet. 2007. 81, 559-575.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype and pedigree data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Fit mixed model
# df$rep &lt;- df$id
# model &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                   data = df,
#                   covmat = list(id = K, rep = NULL))
# refblup &lt;- model$random$id$Estimate
# names(refblup) &lt;- rownames(model$random$id)
# 
# # Convert blup of individuals into blup of variants
# mkrblup &lt;- ghap.varblup(object = plink,
#                         gebv = refblup,
#                         covmat = K)
# 
# # Build GEBVs from variant effects and compare predictions
# gebv &lt;- ghap.profile(object = plink, score = mkrblup)
# plot(gebv$SCORE, refblup); abline(0,1)

</code></pre>

<hr>
<h2 id='ghap.relfind'>
Find relatives in IBD estimates
</h2><span id='topic+ghap.relfind'></span>

<h3>Description</h3>

<p>This function infers relationships from IBD sharing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.relfind(ibdpairs, v = 50,
             breakclass = FALSE, ncores=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.relfind_+3A_ibdpairs">ibdpairs</code></td>
<td>

<p>A dataframe containing IBD estimates, such as those provided by the output of &ndash;genome in plink.
</p>
</td></tr>
<tr><td><code id="ghap.relfind_+3A_v">v</code></td>
<td>

<p>A hyperparameter controling the variance of the likelihood functions (smaller values lead to more variance).
</p>
</td></tr>
<tr><td><code id="ghap.relfind_+3A_breakclass">breakclass</code></td>
<td>

<p>A logical value indicating if relationship types 2 and 3 should be reported using their subclasses (default = FALSE).
</p>
</td></tr>
<tr><td><code id="ghap.relfind_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input dataframe must contain columns POP1 (or FID1), ID1 (or IID1), POP2 (or FID2), ID2 (or IID2), Z0, Z1, Z2 and PI_HAT. Columns Z0, Z1 and Z2 are the IBD sharing estimates representing the proportions of the genome where the two individuals being compared share exactly 0, 1 and 2 alleles identically by descent, respectively. The last column is Z2 + Z1/2, namely the proportion of the genome shared identically by descent.
</p>
<p>This function implements a method based on composite likelihood scores to infer relationships based on the values of Z0, Z1, Z2 and PI_HAT. The predicted values are:
</p>
<p>-1 = duplicates or monozygotic twins <br />
0 = parent-offspring with inbreeding or self-fertilization <br />
1 = parent-offspring <br />
2 = full-siblings <br />
3 = other types of relationships <br />
4 = unrelated <br />
</p>
<p>Briefly, for each relationship type, the likelihood of each of the four IBD values is computed from a beta distribution with parameters a = m*v and b = (1-m)*v, where m is the expected value according to the relationship type and v is a hyperparameter controling the variance around the expected value (default v = 50). The composite likelihood is computed by summing the log-likelihoods for the four IBD values. The prediction is made by adopting the relationship type with the highest composite likelihood score. Details of the expected values of each relationship type is found in our vignette. This classification strategy is inspired by the method reported by Staples et al. (2014), albeit it is a different method. While Staples and collaborators infer relationships through Gaussian Kernel Density Estimation using only Z0 and Z1 values, our strategy uses the composite score formed by the sum of beta log-likelihoods for all IBD values.
</p>
<p>An important detail is that relationship types 2 and 3 are in fact modelled through two and four different composite likelihoods, respectively, which are combined in order to achieve more robust and stable predictions. The user can choose to break down the subclasses via the argument 'breakclass = TRUE'. Reporting the subclasses is not default due to the reduced accuracy in distinguishing them. In addition, other relationship types not implicitly modelled in this version of the package may be confused with one of those subclasses. However, breaking these subclasses down may be useful for users seeking specific relationships in the data, as well as for those willing to perform pedigree simulations. The additional subclasses are:
</p>
<p>2.1 = full-siblings<br />
2.2 = full-siblings from a self-fertilized parent (or related parents)<br />
3.1 = half-siblings, grandparent-grandchild or avuncular with inbreeding <br />
3.2 = half-siblings, grandparent-grandchild or avuncular <br />
3.3 = first-cousin or half-avuncular <br />
3.4 = half-cousin and distant relatives <br />
</p>
<p>If the user chooses to run the analysis with 'breakclass = TRUE', beware that other types of cryptic relationships will be misclassified as pertaining to one of those four subclasses.
</p>


<h3>Value</h3>

<p>The function returns the original dataframe with the extra column 'REL', containing the relationship predictions.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>C. C. Chang et al. Second-generation PLINK: rising to the challenge of larger and richer datasets. Gigascience. 2015. 4, 7.
</p>
<p>J. Staples et al. PRIMUS: Rapid Reconstruction of Pedigrees from Genome-wide Estimates of Identity by Descent. 2014. 95, 553-564.
</p>
<p>S. Purcell et al. PLINK: a tool set for whole-genome association and population-based linkage analyses. Am. J. Hum. Genet. 2007. 81, 559-575.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load pedigree data
# ped &lt;- read.table(file = "example.pedigree", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute A1 allele frequencies
# p &lt;- ghap.freq(plink, type = "A1")
# 
# # Compute IBD statistics for individual 1
# pairlist &lt;- data.frame(ID1 = pure1[1], ID2 = pure1[-1])
# ibd &lt;- ghap.ibd(object = plink, pairlist = pairlist, freq = p,
#                 refsize = length(pure1))
# 
# # Predict relationships for individual 1
# # 1 = parent-offspring
# # 3 = other types of relationship
# # 4 = unrelated
# rel &lt;- ghap.relfind(ibdpairs = ibd)
# table(rel$REL)
# 
# # Confirm with pedigree
# toprel &lt;- rel$ID2[which(rel$REL == 1)]
# ped[which(ped$id %in% toprel &amp; ped$dam == pure1[1]),]

</code></pre>

<hr>
<h2 id='ghap.remlci'>
Confidence intervals for functions of variance components
</h2><span id='topic+ghap.remlci'></span>

<h3>Description</h3>

<p>Approximation of standard errors and confidence intervals of arbitrary functions of variance components using a sampling-based method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.remlci(fun, vcp, ai, n = 10000,
            conf.level = 0.95,
            include.samples = FALSE,
            ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.remlci_+3A_fun">fun</code></td>
<td>

<p>Function of variance components. See details.
</p>
</td></tr>
<tr><td><code id="ghap.remlci_+3A_vcp">vcp</code></td>
<td>

<p>A matrix or dataframe containing variance components, such as supplied by the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.remlci_+3A_ai">ai</code></td>
<td>

<p>The inverse of the average information matrix, such as supplied by the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function.
</p>
</td></tr>
<tr><td><code id="ghap.remlci_+3A_conf.level">conf.level</code></td>
<td>

<p>A numeric value informing the confidence level (default = 0.95).
</p>
</td></tr>
<tr><td><code id="ghap.remlci_+3A_include.samples">include.samples</code></td>
<td>

<p>A logical value indicating if samples of the likelihood function should be kept.
</p>
</td></tr>
<tr><td><code id="ghap.remlci_+3A_n">n</code></td>
<td>

<p>A numerical value giving the number of samples to draw from the likelihood function (default = 10000).
</p>
</td></tr>
<tr><td><code id="ghap.remlci_+3A_ncores">ncores</code></td>
<td>

<p>A numerical value specifying the number of cores to use in parallel computations (default = 1).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements the method of Meyer &amp; Houle (2013) to approximate standard errors and confidence intervals of arbitrary functions of variance components. The method consists in assuming that REML estimates of variance components asymptotically follow a multivariate normal distribution with mean equals to the REML estimates themselves and covariance matrix equals the inverse of the average information matrix. Following that assumption, samples are drawn from that distribution and the user-defined function is applied to the samples. Standard errors are obtained as the standard deviation of the resulting vector, and confidence intervals are derived from vector quantiles.
</p>
<p>The user must provide a function of variance components to the fun argument. The function has to be set assuming that the components are stored in a vector named x. For example, if variance components come from an animal model and the user wishes to obtain standard errors and confidence intervals for the heritability, simply use fun = function(x){x[1]/sum(x)}.
</p>


<h3>Value</h3>

<p>The returned object is a list with the following items:
</p>
<table>
<tr><td><code>stde</code></td>
<td>

<p>The standard error estimate.
</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>

<p>The lower and upper limits of the confidence interval.
</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>

<p>A vector containing the samples from the multivariate normal distribution. Only present in the output if the argument include.samples is set to TRUE.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>K. Meyer, D. Houle. Sampling based approximation of confidence intervals for functions of genetic covariance matrices. Proc. Assoc. Adv. Anim. Breed. 2013. 20, 523–527
</p>
<p>J. Jensen et al. Residual maximum likelihood estimation of (Co)variance components in multivariate mixed linear models using average information. J. Ind. Soc. Ag. Statistics 1997. 49, 215-236.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype and pedigree data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Fit mixed model
# df$rep &lt;- df$id
# model &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                   data = df,
#                   covmat = list(id = K, rep = NULL))
# 
# # Compute confidence interval for heritability
# h2 &lt;- model$vcp$Estimate[1]/sum(model$vcp$Estimate)
# h2ci &lt;- ghap.remlci(fun = function(x){x[1]/sum(x)},
#                     vcp = model$vcp, ai = model$AI)
# print(h2)
# print(h2ci)

</code></pre>

<hr>
<h2 id='ghap.roh'>
Detection of runs of homozygosity (ROH)
</h2><span id='topic+ghap.roh'></span>

<h3>Description</h3>

<p>Map haplotype segments that are likely identical-by-descent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ghap.roh(object, minroh = 1e+6, method = "hmm", freq = NULL,
          genpos = NULL, inbcoef = NULL, error = 0.25/100,
          only.active.samples = TRUE, only.active.markers = TRUE,
          ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>The following arguments are used by both the 'hmm' and 'naive' methods:
</p>
<table>
<tr><td><code id="ghap.roh_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase or plink).
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_minroh">minroh</code></td>
<td>

<p>Minimum ROH length to output.
</p>
</td></tr> 
<tr><td><code id="ghap.roh_+3A_method">method</code></td>
<td>

<p>Character value indicating which method to use: 'naive' or 'hmm' (default).
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be included in the search (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used in the search (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>
<p>The following arguments are only used by the 'hmm' method:
</p>
<table>
<tr><td><code id="ghap.roh_+3A_freq">freq</code></td>
<td>

<p>Named numeric vector of allele frequencies, such as provided by function <code><a href="#topic+ghap.freq">ghap.freq</a></code>.
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_genpos">genpos</code></td>
<td>

<p>Named numeric vector of genetic positions. If not supplied, 1 cM = 1 Mb is assumed and genetic distances between consecutive markers are set to d/1e+6, where d is the distance in base pairs.
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_inbcoef">inbcoef</code></td>
<td>

<p>Named numeric vector of starting values for genomic inbreeding (i.e., guess for the proportion of the genome covered by ROH).
</p>
</td></tr>
<tr><td><code id="ghap.roh_+3A_error">error</code></td>
<td>

<p>Numeric value representing the expected genotyping error rate (default = 0.25/100).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function searchs for runs of homozygosity (ROH) via two different methods: <br />
</p>
<p>The 'naive' method simply finds streches of homozygous genotypes in the observed haplotypes that are larger then a user-definied minimum size (default is 1 Mbp). The 'hmm' method uses a Hidden Markov Model that takes genotyping error and recombination into account while detecting ROHs. The 'hmm' model in GHap is similar to the ones described by Narasimhan et al (2016) and Druet &amp; Gautier (2017), differing slightly in model fitting and definition of transition and emission probabilities (details are covered in our vignette). <br />
</p>
<p>The 'hmm' method requires allele frequencies for each marker, as well as starting values for the expected proportion of the genome covered by ROH (genomic inbreeding) for each individual. Estimates of allele frequencies can be either based on a reference or estimated from the data with the <code><a href="#topic+ghap.freq">ghap.freq</a></code> function. Starting values for genomic inbreeding can be obtained by running the function with the 'naive' method first and then computing starting values with <code><a href="#topic+ghap.froh">ghap.froh</a></code> (see the examples). A genetic map with positions in cM can be provided by the user via the genpos argument. If genetic positions are not provided, 1 cM = 1 Mb is assumed.<br />
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the following columns:
</p>
<table>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Segment start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Segment end position.
</p>
</td></tr>
<tr><td><code>LENGTH</code></td>
<td>

<p>Length of run of homozygosity.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>V. Narasimhan et al. BCFtools/RoH: a hidden Markov model approach for detecting autozygosity from next-generation sequencing data. Bioinformatics. 2016. 32:1749-1751.
</p>
<p>T. Druet &amp; M. Gautier. A model-based approach to characterize individual inbreeding at both global and local genomic scales. Molecular Ecology. 2017. 26:5820-5841.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.freq">ghap.freq</a></code>, <code><a href="#topic+ghap.froh">ghap.froh</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# ### RUN ###
# 
# # Subset pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # ROH via the 'naive' method
# roh1 &lt;- ghap.roh(plink, method = "naive")
# froh1 &lt;- ghap.froh(plink, roh1)
# 
# # ROH via the 'hmm' method
# freq &lt;- ghap.freq(plink, type = 'A1')
# inbcoef &lt;- froh1$FROH1; names(inbcoef) &lt;- froh1$ID
# roh2 &lt;- ghap.roh(plink, method = "hmm", freq = freq,
#                 inbcoef = inbcoef)
# froh2 &lt;- ghap.froh(plink, roh2)
#
# # Method 'hmm' using Fhat3 as starting values
# inbcoef &lt;- ibc$Fhat3; names(inbcoef) &lt;- ibc$ID
# inbcoef[which(inbcoef &lt; 0)] &lt;- 0.01
# roh3 &lt;- ghap.roh(plink, method = "hmm", freq = freq,
#                  inbcoef = inbcoef)
# froh3 &lt;- ghap.froh(plink, roh3)

</code></pre>

<hr>
<h2 id='ghap.simadmix'>
Simulate individuals from specified admixture proportions
</h2><span id='topic+ghap.simadmix'></span>

<h3>Description</h3>

<p>Generation of simulated haplotypes based on a list of user-defined ancestral populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.simadmix(object, n.individuals,
                n.generations, ancestors,
                proportions = NULL,
                alpha = NULL,
                out.file,
                only.active.markers = TRUE,
                ncores = 1,verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.simadmix_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_n.individuals">n.individuals</code></td>
<td>

<p>Number of individuals to simulate.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_n.generations">n.generations</code></td>
<td>

<p>Number of generations past the admixture event.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_ancestors">ancestors</code></td>
<td>

<p>List of ancestral populations. Each ancestral population is given as a vector of ids of the ancestors belonging to that population.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_proportions">proportions</code></td>
<td>

<p>A dataframe containing the ancestry proportions in the simulated individuals. The number of columns has to be equal to the number of ancestral populations defined in the ancestors list, and the number of row has to be equal to the number of simulated individuals. See argument 'alpha' if you want the function to generate random samples for admixture proportions.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_alpha">alpha</code></td>
<td>

<p>A list with same size of the 'ancestors' list, with each value representing the vector of parameters to be used for sampling ancestry proportions from a Direchelet distribution.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_out.file">out.file</code></td>
<td>

<p>Output file name.
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used in simulations (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.simadmix_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a list of ancestral populations, this function simulates haplotypes of individuals descending from admixture among these populations after a defined number of generations. The ancestry proportions can be sampled from a Direchelet distribution with a vector of parameters alpha. For example, if three ancestral populations are considered and the parameters are set as alpha = list(pop1 = 1, pop2 = 1, pop3 = 1), the resulting simulated individuals will have a highly diverse configuration of ancestry proportions. On the other hand, by setting alpha = list(pop1 = 0, pop2 = 1, pop3 = 0) for example, all individuals will descend entirely from population 2 without admixture. The user can play with these values to fine tune the desired sampling distribution. Alternatively, exact proportions for each simulated individual can be set through the 'proportions' argument by providing a dataframe containing the desired ancestry values.
</p>


<h3>Value</h3>

<p>The function outputs the following files:
</p>

<ul>
<li> <p><strong>.samples</strong>: space-delimited file without header containing two columns: Population and ID of simulated individuals (numbered from 1 to n). The first column is filled with &quot;SIM&quot;. 
</p>
</li>
<li> <p><strong>.markers</strong>: space-delimited file without header containing five columns: Chromosome, Marker, Position (in bp), Reference Allele (A0) and Alternative Allele (A1).
</p>
</li>
<li> <p><strong>.phase</strong>: space-delimited file without header containing the phased genotype matrix of the simulated progeny. The dimension of the matrix is <em>m x 2n</em>, where <em>m</em> is the number of markers and <em>n</em> is the number of simulated individuals (i.e., two columns per individual, representing the two phased chromosome alleles).
</p>
</li>
<li> <p><strong>.proportions</strong>: space-delimited file with header containing the following columns: Population, ID and K columns of ancestry proportions, one for each ancestral population.
</p>
</li>
<li> <p><strong>.haplotypes</strong>: space-delimited file with header containing ancestry tracks with the following columns: Population, ID, haplotype number, chromosome name, starting position, ending position, track size and ancestry of the segment. 
</p>
</li></ul>

<p>The user can then treat these files as a regular GHap input, or use them to build the Oxford HAPS/SAMPLES format for analysis with other software. The simulated data can be useful in the evaluation of accuracy of different algorithms designed for admixture analysis, as well as of other methods in the field of population genomics.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# phase &lt;- ghap.loadphase("example")
# 
# # Make vectors of ancestors
# pure1 &lt;- unique(phase$id[which(phase$pop == "Pure1")])
# pure2 &lt;- unique(phase$id[which(phase$pop == "Pure2")])
# 
# # Simulate proportions
# ngroup &lt;- 30
# pop1 &lt;- c(rep(1, times = ngroup), # purebred from population 1
#           runif(n = ngroup, min = 0.1, max = 0.9), # admixed individuals
#           rep(0, times = ngroup)) # purebred from population 2
# pop2 &lt;- 1-pop1
# prop &lt;- data.frame(pop1,pop2)
# 
# # Simulate individuals
# set.seed(1988)
# ghap.simadmix(object = phase, n.individuals = nrow(prop),
#               n.generations = 10,
#               ancestors = list(pop1 = pure1, pop2 = pure2),
#               proportions = prop, out.file = "sim")
# ghap.compress(input.file = "sim", out.file = "sim")
# sim &lt;- ghap.loadphase("sim")
# 
# # Unsupervised analysis with K = 2
# prototypes &lt;- ghap.anctrain(object = sim, K = 2)
# hapadmix &lt;- ghap.anctest(object = sim,
#                          prototypes = prototypes,
#                          test = unique(sim$id))
# anctracks &lt;- ghap.ancsmooth(object = sim, admix = hapadmix)
# 
# # Load simulated ancestry proportions
# ancsim &lt;- NULL
# ancsim$proportions2 &lt;- read.table(file = "sim.proportions", header=T)
# ancsim$haplotypes &lt;- read.table(file = "sim.haplotypes", header=T)
# 
# # Compare estimates with real values
# # Obs: the original populations had introgression from each other
# # Admixture seen in the estimates of purebreds reflect that introgression
# ghap.ancplot(ancsmooth = ancsim)
# ghap.ancplot(ancsmooth = anctracks)
# cor(anctracks$proportions2$K1, ancsim$proportions2$pop1)
# ghap.karyoplot(ancsmooth = ancsim, ids = sim$id[66])
# ghap.karyoplot(ancsmooth = anctracks, ids = sim$id[66])

</code></pre>

<hr>
<h2 id='ghap.simmating'>
Simulate individuals from specified matings
</h2><span id='topic+ghap.simmating'></span>

<h3>Description</h3>

<p>Generation of simulated haplotypes based on in silico matings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.simmating(object, n.individuals = 1,
                 parent1 = NULL, parent2 = NULL,
                 model = "proportional", out.file,
                 only.active.markers = TRUE,
                 ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.simmating_+3A_object">object</code></td>
<td>

<p>A GHap.phase object.
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_n.individuals">n.individuals</code></td>
<td>

<p>Number of individuals to simulate.
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_parent1">parent1</code></td>
<td>

<p>Vector containing the ids of candidate sires. When a character vector is provided, all candidates are considered equally likely to be selected. Alternatively, a named numeric vector of probabilities (with sire ids used as names) can be used in order to make specific sires more likely to be selected.
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_parent2">parent2</code></td>
<td>

<p>Vector containing the ids of candidate dams. When a character vector is provided, all candidates are considered equally likely to be selected. Alternatively, a named numeric vector of probabilities (with dam ids used as names) can be used in order to make specific dams more likely to be selected.
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_model">model</code></td>
<td>

<p>The model used for sampling the number of recombinations per chromosome (default = &quot;proportional&quot;). See details for more options.
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_out.file">out.file</code></td>
<td>

<p>Output file name.
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_only.active.markers">only.active.markers</code></td>
<td>

<p>A logical value specifying whether only active markers should be used in simulations (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computing (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.simmating_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a list of candidate parents, this function samples sire i with probability p_i and dam j with probability p_j (these probabilities should be provided by the user, otherwise matings will occur at random). Once sire and dam are sampled, gametes are simulated by creating recombinant parental haplotypes. The progeny is then obtained by uniting the simulated gametes.
</p>
<p>The default model (&quot;proportional&quot;) assumes that the number of recombinations per meiosis across all chromosomes follows a Poisson distribution with mean equal to nchr (the number of chromosome pairs), such that the number of recombinations for a given chromosome is sampled from a Poisson distribution with mean prop*nchr, where prop is the proportion of the genome size covered by that chromosome. Therefore, this option takes chromosome size in consideration while sampling the number of recombination events. In option &quot;uniform&quot;, the number of recombinations is sampled from a Poisson distribution with mean 1 for each chromosome instead. Alternatively, the model argument can also take a named vector of chromosome-specific recombination rates in cM/Mb. In this option, the number of recombinations for a given chromosome is sampled from a Poisson distribution with mean chrsize*chrrate/100, where chrsize is the size of the chromosome in Mb and chrrate is the recombination rate in cM/Mb. A last option is offered where the model argument is a named vector of marker-specific recombination rates in cM/Mb. The number of recombinations for a given chromosome is also sampled from a Poisson distribution with mean chrsize*chrrate/100, but with chrrate calculated as the average across markers within the same chromosome. In this model, instead of placing the recombination breakpoint randomly within a chromosome for each gamete, marker-specific recombination rates are taken into account, making regions in the chromosome with higher recombination rates more susceptible to breaks.
</p>


<h3>Value</h3>

<p>The function outputs the following files:
</p>

<ul>
<li> <p><strong>.samples</strong>: space-delimited file without header containing two columns: Population and ID of simulated individuals (numbered from 1 to n). The first column is filled with &quot;SIM&quot;. 
</p>
</li>
<li> <p><strong>.markers</strong>: space-delimited file without header containing five columns: Chromosome, Marker, Position (in bp), Reference Allele (A0) and Alternative Allele (A1).
</p>
</li>
<li> <p><strong>.phase</strong>: space-delimited file without header containing the phased genotype matrix of the simulated progeny. The dimension of the matrix is <em>m x 2n</em>, where <em>m</em> is the number of markers and <em>n</em> is the number of simulated individuals (i.e., two columns per individual, representing the two phased chromosome alleles).
</p>
</li>
<li> <p><strong>.pedrigree</strong>: space-delimited file without header containing three columns: individual number, sire ID and dam ID. 
</p>
</li></ul>

<p>The user can then treat these files as a regular GHap input, or use them to build the Oxford HAPS/SAMPLES format for analysis with other software. The simulated data can be useful in the evaluation of mating plans, since the in silico progeny can help in the characterization of the expected distribution of genomic inbreeding coefficients, ancestry proportions and EBVs in the progeny. Since the function does not check for sex differences between parents, the user can perform simulations of self-fertilization (relevant for plant breeders) and same sex matings.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Simulation using only two specific parents
# parent1 &lt;- phase$id[1]
# parent2 &lt;- phase$id[3]
# ghap.simmating(phase, n.individuals = 100,
#                parent1 = parent1, parent2 = parent2,
#                out.file = "sim1", ncores = 1)
# 
# # Simulation using candidates with unequal probabilities
# parent1 &lt;- c(0.5,0.25,0.25)
# names(parent1) &lt;- phase$id[c(1,3,5)]
# parent2 &lt;- c(0.7,0.2,0.1)
# names(parent2) &lt;- phase$id[c(7,9,11)]
# ghap.simmating(phase, n.individuals = 100,
#                parent1 = parent1, parent2 = parent2,
#                out.file = "sim2", ncores = 1)

</code></pre>

<hr>
<h2 id='ghap.simpheno'>
Quantitative trait simulation using real genotype data
</h2><span id='topic+ghap.simpheno'></span>

<h3>Description</h3>

<p>Simulates phenotypes from a quantitative trait with arbitrary variant-specific heritabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.simpheno(object, h2, r2 = 0, nrep = 1,
              balanced = TRUE, seed = NULL, 
              only.active.samples = TRUE,
              ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.simpheno_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase or plink).
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_h2">h2</code></td>
<td>

<p>A named numeric value specifying the heritability per variant. The sum of variant-specific heritabilities will be set as the narrow-sense heritability, and must not exceed 1.
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_r2">r2</code></td>
<td>

<p>A numeric value specifying the repeatability (default = 0). Only relevant if nrep &gt; 1.
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_nrep">nrep</code></td>
<td>

<p>A numeric value specifying the number of repeated measures per subject.
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_balanced">balanced</code></td>
<td>

<p>A logical value specifying whether the output data should be balanced (default = TRUE). If balanced = FALSE, the number of repeated measures per subject will be heterogeneous, following a uniform distribution with minimum zero and maximum nrep. Only relevant if nrep &gt; 1.
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_seed">seed</code></td>
<td>

<p>A numeric value used to set the random number generation state (default = NULL). This is useful for reproducibility of the results.
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_only.active.samples">only.active.samples</code></td>
<td>

<p>A logical value specifying whether only active samples should be used for calculations (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.simpheno_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation considers the model:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{y} = \mathbf{Zu} + \mathbf{Zp} + \mathbf{e}</code>
</p>

<p>where <code class="reqn">\mathbf{u}</code> is a vector of breeding values, <code class="reqn">\mathbf{p}</code> is a vector of permanent environmental effects, <code class="reqn">\mathbf{Z}</code> is an incidence matrix mapping <code class="reqn">\mathbf{y}</code> to <code class="reqn">\mathbf{u}</code> and <code class="reqn">\mathbf{p}</code>, and <code class="reqn">\mathbf{e}</code> is the vector of residuals. True breeding values are computed from the sum of causal variant effects specified in the 'h2' argument. Both the residual and permanent environmental effects are sampled from normal distributions.
</p>


<h3>Value</h3>

<p>The function returns a data frame with items:
</p>
<table>
<tr><td><code>POP</code></td>
<td>

<p>Original population label.
</p>
</td></tr>
<tr><td><code>ID</code></td>
<td>

<p>Individual name.
</p>
</td></tr>
<tr><td><code>PHENO</code></td>
<td>

<p>Phenotypic observation.
</p>
</td></tr>
<tr><td><code>TBV</code></td>
<td>

<p>True breeding value.
</p>
</td></tr>
<tr><td><code>REP</code></td>
<td>

<p>Permanent environmental effect (only present if nrep &gt; 1).
</p>
</td></tr>
<tr><td><code>RESIDUAL</code></td>
<td>

<p>Residual value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load phase data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Subset Pure1 population
# pure1 &lt;- unique(phase$id[which(phase$pop == "Pure1")])
# phase &lt;- ghap.subset(object = phase, ids = pure1,
#                      variants = phase$marker)
# freq &lt;- ghap.freq(object = phase, type = "maf")
# 
# # Heritability   = 0.3
# # Number of QTLs = 1000
# # Major QTLs     = 0
# # Records per id = 1
# nqtl &lt;- 1000
# h2 &lt;- 0.3
# mkr &lt;- sample(names(freq[which(freq &gt; 0.05)]), size = nqtl)
# eff &lt;- runif(n = nqtl, min = 0, max = 1)
# eff &lt;- h2*eff/sum(eff)
# names(eff) &lt;- mkr
# df1 &lt;- ghap.simpheno(object = phase, h2 = eff)
# 
# # Heritability   = 0.5
# # Number of QTLs = 100
# # Major QTLs     = 1
# # Records per id = 5 (balanced)
# # Repeatability = 0.2
# nqtl &lt;- 100
# h2 &lt;- 0.4
# r2 &lt;- 0.2
# reps &lt;- 5
# mkr &lt;- sample(names(freq[which(freq &gt; 0.05)]), size = nqtl)
# eff &lt;- runif(n = nqtl, min = 0, max = 1)
# eff &lt;- h2*eff/sum(eff)
# eff[which(eff == min(eff))] &lt;- 0.1
# names(eff) &lt;- mkr
# df2 &lt;- ghap.simpheno(object = phase, h2 = eff,
#                      r2 = r2, nrep = reps)
# 
# # Heritability   = 0.5
# # Number of QTLs = 100
# # Major QTLs     = 1
# # Records per id = 5 (unbalanced)
# # Repeatability = 0.2
# nqtl &lt;- 100
# h2 &lt;- 0.4
# r2 &lt;- 0.2
# reps &lt;- 5
# mkr &lt;- sample(names(freq[which(freq &gt; 0.05)]), size = nqtl)
# eff &lt;- runif(n = nqtl, min = 0, max = 1)
# eff &lt;- h2*eff/sum(eff)
# eff[which(eff == min(eff))] &lt;- 0.1
# names(eff) &lt;- mkr
# df3 &lt;- ghap.simpheno(object = phase, h2 = eff, r2 = r2,
#                      nrep = reps, balanced = FALSE)


</code></pre>

<hr>
<h2 id='ghap.slice'>
Get a slice of a GHap object
</h2><span id='topic+ghap.slice'></span>

<h3>Description</h3>

<p>This function parses a binary PLINK, phased or HapGenotypes matrix and returns the slice as an R matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.slice(object, ids, variants, index=FALSE,
           transposed=FALSE, sparse=TRUE,
           unphase=FALSE, impute=FALSE,
           ncores=1, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.slice_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_ids">ids</code></td>
<td>

<p>A character or numeric vector indicating individuals to parse.
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_variants">variants</code></td>
<td>

<p>A character or numeric vector indicating variants to parse. If a &quot;GHap.haplo&quot; object is provided, the vector must be numeric.
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_index">index</code></td>
<td>

<p>A logical value specfying if values provided for ids and variants are indices (see details).
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_transposed">transposed</code></td>
<td>

<p>A logical value specfying if genotypes should be transposed. If FALSE (default), the matrix is returned as variants by individuals. Otherwise, the retrieved matrix is organized as individuals by variants.
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_sparse">sparse</code></td>
<td>

<p>A logical value specfying if the returned matrix should be formatted as a sparse matrix (default TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_unphase">unphase</code></td>
<td>

<p>A logical value specfying if phased genotypes should be retrieved as unphased allele counts. Only meaningful for &quot;GHap.phase&quot; objects.
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_impute">impute</code></td>
<td>

<p>A logical value specfying if missing genotypes should be replaced by 0 (i.e., A0/A0 genotypes, default = FALSE). Only meaningful for &quot;GHap.plink&quot; objects.
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.slice_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function parses the binary input file and returns an R matrix with the requested list of variants (markers or alleles) and individuals. The argument index allows the user to specify individuals either by name (index = FALSE) or by indices as stored in the GHap object (index = TRUE). In the case of &quot;GHap.haplo&quot; objects, HapAlleles can only by parsed via indices.
</p>


<h3>Value</h3>

<p>An R matrix with variants in rows and individuals in columns (this is inverted if transposed = TRUE).
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Select random individuals and markers
# ind &lt;- sample(x = unique(phase$id), size = 5)
# mkr &lt;- sample(x = phase$marker, size = 10)
# 
# # Generate slice of the data
# ghap.slice(object = phase, ids = ind, variants = mkr)
# 
# # Import as unphased data
# ghap.slice(object = phase, ids = ind, variants = mkr,
#            unphase = TRUE)
# 
# # Return transposed matrix
# ghap.slice(object = phase, ids = ind, variants = mkr,
#            unphase = TRUE, transposed = TRUE)
# 
# # Display data as non-sparse matrix
# ghap.slice(object = phase, ids = ind, variants = mkr,
#            unphase = TRUE, transposed = TRUE,
#            sparse = FALSE)

</code></pre>

<hr>
<h2 id='ghap.subset'>
Subset GHap objects
</h2><span id='topic+ghap.subset'></span>

<h3>Description</h3>

<p>This function takes a list of variants and individuals and subsets a GHap object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.subset(object, ids, variants,
            index=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.subset_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.subset_+3A_ids">ids</code></td>
<td>

<p>A character or numeric vector indicating individuals to parse.
</p>
</td></tr>
<tr><td><code id="ghap.subset_+3A_variants">variants</code></td>
<td>

<p>A character or numeric vector indicating variants to parse. If a &quot;GHap.haplo&quot; object is provided, the vector must be numeric.
</p>
</td></tr>
<tr><td><code id="ghap.subset_+3A_index">index</code></td>
<td>

<p>A logical value specfying if values provided for ids and variants are indices (see details).
</p>
</td></tr>
<tr><td><code id="ghap.subset_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function sets to FALSE (i.e., inactivates) all individuals and variants not included in the provided arguments. This procedure avoids expensive subsetting operations by simply flagging which variants and individuals should be used in downstream analyses. The argument index allows the user to specify individuals either by name (index = FALSE) or by indices as stored in the GHap object (index = TRUE). In the case of &quot;GHap.haplo&quot; objects, HapAlleles can only by parsed via indices.
</p>


<h3>Value</h3>

<p>A GHap object of the same type as the one used in the object argument.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy phase data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "phase",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load data
# phase &lt;- ghap.loadphase("example")
# 
# ### RUN ###
# 
# # Subset individuals from population 'Pure1'
# pure1 &lt;- unique(phase$id[which(phase$pop == "Pure1")])
# phase &lt;- ghap.subset(object = phase, ids = pure1,
#                      variants = phase$marker)
# 
# # Calculate allele frequencies for population 'Pure1'
# freq &lt;- ghap.freq(phase, type = 'maf')
# 
# # Subset markers with MAF &gt; 0.05 in population 'Pure1'
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# phase &lt;- ghap.subset(object = phase, ids = pure1,
#                      variants = mkr)

</code></pre>

<hr>
<h2 id='ghap.varblup'>
Convert BLUP of individuals into BLUP of variants
</h2><span id='topic+ghap.varblup'></span>

<h3>Description</h3>

<p>Given genomic estimated breeding values (GEBVs), compute Best Linear Unbiased Predictor (BLUP) solutions for variant effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghap.varblup(object, gebv, covmat, type = 1,
             only.active.variants = TRUE,
             weights = NULL, tol = 1e-12,
             vcp = NULL, errormat = NULL, 
             errorname = "", nlambda = 1000,
             ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ghap.varblup_+3A_object">object</code></td>
<td>

<p>A valid GHap object (phase, haplo or plink).
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_gebv">gebv</code></td>
<td>

<p>A named vector of genomic estimated breeding values.
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_covmat">covmat</code></td>
<td>

<p>An additive genomic relationship matrix, such as obtained with type=1 or type=2 in the <code><a href="#topic+ghap.kinship">ghap.kinship</a></code> function. 
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_type">type</code></td>
<td>

<p>A numeric value indicating the type of relationship matrix (see details in the <code><a href="#topic+ghap.kinship">ghap.kinship</a></code> function).
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_only.active.variants">only.active.variants</code></td>
<td>

<p>A logical value specifying whether only active variants should be included in the calculations (default = TRUE).
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_weights">weights</code></td>
<td>

<p>A numeric vector providing variant-specific weights.
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_tol">tol</code></td>
<td>

<p>A numeric value specifying the scalar to add to the diagonal of the relationship matrix it is not inversible (default = 1e-10).
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_vcp">vcp</code></td>
<td>

<p>A numeric value for the variance in GEBVs.
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_errormat">errormat</code></td>
<td>

<p>A square error matrix for GEBVs. This matrix can be obtained with argument extras = &quot;LHSi&quot; in the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function. If provided, calculation of standard errors and test statistics for the variants is activated.
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_errorname">errorname</code></td>
<td>

<p>The name used for the random effect representing GEBVs in the <code><a href="#topic+ghap.lmm">ghap.lmm</a></code> function. If the error matrix was imported from somewhere else, this argument can be ignored provided that the names in the error matrix match the ones in the relationship matrix.
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_nlambda">nlambda</code></td>
<td>

<p>A numeric value for the number of variants to be used in the estimation of the inflation factor (default = 1000).
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specifying the number of cores to be used in parallel computations (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.varblup_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specifying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the equation:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{\hat{a}} = q\mathbf{DM}^T\mathbf{K}^{-1}\mathbf{\hat{u}}</code>
</p>

<p>where <code class="reqn">\mathbf{M}</code> is the <em>n</em> x <em>m</em> matrix of genotypes, where <em>n</em> is the number of individuals and <em>m</em> is the number of variants (i.e, markers or HapAlleles), <code class="reqn">\mathbf{D} = diag(d_i)</code> with <code class="reqn">d_i</code> being the weight of variant <em>i</em> (default <code class="reqn">d_i = 1</code>), <code class="reqn">q</code> is the inverse weighted sum of variances in the columns of <code class="reqn">\mathbf{M}</code>, <code class="reqn">\mathbf{K}</code> is the additive genomic relationship matrix and <code class="reqn">\hat{u}</code> is the vector of GEBVs.
</p>


<h3>Value</h3>

<p>The function returns a data frame with results from the genome-wide conversion of BLUP of individuals into BLUP of variants. If a GHap.haplo object is used, the first columns of the data frame will be:
</p>
<table>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>BLOCK</code></td>
<td>

<p>Block alias.
</p>
</td></tr>
<tr><td><code>BP1</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP2</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
</table>
<p>For GHap.phase and GHap.plink objects, the first columns will be:
</p>
<table>
<tr><td><code>CHR</code></td>
<td>

<p>Chromosome name.
</p>
</td></tr>
<tr><td><code>MARKER</code></td>
<td>

<p>Block start position.
</p>
</td></tr>
<tr><td><code>BP</code></td>
<td>

<p>Block end position.
</p>
</td></tr>
</table>
<p>The remaining columns of the data frame will be equal for any class of GHap objects:
</p>
<table>
<tr><td><code>ALLELE</code></td>
<td>

<p>Identity of the counted (A1 or haplotype) allele.
</p>
</td></tr>
<tr><td><code>FREQ</code></td>
<td>

<p>Frequency of the allele.
</p>
</td></tr>
<tr><td><code>SCORE</code></td>
<td>

<p>Estimated BLUP of the allele.
</p>
</td></tr>
<tr><td><code>VAR</code></td>
<td>

<p>Variance in allele-specific breeding values.
</p>
</td></tr>
<tr><td><code>pVAR</code></td>
<td>

<p>Proportion of variance explained by the allele.
</p>
</td></tr>
<tr><td><code>CENTER</code></td>
<td>

<p>Average genotype (meaningful only for predictions with <code><a href="#topic+ghap.profile">ghap.profile</a></code>).
</p>
</td></tr>
<tr><td><code>SCALE</code></td>
<td>

<p>A constant set to 1 (meaningful only for predictions with <code><a href="#topic+ghap.profile">ghap.profile</a></code>).
</p>
</td></tr>
</table>
<p>If an error matrix for GEBVs is provided through the 'errormat' argument, the following additional columns are included in the data frame:
</p>
<table>
<tr><td><code>SE</code></td>
<td>

<p>Standard error for the BLUP of the allele.
</p>
</td></tr>
<tr><td><code>CHISQ.EXP</code></td>
<td>

<p>Expected values for the test statistics.
</p>
</td></tr>
<tr><td><code>CHISQ.OBS</code></td>
<td>

<p>Observed value for the test statistics.
</p>
</td></tr>
<tr><td><code>CHISQ.GC</code></td>
<td>

<p>Test statistics scaled by the inflation factor (Genomic Control). Inflation is computed through regression of observed quantiles onto expected quantiles. In order to avoid overestimation by variants rejecting the null hypothesis, a random sample of variants (with size controled via the nlambda argument) is taken within three standard deviations from the mean of the distribution of test statistics.
</p>
</td></tr>
<tr><td><code>LOGP</code></td>
<td>

<p>log10(1/P) or -log10(P) for the BLUP of the allele.
</p>
</td></tr>
<tr><td><code>LOGP.GC</code></td>
<td>

<p>log10(1/P) or -log10(P) for the BLUP of the allele (scaled by the inflation factor).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>I. Stranden and D.J. Garrick. Technical note: derivation of equivalent computing algorithms for genomic predictions and reliabilities of animal merit. J Dairy Sci. 2009. 92:2971-2975.
</p>
<p>J.L.G. Duarte et al. Rapid screening for phenotype-genotype associations by linear transformations of genomic evaluations. BMC Bioinformatics. 2014, 15:246.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy plink data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "plink",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Copy metadata in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "meta",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# # Load plink data
# plink &lt;- ghap.loadplink("example")
# 
# # Load phenotype and pedigree data
# df &lt;- read.table(file = "example.phenotypes", header=T)
# 
# ### RUN ###
# 
# # Subset individuals from the pure1 population
# pure1 &lt;- plink$id[which(plink$pop == "Pure1")]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = plink$marker)
# 
# # Subset markers with MAF &gt; 0.05
# freq &lt;- ghap.freq(plink)
# mkr &lt;- names(freq)[which(freq &gt; 0.05)]
# plink &lt;- ghap.subset(object = plink, ids = pure1, variants = mkr)
# 
# # Compute genomic relationship matrix
# # Induce sparsity to help with matrix inversion
# K &lt;- ghap.kinship(plink, sparsity = 0.01)
# 
# # Fit mixed model
# df$rep &lt;- df$id
# model &lt;- ghap.lmm(formula = pheno ~ 1 + (1|id) + (1|rep),
#                   data = df,
#                   covmat = list(id = K, rep = NULL),
#                   extras = "LHSi")
# refblup &lt;- model$random$id$Estimate
# names(refblup) &lt;- rownames(model$random$id)
# 
# # Convert blup of individuals into blup of variants
# mkrblup &lt;- ghap.varblup(object = plink, gebv = refblup,
#                         covmat = K, vcp = model$vcp$Estimate[1],
#                         errormat = model$extras$LHSi, errorname = "id")
# 
# # Build GEBVs from variant effects and compare predictions
# gebv &lt;- ghap.profile(object = plink, score = mkrblup)
# plot(gebv$SCORE, refblup); abline(0,1)
# 
# # Compare variant solutions with regular GWAS
# gwas &lt;- ghap.assoc(object = plink,
#                    formula = pheno ~ 1 + (1|id) + (1|rep),
#                    data = df,
#                    covmat = list(id = K, rep = NULL))
# ghap.manhattan(data = gwas, chr = "CHR", bp = "BP", y = "LOGP")
# ghap.manhattan(data = mkrblup, chr = "CHR", bp = "BP", y = "LOGP")
# plot(mkrblup$LOGP, gwas$LOGP); abline(0,1)

</code></pre>

<hr>
<h2 id='ghap.vcf2phase'>
Convert VCF data into GHap phase
</h2><span id='topic+ghap.vcf2phase'></span>

<h3>Description</h3>

<p>This function takes phased genotype data in the Variant Call Format (VCF) and converts them into the GHap phase format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ghap.vcf2phase(input.files = NULL, vcf.files = NULL,
                 sample.files = NULL, out.file,
                 ncores = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<p>If all input files share the same prefix, the user can use the following shortcut options:
</p>
<table>
<tr><td><code id="ghap.vcf2phase_+3A_input.files">input.files</code></td>
<td>

<p>Character vector with the list of prefixes for input files.
</p>
</td></tr>
<tr><td><code id="ghap.vcf2phase_+3A_out.file">out.file</code></td>
<td>

<p>Character value for the output file name.
</p>
</td></tr>
</table>
<p>The user can also opt to point to input files separately:
</p>
<table>
<tr><td><code id="ghap.vcf2phase_+3A_vcf.files">vcf.files</code></td>
<td>

<p>Character vector containing the list of VCF files.
</p>
</td></tr>
<tr><td><code id="ghap.vcf2phase_+3A_sample.files">sample.files</code></td>
<td>

<p>Character vector containing the list of SAMPLE files.
</p>
</td></tr>
</table>
<p>To turn conversion progress-tracking on or off or set the number of cores please use:
</p>
<table>
<tr><td><code id="ghap.vcf2phase_+3A_ncores">ncores</code></td>
<td>

<p>A numeric value specfying the number of cores to use (default = 1).
</p>
</td></tr>
<tr><td><code id="ghap.vcf2phase_+3A_verbose">verbose</code></td>
<td>

<p>A logical value specfying whether log messages should be printed (default = TRUE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Variant Call Format (VCF) - as described in https://github.com/samtools/hts-specs - is here manipulated to obtain the GHap phase format. Important: the function does not apply filters to the data, except for skipping multi-allelic variants. Should variants be filtered, the user is advised to pre-process the VCF files with third-party software (such as BCFTools). The FORMAT field should also follow the &quot;GT:...&quot; specification, with genotypes placed first in each sample column. Finally, all genotypes should be phased and take one of the following values: &quot;0|0&quot;, &quot;0|1&quot;, &quot;1|0&quot; or &quot;1|1&quot;.
Warning: this function is not optimized for very large datasets.
</p>


<h3>Author(s)</h3>

<p>Yuri Tani Utsunomiya &lt;ytutsunomiya@gmail.com&gt;
</p>


<h3>References</h3>

<p>H. Li et al. The Sequence alignment/map (SAM) format and SAMtools. Bioinformatics. 2009. 25:2078-2079.
</p>
<p>H. Li. A statistical framework for SNP calling, mutation discovery, association mapping and population genetical parameter estimation from sequencing data. Bioinformatics. 2011. 27(21):2987-2993.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ghap.compress">ghap.compress</a></code>, <code><a href="#topic+ghap.loadphase">ghap.loadphase</a></code>, <code><a href="#topic+ghap.fast2phase">ghap.fast2phase</a></code>, <code><a href="#topic+ghap.oxford2phase">ghap.oxford2phase</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# #### DO NOT RUN IF NOT NECESSARY ###
# 
# # Copy the example data in the current working directory
# exfiles &lt;- ghap.makefile(dataset = "example",
#                          format = "vcf",
#                          verbose = TRUE)
# file.copy(from = exfiles, to = "./")
# 
# ### RUN ###
# 
# # Convert from a single genome-wide file
# ghap.vcf2phase(input.files = "example",
#                out.file = "example")
# 
# # Convert from a list of chromosome files
# ghap.vcf2phase(input.files = paste0("example_chr",1:10),
#                out.file = "example")
# 
# # Convert using separate lists for file extensions
# ghap.vcf2phase(vcf.files = paste0("example_chr",1:10,".vcf"),
#                sample.files = paste0("example_chr",1:10,".sample"),
#                out.file = "example")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
