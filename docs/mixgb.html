<!DOCTYPE html><html lang="en"><head><title>Help for package mixgb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mixgb}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mixgb-package'><p>mixgb: Multiple Imputation Through 'XGBoost'</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#createNA'><p>Create missing values for a dataset</p></a></li>
<li><a href='#data_clean'><p>Data cleaning</p></a></li>
<li><a href='#default_params'><p>Auxiliary function for validating xgb.params</p></a></li>
<li><a href='#default_params_cran'><p>Auxiliary function for validating xgb.params compatible with XGBoost CRAN version</p></a></li>
<li><a href='#impute_new'><p>Impute new data with a saved <code>mixgb</code> imputer object</p></a></li>
<li><a href='#mixgb'><p>Multiple imputation through XGBoost</p></a></li>
<li><a href='#mixgb_cv'><p>Use cross-validation to find the optimal <code>nrounds</code></p></a></li>
<li><a href='#nhanes3'><p>A small subset of the NHANES III (1988-1994) newborn data</p></a></li>
<li><a href='#nhanes3_newborn'><p>NHANES III (1988-1994) newborn data</p></a></li>
<li><a href='#pmm'><p>PMM for numeric or binary variable</p></a></li>
<li><a href='#pmm.multiclass'><p>PMM for multiclass variable</p></a></li>
<li><a href='#show_var'><p>Show multiply imputed values for a single variable</p></a></li>
<li><a href='#sortNA'><p>Sort data by increasing number of missing values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Multiple Imputation Through 'XGBoost'</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Multiple imputation using 'XGBoost', subsampling, and predictive mean 
    matching as described in Deng and Lumley (2023) 
    &lt;<a href="https://doi.org/10.1080%2F10618600.2023.2252501">doi:10.1080/10618600.2023.2252501</a>&gt;.  The package supports various types of 
    variables, offers flexible settings, and enables saving an imputation model to impute
    new data. Data processing and memory usage have been optimised to speed up 
    the imputation process.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/agnesdeng/mixgb">https://github.com/agnesdeng/mixgb</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/agnesdeng/mixgb/issues">https://github.com/agnesdeng/mixgb/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, Matrix, mice, Rcpp, Rfast, stats, utils, xgboost
(&ge; 1.7.5.1), magrittr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-30 11:33:18 UTC; agnes</td>
</tr>
<tr>
<td>Author:</td>
<td>Yongshi Deng <a href="https://orcid.org/0000-0001-5845-859X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Thomas Lumley [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yongshi Deng &lt;agnes.yongshideng@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-02 09:20:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='mixgb-package'>mixgb: Multiple Imputation Through 'XGBoost'</h2><span id='topic+mixgb-package'></span>

<h3>Description</h3>

<p>Multiple imputation using 'XGBoost', subsampling, and predictive mean matching as described in Deng and Lumley (2023) <a href="https://doi.org/10.1080/10618600.2023.2252501">doi:10.1080/10618600.2023.2252501</a>. The package supports various types of variables, offers flexible settings, and enables saving an imputation model to impute new data. Data processing and memory usage have been optimised to speed up the imputation process.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Yongshi Deng <a href="mailto:agnes.yongshideng@gmail.com">agnes.yongshideng@gmail.com</a> (<a href="https://orcid.org/0000-0001-5845-859X">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Thomas Lumley <a href="mailto:t.lumley@auckland.ac.nz">t.lumley@auckland.ac.nz</a> [thesis advisor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/agnesdeng/mixgb">https://github.com/agnesdeng/mixgb</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/agnesdeng/mixgb/issues">https://github.com/agnesdeng/mixgb/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling 'rhs(lhs)'.
</p>

<hr>
<h2 id='createNA'>Create missing values for a dataset</h2><span id='topic+createNA'></span>

<h3>Description</h3>

<p>This function creates missing values under the missing complete at random (MCAR) mechanism. It is for demonstration purposes only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createNA(data, var.names = NULL, p = 0.3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createNA_+3A_data">data</code></td>
<td>
<p>A complete data frame.</p>
</td></tr>
<tr><td><code id="createNA_+3A_var.names">var.names</code></td>
<td>
<p>The names of variables where missing values will be generated.</p>
</td></tr>
<tr><td><code id="createNA_+3A_p">p</code></td>
<td>
<p>The proportion of missing values in the data frame or the proportions of missing values corresponding to the variables specified in <code>var.names</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with artificial missing values
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create 30% MCAR data across all variables in a dataset
withNA.df &lt;- createNA(data = iris, p = 0.3)

# Create 30% MCAR data in a specified variable in a dataset
withNA.df &lt;- createNA(data = iris, var.names = c("Sepal.Length"), p = 0.3)

# Create MCAR data in several specified variables in a dataset
withNA.df &lt;- createNA(
  data = iris,
  var.names = c("Sepal.Length", "Petal.Width", "Species"),
  p = c(0.3, 0.2, 0.1)
)
</code></pre>

<hr>
<h2 id='data_clean'>Data cleaning</h2><span id='topic+data_clean'></span>

<h3>Description</h3>

<p>The function 'data_clean()' serves the purpose of performing a preliminary check and fix some evident issues. However, the function cannot resolve all data quality-related problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_clean(rawdata, levels.tol = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_clean_+3A_rawdata">rawdata</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="data_clean_+3A_levels.tol">levels.tol</code></td>
<td>
<p>Tolerant proportion of the number of levels to the number of observations in a multiclass variable. Default: 0.2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A preliminary cleaned dataset
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rawdata &lt;- nhanes3

rawdata[4, 4] &lt;- NaN
rawdata[5, 5] &lt;- Inf
rawdata[6, 6] &lt;- -Inf

cleandata &lt;- data_clean(rawdata = rawdata)
</code></pre>

<hr>
<h2 id='default_params'>Auxiliary function for validating xgb.params</h2><span id='topic+default_params'></span>

<h3>Description</h3>

<p>Auxiliary function for setting up the default XGBoost-related hyperparameters for mixgb and checking the <code>xgb.params</code> argument in <code>mixgb()</code>. For more details on XGBoost hyperparameters, please refer to <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">XGBoost documentation on parameters</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default_params(
  device = "cpu",
  tree_method = "hist",
  eta = 0.3,
  gamma = 0,
  max_depth = 3,
  min_child_weight = 1,
  max_delta_step = 0,
  subsample = 0.7,
  sampling_method = "uniform",
  colsample_bytree = 1,
  colsample_bylevel = 1,
  colsample_bynode = 1,
  lambda = 1,
  alpha = 0,
  max_leaves = 0,
  max_bin = 256,
  num_parallel_tree = 1,
  nthread = -1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="default_params_+3A_device">device</code></td>
<td>
<p>Can be either <code>"cpu"</code> or <code>"cuda"</code>. For ther options please refer to <a href="https://xgboost.readthedocs.io/en/stable/parameter.html#general-parameters">XGBoost documentation on parameters</a>.</p>
</td></tr>
<tr><td><code id="default_params_+3A_tree_method">tree_method</code></td>
<td>
<p>Options: <code>"auto"</code>, <code>"exact"</code>, <code>"approx"</code>, and <code>"hist"</code>. Default: <code>"hist"</code>.</p>
</td></tr>
<tr><td><code id="default_params_+3A_eta">eta</code></td>
<td>
<p>Step size shrinkage. Default: 0.3.</p>
</td></tr>
<tr><td><code id="default_params_+3A_gamma">gamma</code></td>
<td>
<p>Minimum loss reduction required to make a further partition on a leaf node of the tree. Default: 0</p>
</td></tr>
<tr><td><code id="default_params_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum depth of a tree. Default: 3.</p>
</td></tr>
<tr><td><code id="default_params_+3A_min_child_weight">min_child_weight</code></td>
<td>
<p>Minimum sum of instance weight needed in a child. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_+3A_max_delta_step">max_delta_step</code></td>
<td>
<p>Maximum delta step. Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_+3A_subsample">subsample</code></td>
<td>
<p>Subsampling ratio of the data. Default: 0.7.</p>
</td></tr>
<tr><td><code id="default_params_+3A_sampling_method">sampling_method</code></td>
<td>
<p>The method used to sample the data. Default: <code>"uniform"</code>.</p>
</td></tr>
<tr><td><code id="default_params_+3A_colsample_bytree">colsample_bytree</code></td>
<td>
<p>Subsampling ratio of columns when constructing each tree. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_+3A_colsample_bylevel">colsample_bylevel</code></td>
<td>
<p>Subsampling ratio of columns for each level. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_+3A_colsample_bynode">colsample_bynode</code></td>
<td>
<p>Subsampling ratio of columns for each node. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_+3A_lambda">lambda</code></td>
<td>
<p>L2 regularization term on weights. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_+3A_alpha">alpha</code></td>
<td>
<p>L1 regularization term on weights. Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_+3A_max_leaves">max_leaves</code></td>
<td>
<p>Maximum number of nodes to be added (Not used when <code>tree_method = "exact"</code>). Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_+3A_max_bin">max_bin</code></td>
<td>
<p>Maximum number of discrete bins to bucket continuous features (Only used when <code>tree_method</code> is either <code>"hist"</code>, <code>"approx"</code> or <code>"gpu_hist"</code>). Default: 256.</p>
</td></tr>
<tr><td><code id="default_params_+3A_num_parallel_tree">num_parallel_tree</code></td>
<td>
<p>The number of parallel trees used for boosted random forests. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_+3A_nthread">nthread</code></td>
<td>
<p>The number of CPU threads to be used. Default: -1 (all available threads).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of hyperparameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>default_params()

xgb.params &lt;- list(device = "cuda", subsample = 0.9, nthread = 2)
default_params(device = xgb.params$device,
               subsample = xgb.params$subsample,
               nthread = xgb.params$nthread)

xgb.params &lt;- do.call("default_params", xgb.params)
xgb.params
</code></pre>

<hr>
<h2 id='default_params_cran'>Auxiliary function for validating xgb.params compatible with XGBoost CRAN version</h2><span id='topic+default_params_cran'></span>

<h3>Description</h3>

<p>Auxiliary function for setting up the default XGBoost-related hyperparameters for mixgb and checking the <code>xgb.params</code> argument in <code>mixgb()</code>. For more details on XGBoost hyperparameters, please refer to <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">XGBoost documentation on parameters</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default_params_cran(
  eta = 0.3,
  gamma = 0,
  max_depth = 3,
  min_child_weight = 1,
  max_delta_step,
  subsample = 0.7,
  sampling_method = "uniform",
  colsample_bytree = 1,
  colsample_bylevel = 1,
  colsample_bynode = 1,
  lambda = 1,
  alpha = 0,
  tree_method = "auto",
  max_leaves = 0,
  max_bin = 256,
  predictor = "auto",
  num_parallel_tree = 1,
  gpu_id = 0,
  nthread = -1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="default_params_cran_+3A_eta">eta</code></td>
<td>
<p>Step size shrinkage. Default: 0.3.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_gamma">gamma</code></td>
<td>
<p>Minimum loss reduction required to make a further partition on a leaf node of the tree. Default: 0</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum depth of a tree. Default: 3.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_min_child_weight">min_child_weight</code></td>
<td>
<p>Minimum sum of instance weight needed in a child. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_max_delta_step">max_delta_step</code></td>
<td>
<p>Maximum delta step. Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_subsample">subsample</code></td>
<td>
<p>Subsampling ratio of the data. Default: 0.7.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_sampling_method">sampling_method</code></td>
<td>
<p>The method used to sample the data. Default: <code>"uniform"</code>.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_colsample_bytree">colsample_bytree</code></td>
<td>
<p>Subsampling ratio of columns when constructing each tree. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_colsample_bylevel">colsample_bylevel</code></td>
<td>
<p>Subsampling ratio of columns for each level. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_colsample_bynode">colsample_bynode</code></td>
<td>
<p>Subsampling ratio of columns for each node. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_lambda">lambda</code></td>
<td>
<p>L2 regularization term on weights. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_alpha">alpha</code></td>
<td>
<p>L1 regularization term on weights. Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_tree_method">tree_method</code></td>
<td>
<p>Options: <code>"auto"</code>, <code>"exact"</code>, <code>"approx"</code>, and <code>"hist"</code>. Default: <code>"hist"</code>.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_max_leaves">max_leaves</code></td>
<td>
<p>Maximum number of nodes to be added (Not used when <code>tree_method = "exact"</code>). Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_max_bin">max_bin</code></td>
<td>
<p>Maximum number of discrete bins to bucket continuous features (Only used when <code>tree_method</code> is either <code>"hist"</code>, <code>"approx"</code> or <code>"gpu_hist"</code>). Default: 256.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_predictor">predictor</code></td>
<td>
<p>Default: <code>"auto"</code></p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_num_parallel_tree">num_parallel_tree</code></td>
<td>
<p>The number of parallel trees used for boosted random forests. Default: 1.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_gpu_id">gpu_id</code></td>
<td>
<p>Which GPU device should be used. Default: 0.</p>
</td></tr>
<tr><td><code id="default_params_cran_+3A_nthread">nthread</code></td>
<td>
<p>The number of CPU threads to be used. Default: -1 (all available threads).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of hyperparameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>default_params_cran()

xgb.params &lt;- list(subsample = 0.9, gpu_id = 1)
default_params_cran(subsample = xgb.params$subsample, gpu_id = xgb.params$gpu_id)

xgb.params &lt;- do.call("default_params_cran", xgb.params)
xgb.params
</code></pre>

<hr>
<h2 id='impute_new'>Impute new data with a saved <code>mixgb</code> imputer object</h2><span id='topic+impute_new'></span>

<h3>Description</h3>

<p>Impute new data with a saved <code>mixgb</code> imputer object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_new(
  object,
  newdata,
  initial.newdata = FALSE,
  pmm.k = NULL,
  m = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="impute_new_+3A_object">object</code></td>
<td>
<p>A saved imputer object created by <code>mixgb(..., save.models = TRUE)</code></p>
</td></tr>
<tr><td><code id="impute_new_+3A_newdata">newdata</code></td>
<td>
<p>A data.frame or data.table. New data with missing values.</p>
</td></tr>
<tr><td><code id="impute_new_+3A_initial.newdata">initial.newdata</code></td>
<td>
<p>Whether to use the information from the new data to initially impute the missing values of the new data. By default, this is set to <code>FALSE</code>, the original data passed to <code>mixgb()</code> will be used for initial imputation.</p>
</td></tr>
<tr><td><code id="impute_new_+3A_pmm.k">pmm.k</code></td>
<td>
<p>The number of donors for predictive mean matching. If <code>NULL</code> (the default), the <code>pmm.k</code> value in the saved imputer object will be used.</p>
</td></tr>
<tr><td><code id="impute_new_+3A_m">m</code></td>
<td>
<p>The number of imputed datasets. If <code>NULL</code> (the default), the <code>m</code> value in the saved imputer object will be used.</p>
</td></tr>
<tr><td><code id="impute_new_+3A_verbose">verbose</code></td>
<td>
<p>Verbose setting for mixgb. If <code>TRUE</code>, will print out the progress of imputation. Default: <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code>m</code> imputed datasets for new data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
n &lt;- nrow(nhanes3)
idx &lt;- sample(1:n, size = round(0.7 * n), replace = FALSE)
train.data &lt;- nhanes3[idx, ]
test.data &lt;- nhanes3[-idx, ]

params &lt;- list(max_depth = 3, subsample = 0.7, nthread = 2)
mixgb.obj &lt;- mixgb(data = train.data, m = 2, xgb.params = params, nrounds = 10,
                   save.models = TRUE, save.models.folder = tempdir())

# obtain m imputed datasets for train.data
train.imputed &lt;- mixgb.obj$imputed.data
train.imputed

# use the saved imputer to impute new data
test.imputed &lt;- impute_new(object = mixgb.obj, newdata = test.data)
test.imputed
</code></pre>

<hr>
<h2 id='mixgb'>Multiple imputation through XGBoost</h2><span id='topic+mixgb'></span>

<h3>Description</h3>

<p>This function is used to generate multiply-imputed datasets using XGBoost, subsampling and predictive mean matching (PMM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixgb(
  data,
  m = 5,
  maxit = 1,
  ordinalAsInteger = FALSE,
  pmm.type = NULL,
  pmm.k = 5,
  pmm.link = "prob",
  initial.num = "normal",
  initial.int = "mode",
  initial.fac = "mode",
  save.models = FALSE,
  save.vars = NULL,
  save.models.folder = NULL,
  verbose = F,
  xgb.params = list(),
  nrounds = 100,
  early_stopping_rounds = NULL,
  print_every_n = 10L,
  xgboost_verbose = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixgb_+3A_data">data</code></td>
<td>
<p>A data.frame or data.table with missing values</p>
</td></tr>
<tr><td><code id="mixgb_+3A_m">m</code></td>
<td>
<p>The number of imputed datasets. Default: 5</p>
</td></tr>
<tr><td><code id="mixgb_+3A_maxit">maxit</code></td>
<td>
<p>The number of imputation iterations. Default: 1</p>
</td></tr>
<tr><td><code id="mixgb_+3A_ordinalasinteger">ordinalAsInteger</code></td>
<td>
<p>Whether to convert ordinal factors to integers. By default, <code>ordinalAsInteger = FALSE</code>. Setting <code>ordinalAsInteger = TRUE</code> may speed up the imputation process for large datasets.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_pmm.type">pmm.type</code></td>
<td>
<p>The type of predictive mean matching (PMM). Possible values:
</p>

<ul>
<li> <p><code>NULL</code> (default): Imputations without PMM;
</p>
</li>
<li> <p><code>0</code>: Imputations with PMM type 0;
</p>
</li>
<li> <p><code>1</code>: Imputations with PMM type 1;
</p>
</li>
<li> <p><code>2</code>: Imputations with PMM type 2;
</p>
</li>
<li> <p><code>"auto"</code>: Imputations with PMM type 2 for numeric/integer variables; imputations without PMM for categorical variables.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mixgb_+3A_pmm.k">pmm.k</code></td>
<td>
<p>The number of donors for predictive mean matching. Default: 5</p>
</td></tr>
<tr><td><code id="mixgb_+3A_pmm.link">pmm.link</code></td>
<td>
<p>The link for predictive mean matching in binary variables
</p>

<ul>
<li> <p><code>"prob"</code> (default): use probabilities;
</p>
</li>
<li> <p><code>"logit"</code>: use logit values.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mixgb_+3A_initial.num">initial.num</code></td>
<td>
<p>Initial imputation method for numeric type data:
</p>

<ul>
<li> <p><code>"normal"</code> (default);
</p>
</li>
<li> <p><code>"mean"</code>;
</p>
</li>
<li> <p><code>"median"</code>;
</p>
</li>
<li> <p><code>"mode"</code>;
</p>
</li>
<li> <p><code>"sample"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mixgb_+3A_initial.int">initial.int</code></td>
<td>
<p>Initial imputation method for integer type data:
</p>

<ul>
<li> <p><code>"mode"</code> (default);
</p>
</li>
<li> <p><code>"sample"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mixgb_+3A_initial.fac">initial.fac</code></td>
<td>
<p>Initial imputation method for factor type data:
</p>

<ul>
<li> <p><code>"mode"</code> (default);
</p>
</li>
<li> <p><code>"sample"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mixgb_+3A_save.models">save.models</code></td>
<td>
<p>Whether to save imputation models for imputing new data later on. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="mixgb_+3A_save.vars">save.vars</code></td>
<td>
<p>For the purpose of imputing new data, the imputation models for response variables specified in <code>save.vars</code> will be saved. The values in <code>save.vars</code> can be a vector of names or indices. By default, only the imputation models for variables with missing values in the original data will be saved (<code>save.vars = NULL</code>). To save imputation models for all variables, users can specify <code>save.vars = colnames(data)</code>.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_save.models.folder">save.models.folder</code></td>
<td>
<p>Users can specify a directory to save all imputation models. Models will be saved in JSON format by internally calling <code>xgb.save()</code>, which is recommended by XGBoost.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_verbose">verbose</code></td>
<td>
<p>Verbose setting for mixgb. If <code>TRUE</code>, will print out the progress of imputation. Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_xgb.params">xgb.params</code></td>
<td>
<p>A list of XGBoost parameters. For more details, please check <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">XGBoost documentation on parameters</a>.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_nrounds">nrounds</code></td>
<td>
<p>The maximum number of boosting iterations for XGBoost. Default: 100</p>
</td></tr>
<tr><td><code id="mixgb_+3A_early_stopping_rounds">early_stopping_rounds</code></td>
<td>
<p>An integer value <code>k</code>. XGBoost training will stop if the validation performance has not improved for <code>k</code> rounds. Default: 10.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_print_every_n">print_every_n</code></td>
<td>
<p>Print XGBoost evaluation information at every nth iteration if <code>xgboost_verbose &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="mixgb_+3A_xgboost_verbose">xgboost_verbose</code></td>
<td>
<p>Verbose setting for XGBoost training: 0 (silent), 1 (print information) and 2 (print additional information). Default: 0</p>
</td></tr>
<tr><td><code id="mixgb_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to XGBoost</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>save.models = FALSE</code>, this function will return a list of <code>m</code> imputed datasets. If <code>save.models = TRUE</code>, it will return an object with imputed datasets, saved models and parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># obtain m multiply datasets without saving models
params &lt;- list(max_depth = 3, subsample = 0.7, nthread = 2)
mixgb.data &lt;- mixgb(data = nhanes3, m = 2, xgb.params = params, nrounds = 10)

# obtain m multiply imputed datasets and save models for imputing new data later on
mixgb.obj &lt;- mixgb(data = nhanes3, m = 2, xgb.params = params, nrounds = 10,
                   save.models = TRUE, save.models.folder = tempdir())
</code></pre>

<hr>
<h2 id='mixgb_cv'>Use cross-validation to find the optimal <code>nrounds</code></h2><span id='topic+mixgb_cv'></span>

<h3>Description</h3>

<p>Use cross-validation to find the optimal <code>nrounds</code> for an <code>Mixgb</code> imputer. Note that this method relies on the complete cases of a dataset to obtain the optimal <code>nrounds</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixgb_cv(
  data,
  nfold = 5,
  nrounds = 100,
  early_stopping_rounds = 10,
  response = NULL,
  select_features = NULL,
  xgb.params = list(),
  stringsAsFactors = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixgb_cv_+3A_data">data</code></td>
<td>
<p>A data.frame or a data.table with missing values.</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_nfold">nfold</code></td>
<td>
<p>The number of subsamples which are randomly partitioned and of equal size. Default: 5</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_nrounds">nrounds</code></td>
<td>
<p>The max number of iterations in XGBoost training. Default: 100</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_early_stopping_rounds">early_stopping_rounds</code></td>
<td>
<p>An integer value <code>k</code>. Training will stop if the validation performance has not improved for <code>k</code> rounds.</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_response">response</code></td>
<td>
<p>The name or the column index of a response variable. Default: <code>NULL</code> (Randomly select an incomplete variable).</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_select_features">select_features</code></td>
<td>
<p>The names or the indices of selected features. Default: <code>NULL</code> (Select all the other variables in the dataset).</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_xgb.params">xgb.params</code></td>
<td>
<p>A list of XGBoost parameters. For more details, please check <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">XGBoost documentation on parameters</a>.</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>A logical value indicating whether all character vectors in the dataset should be converted to factors.</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. Whether to print out cross-validation results during the process.</p>
</td></tr>
<tr><td><code id="mixgb_cv_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to XGBoost.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the optimal <code>nrounds</code>, <code>evaluation.log</code> and the chosen <code>response</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- list(max_depth = 3, subsample = 0.7, nthread = 2)
cv.results &lt;- mixgb_cv(data = nhanes3, xgb.params = params)
cv.results$best.nrounds

imputed.data &lt;- mixgb(data = nhanes3, m = 3, xgb.params = params,
                      nrounds = cv.results$best.nrounds)
</code></pre>

<hr>
<h2 id='nhanes3'>A small subset of the NHANES III (1988-1994) newborn data</h2><span id='topic+nhanes3'></span>

<h3>Description</h3>

<p>This dataset is a small subset of <code>nhanes3_newborn</code>. It is for demonstration purposes only. More information on NHANES III data can be found on <a href="https://wwwn.cdc.gov/Nchs/Data/Nhanes3/7a/doc/mimodels.pdf">https://wwwn.cdc.gov/Nchs/Data/Nhanes3/7a/doc/mimodels.pdf</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nhanes3)
</code></pre>


<h3>Format</h3>

<p>A data frame of 500 rows and 6 variables. Three variables have missing values.
</p>

<dl>
<dt>HSAGEIR</dt><dd><p>Age at interview (screener) - qty (months). An integer variable from 2 to 11.</p>
</dd>
<dt>HSSEX</dt><dd><p>Sex. A factor variable with levels 1 (Male) and 2 (Female).</p>
</dd>
<dt>DMARETHN</dt><dd><p>Race-ethnicity. A factor variable with levels 1 (Non-Hispanic white), 2 (Non-Hispanic black), 3 (Mexican-American) and 4 (Other).</p>
</dd>
<dt>BMPHEAD</dt><dd><p>Head circumference (cm). Numeric.</p>
</dd>
<dt>BMPRECUM</dt><dd><p>Recumbent length (cm). Numeric.</p>
</dd>
<dt>BMPWT</dt><dd><p>Weight (kg). Numeric.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx">https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx</a>
</p>


<h3>References</h3>

<p>U.S. Department of Health and Human Services
(DHHS).  National Center for Health Statistics.  Third National
Health and Nutrition Examination Survey (NHANES III, 1988-1994):
Multiply Imputed Data Set. CD-ROM, Series 11, No. 7A.
Hyattsville, MD: Centers for Disease Control and Prevention,
2001. Includes access software: Adobe Systems, Inc. Acrobat
Reader version 4.
</p>

<hr>
<h2 id='nhanes3_newborn'>NHANES III (1988-1994) newborn data</h2><span id='topic+nhanes3_newborn'></span>

<h3>Description</h3>

<p>This dataset is extracted from the NHANES III (1988-1994) for the age class <code>Newborn (under 1 year)</code>. Please note that this example dataset only contains selected variables and is for demonstration purposes only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nhanes3_newborn)
</code></pre>


<h3>Format</h3>

<p>A data frame of 2107 rows and 16 variables. Nine variables have missing values.
</p>

<dl>
<dt>HSHSIZER</dt><dd><p>Household size. An integer variable from 1 to 10.</p>
</dd>
<dt>HSAGEIR</dt><dd><p>Age at interview (screener) - qty (months). An integer variable from 2 to 11.</p>
</dd>
<dt>HSSEX</dt><dd><p>Sex. A factor variable with levels 1 (Male) and 2 (Female).</p>
</dd>
<dt>DMARACER</dt><dd><p>Race. A factor variable with levels 1 (White), 2 (Black) and 3 (Other).</p>
</dd>
<dt>DMAETHNR</dt><dd><p>Ethnicity. A factor variable with levels 1 (Mexican-American), 2 (Other Hispanic) and 3 (Not Hispanic).</p>
</dd>
<dt>DMARETHN</dt><dd><p>Race-ethnicity. A factor variable with levels 1 (Non-Hispanic white), 2 (Non-Hispanic black), 3 (Mexican-American) and 4 (Other).</p>
</dd>
<dt>BMPHEAD</dt><dd><p>Head circumference (cm). Numeric.</p>
</dd>
<dt>BMPRECUM</dt><dd><p>Recumbent length (cm). Numeric.</p>
</dd>
<dt>BMPSB1</dt><dd><p>First subscapular skinfold (mm). Numeric.</p>
</dd>
<dt>BMPSB2</dt><dd><p>Second subscapular skinfold (mm). Numeric.</p>
</dd>
<dt>BMPTR1</dt><dd><p>First triceps skinfold (mm). Numeric.</p>
</dd>
<dt>BMPTR2</dt><dd><p>Second triceps skinfold (mm). Numeric.</p>
</dd>
<dt>BMPWT</dt><dd><p>Weight (kg). Numeric.</p>
</dd>
<dt>DMPPIR</dt><dd><p>Poverty income ratio. Numeric.</p>
</dd>
<dt>HFF1</dt><dd><p>Does anyone who lives here smoke cigarettes in the home? A factor variable with levels 1 (Yes) and 2 (No).</p>
</dd>
<dt>HYD1</dt><dd><p>How is the health of subject person in general? An ordinal factor with levels 1 (Excellent), 2 (Very good), 3 (Good), 4 (Fair) and 5 (Poor).</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx">https://wwwn.cdc.gov/nchs/nhanes/nhanes3/datafiles.aspx</a>
</p>


<h3>References</h3>

<p>U.S. Department of Health and Human Services
(DHHS).  National Center for Health Statistics.  Third National
Health and Nutrition Examination Survey (NHANES III, 1988-1994):
Multiply Imputed Data Set. CD-ROM, Series 11, No. 7A.
Hyattsville, MD: Centers for Disease Control and Prevention,
2001. Includes access software: Adobe Systems, Inc. Acrobat
Reader version 4.
</p>

<hr>
<h2 id='pmm'>PMM for numeric or binary variable</h2><span id='topic+pmm'></span>

<h3>Description</h3>

<p>PMM for numeric or binary variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmm(yhatobs, yhatmis, yobs, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pmm_+3A_yhatobs">yhatobs</code></td>
<td>
<p>The predicted values of observed entries in a variable</p>
</td></tr>
<tr><td><code id="pmm_+3A_yhatmis">yhatmis</code></td>
<td>
<p>The predicted values of missing entries in a variable</p>
</td></tr>
<tr><td><code id="pmm_+3A_yobs">yobs</code></td>
<td>
<p>The actual observed values of observed entries in a variable</p>
</td></tr>
<tr><td><code id="pmm_+3A_k">k</code></td>
<td>
<p>The number of donors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The matched observed values of all missing entries
</p>

<hr>
<h2 id='pmm.multiclass'>PMM for multiclass variable</h2><span id='topic+pmm.multiclass'></span>

<h3>Description</h3>

<p>PMM for multiclass variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmm.multiclass(yhatobs, yhatmis, yobs, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pmm.multiclass_+3A_yhatobs">yhatobs</code></td>
<td>
<p>The predicted values of observed entries in a variable</p>
</td></tr>
<tr><td><code id="pmm.multiclass_+3A_yhatmis">yhatmis</code></td>
<td>
<p>The predicted values of missing entries in a variable</p>
</td></tr>
<tr><td><code id="pmm.multiclass_+3A_yobs">yobs</code></td>
<td>
<p>The actual observed values of observed entries in a variable</p>
</td></tr>
<tr><td><code id="pmm.multiclass_+3A_k">k</code></td>
<td>
<p>The number of donors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The matched observed values of all missing entries
</p>

<hr>
<h2 id='show_var'>Show multiply imputed values for a single variable</h2><span id='topic+show_var'></span>

<h3>Description</h3>

<p>Show m sets of imputed values for a specified variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_var(imputation.list, var.name, original.data, true.values = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="show_var_+3A_imputation.list">imputation.list</code></td>
<td>
<p>A list of <code>m</code> imputed datasets returned by the <code>mixgb</code> imputer.</p>
</td></tr>
<tr><td><code id="show_var_+3A_var.name">var.name</code></td>
<td>
<p>The name of a variable of interest.</p>
</td></tr>
<tr><td><code id="show_var_+3A_original.data">original.data</code></td>
<td>
<p>The original data with missing data.</p>
</td></tr>
<tr><td><code id="show_var_+3A_true.values">true.values</code></td>
<td>
<p>A vector of the true values (if known) of the missing values. In general, this is unknown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with <code>m</code> columns, each column represents the imputed values of all missing entries in the specified variable. If <code>true.values</code> is provided, the last column will be the true values of the missing values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#obtain m multiply datasets
library(mixgb)
mixgb.data &lt;- mixgb(data = nhanes3, m = 3)

imputed.BMPHEAD &lt;- show_var(imputation.list = mixgb.data, var.name = "BMPHEAD",
  original.data = nhanes3)
</code></pre>

<hr>
<h2 id='sortNA'>Sort data by increasing number of missing values</h2><span id='topic+sortNA'></span>

<h3>Description</h3>

<p>Sort data by increasing number of missing values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sortNA(data)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
