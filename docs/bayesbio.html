<!DOCTYPE html><html><head><title>Help for package bayesbio</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bayesbio}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#a_hat_mle'><p>Likelihood function of the James-Stein shrinkage factor.</p></a></li>
<li><a href='#allDups'><p>Identify all duplicates values in a vector.</p></a></li>
<li><a href='#bayesbio'><p>bayesbio: Miscellaneous functions useful in bioinformatics and Bayesian statistics</p></a></li>
<li><a href='#cbindFill'><p>cbind while converting missing entries to NA.</p></a></li>
<li><a href='#createStrings'><p>Creates random, unique character strings.</p></a></li>
<li><a href='#ggHorizBar'><p>Create a color-labeled horizontal bar plot in ggplot2.</p></a></li>
<li><a href='#jaccardSets'><p>Jaccard index of two character vectors.</p></a></li>
<li><a href='#mgsub'><p>Multiple pattern gsub.</p></a></li>
<li><a href='#nearestTime'><p>Merge data frames based on the nearest datetime differences.</p></a></li>
<li><a href='#nearestTimeandID'><p>Merge data frames based on the nearest datetime differences and an ID column. Also removes duplicate column names from the result.</p></a></li>
<li><a href='#p.adjust.nlp'><p>Adjust p-values where n is less than p.</p></a></li>
<li><a href='#pubmedQuery'><p>Perform PubMed queries on 2x2 combinations of term vectors.</p></a></li>
<li><a href='#subsupDiag'><p>Add values to the super- and sub-diagonals of a matrix.</p></a></li>
<li><a href='#unequalVarShrink'><p>Perform James-Stein shrinkage estimation using unequal variances</p></a></li>
<li><a href='#weightedShrink'><p>Weighted shrinkage estimation.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Miscellaneous Functions for Bioinformatics and Bayesian
Statistics</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A hodgepodge of hopefully helpful functions. Two of these perform
    shrinkage estimation: one using a simple weighted method where the user can
    specify the degree of shrinkage required, and one using James-Stein shrinkage
    estimation for the case of unequal variances.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, RISmed, testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-05-24 13:50:20 UTC; amckenz</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrew McKenzie [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrew McKenzie &lt;amckenz@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-05-24 16:32:42</td>
</tr>
</table>
<hr>
<h2 id='a_hat_mle'>Likelihood function of the James-Stein shrinkage factor.</h2><span id='topic+a_hat_mle'></span>

<h3>Description</h3>

<p>To be used in MLE computation of the James-Stein shrinkage factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>a_hat_mle(stat, vars, a_hat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="a_hat_mle_+3A_stat">stat</code></td>
<td>
<p>Input statistics to be shrinkage estimated.</p>
</td></tr>
<tr><td><code id="a_hat_mle_+3A_vars">vars</code></td>
<td>
<p>Corresponding variances of equal length.</p>
</td></tr>
<tr><td><code id="a_hat_mle_+3A_a_hat">a_hat</code></td>
<td>
<p>Shrinkage intensity to be estimated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The likelihood of the function given the parameters.
</p>


<h3>References</h3>

<p>http://projecteuclid.org/euclid.ss/1331729986
</p>

<hr>
<h2 id='allDups'>Identify all duplicates values in a vector.</h2><span id='topic+allDups'></span>

<h3>Description</h3>

<p>By default the base R function duplicated only identifies the duplicated values after the first in a vector as TRUE. This function identifies all of the duplicates as true.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allDups(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="allDups_+3A_x">x</code></td>
<td>
<p>The input vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector.
</p>

<hr>
<h2 id='bayesbio'>bayesbio: Miscellaneous functions useful in bioinformatics and Bayesian statistics</h2><span id='topic+bayesbio'></span><span id='topic+bayesbio-package'></span>

<h3>Description</h3>

<p>A hodgepodge of hopefully helpful functions. Two of these perform
shrinkage estimation: one using a simple weighted method where the user can
specify the degree of shrinkage required, and one using James-Stein shrinkage
estimation for the case of unequal variances.
</p>

<hr>
<h2 id='cbindFill'>cbind while converting missing entries to NA.</h2><span id='topic+cbindFill'></span>

<h3>Description</h3>

<p>cbind usually malfunctions on vector of unequal lengths; this function allows vectors of unequal length to be combined, while filling the missing entries with NAs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cbindFill(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cbindFill_+3A_...">...</code></td>
<td>
<p>A set of vectors separated by commas.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix that combines the inputted vectors.
</p>


<h3>References</h3>

<p>http://r.789695.n4.nabble.com/How-to-join-matrices-of-different-row-length-from-a-list-td3177212.html; http://stackoverflow.com/a/7962286/560791
</p>

<hr>
<h2 id='createStrings'>Creates random, unique character strings.</h2><span id='topic+createStrings'></span>

<h3>Description</h3>

<p>Makes them unique by randomly choosing the character strings; and, in case it is necessary, adding numbers to the end using make.unique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createStrings(number, length, upper = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createStrings_+3A_number">number</code></td>
<td>
<p>Specifies the number of character strings that should be created.</p>
</td></tr>
<tr><td><code id="createStrings_+3A_length">length</code></td>
<td>
<p>Specifies the length of each character string in letters.</p>
</td></tr>
<tr><td><code id="createStrings_+3A_upper">upper</code></td>
<td>
<p>Binary parameter specifying whether the character strings should be uppercase. Default = FALSE, so the character strings are all lowercase.</p>
</td></tr>
</table>


<h3>References</h3>

<p>http://stackoverflow.com/a/1439541/560791
</p>

<hr>
<h2 id='ggHorizBar'>Create a color-labeled horizontal bar plot in ggplot2.</h2><span id='topic+ggHorizBar'></span>

<h3>Description</h3>

<p>This function takes a data frame and creates a horizontal (by default) bar plot from it while ordering the values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggHorizBar(data_df, dataCol, namesCol, labelsCol, decreasing = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggHorizBar_+3A_data_df">data_df</code></td>
<td>
<p>Data frame with columns to specify the data values, the row names, and the fill colors of each of the bars.</p>
</td></tr>
<tr><td><code id="ggHorizBar_+3A_datacol">dataCol</code></td>
<td>
<p>The column name that specifies the values to be plotted.</p>
</td></tr>
<tr><td><code id="ggHorizBar_+3A_namescol">namesCol</code></td>
<td>
<p>The column name that specifies the corresponding names for each of the bar plots to be plotted.</p>
</td></tr>
<tr><td><code id="ggHorizBar_+3A_labelscol">labelsCol</code></td>
<td>
<p>The column name that specifies the groups of the labels.</p>
</td></tr>
<tr><td><code id="ggHorizBar_+3A_decreasing">decreasing</code></td>
<td>
<p>Logical specifying whether the values in dataCol should be in decreasing order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object, which can be plotted via the plot() function or saved via the ggsave() function.
</p>

<hr>
<h2 id='jaccardSets'>Jaccard index of two character vectors.</h2><span id='topic+jaccardSets'></span>

<h3>Description</h3>

<p>This function compares the elements in two character vectors to find the Jaccard index, i.e. the number of intersections divided by the total number of elements in both sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccardSets(set1, set2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccardSets_+3A_set1">set1</code></td>
<td>
<p>Character vector.</p>
</td></tr>
<tr><td><code id="jaccardSets_+3A_set2">set2</code></td>
<td>
<p>Character vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number (one-element numeric vector) specifying the Jaccard index from comparing the two sets.
</p>


<h3>References</h3>

<p>https://en.wikipedia.org/wiki/Jaccard_index
</p>

<hr>
<h2 id='mgsub'>Multiple pattern gsub.</h2><span id='topic+mgsub'></span>

<h3>Description</h3>

<p>An extension to gsub that handles vectors of patterns and replacements, avoiding recursion problems associated with overlap at the extense of computation time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mgsub(pattern, replacement, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mgsub_+3A_pattern">pattern</code></td>
<td>
<p>Character vector of patterns to match.</p>
</td></tr>
<tr><td><code id="mgsub_+3A_replacement">replacement</code></td>
<td>
<p>Character vector of replacements for each pattern.</p>
</td></tr>
<tr><td><code id="mgsub_+3A_x">x</code></td>
<td>
<p>Character vector in which the gsub should be performed.</p>
</td></tr>
<tr><td><code id="mgsub_+3A_...">...</code></td>
<td>
<p>Additional arguments to grep.</p>
</td></tr>
</table>


<h3>References</h3>

<p>http://stackoverflow.com/a/15254254/560791
</p>

<hr>
<h2 id='nearestTime'>Merge data frames based on the nearest datetime differences.</h2><span id='topic+nearestTime'></span>

<h3>Description</h3>

<p>Takes two data frames each with time/date columns in date-time or date format (i.e., able to be compared using the function difftime), finds the rows of df2 that minimize the absolute value of the datetime for each of the rows in df1, and merges the corresponding rows of df2 into df1 for downstream processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearestTime(df1, df2, timeCol1, timeCol2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nearestTime_+3A_df1">df1</code></td>
<td>
<p>Data frame containing the dates for which the differences between the other data frame's date column should be minimized for each row.</p>
</td></tr>
<tr><td><code id="nearestTime_+3A_df2">df2</code></td>
<td>
<p>Data frame containing the dates which should be compared to, as well as other values that should be merged to df1 per minimized date time.</p>
</td></tr>
<tr><td><code id="nearestTime_+3A_timecol1">timeCol1</code></td>
<td>
<p>Character vector specifying the date/time column in df1.</p>
</td></tr>
<tr><td><code id="nearestTime_+3A_timecol2">timeCol2</code></td>
<td>
<p>Character vector specifying the date/time column in df2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A merged data frame that minimizes datetime differences.
</p>

<hr>
<h2 id='nearestTimeandID'>Merge data frames based on the nearest datetime differences and an ID column. Also removes duplicate column names from the result.</h2><span id='topic+nearestTimeandID'></span>

<h3>Description</h3>

<p>Takes two data frames each with time/date columns in date-time or date format (i.e., able to be compared using the function difftime), finds the rows of df2 that minimize the absolute value of the datetime for each of the rows in df1, and merges the corresponding rows of df2 into df1 for downstream processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearestTimeandID(df1, df2, timeCol1, timeCol2, IDcol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nearestTimeandID_+3A_df1">df1</code></td>
<td>
<p>Data frame containing the dates for which the differences between the other data frame's date column should be minimized for each row.</p>
</td></tr>
<tr><td><code id="nearestTimeandID_+3A_df2">df2</code></td>
<td>
<p>Data frame containing the dates which should be compared to, as well as other values that should be merged to df1 per minimized date time.</p>
</td></tr>
<tr><td><code id="nearestTimeandID_+3A_timecol1">timeCol1</code></td>
<td>
<p>Character vector specifying the date/time column in df1.</p>
</td></tr>
<tr><td><code id="nearestTimeandID_+3A_timecol2">timeCol2</code></td>
<td>
<p>Character vector specifying the date/time column in df2.</p>
</td></tr>
<tr><td><code id="nearestTimeandID_+3A_idcol">IDcol</code></td>
<td>
<p>Must be unique by row in df1. Multiple versions are allowed (and expected at least in some rows, as that is the point of the function) in df2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A merged data frame that minimizes datetime differences.
</p>

<hr>
<h2 id='p.adjust.nlp'>Adjust p-values where n is less than p.</h2><span id='topic+p.adjust.nlp'></span>

<h3>Description</h3>

<p>This function recapitulates p.adjust but allows the number of hypothesis tests n to be less than the number of p-values p. Statistical properties of the p-value adjustments may not hold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.adjust.nlp(p, method = p.adjust.methods, n = length(p))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p.adjust.nlp_+3A_p">p</code></td>
<td>
<p>Numeric vector of p-values.</p>
</td></tr>
<tr><td><code id="p.adjust.nlp_+3A_method">method</code></td>
<td>
<p>Correction method.</p>
</td></tr>
<tr><td><code id="p.adjust.nlp_+3A_n">n</code></td>
<td>
<p>Number of comparisons to be made.</p>
</td></tr>
</table>


<h3>References</h3>

<p>http://stackoverflow.com/a/30110186/560791
</p>

<hr>
<h2 id='pubmedQuery'>Perform PubMed queries on 2x2 combinations of term vectors.</h2><span id='topic+pubmedQuery'></span>

<h3>Description</h3>

<p>Perform PubMed queries on the intersections of two character vectors. This function is a wrapper to RISmed::EUtilsSummary with type = 'esearch', db = 'pubmed'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pubmedQuery(rowTerms, colTerms, sleepTime = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pubmedQuery_+3A_rowterms">rowTerms</code></td>
<td>
<p>Character vector of terms that should make up the rows of the resulting mention count data frame.</p>
</td></tr>
<tr><td><code id="pubmedQuery_+3A_colterms">colTerms</code></td>
<td>
<p>Character vector of terms for the columns.</p>
</td></tr>
<tr><td><code id="pubmedQuery_+3A_sleeptime">sleepTime</code></td>
<td>
<p>How much time (in seconds) to sleep between successive PubMed queries. If you set this too low, PubMed may shut down your connection to prevent overloading their servers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of the number of mentions for each combination of terms.
</p>

<hr>
<h2 id='subsupDiag'>Add values to the super- and sub-diagonals of a matrix.</h2><span id='topic+subsupDiag'></span>

<h3>Description</h3>

<p>Takes a matrix and adds values to the values that are one above the diagonal (ie the superdiagonal) and the values that are one below the diagonal (ie the subdiagonal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsupDiag(matrix, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsupDiag_+3A_matrix">matrix</code></td>
<td>
<p>Matrix whose super- and sub-diagonals values should be replaced.</p>
</td></tr>
<tr><td><code id="subsupDiag_+3A_x">x</code></td>
<td>
<p>Numeric vector used to replace values in the matrix. If the inputted vector is not of the same length as both the super- and sub-diagonals of the matrix, then short vector recycling will occur (e.g., x can be one value to replace all of the super- and sub-diagonals of the matrix with that one value).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original matrix with the values added.
</p>


<h3>References</h3>

<p>http://stackoverflow.com/a/9885186/560791
</p>

<hr>
<h2 id='unequalVarShrink'>Perform James-Stein shrinkage estimation using unequal variances</h2><span id='topic+unequalVarShrink'></span>

<h3>Description</h3>

<p>Traditional JS shrinkage estimation assumes equal variances for each of the data points, while this algorithm extends JS shrinkage estimation to entries with different variances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unequalVarShrink(stat, vars, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unequalVarShrink_+3A_stat">stat</code></td>
<td>
<p>Input statistics to be shrinkage estimated.</p>
</td></tr>
<tr><td><code id="unequalVarShrink_+3A_vars">vars</code></td>
<td>
<p>Corresponding variances of equal length.</p>
</td></tr>
<tr><td><code id="unequalVarShrink_+3A_verbose">verbose</code></td>
<td>
<p>Whether information about the algorithm should be reported.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the shrinkage estimated statistics.
</p>


<h3>References</h3>

<p>http://projecteuclid.org/euclid.ss/1331729986
</p>

<hr>
<h2 id='weightedShrink'>Weighted shrinkage estimation.</h2><span id='topic+weightedShrink'></span>

<h3>Description</h3>

<p>Shrink values towards the mean (in the sample or the overall cohort) to an inverse degree to the confidence you assign to that observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedShrink(x, n, m = NULL, meanVal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedShrink_+3A_x">x</code></td>
<td>
<p>Numeric vector of values to be shrunken towards the mean.</p>
</td></tr>
<tr><td><code id="weightedShrink_+3A_n">n</code></td>
<td>
<p>Numeric vector with corresponding entries to x, specifying the number of observations used to calculate x, or some other confidence weight to associate with x.</p>
</td></tr>
<tr><td><code id="weightedShrink_+3A_m">m</code></td>
<td>
<p>Number specifying weight of the shrinkage estimation, relative to the number of observations in the input vector n. Defaults to the minimum of n, but this is an arbitrary value and should be explored to find an optimal value for your use case.</p>
</td></tr>
<tr><td><code id="weightedShrink_+3A_meanval">meanVal</code></td>
<td>
<p>Number specifying the overall mean towards which the values should be shrunken. Defaults to NULL, in which case it is calculated as the (non-weighted) arithmetic mean of the values in the inputted vector x.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector with shrunken data values.
</p>


<h3>References</h3>

<p>http://math.stackexchange.com/a/41513
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
