<!DOCTYPE html><html lang="en"><head><title>Help for package baytrends</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {baytrends}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#baytrends-package'><p>baytrends: Long Term Water Quality Trend Analysis</p></a></li>
<li><a href='#.appendDateFeatures'><p>Appends date features to data frame</p></a></li>
<li><a href='#.checkRange'><p>Check Data Range &ndash; function that checks for allowable values</p></a></li>
<li><a href='#.chkParameter'><p>Reduce dataframe and parameter list based on user selected parameterFilt</p></a></li>
<li><a href='#.ExpLNiCens'><p>Expectation maximization function: Log-normal case, i censured</p></a></li>
<li><a href='#.ExpLNlCens'><p>Expectation maximization function: Log-normal case, left censured</p></a></li>
<li><a href='#.ExpLNmCens'><p>Expectation maximization function: Log-normal case, Cens</p></a></li>
<li><a href='#.ExpLNrCens'><p>Expectation maximization function: Log-normal case, right censured</p></a></li>
<li><a href='#.ExpNiCens'><p>Expectation maximization function: Normal case, i censured</p></a></li>
<li><a href='#.ExpNlCens'><p>Expectation maximization function: Normal case, left censured</p></a></li>
<li><a href='#.ExpNmCens'><p>Expectation maximization function: Normal case</p></a></li>
<li><a href='#.ExpNrCens'><p>Expectation maximization function: Normal case, right censured</p></a></li>
<li><a href='#.F'><p>Print out figure title  (customization of pandoc.emphasis and pandoc.strong )</p></a></li>
<li><a href='#.findFile'><p>Find Recent File Information</p></a></li>
<li><a href='#.fmtPval'><p>Format pvalues</p></a></li>
<li><a href='#.gamANOVA'><p>Prepare ANOVA table for GAM analysis</p></a></li>
<li><a href='#.gamCoeff'><p>Prepare table of coefficients for GAM analysis</p></a></li>
<li><a href='#.gamDiffPORtbl'><p>Compute and present report on percent different for log-transformed data</p></a></li>
<li><a href='#.gamPlotCalc'><p>plots data and gam fit vs. time</p></a></li>
<li><a href='#.H'><p>Print out header (shortened pandoc.header)</p></a></li>
<li><a href='#.H1'><p>Print out 1st level header (shortened pandoc.header)</p></a></li>
<li><a href='#.H2'><p>Print out 2nd level header (shortened pandoc.header)</p></a></li>
<li><a href='#.H3'><p>Print out 3rd level header (shortened pandoc.header)</p></a></li>
<li><a href='#.H4'><p>Print out 4th level header (shortened pandoc.header)</p></a></li>
<li><a href='#.H5'><p>Print out 5th level header (shortened pandoc.header)</p></a></li>
<li><a href='#.initializeResults'><p>####</p>
Initialize stat.gam.result and chng.gam.result</a></li>
<li><a href='#.mergeFlow'><p>merge flow variable into analysis data frame and update iSpec with variable name</p></a></li>
<li><a href='#.mergeSalinity'><p>merge salinity into analysis data frame and update iSpec with variable name</p></a></li>
<li><a href='#.P'><p>Paragraph  (customization of pandoc.p)</p></a></li>
<li><a href='#.reAttDF'><p>Re-attribute df based on previous df</p></a></li>
<li><a href='#.T'><p>Print out table title (customization of pandoc.emphasis and pandoc.strong )</p></a></li>
<li><a href='#.V'><p>Print out text  (blended pandoc.emphasis, .verbatim, and .strong)</p></a></li>
<li><a href='#.vTable'><p>Print out character vector table in wrapped mode</p></a></li>
<li><a href='#analysisOrganizeData'><p>Analysis Organization &amp; Data Preparation</p></a></li>
<li><a href='#appendDateFeatures'><p>Append Date Features</p></a></li>
<li><a href='#baseDay'><p>Base Day</p></a></li>
<li><a href='#baseDay2decimal'><p>Base Day</p></a></li>
<li><a href='#closeOut'><p>Document Processing Time and Other Session Time</p></a></li>
<li><a href='#createResiduals'><p>Calculate GAM residuals</p></a></li>
<li><a href='#dataCensored'><p>Chesapeake Bay Program Monitoring Data, 1985-2016</p></a></li>
<li><a href='#dectime'><p>Decimal Time</p></a></li>
<li><a href='#dectime2Date'><p>Date Conversion</p></a></li>
<li><a href='#detrended.flow'><p>Create Seasonally Detrended Flow Data Set</p></a></li>
<li><a href='#detrended.salinity'><p>Create Seasonally Detrended Salinty Data Set</p></a></li>
<li><a href='#eventNum'><p>Event Processing</p></a></li>
<li><a href='#fillMissing'><p>Fill Missing Values</p></a></li>
<li><a href='#filterWgts'><p>Create filter weights</p></a></li>
<li><a href='#flwAveragePred'><p>Flow Averaged Predictions</p></a></li>
<li><a href='#gamDiff'><p>Compute an estimate of difference based on GAM results</p></a></li>
<li><a href='#gamPlotDisp'><p>Plot censored gam fits vs. time</p></a></li>
<li><a href='#gamPlotDispSeason'><p>Plot censored gam fits vs. time</p></a></li>
<li><a href='#gamTest'><p>Perform GAM analysis</p></a></li>
<li><a href='#gamTestSeason'><p>Perform GAM analysis for Specified Season</p></a></li>
<li><a href='#getUSGSflow'><p>Retrieve USGS daily flow data in a wide format</p></a></li>
<li><a href='#impute'><p>Impute Censored Values</p></a></li>
<li><a href='#imputeDF'><p>Impute Censored Values in dataframes</p></a></li>
<li><a href='#layerAggregation'><p>Aggregate data layers</p></a></li>
<li><a href='#layerLukup'><p>Layer List</p></a></li>
<li><a href='#loadData'><p>Load/Clean CSV and TXT Data File</p></a></li>
<li><a href='#loadExcel'><p>Load/Clean Excel sheet</p></a></li>
<li><a href='#loadModels'><p>Load Built-in GAM formulas</p></a></li>
<li><a href='#loadModelsResid'><p>Load Built-in GAM formulas for calculating residuals</p></a></li>
<li><a href='#makeSurvDF'><p>Convert dataframe to include survival (Surv) objects</p></a></li>
<li><a href='#na2miss'><p>Recode Data</p></a></li>
<li><a href='#nobs'><p>Compute the Number of Non-Missing Observations</p></a></li>
<li><a href='#parameterList'><p>Parameter List</p></a></li>
<li><a href='#sal'><p>Salinity data</p></a></li>
<li><a href='#saveDF'><p>Save R object to disk</p></a></li>
<li><a href='#seasAdjflow'><p>Create Daily Seasonally-adjusted Log Flow Residuals</p></a></li>
<li><a href='#selectData'><p>Select data for analysis from a larger data frame</p></a></li>
<li><a href='#stationMasterList'><p>Chesapeake Bay Program long-term tidal monitoring stations</p></a></li>
<li><a href='#unSurv'><p>Converts Surv object into a 3-column matrix</p></a></li>
<li><a href='#unSurvDF'><p>Converts Surv objects in a dataframe to &quot;lo&quot; and &quot;hi&quot; values</p></a></li>
<li><a href='#usgsGages'><p>USGS Gages</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Long Term Water Quality Trend Analysis</td>
</tr>
<tr>
<td>Description:</td>
<td>Enable users to evaluate long-term trends using a Generalized 
    Additive Modeling (GAM) approach. The model development includes selecting a 
    GAM structure to describe nonlinear seasonally-varying changes over time, 
    incorporation of hydrologic variability via either a river flow or salinity, 
    the use of an intervention to deal with method or laboratory changes 
    suspected to impact data values, and representation of left- and 
    interval-censored data. The approach has been applied to water quality data 
    in the Chesapeake Bay, a major estuary on the east coast of the United 
    States to provide insights to a range of management- and research-focused 
    questions.  Methodology described in Murphy (2019) 
    &lt;<a href="https://doi.org/10.1016%2Fj.envsoft.2019.03.027">doi:10.1016/j.envsoft.2019.03.027</a>&gt;.</td>
</tr>
<tr>
<td>Author:</td>
<td>Rebecca Murphy, Elgin Perry, Jennifer Keisman, Jon Harcum, Erik W Leppo</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.12</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Erik W Leppo &lt;Erik.Leppo@tetratech.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>dataRetrieval, digest, dplyr, fitdistrplus, grDevices,
lubridate, knitr, memoise, mgcv, pander, plyr, readxl,
sessioninfo, survival</td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, imputeTS, markdown, nlme, rmarkdown, testthat</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tetratech/baytrends">https://github.com/tetratech/baytrends</a>,
<a href="https://tetratech.github.io/baytrends/">https://tetratech.github.io/baytrends/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tetratech/baytrends/issues">https://github.com/tetratech/baytrends/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Collate:</td>
<td>analysisOrganizeData.R appendDateFeatures.R baytrends.R
checkRange.R chkParameter.R closeOut.R createResiduals.R data.R
detrended.flow.R detrended.salinity.R expectMaxFunctions.r
findFile.R flwAveragePred.R fmtPval.R gamDiff.R gamPlotCalc.r
gamPlotDisp.R gamPlotDispSeason.R gamTables.R gamTest.r
gamTestSeason.r getUSGSflow.R headers2.R imputeCensored.R
initializeResults.r layerAggregation.R loadData.R loadExcel.R
loadModels.R loadModelsResid.R makeSurvDF.R mergeFlow.R
mergeSalinity.R reAttDF.R saveDF.R seasAdjflow2.R selectData.R
smwrBase_baseDay.R smwrBase_baseDay2decimal.R
smwrBase_dectime.R smwrBase_dectime2Date.R
smwrBase_eventProcessing.R smwrBase_fillMissing.R
smwrBase_na2miss.R supportFunctions.R unSurv.R gdata_nobs.R
zzz.R</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-26 14:07:11 UTC; Erik.Leppo</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-26 14:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='baytrends-package'>baytrends: Long Term Water Quality Trend Analysis</h2><span id='topic+baytrends'></span><span id='topic+baytrends-package'></span>

<h3>Description</h3>

<p>The baytrends package was developed to enable users to evaluate long-term
trends in the Chesapeake Bay using a Generalized Additive Modeling (GAM)
approach. The model development includes selecting a GAM structure to
describe nonlinear seasonally-varying changes over time, incorporation of
hydrologic variability via either a river flow or salinity, the use of an
intervention to deal with method or laboratory changes suspected to impact
data values, and representation of left- and interval-censored data. This
approach, which is fully transferable to other systems, allows for Chesapeake
Bay water quality data to be evaluated in a statistically rigorous, yet
flexible way to provide insights to a range of management- and
research-focused questions. Methodology described in Murphy, RR, E Perry, 
J Harcum, and J Keisman  2019  A Generalized Additive Model approach to 
evaluating water quality: Chesapeake Bay case study.  Environmental Modelling
&amp; Software, 118 (2019) 1-13. 
&lt;https://doi.org/10.1016/j.envsoft.2019.03.027&gt;.
</p>


<h3>Details</h3>

<p>This software program is preliminary or provisional and is subject 
to revision. This software program is for testing only, no warranty, 
expressed or implied, is made as to the accuracy and functioning of the
program and related program material nor shall the fact of distribution 
constitute any such warranty, and no responsibility is assumed in connection 
therewith. This software is provided 'AS IS.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tetratech/baytrends">https://github.com/tetratech/baytrends</a>
</p>
</li>
<li> <p><a href="https://tetratech.github.io/baytrends/">https://tetratech.github.io/baytrends/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tetratech/baytrends/issues">https://github.com/tetratech/baytrends/issues</a>
</p>
</li></ul>


<hr>
<h2 id='.appendDateFeatures'>Appends date features to data frame</h2><span id='topic+.appendDateFeatures'></span>

<h3>Description</h3>

<p>Appends date features to data frame. Creates new column 'date' based on var
if date is not already in the data frame. The newly created (or existing)
date column is truncated to day. Columns for year, day of year (doy), decimal
year (dyear), and month are added based on date. This function relies on
smwrBase::baseDay and smwrBase::baseDay2decimal for doy and decimal year.
</p>
<p>The baseDay and baseDay2decimal functions have been added to this package 
from smwrBase package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.appendDateFeatures(df, var = "date")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".appendDateFeatures_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id=".appendDateFeatures_+3A_var">var</code></td>
<td>
<p>variable with stored date</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data frame with appended date features including year, doy,
decimal year, and month
</p>

<hr>
<h2 id='.checkRange'>Check Data Range &ndash; function that checks for allowable values</h2><span id='topic+.checkRange'></span>

<h3>Description</h3>

<p>Check Data Range &ndash; function that checks for allowable values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.checkRange(df, var, varScrn = NULL, numNA = FALSE, deleteOption = "pass")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".checkRange_+3A_df">df</code></td>
<td>
<p>Data frame with data to check</p>
</td></tr>
<tr><td><code id=".checkRange_+3A_var">var</code></td>
<td>
<p>Variable to perform screen check on</p>
</td></tr>
<tr><td><code id=".checkRange_+3A_varscrn">varScrn</code></td>
<td>
<p>Range to check (see examples)</p>
</td></tr>
<tr><td><code id=".checkRange_+3A_numna">numNA</code></td>
<td>
<p>How to treat missing numeric values (TRUE: treat as pass,
FALSE[default]: treat as fail)</p>
</td></tr>
<tr><td><code id=".checkRange_+3A_deleteoption">deleteOption</code></td>
<td>
<p>Option for how to return df (&quot;pass&quot;: return rows that
pass check, &quot;fail&quot;: return rows that fail check, &quot;mark&quot;: return column with
TRUE/FALSE for pass/fail)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame modified based on user selected options. see attributes
for screening results
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create an example data frame
df &lt;- data.frame(
       x1 = c("X1","Y2","A1","B2","C1", "X1","","A1","","C1"),
       x2 = seq(5, 14 ) + runif(10) ,
       x3 = as.POSIXct(c("1/10/2008", "1/21/2008", "3/1/2008", "3/26/1993",
                         "11/1/2012", "6/10/2000", "8/2/1990", "7/8/2005",
                         "1/6/2008", "9/11/2008"),
                         format="%m/%d/%Y"), stringsAsFactors =FALSE)
# add a few missing values
df[1,1]=NA
df[3,2]=NA
df[5,3]=NA
df

# establish allowable values for screening
x1Scrn &lt;- as.character(c("A1", "B2", "C1", "Y2"))   # character
x2Scrn &lt;- c(7,13)                                   # min/max value
x3Scrn &lt;- as.POSIXct(c("1999-01-01", "2008-09-10")) # min/max date 
# (POSIXct format)

# return df with new column indicating pass [TRUE] / fail [FALSE]
.checkRange(df, var="x1", varScrn=x1Scrn, numNA=FALSE, deleteOption='mark')
.checkRange(df, var="x2", varScrn=x2Scrn, numNA=FALSE, deleteOption='mark')
.checkRange(df, var="x3", varScrn=x3Scrn, numNA=FALSE, deleteOption='mark')

# return df with only rows that pass check
.checkRange(df, var="x1", varScrn=x1Scrn, numNA=FALSE, deleteOption='pass')
.checkRange(df, var="x2", varScrn=x2Scrn, numNA=FALSE, deleteOption='pass')
.checkRange(df, var="x3", varScrn=x3Scrn, numNA=FALSE, deleteOption='pass')
</code></pre>

<hr>
<h2 id='.chkParameter'>Reduce dataframe and parameter list based on user selected parameterFilt</h2><span id='topic+.chkParameter'></span>

<h3>Description</h3>

<p>Reduce dataframe and parameter list based on user selected parameterFilt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.chkParameter(df, parameterFilt = parameterFilt, parameterList)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".chkParameter_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id=".chkParameter_+3A_parameterfilt">parameterFilt</code></td>
<td>
<p>parameter filter</p>
</td></tr>
<tr><td><code id=".chkParameter_+3A_parameterlist">parameterList</code></td>
<td>
<p>parameter list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#df &lt;- chkParameter(df,parameterFilt=c("tn", "tp"))
</code></pre>

<hr>
<h2 id='.ExpLNiCens'>Expectation maximization function: Log-normal case, i censured</h2><span id='topic+.ExpLNiCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Log-normal case, i censured
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpLNiCens(l, u, mu, sigma, iCens = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpLNiCens_+3A_l">l</code></td>
<td>
<p>l</p>
</td></tr>
<tr><td><code id=".ExpLNiCens_+3A_u">u</code></td>
<td>
<p>u</p>
</td></tr>
<tr><td><code id=".ExpLNiCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpLNiCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
<tr><td><code id=".ExpLNiCens_+3A_icens">iCens</code></td>
<td>
<p>default=NA</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpLNlCens'>Expectation maximization function: Log-normal case, left censured</h2><span id='topic+.ExpLNlCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Log-normal case, left censured
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpLNlCens(l, u, mu, sigma, lCens = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpLNlCens_+3A_l">l</code></td>
<td>
<p>l</p>
</td></tr>
<tr><td><code id=".ExpLNlCens_+3A_u">u</code></td>
<td>
<p>u</p>
</td></tr>
<tr><td><code id=".ExpLNlCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpLNlCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
<tr><td><code id=".ExpLNlCens_+3A_lcens">lCens</code></td>
<td>
<p>default=NA</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpLNmCens'>Expectation maximization function: Log-normal case, Cens</h2><span id='topic+.ExpLNmCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Log-normal case, Cens
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpLNmCens(df, dep, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpLNmCens_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id=".ExpLNmCens_+3A_dep">dep</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id=".ExpLNmCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpLNmCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpLNrCens'>Expectation maximization function: Log-normal case, right censured</h2><span id='topic+.ExpLNrCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Log-normal case, right censured
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpLNrCens(l, u, mu, sigma, rCens = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpLNrCens_+3A_l">l</code></td>
<td>
<p>l</p>
</td></tr>
<tr><td><code id=".ExpLNrCens_+3A_u">u</code></td>
<td>
<p>u</p>
</td></tr>
<tr><td><code id=".ExpLNrCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpLNrCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
<tr><td><code id=".ExpLNrCens_+3A_rcens">rCens</code></td>
<td>
<p>default=NA</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpNiCens'>Expectation maximization function: Normal case, i censured</h2><span id='topic+.ExpNiCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Normal case, i censured
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpNiCens(l, u, mu, sigma, iCens = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpNiCens_+3A_l">l</code></td>
<td>
<p>l</p>
</td></tr>
<tr><td><code id=".ExpNiCens_+3A_u">u</code></td>
<td>
<p>u</p>
</td></tr>
<tr><td><code id=".ExpNiCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpNiCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
<tr><td><code id=".ExpNiCens_+3A_icens">iCens</code></td>
<td>
<p>default=NA</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpNlCens'>Expectation maximization function: Normal case, left censured</h2><span id='topic+.ExpNlCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Normal case, left censured
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpNlCens(l, u, mu, sigma, lCens = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpNlCens_+3A_l">l</code></td>
<td>
<p>l</p>
</td></tr>
<tr><td><code id=".ExpNlCens_+3A_u">u</code></td>
<td>
<p>u</p>
</td></tr>
<tr><td><code id=".ExpNlCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpNlCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
<tr><td><code id=".ExpNlCens_+3A_lcens">lCens</code></td>
<td>
<p>default=NA</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpNmCens'>Expectation maximization function: Normal case</h2><span id='topic+.ExpNmCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Normal case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpNmCens(df, dep, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpNmCens_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id=".ExpNmCens_+3A_dep">dep</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id=".ExpNmCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpNmCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
</table>

<hr>
<h2 id='.ExpNrCens'>Expectation maximization function: Normal case, right censured</h2><span id='topic+.ExpNrCens'></span>

<h3>Description</h3>

<p>Expectation maximization function: Normal case, right censured
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.ExpNrCens(l, u, mu, sigma, rCens = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".ExpNrCens_+3A_l">l</code></td>
<td>
<p>l</p>
</td></tr>
<tr><td><code id=".ExpNrCens_+3A_u">u</code></td>
<td>
<p>u</p>
</td></tr>
<tr><td><code id=".ExpNrCens_+3A_mu">mu</code></td>
<td>
<p>predicted values from mgcv::gam</p>
</td></tr>
<tr><td><code id=".ExpNrCens_+3A_sigma">sigma</code></td>
<td>
<p>model standard deviation</p>
</td></tr>
<tr><td><code id=".ExpNrCens_+3A_rcens">rCens</code></td>
<td>
<p>default=NA</p>
</td></tr>
</table>

<hr>
<h2 id='.F'>Print out figure title  (customization of pandoc.emphasis and pandoc.strong )</h2><span id='topic+.F'></span>

<h3>Description</h3>

<p>Print out figure title  (customization of pandoc.emphasis and pandoc.strong )
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.F(text, n = NULL, t = "e")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".F_+3A_text">text</code></td>
<td>
<p>text of figure title</p>
</td></tr>
<tr><td><code id=".F_+3A_n">n</code></td>
<td>
<p>figure number</p>
</td></tr>
<tr><td><code id=".F_+3A_t">t</code></td>
<td>
<p>emphasis or stong</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>text&lt;-"Hello World!"
.F(text)
.F(text, 4)
.F(text, 4,'e')
.F(text, 4,'s')
</code></pre>

<hr>
<h2 id='.findFile'>Find Recent File Information</h2><span id='topic+.findFile'></span>

<h3>Description</h3>

<p>Find recent file information based on folder and file name (allows for wildcard
structure)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.findFile(folder = ".", file = "*.*", n = 1, fileNameOnly = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".findFile_+3A_folder">folder</code></td>
<td>
<p>folder (i.e., directory to look in, can use relative path )</p>
</td></tr>
<tr><td><code id=".findFile_+3A_file">file</code></td>
<td>
<p>file (can use wildcards, e.g., &quot;*.csv&quot;)</p>
</td></tr>
<tr><td><code id=".findFile_+3A_n">n</code></td>
<td>
<p>number of files to return (e.g., value of 1 returns most recent
file, value of 'all' returns all files)</p>
</td></tr>
<tr><td><code id=".findFile_+3A_filenameonly">fileNameOnly</code></td>
<td>
<p>logical field, if TRUE only return file name</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used to search a selected directory for information
about the most recently modified files in that directory. The default
setting searches the current working directory. Relative directory
addresses can be used. The default settings returns the name of the most
recently modified file. Employing wildcards in the file argument can narrow
the file search, e.g., &quot;*.csv&quot; will only return comma delimited files.
</p>
<p>The default setting for the argument, n (of 1), will only return a single
file. This value can be increased to any number (2, 3,...) to change the
maximum number of files returned; or the argument can be set to 'all' to
return all files. Setting the argument, fileNameOnly, to FALSE will result
in returning additional file meta data related to file size, modified
date/time and create date/time.
</p>
<p>The results are in descending order of modified date/time.
</p>


<h3>Value</h3>

<p>returns file name as a character string
</p>


<h3>Examples</h3>

<pre><code class='language-R'># name of most recently modified file
## Not run: 
.findFile()         # current directory
.findFile("..")     # one directory up
#
# list of files and common attributes one directory up
.findFile(folder="..", file="*.*", n=2, fileNameOnly=FALSE)      
                                                       #two most recent files
.findFile(folder="..", file="*.*", n="all", fileNameOnly=FALSE)  #all files

## End(Not run)
</code></pre>

<hr>
<h2 id='.fmtPval'>Format pvalues</h2><span id='topic+.fmtPval'></span>

<h3>Description</h3>

<p>Format pvalues
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fmtPval(pval)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".fmtPval_+3A_pval">pval</code></td>
<td>
<p>pvalue to format</p>
</td></tr>
</table>

<hr>
<h2 id='.gamANOVA'>Prepare ANOVA table for GAM analysis</h2><span id='topic+.gamANOVA'></span>

<h3>Description</h3>

<p>Prepare ANOVA table for GAM analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.gamANOVA(gamo)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".gamANOVA_+3A_gamo">gamo</code></td>
<td>
<p>output from gam model</p>
</td></tr>
</table>

<hr>
<h2 id='.gamCoeff'>Prepare table of coefficients for GAM analysis</h2><span id='topic+.gamCoeff'></span>

<h3>Description</h3>

<p>Prepare table of coefficients for GAM analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.gamCoeff(lmo, iSpec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".gamCoeff_+3A_lmo">lmo</code></td>
<td>
<p>output from gam model</p>
</td></tr>
<tr><td><code id=".gamCoeff_+3A_ispec">iSpec</code></td>
<td>
<p>data frame with intervenList</p>
</td></tr>
</table>

<hr>
<h2 id='.gamDiffPORtbl'>Compute and present report on percent different for log-transformed data</h2><span id='topic+.gamDiffPORtbl'></span>

<h3>Description</h3>

<p>Compute and present report on percent different for log-transformed data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.gamDiffPORtbl(por.diff, iSpec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".gamDiffPORtbl_+3A_por.diff">por.diff</code></td>
<td>
<p>Output from gam.por.diff</p>
</td></tr>
<tr><td><code id=".gamDiffPORtbl_+3A_ispec">iSpec</code></td>
<td>
<p>data set specifications</p>
</td></tr>
</table>

<hr>
<h2 id='.gamPlotCalc'>plots data and gam fit vs. time</h2><span id='topic+.gamPlotCalc'></span>

<h3>Description</h3>

<p>plots data and gam fit vs. time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.gamPlotCalc(
  dep,
  tsdat,
  pgam,
  iSpec,
  analySpec,
  t.deriv = FALSE,
  alpha = 0.05,
  dayStep = 10,
  step.pt = "none",
  q.doy,
  flow.detrended = flow.detrended,
  salinity.detrended = salinity.detrended
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".gamPlotCalc_+3A_dep">dep</code></td>
<td>
<p>variable dep</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_tsdat">tsdat</code></td>
<td>
<p>variable tsdat</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_pgam">pgam</code></td>
<td>
<p>variable pgam</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_ispec">iSpec</code></td>
<td>
<p>variable iSpec</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_analyspec">analySpec</code></td>
<td>
<p>variable analySpec</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_t.deriv">t.deriv</code></td>
<td>
<p>variable t.deriv</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_alpha">alpha</code></td>
<td>
<p>variable alpha</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_daystep">dayStep</code></td>
<td>
<p>variable dayStep</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_step.pt">step.pt</code></td>
<td>
<p>variable step.pt</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_q.doy">q.doy</code></td>
<td>
<p>vector of days of year</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_flow.detrended">flow.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = flow.detrended.</p>
</td></tr>
<tr><td><code id=".gamPlotCalc_+3A_salinity.detrended">salinity.detrended</code></td>
<td>
<p>data generated by detrended.salinity.  Default = salinity.detrended.</p>
</td></tr>
</table>

<hr>
<h2 id='.H'>Print out header (shortened pandoc.header)</h2><span id='topic+.H'></span>

<h3>Description</h3>

<p>Print out header (shortened pandoc.header)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.H(text, n = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".H_+3A_text">text</code></td>
<td>
<p>text of header</p>
</td></tr>
<tr><td><code id=".H_+3A_n">n</code></td>
<td>
<p>header level number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.H("1st level header",1)
</code></pre>

<hr>
<h2 id='.H1'>Print out 1st level header (shortened pandoc.header)</h2><span id='topic+.H1'></span>

<h3>Description</h3>

<p>Print out 1st level header (shortened pandoc.header)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.H1(text)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".H1_+3A_text">text</code></td>
<td>
<p>text of header</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.H1("1st level header")
.H3("3rd level header")
</code></pre>

<hr>
<h2 id='.H2'>Print out 2nd level header (shortened pandoc.header)</h2><span id='topic+.H2'></span>

<h3>Description</h3>

<p>Print out 2nd level header (shortened pandoc.header)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.H2(text)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".H2_+3A_text">text</code></td>
<td>
<p>text of header</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.H2("2nd level header")
.H3("3rd level header")
</code></pre>

<hr>
<h2 id='.H3'>Print out 3rd level header (shortened pandoc.header)</h2><span id='topic+.H3'></span>

<h3>Description</h3>

<p>Print out 3rd level header (shortened pandoc.header)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.H3(text)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".H3_+3A_text">text</code></td>
<td>
<p>text of header</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.H2("2nd level header")
.H3("3rd level header")
</code></pre>

<hr>
<h2 id='.H4'>Print out 4th level header (shortened pandoc.header)</h2><span id='topic+.H4'></span>

<h3>Description</h3>

<p>Print out 4th level header (shortened pandoc.header)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.H4(text)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".H4_+3A_text">text</code></td>
<td>
<p>text of header</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.H2("2nd level header")
.H4("4th level header")
</code></pre>

<hr>
<h2 id='.H5'>Print out 5th level header (shortened pandoc.header)</h2><span id='topic+.H5'></span>

<h3>Description</h3>

<p>Print out 5th level header (shortened pandoc.header)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.H5(text)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".H5_+3A_text">text</code></td>
<td>
<p>text of header</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.H2("2nd level header")
.H5("5th level header")
</code></pre>

<hr>
<h2 id='.initializeResults'>####
Initialize stat.gam.result and chng.gam.result</h2><span id='topic+.initializeResults'></span>

<h3>Description</h3>

<p>####
Initialize stat.gam.result and chng.gam.result
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.initializeResults()
</code></pre>

<hr>
<h2 id='.mergeFlow'>merge flow variable into analysis data frame and update iSpec with variable name</h2><span id='topic+.mergeFlow'></span>

<h3>Description</h3>

<p>merge flow variable into analysis data frame and update iSpec with variable name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.mergeFlow(
  ct1 = ct1,
  iSpec = iSpec,
  gageID = gageID,
  hydro.var = hydro.var,
  flow.detrended = flow.detrended
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".mergeFlow_+3A_ct1">ct1</code></td>
<td>
<p>analysis data frame</p>
</td></tr>
<tr><td><code id=".mergeFlow_+3A_ispec">iSpec</code></td>
<td>
<p>iSpec</p>
</td></tr>
<tr><td><code id=".mergeFlow_+3A_gageid">gageID</code></td>
<td>
<p>&quot;q&quot; + USGS gage ID</p>
</td></tr>
<tr><td><code id=".mergeFlow_+3A_hydro.var">hydro.var</code></td>
<td>
<p>averaging windows</p>
</td></tr>
<tr><td><code id=".mergeFlow_+3A_flow.detrended">flow.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = flow.detrended.</p>
</td></tr>
</table>

<hr>
<h2 id='.mergeSalinity'>merge salinity into analysis data frame and update iSpec with variable name</h2><span id='topic+.mergeSalinity'></span>

<h3>Description</h3>

<p>merge salinity into analysis data frame and update iSpec with variable name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.mergeSalinity(
  ct1 = ct1,
  iSpec = iSpec,
  salinity.detrended = salinity.detrended
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".mergeSalinity_+3A_ct1">ct1</code></td>
<td>
<p>analysis data frame</p>
</td></tr>
<tr><td><code id=".mergeSalinity_+3A_ispec">iSpec</code></td>
<td>
<p>iSpec</p>
</td></tr>
<tr><td><code id=".mergeSalinity_+3A_salinity.detrended">salinity.detrended</code></td>
<td>
<p>data generated by detrended.salinity.  Default = detrended.salinity.</p>
</td></tr>
</table>

<hr>
<h2 id='.P'>Paragraph  (customization of pandoc.p)</h2><span id='topic+.P'></span>

<h3>Description</h3>

<p>Paragraph  (customization of pandoc.p)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.P(text = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".P_+3A_text">text</code></td>
<td>
<p>text of paragraph</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.P()
</code></pre>

<hr>
<h2 id='.reAttDF'>Re-attribute df based on previous df</h2><span id='topic+.reAttDF'></span>

<h3>Description</h3>

<p>Re-attribute df based on previous df. This is useful if you run a drop column command
run an aggregate function. This types of functions drop the attributes. This function
examines to original and new dfs and adds the attributes from the original df
to the new df whenever the new df doesn't have a particular attribute. (This navigates
around the issue of changed structure.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.reAttDF(df1, df0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".reAttDF_+3A_df1">df1</code></td>
<td>
<p>new data frame</p>
</td></tr>
<tr><td><code id=".reAttDF_+3A_df0">df0</code></td>
<td>
<p>old data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create data frame
df0 &lt;- data.frame (sta=c("A","A"), lay=c("B","C"), x1 =c(NA,2), x2 =c( 4,14))

#add simple attribute
attr(df0, "Attribute1") &lt;- "Test attribute1"

#run aggregate -- loose attributes
df1 &lt;- aggregate(x2 ~ sta, data=df0, mean, na.action=na.pass, na.rm=TRUE)
df2 &lt;- .reAttDF(df1, df0)
</code></pre>

<hr>
<h2 id='.T'>Print out table title (customization of pandoc.emphasis and pandoc.strong )</h2><span id='topic+.T'></span>

<h3>Description</h3>

<p>Print out table title (customization of pandoc.emphasis and pandoc.strong )
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.T(text, n = NULL, t = "e")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".T_+3A_text">text</code></td>
<td>
<p>text of table title</p>
</td></tr>
<tr><td><code id=".T_+3A_n">n</code></td>
<td>
<p>table number</p>
</td></tr>
<tr><td><code id=".T_+3A_t">t</code></td>
<td>
<p>emphasis or stong</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>text&lt;-"Hello World!"
.T(text)
.T(text, 4)
.T(text, 4,'e')
.T(text, 4,'s')
</code></pre>

<hr>
<h2 id='.V'>Print out text  (blended pandoc.emphasis, .verbatim, and .strong)</h2><span id='topic+.V'></span>

<h3>Description</h3>

<p>Print out text  (blended pandoc.emphasis, .verbatim, and .strong)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.V(text = " ", t = "v")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".V_+3A_text">text</code></td>
<td>
<p>text</p>
</td></tr>
<tr><td><code id=".V_+3A_t">t</code></td>
<td>
<p>emphasis or stong or verbatim</p>
</td></tr>
</table>


<h3>Value</h3>

<p>n/a
</p>


<h3>See Also</h3>

<p>.F .H .H2 .H3 .H4 .P .T .V
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.V("Hello World!",'v')
.V("Hello World!",'e')
.V("Hello World!",'s')
.V("Hello World!")
</code></pre>

<hr>
<h2 id='.vTable'>Print out character vector table in wrapped mode</h2><span id='topic+.vTable'></span>

<h3>Description</h3>

<p>Print out character vector table in wrapped mode
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.vTable(x = c(" "), width = 65)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".vTable_+3A_x">x</code></td>
<td>
<p>character vector</p>
</td></tr>
<tr><td><code id=".vTable_+3A_width">width</code></td>
<td>
<p>wrap width [default=65]</p>
</td></tr>
</table>

<hr>
<h2 id='analysisOrganizeData'>Analysis Organization &amp; Data Preparation</h2><span id='topic+analysisOrganizeData'></span>

<h3>Description</h3>

<p>This function assesses the user supplied specifications in the argument,
analySpec, and prepares the data (argument df) for analysis. In those cases
where the user doesn't supply a needed specification, a basic option is
supplied by this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analysisOrganizeData(
  df,
  analySpec = list(),
  reports = c(0, 1, 2, 3, 4),
  parameterList = NA,
  stationMasterList = NA,
  layerLukup = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="analysisOrganizeData_+3A_df">df</code></td>
<td>
<p>Data frame of water quality data</p>
</td></tr>
<tr><td><code id="analysisOrganizeData_+3A_analyspec">analySpec</code></td>
<td>
<p>Specifications for analysis</p>
</td></tr>
<tr><td><code id="analysisOrganizeData_+3A_reports">reports</code></td>
<td>
<p>Optional reports about parameters, layers and stations
[default = c(0,1,2,3)]</p>
</td></tr>
<tr><td><code id="analysisOrganizeData_+3A_parameterlist">parameterList</code></td>
<td>
<p>User-supplied dataframe with list of parameters [default
= NA]</p>
</td></tr>
<tr><td><code id="analysisOrganizeData_+3A_stationmasterlist">stationMasterList</code></td>
<td>
<p>User-supplied dataframe with list of stations
[default = NA]</p>
</td></tr>
<tr><td><code id="analysisOrganizeData_+3A_layerlukup">layerLukup</code></td>
<td>
<p>User-supplied dataframe with list of layers [default = NA]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The supplied data frame, df, is a data frame with the variables station,
date, and layer included along with multiple additional columns for a
variety of water quality variables structured as numeric fields or 
survival::Surv objects. An example data frame, dataCensored, is included
with baytrends as an example.
</p>
<p>The argument, analySpec, is a list that includes basic specifications for
performing GAM analyses. The components in analySpec are identified below.
The user may create analySpec (which can include all or some of the below
components; and pass the user-supplied analySpec to this function. Or, the
user may accept the default argument and allow analysisOrganizeData to
create and return analySpec. If the user passes a user-supplied analySpec,
then analysisOrganizeData will &quot;fill in&quot; required arguments not provided by
the user. The user can also adjust analySpec after it is returned from
analysisOrganizeData although requirements for down selecting the data frame,
df, or aggregating data by layer would need to be passed to analysisOrganizeData.    
</p>
<p>The default setting for the argument report is to provide tabular summary
reports about the parameters, stations, and layers to be analyzed. Setting
report=NA will suppress the tabular summary reports.
</p>
<p>The user can supply their own parameterList, stationMasterList, or
layerLukup data sets; or the user can use the example data frames included
with baytrends.
</p>
<p>The following steps are performed by analysisOrganizeData:
</p>
<p>1) Review user supplied specifications through the analySpec argument. Fill
in with default values. For example, if the user doesn't specify a dataframe
with a list of stations, parameters, or layers, then the built-in data
frames, baytrends::stationMasterList, baytrends::parameterList, and
baytrends::layerLukup are used. Some other default values include the
following: date range (1/1/1984-present), parameter list (all parameters in
data set parameterList), layers (all layers in data set layerLukup), layer
aggregation option (0, no aggregation), minimum number of observations to
perform a GAM analysis (60), GAM formulas (Linear Trend with Seasonality,
Non-linear Trend with Seasonality, and Non-linear trend with Seasonality
(plus Interactions)), GAM alpha level for plots and output (0.05), periods
for multi-time period analyses using GAM (Full Record, 1999/00-Present, and
2005/06-Present), and seasons for sub-annual analyses using GAM (All,
Spring1, Spring2, Summer1, Summer2, SAV1, SAV2, Winter, and Fall.)
</p>
<p>2) Based on the settings in analySpec, the data frame df, is down selected
based on parameters, stations, dates, and layers. A dependent variable list
(depVarList) is created that includes variable descriptions, units, and log
transformation selections. A station list (stationList) is created that
includes the station ID, a selected USGS gage for correlating flow, and
latitude/longitude.  
</p>
<p>3) Aggregate data layers. If analySpec$layerAggOption is equal to 0, then
there is no aggregation. The analySpec$layerAggOption of 1 would result in
averaging (mean) surface and above pycnocline data. In this example, records
with layer = &quot;S&quot; and layer = &quot;AP&quot; are relabeled as &quot;SAP&quot;. Other
layerAggOption values are 2) &quot;B&quot;&amp;&quot;BP&quot;; 3) &quot;S&quot;&amp;&quot;AP&quot; and &quot;B&quot;&amp;&quot;BP&quot;; 4) all
layers; and 5) &quot;S&quot;&amp;&quot;B&quot;, respectively. A layer list (layerList) is created
and returned.
</p>
<p>4) Data are then averaged (mean) by date.  
</p>
<p>5) Date features are added. Columns for year, day of year (doy), decimal
year (dyear), and month are added based on date. Note that the doy is based on 
a 366 day calendar regardless of leap year.
</p>
<p>6) Reports on the number of records (0), parameters (1), layers (2) and
stations (3) can be controlled with the reports option.
</p>


<h3>Value</h3>

<p>Returns a list. Use dfr[[&quot;df&quot;]] and dfr[[&quot;analySpec&quot;]] to extract
updated data frame and updated (or created) analySpec. analySpec is a list
that includes the following components:
</p>
<p>analyTitle       - Analysis trend title
</p>
<p>parameterFilt    - Parameter filter used for data down selection
</p>
<p>stationFilt      - Station filter used for data down selection
</p>
<p>dateFilt         - Date filter for data down selection (default =  c( as.POSIXct('1984-01-01')
, as.POSIXct(Sys.time())))
</p>
<p>setTZ            - time zone (default = &quot;America/New_York&quot;)
</p>
<p>layerFilt        - Layer filter
</p>
<p>layerAggOption   - Layer averaging option (default = 0). Other options are:
1: combine &quot;S&quot; &amp; &quot;AP&quot; (&quot;SAP&quot;); 2: combine &quot;B&quot; &amp; &quot;BP&quot; (&quot;BBP&quot;); 3: opt 1 &amp; 2
(&quot;SAP&quot;, &quot;BBP&quot;); 4: combine all (&quot;ALL&quot;)); 5: combine &quot;S&quot; and &quot;B&quot; (&quot;SB&quot;)
</p>
<p>obsMin           - Minimum number of observations required to allow GAM
analysis to proceed for a specific station, parameter, and layer
combination (default = 60).
</p>
<p>obsMinInter      - Minimum number of observations required to allow GAM
analysis to proceed for a specific intervention (default = 10).
</p>
<p>gamAlpha         - Alpha level used GAM analyses (default = 0.05).
</p>
<p>censorTrim       - Values to apply for trimming data due to too much
censoring (default = c(0.5, 0.4)). First argument indicates fraction of
observations in a year that are allowed to be censored. Second argument is
the fraction of years, starting from the beginning of the record, that are
allowed to be &quot;flagged&quot; for too much censoring. A minimum of two years must
have too much censoring before data are removed. The default settings can
be read as no more than 40 percent of the beginning years of data are
allowed to have more than 50 percent censoring before the beginning portion
of the record is trimmed. For example, years 1 and 3 of data have more than
50 percent censoring then the first three years of data are trimmed.
Similarly, for years 1 and 4, then the first four years are removed. If
years 1 and 5 have more than 50 percent censoring the data are kept since
2/5 is not greater than 0.4. Changing this setting to, say, c(0.2,0.4) would require
that 80
</p>
<p>gamModels        - model formulations. See baytrends::loadModels() for 
simplified approach for selecting which built-in models to include
</p>
<p>showGamNumOnPlot	- Show gam option (i.e., 0-6) on gam plots (TRUE/FALSE)
</p>
<p>gamDiffPeriods   - list of time periods (years) used for computing changes
(differences). The default options are: full record, 1999/00-present, and
2005/06-present.  
</p>
<p>gamDiffSeasons   - list List of seasons used for sub-annual analyses of
computing differences. The default options include the following: All
(months 1:12), Spring1 (3:5), Spring2 (months: 4:6)), Summer1 (months:
6:9)), Summer2 (months: 7:9)), SAV1 (months: 4:10)), SAV2 (months:
3:5,9:11)), Winter (months: 1:2)), and Fall (months: 10:12))).
</p>
<p>gamDiffNumChgYrs - number of years to use in computing differences.
</p>
<p>gamPenalty       - allow the user to set the mgcv::gam select argument to
TRUE, FALSE, or baytrend algorithm default (default = NA). When the default
option is specified, then the mgcv::gam select argument is set to FALSE
when none of the data are censored; otherwise (when some censoring exists
in the data set) the select argument is set to TRUE
</p>
<p>gamPenaltyCrit   - edf and F-stat values used to flag ANOVA table results
(default = c(1, 9e9))
</p>
<p>gamCoeffDeltaMaxCrit - convergence criteria for expectation maximization
(default = 1e-6)
</p>
<p>gamFlw_Sal.Wgt.Perc - percentiles of flow [or salinity] to use for
computing flow [salinity] averaged result (default = c(0.05, 0.25, 0.50,
0.75, 0.95))
</p>
<p>gamLegend        - default settings for gam figure legend
</p>
<p>idVar            - primary key for data frame returned as df
</p>
<p>depVarList       - data frame of dependent variables (useful for setting up gam analyses in for loops)
</p>
<p>stationList      - data frame of stations (useful for setting up gam analyses in for loops)
</p>
<p>layerList        - data frame of layers (useful for setting up gam analyses in for loops)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># run analysis relying on default specifications, examine analySpec for
# default options
dfr &lt;- analysisOrganizeData(dataCensored)
df        &lt;- dfr[["df"]]
analySpec &lt;- dfr[["analySpec"]]

# analyze bottom dissolved oxygen at 2 stations using only data from 1/1/1995-12/31/2015
analySpec &lt;-list()
analySpec$parameterFilt &lt;- c('do')
analySpec$layerFilt     &lt;- c('B')
analySpec$stationFilt   &lt;- c('CB3.3C', 'CB5.4')
analySpec$dateFilt      &lt;- as.POSIXct(c("1995-01-01", "2015-12-31"))
dfr &lt;- analysisOrganizeData(dataCensored, analySpec)
df        &lt;- dfr[["df"]]
analySpec &lt;- dfr[["analySpec"]]

</code></pre>

<hr>
<h2 id='appendDateFeatures'>Append Date Features</h2><span id='topic+appendDateFeatures'></span>

<h3>Description</h3>

<p>Appends date features to data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>appendDateFeatures(df, var = "date")
</code></pre>

<hr>
<h2 id='baseDay'>Base Day</h2><span id='topic+baseDay'></span>

<h3>Description</h3>

<p>Computes the base day of the year, a reference value that can be 
used to group days for the computation of summary statistics.  From smwrBase package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>baseDay(x, numeric = TRUE, year = c("calendar", "water", "climate"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="baseDay_+3A_x">x</code></td>
<td>
<p>a vector of class POSIXt, Dates, or character that represents a
date. Missing values are permitted.</p>
</td></tr>
<tr><td><code id="baseDay_+3A_numeric">numeric</code></td>
<td>
<p>a logical value; <code>TRUE</code> means return the numeric value
of the day, <code>FALSE</code> means return a factor.</p>
</td></tr>
<tr><td><code id="baseDay_+3A_year">year</code></td>
<td>
<p>a character string indicating the basis of the factor levels. See
<b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The base day is computed such that all dates have the same reference value
regardless of whether the year is a leap year or not. If <code>year</code> is 
&quot;calendar,&quot; then the factor levels or day number begin on January 1; if <code>year</code> is
&quot;water,&quot; then the factor levels or day number begin on October 1; and if <code>year</code> is
&quot;climate,&quot; then the factor levels or day number begin on April 1.
</p>


<h3>Value</h3>

<p>An integer value representing the base day number if <code>numeric</code>
is <code>TRUE</code>. Otherwise a factor with levels for every day of the year.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The default numeric result
baseDay(c("2000-02-29", "2000-03-01", "2001-03-01"))
# The result as a factor
baseDay(c("2000-02-29", "2000-03-01", "2001-03-01"), numeric=FALSE)
</code></pre>

<hr>
<h2 id='baseDay2decimal'>Base Day</h2><span id='topic+baseDay2decimal'></span>

<h3>Description</h3>

<p>Computes the decimal time representation of the base day of the year.  
From smwrBase package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>baseDay2decimal(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="baseDay2decimal_+3A_x">x</code></td>
<td>
<p>a vector of baseDay values, character, or factors of the form month 
abbreviation and day number, generally created from <code>baseDay</code>. Missing 
values are permitted and result in missing values in the output. Unmatched 
values also result in missing values in the output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the base day.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+baseDay">baseDay</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The baseDay ordered by calendar year
bd.tmp &lt;- baseDay(c("2000-02-29", "2000-03-01", "2001-03-01"), 
  numeric=FALSE)
baseDay2decimal(bd.tmp)
# ordered by water year, result should agree
bd.tmp &lt;- baseDay(c("2000-02-29", "2000-03-01", "2001-03-01"), 
  numeric=FALSE, year="water")
baseDay2decimal(bd.tmp)
</code></pre>

<hr>
<h2 id='closeOut'>Document Processing Time and Other Session Time</h2><span id='topic+closeOut'></span>

<h3>Description</h3>

<p>Document Processing Time and Other Session Time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>closeOut(timeProcess = TRUE, contInfo = TRUE, sessInfo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="closeOut_+3A_timeprocess">timeProcess</code></td>
<td>
<p>Processing time</p>
</td></tr>
<tr><td><code id="closeOut_+3A_continfo">contInfo</code></td>
<td>
<p>Contact information</p>
</td></tr>
<tr><td><code id="closeOut_+3A_sessinfo">sessInfo</code></td>
<td>
<p>Session information</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Reports out processing time, contact information,
and session information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>closeOut()
</code></pre>

<hr>
<h2 id='createResiduals'>Calculate GAM residuals</h2><span id='topic+createResiduals'></span>

<h3>Description</h3>

<p>Use GAM analysis to compute residuals. Relies on mgcv::gam to perform general
additive model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createResiduals(
  df,
  dep,
  residualModel = "doy_flw_sal",
  analySpec = analySpec,
  gamTable = FALSE,
  gamPlot = FALSE,
  flow.detrended = NA,
  salinity.detrended = NA,
  width = 10,
  height = 3.5,
  folder_r = "pltResiduals",
  ProjRoot
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createResiduals_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_dep">dep</code></td>
<td>
<p>variable</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_residualmodel">residualModel</code></td>
<td>
<p>which gam formula is used to compute. 
Default = 'doy_flw_sal'</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_gamtable">gamTable</code></td>
<td>
<p>gam table setting (set to FALSE to turn off table output)
Default = FALSE</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_gamplot">gamPlot</code></td>
<td>
<p>gam plot setting (set to FALSE to turn off plotting)
Default = FALSE</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_flow.detrended">flow.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = NA</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_salinity.detrended">salinity.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = NA</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_width">width</code></td>
<td>
<p>width of png figure (inches). Default = 10</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_height">height</code></td>
<td>
<p>height of png figure (inches). Default = 3.5</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_folder_r">folder_r</code></td>
<td>
<p>folder to store residual plots</p>
</td></tr>
<tr><td><code id="createResiduals_+3A_projroot">ProjRoot</code></td>
<td>
<p>Root folder for project.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns df with appended column of data
</p>

<hr>
<h2 id='dataCensored'>Chesapeake Bay Program Monitoring Data, 1985-2016</h2><span id='topic+dataCensored'></span>

<h3>Description</h3>

<p>Selected 1985-2016 data for eight (8) stations from the
Chesapeake Bay Monitoring Program. Water quality variables are stored as
either class 'num' for variables with no censoring or class 'Surv' 
(see survival::Surv) that allows for left- and interval-censored data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataCensored
</code></pre>


<h3>Format</h3>

<p>A data frame with 13,062 rows and 17 variables:
</p>

<dl>
<dt>station</dt><dd><p>station identifier</p>
</dd>
<dt>date</dt><dd><p>sample date</p>
</dd>
<dt>layer</dt><dd><p>sample layer</p>
</dd>
<dt>secchi</dt><dd><p>Secchi depth [m]</p>
</dd>
<dt>salinity</dt><dd><p>Salinity [ppt]</p>
</dd>
<dt>do</dt><dd><p>Dissolved Oxygen [mg/L]</p>
</dd>
<dt>wtemp</dt><dd><p>Water Temperature [deg C]</p>
</dd>
<dt>chla</dt><dd><p>Corrected Chlorophyll-a [ug/L]</p>
</dd>
<dt>tn</dt><dd><p>Total Nitrogen [mg/L]</p>
</dd>
<dt>tp</dt><dd><p>Total Phosphorus [mg/L]</p>
</dd>
<dt>tss</dt><dd><p>Total Suspended Solids [mg/L]</p>
</dd>
<dt>din</dt><dd><p>Dissolved Inorganic Nitrogen [mg/L]</p>
</dd>
<dt>po4</dt><dd><p>Orthophosphorus [mg/L]</p>
</dd>
<dt>tdn</dt><dd><p>Total Dissolved Nitrogen [mg/L]</p>
</dd>
<dt>tdp</dt><dd><p>Total Dissolved Phosphorus [mg/L]</p>
</dd>
<dt>nh4</dt><dd><p>Ammonium [mg/L]</p>
</dd>
<dt>no23</dt><dd><p>Nitrite + Nitrate [mg/L]</p>
</dd>
</dl>


<hr>
<h2 id='dectime'>Decimal Time</h2><span id='topic+dectime'></span>

<h3>Description</h3>

<p>Convert date/time data to be expressed as year and fractional part of year. This
can be useful for plotting or representing time in a regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dectime(
  dates,
  times,
  time.format,
  date.format,
  Date.noon = TRUE,
  year.type = c("calendar", "water", "climate")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dectime_+3A_dates">dates</code></td>
<td>
<p>a vector of a valid date object, or character representation of
dates. Missing values are permitted and produce corresponding missing
values in the output.</p>
</td></tr>
<tr><td><code id="dectime_+3A_times">times</code></td>
<td>
<p>a character representation of times. Missing values are
permitted and produce corresponding missing values in the output.</p>
</td></tr>
<tr><td><code id="dectime_+3A_time.format">time.format</code></td>
<td>
<p>format to convert <code>times</code>. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="dectime_+3A_date.format">date.format</code></td>
<td>
<p>format to convert <code>dates</code> is character.</p>
</td></tr>
<tr><td><code id="dectime_+3A_date.noon">Date.noon</code></td>
<td>
<p>logical, if <code>TRUE</code> and <code>dates</code> is class &quot;Date,&quot; then
set set the time to noon, otherwise no time adjustment is made. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="dectime_+3A_year.type">year.type</code></td>
<td>
<p>a character string indicating the type of year to determine the
offset, must be one of &quot;calendar,&quot; &quot;water,&quot; or &quot;climate.&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The format for <code>times</code> must be one of &quot;hm,&quot; &quot;hms,&quot; or &quot;ms.&quot; Note that
this is actually a conversion function, see <b>See Also</b>. If <code>times</code>
is missing, <code>dates</code> is class &quot;Date,&quot; and <code>Date.noon</code> is <code>TRUE</code>,
then set the time to 12:00, so that the decimal time represents the center of
the day.
</p>
<p>Added from smwrBase.
</p>


<h3>Value</h3>

<p>A vector representation of the data in decimal format&ndash;year and
decimal fraction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dectime("11/11/1918", date.format="%m/%d/%Y")
dectime(1988:1990)
</code></pre>

<hr>
<h2 id='dectime2Date'>Date Conversion</h2><span id='topic+dectime2Date'></span>

<h3>Description</h3>

<p>Convert time data expressed as year and fractional part of year to class &quot;Date.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dectime2Date(x, Date.noon = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dectime2Date_+3A_x">x</code></td>
<td>
<p>the decimal date to convert.</p>
</td></tr>
<tr><td><code id="dectime2Date_+3A_date.noon">Date.noon</code></td>
<td>
<p>correct from noon correction for <code>dectime</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Added from smwrBase.
</p>


<h3>Value</h3>

<p>A vector of class &quot;Date&quot; corresponding to each value in <code>x</code>.
</p>


<h3>Note</h3>

<p>A small value, representing about 1 minute, is added to each value in <code>x</code>
to prevent truncation errors in the conversion. This can cause some errors if
the data were converted from date and time data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dectime">dectime</a></code>, <code><a href="base.html#topic+as.Date">as.Date</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dectime("02/07/2013", date.format="%m/%d/%Y")
# Convert back the printed result:
dectime2Date(2013.103)
</code></pre>

<hr>
<h2 id='detrended.flow'>Create Seasonally Detrended Flow Data Set</h2><span id='topic+detrended.flow'></span>

<h3>Description</h3>

<p>This function creates a seasonally detrended flow data set for
selected USGS gages. The created data set is used to support application of
GAMs that include a hydrologic term as one of the independent variables.
The output from this function should be stored as an .rda file for repeated
use with baytrends.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detrended.flow(
  usgsGageID,
  siteName,
  yearStart,
  yearEnd,
  dvAvgWinSel = c(1, 5, 10, 15, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210),
  dvAvgWgtSel = "uniform",
  dvAvgSidesSel = 1,
  lowess.f = 0.2,
  span = 10,
  max.fill = 10
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detrended.flow_+3A_usgsgageid">usgsGageID</code></td>
<td>
<p>USGS GageIDs (e.g., &quot;01491000&quot;)</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_sitename">siteName</code></td>
<td>
<p>USGS SiteName (only used for plots)</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_yearstart">yearStart</code></td>
<td>
<p>start year (recommended as at least one year before
corresponding water quality data set)</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_yearend">yearEnd</code></td>
<td>
<p>end year</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_dvavgwinsel">dvAvgWinSel</code></td>
<td>
<p>Averaging window (days) for smoothing the residuals of the
seasonally adjusted daily flow values 
[default = c(1, 5, 10, 15, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210)]</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_dvavgwgtsel">dvAvgWgtSel</code></td>
<td>
<p>Averaging method (&quot;uniform&quot;, &quot;weighted&quot;, or &quot;centered&quot;)
for creating weights. If using &quot;weighted&quot; then use dvAvgSidesSel=1.  If
using &quot;centered&quot; then use dvAvgSidesSel=2. [default = &quot;uniform&quot;]</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_dvavgsidessel">dvAvgSidesSel</code></td>
<td>
<p>If dvAvgSidesSel=1 only past values are used, if
dvAvgSidesSel=2 then values are centered around lag 0. [default = 1]</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_lowess.f">lowess.f</code></td>
<td>
<p>lowess smoother span applied to computed standard deviation
(see Details). This gives the proportion of points which influence the
smooth at each value. Larger values give more smoothness. [default = 0.2]</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_span">span</code></td>
<td>
<p>maximum number of observations on each side of range of missing
values to use in filling in data [default = 10]</p>
</td></tr>
<tr><td><code id="detrended.flow_+3A_max.fill">max.fill</code></td>
<td>
<p>maximum gap to fill in [default = 10]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a list of seasonally detrended flow and 
companion statistics; and relies on USGS' dataRetrieval package to retrieve
daily flow data.   
</p>
<p>It is the user responsibility to save the resulting list as 
<b>flow.detrended</b> for integration with baytrends.  
</p>
<p>For the purposes of baytrends, it is expected that the user 
would identify all USGS gages that are expected to be evaluated so that a 
single data file is created. To best match up with water quality data, we 
recommend retrieving flow data for one year prior to the first year of 
water quality data. This allows for creating a time-averaged flow data set 
and not loose the first few months of water quality data due to lack of 
matching flow data. Data retrievals should also be made in light of the 
time needed by the USGS to review and approve their flow records.
</p>
<p>After retrieval, the following computation steps are performed to create a
data frame for each USGS gage (the data frame naming convention is
<b>qNNNNNNNN</b> where NNNNNNNN is the USGS gage ID):   
</p>
<p>1) The daily flow data are converted to cubic meters per second [cms] and
stored as the variable <b>q</b>.  
</p>
<p>2) The day of year (<b>doy</b>) is added to the data set. We use a 366 day
calendar regardless of leap year.      
</p>
<p>3) The Log (ln) flow is computed and stored as <b>LogQ</b>.    
</p>
<p>4) A seasonal GAM, i.e., gamoutput &lt;- gam(LogQ ~  s(doy, bs='cc')) is
evaluated and the predicted values stored as <b>qNNNNNNNN.gam</b>.  
</p>
<p>5) The GAM residuals, i.e., &quot;residuals(gamoutput)&quot; are extracted and stored
as the variable, <b>d1</b>.  
</p>
<p>6) Based on the specifications for dvAvgWinSel, dvAvgWgtSel, and
dvAvgSidesSel, the values of <b>d1</b> are time averaged and additional
variables <b>dxxx</b> are added to the data frame where xxx corresponds to
list of averaging windows specified in dvAvgWinSel. These values of
<b>dxxx</b> are used in GAMs that include a hydrologic independent
variable.
</p>
<p>After the above data frame is created, the following four (4) additional
data frames are created for each USGS gage and combined into a list named
<b>qNNNNNNNN.sum</b>:   
</p>
<p><b>mean</b> &ndash; For each doy (i.e., 366 days of year), the mean across all
years for each value of d in the above data frame, qNNNNNNNN.   
</p>
<p><b>sd</b> &ndash; For each doy (i.e., 366 days of year), the standard deviation 
across all years for each value of d in the above data frame, qNNNNNNNN.  
</p>
<p><b>nobs</b> &ndash; For each doy (i.e., 366 days of year), the number of 
observations across all years for each value of d in the above data frame
, qNNNNNNNN.  
</p>
<p><b>lowess.sd</b> &ndash; Lowess smoothed standard deviations. (These values are
used for computing confidence intervals in the flow averaged GAM.)  
</p>
<p>The process of creating the above data frame, <b>qNNNNNNNN</b>, and list,
<b>qNNNNNNNN.sum</b>, is repeated for each USGS gage and combined together
in a single list. The beginning of the list includes meta data documenting
the retrieval parameters.
</p>
<p>This function can be used in conjunction with an RMD file to knit (create)
a report (DOCX or HTML).
</p>


<h3>Value</h3>

<p>Returns a list of seasonally detrended flow data. You should save the
resulting list as flow.detrended for use with baytrends.  This function
also creates diagnostic plots that can be saved to a report when this
function is called from an .Rmd script.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Define Function Inputs
usgsGageID    &lt;- c("01491000", "01578310")
siteName      &lt;- c("Choptank River near Greensboro, MD",
                   "Susquehanna River at Conowingo, MD")
yearStart     &lt;- 1983
yearEnd       &lt;- 2016
dvAvgWinSel   &lt;- c(1, 5, 10, 15, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210)
dvAvgWgtSel   &lt;- "uniform"
dvAvgSidesSel &lt;- 1
lowess.f      &lt;- 0.2
                 
# Run Function
flow.detrended &lt;- detrended.flow(usgsGageID, siteName, yearStart, yearEnd
                                , dvAvgWinSel, dvAvgWgtSel, dvAvgSidesSel
                               , lowess.f)

## End(Not run)
</code></pre>

<hr>
<h2 id='detrended.salinity'>Create Seasonally Detrended Salinty Data Set</h2><span id='topic+detrended.salinity'></span>

<h3>Description</h3>

<p>This function creates a seasonally detrended salinity data set 
for selected stations. The created data set is used to support application 
of GAMs that include a hydrologic term as one of the independent variables.
The output from this function should be stored as an .rda file for repeated
use with baytrends.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detrended.salinity(
  df.sal,
  dvAvgWinSel = 30,
  lowess.f = 0.2,
  minObs = 40,
  minObs.sd = 10
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detrended.salinity_+3A_df.sal">df.sal</code></td>
<td>
<p>data frame with salinty data (required variables in data frame
are: station, date, layer, and salinity)</p>
</td></tr>
<tr><td><code id="detrended.salinity_+3A_dvavgwinsel">dvAvgWinSel</code></td>
<td>
<p>Averaging window (days) selection for pooling data to 
compute summary statistics</p>
</td></tr>
<tr><td><code id="detrended.salinity_+3A_lowess.f">lowess.f</code></td>
<td>
<p>lowess smoother span applied to computed standard deviation
(see Details). This gives the proportion of points which influence the
smooth at each value. Larger values give more smoothness.</p>
</td></tr>
<tr><td><code id="detrended.salinity_+3A_minobs">minObs</code></td>
<td>
<p>Minimum number of observations for performing analysis (default
is 40)</p>
</td></tr>
<tr><td><code id="detrended.salinity_+3A_minobs.sd">minObs.sd</code></td>
<td>
<p>Minimum number of observations in averaging window for
calculation of the standard deviation (default is 10)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a list of seasonally detrended salinity and 
companion statistics; and relies on a user supplied data frame that 
contains the following variables: station, date, layer, and salinity. See
structure of sal data in example below.  
</p>
<p>It is the user responsibility to save the resulting list as
<b>salinity.detrended</b> for integration with baytrends.
</p>
<p>For the purposes of baytrends, it is expected that the user would identify
a data set with all salinity data that are expected to be evaluated so that
a single data file is created. The following computation steps are
performed: 
</p>
<p>1) Extract the list of stations, minimum year, and maximum year in data 
set. Initialize the <b>salinity.detrended</b> list with this information 
along with meta data documenting the retrieval parameters. 
</p>
<p>2) Downselect the input data frame to only include data where the 
layer is equal to 'S', 'AP', 'BP' or 'B'.
</p>
<p>3) Average the 'S' and 'AP' salinity data; and the 'B' and 'BP salinity
data together to create average salinity values for SAP (surface and above 
pycnocline) and BBP (bottom and below pycnocline), respectively. These 
values are stored as the variables, <b>salinity.SAP</b> and 
<b>salinity.BBP</b> together with the <b>date</b> and day of year 
(<b>doy</b>) in a data frame corresponding to the station ID.
</p>
<p>4) For each station/layer combination with atleast <b>minObs</b>
observations, a seasonal GAM, i.e., gamoutput &lt;- gam(salinity ~  s(doy, 
bs='cc')) is evaluated and the predicted values stored in the above data 
frame as <b>salinity.SAP.gam</b> and <b>salinity.BBP.gam</b>.  
</p>
<p>5) The GAM residuals, i.e., &quot;residuals(gamoutput)&quot; are extracted and stored
as the variable, <b>SAP</b> or <b>BBP</b> in the above data frame. 
(These are the values that are used for GAMs that include salinity.) 
</p>
<p>6) After the above data frame is created and appended to the 
list <b>salinity.detrended</b>, the following four (4) additional
data frames are created for each station.  
</p>
<p><b>mean</b> &ndash; For each doy (i.e., 366 days of year), the mean across all 
years for each value of d. Since samples are not collected on a daily basis
it is necessary to aggregate data from within a +/- one-half of
<b>dvAvgWinSel</b>-day window around d. (This includes wrapping around the
calendar year. That is, the values near the beginning of the year, say
January 2, would include values from the last part of December and the
first part of January. The variables in the mean data frame are doy, SAP, 
and BBP.   
</p>
<p><b>sd</b> &ndash; For each doy (i.e., 366 days of year), the standard deviation 
across all years for each value of d. (See mean calculations for additional
details.)    
</p>
<p><b>nobs</b> &ndash; For each doy (i.e., 366 days of year), the number of 
observations across all years for each value of d. (See mean calculations 
for additional details.)     
</p>
<p><b>lowess.sd</b> &ndash; Lowess smoothed standard deviations. It is noted that
some stations do not include regular sampling in all months of the year or
for other reasons have few observations from which to compute standard
deviations. Through visual inspection of plots, we found that the standard
deviation could become unstable when the number  of observations is small.
For this reason, when the number of observations is less than
<b>minObs.sd</b>, the corresponding value of lowess.sd is removed and
interpolated from the remaining observations.
</p>
<p>The above four data frames (mean, sd, nobs, and lowess.sd) are created, 
they are added to a list using a <b>station.sum</b> naming convention and 
appended to the list <b>salinity.detrended</b>.
</p>


<h3>Value</h3>

<p>Returns a list of seasonally detrended salinity data. You should save
the resulting list as salinity.detrended for use with baytrends.  This
function also creates diagnostic plots that can be saved to a report when
this function is called from an .Rmd script.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Show Example Dataset (sal)
str(sal)

# Define Function Inputs
df.sal        &lt;- sal
dvAvgWinSel   &lt;- 30
lowess.f      &lt;- 0.2
minObs        &lt;- 40
minObs.sd    &lt;- 10
                 
# Run Function
salinity.detrended &lt;- detrended.salinity(df.sal, dvAvgWinSel, 
                                 lowess.f, minObs, minObs.sd) 

## End(Not run)              
</code></pre>

<hr>
<h2 id='eventNum'>Event Processing</h2><span id='topic+eventNum'></span><span id='topic+eventLen'></span><span id='topic+eventSeq'></span>

<h3>Description</h3>

<p>Computes the event number <code>eventNum</code>, the length of events
<code>eventLen</code>, or the sequence number for individual observations within an
event <code>eventSeq</code>.  Added from smwrBase.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eventNum(event, reset = FALSE, na.fix = FALSE)

eventSeq(eventno)

eventLen(eventno, summary = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eventNum_+3A_event">event</code></td>
<td>
<p>a logical vector where <code>TRUE</code> indicates that an event
occurred. Missing values are treated as instructed by <code>na.fix</code>.</p>
</td></tr>
<tr><td><code id="eventNum_+3A_reset">reset</code></td>
<td>
<p>a logical value indicating whether the event is assumed to
continue until the next event, or only while event is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="eventNum_+3A_na.fix">na.fix</code></td>
<td>
<p>the value to use where event has missing values (<code>NA</code>s).</p>
</td></tr>
<tr><td><code id="eventNum_+3A_eventno">eventno</code></td>
<td>
<p>an integer vector indicating the event number. Generally the
output from the <code>eventNum</code> function.</p>
</td></tr>
<tr><td><code id="eventNum_+3A_summary">summary</code></td>
<td>
<p>a logical value, controlling output. See <b>Value</b> for
details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>eventNum</code> returns an integer vector the same
length as <code>event</code> indicating the event sequence number.<br />
</p>
<p>The function <code>eventLen</code> returns an integer vector the same length as
<code>eventno</code> indicating the sequence length of the event if <code>summary</code>
is <code>FALSE</code>, or a named integer vector indicating the sequence length of
each event if <code>summary</code> is <code>TRUE</code>.<br />
</p>
<p>The function <code>eventSeq</code> returns an integer vector the same length as
<code>eventno</code> indicating the sequence number of each element in the
event.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Notice the difference caused by setting reset to TRUE
eventNum(c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE))
eventNum(c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE), reset=TRUE)

## Notice the difference caused by setting reset to TRUE
eventSeq(eventNum(c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE)))
eventSeq(eventNum(c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE), reset=TRUE))

## Notice the difference caused by setting reset to TRUE
eventLen(eventNum(c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE), reset=TRUE))
## This is an example of the summary option
eventLen(eventNum(c(TRUE,TRUE,FALSE,FALSE,TRUE,FALSE), reset=TRUE), summary=TRUE)
</code></pre>

<hr>
<h2 id='fillMissing'>Fill Missing Values</h2><span id='topic+fillMissing'></span>

<h3>Description</h3>

<p>Replace missing values in time-series data by interpolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fillMissing(x, span = 10, Dates = NULL, max.fill = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fillMissing_+3A_x">x</code></td>
<td>
<p>the sequence of observations. Missing values are permitted and will
be replaced.</p>
</td></tr>
<tr><td><code id="fillMissing_+3A_span">span</code></td>
<td>
<p>the maximum number of observations on each side of each range of
missing values to use in constructing the time-series model. See
<b>Details</b>.</p>
</td></tr>
<tr><td><code id="fillMissing_+3A_dates">Dates</code></td>
<td>
<p>an optional vector of dates/times associated with each value 
in <code>x</code>. Useful if there are gaps in dates/times.</p>
</td></tr>
<tr><td><code id="fillMissing_+3A_max.fill">max.fill</code></td>
<td>
<p>the maximum gap to fill.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Missing values at the beginning and end of <code>x</code> will not be replaced. <br />
</p>
<p>The argument <code>span</code> is used to help set the range of values used to
construct the <code>StructTS</code> model. If <code>span</code> is set small, then the
variance of epsilon dominates and the estimates are not smooth. If
<code>span</code> is large, then the variance of level dominates and the estimates
are linear interpolations. The variances of level and epsilon are components
of the state-space model used to interpolate values, see <code><a href="stats.html#topic+StructTS">StructTS</a></code> for details. 
See <b>Note</b> for more information about the method.<br />
</p>
<p>If <code>span</code> is set larger than 99, then the entire time series is used to
estimate all missing values.  This approach may be useful if there are many
periods of missing values. If <code>span</code> is set to any number less than 4,
then simple linear interpolation will be used to replace missing values.
</p>
<p>Added from smwrBase.
</p>


<h3>Value</h3>

<p>The observations in <code>x</code> with missing values replaced by
interpolation.
</p>


<h3>Note</h3>

<p>The method used to interpolate missing values is based on
<code>tsSmooth</code> constructed using <code>StructTS</code> on <code>x</code> with
<code>type</code> set to &quot;trend.&quot; The smoothing method basically uses the
information (slope) from two values previous to missing values and the two
values following missing values to smoothly interpolate values accounting for
any change in slope. Beauchamp (1989) used time-series methods for synthesizing
missing streamflow records. The group that is used to define the statistics that
control the interpolation is very simply defined by <code>span</code> rather than
the more in-depth measures described in Elshorbagy and others (2000).
</p>
<p>If the data have gaps rather than missing values, then fillMissing will return
a vector longer than <code>x</code> if <code>Dates</code> is given and the return data
cannot be inserted into the original data frame. If <code>Dates</code> is not given,
then the gap will be recognized and not be filled. The function
<code>insertMissing</code> can be used to create a data frame with the complete
sequence of dates.
</p>


<h3>References</h3>

<p>Beauchamp, J.J., 1989, Comparison of regression and time-series
methods for synthesizing missing streamflow records: Water Resources
Bulletin, v. 25, no. 5, p. 961&ndash;975.<br />
</p>
<p>Elshorbagy, A.A., Panu, U.S., and Simonovic, S.P., 2000, Group-based estimation
of missing hydrological data, I. Approach and general methodology:
Hydrological Sciences Journal, v. 45, no. 6, p. 849&ndash;866.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+tsSmooth">tsSmooth</a></code>, <code><a href="stats.html#topic+StructTS">StructTS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#library(smwrData)
data(Q05078470)
# Create missing values in flow, the first sequence is a peak and the second is a recession
Q05078470$FlowMiss &lt;- Q05078470$FLOW
Q05078470$FlowMiss[c(109:111, 198:201)] &lt;- NA
# Interpolate the missing values
Q05078470$FlowFill &lt;- fillMissing(Q05078470$FlowMiss)
# How did we do (line is actual, points are filled values)?
par(mfrow=c(2,1), mar=c(5.1, 4.1, 1.1, 1.1))
with(Q05078470[100:120, ], plot(DATES, FLOW, type="l"))
with(Q05078470[109:111, ], points(DATES, FlowFill))
with(Q05078470[190:210, ], plot(DATES, FLOW, type="l"))
with(Q05078470[198:201, ], points(DATES, FlowFill))

## End(Not run)
</code></pre>

<hr>
<h2 id='filterWgts'>Create filter weights</h2><span id='topic+filterWgts'></span>

<h3>Description</h3>

<p>Create filter weights. Typically used to compute even,
weighted, or center-weighted averages for smoothing. Can
be used as a vector of weights in stats::filter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterWgts(n = NULL, type = "weighted")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filterWgts_+3A_n">n</code></td>
<td>
<p>number of values</p>
</td></tr>
<tr><td><code id="filterWgts_+3A_type">type</code></td>
<td>
<p>Averaging method (&quot;uniform&quot; [even], &quot;weighted&quot; [default], or &quot;centered&quot;) for creating weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns vector of weights
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wgts&lt;- filterWgts(0,"uniform")
wgts&lt;- filterWgts(7,"uniform")
wgts&lt;- filterWgts(7,"centered")
wgts&lt;- filterWgts(7,"weighted")
x &lt;- 1:100
filter(x, filterWgts(7,"weighted"), sides=1)
</code></pre>

<hr>
<h2 id='flwAveragePred'>Flow Averaged Predictions</h2><span id='topic+flwAveragePred'></span>

<h3>Description</h3>

<p>Compute flow[salinity] weighted predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flwAveragePred(pdat, pgam, normPct)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flwAveragePred_+3A_pdat">pdat</code></td>
<td>
<p>prediction data set</p>
</td></tr>
<tr><td><code id="flwAveragePred_+3A_pgam">pgam</code></td>
<td>
<p>gam model</p>
</td></tr>
<tr><td><code id="flwAveragePred_+3A_normpct">normPct</code></td>
<td>
<p>vector of percentiles to use in weighting</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame of flow[salinity] averaged predictions and standard errors
</p>

<hr>
<h2 id='gamDiff'>Compute an estimate of difference based on GAM results</h2><span id='topic+gamDiff'></span>

<h3>Description</h3>

<p>Compute an estimate of difference based on GAM results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamDiff(
  gamRslt,
  iSpec,
  analySpec,
  base.yr.set = NA,
  test.yr.set = NA,
  doy.set = NA,
  alpha = 0.05,
  flow.detrended = NA,
  salinity.detrended = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamDiff_+3A_gamrslt">gamRslt</code></td>
<td>
<p>output from gam model</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_ispec">iSpec</code></td>
<td>
<p>data set specifications (see details for required content)</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_base.yr.set">base.yr.set</code></td>
<td>
<p>vector of years used for baseline period</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_test.yr.set">test.yr.set</code></td>
<td>
<p>vector of years used for test period</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_doy.set">doy.set</code></td>
<td>
<p>vector of days used to establish sub-annual analyses 
(see details)</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_alpha">alpha</code></td>
<td>
<p>alpha level for computing confidence intervals</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_flow.detrended">flow.detrended</code></td>
<td>
<p>data generated by detrended.flow.
Default = flow.detrended.</p>
</td></tr>
<tr><td><code id="gamDiff_+3A_salinity.detrended">salinity.detrended</code></td>
<td>
<p>data generated by detrended.salinity.
Default = detrended.salinity.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>iSpec is a list containing information about the date range and 
transformations. Specifically, iSpec must include iSpec$yearBegin, 
iSpec$yearEnd, iSpec$centerYear corresponding to beginning year of record, 
ending year of record and centering year. Also, iSpec must include 
iSpec$transform and iSpec$logConst. (See online help for selectData for 
more information on these values.)
</p>
<p>base.yr.set and test.yr.set represent two time periods used to compare 
differences. For example, base.yr.set=c(1999,2000) and test.yr.set=c(2013,
2014) would compare GAM predictions from 1999-2000 versus 2013-2014. There 
is no particular limit to the number of years included in the specification
for base.yr.set and test.yr.set. For example, a user could specify 
c(2001:2002,2004) to use the years 2001, 2002, and 2004, skipping 2003 
because 2003 was an abnormal year (particularly wet, particularly dry,
hurricanes, etc.).
</p>
<p>base.yr.set and test.yr.set must be within the years specified by
the range from iSpec$yearBegin to iSpec$yearEnd (inclusive). If not, this 
function defaults to using the first two years (or last two years) of 
record. If base.yr.set and test.yr.set are left to their default values of 
NA, then the first two and last two years will be used
</p>
<p>doy.set represents the days of year for which GAM predictions are made and 
used to compute base.yr and test.yr means. For example doy.set= c(15, 46, 
75, 106, 136, 167, 197, 228, 259, 289, 320, 350) would result in the 15th 
of each month being used in the analysis; whereas doy.set= c(15, 46, 75) 
would just use Jan-15, Feb-15, and Mar-15. (Keep in mind that this package 
uses a 366 day calendar every year such that Mar-1 is always day 61, 
regardless of leap year.) If doy.set is left to the default value of NA, 
then c(15, 46, 75, 106, 136, 167, 197, 228, 259, 289, 320, 350) is used.
</p>
<p>The baseDay function has been added to this package from the smwrBase 
package.
</p>


<h3>Value</h3>

<p>Returns a nest list that includes the base and test years, doys,
period means in analyzed units, period means in observed units, percent
change, difference estimate, difference estimate in observed units,
standard error, confidence intervals, t statistic, p value, and alpha
level. The alpha level corresponds to the confidence intervals. The first
list (gamDiff.regular) uses the computed model to estimate differences and
is applicable for GAM formulas that do not involve an intervention term.
The second list (gamDiff.adjusted) performs computations by projecting the
most recent intervention (e.g., the current lab method) to all time
periods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># run analysisOrganizeData function to create the list analySpec
dfr &lt;- analysisOrganizeData (dataCensored, report=NA)
df        &lt;- dfr[["df"]]
analySpec &lt;- dfr[["analySpec"]]

# set GAM models to just one model
analySpec$gamModels &lt;- list(
  list(option=2
       , name= "Non-linear trend with Seasonality (plus Interactions)"
       , model= "~ cyear + s(cyear) + s(doy,bs='cc') + 
       ti(cyear,doy,bs=c('tp','cc'))"
       , deriv=FALSE))

# run GAM for a single water quality variable, station and layer
gamResult &lt;- gamTest(df, 'tn', 'CB5.4', 'S', analySpec=analySpec)

# use gamDiff to replicate estimates of change calculated in the above
gamDiff(gamRslt=gamResult[["gamOutput2"]]$gamRslt,
        iSpec=gamResult$iSpec, analySpec=analySpec,
        base.yr.set = NA, test.yr.set = NA,
        doy.set = NA, alpha = 0.05)

# use gamDiff to calculate changes from 2005/06 to 2013/14
gamDiff(gamRslt=gamResult[["gamOutput2"]]$gamRslt,
        iSpec=gamResult$iSpec, analySpec=analySpec,
        base.yr.set = c(2004:2005), test.yr.set = c(2013:2014),
        doy.set = NA, alpha = 0.05)

</code></pre>

<hr>
<h2 id='gamPlotDisp'>Plot censored gam fits vs. time</h2><span id='topic+gamPlotDisp'></span>

<h3>Description</h3>

<p>Plot censored gam fits vs. time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamPlotDisp(
  gamResult = gamResult,
  analySpec = analySpec,
  fullModel = 2,
  seasAvgModel = 2,
  seasonalModel = 2,
  diffType = "regular",
  obserPlot = TRUE,
  interventionPlot = TRUE,
  seasAvgPlot = TRUE,
  seasAvgConfIntPlot = TRUE,
  seasAvgSigPlot = TRUE,
  fullModelPlot = TRUE,
  seasModelPlot = TRUE,
  BaseCurrentMeanPlot = TRUE,
  adjustedPlot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamPlotDisp_+3A_gamresult">gamResult</code></td>
<td>
<p>output from procedure gamTest</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_fullmodel">fullModel</code></td>
<td>
<p>GAM # for displaying full GAM (e.g., 0, 1, 2)</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_seasavgmodel">seasAvgModel</code></td>
<td>
<p>GAM # for displaying seasonally average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_seasonalmodel">seasonalModel</code></td>
<td>
<p>GAM # for displaying seasonal GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_difftype">diffType</code></td>
<td>
<p>plot predicted baseline mean ('regular') or adjusted baseline mean ('adjusted')</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_obserplot">obserPlot</code></td>
<td>
<p>logical field indicating whether to plot observations</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_interventionplot">interventionPlot</code></td>
<td>
<p>logical field indicating whether to plot interventions (e.g., method changes)</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_seasavgplot">seasAvgPlot</code></td>
<td>
<p>logical field indicating whether to plot seasonal average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_seasavgconfintplot">seasAvgConfIntPlot</code></td>
<td>
<p>logical field indicating whether to plot confidence interval for seasonal average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_seasavgsigplot">seasAvgSigPlot</code></td>
<td>
<p>logical field indicating whether to plot significant increasing and decreasing trends for seasonal average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_fullmodelplot">fullModelPlot</code></td>
<td>
<p>logical field indicating whether to plot full GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_seasmodelplot">seasModelPlot</code></td>
<td>
<p>logical field indicating whether to plot seasonal GAM</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_basecurrentmeanplot">BaseCurrentMeanPlot</code></td>
<td>
<p>logical field indicating whether to plot baseline and current mean</p>
</td></tr>
<tr><td><code id="gamPlotDisp_+3A_adjustedplot">adjustedPlot</code></td>
<td>
<p>logical field indicating whether to plot adjusted model</p>
</td></tr>
</table>

<hr>
<h2 id='gamPlotDispSeason'>Plot censored gam fits vs. time</h2><span id='topic+gamPlotDispSeason'></span>

<h3>Description</h3>

<p>Plot censored gam fits vs. time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamPlotDispSeason(
  gamResult = gamResult,
  analySpec = analySpec,
  fullModel = 2,
  seasAvgModel = 2,
  seasonalModel = 2,
  diffType = "regular",
  obserPlot = TRUE,
  interventionPlot = TRUE,
  seasAvgPlot = TRUE,
  seasAvgConfIntPlot = TRUE,
  seasAvgSigPlot = TRUE,
  fullModelPlot = TRUE,
  seasModelPlot = TRUE,
  BaseCurrentMeanPlot = TRUE,
  adjustedPlot = FALSE,
  gamSeasonFocus = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamPlotDispSeason_+3A_gamresult">gamResult</code></td>
<td>
<p>output from procedure gamTest</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_fullmodel">fullModel</code></td>
<td>
<p>GAM # for displaying full GAM (e.g., 0, 1, 2)</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_seasavgmodel">seasAvgModel</code></td>
<td>
<p>GAM # for displaying seasonally average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_seasonalmodel">seasonalModel</code></td>
<td>
<p>GAM # for displaying seasonal GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_difftype">diffType</code></td>
<td>
<p>plot predicted baseline mean ('regular') or adjusted baseline mean ('adjusted')</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_obserplot">obserPlot</code></td>
<td>
<p>logical field indicating whether to plot observations</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_interventionplot">interventionPlot</code></td>
<td>
<p>logical field indicating whether to plot interventions (e.g., method changes)</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_seasavgplot">seasAvgPlot</code></td>
<td>
<p>logical field indicating whether to plot seasonal average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_seasavgconfintplot">seasAvgConfIntPlot</code></td>
<td>
<p>logical field indicating whether to plot confidence interval for seasonal average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_seasavgsigplot">seasAvgSigPlot</code></td>
<td>
<p>logical field indicating whether to plot significant increasing and decreasing trends for seasonal average GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_fullmodelplot">fullModelPlot</code></td>
<td>
<p>logical field indicating whether to plot full GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_seasmodelplot">seasModelPlot</code></td>
<td>
<p>logical field indicating whether to plot seasonal GAM</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_basecurrentmeanplot">BaseCurrentMeanPlot</code></td>
<td>
<p>logical field indicating whether to plot baseline and current mean</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_adjustedplot">adjustedPlot</code></td>
<td>
<p>logical field indicating whether to plot adjusted model</p>
</td></tr>
<tr><td><code id="gamPlotDispSeason_+3A_gamseasonfocus">gamSeasonFocus</code></td>
<td>
<p>logical field indicating whether to plot focus on season mean</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gamPlotDisp">gamPlotDisp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Specify parameter and station to analyze
dep        &lt;- 'do'
stat       &lt;- 'CB5.4'
layer      &lt;- 'B'

# Prepare data and set up specifications for analysis
dfr &lt;- analysisOrganizeData (dataCensored)
df        &lt;- dfr[[1]]
analySpec &lt;- dfr[[2]]

# Apply gamTest 
gamResult &lt;- gamTest(df, dep, stat, layer, analySpec=analySpec)
gamPlotDisp(gamResult = gamResult, analySpec = analySpec,
            fullModel = 2, seasAvgModel = 2, seasonalModel = 2,
            diffType = "regular", obserPlot = TRUE, interventionPlot = TRUE,
            seasAvgPlot = TRUE, seasAvgConfIntPlot = FALSE,
            seasAvgSigPlot = FALSE, fullModelPlot = TRUE, seasModelPlot = TRUE,
            BaseCurrentMeanPlot = FALSE, adjustedPlot = FALSE)

# Apply gamTestSeason
gamResult2 &lt;- gamTestSeason(df, dep, stat, layer, analySpec=analySpec,
                            gamSeasonPlot = c("7/15-8/15", "purple", "range"))
gamPlotDispSeason(gamResult = gamResult2, analySpec = analySpec,
                  fullModel = 2, seasAvgModel = 2, seasonalModel = 2,
                  diffType = "regular", obserPlot = TRUE, interventionPlot = TRUE,
                  seasAvgPlot = TRUE, seasAvgConfIntPlot = FALSE,
                  seasAvgSigPlot = FALSE, fullModelPlot = FALSE, seasModelPlot = FALSE,
                  BaseCurrentMeanPlot = TRUE, adjustedPlot = FALSE, gamSeasonFocus = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='gamTest'>Perform GAM analysis</h2><span id='topic+gamTest'></span>

<h3>Description</h3>

<p>Perform GAM analysis. Relies on mgcv::gam to perform general additive model.
<code><a href="mgcv.html#topic+gam">gam</a></code>
The baseDay function has been added to this package from the smwrBase package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamTest(
  df,
  dep,
  stat,
  layer = NA,
  analySpec,
  gamTable = TRUE,
  gamPlot = 10,
  gamDiffModel = NA,
  flow.detrended = NA,
  salinity.detrended = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamTest_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="gamTest_+3A_dep">dep</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id="gamTest_+3A_stat">stat</code></td>
<td>
<p>station</p>
</td></tr>
<tr><td><code id="gamTest_+3A_layer">layer</code></td>
<td>
<p>layer</p>
</td></tr>
<tr><td><code id="gamTest_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
<tr><td><code id="gamTest_+3A_gamtable">gamTable</code></td>
<td>
<p>gam table setting (set to FALSE to turn off table output)</p>
</td></tr>
<tr><td><code id="gamTest_+3A_gamplot">gamPlot</code></td>
<td>
<p>gam plot setting (set to FALSE to turn off plotting)</p>
</td></tr>
<tr><td><code id="gamTest_+3A_gamdiffmodel">gamDiffModel</code></td>
<td>
<p>GAM model(s) used for computing differences on sub-annual/multi-period basis</p>
</td></tr>
<tr><td><code id="gamTest_+3A_flow.detrended">flow.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = NA.</p>
</td></tr>
<tr><td><code id="gamTest_+3A_salinity.detrended">salinity.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Set <code>gamPlot=FALSE</code> to turn off plotting. Computing the information
(&quot;predictions&quot;) to create plots is one of the more time consumings aspects of
the <code>gamTest</code> function. Setting <code>gamPlot=FALSE</code> turns off these
computations and speeds up <code>gamTest</code>. The disadvantage is that no
predictions are returned; however, the tabularized results stored in
<code>stat.gam.result</code> and, if requested, <code>chng.gam.result</code> are still
returned.
</p>
<p>Setting <code>gamPlot</code> to a value between 1-30 changes the resolution of the
resulting figure by setting the interval on which the prediction data set is
made. By default <code>gamPlot</code> is set to 10. That is, a prediction is made
every 10th day, or about 36 predictions per year. Values closer to 1 result
in larger returned prediction data sets and take more computation time.
Values closer to 30 result in smaller returned data sets and take less
computation time. Although there is no change in the fitted model, values
closer to 30 may have slight degraded figure quality if there is subtantial
seasonality in the fitted model since the seasonal minimum and maximum might
not be included in the prediction data set and therefore not plotted. Values
greater than 30 are treated as 30. Setting <code>gamPlot=30</code> might be
advantangeous when the analysis only requires cursory figure examination.
</p>
<p>Setting <code>gamTable=FALSE</code> will turn off table output to the console. This
may be advantageous to reduce the amount of output. Since these computations
do not significantly affect <code>gamTest</code> run time, the standard Analysis of
Variance, GAM Parameter Coefficients, Diagnostics, and Estimates of Change
tables are returned from <code>gamTest</code> regardless of the <code>gamTable</code>
setting. Many of the values from these tables are also returned as part of 
tabularized <code>stat.gam.result</code>.
</p>
<p>The default settings for <code>gamDiffModel</code> (i.e., <code>gamDiffModel=NA</code>)
will not result in sub-annual (i.e., seasonal) differences being computed. In
this default setting, the returned <code>chng.gam.result</code> that is returned
from <code>gamTest</code> will be empty. If <code>gamDiffModel</code> is a value (i.e.,
not <code>NA</code>), then <code>chng.gam.result</code> will include one row for each
combination of years specified in <code>analySpec$gamDiffPeriods</code>, seasons
specified in <code>analySpec$gamDiffSeason</code>, and the number of models listed
in <code>gamDiffModel</code>. For example <code>gamDiffModel=c(0,1,2)</code> would
result in sub-annual being computed for gam0, gam1, and gam2.
</p>
<p><strong>Flow and Salinity Adjustments (gam4).</strong> It is necessary to create and
pass properly formatted data via the <code>flow.detrended</code> and
<code>salinity.detrended</code> arguments to evaluate gam4 models. See
<code><a href="#topic+detrended.flow">detrended.flow</a></code> and <code><a href="#topic+detrended.salinity">detrended.salinity</a></code> for more
information on how to create properly formatted data.
</p>


<h3>Value</h3>

<p>Returns a list with results
</p>

<ul>
<li> <p><strong>stat.gam.result &ndash;</strong> Data frame with summary results in a tabular format suitable for output to a csv file
</p>
</li>
<li> <p><strong>chng.gam.result &ndash;</strong> Data frame with estimate of change for sub-annual differences based on the 
settings specified in <code>gamDiffModel</code>. Includes all data from stat.gam.result and sub-annual estimates of change
in a tabular format suitable for output to a csv file. 
</p>
</li>
<li> <p><strong>data &ndash;</strong> Data frame of data used in analysis (for example years with large proportion of censored data might be removed from the analysis and not included in this data frame)
</p>
</li>
<li> <p><strong>data.all &ndash;</strong> Data frame of all potential data available for analysis
</p>
</li>
<li> <p><strong>iSpec &ndash;</strong> List of baytrends analysis settings used for a specific analysis of station and parameter
</p>
</li>
<li> <p><strong>gamOutput0 &ndash;</strong>	Results including model predictions for gam formula 0 (i.e., gam0)
</p>
</li>
<li> <p><strong>gamOutput1 &ndash;</strong>	Results including model predictions for gam formula 1 (i.e., gam1)
</p>
</li>
<li> <p><strong>gamOutput2 &ndash;</strong>	Results including model predictions for gam formula 2 (i.e., gam2)
</p>
</li>
<li> <p><strong>gamOutput3 &ndash;</strong>	Results including model predictions for gam formula 3 (i.e., gam3)
</p>
</li>
<li> <p><strong>gamOutput4 &ndash;</strong>	Results including model predictions for gam formula 4 (i.e., gam4)
</p>
</li>
<li> <p><strong>gamOutput5 &ndash;</strong>	Results including model predictions for gam formula 5 (i.e., gam5)
</p>
</li>
<li> <p><strong>gamOutput6 &ndash;</strong>	Results including model predictions for gam formula 6 (i.e., gam6)
</p>
</li></ul>

<p><strong>gamOutput* &ndash;</strong> For each evaluated model, <code>gamOutput*</code> (see above
element list) is a list with the following elements:
</p>

<ul>
<li> <p><strong>gamOption &ndash;</strong> gam formula ID, i.e., 0, 1, 2, 3, 4 , 5, 6 corresponding to gam0, gam1, gam2, etc.
</p>
</li>
<li> <p><strong>gamRslt &ndash;</strong> mgcv::gam output
</p>
</li>
<li> <p><strong>gamRsltSum &ndash;</strong> &quot;summary&quot; of mgcv::gam, i.e., summary(mgcv::gam)
</p>
</li>
<li> <p><strong>gamANOVAtbl &ndash;</strong> GAM Analysis of Variance table 
</p>
</li>
<li> <p><strong>gamCoefftbl &ndash;</strong> GAM Parameter Coefficients table
</p>
</li>
<li> <p><strong>gamDiagnostics &ndash;</strong> GAM Diagnostics table(AIC, RMSE, and Adj. R-squared)
</p>
</li>
<li> <p><strong>perChange &ndash;</strong> Estimates of Change table
</p>
</li>
<li> <p><strong>porDiff.regular &ndash;</strong> Estimate of change in list format
</p>
</li>
<li> <p><strong>porDiff.adjusted &ndash;</strong> Estimate of change adjusted for interventions in list format 
</p>
</li>
<li> <p><strong>predictions &ndash;</strong> Data frame of gam predictions (all information used to create baytrends graphics excluding measurements)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Specify parameter and station to analyze
dep        &lt;- 'do'
stat       &lt;- 'CB5.4'
layer      &lt;- 'B'

# Prepare data and set up specifications for analysis
dfr &lt;- analysisOrganizeData (dataCensored)
df        &lt;- dfr[[1]]
analySpec &lt;- dfr[[2]]

# Apply gamTest 
gamResult &lt;- gamTest(df, dep, stat, layer, analySpec=analySpec)
gamPlotDisp(gamResult = gamResult, analySpec = analySpec,
            fullModel = 2, seasAvgModel = 2, seasonalModel = 2,
            diffType = "regular", obserPlot = TRUE, interventionPlot = TRUE,
            seasAvgPlot = TRUE, seasAvgConfIntPlot = FALSE,
            seasAvgSigPlot = FALSE, fullModelPlot = TRUE, seasModelPlot = TRUE,
            BaseCurrentMeanPlot = FALSE, adjustedPlot = FALSE)

# Apply gamTestSeason
gamResult2 &lt;- gamTestSeason(df, dep, stat, layer, analySpec=analySpec,
                            gamSeasonPlot = c("7/15-8/15", "purple", "range"))
gamPlotDispSeason(gamResult = gamResult2, analySpec = analySpec,
                  fullModel = 2, seasAvgModel = 2, seasonalModel = 2,
                  diffType = "regular", obserPlot = TRUE, interventionPlot = TRUE,
                  seasAvgPlot = TRUE, seasAvgConfIntPlot = FALSE,
                  seasAvgSigPlot = FALSE, fullModelPlot = FALSE, seasModelPlot = FALSE,
                  BaseCurrentMeanPlot = TRUE, adjustedPlot = FALSE, gamSeasonFocus = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='gamTestSeason'>Perform GAM analysis for Specified Season</h2><span id='topic+gamTestSeason'></span>

<h3>Description</h3>

<p>Perform GAM analysis for Specified Season. Relies on mgcv::gam to perform general additive model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamTestSeason(
  df,
  dep,
  stat,
  layer = NA,
  analySpec,
  gamTable = TRUE,
  gamPlot = 10,
  gamDiffModel = c(2),
  flow.detrended = NA,
  salinity.detrended = NA,
  gamSeasonPlot = c("7/1-9/30", "purple", "range")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamTestSeason_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_dep">dep</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_stat">stat</code></td>
<td>
<p>station</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_layer">layer</code></td>
<td>
<p>layer</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_gamtable">gamTable</code></td>
<td>
<p>gam table setting (set to FALSE to turn off table output)</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_gamplot">gamPlot</code></td>
<td>
<p>gam plot setting (set to FALSE to turn off plotting)</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_gamdiffmodel">gamDiffModel</code></td>
<td>
<p>GAM model(s) used for computing differences on sub-annual/multi-period basis</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_flow.detrended">flow.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = NA.</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_salinity.detrended">salinity.detrended</code></td>
<td>
<p>data generated by detrended.flow.  Default = NA.</p>
</td></tr>
<tr><td><code id="gamTestSeason_+3A_gamseasonplot">gamSeasonPlot</code></td>
<td>
<p>Character vector for evaluating and displaying seasonal model (see details for further information).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>gamSeasonPlot is an additional argument (relative to the arguments used in
the gamTest function) that is used to target a specific season for the focus
of output and can be a 2- or 3-element vector. While the GAM is fit to all
data as in the function gamTest, the output figure will only show the model
corresponding to the gamSeasonPlot specifications. The first element of
gamSeasonPlot can be a single date (e.g., ‘8/28’) or a date range (e.g.,
‘7/1-9/30’). The second element specifies the color of the line to be
plotted. If a date range is specified as the first element and an optional
third element is provided as ‘range’, then the plot will show the season
minimum and maximum as well as the mean; otherwise, only the mean is plotted.
If the first element of gamSeasonPlot is a single date then observations
within a +/- 15-day window of the date are plotted; otherwise, only
observations within the date range are plotted. Estimates of difference are
computed with baytrends::gamDiff by setting the argument doy.set to either
the single date provided from gamSeasonPlot or the same doys used to compute
the season mean. The option to specify seasons that &quot;wrap&quot; around end of 
year, i.e., 12/1-1/30, has not been implemented.
</p>


<h3>Value</h3>

<p>Returns a list with results
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamTest">gamTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Specify parameter and station to analyze
dep        &lt;- 'do'
stat       &lt;- 'CB5.4'
layer      &lt;- 'B'

# Prepare data and set up specifications for analysis
dfr &lt;- analysisOrganizeData (dataCensored)
df        &lt;- dfr[[1]]
analySpec &lt;- dfr[[2]]

# Apply gamTest 
gamResult &lt;- gamTest(df, dep, stat, layer, analySpec=analySpec)
gamPlotDisp(gamResult = gamResult, analySpec = analySpec,
            fullModel = 2, seasAvgModel = 2, seasonalModel = 2,
            diffType = "regular", obserPlot = TRUE, interventionPlot = TRUE,
            seasAvgPlot = TRUE, seasAvgConfIntPlot = FALSE,
            seasAvgSigPlot = FALSE, fullModelPlot = TRUE, seasModelPlot = TRUE,
            BaseCurrentMeanPlot = FALSE, adjustedPlot = FALSE)

# Apply gamTestSeason
gamResult2 &lt;- gamTestSeason(df, dep, stat, layer, analySpec=analySpec,
                            gamSeasonPlot = c("7/15-8/15", "purple", "range"))
gamPlotDispSeason(gamResult = gamResult2, analySpec = analySpec,
                  fullModel = 2, seasAvgModel = 2, seasonalModel = 2,
                  diffType = "regular", obserPlot = TRUE, interventionPlot = TRUE,
                  seasAvgPlot = TRUE, seasAvgConfIntPlot = FALSE,
                  seasAvgSigPlot = FALSE, fullModelPlot = FALSE, seasModelPlot = FALSE,
                  BaseCurrentMeanPlot = TRUE, adjustedPlot = FALSE, gamSeasonFocus = TRUE)

## End(Not run)     
</code></pre>

<hr>
<h2 id='getUSGSflow'>Retrieve USGS daily flow data in a wide format</h2><span id='topic+getUSGSflow'></span>

<h3>Description</h3>

<p>Retrieve USGS daily flow data from NWIS based on list of site IDs (relying on
dataRetrieval::readNWISdv and dataRetrieval::renameNWISColumns. The flow
and data qualifier code for each site is organized into two columns (e.g.,
&quot;q10174500&quot;, &quot;q101745000cd&quot; for USGS gage 10174500). Flow is stored as cubic
meters per second [cms].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getUSGSflow(
  siteNumber,
  yearStart,
  yearEnd,
  fill = TRUE,
  span = 10,
  max.fill = 10
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getUSGSflow_+3A_sitenumber">siteNumber</code></td>
<td>
<p>List of site numbers</p>
</td></tr>
<tr><td><code id="getUSGSflow_+3A_yearstart">yearStart</code></td>
<td>
<p>Beginning year of data retrieval</p>
</td></tr>
<tr><td><code id="getUSGSflow_+3A_yearend">yearEnd</code></td>
<td>
<p>Ending year of data retrieval</p>
</td></tr>
<tr><td><code id="getUSGSflow_+3A_fill">fill</code></td>
<td>
<p>TRUE[default]/FALSE field indicating whether to fill in missing
values using with USGS' fillMissing function</p>
</td></tr>
<tr><td><code id="getUSGSflow_+3A_span">span</code></td>
<td>
<p>the maximum number of observations on each side of each range of
missing values to use in constructing the time series model [default=10]</p>
</td></tr>
<tr><td><code id="getUSGSflow_+3A_max.fill">max.fill</code></td>
<td>
<p>the maximum gap to fill [default=10]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function automatically 'fills in' missing values [unless the user turns
this feature off] using code developed by USGS (see smwrBase::fillMissing). 
The user can also control the maximum gap size to fill in. If a daily flow
value is missing, then the corresponding data qualifier fields is set to
'NaN'. The user can use this setting to identify which flows are filled in.
</p>


<h3>Value</h3>

<p>USGS daily flow data for sites in a wide format
</p>


<h3>Examples</h3>

<pre><code class='language-R'># set retrieval parameters
yearStart   &lt;- 2014
yearEnd     &lt;- 2014
siteNumber &lt;- c('01578310')

# regular retrieval (default usage)
df &lt;- getUSGSflow(siteNumber, yearStart, yearEnd)

</code></pre>

<hr>
<h2 id='impute'>Impute Censored Values</h2><span id='topic+impute'></span>

<h3>Description</h3>

<p>Impute value for multiply censored data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute(x, imputeOption = "mid")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="impute_+3A_x">x</code></td>
<td>
<p>vector of type survival::Surv</p>
</td></tr>
<tr><td><code id="impute_+3A_imputeoption">imputeOption</code></td>
<td>
<p>imputation method [default= &quot;mid&quot;], valid impute options
are &quot;lower&quot;, &quot;upper&quot;, &quot;mid&quot;, &quot;norm&quot;, &quot;lnorm&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The imputeOption values of <code>"lower"</code>, <code>"upper"</code> and <code>"mid"</code>
impute the lower limit, upper limit, and midpoint between the lower and upper
limit. In the context of typical water quality data, these options would be
equivalent to zero, detection limit and 1/2 detection limit substitution.
Options for substituting the normal [<code>"norm"</code>] or lognormal
[<code>"lnorm"</code>] expectation can also be used.
</p>


<h3>Value</h3>

<p>vector where x is transformed into a simple numeric variable
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeSurvDF">makeSurvDF</a></code>,  <code><a href="#topic+unSurvDF">unSurvDF</a></code>
,  <code><a href="#topic+unSurv">unSurv</a></code>,  <code><a href="#topic+imputeDF">imputeDF</a></code>,  <code><a href="#topic+imputeDF">imputeDF</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x  &lt;- dataCensored[1:20,"tdp"]
x.lower &lt;- impute(x,'lower')
x.mid   &lt;- impute(x,'mid')
x.upper &lt;- impute(x,'upper')
x.norm  &lt;- impute(x,'norm')
x.lnorm &lt;- impute(x,'lnorm')

## End(Not run)
</code></pre>

<hr>
<h2 id='imputeDF'>Impute Censored Values in dataframes</h2><span id='topic+imputeDF'></span>

<h3>Description</h3>

<p>Impute value for multiply censored data in data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeDF(df, imputeOption = "mid")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="imputeDF_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="imputeDF_+3A_imputeoption">imputeOption</code></td>
<td>
<p>imputation method [default= &quot;mid&quot;], valid impute options
are &quot;lower&quot;, &quot;upper&quot;, &quot;mid&quot;, &quot;norm&quot;, &quot;lnorm&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The imputeOption values of <code>"lower"</code>, <code>"upper"</code> and <code>"mid"</code>
impute the lower limit, upper limit, and midpoint between the lower and upper
limit. In the context of typical water quality data, these options would be
equivalent to zero, detection limit and 1/2 detection limit substitution.
Options for substituting the normal [<code>"norm"</code>] or lognormal
[<code>"lnorm"</code>] expectation can also be used.
</p>


<h3>Value</h3>

<p>dataframe where fields with censored data (i.e., Surv objects) are
transformed into a simple numeric fields
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeSurvDF">makeSurvDF</a></code>,  <code><a href="#topic+unSurvDF">unSurvDF</a></code>
,  <code><a href="#topic+unSurv">unSurv</a></code>,  <code><a href="#topic+impute">impute</a></code>,  <code><a href="#topic+imputeDF">imputeDF</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
df  &lt;- dataCensored[1:20, ]
df.lower &lt;- imputeDF(df,'lower')
df.mid   &lt;- imputeDF(df,'mid')
df.upper &lt;- imputeDF(df,'upper')
df.norm  &lt;- imputeDF(df,'norm')
df.lnorm &lt;- imputeDF(df,'lnorm')

## End(Not run)
</code></pre>

<hr>
<h2 id='layerAggregation'>Aggregate data layers</h2><span id='topic+layerAggregation'></span>

<h3>Description</h3>

<p>This function aggregates data layers. Steps: 1) Perform first level error checking
to make sure that the data set contains 'layer' and valid aggregation option was
selected. 2) Perform second level error checking to make sure the aggregation option
selection makes sense (e.g. cannot aggregate &quot;S&quot; and &quot;AP&quot; if no &quot;AP&quot; data are in the
data set). 3) Average the data by taking the median or mean based on user input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layerAggregation(df, avgTechnique = "mean", layerAggOption = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="layerAggregation_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="layerAggregation_+3A_avgtechnique">avgTechnique</code></td>
<td>
<p>method for aggregating data (&quot;mean&quot; [default], &quot;median&quot;)</p>
</td></tr>
<tr><td><code id="layerAggregation_+3A_layeraggoption">layerAggOption</code></td>
<td>
<p>(0[default]: no aggregation; 1: combine &quot;S&quot; &amp; &quot;AP&quot;
(&quot;SAP&quot;); 2: combine &quot;B&quot; &amp; &quot;BP&quot; (&quot;BBP&quot;); 3: opt 1 &amp; 2 (&quot;SAP&quot;, &quot;BBP&quot;); 4:
combine all (&quot;ALL&quot;)); 5: combine &quot;S&quot; and &quot;B&quot; (&quot;SB&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame with aggregated data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dfr    &lt;- analysisOrganizeData(dataCensored)

# retrieve all corrected chlorophyll-a concentrations for Station CB5.4,
# missing values are removed and transformation applied. Note, a 
# warning is displayed indicating that data set has layers but user did
# not specify layer in retrieval. layerAggregation then aggregates per 
# specifications
dfr2   &lt;- selectData(dfr[["df"]], 'chla', 'CB5.4', analySpec=dfr[["analySpec"]])
df2    &lt;- dfr2[[1]]   # data frame of selected data
iSpec2 &lt;- dfr2[[2]]   # meta data about selected data
df2a   &lt;- layerAggregation(df2, avgTechnique="mean", layerAggOption=4)

## End(Not run)

</code></pre>

<hr>
<h2 id='layerLukup'>Layer List</h2><span id='topic+layerLukup'></span>

<h3>Description</h3>

<p>A lookup table of layer abbreviations and the corresponding
names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layerLukup
</code></pre>


<h3>Format</h3>

<p>A data frame with 10 rows and 3 variables:
</p>

<dl>
<dt>layers</dt><dd><p>Layer codes</p>
</dd>
<dt>order</dt><dd><p>Analysis order</p>
</dd>
<dt>name</dt><dd><p>Layer name</p>
</dd>
</dl>


<hr>
<h2 id='loadData'>Load/Clean CSV and TXT Data File</h2><span id='topic+loadData'></span>

<h3>Description</h3>

<p>Load and clean comma delimited (*.csv) or tab delimited (*.txt) file and
perform some rudimentary data cleaning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadData(
  file = NA,
  folder = ".",
  pk = NA,
  remDup = TRUE,
  remNAcol = TRUE,
  remNArow = TRUE,
  convDates = TRUE,
  tzSel = "America/New_York",
  commChar = "#",
  naChar = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadData_+3A_file">file</code></td>
<td>
<p>file (can use wildcards, e.g., &quot;*.csv&quot;)</p>
</td></tr>
<tr><td><code id="loadData_+3A_folder">folder</code></td>
<td>
<p>folder (i.e., directory to look in, can use relative path )</p>
</td></tr>
<tr><td><code id="loadData_+3A_pk">pk</code></td>
<td>
<p>vector of columns that form the primary key for data set</p>
</td></tr>
<tr><td><code id="loadData_+3A_remdup">remDup</code></td>
<td>
<p>logical field indicating whether duplicate rows are deleted</p>
</td></tr>
<tr><td><code id="loadData_+3A_remnacol">remNAcol</code></td>
<td>
<p>logical field indicating whether columns with all NA are deleted</p>
</td></tr>
<tr><td><code id="loadData_+3A_remnarow">remNArow</code></td>
<td>
<p>logical field indicating whether rows with all NA are deleted</p>
</td></tr>
<tr><td><code id="loadData_+3A_convdates">convDates</code></td>
<td>
<p>vector or logical field indicating whether date-like columns
should be converted to POSIXct format (see details)</p>
</td></tr>
<tr><td><code id="loadData_+3A_tzsel">tzSel</code></td>
<td>
<p>time zone to use for date conversions (default: &quot;America/New_York&quot;)</p>
</td></tr>
<tr><td><code id="loadData_+3A_commchar">commChar</code></td>
<td>
<p>character for comment line to be skipped</p>
</td></tr>
<tr><td><code id="loadData_+3A_nachar">naChar</code></td>
<td>
<p>characters to treat as NA</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function reads in a single comma delimited (*.csv) or tab
delimited (*.txt) file using either <code>utils::read.table</code> or <code>utils::read.csv</code>
based on the file extension. The user can use the wildcard feature for the
file argument (e.g., file='*.csv') and the function will identify the most
recently modified csv or txt file in the folder for importing.
</p>
<p>Some specific features of this function include the following:
</p>
<p>1. Leading '0's in character strings that would otherwise be trimmed and
treated as numeric variables (e.g., USGS flow gages, state and county FIPS
codes) are preserved. To effectively use this functionality, data
maintained in a spreadsheet would be enclosed in quotes (e.g., &quot;01578310&quot;).
When exported to csv or txt files the field would be in triple quotes
(e.g., &quot;&quot;&quot;01578310&quot;&quot;&quot;). Any column read in as integer is converted to numeric.
</p>
<p>2. Rows and columns with no data (i.e., all NA) are deleted unless default
settings for remNAcol and remNArow are changed to FALSE.
</p>
<p>3. Completely duplicate rows are deleted unless default setting for remDup
is changed to FALSE.
</p>
<p>4. Rows beginning with '#' are skipped unless commChar set to &quot;&quot;
</p>
<p>5. If a primary key (either single or multiple columns) is selected, the
function enforces the primary key by deleting duplicate entries based on
the primary key. Columns corresponding to the primary key (when specified)
are moved to the first columns.
</p>
<p>6. If convDates is a vector (i.e., <code>c('beginDate', 'endDate')</code>), then a date
conversion is attempted for the corresponding columns found in the input
file. If TRUE, then a date conversion is attempted for all columns found in
the input file with 'date' in the name, If FALSE, no date conversion is
attempted.
</p>
<p>Some other common time zones include the following: America/New_York,
America/Chicago, America/Denver, America/Los_Angeles, America/Anchorage,
America/Honolulu, America/Jamaica, America/Managua, America/Phoenix,
America/Metlakatla
</p>
<p>A brief table reporting the results of the import are printed.
</p>
<p>Note that columns containing just F, T, FALSE, TRUE are stored as logical fields
</p>


<h3>Value</h3>

<p>Returns data frame
</p>

<hr>
<h2 id='loadExcel'>Load/Clean Excel sheet</h2><span id='topic+loadExcel'></span>

<h3>Description</h3>

<p>Load and clean one sheet from an Excel file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadExcel(
  file = NA,
  sheet = 1,
  folder = ".",
  pk = NA,
  remDup = TRUE,
  remNAcol = TRUE,
  remNArow = TRUE,
  convDates = TRUE,
  tzSel = "America/New_York"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadExcel_+3A_file">file</code></td>
<td>
<p>file (can use wildcards, e.g., &quot;*.xlsx&quot;)</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_sheet">sheet</code></td>
<td>
<p>worksheet name to load from Excel file</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_folder">folder</code></td>
<td>
<p>folder (i.e., directory to look in, can use relative path )</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_pk">pk</code></td>
<td>
<p>vector of columns that form the primary key for data set</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_remdup">remDup</code></td>
<td>
<p>logical field indicating whether duplicate rows are deleted</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_remnacol">remNAcol</code></td>
<td>
<p>logical field indicating whether columns with all NA are deleted</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_remnarow">remNArow</code></td>
<td>
<p>logical field indicating whether rows with all NA are deleted</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_convdates">convDates</code></td>
<td>
<p>vector or logical field indicating whether date-like columns
should be converted to POSIXct format (see details)</p>
</td></tr>
<tr><td><code id="loadExcel_+3A_tzsel">tzSel</code></td>
<td>
<p>time zone to use for date conversions (default: &quot;America/New_York&quot;)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function reads in a single sheet from an Excel file using
readxl::read_excel to load the data
</p>
<p>After reading data in with readxl::read_excel, some specific additional
steps are implemented:
</p>
<p>1. Double quotes are removed from beginning and ending of all
fields. The purpose is to maintaion leading zeroes (e.g., USGS flow gages).
To effectively use this functionality, data maintained in a spreadsheet
would be enclosed in quotes (e.g., &quot;01578310&quot;). If exported to csv or txt
files the field would be in triple quotes (e.g., &quot;&quot;&quot;01578310&quot;&quot;&quot;). Any
column read in as integer is converted to numeric.
</p>
<p>2. Rows and columns with no data (i.e., all NA) are deleted unless default
settings for remNAcol and remNArow are changed to FALSE.
</p>
<p>3. Completely duplicate rows are deleted unless default setting for remDup
is changed to FALSE.
</p>
<p>4. If a primary key (either single or multiple columns) is selected, the
function enforces the primary key by deleting duplicate entries based on
the primary key. Columns corresponding to the primary key (when specified)
are moved to the first columns.
</p>
<p>5. If convDates is a vector (i.e., <code>c('beginDate', 'endDate')</code>), then
a date conversion to <code>as.POSIXct</code> is attempted for the corresponding
columns found in the input file. If TRUE, then a date conversion is
attempted for all columns found in the input file with 'date' in the name,
If FALSE, no date conversion is attempted.
</p>
<p>Some other common time zones include the following: America/New_York,
America/Chicago, America/Denver, America/Los_Angeles, America/Anchorage,
America/Honolulu, America/Jamaica, America/Managua, America/Phoenix,
America/Metlakatla
</p>
<p>A brief table reporting the results of the import are printed.
</p>
<p>Note that columns containing just F, T, FALSE, TRUE are stored as logical fields
</p>


<h3>Value</h3>

<p>Returns data frame
</p>

<hr>
<h2 id='loadModels'>Load Built-in GAM formulas</h2><span id='topic+loadModels'></span>

<h3>Description</h3>

<p>Returns built-in GAM formulas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadModels(gamSelect = "gam4")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadModels_+3A_gamselect">gamSelect</code></td>
<td>
<p>character vector of models (Current options include gam0,
gam1, gam2, gam3, gam4, gam5)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, the function analysisOrganizeData will store the formulas for
gam0-gam4 in the variable analySpec$gamModels as a list. The user can
customize this list with the function loadModels (see example).
</p>


<h3>Value</h3>

<p>Returns a list with GAM formulas
</p>


<h3>Examples</h3>

<pre><code class='language-R'># run analysisOrganizeData function to create the list analySpec
dfr &lt;- analysisOrganizeData (dataCensored, report=NA)
df        &lt;- dfr[["df"]]
analySpec &lt;- dfr[["analySpec"]]

# current models in analySpec
analySpec$gamModels

# set models in analySpec to gam0, gam1, and gam2 only
analySpec$gamModels &lt;- loadModels(c('gam0','gam1','gam2'))

</code></pre>

<hr>
<h2 id='loadModelsResid'>Load Built-in GAM formulas for calculating residuals</h2><span id='topic+loadModelsResid'></span>

<h3>Description</h3>

<p>Load Built-in GAM formulas for calculating residuals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadModelsResid(gamSelect = "doy_flw_sal")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadModelsResid_+3A_gamselect">gamSelect</code></td>
<td>
<p>character vector of models (Current options include 'doy',
'doy_flw_sal', 'doy_flw_sal_int')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with GAM formulas
</p>

<hr>
<h2 id='makeSurvDF'>Convert dataframe to include survival (Surv) objects</h2><span id='topic+makeSurvDF'></span>

<h3>Description</h3>

<p>Within a dataframe, paired numeric fields that use a &quot;_lo&quot; and
&quot;_hi&quot; suffix naming convention (e.g., &quot;conc_lo&quot; &quot;conc_hi&quot;) are combined
into a single Surv object (e.g., &quot;conc&quot;) using the &quot;interval2&quot; option
provided by through the <code>survival::Surv(conc_lo, conc_hi, type =
  "interval2")</code> syntax.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeSurvDF(df, suf_lo = "_lo", suf_hi = "_hi")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makeSurvDF_+3A_df">df</code></td>
<td>
<p>name of data frame</p>
</td></tr>
<tr><td><code id="makeSurvDF_+3A_suf_lo">suf_lo</code></td>
<td>
<p>Column name suffix for &quot;lo&quot; values.  Default = &quot;_lo&quot;</p>
</td></tr>
<tr><td><code id="makeSurvDF_+3A_suf_hi">suf_hi</code></td>
<td>
<p>Column name suffix for &quot;hi&quot; values.  Default = &quot;_hi&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Converting fields to Surv objects works with field pairs that have a &quot;_lo&quot; 
and &quot;_hi&quot; suffix naming convention. The numeric value for &quot;_hi&quot; must be greater than 
or equal to the &quot;_lo&quot; value. Source data that violate this requirement are 
set to NA with a summary report outputted to the console.
</p>
<p>The user can specify their own values for the lo/hi suffixes or use the defaults.
</p>


<h3>Value</h3>

<p>dataframe with Surv fields
</p>


<h3>See Also</h3>

<p><code><a href="#topic+unSurv">unSurv</a></code>,  <code><a href="#topic+unSurvDF">unSurvDF</a></code>,  <code><a href="#topic+impute">impute</a></code>,  <code><a href="#topic+imputeDF">imputeDF</a></code>,  <code><a href="#topic+saveDF">saveDF</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- dataCensored[1:20,]
colnames(df)
df1 &lt;- unSurvDF(df)
colnames(df1)
# Default values
df2 &lt;- makeSurvDF(df1)
colnames(df2)
# User values
df3 &lt;- unSurvDF(df, "_LOW", "_HIGH")
colnames(df3)
df4 &lt;- makeSurvDF(df3, "_LOW", "_HIGH")
colnames(df4)

</code></pre>

<hr>
<h2 id='na2miss'>Recode Data</h2><span id='topic+na2miss'></span><span id='topic+miss2na'></span>

<h3>Description</h3>

<p>Converts missing values (<code>NA</code>s) to or from a user specified value.
From smwrBase package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>na2miss(x, to = -99999)

miss2na(x, from = -99999)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na2miss_+3A_x">x</code></td>
<td>
<p>a vector. Missing values (<code>NA</code>s) are allowed.</p>
</td></tr>
<tr><td><code id="na2miss_+3A_to">to</code></td>
<td>
<p>the replacement value for <code>NA</code>.</p>
</td></tr>
<tr><td><code id="na2miss_+3A_from">from</code></td>
<td>
<p>the target value to match and replace with <code>NA</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object like <code>x</code> with each target value replaced by the
specified value.
</p>


<h3>Note</h3>

<p>The function <code>na2miss</code> converts missing values (<code>NA</code>) to the
value <code>to</code> and is useful to prepare a vector for export and subsequent
use by software external to R that does not handle NAs.<br /> The function
<code>miss2na</code> converts the value <code>from</code> to <code>NA</code> and can be used to
recode data imported from external software that uses a special value to
indicate missing values.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Construct simple substitutions
na2miss(c(1, 2, 3, NA, 5, 6))
</code></pre>

<hr>
<h2 id='nobs'>Compute the Number of Non-Missing Observations</h2><span id='topic+nobs'></span>

<h3>Description</h3>

<p>Compute the number of non-missing observations. 
Provides a 'default' method to handle vectors, and a method for data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nobs_+3A_object">object</code></td>
<td>
<p>Target Object</p>
</td></tr>
<tr><td><code id="nobs_+3A_...">...</code></td>
<td>
<p>Optional parameters (currently ignored)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculate the number of observations in 'object'.
</p>
<p>* For numeric vectors, this is simply the number of non-NA elements, as 
computed by 'sum(!is.na(object))'.
</p>
<p>* For dataframe objects, the result is a vector containing the number of 
non-NA elementes of each column.
</p>
<p>The 'nobs' and 'nobs.lm' functions defined in gtools are simply aliases for 
the functions in the base R 'stats' package, provided for backwards 
compatibility.
</p>
<p>&lsquo;baytrends' borrowed 'gdata::nobs' &rsquo;as is' to avoid being archived in 2020.
https://github.com/tetratech/baytrends/issues/56
</p>


<h3>Note</h3>

<p>The base R package 'stats' now provides a S3 dispatch function for nobs, and
methods for for objects of classes &quot;lm&quot;, &quot;glm&quot;, &quot;nls&quot; and &quot;logLik&quot;, as well
as a default method.
</p>
<p>Since they provided a subset of the the functionality, the base method 
dispatch (nobs) function and method for &quot;lm&quot; objects ('nobs.lm') are, as of 
gdata version 2.10.1, simply aliases for the equivalent functions in the base
R 'stats' package.
</p>
<p>Since &lsquo;gdata'&rsquo;s default method ('nobs.default') processes vectors and hands 
any other data/object types to 'stats:::nobs.default'.
</p>


<h3>Author(s)</h3>

<p>Gregory R. Warnes greg@warnes.net
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1,2,3,5,NA,6,7,1,NA )
length(x)
nobs(x)

df &lt;- data.frame(x=rnorm(100), y=rnorm(100))
df[1,1] &lt;- NA
df[1,2] &lt;- NA
df[2,1] &lt;- NA

nobs(df)

fit &lt;- lm(y ~ x, data=df)
nobs(fit)

</code></pre>

<hr>
<h2 id='parameterList'>Parameter List</h2><span id='topic+parameterList'></span>

<h3>Description</h3>

<p>A lookup table of water quality parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parameterList
</code></pre>


<h3>Format</h3>

<p>A data frame with 82 rows and 13 variables:
</p>

<dl>
<dt>parm</dt><dd><p>&quot;preferred&quot; parameter ID</p>
</dd>
<dt>parmSource</dt><dd><p>parmamter field as may be found in sample data sets</p>
</dd>
<dt>parmCat</dt><dd><p>Parameter Group Header</p>
</dd>
<dt>parmName</dt><dd><p>Full parameter name</p>
</dd>
<dt>parmCalc</dt><dd><p>indicator if parameter is calculated</p>
</dd>
<dt>parmNamelc</dt><dd><p>parameter name in lower case</p>
</dd>
<dt>parmUnits</dt><dd><p>units</p>
</dd>
<dt>parmRecensor</dt><dd><p>numerical value used in log plots if data are reported
as &lt;= 0</p>
</dd>
<dt>parmRO1</dt><dd><p>Parameter sort order level 1</p>
</dd>
<dt>parmRO2</dt><dd><p>Parameter sort order level 2</p>
</dd>
<dt>parmTrend</dt><dd><p>TRUE/FALSE for whether parameter should be analyzed for
trend</p>
</dd>
<dt>logTrans</dt><dd><p>TRUE/FALSE for whether parameter should be analyzed in log
transposed</p>
</dd>
<dt>trendIncrease</dt><dd><p>Should an increase in conccentration be interpreted
as 'improving', 'degrading', 'increasing', or 'decreasing'</p>
</dd>
</dl>


<hr>
<h2 id='sal'>Salinity data</h2><span id='topic+sal'></span>

<h3>Description</h3>

<p>Salinity data, 1984 to 2016, for 8 stations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sal
</code></pre>


<h3>Format</h3>

<p>A data frame with 51,092 rows and 4 variables:
</p>

<dl>
<dt>station</dt><dd><p>CBP Station ID</p>
</dd>
<dt>date</dt><dd><p>date, YYYY-MM-DD</p>
</dd>
<dt>layer</dt><dd><p>sample layer</p>
</dd>
<dt>salinity</dt><dd><p>Measured salinity</p>
</dd>
</dl>


<hr>
<h2 id='saveDF'>Save R object to disk</h2><span id='topic+saveDF'></span>

<h3>Description</h3>

<p>Saves R object to disk using csv and/or Rdata format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveDF(
  rObj,
  note = NULL,
  rData = FALSE,
  csv = TRUE,
  attr = FALSE,
  timeStamp = TRUE,
  folder = "_save_df"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="saveDF_+3A_robj">rObj</code></td>
<td>
<p>Name of R object to save.</p>
</td></tr>
<tr><td><code id="saveDF_+3A_note">note</code></td>
<td>
<p>Suffix to include in file name.</p>
</td></tr>
<tr><td><code id="saveDF_+3A_rdata">rData</code></td>
<td>
<p>Logical field to save rObj as an rData file (FALSE [default]).</p>
</td></tr>
<tr><td><code id="saveDF_+3A_csv">csv</code></td>
<td>
<p>Logical field to save rObj as an a csv file (TRUE [default]).</p>
</td></tr>
<tr><td><code id="saveDF_+3A_attr">attr</code></td>
<td>
<p>Logical field to save data frame attributes as a text file (FALSE [default]).</p>
</td></tr>
<tr><td><code id="saveDF_+3A_timestamp">timeStamp</code></td>
<td>
<p>Logical field to include date/time stamp in file name (TRUE [default]).</p>
</td></tr>
<tr><td><code id="saveDF_+3A_folder">folder</code></td>
<td>
<p>Subdirectory for saving file ('_save_df is default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Output files are saved with an &quot;rObj_note_YYYY_MM_DD_HHMMSS&quot; naming
convetion. By default, files are saved as csv files to a '_save_df'
subdirectory relative to the working directory and include a time stamp in
the file name using utils::write.csv. The default folder can be changed
with the folder argument. Inclusion of a time stamp in the file name
enables saving the same object at multiple steps through an R script, but
can be turned off with the timeStamp argument. To also save object as rData
file, set rData=TRUE.
</p>


<h3>Value</h3>

<p>Nothing returned. Saves R object to disk using csv and/or Rdata format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
df &lt;- data.frame(x=c(1:100))
saveDF(df, 'test_note')

## End(Not run)

</code></pre>

<hr>
<h2 id='seasAdjflow'>Create Daily Seasonally-adjusted Log Flow Residuals</h2><span id='topic+seasAdjflow'></span>

<h3>Description</h3>

<p>Create Daily Seasonally-adjusted Log Flow Residuals. The procedure to compute
daily seasonally-adjusted log flow residuals is the following: 1) Check to
make sure that the raw flow data are in the data set and that seasonally
adjusted values have not already been computed. If so, no additional
computations are performed. If not, then proceed with remaining steps. 2) Add
date features if not already in the data set. 3) Compute and store Log (ln) flow
as 'LogQ...' 4) Compute GAM model and store seasonally adjusted LogQ flow
residuals as 'sa0LogQ...' 5) Smooth seasonally adjusted Log flow residuals by
an averaged values based on dvAvgWin, dvAvgWgt, and dvAvgSides and store as
&quot;saxLogQ...&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seasAdjflow(
  dvFlow = dvFlow,
  siteNumber = NULL,
  dvAvgWin = c(7, 31),
  dvAvgWgt = "weighted",
  dvAvgSides = 1,
  plotResid = c(1)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seasAdjflow_+3A_dvflow">dvFlow</code></td>
<td>
<p>data frame with daily flow data. The flow and data qualifier
code for each site is organized into two columns (e.g., &quot;q01594440&quot;,
&quot;q01594440cd&quot; for USGS gage 01594440)</p>
</td></tr>
<tr><td><code id="seasAdjflow_+3A_sitenumber">siteNumber</code></td>
<td>
<p>a single USGS gage ID</p>
</td></tr>
<tr><td><code id="seasAdjflow_+3A_dvavgwin">dvAvgWin</code></td>
<td>
<p>Averaging window (days) for smoothing the residuals of the
seasonally adjusted daily flow values.</p>
</td></tr>
<tr><td><code id="seasAdjflow_+3A_dvavgwgt">dvAvgWgt</code></td>
<td>
<p>Averaging method (&quot;uniform&quot;, &quot;weighted&quot; [default], or
&quot;centered&quot;) for creating weights. If using &quot;weighted&quot; then use
dvAvgSides=1.  If using &quot;centered&quot; then use dvAvgSides=2.</p>
</td></tr>
<tr><td><code id="seasAdjflow_+3A_dvavgsides">dvAvgSides</code></td>
<td>
<p>If dvAvgSides=1 only past values are used, if dvAvgSides=2
then values are centered around lag 0.</p>
</td></tr>
<tr><td><code id="seasAdjflow_+3A_plotresid">plotResid</code></td>
<td>
<p>plot residuals for selected averaging windows.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return data frame of flow data with additional seasonally adjusted values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Set Retrieval Parameters
yearStart   &lt;- 1983
yearEnd     &lt;- 2015
siteNumbers &lt;- c("01578310")

# Regular Retrieval (default usage)
df &lt;- getUSGSflow(siteNumbers, yearStart, yearEnd, fill=TRUE)
# Apply default smoothing
df &lt;- seasAdjflow(df,"01578310")

</code></pre>

<hr>
<h2 id='selectData'>Select data for analysis from a larger data frame</h2><span id='topic+selectData'></span>

<h3>Description</h3>

<p>Select data for analysis from a larger data frame based on dependent
variable, station, and layer. Removing records with missing
values, performing log-transformations, and adding a centering date are
performed based on settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectData(
  df,
  dep,
  stat,
  layer = NA,
  transform = TRUE,
  remMiss = TRUE,
  analySpec
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selectData_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="selectData_+3A_dep">dep</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id="selectData_+3A_stat">stat</code></td>
<td>
<p>station</p>
</td></tr>
<tr><td><code id="selectData_+3A_layer">layer</code></td>
<td>
<p>layer (optional)</p>
</td></tr>
<tr><td><code id="selectData_+3A_transform">transform</code></td>
<td>
<p>logical field to return log-transformed value (TRUE [default])</p>
</td></tr>
<tr><td><code id="selectData_+3A_remmiss">remMiss</code></td>
<td>
<p>logical field to remove records where dependent
variable, dep, is a missing value (TRUE [default])</p>
</td></tr>
<tr><td><code id="selectData_+3A_analyspec">analySpec</code></td>
<td>
<p>analytical specifications</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned data frame will include dyear and cyear. dyear is the decimal
year computed using smwrBase::baseDay2decimal and smwrBase::baseDay. From
this, the minimum and maximum 'dyear' are averaged. This averaged value,
centerYear, is used to compute the centering date, cyear, using cyear =
dyear - centerYear.
</p>
<p>The variable identified by dep is copied to the variable name dep+&quot;.orig&quot;
(e.g., chla.orig) allowing the user to track the original concentrations. A
new column, recensor, is added. The value of recensor is FALSE unless the
value of dep.orig was &lt;=0. In the cases where dep.orig is &lt;= 0, recensor is
set to TRUE and the value of dep is set to &quot;less-than&quot; a small positive
value which is stored as iSpec$recensor. If transform=TRUE, the returned
data frame will also include a variable &quot;ln&quot;+dep (i.e., &quot;lnchla&quot; for log
transformed chla).
</p>
<p>The data frame will include a column, intervention, which is a factor identifying
different periods of record such as when different laboratory methods were
used and is based on the data frame methodsList that is loaded into the
global environment. This column is set to &quot;A&quot; with only 1 level if the data
frame methodsList has not been loaded into the global environment.
</p>
<p>The data frame will include a column, lowCensor, to indicate whether the
data record occurs in a year with a low level of censoring over that
particular year. The function gamTest uses this column to identify years of
record (i.e., when lowCensor==FALSE) that should not be used in analyses.
</p>
<p>If remMiss=TRUE, then the returned data frame will be down selected by
removing records where the variable identified in 'dep' is missing;
otherwise, no down selection is performed.
</p>
<p>iSpec contains a large list of information
</p>
<p>dep - name of column where dependent variable is stored, could be &quot;ln&quot;+dep
for variables that will be analyzed after natural log transformation
</p>
<p>depOrig - name of original dependent variable, could be same as dep if no
transformation is used
</p>
<p>stat - name of station
</p>
<p>stationMethodGroup - name of station group that the station belongs to,
derived from station list (stationMasterList) and used to identify interventions
specified in methodsList table
</p>
<p>intervenNum - number of interventions found for this station and dependent
variable as derived from methodsList table, a value of 1 is assigned if no
methodsList entry is found
</p>
<p>intervenList - data frame of interventions identified by beginning and ending
date and labeled consecutively starting with &quot;A&quot;
</p>
<p>layer - layer
</p>
<p>layerName - layer name derived from layerLukup
</p>
<p>transform - TRUE/FALSE indicating whether log transformations were taken
</p>
<p>trendIncrease - an indicator for interpretation of an increasing concentration
</p>
<p>logConst - not currently used
</p>
<p>recensor - small value that observations &lt;=0 are recensored to as &quot;less than&quot;
the small value
</p>
<p>censorFrac - data frame indicating the yearly number of observations and
fraction of observations reported as less than, uncensored, interval
censored, less than zero, and recensored; also includes a 'lowCensor' field
indicating which years will be dropped by gamTest due to high yearly
censoring
</p>
<p>yearRangeDropped - year range of data that will be dropped due to censoring
</p>
<p>censorFracSum - censoring overall summary
</p>
<p>centerYear - centering year
</p>
<p>parmName - parameter name
</p>
<p>parmNamelc - parameter name in lower case
</p>
<p>parmUnits - parameter units
</p>
<p>statLayer - station/layer label, e.g., &quot;LE3.1 (S)&quot;
</p>
<p>usgsGageID - USGS gage used for flow adjustments
</p>
<p>usgsGageName - USGS gage used for flow adjustments
</p>
<p>numObservations - number of observations
</p>
<p>dyearBegin - begin date in decimal form
</p>
<p>dyearEnd - end date in decimal form
</p>
<p>dyearLength - period of record length
</p>
<p>yearBegin - period of record begin year
</p>
<p>yearend - period of record end year
</p>
<p>dateBegin - begin date
</p>
<p>dateEnd - end date
</p>
<p>The baseDay and baseDay2decimal functions have been added to this package 
from the smwrBase package.
</p>


<h3>Value</h3>

<p>A nest list is returned. The first element of the nest list is the down-selected
data frame. The second element is the list, iSpec, contains specifications for
data extraction. See examples for usage and details for further discussion of the data
processing and components of each element.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dfr    &lt;- analysisOrganizeData(dataCensored)

# retrieve Secchi depth for Station CB5.4, no transformations are applied
dfr1   &lt;- selectData(dfr[["df"]], 'secchi', 'CB5.4', 'S', transform=FALSE,
                    remMiss=FALSE, analySpec=dfr[["analySpec"]])
df1    &lt;- dfr1[[1]]   # data frame of selected data
iSpec1 &lt;- dfr1[[2]]   # meta data about selected data

# retrieve surface corrected chlorophyll-a concentrations for Station CB5.4,
# missing values are removed and transformation applied
dfr2   &lt;- selectData(dfr[["df"]], 'chla', 'CB5.4', 'S', analySpec=dfr[["analySpec"]])
df2    &lt;- dfr2[[1]]   # data frame of selected data
iSpec2 &lt;- dfr2[[2]]   # meta data about selected data

## End(Not run)
</code></pre>

<hr>
<h2 id='stationMasterList'>Chesapeake Bay Program long-term tidal monitoring stations</h2><span id='topic+stationMasterList'></span>

<h3>Description</h3>

<p>Chesapeake Bay Program long-term tidal monitoring stations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stationMasterList
</code></pre>


<h3>Format</h3>

<p>A data frame with 145 rows and 19 variables:
</p>

<dl>
<dt>station</dt><dd><p>Water quality station code</p>
</dd>
<dt>state</dt><dd><p>State location</p>
</dd>
<dt>locationType</dt><dd><p>As identified in the state trend reports, whether this
station is in the mainstem or tributary monitoring</p>
</dd>
<dt>waterbody</dt><dd><p>Location as identified in the CBP CIMS database</p>
</dd>
<dt>latitude</dt><dd><p>From the CBP CIMS database, and verified in a GIS map</p>
</dd>
<dt>longitude</dt><dd><p>From the CBP CIMS database, and verified in a GIS map</p>
</dd>
<dt>cbSeg92</dt><dd><p>Match to CB 92 Segmentation scheme (for 303d list)</p>
</dd>
<dt>usgsGageName</dt><dd><p>Manual match to a USGS fall-line monitoring station
(See usgsGages$siteName)</p>
</dd>
<dt>usgsGageID</dt><dd><p>USGS station code (See usgsGages$siteNumber)</p>
</dd>
<dt>usgsGageMatch</dt><dd><p>Identifies how the USGS-to-TribStation match was
made. Direct: If the station falls within a tributary with a USGS station,
or in the mainstem. Indirect: If the station is in a small sub-tributary
of one of the major tributaries. The USGS station may not be that
representative, but it is better than matching to the Susquehanna.
SusDefault: If there was no clear match, the tidal station was matched to
the Susquehanna River.</p>
</dd>
<dt>stationRO1</dt><dd><p>Station sort order level 1</p>
</dd>
<dt>stationRO2</dt><dd><p>Station sort order level 2</p>
</dd>
<dt>stationGrpName</dt><dd><p>Station group header</p>
</dd>
<dt>stationMethodGroup</dt><dd><p>Foreign key to methodsList table</p>
</dd>
<dt>hydroTerm</dt><dd><p>&quot;flow&quot; or &quot;salinity&quot; to indicate whether to model flow or
salinity effects (if missing, &quot;flow&quot; assumed)</p>
</dd>
<dt>flwAvgWin</dt><dd><p>list of averaging windows if flow is selected in
hydroTerm (options are: 1, 5, 10, 15, 20, 30, 40, 50, 60, 90, 120, 150,
180, 210)</p>
</dd>
<dt>flwParms</dt><dd><p>list of parameters to model with flow (regardless of
hydroTerm value), each parameter separated by a space</p>
</dd>
<dt>salParms</dt><dd><p>list of parameters to model with salinity (regardless of
hydroTerm value), each parameter separated by a space</p>
</dd>
<dt>notes</dt><dd><p>Optional note to track updates</p>
</dd>
</dl>


<hr>
<h2 id='unSurv'>Converts Surv object into a 3-column matrix</h2><span id='topic+unSurv'></span>

<h3>Description</h3>

<p>Converts Surv object into a 3-column matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unSurv(x, col_lo = "lo", col_hi = "hi")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unSurv_+3A_x">x</code></td>
<td>
<p>vector (Surv object)</p>
</td></tr>
<tr><td><code id="unSurv_+3A_col_lo">col_lo</code></td>
<td>
<p>Output column name for &quot;lo&quot; values.  Default = &quot;lo&quot;</p>
</td></tr>
<tr><td><code id="unSurv_+3A_col_hi">col_hi</code></td>
<td>
<p>Output column name for &quot;hi&quot; values.  Default = &quot;hi&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The third column of the returned matrix (type) has the following 
meanings:
</p>
<p>1  &ndash; no censoring
</p>
<p>2  &ndash; left censored (&quot;less than in a survival sense&quot;
, e.g., [-Inf to 10], &lt;10)
</p>
<p>3  &ndash; interval censored (&quot;less than in a water quality sense&quot;, 
e.g., &quot;0 - &lt;3&quot;, &quot;1 - 3&quot;)
</p>
<p>NA &ndash; missing value
</p>
<p>The user can specify the names of the low and high columns in the output.
Defaults are &quot;lo&quot; and &quot;hi&quot;.
</p>


<h3>Value</h3>

<p>Returns a 3-column matrix: lo, hi, type
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeSurvDF">makeSurvDF</a></code>,  <code><a href="#topic+unSurvDF">unSurvDF</a></code>
,  <code><a href="#topic+impute">impute</a></code>,  <code><a href="#topic+imputeDF">imputeDF</a></code>,  <code><a href="#topic+saveDF">saveDF</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df1 &lt;- dataCensored[dataCensored$station=="CB3.3C"
          &amp; dataCensored$date &lt; as.POSIXct("1985-08-01") 
          , c("station","date","chla")]
colnames(df1)
# Default values
chla_1 &lt;- unSurv(df1$chla)
colnames(chla_1)
# User values
chla_2 &lt;- unSurv(df1$chla, "LOW", "HIGH")
colnames(chla_2)

</code></pre>

<hr>
<h2 id='unSurvDF'>Converts Surv objects in a dataframe to &quot;lo&quot; and &quot;hi&quot; values</h2><span id='topic+unSurvDF'></span>

<h3>Description</h3>

<p>Converts Surv objects in a dataframe to &quot;lo&quot; (i.e., lower) and
&quot;hi&quot; (i.e., upper) values. The user can specify their own values or use the
defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unSurvDF(df, suf_lo = "_lo", suf_hi = "_hi")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unSurvDF_+3A_df">df</code></td>
<td>
<p>dataframe with Surv objects</p>
</td></tr>
<tr><td><code id="unSurvDF_+3A_suf_lo">suf_lo</code></td>
<td>
<p>Column name suffix for &quot;lo&quot; values.  Default = &quot;_lo&quot;</p>
</td></tr>
<tr><td><code id="unSurvDF_+3A_suf_hi">suf_hi</code></td>
<td>
<p>Column name suffix for &quot;hi&quot; values.  Default = &quot;_hi&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns dataframe with censored data converted to lo/hi format
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeSurvDF">makeSurvDF</a></code>,  <code><a href="#topic+unSurv">unSurv</a></code>
,  <code><a href="#topic+impute">impute</a></code>,  <code><a href="#topic+imputeDF">imputeDF</a></code>,  <code><a href="#topic+saveDF">saveDF</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- dataCensored[dataCensored$station=="CB3.3C", ][1:20,]
colnames(df)
# Default values
df2 &lt;- unSurvDF(df)
colnames(df2)
# User values
df3 &lt;- unSurvDF(df, "_LOW", "_HIGH")
colnames(df3)

</code></pre>

<hr>
<h2 id='usgsGages'>USGS Gages</h2><span id='topic+usgsGages'></span>

<h3>Description</h3>

<p>List of core USGS gages for CBP trend analyses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>usgsGages
</code></pre>


<h3>Format</h3>

<p>A data frame with 9 rows and 2 variables:
</p>

<dl>
<dt>usgsGageID</dt><dd><p>USGS Gage ID</p>
</dd>
<dt>siteName</dt><dd><p>USGS Site Name</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
