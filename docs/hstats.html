<!DOCTYPE html><html><head><title>Help for package hstats</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hstats}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#[.hstats_matrix'><p>Subsets &quot;hstats_matrix&quot; Object</p></a></li>
<li><a href='#average_loss'><p>Average Loss</p></a></li>
<li><a href='#dim.hstats_matrix'><p>Dimensions of &quot;hstats_matrix&quot; Object</p></a></li>
<li><a href='#dimnames.hstats_matrix'><p>Dimnames of &quot;hstats_matrix&quot; Object</p></a></li>
<li><a href='#dimnames&lt;-.hstats_matrix'><p>Dimnames (Replacement Method) of &quot;hstats_matrix&quot;</p></a></li>
<li><a href='#h2'><p>Total Interaction Strength</p></a></li>
<li><a href='#h2_overall'><p>Overall Interaction Strength</p></a></li>
<li><a href='#h2_pairwise'><p>Pairwise Interaction Strength</p></a></li>
<li><a href='#h2_threeway'><p>Three-way Interaction Strength</p></a></li>
<li><a href='#hstats'><p>Calculate Interaction Statistics</p></a></li>
<li><a href='#ice'><p>Individual Conditional Expectations</p></a></li>
<li><a href='#multivariate_grid'><p>Multivariate Grid</p></a></li>
<li><a href='#partial_dep'><p>Partial Dependence Plot</p></a></li>
<li><a href='#pd_importance'><p>PD Bases Importance (Experimental)</p></a></li>
<li><a href='#perm_importance'><p>Permutation Importance</p></a></li>
<li><a href='#plot.hstats'><p>Plot Method for &quot;hstats&quot; Object</p></a></li>
<li><a href='#plot.hstats_matrix'><p>Plots &quot;hstats_matrix&quot; Object</p></a></li>
<li><a href='#plot.ice'><p>Plots &quot;ice&quot; Object</p></a></li>
<li><a href='#plot.partial_dep'><p>Plots &quot;partial_dep&quot; Object</p></a></li>
<li><a href='#print.hstats'><p>Print Method</p></a></li>
<li><a href='#print.hstats_matrix'><p>Prints &quot;hstats_matrix&quot; Object</p></a></li>
<li><a href='#print.hstats_summary'><p>Print Method</p></a></li>
<li><a href='#print.ice'><p>Prints &quot;ice&quot; Object</p></a></li>
<li><a href='#print.partial_dep'><p>Prints &quot;partial_dep&quot; Object</p></a></li>
<li><a href='#summary.hstats'><p>Summary Method</p></a></li>
<li><a href='#univariate_grid'><p>Univariate Grid</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Interaction Statistics</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Fast, model-agnostic implementation of different H-statistics
    introduced by Jerome H. Friedman and Bogdan E. Popescu (2008)
    &lt;<a href="https://doi.org/10.1214%2F07-AOAS148">doi:10.1214/07-AOAS148</a>&gt;.  These statistics quantify interaction
    strength per feature, feature pair, and feature triple.  The package
    supports multi-output predictions and can account for case weights.
    In addition, several variants of the original statistics are provided.
    The shape of the interactions can be explored through partial
    dependence plots or individual conditional expectation plots. 'DALEX'
    explainers, meta learners ('mlr3', 'tidymodels', 'caret') and most
    other models work out-of-the-box.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mayer79/hstats">https://github.com/mayer79/hstats</a>,
<a href="https://mayer79.github.io/hstats/">https://mayer79.github.io/hstats/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mayer79/hstats/issues">https://github.com/mayer79/hstats/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-03 15:31:02 UTC; Michael</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Mayer [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Mayer &lt;mayermichael79@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-03 15:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+5B.hstats_matrix'>Subsets &quot;hstats_matrix&quot; Object</h2><span id='topic++5B.hstats_matrix'></span>

<h3>Description</h3>

<p>Use standard square bracket subsetting to select rows and/or columns of
statistics &quot;M&quot; (and &quot;SE&quot; in case of permutation importance statistics).
Implies <code>head()</code> and <code>tail()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats_matrix'
x[i, j, ...]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B.hstats_matrix_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_matrix&quot;.</p>
</td></tr>
<tr><td><code id="+2B5B.hstats_matrix_+3A_i">i</code></td>
<td>
<p>Row subsetting.</p>
</td></tr>
<tr><td><code id="+2B5B.hstats_matrix_+3A_j">j</code></td>
<td>
<p>Column subsetting.</p>
</td></tr>
<tr><td><code id="+2B5B.hstats_matrix_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new object of class &quot;hstats_matrix&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- lm(as.matrix(iris[1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
imp &lt;- perm_importance(fit, X = iris, y = c("Sepal.Length", "Sepal.Width"))
head(imp, 1)
tail(imp, 2)
imp[1, "Sepal.Length"]
imp[1]
imp[, "Sepal.Width"]$SE
plot(imp[, "Sepal.Width"])
</code></pre>

<hr>
<h2 id='average_loss'>Average Loss</h2><span id='topic+average_loss'></span><span id='topic+average_loss.default'></span><span id='topic+average_loss.ranger'></span><span id='topic+average_loss.explainer'></span>

<h3>Description</h3>

<p>Calculates the average loss of a model on a given dataset,
optionally grouped by a variable. Use <code>plot()</code> to visualize the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>average_loss(object, ...)

## Default S3 method:
average_loss(
  object,
  X,
  y,
  pred_fun = stats::predict,
  loss = "squared_error",
  agg_cols = FALSE,
  BY = NULL,
  by_size = 4L,
  w = NULL,
  ...
)

## S3 method for class 'ranger'
average_loss(
  object,
  X,
  y,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  loss = "squared_error",
  agg_cols = FALSE,
  BY = NULL,
  by_size = 4L,
  w = NULL,
  ...
)

## S3 method for class 'explainer'
average_loss(
  object,
  X = object[["data"]],
  y = object[["y"]],
  pred_fun = object[["predict_function"]],
  loss = "squared_error",
  agg_cols = FALSE,
  BY = NULL,
  by_size = 4L,
  w = object[["weights"]],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="average_loss_+3A_object">object</code></td>
<td>
<p>Fitted model object.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>pred_fun(object, X, ...)</code>,
for instance <code>type = "response"</code> in a <code><a href="stats.html#topic+glm">glm()</a></code> model, or <code>reshape = TRUE</code> in a
multiclass XGBoost model.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_x">X</code></td>
<td>
<p>A data.frame or matrix serving as background dataset.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_y">y</code></td>
<td>
<p>Vector/matrix of the response, or the corresponding column names in <code>X</code>.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_pred_fun">pred_fun</code></td>
<td>
<p>Prediction function of the form <code style="white-space: pre;">&#8288;function(object, X, ...)&#8288;</code>,
providing <code class="reqn">K \ge 1</code> predictions per row. Its first argument represents the
model <code>object</code>, its second argument a data structure like <code>X</code>. Additional arguments
(such as <code>type = "response"</code> in a GLM, or <code>reshape = TRUE</code> in a multiclass XGBoost
model) can be passed via <code>...</code>. The default, <code><a href="stats.html#topic+predict">stats::predict()</a></code>, will work in
most cases.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_loss">loss</code></td>
<td>
<p>One of &quot;squared_error&quot;, &quot;logloss&quot;, &quot;mlogloss&quot;, &quot;poisson&quot;,
&quot;gamma&quot;, &quot;absolute_error&quot;, &quot;classification_error&quot;. Alternatively, a loss function
can be provided that turns observed and predicted values into a numeric vector or
matrix of unit losses of the same length as <code>X</code>.
For &quot;mlogloss&quot;, the response <code>y</code> can either be a dummy matrix or a discrete vector.
The latter case is handled via a fast version of <code>model.matrix(~ as.factor(y) + 0)</code>.
For &quot;classification_error&quot;, both predictions and responses can be non-numeric.
For &quot;squared_error&quot;, both predictions and responses can be factors with identical
levels. In this case, squared error is evaulated for each one-hot-encoded column.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_agg_cols">agg_cols</code></td>
<td>
<p>Should multivariate losses be summed up? Default is <code>FALSE</code>.
In combination with the squared error loss, <code>agg_cols = TRUE</code> gives
the Brier score for (probabilistic) classification.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_by">BY</code></td>
<td>
<p>Optional grouping vector or column name.
Numeric <code>BY</code> variables with more than <code>by_size</code> disjoint values will be
binned into <code>by_size</code> quantile groups of similar size.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_by_size">by_size</code></td>
<td>
<p>Numeric <code>BY</code> variables with more than <code>by_size</code> unique values will
be binned into quantile groups. Only relevant if <code>BY</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="average_loss_+3A_w">w</code></td>
<td>
<p>Optional vector of case weights. Can also be a column name of <code>X</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>average_loss(default)</code>: Default method.
</p>
</li>
<li> <p><code>average_loss(ranger)</code>: Method for &quot;ranger&quot; models.
</p>
</li>
<li> <p><code>average_loss(explainer)</code>: Method for DALEX &quot;explainer&quot;.
</p>
</li></ul>


<h3>Losses</h3>

<p>The default <code>loss</code> is the &quot;squared_error&quot;. Other choices:
</p>

<ul>
<li><p> &quot;absolute_error&quot;: The absolute error is the loss corresponding to median regression.
</p>
</li>
<li><p> &quot;poisson&quot;: Unit Poisson deviance, i.e., the loss function used in
Poisson regression. Actual values <code>y</code> and predictions must be non-negative.
</p>
</li>
<li><p> &quot;gamma&quot;: Unit gamma deviance, i.e., the loss function of Gamma regression.
Actual values <code>y</code> and predictions must be positive.
</p>
</li>
<li><p> &quot;logloss&quot;: The Log Loss is the loss function used in logistic regression,
and the top choice in probabilistic binary classification. Responses <code>y</code> and
predictions must be between 0 and 1. Predictions represent probabilities of
having a &quot;1&quot;.
</p>
</li>
<li><p> &quot;mlogloss&quot;: Multi-Log-Loss is the natural loss function in probabilistic multi-class
situations. If there are K classes and n observations, the predictions form
a (n x K) matrix of probabilities (with row-sums 1).
The observed values <code>y</code> are either passed as (n x K) dummy matrix,
or as discrete vector with corresponding levels.
The latter case is turned into a dummy matrix by a fast version of
<code>model.matrix(~ as.factor(y) + 0)</code>.
</p>
</li>
<li><p> &quot;classification_error&quot;: Misclassification error. Both the
observed values <code>y</code> and the predictions can be character/factor. This
loss function can be used in non-probabilistic classification settings.
BUT: Probabilistic classification (with &quot;mlogloss&quot;) is clearly preferred in most
situations.
</p>
</li>
<li><p> A function with signature <code>f(actual, predicted)</code>, returning a numeric
vector or matrix of the same length as the input.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ ., data = iris)
average_loss(fit, X = iris, y = "Sepal.Length")
average_loss(fit, X = iris, y = iris$Sepal.Length, BY = iris$Sepal.Width)
average_loss(fit, X = iris, y = "Sepal.Length", BY = "Sepal.Width")

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width + Species, data = iris)
average_loss(fit, X = iris, y = iris[, 1:2])
L &lt;- average_loss(
  fit, X = iris, y = iris[, 1:2], loss = "gamma", BY = "Species"
)
L
plot(L)
</code></pre>

<hr>
<h2 id='dim.hstats_matrix'>Dimensions of &quot;hstats_matrix&quot; Object</h2><span id='topic+dim.hstats_matrix'></span>

<h3>Description</h3>

<p>Implies <code>nrow()</code> and <code>ncol()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats_matrix'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.hstats_matrix_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_matrix&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of length two providing the number of rows and columns
of &quot;M&quot; object stored in <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
s &lt;- hstats(fit, X = iris[-1])
x &lt;- h2_pairwise(s)
dim(x)
nrow(x)
ncol(x)
</code></pre>

<hr>
<h2 id='dimnames.hstats_matrix'>Dimnames of &quot;hstats_matrix&quot; Object</h2><span id='topic+dimnames.hstats_matrix'></span>

<h3>Description</h3>

<p>Extracts dimnames of the &quot;M&quot; matrix in <code>x</code>. Implies <code>rownames()</code> and <code>colnames()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats_matrix'
dimnames(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimnames.hstats_matrix_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_matrix&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dimnames of the statistics matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- lm(as.matrix(iris[1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[3:5], verbose = FALSE)
x &lt;- h2_pairwise(s)
dimnames(x)
rownames(x)
colnames(x)
</code></pre>

<hr>
<h2 id='dimnames+26lt+3B-.hstats_matrix'>Dimnames (Replacement Method) of &quot;hstats_matrix&quot;</h2><span id='topic+dimnames+3C-.hstats_matrix'></span>

<h3>Description</h3>

<p>This implies <code>colnames(x) &lt;- ...</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 replacement method for class 'hstats_matrix'
dimnames(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimnames+2B26lt+2B3B-.hstats_matrix_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_matrix&quot;.</p>
</td></tr>
<tr><td><code id="dimnames+2B26lt+2B3B-.hstats_matrix_+3A_value">value</code></td>
<td>
<p>A list with rownames and column names compliant with <code style="white-space: pre;">&#8288;$M&#8288;</code> (and <code style="white-space: pre;">&#8288;$SE&#8288;</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Like <code>x</code>, but with replaced dimnames.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- lm(as.matrix(iris[1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[3:5], verbose = FALSE)
x &lt;- h2_overall(s)
colnames(x) &lt;- c("Sepal Length", "Sepal Width")
plot(x)

rownames(x)[2:3] &lt;- c("Petal Width", "Petal Length")
plot(x)
</code></pre>

<hr>
<h2 id='h2'>Total Interaction Strength</h2><span id='topic+h2'></span><span id='topic+h2.default'></span><span id='topic+h2.hstats'></span>

<h3>Description</h3>

<p>Proportion of prediction variability unexplained by main effects of <code>v</code>, see Details.
Use <code>plot()</code> to get a barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2(object, ...)

## Default S3 method:
h2(object, ...)

## S3 method for class 'hstats'
h2(object, normalize = TRUE, squared = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="h2_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="h2_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the model is additive in all features, then the (centered) prediction
function <code class="reqn">F</code> equals the sum of the (centered) partial dependence
functions <code class="reqn">F_j(x_j)</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">
  F(\mathbf{x}) = \sum_{j}^{p} F_j(x_j)
</code>
</p>

<p>(check <code><a href="#topic+partial_dep">partial_dep()</a></code> for all definitions).
To measure the relative amount of variability unexplained by all main effects,
we can therefore study the test statistic of total interaction strength
</p>
<p style="text-align: center;"><code class="reqn">
  H^2 = \frac{\frac{1}{n} \sum_{i = 1}^n \big[F(\mathbf{x}_i) - 
  \sum_{j = 1}^p\hat F_j(x_{ij})\big]^2}{\frac{1}{n} 
  \sum_{i = 1}^n\big[F(\mathbf{x}_i)\big]^2}.
</code>
</p>

<p>A value of 0 means there are no interaction effects at all.
Due to (typically undesired) extrapolation effects, depending on the model,
values above 1 may occur.
</p>
<p>In Żółkowski et al. (2023), <code class="reqn">1 - H^2</code> is called <em>additivity index</em>.
A similar measure using accumulated local effects is discussed in Molnar (2020).
</p>


<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>h2(default)</code>: Default method of total interaction strength.
</p>
</li>
<li> <p><code>h2(hstats)</code>: Total interaction strength from &quot;interact&quot; object.
</p>
</li></ul>


<h3>References</h3>


<ol>
<li><p> Żółkowski, Artur, Mateusz Krzyziński, and Paweł Fijałkowski.
<em>Methods for extraction of interactions from predictive models.</em>
Undergraduate thesis. Faculty of Mathematics and Information Science,
Warsaw University of Technology (2023).
</p>
</li>
<li><p> Molnar, Christoph, Giuseppe Casalicchio, and Bernd Bischl&quot;.
<em>Quantifying Model Complexity via Functional Decomposition for Better Post-hoc Interpretability</em>,
in Machine Learning and Knowledge Discovery in Databases,
Springer International Publishing (2020): 193-204.
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+hstats">hstats()</a></code>, <code><a href="#topic+h2_overall">h2_overall()</a></code>, <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code>, <code><a href="#topic+h2_threeway">h2_threeway()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
s &lt;- hstats(fit, X = iris[, -1])
h2(s)

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[, 3:5])
h2(s)

# MODEL 3: No interactions
fit &lt;- lm(Sepal.Length ~ ., data = iris)
s &lt;- hstats(fit, X = iris[, -1], verbose = FALSE)
h2(s)
</code></pre>

<hr>
<h2 id='h2_overall'>Overall Interaction Strength</h2><span id='topic+h2_overall'></span><span id='topic+h2_overall.default'></span><span id='topic+h2_overall.hstats'></span>

<h3>Description</h3>

<p>Friedman and Popescu's statistic of overall interaction strength per
feature, see Details. Use <code>plot()</code> to get a barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2_overall(object, ...)

## Default S3 method:
h2_overall(object, ...)

## S3 method for class 'hstats'
h2_overall(
  object,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2_overall_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="h2_overall_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="h2_overall_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_overall_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_overall_+3A_sort">sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td></tr>
<tr><td><code id="h2_overall_+3A_zero">zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The logic of Friedman and Popescu (2008) is as follows:
If there are no interactions involving feature <code class="reqn">x_j</code>, we can decompose the
(centered) prediction function <code class="reqn">F</code> into the sum of the (centered) partial
dependence <code class="reqn">F_j</code> on <code class="reqn">x_j</code> and the (centered) partial dependence
<code class="reqn">F_{\setminus j}</code> on all other features <code class="reqn">\mathbf{x}_{\setminus j}</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">
  F(\mathbf{x}) = F_j(x_j) + F_{\setminus j}(\mathbf{x}_{\setminus j}).
</code>
</p>

<p>Correspondingly, Friedman and Popescu's statistic of overall interaction
strength of <code class="reqn">x_j</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">
  H_j^2 = \frac{\frac{1}{n} \sum_{i = 1}^n\big[F(\mathbf{x}_i) - 
  \hat F_j(x_{ij}) - \hat F_{\setminus j}(\mathbf{x}_{i\setminus j})
  \big]^2}{\frac{1}{n} \sum_{i = 1}^n\big[F(\mathbf{x}_i)\big]^2}
</code>
</p>

<p>(check <code><a href="#topic+partial_dep">partial_dep()</a></code> for all definitions).
</p>
<p><strong>Remarks:</strong>
</p>

<ol>
<li><p> Partial dependence functions (and <code class="reqn">F</code>) are all centered to
(possibly weighted) mean 0.
</p>
</li>
<li><p> Partial dependence functions (and <code class="reqn">F</code>) are evaluated over the data distribution.
This is different to partial dependence plots, where one uses a fixed grid.
</p>
</li>
<li><p> Weighted versions follow by replacing all arithmetic means by corresponding
weighted means.
</p>
</li>
<li><p> Multivariate predictions can be treated in a component-wise manner.
</p>
</li>
<li><p> Due to (typically undesired) extrapolation effects of partial dependence functions,
depending on the model, values above 1 may occur.
</p>
</li>
<li> <p><code class="reqn">H^2_j = 0</code> means there are no interactions associated with <code class="reqn">x_j</code>.
The higher the value, the more prediction variability comes from interactions
with <code class="reqn">x_j</code>.
</p>
</li>
<li><p> Since the denominator is the same for all features, the values of the test
statistics can be compared across features.
</p>
</li></ol>



<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>h2_overall(default)</code>: Default method of overall interaction strength.
</p>
</li>
<li> <p><code>h2_overall(hstats)</code>: Overall interaction strength from &quot;hstats&quot; object.
</p>
</li></ul>


<h3>References</h3>

<p>Friedman, Jerome H., and Bogdan E. Popescu. <em>&quot;Predictive Learning via Rule Ensembles.&quot;</em>
The Annals of Applied Statistics 2, no. 3 (2008): 916-54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hstats">hstats()</a></code>, <code><a href="#topic+h2">h2()</a></code>, <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code>, <code><a href="#topic+h2_threeway">h2_threeway()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
s &lt;- hstats(fit, X = iris[, -1])
h2_overall(s)
plot(h2_overall(s))

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[, 3:5], verbose = FALSE)
plot(h2_overall(s, zero = FALSE))
</code></pre>

<hr>
<h2 id='h2_pairwise'>Pairwise Interaction Strength</h2><span id='topic+h2_pairwise'></span><span id='topic+h2_pairwise.default'></span><span id='topic+h2_pairwise.hstats'></span>

<h3>Description</h3>

<p>Friedman and Popescu's statistic of pairwise interaction strength, see Details.
Use <code>plot()</code> to get a barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2_pairwise(object, ...)

## Default S3 method:
h2_pairwise(object, ...)

## S3 method for class 'hstats'
h2_pairwise(
  object,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2_pairwise_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="h2_pairwise_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="h2_pairwise_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_pairwise_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_pairwise_+3A_sort">sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td></tr>
<tr><td><code id="h2_pairwise_+3A_zero">zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Following Friedman and Popescu (2008), if there are no interaction effects between
features <code class="reqn">x_j</code> and <code class="reqn">x_k</code>, their two-dimensional (centered) partial dependence
function <code class="reqn">F_{jk}</code> can be written as the sum of the (centered) univariate partial
dependencies <code class="reqn">F_j</code> and <code class="reqn">F_k</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">
  F_{jk}(x_j, x_k) = F_j(x_j)+ F_k(x_k).
</code>
</p>

<p>Correspondingly, Friedman and Popescu's statistic of pairwise
interaction strength between <code class="reqn">x_j</code> and <code class="reqn">x_k</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">
  H_{jk}^2 = \frac{A_{jk}}{\frac{1}{n} \sum_{i = 1}^n\big[\hat F_{jk}(x_{ij}, x_{ik})\big]^2},
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  A_{jk} = \frac{1}{n} \sum_{i = 1}^n\big[\hat F_{jk}(x_{ij}, x_{ik}) - 
   \hat F_j(x_{ij}) - \hat F_k(x_{ik})\big]^2
</code>
</p>

<p>(check <code><a href="#topic+partial_dep">partial_dep()</a></code> for all definitions).
</p>
<p><strong>Remarks:</strong>
</p>

<ol>
<li><p> Remarks 1 to 5 of <code><a href="#topic+h2_overall">h2_overall()</a></code> also apply here.
</p>
</li>
<li> <p><code class="reqn">H^2_{jk} = 0</code> means there are no interaction effects between <code class="reqn">x_j</code>
and <code class="reqn">x_k</code>. The larger the value, the more of the joint effect of the two
features comes from the interaction.
</p>
</li>
<li><p> Since the denominator differs between variable pairs, unlike <code class="reqn">H_j</code>,
this test statistic is difficult to compare between variable pairs.
If both main effects are very weak, a negligible interaction can get a
high <code class="reqn">H^2_{jk}</code>. Therefore, Friedman and Popescu (2008) suggests to calculate
<code class="reqn">H^2_{jk}</code> only for <em>important</em> variables (see &quot;Modification&quot; below).
</p>
</li></ol>

<p><strong>Modification</strong>
</p>
<p>To be better able to compare pairwise interaction strength across variable pairs,
and to overcome the problem mentioned in the last remark, we suggest as alternative
the unnormalized test statistic on the scale of the predictions,
i.e., <code class="reqn">\sqrt{A_{jk}}</code>. Set <code>normalize = FALSE</code> and <code>squared = FALSE</code> to obtain
this statistic.
Furthermore, instead of focusing on pairwise calculations for the most <em>important</em>
features, we can select features with <em>strongest overall interactions</em>.
</p>


<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>h2_pairwise(default)</code>: Default pairwise interaction strength.
</p>
</li>
<li> <p><code>h2_pairwise(hstats)</code>: Pairwise interaction strength from &quot;hstats&quot; object.
</p>
</li></ul>


<h3>References</h3>

<p>Friedman, Jerome H., and Bogdan E. Popescu. <em>&quot;Predictive Learning via Rule Ensembles.&quot;</em>
The Annals of Applied Statistics 2, no. 3 (2008): 916-54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hstats">hstats()</a></code>, <code><a href="#topic+h2">h2()</a></code>, <code><a href="#topic+h2_overall">h2_overall()</a></code>, <code><a href="#topic+h2_threeway">h2_threeway()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
s &lt;- hstats(fit, X = iris[, -1])

# Proportion of joint effect coming from pairwise interaction
# (for features with strongest overall interactions)
h2_pairwise(s)
h2_pairwise(s, zero = FALSE)  # Drop 0

# Absolute measure as alternative
abs_h &lt;- h2_pairwise(s, normalize = FALSE, squared = FALSE, zero = FALSE)
abs_h
abs_h$M

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[, 3:5], verbose = FALSE)
x &lt;- h2_pairwise(s)
plot(x)
</code></pre>

<hr>
<h2 id='h2_threeway'>Three-way Interaction Strength</h2><span id='topic+h2_threeway'></span><span id='topic+h2_threeway.default'></span><span id='topic+h2_threeway.hstats'></span>

<h3>Description</h3>

<p>Friedman and Popescu's statistic of three-way interaction strength, see Details.
Use <code>plot()</code> to get a barplot. In <code>hstats()</code>, set <code>threeway_m</code> to a value above 2
to calculate this statistic for all feature triples of the <code>threeway_m</code>
features with strongest overall interaction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2_threeway(object, ...)

## Default S3 method:
h2_threeway(object, ...)

## S3 method for class 'hstats'
h2_threeway(
  object,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2_threeway_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="h2_threeway_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="h2_threeway_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_threeway_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2_threeway_+3A_sort">sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td></tr>
<tr><td><code id="h2_threeway_+3A_zero">zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Friedman and Popescu (2008) describe a test statistic to measure three-way
interactions: in case there are no three-way interactions between features
<code class="reqn">x_j</code>, <code class="reqn">x_k</code> and <code class="reqn">x_l</code>, their (centered) three-dimensional partial
dependence function <code class="reqn">F_{jkl}</code> can be decomposed into lower order terms:
</p>
<p style="text-align: center;"><code class="reqn">
  F_{jkl}(x_j, x_k, x_l) = B_{jkl} - C_{jkl}
</code>
</p>

<p>with
</p>
<p style="text-align: center;"><code class="reqn">
  B_{jkl} = F_{jk}(x_j, x_k) + F_{jl}(x_j, x_l) + F_{kl}(x_k, x_l)
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
  C_{jkl} =  F_j(x_j) + F_k(x_k) + F_l(x_l).
</code>
</p>

<p>The squared and scaled difference between the two sides of the equation leads to the statistic
</p>
<p style="text-align: center;"><code class="reqn">
  H_{jkl}^2 = \frac{\frac{1}{n} \sum_{i = 1}^n \big[\hat F_{jkl}(x_{ij}, x_{ik}, x_{il}) - B^{(i)}_{jkl} + C^{(i)}_{jkl}\big]^2}{\frac{1}{n} \sum_{i = 1}^n \hat F_{jkl}(x_{ij}, x_{ik}, x_{il})^2},
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  B^{(i)}_{jkl} = \hat F_{jk}(x_{ij}, x_{ik}) + \hat F_{jl}(x_{ij}, x_{il}) + 
  \hat F_{kl}(x_{ik}, x_{il})
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
  C^{(i)}_{jkl} = \hat F_j(x_{ij}) + \hat F_k(x_{ik}) + \hat F_l(x_{il}).
</code>
</p>

<p>Similar remarks as for <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code> apply.
</p>


<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>h2_threeway(default)</code>: Default pairwise interaction strength.
</p>
</li>
<li> <p><code>h2_threeway(hstats)</code>: Pairwise interaction strength from &quot;hstats&quot; object.
</p>
</li></ul>


<h3>References</h3>

<p>Friedman, Jerome H., and Bogdan E. Popescu. <em>&quot;Predictive Learning via Rule Ensembles.&quot;</em>
The Annals of Applied Statistics 2, no. 3 (2008): 916-54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hstats">hstats()</a></code>, <code><a href="#topic+h2">h2()</a></code>, <code><a href="#topic+h2_overall">h2_overall()</a></code>, <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(uptake ~ Type * Treatment * conc, data = CO2)
s &lt;- hstats(fit, X = CO2[, 2:4], threeway_m = 5)
h2_threeway(s)

#' MODEL 2: Multivariate output (taking just twice the same response as example)
fit &lt;- lm(cbind(up = uptake, up2 = 2 * uptake) ~ Type * Treatment * conc, data = CO2)
s &lt;- hstats(fit, X = CO2[, 2:4], threeway_m = 5)
h2_threeway(s)
h2_threeway(s, normalize = FALSE, squared = FALSE)  # Unnormalized H
plot(h2_threeway(s))
</code></pre>

<hr>
<h2 id='hstats'>Calculate Interaction Statistics</h2><span id='topic+hstats'></span><span id='topic+hstats.default'></span><span id='topic+hstats.ranger'></span><span id='topic+hstats.explainer'></span>

<h3>Description</h3>

<p>This is the main function of the package. It does the expensive calculations behind
the following H-statistics:
</p>

<ul>
<li><p> Total interaction strength <code class="reqn">H^2</code>, a statistic measuring the proportion of
prediction variability unexplained by main effects of <code>v</code>, see <code><a href="#topic+h2">h2()</a></code> for details.
</p>
</li>
<li><p> Friedman and Popescu's statistic <code class="reqn">H^2_j</code> of overall interaction strength per
feature, see <code><a href="#topic+h2_overall">h2_overall()</a></code> for details.
</p>
</li>
<li><p> Friedman and Popescu's statistic <code class="reqn">H^2_{jk}</code> of pairwise interaction strength,
see <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code> for details.
</p>
</li>
<li><p> Friedman and Popescu's statistic <code class="reqn">H^2_{jkl}</code> of three-way interaction strength,
see <code><a href="#topic+h2_threeway">h2_threeway()</a></code> for details. To save time, this statistic is not calculated
by default. Set <code>threeway_m</code> to a value above 2 to get three-way statistics of the
<code>threeway_m</code> variables with strongest overall interaction.
</p>
</li></ul>

<p>Furthermore, it allows to calculate an experimental partial dependence based
measure of feature importance, <code class="reqn">\textrm{PDI}_j^2</code>. It equals the proportion of
prediction variability unexplained by other features, see <code><a href="#topic+pd_importance">pd_importance()</a></code>
for details. This statistic is not shown by <code>summary()</code> or <code>plot()</code>.
</p>
<p>Instead of using <code>summary()</code>, interaction statistics can also be obtained via the
more flexible functions <code><a href="#topic+h2">h2()</a></code>, <code><a href="#topic+h2_overall">h2_overall()</a></code>, <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code>, and
<code><a href="#topic+h2_threeway">h2_threeway()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hstats(object, ...)

## Default S3 method:
hstats(
  object,
  X,
  v = NULL,
  pred_fun = stats::predict,
  pairwise_m = 5L,
  threeway_m = 0L,
  approx = FALSE,
  grid_size = 50L,
  n_max = 500L,
  eps = 1e-10,
  w = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'ranger'
hstats(
  object,
  X,
  v = NULL,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  pairwise_m = 5L,
  threeway_m = 0L,
  approx = FALSE,
  grid_size = 50L,
  n_max = 500L,
  eps = 1e-10,
  w = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'explainer'
hstats(
  object,
  X = object[["data"]],
  v = NULL,
  pred_fun = object[["predict_function"]],
  pairwise_m = 5L,
  threeway_m = 0L,
  approx = FALSE,
  grid_size = 50L,
  n_max = 500L,
  eps = 1e-10,
  w = object[["weights"]],
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hstats_+3A_object">object</code></td>
<td>
<p>Fitted model object.</p>
</td></tr>
<tr><td><code id="hstats_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>pred_fun(object, X, ...)</code>,
for instance <code>type = "response"</code> in a <code><a href="stats.html#topic+glm">glm()</a></code> model, or <code>reshape = TRUE</code> in a
multiclass XGBoost model.</p>
</td></tr>
<tr><td><code id="hstats_+3A_x">X</code></td>
<td>
<p>A data.frame or matrix serving as background dataset.</p>
</td></tr>
<tr><td><code id="hstats_+3A_v">v</code></td>
<td>
<p>Vector of feature names. The default (<code>NULL</code>) will use all column names of
<code>X</code> except the column name of the optional case weight <code>w</code> (if specified as name).</p>
</td></tr>
<tr><td><code id="hstats_+3A_pred_fun">pred_fun</code></td>
<td>
<p>Prediction function of the form <code style="white-space: pre;">&#8288;function(object, X, ...)&#8288;</code>,
providing <code class="reqn">K \ge 1</code> predictions per row. Its first argument represents the
model <code>object</code>, its second argument a data structure like <code>X</code>. Additional arguments
(such as <code>type = "response"</code> in a GLM, or <code>reshape = TRUE</code> in a multiclass XGBoost
model) can be passed via <code>...</code>. The default, <code><a href="stats.html#topic+predict">stats::predict()</a></code>, will work in
most cases.</p>
</td></tr>
<tr><td><code id="hstats_+3A_pairwise_m">pairwise_m</code></td>
<td>
<p>Number of features for which pairwise statistics are to be
calculated. The features are selected based on Friedman and Popescu's overall
interaction strength <code class="reqn">H^2_j</code>. Set to to 0 to avoid pairwise calculations.
For multivariate predictions, the union of the <code>pairwise_m</code> column-wise
strongest variable names is taken. This can lead to very long run-times.</p>
</td></tr>
<tr><td><code id="hstats_+3A_threeway_m">threeway_m</code></td>
<td>
<p>Like <code>pairwise_m</code>, but controls the feature count for
three-way interactions. Cannot be larger than <code>pairwise_m</code>.
To save computation time, the default is 0.</p>
</td></tr>
<tr><td><code id="hstats_+3A_approx">approx</code></td>
<td>
<p>Should quantile approximation be applied to dense numeric features?
The default is <code>FALSE</code>. Setting this option to <code>TRUE</code> brings a massive speed-up
for one-way calculations. It can, e.g., be used when the number of features is
very large.</p>
</td></tr>
<tr><td><code id="hstats_+3A_grid_size">grid_size</code></td>
<td>
<p>Integer controlling the number of quantile midpoints used to
approximate dense numerics. The quantile midpoints are calculated after
subampling via <code>n_max</code>. Only relevant if <code>approx = TRUE</code>.</p>
</td></tr>
<tr><td><code id="hstats_+3A_n_max">n_max</code></td>
<td>
<p>If <code>X</code> has more than <code>n_max</code> rows, a random sample of <code>n_max</code> rows is
selected from <code>X</code>. In this case, set a random seed for reproducibility.</p>
</td></tr>
<tr><td><code id="hstats_+3A_eps">eps</code></td>
<td>
<p>Threshold below which numerator values are set to 0. Default is 1e-10.</p>
</td></tr>
<tr><td><code id="hstats_+3A_w">w</code></td>
<td>
<p>Optional vector of case weights. Can also be a column name of <code>X</code>.</p>
</td></tr>
<tr><td><code id="hstats_+3A_verbose">verbose</code></td>
<td>
<p>Should a progress bar be shown? The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;hstats&quot; containing these elements:
</p>

<ul>
<li> <p><code>X</code>: Input <code>X</code> (sampled to <code>n_max</code> rows, after optional quantile approximation).
</p>
</li>
<li> <p><code>w</code>: Case weight vector <code>w</code> (sampled to <code>n_max</code> values), or <code>NULL</code>.
</p>
</li>
<li> <p><code>v</code>: Vector of column names in <code>X</code> for which overall
H statistics have been calculated.
</p>
</li>
<li> <p><code>f</code>: Matrix with (centered) predictions <code class="reqn">F</code>.
</p>
</li>
<li> <p><code>mean_f2</code>: (Weighted) column means of <code>f</code>. Used to normalize <code class="reqn">H^2</code> and
<code class="reqn">H^2_j</code>.
</p>
</li>
<li> <p><code>F_j</code>: List of matrices, each representing (centered)
partial dependence functions <code class="reqn">F_j</code>.
</p>
</li>
<li> <p><code>F_not_j</code>: List of matrices with (centered) partial dependence
functions <code class="reqn">F_{\setminus j}</code> of other features.
</p>
</li>
<li> <p><code>K</code>: Number of columns of prediction matrix.
</p>
</li>
<li> <p><code>pred_names</code>: Column names of prediction matrix.
</p>
</li>
<li> <p><code>pairwise_m</code>: Like input <code>pairwise_m</code>, but capped at <code>length(v)</code>.
</p>
</li>
<li> <p><code>threeway_m</code>: Like input <code>threeway_m</code>, but capped at the smaller of
<code>length(v)</code> and <code>pairwise_m</code>.
</p>
</li>
<li> <p><code>eps</code>: Like input <code>eps</code>.
</p>
</li>
<li> <p><code>pd_importance</code>: List with numerator and denominator of <code class="reqn">\textrm{PDI}_j</code>.
</p>
</li>
<li> <p><code>h2</code>: List with numerator and denominator of <code class="reqn">H^2</code>.
</p>
</li>
<li> <p><code>h2_overall</code>: List with numerator and denominator of <code class="reqn">H^2_j</code>.
</p>
</li>
<li> <p><code>v_pairwise</code>: Subset of <code>v</code> with largest <code class="reqn">H^2_j</code> used for pairwise
calculations. Only if pairwise calculations have been done.
</p>
</li>
<li> <p><code>combs2</code>: Named list of variable pairs for which pairwise partial
dependence functions are available. Only if pairwise calculations have been done.
</p>
</li>
<li> <p><code>F_jk</code>: List of matrices, each representing (centered) bivariate
partial dependence functions <code class="reqn">F_{jk}</code>.
Only if pairwise calculations have been done.
</p>
</li>
<li> <p><code>h2_pairwise</code>: List with numerator and denominator of <code class="reqn">H^2_{jk}</code>.
Only if pairwise calculations have been done.
</p>
</li>
<li> <p><code>v_threeway</code>: Subset of <code>v</code> with largest <code>h2_overall()</code> used for three-way
calculations. Only if three-way calculations have been done.
</p>
</li>
<li> <p><code>combs3</code>: Named list of variable triples for which three-way partial
dependence functions are available. Only if three-way calculations have been done.
</p>
</li>
<li> <p><code>F_jkl</code>: List of matrices, each representing (centered) three-way
partial dependence functions <code class="reqn">F_{jkl}</code>.
Only if three-way calculations have been done.
</p>
</li>
<li> <p><code>h2_threeway</code>: List with numerator and denominator of <code class="reqn">H^2_{jkl}</code>.
Only if three-way calculations have been done.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>hstats(default)</code>: Default hstats method.
</p>
</li>
<li> <p><code>hstats(ranger)</code>: Method for &quot;ranger&quot; models.
</p>
</li>
<li> <p><code>hstats(explainer)</code>: Method for DALEX &quot;explainer&quot;.
</p>
</li></ul>


<h3>References</h3>

<p>Friedman, Jerome H., and Bogdan E. Popescu. <em>&quot;Predictive Learning via Rule Ensembles.&quot;</em>
The Annals of Applied Statistics 2, no. 3 (2008): 916-54.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2">h2()</a></code>, <code><a href="#topic+h2_overall">h2_overall()</a></code>, <code><a href="#topic+h2_pairwise">h2_pairwise()</a></code>, <code><a href="#topic+h2_threeway">h2_threeway()</a></code>,
and <code><a href="#topic+pd_importance">pd_importance()</a></code> for specific statistics calculated from the resulting object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
s &lt;- hstats(fit, X = iris[, -1])
s
plot(s)
plot(s, zero = FALSE)  # Drop 0
summary(s)
  
# Absolute pairwise interaction strengths
h2_pairwise(s, normalize = FALSE, squared = FALSE, zero = FALSE)

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[, 3:5], verbose = FALSE)
plot(s)
summary(s)

# MODEL 3: Gamma GLM with log link
fit &lt;- glm(Sepal.Length ~ ., data = iris, family = Gamma(link = log))

# No interactions for additive features, at least on link scale
s &lt;- hstats(fit, X = iris[, -1], verbose = FALSE)
summary(s)

# On original scale, we have interactions everywhere. 
# To see three-way interactions, we set threeway_m to a value above 2.
s &lt;- hstats(fit, X = iris[, -1], type = "response", threeway_m = 5)
plot(s, ncol = 1)  # All three types use different denominators

# All statistics on same scale (of predictions)
plot(s, squared = FALSE, normalize = FALSE, facet_scale = "free_y")
</code></pre>

<hr>
<h2 id='ice'>Individual Conditional Expectations</h2><span id='topic+ice'></span><span id='topic+ice.default'></span><span id='topic+ice.ranger'></span><span id='topic+ice.explainer'></span>

<h3>Description</h3>

<p>Disaggregated partial dependencies, see reference. The plot method supports
up to two grouping variables via <code>BY</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ice(object, ...)

## Default S3 method:
ice(
  object,
  v,
  X,
  pred_fun = stats::predict,
  BY = NULL,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE,
  n_max = 100L,
  ...
)

## S3 method for class 'ranger'
ice(
  object,
  v,
  X,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  BY = NULL,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE,
  n_max = 100L,
  ...
)

## S3 method for class 'explainer'
ice(
  object,
  v = v,
  X = object[["data"]],
  pred_fun = object[["predict_function"]],
  BY = NULL,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE,
  n_max = 100L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ice_+3A_object">object</code></td>
<td>
<p>Fitted model object.</p>
</td></tr>
<tr><td><code id="ice_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>pred_fun(object, X, ...)</code>,
for instance <code>type = "response"</code> in a <code><a href="stats.html#topic+glm">glm()</a></code> model, or <code>reshape = TRUE</code> in a
multiclass XGBoost model.</p>
</td></tr>
<tr><td><code id="ice_+3A_v">v</code></td>
<td>
<p>One or more column names over which you want to calculate the ICE.</p>
</td></tr>
<tr><td><code id="ice_+3A_x">X</code></td>
<td>
<p>A data.frame or matrix serving as background dataset.</p>
</td></tr>
<tr><td><code id="ice_+3A_pred_fun">pred_fun</code></td>
<td>
<p>Prediction function of the form <code style="white-space: pre;">&#8288;function(object, X, ...)&#8288;</code>,
providing <code class="reqn">K \ge 1</code> predictions per row. Its first argument represents the
model <code>object</code>, its second argument a data structure like <code>X</code>. Additional arguments
(such as <code>type = "response"</code> in a GLM, or <code>reshape = TRUE</code> in a multiclass XGBoost
model) can be passed via <code>...</code>. The default, <code><a href="stats.html#topic+predict">stats::predict()</a></code>, will work in
most cases.</p>
</td></tr>
<tr><td><code id="ice_+3A_by">BY</code></td>
<td>
<p>Optional grouping vector/matrix/data.frame (up to two columns),
or up to two column names. Unlike with <code><a href="#topic+partial_dep">partial_dep()</a></code>, these variables are not
binned. The first variable is visualized on the color scale, while the second
one goes into a <code>facet_wrap()</code>. Thus, make sure that the second variable is
discrete.</p>
</td></tr>
<tr><td><code id="ice_+3A_grid">grid</code></td>
<td>
<p>Evaluation grid. A vector (if <code>length(v) == 1L</code>), or a matrix/data.frame
otherwise. If <code>NULL</code>, calculated via <code><a href="#topic+multivariate_grid">multivariate_grid()</a></code>.</p>
</td></tr>
<tr><td><code id="ice_+3A_grid_size">grid_size</code></td>
<td>
<p>Controls the approximate grid size. If <code>x</code> has p columns, then each
(non-discrete) column will be reduced to about the p-th root of <code>grid_size</code> values.</p>
</td></tr>
<tr><td><code id="ice_+3A_trim">trim</code></td>
<td>
<p>The default <code>c(0.01, 0.99)</code> means that values outside the
1% and 99% quantiles of non-discrete numeric columns are removed before calculation
of grid values. Set to <code>0:1</code> for no trimming.</p>
</td></tr>
<tr><td><code id="ice_+3A_strategy">strategy</code></td>
<td>
<p>How to find grid values of non-discrete numeric columns?
Either &quot;uniform&quot; or &quot;quantile&quot;, see description of <code><a href="#topic+univariate_grid">univariate_grid()</a></code>.</p>
</td></tr>
<tr><td><code id="ice_+3A_na.rm">na.rm</code></td>
<td>
<p>Should missing values be dropped from the grid? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ice_+3A_n_max">n_max</code></td>
<td>
<p>If <code>X</code> has more than <code>n_max</code> rows, a random sample of <code>n_max</code> rows is
selected from <code>X</code>. In this case, set a random seed for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ice&quot; containing these elements:
</p>

<ul>
<li> <p><code>data</code>: data.frame containing the ice values.
</p>
</li>
<li> <p><code>grid</code>: Vector, matrix or data.frame of grid values.
</p>
</li>
<li> <p><code>v</code>: Same as input <code>v</code>.
</p>
</li>
<li> <p><code>K</code>: Number of columns of prediction matrix.
</p>
</li>
<li> <p><code>pred_names</code>: Column names of prediction matrix.
</p>
</li>
<li> <p><code>by_names</code>: Column name(s) of grouping variable(s) (or <code>NULL</code>).
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>ice(default)</code>: Default method.
</p>
</li>
<li> <p><code>ice(ranger)</code>: Method for &quot;ranger&quot; models.
</p>
</li>
<li> <p><code>ice(explainer)</code>: Method for DALEX &quot;explainer&quot;.
</p>
</li></ul>


<h3>References</h3>

<p>Goldstein, Alex, and Adam Kapelner and Justin Bleich and Emil Pitkin.
<em>Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation.</em>
Journal of Computational and Graphical Statistics, 24, no. 1 (2015): 44-65.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Species * Petal.Length, data = iris)
plot(ice(fit, v = "Sepal.Width", X = iris))

# Stratified by one variable
ic &lt;- ice(fit, v = "Petal.Length", X = iris, BY = "Species")
ic
plot(ic)
plot(ic, center = TRUE)

## Not run: 
# Stratified by two variables (the second one goes into facets)
ic &lt;- ice(fit, v = "Petal.Length", X = iris, BY = c("Petal.Width", "Species"))
plot(ic)
plot(ic, center = TRUE)

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
ic &lt;- ice(fit, v = "Petal.Width", X = iris, BY = iris$Species)
plot(ic)
plot(ic, center = TRUE)
plot(ic, swap_dim = TRUE)

## End(Not run)

# MODEL 3: Gamma GLM -&gt; pass options to predict() via ...
fit &lt;- glm(Sepal.Length ~ ., data = iris, family = Gamma(link = log))
plot(ice(fit, v = "Petal.Length", X = iris, BY = "Species"))
plot(ice(fit, v = "Petal.Length", X = iris, type = "response", BY = "Species"))
</code></pre>

<hr>
<h2 id='multivariate_grid'>Multivariate Grid</h2><span id='topic+multivariate_grid'></span>

<h3>Description</h3>

<p>This function creates a multivariate grid. Each column of the input <code>x</code> is turned
(independently) into a vector of grid values via <code><a href="#topic+univariate_grid">univariate_grid()</a></code>.
Combinations are then formed by calling <code><a href="base.html#topic+expand.grid">expand.grid()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariate_grid(
  x,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multivariate_grid_+3A_x">x</code></td>
<td>
<p>A vector, matrix, or data.frame to turn into a grid of values.</p>
</td></tr>
<tr><td><code id="multivariate_grid_+3A_grid_size">grid_size</code></td>
<td>
<p>Controls the approximate grid size. If <code>x</code> has p columns, then each
(non-discrete) column will be reduced to about the p-th root of <code>grid_size</code> values.</p>
</td></tr>
<tr><td><code id="multivariate_grid_+3A_trim">trim</code></td>
<td>
<p>The default <code>c(0.01, 0.99)</code> means that values outside the
1% and 99% quantiles of non-discrete numeric columns are removed before calculation
of grid values. Set to <code>0:1</code> for no trimming.</p>
</td></tr>
<tr><td><code id="multivariate_grid_+3A_strategy">strategy</code></td>
<td>
<p>How to find grid values of non-discrete numeric columns?
Either &quot;uniform&quot; or &quot;quantile&quot;, see description of <code><a href="#topic+univariate_grid">univariate_grid()</a></code>.</p>
</td></tr>
<tr><td><code id="multivariate_grid_+3A_na.rm">na.rm</code></td>
<td>
<p>Should missing values be dropped from the grid? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector, matrix, or data.frame with evaluation points.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+univariate_grid">univariate_grid()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>multivariate_grid(iris[1:2], grid_size = 4)
multivariate_grid(iris$Species)  # Works also in the univariate case
</code></pre>

<hr>
<h2 id='partial_dep'>Partial Dependence Plot</h2><span id='topic+partial_dep'></span><span id='topic+partial_dep.default'></span><span id='topic+partial_dep.ranger'></span><span id='topic+partial_dep.explainer'></span>

<h3>Description</h3>

<p>Estimates the partial dependence function of feature(s) <code>v</code> over a
grid of values. Both multivariate and multivariable situations are supported.
The resulting object can be plotted via <code>plot()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partial_dep(object, ...)

## Default S3 method:
partial_dep(
  object,
  v,
  X,
  pred_fun = stats::predict,
  BY = NULL,
  by_size = 4L,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE,
  n_max = 1000L,
  w = NULL,
  ...
)

## S3 method for class 'ranger'
partial_dep(
  object,
  v,
  X,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  BY = NULL,
  by_size = 4L,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE,
  n_max = 1000L,
  w = NULL,
  ...
)

## S3 method for class 'explainer'
partial_dep(
  object,
  v,
  X = object[["data"]],
  pred_fun = object[["predict_function"]],
  BY = NULL,
  by_size = 4L,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE,
  n_max = 1000L,
  w = object[["weights"]],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partial_dep_+3A_object">object</code></td>
<td>
<p>Fitted model object.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>pred_fun(object, X, ...)</code>,
for instance <code>type = "response"</code> in a <code><a href="stats.html#topic+glm">glm()</a></code> model, or <code>reshape = TRUE</code> in a
multiclass XGBoost model.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_v">v</code></td>
<td>
<p>One or more column names over which you want to calculate the partial
dependence.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_x">X</code></td>
<td>
<p>A data.frame or matrix serving as background dataset.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_pred_fun">pred_fun</code></td>
<td>
<p>Prediction function of the form <code style="white-space: pre;">&#8288;function(object, X, ...)&#8288;</code>,
providing <code class="reqn">K \ge 1</code> predictions per row. Its first argument represents the
model <code>object</code>, its second argument a data structure like <code>X</code>. Additional arguments
(such as <code>type = "response"</code> in a GLM, or <code>reshape = TRUE</code> in a multiclass XGBoost
model) can be passed via <code>...</code>. The default, <code><a href="stats.html#topic+predict">stats::predict()</a></code>, will work in
most cases.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_by">BY</code></td>
<td>
<p>Optional grouping vector or column name. The partial dependence
function is calculated per <code>BY</code> group. Each <code>BY</code> group
uses the same evaluation grid to improve assessment of (non-)additivity.
Numeric <code>BY</code> variables with more than <code>by_size</code> disjoint values will be
binned into <code>by_size</code> quantile groups of similar size. To improve robustness,
subsampling of <code>X</code> is done within group. This only applies to <code>BY</code> groups with
more than <code>n_max</code> rows.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_by_size">by_size</code></td>
<td>
<p>Numeric <code>BY</code> variables with more than <code>by_size</code> unique values will
be binned into quantile groups. Only relevant if <code>BY</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_grid">grid</code></td>
<td>
<p>Evaluation grid. A vector (if <code>length(v) == 1L</code>), or a matrix/data.frame
otherwise. If <code>NULL</code>, calculated via <code><a href="#topic+multivariate_grid">multivariate_grid()</a></code>.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_grid_size">grid_size</code></td>
<td>
<p>Controls the approximate grid size. If <code>x</code> has p columns, then each
(non-discrete) column will be reduced to about the p-th root of <code>grid_size</code> values.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_trim">trim</code></td>
<td>
<p>The default <code>c(0.01, 0.99)</code> means that values outside the
1% and 99% quantiles of non-discrete numeric columns are removed before calculation
of grid values. Set to <code>0:1</code> for no trimming.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_strategy">strategy</code></td>
<td>
<p>How to find grid values of non-discrete numeric columns?
Either &quot;uniform&quot; or &quot;quantile&quot;, see description of <code><a href="#topic+univariate_grid">univariate_grid()</a></code>.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_na.rm">na.rm</code></td>
<td>
<p>Should missing values be dropped from the grid? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_n_max">n_max</code></td>
<td>
<p>If <code>X</code> has more than <code>n_max</code> rows, a random sample of <code>n_max</code> rows is
selected from <code>X</code>. In this case, set a random seed for reproducibility.</p>
</td></tr>
<tr><td><code id="partial_dep_+3A_w">w</code></td>
<td>
<p>Optional vector of case weights. Can also be a column name of <code>X</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;partial_dep&quot; containing these elements:
</p>

<ul>
<li> <p><code>data</code>: data.frame containing the partial dependencies.
</p>
</li>
<li> <p><code>v</code>: Same as input <code>v</code>.
</p>
</li>
<li> <p><code>K</code>: Number of columns of prediction matrix.
</p>
</li>
<li> <p><code>pred_names</code>: Column names of prediction matrix.
</p>
</li>
<li> <p><code>by_name</code>: Column name of grouping variable (or <code>NULL</code>).
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>partial_dep(default)</code>: Default method.
</p>
</li>
<li> <p><code>partial_dep(ranger)</code>: Method for &quot;ranger&quot; models.
</p>
</li>
<li> <p><code>partial_dep(explainer)</code>: Method for DALEX &quot;explainer&quot;.
</p>
</li></ul>


<h3>Partial Dependence Functions</h3>

<p>Let <code class="reqn">F: R^p \to R</code> denote the prediction function that maps the
<code class="reqn">p</code>-dimensional feature vector <code class="reqn">\mathbf{x} = (x_1, \dots, x_p)</code>
to its prediction. Furthermore, let
</p>
<p style="text-align: center;"><code class="reqn">
  F_s(\mathbf{x}_s) = E_{\mathbf{x}_{\setminus s}}(F(\mathbf{x}_s, \mathbf{x}_{\setminus s}))
</code>
</p>

<p>be the partial dependence function of <code class="reqn">F</code> on the feature subset
<code class="reqn">\mathbf{x}_s</code>, where <code class="reqn">s \subseteq \{1, \dots, p\}</code>, as introduced in
Friedman (2001). Here, the expectation runs over the joint marginal distribution
of features <code class="reqn">\mathbf{x}_{\setminus s}</code> not in <code class="reqn">\mathbf{x}_s</code>.
</p>
<p>Given data, <code class="reqn">F_s(\mathbf{x}_s)</code> can be estimated by the empirical partial
dependence function
</p>
<p style="text-align: center;"><code class="reqn">
  \hat F_s(\mathbf{x}_s) = \frac{1}{n} \sum_{i = 1}^n F(\mathbf{x}_s, \mathbf{x}_{i\setminus s}),
</code>
</p>

<p>where <code class="reqn">\mathbf{x}_{i\setminus s}</code> <code class="reqn">i = 1, \dots, n</code>, are the observed values
of <code class="reqn">\mathbf{x}_{\setminus s}</code>.
</p>
<p>A partial dependence plot (PDP) plots the values of <code class="reqn">\hat F_s(\mathbf{x}_s)</code>
over a grid of evaluation points <code class="reqn">\mathbf{x}_s</code>.
</p>


<h3>References</h3>

<p>Friedman, Jerome H. <em>&quot;Greedy Function Approximation: A Gradient Boosting Machine.&quot;</em>
Annals of Statistics 29, no. 5 (2001): 1189-1232.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Species * Petal.Length, data = iris)
(pd &lt;- partial_dep(fit, v = "Species", X = iris))
plot(pd)

## Not run: 
# Stratified by BY variable (numerics are automatically binned)
pd &lt;- partial_dep(fit, v = "Species", X = iris, BY = "Petal.Length")
plot(pd)

# Multivariable input
v &lt;- c("Species", "Petal.Length")
pd &lt;- partial_dep(fit, v = v, X = iris, grid_size = 100L)
plot(pd, rotate_x = TRUE)
plot(pd, d2_geom = "line")  # often better to read

# With grouping
pd &lt;- partial_dep(fit, v = v, X = iris, grid_size = 100L, BY = "Petal.Width")
plot(pd, rotate_x = TRUE)
plot(pd, rotate_x = TRUE, d2_geom = "line")
plot(pd, rotate_x = TRUE, d2_geom = "line", swap_dim = TRUE)

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
pd &lt;- partial_dep(fit, v = "Petal.Width", X = iris, BY = "Species")
plot(pd, show_points = FALSE)
pd &lt;- partial_dep(fit, v = c("Species", "Petal.Width"), X = iris)
plot(pd, rotate_x = TRUE)
plot(pd, d2_geom = "line", rotate_x = TRUE)
plot(pd, d2_geom = "line", rotate_x = TRUE, swap_dim = TRUE)

# Multivariate, multivariable, and BY (no plot available)
pd &lt;- partial_dep(
  fit, v = c("Petal.Width", "Petal.Length"), X = iris, BY = "Species"
)
pd

## End(Not run)

# MODEL 3: Gamma GLM -&gt; pass options to predict() via ...
fit &lt;- glm(Sepal.Length ~ ., data = iris, family = Gamma(link = log))
plot(partial_dep(fit, v = "Petal.Length", X = iris), show_points = FALSE)
plot(partial_dep(fit, v = "Petal.Length", X = iris, type = "response"))
</code></pre>

<hr>
<h2 id='pd_importance'>PD Bases Importance (Experimental)</h2><span id='topic+pd_importance'></span><span id='topic+pd_importance.default'></span><span id='topic+pd_importance.hstats'></span>

<h3>Description</h3>

<p>Experimental variable importance method based on partial dependence functions.
While related to Greenwell et al., our suggestion measures not only main effect
strength but also interaction effects. It is very closely related to <code class="reqn">H^2_j</code>,
see Details. Use <code>plot()</code> to get a barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pd_importance(object, ...)

## Default S3 method:
pd_importance(object, ...)

## S3 method for class 'hstats'
pd_importance(
  object,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pd_importance_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="pd_importance_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="pd_importance_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="pd_importance_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="pd_importance_+3A_sort">sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td></tr>
<tr><td><code id="pd_importance_+3A_zero">zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">x_j</code> has no effects, the (centered) prediction function <code class="reqn">F</code>
equals the (centered) partial dependence <code class="reqn">F_{\setminus j}</code> on all other
features <code class="reqn">\mathbf{x}_{\setminus j}</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">
    F(\mathbf{x}) = F_{\setminus j}(\mathbf{x}_{\setminus j}).
</code>
</p>

<p>Therefore, the following measure of variable importance follows:
</p>
<p style="text-align: center;"><code class="reqn">
  \textrm{PDI}_j = \frac{\frac{1}{n} \sum_{i = 1}^n\big[F(\mathbf{x}_i) - 
  \hat F_{\setminus j}(\mathbf{x}_{i\setminus j})\big]^2}{\frac{1}{n} \sum_{i = 1}^n
  \big[F(\mathbf{x}_i)\big]^2}.
</code>
</p>

<p>It differs from <code class="reqn">H^2_j</code> only by not subtracting the main effect of the <code class="reqn">j</code>-th
feature in the numerator. It can be read as the proportion of prediction variability
unexplained by all other features. As such, it measures variable importance of
the <code class="reqn">j</code>-th feature, including its interaction effects (check <code><a href="#topic+partial_dep">partial_dep()</a></code>
for all definitions).
</p>
<p>Remarks 1 to 4 of <code><a href="#topic+h2_overall">h2_overall()</a></code> also apply here.
</p>


<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>pd_importance(default)</code>: Default method of PD based feature importance.
</p>
</li>
<li> <p><code>pd_importance(hstats)</code>: PD based feature importance from &quot;hstats&quot; object.
</p>
</li></ul>


<h3>References</h3>

<p>Greenwell, Brandon M., Bradley C. Boehmke, and Andrew J. McCarthy.
<em>A Simple and Effective Model-Based Variable Importance Measure.</em> Arxiv (2018).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hstats">hstats()</a></code>, <code><a href="#topic+perm_importance">perm_importance()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . , data = iris)
s &lt;- hstats(fit, X = iris[, -1])
plot(pd_importance(s))

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width + Species, data = iris)
s &lt;- hstats(fit, X = iris[, 3:5])
plot(pd_importance(s))
</code></pre>

<hr>
<h2 id='perm_importance'>Permutation Importance</h2><span id='topic+perm_importance'></span><span id='topic+perm_importance.default'></span><span id='topic+perm_importance.ranger'></span><span id='topic+perm_importance.explainer'></span>

<h3>Description</h3>

<p>Calculates permutation importance for a set of features or a set of feature groups.
By default, importance is calculated for all columns in <code>X</code> (except column names
used as response <code>y</code> or case weight <code>w</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perm_importance(object, ...)

## Default S3 method:
perm_importance(
  object,
  X,
  y,
  v = NULL,
  pred_fun = stats::predict,
  loss = "squared_error",
  m_rep = 4L,
  agg_cols = FALSE,
  normalize = FALSE,
  n_max = 10000L,
  w = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'ranger'
perm_importance(
  object,
  X,
  y,
  v = NULL,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  loss = "squared_error",
  m_rep = 4L,
  agg_cols = FALSE,
  normalize = FALSE,
  n_max = 10000L,
  w = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'explainer'
perm_importance(
  object,
  X = object[["data"]],
  y = object[["y"]],
  v = NULL,
  pred_fun = object[["predict_function"]],
  loss = "squared_error",
  m_rep = 4L,
  agg_cols = FALSE,
  normalize = FALSE,
  n_max = 10000L,
  w = object[["weights"]],
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perm_importance_+3A_object">object</code></td>
<td>
<p>Fitted model object.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>pred_fun(object, X, ...)</code>,
for instance <code>type = "response"</code> in a <code><a href="stats.html#topic+glm">glm()</a></code> model, or <code>reshape = TRUE</code> in a
multiclass XGBoost model.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_x">X</code></td>
<td>
<p>A data.frame or matrix serving as background dataset.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_y">y</code></td>
<td>
<p>Vector/matrix of the response, or the corresponding column names in <code>X</code>.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_v">v</code></td>
<td>
<p>Vector of feature names, or named list of feature groups.
The default (<code>NULL</code>) will use all column names of <code>X</code> with the following exception:
If <code>y</code> or <code>w</code> are passed  as column names, they are dropped.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_pred_fun">pred_fun</code></td>
<td>
<p>Prediction function of the form <code style="white-space: pre;">&#8288;function(object, X, ...)&#8288;</code>,
providing <code class="reqn">K \ge 1</code> predictions per row. Its first argument represents the
model <code>object</code>, its second argument a data structure like <code>X</code>. Additional arguments
(such as <code>type = "response"</code> in a GLM, or <code>reshape = TRUE</code> in a multiclass XGBoost
model) can be passed via <code>...</code>. The default, <code><a href="stats.html#topic+predict">stats::predict()</a></code>, will work in
most cases.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_loss">loss</code></td>
<td>
<p>One of &quot;squared_error&quot;, &quot;logloss&quot;, &quot;mlogloss&quot;, &quot;poisson&quot;,
&quot;gamma&quot;, &quot;absolute_error&quot;, &quot;classification_error&quot;. Alternatively, a loss function
can be provided that turns observed and predicted values into a numeric vector or
matrix of unit losses of the same length as <code>X</code>.
For &quot;mlogloss&quot;, the response <code>y</code> can either be a dummy matrix or a discrete vector.
The latter case is handled via a fast version of <code>model.matrix(~ as.factor(y) + 0)</code>.
For &quot;classification_error&quot;, both predictions and responses can be non-numeric.
For &quot;squared_error&quot;, both predictions and responses can be factors with identical
levels. In this case, squared error is evaulated for each one-hot-encoded column.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_m_rep">m_rep</code></td>
<td>
<p>Number of permutations (default 4).</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_agg_cols">agg_cols</code></td>
<td>
<p>Should multivariate losses be summed up? Default is <code>FALSE</code>.
In combination with the squared error loss, <code>agg_cols = TRUE</code> gives
the Brier score for (probabilistic) classification.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_normalize">normalize</code></td>
<td>
<p>Should importance statistics be divided by average loss?
Default is <code>FALSE</code>. If <code>TRUE</code>, an importance of 1 means that the average loss
has been doubled by shuffling that feature's column.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_n_max">n_max</code></td>
<td>
<p>If <code>X</code> has more than <code>n_max</code> rows, a random sample of <code>n_max</code> rows is
selected from <code>X</code>. In this case, set a random seed for reproducibility.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_w">w</code></td>
<td>
<p>Optional vector of case weights. Can also be a column name of <code>X</code>.</p>
</td></tr>
<tr><td><code id="perm_importance_+3A_verbose">verbose</code></td>
<td>
<p>Should a progress bar be shown? The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The permutation importance of a feature is defined as the increase in the average
loss when shuffling the corresponding feature values before calculating predictions.
By default, the process is repeated <code>m_rep = 4</code> times, and the results are averaged.
In most of the cases, importance values should be derived from an independent test
data set. Set <code>normalize = TRUE</code> to get <em>relative</em> increases in average loss.
</p>


<h3>Value</h3>

<p>An object of class &quot;hstats_matrix&quot; containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li></ul>



<h3>Methods (by class)</h3>


<ul>
<li> <p><code>perm_importance(default)</code>: Default method.
</p>
</li>
<li> <p><code>perm_importance(ranger)</code>: Method for &quot;ranger&quot; models.
</p>
</li>
<li> <p><code>perm_importance(explainer)</code>: Method for DALEX &quot;explainer&quot;.
</p>
</li></ul>


<h3>Losses</h3>

<p>The default <code>loss</code> is the &quot;squared_error&quot;. Other choices:
</p>

<ul>
<li><p> &quot;absolute_error&quot;: The absolute error is the loss corresponding to median regression.
</p>
</li>
<li><p> &quot;poisson&quot;: Unit Poisson deviance, i.e., the loss function used in
Poisson regression. Actual values <code>y</code> and predictions must be non-negative.
</p>
</li>
<li><p> &quot;gamma&quot;: Unit gamma deviance, i.e., the loss function of Gamma regression.
Actual values <code>y</code> and predictions must be positive.
</p>
</li>
<li><p> &quot;logloss&quot;: The Log Loss is the loss function used in logistic regression,
and the top choice in probabilistic binary classification. Responses <code>y</code> and
predictions must be between 0 and 1. Predictions represent probabilities of
having a &quot;1&quot;.
</p>
</li>
<li><p> &quot;mlogloss&quot;: Multi-Log-Loss is the natural loss function in probabilistic multi-class
situations. If there are K classes and n observations, the predictions form
a (n x K) matrix of probabilities (with row-sums 1).
The observed values <code>y</code> are either passed as (n x K) dummy matrix,
or as discrete vector with corresponding levels.
The latter case is turned into a dummy matrix by a fast version of
<code>model.matrix(~ as.factor(y) + 0)</code>.
</p>
</li>
<li><p> &quot;classification_error&quot;: Misclassification error. Both the
observed values <code>y</code> and the predictions can be character/factor. This
loss function can be used in non-probabilistic classification settings.
BUT: Probabilistic classification (with &quot;mlogloss&quot;) is clearly preferred in most
situations.
</p>
</li>
<li><p> A function with signature <code>f(actual, predicted)</code>, returning a numeric
vector or matrix of the same length as the input.
</p>
</li></ul>



<h3>References</h3>

<p>Fisher A., Rudin C., Dominici F. (2018). All Models are Wrong but many are Useful:
Variable Importance for Black-Box, Proprietary, or Misspecified Prediction
Models, using Model Class Reliance. Arxiv.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ ., data = iris)
s &lt;- perm_importance(fit, X = iris, y = "Sepal.Length")
s
s$M
s$SE  # Standard errors are available thanks to repeated shuffling
plot(s)
plot(s, err_type = "SD")  # Standard deviations instead of standard errors

# Groups of features can be passed as named list
v &lt;- list(petal = c("Petal.Length", "Petal.Width"), species = "Species")
s &lt;- perm_importance(fit, X = iris, y = "Sepal.Length", v = v, verbose = FALSE)
s
plot(s)

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width + Species, data = iris)
s &lt;- perm_importance(fit, X = iris[, 3:5], y = iris[, 1:2], normalize = TRUE)
s
plot(s)
plot(s, swap_dim = TRUE, top_m = 2)
</code></pre>

<hr>
<h2 id='plot.hstats'>Plot Method for &quot;hstats&quot; Object</h2><span id='topic+plot.hstats'></span>

<h3>Description</h3>

<p>Plot method for object of class &quot;hstats&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats'
plot(
  x,
  which = 1:3,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  top_m = 15L,
  zero = TRUE,
  fill = getOption("hstats.fill"),
  viridis_args = getOption("hstats.viridis_args"),
  facet_scales = "free",
  ncol = 2L,
  rotate_x = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hstats_+3A_x">x</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_which">which</code></td>
<td>
<p>Which statistic(s) to be shown? Default is <code>1:3</code>, i.e.,
show <code class="reqn">H^2_j</code> (1), <code class="reqn">H^2_{jk}</code> (2), and <code class="reqn">H^2_{jkl}</code> (3).</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_sort">sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_top_m">top_m</code></td>
<td>
<p>How many rows should be plotted? <code>Inf</code> for all.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_zero">zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_fill">fill</code></td>
<td>
<p>Fill color of ungrouped bars. The default equals the global option
<code>hstats.fill = "#fca50a"</code>. To change the global option, use
<code style="white-space: pre;">&#8288;options(stats.fill = new value)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_viridis_args">viridis_args</code></td>
<td>
<p>List of viridis color scale arguments, see
<code style="white-space: pre;">&#8288;[ggplot2::scale_color_viridis_d()]&#8288;</code>.
The default points to the global option <code>hstats.viridis_args</code>,
which corresponds to <code>list(begin = 0.2, end = 0.8, option = "B")</code>.
E.g., to switch to a standard viridis scale, you can change the default via
<code>options(hstats.viridis_args = list())</code>, or set <code>viridis_args = list()</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_facet_scales">facet_scales</code></td>
<td>
<p>Value passed as <code>scales</code> argument to <code style="white-space: pre;">&#8288;[ggplot2::facet_wrap()]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_ncol">ncol</code></td>
<td>
<p>Passed to <code style="white-space: pre;">&#8288;[ggplot2::facet_wrap()]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_rotate_x">rotate_x</code></td>
<td>
<p>Should x axis labels be rotated by 45 degrees?</p>
</td></tr>
<tr><td><code id="plot.hstats_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="ggplot2.html#topic+geom_bar">ggplot2::geom_bar()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+hstats">hstats()</a></code> for examples.
</p>

<hr>
<h2 id='plot.hstats_matrix'>Plots &quot;hstats_matrix&quot; Object</h2><span id='topic+plot.hstats_matrix'></span>

<h3>Description</h3>

<p>Plot method for objects of class &quot;hstats_matrix&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats_matrix'
plot(
  x,
  top_m = 15L,
  fill = getOption("hstats.fill"),
  swap_dim = FALSE,
  viridis_args = getOption("hstats.viridis_args"),
  facet_scales = "fixed",
  ncol = 2L,
  rotate_x = FALSE,
  err_type = c("SE", "SD", "No"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hstats_matrix_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_matrix&quot;.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_top_m">top_m</code></td>
<td>
<p>How many rows should be plotted? <code>Inf</code> for all.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_fill">fill</code></td>
<td>
<p>Fill color of ungrouped bars. The default equals the global option
<code>hstats.fill = "#fca50a"</code>. To change the global option, use
<code style="white-space: pre;">&#8288;options(stats.fill = new value)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_swap_dim">swap_dim</code></td>
<td>
<p>Switches the role of grouping and facetting (default is <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_viridis_args">viridis_args</code></td>
<td>
<p>List of viridis color scale arguments, see
<code style="white-space: pre;">&#8288;[ggplot2::scale_color_viridis_d()]&#8288;</code>.
The default points to the global option <code>hstats.viridis_args</code>,
which corresponds to <code>list(begin = 0.2, end = 0.8, option = "B")</code>.
E.g., to switch to a standard viridis scale, you can change the default via
<code>options(hstats.viridis_args = list())</code>, or set <code>viridis_args = list()</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_facet_scales">facet_scales</code></td>
<td>
<p>Value passed as <code>scales</code> argument to <code style="white-space: pre;">&#8288;[ggplot2::facet_wrap()]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_ncol">ncol</code></td>
<td>
<p>Passed to <code style="white-space: pre;">&#8288;[ggplot2::facet_wrap()]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_rotate_x">rotate_x</code></td>
<td>
<p>Should x axis labels be rotated by 45 degrees?</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_err_type">err_type</code></td>
<td>
<p>The error type to show, by default &quot;SE&quot; (standard errors). Set to
&quot;SD&quot; for standard deviations (SE * sqrt(m_rep)), or &quot;No&quot; for no bars.
Currently, supported only for <code><a href="#topic+perm_importance">perm_importance()</a></code>.</p>
</td></tr>
<tr><td><code id="plot.hstats_matrix_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="ggplot2.html#topic+geom_bar">ggplot2::geom_bar()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;.
</p>

<hr>
<h2 id='plot.ice'>Plots &quot;ice&quot; Object</h2><span id='topic+plot.ice'></span>

<h3>Description</h3>

<p>Plot method for objects of class &quot;ice&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ice'
plot(
  x,
  center = FALSE,
  alpha = 0.2,
  color = getOption("hstats.color"),
  swap_dim = FALSE,
  viridis_args = getOption("hstats.viridis_args"),
  facet_scales = "fixed",
  rotate_x = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ice_+3A_x">x</code></td>
<td>
<p>An object of class &quot;ice&quot;.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_center">center</code></td>
<td>
<p>Should curves be centered? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_alpha">alpha</code></td>
<td>
<p>Transparency passed to <code>ggplot2::geom_line()</code>.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_color">color</code></td>
<td>
<p>Color of lines and points (in case there is no color/fill aesthetic).
The default equals the global option <code>hstats.color = "#3b528b"</code>.
To change the global option, use <code style="white-space: pre;">&#8288;options(stats.color = new value)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_swap_dim">swap_dim</code></td>
<td>
<p>Swaps between color groups and facets. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_viridis_args">viridis_args</code></td>
<td>
<p>List of viridis color scale arguments, see
<code style="white-space: pre;">&#8288;[ggplot2::scale_color_viridis_d()]&#8288;</code>.
The default points to the global option <code>hstats.viridis_args</code>,
which corresponds to <code>list(begin = 0.2, end = 0.8, option = "B")</code>.
E.g., to switch to a standard viridis scale, you can change the default via
<code>options(hstats.viridis_args = list())</code>, or set <code>viridis_args = list()</code>.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_facet_scales">facet_scales</code></td>
<td>
<p>Value passed as <code>scales</code> argument to <code style="white-space: pre;">&#8288;[ggplot2::facet_wrap()]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_rotate_x">rotate_x</code></td>
<td>
<p>Should x axis labels be rotated by 45 degrees?</p>
</td></tr>
<tr><td><code id="plot.ice_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="ggplot2.html#topic+geom_bar">ggplot2::geom_bar()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+ice">ice()</a></code> for examples.
</p>

<hr>
<h2 id='plot.partial_dep'>Plots &quot;partial_dep&quot; Object</h2><span id='topic+plot.partial_dep'></span>

<h3>Description</h3>

<p>Plot method for objects of class &quot;partial_dep&quot;. Can do (grouped) line plots or
heatmaps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'partial_dep'
plot(
  x,
  color = getOption("hstats.color"),
  swap_dim = FALSE,
  viridis_args = getOption("hstats.viridis_args"),
  facet_scales = "fixed",
  rotate_x = FALSE,
  show_points = TRUE,
  d2_geom = c("tile", "point", "line"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.partial_dep_+3A_x">x</code></td>
<td>
<p>An object of class &quot;partial_dep&quot;.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_color">color</code></td>
<td>
<p>Color of lines and points (in case there is no color/fill aesthetic).
The default equals the global option <code>hstats.color = "#3b528b"</code>.
To change the global option, use <code style="white-space: pre;">&#8288;options(stats.color = new value)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_swap_dim">swap_dim</code></td>
<td>
<p>Switches the role of grouping and facetting (default is <code>FALSE</code>).
Exception: For the 2D PDP with <code>d2_geom = "line"</code>, it swaps the role of the two
variables in <code>v</code>.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_viridis_args">viridis_args</code></td>
<td>
<p>List of viridis color scale arguments, see
<code style="white-space: pre;">&#8288;[ggplot2::scale_color_viridis_d()]&#8288;</code>.
The default points to the global option <code>hstats.viridis_args</code>,
which corresponds to <code>list(begin = 0.2, end = 0.8, option = "B")</code>.
E.g., to switch to a standard viridis scale, you can change the default via
<code>options(hstats.viridis_args = list())</code>, or set <code>viridis_args = list()</code>.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_facet_scales">facet_scales</code></td>
<td>
<p>Value passed as <code>scales</code> argument to <code style="white-space: pre;">&#8288;[ggplot2::facet_wrap()]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_rotate_x">rotate_x</code></td>
<td>
<p>Should x axis labels be rotated by 45 degrees?</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_show_points">show_points</code></td>
<td>
<p>Logical flag indicating whether to show points (default) or not.
No effect for 2D PDPs.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_d2_geom">d2_geom</code></td>
<td>
<p>The geometry used for 2D PDPs, by default &quot;tile&quot;. Option &quot;point&quot;
is useful, e.g., when the grid represents spatial points. Option &quot;line&quot; produces
lines grouped by the second variable.</p>
</td></tr>
<tr><td><code id="plot.partial_dep_+3A_...">...</code></td>
<td>
<p>Arguments passed to geometries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;ggplot&quot;.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+partial_dep">partial_dep()</a></code> for examples.
</p>

<hr>
<h2 id='print.hstats'>Print Method</h2><span id='topic+print.hstats'></span>

<h3>Description</h3>

<p>Print method for object of class &quot;hstats&quot;. Shows <code class="reqn">H^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hstats_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="print.hstats_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, the input is returned.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+hstats">hstats()</a></code> for examples.
</p>

<hr>
<h2 id='print.hstats_matrix'>Prints &quot;hstats_matrix&quot; Object</h2><span id='topic+print.hstats_matrix'></span>

<h3>Description</h3>

<p>Print method for object of class &quot;hstats_matrix&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats_matrix'
print(x, top_m = Inf, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hstats_matrix_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_matrix&quot;.</p>
</td></tr>
<tr><td><code id="print.hstats_matrix_+3A_top_m">top_m</code></td>
<td>
<p>Number of rows to print.</p>
</td></tr>
<tr><td><code id="print.hstats_matrix_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, the input is returned.
</p>

<hr>
<h2 id='print.hstats_summary'>Print Method</h2><span id='topic+print.hstats_summary'></span>

<h3>Description</h3>

<p>Print method for object of class &quot;hstats_summary&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats_summary'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hstats_summary_+3A_x">x</code></td>
<td>
<p>An object of class &quot;hstats_summary&quot;.</p>
</td></tr>
<tr><td><code id="print.hstats_summary_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, the input is returned.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+hstats">hstats()</a></code> for examples.
</p>

<hr>
<h2 id='print.ice'>Prints &quot;ice&quot; Object</h2><span id='topic+print.ice'></span>

<h3>Description</h3>

<p>Print method for object of class &quot;ice&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ice'
print(x, n = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ice_+3A_x">x</code></td>
<td>
<p>An object of class &quot;ice&quot;.</p>
</td></tr>
<tr><td><code id="print.ice_+3A_n">n</code></td>
<td>
<p>Number of rows to print.</p>
</td></tr>
<tr><td><code id="print.ice_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, the input is returned.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+ice">ice()</a></code> for examples.
</p>

<hr>
<h2 id='print.partial_dep'>Prints &quot;partial_dep&quot; Object</h2><span id='topic+print.partial_dep'></span>

<h3>Description</h3>

<p>Print method for object of class &quot;partial_dep&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'partial_dep'
print(x, n = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.partial_dep_+3A_x">x</code></td>
<td>
<p>An object of class &quot;partial_dep&quot;.</p>
</td></tr>
<tr><td><code id="print.partial_dep_+3A_n">n</code></td>
<td>
<p>Number of rows to print.</p>
</td></tr>
<tr><td><code id="print.partial_dep_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, the input is returned.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+partial_dep">partial_dep()</a></code> for examples.
</p>

<hr>
<h2 id='summary.hstats'>Summary Method</h2><span id='topic+summary.hstats'></span>

<h3>Description</h3>

<p>Summary method for &quot;hstats&quot; object. Note that only the top 4 overall, the top 3
pairwise and the top 1 three-way statistics are shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hstats'
summary(
  object,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.hstats_+3A_object">object</code></td>
<td>
<p>Object of class &quot;hstats&quot;.</p>
</td></tr>
<tr><td><code id="summary.hstats_+3A_normalize">normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summary.hstats_+3A_squared">squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summary.hstats_+3A_sort">sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td></tr>
<tr><td><code id="summary.hstats_+3A_zero">zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summary.hstats_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;summary_hstats&quot; representing a named list with statistics
&quot;h2&quot;, &quot;h2_overall&quot;, &quot;h2_pairwise&quot;, &quot;h2_threeway&quot;, all of class &quot;hstats_matrix&quot;.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+hstats">hstats()</a></code> for examples.
</p>

<hr>
<h2 id='univariate_grid'>Univariate Grid</h2><span id='topic+univariate_grid'></span>

<h3>Description</h3>

<p>Creates evaluation grid for any numeric or non-numeric vector <code>z</code>.
</p>
<p>For discrete <code>z</code> (non-numeric, or numeric with at most <code>grid_size</code> unique values),
this is simply <code>sort(unique(z))</code>.
</p>
<p>Otherwise, if <code>strategy = "uniform"</code> (default), the evaluation points form a regular
grid over the trimmed range of <code>z</code>. By trimmed range we mean the
range of <code>z</code> after removing values outside <code>trim[1]</code> and <code>trim[2]</code> quantiles.
Set <code>trim = 0:1</code> for no trimming.
</p>
<p>If <code>strategy = "quantile"</code>, the evaluation points are quantiles over a regular grid
of probabilities from <code>trim[1]</code> to <code>trim[2]</code>.
</p>
<p>Quantiles are calculated via the inverse of the ECDF, i.e., via
<code style="white-space: pre;">&#8288;stats::quantile(..., type = 1&#8288;</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univariate_grid(
  z,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="univariate_grid_+3A_z">z</code></td>
<td>
<p>A vector or factor.</p>
</td></tr>
<tr><td><code id="univariate_grid_+3A_grid_size">grid_size</code></td>
<td>
<p>Approximate grid size.</p>
</td></tr>
<tr><td><code id="univariate_grid_+3A_trim">trim</code></td>
<td>
<p>The default <code>c(0.01, 0.99)</code> means that values outside the
1% and 99% quantiles of non-discrete numeric columns are removed before calculation
of grid values. Set to <code>0:1</code> for no trimming.</p>
</td></tr>
<tr><td><code id="univariate_grid_+3A_strategy">strategy</code></td>
<td>
<p>How to find grid values of non-discrete numeric columns?
Either &quot;uniform&quot; or &quot;quantile&quot;, see description of <code><a href="#topic+univariate_grid">univariate_grid()</a></code>.</p>
</td></tr>
<tr><td><code id="univariate_grid_+3A_na.rm">na.rm</code></td>
<td>
<p>Should missing values be dropped from the grid? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector or factor of evaluation points.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multivariate_grid">multivariate_grid()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>univariate_grid(iris$Species)
univariate_grid(rev(iris$Species))                       # Same

x &lt;- iris$Sepal.Width
univariate_grid(x, grid_size = 5)                        # Uniform binning
univariate_grid(x, grid_size = 5, strategy = "quantile")  # Quantile
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
