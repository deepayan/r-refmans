<!DOCTYPE html><html><head><title>Help for package lax</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lax}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lax-package'><p>lax: Loglikelihood Adjustment for Extreme Value Models</p></a></li>
<li><a href='#alogLik'><p>Loglikelihood adjustment for model fits</p></a></li>
<li><a href='#anova.lax'><p>Comparison of nested models</p></a></li>
<li><a href='#bernoulli'><p>Inference for the Bernoulli distribution</p></a></li>
<li><a href='#eva'><p>Loglikelihood adjustment for eva fits</p></a></li>
<li><a href='#evd'><p>Loglikelihood adjustment for evd fits</p></a></li>
<li><a href='#evir'><p>Loglikelihood adjustment for evir fits</p></a></li>
<li><a href='#extRemes'><p>Loglikelihood adjustment for extRemes fits</p></a></li>
<li><a href='#fExtremes'><p>Loglikelihood adjustment for fExtremes fits</p></a></li>
<li><a href='#ismev'><p>Loglikelihood adjustment for ismev fits</p></a></li>
<li><a href='#ismev_refits'><p>Maximum-likelihood (Re-)Fitting using the ismev package</p></a></li>
<li><a href='#lax-internal'><p>Internal lax functions</p></a></li>
<li><a href='#logLik.logLikVec'><p>Sum loglikelihood contributions from individual observations</p></a></li>
<li><a href='#logLikVec'><p>Evaluate loglikelihood contributions from specific observations</p></a></li>
<li><a href='#mev'><p>Loglikelihood adjustment for mev fits</p></a></li>
<li><a href='#ow'><p>Oxford and Worthing annual maximum temperatures</p></a></li>
<li><a href='#plot.retlev'><p>Plot diagnostics for a retlev object</p></a></li>
<li><a href='#POT'><p>Loglikelihood adjustment for POT fits</p></a></li>
<li><a href='#pot_refit'><p>Fits a Poisson point process to the data, an approach sometimes known as</p>
peaks over thresholds (POT), and returns an object of class &quot;potd&quot;.</a></li>
<li><a href='#print.retlev'><p>Print method for retlev object</p></a></li>
<li><a href='#print.summary.retlev'><p>Print method for objects of class <code>"summary.retlev"</code></p></a></li>
<li><a href='#return_level'><p>Return Level Inferences for Stationary Extreme Value Models</p></a></li>
<li><a href='#summary.retlev'><p>Summary method for a <code>"retlev"</code> object</p></a></li>
<li><a href='#texmex'><p>Loglikelihood adjustment of texmex fits</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Loglikelihood Adjustment for Extreme Value Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-25</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs adjusted inferences based on model objects fitted, using 
    maximum likelihood estimation, by the extreme value analysis packages
    'eva' <a href="https://cran.r-project.org/package=eva">https://cran.r-project.org/package=eva</a>, 
    'evd' <a href="https://cran.r-project.org/package=evd">https://cran.r-project.org/package=evd</a>, 
    'evir' <a href="https://cran.r-project.org/package=evir">https://cran.r-project.org/package=evir</a>, 
    'extRemes' <a href="https://cran.r-project.org/package=extRemes">https://cran.r-project.org/package=extRemes</a>, 
    'fExtremes' <a href="https://cran.r-project.org/package=fExtremes">https://cran.r-project.org/package=fExtremes</a>, 
    'ismev' <a href="https://cran.r-project.org/package=ismev">https://cran.r-project.org/package=ismev</a>, 
    'mev' <a href="https://cran.r-project.org/package=mev">https://cran.r-project.org/package=mev</a>, 
    'POT' <a href="https://cran.r-project.org/package=POT">https://cran.r-project.org/package=POT</a> and
    'texmex' <a href="https://cran.r-project.org/package=texmex">https://cran.r-project.org/package=texmex</a>. 
    Adjusted standard errors and an adjusted loglikelihood are provided, using    
    the 'chandwich' package <a href="https://cran.r-project.org/package=chandwich">https://cran.r-project.org/package=chandwich</a>
    and the object-oriented features of the 'sandwich' package 
    <a href="https://cran.r-project.org/package=sandwich">https://cran.r-project.org/package=sandwich</a>. The adjustment is based on a 
    robust sandwich estimator of the parameter covariance matrix, based on the 
    methodology in Chandler and Bate (2007) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasm015">doi:10.1093/biomet/asm015</a>&gt;. This 
    can be used for cluster correlated data when interest lies in the 
    parameters of the marginal distributions, or for performing inferences that 
    are robust to certain types of model misspecification.  Univariate extreme 
    value models, including regression models, are supported.  </td>
</tr>
<tr>
<td>Imports:</td>
<td>chandwich, exdex, graphics, numDeriv, revdbayes, sandwich,
stats, utils</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>distillery, eva, evd, evir, extRemes, fExtremes, ismev,
knitr, mev, POT, rmarkdown, testthat, texmex</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://paulnorthrop.github.io/lax/">https://paulnorthrop.github.io/lax/</a>,
<a href="https://github.com/paulnorthrop/lax">https://github.com/paulnorthrop/lax</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/paulnorthrop/lax/issues">https://github.com/paulnorthrop/lax/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-25 14:34:49 UTC; Paul</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul J. Northrop [aut, cre, cph],
  Camellia Yin [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul J. Northrop &lt;p.northrop@ucl.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-25 14:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='lax-package'>lax: Loglikelihood Adjustment for Extreme Value Models</h2><span id='topic+lax'></span><span id='topic+lax-package'></span>

<h3>Description</h3>

<p>Performs adjusted inferences based on model objects fitted, using maximum
likelihood estimation, by the extreme value analysis packages
<a href="https://cran.r-project.org/package=evd">eva</a>,
<a href="https://cran.r-project.org/package=evd">evd</a>,
<a href="https://cran.r-project.org/package=evir">evir</a>,
<a href="https://cran.r-project.org/package=extRemes">extRemes</a>,
<a href="https://cran.r-project.org/package=fExtremes">fExtremes</a>,
<a href="https://cran.r-project.org/package=ismev">ismev</a>,
<a href="https://cran.r-project.org/package=mev">mev</a>,
<a href="https://cran.r-project.org/package=POT">POT</a> and
<a href="https://cran.r-project.org/package=texmex">texmex</a>.
Univariate extreme value models, including regression models, are supported.
Adjusted standard errors and an adjusted loglikelihood are provided,
using the
<a href="https://cran.r-project.org/package=chandwich">chandwich package</a>
and the object-oriented features of the
<a href="https://cran.r-project.org/package=sandwich">sandwich package</a>.
</p>


<h3>Details</h3>

<p>The adjustment is based on a robust sandwich estimator of the parameter
covariance matrix, based on the methodology in Chandler and Bate (2007).
This can be used for cluster correlated data
when interest lies in the parameters of the marginal distributions, or for
performing inferences that are robust to certain types of model
misspecification.
</p>
<p>The main function is <code><a href="#topic+alogLik">alogLik</a></code>, which works in an
object-oriented way, operating on fitted model objects.
This function performs the loglikelihood adjustments using
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
See the following package-specific help pages for details and examples:
<code><a href="#topic+eva">eva</a></code>,
<code><a href="#topic+evd">evd</a></code>,
<code><a href="#topic+evir">evir</a></code>,
<code><a href="#topic+extRemes">extRemes</a></code>,
<code><a href="#topic+fExtremes">fExtremes</a></code>,
<code><a href="#topic+ismev">ismev</a></code>,
<code><a href="#topic+mev">mev</a></code>,
<code><a href="#topic+POT">POT</a></code>,
<code><a href="#topic+texmex">texmex</a></code>.
</p>
<p>See <code>vignette("lax-vignette", package = "lax")</code> for an overview of the
package.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Paul J. Northrop <a href="mailto:p.northrop@ucl.ac.uk">p.northrop@ucl.ac.uk</a> [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Camellia Yin [copyright holder]
</p>
</li></ul>



<h3>References</h3>

<p>Bader, B. and Yan, J. (2020). eva: Extreme Value Analysis with
Goodness-of-Fit Testing. R package version 0.2.6.
<a href="https://CRAN.R-project.org/package=eva">https://CRAN.R-project.org/package=eva</a>
</p>
<p>Belzile, L., Wadsworth, J. L., Northrop, P. J., Grimshaw, S. D.
and Huser, R. (2019). mev: Multivariate Extreme Value Distributions.
R package version 1.12.2. <a href="https://github.com/lbelzile/mev/">https://github.com/lbelzile/mev/</a>
</p>
<p>Berger S., Graham N., Zeileis A. (2017). Various Versatile
Variances: An Object-Oriented Implementation of Clustered Covariances in R.
Technical Report 2017-12, Working Papers in Economics and Statistics,
Research Platform Empirical and Experimental Economics, Universitat
Innsbruck. <a href="https://EconPapers.RePEc.org/RePEc:inn:wpaper:2017-12">https://EconPapers.RePEc.org/RePEc:inn:wpaper:2017-12</a>.
</p>
<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Gilleland, E. and Katz, R. W. (2016). extRemes 2.0: An Extreme
Value Analysis Package in R. <em>Journal of Statistical Software</em>,
<strong>72</strong>(8), 1-39. <a href="https://doi.org/10.18637/jss.v072.i08">doi:10.18637/jss.v072.i08</a>
</p>
<p>Northrop, P. J. and Chandler, R. E. (2018).
chandwich: Chandler-Bate Sandwich Loglikelihood Adjustment. R package
version 1.1. <a href="https://CRAN.R-project.org/package=chandwich">https://CRAN.R-project.org/package=chandwich</a>.
</p>
<p>Pfaff, B. and McNeil, A. (2018). evir: Extreme Values in R.
R package version 1.7-4. <a href="https://CRAN.R-project.org/package=evir">https://CRAN.R-project.org/package=evir</a>
</p>
<p>Ribatet, M. and Dutang, C. (2019). POT: Generalized Pareto
Distribution and Peaks Over Threshold. R package version 1.1-7.
<a href="https://CRAN.R-project.org/package=POT">https://CRAN.R-project.org/package=POT</a>
</p>
<p>Southworth, H., Heffernan, J. E. and Metcalfe, P. D. (2017).
texmex: Statistical modelling of extreme values. R package version 2.4.
<a href="https://CRAN.R-project.org/package=texmex">https://CRAN.R-project.org/package=texmex</a>.
</p>
<p>Stephenson, A. G. evd: Extreme Value Distributions.
<em>R News</em>, <strong>2</strong>(2):31-32, June 2002.
<a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>
</p>
<p>Stephenson, A. G., Heffernan, J. E. and Gilleland, E. (2018).
ismev: An Introduction to Statistical Modeling of Extreme Values.
R package version 1.42. <a href="https://CRAN.R-project.org/package=ismev">https://CRAN.R-project.org/package=ismev</a>.
</p>
<p>Wuertz, D., Setz, T. and Chalabi, Y. (2017). fExtremes:
Rmetrics - Modelling Extreme Events in Finance. R package version
3042.82. <a href="https://CRAN.R-project.org/package=fExtremes">https://CRAN.R-project.org/package=fExtremes</a>
</p>
<p>Zeileis A. (2004). Econometric Computing with HC and HAC
Covariance Matrix Estimators. <em>Journal of Statistical Software</em>,
<strong>11</strong>(10), 1-17. <a href="https://doi.org/10.18637/jss.v011.i10">doi:10.18637/jss.v011.i10</a>.
</p>
<p>Zeileis A. (2006). Object-Oriented Computation of Sandwich
Estimators. <em>Journal of Statistical Software</em>, <strong>16</strong>(9),
1-16. <a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://paulnorthrop.github.io/lax/">https://paulnorthrop.github.io/lax/</a>
</p>
</li>
<li> <p><a href="https://github.com/paulnorthrop/lax">https://github.com/paulnorthrop/lax</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/paulnorthrop/lax/issues">https://github.com/paulnorthrop/lax/issues</a>
</p>
</li></ul>


<hr>
<h2 id='alogLik'>Loglikelihood adjustment for model fits</h2><span id='topic+alogLik'></span>

<h3>Description</h3>

<p>This function is generic.  It performs adjustment of the loglikelihood
associated with fitted model objects, following Chandler and Bate (2007).
Certain classes of extreme value model objects are supported automatically.
For details see the <code>alogLik</code> help pages for the packages:
<code><a href="#topic+evd">evd</a></code>,
<code><a href="#topic+evir">evir</a></code>,
<code><a href="#topic+extRemes">extRemes</a></code>,
<code><a href="#topic+fExtremes">fExtremes</a></code>,
<code><a href="#topic+ismev">ismev</a></code>,
<code><a href="#topic+mev">mev</a></code>,
<code><a href="#topic+POT">POT</a></code>,
<code><a href="#topic+texmex">texmex</a></code>.
User-supplied objects can also be supported: the requirements for these
objects are explained in <strong>Details</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alogLik(
  x,
  cluster = NULL,
  use_vcov = TRUE,
  binom = FALSE,
  k,
  inc_cens = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alogLik_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="alogLik_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="alogLik_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="alogLik_+3A_binom">binom</code></td>
<td>
<p>A logical scalar.  This option is only relevant to
<strong>GP models</strong> and is only available in the <strong>stationary</strong>
(no covariates) case. If <code>binom = FALSE</code> then loglikelihood
adjustment is only performed using the GP model. If <code>binom = TRUE</code>
then loglikelihood adjustment is also performed for inferences about the
probability of threshold exceedance, using a Bernoulli model for the
instances of threshold exceedance.</p>
</td></tr>
<tr><td><code id="alogLik_+3A_k">k</code></td>
<td>
<p>A non-negative integer scalar.  This option is only relevant to
<strong>GP models</strong> and is only available in the <strong>stationary</strong>
(no covariates) case.  If <code>k</code> is supplied then it is passed as the
run parameter <code class="reqn">K</code> to <code><a href="exdex.html#topic+kgaps">kgaps</a></code> for making inferences
about the extremal index <code class="reqn">\theta</code> using the <code class="reqn">K</code>-gaps model of
Suveges and Davison (2010).</p>
</td></tr>
<tr><td><code id="alogLik_+3A_inc_cens">inc_cens</code></td>
<td>
<p>A logical scalar.  This argument is only relevant if
<code>k</code> is supplied.  Passed to <code><a href="exdex.html#topic+kgaps">kgaps</a></code> to indicate
whether or not to include censored inter-exceedance times, relating to
the first and last observations.</p>
</td></tr>
<tr><td><code id="alogLik_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Object <code>x</code> <em>must</em> have the following S3
methods:
</p>

<ul>
<li> <p><code>logLikVec</code>: returns a vector of the contributions to the
independence loglikelihood from individual observations;
</p>
</li>
<li> <p><code>coef</code>: returns a vector of model coefficients, see
<code><a href="stats.html#topic+coef">coef</a></code>;
</p>
</li>
<li> <p><code>nobs</code>: returns the number of (non-missing) observations
used in a model fit, see <code><a href="stats.html#topic+nobs">nobs</a></code>;
</p>
</li></ul>

<p>and <em>may</em> have the following S3 methods
</p>

<ul>
<li> <p><code>vcov</code>: returns the estimated variance-covariance matrix of
the (main) parameters of a fitted model, see
<code><a href="stats.html#topic+vcov">vcov</a></code>;
</p>
</li>
<li> <p><code>estfun</code>: returns an <code class="reqn">n</code> by <code class="reqn">k</code> matrix, in which each
column gives the derivative of the loglikelihood at each of <code class="reqn">n</code>
observation with respect to the <code class="reqn">k</code> parameters of the model, see
<code><a href="sandwich.html#topic+estfun">estfun</a></code>.
</p>
</li></ul>

<p>Loglikelihood adjustment is performed using the
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> function in the
<code><a href="chandwich.html#topic+chandwich">chandwich</a></code> package.
The relevant arguments to <code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>, namely
<code>loglik, mle, H</code> and <code>V</code>, are created based on the class of
the object <code>x</code>.
</p>
<p>If a <code>vcov</code> method is not available, or if <code>use_vcov = FALSE</code>,
then the variance-covariance matrix of the MLE (from which <code>H</code> is
calculated) is estimated inside <code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>
using <code><a href="stats.html#topic+optim">optimHess</a></code>.
</p>
<p>The <code>sandwich</code> package is used to estimate the variance matrix
<code>V</code> of the score vector: <code><a href="sandwich.html#topic+meat">meat</a></code> is used if
<code>cluster = NULL</code>; <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> is used if
<code>cluster</code> is not <code>NULL</code>.
If <code>cluster</code> is <code>NULL</code> then any arguments of
<code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> present in ... will be ignored.
Similarly, if <code>cluster</code> is not <code>NULL</code> then any arguments of
<code><a href="sandwich.html#topic+meat">meat</a></code> present in ... will be ignored.
<code><a href="sandwich.html#topic+meat">meat</a></code> and <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code>
require an <code><a href="sandwich.html#topic+estfun">estfun</a></code> method to be available, which,
in the current context, provides matrix of score contributions.
If a bespoke <code>estfun</code> method is not provided then this is constructed
by estimating the score contributions using <code><a href="numDeriv.html#topic+jacobian">jacobian</a></code>.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
</p>
<p>The original fitted model object is available as an attribute named
<code>"original_fit"</code>, accessible using <code>attr(name, "original_fit")</code>,
where <code>name</code> is the name of the object to which the object returned
from <code>alogLik</code> is assigned.
</p>
<p>If <code>binom = TRUE</code> then the returned object has an extra attribute
named <code>pu_aloglik</code> that contains an object inheriting from class
<code>"chandwich"</code> relating specifically to inferences about the
probability of threshold exceedance. Also, the 4th component of the class
of the returned object becomes <code>"bin-gpd"</code>.
</p>
<p>If <code>k</code> is supplied then the returned object has an extra attribute
named <code>theta</code> that contains an object inheriting from class
<code>c("kgaps", "exdex")</code> relating specifically to inferences about the
extremal index <code class="reqn">\theta</code>.  See the <strong>Value</strong> section in
<code><a href="exdex.html#topic+kgaps">kgaps</a></code>.
</p>
<p>If <code>x</code> is one of the supported models then the class of the returned
object is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "name_of_package")</code>, where
<code>"name_of_package"</code> is the name of the package from which the input
object <code>x</code> originated.  The remaining 2 components depend on the
model that was fitted.  See the documentation of the relevant package
for details:
<code><a href="#topic+evd">evd</a></code>,
<code><a href="#topic+evir">evir</a></code>,
<code><a href="#topic+extRemes">extRemes</a></code>,
<code><a href="#topic+fExtremes">fExtremes</a></code>,
<code><a href="#topic+ismev">ismev</a></code>,
<code><a href="#topic+mev">mev</a></code>,
<code><a href="#topic+POT">POT</a></code>,
<code><a href="#topic+texmex">texmex</a></code>.
</p>
<p>Otherwise, the class of the returned object is
<code>c("lax", "chandwich", class(x))</code>.
</p>
<p>Objects returned from 'aloglik' have 'anova', 'coef', 'confint', 'logLik',
'nobs', 'plot', 'print', 'summary' and 'vcov' methods.
</p>


<h3>Examples</h3>

<p>See the (package-specific) examples in <code><a href="#topic+evd">evd</a></code>,
<code><a href="#topic+evir">evir</a></code>, <code><a href="#topic+extRemes">extRemes</a></code>,<code><a href="#topic+fExtremes">fExtremes</a></code>,
<code><a href="#topic+ismev">ismev</a></code>, <code><a href="#topic+mev">mev</a></code>, <code><a href="#topic+POT">POT</a></code> and
<code><a href="#topic+texmex">texmex</a></code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="chandwich.html#topic+summary.chandwich">summary.chandwich</a></code>,
<code><a href="chandwich.html#topic+plot.chandwich">plot.chandwich</a></code>,
<code><a href="chandwich.html#topic+confint.chandwich">confint.chandwich</a></code>,
<code><a href="chandwich.html#topic+anova.chandwich">anova.chandwich</a></code>,
<code><a href="chandwich.html#topic+coef.chandwich">coef.chandwich</a></code>,
<code><a href="chandwich.html#topic+vcov.chandwich">vcov.chandwich</a></code>
and <code><a href="chandwich.html#topic+logLik.chandwich">logLik.chandwich</a></code>
for S3 methods for objects of class <code>"chandwich"</code>.
</p>
<p><code><a href="chandwich.html#topic+conf_region">conf_region</a></code> for confidence regions for
pairs of parameters.
</p>
<p><code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> in the <code>chandwich</code>
package to adjust a user-supplied loglikelihood.
</p>
<p><code><a href="sandwich.html#topic+meat">meat</a></code> and
<code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> in the sandwich package.
</p>

<hr>
<h2 id='anova.lax'>Comparison of nested models</h2><span id='topic+anova.lax'></span>

<h3>Description</h3>

<p><code>anova</code> method for objects of class <code>"lax"</code>.
Compares two or more nested models using the adjusted likelihood ratio
test statistic (ALRTS) described in Section 3.5 of Chandler and Bate (2007).
The nesting must result from the simple constraint that a subset of the
parameters of the larger model is held fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lax'
anova(object, object2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.lax_+3A_object">object</code></td>
<td>
<p>An object of class <code>"lax"</code>, inheriting from class
<code>"chandwich"</code>, returned by <code><a href="#topic+alogLik">alogLik</a></code>.</p>
</td></tr>
<tr><td><code id="anova.lax_+3A_object2">object2</code></td>
<td>
<p>An object of class <code>"lax"</code>, inheriting from class
<code>"chandwich"</code>, returned by <code><a href="#topic+alogLik">alogLik</a></code>.</p>
</td></tr>
<tr><td><code id="anova.lax_+3A_...">...</code></td>
<td>
<p>Further objects of class <code>"lax"</code> and/or arguments
to be passed to <code><a href="chandwich.html#topic+anova.chandwich">anova.chandwich</a></code>, and then on to
<code><a href="chandwich.html#topic+compare_models">compare_models</a></code>, in particular <code>type</code>, which
chooses the type of adjustment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objects of class <code>"lax"</code> need not be provided in nested
order: they will be ordered inside <code>anova.lax</code> based on the
values of <code>attr(., "p_current")</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"anova"</code> inheriting from class
<code>"data.frame"</code>, with four columns:
</p>
<table>
<tr><td><code>Model.Df</code></td>
<td>
<p>The number of parameters in the model</p>
</td></tr>
<tr><td><code>Df</code></td>
<td>
<p>The decrease in the number of parameter compared the model
in the previous row</p>
</td></tr>
<tr><td><code>ALRTS</code></td>
<td>
<p>The adjusted likelihood ratio test statistic</p>
</td></tr>
<tr><td><code>Pr(&gt;ALRTS)</code></td>
<td>
<p>The p-value associated with the test that the
model is a valid simplification of the model in the previous row.</p>
</td></tr>
</table>
<p>The row names are the names of the model objects.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>


<h3>See Also</h3>

<p><code><a href="chandwich.html#topic+anova.chandwich">anova.chandwich</a></code>: the <code>anova</code> method
on which <code>anova.lax</code> is based.
</p>
<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>got_evd &lt;- requireNamespace("evd", quietly = TRUE)
if (got_evd) {
  library(evd)
  small &lt;- fgev(ow$temp, nsloc = ow[, "loc"])
  adj_small &lt;- alogLik(small, cluster = ow$year)
  tiny &lt;- fgev(ow$temp)
  adj_tiny &lt;- alogLik(tiny, cluster = ow$year)
  anova(adj_small, adj_tiny)

  set.seed(4082019)
  uvdata &lt;- evd::rgev(100, loc = 0.13, scale = 1.1, shape = 0.2)
  M0 &lt;- fgev(uvdata)
  M1 &lt;- fgev(uvdata, nsloc = (-49:50)/100)
  adj0 &lt;- alogLik(M0)
  adj1 &lt;- alogLik(M1)
  anova(adj1, adj0)
}

got_extRemes &lt;- requireNamespace("extRemes", quietly = TRUE)
if (got_extRemes) {
  library(extRemes)
  large &lt;- fevd(temp, ow, location.fun = ~ loc, scale.fun = ~ loc,
                shape.fun = ~ loc)
  medium &lt;- fevd(temp, ow, location.fun = ~ loc, scale.fun = ~ loc)
  small &lt;- fevd(temp, ow, location.fun = ~ loc)
  tiny &lt;- fevd(temp, ow)
  adj_large &lt;- alogLik(large, cluster = ow$year)
  adj_medium &lt;- alogLik(medium, cluster = ow$year)
  adj_small &lt;- alogLik(small, cluster = ow$year)
  adj_tiny &lt;- alogLik(tiny, cluster = ow$year)
  anova(adj_large, adj_medium, adj_small, adj_tiny)
}
</code></pre>

<hr>
<h2 id='bernoulli'>Inference for the Bernoulli distribution</h2><span id='topic+bernoulli'></span><span id='topic+fit_bernoulli'></span><span id='topic+logLikVec.bernoulli'></span><span id='topic+nobs.bernoulli'></span><span id='topic+coef.bernoulli'></span><span id='topic+vcov.bernoulli'></span><span id='topic+logLik.bernoulli'></span><span id='topic+alogLik.bernoulli'></span>

<h3>Description</h3>

<p>Functions involved in making inferences about the probability of success
in a Bernoulli distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_bernoulli(data)

## S3 method for class 'bernoulli'
logLikVec(object, pars = NULL, ...)

## S3 method for class 'bernoulli'
nobs(object, ...)

## S3 method for class 'bernoulli'
coef(object, ...)

## S3 method for class 'bernoulli'
vcov(object, ...)

## S3 method for class 'bernoulli'
logLik(object, ...)

## S3 method for class 'bernoulli'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bernoulli_+3A_data">data</code></td>
<td>
<p>A numeric vector of outcomes from Bernoulli trials: 0 for a
failure, 1 for a success.  Alternatively, a logical vector with FALSE
for a failure and TRUE for a success.</p>
</td></tr>
<tr><td><code id="bernoulli_+3A_pars">pars</code></td>
<td>
<p>A numeric parameter vector of length 1 containing the value of
the Bernoulli success probability.</p>
</td></tr>
<tr><td><code id="bernoulli_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
<tr><td><code id="bernoulli_+3A_x">x</code>, <code id="bernoulli_+3A_object">object</code></td>
<td>
<p>A fitted model object returned from <code>fit_bernoulli()</code>.</p>
</td></tr>
<tr><td><code id="bernoulli_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster each
observation in <code>data</code> originates.</p>
</td></tr>
<tr><td><code id="bernoulli_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit_bernoulli</code>: fit a Bernoulli distribution
</p>
<p><code>logLikVec.bernoulli</code>: calculates contributions to a loglikelihood based
on the Bernoulli distribution.  The loglikelihood is calculated up to an
additive constant.
</p>
<p><code>nobs, coef, vcov</code> and <code>logLik</code> methods are provided.
</p>


<h3>Value</h3>

<p><code>fit_bernoulli</code> returns an object of class <code>"bernoulli"</code>, a list
with components: <code>logLik, mle, nobs, vcov, data, obs_data</code>, where
<code>data</code> are the input data and <code>obs_data</code> are the input data after
any missing values have been removed, using
<code><a href="stats.html#topic+na.fail">na.omit</a></code>.
</p>
<p><code>logLikVec.bernoulli</code> returns an object of class <code>"logLikVec"</code>, a
vector length <code>length(data)</code> containing the likelihood contributions
from the individual observations in <code>data</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Binomial">Binomial</a></code>.  The Bernoulli distribution is the
special case where <code>size = 1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Set up data
x &lt;- exdex::newlyn
u &lt;- quantile(x, probs = 0.9)
exc &lt;- x &gt; u

# Fit a Bernoulli distribution
fit &lt;- fit_bernoulli(exc)

# Calculate the loglikelihood at the MLE
res &lt;- logLikVec(fit)

# The logLik method sums the individual loglikelihood contributions.
logLik(res)

# nobs, coef, vcov, logLik methods for objects returned from fit_bernoulli()
nobs(fit)
coef(fit)
vcov(fit)
logLik(fit)

# Adjusted loglikelihood
# Create 5 clusters each corresponding approximately to 1 year of data
cluster &lt;- rep(1:5, each = 579)[-1]
afit &lt;- alogLik(fit, cluster = cluster, cadjust = FALSE)
summary(afit)
</code></pre>

<hr>
<h2 id='eva'>Loglikelihood adjustment for eva fits</h2><span id='topic+eva'></span><span id='topic+alogLik.gevrFit'></span><span id='topic+alogLik.gpdFit'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code><a href="eva.html#topic+gevrFit">gevrFit</a></code> and <code><a href="eva.html#topic+gpdFit">gpdFit</a></code> in the eva package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gevrFit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'gpdFit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eva_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="eva_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="eva_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="eva_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>
<p>In the stationary case (no covariates) the function
<code><a href="eva.html#topic+gevrFit">gevrFit</a></code> and <code><a href="eva.html#topic+gpdFit">gpdFit</a></code> in the eva
package offer standard errors based on the expected information or on the
observed information, via the argument <code>information</code>.  In contrast,
<code>alogLik()</code> always bases calculations on the observed information
matrix. Therefore, unadjusted standard errors resulting from
<code>alogLik()</code> may be different the corresponding standard errors
from  <code><a href="eva.html#topic+gevrFit">gevrFit</a></code> or <code><a href="eva.html#topic+gpdFit">gpdFit</a></code>.
</p>
<p>For <code><a href="eva.html#topic+gevrFit">gevrFit</a></code> only GEV fits (<code>gumbel = FALSE</code>) are
supported.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "eva")</code>.
The 4th component depends on which model was fitted.
<code>"rlarg"</code> if <code><a href="eva.html#topic+gevrFit">gevrFit</a></code> was used;
<code>"gpd"</code> if <code><a href="eva.html#topic+gpdFit">gpdFit</a></code> was used.
The 5th component is
<code>"stat"</code> if there are no covariates in the mode and
<code>"nonstat"</code> otherwise.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the eva package
got_eva &lt;- requireNamespace("eva", quietly = TRUE)

if (got_eva) {
  library(eva)
  # An example from the eva::gpdFit documentation
  set.seed(7)
  x &lt;- eva::rgpd(2000, loc = 0, scale = 2, shape = 0.2)
  mle_fit &lt;- eva::gpdFit(x, threshold = 4, method = "mle")
  adj_mle_fit &lt;- alogLik(mle_fit)
  summary(adj_mle_fit)

  # Another example from the eva::gpdFit documentation
  # A linear trend in the scale parameter
  set.seed(7)
  n &lt;- 300
  x2 &lt;- eva::rgpd(n, loc = 0, scale = 1 + 1:n / 200, shape = 0)
  covs &lt;- as.data.frame(seq(1, n, 1))
  names(covs) &lt;- c("Trend1")
  result1 &lt;- eva::gpdFit(x2, threshold = 0, scalevars = covs,
                         scaleform = ~ Trend1)
  adj_result1 &lt;- alogLik(result1)
  summary(adj_result1)

  # An example from the eva::gevrFit documentation
  set.seed(7)
  x1 &lt;- eva::rgevr(500, 1, loc = 0.5, scale = 1, shape = 0.3)
  result1 &lt;- eva::gevrFit(x1, method = "mle")
  adj_result1 &lt;- alogLik(result1)
  summary(adj_result1)

  # Another example from the eva::gevrFit documentation
  # A linear trend in the location and scale parameter
  n &lt;- 100
  r &lt;- 10
  x2 &lt;- eva::rgevr(n, r, loc = 100 + 1:n / 50,  scale = 1 + 1:n / 300,
                   shape = 0)
  covs &lt;- as.data.frame(seq(1, n, 1))
  names(covs) &lt;- c("Trend1")
  # Create some unrelated covariates
  covs$Trend2 &lt;- rnorm(n)
  covs$Trend3 &lt;- 30 * runif(n)
  result2 &lt;- eva::gevrFit(data = x2, method = "mle", locvars = covs,
                          locform = ~ Trend1 + Trend2*Trend3,
                          scalevars = covs, scaleform = ~ Trend1)
  adj_result2 &lt;- alogLik(result2)
  summary(adj_result2)
}
</code></pre>

<hr>
<h2 id='evd'>Loglikelihood adjustment for evd fits</h2><span id='topic+evd'></span><span id='topic+alogLik.evd'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code><a href="evd.html#topic+fgev">fgev</a></code> and <code><a href="evd.html#topic+fpot">fpot</a></code> in the evd package.
If <code>x</code> is returned from <code><a href="evd.html#topic+fgev">fgev</a></code> then the call must
have used <code>prob = NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'evd'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evd_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="evd_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="evd_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="evd_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "evd")</code>.
The remaining 2 components depend on the model that was fitted.
If <code><a href="evd.html#topic+fgev">fgev</a></code> was used then these components are
<code>c("gev", "stat")</code> if <code>nsloc</code> was <code>NULL</code> and
<code>c("gev", "nonstat")</code> if <code>nsloc</code> was not <code>NULL</code>.
If <code><a href="evd.html#topic+fpot">fpot</a></code> was used then these components are
<code>c("pot", "gpd")</code> if <code>model</code> was <code>"gpd"</code> and
<code>c("pot", "pp")</code> if <code>model</code> was <code>"pp"</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the evd package
got_evd &lt;- requireNamespace("evd", quietly = TRUE)

if (got_evd) {
  library(evd)
  # An example from the evd::fgev documentation
  set.seed(3082019)
  uvdata &lt;- evd::rgev(100, loc = 0.13, scale = 1.1, shape = 0.2)
  M1 &lt;- evd::fgev(uvdata, nsloc = (-49:50)/100)
  adj_fgev &lt;- alogLik(M1)
  summary(adj_fgev)

  # An example from Chandler and Bate (2007)
  owfit &lt;- fgev(ow$temp, nsloc = ow$loc)
  adj_owfit &lt;- alogLik(owfit, cluster = ow$year)
  summary(adj_owfit)

  # An example from the evd::fpot documentation
  set.seed(3082019)
  uvdata &lt;- evd::rgpd(100, loc = 0, scale = 1.1, shape = 0.2)
  M1 &lt;- fpot(uvdata, 1)
  adj_fpot &lt;- alogLik(M1)
  summary(adj_fpot)
  # Fit using the pp model, rather than the gpd
  M1 &lt;- fpot(uvdata, 1, model = "pp", npp = 365)
  adj_fpot &lt;- alogLik(M1)
  summary(adj_fpot)
}
</code></pre>

<hr>
<h2 id='evir'>Loglikelihood adjustment for evir fits</h2><span id='topic+evir'></span><span id='topic+alogLik.gev'></span><span id='topic+alogLik.gpd'></span><span id='topic+alogLik.potd'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code><a href="evir.html#topic+gev">gev</a></code>, <code><a href="evir.html#topic+gpd">gpd</a></code> and <code><a href="evir.html#topic+pot">pot</a></code>
in the evir package.
If <code>x</code> was returned from <code><a href="evir.html#topic+pot">pot</a></code> then the model will
need to be re-fitted using <code><a href="#topic+pot_refit">pot_refit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gev'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'gpd'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'potd'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evir_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="evir_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="evir_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="evir_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>
<p>If <code><a href="evir.html#topic+pot">pot</a></code> was used then <code>x</code> does not contain the
raw data that <code>alogLik</code> needs.  The model will need to be
re-fitted using <code><a href="#topic+pot_refit">pot_refit</a></code> and the user will be prompted to
do this by an error message produced by <code><a href="#topic+alogLik">alogLik</a></code>.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "evir")</code>.
The remaining 2 components depend on the model that was fitted.
If <code><a href="evir.html#topic+gev">gev</a></code> was used then these components are
<code>c("gev", "stat")</code>.
If <code><a href="evir.html#topic+gpd">gpd</a></code> was used then these components are
<code>c("gpd", "stat")</code>.
If <code><a href="#topic+pot_refit">pot_refit</a></code> was used then these components are
<code>c("potd", "stat")</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the evir package
got_evir &lt;- requireNamespace("evir", quietly = TRUE)
if (got_evir) {
  library(evir)
  # An example from the evir::gev documentation
  data(bmw)
  out &lt;- gev(bmw, "month")
  adj_out &lt;- alogLik(out)
  summary(adj_out)

  # An example from the evir::gpd documentation
  data(danish)
  out &lt;- gpd(danish, 10)
  adj_out &lt;- alogLik(out)
  summary(adj_out)

  # An example from the evir::pot documentation
  # We use lax::pot_refit() to return the input data
  out &lt;- pot_refit(danish, 10)
  adj_out &lt;- alogLik(out)
  summary(adj_out)
}
</code></pre>

<hr>
<h2 id='extRemes'>Loglikelihood adjustment for extRemes fits</h2><span id='topic+extRemes'></span><span id='topic+alogLik.fevd'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the function
<code><a href="extRemes.html#topic+fevd">fevd</a></code> in the
<code><a href="extRemes.html#topic+extRemes-package">extRemes</a></code> package.
The model must have been fitted using maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fevd'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extRemes_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="extRemes_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="extRemes_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="extRemes_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "extRemes")</code>.
The remaining 2 components depend on the model that was fitted.
The 4th component is: <code>"gev"</code> if <code>x$type = "GEV"</code> or
<code>x$type = "Gumbel"</code>; <code>"gp"</code> if <code>x$type = "GP"</code> or
<code>x$type = "Exponential"</code>; <code>"pp"</code> if <code>x$type = "PP"</code>.
The 5th component is
<code>"stat"</code> if <code><a href="extRemes.html#topic+is.fixedfevd">is.fixedfevd</a> = TRUE</code> and
<code>"nonstat"</code> if <code><a href="extRemes.html#topic+is.fixedfevd">is.fixedfevd</a> = FALSE</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the extRemes and distillery packages
got_extRemes &lt;- requireNamespace("extRemes", quietly = TRUE)
got_distillery &lt;- requireNamespace("distillery", quietly = TRUE)

if (got_extRemes &amp; got_distillery) {
  library(extRemes)
  library(distillery)
  # Examples from the extRemes::fevd documentation
  data(PORTw)

  # GEV
  fit0 &lt;- fevd(TMX1, PORTw, units = "deg C", use.phi = TRUE)
  adj_fit0 &lt;- alogLik(fit0)
  summary(adj_fit0)

  # GEV regression
  fitPORTstdmax &lt;- fevd(TMX1, PORTw, scale.fun = ~STDTMAX, use.phi = TRUE)
  adj_fit1 &lt;- alogLik(fitPORTstdmax)
  summary(adj_fit1)
  fitPORTstdmax2 &lt;- fevd(TMX1, PORTw, location.fun = ~STDTMAX,
                         scale.fun = ~STDTMAX, use.phi = TRUE)
  adj_fit2 &lt;- alogLik(fitPORTstdmax2)
  summary(adj_fit2)
  anova(adj_fit0, adj_fit1)
  anova(adj_fit1, adj_fit2)
  anova(adj_fit0, adj_fit2)
  anova(adj_fit0, adj_fit1, adj_fit2)

  # Gumbel
  fit0 &lt;- fevd(TMX1, PORTw, type = "Gumbel", units = "deg C")
  adj_fit0 &lt;- alogLik(fit0)
  summary(adj_fit0)

  # GP
  data(damage)
  fit1 &lt;- fevd(Dam, damage, threshold = 6, type = "GP",
               time.units = "2.05/year")
  adj_fit1 &lt;- alogLik(fit1)
  summary(adj_fit1)

  # Exponential
  fit0 &lt;- fevd(Dam, damage, threshold = 6, type="Exponential",
               time.units = "2.05/year")
  adj_fit0 &lt;- alogLik(fit0)
  summary(adj_fit0)

  # GP non-constant threshold
  data(Fort)
  fit &lt;- fevd(Prec, Fort, threshold = 0.475,
              threshold.fun = ~I(-0.15 * cos(2 * pi * month / 12)),
              type = "GP")
  adj_fit &lt;- alogLik(fit)
  summary(adj_fit)

  # Exponential non-constant threshold
  fit &lt;- fevd(Prec, Fort, threshold = 0.475,
              threshold.fun = ~I(-0.15 * cos(2 * pi * month / 12)),
              type = "Exponential")
  adj_fit &lt;- alogLik(fit)
  summary(adj_fit)

  # PP model
  fit &lt;- fevd(Prec, Fort, threshold = 0.475, type = "PP", units = "inches")
  adj_fit &lt;- alogLik(fit)
  summary(adj_fit)

  # PP non-constant threshold
  fit &lt;- fevd(Prec, Fort, threshold = 0.475,
              threshold.fun=~I(-0.15 * cos(2 * pi * month / 12)),
              type = "PP")
  adj_fit &lt;- alogLik(fit)
  summary(adj_fit)
}
</code></pre>

<hr>
<h2 id='fExtremes'>Loglikelihood adjustment for fExtremes fits</h2><span id='topic+fExtremes'></span><span id='topic+alogLik.fGEVFIT'></span><span id='topic+alogLik.fGPDFIT'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code><a href="fExtremes.html#topic+GevModelling">gevFit</a></code>,
<code><a href="fExtremes.html#topic+GevModelling">gumbelFit</a></code> and
<code><a href="fExtremes.html#topic+GpdModelling">gpdFit</a></code>
in the <code><a href="fExtremes.html#topic+00Extremes-package">fExtremes</a></code> package.
The model must have been fitted using maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fGEVFIT'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'fGPDFIT'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fExtremes_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="fExtremes_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="fExtremes_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="fExtremes_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "fExtremes")</code>.
The remaining 2 components depend on the model that was fitted.
If <code><a href="fExtremes.html#topic+GevModelling">gevFit</a></code> or
<code><a href="fExtremes.html#topic+GevModelling">gumbelFit</a></code> was used then these
components are <code>c("gev", "stat")</code>.
If <code><a href="fExtremes.html#topic+GpdModelling">gpdFit</a></code> was used then these
components are <code>c("gpd", "stat")</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the fExtremes package
got_fExtremes &lt;- requireNamespace("fExtremes", quietly = TRUE)
if (got_fExtremes) {
  library(fExtremes)

  # GEV
  # An example from the fExtremes::gevFit documentation
  set.seed(4082019)
  x &lt;- fExtremes::gevSim(model = list(xi=0.25, mu=0, beta=1), n = 1000)
  # Fit GEV distribution by maximum likelihood estimation
  fit &lt;- fExtremes::gevFit(x)
  adj_fit &lt;- alogLik(fit)
  summary(adj_fit)

  # GP
  # An example from the fExtremes::gpdFit documentation
  # Simulate GP data
  x &lt;- fExtremes::gpdSim(model = list(xi = 0.25, mu = 0, beta = 1), n = 1000)
  # Fit GP distribution by maximum likelihood estimation
  fit &lt;- fExtremes::gpdFit(x, u = min(x))
  adj_fit &lt;- alogLik(fit)
  summary(adj_fit)
}
</code></pre>

<hr>
<h2 id='ismev'>Loglikelihood adjustment for ismev fits</h2><span id='topic+ismev'></span><span id='topic+alogLik.gev.fit'></span><span id='topic+alogLik.pp.fit'></span><span id='topic+alogLik.gpd.fit'></span><span id='topic+alogLik.rlarg.fit'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code><a href="ismev.html#topic+gev.fit">gev.fit</a></code>, <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code>,
<code><a href="ismev.html#topic+pp.fit">pp.fit</a></code> and <code><a href="ismev.html#topic+rlarg.fit">rlarg.fit</a></code> in the
<code><a href="ismev.html#topic+ismev">ismev</a></code> package.  If regression modelling is used then
the model will need to be re-fitted, see <code><a href="#topic+ismev_refits">ismev_refits</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gev.fit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'pp.fit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'gpd.fit'
alogLik(
  x,
  cluster = NULL,
  use_vcov = TRUE,
  binom = FALSE,
  k,
  inc_cens = TRUE,
  ...
)

## S3 method for class 'rlarg.fit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ismev_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="ismev_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="ismev_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="ismev_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
<tr><td><code id="ismev_+3A_binom">binom</code></td>
<td>
<p>A logical scalar.  This option is only relevant to
<strong>GP models</strong> and is only available in the <strong>stationary</strong>
(no covariates) case. If <code>binom = FALSE</code> then loglikelihood
adjustment is only performed using the GP model. If <code>binom = TRUE</code>
then loglikelihood adjustment is also performed for inferences about the
probability of threshold exceedance, using a Bernoulli model for the
instances of threshold exceedance.</p>
</td></tr>
<tr><td><code id="ismev_+3A_k">k</code></td>
<td>
<p>A non-negative integer scalar.  This option is only relevant to
<strong>GP models</strong> and is only available in the <strong>stationary</strong>
(no covariates) case.  If <code>k</code> is supplied then it is passed as the
run parameter <code class="reqn">K</code> to <code><a href="exdex.html#topic+kgaps">kgaps</a></code> for making inferences
about the extremal index <code class="reqn">\theta</code> using the <code class="reqn">K</code>-gaps model of
Suveges and Davison (2010).</p>
</td></tr>
<tr><td><code id="ismev_+3A_inc_cens">inc_cens</code></td>
<td>
<p>A logical scalar.  This argument is only relevant if
<code>k</code> is supplied.  Passed to <code><a href="exdex.html#topic+kgaps">kgaps</a></code> to indicate
whether or not to include censored inter-exceedance times, relating to
the first and last observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>
<p>If regression modelling is used then the ismev functions
<code><a href="ismev.html#topic+gev.fit">gev.fit</a></code>, <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code>,
<code><a href="ismev.html#topic+pp.fit">pp.fit</a></code> and <code><a href="ismev.html#topic+rlarg.fit">rlarg.fit</a></code>
return residuals but <code><a href="#topic+alogLik">alogLik</a></code> needs the raw data.
The model will need to be re-fitted, using one of the functions in
<code><a href="#topic+ismev_refits">ismev_refits</a></code>, and the user will be prompted to do this
by an error message produced by <code><a href="#topic+alogLik">alogLik</a></code>.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
</p>
<p><code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "ismev")</code>.
The remaining 2 components depend on the model that was fitted.
The 4th component is:
<code>"gev"</code> if <code><a href="ismev.html#topic+gev.fit">gev.fit</a></code>
(or <code><a href="#topic+gev_refit">gev_refit</a></code>) was used;
<code>"gpd"</code> if <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code>
(or <code><a href="#topic+gpd_refit">gpd_refit</a></code>) was used;
<code>"pp"</code> <code><a href="ismev.html#topic+pp.fit">pp.fit</a></code>
(or <code><a href="#topic+pp_refit">pp_refit</a></code>) was used;
<code>"rlarg"</code> <code><a href="ismev.html#topic+rlarg.fit">rlarg.fit</a></code>
(or <code><a href="#topic+rlarg_refit">rlarg_refit</a></code>) was used.
The 5th component is
<code>"stat"</code> if <code>x$trans = FALSE</code> and
<code>"nonstat"</code> if <code>x$trans = TRUE</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the ismev package
got_ismev &lt;- requireNamespace("ismev", quietly = TRUE)

if (got_ismev) {
  library(ismev)

  # GEV model -----

  # An example from the ismev::gev.fit documentation
  gev_fit &lt;- gev.fit(revdbayes::portpirie, show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit)
  summary(adj_gev_fit)

  # An example from chapter 6 of Coles (2001)
  data(fremantle)
  xdat &lt;- fremantle[, "SeaLevel"]
  # Set year 1897 to 1 for consistency with page 113 of Coles (2001)
  ydat &lt;- cbind(fremantle[, "Year"] - 1896, fremantle[, "SOI"])
  gev_fit &lt;- gev_refit(xdat, ydat, mul = 1:2, show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit)
  summary(adj_gev_fit)

  # An example from Chandler and Bate (2007)
  gev_fit &lt;- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4,
                       show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit, cluster = ow$year)
  summary(adj_gev_fit)
  # Get closer to the values reported in Table 2 of Chandler and Bate (2007)
  gev_fit &lt;- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4,
                       show = FALSE, method = "BFGS")
  # Call sandwich::meatCL() with cadjust = FALSE
  adj_gev_fit &lt;- alogLik(gev_fit, cluster = ow$year, cadjust = FALSE)
  summary(adj_gev_fit)

  # GP model -----

  # An example from the ismev::gpd.fit documentation
  
  data(rain)
  rain_fit &lt;- gpd.fit(rain, 10, show = FALSE)
  adj_rain_fit &lt;- alogLik(rain_fit)
  summary(adj_rain_fit)
  # Continuing to the regression example on page 119 of Coles (2001)
  ydat &lt;- as.matrix((1:length(rain)) / length(rain))
  reg_rain_fit &lt;- gpd_refit(rain, 30, ydat = ydat, sigl = 1, siglink = exp,
                            show = FALSE)
  adj_reg_rain_fit &lt;- alogLik(reg_rain_fit)
  summary(adj_reg_rain_fit)
  
  # Binomial-GP model -----

  # Use Newlyn seas surges data from the exdex package
  surges &lt;- exdex::newlyn
  u &lt;- quantile(surges, probs = 0.9)
  newlyn_fit &lt;- gpd.fit(surges, u, show = FALSE)
  # Create 5 clusters each corresponding approximately to 1 year of data
  cluster &lt;- rep(1:5, each = 579)[-1]
  adj_newlyn_fit &lt;- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,
                            cadjust = FALSE)
  summary(adj_newlyn_fit)
  summary(attr(adj_newlyn_fit, "pu_aloglik"))

  # Add inference about the extremal index theta, using K = 1
  adj_newlyn_theta &lt;- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,
                              k = 1, cadjust = FALSE)
  summary(attr(adj_newlyn_theta, "theta"))

  # PP model -----

  # An example from the ismev::pp.fit documentation
  data(rain)
  # Start from the mle to save time
  init &lt;- c(40.55755732, 8.99195409, 0.05088103)
  muinit &lt;- init[1]
  siginit &lt;- init[2]
  shinit &lt;- init[3]
  rain_fit &lt;- pp_refit(rain, 10, muinit = muinit, siginit = siginit,
                       shinit = shinit, show = FALSE)
  adj_rain_fit &lt;- alogLik(rain_fit)
  summary(adj_rain_fit)

  # An example from chapter 7 of Coles (2001).
  # Code from demo ismev::wooster.temps
  data(wooster)
  x &lt;- seq(along = wooster)
  usin &lt;- function(x, a, b, d) {
    return(a + b * sin(((x - d) * 2 * pi) / 365.25))
  }
  wu &lt;- usin(x, -30, 25, -75)
  ydat &lt;- cbind(sin(2 * pi * x / 365.25), cos(2 * pi *x / 365.25))
  # Start from the mle to save time
  init &lt;- c(-15.3454188, 9.6001844, 28.5493828, 0.5067104, 0.1023488,
            0.5129783, -0.3504231)
  muinit &lt;- init[1:3]
  siginit &lt;- init[4:6]
  shinit &lt;- init[7]
  wooster.pp &lt;- pp_refit(-wooster, threshold = wu, ydat = ydat, mul = 1:2,
                         sigl = 1:2, siglink = exp, method = "BFGS",
                         muinit = muinit, siginit = siginit, shinit = shinit,
                         show = FALSE)
  adj_pp_fit &lt;- alogLik(wooster.pp)
  summary(adj_pp_fit)

  # r-largest order statistics model -----

  # An example based on the ismev::rlarg.fit() documentation
  vdata &lt;- revdbayes::venice
  rfit &lt;- rlarg.fit(vdata, muinit = 120.54, siginit = 12.78,
                    shinit = -0.1129, show = FALSE)
  adj_rfit &lt;- alogLik(rfit)
  summary(adj_rfit)

  
  # Adapt this example to add a covariate
  set.seed(30102019)
  ydat &lt;- matrix(runif(nrow(vdata)), nrow(vdata), 1)
  rfit2 &lt;- rlarg_refit(vdata, ydat = ydat, mul = 1,
                       muinit = c(120.54, 0), siginit = 12.78,
                       shinit = -0.1129, show = FALSE)
  adj_rfit2 &lt;- alogLik(rfit2)
  summary(adj_rfit2)
  
}
</code></pre>

<hr>
<h2 id='ismev_refits'>Maximum-likelihood (Re-)Fitting using the ismev package</h2><span id='topic+ismev_refits'></span><span id='topic+gev_refit'></span><span id='topic+gpd_refit'></span><span id='topic+pp_refit'></span><span id='topic+rlarg_refit'></span>

<h3>Description</h3>

<p>These are a slightly modified versions of the <code><a href="ismev.html#topic+gev.fit">gev.fit</a></code>,
<code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code>, <code><a href="ismev.html#topic+pp.fit">pp.fit</a></code> and
<code><a href="ismev.html#topic+rlarg.fit">rlarg.fit</a></code> functions in the <code><a href="ismev.html#topic+ismev">ismev</a></code>
package.
The modification is to add to the returned object regression design matrices
for the parameters of the model.  That is,
<code>xdat, ydat, mulink, siglink, shlink</code> and matrices
<code>mumat, sigmat, shmat</code> for the location, scale and shape parameters
<code><a href="ismev.html#topic+gev.fit">gev.fit</a></code>, <code><a href="ismev.html#topic+pp.fit">pp.fit</a></code> and
<code><a href="ismev.html#topic+rlarg.fit">rlarg.fit</a></code>, and <code>xdat</code>,
<code>ydat, siglink, shlink</code> and matrices <code>sigmat, shmat</code> for the
scale and shape parameters for <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev_refit(
  xdat,
  ydat = NULL,
  mul = NULL,
  sigl = NULL,
  shl = NULL,
  mulink = identity,
  siglink = identity,
  shlink = identity,
  muinit = NULL,
  siginit = NULL,
  shinit = NULL,
  show = TRUE,
  method = "Nelder-Mead",
  maxit = 10000,
  ...
)

gpd_refit(
  xdat,
  threshold,
  npy = 365,
  ydat = NULL,
  sigl = NULL,
  shl = NULL,
  siglink = identity,
  shlink = identity,
  siginit = NULL,
  shinit = NULL,
  show = TRUE,
  method = "Nelder-Mead",
  maxit = 10000,
  ...
)

pp_refit(
  xdat,
  threshold,
  npy = 365,
  ydat = NULL,
  mul = NULL,
  sigl = NULL,
  shl = NULL,
  mulink = identity,
  siglink = identity,
  shlink = identity,
  muinit = NULL,
  siginit = NULL,
  shinit = NULL,
  show = TRUE,
  method = "Nelder-Mead",
  maxit = 10000,
  ...
)

rlarg_refit(
  xdat,
  r = dim(xdat)[2],
  ydat = NULL,
  mul = NULL,
  sigl = NULL,
  shl = NULL,
  mulink = identity,
  siglink = identity,
  shlink = identity,
  muinit = NULL,
  siginit = NULL,
  shinit = NULL,
  show = TRUE,
  method = "Nelder-Mead",
  maxit = 10000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ismev_refits_+3A_xdat">xdat</code></td>
<td>
<p>A numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_ydat">ydat</code></td>
<td>
<p>A matrix of covariates for generalized linear modelling
of the parameters (or <code>NULL</code> (the default) for stationary
fitting). The number of rows should be the same as the length
of <code>xdat</code>.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_mul">mul</code>, <code id="ismev_refits_+3A_sigl">sigl</code>, <code id="ismev_refits_+3A_shl">shl</code></td>
<td>
<p>Numeric vectors of integers, giving the columns
of <code>ydat</code> that contain covariates for generalized linear
modelling of the location, scale and shape parameters repectively
(or <code>NULL</code> (the default) if the corresponding parameter is
stationary).</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_mulink">mulink</code>, <code id="ismev_refits_+3A_siglink">siglink</code>, <code id="ismev_refits_+3A_shlink">shlink</code></td>
<td>
<p>Inverse link functions for generalized
linear modelling of the location, scale and shape parameters
repectively.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_muinit">muinit</code>, <code id="ismev_refits_+3A_siginit">siginit</code>, <code id="ismev_refits_+3A_shinit">shinit</code></td>
<td>
<p>numeric of length equal to total number
of parameters used to model the location, scale or shape parameter(s),
resp.  See Details section for default (NULL) initial values.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_show">show</code></td>
<td>
<p>Logical; if <code>TRUE</code> (the default), print details of
the fit.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_method">method</code></td>
<td>
<p>The optimization method (see <code><a href="stats.html#topic+optim">optim</a></code> for
details).</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_...">...</code></td>
<td>
<p>Other control parameters for the optimization. These
are passed to components of the <code>control</code> argument of
<code>optim</code>.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_threshold">threshold</code></td>
<td>
<p>The threshold; a single number or a numeric
vector of the same length as <code>xdat</code>.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_npy">npy</code></td>
<td>
<p>The number of observations per year/block.</p>
</td></tr>
<tr><td><code id="ismev_refits_+3A_r">r</code></td>
<td>
<p>The largest <code>r</code> order statistics are used for
the fitted model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Heffernan, J. E. and Stephenson, A. G. (2018). ismev: An
Introduction to Statistical Modeling of Extreme Values.
R package version 1.42.
<a href="https://CRAN.R-project.org/package=ismev">https://CRAN.R-project.org/package=ismev</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the ismev package
got_ismev &lt;- requireNamespace("ismev", quietly = TRUE)
if (got_ismev) {
  library(ismev)
  fit1 &lt;- gev.fit(revdbayes::portpirie, show = FALSE)
  ls(fit1)
  fit2 &lt;- gev_refit(revdbayes::portpirie, show = FALSE)
  ls(fit2)

  data(rain)
  fit1 &lt;- gpd.fit(rain, 10)
  ls(fit1)
  fit2 &lt;- gpd_refit(rain, 10)
  ls(fit2)

  fit1 &lt;- pp.fit(rain, 10, show = FALSE)
  ls(fit1)
  fit2 &lt;- pp_refit(rain, 10, show = FALSE)
  ls(fit2)

  data(venice)
  fit1 &lt;- rlarg.fit(venice[, -1], muinit = 120.54, siginit = 12.78,
                   shinit = -0.1129, show = FALSE)
  ls(fit1)
  fit2 &lt;- rlarg_refit(venice[, -1], muinit = 120.54, siginit = 12.78,
                   shinit = -0.1129, show = FALSE)
  ls(fit2)
}
</code></pre>

<hr>
<h2 id='lax-internal'>Internal lax functions</h2><span id='topic+lax-internal'></span><span id='topic+adj_object'></span><span id='topic+return_level_gev'></span><span id='topic+gev_rl_CI'></span><span id='topic+gev_rl_prof'></span><span id='topic+return_level_bingp'></span><span id='topic+bingp_rl_CI'></span><span id='topic+bingp_rl_prof'></span><span id='topic+box_cox_deriv'></span><span id='topic+ismev_ppp'></span><span id='topic+kgaps_loglik'></span>

<h3>Description</h3>

<p>Internal lax functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adj_object(x, cluster = NULL, use_vcov = TRUE, ...)

return_level_gev(x, m, level, npy, prof, inc, type)

gev_rl_CI(x, m, level, npy, type)

gev_rl_prof(x, m, level, npy, inc, type, rl_sym)

return_level_bingp(x, m, level, npy, prof, inc, type, npy_given)

bingp_rl_CI(x, m, level, npy, type, u)

bingp_rl_prof(x, m, level, npy, inc, type, rl_sym, u)

box_cox_deriv(x, lambda = 1, lambda_tol = 1/50, poly_order = 3)

ismev_ppp(a, npy)

kgaps_loglik(theta, N0, N1, sum_qs, n_kgaps)
</code></pre>


<h3>Details</h3>

<p>These functions are not intended to be called by the user.
</p>

<hr>
<h2 id='logLik.logLikVec'>Sum loglikelihood contributions from individual observations</h2><span id='topic+logLik.logLikVec'></span>

<h3>Description</h3>

<p>S3 logLik method for logLikVec objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logLikVec'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.logLikVec_+3A_object">object</code></td>
<td>
<p>An object of class <code>"logLikVec"</code> return from a
<code>logLikVec</code> method.</p>
</td></tr>
<tr><td><code id="logLik.logLikVec_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='logLikVec'>Evaluate loglikelihood contributions from specific observations</h2><span id='topic+logLikVec'></span>

<h3>Description</h3>

<p>Generic function for calculating loglikelihood contributions from
individual observations for a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLikVec(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLikVec_+3A_object">object</code></td>
<td>
<p>A fitted model object.</p>
</td></tr>
<tr><td><code id="logLikVec_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='mev'>Loglikelihood adjustment for mev fits</h2><span id='topic+mev'></span><span id='topic+alogLik.mev_gev'></span><span id='topic+alogLik.mev_pp'></span><span id='topic+alogLik.mev_gpd'></span><span id='topic+alogLik.mev_egp'></span><span id='topic+alogLik.mev_rlarg'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code><a href="mev.html#topic+fit.gev">fit.gev</a></code>, <code><a href="mev.html#topic+fit.gpd">fit.gpd</a></code>, and
<code><a href="mev.html#topic+fit.pp">fit.pp</a></code> and <code><a href="mev.html#topic+fit.rlarg">fit.rlarg</a></code> in the
mev package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mev_gev'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'mev_pp'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'mev_gpd'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'mev_egp'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'mev_rlarg'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mev_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="mev_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="mev_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="mev_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>
<p>If <code>x</code> was returned from <code><a href="mev.html#topic+fit.pp">fit.pp</a></code> then the data
<code>xdat</code> supplied to <code><a href="mev.html#topic+fit.pp">fit.pp</a></code> must contain <em>all</em>
the data, both threshold exceedances and non-exceedances.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "mev")</code>.
The 4th component depends on which model was fitted.
<code>"gev"</code> if <code><a href="mev.html#topic+fit.gev">fit.gev</a></code> was used;
<code>"gpd"</code> if <code><a href="mev.html#topic+fit.gpd">fit.gpd</a></code> was used;
<code>"pp"</code> <code><a href="mev.html#topic+fit.pp">fit.pp</a></code> was used;
<code>"egp"</code> <code><a href="mev.html#topic+fit.egp">fit.egp</a></code> was used;
<code>"rlarg"</code> <code><a href="mev.html#topic+fit.rlarg">fit.rlarg</a></code> was used;
The 5th component is <code>"stat"</code> (for stationary).
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the mev package
got_mev &lt;- requireNamespace("mev", quietly = TRUE)

if (got_mev) {
  library(mev)
  # An example from the mev::gev.fit documentation
  gev_mev &lt;- fit.gev(revdbayes::portpirie)
  adj_gev_mev &lt;- alogLik(gev_mev)
  summary(adj_gev_mev)

  # Use simulated data
  set.seed(1112019)
  x &lt;- revdbayes::rgp(365 * 10, loc = 0, scale = 1, shape = 0.1)
  pfit &lt;- fit.pp(x, threshold = 1, npp = 365)
  adj_pfit &lt;- alogLik(pfit)
  summary(adj_pfit)

  # An example from the mev::fit.gpd documentation
  gpd_mev &lt;- fit.gpd(eskrain, threshold = 35, method = 'Grimshaw')
  adj_gpd_mev &lt;- alogLik(gpd_mev)
  summary(adj_gpd_mev)

  # An example from the mev::fit.egp documentation
  # (model = "egp1" and model = "egp3" also work)
  xdat &lt;- evd::rgpd(n = 100, loc = 0, scale = 1, shape = 0.5)
  fitted &lt;- fit.egp(xdat = xdat, thresh = 1, model = "egp2", show = FALSE)
  adj_fitted &lt;- alogLik(fitted)
  summary(adj_fitted)

  # An example from the mev::fit.rlarg documentation
  set.seed(31102019)
  xdat &lt;- rrlarg(n = 10, loc = 0, scale = 1, shape = 0.1, r = 4)
  fitr &lt;- fit.rlarg(xdat)
  adj_fitr &lt;- alogLik(fitr)
  summary(adj_fitr)
}
</code></pre>

<hr>
<h2 id='ow'>Oxford and Worthing annual maximum temperatures</h2><span id='topic+ow'></span>

<h3>Description</h3>

<p>Annual maximum temperatures at Oxford and Worthing (England), for the
period 1901 to 1980.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ow
</code></pre>


<h3>Format</h3>

<p>A dataframe with 80 rows and 4 columns.
</p>

<ul>
<li><p> Column 1, <code>temp</code>: annual maximum temperatures in degrees
Fahrenheit.
</p>
</li>
<li><p> Column 2, <code>year</code>: year in which the maximum was recorded.
</p>
</li>
<li><p> Column 3, <code>name</code>: name of location, &quot;oxford&quot; or &quot;worthing&quot;
</p>
</li>
<li><p> Column 4, <code>loc</code>: location: 1 for &quot;oxford&quot;, -1 for
&quot;worthing&quot;
</p>
</li></ul>



<h3>Source</h3>

<p>Tabony, R. C. (1983) Extreme value analysis in meteorology.
<em>The Meteorological Magazine</em>, <strong>112</strong>, 77-98.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>

<hr>
<h2 id='plot.retlev'>Plot diagnostics for a retlev object</h2><span id='topic+plot.retlev'></span>

<h3>Description</h3>

<p><code>plot</code> method for an objects of class <code>c("retlev", "lax")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'retlev'
plot(x, y = NULL, level = NULL, legend = TRUE, digits = 3, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.retlev_+3A_x">x</code></td>
<td>
<p>an object of class <code>c("retlev", "lax")</code>, a result of
a call to <code><a href="#topic+return_level">return_level</a></code>, using <code>prof = TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.retlev_+3A_y">y</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="plot.retlev_+3A_level">level</code></td>
<td>
<p>A numeric scalar in (0, 1).  The confidence level required for
the confidence interval for the <code>m</code>-year return level.
If <code>level</code> is not supplied then <code>x$level</code> is used.
<code>level</code> must be no larger than <code>x$level</code>.</p>
</td></tr>
<tr><td><code id="plot.retlev_+3A_legend">legend</code></td>
<td>
<p>A logical scalar.  Should we add a legend (in the top right
of the plot) that gives the approximate values of the MLE and
100<code>level</code>% confidence limits?</p>
</td></tr>
<tr><td><code id="plot.retlev_+3A_digits">digits</code></td>
<td>
<p>An integer. Passed to <code><a href="base.html#topic+Round">signif</a></code> to
round the values in the legend.</p>
</td></tr>
<tr><td><code id="plot.retlev_+3A_plot">plot</code></td>
<td>
<p>A logical scalar.  If <code>TRUE</code> then the plot is produced.
Otherwise, it is not, but the MLE and confidence limits are returned.</p>
</td></tr>
<tr><td><code id="plot.retlev_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to
<code><a href="graphics.html#topic+plot.default">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots the profile loglikelihood for a return level, provided that
<code>x</code> returned by a call to <code><a href="#topic+return_level">return_level</a></code> using
<code>prof = TRUE</code>.  Horizontal lines indicate the values of the
maximised loglikelihood and the critical level used to calculate
the confidence limits.
If <code>level</code> is smaller than <code>x$level</code> then approximate
100<code>level</code>% confidence limits are recalculated based on the
information contained in <code>x$for_plot</code>.
</p>


<h3>Value</h3>

<p>A numeric vector of length 3 containing the lower
100<code>level</code>% confidence limit, the MLE and the upper
100<code>level</code>% confidence limit.
</p>


<h3>Examples</h3>

<p>See the examples in <code><a href="#topic+return_level">return_level</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+return_level">return_level</a></code> to perform inferences about return
levels.
</p>

<hr>
<h2 id='POT'>Loglikelihood adjustment for POT fits</h2><span id='topic+POT'></span><span id='topic+alogLik.uvpot'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from
<code><a href="POT.html#topic+fitGPD">fitGPD</a></code> function in the POT package.
The model must have been fitted using maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'uvpot'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="POT_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="POT_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="POT_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="POT_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
</p>
<p><code>class(x)</code> is <code>c("lax", "chandwich", "POT", "pot", "gpd")</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the POT package
got_POT &lt;- requireNamespace("POT", quietly = TRUE)

if (got_POT) {
  library(POT)
  # An example from the POT::fitgpd documentation.
  set.seed(4082019)
  x &lt;- POT::rgpd(200, 1, 2, 0.25)
  fit &lt;- fitgpd(x, 1, "mle")
  adj_fit &lt;- alogLik(fit)
}
</code></pre>

<hr>
<h2 id='pot_refit'>Fits a Poisson point process to the data, an approach sometimes known as
peaks over thresholds (POT), and returns an object of class &quot;potd&quot;.</h2><span id='topic+pot_refit'></span>

<h3>Description</h3>

<p>This is a slightly modified versions of the <code><a href="evir.html#topic+pot">pot</a></code>
function in the <code>evir</code> package.
The main modification is to add to the returned object the argument
<code>data</code> supplied by the user.  This is added to the returned
(list) object with the name <code>input_data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pot_refit(data, threshold = NA, nextremes = NA, run = NA, picture = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pot_refit_+3A_data">data</code></td>
<td>
<p>numeric vector of data, which may have a times attribute
containing (in an object of class <code>"POSIXct"</code>, or an object that can
be converted to that class; see <code><a href="base.html#topic+as.POSIXct">as.POSIXct</a></code>) the times/dates
of each observation. If no times attribute exists, the data are assumed to
be equally spaced.</p>
</td></tr>
<tr><td><code id="pot_refit_+3A_threshold">threshold</code></td>
<td>
<p>a threshold value (either this or <code>nextremes</code> must be
given but not both).</p>
</td></tr>
<tr><td><code id="pot_refit_+3A_nextremes">nextremes</code></td>
<td>
<p>the number of upper extremes to be used (either this or
<code>threshold</code> must be given but not both).</p>
</td></tr>
<tr><td><code id="pot_refit_+3A_run">run</code></td>
<td>
<p>if the data are to be declustered the run length parameter for
the runs method (see <code><a href="evir.html#topic+decluster">decluster</a></code>) should be entered
here.</p>
</td></tr>
<tr><td><code id="pot_refit_+3A_picture">picture</code></td>
<td>
<p>whether or not a picture should be drawn if declustering is
performed.</p>
</td></tr>
<tr><td><code id="pot_refit_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bernhard Pfaff and Alexander McNeil (2018). evir: Extreme
Values in R. R package version 1.7-4.
<a href="https://CRAN.R-project.org/package=evir">https://CRAN.R-project.org/package=evir</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We need the evir package
got_evir &lt;- requireNamespace("evir", quietly = TRUE)
if (got_evir) {
  library(evir)
  data(danish)
  out &lt;- pot(danish, 10)
  ls(out)
  out &lt;- pot_refit(danish, 10)
  ls(out)
}
</code></pre>

<hr>
<h2 id='print.retlev'>Print method for retlev object</h2><span id='topic+print.retlev'></span>

<h3>Description</h3>

<p><code>print</code> method for an objects of class <code>c("retlev", "lax")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'retlev'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.retlev_+3A_x">x</code></td>
<td>
<p>an object of class <code>c("retlev", "lax")</code>, a result of
a call to <code><a href="#topic+return_level">return_level</a></code>.</p>
</td></tr>
<tr><td><code id="print.retlev_+3A_digits">digits</code></td>
<td>
<p>The argument <code>digits</code> to <code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
<tr><td><code id="print.retlev_+3A_...">...</code></td>
<td>
<p>Additional arguments.  None are used in this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the call to <code><a href="#topic+return_level">return_level</a></code> and the estimates
and 100<code>x$level</code>% confidence limits for the <code>x$m</code>-year
return level.
</p>


<h3>Value</h3>

<p>The argument <code>x</code>, invisibly, as for all
<code><a href="base.html#topic+print">print</a></code> methods.
</p>


<h3>Examples</h3>

<p>See the examples in <code><a href="#topic+return_level">return_level</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+return_level">return_level</a></code>.
</p>

<hr>
<h2 id='print.summary.retlev'>Print method for objects of class <code>"summary.retlev"</code></h2><span id='topic+print.summary.retlev'></span>

<h3>Description</h3>

<p><code>print</code> method for an object <code>x</code> of class <code>"summary.retlev"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.retlev'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.retlev_+3A_x">x</code></td>
<td>
<p>An object of class &quot;summary.retlev&quot;, a result of a call to
<code><a href="#topic+summary.retlev">summary.retlev</a></code>.</p>
</td></tr>
<tr><td><code id="print.summary.retlev_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prints the call and the numeric matrix <code>x$matrix</code> returned from
<code><a href="#topic+summary.retlev">summary.retlev</a></code>.
</p>


<h3>Value</h3>

<p>The argument <code>x</code>, invisibly, as for all
<code><a href="base.html#topic+print">print</a></code> methods.
</p>


<h3>Examples</h3>

<p>See the examples in <code><a href="#topic+return_level">return_level</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+return_level">return_level</a></code> to perform inferences about return
levels.
</p>

<hr>
<h2 id='return_level'>Return Level Inferences for Stationary Extreme Value Models</h2><span id='topic+return_level'></span>

<h3>Description</h3>

<p>Calculates point estimates and confidence intervals for <code>m</code>-year
return levels for <strong>stationary</strong> extreme value fitted model objects
returned from <code><a href="#topic+alogLik">alogLik</a></code>.  Two types of interval may be returned:
(a) intervals based on approximate large-sample normality of the maximum
likelihood estimator for return level, which are symmetric about the point
estimate, and (b) profile likelihood-based intervals based on an (adjusted)
loglikelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>return_level(
  x,
  m = 100,
  level = 0.95,
  npy = 1,
  prof = TRUE,
  inc = NULL,
  type = c("vertical", "cholesky", "spectral", "none")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="return_level_+3A_x">x</code></td>
<td>
<p>An object inheriting from class <code>"lax"</code> returned from
<code><a href="#topic+alogLik">alogLik</a></code>.</p>
</td></tr>
<tr><td><code id="return_level_+3A_m">m</code></td>
<td>
<p>A numeric scalar.  The return period, in years.</p>
</td></tr>
<tr><td><code id="return_level_+3A_level">level</code></td>
<td>
<p>A numeric scalar in (0, 1).  The confidence level required for
confidence interval for the <code>m</code>-year return level.</p>
</td></tr>
<tr><td><code id="return_level_+3A_npy">npy</code></td>
<td>
<p>A numeric scalar.  The (mean) number of observations per year.
<strong>Setting this appropriately is important</strong>. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="return_level_+3A_prof">prof</code></td>
<td>
<p>A logical scalar.  Should we calculate intervals based on
profile loglikelihood?</p>
</td></tr>
<tr><td><code id="return_level_+3A_inc">inc</code></td>
<td>
<p>A numeric scalar. Only relevant if <code>prof = TRUE</code>. The
increment in return level by which we move upwards and downwards from the
MLE for the return level in the search for the lower and upper confidence
limits.  If this is not supplied then <code>inc</code> is set to one hundredth
of the length of the symmetric confidence interval for return level.</p>
</td></tr>
<tr><td><code id="return_level_+3A_type">type</code></td>
<td>
<p>A character scalar.  The argument <code>type</code> to the function
returned by <code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>, that is, the type of
adjustment made to the independence loglikelihood function in creating
an adjusted loglikelihood function.  See <strong>Details</strong> and
<strong>Value</strong> in <code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>At present <code>return_level</code> only supports GEV models.
</p>
<p><strong>Care must be taken in specifying the input value of <code>npy</code>.</strong>
</p>

<ul>
<li> <p><strong>GEV models</strong>: it is common to have one observation per year,
either because the data are annual maxima or because for each year only
the maximum value over a particular season is extracted from the raw
data. In this case, <code>npy = 1</code>, which is the default.  If instead
we extract the maximum values over the first and second halves of each
year then <code>npy = 2</code>.
</p>
</li>
<li> <p><strong>Binomial-GP models</strong>: <code>npy</code> provides information
about the (intended) frequency of sampling in time, that is, the number
of observations that would be observed in a year if there are no
missing values.  If the number of observations may vary between years
then <code>npy</code> should be set equal to the mean number of observations
per year.
</p>
</li></ul>

<p><strong>Supplying <code>npy</code> for binomial-GP models.</strong>
The value of <code>npy</code> (or an equivalent, perhaps differently named,
quantity) may have been set in the call to fit a GP model.
For example, the <code>gpd.fit()</code> function in the <code>ismev</code> package
has a <code>npy</code> argument and the value of <code>npy</code> is stored in the
fitted model object.  If <code>npy</code> is supplied by the user in the call to
<code>return_level</code> then this will be used in preference to the value
stored in the fitted model object.  If these two values differ then no
warning will be given.
</p>
<p>For details of the definition and estimation of return levels see the
Inference for return levels vignette.
</p>
<p>The profile likelihood-based intervals are calculated by
reparameterising in terms of the <code>m</code>-year return level and estimating
the values at which the (adjusted) profile loglikelihood reaches
the critical value <code>logLik(x) - 0.5 * stats::qchisq(level, 1)</code>.
This is achieved by calculating the profile loglikelihood for a sequence
of values of this return level as governed by <code>inc</code>. Once the profile
loglikelihood drops below the critical value the lower and upper limits are
estimated by interpolating linearly between the cases lying either side of
the critical value. The smaller <code>inc</code> the more accurate (but slower)
the calculation will be.
</p>


<h3>Value</h3>

<p>A object (a list) of class <code>"retlev", "lax"</code> with the
components
</p>
<table>
<tr><td><code>rl_sym</code>, <code>rl_prof</code></td>
<td>
<p>Named numeric vectors containing the respective
lower 100<code>level</code>% limit, the MLE and the upper
100<code>level</code>% limit for the return level.
If <code>prof = FALSE</code> then <code>rl_prof</code> will be missing.</p>
</td></tr>
<tr><td><code>rl_se</code></td>
<td>
<p>Estimated standard error of the return level.</p>
</td></tr>
<tr><td><code>max_loglik</code>, <code>crit</code>, <code>for_plot</code></td>
<td>
<p>If <code>prof = TRUE</code> then
these components will be present, containing respectively: the maximised
loglikelihood; the critical value and a matrix with return levels in
the first column (<code>ret_levs</code>) and the corresponding values of the
(adjusted) profile loglikelihood (<code>prof_loglik</code>).</p>
</td></tr>
<tr><td><code>m</code>, <code>level</code></td>
<td>
<p>The input values of <code>m</code> and <code>level</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call to <code>return_level</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coles, S. G. (2001) <em>An Introduction to Statistical
Modeling of Extreme Values</em>, Springer-Verlag, London.
<a href="https://doi.org/10.1007/978-1-4471-3675-0_3">doi:10.1007/978-1-4471-3675-0_3</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.retlev">plot.retlev</a></code> for plotting the profile loglikelihood
for a return level.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># GEV model -----

got_evd &lt;- requireNamespace("evd", quietly = TRUE)

if (got_evd) {
  library(evd)
  # An example from the evd::fgev documentation
  set.seed(4082019)
  uvdata &lt;- evd::rgev(100, loc = 0.13, scale = 1.1, shape = 0.2)
  M1 &lt;- fgev(uvdata)
  adj_fgev &lt;- alogLik(M1)
  # Large inc set here for speed, sacrificing accuracy
  rl &lt;- return_level(adj_fgev, inc = 0.5)
  summary(rl)
  rl
  plot(rl)
}

got_ismev &lt;- requireNamespace("ismev", quietly = TRUE)

if (got_ismev) {
  library(ismev)
  # An example from the ismev::gev.fit documentation
  gev_fit &lt;- gev.fit(revdbayes::portpirie, show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit)
  # Large inc set here for speed, sacrificing accuracy
  rl &lt;- return_level(adj_gev_fit, inc = 0.05)
  summary(rl)
  rl
  plot(rl)
}

# Binomial-GP model -----

if (got_ismev) {
  library(ismev)
  data(rain)
  # An example from the ismev::gpd.fit documentation
  rain_fit &lt;- gpd.fit(rain, 10, show = FALSE)
  adj_rain_fit &lt;- alogLik(rain_fit, binom = TRUE)
  # Large inc set here for speed, sacrificing accuracy
  rl &lt;- return_level(adj_rain_fit, inc = 2.5)
  summary(rl)
  rl
  plot(rl)
}

if (got_ismev) {
  # Use Newlyn seas surges data from the exdex package
  surges &lt;- exdex::newlyn
  u &lt;- quantile(surges, probs = 0.9)
  newlyn_fit &lt;- gpd.fit(surges, u, show = FALSE)
  # Create 5 clusters each corresponding approximately to 1 year of data
  cluster &lt;- rep(1:5, each = 579)[-1]
  adj_newlyn_fit &lt;- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,
                            cadjust = FALSE)
  rl &lt;- return_level(adj_newlyn_fit, inc = 0.02)
  rl

  # Add inference about the extremal index theta, using K = 1
  adj_newlyn_theta &lt;- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,
                              k = 1, cadjust = FALSE)
  rl &lt;- return_level(adj_newlyn_theta, inc = 0.02)
  rl
}
</code></pre>

<hr>
<h2 id='summary.retlev'>Summary method for a <code>"retlev"</code> object</h2><span id='topic+summary.retlev'></span>

<h3>Description</h3>

<p><code>summary</code> method for an objects of class <code>c("retlev", "lax")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'retlev'
summary(object, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.retlev_+3A_object">object</code></td>
<td>
<p>an object of class <code>c("retlev", "lax")</code>, a result of
a call to <code><a href="#topic+return_level">return_level</a></code>.</p>
</td></tr>
<tr><td><code id="summary.retlev_+3A_digits">digits</code></td>
<td>
<p>An integer. Used for number formatting with
<code><a href="base.html#topic+Round">signif</a></code>.  If <code>digits</code> is not specified
(i.e. <code><a href="base.html#topic+missing">missing</a></code>) then <code>signif()</code> will not be called
(i.e. no rounding will be performed).</p>
</td></tr>
<tr><td><code id="summary.retlev_+3A_...">...</code></td>
<td>
<p>Additional arguments.  None are used in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the list element <code>object$call</code>
and a numeric matrix <code>matrix</code> containing the MLE and estimated
SE of the return level.
</p>


<h3>Examples</h3>

<p>See the examples in <code><a href="#topic+return_level">return_level</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+return_level">return_level</a></code>.
</p>

<hr>
<h2 id='texmex'>Loglikelihood adjustment of texmex fits</h2><span id='topic+texmex'></span><span id='topic+alogLik.evmOpt'></span>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment of fitted
extreme value model objects returned from the <code><a href="texmex.html#topic+evm">evm</a></code>
function in the <code><a href="texmex.html#topic+texmex-package">texmex</a></code> package.
The model must have been fitted using maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'evmOpt'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="texmex_+3A_x">x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="texmex_+3A_cluster">cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td></tr>
<tr><td><code id="texmex_+3A_use_vcov">use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>?
Otherwise, <code>H</code> is estimated inside
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code> using
<code><a href="stats.html#topic+optim">optimHess</a></code>.</p>
</td></tr>
<tr><td><code id="texmex_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code><a href="sandwich.html#topic+meat">meat</a></code> (if <code>cluster = NULL</code>),
or <code><a href="sandwich.html#topic+vcovCL">meatCL</a></code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+alogLik">alogLik</a></code> for details.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code><a href="chandwich.html#topic+adjust_loglik">adjust_loglik</a></code>.
<code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "texmex")</code>.
The remaining 2 components depend on the model that was fitted.
The 4th component is: <code>"gev"</code> if <code>x$family$name = "GEV"</code>;
<code>"gpd"</code> if <code>x$family$name = "GPD"</code>;
<code>"egp3"</code> if <code>x$family$name = "EGP3"</code>.
The 5th component is
<code>"stat"</code> if there are no covariates in the mode and
<code>"nonstat"</code> otherwise.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alogLik">alogLik</a></code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Not run to avoid a CRAN check error inherited from the texmex package
# We need the texmex package, and ismev for the fremantle dataset
got_texmex &lt;- requireNamespace("texmex", quietly = TRUE)
got_ismev &lt;- requireNamespace("ismev", quietly = TRUE)
if (got_texmex) {
  library(texmex)
  # Examples from the texmex::evm documentation

  # GEV
  mod &lt;- evm(SeaLevel, data = texmex::portpirie, family = gev)
  adj_mod &lt;- alogLik(mod)
  summary(adj_mod)

  # GP
  mod &lt;- evm(rain, th = 30)
  adj_mod &lt;- alogLik(mod)
  summary(adj_mod)
  mod &lt;- evm(rain, th = 30, cov = "sandwich")
  mod$se
  vcov(adj_mod)
  vcov(mod)

  # EGP3
  mod &lt;- evm(rain, th = 30, family = egp3)
  adj_mod &lt;- alogLik(mod)
  summary(adj_mod)

  # GP regression
  # An example from page 119 of Coles (2001)
  n_rain &lt;- length(rain)
  rain_df &lt;- data.frame(rain = rain, time = 1:n_rain / n_rain)
  evm_fit &lt;- evm(y = rain, data = rain_df, family = gpd, th = 30,
                 phi = ~ time)
  adj_evm_fit &lt;- alogLik(evm_fit)
  summary(adj_evm_fit)
  evm_fit &lt;- evm(y = rain, data = rain_df, family = gpd, th = 30,
                 phi = ~ time, cov = "sandwich")
  evm_fit$se
  vcov(adj_evm_fit)
  vcov(evm_fit)

  # GEV regression
  # An example from page 113 of Coles (2001)
  if (got_ismev) {
    library(ismev)
    data(fremantle)
    new_fremantle &lt;- fremantle
    # Set year 1897 to 1 for consistency with page 113 of Coles (2001)
    new_fremantle[, "Year"] &lt;- new_fremantle[, "Year"] - 1896
    evm_fit &lt;- evm(y = SeaLevel, data = new_fremantle, family = gev,
                   mu = ~ Year + SOI)
    adj_evm_fit &lt;- alogLik(evm_fit)
    summary(adj_evm_fit)
  }

  # An example from Chandler and Bate (2007)
  # Note: evm uses phi = log(sigma)
  evm_fit &lt;- evm(temp, ow, gev, mu = ~ loc, phi = ~ loc, xi = ~loc)
  adj_evm_fit &lt;- alogLik(evm_fit, cluster = ow$year, cadjust = FALSE)
  summary(adj_evm_fit)
}

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
