<!DOCTYPE html><html><head><title>Help for package CTD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CTD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cohorts_coded'><p>Disease cohorts with coded identifiers</p></a></li>
<li><a href='#data.combineData'><p>Combine datasets</p></a></li>
<li><a href='#data.imputeData'><p>Impute missing values</p></a></li>
<li><a href='#data.surrogateProfiles'><p>Generate surrogate profiles</p></a></li>
<li><a href='#data.zscoreData'><p>Z-transform available data</p></a></li>
<li><a href='#graph.connectToExt'><p>Connect a node to its unvisited &quot;extended&quot; neighbors</p></a></li>
<li><a href='#graph.diffuseP1'><p>Diffuse Probability P1 from a starting node</p></a></li>
<li><a href='#graph.diffusionSnapShot'><p>Capture the current state of probability diffusion</p></a></li>
<li><a href='#graph.naivePruning'><p>Network pruning for disease-specific network determination</p></a></li>
<li><a href='#graph.netWalkSnapShot'><p>Capture the current location of a network walker</p></a></li>
<li><a href='#Miller2015'><p>Miller et al. (2015)</p></a></li>
<li><a href='#mle.getEncodingLength'><p>Minimum encoding length</p></a></li>
<li><a href='#mle.getMinPtDistance'><p>Get minimum patient distances</p></a></li>
<li><a href='#mle.getPtBSbyK'><p>Generate patient-specific bitstrings</p></a></li>
<li><a href='#mle.getPtDist'><p>CTDncd: A network-based distance metric.</p></a></li>
<li><a href='#multiNode.getNodeRanks'><p>Generate multi-node node rankings (&quot;adaptive&quot; walk)</p></a></li>
<li><a href='#singleNode.getNodeRanksN'><p>Generate single-node node rankings (&quot;fixed&quot; walk)</p></a></li>
<li><a href='#stat.entropyFunction'><p>Entropy of a bit-string</p></a></li>
<li><a href='#stat.fishersMethod'><p>Fisher's Combined P-value</p></a></li>
<li><a href='#stat.getDirSim'><p>DirSim: The Jaccard distance with directionality incorporated.</p></a></li>
<li><a href='#Thistlethwaite2020'><p>Thistlethwaite et al. (2020)</p></a></li>
<li><a href='#Wangler2017'><p>Wangler et al. (2017)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Method for 'Connecting The Dots' in Weighted Graphs</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-24</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Varduhi Petrosyan &lt;varduhi.petrosyan@bcm.edu&gt;</td>
</tr>
<tr>
<td>Author:</td>
<td>Varduhi Petrosyan[aut,cre],Lillian Thistlethwaite [aut,cre]</td>
</tr>
<tr>
<td>Description:</td>
<td>A method for pattern discovery in weighted graphs as outlined in Thistlethwaite et al. (2021) &lt;<a href="https://doi.org/10.1371%2Fjournal.pcbi.1008550">doi:10.1371/journal.pcbi.1008550</a>&gt;. Two use cases are achieved: 1) Given a weighted graph and a subset of its nodes, do the nodes show significant connectedness? 2) Given a weighted graph and two subsets of its nodes, are the subsets close neighbors or distant?</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0), igraph, stats, grDevices, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, huge, ggplot2, gplots, RColorBrewer,
testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-24 20:29:32 UTC; varduhipetrosyan</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-24 21:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cohorts_coded'>Disease cohorts with coded identifiers</h2><span id='topic+cohorts_coded'></span>

<h3>Description</h3>

<p>Patient sample identifiers mapped to known clinical
diagnoses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cohorts_coded)
</code></pre>


<h3>Format</h3>

<p>cohorts_coded - A list object where elements contain all patient 
IDs associated with a given diagnosis, as included in the dataset
Thistlethwaite2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cohorts_coded)
</code></pre>

<hr>
<h2 id='data.combineData'>Combine datasets</h2><span id='topic+data.combineData'></span>

<h3>Description</h3>

<p>Combine datasets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.combineData(curr_data, more_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.combineData_+3A_curr_data">curr_data</code></td>
<td>
<p>- Current data matrix</p>
</td></tr>
<tr><td><code id="data.combineData_+3A_more_data">more_data</code></td>
<td>
<p>- Data matrix you want to combine with curr_data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>combined.data - Combined data matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Row names and column names are required for both input matrices.
curr_data=matrix(rnorm(500), ncol=100)
rownames(curr_data)=sprintf("Feature%d",sample(seq_len(20), 
                                nrow(curr_data),replace = FALSE))
colnames(curr_data)=sprintf("Sample%d", seq_len(ncol(curr_data)))
more_data=matrix(rnorm(500), ncol=100)
rownames(more_data)=sprintf("Feature%d",sample(seq_len(20), 
                                nrow(curr_data),replace = FALSE))
colnames(more_data) = sprintf("Sample%d", seq_len(ncol(curr_data)))
combined.data = data.combineData(curr_data, more_data)
</code></pre>

<hr>
<h2 id='data.imputeData'>Impute missing values</h2><span id='topic+data.imputeData'></span>

<h3>Description</h3>

<p>Impute missing values as lowest observed value in a reference population
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.imputeData(data, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.imputeData_+3A_data">data</code></td>
<td>
<p>- Normalized data with some missingness. Data matrix with 
features as rows, samples as columns.</p>
</td></tr>
<tr><td><code id="data.imputeData_+3A_ref">ref</code></td>
<td>
<p>- Reference sample data with features as rows, samples as
columns. Can include some missingness.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>imputed.data - Imputed data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Thistlethwaite2020)
data_mx = Thistlethwaite2020
# Data with missing values
dt_w_missing_vals = data_mx[1:25,-seq_len(8)]
# Reference data can also have missing values
ref_data = data_mx[1:25,grep("EDTA-REF", colnames(data_mx))]
fil.rate = apply(ref_data, 1, function(i) sum(is.na(i))/length(i))
# Can only impute data that are found in reference samples
dt_w_missing_vals = dt_w_missing_vals[which(fil.rate&lt;1.0),]
ref_data = ref_data[which(fil.rate&lt;1.0),]
imputed.data = data.imputeData(dt_w_missing_vals, ref_data)
print(any(is.na(imputed.data)))
</code></pre>

<hr>
<h2 id='data.surrogateProfiles'>Generate surrogate profiles</h2><span id='topic+data.surrogateProfiles'></span>

<h3>Description</h3>

<p>Fill in a data matrix rank with surrogate profiles., when your data is
low n, high p.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.surrogateProfiles(data, std = 1, ref_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.surrogateProfiles_+3A_data">data</code></td>
<td>
<p>- Data matrix with observations (e.g., patient samples)
as columns, features (e.g., metabolites or genes) as rows</p>
</td></tr>
<tr><td><code id="data.surrogateProfiles_+3A_std">std</code></td>
<td>
<p>- The level of variability (standard deviation) around each
observed feature's z-score you want to add to generate the 
surrogate profiles</p>
</td></tr>
<tr><td><code id="data.surrogateProfiles_+3A_ref_data">ref_data</code></td>
<td>
<p>- Data matrix for healthy control &quot;reference&quot; samples,
observations (e.g., patient samples) as columns, 
features (e.g., metabolites or genes) as rows</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data_mx_surr - Data matrix with added surrogate profiles
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Miller2015")
data_mx=Miller2015[-1,grep("IEM_", colnames(Miller2015))]
data_mx=apply(data_mx, c(1,2), as.numeric)
diags=unlist(Miller2015["diagnosis",grep("IEM_", colnames(Miller2015))])
refs=data_mx[,which(diags=="No biochemical genetic diagnosis")]
ref_fill=as.numeric(Miller2015$`Times identifed in all 200 samples`[-1])/200
refs2=refs[which(ref_fill&gt;0.8),]
diag_pts=names(diags[which(diags==unique(diags)[1])])
diag_data=data_mx[which(rownames(data_mx) %in% rownames(refs2)), 
                    which(colnames(data_mx) %in% diag_pts)]
data_mx_surr=data.surrogateProfiles(data=diag_data, std=1, ref_data=refs2)
</code></pre>

<hr>
<h2 id='data.zscoreData'>Z-transform available data</h2><span id='topic+data.zscoreData'></span>

<h3>Description</h3>

<p>The z-transform is meant to work with normalized,
imputed metabolomics data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.zscoreData(data, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.zscoreData_+3A_data">data</code></td>
<td>
<p>- Normalized, imputed data. Data matrix includes 
features as rows, samples as columns.</p>
</td></tr>
<tr><td><code id="data.zscoreData_+3A_ref">ref</code></td>
<td>
<p>- Normalized, imputed reference sample data. Data
includes features as rows, samples as columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>zscored.data - Z-transformed data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dis_data = matrix(rexp(500), ncol=100)
rownames(dis_data)=sprintf("Feature%d",seq_len(nrow(dis_data)))
colnames(dis_data)=sprintf("Sample%d",seq_len(ncol(dis_data)))
ref_data = matrix(rexp(500), ncol=100)
rownames(ref_data)=sprintf("Feature%d",seq_len(nrow(ref_data)))
colnames(ref_data)=sprintf("Sample%d",seq_len(ncol(ref_data)))
zscored.data=data.zscoreData(dis_data,ref_data)
</code></pre>

<hr>
<h2 id='graph.connectToExt'>Connect a node to its unvisited &quot;extended&quot; neighbors</h2><span id='topic+graph.connectToExt'></span>

<h3>Description</h3>

<p>Connect a node to its unvisited &quot;extended&quot; neighbors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph.connectToExt(adj_mat, startNode, visitedNodes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph.connectToExt_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights 
for the network.</p>
</td></tr>
<tr><td><code id="graph.connectToExt_+3A_startnode">startNode</code></td>
<td>
<p>- The node most recently visited by the network walker,
from which p1 gets dispersed.</p>
</td></tr>
<tr><td><code id="graph.connectToExt_+3A_visitednodes">visitedNodes</code></td>
<td>
<p>- The history of previous draws in the node ranking
sequence.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>adj_matAfter - The adjacency matrix where the startNode is now
connected to its unvisited &quot;extended&quot; neighbors. An extended neighbor is
the neighbor of a neighbor.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adj_mat = rbind(c(0,2,1,0,0,0,0), # A
                c(2,0,1,0,0,0,0), # B
                c(1,0,0,1,0,0,0), # C
                c(0,0,1,0,2,0,0), # D
                c(0,0,0,2,0,2,1), # E
                c(0,0,0,1,2,0,1), # F
                c(0,0,0,0,1,1,0)  # G
                )
rownames(adj_mat) = c("A", "B", "C", "D", "E", "F", "G")
colnames(adj_mat) = c("A", "B", "C", "D", "E", "F", "G")
ig = graph.adjacency(as.matrix(adj_mat), mode="undirected",weighted=TRUE)
G=vector(mode="list", length=7)
G[seq_len(length(G))] = 0
names(G) = c("A", "B", "C", "D", "E", "F", "G")
startNode = "A"
visitedNodes = c("B", "C")
coords = layout.fruchterman.reingold(ig)
V(ig)$x = coords[,1]
V(ig)$y = coords[,2]
adj_matAfter = graph.connectToExt(adj_mat, startNode, visitedNodes)
</code></pre>

<hr>
<h2 id='graph.diffuseP1'>Diffuse Probability P1 from a starting node</h2><span id='topic+graph.diffuseP1'></span>

<h3>Description</h3>

<p>Recursively diffuse probability from a starting node based on the
connectivity of the network, representing the likelihood that a 
variable is most influenced by a perturbation in the starting node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph.diffuseP1(p1,sn,G,vNodes,thresholdDiff,adj_mat,verbose=FALSE,
                        out_dir="",r_level=1,coords=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph.diffuseP1_+3A_p1">p1</code></td>
<td>
<p>- The probability being dispersed from the starting node, 
sn, which is preferentially distributed between 
network nodes by the probability diffusion algorithm 
based solely on network connectivity.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_sn">sn</code></td>
<td>
<p>- &quot;Start node&quot;, or the node most recently visited by the
network walker, from which p1 gets dispersed.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_g">G</code></td>
<td>
<p>- A list of probabilities, with names of the list being the 
node names in the network.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_vnodes">vNodes</code></td>
<td>
<p>- &quot;Visited nodes&quot;, or the history of previous draws
in the node ranking sequence.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_thresholddiff">thresholdDiff</code></td>
<td>
<p>- When the probability diffusion algorithm exchanges
this amount (thresholdDiff) or less between nodes, 
the algorithm returns up the call stack.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights for
the network, G.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_verbose">verbose</code></td>
<td>
<p>- If debugging or tracking a diffusion event, verbose=TRUE
will activate print statements. Default is FALSE.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_out_dir">out_dir</code></td>
<td>
<p>- If specified, a image sequence will generate in the
output directory specified.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_r_level">r_level</code></td>
<td>
<p>- &quot;Recursion level&quot;, or the current depth in the call stack 
caused by a recursive algorithm. Only relevant if out_dir
is specified.</p>
</td></tr>
<tr><td><code id="graph.diffuseP1_+3A_coords">coords</code></td>
<td>
<p>- The x and y coordinates for each node in the network, to
remain static between images. Only relevant if out_dir
is specified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>G - A list of returned probabilities after the diffusion of
probability has truncated, with names of the list being the node names
in the network.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read in any network via its adjacency matrix
adj_mat=rbind(c(0,1,2,0,0,0,0,0,0), #A's neighbors
                c(1,0,3,0,0,0,0,0,0), #B's neighbors
                c(2,3,0,0,1,0,0,0,0), #C's neighbors
                c(0,0,0,0,0,0,1,1,0), #D's neighbors
                c(0,0,1,0,0,1,0,0,0), #E's neighbors
                c(0,0,0,0,1,0,0,0,0), #F's neighbors
                c(0,0,0,1,0,0,0,1,0), #G's neighbors
                c(0,0,0,1,0,0,1,0,0), #H's neighbors
                c(0,0,0,0,0,0,0,0,0) #I's neighbors
                )
rownames(adj_mat)=c("A","B","C","D","E","F","G","H","I")
colnames(adj_mat)=c("A","B","C","D","E","F","G","H","I")
G=vector(mode="list", length=ncol(adj_mat))
names(G)=colnames(adj_mat)
G=lapply(G, function(i) i[[1]]=0)
probs_afterCurrDraw=graph.diffuseP1(p1=1.0, sn=names(G)[1], G=G,
                                    vNodes=names(G)[1], 
                                    thresholdDiff=0.01, adj_mat, TRUE)
</code></pre>

<hr>
<h2 id='graph.diffusionSnapShot'>Capture the current state of probability diffusion</h2><span id='topic+graph.diffusionSnapShot'></span>

<h3>Description</h3>

<p>Recursively diffuse probability from a starting node based on the
connectivity in a network, G, where the probability represents the
likelihood that a variable will be influenced by a perturbation
in the starting node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph.diffusionSnapShot(adj_mat,G,output_dir,p1,startNode,
                                visitedNodes,recursion_level,coords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph.diffusionSnapShot_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights for
the network, G.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_g">G</code></td>
<td>
<p>- A list of probabilities, with names of the list being the node
names in the network.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_output_dir">output_dir</code></td>
<td>
<p>- The local directory at which you want still PNG images
to be saved.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_p1">p1</code></td>
<td>
<p>- The probability being dispersed from the starting node,
startNode, which is preferentially distributed between network
nodes by the probability diffusion algorithm based solely on
network connectivity.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_startnode">startNode</code></td>
<td>
<p>- The first variable drawn in the node ranking, from
which p1 gets dispersed.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_visitednodes">visitedNodes</code></td>
<td>
<p>- A character vector of node names, storing the
history of previous draws in the node ranking.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_recursion_level">recursion_level</code></td>
<td>
<p>- The current depth in the call stack caused by
a recursive algorithm.</p>
</td></tr>
<tr><td><code id="graph.diffusionSnapShot_+3A_coords">coords</code></td>
<td>
<p>- The x and y coordinates for each node in the network, to
remain static between images.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>0
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 7 node example graph illustrating diffusion of probability based on
# network connectivity.
adj_mat = rbind(c(0,2,1,0,0,0,0), # A
                c(2,0,1,0,0,0,0), # B
                c(1,0,0,1,0,0,0), # C
                c(0,0,1,0,2,0,0), # D
                c(0,0,0,2,0,2,1), # E
                c(0,0,0,1,2,0,1), # F
                c(0,0,0,0,1,1,0)  # G
                )
rownames(adj_mat) = c("A", "B", "C", "D", "E", "F", "G")
colnames(adj_mat) = c("A", "B", "C", "D", "E", "F", "G")
ig = graph.adjacency(as.matrix(adj_mat),mode="undirected",weighted=TRUE)
G=vector(mode="list", length=7)
G[seq_len(length(G))] = 0
names(G) = c("A", "B", "C", "D", "E", "F", "G")
coords = layout.fruchterman.reingold(ig)
V(ig)$x = coords[,1]
V(ig)$y = coords[,2]
# Uncomment to run
#graph.diffusionSnapShot(adj_mat,G,getwd(),1.0,"A","A",1,coords)
</code></pre>

<hr>
<h2 id='graph.naivePruning'>Network pruning for disease-specific network determination</h2><span id='topic+graph.naivePruning'></span>

<h3>Description</h3>

<p>Prune edges from a disease+control &quot;differential&quot; network that also 
occur in the control-only network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph.naivePruning(ig_dis, ig_ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph.naivePruning_+3A_ig_dis">ig_dis</code></td>
<td>
<p>- The igraph object associated with the
disease+reference trained differential network.</p>
</td></tr>
<tr><td><code id="graph.naivePruning_+3A_ig_ref">ig_ref</code></td>
<td>
<p>- The igraph object associated with the reference-only
trained interaction network.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ig_pruned - The pruned igraph object of the disease+reference
differential network, with reference edges subtracted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a 100 node "disease-control" network
adj_mat=matrix(0, nrow=100, ncol=100)
rows = sample(seq_len(100), 50, replace=TRUE)
cols = sample(seq_len(100), 50, replace=TRUE)
for (i in rows) {for (j in cols){adj_mat[i,j]=rnorm(1,0,1)}}
colnames(adj_mat)=sprintf("Metabolite%d", seq_len(100))
ig_dis = graph.adjacency(adj_mat, mode="undirected", weighted=TRUE)
# Generate a 100 node reference "control-only" network
adj_mat2=matrix(0, nrow=100, ncol=100)
rows2 = sample(seq_len(100), 50, replace=TRUE)
cols2 = sample(seq_len(100), 50, replace=TRUE)
for (i in rows2) {for (j in cols2){adj_mat2[i,j]=rnorm(1,0,1)}}
colnames(adj_mat2)=sprintf("Metabolite%d", seq_len(100))
ig_ref = graph.adjacency(adj_mat2, mode="undirected", weighted=TRUE)
ig_pruned=graph.naivePruning(ig_dis, ig_ref)
</code></pre>

<hr>
<h2 id='graph.netWalkSnapShot'>Capture the current location of a network walker</h2><span id='topic+graph.netWalkSnapShot'></span>

<h3>Description</h3>

<p>A network walker steps towards the node that inherited the highest
probability from the last node that it stepped into.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph.netWalkSnapShot(adj_mat,G,output_dir,p1,visitedNodes,S,
                                coords,imgNum=1,useLabels=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph.netWalkSnapShot_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights for
the network, G.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_g">G</code></td>
<td>
<p>- A list of probabilities, with names of the list being the node
names in the network.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_output_dir">output_dir</code></td>
<td>
<p>- The local directory at which you want still PNG images
to be saved.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_p1">p1</code></td>
<td>
<p>- The probability being dispersed from the starting node, 
startNode, which is preferentially distributed between network 
nodes by the probability diffusion algorithm based solely on 
network connectivity.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_visitednodes">visitedNodes</code></td>
<td>
<p>- A character vector of node names, storing the history
of previous draws in the node ranking.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_s">S</code></td>
<td>
<p>- A character vector of node names in the subset you want the
network walker to find.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_coords">coords</code></td>
<td>
<p>- The x and y coordinates for each node in the network, to 
remain static between images.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_imgnum">imgNum</code></td>
<td>
<p>- The image number for this snapshot. If images are being 
generated in a sequence, this serves as an iterator for file
naming.</p>
</td></tr>
<tr><td><code id="graph.netWalkSnapShot_+3A_uselabels">useLabels</code></td>
<td>
<p>- If TRUE, node names will display next to their respective 
nodes in the network. If FALSE, node names will not
display.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>0
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 7 node example graph illustrating diffusion of probability based on network
# connectivity
adj_mat = rbind(c(0,2,1,0,0,0,0), # A
                c(2,0,1,0,0,0,0), # B
                c(1,0,0,1,0,0,0), # C
                c(0,0,1,0,2,0,0), # D
                c(0,0,0,2,0,2,1), # E
                c(0,0,0,1,2,0,1), # F
                c(0,0,0,0,1,1,0)  # G
                )
rownames(adj_mat) = c("A", "B", "C", "D", "E", "F", "G")
colnames(adj_mat) = c("A", "B", "C", "D", "E", "F", "G")
ig = graph.adjacency(as.matrix(adj_mat), mode="undirected", weighted=TRUE)
G=vector(mode="list", length=7)
G[seq_len(length(G))] = 0
names(G) = c("A", "B", "C", "D", "E", "F", "G")
S = c("A", "C")
coords = layout.fruchterman.reingold(ig)
# Uncomment to run
#graph.netWalkSnapShot(adj_mat,G,output_dir=getwd(),p1=1.0,
#                        "A",S,coords,1,TRUE)
</code></pre>

<hr>
<h2 id='Miller2015'>Miller et al. (2015)</h2><span id='topic+Miller2015'></span>

<h3>Description</h3>

<p>Untargeted metabolomic analysis for the clinical screening of 
inborn errors of metabolism. Global metabolic profiling obtained by 
untargeted mass spectrometry-based metabolomic platform for the detection
of novel and known inborn errors of metabolism.  This untargeted approach 
collected z-score values for ~1200 unique compounds (including 
~500 named human analytes) from human plasma.  Data set contains 
186 individual plasma samples (118 confirmed inborn errors of
metabolism).  The outcome describes excellent sensitivity and 
specificity for the detection of a wide rage of metabolic disorders 
and identified novel biomarkers for some diseases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Miller2015)
</code></pre>


<h3>Format</h3>

<p>Miller2015 - The data frame with 1203 metabolite features as rows,
and 186 untargeted metabolomics patient samples as columns, alongside 16
metabolite annotations. The first row also provides the biochemical
diagnosis confirmed for each patient sample.
</p>


<h3>Source</h3>

<p>Supporting Information: jimd1029-sup-0001.xls
</p>


<h3>References</h3>

<p>Miller et al. (2015). Untargeted metabolomic analysis for the
clinical screening of inborn errors of metabolism. J Inherit Metab Dis,
38: 1029–1039. &lt;doi:10.1007/s10545-015-9843-7&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Miller2015)
</code></pre>

<hr>
<h2 id='mle.getEncodingLength'>Minimum encoding length</h2><span id='topic+mle.getEncodingLength'></span>

<h3>Description</h3>

<p>This function calculates the mininmum encoding length associated with a
subset of variables given a background knowledge graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle.getEncodingLength(bs, pvals, ptID, G)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mle.getEncodingLength_+3A_bs">bs</code></td>
<td>
<p>- A list of bitstrings associated with a given patient's
perturbed variables.</p>
</td></tr>
<tr><td><code id="mle.getEncodingLength_+3A_pvals">pvals</code></td>
<td>
<p>- The matrix that gives the perturbation strength significance
for all variables (columns) for each patient (rows)</p>
</td></tr>
<tr><td><code id="mle.getEncodingLength_+3A_ptid">ptID</code></td>
<td>
<p>- The row name in data.pvals corresponding to the patient you
specifically want encoding information for.</p>
</td></tr>
<tr><td><code id="mle.getEncodingLength_+3A_g">G</code></td>
<td>
<p>- A list of probabilities with list names being the node names of
the background graph.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>df - a data.frame object, for every bitstring provided in bs input
parameter, a row is returned with the following data: the patientID; the 
bitstring evaluated where T denotes a hit and 0 denotes a miss; the
subsetSize, or the number of hits in the bitstring; the individual p-values
associated with the variable's perturbations, delimited by '/'; the combined
p-value of all variables in the set using Fisher's method; Shannon's
entropy, IS.null; the minimum encoding length IS.alt; and IS.null-IS.alt,
the d.score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Identify the most significantly connected subset for a given patients'
# perturbations, given the network G
data("Miller2015")
data_mx = Miller2015[-c(1,grep("x - ",rownames(Miller2015))),
                        grep("IEM", colnames(Miller2015))]
data_mx = apply(data_mx, c(1,2), as.numeric)
data_pval=t(apply(data_mx,c(1,2),
                    function(i)2*pnorm(abs(i),lower.tail=FALSE)))
# Choose patient #1's (i.e., IEM_1000's) top 5 perturbed metabolites
ptID = colnames(data_mx)[1]
S=rownames(data_mx)[order(abs(data_mx[,which(colnames(data_mx)==ptID)]),
                            decreasing=TRUE)[seq_len(5)]]
# Build a dummy metabolite network for all metabolites in data_mx
adj_mat=matrix(0, nrow=nrow(data_mx), ncol=nrow(data_mx))
rows=sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
cols=sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
for (i in rows){for (j in cols){adj_mat[i,j]=rnorm(1,mean=0,sd=1)}}
colnames(adj_mat) = rownames(data_mx)
rownames(adj_mat) = rownames(data_mx)
G = vector("numeric", length=ncol(adj_mat))
names(G)=colnames(adj_mat)
ranks = list()
for (n in seq_len(length(S))) { 
    print(sprintf("%d / %d", n, length(S)))
    ind = which(names(G)==S[n])
    ranks[[n]]=singleNode.getNodeRanksN(ind,G,p1=0.9,thresholdDiff=0.01,
                                        adj_mat,S,log2(length(G)),FALSE) 
}
names(ranks) = S
ptBSbyK = mle.getPtBSbyK(S, ranks)
res = mle.getEncodingLength(ptBSbyK, data_pval, ptID, G)
# Rows with d.scores &gt; 4.32 are of interest. Anything less indicates
# no to weak signal.
res = res[order(res[,"d.score"], decreasing=TRUE),]
print(res)
</code></pre>

<hr>
<h2 id='mle.getMinPtDistance'>Get minimum patient distances</h2><span id='topic+mle.getMinPtDistance'></span>

<h3>Description</h3>

<p>Given a series of patient distance matrices, return the minimum
distance between all pairwise patient comparisons made.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle.getMinPtDistance(allSimMatrices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mle.getMinPtDistance_+3A_allsimmatrices">allSimMatrices</code></td>
<td>
<p>- A list of all similarity matrices, across all 
k for a given graph, or across many graphs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>minPtSim - Pairwise patient distances representing the minimum
patient distance observed across several distance matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get patient distances for the first 2 patients in the Miller 2015 dataset.
data("Miller2015")
data_mx = Miller2015[-c(1,grep("x - ",rownames(Miller2015))),
                        grep("IEM", colnames(Miller2015))]
data_mx = apply(data_mx[,c(1,2)], c(1,2), as.numeric)
# Build a network, G
adj_mat = matrix(0, nrow=nrow(data_mx), ncol=nrow(data_mx))
rows = sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
cols = sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
for(i in rows){for(j in cols){adj_mat[i,j]=rnorm(1,0,1)}}
colnames(adj_mat) = rownames(data_mx)
rownames(adj_mat) = rownames(data_mx)
G = vector("numeric", length=ncol(adj_mat))
names(G)=colnames(adj_mat) 
# Look at the top 5 metabolites for each patient. 
kmx=5
topMets_allpts = c()
for(pt in seq_len(ncol(data_mx))){
    topMets_allpts=c(topMets_allpts, 
                    rownames(data_mx)[order(abs(data_mx[,pt]),
                                            decreasing=TRUE)[seq_len(kmx)]])
}
topMets_allpts = unique(topMets_allpts)
# Pre-compute node ranks for all metabolites in topMets_allpts for
# faster distance calculations.
ranks = list()
for(n in seq_len(length(topMets_allpts))){ 
    ind=which(names(G)==topMets_allpts[n])
    ranks[[n]]=singleNode.getNodeRanksN(ind,G,0.9,0.01,adj_mat,
                                        topMets_allpts,log2(length(G))) 
}
names(ranks) = topMets_allpts
# Also pre-compute patient bitstrings for faster distance calculations.
ptBSbyK = list()
for (pt in seq_len(ncol(data_mx))) {
    S=rownames(data_mx)[order(abs(data_mx[,pt]),
                                decreasing=TRUE)[seq_len(kmx)]]
    ptBSbyK[[pt]]=mle.getPtBSbyK(S, ranks)
}
# Build your results ("res") list object to store patient distances at
# different size k's.
res = list()
t = list(ncd=matrix(NA, nrow=ncol(data_mx), ncol=ncol(data_mx)))
rownames(t$ncd) = colnames(data_mx)
colnames(t$ncd) = colnames(data_mx)
for (i in seq_len(kmx)) { res[[i]] = t }
for (pt in seq_len(ncol(data_mx))) {
    print(pt)
    ptID = colnames(data_mx)[pt]
    for (pt2 in pt:ncol(data_mx)) {
        ptID2 = colnames(data_mx)[pt2]
        tmp = mle.getPtDist(ptBSbyK[[pt]],ptID,ptBSbyK[[pt2]],ptID2,data_mx,
                            ranks,p1=0.9,thresholdDiff=0.01,adj_mat)
        for (k in seq_len(kmx)) {
            res[[k]]$ncd[ptID, ptID2] = tmp$NCD[k]
            res[[k]]$ncd[ptID2, ptID] = tmp$NCD[k]
        }
    }
}
res_ncd = lapply(res, function(i) i$ncd)
minPtDist = mle.getMinPtDistance(res_ncd)
</code></pre>

<hr>
<h2 id='mle.getPtBSbyK'>Generate patient-specific bitstrings</h2><span id='topic+mle.getPtBSbyK'></span>

<h3>Description</h3>

<p>This function calculates the bitstrings (1 is a hit; 0 is a miss)
associated with a network walker which tries to find all nodes in
a given subset, S, in a given network, G.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle.getPtBSbyK(S, ranks, num.misses = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mle.getPtBSbyK_+3A_s">S</code></td>
<td>
<p>- A character vector of node names describing the node subset
to be encoded.</p>
</td></tr>
<tr><td><code id="mle.getPtBSbyK_+3A_ranks">ranks</code></td>
<td>
<p>- The list of node ranks calculated over all possible nodes,
starting with each node in subset of interest.</p>
</td></tr>
<tr><td><code id="mle.getPtBSbyK_+3A_num.misses">num.misses</code></td>
<td>
<p>- The number of misses tolerated by the network walker
before path truncation occurs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>pt.byK - a list of bitstrings, with the names of the list elements
the node names of the encoded nodes
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get patient bitstrings for the first 2 patients in the Miller 2015 dataset.
data("Miller2015")
data_mx=Miller2015[-c(1,grep("x - ", rownames(Miller2015))),
                    grep("IEM", colnames(Miller2015))]
data_mx=apply(data_mx[,c(1,2)], c(1,2), as.numeric)
# Build an adjacency matrix for network G
adj_mat=matrix(0, nrow=nrow(data_mx), ncol=nrow(data_mx))
rows=sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
cols=sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
for(i in rows){for (j in cols){adj_mat[i, j]=rnorm(1,0,1)}}
colnames(adj_mat)=rownames(data_mx)
rownames(adj_mat)=rownames(data_mx)
G=vector("numeric", length=ncol(adj_mat))
names(G)=colnames(adj_mat)
# Look at the top 5 metabolites for each patient. 
kmx=5
topMets_allpts=c()
for (pt in seq_len(ncol(data_mx))) { 
    topMets_allpts=c(topMets_allpts,
                    rownames(data_mx)[order(abs(data_mx[,pt]),
                                            decreasing=TRUE)[seq_len(kmx)]])}
topMets_allpts=unique(topMets_allpts)
# Use a single-node or multi-node network walker.
# Here we use a single-node network walker.
ranks=list()
for (n in seq_len(length(topMets_allpts))) { 
    ind=which(names(G)==topMets_allpts[n])
    ranks[[n]]=singleNode.getNodeRanksN(ind,G,0.9,0.01,adj_mat,
                                        topMets_allpts,log2(length(G))) 
}
names(ranks)=topMets_allpts
ptBSbyK=list()
for (pt in seq_len(ncol(data_mx))) {
    S=rownames(data_mx)[order(abs(data_mx[,pt]),
                                decreasing=TRUE)[seq_len(kmx)]]
    ptBSbyK[[pt]]=mle.getPtBSbyK(S, ranks)
}
</code></pre>

<hr>
<h2 id='mle.getPtDist'>CTDncd: A network-based distance metric.</h2><span id='topic+mle.getPtDist'></span>

<h3>Description</h3>

<p>This function calculates the universal distance between patients, using a
mutual information metric, where self-information comes from the minimum
encoding length of each patient's encoded modular perturbations in the
network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle.getPtDist(p1.optBS,ptID,p2.optBS,ptID2,data_mx,ranks,p1,
                        thresholdDiff,adj_mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mle.getPtDist_+3A_p1.optbs">p1.optBS</code></td>
<td>
<p>- The optimal bitstring associated with patient 1.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_ptid">ptID</code></td>
<td>
<p>- The identifier associated with patient 1's sample.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_p2.optbs">p2.optBS</code></td>
<td>
<p>- The optimal bitstring associated with patient 2.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_ptid2">ptID2</code></td>
<td>
<p>- The identifier associated with patient 2's sample.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_data_mx">data_mx</code></td>
<td>
<p>- The matrix that gives the perturbation strength
(z-scores) for all variables (columns) for each
patient (rows).</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_ranks">ranks</code></td>
<td>
<p>- The list of node ranks, starting with each node in patient
1&amp;2's subsets of interest.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_p1">p1</code></td>
<td>
<p>- The probability that is preferentially distributed between
network nodes by the probability diffusion algorithm based
solely on network connectivity. The remaining probability
(i.e., &quot;p0&quot;) is uniformally distributed between network nodes,
regardless of connectivity.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_thresholddiff">thresholdDiff</code></td>
<td>
<p>- When the probability diffusion algorithm exchanges
this amount (thresholdDiff) or less between nodes,
the algorithm returns up the call stack.</p>
</td></tr>
<tr><td><code id="mle.getPtDist_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights for the
network, G.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>patientDistances - a distance matrix, where row and columns are
patient identifiers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get patient distances for the first 2 patients in the Miller 2015 dataset.
data("Miller2015")
data_mx = Miller2015[-c(1,grep("x - ", rownames(Miller2015))),
                        grep("IEM",colnames(Miller2015))]
data_mx = apply(data_mx[,c(1,2)], c(1,2), as.numeric)
# Build a network, G
adj_mat = matrix(0, nrow=nrow(data_mx), ncol=nrow(data_mx))
rows = sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
cols = sample(seq_len(ncol(adj_mat)), 0.1*ncol(adj_mat))
for (i in rows) {for (j in cols) {adj_mat[i,j]=rnorm(1,mean=0,sd=1)}}
colnames(adj_mat) = rownames(data_mx)
rownames(adj_mat) = rownames(data_mx)
G = vector("numeric", length=ncol(adj_mat))
names(G)=colnames(adj_mat) 
# Look at the top 5 metabolites for each patient. 
kmx=5
topMets_allpts = c()
for (pt in seq_len(ncol(data_mx))) {
    topMets_allpts=c(topMets_allpts, 
                    rownames(data_mx)[order(abs(data_mx[,pt]),
                                            decreasing=TRUE)[seq_len(kmx)]])}
topMets_allpts = unique(topMets_allpts)
# Pre-compute node ranks for all metabolites in topMets_allpts
# for faster distance calculations.
ranks = list()
for (n in seq_len(length(topMets_allpts))) { 
    ind = which(names(G)==topMets_allpts[n])
    ranks[[n]]=singleNode.getNodeRanksN(ind,G,0.9,0.01,adj_mat,
                                        topMets_allpts,log2(length(G))) 
}
names(ranks) = topMets_allpts
# Also pre-compute patient bitstrings for faster distance calculations.
ptBSbyK = list()
for (pt in seq_len(ncol(data_mx))) {
    S=rownames(data_mx)[order(abs(data_mx[,pt]),
                                decreasing=TRUE)[seq_len(kmx)]]
    ptBSbyK[[pt]] = mle.getPtBSbyK(S, ranks)
}
# Build your results ("res") list object to store patient distances at
# different size k's.
res = list()
t = list(ncd=matrix(NA, nrow=ncol(data_mx), ncol=ncol(data_mx)))
rownames(t$ncd) = colnames(data_mx)
colnames(t$ncd) = colnames(data_mx)
for (i in seq_len(kmx)) { res[[i]] = t }
for (pt in seq_len(ncol(data_mx))) {
    print(pt)
    ptID = colnames(data_mx)[pt]
    for (pt2 in pt:ncol(data_mx)) {
        ptID2 = colnames(data_mx)[pt2]
        tmp=mle.getPtDist(ptBSbyK[[pt]],ptID,ptBSbyK[[pt2]],ptID2,
                            data_mx,ranks,p1=0.9,thresholdDiff=0.01,adj_mat)
        for (k in seq_len(kmx)) {
            res[[k]]$ncd[ptID, ptID2] = tmp$NCD[k]
            res[[k]]$ncd[ptID2, ptID] = tmp$NCD[k]
        }
    }
}
</code></pre>

<hr>
<h2 id='multiNode.getNodeRanks'>Generate multi-node node rankings (&quot;adaptive&quot; walk)</h2><span id='topic+multiNode.getNodeRanks'></span>

<h3>Description</h3>

<p>This function calculates the node rankings starting from a given node in a
subset of nodes in a given network, G.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiNode.getNodeRanks(S,G,p1,thresholdDiff,adj_mat,num.misses=NULL,
                                verbose=FALSE,out_dir="",useLabels=FALSE,
                                coords=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiNode.getNodeRanks_+3A_s">S</code></td>
<td>
<p>- A character vector of the node names for the subset of nodes you
want to encode.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_g">G</code></td>
<td>
<p>- A list of probabilities with list names being the node names of
the network.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_p1">p1</code></td>
<td>
<p>- The probability that is preferentially distributed between
network nodes by the probability diffusion algorithm based
solely on network connectivity. The remaining probability, 1-p1,
is uniformally distributed between network nodes, regardless of
connectivity.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_thresholddiff">thresholdDiff</code></td>
<td>
<p>- When the probability diffusion algorithm exchanges
this amount or less between nodes, the algorithm 
returns up the call stack.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights for the
network, G.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_num.misses">num.misses</code></td>
<td>
<p>- The number of &quot;misses&quot; the network walker will tolerate
before switching to fixed length codes for remaining
nodes to be found.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_verbose">verbose</code></td>
<td>
<p>- If TRUE, print statements will execute as progress is made.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_out_dir">out_dir</code></td>
<td>
<p>- If specified, a image sequence will generate in the
output directory specified.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_uselabels">useLabels</code></td>
<td>
<p>- If TRUE, node names will display next to their respective
nodes in the network. If FALSE, node names will not
display. Only relevant if out_dir is specified.</p>
</td></tr>
<tr><td><code id="multiNode.getNodeRanks_+3A_coords">coords</code></td>
<td>
<p>- The x and y coordinates for each node in the network, to
remain static between images.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ranks - A list of character vectors of node names in the order they
were drawn by the probability diffusion algorithm, from each starting node
in S.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read in any network via its adjacency matrix
adj_mat=rbind(c(0,1,2,0,0,0,0,0,0), #A's neighbors
                c(1,0,3,0,0,0,0,0,0), #B's neighbors
                c(2,3,0,0,1,0,0,0,0), #C's neighbors
                c(0,0,0,0,0,0,1,1,0), #D's neighbors
                c(0,0,1,0,0,1,0,0,0), #E's neighbors
                c(0,0,0,0,1,0,0,0,0), #F's neighbors
                c(0,0,0,1,0,0,0,1,0), #G's neighbors
                c(0,0,0,1,0,0,1,0,0), #H's neighbors
                c(0,0,0,0,0,0,0,0,0) #I's neighbors
                )
rownames(adj_mat)=c("A","B","C","D","E","F","G","H","I")
colnames(adj_mat)=c("A","B","C","D","E","F","G","H","I")
G=vector(mode="list", length=ncol(adj_mat))
names(G)=colnames(adj_mat)
S=names(G)[seq_len(3)]
ranks=multiNode.getNodeRanks(S, G, p1=0.9, thresholdDiff=0.01, adj_mat)
</code></pre>

<hr>
<h2 id='singleNode.getNodeRanksN'>Generate single-node node rankings (&quot;fixed&quot; walk)</h2><span id='topic+singleNode.getNodeRanksN'></span>

<h3>Description</h3>

<p>This function calculates the node rankings starting from a given perturbed 
variable in a subset of variables in the network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singleNode.getNodeRanksN(n,G,p1,thresholdDiff,adj_mat,
                                    S=NULL,num.misses=NULL,verbose=FALSE,
                                    out_dir="",useLabels=FALSE,coords=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="singleNode.getNodeRanksN_+3A_n">n</code></td>
<td>
<p>- The index (out of a vector of node names) of the node ranking
you want to calculate.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_g">G</code></td>
<td>
<p>- A list of probabilities with list names being the node names
of the network.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_p1">p1</code></td>
<td>
<p>- The probability that is preferentially distributed between
network nodes by the probability diffusion algorithm based
solely on network connectivity. The remaining probability
(i.e., &quot;p0&quot;) is uniformally distributed between network nodes,
regardless of connectivity.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_thresholddiff">thresholdDiff</code></td>
<td>
<p>- When the probability diffusion algorithm exchanges 
this amount or less between nodes, the algorithm 
returns up the call stack.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_adj_mat">adj_mat</code></td>
<td>
<p>- The adjacency matrix that encodes the edge weights for the 
network, G.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_s">S</code></td>
<td>
<p>- A character vector of node names in the subset you want the 
network walker to find.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_num.misses">num.misses</code></td>
<td>
<p>- The number of &quot;misses&quot; the network walker will tolerate
before switching to fixed length codes for remaining
nodes to be found.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_verbose">verbose</code></td>
<td>
<p>- If TRUE, print statements will execute as progress is made.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_out_dir">out_dir</code></td>
<td>
<p>- If specified, a image sequence will generate in the 
output directory specified.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_uselabels">useLabels</code></td>
<td>
<p>- If TRUE, node names will display next to their respective
nodes in the network. If FALSE, node names will not
display. Only relevant if out_dir is specified.</p>
</td></tr>
<tr><td><code id="singleNode.getNodeRanksN_+3A_coords">coords</code></td>
<td>
<p>- The x and y coordinates for each node in the network, to 
remain static between images.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>curr_ns - A character vector of node names in the order they
were drawn by the probability diffusion algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build an adjacency matrix for network G
adj_mat=rbind(c(0,1,2,0,0,0,0,0,0), #A's neighbors
                c(1,0,3,0,0,0,0,0,0), #B's neighbors
                c(2,3,0,0,1,0,0,0,0), #C's neighbors
                c(0,0,0,0,0,0,1,1,0), #D's neighbors
                c(0,0,1,0,0,1,0,0,0), #E's neighbors
                c(0,0,0,0,1,0,0,0,0), #F's neighbors
                c(0,0,0,1,0,0,0,1,0), #G's neighbors
                c(0,0,0,1,0,0,1,0,0), #H's neighbors
                c(0,0,0,0,0,0,0,0,0) #I's neighbors
                )
rownames(adj_mat)=c("A","B","C","D","E","F","G","H","I")
colnames(adj_mat)=c("A","B","C","D","E","F","G","H","I")
G=vector("numeric", length=ncol(adj_mat))
names(G)=colnames(adj_mat)
# Get node rankings for the first metabolite in network G. 
ranks=singleNode.getNodeRanksN(1,G,p1=0.9,thresholdDiff=0.01,adj_mat)
</code></pre>

<hr>
<h2 id='stat.entropyFunction'>Entropy of a bit-string</h2><span id='topic+stat.entropyFunction'></span>

<h3>Description</h3>

<p>The entropy of a bitstring (ex: 1010111000) is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.entropyFunction(bitString)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.entropyFunction_+3A_bitstring">bitString</code></td>
<td>
<p>- A vector of 0's and 1's.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>e - a floating point percentage, between 0 and 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stat.entropyFunction(c(1,0,0,0,1,0,0,0,0,0,0,0,0))       # Output: 0.6193822
stat.entropyFunction(c(1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0)) # Output: 1
stat.entropyFunction(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)) # Output: 0
</code></pre>

<hr>
<h2 id='stat.fishersMethod'>Fisher's Combined P-value</h2><span id='topic+stat.fishersMethod'></span>

<h3>Description</h3>

<p>Fisher's combined p-value, used to combine the results of individual 
statistical tests into an overall hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.fishersMethod(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.fishersMethod_+3A_x">x</code></td>
<td>
<p>- A vector of p-values (floating point numbers).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a floating point number, a combined p-value using Fisher's 
method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stat.fishersMethod(c(0.2,0.1,0.3))   # Output: 0.1152162
</code></pre>

<hr>
<h2 id='stat.getDirSim'>DirSim: The Jaccard distance with directionality incorporated.</h2><span id='topic+stat.getDirSim'></span>

<h3>Description</h3>

<p>DirSim: The Jaccard distance with directionality incorporated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.getDirSim(ptID, ptID2, kmx, data_mx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.getDirSim_+3A_ptid">ptID</code></td>
<td>
<p>- The identifier associated with patient 1's sample.</p>
</td></tr>
<tr><td><code id="stat.getDirSim_+3A_ptid2">ptID2</code></td>
<td>
<p>- The identifier associated with patient 2's sample.</p>
</td></tr>
<tr><td><code id="stat.getDirSim_+3A_kmx">kmx</code></td>
<td>
<p>- The number of top perturbations to consider in distance
calculation.</p>
</td></tr>
<tr><td><code id="stat.getDirSim_+3A_data_mx">data_mx</code></td>
<td>
<p>- The matrix that gives the perturbation strength
(z-scores) for all variables (columns) for each
patient (rows).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dirSim - a distance matrix, where row and columns are
patient identifiers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get patient distances for the first 2 patients in the Miller 2015 dataset.
data("Miller2015")
data_mx = Miller2015[-c(1,grep("x - ", rownames(Miller2015))),
                        grep("IEM",colnames(Miller2015))]
data_mx = apply(data_mx[,c(1,2)], c(1,2), as.numeric)
# Look at the top 5 metabolites for each patient. 
kmx=5
# Build your results ("res") list object to store patient distances at
# different size k's.
res = list()
t = list(dir=matrix(NA, nrow=ncol(data_mx), ncol=ncol(data_mx)))
rownames(t$dir) = colnames(data_mx)
colnames(t$dir) = colnames(data_mx)
for (i in seq_len(kmx)) { res[[i]] = t }
for (pt in seq_len(ncol(data_mx))) {
    print(pt)
    ptID=colnames(data_mx)[pt]
    for (pt2 in pt:ncol(data_mx)) {
        ptID2=colnames(data_mx)[pt2]
        tmp=stat.getDirSim(ptID,ptID2,kmx,data_mx)
        for (k in seq_len(kmx)) {
            res[[k]]$dir[ptID, ptID2]=tmp[k]
            res[[k]]$dir[ptID2, ptID]=tmp[k]
        }
    }
}
</code></pre>

<hr>
<h2 id='Thistlethwaite2020'>Thistlethwaite et al. (2020)</h2><span id='topic+Thistlethwaite2020'></span>

<h3>Description</h3>

<p>Clinical Diagnosis of Metabolic Disorders using Untargeted 
Metabolomic Profiling and Disease-specific Networks Learned from 
Patient Data. A meta-analysis of previous untargeted metabolomics
studies describing 16 unique inborn errors of metabolism.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Thistlethwaite2020)
</code></pre>


<h3>Format</h3>

<p>Thistlethwaite2020 - A data frame with 1364 metabolite 
features as rows and 545 untargeted metabolomics patient samples
as columns, alongside 8 metabolite annotations.
</p>


<h3>Source</h3>

<p><a href="https://genboree.org/Metabolomics-Data-Portal/">Dataset</a>
</p>


<h3>References</h3>

<p>L.R. Thistlethwaite, et al. 2020. In review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Thistlethwaite2020)
</code></pre>

<hr>
<h2 id='Wangler2017'>Wangler et al. (2017)</h2><span id='topic+Wangler2017'></span>

<h3>Description</h3>

<p>A metabolomic map of Zellweger spectrum disorders reveals 
novel disease biomarkers. Global metabolic profiling obtained by 
untargetedmass spectrometry-based metabolomic platform for the 
detectionof novel and known inborn errors of metabolism.  This 
untargeted approach collected z-score values for &gt;650 unique compounds 
fromhuman plasma.  Data set contains 19 individual plasma samples with
confirmed biallelic pathogenic variants in the PEX1 gene. These 
samples revealed elevations in pipecolic acid and long-chain
lysophosphatidylcholines, as well as an unanticipated reduction
in multiple sphingomyelin species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Wangler2017)
</code></pre>


<h3>Format</h3>

<p>Wangler2017 - The data matrix (metabolite features are
rows, patient observations are columns) for 19 untargeted metabolomics 
patient samples, alongside metabolite annotations.
</p>


<h3>Source</h3>

<p>Electronic supplementary material, Supplementary Tables
(<a href="https://tinyurl.com/y4zus9l2">Dataset</a>)
</p>


<h3>References</h3>

<p>M.F. Wangler, et al. (2018). A metabolomic map of Zellweger 
spectrum disorders reveals novel disease biomarkers. Genetics in 
Medicine, 20: 1274-1283. &lt;doi:10.1038/gim.2017.262&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Wangler2017)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
