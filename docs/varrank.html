<!DOCTYPE html><html><head><title>Help for package varrank</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {varrank}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#discretization'><p>Discretization of a Possibly Continuous Data Frame of Random Variables</p></a></li>
<li><a href='#entropy.data'><p>Computes an Empirical Estimation of the Entropy from a Table of Counts</p></a></li>
<li><a href='#mi.data'><p>Empirical Estimate of the Mutual Information from a Table of Counts</p></a></li>
<li><a href='#nassCDS'><p>Airbag and other influences on accident fatalities</p></a></li>
<li><a href='#plot.varrank'><p>Visualization of varrank output</p></a></li>
<li><a href='#print.varrank'><p>Methods for Varrank Objects</p></a></li>
<li><a href='#summary.varrank'><p>Summary Methods for Varrank Objects</p></a></li>
<li><a href='#varrank'><p>Heuristics Tools Based on Mutual Information for Variable Ranking and Feature Selection</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Heuristics Tools Based on Mutual Information for Variable
Ranking</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5</td>
</tr>
<tr>
<td>Author:</td>
<td>Gilles Kratzer <a href="https://orcid.org/0000-0002-5929-8935"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Reinhard Furrer <a href="https://orcid.org/0000-0002-6319-2332"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Annina Cincera [cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Annina Cincera &lt;annina.cincera@math.uzh.ch&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A computational toolbox of heuristics approaches for performing variable ranking and feature selection based on mutual information well adapted for multivariate system epidemiology datasets. The core function is a general implementation of the minimum redundancy maximum relevance model. R. Battiti (1994) &lt;<a href="https://doi.org/10.1109%2F72.298224">doi:10.1109/72.298224</a>&gt;. Continuous variables are discretized using a large choice of rule. Variables ranking can be learned with a sequential forward/backward search algorithm. The two main problems that can be addressed by this package is the selection of the most representative variable within a group of variables of interest (i.e. dimension reduction) and variable ranking with respect to a set of features of interest. </td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Boruta, FSelector, caret, e1071, mlbench, psych, varSelRF,
gplots, entropy, testthat, knitr, markdown</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.math.uzh.ch/pages/varrank/">https://www.math.uzh.ch/pages/varrank/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, FNN, grDevices</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-12 14:17:09 UTC; acince</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-12 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='discretization'>Discretization of a Possibly Continuous Data Frame of Random Variables</h2><span id='topic+discretization'></span>

<h3>Description</h3>

<p>This function discretizes data frame of possibly continuous random variables through rules for discretization. The discretization algorithms are unsupervised and univariate. See details for the complete list (the desired number of bins could also be provided).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretization(data.df = NULL, discretization.method = "cencov", frequency = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discretization_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data to discretize, binary variables must be declared as factors, other as numeric vector. The data frame must be named.</p>
</td></tr>
<tr><td><code id="discretization_+3A_discretization.method">discretization.method</code></td>
<td>
<p>a character vector giving the discretization method to use; see details. If a number is provided, the variable will be discretized by equal binning.</p>
</td></tr>
<tr><td><code id="discretization_+3A_frequency">frequency</code></td>
<td>
<p>logical variable to select the output. If set to TRUE a list with the table of count for each bin and the discretized data frame is returned. If set to FALSE only the discretized data frame is returned.</p>
</td></tr></table>


<h3>Details</h3>

<p><code>discretization()</code> supports multiple rules for discretization. Below is the list of supported rules. IQR() stands for interquartile range.
</p>
<p><code>fd</code> stands for the Freedman–Diaconis rule. The number of bins is given by </p>
<p style="text-align: center;"><code class="reqn">\frac{range(x) * n^{1/3}}{2 * IQR(x)}</code>
</p>
<p> The Freedman–Diaconis rule is known to be less sensitive than the Scott's rule to outlier.
</p>
<p><code>doane</code> stands for doane's rule. The number of bins is given by
</p>
<p style="text-align: center;"><code class="reqn">1 + \log_{2}{n} + \log_{2}{1+\frac{|g|}{\sigma_{g}}}</code>
</p>

<p>is a modification of Sturges' formula which attempts to improve its performance with non-normal data.
</p>
<p><code>cencov</code> stands for Cencov's rule. The number of bins is given by:
</p>
<p style="text-align: center;"><code class="reqn">n^{1/3}</code>
</p>

<p><code>rice</code> stands for Rice' rule. The number of bins is given by:
</p>
<p style="text-align: center;"><code class="reqn">2 n^{1/3}</code>
</p>

<p><code>terrell-scott</code> stands for Terrell-Scott's rule. The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">(2 n)^{1/3}</code>
</p>

<p>This is known that Cencov, Rice and Terrell-Scott rules over estimates k compared to other rules due to his simplicity.
</p>
<p><code>sturges</code> stands for Sturges's rule. The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">1 + \log_2(n)</code>
</p>

<p><code>scott</code> stands for Scott's rule. The number of bins is given by:
</p>
<p style="text-align: center;"><code class="reqn">range(x) / \sigma(x) n^{-1/3}</code>
</p>

<p><code>kmeans</code> apply the classical k-means clustering to one-dimensional continuous data.
</p>


<h3>Value</h3>

<p>the discretized dataframe or a list containing the table of counts for each bin the discretized dataframe</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>References</h3>

<p>Garcia, S., et al.  (2013) A survey of discretization techniques: Taxonomy and empirical analysis in supervised learning. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 25.4, 734-750.
</p>
<p>Cebeci, Z. and Yıldız, F. (2017) Unsupervised Discretization of Continuous Variables in a Chicken Egg Quality Traits Dataset. <em>Turkish Journal of Agriculture-Food Science and Technology</em>, 5.4, 315-320.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rv &lt;- rnorm(n = 100, mean = 0, sd = 2)

entropy.data(freqs.table = discretization(data.df = rv,
discretization.method = "fd",
frequency=TRUE)[[1]])

</code></pre>

<hr>
<h2 id='entropy.data'>Computes an Empirical Estimation of the Entropy from a Table of Counts</h2><span id='topic+entropy.data'></span>

<h3>Description</h3>

<p>This function empirically estimates the Shannon entropy from a table of counts using the observed frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy.data(freqs.table)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="entropy.data_+3A_freqs.table">freqs.table</code></td>
<td>
<p>a table of counts.</p>
</td></tr></table>


<h3>Details</h3>

<p>The general concept of entropy is defined for probability distributions. The 'entropy.data' function estimates empirical entropy from data. The probability is estimated from data using frequency tables. Then the estimates are plug-in in the definition of the entropy to return the so-called empirical entropy. A common known problem of empirical entropy is that the estimations are biased due to the sampling noise. This is also known that the bias will decrease as the sample size increases.</p>


<h3>Value</h3>

<p>Shannon's entropy estimate on natural logarithm scale.</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("varrank")

rv &lt;- rnorm(n = 100, mean = 0, sd = 2)

entropy.data(freqs.table = discretization(data.df = rv,
discretization.method = "fd",
frequency = TRUE)[[1]])
</code></pre>

<hr>
<h2 id='mi.data'>Empirical Estimate of the Mutual Information from a Table of Counts</h2><span id='topic+mi.data'></span>

<h3>Description</h3>

<p>This function estimates the mutual information from observed data</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi.data(X, Y, discretization.method=NULL, k=NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mi.data_+3A_x">X</code></td>
<td>
<p>a data frame containing only numeric or continuous variables.</p>
</td></tr>
<tr><td><code id="mi.data_+3A_y">Y</code></td>
<td>
<p>a data frame containing only numeric or continuous variables.</p>
</td></tr>
<tr><td><code id="mi.data_+3A_discretization.method">discretization.method</code></td>
<td>
<p>a character vector giving the discretization method to use. See <code><a href="#topic+discretization">discretization</a></code>.</p>
</td></tr>
<tr><td><code id="mi.data_+3A_k">k</code></td>
<td>
<p>in case of purely continuous dataset, the mutual information can be computed using the k-nearest neighbours.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mutual information estimation is computed from the observed frequencies through a plugin estimator based on entropy or using the estimator described in A. Kraskov, H. Stogbauer and P.Grassberger (2004) when the data frame is exclusively made of continuous variables.
</p>
<p>The plugin estimator is I(X, Y) = H (X) + H(Y) - H(X, Y), where H() is the entropy computed with <code><a href="#topic+entropy.data">entropy.data</a></code>.</p>


<h3>Value</h3>

<p>Mutual information estimate.</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>References</h3>

<p>Kraskov, A., Stogbauer, H. and  Grassberger, P. (2004) Estimating mutual information. <em>Physical Review E</em>, 69:066138, 1–16.</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- rnorm(n = 100, mean = 0, sd = 2)
X &lt;- rnorm(n = 100, mean = 5, sd = 2)

mi.data(X = Y, Y = X, discretization.method = "sturges")
</code></pre>

<hr>
<h2 id='nassCDS'>Airbag and other influences on accident fatalities</h2><span id='topic+nassCDS'></span>

<h3>Description</h3>

<p>US data, for 1997-2002, from police-reported car crashes in
which there is a harmful event (people or property), and from which at
least one vehicle was towed. Data are restricted to front-seat
occupants, include only a subset of the variables recorded, and
are restricted in other ways also.</p>


<h3>Usage</h3>

<pre><code class='language-R'>nassCDS</code></pre>


<h3>Format</h3>

<p>A data frame with 26217 observations on the following 15 variables.
</p>

<dl>
<dt><code>dvcat</code></dt><dd><p>ordered factor with levels (estimated impact
speeds) <code>1-9km/h</code>, <code>10-24</code>, <code>25-39</code>, <code>40-54</code>,
<code>55+</code>
</p>
</dd>
<dt><code>weight</code></dt><dd><p>Observation weights, albeit of uncertain
accuracy, designed to account for varying sampling probabilities.</p>
</dd>
<dt><code>dead</code></dt><dd><p>factor with levels <code>alive</code> <code>dead</code></p>
</dd>
<dt><code>airbag</code></dt><dd><p>a factor with levels <code>none</code> <code>airbag</code></p>
</dd>
<dt><code>seatbelt</code></dt><dd><p>a factor with levels <code>none</code> <code>belted</code></p>
</dd>
<dt><code>frontal</code></dt><dd><p>a numeric vector; 0 = non-frontal, 1=frontal impact</p>
</dd>
<dt><code>sex</code></dt><dd><p>a factor with levels <code>f</code> <code>m</code></p>
</dd>
<dt><code>ageOFocc</code></dt><dd><p>age of occupant in years</p>
</dd>
<dt><code>yearacc</code></dt><dd><p>year of accident</p>
</dd>
<dt><code>yearVeh</code></dt><dd><p>Year of model of vehicle; a numeric vector</p>
</dd>
<dt><code>abcat</code></dt><dd><p>Did one or more (driver or passenger) airbag(s)
deploy? This factor has levels <code>deploy</code> <code>nodeploy</code>
<code>unavail</code></p>
</dd>
<dt><code>occRole</code></dt><dd><p>a factor with levels <code>driver</code> <code>pass</code></p>
</dd>
<dt><code>deploy</code></dt><dd><p>a numeric vector: 0 if an airbag was
unavailable or did not deploy; 1 if one or more bags deployed.</p>
</dd>
<dt><code>injSeverity</code></dt><dd><p>a numeric vector; 0:none, 1:possible injury,
2:no incapacity, 3:incapacity, 4:killed; 5:unknown, 6:prior death</p>
</dd>
<dt><code>caseid</code></dt><dd><p>character, created by pasting together the
populations sampling unit, the case number, and the vehicle
number.  Within each year, use this to uniquely identify the
vehicle.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data collection used a multi-stage probabilistic sampling scheme.
The observation weight, called national inflation factor
(<code>national</code>) in the data from NASS, is the inverse
of an estimate of the selection probability.  These data
include a subset of the variables from the NASS dataset.  Variables
that are coded here as factors are coded as numeric values in that
dataset.
</p>


<h3>Source</h3>

<p><a href="https://www.stat.colostate.edu/~meyer/airbags.htm">https://www.stat.colostate.edu/~meyer/airbags.htm</a>

</p>
<p>See also\
<a href="https://maths-people.anu.edu.au/~johnm/datasets/airbags/">https://maths-people.anu.edu.au/~johnm/datasets/airbags/</a>
</p>


<h3>References</h3>

<p>Meyer, M.C. and Finney, T. (2005): <em>Who wants airbags?</em>. Chance
18:3-16.
</p>
<p>Farmer, C.H. 2006. <em>Another look at Meyer and Finney's &lsquo;Who wants
airbags?&rsquo;</em>. Chance 19:15-22.
</p>
<p>Meyer, M.C. 2006.  <em>Commentary on &quot;Another look at Meyer and
Finney's &lsquo;Who wants airbags?&rsquo;</em>. Chance 19:23-24.
</p>
<p>For analyses based on the alternative FARS (Fatal Accident Recording
System) data, and associated commentary, see:
</p>
<p>Cummings, P; McKnight, B, 2010. <em>Accounting for vehicle, crash, and
occupant characteristics in traffic crash studies.</em> Injury Prevention 16:
363-366. [The relatively definitive analyses in this paper use a matched
cohort design,
</p>
<p>Olson, CM; Cummings, P, Rivara, FP, 2006. <em>Association of first- and
second-generation air bags with front occupant death in car crashes: a
matched cohort study.</em> Am J Epidemiol 164:161-169. [The relatively
definitive analyses in this paper use a matched cohort design, using
data taken from the FARS (Fatal Accident Recording System) database.]
</p>
<p>Braver, ER; Shardell, M; Teoh, ER, 2010. <em>How have changes in air
bag designs affected frontal crash mortality?</em> Ann Epidemiol 20:499-510.
</p>
<p>The web page <a href="http://www-fars.nhtsa.dot.gov/Main/index.aspx">http://www-fars.nhtsa.dot.gov/Main/index.aspx</a> has a
menu-based interface into the FARS (Fatality Analysis Recording
System) data. The FARS database aims to include every accident in
which there was at least one fatality.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(nassCDS)
xtabs(weight ~ dead + airbag, data=nassCDS)
xtabs(weight ~ dead + airbag + seatbelt + dvcat, data=nassCDS)
tab &lt;- xtabs(weight ~ dead + abcat, data=nassCDS,
             subset=dvcat=="25-39"&amp;frontal==0)[, c(3,1,2)]
round(tab[2, ]/apply(tab,2,sum)*100,2)
</code></pre>

<hr>
<h2 id='plot.varrank'>Visualization of varrank output</h2><span id='topic+plot.varrank'></span>

<h3>Description</h3>

<p><code>plot</code> method for <code>varrank</code> objects with multiple options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varrank'
plot(x,
                       ## block separation
                       colsep = TRUE,
                       rowsep = TRUE,
                       sepcol ="white",
                       sepwidth=c(0.005,0.005),

                       ## cell labeling
                       cellnote = TRUE,
                       notecex = 1.5,
                       notecol = "black",
                       digitcell = 3,

                       ## Row/Column Labelling
                       margins = c(6, 6, 4, 2),
                       labelscex = 1.2,

                       ## color key + density info
                       colkey = NULL,
                       densadj = 0.25,
                       textlines = 2,

                       ## plot labels
                       main = NULL,
                       maincex = 1,
                       ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.varrank_+3A_x">x</code></td>
<td>
<p>an object of class <code>varrank</code>.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_colsep">colsep</code></td>
<td>
<p>(optional) a logical parameter to indicate if columns should be separated from others by narrow space of color. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_rowsep">rowsep</code></td>
<td>
<p>(optional) a logical parameter to indicate if rows should be separated from others by narrow space of color. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_sepcol">sepcol</code></td>
<td>
<p>(optional) the color to use to separate rows or columns. The default is <code>white</code>.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_sepwidth">sepwidth</code></td>
<td>
<p>(optional) Vector of length 2 giving the width
(colsep) or height (rowsep) the separator box drawn by colsep and
rowsep as a function of the width (colsep) or height (rowsep) of a
cell. The defaults is <code>c(0.005, 0.005)</code>.</p>
</td></tr>

<tr><td><code id="plot.varrank_+3A_cellnote">cellnote</code></td>
<td>
<p>(optional) a logical parameter to indicate if the scores should be displayed in cells.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_notecex">notecex</code></td>
<td>
<p>(optional) numeric scaling factor for <code>scores</code>. The default is 1.5.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_notecol">notecol</code></td>
<td>
<p>(optional) character string specifying the color for
<code>cellnote</code> text.  Defaults to &quot;black&quot;.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_digitcell">digitcell</code></td>
<td>
<p>(optional) integer that indicate how many digits of the <code>scores</code> should be displayed. The default is 3.</p>
</td></tr>

<tr><td><code id="plot.varrank_+3A_labelscex">labelscex</code></td>
<td>
<p>the magnification factor to be used for x and y labels relative to the current setting of cex. The default is 1.2.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_margins">margins</code></td>
<td>
<p>numerical vector of the form c(bottom, left, top, right) which gives the number of lines of margin to be specified on the four sides of the plot. The default is c(6, 6, 4, 2).</p>
</td></tr>

<tr><td><code id="plot.varrank_+3A_colkey">colkey</code></td>
<td>
<p>specification for the color scheme to be used. The default is a rainbow color scheme.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_densadj">densadj</code></td>
<td>
<p>numeric scaling value for tuning the kernel width when
a density plot is drawn on the color key.  (See the <code>adjust</code>
parameter for the <code>density</code> function for details.)  Defaults is
0.25.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_textlines">textlines</code></td>
<td>
<p>number of lines to display <code>relevance/redundance</code> in the key. Default is 2.</p>
</td></tr>

<tr><td><code id="plot.varrank_+3A_main">main</code></td>
<td>
<p>an overall title for the plot. Default is none.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_maincex">maincex</code></td>
<td>
<p>main magnification to be used for the plot. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.varrank_+3A_...">...</code></td>
<td>
<p>additional arguments passed to image.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <code>plot</code> method for <code>varrank</code> objects provides an
extensible framework for the visualization <code>varrank</code> output analysis. The
user is allowed to specify block separations, display of scores and the color scheme to be used. The other parameters give a full control on the output. The final rendering depends on the <code>algorithm</code> used. For a 'forward' search the key density is on the upper right corner and for a 'backward'
search the key density is in the bottom left corner.
The default color scheme is continuous heat color from blue to red. A
popular alternative for creating color palettes is <span class="pkg">RColorBrewer</span>,
<a href="https://cran.r-project.org/package=RColorBrewer">https://cran.r-project.org/package=RColorBrewer</a>.
</p>
<p>This <code>plot</code> method is very similar to the <code>heatmap.2</code> function from <span class="pkg">gplots</span>, <a href="https://cran.r-project.org/package=gplots">https://cran.r-project.org/package=gplots</a>.
</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("mlbench", quietly = TRUE)) {
library(mlbench)
data(PimaIndiansDiabetes)

##forward search for all variables
out &lt;- varrank(data.df = PimaIndiansDiabetes,
  method = "estevez",
  variable.important = "diabetes",
  discretization.method = "sturges",
  algorithm = "forward",scheme="mid")

##default output
plot(x = out)

##typical plot for high dimensional datasets
plot(x = out, colsep = FALSE, rowsep = FALSE, cellnote = FALSE)
}
</code></pre>

<hr>
<h2 id='print.varrank'>Methods for Varrank Objects</h2><span id='topic+print.varrank'></span>

<h3>Description</h3>

<p>Methods for computing on <code>varrank</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varrank'
print(x,digits=5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.varrank_+3A_x">x</code></td>
<td>
<p> an object of class <code>varrank</code>.</p>
</td></tr>
<tr><td><code id="print.varrank_+3A_digits">digits</code></td>
<td>
<p> an integer specifying the number of digits to display in the output.</p>
</td></tr>
<tr><td><code id="print.varrank_+3A_...">...</code></td>
<td>
<p>additional arguments passed to print.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>digits</code> gives the number of digits that will be displayed in the output. If more information are needed. There exists a <code><a href="base.html#topic+summary">summary</a></code> S3 function that display more details.
</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("mlbench", quietly = TRUE)) {
library(mlbench)
data(PimaIndiansDiabetes)

##forward search for all variables
varrank.output &lt;- varrank(data.df = PimaIndiansDiabetes,
  method = "peng",
  variable.important = "diabetes",
  discretization.method = "sturges",
  algorithm = "forward", scheme = "mid")

##Print varrank output

varrank.output
}
</code></pre>

<hr>
<h2 id='summary.varrank'>Summary Methods for Varrank Objects</h2><span id='topic+summary.varrank'></span>

<h3>Description</h3>

<p>Methods for detailed display of <code>varrank</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'varrank'
summary(object,digits=3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.varrank_+3A_object">object</code></td>
<td>
<p>an object of class <code>varrank</code>.</p>
</td></tr>
<tr><td><code id="summary.varrank_+3A_digits">digits</code></td>
<td>
<p>an integer specifying the number of digits to display in the output.</p>
</td></tr>
<tr><td><code id="summary.varrank_+3A_...">...</code></td>
<td>
<p>additional arguments passed to summary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>digits</code> gives the number of digits that will be displayed in the output. This method differs of <code><a href="#topic+print.varrank">print.varrank</a></code> by the amount of info displayed.
</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("mlbench", quietly = TRUE)) {

library(mlbench)
data(PimaIndiansDiabetes)

##forward search for all variables
varrank.output &lt;- varrank(data.df = PimaIndiansDiabetes,
  method = "peng",
  variable.important = "diabetes",
  discretization.method = "sturges",
  algorithm = "forward", scheme = "mid")

##Print summary output of varrank object

summary(varrank.output)
}
</code></pre>

<hr>
<h2 id='varrank'>Heuristics Tools Based on Mutual Information for Variable Ranking and Feature Selection</h2><span id='topic+varrank'></span>

<h3>Description</h3>

<p>This function heuristically estimates the variables ranks based on mutual information with multiple model and multiple search schemes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varrank(data.df = NULL, variable.important = NULL, method =
                 c("battiti", "kwak", "peng", "estevez"), algorithm =
                 c("forward", "backward"),
                 scheme = c("mid", "miq"),
                 discretization.method = NULL, ratio = NULL, n.var =
                 NULL, verbose = TRUE)
                 </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varrank_+3A_data.df">data.df</code></td>
<td>
<p>a named data frame with either numeric or factor variables.</p>
</td></tr>
<tr><td><code id="varrank_+3A_variable.important">variable.important</code></td>
<td>
<p>a list of variables that is the target variables.</p>
</td></tr>
<tr><td><code id="varrank_+3A_method">method</code></td>
<td>
<p>the method to be used. See &lsquo;Details&rsquo;. Default is <code>"estevez"</code>.</p>
</td></tr>
<tr><td><code id="varrank_+3A_algorithm">algorithm</code></td>
<td>
<p>the algorithm scheme to be used. Default is '<code>"forward"</code>.</p>
</td></tr>
<tr><td><code id="varrank_+3A_scheme">scheme</code></td>
<td>
<p>the scheme search to be used. <code>"mid"</code> and <code>"miq"</code> stands for the Mutual Information Difference and Quotient schemes, respectively. Those are two ways to combine the relevance and redundancy. They are the two most used mRMRe schemes</p>
</td></tr>
<tr><td><code id="varrank_+3A_discretization.method">discretization.method</code></td>
<td>
<p>a character vector giving the discretization method to use. See <code><a href="#topic+discretization">discretization</a></code>.</p>
</td></tr>
<tr><td><code id="varrank_+3A_ratio">ratio</code></td>
<td>
<p>parameter to be used in <code>"battiti"</code> and <code>"kwak"</code>.</p>
</td></tr>
<tr><td><code id="varrank_+3A_n.var">n.var</code></td>
<td>
<p>number of variables to be returned.</p>
</td></tr>
<tr><td><code id="varrank_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should a progress bar be plotted? As the search scheme.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default <code>varrank</code> performs a variable ranking based on forward search algorithm using mutual information. The scoring is based on one of the four models implemented. The input dataset can be discrete, continuous or mixed variables. The target variables can be a set.
The filter approach based on mutual information is the Minimum Redundancy Maximum Relevance (mRMRe) algorithm. A general formulation of the ensemble of mRMRe techniques is, given a set of features F, a subset of important features C, a candidate feature f_i and possibly some already selected features f_s in S. The local score function for a mid scheme (Mutual Information Difference) is expressed as:
</p>
<p style="text-align: center;"><code class="reqn">g_i(A, C, S, f_i) = MI(f_i;C) - \sum_{f_s} A(f_i, f_s, C) MI(f_i; f_s)</code>
</p>

<p>Depending of the value method, the value of A and B will be set accordingly to:
</p>
<p><code>battiti</code> defined A=B, where B is a user defined parameter (called ratio). Battiti (1994).
</p>
<p><code>kwak</code> defined A = B MI(f_s;C)/H(f_s), where B a user defined parameter (called ratio). Kwak et al. (2002).
</p>
<p><code>peng</code> defined A=1/|S|. Peng et al. (2005).
</p>
<p><code>estevez</code> defined A = 1/|S| min(H(f_i), H(f_s)). Estévez et al. (2009).
</p>
<p>The search algorithm implemented are a forward search i.e. start with an empty set S and fill in. The the returned list is ranked by decreasing order of relevance. A backward search which start with a full set i.e. all variables except <code>variable.importance</code> are considered as selected and the returned list is in increasing order of relevance based solely on mutual information estimation. Thus a backward search will only check for relevance and not for redundancy. <code>n.var</code> is optional if it is not provided, all candidate variables will be ranked.
</p>


<h3>Value</h3>

<p>A list with an entry for the variables ranked and another entry for the score for each ranked variables.</p>


<h3>Author(s)</h3>

<p>Gilles Kratzer</p>


<h3>References</h3>

<p>Kratzer, G. and Furrer, R.  &quot;varrank: an R package for variable ranking based on mutual information with applications to system epidemiology&quot;</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (requireNamespace("mlbench", quietly = TRUE)) {
library(mlbench)
data(PimaIndiansDiabetes)

##forward search for all variables
out1 &lt;- varrank(data.df = PimaIndiansDiabetes,
  method = "estevez",
  variable.important = "diabetes",
  discretization.method = "sturges",
  algorithm = "forward", scheme = "mid")

##forward search for 3 variables
out2 &lt;- varrank(data.df = PimaIndiansDiabetes,
  method = "estevez",
  variable.important = "diabetes",
  discretization.method = "sturges",
  algorithm = "forward",
  scheme = "mid",
  n.var=3)

##backward search for all variables
out3 &lt;- varrank(data.df = PimaIndiansDiabetes,
  method = "peng",
  variable.important = "diabetes",
  discretization.method = "sturges",
  algorithm = "backward",
  scheme = "mid",
  n.var=NULL)
  }

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
