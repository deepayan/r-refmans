<!DOCTYPE html><html><head><title>Help for package dynamicSDM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dynamicSDM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dynamicSDM-package'><p>dynamicSDM: Species Distribution and Abundance Modelling at High Spatio-Temporal Resolution</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#brt_fit'><p>Fit boosted regression tree models to species distribution or abundance data.</p></a></li>
<li><a href='#convert_gbif'><p>Reformats GBIF data into <code>dynamicSDM</code> data frame</p></a></li>
<li><a href='#dynamic_proj'><p>Project species distribution and abundance models onto dynamic environmental covariates.</p></a></li>
<li><a href='#dynamic_proj_covariates'><p>Combine explanatory variable rasters into covariates for each projection date.</p></a></li>
<li><a href='#dynamic_proj_dates'><p>Generate vector of dates for dynamic projections</p></a></li>
<li><a href='#dynamic_proj_GIF'><p>Create GIF of dynamic species distribution and abundance projections</p></a></li>
<li><a href='#extract_buffered_coords'><p>Extract spatially buffered and temporally dynamic explanatory variable data for occurrence</p>
records.</a></li>
<li><a href='#extract_buffered_raster'><p>Extract spatially buffered and temporally dynamic rasters of explanatory variable data.</p></a></li>
<li><a href='#extract_coords_combine'><p>Combine extracted explanatory variable data for occurrence records into single data frame.</p></a></li>
<li><a href='#extract_dynamic_coords'><p>Extract temporally dynamic explanatory variable data for occurrence records.</p></a></li>
<li><a href='#extract_dynamic_raster'><p>Extract temporally dynamic rasters of explanatory variables.</p></a></li>
<li><a href='#extract_static_coords'><p>Extract explanatory variables from static rasters</p></a></li>
<li><a href='#get_moving_window'><p>Generate a “moving window” matrix of optimal size</p></a></li>
<li><a href='#sample_cov_data'><p>Sample projection covariates three variables across for southern Africa.</p></a></li>
<li><a href='#sample_events_data'><p>Sample e-Bird sampling event records</p></a></li>
<li><a href='#sample_explan_data'><p>Sample species occurrence records with associated dynamic explanatory variables</p></a></li>
<li><a href='#sample_extent_data'><p>MULTIPOLYGON object for the extent of southern Africa</p></a></li>
<li><a href='#sample_filt_data'><p>Sample of filtered species occurrence records</p></a></li>
<li><a href='#sample_occ_data'><p>Sample species occurrence records</p></a></li>
<li><a href='#spatiotemp_autocorr'><p>Test for spatial and temporal autocorrelation in species distribution model explanatory data.</p></a></li>
<li><a href='#spatiotemp_bias'><p>Test for spatial and temporal bias in species occurrence records</p></a></li>
<li><a href='#spatiotemp_block'><p>Split occurrence records into spatial and temporal blocks for model fitting.</p></a></li>
<li><a href='#spatiotemp_check'><p>Check species occurrence record formatting, completeness and validity.</p></a></li>
<li><a href='#spatiotemp_extent'><p>Filter species occurrence records by a given spatial and temporal extent.</p></a></li>
<li><a href='#spatiotemp_pseudoabs'><p>Generate pseudo-absence record coordinates and dates</p></a></li>
<li><a href='#spatiotemp_resolution'><p>Filter species occurrence records by given spatial and temporal resolution</p></a></li>
<li><a href='#spatiotemp_thin'><p>Thin species occurrence records by spatial and temporal proximity.</p></a></li>
<li><a href='#spatiotemp_weights'><p>Calculate sampling effort across spatial and temporal buffer from species occurrence records</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Species Distribution and Abundance Modelling at High
Spatio-Temporal Resolution</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.4</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of novel tools for generating species distribution and abundance models (SDM) that are dynamic through both space and time. These highly flexible functions incorporate spatial and temporal aspects across key SDM stages; including when cleaning and filtering species occurrence data, generating pseudo-absence records, assessing and correcting sampling biases and autocorrelation, extracting explanatory variables and projecting distribution patterns. Throughout, functions utilise Google Earth Engine and Google Drive to minimise the computing power and storage demands associated with species distribution modelling at high spatio-temporal resolution.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, googledrive, lubridate, magrittr, reticulate, rgee,
stats, terra, tidyr, grDevices, graphics, methods, utils, sf,
readr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ape, CoordinateCleaner, covr, gargle, gbm, ggplot2, knitr,
magick, matrixStats, rmarkdown, spThin, stars, testthat (&ge;
3.0.0), viridis</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/r-a-dobson/dynamicSDM">https://github.com/r-a-dobson/dynamicSDM</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-a-dobson/dynamicSDM/issues">https://github.com/r-a-dobson/dynamicSDM/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-28 13:51:18 UTC; eerdo</td>
</tr>
<tr>
<td>Author:</td>
<td>Rachel Dobson <a href="https://orcid.org/0000-0003-3990-267X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, ctb],
  Andy J. Challinor <a href="https://orcid.org/0000-0002-8551-6617"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb],
  Robert A. Cheke <a href="https://orcid.org/0000-0002-7437-1934"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb],
  Stewart Jennings <a href="https://orcid.org/0000-0002-1267-8623"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb],
  Stephen G. Willis <a href="https://orcid.org/0000-0002-8656-5808"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb],
  Martin Dallimer <a href="https://orcid.org/0000-0001-8120-3309"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rachel Dobson &lt;eerdo@leeds.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-28 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dynamicSDM-package'>dynamicSDM: Species Distribution and Abundance Modelling at High Spatio-Temporal Resolution</h2><span id='topic+dynamicSDM'></span><span id='topic+dynamicSDM-package'></span>

<h3>Description</h3>

<p>A collection of novel tools for generating species distribution and abundance models (SDM) that are dynamic through both space and time. These highly flexible functions incorporate spatial and temporal aspects across key SDM stages; including when cleaning and filtering species occurrence data, generating pseudo-absence records, assessing and correcting sampling biases and autocorrelation, extracting explanatory variables and projecting distribution patterns. Throughout, functions utilise Google Earth Engine and Google Drive to minimise the computing power and storage demands associated with species distribution modelling at high spatio-temporal resolution.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Rachel Dobson <a href="mailto:eerdo@leeds.ac.uk">eerdo@leeds.ac.uk</a> (<a href="https://orcid.org/0000-0003-3990-267X">ORCID</a>) [contributor]
</p>
<p>Authors:
</p>

<ul>
<li><p> Andy J. Challinor <a href="mailto:A.J.Challinor@leeds.ac.uk">A.J.Challinor@leeds.ac.uk</a> (<a href="https://orcid.org/0000-0002-8551-6617">ORCID</a>) [contributor]
</p>
</li>
<li><p> Robert A. Cheke <a href="mailto:R.A.Cheke@greenwich.ac.uk">R.A.Cheke@greenwich.ac.uk</a> (<a href="https://orcid.org/0000-0002-7437-1934">ORCID</a>) [contributor]
</p>
</li>
<li><p> Stewart Jennings <a href="mailto:S.A.Jennings@leeds.ac.uk">S.A.Jennings@leeds.ac.uk</a> (<a href="https://orcid.org/0000-0002-1267-8623">ORCID</a>) [contributor]
</p>
</li>
<li><p> Stephen G. Willis <a href="mailto:s.g.willis@durham.ac.uk">s.g.willis@durham.ac.uk</a> (<a href="https://orcid.org/0000-0002-8656-5808">ORCID</a>) [contributor]
</p>
</li>
<li><p> Martin Dallimer <a href="mailto:M.Dallimer@leeds.ac.uk">M.Dallimer@leeds.ac.uk</a> (<a href="https://orcid.org/0000-0001-8120-3309">ORCID</a>) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/r-a-dobson/dynamicSDM">https://github.com/r-a-dobson/dynamicSDM</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/r-a-dobson/dynamicSDM/issues">https://github.com/r-a-dobson/dynamicSDM/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='brt_fit'>Fit boosted regression tree models to species distribution or abundance data.</h2><span id='topic+brt_fit'></span>

<h3>Description</h3>

<p>Fit gradient boosting boosted regression tree models to species distribution and abundance data
and associated dynamic explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brt_fit(
  occ.data,
  response.col,
  varnames,
  distribution,
  block.col,
  weights.col,
  test.data,
  interaction.depth,
  n.trees = 5000,
  shrinkage = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brt_fit_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, the data to fit boosted regression tree models to, containing
columns for model response and explanatory variable data. If required, <code>occ.data</code> should contain
<code>block.col</code> and <code>weights.col</code> columns too.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_response.col">response.col</code></td>
<td>
<p>a character string, the name of the column in <code>occ.data</code> containing response
variable column.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_varnames">varnames</code></td>
<td>
<p>a character vector, the names of the columns containing model explanatory
variables in <code>occ.data.</code></p>
</td></tr>
<tr><td><code id="brt_fit_+3A_distribution">distribution</code></td>
<td>
<p>a character string, the model distribution family to use, such as <code>gaussian</code>,
<code>poisson</code> or <code>bernoulli</code>.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_block.col">block.col</code></td>
<td>
<p>optional; a character string, the name of the column in <code>occ.data</code> containing
spatio-temporal block numbers for <code>occ.data</code> splitting. See details for more information.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_weights.col">weights.col</code></td>
<td>
<p>a character string, the name of the column in <code>occ.data</code> containing
spatio-temporal sampling effort weights to be used in the model fitting process.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_test.data">test.data</code></td>
<td>
<p>optional; a data frame, the testing dataset for optimising <code>interaction.depth</code>
when blocking is not used.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>optional; an integer specifying the maximum depth of each tree (i.e.
highest level of variable interactions allowed). Default optimises depth between 1 and 4.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_n.trees">n.trees</code></td>
<td>
<p>optional; an integer, the number of trees in boosted regression tree models.
Default is 5000.</p>
</td></tr>
<tr><td><code id="brt_fit_+3A_shrinkage">shrinkage</code></td>
<td>
<p>optional; an integer, the shrinkage parameter applied to each tree in the boosted
regression tree expansion. Also known as the learning rate. Default is 0.001.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates a gradient boosting <code>gbm</code> object for the response and
explanatory variable data provided, using the <code>gbm</code> R package (Greenwell et al., 2019).
</p>
<p>Key functionality for dynamic SDMs within <code>brt_fit()</code> includes:
</p>

<ul>
<li><p> Optimise <code>interaction.depth</code>
</p>
</li></ul>

<p>If <code>interaction.depth</code> is not given, then <code>brt_fit()</code> will vary the interaction depth parameter
between 1 (an additive model) and 4 (four-way interaction model). For each <code>interaction.depth</code>
value, model performance is measured by calculating the root-mean-square error of model
predictions compared to actual values in the testing data. The <code>interaction.depth</code> value that
results in the lowest root-mean-square error is used when fitting the returned model.
</p>
<p>The model testing dataset used can either be given using <code>test.data</code> or <code>block.col</code>
(expanded on below).
</p>

<ul>
<li><p> Split by spatio-temporal blocks to account for spatial and temporal autocorrelation
</p>
</li></ul>

<p>If <code>block.col</code> is specified, then each unique block is excluded in a jack-knife approach
following Bagchi et al., (2013). This approach uses each block as the model testing dataset in
numerical order, whilst all other <code>block.col</code> blocks are used as training data for the boosted
regression tree model.
</p>
<p>In this case, the function returns a list of fitted boosted regression tree models equal to the
length of unique blocking categories in <code>block.col</code>.
</p>
<p>If <code>block.col</code> is not given, models are fit to all occ.data and a single <code>gbm</code> model is
returned.
</p>

<ul>
<li><p> Weighted by spatio-temporal sampling effort
</p>
</li></ul>

<p>If <code>weights.col</code> is specified, records are weighted by their associated value in this column
when model fitting. For instance, the user may wish to down weigh the importance of records
collected at oversampled sites and times when fitting models, and vice versa, to account for
spatio-temporal biases in occurrence records(Stolar and Nielsen, 2015) .
</p>


<h3>Value</h3>

<p>Returns a <code>gbm</code> model object or list of <code>gbm</code> model objects.
</p>


<h3>References</h3>

<p>Bagchi, R., Crosby, M., Huntley, B., Hole, D. G., Butchart, S. H. M., Collingham, Y.,
Kalra, M., Rajkumar, J., Rahmani, A. &amp; Pandey, M. 2013. Evaluating the effectiveness of
conservation site networks under climate change: accounting for uncertainty. Global Change
Biology, 19, 1236-1248.
</p>
<p>Greenwell, B., Boehmke, B., Cunningham, J., &amp; GBM Developers. 2019.
Package ‘gbm’. R package version, 2.
</p>
<p>Stolar, J. &amp; Nielsen, S. E. 2015. Accounting For Spatially Biased Sampling Effort In
Presence-Only Species Distribution Modelling. Diversity And Distributions, 21, 595-608.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("sample_explan_data")

split &lt;- sample(c(TRUE, FALSE),
               replace=TRUE,
               nrow(sample_explan_data),
               prob = c(0.75, 0.25))

training &lt;- sample_explan_data[split, ]
testing &lt;- sample_explan_data[!split, ]

brt_fit(
 occ.data = training,
 test.data = testing,
 response.col = "presence.absence",
 distribution = "bernoulli",
 varnames = colnames(training)[14:16],
 interaction.depth = 2
)

</code></pre>

<hr>
<h2 id='convert_gbif'>Reformats GBIF data into <code>dynamicSDM</code> data frame</h2><span id='topic+convert_gbif'></span>

<h3>Description</h3>

<p>Function converts GBIF occurrence records into the format required for <code>dynamicSDM</code>
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_gbif(gbif.df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert_gbif_+3A_gbif.df">gbif.df</code></td>
<td>
<p>a data frame, the direct output from GBIF occurrence record download.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For most <code>dynamicSDM</code> functions, an occurrence data frame with record co-ordinate
columns labelled &quot;x&quot; and &quot;y&quot; with numeric columns for record &quot;day&quot;, &quot;month&quot; and &quot;year&quot; are
required. This function takes the input data frame and returns a reformatted data frame
suitable for direct input into <code>dynamicSDM</code> functions.
</p>


<h3>Value</h3>

<p>Returns data frame correctly formatted for input into <code>dynamicSDM</code> functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(sample_occ_data)
converted &lt;- convert_gbif(sample_occ_data)

</code></pre>

<hr>
<h2 id='dynamic_proj'>Project species distribution and abundance models onto dynamic environmental covariates.</h2><span id='topic+dynamic_proj'></span>

<h3>Description</h3>

<p>Projects fitted species distribution and abundance models onto projection covariates for each date
given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynamic_proj(
  dates,
  projection.method,
  local.directory,
  drive.folder,
  user.email,
  sdm.mod,
  sdm.thresh,
  sdm.weight,
  sam.mod,
  sam.weight,
  save.directory,
  save.drive.folder,
  cov.file.type,
  prj = "+proj=longlat +datum=WGS84",
  proj.prj,
  spatial.mask
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynamic_proj_+3A_dates">dates</code></td>
<td>
<p>a character string, vector of dates in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_projection.method">projection.method</code></td>
<td>
<p>a character string or vector, the method or methods to project
distribution and abundance onto projection covariates. Options include <code>proportional</code>, <code>binary</code>,
<code>abundance</code> and <code>stacked</code>. See details for more information.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_local.directory">local.directory</code></td>
<td>
<p>optional; a character string, the path to a local directory to read
projection covariate data frames from.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_drive.folder">drive.folder</code></td>
<td>
<p>optional; a character string, the Google Drive folder to read projection
covariate data frames from. Folder must be uniquely named within Google Drive. Do not provide
path.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_user.email">user.email</code></td>
<td>
<p>optional; a character string, user email for initialising Google Drive. Required
if <code>drive.folder</code> or <code>save.drive.folder</code> used.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_sdm.mod">sdm.mod</code></td>
<td>
<p>optional; a model object or list of model objects fitted to species distribution
data.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_sdm.thresh">sdm.thresh</code></td>
<td>
<p>optional; a numeric value, the threshold to convert projected distribution
suitability into binary presence-absence. Default 0.5. Required if projection.method is
&quot;<code>binary</code>&quot; or  &quot;<code>stacked</code>&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_sdm.weight">sdm.weight</code></td>
<td>
<p>optional; a numeric string, weights given to each <code>sdm.mod</code> model projection,
given in the same order as the <code>sdm.mod</code> list. Default is equal weighting to all models.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_sam.mod">sam.mod</code></td>
<td>
<p>optional; a model object or list of model objects fitted to species abundance data.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_sam.weight">sam.weight</code></td>
<td>
<p>optional; a numeric string, weights given to each <code>sdm.mod</code> model projection,
given in the same order as the <code>sam.mod</code> list. Default is equal weighting to all models.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_save.directory">save.directory</code></td>
<td>
<p>optional; a character string, path to local directory to save projection
rasters to.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_save.drive.folder">save.drive.folder</code></td>
<td>
<p>optional; a character string, Google Drive folder to save projection
rasters to. Folder must be uniquely named within Google Drive. Do not provide path.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_cov.file.type">cov.file.type</code></td>
<td>
<p>a character string, the type of file that contains projection covariates. One
of: &quot;<code>tif</code>&quot; (raster stack) or <code>csv</code>(data frame).</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of input projection covariates.
Default is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_proj.prj">proj.prj</code></td>
<td>
<p>a character string, the coordinate reference system desired for output projection
rasters. Default is assumed to be the same as prj.</p>
</td></tr>
<tr><td><code id="dynamic_proj_+3A_spatial.mask">spatial.mask</code></td>
<td>
<p>an object of class <code>SpatRaster</code> or<code>sf</code> polygon, representing a mask in which
NA cells in the mask layer are removed from the projection covariates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function projects a model object or list of model objects onto projection covariate data
frames for each projection date given.
</p>


<h3>Value</h3>

<p>Exports projection rasters for each projection date to user-specified Google Drive
folder or local directory.
</p>


<h3>Projection covariate input</h3>


<ul>
<li><p> Data frames: if <code>cov.file.type = csv</code>, then projection covariates must be saved &quot;csv&quot; files
in the <code>drive.folder</code> or <code>local.directory</code> given. Here, they must be unique in containing the
relevant projection date in YYYY-MM-DD format. For instance, two or more csv files saved
within the Google Drive folder or local directory that contain the projection date will result
in function error. Additionally, column names of projection covariate data frames must match the
explanatory variable names that fitted models are trained on.
</p>
</li>
<li><p> Raster stacks: if <code>cov.file.type = tif</code>, then projection covariates must be saved &quot;tif&quot;
files, similarly named and formatted as above. Raster layer names must match the explanatory
variable names that fitted models are trained on.
</p>
</li></ul>

<p>Note: It is important to state the coordinate reference system projection of covariates using
argument <code>prj</code>.
</p>


<h3>Model input</h3>

<p>When multiple models are provided in <code>sdm.mod</code> or <code>sam.mod</code>, the function projects each model
onto the projection covariates and takes the average value across all model projections. If
<code>sdm.weight</code> or <code>sam.weight</code> is specified, then the weighted average of model projections is
returned. For example, this could be used to down weigh projections by poorly performing models
in an ensemble (Ara?jo and New, 2007).
</p>


<h3>Projection output</h3>


<ul>
<li><p> proportional: Projects <code>sdm.mod</code> model objects onto projection covariates for each date,
exporting rasters for projected distribution suitability, a continuous measure between 0 (least
suitable) and 1 (most suitable).
</p>
</li>
<li><p> binary: Projects <code>sdm.mod</code> onto projection covariates for each date, exporting rasters for
projected binary presence (1) or absence (0), derived from distribution suitability using
user-specified threshold (<code>sdm.thresh</code>) or default threshold of 0.5 (Jim?nez-Valverde And Lobo,
2007).
</p>
</li>
<li><p> abundance: Projects <code>sam.mod</code> onto projections covariates for each date, exporting rasters for
projected abundance in the units that <code>sam.mod</code> were fitted onto.
</p>
</li>
<li><p> stacked: Follows the binary projection method and then projects abundance onto only binary
presence (1) cells using the abundance projection method.
</p>
</li></ul>

<p>Projections are output as rasters. These can be reprojected to a different coordinate reference
system using argument <code>proj.prj</code>.
</p>
<p>One or both of <code>save.drive.folder</code> and <code>save.directory</code> are required to specify where projection
rasters are to be saved.
</p>


<h3>Google Drive compatibility</h3>

<p>If <code>drive.folder</code> or <code>save.drive.folder</code> given, please ensure the folder name is unique within
your Google Drive. Do not provide the path if the folder is nested within others.
</p>
<p>If one of <code>drive.folder</code> or <code>save.drive.folder</code> are used then <code>user.email</code> is required to access
the appropriate Google Drive user account. This requires users to have installed R package
<code>googledrive</code> and initialised Google Drive with valid log-in credentials. Please follow
instructions on <a href="https://googledrive.tidyverse.org/">https://googledrive.tidyverse.org/</a>.
</p>


<h3>References</h3>

<p>Araujo, M. B. &amp; New, M. 2007. Ensemble Forecasting Of Species Distributions. Trends In Ecology &amp;
Evolution, 22, 42-47.
</p>
<p>Jimenez-Valverde, A. &amp; Lobo, J. M. 2007. Threshold Criteria For Conversion Of Probability Of
Species Presence To Either-Or Presence-Absence. Acta Oecologica, 31, 361-369.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Read in data
data("sample_explan_data")

# Set variable names
variablenames&lt;-c("eight_sum_prec","year_sum_prec","grass_crop_percentage")

model &lt;- brt_fit(sample_explan_data,
                 response.col = "presence.absence",
                 varnames = variablenames,
                 interaction.depth = 1,
                 distribution = "bernoulli",
                 n.trees = 1500)

data(sample_cov_data)
utils::write.csv(sample_cov_data,file=paste0(tempdir(),"/2018-04-01_covariates.csv"))

dynamic_proj(dates = "2018-04-01",
            projection.method = c("proportional"),
            local.directory = tempdir(),
            cov.file.type = "csv",
            sdm.mod = model,
            save.directory = tempdir())

</code></pre>

<hr>
<h2 id='dynamic_proj_covariates'>Combine explanatory variable rasters into covariates for each projection date.</h2><span id='topic+dynamic_proj_covariates'></span>

<h3>Description</h3>

<p>Explanatory variable rasters are imported, resampled to a given spatial resolution and extent,
stacked and then exported as a covariate data frame or raster stack for each projection date.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynamic_proj_covariates(
  dates,
  varnames,
  drive.folder,
  user.email,
  local.directory,
  spatial.ext,
  spatial.mask,
  spatial.res.degrees,
  resample.method,
  cov.file.type,
  prj = "+proj=longlat +datum=WGS84",
  cov.prj,
  save.directory,
  save.drive.folder,
  static.rasters,
  static.varnames,
  static.resample.method,
  static.moving.window.matrix,
  static.GEE.math.fun
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynamic_proj_covariates_+3A_dates">dates</code></td>
<td>
<p>a character string, vector of dates in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_varnames">varnames</code></td>
<td>
<p>a character string, the unique names for each explanatory variable.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_drive.folder">drive.folder</code></td>
<td>
<p>optional; a character string or vector, Google Drive folder or folders to read
projection covariate rasters from. Folder must be uniquely named within Google Drive. Do not
provide path.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_user.email">user.email</code></td>
<td>
<p>optional; a character string, user email for initialising Google Drive. Required
if <code>drive.folder</code> or <code>save.drive.folder</code> used.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_local.directory">local.directory</code></td>
<td>
<p>optional; a character string or vector, path to local directory or
directories to read projection covariate rasters from.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_spatial.ext">spatial.ext</code></td>
<td>
<p>optional; the spatial extent to crop explanatory variable
rasters to. Object of class <code>SpatExtent</code>, <code>SpatRaster</code>, an <code>sf</code> polygon or
numeric vector listing xmin, xmax, ymin and ymax in order.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_spatial.mask">spatial.mask</code></td>
<td>
<p>an object of class <code>Raster</code>, <code>sf</code> or <code>Spatial</code>, representing a mask in which
NA cells in the mask layer are removed from the projection covariates.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_spatial.res.degrees">spatial.res.degrees</code></td>
<td>
<p>optional; a numeric value, the spatial resolution in degrees for
projection rasters to be resampled to. Required if <code>spatial.ext</code> given.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_resample.method">resample.method</code></td>
<td>
<p>a character string or vector length of varnames, specifying resampling
method to use. One of <code>near</code> and <code>bilinear</code>. See details for more information.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_cov.file.type">cov.file.type</code></td>
<td>
<p>a character string, the type of file to export projection covariates as. One
of: <code>tif</code> (SpatRaster with multiple layers) or <code>csv</code>(data frame).</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system desired for projection covariates.
Default is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_cov.prj">cov.prj</code></td>
<td>
<p>a character string, the coordinate reference system desired for output projection
covariates. Default is assumed to be the same as <code>prj</code>.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_save.directory">save.directory</code></td>
<td>
<p>optional; a character string, path to local directory to save projection
covariates to.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_save.drive.folder">save.drive.folder</code></td>
<td>
<p>optional; a character string, Google Drive folder to save projection
covariates to. Folder must be uniquely named within Google Drive. Do not provide path.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_static.rasters">static.rasters</code></td>
<td>
<p>a RasterStack of one or more rasters to be added to covariates for each date.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_static.varnames">static.varnames</code></td>
<td>
<p>a character string or vector, the unique names for each
explanatory variable in order of rasters in <code>static.raster</code> stack.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_static.resample.method">static.resample.method</code></td>
<td>
<p>a character string or vector length of <code>static.varnames</code>, specifying resampling
method to use on static rasters provided. One of <code>near</code> and <code>bilinear</code>. See details for more information..</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_static.moving.window.matrix">static.moving.window.matrix</code></td>
<td>
<p>optional; a matrix of weights with an odd number
of sides, representing the spatial neighbourhood of cells (“moving
window”) to calculate <code>GEE.math.fun</code> across from record co-ordinate. See
details for more information.</p>
</td></tr>
<tr><td><code id="dynamic_proj_covariates_+3A_static.gee.math.fun">static.GEE.math.fun</code></td>
<td>
<p>optional; a character string, the mathematical function to
compute across the specified spatial matrix for each cell in <code>spatial.ext</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Exports combined covariates in &quot;csv&quot; or &quot;tif&quot; file for each projection date to the local
directory or Google Drive folder.
</p>


<h3>Input variable rasters</h3>

<p>For each projection date, the rasters for each explanatory variable are imported from a local
directory or Google Drive folder.
</p>
<p>Such rasters should be uniquely named &quot;tif&quot; files within the directory or drive folder and
contain the variable name (as stated in <code>varnames</code>) and projection date in format &quot;YYYY-MM-DD&quot;.
If more than one “tif” file in the Google Drive folder or local directory matches the projection
date and explanatory variable name, then the function will error.
</p>


<h3>Processing rasters</h3>

<p>If required, rasters are cropped and resampled to the same spatial extent and
resolution. If <code>spatial.mask</code> is given, then cells with NA in this mask layer
are removed from the returned projection covariates. See <code>terra::mask()</code> in R
package <code>terra</code> for details (Hijmans et al., 2022).
</p>
<p>Rasters are then stacked and reprojected if <code>cov.prj</code> is different to <code>prj</code>.
</p>
<p>Note: if explanatory variable rasters are not of the same spatial resolution and extent, then the
function will error. Resample methods (<code>resample.method</code>) include:
</p>

<ul>
<li> <p><code>near</code>:  Each cell acquires the value of its nearest neighbour cell in the original raster. This
is typically used for categorical variables.
</p>
</li>
<li> <p><code>bilinear</code>: the distance-weighted average of the four nearest cells are used to estimate a new
cell value. This is typically used for continuous variables.
</p>
</li></ul>

<p>If only one <code>resample.method</code> is given, but these are more than one explanatory variables, the
same <code>resample.method</code> is used for all.
</p>


<h3>Output covariates</h3>

<p>The raster stacks are then converted into data frames or remain as raster stacks depending on
<code>cov.file.type</code>. Column names or raster layer names will be the unique explanatory variable names
(<code>varnames</code>). These are exported to the local directory or Google Drive folder with file names
containing the relevant projection date in &quot;YYYY-MM-DD&quot; format.
</p>


<h3>Google Drive compatibility</h3>

<p>If <code>drive.folder</code> or <code>save.drive.folder</code> given, please ensure the folder name is unique within
your Google Drive. Do not provide the path if the folder is nested within others.
</p>
<p>If one of <code>drive.folder</code> or <code>save.drive.folder</code> are used then user.email is required to access the
appropriate Google Drive user account. This requires users to have installed R package
<code>googledrive</code> and initialised Google Drive with valid log-in credentials. Please follow
instructions on <a href="https://googledrive.tidyverse.org/">https://googledrive.tidyverse.org/</a>.
</p>


<h3>Static rasters</h3>

<p>If static datasets are to be added into the dynamic projection covariates,
then five arguments are available to specify their inclusion.
</p>
<p>Please provide the static rasters in RasterStack format, specifying any
spatial buffering needed (using <code>static.moving.window.matrix</code> and
<code>static.GEE.math.fun</code> as described below).
</p>
<p>The resample method or methods for rasters within the static raster stack need
to be specified too using <code>static.resample.method</code>. Please also provide
<code>static.varnames</code> to name the static variables in the covariate data exported.
</p>
<p>#' # Spatial buffering of static rasters (optional)
</p>
<p>Using the <code>focal</code> function from <code>terra</code> R package (Hijmans et al., 2022),
<code>GEE.math.fun</code> is calculated across the spatial buffer area from the record
co-ordinate. The spatial buffer area used is specified by the argument
<code>moving.window.matrix</code>, which dictates the neighbourhood of cells
surrounding the cell containing the occurrence record to include in this
calculation.
</p>
<p>See function <code>get_moving_window()</code> to generate appropriate
<code>moving.window.matrix</code>.
</p>


<h3>Mathematical function</h3>

<p><code>GEE.math.fun</code> specifies the mathematical function to be calculated over the
spatial buffered area and temporal period. Options are limited to Google
Earth Engine ImageCollection Reducer functions
(<a href="https://developers.google.com/earth-engine/apidocs/">https://developers.google.com/earth-engine/apidocs/</a>) for which an
analogous R function is available. This includes: &quot;allNonZero&quot;,&quot;anyNonZero&quot;,
&quot;count&quot;, &quot;first&quot;,&quot;firstNonNull&quot;, &quot;last&quot;, &quot;lastNonNull&quot;, &quot;max&quot;,&quot;mean&quot;,
&quot;median&quot;,&quot;min&quot;, &quot;mode&quot;,&quot;product&quot;, &quot;sampleStdDev&quot;, &quot;sampleVariance&quot;,
&quot;stdDev&quot;, &quot;sum&quot; and &quot;variance&quot;.
</p>


<h3>References</h3>

<p>Hijmans, R.J., Bivand, R., Forner, K., Ooms, J., Pebesma, E. and Sumner, M.D.,
2022. Package 'terra'. Maintainer: Vienna, Austria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data("sample_extent_data")

# Set extraction variables
projectiondates &lt;- dynamic_proj_dates("2018-01-01", "2018-12-01", interval = 3,interval.level =
"month")
variablenames &lt;- c("eight_sum_prec", "year_sum_prec")
spatial.res.metres &lt;- 500
cov_resolution &lt;- 0.05

# Get Google Drive email
user.email&lt;-as.character(gargle::gargle_oauth_sitrep()$email)

extract_dynamic_raster(dates=projectiondates,
                      datasetname = "UCSB-CHG/CHIRPS/DAILY",
                      bandname="precipitation",
                      user.email = user.email,
                      spatial.res.metres = spatial.res.metres,
                      GEE.math.fun = "sum",
                      temporal.direction = "prior",
                      temporal.res = 56,
                      spatial.ext = sample_extent_data,
                      varname = variablenames[1],
                      save.directory = tempdir())


extract_dynamic_raster(dates=projectiondates,
                     datasetname = "UCSB-CHG/CHIRPS/DAILY",
                     bandname="precipitation",
                     user.email = user.email,
                     spatial.res.metres = spatial.res.metres,
                     GEE.math.fun = "sum",
                     temporal.direction = "prior",
                     temporal.res = 364,
                     spatial.ext = sample_extent_data,
                     varname = variablenames[2],
                     save.directory = tempdir())

dynamic_proj_covariates(dates = projectiondates,
                       varnames = variablenames,
                       local.directory = tempdir(),
                       spatial.ext = sample_extent_data,
                       spatial.mask = sample_extent_data,
                       spatial.res.degrees = cov_resolution,
                       resample.method = c("bilinear","bilinear"),
                       cov.file.type = "csv",
                       prj="+proj=longlat +datum=WGS84",
                       save.directory = tempdir())

</code></pre>

<hr>
<h2 id='dynamic_proj_dates'>Generate vector of dates for dynamic projections</h2><span id='topic+dynamic_proj_dates'></span>

<h3>Description</h3>

<p>Creates a vector of dates at regular intervals between two given dates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynamic_proj_dates(startdate, enddate, interval.level, interval)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynamic_proj_dates_+3A_startdate">startdate</code></td>
<td>
<p>a character string, the start date in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_dates_+3A_enddate">enddate</code></td>
<td>
<p>a character string, the end date in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_dates_+3A_interval.level">interval.level</code></td>
<td>
<p>a character string, the time-step of intervals. One of <code>day</code>,<code>week</code>, <code>month</code>
or <code>year</code>: can be abbreviated.</p>
</td></tr>
<tr><td><code id="dynamic_proj_dates_+3A_interval">interval</code></td>
<td>
<p>a numeric value, the length of interval in <code>interval.level</code> units to generate
between the start and end date.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function returns a vector of dates between <code>start.date</code> and <code>end.date</code> at given interval
size.
</p>


<h3>Value</h3>

<p>Vector of dates between start date and end date split at regular intervals.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dynamic_proj_dates(
 startdate = "2000-01-01",
 enddate = "2001-01-01",
 interval.level = "month",
 interval = 2
)
</code></pre>

<hr>
<h2 id='dynamic_proj_GIF'>Create GIF of dynamic species distribution and abundance projections</h2><span id='topic+dynamic_proj_GIF'></span>

<h3>Description</h3>

<p>Plots dynamic species distribution and abundance projections through time and combines images into
a GIF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynamic_proj_GIF(
  dates,
  projection.type,
  drive.folder,
  user.email,
  local.directory,
  save.drive.folder,
  save.directory,
  width = 10,
  height = 10,
  legend.max,
  legend.min,
  legend.name,
  file.name,
  borders = FALSE,
  border.regions,
  border.colour = "black",
  colour.palette.custom,
  colour.palette
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynamic_proj_GIF_+3A_dates">dates</code></td>
<td>
<p>a character vector , projection dates in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_projection.type">projection.type</code></td>
<td>
<p>a character string, the type of distribution or abundance projection to
plot. One of <code>proportional</code>, <code>binary</code>, <code>abundance</code> and <code>stacked</code>.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_drive.folder">drive.folder</code></td>
<td>
<p>optional; a character string, the Google Drive folder to read projection
rasters from. Folder must be uniquely named within Google Drive. Do not provide path.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_user.email">user.email</code></td>
<td>
<p>optional; a character string, user email for initialising Google Drive. Required
if <code>drive.folder</code> or <code>save.drive.folder</code> used.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_local.directory">local.directory</code></td>
<td>
<p>optional; a character string, the path to local directory to read
projection rasters from.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_save.drive.folder">save.drive.folder</code></td>
<td>
<p>optional; a character string, Google Drive folder to save GIF to. Folder
must be uniquely named within Google Drive. Do not provide path.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_save.directory">save.directory</code></td>
<td>
<p>optional; a character string, path to local directory to save GIF to.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_width">width</code></td>
<td>
<p>optional; a numeric value, the GIF width in inches Default = 480.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_height">height</code></td>
<td>
<p>optional; a numeric value, the GIF height in inches Default = 480.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_legend.max">legend.max</code></td>
<td>
<p>optional; a numeric value, the maximum limit of legend values to standardise
across projections.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_legend.min">legend.min</code></td>
<td>
<p>optional; a numeric value, the minimum limit of legend values to standardise
across projections.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_legend.name">legend.name</code></td>
<td>
<p>optional; a character string, the name for the legend title. Default =
projection.type.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_file.name">file.name</code></td>
<td>
<p>optional, a character string, the name for the output GIF file. Default =
<code>projection.type</code>.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_borders">borders</code></td>
<td>
<p>a logical indicating whether to add country borders to map. Default = <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_border.regions">border.regions</code></td>
<td>
<p>optional; a character string or vector, the region or regionss for which to
add map borders. Required if <code>borders = TRUE</code>.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_border.colour">border.colour</code></td>
<td>
<p>optional; a character vector, the colour for plotted map borders. Default =
<code>black.</code></p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_colour.palette.custom">colour.palette.custom</code></td>
<td>
<p>optional; a character string or vector, the colours to use as plot
colour palette.</p>
</td></tr>
<tr><td><code id="dynamic_proj_GIF_+3A_colour.palette">colour.palette</code></td>
<td>
<p>optional; a character string, the colormap option to use from <code>viridis</code>. See
details for colour palette options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function reads in projection rasters for each date. These are plotted using <code>ggplot2</code> and
combined into a Graphics Interchange Format (GIF).
</p>


<h3>Value</h3>

<p>Exports GIF to Google Drive folder or local directory.
</p>


<h3>Import projection rasters</h3>

<p>Projection rasters for each date must be “tif” files that are uniquely named with the date
in format &quot;YYYY-MM-DD&quot; and <code>projection.type.</code> If more than one file name matches the date and
<code>projection.type</code>, the function will error.
</p>


<h3>Google Drive compatibility</h3>

<p>If <code>drive.folder</code> or <code>save.drive.folder</code> is given, please ensure the folder name is unique
within your Google Drive. Do not provide the path if the folder is nested within others.
</p>
<p>If one of <code>drive.folder</code> or <code>save.drive.folder</code> are used then <code>user.email</code> is required to access
the appropriate Google Drive user account. This requires users to have installed R package
<code>googledrive</code> and initialised Google Drive with valid log-in credentials. Please follow
instructions on <a href="https://googledrive.tidyverse.org/">https://googledrive.tidyverse.org/</a>.
</p>
<p>Options for colour palettes using <code>viridis</code> are illustrated at:
<a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">https://ggplot2.tidyverse.org/reference/scale_viridis.html</a>. Available options include: &quot;magma&quot;
(or &quot;A&quot;), &quot;inferno&quot; (or &quot;B&quot;), &quot;plasma&quot; (or &quot;C&quot;), &quot;viridis&quot; (or &quot;D&quot;, the default option),
&quot;cividis&quot; (or &quot;E&quot;), &quot;rocket&quot; (or &quot;F&quot;), &quot;mako&quot;(or &quot;G&quot;) and &quot;turbo&quot; (or &quot;H&quot;).
</p>


<h3>References</h3>

<p>Wickham, H., and Chang, W, 2016. Package ‘ggplot2’. Create elegant data
visualisations using the grammar of graphics. Version, 2(1), pp.1-189.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
proj_dates &lt;- dynamic_proj_dates(startdate = "2018-01-01",
                                     enddate = "2018-12-01",
                                     interval = 3,
                                     interval.level = "month")

# Generate fake proportional projection SpatRasters
proj1 &lt;- terra::rast(ncols=22, nrows=25)
proj1 &lt;- terra::setValues(proj1, sample(0:100, terra::ncell(proj1), replace = TRUE)/100)

proj2 &lt;- terra::rast(ncols=22, nrows=25)
proj2 &lt;- terra::setValues(proj2, sample(0:100, terra::ncell(proj2), replace = TRUE)/100)

proj3 &lt;- terra::rast(ncols=22, nrows=25)
proj3 &lt;- terra::setValues(proj3, sample(0:100, terra::ncell(proj3), replace = TRUE)/100)

proj4 &lt;- terra::rast(ncols=22, nrows=25)
proj4 &lt;- terra::setValues(proj4, sample(0:100, terra::ncell(proj4), replace = TRUE)/100)

# Save sample projection rasters to replicate output from `dynamic_proj()`
terra::writeRaster(proj1,
                  filename = paste0(tempdir(),
                  "/",
                  paste0(proj_dates[1], "_proportional.tif")),
                  overwrite = TRUE)
terra::writeRaster(proj2,
                  filename = paste0(tempdir(),
                  "/",
                  paste0(proj_dates[2], "_proportional.tif")),
                  overwrite = TRUE)
terra::writeRaster(proj3,
                  filename = paste0(tempdir(),
                  "/",
                  paste0(proj_dates[3], "_proportional.tif")),
                  overwrite = TRUE)
terra::writeRaster(proj4,
                  filename = paste0(tempdir(),
                  "/",
                  paste0(proj_dates[4], "_proportional.tif")),
                  overwrite = TRUE)

dynamic_proj_GIF(dates = proj_dates,
                projection.type = "proportional",
                local.directory = tempdir(),
                save.directory = tempdir())

</code></pre>

<hr>
<h2 id='extract_buffered_coords'>Extract spatially buffered and temporally dynamic explanatory variable data for occurrence
records.</h2><span id='topic+extract_buffered_coords'></span>

<h3>Description</h3>

<p>For each species occurrence record co-ordinate and date, spatially buffered and temporally dynamic
explanatory data are extracted using Google Earth Engine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_buffered_coords(
  occ.data,
  datasetname,
  bandname,
  spatial.res.metres,
  GEE.math.fun,
  moving.window.matrix,
  user.email,
  save.method,
  varname,
  temporal.res,
  temporal.level,
  temporal.direction,
  categories,
  save.directory,
  agg.factor,
  prj = "+proj=longlat +datum=WGS84",
  resume = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_buffered_coords_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_datasetname">datasetname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset to extract data from.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_bandname">bandname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset bandname to extract data for.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_spatial.res.metres">spatial.res.metres</code></td>
<td>
<p>a numeric value, the spatial resolution in metres for data extraction.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_gee.math.fun">GEE.math.fun</code></td>
<td>
<p>a character string, the mathematical function to compute across the specified
spatial matrix and period for each record.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_moving.window.matrix">moving.window.matrix</code></td>
<td>
<p>a matrix of weights with an odd number of sides, representing the
spatial neighbourhood of cells (“moving window”) to calculate <code>GEE.math.fun</code> across from record
co-ordinate. See details for more information.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_user.email">user.email</code></td>
<td>
<p>a character string, user email for initialising Google Drive.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_save.method">save.method</code></td>
<td>
<p>a character string, the method used to save extracted variable data. One of
<code>split</code> or <code>combined</code>: can be abbreviated. See details.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_varname">varname</code></td>
<td>
<p>optional; a character string, a unique name for the explanatory variable. Default
varname is “bandname_temporal.res_temporal.direction_GEE.math.fun_buffered&quot;.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_temporal.res">temporal.res</code></td>
<td>
<p>optional; a numeric value, the temporal resolution in days to extract data and
calculate <code>GEE.math.fun</code> across from occurrence record date.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_temporal.level">temporal.level</code></td>
<td>
<p>a character string, the temporal resolution of the explanatory variable
data. One of <code>day</code>, <code>month</code> or <code>year</code>: can be abbreviated. Default; <code>day.</code></p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_temporal.direction">temporal.direction</code></td>
<td>
<p>optional; a character string, the temporal direction for extracting data
across relative to the record date. One of <code>prior</code> or <code>post</code>: can be abbreviated.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_categories">categories</code></td>
<td>
<p>optional; a character string, the categories to use in calculation if data are
categorical. See details for more information.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_save.directory">save.directory</code></td>
<td>
<p>a character string, path to a local directory to save extracted variable
data to.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_agg.factor">agg.factor</code></td>
<td>
<p>optional;a postive integer, the aggregation factor expressed as number of cells
in each direction. See details.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of <code>occ.data</code> coordinates.Default
is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
<tr><td><code id="extract_buffered_coords_+3A_resume">resume</code></td>
<td>
<p>a logical indicating whether to search <code>save.directory</code> and return to previous
progress. Only possible if save.method = <code>split</code> has previously and currently been employed.
Default = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each individual species occurrence record co-ordinate and date, this function
extracts data for a given band within a Google Earth Engine dataset across a user-specified
spatial buffer and temporal period and calculates a mathematical function on such data.
</p>


<h3>Value</h3>

<p>Returns details of successful explanatory variable extractions.
</p>


<h3>Temporal dimension</h3>

<p>If <code>temporal.res</code> and <code>temporal.direction</code> are not given, the function
extracts explanatory variable data for all of the cells surrounding and including the cell
containing the occurrence record co-ordinates.
</p>
<p>If <code>temporal.res</code> and <code>temporal.direction</code> is given, the function extracts explanatory variable
data for which <code>GEE.math.fun</code> has been first calculated over this period in relation to the
occurrence record date.
</p>


<h3>Spatial dimension</h3>

<p>Using the <code>focal</code> function from <code>terra</code> R package (Hijmans et al., 2022), <code>GEE.math.fun</code> is
calculated across the spatial buffer area from the record co-ordinate. The spatial buffer area
used is specified by the argument <code>moving.window.matrix</code>, which dictates the neighbourhood of
cells surrounding the cell containing the occurrence record to include in this calculation.
</p>
<p>See function <code>get_moving_window()</code> to generate appropriate <code>moving.window.matrix</code>.
</p>


<h3>Mathematical function</h3>

<p><code>GEE.math.fun</code> specifies the mathematical function to be calculated over the spatial buffered
area and temporal period. Options are limited to Google Earth Engine ImageCollection Reducer
functions (<a href="https://developers.google.com/earth-engine/apidocs/">https://developers.google.com/earth-engine/apidocs/</a>) for which an analogous R
function is available. This includes: &quot;allNonZero&quot;,&quot;anyNonZero&quot;, &quot;count&quot;,
&quot;first&quot;,&quot;firstNonNull&quot;, &quot;last&quot;, &quot;lastNonNull&quot;, &quot;max&quot;,&quot;mean&quot;, &quot;median&quot;,&quot;min&quot;, &quot;mode&quot;,&quot;product&quot;,
&quot;sampleStdDev&quot;, &quot;sampleVariance&quot;, &quot;stdDev&quot;, &quot;sum&quot; and &quot;variance&quot;.
</p>


<h3>Categorical data</h3>

<p>When explanatory variable data are categorical (e.g. land cover classes), argument <code>categories</code>
can be used to specify the categories of importance to the calculation. The category or
categories given will be converted in a binary representation, with “1” for those listed, and
“0” for all others in the dataset. Ensure that the <code>GEE.math.fun</code> given is appropriate for such
data. For example, the sum of suitable land cover classified cells across the “moving window”
from the species occurrence record co-ordinates.
</p>


<h3>Categorical data and temporally dynamic variables</h3>

<p>Please be aware, if specific categories are given (argument <code>categories</code>) when extracting
categorical data, then temporal buffering cannot be completed. The most recent categorical data
to the occurrence record date will be used for spatial buffering.
</p>
<p>If specific categories are not given when extracting from categorical datasets, be careful to
choose appropriate mathematical functions for such data. For instance, &quot;first&quot; or &quot;last&quot; may be
more relevant that &quot;sum&quot; of land cover classification numbers.
</p>


<h3>Temporal level to extract data at:</h3>

<p><code>temporal.level</code> states the temporal resolution of the explanatory variable data and improves
the speed of <code>extract_buffered_coords()</code> extraction. For example, if the explanatory data
represents an annual variable, then all record co-ordinates from the same year can be extracted
from the same buffered raster, saving computation time. However, if the explanatory data
represents a daily variable, then only records from the exact same day can be extracted from the
same raster. For the former, <code>temporal.level</code> argument should be <code>year</code> and for the latter,
<code>temporal.level</code> should be <code>day</code>.
</p>


<h3>Aggregation factor</h3>

<p><code>agg.factor</code> given represents the factor to aggregate <code>RasterLayer</code> data with function
<code>aggregate</code> in <code>terra</code> R package (Hijmans et al., 2022). Aggregation uses the <code>GEE.math.fun</code> as
the function. Following aggregation spatial buffering using the moving window matrix occurs.
This is included to minimise computing time if data are of high spatial resolution and a large
spatial buffer is needed. Ensure to calculate <code>get_moving_window()</code> with the spatial resolution
of the data post-aggregation by this factor.
</p>


<h3>Google Earth Engine</h3>

<p><code>extract_buffered_coords()</code> requires users to have installed R package <code>rgee</code> (Aybar et al.,
2020) and initialised Google Earth Engine with valid log-in credentials. Please follow
instructions on the following website <a href="https://cran.r-project.org/package=rgee">https://cran.r-project.org/package=rgee</a>
</p>

<ul>
<li> <p><code>datasetname</code> must be in the accepted Google Earth Engine catalogue layout (e.g.
“MODIS/006/MCD12Q1” or “UCSB-CHG/CHIRPS/DAILY”)
</p>
</li>
<li> <p><code>bandname</code> must be as specified under the
dataset in the Google Earth Engine catalogue (e.g. “LC_Type5”, “precipitation”). For datasets
and band names, see <a href="https://developers.google.com/earth-engine/datasets">https://developers.google.com/earth-engine/datasets</a>.
</p>
</li></ul>



<h3>Google Drive</h3>

<p><code>extract_buffered_coords()</code> also requires users to have installed the R package
<code>googledrive</code>(D'Agostino McGowan and Bryan, 2022) and initialised Google Drive with valid log-in
credentials, which must be stated using argument <code>user.email</code>. Please follow instructions on
<a href="https://googledrive.tidyverse.org/">https://googledrive.tidyverse.org/</a> for initialising the <code>googledrive</code> package.
</p>
<p>Note: When running this function a folder labelled &quot;dynamicSDM_download_bucket&quot; will be created
in your Google Drive. This will be emptied once the function has finished running and output
rasters will be found in the save.drive.folder or save.directory specified.
</p>


<h3>Exporting extracted data</h3>

<p>For <code>save.method</code> = <code>combined</code>, the function with save “csv” files containing all occurrence
records and associated values for the explanatory variable.
</p>
<p>For <code>save.method</code> = <code>split</code>, the function will save individual “csv” files for each record with
each unique period of the given temporal.level (e.g. each year, each year and month combination
or each unique date).
</p>
<p><code>split</code> protects users if internet connection is lost when extracting data for large occurrence
datasets. The argument <code>resume</code> can be used to resume to previous progress if connection is
lost.
</p>


<h3>References</h3>

<p>Aybar, C., Wu, Q., Bautista, L., Yali, R. and Barja, A., 2020. rgee: An R package for
interacting with Google Earth Engine. Journal of Open Source Software, 5(51), p.2272.
</p>
<p>D'Agostino McGowan L., and Bryan J., 2022. googledrive: An Interface to Google Drive.
<a href="https://googledrive.tidyverse.org">https://googledrive.tidyverse.org</a>, <a href="https://github.com/tidyverse/googledrive">https://github.com/tidyverse/googledrive</a>.
</p>
<p>Hijmans, R.J., Bivand, R., Forner, K., Ooms, J., Pebesma, E. and Sumner, M.D.,
2022. Package 'terra'. Maintainer: Vienna, Austria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(sample_filt_data)



user.email&lt;-as.character(gargle::gargle_oauth_sitrep()$email)

matrix&lt;-get_moving_window(radial.distance = 10000,
                            spatial.res.degrees = 0.05,
                            spatial.ext = sample_extent_data)

extract_buffered_coords(occ.data = sample_filt_data,
                      datasetname = "MODIS/006/MCD12Q1",
                      bandname = "LC_Type5",
                      spatial.res.metres = 500,
                      GEE.math.fun = "sum",
                      moving.window.matrix=matrix,
                      user.email = user.email,
                      save.method ="split",
                      temporal.level = "year",
                      categories = c(6,7),
                      agg.factor = 12,
                      varname = "total_grass_crop_lc",
                      save.directory = tempdir()
)

</code></pre>

<hr>
<h2 id='extract_buffered_raster'>Extract spatially buffered and temporally dynamic rasters of explanatory variable data.</h2><span id='topic+extract_buffered_raster'></span>

<h3>Description</h3>

<p>Extract rasters for spatially buffered and temporally dynamic explanatory variables at each
projection date using Google Earth Engine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_buffered_raster(
  dates,
  spatial.ext,
  datasetname,
  bandname,
  temporal.level,
  spatial.res.metres,
  GEE.math.fun,
  moving.window.matrix,
  user.email,
  varname,
  temporal.res,
  temporal.direction,
  categories,
  save.directory,
  agg.factor,
  save.drive.folder,
  resume = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_buffered_raster_+3A_dates">dates</code></td>
<td>
<p>a character string, vector of dates in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_spatial.ext">spatial.ext</code></td>
<td>
<p>the spatial extent for the extracted raster. Object from which extent
can be extracted of class <code>SpatExtent</code>, <code>SpatRaster</code>, <code>sf</code> polygon or
numeric vector listing xmin, xmax, ymin and ymax in order.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_datasetname">datasetname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset to extract data from.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_bandname">bandname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset bandname to extract data for.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_temporal.level">temporal.level</code></td>
<td>
<p>a character string indicating the temporal resolution of the remote-sensing
dataset (<code>datasetname</code>). One of <code>day</code>, <code>month</code> or <code>year</code>: can be abbreviated. Default; <code>day</code>.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_spatial.res.metres">spatial.res.metres</code></td>
<td>
<p>a numeric value, specifying the spatial resolution in metres of the
raster to be extracted.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_gee.math.fun">GEE.math.fun</code></td>
<td>
<p>a character string, the mathematical function to compute across the specified
period and spatial buffer from each projection date and cell.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_moving.window.matrix">moving.window.matrix</code></td>
<td>
<p>a matrix of weights with an odd number of sides to specify spatial
neighbourhood of cells (&quot;moving window&quot;) to calculate <code>GEE.math.fun</code> across for each cell in
<code>spatial.ext</code>. See details for more information.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_user.email">user.email</code></td>
<td>
<p>a character string, user email for initialising Google Drive.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_varname">varname</code></td>
<td>
<p>optional; a character string, the unique name for the explanatory variable. Default
varname is “bandname_temporal.res_temporal.direction_ GEE.math.fun_buffered_raster&quot;.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_temporal.res">temporal.res</code></td>
<td>
<p>optional; a numeric value, the temporal resolution in days prior or post each
projection date to calculate <code>GEE.math.fun</code> across.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_temporal.direction">temporal.direction</code></td>
<td>
<p>optional; a character string, the temporal direction for extracting
dynamic variable data across relative to each projection date given. One of <code>prior</code> or <code>post</code>:
can be abbreviated.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_categories">categories</code></td>
<td>
<p>optional; a character string, the categories to use in the calculation if data
are categorical. See details for more information.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_save.directory">save.directory</code></td>
<td>
<p>optional; a character string, path to local directory to save extracted
rasters to.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_agg.factor">agg.factor</code></td>
<td>
<p>optional;a postive integer, the aggregation factor expressed as number of cells
in each direction. See details.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_save.drive.folder">save.drive.folder</code></td>
<td>
<p>optional; a character string, Google Drive folder to save extracted
rasters to. Folder must be uniquely named within Google Drive. Do not provide path.</p>
</td></tr>
<tr><td><code id="extract_buffered_raster_+3A_resume">resume</code></td>
<td>
<p>a logical indicating whether to search <code>save.directory</code> or <code>save.drive.folder</code> and
return to previous progress through projection dates.Default = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each projection date, this function downloads rasters at a given spatial extent and
resolution for spatially buffered and temporally dynamic explanatory variables. Rasters can be
saved directly to Google Drive or a local directory. These rasters can be
combined to create projection covariate data frames for projecting dynamic species distribution
and abundance at high spatiotemporal resolution.
</p>


<h3>Value</h3>

<p>Returns details of successful explanatory variable raster extractions for each projection
date.
</p>


<h3>Temporal dimension</h3>

<p>If <code>temporal.res</code> and <code>temporal.direction</code> are not given, explanatory variable data for all
cells within <code>spatial.ext</code> are extracted. If <code>temporal.res</code> and <code>temporal.direction</code> are given,
explanatory variable data for all cells within <code>spatial.ext</code> are extracted, for which
<code>GEE.math.fun</code> has been first calculated over the specified period in relation to the projection
date (prior or post).
</p>


<h3>Categorical data and temporally dynamic variables</h3>

<p>Please be aware, if specific categories are given (argument <code>categories</code>) when extracting
categorical data, then temporal buffering cannot be completed. The most recent categorical data
to the occurrence record date will be used and spatial buffering will take place.
</p>
<p>If, specific categories are not given when extracting from categorical datasets, be careful to
choose appropriate mathematical functions for such data. For instance, &quot;first&quot; or &quot;last&quot; may be
more relevant that &quot;sum&quot; of land cover classification numbers.
</p>


<h3>Spatial dimension</h3>

<p>Using the <code>focal</code> function in <code>terra</code> R package (Hijmans et al., 2022), <code>GEE.math.fun</code> is
calculated across the spatial buffer area from each cell in <code>spatial.ext</code>. The spatial buffer
area used is defined by <code style="white-space: pre;">&#8288;moving.window matrix&#8288;</code>, which dictates the neighbourhood of cells
surrounding each cell in <code>spatial.ext</code> to include in the calculation.
See <a href="#topic+get_moving_window">get_moving_window</a>.
</p>


<h3>Mathematical function</h3>

<p><code>GEE.math.fun</code> specifies the mathematical function to be calculated over the spatial buffered
area and temporal period. Options are limited to Google Earth Engine ImageCollection Reducer
functions (<a href="https://developers.google.com/earth-engine/apidocs/">https://developers.google.com/earth-engine/apidocs/</a>) for which an analogous R
function is available. This includes: &quot;allNonZero&quot;,&quot;anyNonZero&quot;, &quot;count&quot;,
&quot;first&quot;,&quot;firstNonNull&quot;, &quot;last&quot;, &quot;lastNonNull&quot;, &quot;max&quot;,&quot;mean&quot;, &quot;median&quot;,&quot;min&quot;, &quot;mode&quot;,&quot;product&quot;,
&quot;sampleStdDev&quot;, &quot;sampleVariance&quot;, &quot;stdDev&quot;, &quot;sum&quot; and &quot;variance&quot;.
</p>


<h3>Categorical data</h3>

<p>If explanatory variable data are categorical (e.g. land cover classes), <code>categories</code> can be used
to specify the categories of importance to the calculation. The category or categories given
will be converted in a binary representation, with “1” for those listed, and “0” for all others
in the dataset. Ensure that the <code>GEE.math.fun</code> given is appropriate for such data.
</p>
<p>For example, this function could return the sum of suitable land cover classified cells in the
“moving window” from each cell across spatial extent given.
</p>


<h3>Aggregation factor</h3>

<p><code>agg.factor</code> given represents the factor to aggregate <code>SpatRaster</code> data with function
<code>aggregate</code> in <code>terra</code> R package (Hijmans et al., 2022). Aggregation uses the <code>GEE.math.fun</code> as
the function. Following aggregation spatial buffering using the moving window matrix occurs.
This is included to minimise computing time if data are of high spatial resolution and a large
spatial buffer is needed. Ensure to calculate <code>get_moving_window()</code> with the spatial resolution
of the data post-aggregation by this factor.
</p>


<h3>Google Earth Engine</h3>

<p><code>extract_buffered_raster()</code> requires users to have installed R package <code>rgee</code> (Aybar et al.,
2020) and initialised Google Earth Engine with valid log-in credentials. Please follow
instructions on the following website <a href="https://cran.r-project.org/package=rgee">https://cran.r-project.org/package=rgee</a>
</p>

<ul>
<li> <p><code>datasetname</code> must be in the accepted Google Earth Engine catalogue layout (e.g.
“MODIS/006/MCD12Q1” or “UCSB-CHG/CHIRPS/DAILY”)
</p>
</li>
<li> <p><code>bandname</code> must be as specified under the dataset in the Google Earth Engine catalogue (e.g.
“LC_Type5”, “precipitation”). For datasets and band names, see
<a href="https://developers.google.com/earth-engine/datasets">https://developers.google.com/earth-engine/datasets</a>.
</p>
</li></ul>



<h3>Google Drive</h3>

<p><code>extract_buffered_raster()</code> also requires users to have installed the R package
<code>googledrive</code>(D'Agostino McGowan and Bryan, 2022) and initialised Google Drive with valid log-in
credentials, which must be stated using argument <code>user.email</code>. Please follow instructions on
<a href="https://googledrive.tidyverse.org/">https://googledrive.tidyverse.org/</a> for initialising the <code>googledrive</code> package.
</p>
<p>The <code>save.drive.folder</code> must be uniquely named within your Google Drive and do not provide the
path.
</p>


<h3>Occasional rgee errors</h3>

<p>As this function uses the <code>rgee</code> package to extract rasters from Google Earth Engine, below we
outline occasional <code>rgee</code> errors that may occur when extracting rasters:
</p>

<ul>
<li><p> &quot;To avoid memory excess problems, ee_as_raster will not build Raster objects for large images&quot;
</p>
</li></ul>

<p>This can be a sporadic error. It may be related to GEE server usage or internet
connection at the time you tested the function. Try restarting your R session or try again at
another time. Also, try clearing the files from the &quot;dynamicSDM_download_bucket&quot; in your Google
Drive.
</p>
<p>This error could also be due to an issue with your input <code>spatial.res.metres</code>. This
function will extract rasters at all typical spatial resolutions of remote-sensing data and at
global extents. If this error persists, please ensure you have not accidentally given an
unrealistically high spatial resolution (e.g. <code>spatial.res.metres = 0.01</code> when you may be
confusing the spatial resolution in degrees with metres).
</p>

<ul>
<li><p> &quot;Pixel type not supported: Type Long. Convert the image to a floating point type or a smaller
integer type, for example, using ee.Image.toDouble()&quot;
</p>
</li></ul>

<p>This error appears when <code>rgee</code> has been given an input that cannot be extracted. Some common
causes include:
</p>

<ul>
<li><p> Inappropriate <code>GEE.math.fun</code> for extracting categorical data.
</p>
</li>
<li><p> Dates or spatial extents that are not covered by the chosen GEE dataset. Remember to check
whether the first projection date minus <code>temporal.res</code> is still within the temporal extent of the
dataset.
</p>
</li></ul>



<h3>References</h3>

<p>Aybar, C., Wu, Q., Bautista, L., Yali, R. and Barja, A., 2020. rgee: An R package for
interacting with Google Earth Engine. Journal of Open Source Software, 5(51), p.2272.
</p>
<p>D'Agostino McGowan L., and Bryan J., 2022. googledrive: An Interface to Google Drive.
<a href="https://googledrive.tidyverse.org">https://googledrive.tidyverse.org</a>, <a href="https://github.com/tidyverse/googledrive">https://github.com/tidyverse/googledrive</a>.
</p>
<p>Hijmans, R.J., Bivand, R., Forner, K., Ooms, J., Pebesma, E. and Sumner, M.D.,
2022. Package 'terra'. Maintainer: Vienna, Austria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dates &lt;- dynamic_proj_dates("2018-01-01", "2018-12-01", interval = 3,interval.level = "month")


data("sample_extent_data")
user.email&lt;-as.character(gargle::gargle_oauth_sitrep()$email)

matrix&lt;-get_moving_window(radial.distance = 10000,
                            spatial.res.degrees = 0.05,
                            spatial.ext = sample_extent_data)

extract_buffered_raster(dates = dates,
                       datasetname = "MODIS/006/MCD12Q1",
                       bandname="LC_Type5",
                       spatial.res.metres = 500,
                       GEE.math.fun = "sum",
                       moving.window.matrix = matrix,
                       user.email = user.email,
                       categories=c(6,7),
                       agg.factor = 12,
                       spatial.ext = sample_extent_data,
                       varname = "total_grass_crop_lc",
                       save.directory = tempdir())

</code></pre>

<hr>
<h2 id='extract_coords_combine'>Combine extracted explanatory variable data for occurrence records into single data frame.</h2><span id='topic+extract_coords_combine'></span>

<h3>Description</h3>

<p>Combines the split output files from functions <code>extract_dynamic_coords()</code> and
<code>extract_buffered_coords()</code> into single data frame containing all occurrence records and
explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_coords_combine(
  varnames,
  local.directory,
  set_class = FALSE,
  col_classes
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_coords_combine_+3A_varnames">varnames</code></td>
<td>
<p>a character string, the unique names for each explanatory variable.</p>
</td></tr>
<tr><td><code id="extract_coords_combine_+3A_local.directory">local.directory</code></td>
<td>
<p>a character string or vector, the path to local directory or directories to
read extracted explanatory data frames from.</p>
</td></tr>
<tr><td><code id="extract_coords_combine_+3A_set_class">set_class</code></td>
<td>
<p>a logical indicating whether to set the classes of each column in the data
before merging to avoid error. See details for more information.</p>
</td></tr>
<tr><td><code id="extract_coords_combine_+3A_col_classes">col_classes</code></td>
<td>
<p>optional; a named vector specifying the classes for columns within occ.data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When functions <code>extract_dynamic_coords()</code> and <code>extract_buffered_coords()</code> have been used
to extract dynamic explanatory variables for occurrence records, the output for individual
records and each variable will be split into separate “csv” files.
</p>
<p>This function reads in these files and combines data into a single data frame containing each
occurrence records and associated explanatory data from each variable.
</p>
<p>To prevent error, the “csv” files must be uniquely named within the folder(s) and include an
exact character match for the varnames provided. All “csv” files matching the varnames should
have the same number and names of columns. This is the default output
of<code>extract_dynamic_coords()</code> and <code>extract_buffered_coords()</code>.
</p>


<h3>Value</h3>

<p>Returns a data frame containing all occurrence records with associated explanatory
variable data.
</p>


<h3>Column classes</h3>

<p>When co-ordinate data have been extracted using the <code>split</code> method in <code>extract_dynamic_coords()</code>
and <code>extract_buffered_coords()</code>, sometimes the classes of columns in the separate exported data
frames can vary. For instance, one split row may contain an NA value in one column, whilst
another split contains a numerical value. When <code>extract_coords_combine()</code> attempts to read these
in and bind them together, an error can occur due to the class mismatch (logical compared to
numeric).
</p>
<p>There are two arguments that can help to resolve this error:
</p>

<ul>
<li><p> If <code>set_class = TRUE</code> and <code>col_classes</code> is given, then the column classes for each split data
frame will be set as the classes in <code>col_classes</code>.
</p>
</li>
<li><p> If <code>set_class = TRUE</code> and <code>col_classes</code> is not given, then the column classes for each split
data frame will be set by the classes of columns in the first read in csv. Be aware that this
approach may be inaccurate and lead to parsing warnings, as it depends on the first split
containing the correct classes (e.g. numeric not a logical in the example above).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
data(sample_filt_data)


dynamicSDM::extract_dynamic_coords(
 occ.data = sample_filt_data,
 datasetname = "UCSB-CHG/CHIRPS/DAILY",
 bandname = "precipitation",
 spatial.res.metres = 10000,
 GEE.math.fun = "sum",
 temporal.direction = "prior",
 temporal.res = 56,
 save.method = "split",
 varname = "eightweekprec",
 save.directory = tempdir()
)
dynamicSDM::extract_dynamic_coords(
 occ.data = sample_filt_data,
 datasetname = "UCSB-CHG/CHIRPS/DAILY",
 bandname = "precipitation",
 spatial.res.metres = 10000,
 GEE.math.fun = "sum",
 temporal.direction = "prior",
 temporal.res = 364,
 save.method = "combined",
 varname = "annualweekprec",
 save.directory = tempdir()
)

extract_coords_combine(varnames = c("eightweekprec", "annualweekprec"),
                      local.directory = tempdir(),
                      set_class = TRUE,
                      col_classes = c(sapply(sample_filt_data,class),
                                    eightweekprec = "numeric",
                                    annualweekprec="numeric"))

</code></pre>

<hr>
<h2 id='extract_dynamic_coords'>Extract temporally dynamic explanatory variable data for occurrence records.</h2><span id='topic+extract_dynamic_coords'></span>

<h3>Description</h3>

<p>For each species occurrence record co-ordinate and date, temporally dynamic explanatory data are
extracted using Google Earth engine
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_dynamic_coords(
  occ.data,
  datasetname,
  bandname,
  spatial.res.metres,
  GEE.math.fun,
  save.method,
  temporal.res,
  temporal.direction,
  varname,
  resume = FALSE,
  save.directory
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_dynamic_coords_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_datasetname">datasetname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset to extract data from.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_bandname">bandname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset bandname to extract data for.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_spatial.res.metres">spatial.res.metres</code></td>
<td>
<p>a numeric value, the spatial resolution in metres for data extraction.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_gee.math.fun">GEE.math.fun</code></td>
<td>
<p>a character string, the mathematical function to compute across the
<code>temporal.res</code> period for each record.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_save.method">save.method</code></td>
<td>
<p>a character string, the method used to save extracted variable data. One of
<code>split</code> or <code>combined</code>: can be abbreviated. See details.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_temporal.res">temporal.res</code></td>
<td>
<p>a numeric value, the temporal resolution in days to extract data and
calculate <code>GEE.math.fun</code> across from each record's date.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_temporal.direction">temporal.direction</code></td>
<td>
<p>a character string, the temporal direction for extracting data across
relative to the record date. One of <code>prior</code> or <code>post</code>: can be abbreviated.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_varname">varname</code></td>
<td>
<p>optional; a character string, the unique name for the explanatory variable.
Default varname is &quot;bandname_temporal.res_temporal.direction_ GEE.math.fun&quot;.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_resume">resume</code></td>
<td>
<p>a logical indicating whether to search <code>save.directory</code> and start from previous
progress by function. Only possible if <code>save.method</code> = <code>split</code> has been used.</p>
</td></tr>
<tr><td><code id="extract_dynamic_coords_+3A_save.directory">save.directory</code></td>
<td>
<p>a character string, the path to a local directory to save extracted
variable data to.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each individual species occurrence record co-ordinate and date, this function extracts data
for a given band within a Google Earth Engine dataset across a user-specified period and
calculates a mathematical function on such data.
</p>


<h3>Value</h3>

<p>Returns details of successful explanatory variable extractions.
</p>


<h3>Google Earth Engine</h3>

<p><code>extract_dynamic_coords()</code> requires users to have installed R package <code>rgee</code> (Aybar et al.,
2020) and initialised Google Earth Engine with valid log-in credentials. Please follow
instructions on the following website <a href="https://cran.r-project.org/package=rgee">https://cran.r-project.org/package=rgee</a>.
</p>

<ul>
<li> <p><code>datasetname</code> must be in the accepted Google Earth Engine catalogue layout (e.g.
<code>"MODIS/006/MCD12Q1"</code> &quot;or <code>"UCSB-CHG/CHIRPS/DAILY"</code>)
</p>
</li>
<li> <p><code>bandname</code> must be as specified under the
dataset in the Google Earth Engine catalogue (e.g. <code>"LC_Type5"</code>, <code>"precipitation"</code>). For
datasets
and band names, see <a href="https://developers.google.com/earth-engine/datasets">https://developers.google.com/earth-engine/datasets</a>.
</p>
</li></ul>



<h3>Mathematical function</h3>

<p><code>GEE.math.fun</code> specifies the mathematical function to be calculated over the temporal period
from each record's date. Options are limited to Google Earth Engine ImageCollection Reducer
functions (<a href="https://developers.google.com/earth-engine/apidocs/">https://developers.google.com/earth-engine/apidocs/</a>) for which an analogous R
function is available. This includes: &quot;allNonZero&quot;,&quot;anyNonZero&quot;, &quot;count&quot;,
&quot;first&quot;,&quot;firstNonNull&quot;, &quot;last&quot;, &quot;lastNonNull&quot;, &quot;max&quot;,&quot;mean&quot;, &quot;median&quot;,&quot;min&quot;, &quot;mode&quot;,&quot;product&quot;,
&quot;sampleStdDev&quot;, &quot;sampleVariance&quot;, &quot;stdDev&quot;, &quot;sum&quot; and &quot;variance&quot;.
</p>


<h3>Categorical data</h3>

<p>Please be aware, at current this function does not support the extraction of temporally dynamic
variables for specific categories within categorical datasets.
</p>
<p>When extracting from categorical datasets, be careful to choose appropriate mathematical
functions for such data. For instance, &quot;first&quot; or &quot;last&quot; may be more relevant that &quot;sum&quot; of land
cover classification numbers.
</p>


<h3>Exporting extracted data</h3>

<p>For <code>save.method</code> = <code>combined</code>, the function with save “csv” files containing all occurrence
records and associated values for the explanatory variable.
</p>
<p>For <code>save.method</code> = <code>split</code>, the function will save individual “csv” files for each record with
each unique period of the given temporal.level (e.g. each year, each year and month combination
or each unique date).
</p>
<p><code>split</code> protects users if internet connection is lost when extracting data for large occurrence
datasets. The argument <code>resume</code> can be used to resume to previous progress if connection is
lost.
</p>


<h3>References</h3>

<p>Aybar, C., Wu, Q., Bautista, L., Yali, R. and Barja, A., 2020. rgee: An R package for
interacting with Google Earth Engine. Journal of Open Source Software, 5(51), p.2272.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(sample_filt_data)



extract_dynamic_coords(occ.data=sample_filt_data,
 datasetname = "UCSB-CHG/CHIRPS/DAILY",
 bandname="precipitation",
 spatial.res.metres = 5566 ,
 GEE.math.fun = "sum",
 temporal.direction = "prior",
 temporal.res = 364,
 save.method = "split",
 resume = TRUE,
 varname = "total_annual_precipitation_prior",
 save.directory= tempdir())


</code></pre>

<hr>
<h2 id='extract_dynamic_raster'>Extract temporally dynamic rasters of explanatory variables.</h2><span id='topic+extract_dynamic_raster'></span>

<h3>Description</h3>

<p>Extract rasters for temporally dynamic explanatory variables at each projection date using Google
Earth Engine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_dynamic_raster(
  dates,
  spatial.ext,
  datasetname,
  bandname,
  spatial.res.metres,
  GEE.math.fun,
  user.email,
  varname,
  temporal.res,
  temporal.direction,
  save.directory,
  save.drive.folder,
  resume = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_dynamic_raster_+3A_dates">dates</code></td>
<td>
<p>a character string, vector of dates in format &quot;YYYY-MM-DD&quot;.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_spatial.ext">spatial.ext</code></td>
<td>
<p>the spatial extent for the extracted raster. Object from which extent can be
extracted of class <code>SpatExtent</code>, <code>SpatRaster</code>, an <code>sf</code> polygon or a
numeric vector listing xmin, xmax, ymin and ymax in order.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_datasetname">datasetname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset to extract data from.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_bandname">bandname</code></td>
<td>
<p>a character string, the Google Earth Engine dataset bandname to extract data for.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_spatial.res.metres">spatial.res.metres</code></td>
<td>
<p>a numeric value, specifying the spatial resolution in metres of the
raster to be extracted.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_gee.math.fun">GEE.math.fun</code></td>
<td>
<p>a character string, the mathematical function to compute across the specified
time frame from each projection date and for each cell.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_user.email">user.email</code></td>
<td>
<p>a character string, user email for initialising Google Drive.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_varname">varname</code></td>
<td>
<p>optional; a character string, the unique name for the explanatory variable. Default
varname is “bandname_temporal.res_temporal.direction_ GEE.math.fun_raster&quot;.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_temporal.res">temporal.res</code></td>
<td>
<p>a numeric value, the temporal resolution in days to extract data across.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_temporal.direction">temporal.direction</code></td>
<td>
<p>a character string, the temporal direction for extracting dynamic
variable data across relative to each projection date given. One of <code>prior</code> or <code>post</code>: can
be abbreviated.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_save.directory">save.directory</code></td>
<td>
<p>optional; a character string, path to local directory to save extracted
rasters to.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_save.drive.folder">save.drive.folder</code></td>
<td>
<p>optional; a character string, Google Drive folder name to save extracted
rasters to. Folder must be uniquely named within your Google Drive. Do not provide path.</p>
</td></tr>
<tr><td><code id="extract_dynamic_raster_+3A_resume">resume</code></td>
<td>
<p>a logical indicating whether to search <code>save.directory</code> or <code>save.drive.folder</code> and
return to previous progress through projection dates.Default = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each projection date, this function downloads rasters at a given spatial extent and
resolution for temporally dynamic explanatory variables. For each cell within the spatial
extent, the <code>GEE.math.fun</code> is calculated on the data extracted from across the specified number
of days prior or post the projection date. Rasters can be saved to Google Drive or a local
directory too. These rasters can be combined to create projection covariate data frames for
projecting dynamic species distribution and abundance at high spatiotemporal resolution.
</p>


<h3>Value</h3>

<p>Returns details of successful explanatory variable extractions for each projection date.
</p>


<h3>Google Earth Engine</h3>

<p><code>extract_dynamic_raster()</code> requires users to have installed the R package <code>rgee</code> (Aybar et al.,
2020) and initialised Google Earth Engine with valid log-in credentials. Please follow
instructions on the following website <a href="https://cran.r-project.org/package=rgee">https://cran.r-project.org/package=rgee</a>.
</p>

<ul>
<li> <p><code>datasetname</code> must be in the accepted Google Earth Engine catalogue layout (e.g.
“MODIS/006/MCD12Q1” or “UCSB-CHG/CHIRPS/DAILY”)
</p>
</li>
<li> <p><code>bandname</code> must be as specified under the dataset in the Google Earth Engine catalogue (e.g.
“LC_Type5”, “precipitation”). For datasets and band names, see
<a href="https://developers.google.com/earth-engine/datasets">https://developers.google.com/earth-engine/datasets</a>.
</p>
</li></ul>



<h3>Google Drive</h3>

<p><code>extract_dynamic_raster()</code> also requires users to have installed the R package
<code>googledrive</code>(D'Agostino McGowan and Bryan, 2022) and initialised Google Drive with valid log-in
credentials, which must be stated using argument <code>user.email</code>. Please follow instructions on
<a href="https://googledrive.tidyverse.org/">https://googledrive.tidyverse.org/</a> for initialising the <code>googledrive</code> package.
</p>
<p>The <code>save.drive.folder</code> must be uniquely named within your Google Drive and do not provide the
path.
</p>
<p>Note: When running this function a folder labelled &quot;dynamicSDM_download_bucket&quot; will be created in
your Google Drive. This will be emptied once the function has finished running and output rasters
will be found in the <code>save.drive.folder</code> or <code>save.directory</code>.
</p>


<h3>Mathematical function</h3>

<p><code>GEE.math.fun</code> specifies the mathematical function to be calculated over the temporal period
from each projection date. Options are limited to Google Earth Engine ImageCollection Reducer
functions (<a href="https://developers.google.com/earth-engine/apidocs/">https://developers.google.com/earth-engine/apidocs/</a>) for which an analogous R
function is available. This includes: &quot;allNonZero&quot;,&quot;anyNonZero&quot;, &quot;count&quot;,
&quot;first&quot;,&quot;firstNonNull&quot;, &quot;last&quot;, &quot;lastNonNull&quot;, &quot;max&quot;,&quot;mean&quot;, &quot;median&quot;,&quot;min&quot;, &quot;mode&quot;,&quot;product&quot;,
&quot;sampleStdDev&quot;, &quot;sampleVariance&quot;, &quot;stdDev&quot;, &quot;sum&quot; and &quot;variance&quot;.
</p>


<h3>Categorical data</h3>

<p>Please be aware, at current this function does not support the extraction of temporally dynamic
variables for specific categories within categorical datasets.
</p>
<p>When extracting from categorical datasets, be careful to choose appropriate mathematical
functions for such data. For instance, &quot;first&quot; or &quot;last&quot; may be more relevant that &quot;sum&quot; of land
cover classification numbers.
</p>


<h3>Occasional rgee errors</h3>

<p>As this function uses the <code>rgee</code> package to extract rasters from Google Earth Engine, below we
outline occasional <code>rgee</code> errors that may occur when extracting rasters:
</p>

<ul>
<li><p> &quot;To avoid memory excess problems, ee_as_raster will not build Raster objects for large images&quot;
</p>
</li></ul>

<p>This can be a sporadic error. It may be related to GEE server usage or internet
connection at the time you tested the function. Try restarting your R session or try again at
another time. Also, try clearing the files from the &quot;dynamicSDM_download_bucket&quot; in your Google
Drive.
</p>
<p>This error could also be due to an issue with your input <code>spatial.res.metres</code>. This
function will extract rasters at all typical spatial resolutions of remote-sensing data and at
global extents. If this error persists, please ensure you have not accidentally given an
unrealistically high spatial resolution (e.g. <code>spatial.res.metres = 0.01</code> when you may be
confusing the spatial resolution in degrees with metres).
</p>

<ul>
<li><p> &quot;Pixel type not supported: Type Long. Convert the image to a floating point type or a smaller
integer type, for example, using ee.Image.toDouble()&quot;
</p>
</li></ul>

<p>This error appears when <code>rgee</code> has been given an input that cannot be extracted. Some common
causes include:
</p>

<ul>
<li><p> Inappropriate <code>GEE.math.fun</code> for extracting categorical data.
</p>
</li>
<li><p> Dates or spatial extents that are not covered by the chosen GEE dataset. Remember to check
whether the first projection date minus <code>temporal.res</code> is still within the temporal extent of the
dataset.
</p>
</li></ul>



<h3>References</h3>

<p>Aybar, C., Wu, Q., Bautista, L., Yali, R. and Barja, A., 2020. rgee: An R package for
interacting with Google Earth Engine. Journal of Open Source Software, 5(51), p.2272.
</p>
<p>D'Agostino McGowan L., and Bryan J., 2022. googledrive: An Interface to Google Drive.
https://googledrive.tidyverse.org, https://github.com/tidyverse/googledrive.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dates &lt;- dynamic_proj_dates("2018-01-01", "2018-12-01", interval = 3,interval.level = "month")


data("sample_extent_data")
user.email&lt;-as.character(gargle::gargle_oauth_sitrep()$email)

extract_dynamic_raster(dates = dates,
                      datasetname = "UCSB-CHG/CHIRPS/DAILY",
                      bandname="precipitation",
                      user.email = user.email,
                      spatial.res.metres = 5566,
                      GEE.math.fun = "sum",
                      temporal.direction = "prior",
                      temporal.res = 56,
                      spatial.ext = sample_extent_data,
                      varname = "total_annual_precipitation_prior",
                      save.directory = tempdir())




</code></pre>

<hr>
<h2 id='extract_static_coords'>Extract explanatory variables from static rasters</h2><span id='topic+extract_static_coords'></span>

<h3>Description</h3>

<p>Explanatory variable data are extracted from static environmental rasters at
record co-ordinate or across moving window matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_static_coords(
  occ.data,
  varnames,
  extraction.method = "simple",
  static.rasters,
  moving.window.matrix,
  GEE.math.fun
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_static_coords_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates
and dates with column names as follows; record longitude as &quot;x&quot;, latitude as
&quot;y&quot;, and associated explanatory variable data.</p>
</td></tr>
<tr><td><code id="extract_static_coords_+3A_varnames">varnames</code></td>
<td>
<p>a character string or vector, the unique names for each
explanatory variable in order of layers in the SpatRaster.</p>
</td></tr>
<tr><td><code id="extract_static_coords_+3A_extraction.method">extraction.method</code></td>
<td>
<p>a character string or vector, the methods to extract
data from SpatRaster using <code>terra</code> package <code>extract</code> function. One of <code>simple</code>
or <code>bilinear</code>. If <code>simple</code> values for the cell a point falls in are
returned. If <code>bilinear</code> the returned values are interpolated from the values
of the four nearest raster cells.</p>
</td></tr>
<tr><td><code id="extract_static_coords_+3A_static.rasters">static.rasters</code></td>
<td>
<p>a <code>SpatRaster</code> containing one or more SpatRaster layers
to extract data from.</p>
</td></tr>
<tr><td><code id="extract_static_coords_+3A_moving.window.matrix">moving.window.matrix</code></td>
<td>
<p>optional; a matrix of weights with an odd number
of sides, representing the spatial neighbourhood of cells (“moving
window”) to calculate <code>GEE.math.fun</code> across from record co-ordinate. See
details for more information.</p>
</td></tr>
<tr><td><code id="extract_static_coords_+3A_gee.math.fun">GEE.math.fun</code></td>
<td>
<p>optional; a character string, the mathematical function to
compute across the specified spatial matrix for each record.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function to extract data from static rasters either at occurrence
record co-ordinates or spatially buffered using a moving window matrix.
</p>
<p>Note:
</p>

<ul>
<li> <p><code>varnames</code> must be in the order of raster layers within the SpatRaster.
</p>
</li>
<li> <p><code>extraction.method</code> must be of length one to apply to all layers, or
length equal to the number of layers in <code>static.rasters</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>Returns the occurrence data frame with added columns for extracted
data.
</p>


<h3>Spatial buffering (optional)</h3>

<p>Using the <code>focal</code> function from <code>terra</code> R package (Hijmans et al., 2022),
<code>GEE.math.fun</code> is calculated across the spatial buffer area from the record
co-ordinate. The spatial buffer area used is specified by the argument
<code>moving.window.matrix</code>, which dictates the neighbourhood of cells
surrounding the cell containing the occurrence record to include in this
calculation.
</p>
<p>See function <code>get_moving_window()</code> to generate appropriate
<code>moving.window.matrix</code>.
</p>


<h3>Mathematical function</h3>

<p><code>GEE.math.fun</code> specifies the mathematical function to be calculated over the
spatial buffered area and temporal period. Options are limited to Google
Earth Engine ImageCollection Reducer functions
(<a href="https://developers.google.com/earth-engine/apidocs/">https://developers.google.com/earth-engine/apidocs/</a>) for which an
analogous R function is available. This includes: &quot;allNonZero&quot;,&quot;anyNonZero&quot;,
&quot;count&quot;, &quot;first&quot;,&quot;firstNonNull&quot;, &quot;last&quot;, &quot;lastNonNull&quot;, &quot;max&quot;,&quot;mean&quot;,
&quot;median&quot;,&quot;min&quot;, &quot;mode&quot;,&quot;product&quot;, &quot;sampleStdDev&quot;, &quot;sampleVariance&quot;,
&quot;stdDev&quot;, &quot;sum&quot; and &quot;variance&quot;.
</p>


<h3>References</h3>

<p>Hijmans, R.J., Bivand, R., Forner, K., Ooms, J., Pebesma, E. and Sumner, M.D.,
2022. Package ‘terra’. Maintainer: Vienna, Austria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("sample_explan_data")
random_cat_layer &lt;- terra::rast(sample_extent_data)
random_cat_layer &lt;- terra::setValues(random_cat_layer,
                                    sample(0:10, terra::ncell(random_cat_layer),
                                           replace = TRUE))

extract_static_coords(occ.data = sample_explan_data,
                     varnames = "random_cat_layer",
                     static.rasters = random_cat_layer)


</code></pre>

<hr>
<h2 id='get_moving_window'>Generate a “moving window” matrix of optimal size</h2><span id='topic+get_moving_window'></span>

<h3>Description</h3>

<p>Calculates an optimal “moving window” matrix size for use when extracting spatially buffered
explanatory variables, by using the radius of interest and spatial resolution of environmental
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_moving_window(
  radial.distance,
  spatial.res.degrees,
  spatial.res.metres,
  spatial.ext
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_moving_window_+3A_radial.distance">radial.distance</code></td>
<td>
<p>a numeric value, the radius of interest in metres.</p>
</td></tr>
<tr><td><code id="get_moving_window_+3A_spatial.res.degrees">spatial.res.degrees</code></td>
<td>
<p>a numeric value, the spatial resolution in degrees of explanatory
variable data.</p>
</td></tr>
<tr><td><code id="get_moving_window_+3A_spatial.res.metres">spatial.res.metres</code></td>
<td>
<p>a numeric value, the spatial resolution in metres of explanatory
variable data.</p>
</td></tr>
<tr><td><code id="get_moving_window_+3A_spatial.ext">spatial.ext</code></td>
<td>
<p>the spatial extent of the study. Object from which extent
can be extracted of class <code>SpatExtent</code>, <code>SpatRaster</code>, <code>sf</code> polygon or
numeric vector listing xmin, xmax, ymin and ymax in order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns &quot;moving window&quot; matrix with an odd number of sides and equal weights.
</p>


<h3>Importance for other functions in <code>dynamicSDM</code> To extract spatially buffered explanatory</h3>

<p>variable data using dynamicSDM functions <code>extract_buffered_coords()</code> or
<code>extract_buffered_raster()</code>, a “moving window” matrix specifying the neighbourhood of cells to
include in the calculation is required.
</p>
<p>For example, by using a three by three “moving window” matrix of equal weights, the explanatory
variable would be calculated across the nine grid cells neighbouring the cell of interest and the
cell of interest.
</p>


<h3>Why use a moving window matrix instead of circular buffer?</h3>

<p>The benefit of using a “moving window” over calculating explanatory
variable values across a set radius from each record co-ordinate, is that when
generating projection rasters at high spatial and temporal resolution, these
can be generated much faster as the “moving windows” standardise the
calculation.
</p>


<h3>Function calculation</h3>


<ul>
<li> 

<ol>
<li><p> To calculate the “moving window” matrix size, the <code>get_moving_window()</code> function first
calculates the circular area of interest, using the user-specified radius of interest and the
equation for area of a circle.
</p>
</li></ol>

</li></ul>

<p>This radius should be chosen to represent the radial distance from species occurrence record
co-ordinates that the explanatory variable data might be relevant and impact species presence.
</p>

<ul>
<li> 

<ol>
<li><p> Then, the average grid cell area of the explanatory variable data (derived from user-provided
spatial resolution and extent) is calculated. If <code>spatial.res.degrees</code> is given then <code>spatial.ext</code>
is required to calculate average cell area size. If <code>spatial.res.metres</code> is given then average
cell area is calculated by squaring this value to get cell area in square metres.
</p>
</li></ol>

</li>
<li> 

<ol>
<li><p> Finally, the function then calculates the optimal “moving window” matrix that best matches
circular area of interest with the “moving window” matrix area. The matrix of weights will have an
odd number of sides.
</p>
</li></ol>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>get_moving_window(radial.distance = 100000, spatial.res.metres = 111320)

</code></pre>

<hr>
<h2 id='sample_cov_data'>Sample projection covariates three variables across for southern Africa.</h2><span id='topic+sample_cov_data'></span>

<h3>Description</h3>

<p>Data frame of co-ordinates and associated dynamic explanatory variable values for &quot;2018-04-01&quot;
cropped to southern Africa at 2 degree resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_cov_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 225 rows and 6 variables
</p>

<dl>
<dt>X</dt><dd><p>row name</p>
</dd>
<dt>x</dt><dd><p>grid cell longitude</p>
</dd>
<dt>y</dt><dd><p>grid cell latitude</p>
</dd>
<dt>eight_sum_prec</dt><dd><p>sum Climate Hazards Group InfraRed Precipitation With Station Data
(Funk et al., 2015) total daily precipitation at record co-ordinate across 52-weeks prior to
&quot;2018-04-01&quot; (mm).</p>
</dd>
<dt>grass_crop_percentage</dt><dd><p>total number of MODIS Land Cover Type Yearly 500m (Friedl et al.,
2019) &quot;cereal cropland&quot; and &quot;grassland&quot; cells in surrounding area of record co-ordinate in
2018.</p>
</dd>
<dt>year_sum_prec</dt><dd><p>sum Climate Hazards Group InfraRed Precipitation With Station Data (Funk
et al., 2015) total daily precipitation at record co-ordinate across 52-weeks prior to
&quot;2018-04-01&quot; (mm).</p>
</dd>
</dl>



<h3>References</h3>

<p>Friedl, M., Sulla-Menashe, D. (2019). MCD12Q1 MODIS/Terra+Aqua Land Cover Type Yearly L3 Global
500m SIN Grid V006. NASA EOSDIS Land Processes DAAC. Accessed 2022-11-24 from
</p>
<p>Funk, Chris, Pete Peterson, Martin Landsfeld, Diego Pedreros, James Verdin, Shraddhanand Shukla,
Gregory Husak, James Rowland, Laura Harrison, Andrew Hoell &amp; Joel Michaelsen. &quot;The climate
hazards infrared precipitation with stations-a new environmental record for monitoring extremes&quot;.
Scientific Data 2, 150066.
</p>

<hr>
<h2 id='sample_events_data'>Sample e-Bird sampling event records</h2><span id='topic+sample_events_data'></span>

<h3>Description</h3>

<p>A dataset containing a sample of e-Bird sampling events for all bird species across southern
Africa between 2000-2020 (Fink et al., 2021, GBIF, 2021).
The variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_events_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows and 5 variables:
</p>

<dl>
<dt>day</dt><dd><p>avian e-Bird sampling event day.</p>
</dd>
<dt>month</dt><dd><p>avian e-Bird sampling event month.</p>
</dd>
<dt>year</dt><dd><p>avian e-Bird sampling event year.</p>
</dd>
<dt>y</dt><dd><p>avian e-Bird sampling event latitude.</p>
</dd>
<dt>x</dt><dd><p>avian e-Bird sampling event longitude.</p>
</dd>
</dl>



<h3>References</h3>

<p>Fink, D., T. Auer, A. Johnston, M. Strimas-Mackey, O. Robinson, S. Ligocki, W. Hochachka, L.
Jaromczyk, C. Wood, I. Davies, M. Iliff, L. Seitz. 2021. eBird Status and Trends, Data Version:
2020; Released: 2021. Cornell Lab of Ornithology, Ithaca, New York.
<a href="https://doi.org/10.2173/ebirdst.2020">doi:10.2173/ebirdst.2020</a>
</p>
<p>GBIF.org (12 July 2021) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.ppcu6q">doi:10.15468/dl.ppcu6q</a>
</p>

<hr>
<h2 id='sample_explan_data'>Sample species occurrence records with associated dynamic explanatory variables</h2><span id='topic+sample_explan_data'></span>

<h3>Description</h3>

<p>A dataset containing a sample of the bird species, the red-billed quelea (Quelea
quelea), distribution records from between 2002-2019 (GBIF 2021, GBIF 2022); generated
pseudo-absence records, and associated extracted dynamic explanatory variables. The variables
are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_explan_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 330 rows and 17 variables:
</p>

<dl>
<dt>x</dt><dd><p>species occurrence record longitude.</p>
</dd>
<dt>y</dt><dd><p>species occurrence record latitude.</p>
</dd>
<dt>year</dt><dd><p>species occurrence record year.</p>
</dd>
<dt>month</dt><dd><p>species occurrence record month.</p>
</dd>
<dt>day</dt><dd><p>species occurrence record day.</p>
</dd>
<dt>decimalLatitude</dt><dd><p>species occurrence record latitude.</p>
</dd>
<dt>decimalLongitude</dt><dd><p>species occurrence record longitude.</p>
</dd>
<dt>occurrenceStatus</dt><dd><p>species presence or absence character.</p>
</dd>
<dt>source</dt><dd><p>source of occurrence or pseudo-absence data point.</p>
</dd>
<dt>species</dt><dd><p>name of species occurrence records belong to name</p>
</dd>
<dt>SAMP_EFFORT</dt><dd><p>total number of avian e-Bird sampling events within spatiotemporal buffer of
occurrence record location and dates.</p>
</dd>
<dt>REL_SAMP_EFFORT</dt><dd><p>proportion of total number of avian e-Bird sampling events within
spatiotemporal buffer of occurrence record location and dates relative to other records</p>
</dd>
<dt>unique.ID.DYN</dt><dd><p>unique id value assigned when extracting dynamic explanatory variable
data</p>
</dd>
<dt>eight_sum_prec</dt><dd><p>sum Climate Hazards Group InfraRed Precipitation With Station Data (Funk
et al., 2016) total daily precipitation at record co-ordinate across 52-weeks prior to record
date (mm).</p>
</dd>
<dt>grass_crop_percentage</dt><dd><p>total number of MODIS Land Cover Type Yearly 500m (Friedl &amp;
Sulla-Menashe, 2019) &quot;cereal cropland&quot; and &quot;grassland&quot; cells in surrounding area of record
co-ordinate in record year.</p>
</dd>
<dt>year_sum_prec</dt><dd><p>sum Climate Hazards Group InfraRed Precipitation With Station Data (CHIRPS
Daily) total daily precipitation at record co-ordinate across 52-weeks prior to record date
(mm).</p>
</dd>
<dt>presence.absence</dt><dd><p>binary species presence or absence at record location and date.</p>
</dd>
</dl>



<h3>References</h3>

<p>Friedl, M., Sulla-Menashe, D. (2019). MCD12Q1 MODIS/Terra+Aqua Land Cover Type Yearly L3 Global
500m SIN Grid V006. NASA EOSDIS Land Processes DAAC.
</p>
<p>Funk, Chris, Pete Peterson, Martin Landsfeld, Diego Pedreros, James Verdin, Shraddhanand Shukla,
Gregory Husak, James Rowland, Laura Harrison, Andrew Hoell &amp; Joel Michaelsen. &quot;The climate
hazards infrared precipitation with stations-a new environmental record for monitoring extremes&quot;.
Scientific Data 2, 150066. doi:10.1038/sdata.2015.66 2015.
</p>
<p>GBIF.org (12 July 2021) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.ppcu6q">doi:10.15468/dl.ppcu6q</a>
</p>
<p>GBIF.org (25 July 2022) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.k2kftv">doi:10.15468/dl.k2kftv</a>
</p>

<hr>
<h2 id='sample_extent_data'>MULTIPOLYGON object for the extent of southern Africa</h2><span id='topic+sample_extent_data'></span>

<h3>Description</h3>

<p>A MULTIPOLYGON (package &quot;sf&quot;) object containing polygons for each country within southern Africa.
The variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_extent_data
</code></pre>


<h3>Format</h3>

<p>A simple feature collection with 10 features and 1 field.
</p>

<dl>
<dt>geometry</dt><dd><p>MULTIPOLYGON object co-ordinates for country boundaries.</p>
</dd>
<dt>name</dt><dd><p>name of country the polygon represents.</p>
</dd>
</dl>


<hr>
<h2 id='sample_filt_data'>Sample of filtered species occurrence records</h2><span id='topic+sample_filt_data'></span>

<h3>Description</h3>

<p>A dataset containing a sample of the bird species, the red-billed quelea (Quelea quelea),
distribution records (GBIF 2021 &amp; GBIF 2022) that have been filtered to special extent of
southern Africa and quality checked using <code>dynamicSDM</code> functions.
The variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_filt_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 330 rows and 12 variables:
</p>

<dl>
<dt>x</dt><dd><p>species occurrence record x</p>
</dd>
<dt>y</dt><dd><p>species occurrence record y</p>
</dd>
<dt>year</dt><dd><p>species occurrence record year.</p>
</dd>
<dt>month</dt><dd><p>species occurrence record month.</p>
</dd>
<dt>day</dt><dd><p>species occurrence record day.</p>
</dd>
<dt>decimalLatitude</dt><dd><p>species occurrence record latitude.</p>
</dd>
<dt>decimalLongitude</dt><dd><p>species occurrence record longitude.</p>
</dd>
<dt>occurrenceStatus</dt><dd><p>species presence or absence character.</p>
</dd>
<dt>source</dt><dd><p>source of occurrence or pseudo-absence data point.</p>
</dd>
<dt>species</dt><dd><p>name of species occurrence records belong to name</p>
</dd>
<dt>SAMP_EFFORT</dt><dd><p>total number of avian e-Bird sampling events within spatiotemporal buffer of
occurrence record location and dates.</p>
</dd>
<dt>REL_SAMP_EFFORT</dt><dd><p>proportion of total number of avian e-Bird sampling events within
spatiotemporal buffer of occurrence record location and dates relative to other records</p>
</dd>
</dl>



<h3>References</h3>

<p>GBIF.org (12 July 2021) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.ppcu6q">doi:10.15468/dl.ppcu6q</a>
</p>
<p>GBIF.org (25 July 2022) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.k2kftv">doi:10.15468/dl.k2kftv</a>
</p>

<hr>
<h2 id='sample_occ_data'>Sample species occurrence records</h2><span id='topic+sample_occ_data'></span>

<h3>Description</h3>

<p>A dataset containing a sample of the bird species, the red-billed quelea (Quelea quelea),
distribution records between 1976-2021 (GBIF 2021 &amp; GBIF 2022).
The variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_occ_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 600 rows and 7 variables:
</p>

<dl>
<dt>year</dt><dd><p>species occurrence record year.</p>
</dd>
<dt>month</dt><dd><p>species occurrence record month.</p>
</dd>
<dt>day</dt><dd><p>species occurrence record day.</p>
</dd>
<dt>decimalLatitude</dt><dd><p>species occurrence record latitude.</p>
</dd>
<dt>decimalLongitude</dt><dd><p>species occurrence record longitude.</p>
</dd>
<dt>occurrenceStatus</dt><dd><p>species presence or absence character.</p>
</dd>
<dt>source</dt><dd><p>source of occurrence or pseudo-absence data point.</p>
</dd>
</dl>



<h3>References</h3>

<p>GBIF.org (12 July 2021) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.ppcu6q">doi:10.15468/dl.ppcu6q</a>
</p>
<p>GBIF.org (25 July 2022) GBIF Occurrence Download <a href="https://doi.org/10.15468/dl.k2kftv">doi:10.15468/dl.k2kftv</a>
</p>

<hr>
<h2 id='spatiotemp_autocorr'>Test for spatial and temporal autocorrelation in species distribution model explanatory data.</h2><span id='topic+spatiotemp_autocorr'></span>

<h3>Description</h3>

<p>Function performs statistical tests to assess spatial and temporal autocorrelation in given
explanatory variable data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_autocorr(
  occ.data,
  varname,
  temporal.level,
  plot = FALSE,
  prj = "+proj=longlat +datum=WGS84"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_autocorr_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot; and associated explanatory data.</p>
</td></tr>
<tr><td><code id="spatiotemp_autocorr_+3A_varname">varname</code></td>
<td>
<p>a character string or vector, the name(s) of the columns within <code>occ.data</code>
containing data to test for autocorrelation.</p>
</td></tr>
<tr><td><code id="spatiotemp_autocorr_+3A_temporal.level">temporal.level</code></td>
<td>
<p>a character string or vector, the time step(s) to test for temporal
autocorrelation at. One or multiple of <code>day</code> or <code>month</code>, <code>year</code>. Can be abbreviated.</p>
</td></tr>
<tr><td><code id="spatiotemp_autocorr_+3A_plot">plot</code></td>
<td>
<p>a logical indicating whether to generate plot of temporal autocorrelation. See details
for plot description. Default = <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_autocorr_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of occurrence data.
Default is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To test for temporal autocorrelation, the function first calculates the average value
across records for each time step (<code>temporal.level</code>). The correlation between the average value
at one time point (t) and the value at the previous time point (t-1) is calculated and plotted
(if <code>plot</code> = TRUE) A significant relationship between values at consecutive data points
indicates temporal autocorrelation is present.
</p>
<p>To test for spatial autocorrelation, the function calculates a distance matrix between all
record co-ordinates. Moran’s I statistical test is calculated to test whether points closer in
space have more similar values than those more distant from each other(Legendre, 1993). Please
note that NA values are removed before Moran's I calculation.
</p>
<p>As the spatial autocorrelation calculation involves computation of a distance matrix between all
occurrence records. To reduce computation time, it is recommended that a sample of large
occurrence datasets are input.
</p>


<h3>Value</h3>

<p>Returns a list of temporal and spatial autocorrelation test results for each variable.
</p>


<h3>References</h3>

<p>Legendre, P. J. E. 1993. Spatial Autocorrelation: Trouble Or New Paradigm? 74, 1659-1673.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sample_explan_data")
spatiotemp_autocorr(sample_explan_data,
                   varname = c("year_sum_prec","eight_sum_prec"),
                   temporal.level = c("year","month","day"))
</code></pre>

<hr>
<h2 id='spatiotemp_bias'>Test for spatial and temporal bias in species occurrence records</h2><span id='topic+spatiotemp_bias'></span>

<h3>Description</h3>

<p>Generates plots for visual assessment of spatial and temporal biases in occurrence records. Tests
whether the spatiotemporal distribution of records is significantly different from the
distribution from random sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_bias(
  occ.data,
  temporal.level,
  plot = FALSE,
  spatial.method = "simple",
  centroid,
  radius,
  prj = "+proj=longlat +datum=WGS84"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_bias_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_bias_+3A_temporal.level">temporal.level</code></td>
<td>
<p>a character string or vector, the time step(s) to test for temporal bias at.
One or multiple of <code>day</code> or <code>month</code>, <code>year.</code> Can be abbreviated.</p>
</td></tr>
<tr><td><code id="spatiotemp_bias_+3A_plot">plot</code></td>
<td>
<p>a logical indicating whether to generate plots of spatial and temporal bias. See
details for plot descriptions. Default = <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_bias_+3A_spatial.method">spatial.method</code></td>
<td>
<p>a character string, the method to calculate the spatial bias statistic. One
of; <code>simple</code>, <code>convex_hull</code> or <code>core</code>. See details.</p>
</td></tr>
<tr><td><code id="spatiotemp_bias_+3A_centroid">centroid</code></td>
<td>
<p>a numeric vector of length two, specifying the centroid co-ordinates in the order
of longitude then latitude. Only required if <code>spatial.method</code> = <code>core.</code> Default is mean of all
occurrence record co-ordinates.</p>
</td></tr>
<tr><td><code id="spatiotemp_bias_+3A_radius">radius</code></td>
<td>
<p>a numeric value, the radial distance in metres from the given centroid co-ordinate
to measure spatial bias within. Only required if <code>spatial.method</code> = <code>core.</code> See details for more
information. Default is mean distance of all co-ordinates from <code>centroid</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_bias_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of occ.data co-ordinates. Default
is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns list containing chi-squared and t-test results, and plots if specified.
</p>


<h3>Temporal bias</h3>

<p>To assess temporal sampling bias, the function returns a histogram plot
of the frequency distribution of records across the given time step specified by <code>temporal.level</code>
(if <code>plot = TRUE</code>). The observed frequency of sampling across the categorical time steps are
compared to the distribution expected from random sampling, using a chi-squared test (Greenwood
and Nikulin, 1996) .
</p>


<h3>Spatial bias</h3>

<p>To assess spatial sampling bias, the function returns a scatter plot of the spatial
distribution of occurrence records to illustrate any spatial clustering (if <code>plot = TRUE</code>). The
average nearest neighbour distance of record co-ordinates is then compared to that of records
randomly generated at same density using a t-test, following the nearest neighbour index
established by Clark and Evans (1954).
</p>


<h3>Bias: methods</h3>

<p>Below we outline the methods for which these tests for biases can be applied. <code>dynamicSDM</code> offers
the additional functionality of the <code>core</code> approach. This enables users to explore sampling biases
in set areas of a species range. This may be valuable if periphery-core relationships could lead
to inaccurate inferences of sampling bias. For instance, if species are expanding or shifting
their ranges through space and time.
#'
</p>

<ul>
<li> <p><code>simple</code> - generates the random points within a rectangle created using
the minimum and maximum longitude and latitude of occurrence co-ordinates.
</p>
</li>
<li> <p><code>convex_hull</code> - generates the random points within the convex hull of occurrence record
co-ordinates (i.e. the smallest convex set that contains all records).
</p>
</li>
<li> <p><code>core</code> - generates the random points within specified circular area generated from a centroid
point and radius. If these arguments ( <code>centroid</code> and <code>radius</code>) are not provided then <code>centroid</code>
is calculated by averaging co-ordinates of all occurrence records, and <code>radius</code> is the mean
distance away of all records from the centroid.
</p>
</li></ul>

<p>For each method, only occurrence records within the specified area are tested for spatial and
temporal sampling biases.
</p>


<h3>Computation time</h3>

<p>As the spatial bias test involves the calculation of a distance matrix. To reduce computation
time, it is recommended that only a representative sample of large occurrence datasets are input.
</p>


<h3>References</h3>

<p>Clark, P. J. &amp; Evans, F. C. J. E. 1954. Distance To Nearest Neighbor As A Measure Of Spatial
Relationships In Populations. 35, 445-453.
</p>
<p>Greenwood, P. E. &amp; Nikulin, M. S. 1996. A Guide To Chi-Squared Testing, John Wiley &amp; Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(sample_explan_data)

bias_simple &lt;- spatiotemp_bias(
occ.data = sample_explan_data,
temporal.level = c("year"),
spatial.method = "simple",
plot = FALSE
)

</code></pre>

<hr>
<h2 id='spatiotemp_block'>Split occurrence records into spatial and temporal blocks for model fitting.</h2><span id='topic+spatiotemp_block'></span>

<h3>Description</h3>

<p>Splits occurrence records into spatial and temporal sampling units and groups sampling units into
multiple blocks that have similar mean and range of environmental explanatory variables and sample
size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_block(
  occ.data,
  vars.to.block.by,
  spatial.layer,
  spatial.split.degrees,
  temporal.block,
  n.blocks = 10,
  iterations = 5000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_block_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;, and associated explanatory variable data.</p>
</td></tr>
<tr><td><code id="spatiotemp_block_+3A_vars.to.block.by">vars.to.block.by</code></td>
<td>
<p>a character string or vector, the explanatory variable column names to
group sampling units based upon.</p>
</td></tr>
<tr><td><code id="spatiotemp_block_+3A_spatial.layer">spatial.layer</code></td>
<td>
<p>optional; a <code>SpatRaster</code> object, a categorical spatial layer for sample
unit splitting.</p>
</td></tr>
<tr><td><code id="spatiotemp_block_+3A_spatial.split.degrees">spatial.split.degrees</code></td>
<td>
<p>a numeric value, the grid cell resolution in degrees to split
<code>spatial.layer</code> by. Required if <code>spatial.layer</code> given.</p>
</td></tr>
<tr><td><code id="spatiotemp_block_+3A_temporal.block">temporal.block</code></td>
<td>
<p>optional; a character string or vector, the time step for sampling unit
splitting. Any combination of <code>day</code>, <code>month</code>, <code>year</code> or <code>quarter.</code> See details.</p>
</td></tr>
<tr><td><code id="spatiotemp_block_+3A_n.blocks">n.blocks</code></td>
<td>
<p>optional; a numeric value of two or more, the number of blocks to group
occurrence records into. Default; 10.</p>
</td></tr>
<tr><td><code id="spatiotemp_block_+3A_iterations">iterations</code></td>
<td>
<p>optional; a numeric value, the number of random block groupings to trial before
selecting the optimal grouping. Default; 5000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns occurrence data frame with column &quot;BLOCK.CATS&quot;, assigning each record to a
spatiotemporal block.
</p>


<h3>Blocking for autocorrelation</h3>

<p>Blocking is an established method to account for spatial autocorrelation in SDMs. Following Bagchi
et al., (2013), the blocking method involves splitting occurrence data into sampling units based
upon non-contiguous ecoregions, which are then grouped into spatially disaggregated blocks of
approximately equal sample size, within which the mean and range of explanatory variable data are
similar. When species distribution model fitting, blocks are left out in-turn in a jack-knife
approach for model training and testing.
</p>
<p>We adapt this approach to account for temporal autocorrelation by enabling users to split records
into sampling units based upon spatial and temporal characteristic before blocking occurs.
</p>


<h3>Spatial splitting</h3>

<p>If the <code>spatial.layer</code> has categories that take up large contiguous areas,
<code>spatiotemp_block()</code> will split categories into smaller units using grid cells at specified
resolution (<code>spatial.split.degrees</code>).
</p>


<h3>Temporal splitting</h3>

<p>If <code>temporal.block</code> is given, then occurrence records with unique values for the given level are
considered unique sampling unit. For instance, if <code>temporal.block</code> = <code>year</code>, then records from the
same year are considered a sampling unit to be grouped into blocks.
</p>
<p>Note: If spatial splitting is also used, then spatial characteristics may split these further into
separate sampling units.
</p>
<p>The <code>temporal.block</code> option <code>quarter</code> splits occurrence records into sampling units based on which
quarter of the year the record month belongs to: (1) January-March, (2) April-June, (3)
July-September and (4) October-December. This could be employed if seasonal biases in occurrence
record collection are driving autocorrelation.
</p>


<h3>Block generation</h3>

<p>Once split into sampling units based upon temporal and spatial characteristics, these units are
then assigned into given number of blocks (<code>n.blocks</code>), so that the mean and range of explanatory
variables (<code>vars.to.block.by</code>) and total sample size are similar across each. The number of
<code>iterations</code> specifies how many random shuffles are used to optimise block equalisation.
</p>


<h3>References</h3>

<p>Bagchi, R., Crosby, M., Huntley, B., Hole, D. G., Butchart, S. H. M., Collingham, Y.,
Kalra, M., Rajkumar, J., Rahmani, A. &amp; Pandey, M. 2013. Evaluating the effectiveness of
conservation site networks under climate change: accounting for uncertainty. Global Change
Biology, 19, 1236-1248.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("sample_explan_data")
data("sample_extent_data")
random_cat_layer &lt;- terra::rast(sample_extent_data)
random_cat_layer &lt;- terra::setValues(random_cat_layer,
                                    sample(0:10, terra::ncell(random_cat_layer),
                                           replace = TRUE))

spatiotemp_block(
 occ.data = sample_explan_data,
 spatial.layer = random_cat_layer,
 spatial.split.degrees = 3,
 temporal.block = c("month"),
 vars.to.block.by = colnames(sample_explan_data)[14:16],
 n.blocks = 3,
 iterations = 30
)

</code></pre>

<hr>
<h2 id='spatiotemp_check'>Check species occurrence record formatting, completeness and validity.</h2><span id='topic+spatiotemp_check'></span>

<h3>Description</h3>

<p>Checks the occurrence record data frame contains the column names and classes required for
dynamicSDM functions. Option to exclude records containing missing, duplicate or invalid
co-ordinates or dates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_check(
  occ.data,
  na.handle,
  duplicate.handle,
  coord.handle,
  date.handle,
  date.res,
  coordclean = FALSE,
  coordclean.species = "species_1",
  coordclean.handle = "exclude",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_check_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_na.handle">na.handle</code></td>
<td>
<p>a character string, method for handling missing data (NA values) in record
co-ordinates and dates. One of <code>exclude</code> or <code>ignore</code>: can be abbreviated. Default; <code>exclude</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_duplicate.handle">duplicate.handle</code></td>
<td>
<p>a character string, method for handling duplicate record co-ordinates or
dates. One of <code>exclude</code> or <code>ignore</code>: can be abbreviated. Default; <code>exclude</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_coord.handle">coord.handle</code></td>
<td>
<p>a character string, method for handling invalid co-ordinates in record data.
One of <code>exclude</code> or <code>ignore</code>: can be abbreviated. Default; <code>exclude</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_date.handle">date.handle</code></td>
<td>
<p>a character string, method for handling invalid dates in record data. One of
<code>exclude</code> or <code>ignore</code>: can be abbreviated. Default; <code>exclude</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_date.res">date.res</code></td>
<td>
<p>a character string, stating the temporal resolution to complete checks on. One of
<code>year</code>, <code>month</code> or <code>day</code>. If not given, dates are not checked.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_coordclean">coordclean</code></td>
<td>
<p>a logical indicating whether to run function
<code>clean_coordinates</code> from package <code>CoordinateCleaner</code> on <code>occ.data</code>. Default = FALSE.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_coordclean.species">coordclean.species</code></td>
<td>
<p>a character string or vector, specifying the name of the species that
all of <code>occ.data</code> records belong to, or a character vector the length of <code>nrow(occ.data)</code>
specifying which species each record belongs to. Required if <code>coordclean</code> = TRUE.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_coordclean.handle">coordclean.handle</code></td>
<td>
<p>a character string, method for handling records flagged by
<code>CoordinateCleaner</code>. One of <code>exclude</code> or <code>report</code>. Default: exclude.</p>
</td></tr>
<tr><td><code id="spatiotemp_check_+3A_...">...</code></td>
<td>
<p>Other arguments passed onto <code>CoordinateCleaner</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>By default, returns occurrence record data frame, filtered to exclude records containing
missing, duplicate or invalid data in record co-ordinates and dates.
</p>


<h3><code>date.res</code> argument</h3>

<p>The <code>date.res</code> states the temporal resolution to check dates, including when searching for
duplicate records, removing records with NA values and checking for invalid dates.
</p>


<h3>Validity checks</h3>

<p>Record dates and co-ordinates are checked for validity using the following rules:
</p>

<ul>
<li><p> Dates must be real dates that could exist. For example, 50th February 2000 is not a valid date.
</p>
</li>
<li><p> Co-ordinates must have longitude (x) values between -180 and 180, and latitude (y) values
between -90 and 90 to be considered valid.
</p>
</li></ul>



<h3><code>CoordinateCleaner</code> compatibility</h3>

<p><code>spatiotemp_check()</code> acts as a helper function for compatibility with the R package
<code>CoordinateCleaner</code> (Zizka et al., 2019), which offers a diversity of functions for checking the
co-ordinates of occurrence records.
</p>
<p>If <code>coordclean</code> = TRUE, then <code>coordclean.species</code> must be provided to identify which species each
record belonds to. If <code>coordclean.handle</code> = <code>exclude</code> then all <code>occ.data</code> records flagged by
<code>CoordinateCleaner::clean_coordinates()</code> as potentially erroneous are removed in the returned
data.
</p>
<p>If  <code>coordclean.handle</code> = <code>report</code>, then the occurrence data frame is returned with an additional
<code>CC_REPORT</code> column. This column contains the output from
<code>CoordinateCleaner::clean_coordinates()</code> which indicates the potentially erroneous records.
</p>


<h3>References</h3>

<p>Zizka A, Silvestro D, Andermann T, Azevedo J, Duarte Ritter C, Edler D, Farooq H,
Herdean A, Ariza M, Scharn R, Svanteson S, Wengstrom N, Zizka V, Antonelli A (2019).
“CoordinateCleaner: standardized cleaning of occurrence records from biological collection
databases.” Methods in Ecology and Evolution, -7. <a href="https://doi.org/10.1111/2041-210X.13152">doi:10.1111/2041-210X.13152</a>, R package version
2.0-20, <a href="https://github.com/ropensci/CoordinateCleaner">https://github.com/ropensci/CoordinateCleaner</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sample_occ_data)
sample_occ_data&lt;-convert_gbif(sample_occ_data)

nrow(sample_occ_data)

filtered&lt;-spatiotemp_check(
 occ.data = sample_occ_data,
 coord.handle = "exclude",
 date.handle = "exclude",
 duplicate.handle = "exclude",
 na.handle = "exclude"
)
nrow(filtered)


filtered_CC&lt;-spatiotemp_check(
 occ.data = sample_occ_data,
 coord.handle = "exclude",
 date.handle = "exclude",
 duplicate.handle = "exclude",
 na.handle = "exclude",
 coordclean = TRUE,
 coordclean.species = "quelea",
 coordclean.handle = "exclude"
)
nrow(filtered_CC)


</code></pre>

<hr>
<h2 id='spatiotemp_extent'>Filter species occurrence records by a given spatial and temporal extent.</h2><span id='topic+spatiotemp_extent'></span>

<h3>Description</h3>

<p>Function excludes species occurrence records with co-ordinates outside a given spatial extent and
record dates outside a given temporal extent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_extent(
  occ.data,
  temporal.ext,
  spatial.ext,
  prj = "+proj=longlat +datum=WGS84"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_extent_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_extent_+3A_temporal.ext">temporal.ext</code></td>
<td>
<p>optional; a character vector, two dates in format &quot;YYYY-MM-DD&quot;. First date
represents start of temporal extent and second date represents end of temporal extent for
inclusion.</p>
</td></tr>
<tr><td><code id="spatiotemp_extent_+3A_spatial.ext">spatial.ext</code></td>
<td>
<p>the spatial extent to filter by. Object from which extent
can be extracted of class <code>SpatExtent</code>, <code>SpatRaster</code>, <code>sf</code> polygon or
numeric vector listing xmin, xmax, ymin and ymax in order.</p>
</td></tr>
<tr><td><code id="spatiotemp_extent_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of input <code>occ.data</code> co-ordinates.
Default is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data frame of occurrence records filtered to the spatial and temporal extent
given.
</p>


<h3>Spatial extent</h3>

<p>If <code>spatial.ext</code> is provided, <code>spatiotemp_extent()</code> checks whether species occurrence record
co-ordinates are within the given spatial extent of the study (<code>spatial.ext</code>) and excludes any
outside of this extent.
</p>
<p>If <code>spatial.ext</code> object can be used as a mask by <code>terra::mask()</code> then the mask is used to filter
records in a more targeted way. If not, then the rectangular extent of the <code>spatial.ext</code> object
is used.
</p>


<h3>Temporal extent</h3>

<p>If <code>temporal.ext</code> is provided, <code>spatiotemp_extent()</code> checks whether species
occurrence record dates are within the given temporal extent of the study and excludes any outside
of this extent.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sample_filt_data)
data(sample_extent_data)

results &lt;- spatiotemp_extent(occ.data = sample_filt_data,
                            spatial.ext = sample_extent_data,
                            temporal.ext = c("2012-01-01", "2017-01-01"))

</code></pre>

<hr>
<h2 id='spatiotemp_pseudoabs'>Generate pseudo-absence record coordinates and dates</h2><span id='topic+spatiotemp_pseudoabs'></span>

<h3>Description</h3>

<p>Function generates specified number of pseudo-absence record co-ordinates and dates either
randomly or buffered in space and time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_pseudoabs(
  spatial.method,
  temporal.method,
  occ.data,
  spatial.ext,
  temporal.ext,
  spatial.buffer,
  temporal.buffer,
  n.pseudoabs = 100,
  prj = "+proj=longlat +datum=WGS84"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_pseudoabs_+3A_spatial.method">spatial.method</code></td>
<td>
<p>a character string, the spatial method for pseudo-absence generation. One of
<code>buffer</code> or <code>random</code>: can be abbreviated.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_temporal.method">temporal.method</code></td>
<td>
<p>a character string, the temporal method for pseudo-absence generation. One
of <code>buffer</code> or <code>random</code>: can be abbreviated.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_occ.data">occ.data</code></td>
<td>
<p>optional; a data frame, with columns for occurrence record co-ordinates and dates
with column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;. Required if either <code>temporal.method</code> or <code>spatial.method</code> is <code>buffer</code>.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_spatial.ext">spatial.ext</code></td>
<td>
<p>the spatial extent to randomly generate pseudo-absences
within. Object from which extent can be extracted of class <code>SpatExtent</code>,
<code>SpatRaster</code>, an <code>sf</code> polygon or a numeric vector listing xmin, xmax, ymin
and ymax in order. Required if <code>spatial.method</code> is <code>random</code>, and optionally
used if <code>buffer</code>. See details.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_temporal.ext">temporal.ext</code></td>
<td>
<p>optional; a character vector, two dates in format &quot;YYYY-MM-DD&quot;. The first
represents the start of the temporal extent and the second represents the end of temporal extent
to randomly generate pseudo-absences dates within. Required if <code>temporal.method</code> is <code>random</code>,
and optionally used if <code>buffer</code>. See details.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_spatial.buffer">spatial.buffer</code></td>
<td>
<p>optional; a numeric value or vector, the radius/radii in metres to generate
buffered pseudo-absence coordinates within. Only required if spatial.method is <code>buffer</code>. See
details.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_temporal.buffer">temporal.buffer</code></td>
<td>
<p>optional; a numeric value or vector, the period(s) in days to generate
buffered pseudo-absence dates within. Only required if temporal.method is <code>buffer</code> . See
details.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_n.pseudoabs">n.pseudoabs</code></td>
<td>
<p>optional; a numeric value, the number of pseudo-absence records to generate.
Default; 100.</p>
</td></tr>
<tr><td><code id="spatiotemp_pseudoabs_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of input <code>occ.data</code> co-ordinates.
Default is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Below we outline the various approaches to generating pseudo-absences through space and time
available in the dynamicSDM package. To select the appropriate pseudo-absence generation
approach and buffer size, there are many considerations. We recommend seeking the appropritae
literature to inform your decision when species distribution modelling (Barbet-Massin et al.,
2012, Phillips et al., 2009, Vanderwal et al., 2009).
</p>


<h3>Value</h3>

<p>Returns data frame of pseudo-absence coordinates and dates.
</p>


<h3>Spatial buffer</h3>

<p>If <code>spatial.method</code> is <code>buffer</code>, then the pseudo-absence record co-ordinates are randomly
generated in a buffered area defined either by
</p>

<ul>
<li><p> single numeric value for <code>spatial.buffer</code> - anywhere between the occurrence record and the
circular distance surrounding this point (as specified in metres).
</p>
</li>
<li><p> two numeric values for <code>spatial.buffer</code> - anywhere between the closest radius from the
occurrence record and the furthest away radius (as specified in metres).
</p>
</li></ul>

<p>For example, if <code>spatial.buffer = c(3000,10000)</code>, then pseudo-absence co-ordinates are randomly
generated at least 3000m radius away from occurrence record co-ordinate but within 10000m radius.
Whereas, if <code>spatial.buffer = 10000</code>, then pseudo-absence co-ordinates are randomly generated
anywhere between 0m and 10000m radius from the occurrence record.
</p>
<p>If <code>spatial.ext</code> is given too, then the generated pseudo-absences are not only constrained to the
buffered area but also to this extent. For instance, if occurrence records are coastal, you may
want to clip buffers to only terrestrial regions using a country polygon given in <code>spatial.ext</code>.
</p>


<h3>Spatial random</h3>

<p>If <code>spatial.method</code> is <code>random</code>, then the pseudo-absence record co-ordinates are randomly
generated across <code>spatial.ext</code> object given.
</p>
<p>If <code>spatial.ext</code> is a <code>sf</code> polygon or <code>SpatRaster</code> (mask if possible before
input) then these shapes are used, instead of a simple rectangular
extent (<code>SpatExtent</code>). Therefore, inputting one of these objects will allow for more specific pseudo-absence
generation.
</p>
<p>For example, inputting an <code>sf</code> polygon of a specific countries will ensure co-ordinates
are terrestrial, whereas an extent (xmin, xmax, ymin, ymax) that encompasses these countries may
result in the generation of pseudo-absence records in inappropriate areas, such as oceans or
non-study-area countries.
</p>


<h3>Temporal buffer</h3>

<p>If <code>temporal.method</code> is <code>buffer</code>, then pseudo-absence record dates are randomly generated between
in a period defined by:
</p>

<ul>
<li><p> single numeric value for temporal.buffer - any date between the occurrence record date and the
total number of days specified prior or post.
</p>
</li>
<li><p> two numeric values for temporal.buffer - any date between the closest and furthers away number
of days specified.
</p>
</li></ul>

<p>For example, if <code>temporal.buffer = c(14,30)</code>, then pseudo-absence dates randomly generated at
least 14 days from occurrence record dates but within 30 days. Whereas if <code>temporal.buffer = 30</code>,
pseudo-absence dates are randomly generated anywhere between 0 and 30 days prior or post the
occurrence record date.
</p>
<p>If <code>temporal.ext</code> is given too, then the generated pseudo-absence dates are not only constrained
to the buffer period but also to this temporal extent. For instance, an occurrence record recorded
at the start of <code>temporal.ext</code> with 7 day buffer, may result in generated pseudo-absences outside
of the temporal extent of the study.
</p>


<h3>Temporal random</h3>

<p>If <code>temporal.method</code> is <code>random</code>, then pseudo-absence record dates are randomly
generated within the two <code>temporal.ext</code> dates given.
</p>


<h3>References</h3>

<p>Barbet-Massin, M., Jiguet, F., Albert, C. H., Thuiller, W. J. M. I. E. &amp; Evolution 2012. Selecting
Pseudo-Absences For Species Distribution Models: How, Where And How Many? 3, 327-338.
</p>
<p>Phillips, S. J., Dudik, M., Elith, J., Graham, C. H., Lehmann, A., Leathwick, J. &amp; Ferrier, S.
2009. Sample Selection Bias And Presence-Only Distribution Models: Implications For Background And
Pseudo-Absence Data. 19, 181-197.
</p>
<p>Vanderwal, J., Shoo, L. P., Graham, C. &amp; Williams, S. E. 2009. Selecting Pseudo-Absence Data For
Presence-Only Distribution Modeling: How Far Should You Stray From What You Know? Ecological
Modelling, 220, 589-594.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("sample_filt_data")


spatiotemp_pseudoabs(
 sample_filt_data,
 spatial.method = "random",
 temporal.method = "random",
 spatial.ext = c(20, 36, -35, -12),
 temporal.ext = c("2011-01-01", "2017-01-01")
)

</code></pre>

<hr>
<h2 id='spatiotemp_resolution'>Filter species occurrence records by given spatial and temporal resolution</h2><span id='topic+spatiotemp_resolution'></span>

<h3>Description</h3>

<p>Filters species occurrence record data frame to exclude records with co-ordinates and dates that
do not meet specified spatial and temporal resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_resolution(occ.data, spatial.res, temporal.res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_resolution_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_resolution_+3A_spatial.res">spatial.res</code></td>
<td>
<p>optional; a numeric value, the minimum acceptable number of decimal places
given for occurrence record co-ordinates.</p>
</td></tr>
<tr><td><code id="spatiotemp_resolution_+3A_temporal.res">temporal.res</code></td>
<td>
<p>optional; a character string, the minimum acceptable temporal resolution of
occurrence record dates. One of <code>day</code> , <code>month</code> or <code>year</code>: can be abbreviated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Excludes species occurrence records that do not meet the minimum spatial and temporal
resolution specified.
</p>
<p>If <code>spatial.res</code> given, the value of 1 represents an acceptable co-ordinate resolution of one
decimal place, roughly equal to 11.1km, and value of 3 represents three decimal places, roughly
equal to 111m.
</p>
<p>If <code>temporal.res</code> given, <code>temporal.res = day</code> would result in exclusion of records without
values for year, month and day, and <code>temporal.res = year</code> would only exclude records without
values for year.
</p>
<p><code>spatial.res</code> and <code>temporal.res</code> can be informed based upon the highest spatial and temporal
resolution of the datasets to be utilised when extracting dynamic variables.
</p>
<p>For example, if explanatory variables datasets are annual, then a <code>temporal.res</code> of <code>year</code> is
adequate, whereas if datasets are daily, then <code>temporal.res</code> of <code>day</code> may be more appropriate.
</p>


<h3>Value</h3>

<p>Returns a data frame of species records filtered by the minimum acceptable spatial
resolution of co-ordinates and temporal resolution of dates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sample_occ_data)
sample_occ_data &lt;- convert_gbif(sample_occ_data)

spatial_res_high &lt;- spatiotemp_resolution(sample_occ_data, spatial.res = 4)

spatial_res_low &lt;- spatiotemp_resolution(sample_occ_data, spatial.res = 1)

temporal_res &lt;- spatiotemp_resolution(sample_occ_data, temporal.res = "day")
</code></pre>

<hr>
<h2 id='spatiotemp_thin'>Thin species occurrence records by spatial and temporal proximity.</h2><span id='topic+spatiotemp_thin'></span>

<h3>Description</h3>

<p>Thins species occurrence records that are within minimum spatial and temporal distance apart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_thin(
  occ.data,
  temporal.method,
  temporal.dist,
  spatial.split.degrees,
  spatial.dist = 0,
  iterations = 100,
  prj = "+proj=longlat +datum=WGS84"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_thin_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_thin_+3A_temporal.method">temporal.method</code></td>
<td>
<p>a character string, the method to calculate temporal distance between
records. One of <code>DOY</code> or <code>day.</code> See details for more information.</p>
</td></tr>
<tr><td><code id="spatiotemp_thin_+3A_temporal.dist">temporal.dist</code></td>
<td>
<p>a numeric value, the temporal buffer in days to thin records by.</p>
</td></tr>
<tr><td><code id="spatiotemp_thin_+3A_spatial.split.degrees">spatial.split.degrees</code></td>
<td>
<p>a numeric value, the grid cell resolution in degrees to split
occurrence records by before temporal thinning.</p>
</td></tr>
<tr><td><code id="spatiotemp_thin_+3A_spatial.dist">spatial.dist</code></td>
<td>
<p>a numeric value, the spatial buffer distances in metres to thin records by.
Default no spatial thinning.</p>
</td></tr>
<tr><td><code id="spatiotemp_thin_+3A_iterations">iterations</code></td>
<td>
<p>a numeric value, the number of iterations to randomly thin occurrence records
by. Default; 100.</p>
</td></tr>
<tr><td><code id="spatiotemp_thin_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of occ.data co-ordinates. Default
is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data frame of occurrence records thinned by specified temporal and spatial
distance.
</p>


<h3>Overview</h3>

<p><code>spatiotemp_thin()</code> calculates the temporal distance between occurrence records in given area
and excludes records below minimum temporal distance apart. Then calculates the spatial distance
between all occurrence records and filters records below the minimum spatial distance apart using
the <code>spThin</code> package function for spatial thinning (Aiello-Lammens et al., 2015). This approach
has been shown to improve species distribution model performance (Boria et al., 2014).
</p>


<h3>Temporal thinning methods</h3>

<p>For temporal thinning, the function first splits occurrence records into grid cells of given size
in degrees (set by <code>spatial.split.degrees</code>). This is to prevent spatially distant but temporally
close records from being excluded. For each grid cell, all records within the cell are temporally
thinned. This process works by removing records that are within given temporal distance
(<code>temporal.dist</code>) from each other by randomly selecting one of the two. This iterates through
until no records are within the given temporal distance of each other in each grid cell, following
a similar algorithm to <code>spThin</code> (Aiello-Lammens et al., 2015).
</p>
<p>Two methods exist for measuring the temporal distance between occurrence records.
</p>

<ul>
<li> 

<ol>
<li> <p><code>doy</code> - calculates the minimum days apart within the annual cycle
</p>
</li></ol>

</li>
<li> 

<ol>
<li> <p><code>day</code> - uses the absolute number of days.
</p>
</li></ol>

</li></ul>

<p>For instance, two dates “2010-01-05” and “2012-12-05” can be calculated as either 1065 absolute
days apart, or within the annual cycle these dates represent day 5 and day 339 of the year, and
are 31 days apart. Therefore, thinning by 40 days using the <code>DOY</code> method would remove one of these
records, but using the <code>day</code> method would not. The chosen <code>temporal.method</code> will depend upon
whether bias towards a point within the annual cycle or a point in linear time.
</p>


<h3>Spatial thinning</h3>

<p>Following temporal thinning, spatial thinning occurs across entire dataset. The spatial distance
between each record is calculated, and records within the given spatial distance (<code>spatial.dist</code>)
from each other are excluded by randomly selecting one of these. This iterates through until no
records are with the given spatial distances of each other across entire dataset using the package
<code>spThin</code> (Aiello-Lammens et al., 2015).
</p>
<p>As random selection could alter the total number of occurrence records remaining in the occurrence
record dataset, this process is iterated through a specified number of times (<code>iterations</code>) and
the thinned data frame with the highest number of records remaining is returned.
</p>


<h3>References</h3>

<p>Aiello-Lammens, M. E., Boria, R. A., Radosavljevic, A., Vilela, B. &amp; Anderson, R. P.
2015. spThin: an R package for spatial thinning of species occurrence records for use in
ecological niche models. Ecography, 38, 541-545.
</p>
<p>Boria, R. A., Olson, L. E., Goodman, S. M. &amp; Anderson, R. P. 2014. Spatial Filtering To Reduce
Sampling Bias Can Improve The Performance Of Ecological Niche Models. Ecological Modelling, 275,
73-77.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("sample_filt_data")

n.iterations &lt;- 500

spatiotemp_thin(
 occ.data = sample_filt_data,
 temporal.method = "day",
 temporal.dist = 100,
 spatial.split.degrees = 3,
 spatial.dist = 100000,
 iterations = n.iterations
)

</code></pre>

<hr>
<h2 id='spatiotemp_weights'>Calculate sampling effort across spatial and temporal buffer from species occurrence records</h2><span id='topic+spatiotemp_weights'></span>

<h3>Description</h3>

<p>Calculates the total number of sampling events across a given spatial and temporal buffer from
each occurrence record’s co-ordinate and date.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatiotemp_weights(
  occ.data,
  samp.events,
  spatial.dist = 0,
  temporal.dist = 0,
  prj = "+proj=longlat +datum=WGS84"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spatiotemp_weights_+3A_occ.data">occ.data</code></td>
<td>
<p>a data frame, with columns for occurrence record co-ordinates and dates with
column names as follows; record longitude as &quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as
&quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_weights_+3A_samp.events">samp.events</code></td>
<td>
<p>a data.frame, sampling events with column names as follows; record longitude as
&quot;x&quot;, latitude as &quot;y&quot;, year as &quot;year&quot;, month as &quot;month&quot;, and day as &quot;day&quot;.</p>
</td></tr>
<tr><td><code id="spatiotemp_weights_+3A_spatial.dist">spatial.dist</code></td>
<td>
<p>a numeric value, the spatial distance in metres representing the radius from
occurrence record co-ordinate to sum sampling events across.</p>
</td></tr>
<tr><td><code id="spatiotemp_weights_+3A_temporal.dist">temporal.dist</code></td>
<td>
<p>a numeric value, the temporal distance in days, representing the period
before and after the occurrence record date to sum sampling events across.</p>
</td></tr>
<tr><td><code id="spatiotemp_weights_+3A_prj">prj</code></td>
<td>
<p>a character string, the coordinate reference system of input <code>occ.data</code> co-ordinates
Default is &quot;+proj=longlat +datum=WGS84&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each occurrence record, this function calculates the total number of sampling events
within given radius (<code>spatial.dist</code>) from each record co-ordinate and days (<code>temporal.dist</code>)
both prior and post record date.
</p>
<p>In addition to total sampling events, the function also calculates relative sampling effort,
scaling from 0 (least sampled) to 1 (most sampled).
</p>
<p>Output could be used to calculate model weights to correct spatial and temporal biases in
occurrence record collections (Stolar and Nielsen, 2015).
</p>


<h3>Value</h3>

<p>Returns input occurrence record data frame with additional columns for sampling effort
&quot;SAMP_EFFORT&quot; and relative sampling effort &quot;REL_SAMP_EFFORT&quot;.
</p>


<h3>References</h3>

<p>Stolar, J. &amp; Nielsen, S. E. 2015. Accounting For Spatially Biased Sampling Effort In
Presence-Only Species Distribution Modelling. Diversity And Distributions, 21, 595-608.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("sample_explan_data")
data("sample_events_data")

spatiotemp_weights(
 occ.data = sample_explan_data,
 samp.events = sample_events_data,
 spatial.dist = 200000,
 temporal.dist = 20
)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
