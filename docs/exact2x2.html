<!DOCTYPE html><html><head><title>Help for package exact2x2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {exact2x2}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#binomMeld.test'>
<p>Melded Binomial Confidence Intervals and Tests</p></a></li>
<li><a href='#borrControl'>
<p>Algorithm variables used by borrTest.</p></a></li>
<li><a href='#borrOrderingInternal'>
<p>BORR Ordering, internal calculation functions</p></a></li>
<li><a href='#borrTest'>
<p>Boundary-Optimized Rejection Region Test</p></a></li>
<li><a href='#boschloo'>
<p>Boschloo's test for 2x2 Tables</p></a></li>
<li><a href='#calcTall'>
<p>Calculate all Tstat for all values of the (n1+1) X (n2+1) sample space from the two sample binomial problem.</p></a></li>
<li><a href='#constrMLE.difference'><p>Calculate constrained MLEs.</p></a></li>
<li><a href='#exact2x2'><p>Exact Conditional Tests for 2 by 2 Tables of Count Data</p></a></li>
<li><a href='#exact2x2-internal'><p>Internal functions for exact2x2. Not to be called by user.</p></a></li>
<li><a href='#exact2x2-package'>
<p>Exact Tests and Confidence Intervals for 2x2 Tables</p></a></li>
<li><a href='#exact2x2Plot'><p> Plot p-value function for one 2 by 2 table.</p></a></li>
<li><a href='#mcnemarExactDP'><p>Exact McNemar (Paired Binary) Test with Difference in Proportions</p></a></li>
<li><a href='#pickTstat'>
<p>Pick T statistic (ordering function) for unconditional exact test.</p></a></li>
<li><a href='#plotT'>
<p>Plot or Print  ordering function for unconditional exact test</p></a></li>
<li><a href='#power2grid'>
<p>Create grid for root search.</p></a></li>
<li><a href='#power2x2'><p>Calculate exact power or sample size for conditional tests for two independent binomials.</p></a></li>
<li><a href='#powerPaired2x2'>
<p>Power for exact McNemar's test</p></a></li>
<li><a href='#ucControl'>
<p>Algorithm variables used by uncondExact2x2.</p></a></li>
<li><a href='#uncondExact2x2'>
<p>Unconditional exact tests for 2x2 tables</p></a></li>
<li><a href='#uncondExact2x2-internal'>
<p>Internal functions for unconditional exact tests.</p></a></li>
<li><a href='#uncondPower2x2'>
<p>Calculate power or sample size for any 2x2 test.</p></a></li>
<li><a href='#unirootGrid'>
<p>Function to find a root by grid search.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Exact Tests and Confidence Intervals for 2x2 Tables</td>
</tr>
<tr>
<td>Version:</td>
<td>1.6.9</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-25</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael P. Fay [aut, cre], 
  Sally A. Hunsberger [ctb], 
  Martha Nason [ctb], 
  Erin Gabriel [ctb],
  Keith Lumbard [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael P. Fay &lt;mfay@niaid.nih.gov&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), stats (&ge; 3.1.1), exactci, ssanv</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates conditional exact tests (Fisher's exact test, Blaker's exact test, or  exact McNemar's test) and unconditional exact tests (including score-based tests on differences in proportions, ratios of proportions, and odds ratios, and Boshcloo's test) with appropriate matching confidence intervals, and provides power and sample size calculations. Gives melded confidence intervals for the binomial case (Fay, et al, 2015, &lt;<a href="https://doi.org/10.1111%2Fbiom.12231">doi:10.1111/biom.12231</a>&gt;). Gives boundary-optimized rejection region test (Gabriel, et al, 2018, &lt;<a href="https://doi.org/10.1002%2Fsim.7579">doi:10.1002/sim.7579</a>&gt;), an unconditional exact test for the situation where the controls are all expected to fail. Gives confidence intervals compatible with exact McNemar's or sign tests (Fay and Lumbard, 2021, &lt;<a href="https://doi.org/10.1002%2Fsim.8829">doi:10.1002/sim.8829</a>&gt;). For review of these kinds of exact tests see Fay and Hunsberger (2021, &lt;<a href="https://doi.org/10.1214%2F21-SS131">doi:10.1214/21-SS131</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, Exact (&ge; 2.0), ggplot2, grid, gridExtra</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-25 18:35:19 UTC; faym</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-25 19:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='binomMeld.test'>
Melded Binomial Confidence Intervals and Tests 
</h2><span id='topic+binomMeld.test'></span>

<h3>Description</h3>

<p>Creates tests to compare two binomials, giving confidence intervals for either the difference in proportions, the rate ratio, or the odds ratio. The 95 percent confidence intervals have been shown to guarantee nominal coverage by extensive numerical calculations. It has been theoretically proven that the p-values from the one-sided tests on the null hypothesis of equality match Fisher's exact p-values.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binomMeld.test(x1, n1, x2, n2, nullparm = NULL, 
    parmtype = c("difference", "oddsratio", "ratio"), 
    conf.level = 0.95, conf.int=TRUE, 
    alternative = c("two.sided", "less", "greater"), 
    midp=FALSE, nmc=0, eps=10^-8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomMeld.test_+3A_x1">x1</code></td>
<td>
<p>number of events in group 1</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_n1">n1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_x2">x2</code></td>
<td>
<p>number of events in group 2</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_n2">n2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_nullparm">nullparm</code></td>
<td>
<p>value of the parameter of interest at null, default of NULL gives 0 for parmtype='difference' and 1 for parmtype='ratio' or 'oddsratio'</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_parmtype">parmtype</code></td>
<td>
<p>type of parameter of interest, one of &quot;difference&quot;, &quot;ratio&quot; or &quot;oddsratio&quot; (see details)</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_conf.int">conf.int</code></td>
<td>
<p>logical, calculate confidence intervals?</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_alternative">alternative</code></td>
<td>
<p>alternative hypothesis, one of &quot;two.sided&quot;, &quot;less&quot;, or &quot;greater&quot; (see details)</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_midp">midp</code></td>
<td>
<p>logical, do mid-p version of p-value and confidence intervals?</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_nmc">nmc</code></td>
<td>
<p>integer,  number of Monte Carlo replications for p-value and CI calculations, 0 (default) means calculate by numeric integration instead</p>
</td></tr>
<tr><td><code id="binomMeld.test_+3A_eps">eps</code></td>
<td>
<p>small number used to adjust numeric integration (see note)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume X1~ Binomial(n1,p1) and X2~Binomial(n2,p2). We want to test hypotheses on a function of p1 and p2. The functions are given by parmtype: difference tests p2-p1,
ratio tests p2/p1, and odds ratio tests p2(1-p1)/(p1(1-p2)).  Let g(p1,p2) be one of the three functions. So when alternative is &quot;less&quot; we test H0: g(p1,p2) &gt;= nullparm vs. H1: g(p1,p2)&lt;nullparm.
</p>
<p>For details when <code>midp=FALSE</code> see Fay, Proschan, and Brittain (2015). 
</p>
<p>When <code>midp=TRUE</code>, the method performs the mid-p version on the p-value and the associated confidence intervals. 
This means that we replace the confidence distribution random variables in the p-value and CI calculations
with a random variable that is a mixture of the lower and upper CD random variables. For example, if W1L and W1U are the 
lower and upper confidence distribution random variables for group 1, then we replace those values in all calculations 
with W1midp = U1*W1L + (1-U1)*W1U, where U1 is a Bernoulli with parameter 0.5. 
For a discussion of mid-p p-values and the associated confidence intervals in a closely related context, see the vignette on mid p-values or Fay and Brittain (2016, especially the Appendix).
</p>


<h3>Value</h3>

<p>An object of class 'htest'. A list with elements
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>proportion of events in group 1</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>proportion of events in group 2</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>confidence interval</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>estimate of g(p1,p2) by plugging in sample proportions, i.e., unconditional MLE</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>value of g(p1,p2) under null</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>type of alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>character explicit description of data</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For numeric integration, the integrate function may have problems if nearly all of the integrand values are about 0 within the range of integration. Because of this, 
we use the eps value to make sure we integrate over ranges in which the integrand is nontrivially greater than 0. We restrict the range then add eps back to the p-value 
so that if the integrate function works perfectly, then the p-values would be very slightly conservative (for very small eps). 
There is no need to adjust the eps value. See code for detailed description of how eps is used in the calculation before changing it from the default.
</p>
<p>An alternative method of calculation is to use Monte Carlo simulation (option with <code>nmc&gt;0</code>). 
This provides a check of the numeric integration. 
There is no need to do Monte Carlo simulations for routine use. Please inform the package maintainer if the p-values or confidence intervals are substantially different when <code>nmc=0</code> and <code>nmc=10^7</code>.
</p>


<h3>Author(s)</h3>

<p>Michael P. Fay</p>


<h3>References</h3>

<p>Fay, MP, Proschan, MA, and Brittain, E (2015) Combining One Sample Confidence Procedures for Inferences in the Two Sample Case. Biometrics 71: 146-156. 
</p>
<p>Fay, Michael P., and Erica H. Brittain. (2016). Finite sample pointwise confidence intervals for a survival distribution with right-censored data. Statistics in medicine. 35: 2726-2740.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Note the p-value for all tests of equality 
# (Null Hypthesis: true prop 1=true prop 2)
# are the same, and equal to the 
# Fisher's exact (central) p-value
binomMeld.test(3,5,1,8,parmtype="difference")
binomMeld.test(3,5,1,8,parmtype="ratio")
# note that binomMeld.test gives the unconditional MLE 
# for the odds ratio, while fisher.test and exact2x2 
# gives the conditional MLE for the odds ratio
# (also fisher.test gives the odds ratio defined as 
#  the inverse of how it is defined in binomMeld.test)
binomMeld.test(3,5,1,8,parmtype="oddsratio")
exact2x2(matrix(c(1,8-1,3,5-3),2,2),tsmethod="central")

</code></pre>

<hr>
<h2 id='borrControl'>
Algorithm variables used by borrTest.
</h2><span id='topic+borrControl'></span>

<h3>Description</h3>

<p>Function that gives list of algorithm variables used by 
<code><a href="#topic+borrTest">borrTest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>borrControl(nAlphaGrid=10000,nThetaGrid=1000, maxIter=0, digits=4, orderFunc=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="borrControl_+3A_nalphagrid">nAlphaGrid</code></td>
<td>

<p>number used for defining grid for searching over the (0,1) space for significance levels.
Used in <code><a href="#topic+borrOrderingAlphaGrid">borrOrderingAlphaGrid</a></code>.
</p>
</td></tr>
<tr><td><code id="borrControl_+3A_nthetagrid">nThetaGrid</code></td>
<td>

<p>number of evenly spaced grid elements for searching over the (0,1) space for theta. 
Used in both <code><a href="#topic+borrOrderingAlphaGrid">borrOrderingAlphaGrid</a></code> and  and <code><a href="#topic+borrOrderingByRR">borrOrderingByRR</a></code>.
</p>
</td></tr>
<tr><td><code id="borrControl_+3A_maxiter">maxIter</code></td>
<td>

<p>maximum number of searches over the alpha space. Used in  <code><a href="#topic+borrOrderingAlphaGrid">borrOrderingAlphaGrid</a></code>.
</p>
</td></tr>
<tr><td><code id="borrControl_+3A_digits">digits</code></td>
<td>

<p>number of digits for rounding alpha star values. Used in <code><a href="#topic+borrOrderingByRR">borrOrderingByRR</a></code>.
</p>
</td></tr>
<tr><td><code id="borrControl_+3A_orderfunc">orderFunc</code></td>
<td>

<p>character vector to determine function to do the borr ordering. <code>NULL</code> checks for precalculated values then does <code><a href="#topic+borrOrderingAlphaGrid">borrOrderingAlphaGrid</a></code>. 'AlphaGrid' uses <code><a href="#topic+borrOrderingAlphaGrid">borrOrderingAlphaGrid</a></code>
and 'ByRR' uses <code><a href="#topic+borrOrderingByRR">borrOrderingByRR</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <code><a href="#topic+borrOrderingAlphaGrid">borrOrderingAlphaGrid</a></code>
we create a grid for searching over the significance level space, for the first calculation (zeroth iteration) we use <code>alpha.seq</code> where 
<code>alpha.seq &lt;-
    sort(unique(c(
      10 ^ seq(log10(minAlpha), 0, length = nAlphaGrid / 2),
      seq(minAlpha, 10 ^ 0, length = nAlphaGrid / 2)
    )))</code>, where <code>minAlpha</code> is the one-sided p-value at the point (x1=n1, x2=0)
given by <code>minAlpha&lt;- dbinom(0,nT,nC/(nC+nT))*dbinom(nC,nC,nC/(nC+nT))</code>.
If there are ties and <code>maxIter</code> is greater than 0, then replace each tied value with an equally spaced grid (with nAlphaGrid elements) between the adjacent non-tied values. 
If the lowest value in the grid, <code>minAlpha</code>, is tied, then set <code>minAlpha&lt;-minAlpha/10</code> 
at the beginning of the iteration.
Repeat this process up to <code>maxIter</code> times.
</p>
<p>See <a href="#topic+borrOrderingInternal">borrOrderingInternal</a> for more details of algorithms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>borrControl(nThetaGrid=10^3)
</code></pre>

<hr>
<h2 id='borrOrderingInternal'>
BORR Ordering, internal calculation functions
</h2><span id='topic+borrOrderingInternal'></span><span id='topic+borrOrderingAlphaGrid'></span><span id='topic+borrOrderingByRR'></span><span id='topic+borrOrderingPreCalc'></span><span id='topic+borrPreCalc'></span><span id='topic+calcRejectProb'></span><span id='topic+getThreshold'></span>

<h3>Description</h3>

<p>Three functions for calculating the BORR ordering. The default did some slow <code>borrOrdering</code> calculations are done ahead of time and stored in sysdata.rda, for n1 and n2 smaller than 21 and for <code>tuningParm=0.025</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>borrOrderingAlphaGrid(n1, n2, tuningParm = 0.025, controlborr = borrControl())

borrOrderingByRR(n1, n2, tuningParm = 0.025, controlborr = borrControl())

borrOrderingPreCalc(n1, n2, tuningParm=0.025, orderPreCalc=orderPreCalc)

borrPreCalc(NList=seq(2,20),
           tuningParm = 0.025,
           controlborr = borrControl())
           
calcRejectProb(p.ctrl, Threshold, p.trt = p.ctrl, n.trt, n.ctrl, max.uninf.ctrls = n.ctrl)

getThreshold(n.ctrl, n.trt, tuningParm = 0.025, nThetaGrid = 1000, 
    max.uninf.ctrls = n.ctrl, forceConvex = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="borrOrderingInternal_+3A_n1">n1</code></td>
<td>

<p>sample size in group 1
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_n2">n2</code></td>
<td>

<p>sample size in group 2
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_tuningparm">tuningParm</code></td>
<td>

<p>tuning parameter, default is 0.025 and designs BORR tests with maximum power
for one-sided 0.025 tests
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_controlborr">controlborr</code></td>
<td>

<p>a list of control parameters to define algorithms, see <code><a href="#topic+borrControl">borrControl</a></code>
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_orderprecalc">orderPreCalc</code></td>
<td>

<p>a list of precalculated orderings (see details)
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_nlist">NList</code></td>
<td>

<p>list of n1 and n2 values for creating <code>orderPreCalc</code> object. Does all possible combinations
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_p.ctrl">p.ctrl</code></td>
<td>

<p>vector of theta values for theta1, usually determined by <code>controlborr$nThetaGrid</code> 
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_threshold">Threshold</code></td>
<td>

<p>vector of threshold values that define one rejection region.
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_p.trt">p.trt</code></td>
<td>

<p>vector of theta values for theta2, usually determined by <code>controlborr$nThetaGrid</code>
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_n.trt">n.trt</code></td>
<td>

<p>n2 (notation matches the Gabriel, et al paper)
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_n.ctrl">n.ctrl</code></td>
<td>

<p>n1 (notation matches the Gabriel, et al paper)
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_max.uninf.ctrls">max.uninf.ctrls</code></td>
<td>

<p>set to n.ctrl, see code before changing it
</p>
</td></tr>
<tr><td><code id="borrOrderingInternal_+3A_forceconvex">forceConvex</code></td>
<td>

<p>logical, should always be TRUE. If you want to try FALSE check the code first.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All BORR ordering functions automatically enforce Barnard's convexity in the 
rejection regions (in response to the letter of Martin Andres). 
Note that the original ordering in Figure 2 of Gabriel et al was incorrect. 
The correct value is in the response  letter by Gabriel et al (see also the example code 
in <code><a href="#topic+borrTest">borrTest</a></code>).
</p>
<p>The <code>controlborr$orderFunc</code> determines which function calculates the borr ordering. 
When  <code>controlborr$orderFunc=NULL</code> (the default) the code first searches to see if there is a precalculated ordering (see below), and if not it calls <code>borrOrderingByRR</code> if <code>n1+n2&lt;=16</code>,
and otherwise calls <code>borrOrderingAlphaGrid</code>. 
When  <code>controlborr$orderFunc='AlphaGrid'</code> then it calls <code>borrOrderingAlphaGrid</code>,
when <code>controlborr$orderFunc='ByRR'</code> then it calls <code>borrOrderingByRR</code>.
</p>
<p>The function <code>borrOrderingByRR</code> calculates the ordering based on trying convex 
rejection regions and calculating the alpha star value when different points that are added are 
just barely rejected. This leads to fast and accurate calculates for small n1 and n2 (less than 8), but can be slow for larger n1 and n2. It rounds the alpha star values to the nearest <code>controlborr$digits</code>, to avoid computer problems with ties (remember the alpha star values themselves are calculated by a grid on the theta values).
</p>
<p>The function <code>borrOrderingAlphaGrid</code> calculates the ordering based on a grid of alpha values.
It can be faster for larger n1 and n2, but its accuracy depends on the <code>controlborr$nAlphaGrid</code>. 
</p>
<p>The function <code>borrPreCalc</code> as run in the example should produce <code>orderPreCalc</code>. It was actually run on a parallel processing machine as 361 separate jobs. These calculations can 
take a bit of time. Then <code><a href="#topic+borrOrdering">borrOrdering</a></code> (when <code>controlborr$orderFunc=NULL</code>)
will automatically check to see if the ordering has previously been calculated and if so will call 
<code>borrOrderingPreCalc</code> and if not call <code>borrOrderingAlphaGrid</code>.
</p>
<p>The functions <code>calcRejectProb</code> and <code>getThreshold</code> are called by both <code>borrOrderingAlphaGrid</code> and <code>borrOrderingByRR</code>. 
</p>


<h3>Value</h3>

<p>The function <code>borrOrderingAlphaGrid</code> and <code>borrOrderingByRR</code>  returns an rank matrix
as well as an alpha matrix. 
The alpha matrix is the minimum alpha for each point to just enter the rejection region
(in the notation of Gabriel et al, it is Min(alphastar: delta(alphastar, NC, NT, YC, YT)=1)).  
The rank matrix is the ordering matrix as in Figure 2 (see correction in letter).
The <code>borrOrderingPreCalc</code> only returns the rank matrix. 
The list <code>orderPreCalc</code> has elements:
</p>
<table>
<tr><td><code>orderList</code></td>
<td>
<p> a list of the rank matrices, with orderList[[i]] associated with n1List[i] and n2List[i]</p>
</td></tr>
<tr><td><code>controlborr</code></td>
<td>
<p>control used in calculating orderings, see <code><a href="#topic+borrControl">borrControl</a></code></p>
</td></tr>
<tr><td><code>tuningParm</code></td>
<td>
<p>the tuning parmeter used in the orderings</p>
</td></tr>
<tr><td><code>n1List</code></td>
<td>
<p>the n1List used in the orderings</p>
</td></tr>
<tr><td><code>n2List</code></td>
<td>
<p>the n2List used in the orderings</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gabriel, EE, Nason, M, Fay, MP, and Follmann, DA. (2018). A boundary-optimized rejection region test for the two-sample binomial problem. Statistics in Medicine. 37(7)  (DOI: 10.1002/sim.7579).
</p>
<p>Antonio Martin Andres. Letter to the editor about Gabriel et al. Statistics in Medicine (to appear).
</p>
<p>Gabriel, EE, Nason, M, Fay, MP, and Follmann, DA. Reply to letter from Martin Andres. Statistics in Medicine (to appear).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This is the call that should produce the orderPreCalc object 
# used by borrOrderingPreCalc
orderPreCalc&lt;-borrPreCalc(NList=2:20,
    tuningParm = 0.025,
    controlborr = borrControl(nAlphaGrid = 10000, 
    nThetaGrid=1000, maxIter=0)) 

## End(Not run)
</code></pre>

<hr>
<h2 id='borrTest'>
Boundary-Optimized Rejection Region Test</h2><span id='topic+borrTest'></span><span id='topic+borrPvals'></span><span id='topic+borrOrdering'></span><span id='topic+powerBorr'></span>

<h3>Description</h3>

<p>An unconditional exact test for the two-sample binomial problem 
when it is expected that theta1 (probability of an event in group 1)   
will be close to 1. Used for test versus control when all controls are 
expected to fail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>borrTest(x1, n1, x2, n2, tuningParm = 0.025,
    parmtype = c("ratio", "difference", "oddsratio"), 
    nullparm = NULL, alternative = c("less", "greater", "two.sided"), 
    conf.int = TRUE, conf.level = 0.975,  
    controlUC = ucControl(), controlborr = borrControl(), ...)

borrPvals(n1,n2, tuningParm=0.025,    
    parmtype = c("ratio", "difference","oddsratio"), 
    nullparm = NULL, alternative = c("less", "greater","two.sided"),  
    conf.int = TRUE, conf.level = 0.975,
    controlUC=ucControl(), controlborr=borrControl(),...)

borrOrdering(n1,n2,tuningParm = .025,
            controlborr=borrControl())
            
powerBorr(n1,n2,p1,p2,alpha=0.025,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="borrTest_+3A_x1">x1</code></td>
<td>

<p>number of events in group 1
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_n1">n1</code></td>
<td>

<p>sample size in group 1
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_x2">x2</code></td>
<td>

<p>number of events in group 2
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_n2">n2</code></td>
<td>

<p>sample size in group 2
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_tuningparm">tuningParm</code></td>
<td>

<p>tuning parameter, default is 0.025 and designs BORR tests with maximum power
for one-sided 0.025 tests
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_parmtype">parmtype</code></td>
<td>

<p>parameter type, either 'ratio' for theta2/theta1, 
'difference' for theta2-theta1, or
'oddsratio' for theta2*(1-theta1)/(theta1*(1-theta2)).
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_nullparm">nullparm</code></td>
<td>

<p>null parameter value, default=NULL gives parameter value for 
theta1=theta2 (e.g., 1 for 'ratio' or 0 for 'difference' ).
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_alternative">alternative</code></td>
<td>

<p>alternative hypothesis, BORR tests are designed for alternative='less' 
(see Note for other alternatives)
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_conf.int">conf.int</code></td>
<td>

<p>logical, should confidence interval be calculated?
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_conf.level">conf.level</code></td>
<td>

<p>confidence level, default is 0.975 (see note)
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_controluc">controlUC</code></td>
<td>

<p>a list of control parameters to define algorithms in the call to <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>, see <code><a href="#topic+ucControl">ucControl</a></code> 
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_controlborr">controlborr</code></td>
<td>

<p>a list of control parameters to define algorithms, see <code><a href="#topic+borrControl">borrControl</a></code>
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_p1">p1</code></td>
<td>

<p>probability of an event in group 1
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_p2">p2</code></td>
<td>

<p>probability of an event in group 2
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_alpha">alpha</code></td>
<td>

<p>alpha-level for rejecting, reject when p-value </p>
<p style="text-align: center;"><code class="reqn">latex</code>
</p>
<p> alpha
</p>
</td></tr>
<tr><td><code id="borrTest_+3A_...">...</code></td>
<td>

<p>extra arguments passed (only used for <code>powerBorr</code>, passes arguments to the <code>borrPvals</code> function)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The boundary-optimized rejection region test is designed to test the one-sided alternative that 
theta2 &lt; theta1, where X1 is binomial(n1,theta1), and X2 is binomial(n2,theta2). The test is 
designed to be optimal when theta1 is very close to 1. For example, in a vaccine malaria challenge study
where we expect all n1 individuals that got the control vaccine to have the event (get malaria when challenged with malaria). For details see Gabriel et al (2018). 
</p>
<p>The function <code>borrTest</code> tests the results of one study, and returns 
an <code>htest</code> object. The function <code>borrPvals</code> calculates the p-values for every possible result of a study. The function <code>borrOrdering</code> orders every possible result of the study.
See <code><a href="#topic+borrOrderingInternal">borrOrderingInternal</a></code> for calculation details. The function <code>powerBorr</code> calculates the power
where p-values are calculated by <code>borrPvals</code> and rejection is when </p>
<p style="text-align: center;"><code class="reqn">latex</code>
</p>
<p> alpha.
</p>


<h3>Value</h3>

<p>The function <code>borrPvals</code> returns a (n1+1) by (n2+1) matrix of p-values for all possible x1 and x2 values. The function <code>borrOrdering</code> returns a matrix with the rank of all possible x1 and x2 values. The function <code>borrTest</code> returns a list of class <code>htest</code> with elements: 
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>proportion in sample 1</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>proportion in sample 2</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value from test</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>confidence interval on parameter given by parmtype</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>MLE estimate of parameter given by parmtype</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>null hypothesis value of parameter given by parmtype</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>description of data</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The tests are designed to have good power for the one-sided test that H0: theta2 <code class="reqn">\ge</code> theta1, with 
alternative H1: theta2 &lt; theta1 at significance level equal to <code>tuningParm</code>. Since the default <code>tuningParm</code> is 0.025, the default confidence level is 0.975 so that the confidence intervals will be compatible with the test where the one-sided p-values reject at level 0.025. 
</p>
<p>Sometimes you may want two-sided confidence intervals on the 
parameter of interest. If you ask for a two-sided alternative, then the confidence interval and the resulting p-value will be two-sided as well. The default is a 'central' interval, so the two-sided p-value should be twice the minimum of the one-sided p-values. Further, with a <code>conf.level</code> of 0.95 for the two-sided alternative, the error on each side will be bounded by 0.025. </p>


<h3>Author(s)</h3>

<p>Martha Nason, Erin Gabriel, Michael P. Fay
</p>


<h3>References</h3>

<p>Gabriel, EE, Nason, M, Fay, MP, and Follmann, DA. (2018). A boundary-optimized rejection region test for the two-sample binomial problem. Statistics in Medicine. 37(7): 1047-1058  (DOI: 10.1002/sim.7579).
</p>
<p>Gabriel, EE, Nason, M, Fay, MP, and Follmann, DA. (2018). Reply to letter from Martin Andres. Statistics in Medicine 37(14): 2303-2306.
</p>
<p>Martin Andres, Antonio. (2018). Letter to the editor about Gabriel et al. Statistics in Medicine 37(14) 2301-2302.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: borrTest(4,4,1,4)
# Note Figure 2 in Gabriel et al is incorrect. The correct value 
# is in the response letter, and given by 
borrOrdering(4,4,tuningParm=0.025)$rankMat
</code></pre>

<hr>
<h2 id='boschloo'>
Boschloo's test for 2x2 Tables</h2><span id='topic+boschloo'></span>

<h3>Description</h3>

<p>Boschloo's test is an exact unconditional test for 2x2 tables based on ordering the sample space by Fisher's exact p-values. This function generalizes that test in several ways (see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boschloo(x1, n1, x2, n2, alternative = c("two.sided", "less", "greater"), 
    or = NULL, conf.int = FALSE, conf.level = 0.95, midp = FALSE, 
    tsmethod = c("central", "minlike"), control=ucControl())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boschloo_+3A_x1">x1</code></td>
<td>
<p>number of events in group 1</p>
</td></tr>
<tr><td><code id="boschloo_+3A_n1">n1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="boschloo_+3A_x2">x2</code></td>
<td>
<p>number of events in group 2</p>
</td></tr>
<tr><td><code id="boschloo_+3A_n2">n2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code id="boschloo_+3A_alternative">alternative</code></td>
<td>

<p>alternative hypothesis, one of &quot;two.sided&quot;, &quot;less&quot;, or &quot;greater&quot;, default is &quot;two.sided&quot; (see details)
</p>
</td></tr>
<tr><td><code id="boschloo_+3A_or">or</code></td>
<td>
<p>odds ratio under the null hypothesis</p>
</td></tr>
<tr><td><code id="boschloo_+3A_conf.int">conf.int</code></td>
<td>
<p>logical, calculate confidence interval?</p>
</td></tr>
<tr><td><code id="boschloo_+3A_conf.level">conf.level</code></td>
<td>

<p>confidence level
</p>
</td></tr>
<tr><td><code id="boschloo_+3A_midp">midp</code></td>
<td>
<p>logical. Use mid-p-value method?
</p>
</td></tr>
<tr><td><code id="boschloo_+3A_tsmethod">tsmethod</code></td>
<td>
<p>two-sided method, either &quot;central&quot; or &quot;minlike&quot; (see details)</p>
</td></tr>
<tr><td><code id="boschloo_+3A_control">control</code></td>
<td>
<p>list of algorithm parameters, see <code><a href="#topic+ucControl">ucControl</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The traditional Boschloo (1970) test is to use Fisher's exact p-values (under the null that p1=p2) to order the sample space and to use that ordering to perform an unconditional exact test. Here we generalize this to test for different null hypothesis values (other that odds ratios of 1). 
</p>
<p>For the two-sided alternatives, the traditional method uses 
tsmethod='minlike' (for example, in the Exact R package)
but our default is tsmethod='central'. The one-sided tests use ordering by 
the appropriate p-value (or 1 minus the p-value for alternative='greater' so that the ordering function follows our convention for user supplied ordering functions, see method='user' option in <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>).
</p>
<p>The option <code>midp</code> orders the sample space by the mid-p value associated with 
Fisher's exact test, and additionally gives mid-p values. This means that unlike the <code>midp=FALSE</code> case, when <code>midp=TRUE</code> the test is not exact (i.e., guaranteed to bound the type I error rate at the nominal level), but has type I error rates that are on average (over the possible null parameter values) closer to the nominal level. 
</p>
<p>If you want to order by the mid-p values from Fisher's exact test but get an exact test, use the <code>method="FisherAdj"</code> with <code>midp=FALSE</code> in <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>. 
</p>
<p>The <code>boschloo</code> function only gives confidence intervals for the odds ratio, for getting confidence intervals closely related to Boschloo p-values (but not exactly matching Boschloo p-values) for the difference or ratio, use <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code> with <code>method="FisherAdj"</code>.
</p>


<h3>Value</h3>

<p>a list of class 'htest' with elements:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>proportion in sample 1</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>proportion in sample 2</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value from test</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>confidence interval on odds ratio</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>odds ratio estimate</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>null hypothesis value of odds ratio</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>description of data</p>
</td></tr>
</table>


<h3>References</h3>

<p>Boschloo, R. D. &quot;Raised conditional level of significance for the 2x2-table when testing the equality of two probabilities.&quot; Statistica Neerlandica 24.1 (1970): 1-9.
</p>


<h3>See Also</h3>

   <p><code>exact.test</code> in package <a href="https://CRAN.R-project.org/package=Exact"><span class="pkg">Exact</span></a> for Boschloo test p-value computation. Also see <code>method"FisherAdj"</code> in <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code> for a closely related test. </p>


<h3>Examples</h3>

<pre><code class='language-R'># defaults to the central two-sided version
boschloo(1,5,6,7)
boschloo(1,5,6,7,alternative="greater")
## traditional two-sided Boschloo test (not central!)
boschloo(1,5,6,7, tsmethod="minlike")
</code></pre>

<hr>
<h2 id='calcTall'>
Calculate all Tstat for all values of the (n1+1) X (n2+1) sample space from the two sample binomial problem.
</h2><span id='topic+calcTall'></span>

<h3>Description</h3>

<p>Used mostly by internal call from <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>.
If <code>EplusM=FALSE</code> and <code>tiebreak=FALSE</code> then the result is just
<code>Tstat(allx,n1,ally,n2,delta0)</code>. Otherwise does more complicated 
calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcTall(Tstat, allx, n1, ally, n2, delta0 = 0, parmtype = "difference", 
    alternative = "two.sided", tsmethod = "central", EplusM = FALSE, tiebreak = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcTall_+3A_tstat">Tstat</code></td>
<td>

<p>ordering function
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_allx">allx</code></td>
<td>

<p>vector of x1 values, typically rep(0:n1,n2+1)
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_n1">n1</code></td>
<td>

<p>sample size in group 1 
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_ally">ally</code></td>
<td>

<p>vector of x2 values, typically rep(0:n2,each=n1+1)
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_n2">n2</code></td>
<td>

<p>sample size in group 2
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_delta0">delta0</code></td>
<td>

<p>null parameter value for input into Tstat
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_parmtype">parmtype</code></td>
<td>

<p>parmeter type, either 'difference', 'ratio', or 'oddsratio'
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_alternative">alternative</code></td>
<td>

<p>alternative hypothesis, either 'two.sided' or not
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_tsmethod">tsmethod</code></td>
<td>

<p>two-sided method, either 'central' or 'square'  
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_eplusm">EplusM</code></td>
<td>

<p>logical, do E+M ordering of Lloyd (2008)?
</p>
</td></tr>
<tr><td><code id="calcTall_+3A_tiebreak">tiebreak</code></td>
<td>

<p>logical, do tie break method? Only allowed when tsmethod!='square'.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>tiebreak=TRUE</code> does a method that breaks ties in the ordering function differently  depending on the <code>parmtype</code> value. The tie breaks are developed to make sense when <code>method="simple"</code> and <code>tsmethod!="square"</code>, when applied to other methods it may not necessarily break ties reasonably. For that reason <code>tiebreak=TRUE</code> returns an error when <code>tsmethod="square"</code>. For <code>parmtype="difference"</code> ties are broken based on Z scores on the difference in proportions, with larger values of <code>Z</code>
treated as larger. This means that when the sample proportions are equal,
the ties are not broken. For <code>parmtype="ratio"</code> ties are broken based
on <code>abs(Z)</code>, where the Z scores are based on the difference in log proportions, except when x1=0 (when ties are broken by x2) or x2=0 (when ties are broken by 1/x1). For <code>parmtype="oddsratio"</code> ties are broken based
on <code>abs(Z)</code>, where here the Z scores are based on the 
difference in log odds, except when x1=0 or x1=n1 or x2=0 or x2=n2 (see code for specifics). 
</p>
<p>The E+M method, is to take an existing ordering function, Tstat, and calculate
a one-sided p-value based on that ordering function evaluated at the constrained 
maximum likelihood estimates of the parameters. The ordering is then 
the set of one-sided p-values from Pr[T(X)&lt;=T(xobs)],  except when 
<code>alternative="two.sided"</code> and <code>tsmethod="square"</code> in which case 
it is 1-p, where p, the p-value, is based on Pr[T(X)&gt;=T(xobs)]. The latter exception is needed so that larger values are more likely to reject.
</p>
<p>If <code>tiebreak=TRUE</code> and <code>EplusM=TRUE</code>, the teibreak calculations are always done first. 
</p>


<h3>Value</h3>

<p>a vector of the same length as allx, giving values of Tstat function at all
values in the sample space.
</p>

<hr>
<h2 id='constrMLE.difference'>Calculate constrained MLEs.
</h2><span id='topic+constrMLE.difference'></span><span id='topic+constrMLE.ratio'></span><span id='topic+constrMLE.oddsratio'></span><span id='topic+constrMLE'></span>

<h3>Description</h3>

<p>Calculate the constrained maximum likelihood estimate from 
2 independent binomials for the null hypothesis parameter (difference, ratio, or odds ratio of the two binomial parameters).</p>


<h3>Usage</h3>

<pre><code class='language-R'>constrMLE.difference(X1, N1, X2, N2, delta0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constrMLE.difference_+3A_x1">X1</code></td>
<td>
<p>vector, number of events in group 1</p>
</td></tr>
<tr><td><code id="constrMLE.difference_+3A_n1">N1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="constrMLE.difference_+3A_x2">X2</code></td>
<td>
<p>vector, number of events in group 2</p>
</td></tr>
<tr><td><code id="constrMLE.difference_+3A_n2">N2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code id="constrMLE.difference_+3A_delta0">delta0</code></td>
<td>
<p>null parameter value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details see 
Farrrington and Manning (1990) for the difference, 
Miettinen and Nurminen (1985) for the ratio,
and 
Agresti and Min (2002) for the odds ratio.
</p>


<h3>Value</h3>

<p>a list with the constrained MLE parameters, p1 and p2.
</p>


<h3>References</h3>

<p>Agresti and Min 2002, Biostatistics 3:379-386.
</p>
<p>Farrrington and Manning, Stat in Med 1990, 1447-1454.
</p>
<p>Miettinen, 0. and Nurminen, M. (1985). Comparative analysis
of two rates. Statistics in Medicine 4, 213-226.
</p>

<hr>
<h2 id='exact2x2'>Exact Conditional Tests for 2 by 2 Tables of Count Data</h2><span id='topic+exact2x2'></span><span id='topic+fisher.exact'></span><span id='topic+blaker.exact'></span><span id='topic+mcnemar.exact'></span>

<h3>Description</h3>

<p>Performs exact conditional tests for two by two tables. For independent binary responses, performs 
either Fisher's exact test or Blaker's exact test for testing hypotheses about the odds ratio. 
The commands follow the style of  <code><a href="stats.html#topic+fisher.test">fisher.test</a></code>, the difference is that
for two-sided tests there are three methods for calculating the exact test, and for each of the three methods
its matching 
confidence interval is returned (see details).  
For paired binary data resulting in a two by two table, performs an exact McNemar's test.</p>


<h3>Usage</h3>

<pre><code class='language-R'>exact2x2(x, y = NULL, or = 1, alternative = "two.sided",
    tsmethod = NULL, conf.int = TRUE, conf.level = 0.95,
    tol = 0.00001, conditional = TRUE, paired=FALSE, 
    plot=FALSE, midp=FALSE)
fisher.exact(x, y = NULL, or = 1, alternative = "two.sided",
    tsmethod = "minlike", conf.int = TRUE, conf.level = 0.95,
    tol = 0.00001, midp=FALSE)
blaker.exact(x, y = NULL, or = 1, alternative = "two.sided",
    conf.int = TRUE, conf.level = 0.95, tol = 0.00001)
mcnemar.exact(x,y=NULL, conf.level=.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exact2x2_+3A_x">x</code></td>
<td>
<p>either a two-dimensional contingency table in matrix form,
or a factor object.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_y">y</code></td>
<td>
<p>a factor object; ignored if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_or">or</code></td>
<td>
<p>the hypothesized odds ratio. Must be a single numeric.  </p>
</td></tr>
<tr><td><code id="exact2x2_+3A_alternative">alternative</code></td>
<td>
<p>indicates the alternative hypothesis and must be
one of <code>"two.sided"</code>, <code>"greater"</code> or <code>"less"</code>.
if &quot;two.sided&quot; uses method defined by tsmethod.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_tsmethod">tsmethod</code></td>
<td>
<p>one of &quot;minlike&quot;,&quot;central&quot;, or &quot;blaker&quot;. NULL defaults to &quot;minlike&quot; when 
paired=FALSE and &quot;central&quot; when paired=TRUE or midp=TRUE.
Defines type of two-sided method (see details). Ignored if alternative=&quot;less&quot; or &quot;greater&quot;.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_conf.int">conf.int</code></td>
<td>
<p>logical indicating if a confidence interval should be
computed.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the returned confidence
interval.  Only used if
<code>conf.int = TRUE</code>.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_tol">tol</code></td>
<td>
<p>tolerance for confidence interval estimation.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_conditional">conditional</code></td>
<td>
<p>TRUE. Unconditional exact tests should use <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>.</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_paired">paired</code></td>
<td>
<p>logical. TRUE gives exact McNemar's test, FALSE are all other tests</p>
</td></tr>
<tr><td><code id="exact2x2_+3A_midp">midp</code></td>
<td>
<p>logical. TRUE gives mid p-values and mid-p CIs. Not supported for tsmethod='minlike' or 'blaker' </p>
</td></tr>
<tr><td><code id="exact2x2_+3A_plot">plot</code></td>
<td>
<p>logical. TRUE gives basic plot of point null odds ratios by p-values, for greater plot control use <code><a href="#topic+exact2x2Plot">exact2x2Plot</a></code>. Not supported for midp=TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The motivation for this package is to match the different two-sided conditional exact tests 
for 2x2 tables with the appropriate confidence intervals. 
</p>
<p>There are three ways to calculate the two-sided conditional exact tests, 
motivated by three different ways to define the p-value. 
The usual two-sided Fisher's exact test defines the p-value as the sum of probability
of tables with 
smaller likelihood than the observed table (<code>tsmethod</code>=&quot;minlike&quot;). 
The central Fisher's exact test defines the p-value as twice the one-sided p-values
(but with a maximum p-value of 1). Blaker's (2000) exact test defines the p-value
as the sum of the tail probibility in the observed tail plus the largest tail probability
in the opposite tail that is not greater than the observed tail probability. 
</p>
<p>In <code><a href="stats.html#topic+fisher.test">fisher.test</a></code> the p-value uses the two-sample method 
associated with <code>tsmethod</code>=&quot;minlike&quot;, but the confidence interval method 
associated with  <code>tsmethod</code>=&quot;central&quot;. The probability that the
lower central confidence limit is less than the true odds ratio is bounded by 
<code>1-(1-conf.level)/2</code> for the central intervals, but not for the other two two-sided 
methods.   
The confidence intervals in for <code>exact2x2</code> match the test associated 
with alternative. In other words, the confidence interval is the smallest interval that contains the confidence set that is 
the inversion of the associated test (see Fay, 2010).
The functions <code>fisher.exact</code> and <code>blaker.exact</code> are just wrappers for certain
options in  <code>exact2x2</code>.
</p>
<p>If <code>x</code> is a matrix, it is taken as a two-dimensional contingency
table, and hence its entries should be nonnegative integers.
Otherwise, both <code>x</code> and <code>y</code> must be vectors of the same
length.  Incomplete cases are removed, the vectors are coerced into
factor objects, and the contingency table is computed from these.
</p>
<p>P-values are obtained directly using the (central or non-central) hypergeometric
distribution. 
</p>
<p>The null of conditional
independence is equivalent to the hypothesis that the odds ratio
equals one.  &lsquo;Exact&rsquo; inference can be based on observing that in
general, given all marginal totals fixed, the first element of the
contingency table has a non-central hypergeometric distribution with
non-centrality parameter given by the odds ratio (Fisher, 1935).  The
alternative for a one-sided test is based on the odds ratio, so
<code>alternative = "greater"</code> is a test of the odds ratio being bigger
than <code>or</code>.
</p>
<p>When paired=TRUE, this denotes there is some pairing of the data. For example, 
instead of Group A and Group B, we may have pretest and posttest binary responses. 
The proper two-sided test for such a setup is McNemar's Test, which only uses the off-diagonal
elements of the 2x2 table, and tests that both are equal or not. The exact version 
is based on the binomial distribution on one of the off-diagonal values conditioned on the total 
of both off-diagonal values. We use <code><a href="exactci.html#topic+binom.exact">binom.exact</a></code> from the <code>exactci</code> package, and convert the 
p estimates and confidence intervals (see note) to odds ratios (see Breslow and Day, 1980, p. 165). The function 
<code>mcnemar.exact</code> is just a wrapper to call <code>exact2x2</code> with <code>paired=TRUE, alternative="two.sided",tsmethod="central"</code>. 
One-sided exact McNemar-type tests may be calculated using the  <code>exact2x2</code> function with <code>paired=TRUE</code>.
For details of McNemar-type tests see Fay (2010, R Journal). 
</p>
<p>The mid p-value is an adjusted p-value to account for discreteness. The mid-p adjustment is not guaranteed to give type I error rates that are less than or equal to nominal levels, but gives p-values that lead to the probability of rejection that is sometimes less than the nominal level and sometimes greater than the nominal level. This adjustment is sometimes used because exact p-values for discrete data cannot give actual type I error rates equal to the nominal value unless randomization is done (and that is not typically done because two researchers doing the same method could get different answers). Essentially, exact p-values lead to the probability of rejecting being less than the nominal level for most parameter values in the null hypothesis in order to make sure that it is not greater than the nominal level for ANY parameter values in the null hypothesis. The mid p-value was studied by Lancaster (1961), and for the 2x2 case by Hirji et al (1991).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the odds ratio</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>an estimate of the odds ratio.  Note that the
<em>conditional</em> Maximum Likelihood Estimate (MLE) rather than the
unconditional MLE (the sample odds ratio) is used.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the odds ratio under the null, <code>or</code>.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string, changes depending on alternative and tsmethod</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data</p>
</td></tr>
</table>


<h3>Note</h3>

<p> The default exact confidence intervals for the odds ratio when paired=TRUE (those matching the exact McNemar's test) 
are transformations of the Clopper-Pearson exact confidence intervals for a single binomial parameter which are central intervals. 
See note for <code><a href="exactci.html#topic+binom.exact">binom.exact</a></code> for discussion of exact binomial confidence intervals. </p>


<h3>Author(s)</h3>

<p>Michael Fay
</p>


<h3>References</h3>

<p>Blaker, H. (2000) Confidence curves and improved exact confidence intervals for discrete distributions.
Canadian Journal of Statistics 28: 783-798.
</p>
<p>Breslow, NE and Day NE (1980). Staistical Methods in Cancer Research: Vol 1-The analysis of Case-Control Studies.
IARC Scientific Publications. IARC, Lyon.
</p>
<p>Fay, M. P. (2010). Confidence intervals that Match Fisher's exact and Blaker's exact tests. Biostatistics,
11: 373-374 (go to doc directory for earlier version or 
<a href="https://www.niaid.nih.gov/about/brb-staff-fay">https://www.niaid.nih.gov/about/brb-staff-fay</a> for link to official version).
</p>
<p>Fay M.P. (2010). Two-sided Exact Tests and Matching Confidence Intervals for Discrete Data. R Journal 2(1):53-58.
</p>
<p>Fisher, R.A. (1935) The logic of inductive inference. Journal of the Royal Statistical Society
Series A 98:39-54.
</p>
<p>Hirji, K.F., Tan, S-J, and Elashoff, R.M. (1991). A quasi-exact test for comparing two binomial proportions. Statistics in Medicine 10: 1137-1153.
</p>
<p>Lancaster, H.O. (1961). Significance tests in discrete distributions. JASA 56: 223-234.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fisher.test">fisher.test</a></code> or <code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## In example 1, notice how fisher.test rejects the null at the 5 percent level, 
## but the 95 percent confidence interval on the odds ratio contains 1 
## The intervals do not match the p-value.
## In fisher.exact you get p-values and the matching confidence intervals 
example1&lt;-matrix(c(6,12,12,5),2,2,dimnames=list(c("Group A","Group B"),c("Event","No Event")))
example1
fisher.test(example1)
fisher.exact(example1,tsmethod="minlike")
fisher.exact(example1,tsmethod="central")
blaker.exact(example1)
## In example 2, this same thing happens, for
## tsmethod="minlike"... this cannot be avoided because 
## of the holes in the confidence set.
##  
example2&lt;-matrix(c(7,255,30,464),2,2,dimnames=list(c("Group A","Group B"),c("Event","No Event")))
example2
fisher.test(example2)
exact2x2(example2,tsmethod="minlike")
## you can never get a test-CI inconsistency when tsmethod="central"
exact2x2(example2,tsmethod="central")
</code></pre>

<hr>
<h2 id='exact2x2-internal'>Internal functions for exact2x2. Not to be called by user.</h2><span id='topic+exact2x2CI'></span><span id='topic+mcnemar.exact.calc'></span><span id='topic+fisherCalcMidp'></span><span id='topic+exact2x2Pvals'></span><span id='topic+binomMeldCalcInt'></span><span id='topic+binomMeldCalcMC'></span>

<h3>Description</h3>

<p>The function <code>exact2x2Pvals</code> can calculate p-values for a vector of odds ratios.
The function <code>exact2x2CI</code> is the code that calculates the confidence intervals for the two-sided 
Fisher's exact test and Blaker's exact test.  The functions <code>binomMeldCalcInt</code> and <code>binomMeldCalcMC</code>
are called by <code><a href="#topic+binomMeld.test">binomMeld.test</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisherCalcMidp(x,or,alternative,conf.int,conf.level)
exact2x2Pvals(x, or, relErr=1+10^(-7),tsmethod = "minlike", alternative="two.sided")
exact2x2CI(x, tsmethod="minlike", conf.level=0.95, tol=0.00001, orRange=c(10^-10,10^10))
mcnemar.exact.calc(bb,cc,or,alternative,tsmethod="central",conf.level=.95, midp=FALSE)
binomMeldCalcInt(x1,n1,x2,n2,nullparm=NULL, 
           parmtype=c("difference","oddsratio","ratio"),
           conf.level=0.95, conf.int=TRUE,
           alternative=c("two.sided","less","greater"), midp=FALSE, eps=10^-8)
binomMeldCalcMC(x1,n1,x2,n2,nullparm=NULL, 
                           parmtype=c("difference","oddsratio","ratio"),
                           conf.level=0.95, conf.int=TRUE,
                           alternative=c("two.sided","less","greater"),
                           midp=FALSE,nmc=10^6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exact2x2-internal_+3A_x">x</code></td>
<td>
<p>matrix representing 2 by 2 table</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_or">or</code></td>
<td>
<p>odds ratio, may be a vector</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_relerr">relErr</code></td>
<td>
<p>relative error. This is used to handle true ties on the computer. (see details). </p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_tsmethod">tsmethod</code></td>
<td>
<p>either &quot;minlike&quot;,&quot;blaker&quot;, &quot;central&quot;</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_conf.int">conf.int</code></td>
<td>
<p>logical, calculate CI?</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_tol">tol</code></td>
<td>
<p>tolerance</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_orrange">orRange</code></td>
<td>
<p>range for search for odds ratio confidence interval</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_alternative">alternative</code></td>
<td>
<p>indicates the alternative hypothesis and must be
one of <code>"two.sided"</code>, <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="exact2x2-internal_+3A_midp">midp</code></td>
<td>
<p>logical. Do midp adjustment?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>P-values for both the two-sided Fisher's exact and Blaker's exact test add probabilities from the opposite tail if 
either the cumulative probabilities (for Blaker's test) or the probabilities (Fisher's test) are less than or equal to those 
of the observed tail. Since sometimes the p-value at odds ratio=1 is important, we may have problems if the opposite tail is 
some very small different probability due to computer rounding, when mathematically the probabilities are exactly the same 
and should be included. To get around this problem <code><a href="stats.html#topic+fisher.test">fisher.test</a></code> uses relErr so that it chooses all
d&lt;= d[i]*relErr and if mathematically d[i] is equal to another value in d but there is a slightly computer rounding error, that value
will be included. We use the same tactic here.
</p>
<p>The function <code>mcnemar.exact.calc</code> is just a simple call to <code>binom.test</code> with 
<code>p=.5</code>.
</p>


<h3>Value</h3>

<p>Output from <code>exact2x2Pvals</code> is a LIST, with
</p>
<table>
<tr><td><code>or</code></td>
<td>
<p>vector of odds ratios</p>
</td></tr>
<tr><td><code>pvals</code></td>
<td>
<p>vector of two-sided p-values</p>
</td></tr>
</table>
<p>Output from <code>exact2x2CI</code> is a confidence interval with attributes: conf.level and conf.int.prec (a list 
of the bounds on the precision of the limits).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exact2x2">exact2x2</a></code> </p>

<hr>
<h2 id='exact2x2-package'>
Exact Tests and Confidence Intervals for 2x2 Tables
</h2><span id='topic+exact2x2-package'></span>

<h3>Description</h3>

<p>There are 8 main functions in the package. 
The <code><a href="#topic+exact2x2">exact2x2</a></code> function calculates the exact conditional tests with matching confidence intervals as detailed in Fay (2010a &lt;DOI:10.1093/biostatistics/kxp050&gt;,2010b). The functions <code><a href="#topic+ss2x2">ss2x2</a></code> and <code><a href="#topic+power2x2">power2x2</a></code> calculate the sample size and power related to the tests of <code>exact2x2</code>. The <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>
and <code><a href="#topic+boschloo">boschloo</a></code> functions calculate unconditional exact tests (see Fay  and Hunsberger, 2021, &lt;DOI:10.1214/21-SS131&gt;).
The <code><a href="#topic+binomMeld.test">binomMeld.test</a></code> function calculates melded confidence intervals for two sample binomial inferences (see Fay, Proschan, and Brittain, 2015 &lt;DOI:10.1111/biom.12231&gt;).
Finally, the <code><a href="#topic+borrTest">borrTest</a></code> function calculates the boundary optimized rejection region test that 
creates unconditional exact tests that have power optimized when group 1 is expected to have 100 percent failure. For example, in vaccine challenge studies where the control group are all expected to get infected (see Gabriel, et al, 2018 &lt;DOI:10.1002/sim.7579&gt;, the letter about that paper by Martin Andres &lt;DOI:10.1002/sim.7630&gt;, and the response &lt;DOI:10.1002/sim.7684&gt;). The  <code><a href="#topic+mcnemarExactDP">mcnemarExactDP</a></code> function give p-values and confidence intervals compatible with exact McNemar's or sign tests (Fay and Lumbard, 2021, &lt;DOI:10.1002/sim.8829&gt;).
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> bpcp</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.6.9</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-01-25</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL3</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Michael P. Fay, Sally A. Hunsberger, Martha Nason, Erin Gabriel, Keith Lumbard
</p>
<p>Maintainer: Michael P. Fay &lt;mfay@niaid.nih.gov&gt;
</p>


<h3>References</h3>

<p>Fay, M. P. (2010a). Confidence intervals that Match Fisher's exact and Blaker's exact tests. Biostatistics,
11: 373-374 (go to doc directory for earlier version or 
<a href="https://www.niaid.nih.gov/about/brb-staff-fay">https://www.niaid.nih.gov/about/brb-staff-fay</a> for link to official version).
</p>
<p>Fay, M.P. (2010b). Two-sided Exact Tests and Matching Confidence Intervals for Discrete Data. R Journal 2(1):53-58.
</p>
<p>Fay, M.P. and Hunsberger, S.A. (2021). Practical Valid Inferences for the Two-Sample Binomial Problem. Statistics Surveys 15:72-110.
</p>
<p>Fay, MP, Proschan, MA, and Brittain, E (2015). Combining One Sample Confidence Procedures for Inference in the Two Sample Case. Biometrics. 71: 146-156. 
</p>
<p>Gabriel, EE, Nason, M, Fay, MP, and Follmann, DA. (2018). A boundary-optimized rejection region test for the two-sample binomial problem. Statistics in Medicine. 37(7): 1047-1058  (DOI: 10.1002/sim.7579).
</p>
<p>Gabriel, EE, Nason, M, Fay, MP, and Follmann, DA. (2018). Reply to letter from Martin Andres. Statistics in Medicine 37(14): 2303-2306.
</p>
<p>Martin Andres, Antonio. (2018). Letter to the editor about Gabriel et al. Statistics in Medicine 37(14) 2301-2302.
</p>

<hr>
<h2 id='exact2x2Plot'> Plot p-value function for one 2 by 2 table.
</h2><span id='topic+exact2x2Plot'></span>

<h3>Description</h3>

<p>Plots two-sided p-values as a function of odds ratios. Can plot three types of p-values: the two-sided Fisher's exact, the central 
Fisher's exact (i.e., twice the one-sided Fisher's exact), and Blaker's exact.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exact2x2Plot(x, y=NULL, OR = NULL, ndiv = 1000, tsmethod=NULL,
    method = NULL, paired=FALSE, orRange = NULL, dolog = TRUE,
    dolines = FALSE, dopoints = TRUE, doci=TRUE,  
    alternative=c("two.sided","less","greater"),
    conf.level=.95, alphaline=TRUE, newplot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exact2x2Plot_+3A_x">x</code></td>
<td>
<p>matrix representing the 2 by 2 table</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_y">y</code></td>
<td>
<p>a factor object; ignored if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_or">OR</code></td>
<td>
<p>odds ratio values for plot, if NULL divides orRange into ndiv pieces</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_ndiv">ndiv</code></td>
<td>
<p>number of pieces to divide up odds ratio range</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_tsmethod">tsmethod</code></td>
<td>
<p>either &quot;minlike&quot;,&quot;blaker&quot; or &quot;central&quot;</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_method">method</code></td>
<td>
<p>same as tsmethod, kept for backward compatability</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_paired">paired</code></td>
<td>
<p>logical, do paired analysis giving McNemar's test p-values</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_orrange">orRange</code></td>
<td>
<p>range for calculating odds ratios</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_dolog">dolog</code></td>
<td>
<p>logical,plot odds ratios on log scale?</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_dolines">dolines</code></td>
<td>
<p>logical, add lines to a plot?</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_dopoints">dopoints</code></td>
<td>
<p>logical, add points to a plot?</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_doci">doci</code></td>
<td>
<p>logical, add vertical lines at confidence interval?</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_alternative">alternative</code></td>
<td>
<p>one of &quot;two.sided&quot;,&quot;less&quot;,&quot;greater&quot;, type of alternative for p-values</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_conf.level">conf.level</code></td>
<td>
<p>when doci=TRUE, level for confidence interval to be plotted</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_alphaline">alphaline</code></td>
<td>
<p>logical, if doci=TRUE should a line be drawn at the significance level?</p>
</td></tr>  
<tr><td><code id="exact2x2Plot_+3A_newplot">newplot</code></td>
<td>
<p>logical,start a new plot?</p>
</td></tr>
<tr><td><code id="exact2x2Plot_+3A_...">...</code></td>
<td>
<p>values passed to plot, points, or lines statement</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+exact2x2">exact2x2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>example1&lt;-matrix(c(6,12,12,5),2,2,dimnames=list(c("Group A","Group B"),c("Event","No Event")))
example1
exact2x2Plot(example1)
## add lines from central Fisher's exact
exact2x2Plot(example1,method="central",dolines=TRUE,newplot=FALSE,col="red")
</code></pre>

<hr>
<h2 id='mcnemarExactDP'>Exact McNemar (Paired Binary) Test with Difference in Proportions</h2><span id='topic+mcnemarExactDP'></span>

<h3>Description</h3>

<p>Gives a valid (i.e., exact) test of paired binary responses, with compatible confidence intervals on the difference in proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcnemarExactDP(x, m, n, nullparm = 0, alternative = c("two.sided", "less", "greater"), 
    conf.level = 0.95, nmc = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcnemarExactDP_+3A_m">m</code></td>
<td>

<p>number of pairs with mismatched responses  
</p>
</td></tr>
<tr><td><code id="mcnemarExactDP_+3A_x">x</code></td>
<td>

<p>number of pairs with response of 1 for treatment and 0 for control
</p>
</td></tr>
<tr><td><code id="mcnemarExactDP_+3A_n">n</code></td>
<td>

<p>total number of pairs
</p>
</td></tr>
<tr><td><code id="mcnemarExactDP_+3A_nullparm">nullparm</code></td>
<td>

<p>null parameter value for the difference in proportions: proportion with events on treatment minus proportion with events on control
</p>
</td></tr>
<tr><td><code id="mcnemarExactDP_+3A_alternative">alternative</code></td>
<td>

<p>alternative hypothesis, must be one of &quot;two.sided&quot;, &quot;greater&quot; or &quot;less&quot;</p>
</td></tr>
<tr><td><code id="mcnemarExactDP_+3A_conf.level">conf.level</code></td>
<td>

<p>confidence level for the returned confidence interval
</p>
</td></tr>
<tr><td><code id="mcnemarExactDP_+3A_nmc">nmc</code></td>
<td>

<p>number of Monte Carlo replications, nmc=0 (default) uses numeric integration instead
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For paired binary responses, a simple test is McNemars test, which conditions on the number of discordant pairs. 
The <code><a href="#topic+mcnemar.exact">mcnemar.exact</a></code> function gives results in terms of odds ratios. This function gives results in terms 
of the difference in proportions. The p-values will be identical between the two functions, but the estimates and 
confidence intervals will be different.
</p>
<p>For this function, we use the melding idea (Fay, et al, 2015), to create compatable confidence intervals
with exact versions of McNemars test. For details see Fay and Lumbard (2021).
See Fagerland, et al (2013) for other parameters and methods related to paired binary responses. 
The advantage of this version is that it is exact, and faster than the unconditional exact methods (which may be more powerful). 
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the difference in proportions</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>sample proportions and their difference</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>difference in proportions under the null</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string describing the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael P. Fay, Keith Lumbard
</p>


<h3>References</h3>

<p>Fay, MP, Proschan, MA, and Brittain, E (2015). Combining one-sample confidence procedures for inference in the two-sample case. Biometrics,71(1),146-156.
</p>
<p>Fay MP, and Lumbard, K (2021). Confidence Intervals for Difference in Proportions for Matched Pairs Compatible with Exact McNemars or Sign Tests. Statistics in Medicine, 40(5): 1147-1159.
</p>
<p>Fagerland, Lydersen and Laake (2013), Recommended tests and confidence
intervals for paired binomial proportions. Statitics in Medicine, 33:2850-2875.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+mcnemar.exact">mcnemar.exact</a></code> or <code><a href="#topic+exact2x2">exact2x2</a></code> with paired=TRUE for confidence intervals on the odds ratio.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For test on contingency table of the pairs
# From Bentur, et al (2009) Pediatric Pulmonology 44:845-850.
# see also Table II of Fagerland, Lydersen and Laake 
# (2013, Stat in Med, 33: 2850-2875)
# 
#                 After SCT
#                 AHR       No AHR
#              ----------------- 
# Before SCT  |    
#         AHR |    1         1 
#      No AHR |    7        12
#              -----------------

ahr&lt;-matrix(c(1,7,1,12),2,2,
            dimnames=list(paste("Before SCT,",c("AHR","No AHR")),
                          paste("After SCT,",c("AHR","No AHR"))))
mcnemarExactDP(n=sum(ahr),m=ahr[1,2]+ahr[2,1], x=ahr[1,2])
# compare to mcnemar.exact
# same p-value, but mcnemar.exact gives conf int on odds ratio 
mcnemar.exact(ahr)
</code></pre>

<hr>
<h2 id='pickTstat'>
Pick T statistic (ordering function) for unconditional exact test.</h2><span id='topic+pickTstat'></span>

<h3>Description</h3>

<p>Called from <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pickTstat(method, parmtype, tsmethod, alternative)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pickTstat_+3A_method">method</code></td>
<td>

<p>method type, one of &quot;simple&quot;, &quot;wald-pooled&quot;, &quot;wald-unpooled&quot;, &quot;score&quot; (see details) 
</p>
</td></tr>
<tr><td><code id="pickTstat_+3A_parmtype">parmtype</code></td>
<td>

<p>type of parameter of interest, one of &quot;difference&quot;, &quot;ratio&quot; or &quot;oddsratio&quot; 
(see details)</p>
</td></tr>
<tr><td><code id="pickTstat_+3A_tsmethod">tsmethod</code></td>
<td>
<p>two-sided method, either &quot;central&quot; or &quot;square&quot; (see details) </p>
</td></tr>
<tr><td><code id="pickTstat_+3A_alternative">alternative</code></td>
<td>

<p>alternative hypothesis, one of &quot;two.sided&quot;, &quot;less&quot;, or &quot;greater&quot;, default is &quot;two.sided&quot; 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See 'details' section of <code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>.
</p>


<h3>Value</h3>

<p>A function that has the following arguments:
</p>
<table>
<tr><td><code>X1</code></td>
<td>
<p>vector, number of events in group 1</p>
</td></tr>
<tr><td><code>N1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code>X2</code></td>
<td>
<p>vector, number of events in group 2</p>
</td></tr>
<tr><td><code>N2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code>delta0</code></td>
<td>
<p>null parameter value</p>
</td></tr>
</table>
<p>and outputs a vector the same length as X1 and X2.  
</p>

<hr>
<h2 id='plotT'>
Plot or Print  ordering function for unconditional exact test
</h2><span id='topic+plotT'></span><span id='topic+plotT.function'></span><span id='topic+plotT.numeric'></span><span id='topic+orderMat'></span><span id='topic+orderMat.function'></span><span id='topic+orderMat.numeric'></span>

<h3>Description</h3>

<p>The function <code>orderMat</code> prints the values for the ordering function for all
possible values of X1 and X2 in matrix form.
</p>
<p>The function <code>plotT</code> plots the ranking of the ordering function on an n1+1 by n2+1 grid,
where each square represents a possible values for (x1,x2).
The default colors are from dark blue (highest) to light blue to white 
(middle) to light red to dard red (lowest), with black=NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotT(x, ...)

## S3 method for class 'function'
plotT(x, n1, n2, delta0 = 1, main = "",...)


## S3 method for class 'numeric'
plotT(x, n1, n2, delta0 = 1, main = "",...)


orderMat(x, ...)

## S3 method for class 'function'
orderMat(x,n1,n2,delta0,graphStyle=FALSE,...)

## S3 method for class 'numeric'
orderMat(x,n1,n2,delta0,graphStyle=FALSE,...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotT_+3A_x">x</code></td>
<td>

<p>object, either a Tstat function, or a vector of all (n1+1)*(n2+1) possible values of the function (see details).
</p>
</td></tr>
<tr><td><code id="plotT_+3A_n1">n1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="plotT_+3A_n2">n2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code id="plotT_+3A_delta0">delta0</code></td>
<td>

<p>null value of parameter (if needed for Tstat function)
</p>
</td></tr>
<tr><td><code id="plotT_+3A_main">main</code></td>
<td>

<p>plot title
</p>
</td></tr>
<tr><td><code id="plotT_+3A_graphstyle">graphStyle</code></td>
<td>

<p>logical, order rows with lowest x1 value on the bottom?   
</p>
</td></tr>
<tr><td><code id="plotT_+3A_...">...</code></td>
<td>

<p>arguments to be passed to the Tstat function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> is all the values of the Tstat function, then the values should be 
ordered by cycling through the x1 values (0 to n1) for each x2 value.
Specifically, it should be the result of <code>Tstat(X1,n1,X2,n2,delta0)</code>
where X1=rep(0:n1,n2+1) and X2=rep(0:n2,each=n1+1).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
parorig&lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2),mar=c(1,3,3,1))
TT1&lt;-pickTstat(method="score", parmtype="ratio", tsmethod="central", alternative="two.sided")
round(orderMat(TT1,8,8,1,graphStyle=TRUE),2)
TT2&lt;-pickTstat(method="simple", parmtype="ratio", tsmethod="central", alternative="two.sided")
TT3&lt;-pickTstat(method="simple", parmtype="difference", tsmethod="central", alternative="two.sided")
plotT(TT2, 8,8, 1, main="Ratio, Simple")
plotT(TT3, 8,8, 0, main="Difference, Simple")
plotT(TT1, 8,8, 1, main="Ratio, Score (delta0=1)")
TF&lt;-pickTstat(method="FisherAdj", parmtype="ratio", tsmethod="central", alternative="two.sided")
plotT(TF,8,8,1, main="FisherAdj")
par(parorig)
</code></pre>

<hr>
<h2 id='power2grid'>
Create grid for root search.
</h2><span id='topic+power2grid'></span><span id='topic+power2grid'></span><span id='topic+power2gridRatio'></span><span id='topic+power2gridDifference'></span>

<h3>Description</h3>

<p>Used with <code><a href="#topic+unirootGrid">unirootGrid</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power2grid(power2 = 3, from = 10, to = 1, dolog = TRUE)
power2gridRatio(power2 = 3)
power2gridDifference(power2 = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power2grid_+3A_power2">power2</code></td>
<td>

<p>positive integer, determines length of grid, <code>length(grid)=1+2^power2</code>
</p>
</td></tr>
<tr><td><code id="power2grid_+3A_from">from</code></td>
<td>

<p>lowest value of grid
</p>
</td></tr>
<tr><td><code id="power2grid_+3A_to">to</code></td>
<td>

<p>highest value of grid
</p>
</td></tr>
<tr><td><code id="power2grid_+3A_dolog">dolog</code></td>
<td>

<p>logical, make grid equally spaced on the log scale?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>power2gridRatio</code> gives a grid for searching from 0 to Inf
equally spaced on the log scale,
with about half of the observations from 0.5 to 2.
and <code>power2gridDifference</code> gives an equally spaced grid for searching from -1 to 1.
</p>


<h3>Value</h3>

<p>a vector for grid search of length <code>1+2^power2</code> for use in
<code><a href="#topic+unirootGrid">unirootGrid</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+unirootGrid">unirootGrid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>power2gridRatio(3)
power2gridDifference(3)
power2grid(3,from=-1,to=1,dolog=FALSE)
power2grid(3, from=1,to=9, dolog=FALSE)
power2grid(3, from=1,to=9, dolog=TRUE)

</code></pre>

<hr>
<h2 id='power2x2'>Calculate exact power or sample size for conditional tests for two independent binomials.
</h2><span id='topic+power2x2'></span><span id='topic+ss2x2'></span>

<h3>Description</h3>

<p>Power is calculated by <code>power2x2</code> which calls <code><a href="#topic+exact2x2">exact2x2</a></code> function repeatedly. Default (strict=FALSE) does not count rejections in the wrong direction. 
</p>
<p>Sample size is calculated by <code>ss2x2</code> which calls <code>power2x2</code> repeatedly finding the lowest sample size that has at least the nominal power, using the <code><a href="ssanv.html#topic+uniroot.integer">uniroot.integer</a></code> function from the <code>ssanv</code> package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power2x2(p0,p1,n0,n1=NULL,sig.level=0.05,
 alternative=c("two.sided","one.sided"),paired=FALSE,
 strict=FALSE,tsmethod=NULL,nullOddsRatio=1,
 errbound=10^-6,approx=FALSE)

ss2x2(p0,p1,power=.80,n1.over.n0=1,sig.level=0.05,
 alternative=c("two.sided","one.sided"),paired=FALSE,
 strict=FALSE,tsmethod=NULL,nullOddsRatio=1,
 errbound=10^-6,print.steps=FALSE, approx=FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power2x2_+3A_p0">p0</code></td>
<td>
<p> true event rate in control group </p>
</td></tr>
<tr><td><code id="power2x2_+3A_p1">p1</code></td>
<td>
<p> true event rate in treatment group</p>
</td></tr>
<tr><td><code id="power2x2_+3A_n0">n0</code></td>
<td>
<p> number of observations in control group </p>
</td></tr>
<tr><td><code id="power2x2_+3A_n1">n1</code></td>
<td>
<p> number of observations in treatment group (if NULL n1=n0)</p>
</td></tr>
<tr><td><code id="power2x2_+3A_sig.level">sig.level</code></td>
<td>
<p> significance level (Type I error probability) </p>
</td></tr>
<tr><td><code id="power2x2_+3A_power">power</code></td>
<td>
<p>minimum power for sample size calculation</p>
</td></tr> 
<tr><td><code id="power2x2_+3A_n1.over.n0">n1.over.n0</code></td>
<td>
<p>ratio of n1 over n0, allows for non-equal sample size allocation</p>
</td></tr>
<tr><td><code id="power2x2_+3A_alternative">alternative</code></td>
<td>
<p>character, either &quot;two.sided&quot; or &quot;one.sided&quot;, one sided tests the proper direction according to p0 and p1</p>
</td></tr>
<tr><td><code id="power2x2_+3A_strict">strict</code></td>
<td>
<p>use strict interpretation of two-sided test, if TRUE counts rejections in wrong direction</p>
</td></tr>
<tr><td><code id="power2x2_+3A_tsmethod">tsmethod</code></td>
<td>
<p>two.sided method, ignored if strict=FALSE, or alternative equals 'less' or 'greater'. 
see <code><a href="#topic+exact2x2">exact2x2</a></code> for details.</p>
</td></tr>
<tr><td><code id="power2x2_+3A_nulloddsratio">nullOddsRatio</code></td>
<td>
<p>null odds ratio value for tests</p>
</td></tr>
<tr><td><code id="power2x2_+3A_paired">paired</code></td>
<td>
<p>must be FALSE, for TRUE instead use <code><a href="#topic+powerPaired2x2">powerPaired2x2</a></code></p>
</td></tr>
<tr><td><code id="power2x2_+3A_print.steps">print.steps</code></td>
<td>
<p>logical, print steps for calculation of sample size?</p>
</td></tr>
<tr><td><code id="power2x2_+3A_errbound">errbound</code></td>
<td>
<p>bound on error of calculation </p>
</td></tr>
<tr><td><code id="power2x2_+3A_approx">approx</code></td>
<td>
<p>give sample size or power using normal approximation only</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assuming X0 ~ Binomial(n0,p0) and X1 ~ Binomial(n1,p1), 
calculates the power by repeatedly calling exact2x2 and summing probability of rejection. For speed, the function does not 
calculate the very unlikely values of X0 and X1 unless errbound=0. Power is exact, but may underestimate by at most errbound.
</p>
<p>When strict=FALSE we do not count rejections in the wrong direction. This means that we must know the direction of the rejection, so two.sided tests are calculated as one.sided tests (in the correct direction) with level equal to sig.level/2. This is like using the tsmethod='central'. 
</p>
<p>When <code>approx</code>=TRUE for <code>power2x2</code> use a continuity corrected normal approximation (Fleiss, 1981, p. 44). For <code>ss2x2</code> the calculations may be slow, so use 
<code>print.steps=TRUE</code> to see progress. 
</p>


<h3>Value</h3>

<p>Both <code>power2x2</code> and <code>ss2x2</code> return an object of class 'power.htest'. A list with elements
</p>
<table>
<tr><td><code>power</code></td>
<td>
<p>power to reject</p>
</td></tr>
<tr><td><code>n0</code></td>
<td>
<p>sample size in control group</p>
</td></tr>
<tr><td><code>n1</code></td>
<td>
<p>sample size in treatment group</p>
</td></tr>
<tr><td><code>p0</code></td>
<td>
<p> true event rate in control group </p>
</td></tr>
<tr><td><code>p1</code></td>
<td>
<p> true event rate in treatment group</p>
</td></tr>
<tr><td><code>sig.level</code></td>
<td>
<p> Significance level (Type I error probability) </p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis</p>
</td></tr>
<tr><td><code>note</code></td>
<td>
<p>note about error bound</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>There may be convergence issues using strict=FALSE with tsmethod=&quot;minlike&quot; or &quot;blaker&quot; since the power is not guaranteed to be increasing in the sample size.  
</p>


<h3>Note</h3>

<p> The calculations in ss2x2 can be slow when p0 is close to p1 and/or the power is large. If p0 and p1 are close with large power, it may be safer to first calculate ss2x2 with approx=TRUE
to see what the starting value will be close to. If the starting sample sizes are large (&gt;100), it may take a while.
</p>
<p>Note when strict=FALSE (default), the two.sided results at the 0.05 level for Fisher's exact test are like the one.sided Fisher's exact test at the 0.025 level.  
</p>


<h3>Author(s)</h3>

<p> Michael P. Fay </p>


<h3>References</h3>

 
<p>Fleiss. JL (1981) Statistical Methods for Rates and Proportions (second edition). Wiley. </p>


<h3>See Also</h3>

<p>See  <code><a href="ssanv.html#topic+ss.nonadh">ss.nonadh</a></code> function (refinement=&quot;Fisher.exact&quot;) from the <code>ssanv</code> package for calculation that accounts for nonadherence in proportion of subjects. That function calls <code><a href="stats.html#topic+fisher.test">fisher.test</a></code>. For power for McNemar-like test see <code><a href="#topic+powerPaired2x2">powerPaired2x2</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>power2x2(.2,.8,12,15)
# calculate sample size with 2:1 allocation to groups
ss2x2(.2,.8,n1.over.n0=2,power=.8,approx=TRUE)
ss2x2(.2,.8,n1.over.n0=2,power=.8,print.steps=TRUE)
</code></pre>

<hr>
<h2 id='powerPaired2x2'>
Power for exact McNemar's test
</h2><span id='topic+powerPaired2x2'></span>

<h3>Description</h3>

<p>Calculate the power for the exact McNemar's test (i.e., <code>exact2x2</code> with <code>paired=TRUE</code>) given the number of pairs
and the probability of a positive response only in the test individual in the pair (pb), and the probability of a positive response only in the control individual in the pair (pc).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerPaired2x2(pb, pc, npairs, sig.level = 0.05, 
   alternative = c("two.sided", "one.sided"), 
   strict = FALSE, nullOddsRatio = 1, errbound = 10^-6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerPaired2x2_+3A_pb">pb</code></td>
<td>

<p>probability of a (0,1) response for a pair, meaning negative response in the control individual and a positive response in the test individual
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_pc">pc</code></td>
<td>

<p>probability of a (1,0) response for a pair, meaning positive response in the control individual and a negative response in the test individual
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_npairs">npairs</code></td>
<td>

<p>the number of pairs
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_sig.level">sig.level</code></td>
<td>

<p>significance level (also called alpha-level)
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_alternative">alternative</code></td>
<td>

<p>either 'one.sided' or 'two.sided' (see <code>tsmethod</code> for two-sided method)
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_strict">strict</code></td>
<td>

<p>use strict interpretation in two-sided case (i.e., TRUE allows rejections in the 'wrong' direction)
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_nulloddsratio">nullOddsRatio</code></td>
<td>

<p>null odds ratio, internally passed to <code>or</code> argument of <code>exact2x2</code> with <code>paired=TRUE</code>
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_errbound">errbound</code></td>
<td>

<p>error bound, <code>errbound=0</code> does exact calculation, when <code>errbound&gt;0</code> then speed up calculations by not calculating outcomes at either extreme with tail probabilities less than errbound/2 which may underestimate power by at most errbound.
</p>
</td></tr>
<tr><td><code id="powerPaired2x2_+3A_...">...</code></td>
<td>

<p>arguments passed to <code><a href="#topic+exact2x2">exact2x2</a></code> (except these arguments cannot be passed this way: 
<code>or</code>, <code>alternative</code>, <code>conf.int</code>, <code>paired</code>, <code>plot</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>alternative='one.sided'</code> then the test automatically picks the side that is most powerful.
At this point there is no ssPaired2x2 function.
</p>


<h3>Value</h3>

<p>An object of class 'power.htest' with elements:


</p>
<table>
<tr><td><code>power</code></td>
<td>
<p>power</p>
</td></tr>
<tr><td><code>npairs</code></td>
<td>
<p>number of pairs</p>
</td></tr>
<tr><td><code>pb</code></td>
<td>
<p>probability of a (control,test)=(0,1) response for a pair</p>
</td></tr>
<tr><td><code>pc</code></td>
<td>
<p>probability of a (control,test)=(1,0) response for a pair</p>
</td></tr>
<tr><td><code>sig.level</code></td>
<td>
<p>significance level or alpha-level</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>either one-sided or two-sided</p>
</td></tr>
<tr><td><code>nullOddsRatio</code></td>
<td>
<p>null odds ratio (or boundary between null and alternative for one-sided tests)</p>
</td></tr>
<tr><td><code>note</code></td>
<td>
<p>notes about calculation (e.g., errbound value)</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description of method</p>
</td></tr>

</table>


<h3>Examples</h3>

<pre><code class='language-R'>powerPaired2x2(.5,.3,npairs=20)
</code></pre>

<hr>
<h2 id='ucControl'>
Algorithm variables used by uncondExact2x2.
</h2><span id='topic+ucControl'></span>

<h3>Description</h3>

<p>Function that gives list of algorithm variables used by 
<code><a href="#topic+uncondExact2x2">uncondExact2x2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ucControl(nCIgrid = 500, errbound = 0, nPgrid = 100, 
   power2 = 20, maxPgridRatio = 1 - 10^-6, 
   minPgridRatio = 10^-6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ucControl_+3A_ncigrid">nCIgrid</code></td>
<td>

<p>number of elements in the grid search for the confidence interval.
</p>
</td></tr>
<tr><td><code id="ucControl_+3A_errbound">errbound</code></td>
<td>

<p>Used with large sample sizes to speed calculations, only calculate univariate binomial distribution in the middle part, exclude both tails with less than errbound/2 in each tail. When errbound=0, calculate the full distributions. 
</p>
</td></tr>
<tr><td><code id="ucControl_+3A_npgrid">nPgrid</code></td>
<td>

<p>number of elements to search over the null parameter space.
</p>
</td></tr>
<tr><td><code id="ucControl_+3A_power2">power2</code></td>
<td>

<p>how precise to make the grid search for the confidence interval when using the &lsquo;faster&rsquo; algorithm (e.g., when method='user-fixed').
</p>
</td></tr>
<tr><td><code id="ucControl_+3A_maxpgridratio">maxPgridRatio</code></td>
<td>

<p>maximum binomial probability for the search over the null nuisance parameter space, when parmtype='ratio' or 'oddsratio'
</p>
</td></tr>
<tr><td><code id="ucControl_+3A_minpgridratio">minPgridRatio</code></td>
<td>

<p>maximum binomial probability for the search over the null nuisance parameter space, when parmtype='ratio' or 'oddsratio'
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A LIST of all the named elements (see arguments to call).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ucControl(errbound=10^-5)
</code></pre>

<hr>
<h2 id='uncondExact2x2'>
Unconditional exact tests for 2x2 tables
</h2><span id='topic+uncondExact2x2'></span><span id='topic+uncondExact2x2Pvals'></span>

<h3>Description</h3>

<p>The <code>uncondExact2x2</code> function tests 2x2 tables assuming two independent binomial responses. Unlike the conditional exact tests which condition on both margins of the 2x2 table (see <code><a href="#topic+exact2x2">exact2x2</a></code>), these unconditional tests only condition on one margin of the 2x2 table (i.e., condition on the sample sizes of the binomial responses). This makes the calculations difficult because now there is a nuisance parameter and calculations must be done over nearly the entire nuisance parameter space. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uncondExact2x2(x1, n1, x2, n2, 
    parmtype = c("difference", "ratio", "oddsratio"), nullparm = NULL, 
    alternative = c("two.sided","less", "greater"),  
    conf.int = FALSE, conf.level = 0.95, 
    method = c("FisherAdj", "simple", "score","wald-pooled", "wald-unpooled",  "user", 
      "user-fixed"), 
    tsmethod = c("central","square"), midp = FALSE, 
    gamma = 0, EplusM=FALSE, tiebreak=FALSE,
    plotprobs = FALSE, control=ucControl(), Tfunc=NULL,...)

uncondExact2x2Pvals(n1, n2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uncondExact2x2_+3A_x1">x1</code></td>
<td>
<p>number of events in group 1</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_n1">n1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_x2">x2</code></td>
<td>
<p>number of events in group 2</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_n2">n2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_parmtype">parmtype</code></td>
<td>

<p>type of parameter of interest, one of &quot;difference&quot;, &quot;ratio&quot; or &quot;oddsratio&quot; (see details)
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_nullparm">nullparm</code></td>
<td>

<p>value of the parameter of interest at null hypothesis, NULL defaults to 0 for parmtype='difference' and 1 for parmtype='ratio' or 'oddsratio' 
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_alternative">alternative</code></td>
<td>

<p>alternative hypothesis, one of &quot;two.sided&quot;, &quot;less&quot;, or &quot;greater&quot;, default is &quot;two.sided&quot; (see details)
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_conf.int">conf.int</code></td>
<td>
<p>logical, calculate confidence interval?</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_conf.level">conf.level</code></td>
<td>

<p>confidence level
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_method">method</code></td>
<td>

<p>method type, one of &quot;FisherAdj&quot; (default), &quot;simple&quot;, &quot;simpleTB&quot;, &quot;wald-pooled&quot;, &quot;wald-unpooled&quot;, &quot;score&quot;, &quot;user&quot;, or &quot;user-fixed&quot; (see details)
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_tsmethod">tsmethod</code></td>
<td>
<p>two-sided method, either &quot;central&quot; or &quot;square&quot; (see details)</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_midp">midp</code></td>
<td>
<p>logical. Use mid-p-value method?
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_gamma">gamma</code></td>
<td>
<p>Beger-Boos adjustment parameter. 0 means no adjustment. (see details).
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_eplusm">EplusM</code></td>
<td>
<p>logical, do the E+M adjustment? (see details)</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_tiebreak">tiebreak</code></td>
<td>
<p>logical, do tiebreak adjustment? (see details)</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_plotprobs">plotprobs</code></td>
<td>
<p>logical, plot probabilities?</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_control">control</code></td>
<td>
<p>list of algorithm parameters, see <code><a href="#topic+ucControl">ucControl</a></code>
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_tfunc">Tfunc</code></td>
<td>
<p>test statistic function for ordering the sample space when method='user', ignored otherwise (see details) 
</p>
</td></tr>
<tr><td><code id="uncondExact2x2_+3A_...">...</code></td>
<td>
<p>extra arguments passed to Tfunc (for uncondExact2x2), or passed to uncondExact2x2 (for uncondExact2x2Pvals)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>uncondExact2x2</code> function gives unconditional exact tests and confidence intervals for two independent binomial observations. The <code>uncondExact2x2Pvals</code> function repeatedly calls <code>uncondExact2x2</code> to get the p-values
for the entire sample space. 
</p>
<p>Let X1 be binomial(n1,theta1) and X2 be binomial(n2,theta2). The parmtype determines the parameter of interest: &lsquo;difference&rsquo; is theta2 - theta1, 'ratio' is theta2/theta1, and &lsquo;oddsratio&rsquo; 
is (theta2*(1-theta1))/(theta1*(1-theta2)). 
</p>
<p>The options <code>method</code>, <code>parmtype</code>, <code>tsmethod</code>, <code>alternative</code>,
<code>EplusM</code>, and <code>tiebreak</code> define some built-in test statistic
function, Tstat, that is used to order the sample space, using <code><a href="#topic+pickTstat">pickTstat</a></code> and <code><a href="#topic+calcTall">calcTall</a></code>. The first 5 arguments of Tstat must be
<code>Tstat(X1,N1,X2,N2, delta0)</code>, where X1 and X2 must allow vectors,
and delta0 is the null parameter value (but delta0 does not need to be used in the ordering). 
Ordering when <code>parmtype="ratio"</code>
or <code>parmtype="oddsratio"</code> is only used when there is information about the 
parameter. So the ordering function value is not used for ordering when x1=0 and x2=0 for <code>parmtype="ratio"</code>, and 
it is not used when (x1=0 and x2=0) or (x1=n1 and x2=n2) for <code>parmtype="oddsratio"</code>.
</p>
<p>We describe the ordering functions first for the basic case,  the case when <code>tsmethod="central"</code> or <code>alternative!="two.sided"</code>,
<code>EplusM=FALSE</code>, and <code>tiebreak=FALSE</code>. In this basic case the ordering function, Tstat, is determined by <code>method</code> and <code>parmtype</code>:
</p>

<ul>
<li><p> method='simple' - Tstat essentially replaces theta1 with x1/n1 and theta2 with x2/n2 in the parameter definition. If parmtype=&lsquo;difference&rsquo; 
then <code>Tstat(X1,N1,X2,N2,delta0)</code> returns  <code>X2/N2-X1/N1-delta0</code>. If parmtype='ratio' then the Tstat function
returns <code>log(X2/N2) - log(X1/N1) - log(delta0)</code>.
If parmtype='oddsratio' we get
<code>log( X2*(N1-X1)/(delta0*X1*(N2-X2)))</code>. 
</p>
</li>
<li><p> method='wald-pooled' - Tstat is a Z statistic on the difference  using the pooled variance (not allowed if <code>parmtype!="difference"</code>)
</p>
</li>
<li><p>  method='wald-unpooled' - Tstat is a Z statistics on the difference using unpooled variance (not allowed if <code>parmtype!="difference"</code>)
</p>
</li>
<li><p> method='score' - Tstat is a Z statistic formed using score statistics,
where the parameter is defined by parmtype,
and the constrained maximum likelihood estimates of the parameter are calculated 
by <code><a href="#topic+constrMLE.difference">constrMLE.difference</a></code>, <code><a href="#topic+constrMLE.ratio">constrMLE.ratio</a></code>, 
or <code><a href="#topic+constrMLE.oddsratio">constrMLE.oddsratio</a></code>. 
</p>
</li>
<li><p> method='FisherAdj' - Tstat is a one-sided Fisher's 'exact' mid p-value. The mid p-value is an adjustment for ties that technically removes the 'exactness' of the Fisher's p-value...BUT, here we are only using it to order the sample space, so the results of the resulting unconditional test will still be exact. 
</p>
</li>
<li><p> method='user' - Tstat is a user supplied statistic given by <code>Tfunc</code>, it must be a function with the first 5 elements of its call being (X1, N1, X2, N2, delta0). The function must returns a vector of length the same as X1 and X2, where higher values suggest larger theta2 compared to theta1 (when <code>tsmethod!="square"</code>) or 
higher values suggest more extreme (when <code>tsmethod=="square"</code> and 
<code>alternative=="two.sided"</code>). A slower algorithm that does not require monotonicity of one-sided p-values with respect to delta0 is used.
</p>
</li>
<li><p> method='user-fixed' - For advanced users. Tstat is a user supplied statistic given by <code>Tfunc</code>. It should have first 5 elements as described above but its result should not change with delta0 and it must meet Barnard's 
convexity conditions. If these conditions are met (the conditions 
are not checked, since checking them will slow the algorithm), then the p-values will be monotonic in delta0 (the null parameter for a two-sided test) and we can use a faster algorithm.
</p>
</li></ul>

<p>In the basic case, if <code>alternative="two.sided"</code>, the argument <code>tsmethod</code>=&quot;central&quot; gives the two-sided central method. The p-value is just twice the minimum of the 
one-sided p-values (or 1 if the doubling is greater than 1). 
</p>
<p>Now consider cases other than the basic case. 
The <code>tsmethod="square"</code> option gives the square of the test statistic
(when method=&quot;simple&quot;, &quot;score&quot;, &quot;wald-pooled&quot;, or &quot;wald-unpooled&quot;) and larger values suggest rejection in either direction (unless method='user', then the user supplies any test statistic for which larger values suggest rejection).
</p>
<p>The <code>tiebreak=TRUE</code> option breaks ties in a reasonable way when 
<code>method="simple"</code> (see 'details' section of <code><a href="#topic+calcTall">calcTall</a></code>).
The <code>EplusM=TRUE</code> option performs Lloyd's (2008) E+M ordering 
on Tstat (see 'details' section of <code><a href="#topic+calcTall">calcTall</a></code>).
</p>
<p>If <code>tiebreak=TRUE</code> and <code>EplusM=TRUE</code>, the tiebreak calculations are always done first. 
</p>
<p>Berger and Boos (1994) developed a very general method for calculating p-values when a nuisance parameter is present.
First, calculate a (1-gamma) confidence interval for the nuisance parameter, check for the supremum over the union of the null hypothesis parameter space 
and that confidence interval, then add back gamma to the p-value. This adjustment is valid (in other words, applied to exact tests it still gives an adjustment that is exact). The Berger-Boos adjustment is applied when <code>gamma</code>&gt;0.
</p>
<p>When method='simple' or method='user-fixed' does a simple grid search algorithm using <code><a href="#topic+unirootGrid">unirootGrid</a></code>.
No checks are done on the Tstat function when method='user-fixed' to make sure the simple grid search will converge to the 
proper answer. So method='user-fixed' should be used by advanced users only. 
</p>
<p>When <code>midp=TRUE</code> the mid p-value is calculated (and the associated confidence interval if <code>conf.int=TRUE</code>) instead of the standard p-value. Loosely speaking, the standard p-value calculates the probability of observing equal or more extreme responses, while the  mid p-value calculates the probability of more extreme responses plus 1/2 the probability of equally extreme responses. The tests and confidence intervals when 
<code>midp=TRUE</code> are not exact, but give type I error rates and coverage of confidence intervals closer to the nominal values.
The mid p-value was studied by Lancaster (1961), see vignette on mid p-values for details. 
</p>
<p>See Fay and Hunsberger (2021) for a review paper giving the details for these kinds of unconditional exact tests.
</p>


<h3>Value</h3>

<p>The function <code>uncondExact2x2Pvals</code> returns a (n1+1) by (n2+1) matrix of p-values for all possible x1 and x2 values, while <code>uncondExact2x2</code> returns
a list of class 'htest' with elements:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>proportion in sample 1</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>proportion in sample 2</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value from test</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>confidence interval on parameter given by parmtype</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>MLE estimate of parameter given by parmtype</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>null hypothesis value of parameter given by parmtype</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>alternative hypothesis</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>description of data</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>The algorithm for calculating the p-values and confidence intervals is based on a series of grid searches.
Because the grid searches are often trying to optimize non-monotonic functions, the algorithm is not 
guaranteed to give the correct answer. At the cost of increasing computation time, 
better accuracy can be obtained by increasing 
control$nPgrid,  and less often by increasing control$nCIgrid.
</p>


<h3>Author(s)</h3>

<p>Michael P. Fay, Sally A. Hunsberger
</p>


<h3>References</h3>

<p>Berger, R. L. and Boos, D. D. (1994). P values maximized
over a confidence set for the nuisance parameter. Journal
of the American Statistical Association 89 1012-1016.
</p>
<p>Fay, M.P. and Hunsberger, S.A. (2021). Practical valid inferences for the two-sample binomial problem. Statistics Surveys 15:72-110.
</p>
<p>Lancaster, H.O. (1961). Significance tests in discrete distributions. JASA 56: 223-234.
</p>
<p>Lloyd, C. J. (2008). Exact p-values for discrete models obtained
by estimation and maximization. Australian &amp; New
Zealand Journal of Statistics 50 329-345.
</p>


<h3>See Also</h3>

<p> See <code><a href="#topic+boschloo">boschloo</a></code> for unconditional exact tests with ordering
function based on Fisher's exact p-values. </p>


<h3>Examples</h3>

<pre><code class='language-R'># default uses method="FisherAdj"
uncondExact2x2(1,10,9,10, 
               parmtype="ratio")
uncondExact2x2(1,10,9,10, 
               method="score",parmtype="ratio")





</code></pre>

<hr>
<h2 id='uncondExact2x2-internal'>
Internal functions for unconditional exact tests. 
</h2><span id='topic+createR'></span><span id='topic+fillsquare'></span><span id='topic+getColor'></span><span id='topic+getDeltaGrid'></span><span id='topic+getPDQD'></span><span id='topic+getPI'></span><span id='topic+getPrange'></span><span id='topic+plotRankMat'></span>

<h3>Description</h3>

<p>Not to be called directly.</p>

<hr>
<h2 id='uncondPower2x2'>
Calculate power or sample size for any 2x2 test.
</h2><span id='topic+Power2x2'></span><span id='topic+uncondPower2x2'></span><span id='topic+SS2x2'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+Power2x2">Power2x2</a></code> and <code>SS2x2</code> calculates the power or sample size for any 2x2 test, while the function <code><a href="#topic+uncondPower2x2">uncondPower2x2</a></code> calculates power for only tests supported by 
<code><a href="#topic+uncondExact2x2Pvals">uncondExact2x2Pvals</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power2x2(n1, n2, theta1, theta2, alpha, pvalFunc, ...)

uncondPower2x2(n1,n2, theta1, theta2, alpha, ...)

SS2x2(theta1, theta2, alpha, pvalFunc, power=0.90, 
  n1start=10, increaseby=1, n2.over.n1=1,  
  maxiter=50, printSteps=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uncondPower2x2_+3A_n1">n1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_n2">n2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_theta1">theta1</code></td>
<td>

<p>probability of success in group 1
</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_theta2">theta2</code></td>
<td>

<p>probability of success in group 2
</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_alpha">alpha</code></td>
<td>

<p>significance level
</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_pvalfunc">pvalFunc</code></td>
<td>

<p>function that inputs x1,n1,x2,n2 and outputs a p-value.
</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_power">power</code></td>
<td>
<p>target power</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_n1start">n1start</code></td>
<td>
<p> value of n1 for first iteration</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_increaseby">increaseby</code></td>
<td>
<p>positive integer, how much to increase n1 by for each iteration</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_n2.over.n1">n2.over.n1</code></td>
<td>
<p>ratio of n2/n1</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_printsteps">printSteps</code></td>
<td>
<p>logical, should the power and sample size be printed after each iteration?</p>
</td></tr>
<tr><td><code id="uncondPower2x2_+3A_...">...</code></td>
<td>

<p>arguments passed to <code><a href="#topic+uncondExact2x2Pvals">uncondExact2x2Pvals</a></code> 
(for <code>uncondPower2x2</code>), or to <code>Power2x2</code> (for <code>SS2x2</code>). Not used and saved for future 
use for <code>Power2x2</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Power2x2</code> is a very simple function
to calculate power. It calculates power where rejection is when the p-value from <code>pvalFunc</code> is less than or equal to <code>alpha</code>. The function <code>SS2x2</code> repeatedly calls <code>Power2x2</code> as it increases the sample size, stopping when 
the power is greater than <code>'power'</code>.
</p>
<p>The function <code><a href="#topic+uncondPower2x2">uncondPower2x2</a></code> is similar except the 
p-values are calculated by <code><a href="#topic+uncondExact2x2Pvals">uncondExact2x2Pvals</a></code>.
</p>


<h3>Value</h3>

<p>the power functions return only the power. The sample size function returns a list of class 'htest.power'.
</p>


<h3>See Also</h3>

<p>For power and sample size for conditional exact tests (e.g., Fisher's exact tests) see  <code><a href="#topic+power2x2">power2x2</a></code> and <code><a href="#topic+ss2x2">ss2x2</a></code>. For power for the boundary-optimized rejection region (BORR) test  see <code><a href="#topic+powerBorr">powerBorr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(exact2x2)
Power2x2(3,4,.1,.9,0.025, pvalFunc=
  function(x1,n1,x2,n2){
      boschloo(x1,n1,x2,n2, alternative="greater", 
        or=1,tsmethod="central", midp=TRUE)$p.value
  }
)
## 
## Not run: 
SS2x2(.1,.9,0.025, n1start=5, pvalFunc=
           function(x1,n1,x2,n2){
             boschloo(x1,n1,x2,n2, alternative="greater", 
                      or=1,tsmethod="central", midp=TRUE)$p.value
           }
)

## End(Not run)
</code></pre>

<hr>
<h2 id='unirootGrid'>
Function to find a root by grid search. 
</h2><span id='topic+unirootGrid'></span>

<h3>Description</h3>

<p>Find the root (value where the function equals 0) of a monotonic function, <code>func</code>, 
using a halving algorithm grid search. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unirootGrid(func, power2 = 12, step.up = TRUE, pos.side = FALSE, 
    print.steps = FALSE, power2grid = power2gridRatio, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unirootGrid_+3A_func">func</code></td>
<td>

<p>monotonic function
</p>
</td></tr>
<tr><td><code id="unirootGrid_+3A_power2">power2</code></td>
<td>

<p>positive integer, number of grid points is 1+2^power2
</p>
</td></tr>
<tr><td><code id="unirootGrid_+3A_step.up">step.up</code></td>
<td>
<p> logical, 
start the search at the lower end of the grid and step up?
</p>
</td></tr>
<tr><td><code id="unirootGrid_+3A_pos.side">pos.side</code></td>
<td>

<p>logical, should the root be on the positive side? In other words, should func(root)&gt;=0
</p>
</td></tr>
<tr><td><code id="unirootGrid_+3A_print.steps">print.steps</code></td>
<td>

<p>logical, should each step that is evaluated be printed?
</p>
</td></tr>
<tr><td><code id="unirootGrid_+3A_power2grid">power2grid</code></td>
<td>

<p>function that returns the grid. Take one argument, <code>power2</code>
</p>
</td></tr>
<tr><td><code id="unirootGrid_+3A_...">...</code></td>
<td>

<p>arguments passed to <code>func</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The grid is defined with the <code>power2grid</code> argument that defines a function 
with an argument <code>power2</code>, and returns a grid with <code>1+2^power2</code>
elements. The root is found by a halving algorithm on the grid, so <code>func</code>
is calculated only <code>power2+1</code> times. The &lsquo;root&rsquo; is the element that is closest to the root, 
either on the positive side (<code>pos.side=TRUE</code>) or not.
</p>
<p>The <code>unirootGrid</code> function calls <code><a href="ssanv.html#topic+uniroot.integer">uniroot.integer</a></code> and finds roots based on grid search. 
The functions <code><a href="#topic+power2gridRatio">power2gridRatio</a></code> and <code><a href="#topic+power2gridDifference">power2gridDifference</a></code>
create grids for searching (0,Inf) and (-1,1) respectively. 
The <code><a href="#topic+power2gridRatio">power2gridRatio</a></code> grid is equally spaced on the log scale with about half of the grid between 0.5 and 2.
The function <code><a href="#topic+power2grid">power2grid</a></code> allows more flexibility in defining grids.
</p>


<h3>Value</h3>

<p>A list with elements:
</p>
<table>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations</p>
</td></tr>
<tr><td><code>f.root</code></td>
<td>
<p>value of func at root</p>
</td></tr>
<tr><td><code>root</code></td>
<td>
<p>root, element on the grid that is closest to the root on the negative side (if pos.side=FALSE)</p>
</td></tr>
<tr><td><code>bound</code></td>
<td>
<p>interval for the  accuracy</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael P. Fay
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code> and <code><a href="ssanv.html#topic+uniroot.integer">uniroot.integer</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># print.steps prints all iterations, 
# with x=rank of grid value (e.g., x=1 is lowest value in grid) 
# f(x) really is f(grid[x]) where grid is from the power2grid function 
unirootGrid(function(x){ x - .37}, power2=10, power2grid=power2gridRatio, 
  print.steps=TRUE, pos.side=TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
