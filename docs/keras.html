<!DOCTYPE html><html><head><title>Help for package keras</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {keras}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#keras-package'><p>R interface to Keras</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#+25+26lt+3B-+25'><p>Assign values to names</p></a></li>
<li><a href='#+25+26lt+3B-active+25'><p>Make an Active Binding</p></a></li>
<li><a href='#+25py_class+25'><p>Make a python class constructor</p></a></li>
<li><a href='#activation_relu'><p>Activation functions</p></a></li>
<li><a href='#adapt'><p>Fits the state of the preprocessing layer to the data being passed</p></a></li>
<li><a href='#application_densenet'><p>Instantiates the DenseNet architecture.</p></a></li>
<li><a href='#application_efficientnet'><p>Instantiates the EfficientNetB0 architecture</p></a></li>
<li><a href='#application_inception_resnet_v2'><p>Inception-ResNet v2 model, with weights trained on ImageNet</p></a></li>
<li><a href='#application_inception_v3'><p>Inception V3 model, with weights pre-trained on ImageNet.</p></a></li>
<li><a href='#application_mobilenet'><p>MobileNet model architecture.</p></a></li>
<li><a href='#application_mobilenet_v2'><p>MobileNetV2 model architecture</p></a></li>
<li><a href='#application_mobilenet_v3'><p>Instantiates the MobileNetV3Large architecture</p></a></li>
<li><a href='#application_nasnet'><p>Instantiates a NASNet model.</p></a></li>
<li><a href='#application_resnet'><p>Instantiates the ResNet architecture</p></a></li>
<li><a href='#application_vgg'><p>VGG16 and VGG19 models for Keras.</p></a></li>
<li><a href='#application_xception'><p>Instantiates the Xception architecture</p></a></li>
<li><a href='#backend'><p>Keras backend tensor engine</p></a></li>
<li><a href='#bidirectional'><p>Bidirectional wrapper for RNNs</p></a></li>
<li><a href='#callback_backup_and_restore'><p>Callback to back up and restore the training state</p></a></li>
<li><a href='#callback_csv_logger'><p>Callback that streams epoch results to a csv file</p></a></li>
<li><a href='#callback_early_stopping'><p>Stop training when a monitored quantity has stopped improving.</p></a></li>
<li><a href='#callback_lambda'><p>Create a custom callback</p></a></li>
<li><a href='#callback_learning_rate_scheduler'><p>Learning rate scheduler.</p></a></li>
<li><a href='#callback_model_checkpoint'><p>Save the model after every epoch.</p></a></li>
<li><a href='#callback_progbar_logger'><p>Callback that prints metrics to stdout.</p></a></li>
<li><a href='#callback_reduce_lr_on_plateau'><p>Reduce learning rate when a metric has stopped improving.</p></a></li>
<li><a href='#callback_remote_monitor'><p>Callback used to stream events to a server.</p></a></li>
<li><a href='#callback_tensorboard'><p>TensorBoard basic visualizations</p></a></li>
<li><a href='#callback_terminate_on_naan'><p>Callback that terminates training when a NaN loss is encountered.</p></a></li>
<li><a href='#clone_model'><p>Clone a model instance.</p></a></li>
<li><a href='#compile.keras.engine.training.Model'><p>Configure a Keras model for training</p></a></li>
<li><a href='#constraints'><p>Weight constraints</p></a></li>
<li><a href='#count_params'><p>Count the total number of scalars composing the weights.</p></a></li>
<li><a href='#create_layer'><p>Create a Keras Layer</p></a></li>
<li><a href='#create_layer_wrapper'><p>Create a Keras Layer wrapper</p></a></li>
<li><a href='#create_wrapper'><p>(Deprecated) Create a Keras Wrapper</p></a></li>
<li><a href='#custom_metric'><p>Custom metric function</p></a></li>
<li><a href='#dataset_boston_housing'><p>Boston housing price regression dataset</p></a></li>
<li><a href='#dataset_cifar10'><p>CIFAR10 small image classification</p></a></li>
<li><a href='#dataset_cifar100'><p>CIFAR100 small image classification</p></a></li>
<li><a href='#dataset_fashion_mnist'><p>Fashion-MNIST database of fashion articles</p></a></li>
<li><a href='#dataset_imdb'><p>IMDB Movie reviews sentiment classification</p></a></li>
<li><a href='#dataset_mnist'><p>MNIST database of handwritten digits</p></a></li>
<li><a href='#dataset_reuters'><p>Reuters newswire topics classification</p></a></li>
<li><a href='#evaluate_generator'><p>(Deprecated) Evaluates the model on a data generator.</p></a></li>
<li><a href='#evaluate.keras.engine.training.Model'><p>Evaluate a Keras model</p></a></li>
<li><a href='#export_savedmodel.keras.engine.training.Model'><p>Export a Saved Model</p></a></li>
<li><a href='#fit_generator'><p>(Deprecated) Fits the model on data yielded batch-by-batch by a generator.</p></a></li>
<li><a href='#fit_image_data_generator'><p>Fit image data generator internal statistics to some sample data.</p></a></li>
<li><a href='#fit_text_tokenizer'><p>Update tokenizer internal vocabulary based on a list of texts or list of</p>
sequences.</a></li>
<li><a href='#fit.keras.engine.training.Model'><p>Train a Keras model</p></a></li>
<li><a href='#flow_images_from_data'><p>Generates batches of augmented/normalized data from image data and labels</p></a></li>
<li><a href='#flow_images_from_dataframe'><p>Takes the dataframe and the path to a directory and generates batches of</p>
augmented/normalized data.</a></li>
<li><a href='#flow_images_from_directory'><p>Generates batches of data from images in a directory (with optional</p>
augmented/normalized data)</a></li>
<li><a href='#freeze_weights'><p>Freeze and unfreeze weights</p></a></li>
<li><a href='#generator_next'><p>Retrieve the next item from a generator</p></a></li>
<li><a href='#get_config'><p>Layer/Model configuration</p></a></li>
<li><a href='#get_file'><p>Downloads a file from a URL if it not already in the cache.</p></a></li>
<li><a href='#get_input_at'><p>Retrieve tensors for layers with multiple nodes</p></a></li>
<li><a href='#get_layer'><p>Retrieves a layer based on either its name (unique) or index.</p></a></li>
<li><a href='#get_weights'><p>Layer/Model weights as R arrays</p></a></li>
<li><a href='#hdf5_matrix'><p>Representation of HDF5 dataset to be used instead of an R array</p></a></li>
<li><a href='#image_data_generator'><p>Deprecated Generate batches of image data with real-time data augmentation.</p>
The data will be looped over (in batches).</a></li>
<li><a href='#image_dataset_from_directory'><p>Create a dataset from a directory</p></a></li>
<li><a href='#image_load'><p>Loads an image into PIL format.</p></a></li>
<li><a href='#image_to_array'><p>3D array representation of images</p></a></li>
<li><a href='#imagenet_decode_predictions'><p>Decodes the prediction of an ImageNet model.</p></a></li>
<li><a href='#imagenet_preprocess_input'><p>Preprocesses a tensor or array encoding a batch of images.</p></a></li>
<li><a href='#implementation'><p>Keras implementation</p></a></li>
<li><a href='#initializer_constant'><p>Initializer that generates tensors initialized to a constant value.</p></a></li>
<li><a href='#initializer_glorot_normal'><p>Glorot normal initializer, also called Xavier normal initializer.</p></a></li>
<li><a href='#initializer_glorot_uniform'><p>Glorot uniform initializer, also called Xavier uniform initializer.</p></a></li>
<li><a href='#initializer_he_normal'><p>He normal initializer.</p></a></li>
<li><a href='#initializer_he_uniform'><p>He uniform variance scaling initializer.</p></a></li>
<li><a href='#initializer_identity'><p>Initializer that generates the identity matrix.</p></a></li>
<li><a href='#initializer_lecun_normal'><p>LeCun normal initializer.</p></a></li>
<li><a href='#initializer_lecun_uniform'><p>LeCun uniform initializer.</p></a></li>
<li><a href='#initializer_ones'><p>Initializer that generates tensors initialized to 1.</p></a></li>
<li><a href='#initializer_orthogonal'><p>Initializer that generates a random orthogonal matrix.</p></a></li>
<li><a href='#initializer_random_normal'><p>Initializer that generates tensors with a normal distribution.</p></a></li>
<li><a href='#initializer_random_uniform'><p>Initializer that generates tensors with a uniform distribution.</p></a></li>
<li><a href='#initializer_truncated_normal'><p>Initializer that generates a truncated normal distribution.</p></a></li>
<li><a href='#initializer_variance_scaling'><p>Initializer capable of adapting its scale to the shape of weights.</p></a></li>
<li><a href='#initializer_zeros'><p>Initializer that generates tensors initialized to 0.</p></a></li>
<li><a href='#install_keras'><p>Install TensorFlow and Keras, including all Python dependencies</p></a></li>
<li><a href='#is_keras_available'><p>Check if Keras is Available</p></a></li>
<li><a href='#k_abs'><p>Element-wise absolute value.</p></a></li>
<li><a href='#k_all'><p>Bitwise reduction (logical AND).</p></a></li>
<li><a href='#k_any'><p>Bitwise reduction (logical OR).</p></a></li>
<li><a href='#k_arange'><p>Creates a 1D tensor containing a sequence of integers.</p></a></li>
<li><a href='#k_argmax'><p>Returns the index of the maximum value along an axis.</p></a></li>
<li><a href='#k_argmin'><p>Returns the index of the minimum value along an axis.</p></a></li>
<li><a href='#k_backend'><p>Active Keras backend</p></a></li>
<li><a href='#k_batch_dot'><p>Batchwise dot product.</p></a></li>
<li><a href='#k_batch_flatten'><p>Turn a nD tensor into a 2D tensor with same 1st dimension.</p></a></li>
<li><a href='#k_batch_get_value'><p>Returns the value of more than one tensor variable.</p></a></li>
<li><a href='#k_batch_normalization'><p>Applies batch normalization on x given mean, var, beta and gamma.</p></a></li>
<li><a href='#k_batch_set_value'><p>Sets the values of many tensor variables at once.</p></a></li>
<li><a href='#k_bias_add'><p>Adds a bias vector to a tensor.</p></a></li>
<li><a href='#k_binary_crossentropy'><p>Binary crossentropy between an output tensor and a target tensor.</p></a></li>
<li><a href='#k_cast'><p>Casts a tensor to a different dtype and returns it.</p></a></li>
<li><a href='#k_cast_to_floatx'><p>Cast an array to the default Keras float type.</p></a></li>
<li><a href='#k_categorical_crossentropy'><p>Categorical crossentropy between an output tensor and a target tensor.</p></a></li>
<li><a href='#k_clear_session'><p>Destroys the current TF graph and creates a new one.</p></a></li>
<li><a href='#k_clip'><p>Element-wise value clipping.</p></a></li>
<li><a href='#k_concatenate'><p>Concatenates a list of tensors alongside the specified axis.</p></a></li>
<li><a href='#k_constant'><p>Creates a constant tensor.</p></a></li>
<li><a href='#k_conv1d'><p>1D convolution.</p></a></li>
<li><a href='#k_conv2d'><p>2D convolution.</p></a></li>
<li><a href='#k_conv2d_transpose'><p>2D deconvolution (i.e. transposed convolution).</p></a></li>
<li><a href='#k_conv3d'><p>3D convolution.</p></a></li>
<li><a href='#k_conv3d_transpose'><p>3D deconvolution (i.e. transposed convolution).</p></a></li>
<li><a href='#k_cos'><p>Computes cos of x element-wise.</p></a></li>
<li><a href='#k_count_params'><p>Returns the static number of elements in a Keras variable or tensor.</p></a></li>
<li><a href='#k_ctc_batch_cost'><p>Runs CTC loss algorithm on each batch element.</p></a></li>
<li><a href='#k_ctc_decode'><p>Decodes the output of a softmax.</p></a></li>
<li><a href='#k_ctc_label_dense_to_sparse'><p>Converts CTC labels from dense to sparse.</p></a></li>
<li><a href='#k_cumprod'><p>Cumulative product of the values in a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_cumsum'><p>Cumulative sum of the values in a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_depthwise_conv2d'><p>Depthwise 2D convolution with separable filters.</p></a></li>
<li><a href='#k_dot'><p>Multiplies 2 tensors (and/or variables) and returns a <em>tensor</em>.</p></a></li>
<li><a href='#k_dropout'><p>Sets entries in <code>x</code> to zero at random, while scaling the entire tensor.</p></a></li>
<li><a href='#k_dtype'><p>Returns the dtype of a Keras tensor or variable, as a string.</p></a></li>
<li><a href='#k_elu'><p>Exponential linear unit.</p></a></li>
<li><a href='#k_epsilon'><p>Fuzz factor used in numeric expressions.</p></a></li>
<li><a href='#k_equal'><p>Element-wise equality between two tensors.</p></a></li>
<li><a href='#k_eval'><p>Evaluates the value of a variable.</p></a></li>
<li><a href='#k_exp'><p>Element-wise exponential.</p></a></li>
<li><a href='#k_expand_dims'><p>Adds a 1-sized dimension at index <code>axis</code>.</p></a></li>
<li><a href='#k_eye'><p>Instantiate an identity matrix and returns it.</p></a></li>
<li><a href='#k_flatten'><p>Flatten a tensor.</p></a></li>
<li><a href='#k_floatx'><p>Default float type</p></a></li>
<li><a href='#k_foldl'><p>Reduce elems using fn to combine them from left to right.</p></a></li>
<li><a href='#k_foldr'><p>Reduce elems using fn to combine them from right to left.</p></a></li>
<li><a href='#k_function'><p>Instantiates a Keras function</p></a></li>
<li><a href='#k_gather'><p>Retrieves the elements of indices <code>indices</code> in the tensor <code>reference</code>.</p></a></li>
<li><a href='#k_get_session'><p>TF session to be used by the backend.</p></a></li>
<li><a href='#k_get_uid'><p>Get the uid for the default graph.</p></a></li>
<li><a href='#k_get_value'><p>Returns the value of a variable.</p></a></li>
<li><a href='#k_get_variable_shape'><p>Returns the shape of a variable.</p></a></li>
<li><a href='#k_gradients'><p>Returns the gradients of <code>variables</code> w.r.t. <code>loss</code>.</p></a></li>
<li><a href='#k_greater'><p>Element-wise truth value of (x &gt; y).</p></a></li>
<li><a href='#k_greater_equal'><p>Element-wise truth value of (x &gt;= y).</p></a></li>
<li><a href='#k_hard_sigmoid'><p>Segment-wise linear approximation of sigmoid.</p></a></li>
<li><a href='#k_identity'><p>Returns a tensor with the same content as the input tensor.</p></a></li>
<li><a href='#k_image_data_format'><p>Default image data format convention ('channels_first' or 'channels_last').</p></a></li>
<li><a href='#k_in_test_phase'><p>Selects <code>x</code> in test phase, and <code>alt</code> otherwise.</p></a></li>
<li><a href='#k_in_top_k'><p>Returns whether the <code>targets</code> are in the top <code>k</code> <code>predictions</code>.</p></a></li>
<li><a href='#k_in_train_phase'><p>Selects <code>x</code> in train phase, and <code>alt</code> otherwise.</p></a></li>
<li><a href='#k_int_shape'><p>Returns the shape of tensor or variable as a list of int or NULL entries.</p></a></li>
<li><a href='#k_is_keras_tensor'><p>Returns whether <code>x</code> is a Keras tensor.</p></a></li>
<li><a href='#k_is_placeholder'><p>Returns whether <code>x</code> is a placeholder.</p></a></li>
<li><a href='#k_is_sparse'><p>Returns whether a tensor is a sparse tensor.</p></a></li>
<li><a href='#k_is_tensor'><p>Returns whether <code>x</code> is a symbolic tensor.</p></a></li>
<li><a href='#k_l2_normalize'><p>Normalizes a tensor wrt the L2 norm alongside the specified axis.</p></a></li>
<li><a href='#k_learning_phase'><p>Returns the learning phase flag.</p></a></li>
<li><a href='#k_less'><p>Element-wise truth value of (x &lt; y).</p></a></li>
<li><a href='#k_less_equal'><p>Element-wise truth value of (x &lt;= y).</p></a></li>
<li><a href='#k_local_conv1d'><p>Apply 1D conv with un-shared weights.</p></a></li>
<li><a href='#k_local_conv2d'><p>Apply 2D conv with un-shared weights.</p></a></li>
<li><a href='#k_log'><p>Element-wise log.</p></a></li>
<li><a href='#k_logsumexp'><p>(Deprecated) Computes log(sum(exp(elements across dimensions of a tensor))).</p></a></li>
<li><a href='#k_manual_variable_initialization'><p>Sets the manual variable initialization flag.</p></a></li>
<li><a href='#k_map_fn'><p>Map the function fn over the elements elems and return the outputs.</p></a></li>
<li><a href='#k_max'><p>Maximum value in a tensor.</p></a></li>
<li><a href='#k_maximum'><p>Element-wise maximum of two tensors.</p></a></li>
<li><a href='#k_mean'><p>Mean of a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_min'><p>Minimum value in a tensor.</p></a></li>
<li><a href='#k_minimum'><p>Element-wise minimum of two tensors.</p></a></li>
<li><a href='#k_moving_average_update'><p>Compute the moving average of a variable.</p></a></li>
<li><a href='#k_ndim'><p>Returns the number of axes in a tensor, as an integer.</p></a></li>
<li><a href='#k_normalize_batch_in_training'><p>Computes mean and std for batch then apply batch_normalization on batch.</p></a></li>
<li><a href='#k_not_equal'><p>Element-wise inequality between two tensors.</p></a></li>
<li><a href='#k_one_hot'><p>Computes the one-hot representation of an integer tensor.</p></a></li>
<li><a href='#k_ones'><p>Instantiates an all-ones tensor variable and returns it.</p></a></li>
<li><a href='#k_ones_like'><p>Instantiates an all-ones variable of the same shape as another tensor.</p></a></li>
<li><a href='#k_permute_dimensions'><p>Permutes axes in a tensor.</p></a></li>
<li><a href='#k_placeholder'><p>Instantiates a placeholder tensor and returns it.</p></a></li>
<li><a href='#k_pool2d'><p>2D Pooling.</p></a></li>
<li><a href='#k_pool3d'><p>3D Pooling.</p></a></li>
<li><a href='#k_pow'><p>Element-wise exponentiation.</p></a></li>
<li><a href='#k_print_tensor'><p>Prints <code>message</code> and the tensor value when evaluated.</p></a></li>
<li><a href='#k_prod'><p>Multiplies the values in a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_random_binomial'><p>Returns a tensor with random binomial distribution of values.</p></a></li>
<li><a href='#k_random_normal'><p>Returns a tensor with normal distribution of values.</p></a></li>
<li><a href='#k_random_normal_variable'><p>Instantiates a variable with values drawn from a normal distribution.</p></a></li>
<li><a href='#k_random_uniform'><p>Returns a tensor with uniform distribution of values.</p></a></li>
<li><a href='#k_random_uniform_variable'><p>Instantiates a variable with values drawn from a uniform distribution.</p></a></li>
<li><a href='#k_relu'><p>Rectified linear unit.</p></a></li>
<li><a href='#k_repeat'><p>Repeats a 2D tensor.</p></a></li>
<li><a href='#k_repeat_elements'><p>Repeats the elements of a tensor along an axis.</p></a></li>
<li><a href='#k_reset_uids'><p>Reset graph identifiers.</p></a></li>
<li><a href='#k_reshape'><p>Reshapes a tensor to the specified shape.</p></a></li>
<li><a href='#k_resize_images'><p>Resizes the images contained in a 4D tensor.</p></a></li>
<li><a href='#k_resize_volumes'><p>Resizes the volume contained in a 5D tensor.</p></a></li>
<li><a href='#k_reverse'><p>Reverse a tensor along the specified axes.</p></a></li>
<li><a href='#k_rnn'><p>Iterates over the time dimension of a tensor</p></a></li>
<li><a href='#k_round'><p>Element-wise rounding to the closest integer.</p></a></li>
<li><a href='#k_separable_conv2d'><p>2D convolution with separable filters.</p></a></li>
<li><a href='#k_set_learning_phase'><p>Sets the learning phase to a fixed value.</p></a></li>
<li><a href='#k_set_value'><p>Sets the value of a variable, from an R array.</p></a></li>
<li><a href='#k_shape'><p>Returns the symbolic shape of a tensor or variable.</p></a></li>
<li><a href='#k_sigmoid'><p>Element-wise sigmoid.</p></a></li>
<li><a href='#k_sign'><p>Element-wise sign.</p></a></li>
<li><a href='#k_sin'><p>Computes sin of x element-wise.</p></a></li>
<li><a href='#k_softmax'><p>Softmax of a tensor.</p></a></li>
<li><a href='#k_softplus'><p>Softplus of a tensor.</p></a></li>
<li><a href='#k_softsign'><p>Softsign of a tensor.</p></a></li>
<li><a href='#k_sparse_categorical_crossentropy'><p>Categorical crossentropy with integer targets.</p></a></li>
<li><a href='#k_spatial_2d_padding'><p>Pads the 2nd and 3rd dimensions of a 4D tensor.</p></a></li>
<li><a href='#k_spatial_3d_padding'><p>Pads 5D tensor with zeros along the depth, height, width dimensions.</p></a></li>
<li><a href='#k_sqrt'><p>Element-wise square root.</p></a></li>
<li><a href='#k_square'><p>Element-wise square.</p></a></li>
<li><a href='#k_squeeze'><p>Removes a 1-dimension from the tensor at index <code>axis</code>.</p></a></li>
<li><a href='#k_stack'><p>Stacks a list of rank <code>R</code> tensors into a rank <code>R+1</code> tensor.</p></a></li>
<li><a href='#k_std'><p>Standard deviation of a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_stop_gradient'><p>Returns <code>variables</code> but with zero gradient w.r.t. every other variable.</p></a></li>
<li><a href='#k_sum'><p>Sum of the values in a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_switch'><p>Switches between two operations depending on a scalar value.</p></a></li>
<li><a href='#k_tanh'><p>Element-wise tanh.</p></a></li>
<li><a href='#k_temporal_padding'><p>Pads the middle dimension of a 3D tensor.</p></a></li>
<li><a href='#k_tile'><p>Creates a tensor by tiling <code>x</code> by <code>n</code>.</p></a></li>
<li><a href='#k_to_dense'><p>Converts a sparse tensor into a dense tensor and returns it.</p></a></li>
<li><a href='#k_transpose'><p>Transposes a tensor and returns it.</p></a></li>
<li><a href='#k_truncated_normal'><p>Returns a tensor with truncated random normal distribution of values.</p></a></li>
<li><a href='#k_unstack'><p>Unstack rank <code>R</code> tensor into a list of rank <code>R-1</code> tensors.</p></a></li>
<li><a href='#k_update'><p>Update the value of <code>x</code> to <code>new_x</code>.</p></a></li>
<li><a href='#k_update_add'><p>Update the value of <code>x</code> by adding <code>increment</code>.</p></a></li>
<li><a href='#k_update_sub'><p>Update the value of <code>x</code> by subtracting <code>decrement</code>.</p></a></li>
<li><a href='#k_var'><p>Variance of a tensor, alongside the specified axis.</p></a></li>
<li><a href='#k_variable'><p>Instantiates a variable and returns it.</p></a></li>
<li><a href='#k_zeros'><p>Instantiates an all-zeros variable and returns it.</p></a></li>
<li><a href='#k_zeros_like'><p>Instantiates an all-zeros variable of the same shape as another tensor.</p></a></li>
<li><a href='#keras'><p>Main Keras module</p></a></li>
<li><a href='#keras_array'><p>Keras array object</p></a></li>
<li><a href='#keras_model'><p>Keras Model</p></a></li>
<li><a href='#keras_model_custom'><p>(Deprecated) Create a Keras custom model</p></a></li>
<li><a href='#keras_model_sequential'><p>Keras Model composed of a linear stack of layers</p></a></li>
<li><a href='#KerasCallback'><p>(Deprecated) Base R6 class for Keras callbacks</p></a></li>
<li><a href='#KerasConstraint'><p>(Deprecated) Base R6 class for Keras constraints</p></a></li>
<li><a href='#KerasLayer'><p>(Deprecated) Base R6 class for Keras layers</p></a></li>
<li><a href='#KerasWrapper'><p>(Deprecated) Base R6 class for Keras wrappers</p></a></li>
<li><a href='#Layer'><p>(Deprecated) Create a custom Layer</p></a></li>
<li><a href='#layer_activation'><p>Apply an activation function to an output.</p></a></li>
<li><a href='#layer_activation_elu'><p>Exponential Linear Unit.</p></a></li>
<li><a href='#layer_activation_leaky_relu'><p>Leaky version of a Rectified Linear Unit.</p></a></li>
<li><a href='#layer_activation_parametric_relu'><p>Parametric Rectified Linear Unit.</p></a></li>
<li><a href='#layer_activation_relu'><p>Rectified Linear Unit activation function</p></a></li>
<li><a href='#layer_activation_selu'><p>Scaled Exponential Linear Unit.</p></a></li>
<li><a href='#layer_activation_softmax'><p>Softmax activation function.</p></a></li>
<li><a href='#layer_activation_thresholded_relu'><p>Thresholded Rectified Linear Unit.</p></a></li>
<li><a href='#layer_activity_regularization'><p>Layer that applies an update to the cost function based input activity.</p></a></li>
<li><a href='#layer_add'><p>Layer that adds a list of inputs.</p></a></li>
<li><a href='#layer_additive_attention'><p>Additive attention layer, a.k.a. Bahdanau-style attention</p></a></li>
<li><a href='#layer_alpha_dropout'><p>Applies Alpha Dropout to the input.</p></a></li>
<li><a href='#layer_attention'><p>Dot-product attention layer, a.k.a. Luong-style attention</p></a></li>
<li><a href='#layer_average'><p>Layer that averages a list of inputs.</p></a></li>
<li><a href='#layer_average_pooling_1d'><p>Average pooling for temporal data.</p></a></li>
<li><a href='#layer_average_pooling_2d'><p>Average pooling operation for spatial data.</p></a></li>
<li><a href='#layer_average_pooling_3d'><p>Average pooling operation for 3D data (spatial or spatio-temporal).</p></a></li>
<li><a href='#layer_batch_normalization'><p>Layer that normalizes its inputs</p></a></li>
<li><a href='#layer_category_encoding'><p>A preprocessing layer which encodes integer features.</p></a></li>
<li><a href='#layer_center_crop'><p>Crop the central portion of the images to target height and width</p></a></li>
<li><a href='#layer_concatenate'><p>Layer that concatenates a list of inputs.</p></a></li>
<li><a href='#layer_conv_1d'><p>1D convolution layer (e.g. temporal convolution).</p></a></li>
<li><a href='#layer_conv_1d_transpose'><p>Transposed 1D convolution layer (sometimes called Deconvolution).</p></a></li>
<li><a href='#layer_conv_2d'><p>2D convolution layer (e.g. spatial convolution over images).</p></a></li>
<li><a href='#layer_conv_2d_transpose'><p>Transposed 2D convolution layer (sometimes called Deconvolution).</p></a></li>
<li><a href='#layer_conv_3d'><p>3D convolution layer (e.g. spatial convolution over volumes).</p></a></li>
<li><a href='#layer_conv_3d_transpose'><p>Transposed 3D convolution layer (sometimes called Deconvolution).</p></a></li>
<li><a href='#layer_conv_lstm_1d'><p>1D Convolutional LSTM</p></a></li>
<li><a href='#layer_conv_lstm_2d'><p>Convolutional LSTM.</p></a></li>
<li><a href='#layer_conv_lstm_3d'><p>3D Convolutional LSTM</p></a></li>
<li><a href='#layer_cropping_1d'><p>Cropping layer for 1D input (e.g. temporal sequence).</p></a></li>
<li><a href='#layer_cropping_2d'><p>Cropping layer for 2D input (e.g. picture).</p></a></li>
<li><a href='#layer_cropping_3d'><p>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</p></a></li>
<li><a href='#layer_cudnn_gru'><p>(Deprecated) Fast GRU implementation backed by <a href="https://developer.nvidia.com/cudnn">CuDNN</a>.</p></a></li>
<li><a href='#layer_cudnn_lstm'><p>(Deprecated) Fast LSTM implementation backed by <a href="https://developer.nvidia.com/cudnn">CuDNN</a>.</p></a></li>
<li><a href='#layer_dense'><p>Add a densely-connected NN layer to an output</p></a></li>
<li><a href='#layer_dense_features'><p>Constructs a DenseFeatures.</p></a></li>
<li><a href='#layer_depthwise_conv_1d'><p>Depthwise 1D convolution</p></a></li>
<li><a href='#layer_depthwise_conv_2d'><p>Depthwise separable 2D convolution.</p></a></li>
<li><a href='#layer_discretization'><p>A preprocessing layer which buckets continuous features by ranges.</p></a></li>
<li><a href='#layer_dot'><p>Layer that computes a dot product between samples in two tensors.</p></a></li>
<li><a href='#layer_dropout'><p>Applies Dropout to the input.</p></a></li>
<li><a href='#layer_embedding'><p>Turns positive integers (indexes) into dense vectors of fixed size</p></a></li>
<li><a href='#layer_flatten'><p>Flattens an input</p></a></li>
<li><a href='#layer_gaussian_dropout'><p>Apply multiplicative 1-centered Gaussian noise.</p></a></li>
<li><a href='#layer_gaussian_noise'><p>Apply additive zero-centered Gaussian noise.</p></a></li>
<li><a href='#layer_global_average_pooling_1d'><p>Global average pooling operation for temporal data.</p></a></li>
<li><a href='#layer_global_average_pooling_2d'><p>Global average pooling operation for spatial data.</p></a></li>
<li><a href='#layer_global_average_pooling_3d'><p>Global Average pooling operation for 3D data.</p></a></li>
<li><a href='#layer_global_max_pooling_1d'><p>Global max pooling operation for temporal data.</p></a></li>
<li><a href='#layer_global_max_pooling_2d'><p>Global max pooling operation for spatial data.</p></a></li>
<li><a href='#layer_global_max_pooling_3d'><p>Global Max pooling operation for 3D data.</p></a></li>
<li><a href='#layer_gru'><p>Gated Recurrent Unit - Cho et al.</p></a></li>
<li><a href='#layer_gru_cell'><p>Cell class for the GRU layer</p></a></li>
<li><a href='#layer_hashing'><p>A preprocessing layer which hashes and bins categorical features.</p></a></li>
<li><a href='#layer_input'><p>Input layer</p></a></li>
<li><a href='#layer_integer_lookup'><p>A preprocessing layer which maps integer features to contiguous ranges.</p></a></li>
<li><a href='#layer_lambda'><p>Wraps arbitrary expression as a layer</p></a></li>
<li><a href='#layer_layer_normalization'><p>Layer normalization layer (Ba et al., 2016).</p></a></li>
<li><a href='#layer_locally_connected_1d'><p>Locally-connected layer for 1D inputs.</p></a></li>
<li><a href='#layer_locally_connected_2d'><p>Locally-connected layer for 2D inputs.</p></a></li>
<li><a href='#layer_lstm'><p>Long Short-Term Memory unit - Hochreiter 1997.</p></a></li>
<li><a href='#layer_lstm_cell'><p>Cell class for the LSTM layer</p></a></li>
<li><a href='#layer_masking'><p>Masks a sequence by using a mask value to skip timesteps.</p></a></li>
<li><a href='#layer_max_pooling_1d'><p>Max pooling operation for temporal data.</p></a></li>
<li><a href='#layer_max_pooling_2d'><p>Max pooling operation for spatial data.</p></a></li>
<li><a href='#layer_max_pooling_3d'><p>Max pooling operation for 3D data (spatial or spatio-temporal).</p></a></li>
<li><a href='#layer_maximum'><p>Layer that computes the maximum (element-wise) a list of inputs.</p></a></li>
<li><a href='#layer_minimum'><p>Layer that computes the minimum (element-wise) a list of inputs.</p></a></li>
<li><a href='#layer_multi_head_attention'><p>MultiHeadAttention layer</p></a></li>
<li><a href='#layer_multiply'><p>Layer that multiplies (element-wise) a list of inputs.</p></a></li>
<li><a href='#layer_normalization'><p>A preprocessing layer which normalizes continuous features.</p></a></li>
<li><a href='#layer_permute'><p>Permute the dimensions of an input according to a given pattern</p></a></li>
<li><a href='#layer_random_brightness'><p>A preprocessing layer which randomly adjusts brightness during training</p></a></li>
<li><a href='#layer_random_contrast'><p>Adjust the contrast of an image or images by a random factor</p></a></li>
<li><a href='#layer_random_crop'><p>Randomly crop the images to target height and width</p></a></li>
<li><a href='#layer_random_flip'><p>Randomly flip each image horizontally and vertically</p></a></li>
<li><a href='#layer_random_height'><p>Randomly vary the height of a batch of images during training</p></a></li>
<li><a href='#layer_random_rotation'><p>Randomly rotate each image</p></a></li>
<li><a href='#layer_random_translation'><p>Randomly translate each image during training</p></a></li>
<li><a href='#layer_random_width'><p>Randomly vary the width of a batch of images during training</p></a></li>
<li><a href='#layer_random_zoom'><p>A preprocessing layer which randomly zooms images during training.</p></a></li>
<li><a href='#layer_repeat_vector'><p>Repeats the input n times.</p></a></li>
<li><a href='#layer_rescaling'><p>Multiply inputs by <code>scale</code> and adds <code>offset</code></p></a></li>
<li><a href='#layer_reshape'><p>Reshapes an output to a certain shape.</p></a></li>
<li><a href='#layer_resizing'><p>Image resizing layer</p></a></li>
<li><a href='#layer_rnn'><p>Base class for recurrent layers</p></a></li>
<li><a href='#layer_separable_conv_1d'><p>Depthwise separable 1D convolution.</p></a></li>
<li><a href='#layer_separable_conv_2d'><p>Separable 2D convolution.</p></a></li>
<li><a href='#layer_simple_rnn'><p>Fully-connected RNN where the output is to be fed back to input.</p></a></li>
<li><a href='#layer_simple_rnn_cell'><p>Cell class for SimpleRNN</p></a></li>
<li><a href='#layer_spatial_dropout_1d'><p>Spatial 1D version of Dropout.</p></a></li>
<li><a href='#layer_spatial_dropout_2d'><p>Spatial 2D version of Dropout.</p></a></li>
<li><a href='#layer_spatial_dropout_3d'><p>Spatial 3D version of Dropout.</p></a></li>
<li><a href='#layer_stacked_rnn_cells'><p>Wrapper allowing a stack of RNN cells to behave as a single cell</p></a></li>
<li><a href='#layer_string_lookup'><p>A preprocessing layer which maps string features to integer indices.</p></a></li>
<li><a href='#layer_subtract'><p>Layer that subtracts two inputs.</p></a></li>
<li><a href='#layer_text_vectorization'><p>A preprocessing layer which maps text features to integer sequences.</p></a></li>
<li><a href='#layer_unit_normalization'><p>Unit normalization layer</p></a></li>
<li><a href='#layer_upsampling_1d'><p>Upsampling layer for 1D inputs.</p></a></li>
<li><a href='#layer_upsampling_2d'><p>Upsampling layer for 2D inputs.</p></a></li>
<li><a href='#layer_upsampling_3d'><p>Upsampling layer for 3D inputs.</p></a></li>
<li><a href='#layer_zero_padding_1d'><p>Zero-padding layer for 1D input (e.g. temporal sequence).</p></a></li>
<li><a href='#layer_zero_padding_2d'><p>Zero-padding layer for 2D input (e.g. picture).</p></a></li>
<li><a href='#layer_zero_padding_3d'><p>Zero-padding layer for 3D data (spatial or spatio-temporal).</p></a></li>
<li><a href='#learning_rate_schedule_cosine_decay'><p>A LearningRateSchedule that uses a cosine decay schedule</p></a></li>
<li><a href='#learning_rate_schedule_cosine_decay_restarts'><p>A LearningRateSchedule that uses a cosine decay schedule with restarts</p></a></li>
<li><a href='#learning_rate_schedule_exponential_decay'><p>A LearningRateSchedule that uses an exponential decay schedule</p></a></li>
<li><a href='#learning_rate_schedule_inverse_time_decay'><p>A LearningRateSchedule that uses an inverse time decay schedule</p></a></li>
<li><a href='#learning_rate_schedule_piecewise_constant_decay'><p>A LearningRateSchedule that uses a piecewise constant decay schedule</p></a></li>
<li><a href='#learning_rate_schedule_polynomial_decay'><p>A LearningRateSchedule that uses a polynomial decay schedule</p></a></li>
<li><a href='#loss_cosine_proximity'><p>(Deprecated) loss_cosine_proximity</p></a></li>
<li><a href='#loss-functions'><p>Loss functions</p></a></li>
<li><a href='#make_sampling_table'><p>Generates a word rank-based probabilistic sampling table.</p></a></li>
<li><a href='#Metric'><p>Metric</p></a></li>
<li><a href='#metric_accuracy'><p>Calculates how often predictions equal labels</p></a></li>
<li><a href='#metric_auc'><p>Approximates the AUC (Area under the curve) of the ROC or PR curves</p></a></li>
<li><a href='#metric_binary_accuracy'><p>Calculates how often predictions match binary labels</p></a></li>
<li><a href='#metric_binary_crossentropy'><p>Computes the crossentropy metric between the labels and predictions</p></a></li>
<li><a href='#metric_categorical_accuracy'><p>Calculates how often predictions match one-hot labels</p></a></li>
<li><a href='#metric_categorical_crossentropy'><p>Computes the crossentropy metric between the labels and predictions</p></a></li>
<li><a href='#metric_categorical_hinge'><p>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code></p></a></li>
<li><a href='#metric_cosine_proximity'><p>(Deprecated) metric_cosine_proximity</p></a></li>
<li><a href='#metric_cosine_similarity'><p>Computes the cosine similarity between the labels and predictions</p></a></li>
<li><a href='#metric_false_negatives'><p>Calculates the number of false negatives</p></a></li>
<li><a href='#metric_false_positives'><p>Calculates the number of false positives</p></a></li>
<li><a href='#metric_hinge'><p>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code></p></a></li>
<li><a href='#metric_kullback_leibler_divergence'><p>Computes Kullback-Leibler divergence</p></a></li>
<li><a href='#metric_logcosh_error'><p>Computes the logarithm of the hyperbolic cosine of the prediction error</p></a></li>
<li><a href='#metric_mean'><p>Computes the (weighted) mean of the given values</p></a></li>
<li><a href='#metric_mean_absolute_error'><p>Computes the mean absolute error between the labels and predictions</p></a></li>
<li><a href='#metric_mean_absolute_percentage_error'><p>Computes the mean absolute percentage error between <code>y_true</code> and <code>y_pred</code></p></a></li>
<li><a href='#metric_mean_iou'><p>Computes the mean Intersection-Over-Union metric</p></a></li>
<li><a href='#metric_mean_relative_error'><p>Computes the mean relative error by normalizing with the given values</p></a></li>
<li><a href='#metric_mean_squared_error'><p>Computes the mean squared error between labels and predictions</p></a></li>
<li><a href='#metric_mean_squared_logarithmic_error'><p>Computes the mean squared logarithmic error</p></a></li>
<li><a href='#metric_mean_tensor'><p>Computes the element-wise (weighted) mean of the given tensors</p></a></li>
<li><a href='#metric_mean_wrapper'><p>Wraps a stateless metric function with the Mean metric</p></a></li>
<li><a href='#metric_poisson'><p>Computes the Poisson metric between <code>y_true</code> and <code>y_pred</code></p></a></li>
<li><a href='#metric_precision'><p>Computes the precision of the predictions with respect to the labels</p></a></li>
<li><a href='#metric_precision_at_recall'><p>Computes best precision where recall is &gt;= specified value</p></a></li>
<li><a href='#metric_recall'><p>Computes the recall of the predictions with respect to the labels</p></a></li>
<li><a href='#metric_recall_at_precision'><p>Computes best recall where precision is &gt;= specified value</p></a></li>
<li><a href='#metric_root_mean_squared_error'><p>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code></p></a></li>
<li><a href='#metric_sensitivity_at_specificity'><p>Computes best sensitivity where specificity is &gt;= specified value</p></a></li>
<li><a href='#metric_sparse_categorical_accuracy'><p>Calculates how often predictions match integer labels</p></a></li>
<li><a href='#metric_sparse_categorical_crossentropy'><p>Computes the crossentropy metric between the labels and predictions</p></a></li>
<li><a href='#metric_sparse_top_k_categorical_accuracy'><p>Computes how often integer targets are in the top <code>K</code> predictions</p></a></li>
<li><a href='#metric_specificity_at_sensitivity'><p>Computes best specificity where sensitivity is &gt;= specified value</p></a></li>
<li><a href='#metric_squared_hinge'><p>Computes the squared hinge metric</p></a></li>
<li><a href='#metric_sum'><p>Computes the (weighted) sum of the given values</p></a></li>
<li><a href='#metric_top_k_categorical_accuracy'><p>Computes how often targets are in the top <code>K</code> predictions</p></a></li>
<li><a href='#metric_true_negatives'><p>Calculates the number of true negatives</p></a></li>
<li><a href='#metric_true_positives'><p>Calculates the number of true positives</p></a></li>
<li><a href='#metric-or-Metric'><p>metric-or-Metric</p></a></li>
<li><a href='#model_from_saved_model'><p>Load a Keras model from the Saved Model format</p></a></li>
<li><a href='#model_to_json'><p>Model configuration as JSON</p></a></li>
<li><a href='#model_to_saved_model'><p>(Deprecated) Export to Saved Model format</p></a></li>
<li><a href='#model_to_yaml'><p>Model configuration as YAML</p></a></li>
<li><a href='#multi_gpu_model'><p>(Deprecated) Replicates a model on different GPUs.</p></a></li>
<li><a href='#new_learning_rate_schedule_class'><p>Create a new learning rate schedule type</p></a></li>
<li><a href='#new_metric_class'><p>Define new keras types</p></a></li>
<li><a href='#normalize'><p>Normalize a matrix or nd-array</p></a></li>
<li><a href='#optimizer_adadelta'><p>Optimizer that implements the Adadelta algorithm</p></a></li>
<li><a href='#optimizer_adagrad'><p>Optimizer that implements the Adagrad algorithm</p></a></li>
<li><a href='#optimizer_adam'><p>Optimizer that implements the Adam algorithm</p></a></li>
<li><a href='#optimizer_adamax'><p>Optimizer that implements the Adamax algorithm</p></a></li>
<li><a href='#optimizer_ftrl'><p>Optimizer that implements the FTRL algorithm</p></a></li>
<li><a href='#optimizer_nadam'><p>Optimizer that implements the Nadam algorithm</p></a></li>
<li><a href='#optimizer_rmsprop'><p>Optimizer that implements the RMSprop algorithm</p></a></li>
<li><a href='#optimizer_sgd'><p>Gradient descent (with momentum) optimizer</p></a></li>
<li><a href='#pad_sequences'><p>Pads sequences to the same length</p></a></li>
<li><a href='#plot.keras_training_history'><p>Plot training history</p></a></li>
<li><a href='#plot.keras.engine.training.Model'><p>Plot a Keras model</p></a></li>
<li><a href='#pop_layer'><p>Remove the last layer in a model</p></a></li>
<li><a href='#predict_generator'><p>(Deprecated) Generates predictions for the input samples from a data generator.</p></a></li>
<li><a href='#predict_on_batch'><p>Returns predictions for a single batch of samples.</p></a></li>
<li><a href='#predict_proba'><p>(Deprecated) Generates probability or class probability predictions for the input samples.</p></a></li>
<li><a href='#predict.keras.engine.training.Model'><p>Generate predictions from a Keras model</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#regularizer_l1'><p>L1 and L2 regularization</p></a></li>
<li><a href='#regularizer_orthogonal'><p>A regularizer that encourages input vectors to be orthogonal to each other</p></a></li>
<li><a href='#reset_states'><p>Reset the states for a layer</p></a></li>
<li><a href='#save_model_hdf5'><p>Save/Load models using HDF5 files</p></a></li>
<li><a href='#save_model_tf'><p>Save/Load models using SavedModel format</p></a></li>
<li><a href='#save_model_weights_hdf5'><p>Save/Load model weights using HDF5 files</p></a></li>
<li><a href='#save_model_weights_tf'><p>Save model weights in the SavedModel format</p></a></li>
<li><a href='#save_text_tokenizer'><p>Save a text tokenizer to an external file</p></a></li>
<li><a href='#sequences_to_matrix'><p>Convert a list of sequences into a matrix.</p></a></li>
<li><a href='#sequential_model_input_layer'><p>sequential_model_input_layer</p></a></li>
<li><a href='#serialize_model'><p>Serialize a model to an R object</p></a></li>
<li><a href='#skipgrams'><p>Generates skipgram word pairs.</p></a></li>
<li><a href='#summary.keras.engine.training.Model'><p>Print a summary of a Keras model</p></a></li>
<li><a href='#text_dataset_from_directory'><p>Generate a <code>tf.data.Dataset</code> from text files in a directory</p></a></li>
<li><a href='#text_hashing_trick'><p>Converts a text to a sequence of indexes in a fixed-size hashing space.</p></a></li>
<li><a href='#text_one_hot'><p>One-hot encode a text into a list of word indexes in a vocabulary of size n.</p></a></li>
<li><a href='#text_to_word_sequence'><p>Convert text to a sequence of words (or tokens).</p></a></li>
<li><a href='#text_tokenizer'><p>Text tokenization utility</p></a></li>
<li><a href='#texts_to_matrix'><p>Convert a list of texts to a matrix.</p></a></li>
<li><a href='#texts_to_sequences'><p>Transform each text in texts in a sequence of integers.</p></a></li>
<li><a href='#texts_to_sequences_generator'><p>Transforms each text in texts in a sequence of integers.</p></a></li>
<li><a href='#time_distributed'><p>This layer wrapper allows to apply a layer to every temporal slice of an input</p></a></li>
<li><a href='#timeseries_dataset_from_array'><p>Creates a dataset of sliding windows over a timeseries provided as array</p></a></li>
<li><a href='#timeseries_generator'><p>Utility function for generating batches of temporal data.</p></a></li>
<li><a href='#to_categorical'><p>Converts a class vector (integers) to binary class matrix.</p></a></li>
<li><a href='#train_on_batch'><p>Single gradient update or model evaluation over one batch of samples.</p></a></li>
<li><a href='#use_implementation'><p>Select a Keras implementation and backend</p></a></li>
<li><a href='#with_custom_object_scope'><p>Provide a scope with mappings of names to custom objects</p></a></li>
<li><a href='#zip_lists'><p>zip lists</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>R Interface to 'Keras'</td>
</tr>
<tr>
<td>Version:</td>
<td>2.15.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Interface to 'Keras' <a href="https://keras.io">https://keras.io</a>, a high-level neural
  networks 'API'. 'Keras' was developed with a focus on enabling fast experimentation,
  supports both convolution based networks and recurrent networks (as well as
  combinations of the two), and runs seamlessly on both 'CPU' and 'GPU' devices.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://tensorflow.rstudio.com/">https://tensorflow.rstudio.com/</a>,
<a href="https://github.com/rstudio/keras/tree/r2">https://github.com/rstudio/keras/tree/r2</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rstudio/keras/issues">https://github.com/rstudio/keras/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>generics (&ge; 0.0.1), reticulate (&ge; 1.31), tensorflow (&ge;
2.13.0.9000), tfruns (&ge; 1.0), magrittr, zeallot, glue,
methods, R6, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, testthat (&ge; 2.1.0), knitr, rmarkdown, callr,
tfdatasets, withr, png, jpeg</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-19 18:01:27 UTC; tomasz</td>
</tr>
<tr>
<td>Author:</td>
<td>Tomasz Kalinowski [ctb, cph, cre],
  Daniel Falbel [ctb, cph],
  JJ Allaire [aut, cph],
  François Chollet [aut, cph],
  RStudio [ctb, cph, fnd],
  Google [ctb, cph, fnd],
  Yuan Tang <a href="https://orcid.org/0000-0001-5243-233X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb,
    cph],
  Wouter Van Der Bijl [ctb, cph],
  Martin Studer [ctb, cph],
  Sigrid Keydana [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomasz Kalinowski &lt;tomasz@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-20 05:42:42 UTC</td>
</tr>
</table>
<hr>
<h2 id='keras-package'>R interface to Keras</h2><span id='topic+keras-package'></span>

<h3>Description</h3>

<p>Keras is a high-level neural networks API, developed with a focus on enabling
fast experimentation. Keras has the following key features:
</p>


<h3>Details</h3>


<ul>
<li><p> Allows the same code to run on CPU or on GPU, seamlessly.
</p>
</li>
<li><p> User-friendly API which makes it easy to quickly prototype deep learning models.
</p>
</li>
<li><p> Built-in support for convolutional networks (for computer vision), recurrent
networks (for sequence processing), and any combination of both.
</p>
</li>
<li><p> Supports arbitrary network architectures: multi-input or multi-output models,
layer sharing, model sharing, etc. This means that Keras is appropriate for
building essentially any deep learning model, from a memory network to a neural
Turing machine.
</p>
</li>
<li><p> Is capable of running on top of multiple back-ends including
<a href="https://github.com/tensorflow/tensorflow">TensorFlow</a>,
<a href="https://github.com/Microsoft/cntk">CNTK</a>,
or <a href="https://github.com/Theano/Theano">Theano</a>.
</p>
</li></ul>

<p>See the package website at <a href="https://tensorflow.rstudio.com">https://tensorflow.rstudio.com</a> for complete documentation.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Tomasz Kalinowski <a href="mailto:tomasz@posit.co">tomasz@posit.co</a> [contributor, copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> JJ Allaire [copyright holder]
</p>
</li>
<li><p> François Chollet [copyright holder]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Daniel Falbel <a href="mailto:daniel@rstudio.com">daniel@rstudio.com</a> [contributor, copyright holder]
</p>
</li>
<li><p> RStudio [contributor, copyright holder, funder]
</p>
</li>
<li><p> Google [contributor, copyright holder, funder]
</p>
</li>
<li><p> Yuan Tang <a href="mailto:terrytangyuan@gmail.com">terrytangyuan@gmail.com</a> (<a href="https://orcid.org/0000-0001-5243-233X">ORCID</a>) [contributor, copyright holder]
</p>
</li>
<li><p> Wouter Van Der Bijl [contributor, copyright holder]
</p>
</li>
<li><p> Martin Studer [contributor, copyright holder]
</p>
</li>
<li><p> Sigrid Keydana [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://tensorflow.rstudio.com/">https://tensorflow.rstudio.com/</a>
</p>
</li>
<li> <p><a href="https://github.com/rstudio/keras/tree/r2">https://github.com/rstudio/keras/tree/r2</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/rstudio/keras/issues">https://github.com/rstudio/keras/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code><a href="magrittr.html#topic++25+3E+25">%&gt;%</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='+25+26lt+3B-+25'>Assign values to names</h2><span id='topic++25+3C-+25'></span>

<h3>Description</h3>

<p>See <code><a href="zeallot.html#topic++25+3C-+25">%&lt;-%</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %&lt;-% value
</code></pre>

<hr>
<h2 id='+25+26lt+3B-active+25'>Make an Active Binding</h2><span id='topic++25+3C-active+25'></span>

<h3>Description</h3>

<p>Make an Active Binding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sym %&lt;-active% value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26lt+2B3B-active+2B25_+3A_sym">sym</code></td>
<td>
<p>symbol to bind</p>
</td></tr>
<tr><td><code id="+2B25+2B26lt+2B3B-active+2B25_+3A_value">value</code></td>
<td>
<p>A function to call when the value of <code>sym</code> is accessed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Active bindings defined in a <code><a href="#topic++25py_class+25">%py_class%</a></code> are converted to
<code style="white-space: pre;">&#8288;@property&#8288;</code> decorated methods.
</p>


<h3>Value</h3>

<p><code>value</code>, invisibly
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+makeActiveBinding">makeActiveBinding()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x %&lt;-active% function(value) {
  message("Evaluating function of active binding")
  if(missing(value))
    runif(1)
  else
   message("Received: ", value)
}
x
x
x &lt;- "foo"
x &lt;- "foo"
x
rm(x) # cleanup
</code></pre>

<hr>
<h2 id='+25py_class+25'>Make a python class constructor</h2><span id='topic++25py_class+25'></span><span id='topic+py_class'></span>

<h3>Description</h3>

<p>Make a python class constructor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spec %py_class% body
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25py_class+2B25_+3A_spec">spec</code></td>
<td>
<p>a bare symbol <code>MyClassName</code>, or a call <code>MyClassName(SuperClass)</code></p>
</td></tr>
<tr><td><code id="+2B25py_class+2B25_+3A_body">body</code></td>
<td>
<p>an expression that can be evaluated to construct the class
methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The python class constructor, invisibly. Note, the same constructor is
also assigned in the parent frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
MyClass %py_class% {
  initialize &lt;- function(x) {
    print("Hi from MyClass$initialize()!")
    self$x &lt;- x
  }
  my_method &lt;- function() {
    self$x
  }
}

my_class_instance &lt;- MyClass(42)
my_class_instance$my_method()

MyClass2(MyClass) %py_class% {
  "This will be a __doc__ string for MyClass2"

  initialize &lt;- function(...) {
    "This will be the __doc__ string for the MyClass2.__init__() method"
    print("Hi from MyClass2$initialize()!")
    super$initialize(...)
  }
}

my_class_instance2 &lt;- MyClass2(42)
my_class_instance2$my_method()

reticulate::py_help(MyClass2) # see the __doc__ strings and more!

# In addition to `self`, there is also `private` available.
# This is an R environment unique to each class instance, where you can
# store objects that you don't want converted to Python, but still want
# available from methods. You can also assign methods to private, and
# `self` and `private` will be available in private methods.

MyClass %py_class% {

  initialize &lt;- function(x) {
    print("Hi from MyClass$initialize()!")
    private$y &lt;- paste("A Private field:", x)
  }

  get_private_field &lt;- function() {
    private$y
  }

  private$a_private_method &lt;- function() {
    cat("a_private_method() was called.\n")
    cat("private$y is ", sQuote(private$y), "\n")
  }

  call_private_method &lt;- function()
    private$a_private_method()

  # equivalent of @property decorator in python
  an_active_property %&lt;-active% function(x = NULL) {
    if(!is.null(x)) {
      cat("`an_active_property` was assigned", x, "\n")
      return(x)
    } else {
      cat("`an_active_property` was accessed\n")
      return(42)
    }
  }
}

inst1 &lt;- MyClass(1)
inst2 &lt;- MyClass(2)
inst1$get_private_field()
inst2$get_private_field()
inst1$call_private_method()
inst2$call_private_method()
inst1$an_active_property
inst1$an_active_property &lt;- 11

## End(Not run)
</code></pre>

<hr>
<h2 id='activation_relu'>Activation functions</h2><span id='topic+activation_relu'></span><span id='topic+activation_elu'></span><span id='topic+activation_selu'></span><span id='topic+activation_hard_sigmoid'></span><span id='topic+activation_linear'></span><span id='topic+activation_sigmoid'></span><span id='topic+activation_softmax'></span><span id='topic+activation_softplus'></span><span id='topic+activation_softsign'></span><span id='topic+activation_tanh'></span><span id='topic+activation_exponential'></span><span id='topic+activation_gelu'></span><span id='topic+activation_swish'></span>

<h3>Description</h3>

<p><code>relu(...)</code>: Applies the rectified linear unit activation function.
</p>
<p><code>elu(...)</code>: Exponential Linear Unit.
</p>
<p><code>selu(...)</code>: Scaled Exponential Linear Unit (SELU).
</p>
<p><code>hard_sigmoid(...)</code>: Hard sigmoid activation function.
</p>
<p><code>linear(...)</code>: Linear activation function (pass-through).
</p>
<p><code>sigmoid(...)</code>: Sigmoid activation function, <code>sigmoid(x) = 1 / (1 + exp(-x))</code>.
</p>
<p><code>softmax(...)</code>: Softmax converts a vector of values to a probability distribution.
</p>
<p><code>softplus(...)</code>: Softplus activation function, <code>softplus(x) = log(exp(x) + 1)</code>.
</p>
<p><code>softsign(...)</code>: Softsign activation function, <code>softsign(x) = x / (abs(x) + 1)</code>.
</p>
<p><code>tanh(...)</code>: Hyperbolic tangent activation function.
</p>
<p><code>exponential(...)</code>: Exponential activation function.
</p>
<p><code>gelu(...)</code>: Applies the Gaussian error linear unit (GELU) activation function.
</p>
<p><code>swish(...)</code>: Swish activation function, <code>swish(x) = x * sigmoid(x)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_relu(x, alpha = 0, max_value = NULL, threshold = 0)

activation_elu(x, alpha = 1)

activation_selu(x)

activation_hard_sigmoid(x)

activation_linear(x)

activation_sigmoid(x)

activation_softmax(x, axis = -1)

activation_softplus(x)

activation_softsign(x)

activation_tanh(x)

activation_exponential(x)

activation_gelu(x, approximate = FALSE)

activation_swish(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_relu_+3A_x">x</code></td>
<td>
<p>Tensor</p>
</td></tr>
<tr><td><code id="activation_relu_+3A_alpha">alpha</code></td>
<td>
<p>Alpha value</p>
</td></tr>
<tr><td><code id="activation_relu_+3A_max_value">max_value</code></td>
<td>
<p>Max value</p>
</td></tr>
<tr><td><code id="activation_relu_+3A_threshold">threshold</code></td>
<td>
<p>Threshold value for thresholded activation.</p>
</td></tr>
<tr><td><code id="activation_relu_+3A_axis">axis</code></td>
<td>
<p>Integer, axis along which the softmax normalization is applied</p>
</td></tr>
<tr><td><code id="activation_relu_+3A_approximate">approximate</code></td>
<td>
<p>A bool, whether to enable approximation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Activations functions can either be used through <code><a href="#topic+layer_activation">layer_activation()</a></code>, or
through the activation argument supported by all forward layers.
</p>

<ul>
<li> <p><code>activation_selu()</code> to be used together with the initialization &quot;lecun_normal&quot;.
</p>
</li>
<li> <p><code>activation_selu()</code> to be used together with the dropout variant &quot;AlphaDropout&quot;.
</p>
</li></ul>



<h3>Value</h3>

<p>Tensor with the same shape and dtype as <code>x</code>.
</p>


<h3>References</h3>


<ul>
<li> <p><code>activation_swish()</code>: <a href="https://arxiv.org/abs/1710.05941">Searching for Activation Functions</a>
</p>
</li>
<li> <p><code>activation_gelu()</code>: <a href="https://arxiv.org/abs/1606.08415">Gaussian Error Linear Units (GELUs)</a>
</p>
</li>
<li> <p><code>activation_selu()</code>: <a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a>
</p>
</li>
<li> <p><code>activation_elu()</code>: <a href="https://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/activations">https://www.tensorflow.org/api_docs/python/tf/keras/activations</a>
</p>

<hr>
<h2 id='adapt'>Fits the state of the preprocessing layer to the data being passed</h2><span id='topic+adapt'></span>

<h3>Description</h3>

<p>Fits the state of the preprocessing layer to the data being passed
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adapt(object, data, ..., batch_size = NULL, steps = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adapt_+3A_object">object</code></td>
<td>
<p>Preprocessing layer object</p>
</td></tr>
<tr><td><code id="adapt_+3A_data">data</code></td>
<td>
<p>The data to train on. It can be passed either as a
<code>tf.data.Dataset</code> or as an R array.</p>
</td></tr>
<tr><td><code id="adapt_+3A_...">...</code></td>
<td>
<p>Used for forwards and backwards compatibility. Passed on to the underlying method.</p>
</td></tr>
<tr><td><code id="adapt_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer or <code>NULL</code>. Number of asamples per state update. If
unspecified, <code>batch_size</code> will default to <code>32</code>. Do not specify the
batch_size if your data is in the form of datasets, generators, or
<code>keras.utils.Sequence</code> instances (since they generate batches).</p>
</td></tr>
<tr><td><code id="adapt_+3A_steps">steps</code></td>
<td>
<p>Integer or <code>NULL</code>. Total number of steps (batches of samples)
When training with input tensors such as TensorFlow data tensors, the
default <code>NULL</code> is equal to the number of samples in your dataset divided by
the batch size, or <code>1</code> if that cannot be determined. If x is a
<code>tf.data.Dataset</code>, and <code>steps</code> is <code>NULL</code>, the epoch will run until the
input dataset is exhausted. When passing an infinitely repeating dataset,
you must specify the steps argument. This argument is not supported with
array inputs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After calling <code>adapt</code> on a layer, a preprocessing layer's state will not
update during training. In order to make preprocessing layers efficient in
any distribution context, they are kept constant with respect to any
compiled <code>tf.Graph</code>s that call the layer. This does not affect the layer use
when adapting each layer only once, but if you adapt a layer multiple times
you will need to take care to re-compile any compiled functions as follows:
</p>

<ul>
<li><p> If you are adding a preprocessing layer to a <code>keras.Model</code>, you need to
call <code>compile(model)</code> after each subsequent call to <code>adapt()</code>.
</p>
</li>
<li><p> If you are calling a preprocessing layer inside <code>tfdatasets::dataset_map()</code>,
you should call <code>dataset_map()</code> again on the input <code>tf.data.Dataset</code> after each
<code>adapt()</code>.
</p>
</li>
<li><p> If you are using a <code>tensorflow::tf_function()</code> directly which calls a preprocessing
layer, you need to call <code>tf_function</code> again on your callable after
each subsequent call to <code>adapt()</code>.
</p>
</li></ul>

<p><code>keras_model</code> example with multiple adapts:
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_normalization(axis=NULL)
adapt(layer, c(0, 2))
model &lt;- keras_model_sequential(layer)
predict(model, c(0, 1, 2)) # [1] -1  0  1

adapt(layer, c(-1, 1))
compile(model)  # This is needed to re-compile model.predict!
predict(model, c(0, 1, 2)) # [1] 0 1 2
</pre></div>
<p><code>tf.data.Dataset</code> example with multiple adapts:
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_normalization(axis=NULL)
adapt(layer, c(0, 2))
input_ds &lt;- tfdatasets::range_dataset(0, 3)
normalized_ds &lt;- input_ds %&gt;%
  tfdatasets::dataset_map(layer)
str(reticulate::iterate(normalized_ds))
# List of 3
#  $ :tf.Tensor([-1.], shape=(1,), dtype=float32)
#  $ :tf.Tensor([0.], shape=(1,), dtype=float32)
#  $ :tf.Tensor([1.], shape=(1,), dtype=float32)
adapt(layer, c(-1, 1))
normalized_ds &lt;- input_ds %&gt;%
  tfdatasets::dataset_map(layer) # Re-map over the input dataset.
str(reticulate::iterate(normalized_ds$as_numpy_iterator()))
# List of 3
#  $ : num [1(1d)] -1
#  $ : num [1(1d)] 0
#  $ : num [1(1d)] 1
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method">https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method</a>
</p>
</li></ul>


<hr>
<h2 id='application_densenet'>Instantiates the DenseNet architecture.</h2><span id='topic+application_densenet'></span><span id='topic+application_densenet121'></span><span id='topic+application_densenet169'></span><span id='topic+application_densenet201'></span><span id='topic+densenet_preprocess_input'></span>

<h3>Description</h3>

<p>Instantiates the DenseNet architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_densenet(
  blocks,
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000
)

application_densenet121(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000
)

application_densenet169(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000
)

application_densenet201(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000
)

densenet_preprocess_input(x, data_format = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_densenet_+3A_blocks">blocks</code></td>
<td>
<p>numbers of building blocks for the four dense layers.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_include_top">include_top</code></td>
<td>
<p>whether to include the fully-connected layer at the top
of the network.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_weights">weights</code></td>
<td>
<p>one of <code>NULL</code> (random initialization), 'imagenet'
(pre-training on ImageNet), or the path to the weights file to be loaded.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_input_tensor">input_tensor</code></td>
<td>
<p>optional Keras tensor (i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified if <code>include_top</code>
is FALSE (otherwise the input shape has to be <code style="white-space: pre;">&#8288;(224, 224, 3)&#8288;</code>
(with <code>channels_last</code> data format) or <code style="white-space: pre;">&#8288;(3, 224, 224)&#8288;</code> (with
<code>channels_first</code> data format). It should have exactly 3 inputs channels.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_pooling">pooling</code></td>
<td>
<p>optional pooling mode for feature extraction when
<code>include_top</code> is <code>FALSE</code>.
- <code>NULL</code> means that the output of the model will be the 4D tensor output
of the last convolutional layer.
- <code>avg</code> means that global average pooling will be applied to the output
of the last convolutional layer, and thus the output of the model
will be a 2D tensor.
- <code>max</code> means that global max pooling will be applied.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_classes">classes</code></td>
<td>
<p>optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_x">x</code></td>
<td>
<p>a 3D or 4D array consists of RGB values within <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="application_densenet_+3A_data_format">data_format</code></td>
<td>
<p>data format of the image tensor.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Optionally loads weights pre-trained
on ImageNet. Note that when using TensorFlow,
for best performance you should set
<code>image_data_format='channels_last'</code> in your Keras config
at ~/.keras/keras.json.
</p>
<p>The model and the weights are compatible with
TensorFlow, Theano, and CNTK. The data format
convention used by the model is the one
specified in your Keras config file.
</p>

<hr>
<h2 id='application_efficientnet'>Instantiates the EfficientNetB0 architecture</h2><span id='topic+application_efficientnet'></span><span id='topic+application_efficientnet_b0'></span><span id='topic+application_efficientnet_b1'></span><span id='topic+application_efficientnet_b2'></span><span id='topic+application_efficientnet_b3'></span><span id='topic+application_efficientnet_b4'></span><span id='topic+application_efficientnet_b5'></span><span id='topic+application_efficientnet_b6'></span><span id='topic+application_efficientnet_b7'></span>

<h3>Description</h3>

<p>Instantiates the EfficientNetB0 architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_efficientnet_b0(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b1(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b3(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b4(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b5(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b6(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

application_efficientnet_b7(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_efficientnet_+3A_include_top">include_top</code></td>
<td>
<p>Whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_weights">weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_input_shape">input_shape</code></td>
<td>
<p>Optional shape list, only to be specified
if <code>include_top</code> is FALSE.
It should have exactly 3 inputs channels.</p>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_efficientnet_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reference:
</p>

<ul>
<li> <p><a href="https://arxiv.org/abs/1905.11946">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a> (ICML 2019)
</p>
</li></ul>

<p>This function returns a Keras image classification model,
optionally loaded with weights pre-trained on ImageNet.
</p>
<p>For image classification use cases, see
<a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">this page for detailed examples</a>.
</p>
<p>For transfer learning use cases, make sure to read the
<a href="https://keras.io/guides/transfer_learning/">guide to transfer learning &amp; fine-tuning</a>.
</p>
<p>EfficientNet models expect their inputs to be float tensors of pixels with values in the <code style="white-space: pre;">&#8288;[0-255]&#8288;</code> range.
</p>


<h3>Note</h3>

<p>Each Keras Application typically expects a specific kind of input preprocessing.
For EfficientNet, input preprocessing is included as part of the model
(as a <code>Rescaling</code> layer), and thus a calling a preprocessing function is not necessary.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0">https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/applications/">https://keras.io/api/applications/</a>
</p>
</li></ul>


<hr>
<h2 id='application_inception_resnet_v2'>Inception-ResNet v2 model, with weights trained on ImageNet</h2><span id='topic+application_inception_resnet_v2'></span><span id='topic+inception_resnet_v2_preprocess_input'></span>

<h3>Description</h3>

<p>Inception-ResNet v2 model, with weights trained on ImageNet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_inception_resnet_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

inception_resnet_v2_preprocess_input(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_inception_resnet_v2_+3A_include_top">include_top</code></td>
<td>
<p>Whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_weights">weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified
if <code>include_top</code> is FALSE (otherwise the input shape
has to be <code style="white-space: pre;">&#8288;(299, 299, 3)&#8288;</code>.
It should have exactly 3 inputs channels,
and width and height should be no smaller than 71.
E.g. <code style="white-space: pre;">&#8288;(150, 150, 3)&#8288;</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="application_inception_resnet_v2_+3A_x">x</code></td>
<td>
<p><code>preprocess_input()</code> takes an array or floating point tensor, 3D or
4D with 3 color channels, with values in the range <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Do note that the input image format for this model is different than for
the VGG16 and ResNet models (299x299 instead of 224x224).
</p>
<p>The <code>inception_resnet_v2_preprocess_input()</code> function should be used for image
preprocessing.
</p>


<h3>Value</h3>

<p>A Keras model instance.
</p>


<h3>Reference</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1602.07261">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>(https://arxiv.org/abs/1512.00567)
</p>
</li></ul>


<hr>
<h2 id='application_inception_v3'>Inception V3 model, with weights pre-trained on ImageNet.</h2><span id='topic+application_inception_v3'></span><span id='topic+inception_v3_preprocess_input'></span>

<h3>Description</h3>

<p>Inception V3 model, with weights pre-trained on ImageNet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_inception_v3(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

inception_v3_preprocess_input(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_inception_v3_+3A_include_top">include_top</code></td>
<td>
<p>Whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_weights">weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified
if <code>include_top</code> is FALSE (otherwise the input shape
has to be <code style="white-space: pre;">&#8288;(299, 299, 3)&#8288;</code>.
It should have exactly 3 inputs channels,
and width and height should be no smaller than 71.
E.g. <code style="white-space: pre;">&#8288;(150, 150, 3)&#8288;</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="application_inception_v3_+3A_x">x</code></td>
<td>
<p><code>preprocess_input()</code> takes an array or floating point tensor, 3D or
4D with 3 color channels, with values in the range <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Do note that the input image format for this model is different than for
the VGG16 and ResNet models (299x299 instead of 224x224).
</p>
<p>The <code>inception_v3_preprocess_input()</code> function should be used for image
preprocessing.
</p>


<h3>Value</h3>

<p>A Keras model instance.
</p>


<h3>Reference</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a>
</p>
</li></ul>


<hr>
<h2 id='application_mobilenet'>MobileNet model architecture.</h2><span id='topic+application_mobilenet'></span><span id='topic+mobilenet_preprocess_input'></span><span id='topic+mobilenet_decode_predictions'></span><span id='topic+mobilenet_load_model_hdf5'></span>

<h3>Description</h3>

<p>MobileNet model architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_mobilenet(
  input_shape = NULL,
  alpha = 1,
  depth_multiplier = 1L,
  dropout = 0.001,
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  ...
)

mobilenet_preprocess_input(x)

mobilenet_decode_predictions(preds, top = 5)

mobilenet_load_model_hdf5(filepath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_mobilenet_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified if <code>include_top</code>
is FALSE (otherwise the input shape has to be <code style="white-space: pre;">&#8288;(224, 224, 3)&#8288;</code> (with
<code>channels_last</code> data format) or (3, 224, 224) (with <code>channels_first</code> data
format). It should have exactly 3 inputs channels, and width and height
should be no smaller than 32. E.g. <code style="white-space: pre;">&#8288;(200, 200, 3)&#8288;</code> would be one valid
value.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_alpha">alpha</code></td>
<td>
<p>controls the width of the network.
</p>

<ul>
<li><p> If <code>alpha</code> &lt; 1.0, proportionally decreases the number of filters in each layer.
</p>
</li>
<li><p> If <code>alpha</code> &gt; 1.0, proportionally increases the number of filters in each layer.
</p>
</li>
<li><p> If <code>alpha</code> = 1, default number of filters from the paper are used at each layer.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_depth_multiplier">depth_multiplier</code></td>
<td>
<p>depth multiplier for depthwise convolution (also
called the resolution multiplier)</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_dropout">dropout</code></td>
<td>
<p>dropout rate</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_include_top">include_top</code></td>
<td>
<p>whether to include the fully-connected layer at the top of
the network.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_weights">weights</code></td>
<td>
<p><code>NULL</code> (random initialization), <code>imagenet</code> (ImageNet
weights), or the path to the weights file to be loaded.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_input_tensor">input_tensor</code></td>
<td>
<p>optional Keras tensor (i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction when
<code>include_top</code> is <code>FALSE</code>.
- <code>NULL</code> means that the output of the model will be the 4D tensor output
of the last convolutional layer.
- <code>avg</code> means that global average pooling will be applied to the output
of the last convolutional layer, and thus the output of the model will
be a 2D tensor.
- <code>max</code> means that global max pooling will be applied.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_classes">classes</code></td>
<td>
<p>optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_x">x</code></td>
<td>
<p>input tensor, 4D</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_preds">preds</code></td>
<td>
<p>Tensor encoding a batch of predictions.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_top">top</code></td>
<td>
<p>integer, how many top-guesses to return.</p>
</td></tr>
<tr><td><code id="application_mobilenet_+3A_filepath">filepath</code></td>
<td>
<p>File path</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>mobilenet_preprocess_input()</code> function should be used for image
preprocessing. To load a saved instance of a MobileNet model use
the <code>mobilenet_load_model_hdf5()</code> function. To prepare image input
for MobileNet use <code>mobilenet_preprocess_input()</code>. To decode
predictions use <code>mobilenet_decode_predictions()</code>.
</p>


<h3>Value</h3>

<p><code>application_mobilenet()</code> and <code>mobilenet_load_model_hdf5()</code> return a
Keras model instance. <code>mobilenet_preprocess_input()</code> returns image input
suitable for feeding into a mobilenet model. <code>mobilenet_decode_predictions()</code>
returns a list of data frames with variables <code>class_name</code>, <code>class_description</code>,
and <code>score</code> (one data frame per sample in batch input).
</p>


<h3>Reference</h3>


<ul>
<li> <p><a href="https://arxiv.org/pdf/1704.04861v1.pdf">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a>.
</p>
</li></ul>


<hr>
<h2 id='application_mobilenet_v2'>MobileNetV2 model architecture</h2><span id='topic+application_mobilenet_v2'></span><span id='topic+mobilenet_v2_preprocess_input'></span><span id='topic+mobilenet_v2_decode_predictions'></span><span id='topic+mobilenet_v2_load_model_hdf5'></span>

<h3>Description</h3>

<p>MobileNetV2 model architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_mobilenet_v2(
  input_shape = NULL,
  alpha = 1,
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

mobilenet_v2_preprocess_input(x)

mobilenet_v2_decode_predictions(preds, top = 5)

mobilenet_v2_load_model_hdf5(filepath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_mobilenet_v2_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified if <code>include_top</code>
is FALSE (otherwise the input shape has to be <code style="white-space: pre;">&#8288;(224, 224, 3)&#8288;</code> (with
<code>channels_last</code> data format) or (3, 224, 224) (with <code>channels_first</code> data
format). It should have exactly 3 inputs channels, and width and height
should be no smaller than 32. E.g. <code style="white-space: pre;">&#8288;(200, 200, 3)&#8288;</code> would be one valid
value.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_alpha">alpha</code></td>
<td>
<p>controls the width of the network.
</p>

<ul>
<li><p> If <code>alpha</code> &lt; 1.0, proportionally decreases the number of filters in each layer.
</p>
</li>
<li><p> If <code>alpha</code> &gt; 1.0, proportionally increases the number of filters in each layer.
</p>
</li>
<li><p> If <code>alpha</code> = 1, default number of filters from the paper are used at each layer.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_include_top">include_top</code></td>
<td>
<p>whether to include the fully-connected layer at the top of
the network.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_weights">weights</code></td>
<td>
<p><code>NULL</code> (random initialization), <code>imagenet</code> (ImageNet
weights), or the path to the weights file to be loaded.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_input_tensor">input_tensor</code></td>
<td>
<p>optional Keras tensor (i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction when
<code>include_top</code> is <code>FALSE</code>.
- <code>NULL</code> means that the output of the model will be the 4D tensor output
of the last convolutional layer.
- <code>avg</code> means that global average pooling will be applied to the output
of the last convolutional layer, and thus the output of the model will
be a 2D tensor.
- <code>max</code> means that global max pooling will be applied.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_classes">classes</code></td>
<td>
<p>optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_x">x</code></td>
<td>
<p>input tensor, 4D</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_preds">preds</code></td>
<td>
<p>Tensor encoding a batch of predictions.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_top">top</code></td>
<td>
<p>integer, how many top-guesses to return.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v2_+3A_filepath">filepath</code></td>
<td>
<p>File path</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>application_mobilenet_v2()</code> and <code>mobilenet_v2_load_model_hdf5()</code> return a
Keras model instance. <code>mobilenet_v2_preprocess_input()</code> returns image input
suitable for feeding into a mobilenet v2 model. <code>mobilenet_v2_decode_predictions()</code>
returns a list of data frames with variables <code>class_name</code>, <code>class_description</code>,
and <code>score</code> (one data frame per sample in batch input).
</p>


<h3>Reference</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>application_mobilenet
</p>

<hr>
<h2 id='application_mobilenet_v3'>Instantiates the MobileNetV3Large architecture</h2><span id='topic+application_mobilenet_v3'></span><span id='topic+application_mobilenet_v3_large'></span><span id='topic+application_mobilenet_v3_small'></span>

<h3>Description</h3>

<p>Instantiates the MobileNetV3Large architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_mobilenet_v3_large(
  input_shape = NULL,
  alpha = 1,
  minimalistic = FALSE,
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  classes = 1000L,
  pooling = NULL,
  dropout_rate = 0.2,
  classifier_activation = "softmax",
  include_preprocessing = TRUE
)

application_mobilenet_v3_small(
  input_shape = NULL,
  alpha = 1,
  minimalistic = FALSE,
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  classes = 1000L,
  pooling = NULL,
  dropout_rate = 0.2,
  classifier_activation = "softmax",
  include_preprocessing = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_mobilenet_v3_+3A_input_shape">input_shape</code></td>
<td>
<p>Optional shape vector, to be specified if you would
like to use a model with an input image resolution that is not
<code>c(224, 224, 3)</code>.
It should have exactly 3 inputs channels <code>c(224, 224, 3)</code>.
You can also omit this option if you would like
to infer input_shape from an input_tensor.
If you choose to include both input_tensor and input_shape then
input_shape will be used if they match, if the shapes
do not match then we will throw an error.
E.g. <code>c(160, 160, 3)</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_alpha">alpha</code></td>
<td>
<p>controls the width of the network. This is known as the
depth multiplier in the MobileNetV3 paper, but the name is kept for
consistency with MobileNetV1 in Keras.
</p>

<ul>
<li><p> If <code>alpha</code> &lt; 1.0, proportionally decreases the number
of filters in each layer.
</p>
</li>
<li><p> If <code>alpha</code> &gt; 1.0, proportionally increases the number
of filters in each layer.
</p>
</li>
<li><p> If <code>alpha</code> = 1, default number of filters from the paper
are used at each layer.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_minimalistic">minimalistic</code></td>
<td>
<p>In addition to large and small models this module also
contains so-called minimalistic models, these models have the same
per-layer dimensions characteristic as MobilenetV3 however, they don't
utilize any of the advanced blocks (squeeze-and-excite units, hard-swish,
and 5x5 convolutions). While these models are less efficient on CPU, they
are much more performant on GPU/DSP.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_include_top">include_top</code></td>
<td>
<p>Boolean, whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_weights">weights</code></td>
<td>
<p>String, one of <code>NULL</code> (random initialization),
'imagenet' (pre-training on ImageNet),
or the path to the weights file to be loaded.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor (i.e. output of
<code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_classes">classes</code></td>
<td>
<p>Integer, optional number of classes to classify images
into, only to be specified if <code>include_top</code> is TRUE, and
if no <code>weights</code> argument is specified.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_pooling">pooling</code></td>
<td>
<p>String, optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model
will be the 4D tensor output of the
last convolutional block.
</p>
</li>
<li> <p><code>avg</code> means that global average pooling
will be applied to the output of the
last convolutional block, and thus
the output of the model will be a
2D tensor.
</p>
</li>
<li> <p><code>max</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_dropout_rate">dropout_rate</code></td>
<td>
<p>fraction of the input units to drop on the last layer.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to use
on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
When loading pretrained weights, <code>classifier_activation</code> can only
be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_mobilenet_v3_+3A_include_preprocessing">include_preprocessing</code></td>
<td>
<p>Boolean, whether to include the preprocessing
layer (<code>Rescaling</code>) at the bottom of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reference:
</p>

<ul>
<li> <p><a href="https://arxiv.org/pdf/1905.02244.pdf">Searching for MobileNetV3</a> (ICCV 2019)
</p>
</li></ul>



<h4>The following table describes the performance of MobileNets v3:</h4>

<p>MACs stands for Multiply Adds</p>

<table>
<tr>
 <td style="text-align: left;">
   Classification Checkpoint </td><td style="text-align: left;"> MACs(M) </td><td style="text-align: left;"> Parameters(M) </td><td style="text-align: left;"> Top1 Accuracy </td><td style="text-align: left;"> Pixel1 CPU(ms) </td>
</tr>
<tr>
 <td style="text-align: left;">
   mobilenet_v3_large_1.0_224 </td><td style="text-align: left;"> 217 </td><td style="text-align: left;"> 5.4 </td><td style="text-align: left;"> 75.6 </td><td style="text-align: left;"> 51.2 </td>
</tr>
<tr>
 <td style="text-align: left;">
   mobilenet_v3_large_0.75_224 </td><td style="text-align: left;"> 155 </td><td style="text-align: left;"> 4.0 </td><td style="text-align: left;"> 73.3 </td><td style="text-align: left;"> 39.8 </td>
</tr>
<tr>
 <td style="text-align: left;">
   mobilenet_v3_large_minimalistic_1.0_224 </td><td style="text-align: left;"> 209 </td><td style="text-align: left;"> 3.9 </td><td style="text-align: left;"> 72.3 </td><td style="text-align: left;"> 44.1 </td>
</tr>
<tr>
 <td style="text-align: left;">
   mobilenet_v3_small_1.0_224 </td><td style="text-align: left;"> 66 </td><td style="text-align: left;"> 2.9 </td><td style="text-align: left;"> 68.1 </td><td style="text-align: left;"> 15.8 </td>
</tr>
<tr>
 <td style="text-align: left;">
   mobilenet_v3_small_0.75_224 </td><td style="text-align: left;"> 44 </td><td style="text-align: left;"> 2.4 </td><td style="text-align: left;"> 65.4 </td><td style="text-align: left;"> 12.8 </td>
</tr>
<tr>
 <td style="text-align: left;">
   mobilenet_v3_small_minimalistic_1.0_224 </td><td style="text-align: left;"> 65 </td><td style="text-align: left;"> 2.0 </td><td style="text-align: left;"> 61.9 </td><td style="text-align: left;"> 12.2 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>For image classification use cases, see
<a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">this page for detailed examples</a>.
</p>
<p>For transfer learning use cases, make sure to read the
<a href="https://keras.io/guides/transfer_learning/">guide to transfer learning &amp; fine-tuning</a>.
</p>



<h3>Value</h3>

<p>A keras <code>Model</code> instance
</p>


<h3>Note</h3>

<p>Each Keras application typically expects a specific kind of input preprocessing.
For ModelNetV3, by default input preprocessing is included as a part of the
model (as a <code>Rescaling</code> layer), and thus
a preprocessing function is not necessary. In this use case, ModelNetV3 models expect their inputs
to be float tensors of pixels with values in the <code style="white-space: pre;">&#8288;[0-255]&#8288;</code> range.
At the same time, preprocessing as a part of the model (i.e. <code>Rescaling</code>
layer) can be disabled by setting <code>include_preprocessing</code> argument to FALSE.
With preprocessing disabled ModelNetV3 models expect their inputs to be float
tensors of pixels with values in the <code style="white-space: pre;">&#8288;[-1, 1]&#8288;</code> range.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Large">https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Large</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small">https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/applications/">https://keras.io/api/applications/</a>
</p>
</li></ul>


<hr>
<h2 id='application_nasnet'>Instantiates a NASNet model.</h2><span id='topic+application_nasnet'></span><span id='topic+application_nasnetlarge'></span><span id='topic+application_nasnetmobile'></span><span id='topic+nasnet_preprocess_input'></span>

<h3>Description</h3>

<p>Note that only TensorFlow is supported for now,
therefore it only works with the data format
<code>image_data_format='channels_last'</code> in your Keras config
at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_nasnet(
  input_shape = NULL,
  penultimate_filters = 4032L,
  num_blocks = 6L,
  stem_block_filters = 96L,
  skip_reduction = TRUE,
  filter_multiplier = 2L,
  include_top = TRUE,
  weights = NULL,
  input_tensor = NULL,
  pooling = NULL,
  classes = 1000,
  default_size = NULL
)

application_nasnetlarge(
  input_shape = NULL,
  include_top = TRUE,
  weights = NULL,
  input_tensor = NULL,
  pooling = NULL,
  classes = 1000
)

application_nasnetmobile(
  input_shape = NULL,
  include_top = TRUE,
  weights = NULL,
  input_tensor = NULL,
  pooling = NULL,
  classes = 1000
)

nasnet_preprocess_input(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_nasnet_+3A_input_shape">input_shape</code></td>
<td>
<p>Optional shape list, the input shape is by default <code style="white-space: pre;">&#8288;(331, 331, 3)&#8288;</code>
for NASNetLarge and <code style="white-space: pre;">&#8288;(224, 224, 3)&#8288;</code> for NASNetMobile It should have exactly 3
inputs channels, and width and height should be no smaller than 32. E.g.
<code style="white-space: pre;">&#8288;(224, 224, 3)&#8288;</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_penultimate_filters">penultimate_filters</code></td>
<td>
<p>Number of filters in the penultimate layer.
NASNet models use the notation <code>NASNet (N @ P)</code>, where:
- N is the number of blocks
- P is the number of penultimate filters</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_num_blocks">num_blocks</code></td>
<td>
<p>Number of repeated blocks of the NASNet model. NASNet
models use the notation <code>NASNet (N @ P)</code>, where:
- N is the number of blocks
- P is the number of penultimate filters</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_stem_block_filters">stem_block_filters</code></td>
<td>
<p>Number of filters in the initial stem block</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_skip_reduction">skip_reduction</code></td>
<td>
<p>Whether to skip the reduction step at the tail end
of the network. Set to <code>FALSE</code> for CIFAR models.</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_filter_multiplier">filter_multiplier</code></td>
<td>
<p>Controls the width of the network.
</p>

<ul>
<li><p> If <code>filter_multiplier</code> &lt; 1.0, proportionally decreases the number of
filters in each layer.
</p>
</li>
<li><p> If <code>filter_multiplier</code> &gt; 1.0, proportionally increases the number of
filters in each layer. - If <code>filter_multiplier</code> = 1, default number of
filters from the paper are used at each layer.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_nasnet_+3A_include_top">include_top</code></td>
<td>
<p>Whether to include the fully-connected layer at the top
of the network.</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_weights">weights</code></td>
<td>
<p><code>NULL</code> (random initialization) or <code>imagenet</code> (ImageNet weights)</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor (i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction when
<code>include_top</code> is <code>FALSE</code>.
- <code>NULL</code> means that the output of the model will be the 4D tensor output
of the last convolutional layer.
- <code>avg</code> means that global average pooling will be applied to the output
of the last convolutional layer, and thus the output of the model will
be a 2D tensor.
- <code>max</code> means that global max pooling will be applied.</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified.</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_default_size">default_size</code></td>
<td>
<p>Specifies the default image size of the model</p>
</td></tr>
<tr><td><code id="application_nasnet_+3A_x">x</code></td>
<td>
<p>a 4D array consists of RGB values within <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='application_resnet'>Instantiates the ResNet architecture</h2><span id='topic+application_resnet'></span><span id='topic+application_resnet50'></span><span id='topic+application_resnet101'></span><span id='topic+application_resnet152'></span><span id='topic+application_resnet50_v2'></span><span id='topic+application_resnet101_v2'></span><span id='topic+application_resnet152_v2'></span><span id='topic+resnet_preprocess_input'></span><span id='topic+resnet_v2_preprocess_input'></span>

<h3>Description</h3>

<p>Instantiates the ResNet architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_resnet50(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  ...
)

application_resnet101(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  ...
)

application_resnet152(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  ...
)

application_resnet50_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

application_resnet101_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

application_resnet152_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

resnet_preprocess_input(x)

resnet_v2_preprocess_input(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_resnet_+3A_include_top">include_top</code></td>
<td>
<p>Whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_weights">weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified
if <code>include_top</code> is FALSE (otherwise the input shape
has to be <code>c(224, 224, 3)</code> (with <code>'channels_last'</code> data format)
or <code>c(3, 224, 224)</code> (with <code>'channels_first'</code> data format).
It should have exactly 3 inputs channels,
and width and height should be no smaller than 32.
E.g. <code>c(200, 200, 3)</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_resnet_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_resnet_+3A_x">x</code></td>
<td>
<p><code>preprocess_input()</code> takes an array or floating point tensor, 3D or
4D with 3 color channels, with values in the range <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reference:
</p>

<ul>
<li> <p><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> (CVPR 2015)
</p>
</li></ul>

<p>For image classification use cases, see
<a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">this page for detailed examples</a>.
</p>
<p>For transfer learning use cases, make sure to read the
<a href="https://keras.io/guides/transfer_learning/">guide to transfer learning &amp; fine-tuning</a>.
</p>
<p>Note: each Keras Application expects a specific kind of input preprocessing.
For ResNet, call <code>tf.keras.applications.resnet.preprocess_input</code> on your
inputs before passing them to the model.
<code>resnet.preprocess_input</code> will convert the input images from RGB to BGR,
then will zero-center each color channel with respect to the ImageNet dataset,
without scaling.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/applications/">https://keras.io/api/applications/</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(keras)

# instantiate the model
model &lt;- application_resnet50(weights = 'imagenet')

# load the image
img_path &lt;- "elephant.jpg"
img &lt;- image_load(img_path, target_size = c(224,224))
x &lt;- image_to_array(img)

# ensure we have a 4d tensor with single element in the batch dimension,
# the preprocess the input for prediction using resnet50
x &lt;- array_reshape(x, c(1, dim(x)))
x &lt;- imagenet_preprocess_input(x)

# make predictions then decode and print them
preds &lt;- model %&gt;% predict(x)
imagenet_decode_predictions(preds, top = 3)[[1]]

## End(Not run)
</code></pre>

<hr>
<h2 id='application_vgg'>VGG16 and VGG19 models for Keras.</h2><span id='topic+application_vgg'></span><span id='topic+application_vgg16'></span><span id='topic+application_vgg19'></span>

<h3>Description</h3>

<p>VGG16 and VGG19 models for Keras.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_vgg16(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax"
)

application_vgg19(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_vgg_+3A_include_top">include_top</code></td>
<td>
<p>whether to include the 3 fully-connected layers at the top
of the network.</p>
</td></tr>
<tr><td><code id="application_vgg_+3A_weights">weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td></tr>
<tr><td><code id="application_vgg_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_vgg_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified if <code>include_top</code>
is FALSE (otherwise the input shape has to be <code style="white-space: pre;">&#8288;(224, 224, 3)&#8288;</code> It should
have exactly 3 inputs channels, and width and height should be no smaller
than 32. E.g. <code style="white-space: pre;">&#8288;(200, 200, 3)&#8288;</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_vgg_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_vgg_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td></tr>
<tr><td><code id="application_vgg_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Optionally loads weights pre-trained on ImageNet.
</p>
<p>The <code>imagenet_preprocess_input()</code> function should be used for image preprocessing.
</p>


<h3>Value</h3>

<p>Keras model instance.
</p>


<h3>Reference</h3>

<p>- <a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(keras)

model &lt;- application_vgg16(weights = 'imagenet', include_top = FALSE)

img_path &lt;- "elephant.jpg"
img &lt;- image_load(img_path, target_size = c(224,224))
x &lt;- image_to_array(img)
x &lt;- array_reshape(x, c(1, dim(x)))
x &lt;- imagenet_preprocess_input(x)

features &lt;- model %&gt;% predict(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='application_xception'>Instantiates the Xception architecture</h2><span id='topic+application_xception'></span><span id='topic+xception_preprocess_input'></span>

<h3>Description</h3>

<p>Instantiates the Xception architecture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application_xception(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

xception_preprocess_input(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_xception_+3A_include_top">include_top</code></td>
<td>
<p>Whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="application_xception_+3A_weights">weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td></tr>
<tr><td><code id="application_xception_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td></tr>
<tr><td><code id="application_xception_+3A_input_shape">input_shape</code></td>
<td>
<p>optional shape list, only to be specified
if <code>include_top</code> is FALSE (otherwise the input shape
has to be <code style="white-space: pre;">&#8288;(299, 299, 3)&#8288;</code>.
It should have exactly 3 inputs channels,
and width and height should be no smaller than 71.
E.g. <code style="white-space: pre;">&#8288;(150, 150, 3)&#8288;</code> would be one valid value.</p>
</td></tr>
<tr><td><code id="application_xception_+3A_pooling">pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="application_xception_+3A_classes">classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td></tr>
<tr><td><code id="application_xception_+3A_classifier_activation">classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the &quot;top&quot; layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the &quot;top&quot; layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td></tr>
<tr><td><code id="application_xception_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="application_xception_+3A_x">x</code></td>
<td>
<p><code>preprocess_input()</code> takes an array or floating point tensor, 3D or
4D with 3 color channels, with values in the range <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For image classification use cases, see
<a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">this page for detailed examples</a>.
</p>
<p>For transfer learning use cases, make sure to read the
<a href="https://keras.io/guides/transfer_learning/">guide to transfer learning &amp; fine-tuning</a>.
</p>
<p>The default input image size for this model is 299x299.
</p>


<h3>Reference</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1610.02357">Xception: Deep Learning with Depthwise Separable Convolutions</a> (CVPR 2017)
</p>
</li></ul>



<h3>Note</h3>

<p>Each Keras Application typically expects a specific kind of input preprocessing.
For Xception, call <code>xception_preprocess_input()</code> on your
inputs before passing them to the model.
<code>xception_preprocess_input()</code> will scale input pixels between -1 and 1.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/Xception">https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/Xception</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/applications/">https://keras.io/api/applications/</a>
</p>
</li></ul>


<hr>
<h2 id='backend'>Keras backend tensor engine</h2><span id='topic+backend'></span>

<h3>Description</h3>

<p>Obtain a reference to the <code>keras.backend</code> Python module used to implement
tensor operations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backend(convert = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backend_+3A_convert">convert</code></td>
<td>
<p>Boolean; should Python objects be automatically converted
to their <span class="rlang"><b>R</b></span> equivalent? If set to <code>FALSE</code>, you can still manually convert
Python objects to <span class="rlang"><b>R</b></span> via the <code><a href="reticulate.html#topic+py_to_r">py_to_r()</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Reference to Keras backend python module.
</p>


<h3>Note</h3>

<p>See the documentation here <a href="https://keras.io/backend/">https://keras.io/backend/</a> for
additional details on the available functions.
</p>

<hr>
<h2 id='bidirectional'>Bidirectional wrapper for RNNs</h2><span id='topic+bidirectional'></span>

<h3>Description</h3>

<p>Bidirectional wrapper for RNNs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bidirectional(
  object,
  layer,
  merge_mode = "concat",
  weights = NULL,
  backward_layer = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bidirectional_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bidirectional_+3A_layer">layer</code></td>
<td>
<p>A <code>RNN</code> layer instance, such as <code>layer_lstm()</code> or
<code>layer_gru()</code>. It could also be a <code>keras$layers$Layer</code> instance that
meets the following criteria:
</p>

<ol>
<li><p> Be a sequence-processing layer (accepts 3D+ inputs).
</p>
</li>
<li><p> Have a <code>go_backwards</code>, <code>return_sequences</code> and <code>return_state</code> attribute
(with the same semantics as for the <code>RNN</code> class).
</p>
</li>
<li><p> Have an <code>input_spec</code> attribute.
</p>
</li>
<li><p> Implement serialization via <code>get_config()</code> and <code>from_config()</code>. Note
that the recommended way to create new RNN layers is to write a custom RNN
cell and use it with <code>layer_rnn()</code>, instead of subclassing
<code>keras$layers$Layer</code> directly.
</p>
</li>
<li><p> When <code>returns_sequences = TRUE</code>, the output of the masked timestep will
be zero regardless of the layer's original <code>zero_output_for_mask</code> value.
</p>
</li></ol>
</td></tr>
<tr><td><code id="bidirectional_+3A_merge_mode">merge_mode</code></td>
<td>
<p>Mode by which outputs of the forward and backward RNNs will
be combined. One of <code>'sum'</code>, <code>'mul'</code>, <code>'concat'</code>, <code>'ave'</code>, <code>NULL</code>. If
<code>NULL</code>, the outputs will not be combined, they will be returned as a list.
Default value is <code>'concat'</code>.</p>
</td></tr>
<tr><td><code id="bidirectional_+3A_weights">weights</code></td>
<td>
<p>Split and propagated to the <code>initial_weights</code> attribute on the
forward and backward layer.</p>
</td></tr>
<tr><td><code id="bidirectional_+3A_backward_layer">backward_layer</code></td>
<td>
<p>Optional <code>keras.layers.RNN</code>, or <code>keras.layers.Layer</code>
instance to be used to handle backwards input processing. If
<code>backward_layer</code> is not provided, the layer instance passed as the <code>layer</code>
argument will be used to generate the backward layer automatically. Note
that the provided <code>backward_layer</code> layer should have properties matching
those of the <code>layer</code> argument, in particular it should have the same values
for <code>stateful</code>, <code>return_states</code>, <code>return_sequences</code>, etc. In addition,
<code>backward_layer</code> and <code>layer</code> should have different <code>go_backwards</code> argument
values. A <code>ValueError</code> will be raised if these requirements are not met.</p>
</td></tr>
<tr><td><code id="bidirectional_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/recurrent_layers/bidirectional/">https://keras.io/api/layers/recurrent_layers/bidirectional/</a>
</p>
</li></ul>

<p>Other layer wrappers: 
<code><a href="#topic+time_distributed">time_distributed</a>()</code>
</p>

<hr>
<h2 id='callback_backup_and_restore'>Callback to back up and restore the training state</h2><span id='topic+callback_backup_and_restore'></span>

<h3>Description</h3>

<p>Callback to back up and restore the training state
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_backup_and_restore(backup_dir, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_backup_and_restore_+3A_backup_dir">backup_dir</code></td>
<td>
<p>String, path to store the checkpoint.
e.g. <code>backup_dir = normalizePath('./backup')</code>
This is the directory in which the system stores temporary files to
recover the model from jobs terminated unexpectedly. The directory
cannot be reused elsewhere to store other files, e.g. by
<code>BackupAndRestore</code> callback of another training, or by another callback
(<code>ModelCheckpoint</code>) of the same training.</p>
</td></tr>
<tr><td><code id="callback_backup_and_restore_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BackupAndRestore</code> callback is intended to recover training from an
interruption that has happened in the middle of a <code>fit(model)</code> execution, by
backing up the training states in a temporary checkpoint file (with the help
of a <code>tf.train.CheckpointManager</code>), at the end of each epoch. Each backup
overwrites the previously written checkpoint file, so at any given time there
is at most one such checkpoint file for backup/restoring purpose.
</p>
<p>If training restarts before completion, the training state (which includes the
<code>Model</code> weights and epoch number) is restored to the most recently saved state
at the beginning of a new <code>fit()</code> run. At the completion of a <code>fit()</code>
run, the temporary checkpoint file is deleted.
</p>
<p>Note that the user is responsible to bring jobs back after the interruption.
This callback is important for the backup and restore mechanism for fault
tolerance purpose, and the model to be restored from an previous checkpoint is
expected to be the same as the one used to back up. If user changes arguments
passed to compile or fit, the checkpoint saved for fault tolerance can become
invalid.
</p>
<p>Note:
</p>

<ol>
<li><p> This callback is not compatible with eager execution disabled.
</p>
</li>
<li><p> A checkpoint is saved at the end of each epoch. After restoring,
<code>fit()</code> redoes any partial work during the unfinished epoch in which the
training got restarted (so the work done before the interruption doesn't
affect the final model state).
</p>
</li>
<li><p> This works for both single worker and multi-worker modes. When <code>fit()</code>
is used with <code>tf.distribute</code>, it supports <code>tf.distribute.MirroredStrategy</code>,
<code>tf.distribute.MultiWorkerMirroredStrategy</code>, <code>tf.distribute.TPUStrategy</code>, and
<code>tf.distribute.experimental.ParameterServerStrategy</code>.
</p>
</li></ol>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/BackupAndRestore">https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/BackupAndRestore</a>
</p>
</li></ul>


<hr>
<h2 id='callback_csv_logger'>Callback that streams epoch results to a csv file</h2><span id='topic+callback_csv_logger'></span>

<h3>Description</h3>

<p>Supports all values that can be represented as a string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_csv_logger(filename, separator = ",", append = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_csv_logger_+3A_filename">filename</code></td>
<td>
<p>filename of the csv file, e.g. 'run/log.csv'.</p>
</td></tr>
<tr><td><code id="callback_csv_logger_+3A_separator">separator</code></td>
<td>
<p>string used to separate elements in the csv file.</p>
</td></tr>
<tr><td><code id="callback_csv_logger_+3A_append">append</code></td>
<td>
<p><code>TRUE</code>: append if file exists (useful for continuing training).
<code>FALSE</code>: overwrite existing file,</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_early_stopping'>Stop training when a monitored quantity has stopped improving.</h2><span id='topic+callback_early_stopping'></span>

<h3>Description</h3>

<p>Stop training when a monitored quantity has stopped improving.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_early_stopping(
  monitor = "val_loss",
  min_delta = 0,
  patience = 0,
  verbose = 0,
  mode = c("auto", "min", "max"),
  baseline = NULL,
  restore_best_weights = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_early_stopping_+3A_monitor">monitor</code></td>
<td>
<p>quantity to be monitored.</p>
</td></tr>
<tr><td><code id="callback_early_stopping_+3A_min_delta">min_delta</code></td>
<td>
<p>minimum change in the monitored quantity to qualify as an
improvement, i.e. an absolute change of less than min_delta, will count as
no improvement.</p>
</td></tr>
<tr><td><code id="callback_early_stopping_+3A_patience">patience</code></td>
<td>
<p>number of epochs with no improvement after which training
will be stopped.</p>
</td></tr>
<tr><td><code id="callback_early_stopping_+3A_verbose">verbose</code></td>
<td>
<p>verbosity mode, 0 or 1.</p>
</td></tr>
<tr><td><code id="callback_early_stopping_+3A_mode">mode</code></td>
<td>
<p>one of &quot;auto&quot;, &quot;min&quot;, &quot;max&quot;. In <code>min</code> mode, training will stop when
the quantity monitored has stopped decreasing; in <code>max</code> mode it will stop
when the quantity monitored has stopped increasing; in <code>auto</code> mode, the
direction is automatically inferred from the name of the monitored
quantity.</p>
</td></tr>
<tr><td><code id="callback_early_stopping_+3A_baseline">baseline</code></td>
<td>
<p>Baseline value for the monitored quantity to reach.
Training will stop if the model doesn't show improvement
over the baseline.</p>
</td></tr>
<tr><td><code id="callback_early_stopping_+3A_restore_best_weights">restore_best_weights</code></td>
<td>
<p>Whether to restore model weights from
the epoch with the best value of the monitored quantity.
If <code>FALSE</code>, the model weights obtained at the last step of
training are used.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_lambda'>Create a custom callback</h2><span id='topic+callback_lambda'></span>

<h3>Description</h3>

<p>This callback is constructed with anonymous functions that will be called at
the appropriate time. Note that the callbacks expects positional arguments,
as:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_lambda(
  on_epoch_begin = NULL,
  on_epoch_end = NULL,
  on_batch_begin = NULL,
  on_batch_end = NULL,
  on_train_batch_begin = NULL,
  on_train_batch_end = NULL,
  on_train_begin = NULL,
  on_train_end = NULL,
  on_predict_batch_begin = NULL,
  on_predict_batch_end = NULL,
  on_predict_begin = NULL,
  on_predict_end = NULL,
  on_test_batch_begin = NULL,
  on_test_batch_end = NULL,
  on_test_begin = NULL,
  on_test_end = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_lambda_+3A_on_epoch_begin">on_epoch_begin</code></td>
<td>
<p>called at the beginning of every epoch.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_epoch_end">on_epoch_end</code></td>
<td>
<p>called at the end of every epoch.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_batch_begin">on_batch_begin</code></td>
<td>
<p>called at the beginning of every training batch.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_batch_end">on_batch_end</code></td>
<td>
<p>called at the end of every training batch.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_train_batch_begin">on_train_batch_begin</code></td>
<td>
<p>called at the beginning of every batch.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_train_batch_end">on_train_batch_end</code></td>
<td>
<p>called at the end of every batch.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_train_begin">on_train_begin</code></td>
<td>
<p>called at the beginning of model training.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_train_end">on_train_end</code></td>
<td>
<p>called at the end of model training.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_predict_batch_begin">on_predict_batch_begin</code></td>
<td>
<p>called at the beginning of a batch in predict methods.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_predict_batch_end">on_predict_batch_end</code></td>
<td>
<p>called at the end of a batch in predict methods.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_predict_begin">on_predict_begin</code></td>
<td>
<p>called at the beginning of prediction.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_predict_end">on_predict_end</code></td>
<td>
<p>called at the end of prediction.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_test_batch_begin">on_test_batch_begin</code></td>
<td>
<p>called at the beginning of a batch in evaluate methods.
Also called at the beginning of a validation batch in the fit methods,
if validation data is provided.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_test_batch_end">on_test_batch_end</code></td>
<td>
<p>called at the end of a batch in evaluate methods.
Also called at the end of a validation batch in the fit methods,
if validation data is provided.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_test_begin">on_test_begin</code></td>
<td>
<p>called at the beginning of evaluation or validation.</p>
</td></tr>
<tr><td><code id="callback_lambda_+3A_on_test_end">on_test_end</code></td>
<td>
<p>called at the end of evaluation or validation.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code>on_epoch_begin</code> and <code>on_epoch_end</code> expect two positional arguments: <code>epoch</code>, <code>logs</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;on_batch_*&#8288;</code>, <code style="white-space: pre;">&#8288;on_train_batch_*&#8288;</code>, <code style="white-space: pre;">&#8288;on_predict_batch_*&#8288;</code> and <code style="white-space: pre;">&#8288;on_test_batch_*&#8288;</code>, expect
two positional arguments: <code>batch</code>, <code>logs</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;on_train_*&#8288;</code>, <code style="white-space: pre;">&#8288;on_test_*&#8288;</code> and <code style="white-space: pre;">&#8288;on_predict_*&#8288;</code> expect one positional argument: <code>logs</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_learning_rate_scheduler'>Learning rate scheduler.</h2><span id='topic+callback_learning_rate_scheduler'></span>

<h3>Description</h3>

<p>Learning rate scheduler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_learning_rate_scheduler(schedule)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_learning_rate_scheduler_+3A_schedule">schedule</code></td>
<td>
<p>a function that takes an epoch index as input (integer,
indexed from 0) and current learning rate and returns a new learning rate
as output (float).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_model_checkpoint'>Save the model after every epoch.</h2><span id='topic+callback_model_checkpoint'></span>

<h3>Description</h3>

<p><code>filepath</code> can contain named formatting options, which will be filled the
value of <code>epoch</code> and keys in <code>logs</code> (passed in <code>on_epoch_end</code>). For example:
if <code>filepath</code> is <code style="white-space: pre;">&#8288;weights.{epoch:02d}-{val_loss:.2f}.hdf5&#8288;</code>, then the model
checkpoints will be saved with the epoch number and the validation loss in
the filename.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_model_checkpoint(
  filepath,
  monitor = "val_loss",
  verbose = 0,
  save_best_only = FALSE,
  save_weights_only = FALSE,
  mode = c("auto", "min", "max"),
  period = NULL,
  save_freq = "epoch"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_model_checkpoint_+3A_filepath">filepath</code></td>
<td>
<p>string, path to save the model file.</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_monitor">monitor</code></td>
<td>
<p>quantity to monitor.</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_verbose">verbose</code></td>
<td>
<p>verbosity mode, 0 or 1.</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_save_best_only">save_best_only</code></td>
<td>
<p>if <code>save_best_only=TRUE</code>, the latest best model
according to the quantity monitored will not be overwritten.</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_save_weights_only">save_weights_only</code></td>
<td>
<p>if <code>TRUE</code>, then only the model's weights will be
saved (<code>save_model_weights_hdf5(filepath)</code>), else the full model is saved
(<code>save_model_hdf5(filepath)</code>).</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_mode">mode</code></td>
<td>
<p>one of &quot;auto&quot;, &quot;min&quot;, &quot;max&quot;. If <code>save_best_only=TRUE</code>, the decision to
overwrite the current save file is made based on either the maximization or
the minimization of the monitored quantity. For val_acc, this should be
max, for val_loss this should be min, etc. In auto mode, the direction is
automatically inferred from the name of the monitored quantity.</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_period">period</code></td>
<td>
<p>Interval (number of epochs) between checkpoints.</p>
</td></tr>
<tr><td><code id="callback_model_checkpoint_+3A_save_freq">save_freq</code></td>
<td>
<p><code>'epoch'</code> or integer. When using 'epoch', the callback saves
the model after each epoch. When using integer, the callback saves the model
at end of a batch at which this many samples have been seen since last saving.
Note that if the saving isn't aligned to epochs, the monitored metric may
potentially be less reliable (it could reflect as little as 1 batch, since
the metrics get reset every epoch). Defaults to <code>'epoch'</code></p>
</td></tr>
</table>


<h3>For example</h3>

<p>if <code>filepath</code> is
<code style="white-space: pre;">&#8288;weights.{epoch:02d}-{val_loss:.2f}.hdf5&#8288;</code>,: then the model checkpoints will
be saved with the epoch number and the validation loss in the filename.
</p>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_progbar_logger'>Callback that prints metrics to stdout.</h2><span id='topic+callback_progbar_logger'></span>

<h3>Description</h3>

<p>Callback that prints metrics to stdout.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_progbar_logger(count_mode = "samples", stateful_metrics = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_progbar_logger_+3A_count_mode">count_mode</code></td>
<td>
<p>One of &quot;steps&quot; or &quot;samples&quot;. Whether the progress bar
should count samples seens or steps (batches) seen.</p>
</td></tr>
<tr><td><code id="callback_progbar_logger_+3A_stateful_metrics">stateful_metrics</code></td>
<td>
<p>List of metric names that should <em>not</em>
be averaged onver an epoch. Metrics in this list will be logged
as-is in <code>on_epoch_end</code>. All others will be averaged in
<code>on_epoch_end</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_reduce_lr_on_plateau'>Reduce learning rate when a metric has stopped improving.</h2><span id='topic+callback_reduce_lr_on_plateau'></span>

<h3>Description</h3>

<p>Models often benefit from reducing the learning rate by a factor of 2-10 once
learning stagnates. This callback monitors a quantity and if no improvement
is seen for a 'patience' number of epochs, the learning rate is reduced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_reduce_lr_on_plateau(
  monitor = "val_loss",
  factor = 0.1,
  patience = 10,
  verbose = 0,
  mode = c("auto", "min", "max"),
  min_delta = 1e-04,
  cooldown = 0,
  min_lr = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_monitor">monitor</code></td>
<td>
<p>quantity to be monitored.</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_factor">factor</code></td>
<td>
<p>factor by which the learning rate will be reduced. new_lr = lr
\* factor</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_patience">patience</code></td>
<td>
<p>number of epochs with no improvement after which learning
rate will be reduced.</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_verbose">verbose</code></td>
<td>
<p>int. 0: quiet, 1: update messages.</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_mode">mode</code></td>
<td>
<p>one of &quot;auto&quot;, &quot;min&quot;, &quot;max&quot;. In min mode, lr will be reduced when
the quantity monitored has stopped decreasing; in max mode it will be
reduced when the quantity monitored has stopped increasing; in auto mode,
the direction is automatically inferred from the name of the monitored
quantity.</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_min_delta">min_delta</code></td>
<td>
<p>threshold for measuring the new optimum, to only focus on
significant changes.</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_cooldown">cooldown</code></td>
<td>
<p>number of epochs to wait before resuming normal operation
after lr has been reduced.</p>
</td></tr>
<tr><td><code id="callback_reduce_lr_on_plateau_+3A_min_lr">min_lr</code></td>
<td>
<p>lower bound on the learning rate.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_remote_monitor'>Callback used to stream events to a server.</h2><span id='topic+callback_remote_monitor'></span>

<h3>Description</h3>

<p>Callback used to stream events to a server.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_remote_monitor(
  root = "https://localhost:9000",
  path = "/publish/epoch/end/",
  field = "data",
  headers = NULL,
  send_as_json = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_remote_monitor_+3A_root">root</code></td>
<td>
<p>root url of the target server.</p>
</td></tr>
<tr><td><code id="callback_remote_monitor_+3A_path">path</code></td>
<td>
<p>path relative to root to which the events will be sent.</p>
</td></tr>
<tr><td><code id="callback_remote_monitor_+3A_field">field</code></td>
<td>
<p>JSON field under which the data will be stored.</p>
</td></tr>
<tr><td><code id="callback_remote_monitor_+3A_headers">headers</code></td>
<td>
<p>Optional named list of custom HTTP headers. Defaults to:
<code style="white-space: pre;">&#8288;list(Accept = "application/json", &#8288;</code>Content-Type<code style="white-space: pre;">&#8288; = "application/json")&#8288;</code></p>
</td></tr>
<tr><td><code id="callback_remote_monitor_+3A_send_as_json">send_as_json</code></td>
<td>
<p>Whether the request should be sent as application/json.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Events are sent to <code>root + '/publish/epoch/end/'</code> by default. Calls
are HTTP POST, with a <code>data</code> argument which is a JSON-encoded dictionary
of event data. If send_as_json is set to True, the content type of the
request will be application/json. Otherwise the serialized JSON will be
send within a form
</p>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_tensorboard'>TensorBoard basic visualizations</h2><span id='topic+callback_tensorboard'></span>

<h3>Description</h3>

<p>This callback writes a log for TensorBoard, which allows you to visualize
dynamic graphs of your training and test metrics, as well as activation
histograms for the different layers in your model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_tensorboard(
  log_dir = NULL,
  histogram_freq = 0,
  batch_size = NULL,
  write_graph = TRUE,
  write_grads = FALSE,
  write_images = FALSE,
  embeddings_freq = 0,
  embeddings_layer_names = NULL,
  embeddings_metadata = NULL,
  embeddings_data = NULL,
  update_freq = "epoch",
  profile_batch = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_tensorboard_+3A_log_dir">log_dir</code></td>
<td>
<p>The path of the directory where to save the log files to be
parsed by Tensorboard. The default is <code>NULL</code>, which will use the active
run directory (if available) and otherwise will use &quot;logs&quot;.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_histogram_freq">histogram_freq</code></td>
<td>
<p>frequency (in epochs) at which to compute activation
histograms for the layers of the model. If set to 0, histograms won't be
computed.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_batch_size">batch_size</code></td>
<td>
<p>size of batch of inputs to feed to the network
for histograms computation. No longer needed, ignored since TF 1.14.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_write_graph">write_graph</code></td>
<td>
<p>whether to visualize the graph in Tensorboard. The log
file can become quite large when write_graph is set to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_write_grads">write_grads</code></td>
<td>
<p>whether to visualize gradient histograms in TensorBoard.
<code>histogram_freq</code> must be greater than 0.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_write_images">write_images</code></td>
<td>
<p>whether to write model weights to visualize as image in
Tensorboard.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_embeddings_freq">embeddings_freq</code></td>
<td>
<p>frequency (in epochs) at which selected embedding
layers will be saved.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_embeddings_layer_names">embeddings_layer_names</code></td>
<td>
<p>a list of names of layers to keep eye on. If
<code>NULL</code> or empty list all the embedding layers will be watched.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_embeddings_metadata">embeddings_metadata</code></td>
<td>
<p>a named list which maps layer name to a file name in
which metadata for this embedding layer is saved. See the
<a href="https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin#saving_data_for_tensorboard">details</a>
about the metadata file format. In case if the same metadata file is used
for all embedding layers, string can be passed.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_embeddings_data">embeddings_data</code></td>
<td>
<p>Data to be embedded at layers specified in
<code>embeddings_layer_names</code>. Array (if the model has a single input) or list
of arrays (if the model has multiple inputs). Learn <a href="https://www.tensorflow.org/text/guide/word_embeddings">more about embeddings</a></p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_update_freq">update_freq</code></td>
<td>
<p><code>'batch'</code> or <code>'epoch'</code> or integer. When using <code>'batch'</code>, writes
the losses and metrics to TensorBoard after each batch. The same
applies for <code>'epoch'</code>. If using an integer, let's say <code>10000</code>,
the callback will write the metrics and losses to TensorBoard every
10000 samples. Note that writing too frequently to TensorBoard
can slow down your training.</p>
</td></tr>
<tr><td><code id="callback_tensorboard_+3A_profile_batch">profile_batch</code></td>
<td>
<p>Profile the batch to sample compute characteristics. By
default, it will disbale profiling. Set profile_batch=2 profile the second
batch. Must run in TensorFlow eager mode. (TF &gt;= 1.14)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TensorBoard is a visualization tool provided with TensorFlow.
</p>
<p>You can find more information about TensorBoard
<a href="https://www.tensorflow.org/tensorboard/get_started">here</a>.
</p>
<p>When using a backend other than TensorFlow, TensorBoard will still work
(if you have TensorFlow installed), but the only feature available will
be the display of the losses and metrics plots.
</p>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_terminate_on_naan">callback_terminate_on_naan</a>()</code>
</p>

<hr>
<h2 id='callback_terminate_on_naan'>Callback that terminates training when a NaN loss is encountered.</h2><span id='topic+callback_terminate_on_naan'></span>

<h3>Description</h3>

<p>Callback that terminates training when a NaN loss is encountered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_terminate_on_naan()
</code></pre>


<h3>See Also</h3>

<p>Other callbacks: 
<code><a href="#topic+callback_csv_logger">callback_csv_logger</a>()</code>,
<code><a href="#topic+callback_early_stopping">callback_early_stopping</a>()</code>,
<code><a href="#topic+callback_lambda">callback_lambda</a>()</code>,
<code><a href="#topic+callback_learning_rate_scheduler">callback_learning_rate_scheduler</a>()</code>,
<code><a href="#topic+callback_model_checkpoint">callback_model_checkpoint</a>()</code>,
<code><a href="#topic+callback_progbar_logger">callback_progbar_logger</a>()</code>,
<code><a href="#topic+callback_reduce_lr_on_plateau">callback_reduce_lr_on_plateau</a>()</code>,
<code><a href="#topic+callback_remote_monitor">callback_remote_monitor</a>()</code>,
<code><a href="#topic+callback_tensorboard">callback_tensorboard</a>()</code>
</p>

<hr>
<h2 id='clone_model'>Clone a model instance.</h2><span id='topic+clone_model'></span>

<h3>Description</h3>

<p>Model cloning is similar to calling a model on new inputs, except that it
creates new layers (and thus new weights) instead of sharing the weights of
the existing layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clone_model(model, input_tensors = NULL, clone_function = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clone_model_+3A_model">model</code></td>
<td>
<p>Instance of Keras model (could be a functional model or a
Sequential model).</p>
</td></tr>
<tr><td><code id="clone_model_+3A_input_tensors">input_tensors</code></td>
<td>
<p>Optional list of input tensors to build the model upon.
If not provided, placeholders will be created.</p>
</td></tr>
<tr><td><code id="clone_model_+3A_clone_function">clone_function</code></td>
<td>
<p>Callable to be used to clone each layer in the target
model (except <code>InputLayer</code> instances). It takes as argument the layer
instance to be cloned, and returns the corresponding layer instance to be
used in the model copy. If unspecified, this callable defaults to the
following serialization/deserialization function:
</p>
<p><code>function(layer) layer$`__class__`$from_config(layer$get_config())</code>
</p>
<p>By passing a custom callable, you can customize your copy of the model,
e.g. by wrapping certain layers of interest (you might want to replace all
LSTM instances with equivalent <code>Bidirectional(LSTM(...))</code> instances, for
example).</p>
</td></tr>
</table>

<hr>
<h2 id='compile.keras.engine.training.Model'>Configure a Keras model for training</h2><span id='topic+compile.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Configure a Keras model for training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
compile(
  object,
  optimizer = NULL,
  loss = NULL,
  metrics = NULL,
  loss_weights = NULL,
  weighted_metrics = NULL,
  run_eagerly = NULL,
  steps_per_execution = NULL,
  ...,
  target_tensors = NULL,
  sample_weight_mode = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compile.keras.engine.training.Model_+3A_object">object</code></td>
<td>
<p>Model object to compile.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_optimizer">optimizer</code></td>
<td>
<p>String (name of optimizer) or optimizer instance. For most
models, this defaults to <code>"rmsprop"</code></p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_loss">loss</code></td>
<td>
<p>String (name of objective function), objective function or a
<code>keras$losses$Loss</code> subclass instance. An objective function is any
callable with the signature <code>loss = fn(y_true, y_pred)</code>, where y_true =
ground truth values with shape = <code style="white-space: pre;">&#8288;[batch_size, d0, .. dN]&#8288;</code>, except sparse
loss functions such as sparse categorical crossentropy where shape =
<code style="white-space: pre;">&#8288;[batch_size, d0, .. dN-1]&#8288;</code>. y_pred = predicted values with shape =
<code style="white-space: pre;">&#8288;[batch_size, d0, .. dN]&#8288;</code>. It returns a weighted loss float tensor. If a
custom <code>Loss</code> instance is used and reduction is set to <code>NULL</code>, return value
has the shape <code style="white-space: pre;">&#8288;[batch_size, d0, .. dN-1]&#8288;</code> i.e. per-sample or per-timestep
loss values; otherwise, it is a scalar. If the model has multiple outputs,
you can use a different loss on each output by passing a dictionary or a
list of losses. The loss value that will be minimized by the model will
then be the sum of all individual losses, unless <code>loss_weights</code> is
specified.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_metrics">metrics</code></td>
<td>
<p>List of metrics to be evaluated by the model during training
and testing. Each of this can be a string (name of a built-in function),
function or a <code>keras$metrics$Metric</code> class instance. See
<code>?tf$keras$metrics</code>. Typically you will use <code>metrics=list('accuracy')</code>. A
function is any callable with the signature <code>result = fn(y_true, y_pred)</code>.
To specify different metrics for different outputs of a multi-output model,
you could also pass a dictionary, such as <code>metrics=list(output_a = 'accuracy', output_b = c('accuracy', 'mse'))</code>. You can also pass a list to
specify a metric or a list of metrics for each output, such as
<code>metrics=list(list('accuracy'), list('accuracy', 'mse'))</code> or
<code>metrics=list('accuracy', c('accuracy', 'mse'))</code>. When you pass the strings
<code>'accuracy'</code> or <code>'acc'</code>, this is converted to one of
<code>tf.keras.metrics.BinaryAccuracy</code>, <code>tf.keras.metrics.CategoricalAccuracy</code>,
<code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss function
used and the model output shape. A similar conversion is done for the
strings <code>'crossentropy'</code> and <code>'ce'</code>.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_loss_weights">loss_weights</code></td>
<td>
<p>Optional list, dictionary, or named vector specifying
scalar numeric coefficients to weight the loss contributions of different
model outputs. The loss value that will be minimized by the model will then
be the <em>weighted sum</em> of all individual losses, weighted by the
<code>loss_weights</code> coefficients. If a list, it is expected to have a 1:1
mapping to the model's outputs. If a dict, it is expected to map output
names (strings) to scalar coefficients.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_weighted_metrics">weighted_metrics</code></td>
<td>
<p>List of metrics to be evaluated and weighted by
<code>sample_weight</code> or <code>class_weight</code> during training and testing.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_run_eagerly">run_eagerly</code></td>
<td>
<p>Bool. Defaults to <code>FALSE</code>. If <code>TRUE</code>, this Model's logic
will not be wrapped in a <code>tf.function</code>. Recommended to leave this as <code>NULL</code>
unless your Model cannot be run inside a <code>tf.function</code>. <code>run_eagerly=True</code>
is not supported when using
<code>tf.distribute.experimental.ParameterServerStrategy</code>. If the model's logic
uses tensors in R control flow expressions like <code>if</code> and <code>for</code>, the model
is still traceable with <code>tf.function</code>, but you will have to enter a
<code>tfautograph::autograph({})</code> directly.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_steps_per_execution">steps_per_execution</code></td>
<td>
<p>Int. Defaults to 1. The number of batches to run
during each <code>tf.function</code> call. Running multiple batches inside a single
<code>tf.function</code> call can greatly improve performance on TPUs or small models
with a large Python/R overhead. At most, one full epoch will be run each
execution. If a number larger than the size of the epoch is passed, the
execution will be truncated to the size of the epoch. Note that if
<code>steps_per_execution</code> is set to <code>N</code>, <code>Callback.on_batch_begin</code> and
<code>Callback.on_batch_end</code> methods will only be called every <code>N</code> batches (i.e.
before/after each <code>tf.function</code> execution).</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>Arguments supported for backwards compatibility only.</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_target_tensors">target_tensors</code></td>
<td>
<p>By default, Keras will create a placeholder for the
model's target, which will be fed with the target data during training. If
instead you would like to use your own target tensor (in turn, Keras will
not expect external data for these targets at training time), you can
specify them via the <code>target_tensors</code> argument. It should be a single
tensor (for a single-output sequential model).</p>
</td></tr>
<tr><td><code id="compile.keras.engine.training.Model_+3A_sample_weight_mode">sample_weight_mode</code></td>
<td>
<p>If you need to do timestep-wise sample weighting
(2D weights), set this to &quot;temporal&quot;. <code>NULL</code> defaults to sample-wise
weights (1D). If the model has multiple outputs, you can use a different
<code>sample_weight_mode</code> on each output by passing a list of modes.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='constraints'>Weight constraints</h2><span id='topic+constraints'></span><span id='topic+constraint_maxnorm'></span><span id='topic+constraint_nonneg'></span><span id='topic+constraint_unitnorm'></span><span id='topic+constraint_minmaxnorm'></span>

<h3>Description</h3>

<p>Functions that impose constraints on weight values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constraint_maxnorm(max_value = 2, axis = 0)

constraint_nonneg()

constraint_unitnorm(axis = 0)

constraint_minmaxnorm(min_value = 0, max_value = 1, rate = 1, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constraints_+3A_max_value">max_value</code></td>
<td>
<p>The maximum norm for the incoming weights.</p>
</td></tr>
<tr><td><code id="constraints_+3A_axis">axis</code></td>
<td>
<p>The axis along which to calculate weight norms. For instance, in
a dense layer the weight matrix has shape <code style="white-space: pre;">&#8288;input_dim, output_dim&#8288;</code>, set
<code>axis</code> to <code>0</code> to constrain each weight vector of length <code style="white-space: pre;">&#8288;input_dim,&#8288;</code>. In a
convolution 2D layer with <code>dim_ordering="tf"</code>, the weight tensor has shape
<code style="white-space: pre;">&#8288;rows, cols, input_depth, output_depth&#8288;</code>, set <code>axis</code> to <code>c(0, 1, 2)</code> to
constrain the weights of each filter tensor of size <code style="white-space: pre;">&#8288;rows, cols, input_depth&#8288;</code>.</p>
</td></tr>
<tr><td><code id="constraints_+3A_min_value">min_value</code></td>
<td>
<p>The minimum norm for the incoming weights.</p>
</td></tr>
<tr><td><code id="constraints_+3A_rate">rate</code></td>
<td>
<p>The rate for enforcing the constraint: weights will be rescaled to
yield (1 - rate) * norm + rate * norm.clip(low, high). Effectively, this
means that rate=1.0 stands for strict enforcement of the constraint, while
rate&lt;1.0 means that weights will be rescaled at each step to slowly move
towards a value inside the desired interval.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code>constraint_maxnorm()</code> constrains the weights incident to each
hidden unit to have a norm less than or equal to a desired value.
</p>
</li>
<li> <p><code>constraint_nonneg()</code> constraints the weights to be non-negative
</p>
</li>
<li> <p><code>constraint_unitnorm()</code> constrains the weights incident to each hidden
unit to have unit norm.
</p>
</li>
<li> <p><code>constraint_minmaxnorm()</code> constrains the weights incident to each
hidden unit to have the norm between a lower bound and an upper bound.
</p>
</li></ul>



<h3>Custom constraints</h3>

<p>You can implement your own constraint functions in R. A custom
constraint is an R function that takes weights (<code>w</code>) as input
and returns modified weights. Note that keras <code><a href="#topic+backend">backend()</a></code> tensor
functions (e.g. <code><a href="#topic+k_greater_equal">k_greater_equal()</a></code>) should be used in the
implementation of custom constraints. For example:
</p>
<div class="sourceCode r"><pre>nonneg_constraint &lt;- function(w) {
  w * k_cast(k_greater_equal(w, 0), k_floatx())
}

layer_dense(units = 32, input_shape = c(784),
            kernel_constraint = nonneg_constraint)
</pre></div>
<p>Note that models which use custom constraints cannot be serialized using
<code><a href="#topic+save_model_hdf5">save_model_hdf5()</a></code>. Rather, the weights of the model should be saved
and restored using <code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5()</a></code>.
</p>


<h3>See Also</h3>

<p><a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014</a>
</p>
<p><a href="#topic+KerasConstraint">KerasConstraint</a>
</p>

<hr>
<h2 id='count_params'>Count the total number of scalars composing the weights.</h2><span id='topic+count_params'></span>

<h3>Description</h3>

<p>Count the total number of scalars composing the weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_params(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="count_params_+3A_object">object</code></td>
<td>
<p>Layer or model object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer count
</p>


<h3>See Also</h3>

<p>Other layer methods: 
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_input_at">get_input_at</a>()</code>,
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+reset_states">reset_states</a>()</code>
</p>

<hr>
<h2 id='create_layer'>Create a Keras Layer</h2><span id='topic+create_layer'></span>

<h3>Description</h3>

<p>Create a Keras Layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_layer(layer_class, object, args = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_layer_+3A_layer_class">layer_class</code></td>
<td>
<p>Python layer class or R6 class of type KerasLayer</p>
</td></tr>
<tr><td><code id="create_layer_+3A_object">object</code></td>
<td>
<p>Object to compose layer with. This is either a
<code><a href="#topic+keras_model_sequential">keras_model_sequential()</a></code> to add the layer to, or another Layer which
this layer will call.</p>
</td></tr>
<tr><td><code id="create_layer_+3A_args">args</code></td>
<td>
<p>List of arguments to layer constructor function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras layer
</p>


<h3>Note</h3>

<p>The <code>object</code> parameter can be missing, in which case the
layer is created without a connection to an existing graph.
</p>

<hr>
<h2 id='create_layer_wrapper'>Create a Keras Layer wrapper</h2><span id='topic+create_layer_wrapper'></span>

<h3>Description</h3>

<p>Create a Keras Layer wrapper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_layer_wrapper(Layer, modifiers = NULL, convert = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_layer_wrapper_+3A_layer">Layer</code></td>
<td>
<p>A R6 or Python class generator that inherits from
<code>keras$layers$Layer</code></p>
</td></tr>
<tr><td><code id="create_layer_wrapper_+3A_modifiers">modifiers</code></td>
<td>
<p>A named list of functions to modify to user-supplied
arguments before they are passed on to the class constructor. (e.g.,
<code>list(units = as.integer)</code>)</p>
</td></tr>
<tr><td><code id="create_layer_wrapper_+3A_convert">convert</code></td>
<td>
<p>Boolean, whether the Python class and its methods should by
default convert python objects to R objects.
</p>
<p>See guide 'making_new_layers_and_models_via_subclassing.Rmd' for example usage.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R function that behaves similarly to the builtin keras <code style="white-space: pre;">&#8288;layer_*&#8288;</code>
functions. When called, it will create the class instance, and also
optionally call it on a supplied argument <code>object</code> if it is present. This
enables keras layers to compose nicely with the pipe (<code style="white-space: pre;">&#8288;%&gt;%&#8288;</code>).
</p>
<p>The R function will arguments taken from the <code>initialize</code> (or <code style="white-space: pre;">&#8288;__init__&#8288;</code>)
method of the Layer.
</p>
<p>If Layer is an R6 object, this will delay initializing the python
session, so it is safe to use in an R package.
</p>

<hr>
<h2 id='create_wrapper'>(Deprecated) Create a Keras Wrapper</h2><span id='topic+create_wrapper'></span>

<h3>Description</h3>

<p>R6 classes that inherit from <code>keras$layers$Wrapper</code> can now be instantiated
directly by <code>create_layer</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_wrapper(wrapper_class, object, args = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_wrapper_+3A_wrapper_class">wrapper_class</code></td>
<td>
<p>R6 class of type KerasWrapper</p>
</td></tr>
<tr><td><code id="create_wrapper_+3A_object">object</code></td>
<td>
<p>Object to compose layer with. This is either a
<code><a href="#topic+keras_model_sequential">keras_model_sequential()</a></code> to add the layer to, or another Layer which
this layer will call.</p>
</td></tr>
<tr><td><code id="create_wrapper_+3A_args">args</code></td>
<td>
<p>List of arguments to layer constructor function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras wrapper
</p>


<h3>Note</h3>

<p>The <code>object</code> parameter can be missing, in which case the
layer is created without a connection to an existing graph.
</p>

<hr>
<h2 id='custom_metric'>Custom metric function</h2><span id='topic+custom_metric'></span>

<h3>Description</h3>

<p>Custom metric function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>custom_metric(name, metric_fn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="custom_metric_+3A_name">name</code></td>
<td>
<p>name used to show training progress output</p>
</td></tr>
<tr><td><code id="custom_metric_+3A_metric_fn">metric_fn</code></td>
<td>
<p>An R function with signature <code>function(y_true, y_pred){}</code> that accepts tensors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can provide an arbitrary R function as a custom metric. Note that
the <code>y_true</code> and <code>y_pred</code> parameters are tensors, so computations on
them should use backend tensor functions.
</p>
<p>Use the <code>custom_metric()</code> function to define a custom metric.
Note that a name ('mean_pred') is provided for the custom metric
function: this name is used within training progress output.
</p>
<p>If you want to save and load a model with custom metrics, you should
also specify the metric in the call the <code><a href="#topic+load_model_hdf5">load_model_hdf5()</a></code>. For example:
<code>load_model_hdf5("my_model.h5", c('mean_pred' = metric_mean_pred))</code>.
</p>
<p>Alternatively, you can wrap all of your code in a call to
<code><a href="#topic+with_custom_object_scope">with_custom_object_scope()</a></code> which will allow you to refer to the
metric by name just like you do with built in keras metrics.
</p>
<p>Documentation on the available backend tensor functions can be
found at <a href="https://tensorflow.rstudio.com/reference/keras/#backend">https://tensorflow.rstudio.com/reference/keras/#backend</a>.
</p>
<p>Alternative ways of supplying custom metrics:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;custom_metric():&#8288;</code> Arbitrary R function.
</p>
</li>
<li> <p><code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper()</a></code>: Wrap an arbitrary R function in a <code>Metric</code> instance.
</p>
</li>
<li><p> subclass <code>keras$metrics$Metric</code>: see <code>?Metric</code> for example.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='dataset_boston_housing'>Boston housing price regression dataset</h2><span id='topic+dataset_boston_housing'></span>

<h3>Description</h3>

<p>Dataset taken from the StatLib library which is maintained at Carnegie Mellon
University.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_boston_housing(
  path = "boston_housing.npz",
  test_split = 0.2,
  seed = 113L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataset_boston_housing_+3A_path">path</code></td>
<td>
<p>Path where to cache the dataset locally (relative to
~/.keras/datasets).</p>
</td></tr>
<tr><td><code id="dataset_boston_housing_+3A_test_split">test_split</code></td>
<td>
<p>fraction of the data to reserve as test set.</p>
</td></tr>
<tr><td><code id="dataset_boston_housing_+3A_seed">seed</code></td>
<td>
<p>Random seed for shuffling the data before computing the test
split.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>.
</p>
<p>Samples contain 13 attributes of houses at different locations around
the Boston suburbs in the late 1970s. Targets are the median values of the
houses at a location (in k$).
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_cifar10">dataset_cifar10</a>()</code>,
<code><a href="#topic+dataset_cifar100">dataset_cifar100</a>()</code>,
<code><a href="#topic+dataset_fashion_mnist">dataset_fashion_mnist</a>()</code>,
<code><a href="#topic+dataset_imdb">dataset_imdb</a>()</code>,
<code><a href="#topic+dataset_mnist">dataset_mnist</a>()</code>,
<code><a href="#topic+dataset_reuters">dataset_reuters</a>()</code>
</p>

<hr>
<h2 id='dataset_cifar10'>CIFAR10 small image classification</h2><span id='topic+dataset_cifar10'></span>

<h3>Description</h3>

<p>Dataset of 50,000 32x32 color training images, labeled over 10 categories,
and 10,000 test images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_cifar10()
</code></pre>


<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>.
</p>
<p>The <code>x</code> data is an array of RGB image data with shape (num_samples, 3, 32,
32).
</p>
<p>The <code>y</code> data is an array of category labels (integers in range 0-9) with
shape (num_samples).
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_boston_housing">dataset_boston_housing</a>()</code>,
<code><a href="#topic+dataset_cifar100">dataset_cifar100</a>()</code>,
<code><a href="#topic+dataset_fashion_mnist">dataset_fashion_mnist</a>()</code>,
<code><a href="#topic+dataset_imdb">dataset_imdb</a>()</code>,
<code><a href="#topic+dataset_mnist">dataset_mnist</a>()</code>,
<code><a href="#topic+dataset_reuters">dataset_reuters</a>()</code>
</p>

<hr>
<h2 id='dataset_cifar100'>CIFAR100 small image classification</h2><span id='topic+dataset_cifar100'></span>

<h3>Description</h3>

<p>Dataset of 50,000 32x32 color training images, labeled over 100 categories,
and 10,000 test images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_cifar100(label_mode = c("fine", "coarse"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataset_cifar100_+3A_label_mode">label_mode</code></td>
<td>
<p>one of &quot;fine&quot;, &quot;coarse&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>.
</p>
<p>The <code>x</code> data is an array of RGB image data with shape (num_samples, 3, 32, 32).
</p>
<p>The <code>y</code> data is an array of category labels with shape (num_samples).
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_boston_housing">dataset_boston_housing</a>()</code>,
<code><a href="#topic+dataset_cifar10">dataset_cifar10</a>()</code>,
<code><a href="#topic+dataset_fashion_mnist">dataset_fashion_mnist</a>()</code>,
<code><a href="#topic+dataset_imdb">dataset_imdb</a>()</code>,
<code><a href="#topic+dataset_mnist">dataset_mnist</a>()</code>,
<code><a href="#topic+dataset_reuters">dataset_reuters</a>()</code>
</p>

<hr>
<h2 id='dataset_fashion_mnist'>Fashion-MNIST database of fashion articles</h2><span id='topic+dataset_fashion_mnist'></span>

<h3>Description</h3>

<p>Dataset of 60,000 28x28 grayscale images of the 10 fashion article classes,
along with a test set of 10,000 images. This dataset can be used as a drop-in
replacement for MNIST. The class labels are encoded as integers from 0-9 which
correspond to T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt,
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_fashion_mnist()
</code></pre>


<h3>Details</h3>

<p>Dataset of 60,000 28x28 grayscale images of 10 fashion categories,
along with a test set of 10,000 images. This dataset can be used as a drop-in
replacement for MNIST. The class labels are:
</p>

<ul>
<li><p> 0 - T-shirt/top
</p>
</li>
<li><p> 1 - Trouser
</p>
</li>
<li><p> 2 - Pullover
</p>
</li>
<li><p> 3 - Dress
</p>
</li>
<li><p> 4 - Coat
</p>
</li>
<li><p> 5 - Sandal
</p>
</li>
<li><p> 6 - Shirt
</p>
</li>
<li><p> 7 - Sneaker
</p>
</li>
<li><p> 8 - Bag
</p>
</li>
<li><p> 9 - Ankle boot
</p>
</li></ul>



<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>, where
<code>x</code> is an array of grayscale image data with shape (num_samples, 28, 28) and <code>y</code>
is an array of article labels (integers in range 0-9) with shape (num_samples).
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_boston_housing">dataset_boston_housing</a>()</code>,
<code><a href="#topic+dataset_cifar10">dataset_cifar10</a>()</code>,
<code><a href="#topic+dataset_cifar100">dataset_cifar100</a>()</code>,
<code><a href="#topic+dataset_imdb">dataset_imdb</a>()</code>,
<code><a href="#topic+dataset_mnist">dataset_mnist</a>()</code>,
<code><a href="#topic+dataset_reuters">dataset_reuters</a>()</code>
</p>

<hr>
<h2 id='dataset_imdb'>IMDB Movie reviews sentiment classification</h2><span id='topic+dataset_imdb'></span><span id='topic+dataset_imdb_word_index'></span>

<h3>Description</h3>

<p>Dataset of 25,000 movies reviews from IMDB, labeled by sentiment
(positive/negative). Reviews have been preprocessed, and each review is
encoded as a sequence of word indexes (integers). For convenience, words are
indexed by overall frequency in the dataset, so that for instance the integer
&quot;3&quot; encodes the 3rd most frequent word in the data. This allows for quick
filtering operations such as: &quot;only consider the top 10,000 most common
words, but eliminate the top 20 most common words&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_imdb(
  path = "imdb.npz",
  num_words = NULL,
  skip_top = 0L,
  maxlen = NULL,
  seed = 113L,
  start_char = 1L,
  oov_char = 2L,
  index_from = 3L
)

dataset_imdb_word_index(path = "imdb_word_index.json")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataset_imdb_+3A_path">path</code></td>
<td>
<p>Where to cache the data (relative to <code style="white-space: pre;">&#8288;~/.keras/dataset&#8288;</code>).</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_num_words">num_words</code></td>
<td>
<p>Max number of words to include. Words are ranked by how
often they occur (in the training set) and only the most frequent words are
kept</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_skip_top">skip_top</code></td>
<td>
<p>Skip the top N most frequently occuring words (which may not
be informative).</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_maxlen">maxlen</code></td>
<td>
<p>sequences longer than this will be filtered out.</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_seed">seed</code></td>
<td>
<p>random seed for sample shuffling.</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_start_char">start_char</code></td>
<td>
<p>The start of a sequence will be marked with this character.
Set to 1 because 0 is usually the padding character.</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_oov_char">oov_char</code></td>
<td>
<p>Words that were cut out because of the <code>num_words</code> or
<code>skip_top</code> limit will be replaced with this character.</p>
</td></tr>
<tr><td><code id="dataset_imdb_+3A_index_from">index_from</code></td>
<td>
<p>Index actual words with this index and higher.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As a convention, &quot;0&quot; does not stand for a specific word, but instead is used
to encode any unknown word.
</p>


<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>.
</p>
<p>The <code>x</code> data includes integer sequences. If the <code>num_words</code> argument was
specific, the maximum possible index value is <code>num_words-1</code>. If the
<code>maxlen</code> argument was specified, the largest possible sequence length is
<code>maxlen</code>.
</p>
<p>The <code>y</code> data includes a set of integer labels (0 or 1).
</p>
<p>The <code>dataset_imdb_word_index()</code> function returns a list where the
names are words and the values are integer.
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_boston_housing">dataset_boston_housing</a>()</code>,
<code><a href="#topic+dataset_cifar10">dataset_cifar10</a>()</code>,
<code><a href="#topic+dataset_cifar100">dataset_cifar100</a>()</code>,
<code><a href="#topic+dataset_fashion_mnist">dataset_fashion_mnist</a>()</code>,
<code><a href="#topic+dataset_mnist">dataset_mnist</a>()</code>,
<code><a href="#topic+dataset_reuters">dataset_reuters</a>()</code>
</p>

<hr>
<h2 id='dataset_mnist'>MNIST database of handwritten digits</h2><span id='topic+dataset_mnist'></span>

<h3>Description</h3>

<p>Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_mnist(path = "mnist.npz")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataset_mnist_+3A_path">path</code></td>
<td>
<p>Path where to cache the dataset locally (relative to ~/.keras/datasets).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>, where
<code>x</code> is an array of grayscale image data with shape (num_samples, 28, 28) and <code>y</code>
is an array of digit labels (integers in range 0-9) with shape (num_samples).
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_boston_housing">dataset_boston_housing</a>()</code>,
<code><a href="#topic+dataset_cifar10">dataset_cifar10</a>()</code>,
<code><a href="#topic+dataset_cifar100">dataset_cifar100</a>()</code>,
<code><a href="#topic+dataset_fashion_mnist">dataset_fashion_mnist</a>()</code>,
<code><a href="#topic+dataset_imdb">dataset_imdb</a>()</code>,
<code><a href="#topic+dataset_reuters">dataset_reuters</a>()</code>
</p>

<hr>
<h2 id='dataset_reuters'>Reuters newswire topics classification</h2><span id='topic+dataset_reuters'></span><span id='topic+dataset_reuters_word_index'></span>

<h3>Description</h3>

<p>Dataset of 11,228 newswires from Reuters, labeled over 46 topics. As with
<code><a href="#topic+dataset_imdb">dataset_imdb()</a></code> , each wire is encoded as a sequence of word indexes (same
conventions).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_reuters(
  path = "reuters.npz",
  num_words = NULL,
  skip_top = 0L,
  maxlen = NULL,
  test_split = 0.2,
  seed = 113L,
  start_char = 1L,
  oov_char = 2L,
  index_from = 3L
)

dataset_reuters_word_index(path = "reuters_word_index.pkl")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataset_reuters_+3A_path">path</code></td>
<td>
<p>Where to cache the data (relative to <code style="white-space: pre;">&#8288;~/.keras/dataset&#8288;</code>).</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_num_words">num_words</code></td>
<td>
<p>Max number of words to include. Words are ranked by how
often they occur (in the training set) and only the most frequent words are
kept</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_skip_top">skip_top</code></td>
<td>
<p>Skip the top N most frequently occuring words (which may not
be informative).</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_maxlen">maxlen</code></td>
<td>
<p>Truncate sequences after this length.</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_test_split">test_split</code></td>
<td>
<p>Fraction of the dataset to be used as test data.</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_seed">seed</code></td>
<td>
<p>Random seed for sample shuffling.</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_start_char">start_char</code></td>
<td>
<p>The start of a sequence will be marked with this character.
Set to 1 because 0 is usually the padding character.</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_oov_char">oov_char</code></td>
<td>
<p>words that were cut out because of the <code>num_words</code> or
<code>skip_top</code> limit will be replaced with this character.</p>
</td></tr>
<tr><td><code id="dataset_reuters_+3A_index_from">index_from</code></td>
<td>
<p>index actual words with this index and higher.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lists of training and test data: <code style="white-space: pre;">&#8288;train$x, train$y, test$x, test$y&#8288;</code>
with same format as <code><a href="#topic+dataset_imdb">dataset_imdb()</a></code>. The <code>dataset_reuters_word_index()</code>
function returns a list where the names are words and the values are
integer. e.g. <code>word_index[["giraffe"]]</code> might return <code>1234</code>.
</p>


<h3>See Also</h3>

<p>Other datasets: 
<code><a href="#topic+dataset_boston_housing">dataset_boston_housing</a>()</code>,
<code><a href="#topic+dataset_cifar10">dataset_cifar10</a>()</code>,
<code><a href="#topic+dataset_cifar100">dataset_cifar100</a>()</code>,
<code><a href="#topic+dataset_fashion_mnist">dataset_fashion_mnist</a>()</code>,
<code><a href="#topic+dataset_imdb">dataset_imdb</a>()</code>,
<code><a href="#topic+dataset_mnist">dataset_mnist</a>()</code>
</p>

<hr>
<h2 id='evaluate_generator'>(Deprecated) Evaluates the model on a data generator.</h2><span id='topic+evaluate_generator'></span>

<h3>Description</h3>

<p>The generator should return the same kind of data as accepted by
<code>test_on_batch()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate_generator(
  object,
  generator,
  steps,
  max_queue_size = 10,
  workers = 1,
  callbacks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate_generator_+3A_object">object</code></td>
<td>
<p>Model object to evaluate</p>
</td></tr>
<tr><td><code id="evaluate_generator_+3A_generator">generator</code></td>
<td>
<p>Generator yielding lists (inputs, targets) or (inputs,
targets, sample_weights)</p>
</td></tr>
<tr><td><code id="evaluate_generator_+3A_steps">steps</code></td>
<td>
<p>Total number of steps (batches of samples) to yield from
<code>generator</code> before stopping.</p>
</td></tr>
<tr><td><code id="evaluate_generator_+3A_max_queue_size">max_queue_size</code></td>
<td>
<p>Maximum size for the generator queue. If unspecified,
<code>max_queue_size</code> will default to 10.</p>
</td></tr>
<tr><td><code id="evaluate_generator_+3A_workers">workers</code></td>
<td>
<p>Maximum number of threads to use for parallel processing. Note that
parallel processing will only be performed for native Keras generators (e.g.
<code>flow_images_from_directory()</code>) as R based generators must run on the main thread.</p>
</td></tr>
<tr><td><code id="evaluate_generator_+3A_callbacks">callbacks</code></td>
<td>
<p>List of callbacks to apply during evaluation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list of model test loss (or losses for models with multiple outputs)
and model metrics.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='evaluate.keras.engine.training.Model'>Evaluate a Keras model</h2><span id='topic+evaluate.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Evaluate a Keras model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
evaluate(
  object,
  x = NULL,
  y = NULL,
  batch_size = NULL,
  verbose = "auto",
  sample_weight = NULL,
  steps = NULL,
  callbacks = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_object">object</code></td>
<td>
<p>Model object to evaluate</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_x">x</code></td>
<td>
<p>Vector, matrix, or array of test data (or list if the model has
multiple inputs). If all inputs in the model are named, you can also pass a
list mapping input names to data. <code>x</code> can be <code>NULL</code> (default) if feeding
from framework-native tensors (e.g. TensorFlow data tensors). You can also
pass a <code>tfdataset</code> or a generator returning a list with <code style="white-space: pre;">&#8288;(inputs, targets)&#8288;</code> or
<code style="white-space: pre;">&#8288;(inputs, targets, sample_weights)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_y">y</code></td>
<td>
<p>Vector, matrix, or array of target (label) data (or list if the model has
multiple outputs). If all outputs in the model are named, you can also pass
a list mapping output names to data. <code>y</code> can be <code>NULL</code> (default) if feeding
from framework-native tensors (e.g. TensorFlow data tensors).</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer or <code>NULL</code>. Number of samples per gradient update.
If unspecified, <code>batch_size</code> will default to 32.</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (0 = silent, 1 = progress bar, 2 = one line
per epoch). Defaults to 1 in most contexts, 2 if in knitr render or running
on a distributed training server.</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_sample_weight">sample_weight</code></td>
<td>
<p>Optional array of the same length as x, containing
weights to apply to the model's loss for each sample. In the case of
temporal data, you can pass a 2D array with shape (samples,
sequence_length), to apply a different weight to every timestep of every
sample. In this case you should make sure to specify
<code>sample_weight_mode="temporal"</code> in <code><a href="#topic+compile">compile()</a></code>.</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_steps">steps</code></td>
<td>
<p>Total number of steps (batches of samples) before declaring the
evaluation round finished. Ignored with the default value of <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_callbacks">callbacks</code></td>
<td>
<p>List of callbacks to apply during evaluation.</p>
</td></tr>
<tr><td><code id="evaluate.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list of model test loss (or losses for models with multiple
outputs) and model metrics.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='export_savedmodel.keras.engine.training.Model'>Export a Saved Model</h2><span id='topic+export_savedmodel.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Serialize a model to disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
export_savedmodel(
  object,
  export_dir_base,
  overwrite = TRUE,
  versioned = !overwrite,
  remove_learning_phase = TRUE,
  as_text = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_object">object</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> object.</p>
</td></tr>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_export_dir_base">export_dir_base</code></td>
<td>
<p>A string containing a directory in which to export the
SavedModel.</p>
</td></tr>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_overwrite">overwrite</code></td>
<td>
<p>Should the <code>export_dir_base</code> directory be overwritten?</p>
</td></tr>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_versioned">versioned</code></td>
<td>
<p>Should the model be exported under a versioned subdirectory?</p>
</td></tr>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_remove_learning_phase">remove_learning_phase</code></td>
<td>
<p>Should the learning phase be removed by saving
and reloading the model? Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_as_text">as_text</code></td>
<td>
<p>Whether to write the SavedModel in text format.</p>
</td></tr>
<tr><td><code id="export_savedmodel.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>Other arguments passed to tf.saved_model.save. (Used only if
TensorFlow version &gt;= 2.0)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path to the exported directory, as a string.
</p>

<hr>
<h2 id='fit_generator'>(Deprecated) Fits the model on data yielded batch-by-batch by a generator.</h2><span id='topic+fit_generator'></span>

<h3>Description</h3>

<p>The generator is run in parallel to the model, for efficiency. For instance,
this allows you to do real-time data augmentation on images on CPU in
parallel to training your model on GPU.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_generator(
  object,
  generator,
  steps_per_epoch,
  epochs = 1,
  verbose = getOption("keras.fit_verbose", default = 1),
  callbacks = NULL,
  view_metrics = getOption("keras.view_metrics", default = "auto"),
  validation_data = NULL,
  validation_steps = NULL,
  class_weight = NULL,
  max_queue_size = 10,
  workers = 1,
  initial_epoch = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_generator_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_generator">generator</code></td>
<td>
<p>A generator (e.g. like the one provided by
<code><a href="#topic+flow_images_from_directory">flow_images_from_directory()</a></code> or a custom R
<a href="https://rstudio.github.io/reticulate/articles/calling_python.html#generators-1">generator function</a>).
</p>
<p>The output of the generator must be a list of one of these forms:
</p>
<div class="sourceCode"><pre> - (inputs, targets)
 - (inputs, targets, sample_weights)
</pre></div>
<p>This list (a single output of the generator) makes a single batch.
Therefore, all arrays in this list must have the same length (equal to
the size of this batch). Different batches may have different sizes.
For example, the last batch of the epoch is commonly smaller than the
others, if the size of the dataset is not divisible by the batch size.
The generator is expected to loop over its data indefinitely. An epoch
finishes when <code>steps_per_epoch</code> batches have been seen by the model.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_steps_per_epoch">steps_per_epoch</code></td>
<td>
<p>Total number of steps (batches of samples) to yield
from <code>generator</code> before declaring one epoch finished and starting the next
epoch. It should typically be equal to the number of samples if your
dataset divided by the batch size.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_epochs">epochs</code></td>
<td>
<p>Integer. Number of epochs to train the model.
An epoch is an iteration over the entire data provided, as defined by
<code>steps_per_epoch</code>. Note that in conjunction with <code>initial_epoch</code>,
<code>epochs</code> is to be understood as &quot;final epoch&quot;. The model is not trained
for a number of iterations given by <code>epochs</code>, but merely until the epoch
of index <code>epochs</code> is reached.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (0 = silent, 1 = progress bar, 2 = one line
per epoch). Defaults to 1 in most contexts, 2 if in knitr render or running
on a distributed training server.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_callbacks">callbacks</code></td>
<td>
<p>List of callbacks to apply during training.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_view_metrics">view_metrics</code></td>
<td>
<p>View realtime plot of training metrics (by epoch). The
default (<code>"auto"</code>) will display the plot when running within RStudio,
<code>metrics</code> were specified during model <code><a href="#topic+compile">compile()</a></code>, <code>epochs &gt; 1</code> and
<code>verbose &gt; 0</code>. Use the global <code>keras.view_metrics</code> option to establish a
different default.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_validation_data">validation_data</code></td>
<td>
<p>this can be either:
</p>

<ul>
<li><p> a generator for the validation data
</p>
</li>
<li><p> a list (inputs, targets)
</p>
</li>
<li><p> a list (inputs, targets, sample_weights).
on which to evaluate
the loss and any model metrics at the end of each epoch.
The model will not be trained on this data.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_generator_+3A_validation_steps">validation_steps</code></td>
<td>
<p>Only relevant if <code>validation_data</code> is a generator.
Total number of steps (batches of samples) to yield from <code>generator</code> before
stopping at the end of every epoch. It should typically be equal to the number
of samples of your validation dataset divided by the batch size.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_class_weight">class_weight</code></td>
<td>
<p>Optional named list mapping class indices (integer) to a
weight (float) value, used for weighting the loss function (during
training only). This can be useful to tell the model to &quot;pay more
attention&quot; to samples from an under-represented class.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_max_queue_size">max_queue_size</code></td>
<td>
<p>Maximum size for the generator queue. If unspecified,
<code>max_queue_size</code> will default to 10.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_workers">workers</code></td>
<td>
<p>Maximum number of threads to use for parallel processing. Note that
parallel processing will only be performed for native Keras generators (e.g.
<code>flow_images_from_directory()</code>) as R based generators must run on the main thread.</p>
</td></tr>
<tr><td><code id="fit_generator_+3A_initial_epoch">initial_epoch</code></td>
<td>
<p>epoch at which to start training (useful for resuming a
previous training run)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Training history object (invisibly)
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='fit_image_data_generator'>Fit image data generator internal statistics to some sample data.</h2><span id='topic+fit_image_data_generator'></span>

<h3>Description</h3>

<p>Required for <code>featurewise_center</code>, <code>featurewise_std_normalization</code>
and <code>zca_whitening</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_image_data_generator(object, x, augment = FALSE, rounds = 1, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_image_data_generator_+3A_object">object</code></td>
<td>
<p><code><a href="#topic+image_data_generator">image_data_generator()</a></code></p>
</td></tr>
<tr><td><code id="fit_image_data_generator_+3A_x">x</code></td>
<td>
<p>array, the data to fit on (should have rank 4). In case of grayscale data,
the channels axis should have value 1, and in case of RGB data, it should have value 3.</p>
</td></tr>
<tr><td><code id="fit_image_data_generator_+3A_augment">augment</code></td>
<td>
<p>Whether to fit on randomly augmented samples</p>
</td></tr>
<tr><td><code id="fit_image_data_generator_+3A_rounds">rounds</code></td>
<td>
<p>If <code>augment</code>, how many augmentation passes to do over the data</p>
</td></tr>
<tr><td><code id="fit_image_data_generator_+3A_seed">seed</code></td>
<td>
<p>random seed.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other image preprocessing: 
<code><a href="#topic+flow_images_from_data">flow_images_from_data</a>()</code>,
<code><a href="#topic+flow_images_from_dataframe">flow_images_from_dataframe</a>()</code>,
<code><a href="#topic+flow_images_from_directory">flow_images_from_directory</a>()</code>,
<code><a href="#topic+image_load">image_load</a>()</code>,
<code><a href="#topic+image_to_array">image_to_array</a>()</code>
</p>

<hr>
<h2 id='fit_text_tokenizer'>Update tokenizer internal vocabulary based on a list of texts or list of
sequences.</h2><span id='topic+fit_text_tokenizer'></span>

<h3>Description</h3>

<p>Update tokenizer internal vocabulary based on a list of texts or list of
sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_text_tokenizer(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_text_tokenizer_+3A_object">object</code></td>
<td>
<p>Tokenizer returned by <code><a href="#topic+text_tokenizer">text_tokenizer()</a></code></p>
</td></tr>
<tr><td><code id="fit_text_tokenizer_+3A_x">x</code></td>
<td>
<p>Vector/list of strings, or a generator of strings (for
memory-efficiency); Alternatively a list of &quot;sequence&quot; (a sequence is a
list of integer word indices).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Required before using <code><a href="#topic+texts_to_sequences">texts_to_sequences()</a></code>, <code><a href="#topic+texts_to_matrix">texts_to_matrix()</a></code>, or
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix()</a></code>.
</p>


<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+save_text_tokenizer">save_text_tokenizer</a>()</code>,
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix</a>()</code>,
<code><a href="#topic+text_tokenizer">text_tokenizer</a>()</code>,
<code><a href="#topic+texts_to_matrix">texts_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_sequences">texts_to_sequences</a>()</code>,
<code><a href="#topic+texts_to_sequences_generator">texts_to_sequences_generator</a>()</code>
</p>

<hr>
<h2 id='fit.keras.engine.training.Model'>Train a Keras model</h2><span id='topic+fit.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
fit(
  object,
  x = NULL,
  y = NULL,
  batch_size = NULL,
  epochs = 10,
  verbose = getOption("keras.fit_verbose", default = "auto"),
  callbacks = NULL,
  view_metrics = getOption("keras.view_metrics", default = "auto"),
  validation_split = 0,
  validation_data = NULL,
  shuffle = TRUE,
  class_weight = NULL,
  sample_weight = NULL,
  initial_epoch = 0,
  steps_per_epoch = NULL,
  validation_steps = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.keras.engine.training.Model_+3A_object">object</code></td>
<td>
<p>Model to train.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_x">x</code></td>
<td>
<p>Vector, matrix, or array of training data (or list if the model has
multiple inputs). If all inputs in the model are named, you can also pass a
list mapping input names to data. <code>x</code> can be <code>NULL</code> (default) if feeding
from framework-native tensors (e.g. TensorFlow data tensors). You can also
pass a <code>tfdataset</code> or a generator returning a list with <code style="white-space: pre;">&#8288;(inputs, targets)&#8288;</code>
or <code style="white-space: pre;">&#8288;(inputs, targets, sample_weights)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_y">y</code></td>
<td>
<p>Vector, matrix, or array of target (label) data (or list if the
model has multiple outputs). If all outputs in the model are named, you can
also pass a list mapping output names to data. <code>y</code> can be <code>NULL</code> (default)
if feeding from framework-native tensors (e.g. TensorFlow data tensors).</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer or <code>NULL</code>. Number of samples per gradient update.
If unspecified, <code>batch_size</code> will default to 32.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_epochs">epochs</code></td>
<td>
<p>Number of epochs to train the model. Note that in conjunction
with <code>initial_epoch</code>, <code>epochs</code> is to be understood as &quot;final epoch&quot;. The
model is not trained for a number of iterations given by <code>epochs</code>, but
merely until the epoch of index <code>epochs</code> is reached.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (0 = silent, 1 = progress bar, 2 = one line
per epoch). Defaults to 1 in most contexts, 2 if in knitr render or running
on a distributed training server.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_callbacks">callbacks</code></td>
<td>
<p>List of callbacks to be called during training.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_view_metrics">view_metrics</code></td>
<td>
<p>View realtime plot of training metrics (by epoch). The
default (<code>"auto"</code>) will display the plot when running within RStudio,
<code>metrics</code> were specified during model <code><a href="#topic+compile">compile()</a></code>, <code>epochs &gt; 1</code> and
<code>verbose &gt; 0</code>. Use the global <code>keras.view_metrics</code> option to establish a
different default.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_validation_split">validation_split</code></td>
<td>
<p>Float between 0 and 1. Fraction of the training data
to be used as validation data. The model will set apart this fraction of
the training data, will not train on it, and will evaluate the loss and any
model metrics on this data at the end of each epoch. The validation data is
selected from the last samples in the <code>x</code> and <code>y</code> data provided, before
shuffling.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_validation_data">validation_data</code></td>
<td>
<p>Data on which to evaluate the loss and any model
metrics at the end of each epoch. The model will not be trained on this
data. This could be a list (x_val, y_val) or a list (x_val, y_val,
val_sample_weights). <code>validation_data</code> will override <code>validation_split</code>.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle: Logical (whether to shuffle the training data before
each epoch) or string (for &quot;batch&quot;). &quot;batch&quot; is a special option for
dealing with the limitations of HDF5 data; it shuffles in batch-sized
chunks. Has no effect when <code>steps_per_epoch</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_class_weight">class_weight</code></td>
<td>
<p>Optional named list mapping indices (integers) to a
weight (float) value, used for weighting the loss function (during training
only). This can be useful to tell the model to &quot;pay more attention&quot; to
samples from an under-represented class.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_sample_weight">sample_weight</code></td>
<td>
<p>Optional array of the same length as x, containing
weights to apply to the model's loss for each sample. In the case of
temporal data, you can pass a 2D array with shape (samples,
sequence_length), to apply a different weight to every timestep of every
sample. In this case you should make sure to specify
<code>sample_weight_mode="temporal"</code> in <code><a href="#topic+compile">compile()</a></code>.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_initial_epoch">initial_epoch</code></td>
<td>
<p>Integer, Epoch at which to start training (useful for
resuming a previous training run).</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_steps_per_epoch">steps_per_epoch</code></td>
<td>
<p>Total number of steps (batches of samples) before
declaring one epoch finished and starting the next epoch. When training
with input tensors such as TensorFlow data tensors, the default <code>NULL</code> is
equal to the number of samples in your dataset divided by the batch size,
or 1 if that cannot be determined.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_validation_steps">validation_steps</code></td>
<td>
<p>Only relevant if <code>steps_per_epoch</code> is specified.
Total number of steps (batches of samples) to validate before stopping.</p>
</td></tr>
<tr><td><code id="fit.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>history</code> object that contains all information collected during
training.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='flow_images_from_data'>Generates batches of augmented/normalized data from image data and labels</h2><span id='topic+flow_images_from_data'></span>

<h3>Description</h3>

<p>Generates batches of augmented/normalized data from image data and labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flow_images_from_data(
  x,
  y = NULL,
  generator = image_data_generator(),
  batch_size = 32,
  shuffle = TRUE,
  sample_weight = NULL,
  seed = NULL,
  save_to_dir = NULL,
  save_prefix = "",
  save_format = "png",
  subset = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flow_images_from_data_+3A_x">x</code></td>
<td>
<p>data. Should have rank 4. In case of grayscale data, the channels
axis should have value 1, and in case of RGB data, it should have value 3.</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_y">y</code></td>
<td>
<p>labels (can be <code>NULL</code> if no labels are required)</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_generator">generator</code></td>
<td>
<p>Image data generator to use for augmenting/normalizing image
data.</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_batch_size">batch_size</code></td>
<td>
<p>int (default: <code>32</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_shuffle">shuffle</code></td>
<td>
<p>boolean (defaut: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_sample_weight">sample_weight</code></td>
<td>
<p>Sample weights.</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_seed">seed</code></td>
<td>
<p>int (default: <code>NULL</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_save_to_dir">save_to_dir</code></td>
<td>
<p><code>NULL</code> or str (default: <code>NULL</code>). This allows you to
optionally specify a directory to which to save the augmented pictures being
generated (useful for visualizing what you are doing).</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_save_prefix">save_prefix</code></td>
<td>
<p>str (default: &rdquo;). Prefix to use for filenames of saved
pictures (only relevant if <code>save_to_dir</code> is set).</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_save_format">save_format</code></td>
<td>
<p>one of &quot;png&quot;, &quot;jpeg&quot; (only relevant if save_to_dir is
set). Default: &quot;png&quot;.</p>
</td></tr>
<tr><td><code id="flow_images_from_data_+3A_subset">subset</code></td>
<td>
<p>Subset of data (<code>"training"</code> or <code>"validation"</code>) if
<code>validation_split</code> is set in <code><a href="#topic+image_data_generator">image_data_generator()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yields batches indefinitely, in an infinite loop.
</p>


<h3>Yields</h3>

<p><code style="white-space: pre;">&#8288;(x, y)&#8288;</code> where <code>x</code> is an array of image data and <code>y</code> is a
array of corresponding labels. The generator loops indefinitely.
</p>


<h3>See Also</h3>

<p>Other image preprocessing: 
<code><a href="#topic+fit_image_data_generator">fit_image_data_generator</a>()</code>,
<code><a href="#topic+flow_images_from_dataframe">flow_images_from_dataframe</a>()</code>,
<code><a href="#topic+flow_images_from_directory">flow_images_from_directory</a>()</code>,
<code><a href="#topic+image_load">image_load</a>()</code>,
<code><a href="#topic+image_to_array">image_to_array</a>()</code>
</p>

<hr>
<h2 id='flow_images_from_dataframe'>Takes the dataframe and the path to a directory and generates batches of
augmented/normalized data.</h2><span id='topic+flow_images_from_dataframe'></span>

<h3>Description</h3>

<p>Takes the dataframe and the path to a directory and generates batches of
augmented/normalized data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flow_images_from_dataframe(
  dataframe,
  directory = NULL,
  x_col = "filename",
  y_col = "class",
  generator = image_data_generator(),
  target_size = c(256, 256),
  color_mode = "rgb",
  classes = NULL,
  class_mode = "categorical",
  batch_size = 32,
  shuffle = TRUE,
  seed = NULL,
  save_to_dir = NULL,
  save_prefix = "",
  save_format = "png",
  subset = NULL,
  interpolation = "nearest",
  drop_duplicates = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flow_images_from_dataframe_+3A_dataframe">dataframe</code></td>
<td>
<p><code>data.frame</code> containing the filepaths relative to
directory (or absolute paths if directory is <code>NULL</code>) of the images in a
character column. It should include other column/s depending on the
<code>class_mode</code>:
</p>

<ul>
<li><p> if <code>class_mode</code> is &quot;categorical&quot; (default value) it must
include the <code>y_col</code> column with the class/es of each image. Values in
column can be character/list if a single class or list if multiple classes.
</p>
</li>
<li><p> if <code>class_mode</code> is &quot;binary&quot; or &quot;sparse&quot; it must include the given
<code>y_col</code> column with class values as strings.
</p>
</li>
<li><p> if <code>class_mode</code> is &quot;other&quot; it
should contain the columns specified in <code>y_col</code>.
</p>
</li>
<li><p> if <code>class_mode</code> is &quot;input&quot; or NULL no extra column is needed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_directory">directory</code></td>
<td>
<p>character, path to the directory to read images from.
If <code>NULL</code>, data in <code>x_col</code> column should be absolute paths.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_x_col">x_col</code></td>
<td>
<p>character, column in dataframe that contains the filenames
(or absolute paths if directory is <code>NULL</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_y_col">y_col</code></td>
<td>
<p>string or list, column/s in dataframe that has the target data.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_generator">generator</code></td>
<td>
<p>Image data generator to use for augmenting/normalizing image
data.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_target_size">target_size</code></td>
<td>
<p>Either <code>NULL</code> (default to original size) or integer vector
<code style="white-space: pre;">&#8288;(img_height, img_width)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_color_mode">color_mode</code></td>
<td>
<p>one of &quot;grayscale&quot;, &quot;rgb&quot;. Default: &quot;rgb&quot;. Whether the
images will be converted to have 1 or 3 color channels.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_classes">classes</code></td>
<td>
<p>optional list of classes (e.g. <code>c('dogs', 'cats')</code>. Default:
<code>NULL</code> If not provided, the list of classes will be automatically inferred
from the <code>y_col</code>, which will map to the label indices, will be alphanumeric).
The dictionary containing the mapping from class names to class indices
can be obtained via the attribute <code>class_indices</code>.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_class_mode">class_mode</code></td>
<td>
<p>one of &quot;categorical&quot;, &quot;binary&quot;, &quot;sparse&quot;, &quot;input&quot;, &quot;other&quot; or None.
Default: &quot;categorical&quot;. Mode for yielding the targets:
</p>

<ul>
<li><p> &quot;binary&quot;: 1D array of binary labels,
</p>
</li>
<li><p> &quot;categorical&quot;: 2D array of one-hot encoded labels. Supports multi-label output.
</p>
</li>
<li><p> &quot;sparse&quot;: 1D array of integer labels,
</p>
</li>
<li><p> &quot;input&quot;: images identical to input images (mainly used to work with autoencoders),
</p>
</li>
<li><p> &quot;other&quot;: array of y_col data,
</p>
</li>
<li><p> &quot;multi_output&quot;: allow to train a multi-output model. Y is a list or a vector.
<code>NULL</code>, no targets are returned (the generator will only yield batches of
image data, which is useful to use in  <code>predict_generator()</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_batch_size">batch_size</code></td>
<td>
<p>int (default: <code>32</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_shuffle">shuffle</code></td>
<td>
<p>boolean (defaut: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_seed">seed</code></td>
<td>
<p>int (default: <code>NULL</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_save_to_dir">save_to_dir</code></td>
<td>
<p><code>NULL</code> or str (default: <code>NULL</code>). This allows you to
optionally specify a directory to which to save the augmented pictures being
generated (useful for visualizing what you are doing).</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_save_prefix">save_prefix</code></td>
<td>
<p>str (default: &rdquo;). Prefix to use for filenames of saved
pictures (only relevant if <code>save_to_dir</code> is set).</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_save_format">save_format</code></td>
<td>
<p>one of &quot;png&quot;, &quot;jpeg&quot; (only relevant if save_to_dir is
set). Default: &quot;png&quot;.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_subset">subset</code></td>
<td>
<p>Subset of data (<code>"training"</code> or <code>"validation"</code>) if
<code>validation_split</code> is set in <code><a href="#topic+image_data_generator">image_data_generator()</a></code>.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation method used to resample the image if the
target size is different from that of the loaded image. Supported methods
are &quot;nearest&quot;, &quot;bilinear&quot;, and &quot;bicubic&quot;. If PIL version 1.1.3 or newer is
installed, &quot;lanczos&quot; is also supported. If PIL version 3.4.0 or newer is
installed, &quot;box&quot; and &quot;hamming&quot; are also supported. By default, &quot;nearest&quot;
is used.</p>
</td></tr>
<tr><td><code id="flow_images_from_dataframe_+3A_drop_duplicates">drop_duplicates</code></td>
<td>
<p>(deprecated in TF &gt;= 2.3) Boolean, whether to drop
duplicate rows based on filename. The default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yields batches indefinitely, in an infinite loop.
</p>


<h3>Yields</h3>

<p><code style="white-space: pre;">&#8288;(x, y)&#8288;</code> where <code>x</code> is an array of image data and <code>y</code> is a
array of corresponding labels. The generator loops indefinitely.
</p>


<h3>Note</h3>

<p>This functions requires that <code>pandas</code> (Python module) is installed in the
same environment as <code>tensorflow</code> and <code>keras</code>.
</p>
<p>If you are using <code>r-tensorflow</code> (the default environment) you can install
<code>pandas</code> by running <code>reticulate::virtualenv_install("pandas", envname = "r-tensorflow")</code>
or <code>reticulate::conda_install("pandas", envname = "r-tensorflow")</code> depending on
the kind of environment you are using.
</p>


<h3>See Also</h3>

<p>Other image preprocessing: 
<code><a href="#topic+fit_image_data_generator">fit_image_data_generator</a>()</code>,
<code><a href="#topic+flow_images_from_data">flow_images_from_data</a>()</code>,
<code><a href="#topic+flow_images_from_directory">flow_images_from_directory</a>()</code>,
<code><a href="#topic+image_load">image_load</a>()</code>,
<code><a href="#topic+image_to_array">image_to_array</a>()</code>
</p>

<hr>
<h2 id='flow_images_from_directory'>Generates batches of data from images in a directory (with optional
augmented/normalized data)</h2><span id='topic+flow_images_from_directory'></span>

<h3>Description</h3>

<p>Generates batches of data from images in a directory (with optional
augmented/normalized data)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flow_images_from_directory(
  directory,
  generator = image_data_generator(),
  target_size = c(256, 256),
  color_mode = "rgb",
  classes = NULL,
  class_mode = "categorical",
  batch_size = 32,
  shuffle = TRUE,
  seed = NULL,
  save_to_dir = NULL,
  save_prefix = "",
  save_format = "png",
  follow_links = FALSE,
  subset = NULL,
  interpolation = "nearest"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flow_images_from_directory_+3A_directory">directory</code></td>
<td>
<p>path to the target directory. It should contain one
subdirectory per class. Any PNG, JPG, BMP, PPM, or TIF images inside each
of the subdirectories directory tree will be included in the generator.
See <a href="https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d">this script</a>
for more details.</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_generator">generator</code></td>
<td>
<p>Image data generator (default generator does no data
augmentation/normalization transformations)</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_target_size">target_size</code></td>
<td>
<p>integer vector, default: <code>c(256, 256)</code>. The dimensions to
which all images found will be resized.</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_color_mode">color_mode</code></td>
<td>
<p>one of &quot;grayscale&quot;, &quot;rbg&quot;. Default: &quot;rgb&quot;. Whether the
images will be converted to have 1 or 3 color channels.</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_classes">classes</code></td>
<td>
<p>optional list of class subdirectories (e.g. <code>c('dogs', 'cats')</code>). Default: <code>NULL</code>, If not provided, the list of classes will be
automatically inferred (and the order of the classes, which will map to
the label indices, will be alphanumeric).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_class_mode">class_mode</code></td>
<td>
<p>one of &quot;categorical&quot;, &quot;binary&quot;, &quot;sparse&quot; or <code>NULL</code>.
Default: &quot;categorical&quot;. Determines the type of label arrays that are
returned: &quot;categorical&quot; will be 2D one-hot encoded labels, &quot;binary&quot; will
be 1D binary labels, &quot;sparse&quot; will be 1D integer labels. If <code>NULL</code>, no
labels are returned (the generator will only yield batches of image data,
which is useful to use <code><a href="#topic+predict_generator">predict_generator()</a></code>, <code><a href="#topic+evaluate_generator">evaluate_generator()</a></code>,
etc.).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_batch_size">batch_size</code></td>
<td>
<p>int (default: <code>32</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_shuffle">shuffle</code></td>
<td>
<p>boolean (defaut: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_seed">seed</code></td>
<td>
<p>int (default: <code>NULL</code>).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_save_to_dir">save_to_dir</code></td>
<td>
<p><code>NULL</code> or str (default: <code>NULL</code>). This allows you to
optionally specify a directory to which to save the augmented pictures being
generated (useful for visualizing what you are doing).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_save_prefix">save_prefix</code></td>
<td>
<p>str (default: &rdquo;). Prefix to use for filenames of saved
pictures (only relevant if <code>save_to_dir</code> is set).</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_save_format">save_format</code></td>
<td>
<p>one of &quot;png&quot;, &quot;jpeg&quot; (only relevant if save_to_dir is
set). Default: &quot;png&quot;.</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_follow_links">follow_links</code></td>
<td>
<p>whether to follow symlinks inside class subdirectories
(default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_subset">subset</code></td>
<td>
<p>Subset of data (<code>"training"</code> or <code>"validation"</code>) if
<code>validation_split</code> is set in <code><a href="#topic+image_data_generator">image_data_generator()</a></code>.</p>
</td></tr>
<tr><td><code id="flow_images_from_directory_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation method used to resample the image if the
target size is different from that of the loaded image. Supported methods
are &quot;nearest&quot;, &quot;bilinear&quot;, and &quot;bicubic&quot;. If PIL version 1.1.3 or newer is
installed, &quot;lanczos&quot; is also supported. If PIL version 3.4.0 or newer is
installed, &quot;box&quot; and &quot;hamming&quot; are also supported. By default, &quot;nearest&quot;
is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yields batches indefinitely, in an infinite loop.
</p>


<h3>Yields</h3>

<p><code style="white-space: pre;">&#8288;(x, y)&#8288;</code> where <code>x</code> is an array of image data and <code>y</code> is a
array of corresponding labels. The generator loops indefinitely.
</p>


<h3>See Also</h3>

<p>Other image preprocessing: 
<code><a href="#topic+fit_image_data_generator">fit_image_data_generator</a>()</code>,
<code><a href="#topic+flow_images_from_data">flow_images_from_data</a>()</code>,
<code><a href="#topic+flow_images_from_dataframe">flow_images_from_dataframe</a>()</code>,
<code><a href="#topic+image_load">image_load</a>()</code>,
<code><a href="#topic+image_to_array">image_to_array</a>()</code>
</p>

<hr>
<h2 id='freeze_weights'>Freeze and unfreeze weights</h2><span id='topic+freeze_weights'></span><span id='topic+unfreeze_weights'></span>

<h3>Description</h3>

<p>Freeze weights in a model or layer so that they are no longer trainable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freeze_weights(object, from = NULL, to = NULL, which = NULL)

unfreeze_weights(object, from = NULL, to = NULL, which = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freeze_weights_+3A_object">object</code></td>
<td>
<p>Keras model or layer object</p>
</td></tr>
<tr><td><code id="freeze_weights_+3A_from">from</code></td>
<td>
<p>Layer instance, layer name, or layer index within model</p>
</td></tr>
<tr><td><code id="freeze_weights_+3A_to">to</code></td>
<td>
<p>Layer instance, layer name, or layer index within model</p>
</td></tr>
<tr><td><code id="freeze_weights_+3A_which">which</code></td>
<td>
<p>layer names, integer positions, layers, logical vector (of
<code>length(object$layers)</code>), or a function returning a logical vector.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>from</code> and <code>to</code> layer arguments are both inclusive.
</p>
<p>When applied to a model, the freeze or unfreeze is a global operation over
all layers in the model (i.e. layers not within the specified range will be
set to the opposite value, e.g. unfrozen for a call to freeze).
</p>
<p>Models must be compiled again after weights are frozen or unfrozen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
conv_base &lt;- application_vgg16(
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(150, 150, 3)
)

# freeze it's weights
freeze_weights(conv_base)

conv_base

# create a composite model that includes the base + more layers
model &lt;- keras_model_sequential() %&gt;%
  conv_base() %&gt;%
  layer_flatten() %&gt;%
  layer_dense(units = 256, activation = "relu") %&gt;%
  layer_dense(units = 1, activation = "sigmoid")

# compile
model %&gt;% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 2e-5),
  metrics = c("accuracy")
)

model
print(model, expand_nested = TRUE)



# unfreeze weights from "block5_conv1" on
unfreeze_weights(conv_base, from = "block5_conv1")

# compile again since we froze or unfroze weights
model %&gt;% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 2e-5),
  metrics = c("accuracy")
)

conv_base
print(model, expand_nested = TRUE)

# freeze only the last 5 layers
freeze_weights(conv_base, from = -5)
conv_base
# equivalently, also freeze only the last 5 layers
unfreeze_weights(conv_base, to = -6)
conv_base

# Freeze only layers of a certain type, e.g, BatchNorm layers
batch_norm_layer_class_name &lt;- class(layer_batch_normalization())[1]
is_batch_norm_layer &lt;- function(x) inherits(x, batch_norm_layer_class_name)

model &lt;- application_efficientnet_b0()
freeze_weights(model, which = is_batch_norm_layer)
model
# equivalent to:
for(layer in model$layers) {
  if(is_batch_norm_layer(layer))
    layer$trainable &lt;- FALSE
  else
    layer$trainable &lt;- TRUE
}

## End(Not run)
</code></pre>

<hr>
<h2 id='generator_next'>Retrieve the next item from a generator</h2><span id='topic+generator_next'></span>

<h3>Description</h3>

<p>Use to retrieve items from generators (e.g. <code><a href="#topic+image_data_generator">image_data_generator()</a></code>). Will return
either the next item or <code>NULL</code> if there are no more items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generator_next(generator, completed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generator_next_+3A_generator">generator</code></td>
<td>
<p>Generator</p>
</td></tr>
<tr><td><code id="generator_next_+3A_completed">completed</code></td>
<td>
<p>Sentinel value to return from <code>generator_next()</code> if the iteration
completes (defaults to <code>NULL</code> but can be any R value you specify).</p>
</td></tr>
</table>

<hr>
<h2 id='get_config'>Layer/Model configuration</h2><span id='topic+get_config'></span><span id='topic+from_config'></span>

<h3>Description</h3>

<p>A layer config is an object returned from <code>get_config()</code> that contains the
configuration of a layer or model. The same layer or model can be
reinstantiated later (without its trained weights) from this configuration
using <code>from_config()</code>. The config does not include connectivity information,
nor the class name (those are handled externally).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_config(object)

from_config(config, custom_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_config_+3A_object">object</code></td>
<td>
<p>Layer or model object</p>
</td></tr>
<tr><td><code id="get_config_+3A_config">config</code></td>
<td>
<p>Object with layer or model configuration</p>
</td></tr>
<tr><td><code id="get_config_+3A_custom_objects">custom_objects</code></td>
<td>
<p>list of custom objects needed to instantiate the layer,
e.g., custom layers defined by <code>new_layer_class()</code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_config()</code> returns an object with the configuration,
<code>from_config()</code> returns a re-instantiation of the object.
</p>


<h3>Note</h3>

<p>Objects returned from <code>get_config()</code> are not serializable. Therefore,
if you want to save and restore a model across sessions, you can use the
<code>model_to_json()</code> function (for model configuration only, not weights) or
the <code>save_model_tf()</code> function to save the model configuration and weights
to the filesystem.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>
<p>Other layer methods: 
<code><a href="#topic+count_params">count_params</a>()</code>,
<code><a href="#topic+get_input_at">get_input_at</a>()</code>,
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+reset_states">reset_states</a>()</code>
</p>

<hr>
<h2 id='get_file'>Downloads a file from a URL if it not already in the cache.</h2><span id='topic+get_file'></span>

<h3>Description</h3>

<p>Passing the MD5 hash will verify the file after download as well as if it is
already present in the cache.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_file(
  fname,
  origin,
  file_hash = NULL,
  cache_subdir = "datasets",
  hash_algorithm = "auto",
  extract = FALSE,
  archive_format = "auto",
  cache_dir = NULL,
  untar = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_file_+3A_fname">fname</code></td>
<td>
<p>Name of the file. If an absolute path <code style="white-space: pre;">&#8288;/path/to/file.txt&#8288;</code> is
specified the file will be saved at that location.</p>
</td></tr>
<tr><td><code id="get_file_+3A_origin">origin</code></td>
<td>
<p>Original URL of the file.</p>
</td></tr>
<tr><td><code id="get_file_+3A_file_hash">file_hash</code></td>
<td>
<p>The expected hash string of the file after download. The
sha256 and md5 hash algorithms are both supported.</p>
</td></tr>
<tr><td><code id="get_file_+3A_cache_subdir">cache_subdir</code></td>
<td>
<p>Subdirectory under the Keras cache dir where the file is
saved. If an absolute path <code style="white-space: pre;">&#8288;/path/to/folder&#8288;</code> is specified the file will be
saved at that location.</p>
</td></tr>
<tr><td><code id="get_file_+3A_hash_algorithm">hash_algorithm</code></td>
<td>
<p>Select the hash algorithm to verify the file. options
are 'md5', 'sha256', and 'auto'. The default 'auto' detects the hash
algorithm in use.</p>
</td></tr>
<tr><td><code id="get_file_+3A_extract">extract</code></td>
<td>
<p>True tries extracting the file as an Archive, like tar or zip.</p>
</td></tr>
<tr><td><code id="get_file_+3A_archive_format">archive_format</code></td>
<td>
<p>Archive format to try for extracting the file. Options
are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz
files. The default 'auto' is ('tar', 'zip'). None or an empty list will
return no matches found.</p>
</td></tr>
<tr><td><code id="get_file_+3A_cache_dir">cache_dir</code></td>
<td>
<p>Location to store cached files, when <code>NULL</code> it defaults to
the Keras configuration directory.</p>
</td></tr>
<tr><td><code id="get_file_+3A_untar">untar</code></td>
<td>
<p>Deprecated in favor of 'extract'. boolean, whether the file should
be decompressed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Path to the downloaded file
</p>

<hr>
<h2 id='get_input_at'>Retrieve tensors for layers with multiple nodes</h2><span id='topic+get_input_at'></span><span id='topic+get_output_at'></span><span id='topic+get_input_shape_at'></span><span id='topic+get_output_shape_at'></span><span id='topic+get_input_mask_at'></span><span id='topic+get_output_mask_at'></span>

<h3>Description</h3>

<p>Whenever you are calling a layer on some input, you are creating a new tensor
(the output of the layer), and you are adding a &quot;node&quot; to the layer, linking
the input tensor to the output tensor. When you are calling the same layer
multiple times, that layer owns multiple nodes indexed as 1, 2, 3. These
functions enable you to retrieve various tensor properties of layers with
multiple nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_input_at(object, node_index)

get_output_at(object, node_index)

get_input_shape_at(object, node_index)

get_output_shape_at(object, node_index)

get_input_mask_at(object, node_index)

get_output_mask_at(object, node_index)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_input_at_+3A_object">object</code></td>
<td>
<p>Layer or model object</p>
</td></tr>
<tr><td><code id="get_input_at_+3A_node_index">node_index</code></td>
<td>
<p>Integer, index of the node from which to retrieve the
attribute. E.g. <code>node_index = 1</code> will correspond to the first time the
layer was called.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor (or list of tensors if the layer has multiple inputs/outputs).
</p>


<h3>See Also</h3>

<p>Other layer methods: 
<code><a href="#topic+count_params">count_params</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+reset_states">reset_states</a>()</code>
</p>

<hr>
<h2 id='get_layer'>Retrieves a layer based on either its name (unique) or index.</h2><span id='topic+get_layer'></span>

<h3>Description</h3>

<p>Indices are based on order of horizontal graph traversal (bottom-up) and are
1-based. If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take
precedence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_layer(object, name = NULL, index = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_layer_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
<tr><td><code id="get_layer_+3A_name">name</code></td>
<td>
<p>String, name of layer.</p>
</td></tr>
<tr><td><code id="get_layer_+3A_index">index</code></td>
<td>
<p>Integer, index of layer (1-based). Also valid are negative
values, which count from the end of model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A layer instance.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='get_weights'>Layer/Model weights as R arrays</h2><span id='topic+get_weights'></span><span id='topic+set_weights'></span>

<h3>Description</h3>

<p>Layer/Model weights as R arrays
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_weights(object, trainable = NA)

set_weights(object, weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_weights_+3A_object">object</code></td>
<td>
<p>Layer or model object</p>
</td></tr>
<tr><td><code id="get_weights_+3A_trainable">trainable</code></td>
<td>
<p>if <code>NA</code> (the default), all weights are returned. If <code style="white-space: pre;">&#8288;TRUE, &#8288;</code></p>
</td></tr>
<tr><td><code id="get_weights_+3A_weights">weights</code></td>
<td>
<p>Weights as R array</p>
</td></tr>
</table>


<h3>Note</h3>

<p>You can access the Layer/Model as <code>tf.Tensors</code> or <code>tf.Variables</code> at
<code>object$weights</code>, <code>object$trainable_weights</code>, or
<code>object$non_trainable_weights</code>
</p>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+model_to_json">model_to_json</a>()</code>,
<code><a href="#topic+model_to_yaml">model_to_yaml</a>()</code>,
<code><a href="#topic+save_model_hdf5">save_model_hdf5</a>()</code>,
<code><a href="#topic+save_model_tf">save_model_tf</a>()</code>,
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5</a>()</code>,
<code><a href="#topic+serialize_model">serialize_model</a>()</code>
</p>
<p>Other layer methods: 
<code><a href="#topic+count_params">count_params</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_input_at">get_input_at</a>()</code>,
<code><a href="#topic+reset_states">reset_states</a>()</code>
</p>

<hr>
<h2 id='hdf5_matrix'>Representation of HDF5 dataset to be used instead of an R array</h2><span id='topic+hdf5_matrix'></span>

<h3>Description</h3>

<p>Representation of HDF5 dataset to be used instead of an R array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdf5_matrix(datapath, dataset, start = 0, end = NULL, normalizer = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdf5_matrix_+3A_datapath">datapath</code></td>
<td>
<p>string, path to a HDF5 file</p>
</td></tr>
<tr><td><code id="hdf5_matrix_+3A_dataset">dataset</code></td>
<td>
<p>string, name of the HDF5 dataset in the file specified in datapath</p>
</td></tr>
<tr><td><code id="hdf5_matrix_+3A_start">start</code></td>
<td>
<p>int, start of desired slice of the specified dataset</p>
</td></tr>
<tr><td><code id="hdf5_matrix_+3A_end">end</code></td>
<td>
<p>int, end of desired slice of the specified dataset</p>
</td></tr>
<tr><td><code id="hdf5_matrix_+3A_normalizer">normalizer</code></td>
<td>
<p>function to be called on data when retrieved</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Providing <code>start</code> and <code>end</code> allows use of a slice of the dataset.
</p>
<p>Optionally, a normalizer function (or lambda) can be given. This will
be called on every slice of data retrieved.
</p>


<h3>Value</h3>

<p>An array-like HDF5 dataset.
</p>

<hr>
<h2 id='image_data_generator'><a href="base.html#topic+Deprecated">Deprecated</a> Generate batches of image data with real-time data augmentation.
The data will be looped over (in batches).</h2><span id='topic+image_data_generator'></span>

<h3>Description</h3>

<p>Deprecated: <code>image_data_generator</code> is not
recommended for new code. Prefer loading images with
<code>image_dataset_from_directory</code> and transforming the output
TF Dataset with preprocessing layers. For more information, see the
tutorials for loading images and augmenting images, as well as the
preprocessing layer guide.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_data_generator(
  featurewise_center = FALSE,
  samplewise_center = FALSE,
  featurewise_std_normalization = FALSE,
  samplewise_std_normalization = FALSE,
  zca_whitening = FALSE,
  zca_epsilon = 1e-06,
  rotation_range = 0,
  width_shift_range = 0,
  height_shift_range = 0,
  brightness_range = NULL,
  shear_range = 0,
  zoom_range = 0,
  channel_shift_range = 0,
  fill_mode = "nearest",
  cval = 0,
  horizontal_flip = FALSE,
  vertical_flip = FALSE,
  rescale = NULL,
  preprocessing_function = NULL,
  data_format = NULL,
  validation_split = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image_data_generator_+3A_featurewise_center">featurewise_center</code></td>
<td>
<p>Set input mean to 0 over the dataset, feature-wise.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_samplewise_center">samplewise_center</code></td>
<td>
<p>Boolean. Set each sample mean to 0.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_featurewise_std_normalization">featurewise_std_normalization</code></td>
<td>
<p>Divide inputs by std of the dataset,
feature-wise.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_samplewise_std_normalization">samplewise_std_normalization</code></td>
<td>
<p>Divide each input by its std.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_zca_whitening">zca_whitening</code></td>
<td>
<p>apply ZCA whitening.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_zca_epsilon">zca_epsilon</code></td>
<td>
<p>Epsilon for ZCA whitening. Default is 1e-6.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_rotation_range">rotation_range</code></td>
<td>
<p>degrees (0 to 180).</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_width_shift_range">width_shift_range</code></td>
<td>
<p>fraction of total width.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_height_shift_range">height_shift_range</code></td>
<td>
<p>fraction of total height.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_brightness_range">brightness_range</code></td>
<td>
<p>the range of brightness to apply</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_shear_range">shear_range</code></td>
<td>
<p>shear intensity (shear angle in radians).</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_zoom_range">zoom_range</code></td>
<td>
<p>amount of zoom. if scalar z, zoom will be randomly picked
in the range <code style="white-space: pre;">&#8288;[1-z, 1+z]&#8288;</code>. A sequence of two can be passed instead to
select this range.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_channel_shift_range">channel_shift_range</code></td>
<td>
<p>shift range for each channels.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_fill_mode">fill_mode</code></td>
<td>
<p>One of &quot;constant&quot;, &quot;nearest&quot;, &quot;reflect&quot; or &quot;wrap&quot;. Points
outside the boundaries of the input are filled according to the given mode:
</p>

<ul>
<li><p> &quot;constant&quot;: <code>kkkkkkkk|abcd|kkkkkkkk</code> (<code>cval=k</code>)
</p>
</li>
<li><p> &quot;nearest&quot;:  <code>aaaaaaaa|abcd|dddddddd</code>
</p>
</li>
<li><p> &quot;reflect&quot;:  <code>abcddcba|abcd|dcbaabcd</code>
</p>
</li>
<li><p> &quot;wrap&quot;:     <code>abcdabcd|abcd|abcdabcd</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="image_data_generator_+3A_cval">cval</code></td>
<td>
<p>value used for points outside the boundaries when fill_mode is
'constant'. Default is 0.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_horizontal_flip">horizontal_flip</code></td>
<td>
<p>whether to randomly flip images horizontally.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_vertical_flip">vertical_flip</code></td>
<td>
<p>whether to randomly flip images vertically.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_rescale">rescale</code></td>
<td>
<p>rescaling factor. If NULL or 0, no rescaling is applied,
otherwise we multiply the data by the value provided (before applying any
other transformation).</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_preprocessing_function">preprocessing_function</code></td>
<td>
<p>function that will be implied on each input.
The function will run before any other modification on it. The function
should take one argument: one image (tensor with rank 3), and should output
a tensor with the same shape.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_data_format">data_format</code></td>
<td>
<p>'channels_first' or 'channels_last'. In 'channels_first'
mode, the channels dimension (the depth) is at index 1, in 'channels_last'
mode it is at index 3. It defaults to the <code>image_data_format</code> value found
in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it,
then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="image_data_generator_+3A_validation_split">validation_split</code></td>
<td>
<p>fraction of images reserved for validation (strictly
between 0 and 1).</p>
</td></tr>
</table>

<hr>
<h2 id='image_dataset_from_directory'>Create a dataset from a directory</h2><span id='topic+image_dataset_from_directory'></span>

<h3>Description</h3>

<p>Generates a <code>tf.data.Dataset</code> from image files in a directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_dataset_from_directory(
  directory,
  labels = "inferred",
  label_mode = "int",
  class_names = NULL,
  color_mode = "rgb",
  batch_size = 32,
  image_size = c(256, 256),
  shuffle = TRUE,
  seed = NULL,
  validation_split = NULL,
  subset = NULL,
  interpolation = "bilinear",
  follow_links = FALSE,
  crop_to_aspect_ratio = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image_dataset_from_directory_+3A_directory">directory</code></td>
<td>
<p>Directory where the data is located. If labels is
&quot;inferred&quot;, it should contain subdirectories, each containing images for a
class. Otherwise, the directory structure is ignored.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_labels">labels</code></td>
<td>
<p>Either &quot;inferred&quot; (labels are generated from the directory
structure), or a list/tuple of integer labels of the same size as the
number of image files found in the directory. Labels should be sorted
according to the alphanumeric order of the image file paths (obtained via
os.walk(directory) in Python).</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_label_mode">label_mode</code></td>
<td>
<p>Valid values:
</p>

<ul>
<li><p> 'int': labels are encoded as integers (e.g.
for sparse_categorical_crossentropy loss).
</p>
</li>
<li><p> 'categorical': labels are encoded as a categorical vector (e.g. for
categorical_crossentropy loss).
</p>
</li>
<li><p> 'binary': labels (there can be only 2) are encoded as float32 scalars
with values 0 or 1 (e.g. for binary_crossentropy).
</p>
</li>
<li> <p><code>NULL</code>: (no labels).
</p>
</li></ul>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_class_names">class_names</code></td>
<td>
<p>Only valid if &quot;labels&quot; is &quot;inferred&quot;. This is the explict
list of class names (must match names of subdirectories). Used to control
the order of the classes (otherwise alphanumerical order is used).</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_color_mode">color_mode</code></td>
<td>
<p>One of &quot;grayscale&quot;, &quot;rgb&quot;, &quot;rgba&quot;. Default: &quot;rgb&quot;. Whether
the images will be converted to have 1, 3, or 4 channels.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of the batches of data. Default: 32.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_image_size">image_size</code></td>
<td>
<p>Size to resize images to after they are read from disk.
Defaults to (256, 256). Since the pipeline processes batches of images that
must all have the same size, this must be provided.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_shuffle">shuffle</code></td>
<td>
<p>Whether to shuffle the data. Default: TRUE. If set to FALSE,
sorts the data in alphanumeric order.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_seed">seed</code></td>
<td>
<p>Optional random seed for shuffling and transformations.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_validation_split">validation_split</code></td>
<td>
<p>Optional float between 0 and 1, fraction of data to
reserve for validation.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_subset">subset</code></td>
<td>
<p>One of &quot;training&quot;, &quot;validation&quot;, or &quot;both&quot; (available for TF&gt;=2.10).
Only used if validation_split is set. When <code>subset="both"</code>, the utility returns
a tuple of two datasets (the training and validation datasets respectively).</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_interpolation">interpolation</code></td>
<td>
<p>String, the interpolation method used when resizing
images. Defaults to bilinear. Supports bilinear, nearest, bicubic, area,
lanczos3, lanczos5, gaussian, mitchellcubic.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_follow_links">follow_links</code></td>
<td>
<p>Whether to visits subdirectories pointed to by symlinks.
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_crop_to_aspect_ratio">crop_to_aspect_ratio</code></td>
<td>
<p>If <code>TRUE</code>, resize the images without aspect ratio
distortion. When the original aspect ratio differs from the target aspect
ratio, the output image will be cropped so as to return the largest
possible window in the image (of size image_size) that matches the target
aspect ratio. By default (crop_to_aspect_ratio=False), aspect ratio may not
be preserved.</p>
</td></tr>
<tr><td><code id="image_dataset_from_directory_+3A_...">...</code></td>
<td>
<p>Legacy arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If your directory structure is:
</p>
<div class="sourceCode"><pre>main_directory/
...class_a/
......a_image_1.jpg
......a_image_2.jpg
...class_b/
......b_image_1.jpg
......b_image_2.jpg
</pre></div>
<p>Then calling <code>image_dataset_from_directory(main_directory, labels='inferred')</code>
will return a <code>tf.data.Dataset</code> that yields batches of images from the
subdirectories class_a and class_b, together with labels 0 and 1 (0
corresponding to class_a and 1 corresponding to class_b).
</p>
<p>Supported image formats: jpeg, png, bmp, gif. Animated gifs are truncated to
the first frame.
</p>


<h3>Value</h3>

<p>A tf.data.Dataset object. If label_mode is <code>NULL</code>, it yields float32
tensors of shape <code style="white-space: pre;">&#8288;(batch_size, image_size[1], image_size[2], num_channels)&#8288;</code>,
encoding images (see below for rules regarding <code>num_channels</code>).
</p>
<p>Otherwise, it yields pairs of <code style="white-space: pre;">&#8288;(images, labels)&#8288;</code>, where images has shape
<code style="white-space: pre;">&#8288;(batch_size, image_size[1], image_size[2], num_channels)&#8288;</code>, and labels
follows the format described below.
</p>
<p>Rules regarding labels format:
</p>

<ul>
<li><p> if label_mode is int, the labels are an int32 tensor of shape
<code>(batch_size)</code>.
</p>
</li>
<li><p> if label_mode is binary, the labels are a float32 tensor of 1s and 0s of
shape <code style="white-space: pre;">&#8288;(batch_size, 1)&#8288;</code>.
</p>
</li>
<li><p> if label_mode is categorial, the labels are a float32 tensor of shape
<code style="white-space: pre;">&#8288;(batch_size, num_classes)&#8288;</code>, representing a one-hot encoding of the class
index.
</p>
</li></ul>

<p>Rules regarding number of channels in the yielded images:
</p>

<ul>
<li><p> if color_mode is grayscale, there's 1 channel in the image tensors.
</p>
</li>
<li><p> if color_mode is rgb, there are 3 channel in the image tensors.
</p>
</li>
<li><p> if color_mode is rgba, there are 4 channel in the image tensors.
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory">https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory</a>
</p>

<hr>
<h2 id='image_load'>Loads an image into PIL format.</h2><span id='topic+image_load'></span>

<h3>Description</h3>

<p>Loads an image into PIL format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_load(
  path,
  grayscale = FALSE,
  color_mode = "rgb",
  target_size = NULL,
  interpolation = "nearest"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image_load_+3A_path">path</code></td>
<td>
<p>Path to image file</p>
</td></tr>
<tr><td><code id="image_load_+3A_grayscale">grayscale</code></td>
<td>
<p>DEPRECATED use <code>color_mode="grayscale"</code></p>
</td></tr>
<tr><td><code id="image_load_+3A_color_mode">color_mode</code></td>
<td>
<p>One of <code style="white-space: pre;">&#8288;{"grayscale", "rgb", "rgba"}&#8288;</code>.
Default: <code>"rgb"</code>. The desired image format.</p>
</td></tr>
<tr><td><code id="image_load_+3A_target_size">target_size</code></td>
<td>
<p>Either <code>NULL</code> (default to original size) or integer vector
<code style="white-space: pre;">&#8288;(img_height, img_width)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="image_load_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation method used to resample the image if the
target size is different from that of the loaded image. Supported methods
are &quot;nearest&quot;, &quot;bilinear&quot;, and &quot;bicubic&quot;. If PIL version 1.1.3 or newer is
installed, &quot;lanczos&quot; is also supported. If PIL version 3.4.0 or newer is
installed, &quot;box&quot; and &quot;hamming&quot; are also supported. By default, &quot;nearest&quot;
is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A PIL Image instance.
</p>


<h3>See Also</h3>

<p>Other image preprocessing: 
<code><a href="#topic+fit_image_data_generator">fit_image_data_generator</a>()</code>,
<code><a href="#topic+flow_images_from_data">flow_images_from_data</a>()</code>,
<code><a href="#topic+flow_images_from_dataframe">flow_images_from_dataframe</a>()</code>,
<code><a href="#topic+flow_images_from_directory">flow_images_from_directory</a>()</code>,
<code><a href="#topic+image_to_array">image_to_array</a>()</code>
</p>

<hr>
<h2 id='image_to_array'>3D array representation of images</h2><span id='topic+image_to_array'></span><span id='topic+image_array_resize'></span><span id='topic+image_array_save'></span>

<h3>Description</h3>

<p>3D array that represents an image with dimensions (height,width,channels) or
(channels,height,width) depending on the data_format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image_to_array(img, data_format = c("channels_last", "channels_first"))

image_array_resize(
  img,
  height,
  width,
  data_format = c("channels_last", "channels_first")
)

image_array_save(
  img,
  path,
  data_format = NULL,
  file_format = NULL,
  scale = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image_to_array_+3A_img">img</code></td>
<td>
<p>Image</p>
</td></tr>
<tr><td><code id="image_to_array_+3A_data_format">data_format</code></td>
<td>
<p>Image data format (&quot;channels_last&quot; or &quot;channels_first&quot;)</p>
</td></tr>
<tr><td><code id="image_to_array_+3A_height">height</code></td>
<td>
<p>Height to resize to</p>
</td></tr>
<tr><td><code id="image_to_array_+3A_width">width</code></td>
<td>
<p>Width to resize to</p>
</td></tr>
<tr><td><code id="image_to_array_+3A_path">path</code></td>
<td>
<p>Path to save image to</p>
</td></tr>
<tr><td><code id="image_to_array_+3A_file_format">file_format</code></td>
<td>
<p>Optional file format override. If omitted, the format to
use is determined from the filename extension. If a file object was used
instead of a filename, this parameter should always be used.</p>
</td></tr>
<tr><td><code id="image_to_array_+3A_scale">scale</code></td>
<td>
<p>Whether to rescale image values to be within 0,255</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other image preprocessing: 
<code><a href="#topic+fit_image_data_generator">fit_image_data_generator</a>()</code>,
<code><a href="#topic+flow_images_from_data">flow_images_from_data</a>()</code>,
<code><a href="#topic+flow_images_from_dataframe">flow_images_from_dataframe</a>()</code>,
<code><a href="#topic+flow_images_from_directory">flow_images_from_directory</a>()</code>,
<code><a href="#topic+image_load">image_load</a>()</code>
</p>

<hr>
<h2 id='imagenet_decode_predictions'>Decodes the prediction of an ImageNet model.</h2><span id='topic+imagenet_decode_predictions'></span>

<h3>Description</h3>

<p>Decodes the prediction of an ImageNet model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imagenet_decode_predictions(preds, top = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imagenet_decode_predictions_+3A_preds">preds</code></td>
<td>
<p>Tensor encoding a batch of predictions.</p>
</td></tr>
<tr><td><code id="imagenet_decode_predictions_+3A_top">top</code></td>
<td>
<p>integer, how many top-guesses to return.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of data frames with variables <code>class_name</code>, <code>class_description</code>,
and <code>score</code> (one data frame per sample in batch input).
</p>

<hr>
<h2 id='imagenet_preprocess_input'>Preprocesses a tensor or array encoding a batch of images.</h2><span id='topic+imagenet_preprocess_input'></span>

<h3>Description</h3>

<p>Preprocesses a tensor or array encoding a batch of images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imagenet_preprocess_input(x, data_format = NULL, mode = "caffe")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imagenet_preprocess_input_+3A_x">x</code></td>
<td>
<p>Input Numpy or symbolic tensor, 3D or 4D.</p>
</td></tr>
<tr><td><code id="imagenet_preprocess_input_+3A_data_format">data_format</code></td>
<td>
<p>Data format of the image tensor/array.</p>
</td></tr>
<tr><td><code id="imagenet_preprocess_input_+3A_mode">mode</code></td>
<td>
<p>One of &quot;caffe&quot;, &quot;tf&quot;, or &quot;torch&quot;
</p>

<ul>
<li><p> caffe: will convert the images from RGB to BGR,
then will zero-center each color channel with
respect to the ImageNet dataset,
without scaling.
</p>
</li>
<li><p> tf: will scale pixels between -1 and 1, sample-wise.
</p>
</li>
<li><p> torch: will scale pixels between 0 and 1 and then
will normalize each channel with respect to the
ImageNet dataset.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>Preprocessed tensor or array.
</p>

<hr>
<h2 id='implementation'>Keras implementation</h2><span id='topic+implementation'></span>

<h3>Description</h3>

<p>Obtain a reference to the Python module used for the implementation of Keras.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>implementation()
</code></pre>


<h3>Details</h3>

<p>There are currently two Python modules which implement Keras:
</p>

<ul>
<li><p> keras (&quot;keras&quot;)
</p>
</li>
<li><p> tensorflow.keras (&quot;tensorflow&quot;)
</p>
</li></ul>

<p>This function returns a reference to the implementation being currently
used by the keras package. The default implementation is &quot;keras&quot;.
You can override this by setting the <code>KERAS_IMPLEMENTATION</code> environment
variable to &quot;tensorflow&quot;.
</p>


<h3>Value</h3>

<p>Reference to the Python module used for the implementation of Keras.
</p>

<hr>
<h2 id='initializer_constant'>Initializer that generates tensors initialized to a constant value.</h2><span id='topic+initializer_constant'></span>

<h3>Description</h3>

<p>Initializer that generates tensors initialized to a constant value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_constant(value = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_constant_+3A_value">value</code></td>
<td>
<p>float; the value of the generator tensors.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_glorot_normal'>Glorot normal initializer, also called Xavier normal initializer.</h2><span id='topic+initializer_glorot_normal'></span>

<h3>Description</h3>

<p>It draws samples from a truncated normal distribution centered on 0
with <code>stddev = sqrt(2 / (fan_in + fan_out))</code>
where <code>fan_in</code> is the number of input units in the weight tensor
and <code>fan_out</code> is the number of output units in the weight tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_glorot_normal(seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_glorot_normal_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Glorot &amp; Bengio, AISTATS 2010 <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a>
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_glorot_uniform'>Glorot uniform initializer, also called Xavier uniform initializer.</h2><span id='topic+initializer_glorot_uniform'></span>

<h3>Description</h3>

<p>It draws samples from a uniform distribution within <code style="white-space: pre;">&#8288;-limit, limit&#8288;</code>
where <code>limit</code> is <code>sqrt(6 / (fan_in + fan_out))</code>
where <code>fan_in</code> is the number of input units in the weight tensor
and <code>fan_out</code> is the number of output units in the weight tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_glorot_uniform(seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_glorot_uniform_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Glorot &amp; Bengio, AISTATS 2010 <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a>
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_he_normal'>He normal initializer.</h2><span id='topic+initializer_he_normal'></span>

<h3>Description</h3>

<p>It draws samples from a truncated normal distribution centered on 0 with
<code>stddev = sqrt(2 / fan_in)</code> where <code>fan_in</code> is the number of input units in
the weight tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_he_normal(seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_he_normal_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>

<p>He et al., https://arxiv.org/abs/1502.01852
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_he_uniform'>He uniform variance scaling initializer.</h2><span id='topic+initializer_he_uniform'></span>

<h3>Description</h3>

<p>It draws samples from a uniform distribution within <code style="white-space: pre;">&#8288;-limit, limit&#8288;</code> where
<code style="white-space: pre;">&#8288;limit`` is &#8288;</code>sqrt(6 / fan_in)<code>where </code>fan_in' is the number of input units in the
weight tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_he_uniform(seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_he_uniform_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>

<p>He et al., https://arxiv.org/abs/1502.01852
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_identity'>Initializer that generates the identity matrix.</h2><span id='topic+initializer_identity'></span>

<h3>Description</h3>

<p>Only use for square 2D matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_identity(gain = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_identity_+3A_gain">gain</code></td>
<td>
<p>Multiplicative factor to apply to the identity matrix</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_lecun_normal'>LeCun normal initializer.</h2><span id='topic+initializer_lecun_normal'></span>

<h3>Description</h3>

<p>It draws samples from a truncated normal distribution centered on 0 with
<code>stddev &lt;- sqrt(1 / fan_in)</code> where <code>fan_in</code> is the number of input units in
the weight tensor..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_lecun_normal(seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_lecun_normal_+3A_seed">seed</code></td>
<td>
<p>A Python integer. Used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a>
</p>
</li>
<li><p> Efficient Backprop, <cite>LeCun, Yann et al. 1998</cite>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_lecun_uniform'>LeCun uniform initializer.</h2><span id='topic+initializer_lecun_uniform'></span>

<h3>Description</h3>

<p>It draws samples from a uniform distribution within <code style="white-space: pre;">&#8288;-limit, limit&#8288;</code> where
<code>limit</code> is <code>sqrt(3 / fan_in)</code> where <code>fan_in</code> is the number of input units in
the weight tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_lecun_uniform(seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_lecun_uniform_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>

<p>LeCun 98, Efficient Backprop,
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_ones'>Initializer that generates tensors initialized to 1.</h2><span id='topic+initializer_ones'></span>

<h3>Description</h3>

<p>Initializer that generates tensors initialized to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_ones()
</code></pre>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_orthogonal'>Initializer that generates a random orthogonal matrix.</h2><span id='topic+initializer_orthogonal'></span>

<h3>Description</h3>

<p>Initializer that generates a random orthogonal matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_orthogonal(gain = 1, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_orthogonal_+3A_gain">gain</code></td>
<td>
<p>Multiplicative factor to apply to the orthogonal matrix.</p>
</td></tr>
<tr><td><code id="initializer_orthogonal_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Saxe et al., <a href="https://arxiv.org/abs/1312.6120">https://arxiv.org/abs/1312.6120</a>
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_random_normal'>Initializer that generates tensors with a normal distribution.</h2><span id='topic+initializer_random_normal'></span>

<h3>Description</h3>

<p>Initializer that generates tensors with a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_random_normal(mean = 0, stddev = 0.05, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_random_normal_+3A_mean">mean</code></td>
<td>
<p>Mean of the random values to generate.</p>
</td></tr>
<tr><td><code id="initializer_random_normal_+3A_stddev">stddev</code></td>
<td>
<p>Standard deviation of the random values to generate.</p>
</td></tr>
<tr><td><code id="initializer_random_normal_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_random_uniform'>Initializer that generates tensors with a uniform distribution.</h2><span id='topic+initializer_random_uniform'></span>

<h3>Description</h3>

<p>Initializer that generates tensors with a uniform distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_random_uniform_+3A_minval">minval</code></td>
<td>
<p>Lower bound of the range of random values to generate.</p>
</td></tr>
<tr><td><code id="initializer_random_uniform_+3A_maxval">maxval</code></td>
<td>
<p>Upper bound of the range of random values to generate. Defaults to 1 for float types.</p>
</td></tr>
<tr><td><code id="initializer_random_uniform_+3A_seed">seed</code></td>
<td>
<p>seed</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_truncated_normal'>Initializer that generates a truncated normal distribution.</h2><span id='topic+initializer_truncated_normal'></span>

<h3>Description</h3>

<p>These values are similar to values from an <code><a href="#topic+initializer_random_normal">initializer_random_normal()</a></code>
except that values more than two standard deviations from the mean
are discarded and re-drawn. This is the recommended initializer for
neural network weights and filters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_truncated_normal_+3A_mean">mean</code></td>
<td>
<p>Mean of the random values to generate.</p>
</td></tr>
<tr><td><code id="initializer_truncated_normal_+3A_stddev">stddev</code></td>
<td>
<p>Standard deviation of the random values to generate.</p>
</td></tr>
<tr><td><code id="initializer_truncated_normal_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_variance_scaling'>Initializer capable of adapting its scale to the shape of weights.</h2><span id='topic+initializer_variance_scaling'></span>

<h3>Description</h3>

<p>With <code>distribution="normal"</code>, samples are drawn from a truncated normal
distribution centered on zero, with <code>stddev = sqrt(scale / n)</code> where n is:
</p>

<ul>
<li><p> number of input units in the weight tensor, if mode = &quot;fan_in&quot;
</p>
</li>
<li><p> number of output units, if mode = &quot;fan_out&quot;
</p>
</li>
<li><p> average of the numbers of input and output units, if mode = &quot;fan_avg&quot;
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>initializer_variance_scaling(
  scale = 1,
  mode = c("fan_in", "fan_out", "fan_avg"),
  distribution = c("normal", "uniform", "truncated_normal", "untruncated_normal"),
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initializer_variance_scaling_+3A_scale">scale</code></td>
<td>
<p>Scaling factor (positive float).</p>
</td></tr>
<tr><td><code id="initializer_variance_scaling_+3A_mode">mode</code></td>
<td>
<p>One of &quot;fan_in&quot;, &quot;fan_out&quot;, &quot;fan_avg&quot;.</p>
</td></tr>
<tr><td><code id="initializer_variance_scaling_+3A_distribution">distribution</code></td>
<td>
<p>One of &quot;truncated_normal&quot;, &quot;untruncated_normal&quot; and &quot;uniform&quot;.
For backward compatibility, &quot;normal&quot; will be accepted and converted to
&quot;untruncated_normal&quot;.</p>
</td></tr>
<tr><td><code id="initializer_variance_scaling_+3A_seed">seed</code></td>
<td>
<p>Integer used to seed the random generator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With <code>distribution="uniform"</code>, samples are drawn from a uniform distribution
within <code style="white-space: pre;">&#8288;-limit, limit&#8288;</code>, with <code>limit = sqrt(3 * scale / n)</code>.
</p>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_zeros">initializer_zeros</a>()</code>
</p>

<hr>
<h2 id='initializer_zeros'>Initializer that generates tensors initialized to 0.</h2><span id='topic+initializer_zeros'></span>

<h3>Description</h3>

<p>Initializer that generates tensors initialized to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initializer_zeros()
</code></pre>


<h3>See Also</h3>

<p>Other initializers: 
<code><a href="#topic+initializer_constant">initializer_constant</a>()</code>,
<code><a href="#topic+initializer_glorot_normal">initializer_glorot_normal</a>()</code>,
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a>()</code>,
<code><a href="#topic+initializer_he_normal">initializer_he_normal</a>()</code>,
<code><a href="#topic+initializer_he_uniform">initializer_he_uniform</a>()</code>,
<code><a href="#topic+initializer_identity">initializer_identity</a>()</code>,
<code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a>()</code>,
<code><a href="#topic+initializer_lecun_uniform">initializer_lecun_uniform</a>()</code>,
<code><a href="#topic+initializer_ones">initializer_ones</a>()</code>,
<code><a href="#topic+initializer_orthogonal">initializer_orthogonal</a>()</code>,
<code><a href="#topic+initializer_random_normal">initializer_random_normal</a>()</code>,
<code><a href="#topic+initializer_random_uniform">initializer_random_uniform</a>()</code>,
<code><a href="#topic+initializer_truncated_normal">initializer_truncated_normal</a>()</code>,
<code><a href="#topic+initializer_variance_scaling">initializer_variance_scaling</a>()</code>
</p>

<hr>
<h2 id='install_keras'>Install TensorFlow and Keras, including all Python dependencies</h2><span id='topic+install_keras'></span>

<h3>Description</h3>

<p>This function will install Tensorflow and all Keras dependencies. This is a
thin wrapper around <code><a href="tensorflow.html#topic+install_tensorflow">tensorflow::install_tensorflow()</a></code>, with the only
difference being that this includes by default additional extra packages that
keras expects, and the default version of tensorflow installed by
<code>install_keras()</code> may at times be different from the default installed
<code>install_tensorflow()</code>. The default version of tensorflow installed by
<code>install_keras()</code> is &quot;2.15&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_keras(
  method = c("auto", "virtualenv", "conda"),
  conda = "auto",
  version = "default",
  tensorflow = version,
  extra_packages = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_keras_+3A_method">method</code></td>
<td>
<p>Installation method. By default, &quot;auto&quot; automatically finds a
method that will work in the local environment. Change the default to force
a specific installation method. Note that the &quot;virtualenv&quot; method is not
available on Windows.</p>
</td></tr>
<tr><td><code id="install_keras_+3A_conda">conda</code></td>
<td>
<p>The path to a <code>conda</code> executable. Use <code>"auto"</code> to allow
<code>reticulate</code> to automatically find an appropriate <code>conda</code> binary.
See <strong>Finding Conda</strong> and <code><a href="reticulate.html#topic+conda_binary">conda_binary()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="install_keras_+3A_version">version</code></td>
<td>
<p>TensorFlow version to install. Valid values include:
</p>

<ul>
<li> <p><code>"default"</code> installs  2.16
</p>
</li>
<li> <p><code>"release"</code> installs the latest release version of tensorflow (which may
be incompatible with the current version of the R package)
</p>
</li>
<li><p> A version specification like <code>"2.4"</code> or <code>"2.4.0"</code>. Note that if the patch
version is not supplied, the latest patch release is installed (e.g.,
<code>"2.4"</code> today installs version &quot;2.4.2&quot;)
</p>
</li>
<li> <p><code>nightly</code> for the latest available nightly build.
</p>
</li>
<li><p> To any specification, you can append &quot;-cpu&quot; to install the cpu version
only of the package (e.g., <code>"2.4-cpu"</code>)
</p>
</li>
<li><p> The full URL or path to a installer binary or python *.whl file.
</p>
</li></ul>
</td></tr>
<tr><td><code id="install_keras_+3A_tensorflow">tensorflow</code></td>
<td>
<p>Synonym for <code>version</code>. Maintained for backwards.</p>
</td></tr>
<tr><td><code id="install_keras_+3A_extra_packages">extra_packages</code></td>
<td>
<p>Additional Python packages to install along with
TensorFlow.</p>
</td></tr>
<tr><td><code id="install_keras_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="reticulate.html#topic+conda-tools">reticulate::conda_install()</a></code> or
<code><a href="reticulate.html#topic+virtualenv-tools">reticulate::virtualenv_install()</a></code>, depending on the <code>method</code> used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default additional packages are:
tensorflow-hub, tensorflow-datasets, scipy, requests, pyyaml, Pillow, h5py, pandas, pydot, with their
versions potentially constrained for compatibility with the
requested tensorflow version.
</p>


<h3>See Also</h3>

<p><code><a href="tensorflow.html#topic+install_tensorflow">tensorflow::install_tensorflow()</a></code>
</p>

<hr>
<h2 id='is_keras_available'>Check if Keras is Available</h2><span id='topic+is_keras_available'></span>

<h3>Description</h3>

<p>Probe to see whether the Keras Python package is available in the current
system environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_keras_available(version = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_keras_available_+3A_version">version</code></td>
<td>
<p>Minimum required version of Keras (defaults to <code>NULL</code>, no
required version).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Logical indicating whether Keras (or the specified minimum version of
Keras) is available.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# testthat utilty for skipping tests when Keras isn't available
skip_if_no_keras &lt;- function(version = NULL) {
  if (!is_keras_available(version))
    skip("Required keras version not available for testing")
}

# use the function within a test
test_that("keras function works correctly", {
  skip_if_no_keras()
  # test code here
})

## End(Not run)

</code></pre>

<hr>
<h2 id='k_abs'>Element-wise absolute value.</h2><span id='topic+k_abs'></span>

<h3>Description</h3>

<p>Element-wise absolute value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_abs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_abs_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_all'>Bitwise reduction (logical AND).</h2><span id='topic+k_all'></span>

<h3>Description</h3>

<p>Bitwise reduction (logical AND).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_all(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_all_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_all_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform the reduction (axis indexes are
1-based).</p>
</td></tr>
<tr><td><code id="k_all_+3A_keepdims">keepdims</code></td>
<td>
<p>whether the drop or broadcast the reduction axes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A uint8 tensor (0s and 1s).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_any'>Bitwise reduction (logical OR).</h2><span id='topic+k_any'></span>

<h3>Description</h3>

<p>Bitwise reduction (logical OR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_any(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_any_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_any_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform the reduction (axis indexes
are 1-based).</p>
</td></tr>
<tr><td><code id="k_any_+3A_keepdims">keepdims</code></td>
<td>
<p>whether the drop or broadcast the reduction axes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A uint8 tensor (0s and 1s).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_arange'>Creates a 1D tensor containing a sequence of integers.</h2><span id='topic+k_arange'></span>

<h3>Description</h3>

<p>The function arguments use the same convention as Theano's arange: if only
one argument is provided, it is in fact the &quot;stop&quot; argument. The default
type of the returned tensor is <code>'int32'</code> to match TensorFlow's default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_arange(start, stop = NULL, step = 1, dtype = "int32")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_arange_+3A_start">start</code></td>
<td>
<p>Start value.</p>
</td></tr>
<tr><td><code id="k_arange_+3A_stop">stop</code></td>
<td>
<p>Stop value.</p>
</td></tr>
<tr><td><code id="k_arange_+3A_step">step</code></td>
<td>
<p>Difference between two successive values.</p>
</td></tr>
<tr><td><code id="k_arange_+3A_dtype">dtype</code></td>
<td>
<p>Integer dtype to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_argmax'>Returns the index of the maximum value along an axis.</h2><span id='topic+k_argmax'></span>

<h3>Description</h3>

<p>Returns the index of the maximum value along an axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_argmax(x, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_argmax_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_argmax_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform the reduction (axis indexes are
1-based). Pass -1 (the default) to select the last axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_argmin'>Returns the index of the minimum value along an axis.</h2><span id='topic+k_argmin'></span>

<h3>Description</h3>

<p>Returns the index of the minimum value along an axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_argmin(x, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_argmin_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_argmin_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform the reduction (axis indexes are
1-based). Pass -1 (the default) to select the last axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_backend'>Active Keras backend</h2><span id='topic+k_backend'></span>

<h3>Description</h3>

<p>Active Keras backend
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_backend()
</code></pre>


<h3>Value</h3>

<p>The name of the backend Keras is currently using.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_batch_dot'>Batchwise dot product.</h2><span id='topic+k_batch_dot'></span>

<h3>Description</h3>

<p><code>batch_dot</code> is used to compute dot product of <code>x</code> and <code>y</code> when <code>x</code> and <code>y</code>
are data in batch, i.e. in a shape of <code>(batch_size)</code>. <code>batch_dot</code> results in
a tensor or variable with less dimensions than the input. If the number of
dimensions is reduced to 1, we use <code>expand_dims</code> to make sure that ndim is
at least 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_batch_dot(x, y, axes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_batch_dot_+3A_x">x</code></td>
<td>
<p>Keras tensor or variable with 2 more more axes.</p>
</td></tr>
<tr><td><code id="k_batch_dot_+3A_y">y</code></td>
<td>
<p>Keras tensor or variable with 2 or more axes</p>
</td></tr>
<tr><td><code id="k_batch_dot_+3A_axes">axes</code></td>
<td>
<p>List of (or single) integer with target dimensions (axis indexes
are 1-based). The lengths of <code>axes[[1]]</code> and <code>axes[[2]]</code> should be the
same.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with shape equal to the concatenation of <code>x</code>'s shape (less
the dimension that was summed over) and <code>y</code>'s shape (less the batch
dimension and the dimension that was summed over). If the final rank is 1,
we reshape it to <code style="white-space: pre;">&#8288;(batch_size, 1)&#8288;</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_batch_flatten'>Turn a nD tensor into a 2D tensor with same 1st dimension.</h2><span id='topic+k_batch_flatten'></span>

<h3>Description</h3>

<p>In other words, it flattens each data samples of a batch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_batch_flatten(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_batch_flatten_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_batch_get_value'>Returns the value of more than one tensor variable.</h2><span id='topic+k_batch_get_value'></span>

<h3>Description</h3>

<p>Returns the value of more than one tensor variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_batch_get_value(ops)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_batch_get_value_+3A_ops">ops</code></td>
<td>
<p>List of ops to evaluate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of arrays.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+k_batch_set_value">k_batch_set_value()</a></code>
</p>

<hr>
<h2 id='k_batch_normalization'>Applies batch normalization on x given mean, var, beta and gamma.</h2><span id='topic+k_batch_normalization'></span>

<h3>Description</h3>

<p>i.e. returns
<code>output &lt;- (x - mean) / (sqrt(var) + epsilon) * gamma + beta</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_batch_normalization(x, mean, var, beta, gamma, axis = -1, epsilon = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_batch_normalization_+3A_x">x</code></td>
<td>
<p>Input tensor or variable.</p>
</td></tr>
<tr><td><code id="k_batch_normalization_+3A_mean">mean</code></td>
<td>
<p>Mean of batch.</p>
</td></tr>
<tr><td><code id="k_batch_normalization_+3A_var">var</code></td>
<td>
<p>Variance of batch.</p>
</td></tr>
<tr><td><code id="k_batch_normalization_+3A_beta">beta</code></td>
<td>
<p>Tensor with which to center the input.</p>
</td></tr>
<tr><td><code id="k_batch_normalization_+3A_gamma">gamma</code></td>
<td>
<p>Tensor by which to scale the input.</p>
</td></tr>
<tr><td><code id="k_batch_normalization_+3A_axis">axis</code></td>
<td>
<p>Axis (axis indexes are 1-based). Pass -1 (the
default) to select the last axis.</p>
</td></tr>
<tr><td><code id="k_batch_normalization_+3A_epsilon">epsilon</code></td>
<td>
<p>Fuzz factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_batch_set_value'>Sets the values of many tensor variables at once.</h2><span id='topic+k_batch_set_value'></span>

<h3>Description</h3>

<p>Sets the values of many tensor variables at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_batch_set_value(lists)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_batch_set_value_+3A_lists">lists</code></td>
<td>
<p>a list of lists <code style="white-space: pre;">&#8288;(tensor, value)&#8288;</code>. <code>value</code> should be an R array.</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+k_batch_get_value">k_batch_get_value()</a></code>
</p>

<hr>
<h2 id='k_bias_add'>Adds a bias vector to a tensor.</h2><span id='topic+k_bias_add'></span>

<h3>Description</h3>

<p>Adds a bias vector to a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_bias_add(x, bias, data_format = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_bias_add_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_bias_add_+3A_bias">bias</code></td>
<td>
<p>Bias tensor to add.</p>
</td></tr>
<tr><td><code id="k_bias_add_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_binary_crossentropy'>Binary crossentropy between an output tensor and a target tensor.</h2><span id='topic+k_binary_crossentropy'></span>

<h3>Description</h3>

<p>Binary crossentropy between an output tensor and a target tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_binary_crossentropy(target, output, from_logits = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_binary_crossentropy_+3A_target">target</code></td>
<td>
<p>A tensor with the same shape as <code>output</code>.</p>
</td></tr>
<tr><td><code id="k_binary_crossentropy_+3A_output">output</code></td>
<td>
<p>A tensor.</p>
</td></tr>
<tr><td><code id="k_binary_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>Whether <code>output</code> is expected to be a logits tensor. By
default, we consider that <code>output</code> encodes a probability distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_cast'>Casts a tensor to a different dtype and returns it.</h2><span id='topic+k_cast'></span>

<h3>Description</h3>

<p>You can cast a Keras variable but it still returns a Keras tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_cast(x, dtype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_cast_+3A_x">x</code></td>
<td>
<p>Keras tensor (or variable).</p>
</td></tr>
<tr><td><code id="k_cast_+3A_dtype">dtype</code></td>
<td>
<p>String, either (<code>'float16'</code>, <code>'float32'</code>, or <code>'float64'</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Keras tensor with dtype <code>dtype</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_cast_to_floatx'>Cast an array to the default Keras float type.</h2><span id='topic+k_cast_to_floatx'></span>

<h3>Description</h3>

<p>Cast an array to the default Keras float type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_cast_to_floatx(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_cast_to_floatx_+3A_x">x</code></td>
<td>
<p>Array.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same array, cast to its new type.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_categorical_crossentropy'>Categorical crossentropy between an output tensor and a target tensor.</h2><span id='topic+k_categorical_crossentropy'></span>

<h3>Description</h3>

<p>Categorical crossentropy between an output tensor and a target tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_categorical_crossentropy(target, output, from_logits = FALSE, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_categorical_crossentropy_+3A_target">target</code></td>
<td>
<p>A tensor of the same shape as <code>output</code>.</p>
</td></tr>
<tr><td><code id="k_categorical_crossentropy_+3A_output">output</code></td>
<td>
<p>A tensor resulting from a softmax (unless <code>from_logits</code> is
TRUE, in which case <code>output</code> is expected to be the logits).</p>
</td></tr>
<tr><td><code id="k_categorical_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>Logical, whether <code>output</code> is the result of a softmax, or
is a tensor of logits.</p>
</td></tr>
<tr><td><code id="k_categorical_crossentropy_+3A_axis">axis</code></td>
<td>
<p>Axis (axis indexes are 1-based). Pass -1 (the
default) to select the last axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_clear_session'>Destroys the current TF graph and creates a new one.</h2><span id='topic+k_clear_session'></span>

<h3>Description</h3>

<p>Useful to avoid clutter from old models / layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_clear_session()
</code></pre>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_clip'>Element-wise value clipping.</h2><span id='topic+k_clip'></span>

<h3>Description</h3>

<p>Element-wise value clipping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_clip(x, min_value = NULL, max_value = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_clip_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_clip_+3A_min_value">min_value</code></td>
<td>
<p>Float or integer.</p>
</td></tr>
<tr><td><code id="k_clip_+3A_max_value">max_value</code></td>
<td>
<p>Float or integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_concatenate'>Concatenates a list of tensors alongside the specified axis.</h2><span id='topic+k_concatenate'></span>

<h3>Description</h3>

<p>Concatenates a list of tensors alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_concatenate(tensors, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_concatenate_+3A_tensors">tensors</code></td>
<td>
<p>list of tensors to concatenate.</p>
</td></tr>
<tr><td><code id="k_concatenate_+3A_axis">axis</code></td>
<td>
<p>concatenation axis (axis indexes are 1-based). Pass -1 (the
default) to select the last axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_constant'>Creates a constant tensor.</h2><span id='topic+k_constant'></span>

<h3>Description</h3>

<p>Creates a constant tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_constant(value, dtype = NULL, shape = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_constant_+3A_value">value</code></td>
<td>
<p>A constant value</p>
</td></tr>
<tr><td><code id="k_constant_+3A_dtype">dtype</code></td>
<td>
<p>The type of the elements of the resulting tensor.</p>
</td></tr>
<tr><td><code id="k_constant_+3A_shape">shape</code></td>
<td>
<p>Optional dimensions of resulting tensor.</p>
</td></tr>
<tr><td><code id="k_constant_+3A_name">name</code></td>
<td>
<p>Optional name for the tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Constant Tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_conv1d'>1D convolution.</h2><span id='topic+k_conv1d'></span>

<h3>Description</h3>

<p>1D convolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_conv1d(
  x,
  kernel,
  strides = 1,
  padding = "valid",
  data_format = NULL,
  dilation_rate = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_conv1d_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_conv1d_+3A_kernel">kernel</code></td>
<td>
<p>kernel tensor.</p>
</td></tr>
<tr><td><code id="k_conv1d_+3A_strides">strides</code></td>
<td>
<p>stride integer.</p>
</td></tr>
<tr><td><code id="k_conv1d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code>, <code>"causal"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_conv1d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
<tr><td><code id="k_conv1d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>integer dilate rate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of 1D convolution.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_conv2d'>2D convolution.</h2><span id='topic+k_conv2d'></span>

<h3>Description</h3>

<p>2D convolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_conv2d(
  x,
  kernel,
  strides = c(1, 1),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_conv2d_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_conv2d_+3A_kernel">kernel</code></td>
<td>
<p>kernel tensor.</p>
</td></tr>
<tr><td><code id="k_conv2d_+3A_strides">strides</code></td>
<td>
<p>strides</p>
</td></tr>
<tr><td><code id="k_conv2d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_conv2d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>. Whether
to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.</p>
</td></tr>
<tr><td><code id="k_conv2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>vector of 2 integers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of 2D convolution.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_conv2d_transpose'>2D deconvolution (i.e. transposed convolution).</h2><span id='topic+k_conv2d_transpose'></span>

<h3>Description</h3>

<p>2D deconvolution (i.e. transposed convolution).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_conv2d_transpose(
  x,
  kernel,
  output_shape,
  strides = c(1, 1),
  padding = "valid",
  data_format = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_conv2d_transpose_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_conv2d_transpose_+3A_kernel">kernel</code></td>
<td>
<p>kernel tensor.</p>
</td></tr>
<tr><td><code id="k_conv2d_transpose_+3A_output_shape">output_shape</code></td>
<td>
<p>1D int tensor for the output shape.</p>
</td></tr>
<tr><td><code id="k_conv2d_transpose_+3A_strides">strides</code></td>
<td>
<p>strides list.</p>
</td></tr>
<tr><td><code id="k_conv2d_transpose_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_conv2d_transpose_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>. Whether
to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of transposed 2D convolution.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_conv3d'>3D convolution.</h2><span id='topic+k_conv3d'></span>

<h3>Description</h3>

<p>3D convolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_conv3d(
  x,
  kernel,
  strides = c(1, 1, 1),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1, 1, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_conv3d_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_conv3d_+3A_kernel">kernel</code></td>
<td>
<p>kernel tensor.</p>
</td></tr>
<tr><td><code id="k_conv3d_+3A_strides">strides</code></td>
<td>
<p>strides</p>
</td></tr>
<tr><td><code id="k_conv3d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_conv3d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>. Whether
to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.</p>
</td></tr>
<tr><td><code id="k_conv3d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>list of 3 integers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of 3D convolution.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_conv3d_transpose'>3D deconvolution (i.e. transposed convolution).</h2><span id='topic+k_conv3d_transpose'></span>

<h3>Description</h3>

<p>3D deconvolution (i.e. transposed convolution).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_conv3d_transpose(
  x,
  kernel,
  output_shape,
  strides = c(1, 1, 1),
  padding = "valid",
  data_format = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_conv3d_transpose_+3A_x">x</code></td>
<td>
<p>input tensor.</p>
</td></tr>
<tr><td><code id="k_conv3d_transpose_+3A_kernel">kernel</code></td>
<td>
<p>kernel tensor.</p>
</td></tr>
<tr><td><code id="k_conv3d_transpose_+3A_output_shape">output_shape</code></td>
<td>
<p>1D int tensor for the output shape.</p>
</td></tr>
<tr><td><code id="k_conv3d_transpose_+3A_strides">strides</code></td>
<td>
<p>strides</p>
</td></tr>
<tr><td><code id="k_conv3d_transpose_+3A_padding">padding</code></td>
<td>
<p>string, &quot;same&quot; or &quot;valid&quot;.</p>
</td></tr>
<tr><td><code id="k_conv3d_transpose_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>. Whether
to use Theano or TensorFlow/CNTK data format for inputs/kernels/outputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of transposed 3D convolution.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_cos'>Computes cos of x element-wise.</h2><span id='topic+k_cos'></span>

<h3>Description</h3>

<p>Computes cos of x element-wise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_cos(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_cos_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_count_params'>Returns the static number of elements in a Keras variable or tensor.</h2><span id='topic+k_count_params'></span>

<h3>Description</h3>

<p>Returns the static number of elements in a Keras variable or tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_count_params(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_count_params_+3A_x">x</code></td>
<td>
<p>Keras variable or tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integer, the number of elements in <code>x</code>, i.e., the product of the array's static dimensions.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_ctc_batch_cost'>Runs CTC loss algorithm on each batch element.</h2><span id='topic+k_ctc_batch_cost'></span>

<h3>Description</h3>

<p>Runs CTC loss algorithm on each batch element.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_ctc_batch_cost(y_true, y_pred, input_length, label_length)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_ctc_batch_cost_+3A_y_true">y_true</code></td>
<td>
<p>tensor <code style="white-space: pre;">&#8288;(samples, max_string_length)&#8288;</code> containing the truth
labels.</p>
</td></tr>
<tr><td><code id="k_ctc_batch_cost_+3A_y_pred">y_pred</code></td>
<td>
<p>tensor <code style="white-space: pre;">&#8288;(samples, time_steps, num_categories)&#8288;</code> containing the
prediction, or output of the softmax.</p>
</td></tr>
<tr><td><code id="k_ctc_batch_cost_+3A_input_length">input_length</code></td>
<td>
<p>tensor <code style="white-space: pre;">&#8288;(samples, 1)&#8288;</code> containing the sequence length for
each batch item in <code>y_pred</code>.</p>
</td></tr>
<tr><td><code id="k_ctc_batch_cost_+3A_label_length">label_length</code></td>
<td>
<p>tensor <code style="white-space: pre;">&#8288;(samples, 1)&#8288;</code> containing the sequence length for
each batch item in <code>y_true</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor with shape (samples,1) containing the CTC loss of each
element.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_ctc_decode'>Decodes the output of a softmax.</h2><span id='topic+k_ctc_decode'></span>

<h3>Description</h3>

<p>Can use either greedy search (also known as best path) or a constrained
dictionary search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_ctc_decode(
  y_pred,
  input_length,
  greedy = TRUE,
  beam_width = 100L,
  top_paths = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_ctc_decode_+3A_y_pred">y_pred</code></td>
<td>
<p>tensor <code style="white-space: pre;">&#8288;(samples, time_steps, num_categories)&#8288;</code> containing the
prediction, or output of the softmax.</p>
</td></tr>
<tr><td><code id="k_ctc_decode_+3A_input_length">input_length</code></td>
<td>
<p>tensor <code style="white-space: pre;">&#8288;(samples, )&#8288;</code> containing the sequence length for
each batch item in <code>y_pred</code>.</p>
</td></tr>
<tr><td><code id="k_ctc_decode_+3A_greedy">greedy</code></td>
<td>
<p>perform much faster best-path search if <code>TRUE</code>. This does not
use a dictionary.</p>
</td></tr>
<tr><td><code id="k_ctc_decode_+3A_beam_width">beam_width</code></td>
<td>
<p>if <code>greedy</code> is <code>FALSE</code>: a beam search decoder will be used
with a beam of this width.</p>
</td></tr>
<tr><td><code id="k_ctc_decode_+3A_top_paths">top_paths</code></td>
<td>
<p>if <code>greedy</code> is <code>FALSE</code>, how many of the most probable paths
will be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>greedy</code> is <code>TRUE</code>, returns a list of one element
that contains the decoded sequence. If <code>FALSE</code>, returns the <code>top_paths</code>
most probable decoded sequences. Important: blank labels are returned as
<code>-1</code>. Tensor <code>(top_paths)</code> that contains the log probability of each
decoded sequence.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_ctc_label_dense_to_sparse'>Converts CTC labels from dense to sparse.</h2><span id='topic+k_ctc_label_dense_to_sparse'></span>

<h3>Description</h3>

<p>Converts CTC labels from dense to sparse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_ctc_label_dense_to_sparse(labels, label_lengths)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_ctc_label_dense_to_sparse_+3A_labels">labels</code></td>
<td>
<p>dense CTC labels.</p>
</td></tr>
<tr><td><code id="k_ctc_label_dense_to_sparse_+3A_label_lengths">label_lengths</code></td>
<td>
<p>length of the labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sparse tensor representation of the labels.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_cumprod'>Cumulative product of the values in a tensor, alongside the specified axis.</h2><span id='topic+k_cumprod'></span>

<h3>Description</h3>

<p>Cumulative product of the values in a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_cumprod(x, axis = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_cumprod_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_cumprod_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to compute the product (axis indexes are
1-based).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of the cumulative product of values of <code>x</code> along <code>axis</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_cumsum'>Cumulative sum of the values in a tensor, alongside the specified axis.</h2><span id='topic+k_cumsum'></span>

<h3>Description</h3>

<p>Cumulative sum of the values in a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_cumsum(x, axis = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_cumsum_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_cumsum_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to compute the sum (axis indexes are
1-based).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of the cumulative sum of values of <code>x</code> along <code>axis</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_depthwise_conv2d'>Depthwise 2D convolution with separable filters.</h2><span id='topic+k_depthwise_conv2d'></span>

<h3>Description</h3>

<p>Depthwise 2D convolution with separable filters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_depthwise_conv2d(
  x,
  depthwise_kernel,
  strides = c(1, 1),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_depthwise_conv2d_+3A_x">x</code></td>
<td>
<p>input tensor</p>
</td></tr>
<tr><td><code id="k_depthwise_conv2d_+3A_depthwise_kernel">depthwise_kernel</code></td>
<td>
<p>convolution kernel for the depthwise convolution.</p>
</td></tr>
<tr><td><code id="k_depthwise_conv2d_+3A_strides">strides</code></td>
<td>
<p>strides (length 2).</p>
</td></tr>
<tr><td><code id="k_depthwise_conv2d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_depthwise_conv2d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
<tr><td><code id="k_depthwise_conv2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>vector of integers, dilation rates for the separable
convolution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_dot'>Multiplies 2 tensors (and/or variables) and returns a <em>tensor</em>.</h2><span id='topic+k_dot'></span>

<h3>Description</h3>

<p>When attempting to multiply a nD tensor
with a nD tensor, it reproduces the Theano behavior.
(e.g. <code style="white-space: pre;">&#8288;(2, 3) * (4, 3, 5) -&gt; (2, 4, 5)&#8288;</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_dot(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_dot_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_dot_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, dot product of <code>x</code> and <code>y</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_dropout'>Sets entries in <code>x</code> to zero at random, while scaling the entire tensor.</h2><span id='topic+k_dropout'></span>

<h3>Description</h3>

<p>Sets entries in <code>x</code> to zero at random, while scaling the entire tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_dropout(x, level, noise_shape = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_dropout_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="k_dropout_+3A_level">level</code></td>
<td>
<p>fraction of the entries in the tensor that will be set to 0.</p>
</td></tr>
<tr><td><code id="k_dropout_+3A_noise_shape">noise_shape</code></td>
<td>
<p>shape for randomly generated keep/drop flags, must be
broadcastable to the shape of <code>x</code></p>
</td></tr>
<tr><td><code id="k_dropout_+3A_seed">seed</code></td>
<td>
<p>random seed to ensure determinism.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_dtype'>Returns the dtype of a Keras tensor or variable, as a string.</h2><span id='topic+k_dtype'></span>

<h3>Description</h3>

<p>Returns the dtype of a Keras tensor or variable, as a string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_dtype(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_dtype_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>String, dtype of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_elu'>Exponential linear unit.</h2><span id='topic+k_elu'></span>

<h3>Description</h3>

<p>Exponential linear unit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_elu(x, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_elu_+3A_x">x</code></td>
<td>
<p>A tensor or variable to compute the activation function for.</p>
</td></tr>
<tr><td><code id="k_elu_+3A_alpha">alpha</code></td>
<td>
<p>A scalar, slope of negative section.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_epsilon'>Fuzz factor used in numeric expressions.</h2><span id='topic+k_epsilon'></span><span id='topic+k_set_epsilon'></span>

<h3>Description</h3>

<p>Fuzz factor used in numeric expressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_epsilon()

k_set_epsilon(e)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_epsilon_+3A_e">e</code></td>
<td>
<p>float. New value of epsilon.</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_equal'>Element-wise equality between two tensors.</h2><span id='topic+k_equal'></span>

<h3>Description</h3>

<p>Element-wise equality between two tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_equal(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_equal_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_equal_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_eval'>Evaluates the value of a variable.</h2><span id='topic+k_eval'></span>

<h3>Description</h3>

<p>Evaluates the value of a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_eval(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_eval_+3A_x">x</code></td>
<td>
<p>A variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R array.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_exp'>Element-wise exponential.</h2><span id='topic+k_exp'></span>

<h3>Description</h3>

<p>Element-wise exponential.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_exp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_exp_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_expand_dims'>Adds a 1-sized dimension at index <code>axis</code>.</h2><span id='topic+k_expand_dims'></span>

<h3>Description</h3>

<p>Adds a 1-sized dimension at index <code>axis</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_expand_dims(x, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_expand_dims_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_expand_dims_+3A_axis">axis</code></td>
<td>
<p>Position where to add a new axis (axis indexes are 1-based).
Pass -1 (the default) to select the last axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with expanded dimensions.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_eye'>Instantiate an identity matrix and returns it.</h2><span id='topic+k_eye'></span>

<h3>Description</h3>

<p>Instantiate an identity matrix and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_eye(size, dtype = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_eye_+3A_size">size</code></td>
<td>
<p>Integer, number of rows/columns.</p>
</td></tr>
<tr><td><code id="k_eye_+3A_dtype">dtype</code></td>
<td>
<p>String, data type of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_eye_+3A_name">name</code></td>
<td>
<p>String, name of returned Keras variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras variable, an identity matrix.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_flatten'>Flatten a tensor.</h2><span id='topic+k_flatten'></span>

<h3>Description</h3>

<p>Flatten a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_flatten(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_flatten_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, reshaped into 1-D
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_floatx'>Default float type</h2><span id='topic+k_floatx'></span><span id='topic+k_set_floatx'></span>

<h3>Description</h3>

<p>Default float type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_floatx()

k_set_floatx(floatx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_floatx_+3A_floatx">floatx</code></td>
<td>
<p>String, 'float16', 'float32', or 'float64'.</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_foldl'>Reduce elems using fn to combine them from left to right.</h2><span id='topic+k_foldl'></span>

<h3>Description</h3>

<p>Reduce elems using fn to combine them from left to right.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_foldl(fn, elems, initializer = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_foldl_+3A_fn">fn</code></td>
<td>
<p>Function that will be called upon each element in elems and an
accumulator</p>
</td></tr>
<tr><td><code id="k_foldl_+3A_elems">elems</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="k_foldl_+3A_initializer">initializer</code></td>
<td>
<p>The first value used (first element of <code>elems</code> in case of
'NULL&ldquo;)</p>
</td></tr>
<tr><td><code id="k_foldl_+3A_name">name</code></td>
<td>
<p>A string name for the foldl node in the graph</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor with same type and shape as <code>initializer</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_foldr'>Reduce elems using fn to combine them from right to left.</h2><span id='topic+k_foldr'></span>

<h3>Description</h3>

<p>Reduce elems using fn to combine them from right to left.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_foldr(fn, elems, initializer = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_foldr_+3A_fn">fn</code></td>
<td>
<p>Function that will be called upon each element in elems and an
accumulator</p>
</td></tr>
<tr><td><code id="k_foldr_+3A_elems">elems</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="k_foldr_+3A_initializer">initializer</code></td>
<td>
<p>The first value used (last element of <code>elems</code> in case of
NULL)</p>
</td></tr>
<tr><td><code id="k_foldr_+3A_name">name</code></td>
<td>
<p>A string name for the foldr node in the graph</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor with same type and shape as <code>initializer</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_function'>Instantiates a Keras function</h2><span id='topic+k_function'></span>

<h3>Description</h3>

<p>Instantiates a Keras function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_function(inputs, outputs, updates = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_function_+3A_inputs">inputs</code></td>
<td>
<p>List of placeholder tensors.</p>
</td></tr>
<tr><td><code id="k_function_+3A_outputs">outputs</code></td>
<td>
<p>List of output tensors.</p>
</td></tr>
<tr><td><code id="k_function_+3A_updates">updates</code></td>
<td>
<p>List of update ops.</p>
</td></tr>
<tr><td><code id="k_function_+3A_...">...</code></td>
<td>
<p>Named arguments passed to <code>tf$Session$run</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output values as R arrays.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_gather'>Retrieves the elements of indices <code>indices</code> in the tensor <code>reference</code>.</h2><span id='topic+k_gather'></span>

<h3>Description</h3>

<p>Retrieves the elements of indices <code>indices</code> in the tensor <code>reference</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_gather(reference, indices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_gather_+3A_reference">reference</code></td>
<td>
<p>A tensor.</p>
</td></tr>
<tr><td><code id="k_gather_+3A_indices">indices</code></td>
<td>
<p>Indices. Dimension indices are 1-based. Note however that if you pass a
tensor for <code>indices</code> they will be passed as-is, in which case indices will be 0 based
because no normalizing of R 1-based axes to Python 0-based axes is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of same type as <code>reference</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_get_session'>TF session to be used by the backend.</h2><span id='topic+k_get_session'></span><span id='topic+k_set_session'></span>

<h3>Description</h3>

<p>If a default TensorFlow session is available, we will return it. Else, we
will return the global Keras session. If no global Keras session exists at
this point: we will create a new global session. Note that you can manually
set the global session via <code>k_set_session()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_get_session()

k_set_session(session)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_get_session_+3A_session">session</code></td>
<td>
<p>A TensorFlow Session.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TensorFlow session
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_get_uid'>Get the uid for the default graph.</h2><span id='topic+k_get_uid'></span>

<h3>Description</h3>

<p>Get the uid for the default graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_get_uid(prefix = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_get_uid_+3A_prefix">prefix</code></td>
<td>
<p>An optional prefix of the graph.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A unique identifier for the graph.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_get_value'>Returns the value of a variable.</h2><span id='topic+k_get_value'></span>

<h3>Description</h3>

<p>Returns the value of a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_get_value(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_get_value_+3A_x">x</code></td>
<td>
<p>input variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R array.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_get_variable_shape'>Returns the shape of a variable.</h2><span id='topic+k_get_variable_shape'></span>

<h3>Description</h3>

<p>Returns the shape of a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_get_variable_shape(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_get_variable_shape_+3A_x">x</code></td>
<td>
<p>A variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of integers.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_gradients'>Returns the gradients of <code>variables</code> w.r.t. <code>loss</code>.</h2><span id='topic+k_gradients'></span>

<h3>Description</h3>

<p>Returns the gradients of <code>variables</code> w.r.t. <code>loss</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_gradients(loss, variables)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_gradients_+3A_loss">loss</code></td>
<td>
<p>Scalar tensor to minimize.</p>
</td></tr>
<tr><td><code id="k_gradients_+3A_variables">variables</code></td>
<td>
<p>List of variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A gradients tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_greater'>Element-wise truth value of (x &gt; y).</h2><span id='topic+k_greater'></span>

<h3>Description</h3>

<p>Element-wise truth value of (x &gt; y).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_greater(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_greater_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_greater_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_greater_equal'>Element-wise truth value of (x &gt;= y).</h2><span id='topic+k_greater_equal'></span>

<h3>Description</h3>

<p>Element-wise truth value of (x &gt;= y).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_greater_equal(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_greater_equal_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_greater_equal_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_hard_sigmoid'>Segment-wise linear approximation of sigmoid.</h2><span id='topic+k_hard_sigmoid'></span>

<h3>Description</h3>

<p>Faster than sigmoid.
Returns <code>0.</code> if <code>x &lt; -2.5</code>, <code>1.</code> if <code>x &gt; 2.5</code>.
In <code style="white-space: pre;">&#8288;-2.5 &lt;= x &lt;= 2.5&#8288;</code>, returns <code>0.2 * x + 0.5</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_hard_sigmoid(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_hard_sigmoid_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_identity'>Returns a tensor with the same content as the input tensor.</h2><span id='topic+k_identity'></span>

<h3>Description</h3>

<p>Returns a tensor with the same content as the input tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_identity(x, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_identity_+3A_x">x</code></td>
<td>
<p>The input tensor.</p>
</td></tr>
<tr><td><code id="k_identity_+3A_name">name</code></td>
<td>
<p>String, name for the variable to create.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of the same shape, type and content.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_image_data_format'>Default image data format convention ('channels_first' or 'channels_last').</h2><span id='topic+k_image_data_format'></span><span id='topic+k_set_image_data_format'></span>

<h3>Description</h3>

<p>Default image data format convention ('channels_first' or 'channels_last').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_image_data_format()

k_set_image_data_format(data_format)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_image_data_format_+3A_data_format">data_format</code></td>
<td>
<p>string. <code>'channels_first'</code> or <code>'channels_last'</code>.</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_in_test_phase'>Selects <code>x</code> in test phase, and <code>alt</code> otherwise.</h2><span id='topic+k_in_test_phase'></span>

<h3>Description</h3>

<p>Note that <code>alt</code> should have the <em>same shape</em> as <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_in_test_phase(x, alt, training = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_in_test_phase_+3A_x">x</code></td>
<td>
<p>What to return in test phase (tensor or function that returns a
tensor).</p>
</td></tr>
<tr><td><code id="k_in_test_phase_+3A_alt">alt</code></td>
<td>
<p>What to return otherwise (tensor or function that returns a
tensor).</p>
</td></tr>
<tr><td><code id="k_in_test_phase_+3A_training">training</code></td>
<td>
<p>Optional scalar tensor (or R logical or integer) specifying
the learning phase.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>x</code> or <code>alt</code> based on <code>k_learning_phase()</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_in_top_k'>Returns whether the <code>targets</code> are in the top <code>k</code> <code>predictions</code>.</h2><span id='topic+k_in_top_k'></span>

<h3>Description</h3>

<p>Returns whether the <code>targets</code> are in the top <code>k</code> <code>predictions</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_in_top_k(predictions, targets, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_in_top_k_+3A_predictions">predictions</code></td>
<td>
<p>A tensor of shape <code style="white-space: pre;">&#8288;(batch_size, classes)&#8288;</code> and type
<code>float32</code>.</p>
</td></tr>
<tr><td><code id="k_in_top_k_+3A_targets">targets</code></td>
<td>
<p>A 1D tensor of length <code>batch_size</code> and type <code>int32</code> or
<code>int64</code>.</p>
</td></tr>
<tr><td><code id="k_in_top_k_+3A_k">k</code></td>
<td>
<p>An <code>int</code>, number of top elements to consider.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1D tensor of length <code>batch_size</code> and type <code>bool</code>. <code>output[[i]]</code> is
<code>TRUE</code> if <code style="white-space: pre;">&#8288;predictions[i, targets[[i]]&#8288;</code> is within top-<code>k</code> values of
<code>predictions[[i]]</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_in_train_phase'>Selects <code>x</code> in train phase, and <code>alt</code> otherwise.</h2><span id='topic+k_in_train_phase'></span>

<h3>Description</h3>

<p>Note that <code>alt</code> should have the <em>same shape</em> as <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_in_train_phase(x, alt, training = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_in_train_phase_+3A_x">x</code></td>
<td>
<p>What to return in train phase (tensor or function that returns a
tensor).</p>
</td></tr>
<tr><td><code id="k_in_train_phase_+3A_alt">alt</code></td>
<td>
<p>What to return otherwise (tensor or function that returns a
tensor).</p>
</td></tr>
<tr><td><code id="k_in_train_phase_+3A_training">training</code></td>
<td>
<p>Optional scalar tensor (or R logical or integer) specifying
the learning phase.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>x</code> or <code>alt</code> based on the <code>training</code> flag. the <code>training</code>
flag defaults to <code>k_learning_phase()</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_int_shape'>Returns the shape of tensor or variable as a list of int or NULL entries.</h2><span id='topic+k_int_shape'></span>

<h3>Description</h3>

<p>Returns the shape of tensor or variable as a list of int or NULL entries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_int_shape(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_int_shape_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of integers (or NULL entries).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_is_keras_tensor'>Returns whether <code>x</code> is a Keras tensor.</h2><span id='topic+k_is_keras_tensor'></span>

<h3>Description</h3>

<p>A &quot;Keras tensor&quot; is a tensor that was returned by a Keras layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_is_keras_tensor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_is_keras_tensor_+3A_x">x</code></td>
<td>
<p>A candidate tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical: Whether the argument is a Keras tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_is_placeholder'>Returns whether <code>x</code> is a placeholder.</h2><span id='topic+k_is_placeholder'></span>

<h3>Description</h3>

<p>Returns whether <code>x</code> is a placeholder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_is_placeholder(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_is_placeholder_+3A_x">x</code></td>
<td>
<p>A candidate placeholder.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_is_sparse'>Returns whether a tensor is a sparse tensor.</h2><span id='topic+k_is_sparse'></span>

<h3>Description</h3>

<p>Returns whether a tensor is a sparse tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_is_sparse(tensor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_is_sparse_+3A_tensor">tensor</code></td>
<td>
<p>A tensor instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_is_tensor'>Returns whether <code>x</code> is a symbolic tensor.</h2><span id='topic+k_is_tensor'></span>

<h3>Description</h3>

<p>Returns whether <code>x</code> is a symbolic tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_is_tensor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_is_tensor_+3A_x">x</code></td>
<td>
<p>A candidate tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical: Whether the argument is a symbolic tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_l2_normalize'>Normalizes a tensor wrt the L2 norm alongside the specified axis.</h2><span id='topic+k_l2_normalize'></span>

<h3>Description</h3>

<p>Normalizes a tensor wrt the L2 norm alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_l2_normalize(x, axis = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_l2_normalize_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_l2_normalize_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform normalization (axis indexes
are 1-based)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_learning_phase'>Returns the learning phase flag.</h2><span id='topic+k_learning_phase'></span>

<h3>Description</h3>

<p>The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed
as input to any Keras function that uses a different behavior at train time
and test time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_learning_phase()
</code></pre>


<h3>Value</h3>

<p>Learning phase (scalar integer tensor or R integer).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_less'>Element-wise truth value of (x &lt; y).</h2><span id='topic+k_less'></span>

<h3>Description</h3>

<p>Element-wise truth value of (x &lt; y).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_less(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_less_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_less_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_less_equal'>Element-wise truth value of (x &lt;= y).</h2><span id='topic+k_less_equal'></span>

<h3>Description</h3>

<p>Element-wise truth value of (x &lt;= y).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_less_equal(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_less_equal_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_less_equal_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_local_conv1d'>Apply 1D conv with un-shared weights.</h2><span id='topic+k_local_conv1d'></span>

<h3>Description</h3>

<p>Apply 1D conv with un-shared weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_local_conv1d(inputs, kernel, kernel_size, strides, data_format = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_local_conv1d_+3A_inputs">inputs</code></td>
<td>
<p>3D tensor with shape: (batch_size, steps, input_dim)</p>
</td></tr>
<tr><td><code id="k_local_conv1d_+3A_kernel">kernel</code></td>
<td>
<p>the unshared weight for convolution, with shape
(output_length, feature_dim, filters)</p>
</td></tr>
<tr><td><code id="k_local_conv1d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>a list of a single integer, specifying the length of the
1D convolution window</p>
</td></tr>
<tr><td><code id="k_local_conv1d_+3A_strides">strides</code></td>
<td>
<p>a list of a single integer, specifying the stride length of
the convolution</p>
</td></tr>
<tr><td><code id="k_local_conv1d_+3A_data_format">data_format</code></td>
<td>
<p>the data format, channels_first or channels_last</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the tensor after 1d conv with un-shared weights, with shape
(batch_size, output_length, filters)
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_local_conv2d'>Apply 2D conv with un-shared weights.</h2><span id='topic+k_local_conv2d'></span>

<h3>Description</h3>

<p>Apply 2D conv with un-shared weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_local_conv2d(
  inputs,
  kernel,
  kernel_size,
  strides,
  output_shape,
  data_format = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_local_conv2d_+3A_inputs">inputs</code></td>
<td>
<p>4D tensor with shape: (batch_size, filters, new_rows,
new_cols) if data_format='channels_first' or 4D tensor with shape:
(batch_size, new_rows, new_cols, filters) if data_format='channels_last'.</p>
</td></tr>
<tr><td><code id="k_local_conv2d_+3A_kernel">kernel</code></td>
<td>
<p>the unshared weight for convolution, with shape (output_items,
feature_dim, filters)</p>
</td></tr>
<tr><td><code id="k_local_conv2d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>a list of 2 integers, specifying the width and height of
the 2D convolution window.</p>
</td></tr>
<tr><td><code id="k_local_conv2d_+3A_strides">strides</code></td>
<td>
<p>a list of 2 integers, specifying the strides of the
convolution along the width and height.</p>
</td></tr>
<tr><td><code id="k_local_conv2d_+3A_output_shape">output_shape</code></td>
<td>
<p>a list with (output_row, output_col)</p>
</td></tr>
<tr><td><code id="k_local_conv2d_+3A_data_format">data_format</code></td>
<td>
<p>the data format, channels_first or channels_last</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 4d tensor with shape: (batch_size, filters, new_rows, new_cols) if
data_format='channels_first' or 4D tensor with shape: (batch_size,
new_rows, new_cols, filters) if data_format='channels_last'.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_log'>Element-wise log.</h2><span id='topic+k_log'></span>

<h3>Description</h3>

<p>Element-wise log.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_log(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_log_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_logsumexp'>(Deprecated) Computes log(sum(exp(elements across dimensions of a tensor))).</h2><span id='topic+k_logsumexp'></span>

<h3>Description</h3>

<p>This funciton is deprecated. Please use <code>tensorflow::tf$reduce_logsumexp()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_logsumexp(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_logsumexp_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_logsumexp_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to reduce over (axis indexes are 1-based).</p>
</td></tr>
<tr><td><code id="k_logsumexp_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is more numerically stable than log(sum(exp(x))). It avoids
overflows caused by taking the exp of large inputs and underflows caused by
taking the log of small inputs.
</p>


<h3>Value</h3>

<p>The reduced tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_manual_variable_initialization'>Sets the manual variable initialization flag.</h2><span id='topic+k_manual_variable_initialization'></span>

<h3>Description</h3>

<p>This boolean flag determines whether variables should be initialized as they
are instantiated (default), or if the user should handle the initialization
(e.g. via <code>tf$initialize_all_variables()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_manual_variable_initialization(value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_manual_variable_initialization_+3A_value">value</code></td>
<td>
<p>Logical</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_map_fn'>Map the function fn over the elements elems and return the outputs.</h2><span id='topic+k_map_fn'></span>

<h3>Description</h3>

<p>Map the function fn over the elements elems and return the outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_map_fn(fn, elems, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_map_fn_+3A_fn">fn</code></td>
<td>
<p>Function that will be called upon each element in elems</p>
</td></tr>
<tr><td><code id="k_map_fn_+3A_elems">elems</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="k_map_fn_+3A_name">name</code></td>
<td>
<p>A string name for the map node in the graph</p>
</td></tr>
<tr><td><code id="k_map_fn_+3A_dtype">dtype</code></td>
<td>
<p>Output data type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor with dtype <code>dtype</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_max'>Maximum value in a tensor.</h2><span id='topic+k_max'></span>

<h3>Description</h3>

<p>Maximum value in a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_max(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_max_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_max_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to find maximum values (axis indexes are
1-based).</p>
</td></tr>
<tr><td><code id="k_max_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with maximum values of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_maximum'>Element-wise maximum of two tensors.</h2><span id='topic+k_maximum'></span>

<h3>Description</h3>

<p>Element-wise maximum of two tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_maximum(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_maximum_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_maximum_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_mean'>Mean of a tensor, alongside the specified axis.</h2><span id='topic+k_mean'></span>

<h3>Description</h3>

<p>Mean of a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_mean(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_mean_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_mean_+3A_axis">axis</code></td>
<td>
<p>A list of axes to compute the mean over (axis indexes are
1-based).</p>
</td></tr>
<tr><td><code id="k_mean_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1 for each
entry in <code>axis</code>. If <code>keep_dims</code> is <code>TRUE</code>, the reduced dimensions are
retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with the mean of elements of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_min'>Minimum value in a tensor.</h2><span id='topic+k_min'></span>

<h3>Description</h3>

<p>Minimum value in a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_min(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_min_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_min_+3A_axis">axis</code></td>
<td>
<p>An integer, axis to find minimum values (axis indexes are
1-based).</p>
</td></tr>
<tr><td><code id="k_min_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with miminum values of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_minimum'>Element-wise minimum of two tensors.</h2><span id='topic+k_minimum'></span>

<h3>Description</h3>

<p>Element-wise minimum of two tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_minimum(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_minimum_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_minimum_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_moving_average_update'>Compute the moving average of a variable.</h2><span id='topic+k_moving_average_update'></span>

<h3>Description</h3>

<p>Compute the moving average of a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_moving_average_update(x, value, momentum)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_moving_average_update_+3A_x">x</code></td>
<td>
<p>A <code>Variable</code>.</p>
</td></tr>
<tr><td><code id="k_moving_average_update_+3A_value">value</code></td>
<td>
<p>A tensor with the same shape as <code>x</code>.</p>
</td></tr>
<tr><td><code id="k_moving_average_update_+3A_momentum">momentum</code></td>
<td>
<p>The moving average momentum.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An operation to update the variable.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_ndim'>Returns the number of axes in a tensor, as an integer.</h2><span id='topic+k_ndim'></span>

<h3>Description</h3>

<p>Returns the number of axes in a tensor, as an integer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_ndim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_ndim_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integer (scalar), number of axes.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_normalize_batch_in_training'>Computes mean and std for batch then apply batch_normalization on batch.</h2><span id='topic+k_normalize_batch_in_training'></span>

<h3>Description</h3>

<p>Computes mean and std for batch then apply batch_normalization on batch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_normalize_batch_in_training_+3A_x">x</code></td>
<td>
<p>Input tensor or variable.</p>
</td></tr>
<tr><td><code id="k_normalize_batch_in_training_+3A_gamma">gamma</code></td>
<td>
<p>Tensor by which to scale the input.</p>
</td></tr>
<tr><td><code id="k_normalize_batch_in_training_+3A_beta">beta</code></td>
<td>
<p>Tensor with which to center the input.</p>
</td></tr>
<tr><td><code id="k_normalize_batch_in_training_+3A_reduction_axes">reduction_axes</code></td>
<td>
<p>iterable of integers, axes over which to normalize.</p>
</td></tr>
<tr><td><code id="k_normalize_batch_in_training_+3A_epsilon">epsilon</code></td>
<td>
<p>Fuzz factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list length of 3, <code style="white-space: pre;">&#8288;(normalized_tensor, mean, variance)&#8288;</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_not_equal'>Element-wise inequality between two tensors.</h2><span id='topic+k_not_equal'></span>

<h3>Description</h3>

<p>Element-wise inequality between two tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_not_equal(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_not_equal_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_not_equal_+3A_y">y</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_one_hot'>Computes the one-hot representation of an integer tensor.</h2><span id='topic+k_one_hot'></span>

<h3>Description</h3>

<p>Computes the one-hot representation of an integer tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_one_hot(indices, num_classes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_one_hot_+3A_indices">indices</code></td>
<td>
<p>nD integer tensor of shape <code style="white-space: pre;">&#8288;(batch_size, dim1, dim2, ... dim(n-1))&#8288;</code></p>
</td></tr>
<tr><td><code id="k_one_hot_+3A_num_classes">num_classes</code></td>
<td>
<p>Integer, number of classes to consider.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(n + 1)D one hot representation of the input with shape
<code style="white-space: pre;">&#8288;(batch_size, dim1, dim2, ... dim(n-1), num_classes)&#8288;</code>
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_ones'>Instantiates an all-ones tensor variable and returns it.</h2><span id='topic+k_ones'></span>

<h3>Description</h3>

<p>Instantiates an all-ones tensor variable and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_ones(shape, dtype = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_ones_+3A_shape">shape</code></td>
<td>
<p>Tuple of integers, shape of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_ones_+3A_dtype">dtype</code></td>
<td>
<p>String, data type of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_ones_+3A_name">name</code></td>
<td>
<p>String, name of returned Keras variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras variable, filled with <code>1.0</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_ones_like'>Instantiates an all-ones variable of the same shape as another tensor.</h2><span id='topic+k_ones_like'></span>

<h3>Description</h3>

<p>Instantiates an all-ones variable of the same shape as another tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_ones_like(x, dtype = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_ones_like_+3A_x">x</code></td>
<td>
<p>Keras variable or tensor.</p>
</td></tr>
<tr><td><code id="k_ones_like_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned Keras variable. NULL uses the dtype
of x.</p>
</td></tr>
<tr><td><code id="k_ones_like_+3A_name">name</code></td>
<td>
<p>String, name for the variable to create.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras variable with the shape of x filled with ones.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_permute_dimensions'>Permutes axes in a tensor.</h2><span id='topic+k_permute_dimensions'></span>

<h3>Description</h3>

<p>Permutes axes in a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_permute_dimensions(x, pattern)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_permute_dimensions_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_permute_dimensions_+3A_pattern">pattern</code></td>
<td>
<p>A list of dimension indices, e.g. <code style="white-space: pre;">&#8288;(1, 3, 2)&#8288;</code>. Dimension
indices are 1-based.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_placeholder'>Instantiates a placeholder tensor and returns it.</h2><span id='topic+k_placeholder'></span>

<h3>Description</h3>

<p>Instantiates a placeholder tensor and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_placeholder(
  shape = NULL,
  ndim = NULL,
  dtype = NULL,
  sparse = FALSE,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_placeholder_+3A_shape">shape</code></td>
<td>
<p>Shape of the placeholder (integer list, may include <code>NULL</code>
entries).</p>
</td></tr>
<tr><td><code id="k_placeholder_+3A_ndim">ndim</code></td>
<td>
<p>Number of axes of the tensor. At least one of <code>shape</code> or <code>ndim</code>
must be specified. If both are specified, <code>shape</code> is used.</p>
</td></tr>
<tr><td><code id="k_placeholder_+3A_dtype">dtype</code></td>
<td>
<p>Placeholder type.</p>
</td></tr>
<tr><td><code id="k_placeholder_+3A_sparse">sparse</code></td>
<td>
<p>Logical, whether the placeholder should have a sparse type.</p>
</td></tr>
<tr><td><code id="k_placeholder_+3A_name">name</code></td>
<td>
<p>Optional name string for the placeholder.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor instance (with Keras metadata included).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_pool2d'>2D Pooling.</h2><span id='topic+k_pool2d'></span>

<h3>Description</h3>

<p>2D Pooling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_pool2d(
  x,
  pool_size,
  strides = c(1, 1),
  padding = "valid",
  data_format = NULL,
  pool_mode = "max"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_pool2d_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_pool2d_+3A_pool_size">pool_size</code></td>
<td>
<p>list of 2 integers.</p>
</td></tr>
<tr><td><code id="k_pool2d_+3A_strides">strides</code></td>
<td>
<p>list of 2 integers.</p>
</td></tr>
<tr><td><code id="k_pool2d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_pool2d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
<tr><td><code id="k_pool2d_+3A_pool_mode">pool_mode</code></td>
<td>
<p>string, <code>"max"</code> or <code>"avg"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of 2D pooling.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_pool3d'>3D Pooling.</h2><span id='topic+k_pool3d'></span>

<h3>Description</h3>

<p>3D Pooling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_pool3d(
  x,
  pool_size,
  strides = c(1, 1, 1),
  padding = "valid",
  data_format = NULL,
  pool_mode = "max"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_pool3d_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_pool3d_+3A_pool_size">pool_size</code></td>
<td>
<p>list of 3 integers.</p>
</td></tr>
<tr><td><code id="k_pool3d_+3A_strides">strides</code></td>
<td>
<p>list of 3 integers.</p>
</td></tr>
<tr><td><code id="k_pool3d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_pool3d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
<tr><td><code id="k_pool3d_+3A_pool_mode">pool_mode</code></td>
<td>
<p>string, <code>"max"</code> or <code>"avg"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, result of 3D pooling.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_pow'>Element-wise exponentiation.</h2><span id='topic+k_pow'></span>

<h3>Description</h3>

<p>Element-wise exponentiation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_pow(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_pow_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_pow_+3A_a">a</code></td>
<td>
<p>R integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_print_tensor'>Prints <code>message</code> and the tensor value when evaluated.</h2><span id='topic+k_print_tensor'></span>

<h3>Description</h3>

<p>Note that <code>print_tensor</code> returns a new tensor identical to <code>x</code> which should
be used in the following code. Otherwise the print operation is not taken
into account during evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_print_tensor(x, message = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_print_tensor_+3A_x">x</code></td>
<td>
<p>Tensor to print.</p>
</td></tr>
<tr><td><code id="k_print_tensor_+3A_message">message</code></td>
<td>
<p>Message to print jointly with the tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same tensor <code>x</code>, unchanged.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_prod'>Multiplies the values in a tensor, alongside the specified axis.</h2><span id='topic+k_prod'></span>

<h3>Description</h3>

<p>Multiplies the values in a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_prod(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_prod_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_prod_+3A_axis">axis</code></td>
<td>
<p>An integer, axis to compute the product over (axis indexes are
1-based).</p>
</td></tr>
<tr><td><code id="k_prod_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with the product of elements of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_random_binomial'>Returns a tensor with random binomial distribution of values.</h2><span id='topic+k_random_binomial'></span><span id='topic+k_random_bernoulli'></span>

<h3>Description</h3>

<p><code>k_random_binomial()</code> and <code>k_random_bernoulli()</code> are aliases for the same
function. Both are maintained for backwards compatibility. New code
should prefer <code>k_random_bernoulli()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_random_binomial(shape, p = 0, dtype = NULL, seed = NULL)

k_random_bernoulli(shape, p = 0, dtype = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_random_binomial_+3A_shape">shape</code></td>
<td>
<p>A list of integers, the shape of tensor to create.</p>
</td></tr>
<tr><td><code id="k_random_binomial_+3A_p">p</code></td>
<td>
<p>A float, <code style="white-space: pre;">&#8288;0. &lt;= p &lt;= 1&#8288;</code>, probability of binomial distribution.</p>
</td></tr>
<tr><td><code id="k_random_binomial_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned tensor.</p>
</td></tr>
<tr><td><code id="k_random_binomial_+3A_seed">seed</code></td>
<td>
<p>Integer, random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_random_normal'>Returns a tensor with normal distribution of values.</h2><span id='topic+k_random_normal'></span>

<h3>Description</h3>

<p>Returns a tensor with normal distribution of values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_random_normal(shape, mean = 0, stddev = 1, dtype = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_random_normal_+3A_shape">shape</code></td>
<td>
<p>A list of integers, the shape of tensor to create.</p>
</td></tr>
<tr><td><code id="k_random_normal_+3A_mean">mean</code></td>
<td>
<p>A float, mean of the normal distribution to draw samples.</p>
</td></tr>
<tr><td><code id="k_random_normal_+3A_stddev">stddev</code></td>
<td>
<p>A float, standard deviation of the normal distribution to draw
samples.</p>
</td></tr>
<tr><td><code id="k_random_normal_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned tensor.</p>
</td></tr>
<tr><td><code id="k_random_normal_+3A_seed">seed</code></td>
<td>
<p>Integer, random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_random_normal_variable'>Instantiates a variable with values drawn from a normal distribution.</h2><span id='topic+k_random_normal_variable'></span>

<h3>Description</h3>

<p>Instantiates a variable with values drawn from a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_random_normal_variable(
  shape,
  mean,
  scale,
  dtype = NULL,
  name = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_random_normal_variable_+3A_shape">shape</code></td>
<td>
<p>Tuple of integers, shape of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_random_normal_variable_+3A_mean">mean</code></td>
<td>
<p>Float, mean of the normal distribution.</p>
</td></tr>
<tr><td><code id="k_random_normal_variable_+3A_scale">scale</code></td>
<td>
<p>Float, standard deviation of the normal distribution.</p>
</td></tr>
<tr><td><code id="k_random_normal_variable_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_random_normal_variable_+3A_name">name</code></td>
<td>
<p>String, name of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_random_normal_variable_+3A_seed">seed</code></td>
<td>
<p>Integer, random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras variable, filled with drawn samples.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_random_uniform'>Returns a tensor with uniform distribution of values.</h2><span id='topic+k_random_uniform'></span>

<h3>Description</h3>

<p>Returns a tensor with uniform distribution of values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_random_uniform(shape, minval = 0, maxval = 1, dtype = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_random_uniform_+3A_shape">shape</code></td>
<td>
<p>A list of integers, the shape of tensor to create.</p>
</td></tr>
<tr><td><code id="k_random_uniform_+3A_minval">minval</code></td>
<td>
<p>A float, lower boundary of the uniform distribution to draw samples.</p>
</td></tr>
<tr><td><code id="k_random_uniform_+3A_maxval">maxval</code></td>
<td>
<p>A float, upper boundary of the uniform distribution to draw samples.</p>
</td></tr>
<tr><td><code id="k_random_uniform_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned tensor.</p>
</td></tr>
<tr><td><code id="k_random_uniform_+3A_seed">seed</code></td>
<td>
<p>Integer, random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_random_uniform_variable'>Instantiates a variable with values drawn from a uniform distribution.</h2><span id='topic+k_random_uniform_variable'></span>

<h3>Description</h3>

<p>Instantiates a variable with values drawn from a uniform distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_random_uniform_variable(
  shape,
  low,
  high,
  dtype = NULL,
  name = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_random_uniform_variable_+3A_shape">shape</code></td>
<td>
<p>Tuple of integers, shape of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_random_uniform_variable_+3A_low">low</code></td>
<td>
<p>Float, lower boundary of the output interval.</p>
</td></tr>
<tr><td><code id="k_random_uniform_variable_+3A_high">high</code></td>
<td>
<p>Float, upper boundary of the output interval.</p>
</td></tr>
<tr><td><code id="k_random_uniform_variable_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_random_uniform_variable_+3A_name">name</code></td>
<td>
<p>String, name of returned Keras variable.</p>
</td></tr>
<tr><td><code id="k_random_uniform_variable_+3A_seed">seed</code></td>
<td>
<p>Integer, random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras variable, filled with drawn samples.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_relu'>Rectified linear unit.</h2><span id='topic+k_relu'></span>

<h3>Description</h3>

<p>With default values, it returns element-wise <code>max(x, 0)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_relu(x, alpha = 0, max_value = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_relu_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_relu_+3A_alpha">alpha</code></td>
<td>
<p>A scalar, slope of negative section (default=<code>0.</code>).</p>
</td></tr>
<tr><td><code id="k_relu_+3A_max_value">max_value</code></td>
<td>
<p>Saturation threshold.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_repeat'>Repeats a 2D tensor.</h2><span id='topic+k_repeat'></span>

<h3>Description</h3>

<p>If x has shape (samples, dim) and n is 2, the output will have shape
(samples, 2, dim).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_repeat(x, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_repeat_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_repeat_+3A_n">n</code></td>
<td>
<p>Integer, number of times to repeat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_repeat_elements'>Repeats the elements of a tensor along an axis.</h2><span id='topic+k_repeat_elements'></span>

<h3>Description</h3>

<p>If <code>x</code> has shape <code style="white-space: pre;">&#8288;(s1, s2, s3)&#8288;</code> and <code>axis</code> is <code>2</code>, the output
will have shape <code style="white-space: pre;">&#8288;(s1, s2 * rep, s3)&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_repeat_elements(x, rep, axis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_repeat_elements_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_repeat_elements_+3A_rep">rep</code></td>
<td>
<p>Integer, number of times to repeat.</p>
</td></tr>
<tr><td><code id="k_repeat_elements_+3A_axis">axis</code></td>
<td>
<p>Axis along which to repeat (axis indexes are 1-based)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_reset_uids'>Reset graph identifiers.</h2><span id='topic+k_reset_uids'></span>

<h3>Description</h3>

<p>Reset graph identifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_reset_uids()
</code></pre>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_reshape'>Reshapes a tensor to the specified shape.</h2><span id='topic+k_reshape'></span>

<h3>Description</h3>

<p>Reshapes a tensor to the specified shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_reshape(x, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_reshape_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_reshape_+3A_shape">shape</code></td>
<td>
<p>Target shape list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_resize_images'>Resizes the images contained in a 4D tensor.</h2><span id='topic+k_resize_images'></span>

<h3>Description</h3>

<p>Resizes the images contained in a 4D tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_resize_images(x, height_factor, width_factor, data_format)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_resize_images_+3A_x">x</code></td>
<td>
<p>Tensor or variable to resize.</p>
</td></tr>
<tr><td><code id="k_resize_images_+3A_height_factor">height_factor</code></td>
<td>
<p>Positive integer.</p>
</td></tr>
<tr><td><code id="k_resize_images_+3A_width_factor">width_factor</code></td>
<td>
<p>Positive integer.</p>
</td></tr>
<tr><td><code id="k_resize_images_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_resize_volumes'>Resizes the volume contained in a 5D tensor.</h2><span id='topic+k_resize_volumes'></span>

<h3>Description</h3>

<p>Resizes the volume contained in a 5D tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_resize_volumes(x, depth_factor, height_factor, width_factor, data_format)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_resize_volumes_+3A_x">x</code></td>
<td>
<p>Tensor or variable to resize.</p>
</td></tr>
<tr><td><code id="k_resize_volumes_+3A_depth_factor">depth_factor</code></td>
<td>
<p>Positive integer.</p>
</td></tr>
<tr><td><code id="k_resize_volumes_+3A_height_factor">height_factor</code></td>
<td>
<p>Positive integer.</p>
</td></tr>
<tr><td><code id="k_resize_volumes_+3A_width_factor">width_factor</code></td>
<td>
<p>Positive integer.</p>
</td></tr>
<tr><td><code id="k_resize_volumes_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_reverse'>Reverse a tensor along the specified axes.</h2><span id='topic+k_reverse'></span>

<h3>Description</h3>

<p>Reverse a tensor along the specified axes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_reverse(x, axes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_reverse_+3A_x">x</code></td>
<td>
<p>Tensor to reverse.</p>
</td></tr>
<tr><td><code id="k_reverse_+3A_axes">axes</code></td>
<td>
<p>Integer or list of integers of axes to reverse (axis indexes are
1-based).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_rnn'>Iterates over the time dimension of a tensor</h2><span id='topic+k_rnn'></span>

<h3>Description</h3>

<p>Iterates over the time dimension of a tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_rnn(
  step_function,
  inputs,
  initial_states,
  go_backwards = FALSE,
  mask = NULL,
  constants = NULL,
  unroll = FALSE,
  input_length = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_rnn_+3A_step_function">step_function</code></td>
<td>
<p>RNN step function.</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_inputs">inputs</code></td>
<td>
<p>Tensor with shape (samples, ...) (no time dimension),
representing input for the batch of samples at a certain time step.</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_initial_states">initial_states</code></td>
<td>
<p>Tensor with shape (samples, output_dim) (no time
dimension), containing the initial values for the states used in the step
function.</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Logical If <code>TRUE</code>, do the iteration over the time
dimension in reverse order and return the reversed sequence.</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_mask">mask</code></td>
<td>
<p>Binary tensor with shape (samples, time, 1), with a zero for
every element that is masked.</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_constants">constants</code></td>
<td>
<p>A list of constant values passed at each step.</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_unroll">unroll</code></td>
<td>
<p>Whether to unroll the RNN or to use a symbolic loop
(while_loop or scan depending on backend).</p>
</td></tr>
<tr><td><code id="k_rnn_+3A_input_length">input_length</code></td>
<td>
<p>Not relevant in the TensorFlow implementation. Must be
specified if using unrolling with Theano.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with:
</p>

<ul>
<li> <p><code>last_output</code>: the latest output of the rnn, of shape (samples, ...)
</p>
</li>
<li> <p><code>outputs</code>: tensor with shape (samples, time, ...) where each entry
<code>outputs[s, t]</code> is the output of the step function at time t for sample s.
</p>
</li>
<li> <p><code>new_states</code>: list of tensors, latest states returned by the step
function, of shape (samples, ...).
</p>
</li></ul>



<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_round'>Element-wise rounding to the closest integer.</h2><span id='topic+k_round'></span>

<h3>Description</h3>

<p>In case of tie, the rounding mode used is &quot;half to even&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_round(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_round_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_separable_conv2d'>2D convolution with separable filters.</h2><span id='topic+k_separable_conv2d'></span>

<h3>Description</h3>

<p>2D convolution with separable filters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_separable_conv2d(
  x,
  depthwise_kernel,
  pointwise_kernel,
  strides = c(1, 1),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_separable_conv2d_+3A_x">x</code></td>
<td>
<p>input tensor</p>
</td></tr>
<tr><td><code id="k_separable_conv2d_+3A_depthwise_kernel">depthwise_kernel</code></td>
<td>
<p>convolution kernel for the depthwise convolution.</p>
</td></tr>
<tr><td><code id="k_separable_conv2d_+3A_pointwise_kernel">pointwise_kernel</code></td>
<td>
<p>kernel for the 1x1 convolution.</p>
</td></tr>
<tr><td><code id="k_separable_conv2d_+3A_strides">strides</code></td>
<td>
<p>strides list (length 2).</p>
</td></tr>
<tr><td><code id="k_separable_conv2d_+3A_padding">padding</code></td>
<td>
<p>string, <code>"same"</code> or <code>"valid"</code>.</p>
</td></tr>
<tr><td><code id="k_separable_conv2d_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
<tr><td><code id="k_separable_conv2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>list of integers, dilation rates for the separable convolution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_set_learning_phase'>Sets the learning phase to a fixed value.</h2><span id='topic+k_set_learning_phase'></span>

<h3>Description</h3>

<p>Sets the learning phase to a fixed value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_set_learning_phase(value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_set_learning_phase_+3A_value">value</code></td>
<td>
<p>Learning phase value, either 0 or 1 (integers).</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_set_value'>Sets the value of a variable, from an R array.</h2><span id='topic+k_set_value'></span>

<h3>Description</h3>

<p>Sets the value of a variable, from an R array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_set_value(x, value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_set_value_+3A_x">x</code></td>
<td>
<p>Tensor to set to a new value.</p>
</td></tr>
<tr><td><code id="k_set_value_+3A_value">value</code></td>
<td>
<p>Value to set the tensor to, as an R array (of the same shape).</p>
</td></tr>
</table>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_shape'>Returns the symbolic shape of a tensor or variable.</h2><span id='topic+k_shape'></span>

<h3>Description</h3>

<p>Returns the symbolic shape of a tensor or variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_shape(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_shape_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A symbolic shape (which is itself a tensor).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_sigmoid'>Element-wise sigmoid.</h2><span id='topic+k_sigmoid'></span>

<h3>Description</h3>

<p>Element-wise sigmoid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_sigmoid(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_sigmoid_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_sign'>Element-wise sign.</h2><span id='topic+k_sign'></span>

<h3>Description</h3>

<p>Element-wise sign.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_sign(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_sign_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_sin'>Computes sin of x element-wise.</h2><span id='topic+k_sin'></span>

<h3>Description</h3>

<p>Computes sin of x element-wise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_sin(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_sin_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_softmax'>Softmax of a tensor.</h2><span id='topic+k_softmax'></span>

<h3>Description</h3>

<p>Softmax of a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_softmax(x, axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_softmax_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_softmax_+3A_axis">axis</code></td>
<td>
<p>The dimension softmax would be performed on.
The default is -1 which indicates the last dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_softplus'>Softplus of a tensor.</h2><span id='topic+k_softplus'></span>

<h3>Description</h3>

<p>Softplus of a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_softplus(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_softplus_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_softsign'>Softsign of a tensor.</h2><span id='topic+k_softsign'></span>

<h3>Description</h3>

<p>Softsign of a tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_softsign(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_softsign_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_sparse_categorical_crossentropy'>Categorical crossentropy with integer targets.</h2><span id='topic+k_sparse_categorical_crossentropy'></span>

<h3>Description</h3>

<p>Categorical crossentropy with integer targets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_sparse_categorical_crossentropy(
  target,
  output,
  from_logits = FALSE,
  axis = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_sparse_categorical_crossentropy_+3A_target">target</code></td>
<td>
<p>An integer tensor.</p>
</td></tr>
<tr><td><code id="k_sparse_categorical_crossentropy_+3A_output">output</code></td>
<td>
<p>A tensor resulting from a softmax (unless <code>from_logits</code> is TRUE, in which case <code>output</code> is expected to be the logits).</p>
</td></tr>
<tr><td><code id="k_sparse_categorical_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>Boolean, whether <code>output</code> is the result of a softmax, or is a tensor of logits.</p>
</td></tr>
<tr><td><code id="k_sparse_categorical_crossentropy_+3A_axis">axis</code></td>
<td>
<p>Axis (axis indexes are 1-based). Pass -1 (the
default) to select the last axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_spatial_2d_padding'>Pads the 2nd and 3rd dimensions of a 4D tensor.</h2><span id='topic+k_spatial_2d_padding'></span>

<h3>Description</h3>

<p>Pads the 2nd and 3rd dimensions of a 4D tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_spatial_2d_padding(
  x,
  padding = list(list(1, 1), list(1, 1)),
  data_format = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_spatial_2d_padding_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_spatial_2d_padding_+3A_padding">padding</code></td>
<td>
<p>Tuple of 2 lists, padding pattern.</p>
</td></tr>
<tr><td><code id="k_spatial_2d_padding_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A padded 4D tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_spatial_3d_padding'>Pads 5D tensor with zeros along the depth, height, width dimensions.</h2><span id='topic+k_spatial_3d_padding'></span>

<h3>Description</h3>

<p>Pads these dimensions with respectively <code>padding[[1]]</code>, <code>padding[[2]]</code>, and
<code>padding[[3]]</code> zeros left and right. For 'channels_last' data_format, the
2nd, 3rd and 4th dimension will be padded. For 'channels_first' data_format,
the 3rd, 4th and 5th dimension will be padded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_spatial_3d_padding(
  x,
  padding = list(list(1, 1), list(1, 1), list(1, 1)),
  data_format = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_spatial_3d_padding_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_spatial_3d_padding_+3A_padding">padding</code></td>
<td>
<p>List of 3 lists, padding pattern.</p>
</td></tr>
<tr><td><code id="k_spatial_3d_padding_+3A_data_format">data_format</code></td>
<td>
<p>string, <code>"channels_last"</code> or <code>"channels_first"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A padded 5D tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_sqrt'>Element-wise square root.</h2><span id='topic+k_sqrt'></span>

<h3>Description</h3>

<p>Element-wise square root.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_sqrt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_sqrt_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_square'>Element-wise square.</h2><span id='topic+k_square'></span>

<h3>Description</h3>

<p>Element-wise square.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_square(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_square_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_squeeze'>Removes a 1-dimension from the tensor at index <code>axis</code>.</h2><span id='topic+k_squeeze'></span>

<h3>Description</h3>

<p>Removes a 1-dimension from the tensor at index <code>axis</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_squeeze(x, axis = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_squeeze_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_squeeze_+3A_axis">axis</code></td>
<td>
<p>Axis to drop (axis indexes are 1-based).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with the same data as <code>x</code> but reduced dimensions.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_stack'>Stacks a list of rank <code>R</code> tensors into a rank <code>R+1</code> tensor.</h2><span id='topic+k_stack'></span>

<h3>Description</h3>

<p>Stacks a list of rank <code>R</code> tensors into a rank <code>R+1</code> tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_stack(x, axis = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_stack_+3A_x">x</code></td>
<td>
<p>List of tensors.</p>
</td></tr>
<tr><td><code id="k_stack_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform stacking (axis indexes are 1-based).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_std'>Standard deviation of a tensor, alongside the specified axis.</h2><span id='topic+k_std'></span>

<h3>Description</h3>

<p>Standard deviation of a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_std(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_std_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_std_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to compute the standard deviation over
(axis indexes are 1-based).</p>
</td></tr>
<tr><td><code id="k_std_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with the standard deviation of elements of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_stop_gradient'>Returns <code>variables</code> but with zero gradient w.r.t. every other variable.</h2><span id='topic+k_stop_gradient'></span>

<h3>Description</h3>

<p>Returns <code>variables</code> but with zero gradient w.r.t. every other variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_stop_gradient(variables)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_stop_gradient_+3A_variables">variables</code></td>
<td>
<p>tensor or list of tensors to consider constant with respect
to any other variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single tensor or a list of tensors (depending on the passed
argument) that has constant gradient with respect to any other variable.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_sum'>Sum of the values in a tensor, alongside the specified axis.</h2><span id='topic+k_sum'></span>

<h3>Description</h3>

<p>Sum of the values in a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_sum(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_sum_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_sum_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to sum over (axis indexes are 1-based).</p>
</td></tr>
<tr><td><code id="k_sum_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with sum of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_switch'>Switches between two operations depending on a scalar value.</h2><span id='topic+k_switch'></span>

<h3>Description</h3>

<p>Note that both <code>then_expression</code> and <code>else_expression</code>
should be symbolic tensors of the <em>same shape</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_switch(condition, then_expression, else_expression)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_switch_+3A_condition">condition</code></td>
<td>
<p>tensor (<code>int</code> or <code>bool</code>).</p>
</td></tr>
<tr><td><code id="k_switch_+3A_then_expression">then_expression</code></td>
<td>
<p>either a tensor, or a function that returns a tensor.</p>
</td></tr>
<tr><td><code id="k_switch_+3A_else_expression">else_expression</code></td>
<td>
<p>either a tensor, or a function that returns a tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The selected tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_tanh'>Element-wise tanh.</h2><span id='topic+k_tanh'></span>

<h3>Description</h3>

<p>Element-wise tanh.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_tanh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_tanh_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_temporal_padding'>Pads the middle dimension of a 3D tensor.</h2><span id='topic+k_temporal_padding'></span>

<h3>Description</h3>

<p>Pads the middle dimension of a 3D tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_temporal_padding(x, padding = c(1, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_temporal_padding_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
<tr><td><code id="k_temporal_padding_+3A_padding">padding</code></td>
<td>
<p>List of 2 integers, how many zeros to add at the start and end of dim 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A padded 3D tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_tile'>Creates a tensor by tiling <code>x</code> by <code>n</code>.</h2><span id='topic+k_tile'></span>

<h3>Description</h3>

<p>Creates a tensor by tiling <code>x</code> by <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_tile(x, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_tile_+3A_x">x</code></td>
<td>
<p>A tensor or variable</p>
</td></tr>
<tr><td><code id="k_tile_+3A_n">n</code></td>
<td>
<p>A list of integers. The length must be the same as the number of dimensions in <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tiled tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_to_dense'>Converts a sparse tensor into a dense tensor and returns it.</h2><span id='topic+k_to_dense'></span>

<h3>Description</h3>

<p>Converts a sparse tensor into a dense tensor and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_to_dense(tensor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_to_dense_+3A_tensor">tensor</code></td>
<td>
<p>A tensor instance (potentially sparse).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dense tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_transpose'>Transposes a tensor and returns it.</h2><span id='topic+k_transpose'></span>

<h3>Description</h3>

<p>Transposes a tensor and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_transpose(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_transpose_+3A_x">x</code></td>
<td>
<p>Tensor or variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_truncated_normal'>Returns a tensor with truncated random normal distribution of values.</h2><span id='topic+k_truncated_normal'></span>

<h3>Description</h3>

<p>The generated values follow a normal distribution
with specified mean and standard deviation,
except that values whose magnitude is more than
two standard deviations from the mean are dropped and re-picked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_truncated_normal(shape, mean = 0, stddev = 1, dtype = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_truncated_normal_+3A_shape">shape</code></td>
<td>
<p>A list of integers, the shape of tensor to create.</p>
</td></tr>
<tr><td><code id="k_truncated_normal_+3A_mean">mean</code></td>
<td>
<p>Mean of the values.</p>
</td></tr>
<tr><td><code id="k_truncated_normal_+3A_stddev">stddev</code></td>
<td>
<p>Standard deviation of the values.</p>
</td></tr>
<tr><td><code id="k_truncated_normal_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned tensor.</p>
</td></tr>
<tr><td><code id="k_truncated_normal_+3A_seed">seed</code></td>
<td>
<p>Integer, random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_unstack'>Unstack rank <code>R</code> tensor into a list of rank <code>R-1</code> tensors.</h2><span id='topic+k_unstack'></span>

<h3>Description</h3>

<p>Unstack rank <code>R</code> tensor into a list of rank <code>R-1</code> tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_unstack(x, axis = 1L, num = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_unstack_+3A_x">x</code></td>
<td>
<p>a tensor.</p>
</td></tr>
<tr><td><code id="k_unstack_+3A_axis">axis</code></td>
<td>
<p>Axis along which to perform stacking (axis indexes are 1-based).
Negative values wrap around, so the valid range is <code style="white-space: pre;">&#8288;[R, -R]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="k_unstack_+3A_num">num</code></td>
<td>
<p>An int. The length of the dimension axis. Automatically inferred
if NULL (the default).</p>
</td></tr>
<tr><td><code id="k_unstack_+3A_name">name</code></td>
<td>
<p>A name for the operation (optional).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_update'>Update the value of <code>x</code> to <code>new_x</code>.</h2><span id='topic+k_update'></span>

<h3>Description</h3>

<p>Update the value of <code>x</code> to <code>new_x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_update(x, new_x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_update_+3A_x">x</code></td>
<td>
<p>A <code>Variable</code>.</p>
</td></tr>
<tr><td><code id="k_update_+3A_new_x">new_x</code></td>
<td>
<p>A tensor of same shape as <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The variable <code>x</code> updated.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_update_add'>Update the value of <code>x</code> by adding <code>increment</code>.</h2><span id='topic+k_update_add'></span>

<h3>Description</h3>

<p>Update the value of <code>x</code> by adding <code>increment</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_update_add(x, increment)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_update_add_+3A_x">x</code></td>
<td>
<p>A <code>Variable</code>.</p>
</td></tr>
<tr><td><code id="k_update_add_+3A_increment">increment</code></td>
<td>
<p>A tensor of same shape as <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The variable <code>x</code> updated.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_update_sub'>Update the value of <code>x</code> by subtracting <code>decrement</code>.</h2><span id='topic+k_update_sub'></span>

<h3>Description</h3>

<p>Update the value of <code>x</code> by subtracting <code>decrement</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_update_sub(x, decrement)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_update_sub_+3A_x">x</code></td>
<td>
<p>A <code>Variable</code>.</p>
</td></tr>
<tr><td><code id="k_update_sub_+3A_decrement">decrement</code></td>
<td>
<p>A tensor of same shape as <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The variable <code>x</code> updated.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_var'>Variance of a tensor, alongside the specified axis.</h2><span id='topic+k_var'></span>

<h3>Description</h3>

<p>Variance of a tensor, alongside the specified axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_var(x, axis = NULL, keepdims = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_var_+3A_x">x</code></td>
<td>
<p>A tensor or variable.</p>
</td></tr>
<tr><td><code id="k_var_+3A_axis">axis</code></td>
<td>
<p>An integer, the axis to compute the variance over (axis indexes
are 1-based).</p>
</td></tr>
<tr><td><code id="k_var_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the dimensions or not. If
<code>keepdims</code> is <code>FALSE</code>, the rank of the tensor is reduced by 1. If
<code>keepdims</code> is <code>TRUE</code>, the reduced dimension is retained with length 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor with the variance of elements of <code>x</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_variable'>Instantiates a variable and returns it.</h2><span id='topic+k_variable'></span>

<h3>Description</h3>

<p>Instantiates a variable and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_variable(value, dtype = NULL, name = NULL, constraint = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_variable_+3A_value">value</code></td>
<td>
<p>Numpy array, initial value of the tensor.</p>
</td></tr>
<tr><td><code id="k_variable_+3A_dtype">dtype</code></td>
<td>
<p>Tensor type.</p>
</td></tr>
<tr><td><code id="k_variable_+3A_name">name</code></td>
<td>
<p>Optional name string for the tensor.</p>
</td></tr>
<tr><td><code id="k_variable_+3A_constraint">constraint</code></td>
<td>
<p>Optional projection function to be applied to the variable after an optimizer update.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variable instance (with Keras metadata included).
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_zeros'>Instantiates an all-zeros variable and returns it.</h2><span id='topic+k_zeros'></span>

<h3>Description</h3>

<p>Instantiates an all-zeros variable and returns it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_zeros(shape, dtype = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_zeros_+3A_shape">shape</code></td>
<td>
<p>Tuple of integers, shape of returned Keras variable</p>
</td></tr>
<tr><td><code id="k_zeros_+3A_dtype">dtype</code></td>
<td>
<p>String, data type of returned Keras variable</p>
</td></tr>
<tr><td><code id="k_zeros_+3A_name">name</code></td>
<td>
<p>String, name of returned Keras variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variable (including Keras metadata), filled with <code>0.0</code>.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='k_zeros_like'>Instantiates an all-zeros variable of the same shape as another tensor.</h2><span id='topic+k_zeros_like'></span>

<h3>Description</h3>

<p>Instantiates an all-zeros variable of the same shape as another tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_zeros_like(x, dtype = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_zeros_like_+3A_x">x</code></td>
<td>
<p>Keras variable or Keras tensor.</p>
</td></tr>
<tr><td><code id="k_zeros_like_+3A_dtype">dtype</code></td>
<td>
<p>String, dtype of returned Keras variable. NULL uses the dtype
of x.</p>
</td></tr>
<tr><td><code id="k_zeros_like_+3A_name">name</code></td>
<td>
<p>String, name for the variable to create.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras variable with the shape of x filled with zeros.
</p>


<h3>Keras Backend</h3>

<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).
</p>
<p>You can see a list of all available backend functions here:
<a href="https://tensorflow.rstudio.com/reference/keras/index.html#backend">https://tensorflow.rstudio.com/reference/keras/index.html#backend</a>.
</p>

<hr>
<h2 id='keras'>Main Keras module</h2><span id='topic+keras'></span>

<h3>Description</h3>

<p>The <code>keras</code> module object is the equivalent of
<code>keras &lt;- tensorflow::tf$keras</code> and provided mainly as a convenience.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras
</code></pre>


<h3>Format</h3>

<p>An object of class <code>python.builtin.module</code> (inherits from <code>python.builtin.object</code>) of length 0.
</p>


<h3>Value</h3>

<p>the keras Python module
</p>

<hr>
<h2 id='keras_array'>Keras array object</h2><span id='topic+keras_array'></span>

<h3>Description</h3>

<p>Convert an R vector, matrix, or array object to an array that has the optimal
in-memory layout and floating point data type for the current Keras backend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras_array(x, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keras_array_+3A_x">x</code></td>
<td>
<p>Object or list of objects to convert</p>
</td></tr>
<tr><td><code id="keras_array_+3A_dtype">dtype</code></td>
<td>
<p>NumPy data type (e.g. float32, float64). If this is unspecified
then R doubles will be converted to the default floating point type for the
current Keras backend.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Keras does frequent row-oriented access to arrays (for shuffling and drawing
batches) so the order of arrays created by this function is always
row-oriented (&quot;C&quot; as opposed to &quot;Fortran&quot; ordering, which is the default for
R arrays).
</p>
<p>If the passed array is already a NumPy array with the desired <code>dtype</code> and &quot;C&quot;
order then it is returned unmodified (no additional copies are made).
</p>


<h3>Value</h3>

<p>NumPy array with the specified <code>dtype</code> (or list of NumPy arrays if a
list was passed for <code>x</code>).
</p>

<hr>
<h2 id='keras_model'>Keras Model</h2><span id='topic+keras_model'></span>

<h3>Description</h3>

<p>A model is a directed acyclic graph of layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras_model(inputs, outputs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keras_model_+3A_inputs">inputs</code></td>
<td>
<p>Input layer</p>
</td></tr>
<tr><td><code id="keras_model_+3A_outputs">outputs</code></td>
<td>
<p>Output layer</p>
</td></tr>
<tr><td><code id="keras_model_+3A_...">...</code></td>
<td>
<p>Any additional arguments</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(keras)

# input layer
inputs &lt;- layer_input(shape = c(784))

# outputs compose input + dense layers
predictions &lt;- inputs %&gt;%
  layer_dense(units = 64, activation = 'relu') %&gt;%
  layer_dense(units = 64, activation = 'relu') %&gt;%
  layer_dense(units = 10, activation = 'softmax')

# create and compile model
model &lt;- keras_model(inputs = inputs, outputs = predictions)
model %&gt;% compile(
  optimizer = 'rmsprop',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

## End(Not run)
</code></pre>

<hr>
<h2 id='keras_model_custom'>(Deprecated) Create a Keras custom model</h2><span id='topic+keras_model_custom'></span>

<h3>Description</h3>

<p><code>keras_model_custom()</code> is soft-deprecated. Please define custom models by
subclassing <code>keras$Model</code> directly using <code><a href="#topic++25py_class+25">%py_class%</a></code> or <code><a href="R6.html#topic+R6Class">R6::R6Class()</a></code>,
or by calling <code>new_model_class()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras_model_custom(model_fn, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keras_model_custom_+3A_model_fn">model_fn</code></td>
<td>
<p>Function that returns an R custom model</p>
</td></tr>
<tr><td><code id="keras_model_custom_+3A_name">name</code></td>
<td>
<p>Optional name for model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Keras model
</p>

<hr>
<h2 id='keras_model_sequential'>Keras Model composed of a linear stack of layers</h2><span id='topic+keras_model_sequential'></span>

<h3>Description</h3>

<p>Keras Model composed of a linear stack of layers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras_model_sequential(layers = NULL, name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keras_model_sequential_+3A_layers">layers</code></td>
<td>
<p>List of layers to add to the model</p>
</td></tr>
<tr><td><code id="keras_model_sequential_+3A_name">name</code></td>
<td>
<p>Name of model</p>
</td></tr>
<tr><td><code id="keras_model_sequential_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+sequential_model_input_layer">sequential_model_input_layer</a></code>
</p>

<dl>
<dt><code>input_shape</code></dt><dd><p>an integer vector of dimensions (not including the batch
axis), or a <code>tf$TensorShape</code> instance (also not including the batch axis).</p>
</dd>
<dt><code>batch_size</code></dt><dd><p>Optional input batch size (integer or NULL).</p>
</dd>
<dt><code>dtype</code></dt><dd><p>Optional datatype of the input. When not provided, the Keras
default float type will be used.</p>
</dd>
<dt><code>input_tensor</code></dt><dd><p>Optional tensor to use as layer input. If set, the layer
will use the <code>tf$TypeSpec</code> of this tensor rather than creating a new
placeholder tensor.</p>
</dd>
<dt><code>sparse</code></dt><dd><p>Boolean, whether the placeholder created is meant to be sparse.
Default to <code>FALSE</code>.</p>
</dd>
<dt><code>ragged</code></dt><dd><p>Boolean, whether the placeholder created is meant to be ragged.
In this case, values of 'NULL' in the 'shape' argument represent ragged
dimensions. For more information about <code>RaggedTensors</code>, see this
<a href="https://www.tensorflow.org/guide/ragged_tensor">guide</a>. Default to
<code>FALSE</code>.</p>
</dd>
<dt><code>type_spec</code></dt><dd><p>A <code>tf$TypeSpec</code> object to create Input from. This
<code>tf$TypeSpec</code> represents the entire batch. When provided, all other args
except name must be <code>NULL</code>.</p>
</dd>
<dt><code>input_layer_name,name</code></dt><dd><p>Optional name of the input layer (string).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Note</h3>

<p>If any arguments are provided to <code>...</code>, then the sequential model is
initialized with a <code>InputLayer</code> instance. If not, then the first layer passed
to a Sequential model should have a defined input shape. What that means is
that it should have received an <code>input_shape</code> or <code>batch_input_shape</code>
argument, or for some type of layers (recurrent, Dense...) an <code>input_dim</code>
argument.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

library(keras)

model &lt;- keras_model_sequential()
model %&gt;%
  layer_dense(units = 32, input_shape = c(784)) %&gt;%
  layer_activation('relu') %&gt;%
  layer_dense(units = 10) %&gt;%
  layer_activation('softmax')

model %&gt;% compile(
  optimizer = 'rmsprop',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

# alternative way to provide input shape
model &lt;- keras_model_sequential(input_shape = c(784)) %&gt;%
  layer_dense(units = 32) %&gt;%
  layer_activation('relu') %&gt;%
  layer_dense(units = 10) %&gt;%
  layer_activation('softmax')


## End(Not run)
</code></pre>

<hr>
<h2 id='KerasCallback'>(Deprecated) Base R6 class for Keras callbacks</h2><span id='topic+KerasCallback'></span>

<h3>Description</h3>

<p>New custom callbacks implemented as R6 classes are encouraged to inherit from
<code>keras$callbacks$Callback</code> directly.
</p>


<h3>Format</h3>

<p>An <a href="R6.html#topic+R6Class">R6Class</a> generator object
</p>


<h3>Details</h3>

<p>The <code>logs</code> named list that callback methods take as argument will
contain keys for quantities relevant to the current batch or epoch.
</p>
<p>Currently, the <code>fit.keras.engine.training.Model()</code> method for sequential
models will include the following quantities in the <code>logs</code> that
it passes to its callbacks:
</p>

<ul>
<li> <p><code>on_epoch_end</code>: logs include <code>acc</code> and <code>loss</code>, and optionally include <code>val_loss</code> (if validation is enabled in <code>fit</code>), and <code>val_acc</code> (if validation and accuracy monitoring are enabled).
</p>
</li>
<li> <p><code>on_batch_begin</code>: logs include <code>size</code>, the number of samples in the current batch.
</p>
</li>
<li> <p><code>on_batch_end</code>: logs include <code>loss</code>, and optionally <code>acc</code> (if accuracy monitoring is enabled).
</p>
</li></ul>



<h3>Value</h3>

<p><a href="#topic+KerasCallback">KerasCallback</a>.
</p>


<h3>Fields</h3>


<dl>
<dt><code>params</code></dt><dd><p>Named list with training parameters (eg. verbosity, batch size, number of epochs...).</p>
</dd>
<dt><code>model</code></dt><dd><p>Reference to the Keras model being trained.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>on_epoch_begin(epoch, logs)</code></dt><dd><p>Called at the beginning of each epoch.</p>
</dd>
<dt><code>on_epoch_end(epoch, logs)</code></dt><dd><p>Called at the end of each epoch.</p>
</dd>
<dt><code>on_batch_begin(batch, logs)</code></dt><dd><p>Called at the beginning of each batch.</p>
</dd>
<dt><code>on_batch_end(batch, logs)</code></dt><dd><p>Called at the end of each batch.</p>
</dd>
<dt><code>on_train_begin(logs)</code></dt><dd><p>Called at the beginning of training.</p>
</dd>
<dt><code>on_train_end(logs)</code></dt><dd><p>Called at the end of training.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(keras)

LossHistory &lt;- R6::R6Class("LossHistory",
  inherit = KerasCallback,

  public = list(

    losses = NULL,

    on_batch_end = function(batch, logs = list()) {
      self$losses &lt;- c(self$losses, logs[["loss"]])
    }
  )
)

## End(Not run)
</code></pre>

<hr>
<h2 id='KerasConstraint'>(Deprecated) Base R6 class for Keras constraints</h2><span id='topic+KerasConstraint'></span>

<h3>Description</h3>

<p>New custom constraints are encouraged to subclass <code>keras$constraints$Constraint</code> directly.
</p>


<h3>Format</h3>

<p>An <a href="R6.html#topic+R6Class">R6Class</a> generator object
</p>


<h3>Details</h3>

<p>You can implement a custom constraint either by creating an
R function that accepts a weights (<code>w</code>) parameter, or by creating
an R6 class that derives from <code>KerasConstraint</code> and implements a
<code>call</code> method.
</p>


<h3>Methods</h3>


<dl>
<dt><code>call(w)</code></dt><dd><p>Constrain the specified weights.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Models which use custom constraints cannot be serialized using
<code><a href="#topic+save_model_hdf5">save_model_hdf5()</a></code>. Rather, the weights of the model should be saved
and restored using <code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5()</a></code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+constraints">constraints</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
CustomNonNegConstraint &lt;- R6::R6Class(
  "CustomNonNegConstraint",
  inherit = KerasConstraint,
  public = list(
    call = function(x) {
       w * k_cast(k_greater_equal(w, 0), k_floatx())
    }
  )
)

layer_dense(units = 32, input_shape = c(784),
            kernel_constraint = CustomNonNegConstraint$new())

## End(Not run)

</code></pre>

<hr>
<h2 id='KerasLayer'>(Deprecated) Base R6 class for Keras layers</h2><span id='topic+KerasLayer'></span>

<h3>Description</h3>

<p>Custom R6 layers can now inherit directly from <code>keras$layers$Layer</code> or other layers.
</p>


<h3>Format</h3>

<p>An <a href="R6.html#topic+R6Class">R6Class</a> generator object
</p>


<h3>Value</h3>

<p><a href="#topic+KerasLayer">KerasLayer</a>.
</p>


<h3>Methods</h3>

 <dl>
<dt><code>build(input_shape)</code></dt><dd><p>Creates the
layer weights (must be implemented by all layers that have weights)</p>
</dd>
<dt><code>call(inputs,mask)</code></dt><dd><p>Call the layer on an input tensor.</p>
</dd>
<dt><code>compute_output_shape(input_shape)</code></dt><dd><p>Compute the output shape
for the layer.</p>
</dd>
<dt><code>add_loss(losses, inputs)</code></dt><dd><p>Add losses to the layer.</p>
</dd>
<dt><code>add_weight(name,shape,dtype,initializer,regularizer,trainable,constraint)</code></dt><dd><p>Adds
a weight variable to the layer.</p>
</dd> </dl>


<hr>
<h2 id='KerasWrapper'>(Deprecated) Base R6 class for Keras wrappers</h2><span id='topic+KerasWrapper'></span>

<h3>Description</h3>

<p>Instead of inheriting from the proxy class <code>KerasWrapper</code> and using
<code>create_wrapper</code> to create instances, new R6 custom classes are encouraged to
inherit directly from <code>keras$layers$Wrapper</code> and use <code>create_layer</code> to create
instances.
</p>


<h3>Format</h3>

<p>An <a href="R6.html#topic+R6Class">R6Class</a> generator object
</p>


<h3>Value</h3>

<p><a href="#topic+KerasWrapper">KerasWrapper</a>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>build(input_shape)</code></dt><dd><p>Builds the wrapped layer.
Subclasses can extend this to perform custom operations on that layer.</p>
</dd>
<dt><code>call(inputs,mask)</code></dt><dd><p>Calls the wrapped layer on an input tensor.</p>
</dd>
<dt><code>compute_output_shape(input_shape)</code></dt><dd><p>Computes the output shape
for the wrapped layer.</p>
</dd>
<dt><code>add_loss(losses, inputs)</code></dt><dd><p>Subclasses can use this to add losses to the wrapped layer.</p>
</dd>
<dt><code>add_weight(name,shape,dtype,initializer,regularizer,trainable,constraint)</code></dt><dd><p>Subclasses can use this to add weights to the wrapped layer.</p>
</dd> </dl>


<hr>
<h2 id='Layer'>(Deprecated) Create a custom Layer</h2><span id='topic+Layer'></span>

<h3>Description</h3>

<p>This function is maintained but deprecated. Please use <code>new_layer_class()</code> or
<code style="white-space: pre;">&#8288;%py_class%&#8288;</code> to define custom layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Layer(
  classname,
  initialize,
  build = NULL,
  call = NULL,
  compute_output_shape = NULL,
  ...,
  inherit = keras::keras$layers$Layer
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Layer_+3A_classname">classname</code></td>
<td>
<p>the name of the custom Layer.</p>
</td></tr>
<tr><td><code id="Layer_+3A_initialize">initialize</code></td>
<td>
<p>a function. This is where you define the arguments used to further
build your layer. For example, a dense layer would take the <code>units</code> argument.
You should always call <code>super()$`__init__()`</code> to initialize the base
inherited layer.</p>
</td></tr>
<tr><td><code id="Layer_+3A_build">build</code></td>
<td>
<p>a function that takes <code>input_shape</code> as argument. This is where you will
define your weights. Note that if your layer doesn't define trainable weights then
you need not implement this method.</p>
</td></tr>
<tr><td><code id="Layer_+3A_call">call</code></td>
<td>
<p>This is where the layer's logic lives. Unless you want your layer to
support masking, you only have to care about the first argument passed to <code>call</code>
(the input tensor).</p>
</td></tr>
<tr><td><code id="Layer_+3A_compute_output_shape">compute_output_shape</code></td>
<td>
<p>a function that takes <code>input_shape</code> as an argument. In
case your layer modifies the shape of its input, you should specify here the
shape transformation logic. This allows Keras to do automatic shape inference.
If you don't modify the shape of the input then you need not implement this
method.</p>
</td></tr>
<tr><td><code id="Layer_+3A_...">...</code></td>
<td>
<p>Any other methods and/or attributes can be specified using named
arguments. They will be added to the layer class.</p>
</td></tr>
<tr><td><code id="Layer_+3A_inherit">inherit</code></td>
<td>
<p>the Keras layer to inherit from.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that wraps <code>create_layer</code>, similar to <code>keras::layer_dense</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

layer_dense2 &lt;- Layer(
  "Dense2",

  initialize = function(units) {
    super()$`__init__`()
    self$units &lt;- as.integer(units)
  },

  build = function(input_shape) {
    print(class(input_shape))
    self$kernel &lt;- self$add_weight(
      name = "kernel",
      shape = list(input_shape[[2]], self$units),
      initializer = "uniform",
      trainable = TRUE
    )
  },

  call = function(x) {
    tensorflow::tf$matmul(x, self$kernel)
  },

  compute_output_shape = function(input_shape) {
    list(input_shape[[1]], self$units)
  }

)

l &lt;- layer_dense2(units = 10)
l(matrix(runif(10), ncol = 1))


## End(Not run)

</code></pre>

<hr>
<h2 id='layer_activation'>Apply an activation function to an output.</h2><span id='topic+layer_activation'></span>

<h3>Description</h3>

<p>Apply an activation function to an output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation(
  object,
  activation,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_+3A_activation">activation</code></td>
<td>
<p>Name of activation function to use. If you don't specify
anything, no activation is applied (ie. &quot;linear&quot; activation: a(x) = x).</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>
<p>Other activation layers: 
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_elu'>Exponential Linear Unit.</h2><span id='topic+layer_activation_elu'></span>

<h3>Description</h3>

<p>It follows: <code>f(x) =  alpha * (exp(x) - 1.0)</code> for <code>x &lt; 0</code>, <code>f(x) = x</code> for <code>x &gt;= 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_elu(
  object,
  alpha = 1,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_elu_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_alpha">alpha</code></td>
<td>
<p>Scale for the negative factor.</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_elu_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="https://arxiv.org/abs/1511.07289v1">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a>.
</p>
<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_leaky_relu'>Leaky version of a Rectified Linear Unit.</h2><span id='topic+layer_activation_leaky_relu'></span>

<h3>Description</h3>

<p>Allows a small gradient when the unit is not active: <code>f(x) = alpha * x</code> for
<code>x &lt; 0</code>, <code>f(x) = x</code> for <code>x &gt;= 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_leaky_relu(
  object,
  alpha = 0.3,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_leaky_relu_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_alpha">alpha</code></td>
<td>
<p>float &gt;= 0. Negative slope coefficient.</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_leaky_relu_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf">Rectifier Nonlinearities Improve Neural Network Acoustic Models</a>.
</p>
<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_parametric_relu'>Parametric Rectified Linear Unit.</h2><span id='topic+layer_activation_parametric_relu'></span>

<h3>Description</h3>

<p>It follows: <code style="white-space: pre;">&#8288;f(x) = alpha * x`` for &#8288;</code>x &lt; 0<code style="white-space: pre;">&#8288;, &#8288;</code>f(x) = x<code>for</code>x &gt;= 0', where
alpha is a learned array with the same shape as x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_parametric_relu(
  object,
  alpha_initializer = "zeros",
  alpha_regularizer = NULL,
  alpha_constraint = NULL,
  shared_axes = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_parametric_relu_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_alpha_initializer">alpha_initializer</code></td>
<td>
<p>Initializer function for the weights.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_alpha_regularizer">alpha_regularizer</code></td>
<td>
<p>Regularizer for the weights.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_alpha_constraint">alpha_constraint</code></td>
<td>
<p>Constraint for the weights.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_shared_axes">shared_axes</code></td>
<td>
<p>The axes along which to share learnable parameters for the
activation function. For example, if the incoming feature maps are from a
2D convolution with output shape (batch, height, width, channels), and you
wish to share parameters across space so that each filter only has one set
of parameters, set shared_axes=c(1, 2).</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_parametric_relu_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>.
</p>
<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_relu'>Rectified Linear Unit activation function</h2><span id='topic+layer_activation_relu'></span>

<h3>Description</h3>

<p>Rectified Linear Unit activation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_relu(
  object,
  max_value = NULL,
  negative_slope = 0,
  threshold = 0,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_relu_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_max_value">max_value</code></td>
<td>
<p>loat, the maximum output value.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_negative_slope">negative_slope</code></td>
<td>
<p>float &gt;= 0 Negative slope coefficient.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_threshold">threshold</code></td>
<td>
<p>float. Threshold value for thresholded activation.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_relu_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_selu'>Scaled Exponential Linear Unit.</h2><span id='topic+layer_activation_selu'></span>

<h3>Description</h3>

<p>SELU is equal to: <code>scale * elu(x, alpha)</code>, where alpha and scale
are pre-defined constants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_selu(
  object,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_selu_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_selu_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values of <code>alpha</code> and <code>scale</code> are
chosen so that the mean and variance of the inputs are preserved
between two consecutive layers as long as the weights are initialized
correctly (see initializer_lecun_normal) and the number of inputs
is &quot;large enough&quot; (see article for more information).
</p>
<p>Note:
</p>

<ul>
<li><p> To be used together with the initialization &quot;lecun_normal&quot;.
</p>
</li>
<li><p> To be used together with the dropout variant &quot;AlphaDropout&quot;.
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a>, <code><a href="#topic+initializer_lecun_normal">initializer_lecun_normal</a></code>, <code><a href="#topic+layer_alpha_dropout">layer_alpha_dropout</a></code>
</p>
<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_softmax'>Softmax activation function.</h2><span id='topic+layer_activation_softmax'></span>

<h3>Description</h3>

<p>It follows: <code>f(x) =  alpha * (exp(x) - 1.0)</code> for <code>x &lt; 0</code>, <code>f(x) = x</code> for <code>x &gt;= 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_softmax(
  object,
  axis = -1,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_softmax_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_axis">axis</code></td>
<td>
<p>Integer, axis along which the softmax normalization is applied.</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_softmax_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_thresholded_relu">layer_activation_thresholded_relu</a>()</code>
</p>

<hr>
<h2 id='layer_activation_thresholded_relu'>Thresholded Rectified Linear Unit.</h2><span id='topic+layer_activation_thresholded_relu'></span>

<h3>Description</h3>

<p>It follows: <code>f(x) = x</code> for <code>x &gt; theta</code>, <code>f(x) = 0</code> otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_thresholded_relu(
  object,
  theta = 1,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_thresholded_relu_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_theta">theta</code></td>
<td>
<p>float &gt;= 0. Threshold location of activation.</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activation_thresholded_relu_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="https://arxiv.org/abs/1402.3337">Zero-bias autoencoders and the benefits of co-adapting features</a>.
</p>
<p>Other activation layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activation_elu">layer_activation_elu</a>()</code>,
<code><a href="#topic+layer_activation_leaky_relu">layer_activation_leaky_relu</a>()</code>,
<code><a href="#topic+layer_activation_parametric_relu">layer_activation_parametric_relu</a>()</code>,
<code><a href="#topic+layer_activation_relu">layer_activation_relu</a>()</code>,
<code><a href="#topic+layer_activation_selu">layer_activation_selu</a>()</code>,
<code><a href="#topic+layer_activation_softmax">layer_activation_softmax</a>()</code>
</p>

<hr>
<h2 id='layer_activity_regularization'>Layer that applies an update to the cost function based input activity.</h2><span id='topic+layer_activity_regularization'></span>

<h3>Description</h3>

<p>Layer that applies an update to the cost function based input activity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activity_regularization(
  object,
  l1 = 0,
  l2 = 0,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activity_regularization_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_l1">l1</code></td>
<td>
<p>L1 regularization factor (positive float).</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_l2">l2</code></td>
<td>
<p>L2 regularization factor (positive float).</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_activity_regularization_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>Arbitrary. Use the keyword argument <code>input_shape</code> (list
of integers, does not include the samples axis) when using this layer as
the first layer in a model.
</p>


<h3>Output shape</h3>

<p>Same shape as input.
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_add'>Layer that adds a list of inputs.</h2><span id='topic+layer_add'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_add(inputs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_add_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_add_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the sum of the inputs. If <code>inputs</code> is missing, a keras
layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/add">https://www.tensorflow.org/api_docs/python/tf/keras/layers/add</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/add">https://keras.io/api/layers/merging_layers/add</a>
</p>
</li></ul>


<hr>
<h2 id='layer_additive_attention'>Additive attention layer, a.k.a. Bahdanau-style attention</h2><span id='topic+layer_additive_attention'></span>

<h3>Description</h3>

<p>Additive attention layer, a.k.a. Bahdanau-style attention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_additive_attention(
  object,
  use_scale = TRUE,
  ...,
  causal = FALSE,
  dropout = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_additive_attention_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_additive_attention_+3A_use_scale">use_scale</code></td>
<td>
<p>If <code>TRUE</code>, will create a variable to scale the attention scores.</p>
</td></tr>
<tr><td><code id="layer_additive_attention_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
<tr><td><code id="layer_additive_attention_+3A_causal">causal</code></td>
<td>
<p>Boolean. Set to <code>TRUE</code> for decoder self-attention. Adds a mask such
that position <code>i</code> cannot attend to positions <code>j &gt; i</code>. This prevents the
flow of information from the future towards the past.</p>
</td></tr>
<tr><td><code id="layer_additive_attention_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
attention scores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inputs are <code>query</code> tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tq, dim]&#8288;</code>, <code>value</code> tensor of
shape <code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code> and <code>key</code> tensor of shape
<code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code>. The calculation follows the steps:
</p>

<ol>
<li><p> Reshape <code>query</code> and <code>key</code> into shapes <code style="white-space: pre;">&#8288;[batch_size, Tq, 1, dim]&#8288;</code>
and <code style="white-space: pre;">&#8288;[batch_size, 1, Tv, dim]&#8288;</code> respectively.
</p>
</li>
<li><p> Calculate scores with shape <code style="white-space: pre;">&#8288;[batch_size, Tq, Tv]&#8288;</code> as a non-linear
sum: <code>scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)</code>
</p>
</li>
<li><p> Use scores to calculate a distribution with shape
<code style="white-space: pre;">&#8288;[batch_size, Tq, Tv]&#8288;</code>: <code>distribution = tf$nn$softmax(scores)</code>.
</p>
</li>
<li><p> Use <code>distribution</code> to create a linear combination of <code>value</code> with
shape <code style="white-space: pre;">&#8288;[batch_size, Tq, dim]&#8288;</code>:
<code style="white-space: pre;">&#8288;return tf$matmul(distribution, value)&#8288;</code>.
</p>
</li></ol>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention">https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/attention_layers/additive_attention/">https://keras.io/api/layers/attention_layers/additive_attention/</a>
</p>
</li></ul>


<hr>
<h2 id='layer_alpha_dropout'>Applies Alpha Dropout to the input.</h2><span id='topic+layer_alpha_dropout'></span>

<h3>Description</h3>

<p>Alpha Dropout is a dropout that keeps mean and variance of inputs to their
original values, in order to ensure the self-normalizing property even after
this dropout.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_alpha_dropout(object, rate, noise_shape = NULL, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_alpha_dropout_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_alpha_dropout_+3A_rate">rate</code></td>
<td>
<p>float, drop probability (as with <code>layer_dropout()</code>). The
multiplicative noise will have standard deviation <code>sqrt(rate / (1 - rate))</code>.</p>
</td></tr>
<tr><td><code id="layer_alpha_dropout_+3A_noise_shape">noise_shape</code></td>
<td>
<p>Noise shape</p>
</td></tr>
<tr><td><code id="layer_alpha_dropout_+3A_seed">seed</code></td>
<td>
<p>An integer to use as random seed.</p>
</td></tr>
<tr><td><code id="layer_alpha_dropout_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Alpha Dropout fits well to Scaled Exponential Linear Units by randomly
setting activations to the negative saturation value.
</p>


<h3>Input shape</h3>

<p>Arbitrary. Use the keyword argument <code>input_shape</code> (list
of integers, does not include the samples axis) when using this layer as
the first layer in a model.
</p>


<h3>Output shape</h3>

<p>Same shape as input.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout">https://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout</a>
</p>
<p>Other noise layers: 
<code><a href="#topic+layer_gaussian_dropout">layer_gaussian_dropout</a>()</code>,
<code><a href="#topic+layer_gaussian_noise">layer_gaussian_noise</a>()</code>
</p>

<hr>
<h2 id='layer_attention'>Dot-product attention layer, a.k.a. Luong-style attention</h2><span id='topic+layer_attention'></span>

<h3>Description</h3>

<p>Dot-product attention layer, a.k.a. Luong-style attention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_attention(
  inputs,
  use_scale = FALSE,
  score_mode = "dot",
  ...,
  dropout = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_attention_+3A_inputs">inputs</code></td>
<td>
<p>List of the following tensors:
</p>

<ul>
<li><p> query: Query Tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tq, dim]&#8288;</code>.
</p>
</li>
<li><p> value: Value Tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code>.
</p>
</li>
<li><p> key: Optional key Tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code>. If not
given, will use value for both key and value, which is the most common
case.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_attention_+3A_use_scale">use_scale</code></td>
<td>
<p>If <code>TRUE</code>, will create a scalar variable to scale the attention
scores.</p>
</td></tr>
<tr><td><code id="layer_attention_+3A_score_mode">score_mode</code></td>
<td>
<p>Function to use to compute attention scores, one of
<code style="white-space: pre;">&#8288;{"dot", "concat"}&#8288;</code>. <code>"dot"</code> refers to the dot product between the query
and key vectors. <code>"concat"</code> refers to the hyperbolic tangent of the
concatenation of the query and key vectors.</p>
</td></tr>
<tr><td><code id="layer_attention_+3A_...">...</code></td>
<td>
<p>standard layer arguments (e.g., batch_size, dtype, name, trainable, weights)</p>
</td></tr>
<tr><td><code id="layer_attention_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
attention scores. Defaults to 0.0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>inputs are <code>query</code> tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tq, dim]&#8288;</code>, <code>value</code> tensor
of shape <code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code> and <code>key</code> tensor of shape
<code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code>. The calculation follows the steps:
</p>

<ol>
<li><p> Calculate scores with shape <code style="white-space: pre;">&#8288;[batch_size, Tq, Tv]&#8288;</code> as a <code>query</code>-<code>key</code> dot
product: <code>scores = tf$matmul(query, key, transpose_b=TRUE)</code>.
</p>
</li>
<li><p> Use scores to calculate a distribution with shape
<code style="white-space: pre;">&#8288;[batch_size, Tq, Tv]&#8288;</code>: <code>distribution = tf$nn$softmax(scores)</code>.
</p>
</li>
<li><p> Use <code>distribution</code> to create a linear combination of <code>value</code> with
shape <code style="white-space: pre;">&#8288;[batch_size, Tq, dim]&#8288;</code>:
return <code>tf$matmul(distribution, value)</code>.
</p>
</li></ol>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention</a>
</p>
</li></ul>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_average'>Layer that averages a list of inputs.</h2><span id='topic+layer_average'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_average(inputs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_average_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_average_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the average of the inputs. If <code>inputs</code> is missing, a keras
layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/average">https://www.tensorflow.org/api_docs/python/tf/keras/layers/average</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Average">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Average</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/average">https://keras.io/api/layers/merging_layers/average</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_concatenate">layer_concatenate</a>()</code>,
<code><a href="#topic+layer_dot">layer_dot</a>()</code>,
<code><a href="#topic+layer_maximum">layer_maximum</a>()</code>,
<code><a href="#topic+layer_minimum">layer_minimum</a>()</code>,
<code><a href="#topic+layer_multiply">layer_multiply</a>()</code>,
<code><a href="#topic+layer_subtract">layer_subtract</a>()</code>
</p>

<hr>
<h2 id='layer_average_pooling_1d'>Average pooling for temporal data.</h2><span id='topic+layer_average_pooling_1d'></span>

<h3>Description</h3>

<p>Average pooling for temporal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_average_pooling_1d(
  object,
  pool_size = 2L,
  strides = NULL,
  padding = "valid",
  data_format = "channels_last",
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_average_pooling_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_pool_size">pool_size</code></td>
<td>
<p>Integer, size of the average pooling windows.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_strides">strides</code></td>
<td>
<p>Integer, or NULL. Factor by which to downscale. E.g. 2 will
halve the input. If NULL, it will default to <code>pool_size</code>.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_data_format">data_format</code></td>
<td>
<p>One of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, steps, features)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, downsampled_steps, features)&#8288;</code>.
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_average_pooling_2d'>Average pooling operation for spatial data.</h2><span id='topic+layer_average_pooling_2d'></span>

<h3>Description</h3>

<p>Average pooling operation for spatial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_average_pooling_2d(
  object,
  pool_size = c(2L, 2L),
  strides = NULL,
  padding = "valid",
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_average_pooling_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_pool_size">pool_size</code></td>
<td>
<p>integer or list of 2 integers, factors by which to downscale
(vertical, horizontal). (2, 2) will halve the input in both spatial
dimension. If only one integer is specified, the same window length will be
used for both dimensions.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_strides">strides</code></td>
<td>
<p>Integer, list of 2 integers, or NULL. Strides values. If NULL,
it will default to <code>pool_size</code>.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, pooled_rows, pooled_cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, pooled_rows, pooled_cols)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_average_pooling_3d'>Average pooling operation for 3D data (spatial or spatio-temporal).</h2><span id='topic+layer_average_pooling_3d'></span>

<h3>Description</h3>

<p>Average pooling operation for 3D data (spatial or spatio-temporal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_average_pooling_3d(
  object,
  pool_size = c(2L, 2L, 2L),
  strides = NULL,
  padding = "valid",
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_average_pooling_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_pool_size">pool_size</code></td>
<td>
<p>list of 3 integers, factors by which to downscale (dim1,
dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each
dimension.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_strides">strides</code></td>
<td>
<p>list of 3 integers, or NULL. Strides values.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_average_pooling_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_batch_normalization'>Layer that normalizes its inputs</h2><span id='topic+layer_batch_normalization'></span>

<h3>Description</h3>

<p>Layer that normalizes its inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_batch_normalization(
  object,
  axis = -1L,
  momentum = 0.99,
  epsilon = 0.001,
  center = TRUE,
  scale = TRUE,
  beta_initializer = "zeros",
  gamma_initializer = "ones",
  moving_mean_initializer = "zeros",
  moving_variance_initializer = "ones",
  beta_regularizer = NULL,
  gamma_regularizer = NULL,
  beta_constraint = NULL,
  gamma_constraint = NULL,
  synchronized = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_batch_normalization_+3A_object">object</code></td>
<td>
<p>Layer or model object</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_axis">axis</code></td>
<td>
<p>Integer, the axis that should be normalized (typically the features
axis). For instance, after a <code>Conv2D</code> layer with
<code>data_format="channels_first"</code>, set <code>axis=1</code> in <code>BatchNormalization</code>.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_momentum">momentum</code></td>
<td>
<p>Momentum for the moving average.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_epsilon">epsilon</code></td>
<td>
<p>Small float added to variance to avoid dividing by zero.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_center">center</code></td>
<td>
<p>If <code>TRUE</code>, add offset of <code>beta</code> to normalized tensor. If <code>FALSE</code>,
<code>beta</code> is ignored.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, multiply by <code>gamma</code>. If <code>FALSE</code>, <code>gamma</code> is not used. When
the next layer is linear (also e.g. <code>nn.relu</code>), this can be disabled
since the scaling will be done by the next layer.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_beta_initializer">beta_initializer</code></td>
<td>
<p>Initializer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_gamma_initializer">gamma_initializer</code></td>
<td>
<p>Initializer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_moving_mean_initializer">moving_mean_initializer</code></td>
<td>
<p>Initializer for the moving mean.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_moving_variance_initializer">moving_variance_initializer</code></td>
<td>
<p>Initializer for the moving variance.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_beta_regularizer">beta_regularizer</code></td>
<td>
<p>Optional regularizer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_gamma_regularizer">gamma_regularizer</code></td>
<td>
<p>Optional regularizer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_beta_constraint">beta_constraint</code></td>
<td>
<p>Optional constraint for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_gamma_constraint">gamma_constraint</code></td>
<td>
<p>Optional constraint for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_synchronized">synchronized</code></td>
<td>
<p>If <code>TRUE</code>, synchronizes the global batch statistics (mean and
variance) for the layer across all devices at each training step in a
distributed training strategy. If <code>FALSE</code>, each replica uses its own
local batch statistics. Only relevant when used inside a
<code>tf$distribute</code> strategy.</p>
</td></tr>
<tr><td><code id="layer_batch_normalization_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Batch normalization applies a transformation that maintains the mean output
close to 0 and the output standard deviation close to 1.
</p>
<p>Importantly, batch normalization works differently during training and
during inference.
</p>
<p><strong>During training</strong> (i.e. when using <code>fit()</code> or when calling the layer/model
with the argument <code>training=TRUE</code>), the layer normalizes its output using
the mean and standard deviation of the current batch of inputs. That is to
say, for each channel being normalized, the layer returns
<code>gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta</code>, where:
</p>

<ul>
<li> <p><code>epsilon</code> is small constant (configurable as part of the constructor
arguments)
</p>
</li>
<li> <p><code>gamma</code> is a learned scaling factor (initialized as 1), which
can be disabled by passing <code>scale=FALSE</code> to the constructor.
</p>
</li>
<li> <p><code>beta</code> is a learned offset factor (initialized as 0), which
can be disabled by passing <code>center=FALSE</code> to the constructor.
</p>
</li></ul>

<p><strong>During inference</strong> (i.e. when using <code>evaluate()</code> or <code>predict()</code> or when
calling the layer/model with the argument <code>training=FALSE</code> (which is the
default), the layer normalizes its output using a moving average of the
mean and standard deviation of the batches it has seen during training. That
is to say, it returns
<code>gamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta</code>.
</p>
<p><code>self$moving_mean</code> and <code>self$moving_var</code> are non-trainable variables that
are updated each time the layer in called in training mode, as such:
</p>

<ul>
<li> <p><code>moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)</code>
</p>
</li>
<li> <p><code>moving_var = moving_var * momentum + var(batch) * (1 - momentum)</code>
</p>
</li></ul>

<p>As such, the layer will only normalize its inputs during inference
<em>after having been trained on data that has similar statistics as the
inference data</em>.
</p>
<p>When <code>synchronized=TRUE</code> is set and if this layer is used within a
<code>tf$distribute</code> strategy, there will be an <code>allreduce</code> call
to aggregate batch statistics across all replicas at every
training step. Setting <code>synchronized</code> has no impact when the model is
trained without specifying any distribution strategy.
</p>
<p>Example usage:
</p>
<div class="sourceCode R"><pre>strategy &lt;- tf$distribute$MirroredStrategy()

with(strategy$scope(), {
  model &lt;- keras_model_sequential()
  model %&gt;%
    layer_dense(16) %&gt;%
    layer_batch_normalization(synchronized=TRUE)
})
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers">https://keras.io/api/layers</a>
</p>
</li></ul>


<hr>
<h2 id='layer_category_encoding'>A preprocessing layer which encodes integer features.</h2><span id='topic+layer_category_encoding'></span>

<h3>Description</h3>

<p>This layer provides options for condensing data into a categorical encoding
when the total number of tokens are known in advance. It accepts integer
values as inputs, and it outputs a dense or sparse representation of those
inputs. For integer inputs where the total number of tokens is not known, use
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup()</a></code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_category_encoding(
  object,
  num_tokens = NULL,
  output_mode = "multi_hot",
  sparse = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_category_encoding_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_category_encoding_+3A_num_tokens">num_tokens</code></td>
<td>
<p>The total number of tokens the layer should support. All
inputs to the layer must integers in the range <code style="white-space: pre;">&#8288;0 &lt;= value &lt; num_tokens&#8288;</code>,
or an error will be thrown.</p>
</td></tr>
<tr><td><code id="layer_category_encoding_+3A_output_mode">output_mode</code></td>
<td>
<p>Specification for the output of the layer. Defaults to
<code>"multi_hot"</code>. Values can be <code>"one_hot"</code>, <code>"multi_hot"</code> or <code>"count"</code>,
configuring the layer as follows:
</p>

<ul>
<li> <p><code>"one_hot"</code>: Encodes each individual element in the input into an array
of <code>num_tokens</code> size, containing a 1 at the element index. If the last
dimension is size 1, will encode on that dimension. If the last dimension
is not size 1, will append a new dimension for the encoded output.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Encodes each sample in the input into a single array of
<code>num_tokens</code> size, containing a 1 for each vocabulary term present in the
sample. Treats the last dimension as the sample dimension, if input shape
is <code style="white-space: pre;">&#8288;(..., sample_length)&#8288;</code>, output shape will be <code style="white-space: pre;">&#8288;(..., num_tokens)&#8288;</code>.
</p>
</li>
<li> <p><code>"count"</code>: Like <code>"multi_hot"</code>, but the int array contains a count of the
number of times the token at that index appeared in the sample.
</p>
</li></ul>

<p>For all output modes, currently only output up to rank 2 is supported.</p>
</td></tr>
<tr><td><code id="layer_category_encoding_+3A_sparse">sparse</code></td>
<td>
<p>Boolean. If <code>TRUE</code>, returns a <code>SparseTensor</code> instead of a dense
<code>Tensor</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="layer_category_encoding_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding">https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding/">https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding/</a>
</p>
</li></ul>

<p>Other categorical features preprocessing layers: 
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_center_crop'>Crop the central portion of the images to target height and width</h2><span id='topic+layer_center_crop'></span>

<h3>Description</h3>

<p>Crop the central portion of the images to target height and width
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_center_crop(object, height, width, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_center_crop_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_center_crop_+3A_height">height</code></td>
<td>
<p>Integer, the height of the output shape.</p>
</td></tr>
<tr><td><code id="layer_center_crop_+3A_width">width</code></td>
<td>
<p>Integer, the width of the output shape.</p>
</td></tr>
<tr><td><code id="layer_center_crop_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format.
</p>
<p>Output shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., target_height, target_width, channels)&#8288;</code>.
</p>
<p>If the input height/width is even and the target height/width is odd (or
inversely), the input image is left-padded by 1 pixel.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop">https://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_preprocessing/center_crop">https://keras.io/api/layers/preprocessing_layers/image_preprocessing/center_crop</a>
</p>
</li></ul>

<p>Other image preprocessing layers: 
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_concatenate'>Layer that concatenates a list of inputs.</h2><span id='topic+layer_concatenate'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors, all of the same shape expect for the
concatenation axis, and returns a single tensor, the concatenation of all
inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_concatenate(inputs, ..., axis = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_concatenate_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_concatenate_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
<tr><td><code id="layer_concatenate_+3A_axis">axis</code></td>
<td>
<p>Concatenation axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the concatenation of the inputs alongside axis <code>axis</code>. If
<code>inputs</code> is missing, a keras layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate">https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/concatenate">https://keras.io/api/layers/merging_layers/concatenate</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_average">layer_average</a>()</code>,
<code><a href="#topic+layer_dot">layer_dot</a>()</code>,
<code><a href="#topic+layer_maximum">layer_maximum</a>()</code>,
<code><a href="#topic+layer_minimum">layer_minimum</a>()</code>,
<code><a href="#topic+layer_multiply">layer_multiply</a>()</code>,
<code><a href="#topic+layer_subtract">layer_subtract</a>()</code>
</p>

<hr>
<h2 id='layer_conv_1d'>1D convolution layer (e.g. temporal convolution).</h2><span id='topic+layer_conv_1d'></span>

<h3>Description</h3>

<p>This layer creates a convolution kernel that is convolved with the layer
input over a single spatial (or temporal) dimension to produce a tensor of
outputs. If <code>use_bias</code> is TRUE, a bias vector is created and added to the
outputs. Finally, if <code>activation</code> is not <code>NULL</code>, it is applied to the outputs
as well. When using this layer as the first layer in a model, provide an
<code>input_shape</code> argument (list of integers or <code>NULL </code>, e.g. <code style="white-space: pre;">&#8288;(10, 128)&#8288;</code> for
sequences of 10 vectors of 128-dimensional vectors, or <code style="white-space: pre;">&#8288;(NULL, 128)&#8288;</code> for
variable-length sequences of 128-dimensional vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_1d(
  object,
  filters,
  kernel_size,
  strides = 1L,
  padding = "valid",
  data_format = "channels_last",
  dilation_rate = 1L,
  groups = 1L,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of a single integer, specifying the
length of the 1D convolution window.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of a single integer, specifying the stride
length of the convolution. Specifying any stride value != 1 is incompatible
with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code>, <code>"causal"</code> or <code>"same"</code> (case-insensitive).
<code>"valid"</code> means &quot;no padding&quot;.
<code>"same"</code> results in padding the input such that the output has the same
length as the original input.
<code>"causal"</code> results in causal (dilated) convolutions, e.g. <code>output[t]</code> does
not depend on <code style="white-space: pre;">&#8288;input[t+1:]&#8288;</code>. Useful when modeling temporal data where the
model should not violate the temporal order. See <a href="https://arxiv.org/abs/1609.03499">WaveNet: A Generative Model for Raw Audio, section 2.1</a>.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>"channels_last"</code> (default) or <code>"channels_first"</code>.
The ordering of the dimensions in the inputs. <code>"channels_last"</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, length, channels)&#8288;</code> (default format for
temporal data in Keras) while <code>"channels_first"</code> corresponds to inputs
with shape <code style="white-space: pre;">&#8288;(batch, channels, length)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of a single integer, specifying the
dilation rate to use for dilated convolution. Currently, specifying any
<code>dilation_rate</code> value != 1 is incompatible with specifying any <code>strides</code>
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_groups">groups</code></td>
<td>
<p>A positive integer specifying the number of groups in which the
input is split along the channel axis. Each group is convolved separately
with <code>filters / groups</code> filters. The output is the concatenation of all the
groups results along the channel axis. Input channels and <code>filters</code> must both
be divisible by <code>groups</code>.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, steps, input_dim)&#8288;</code>
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, new_steps, filters)&#8288;</code> <code>steps</code> value might have changed due to padding or strides.
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_1d_transpose'>Transposed 1D convolution layer (sometimes called Deconvolution).</h2><span id='topic+layer_conv_1d_transpose'></span>

<h3>Description</h3>

<p>The need for transposed convolutions generally arises from the desire to use
a transformation going in the opposite direction of a normal convolution,
i.e., from something that has the shape of the output of some convolution to
something that has the shape of its input while maintaining a connectivity
pattern that is compatible with said convolution.
When using this layer as the first layer in a model,
provide the keyword argument <code>input_shape</code>
(tuple of integers, does not include the sample axis),
e.g. <code style="white-space: pre;">&#8288;input_shape=(128, 3)&#8288;</code> for data with 128 time steps and 3 channels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_1d_transpose(
  object,
  filters,
  kernel_size,
  strides = 1,
  padding = "valid",
  output_padding = NULL,
  data_format = NULL,
  dilation_rate = 1,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_1d_transpose_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of a single integer, specifying the
length of the 1D convolution window.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_strides">strides</code></td>
<td>
<p>An integer or list of a single integer, specifying the stride
length of the convolution. Specifying any stride value != 1 is incompatible
with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_output_padding">output_padding</code></td>
<td>
<p>An integer specifying the amount of padding along
the time dimension of the output tensor.
The amount of output padding must be lower than the stride.
If set to <code>NULL</code> (default), the output shape is inferred.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>"channels_last"</code> (default) or <code>"channels_first"</code>.
The ordering of the dimensions in the inputs. <code>"channels_last"</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, length, channels)&#8288;</code> (default format for
temporal data in Keras) while <code>"channels_first"</code> corresponds to inputs
with shape <code style="white-space: pre;">&#8288;(batch, channels, length)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of a single integer, specifying the
dilation rate to use for dilated convolution. Currently, specifying any
<code>dilation_rate</code> value != 1 is incompatible with specifying any <code>strides</code>
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_1d_transpose_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, steps, channels)&#8288;</code>
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, new_steps, filters)&#8288;</code>
If <code>output_padding</code> is specified:
</p>
<div class="sourceCode"><pre>new_timesteps = ((timesteps - 1) * strides + kernel_size - 2 * padding + output_padding)
</pre></div>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1603.07285v1">A guide to convolution arithmetic for deep learning</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_2d'>2D convolution layer (e.g. spatial convolution over images).</h2><span id='topic+layer_conv_2d'></span>

<h3>Description</h3>

<p>This layer creates a convolution kernel that is convolved with the layer
input to produce a tensor of outputs. If <code>use_bias</code> is TRUE, a bias vector is
created and added to the outputs. Finally, if <code>activation</code> is not <code>NULL</code>, it
is applied to the outputs as well. When using this layer as the first layer
in a model, provide the keyword argument <code>input_shape</code> (list of integers,
does not include the sample axis), e.g. <code>input_shape=c(128, 128, 3)</code> for
128x128 RGB pictures in <code>data_format="channels_last"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_2d(
  object,
  filters,
  kernel_size,
  strides = c(1L, 1L),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1L, 1L),
  groups = 1L,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 2 integers, specifying the width and
height of the 2D convolution window. Can be a single integer to specify the
same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 2 integers, specifying the strides of
the convolution along the width and height. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive). Note that <code>"same"</code>
is slightly inconsistent across backends with <code>strides</code> != 1, as described
<a href="https://github.com/keras-team/keras/pull/9473#issuecomment-372166860">here</a></p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of 2 integers, specifying the
dilation rate to use for dilated convolution. Can be a single integer to
specify the same value for all spatial dimensions. Currently, specifying
any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_groups">groups</code></td>
<td>
<p>A positive integer specifying the number of groups in which the
input is split along the channel axis. Each group is convolved separately
with <code>filters / groups</code> filters. The output is the concatenation of all the
groups results along the channel axis. Input channels and <code>filters</code> must both
be divisible by <code>groups</code>.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, channels, rows, cols)&#8288;</code>
if data_format='channels_first' or 4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, rows, cols, channels)&#8288;</code> if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, filters, new_rows, new_cols)&#8288;</code> if data_format='channels_first' or 4D tensor with shape:
<code style="white-space: pre;">&#8288;(samples, new_rows, new_cols, filters)&#8288;</code> if data_format='channels_last'.
<code>rows</code> and <code>cols</code> values might have changed due to padding.
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_2d_transpose'>Transposed 2D convolution layer (sometimes called Deconvolution).</h2><span id='topic+layer_conv_2d_transpose'></span>

<h3>Description</h3>

<p>The need for transposed convolutions generally arises from the desire to use
a transformation going in the opposite direction of a normal convolution,
i.e., from something that has the shape of the output of some convolution to
something that has the shape of its input while maintaining a connectivity
pattern that is compatible with said convolution. When using this layer as
the first layer in a model, provide the keyword argument <code>input_shape</code> (list
of integers, does not include the sample axis), e.g. <code>input_shape=c(128L, 128L, 3L)</code> for 128x128 RGB pictures in <code>data_format="channels_last"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_2d_transpose(
  object,
  filters,
  kernel_size,
  strides = c(1, 1),
  padding = "valid",
  output_padding = NULL,
  data_format = NULL,
  dilation_rate = c(1, 1),
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_2d_transpose_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 2 integers, specifying the width and
height of the 2D convolution window. Can be a single integer to specify the
same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 2 integers, specifying the strides of
the convolution along the width and height. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_output_padding">output_padding</code></td>
<td>
<p>An integer or list of 2 integers,
specifying the amount of padding along the height and width
of the output tensor. Can be a single integer to specify the same
value for all spatial dimensions. The amount of output padding along a
given dimension must be lower than the stride along that same dimension.
If set to <code>NULL</code> (default), the output shape is inferred.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>Dialation rate.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_2d_transpose_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(batch, channels, rows, cols)&#8288;</code>
if data_format='channels_first' or 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch, rows, cols, channels)&#8288;</code> if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(batch, filters, new_rows, new_cols)&#8288;</code> if data_format='channels_first' or 4D tensor with shape:
<code style="white-space: pre;">&#8288;(batch, new_rows, new_cols, filters)&#8288;</code> if data_format='channels_last'.
<code>rows</code> and <code>cols</code> values might have changed due to padding.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1603.07285v1">A guide to convolution arithmetic for deep learning</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_3d'>3D convolution layer (e.g. spatial convolution over volumes).</h2><span id='topic+layer_conv_3d'></span>

<h3>Description</h3>

<p>This layer creates a convolution kernel that is convolved with the layer
input to produce a tensor of outputs. If <code>use_bias</code> is TRUE, a bias vector is
created and added to the outputs. Finally, if <code>activation</code> is not <code>NULL</code>, it
is applied to the outputs as well. When using this layer as the first layer
in a model, provide the keyword argument <code>input_shape</code> (list of integers,
does not include the sample axis), e.g. <code>input_shape=c(128L, 128L, 128L, 3L)</code>
for 128x128x128 volumes with a single channel, in
<code>data_format="channels_last"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_3d(
  object,
  filters,
  kernel_size,
  strides = c(1L, 1L, 1L),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1L, 1L, 1L),
  groups = 1L,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 3 integers, specifying the depth,
height, and width of the 3D convolution window. Can be a single integer
to specify the same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 3 integers, specifying the strides of
the convolution along each spatial dimension. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of 3 integers, specifying the
dilation rate to use for dilated convolution. Can be a single integer to
specify the same value for all spatial dimensions. Currently, specifying
any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_groups">groups</code></td>
<td>
<p>A positive integer specifying the number of groups in which the
input is split along the channel axis. Each group is convolved separately
with <code>filters / groups</code> filters. The output is the concatenation of all the
groups results along the channel axis. Input channels and <code>filters</code> must both
be divisible by <code>groups</code>.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>5D tensor with shape: <code style="white-space: pre;">&#8288;(samples, channels, conv_dim1, conv_dim2, conv_dim3)&#8288;</code> if data_format='channels_first' or 5D tensor with
shape: <code style="white-space: pre;">&#8288;(samples, conv_dim1, conv_dim2, conv_dim3, channels)&#8288;</code> if
data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>5D tensor with shape: <code style="white-space: pre;">&#8288;(samples, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)&#8288;</code> if
data_format='channels_first' or 5D tensor with shape: <code style="white-space: pre;">&#8288;(samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)&#8288;</code> if
data_format='channels_last'. <code>new_conv_dim1</code>, <code>new_conv_dim2</code> and
<code>new_conv_dim3</code> values might have changed due to padding.
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_3d_transpose'>Transposed 3D convolution layer (sometimes called Deconvolution).</h2><span id='topic+layer_conv_3d_transpose'></span>

<h3>Description</h3>

<p>The need for transposed convolutions generally arises from the desire to use
a transformation going in the opposite direction of a normal convolution,
i.e., from something that has the shape of the output of some convolution to
something that has the shape of its input while maintaining a connectivity
pattern that is compatible with said convolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_3d_transpose(
  object,
  filters,
  kernel_size,
  strides = c(1, 1, 1),
  padding = "valid",
  output_padding = NULL,
  data_format = NULL,
  dilation_rate = c(1L, 1L, 1L),
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_3d_transpose_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 3 integers, specifying the depth,
height, and width of the 3D convolution window. Can be a single integer
to specify the same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 3 integers, specifying the strides of
the convolution along the depth, height and width.. Can be a single integer
to specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_output_padding">output_padding</code></td>
<td>
<p>An integer or list of 3 integers,
specifying the amount of padding along the depth, height, and width
of the output tensor. Can be a single integer to specify the same
value for all spatial dimensions. The amount of output padding along a
given dimension must be lower than the stride along that same dimension.
If set to <code>NULL</code> (default), the output shape is inferred.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, depth, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape
<code style="white-space: pre;">&#8288;(batch, channels, depth, height, width)&#8288;</code>. It defaults to the
<code>image_data_format</code> value found in your Keras config file at
<code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it will be
&quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>An integer or vector of 3 integers, specifying the
dilation rate to use for dilated convolution. Can be a single integer to
specify the same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything, no
activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix,</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;).</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_3d_transpose_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using this layer as the first layer in a model, provide the keyword argument
<code>input_shape</code> (list of integers, does not include the sample axis), e.g.
<code>input_shape = list(128, 128, 128, 3)</code> for a 128x128x128 volume with 3 channels if
<code>data_format="channels_last"</code>.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1603.07285v1">A guide to convolution arithmetic for deep learning</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_lstm_1d'>1D Convolutional LSTM</h2><span id='topic+layer_conv_lstm_1d'></span>

<h3>Description</h3>

<p>1D Convolutional LSTM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_lstm_1d(
  object,
  filters,
  kernel_size,
  strides = 1L,
  padding = "valid",
  data_format = NULL,
  dilation_rate = 1L,
  activation = "tanh",
  recurrent_activation = "hard_sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_lstm_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the number of
output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of n integers, specifying the
dimensions of the convolution window.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of n integers, specifying the strides of
the convolution. Specifying any stride value != 1 is incompatible with
specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive). <code>"valid"</code> means no
padding. <code>"same"</code> results in padding evenly to the left/right or up/down
of the input such that output has the same height/width dimension as the
input.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, time, ..., channels)&#8288;</code> while <code>channels_first</code>
corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, time, channels, ...)&#8288;</code>. It
defaults to the <code>image_data_format</code> value found in your Keras config file
at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it will be
&quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>An integer or list of n integers, specifying the
dilation rate to use for dilated convolution. Currently, specifying any
<code>dilation_rate</code> value != 1 is incompatible with specifying any <code>strides</code>
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. By default hyperbolic tangent
activation function is applied (<code>tanh(x)</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent step.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used for
the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean. If TRUE, add 1 to the bias of the forget gate at
initialization. Use in combination with <code>bias_initializer="zeros"</code>. This
is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al., 2015</a></p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the <code>recurrent_kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the output
sequence, or the full sequence. (default FALSE)</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_return_state">return_state</code></td>
<td>
<p>Boolean Whether to return the last state in addition to the
output. (default FALSE)</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, process the input sequence
backwards.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each sample
at index i in a batch will be used as initial state for the sample of
index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear
transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for
the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_1d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to an LSTM layer, but the input transformations
and recurrent transformations are both convolutional.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM1D">https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM1D</a>
</p>
</li></ul>


<hr>
<h2 id='layer_conv_lstm_2d'>Convolutional LSTM.</h2><span id='topic+layer_conv_lstm_2d'></span>

<h3>Description</h3>

<p>It is similar to an LSTM layer, but the input transformations and recurrent
transformations are both convolutional.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_lstm_2d(
  object,
  filters,
  kernel_size,
  strides = c(1L, 1L),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1L, 1L),
  activation = "tanh",
  recurrent_activation = "hard_sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  dropout = 0,
  recurrent_dropout = 0,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL,
  input_shape = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_lstm_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of n integers, specifying the
dimensions of the convolution window.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of n integers, specifying the strides of
the convolution. Specifying any stride value != 1 is incompatible with
specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, time, ..., channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, time, channels, ...)&#8288;</code>. It defaults to the <code>image_data_format</code> value found
in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it,
then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>An integer or list of n integers, specifying the
dilation rate to use for dilated convolution. Currently, specifying any
<code>dilation_rate</code> value != 1 is incompatible with specifying any <code>strides</code>
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent
step.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs..</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state..</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean. If TRUE, add 1 to the bias of the forget
gate at initialization. Use in combination with <code>bias_initializer="zeros"</code>.
This is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al.</a></p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_return_state">return_state</code></td>
<td>
<p>Boolean. Whether to return the last state in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, rocess the input
sequence backwards.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop
for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_2d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> if data_format='channels_first' 5D tensor with shape:
<code style="white-space: pre;">&#8288;(samples,time, channels, rows, cols)&#8288;</code>
</p>

<ul>
<li><p> if data_format='channels_last' 5D
tensor with shape: <code style="white-space: pre;">&#8288;(samples,time, rows, cols, channels)&#8288;</code>
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1506.04214v1">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</a>
The current implementation does not include the feedback loop on the cells
output
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_conv_lstm_3d'>3D Convolutional LSTM</h2><span id='topic+layer_conv_lstm_3d'></span>

<h3>Description</h3>

<p>3D Convolutional LSTM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_conv_lstm_3d(
  object,
  filters,
  kernel_size,
  strides = c(1L, 1L, 1L),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1L, 1L, 1L),
  activation = "tanh",
  recurrent_activation = "hard_sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_conv_lstm_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the number of
output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of n integers, specifying the
dimensions of the convolution window.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of n integers, specifying the strides of
the convolution. Specifying any stride value != 1 is incompatible with
specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive). <code>"valid"</code> means no
padding. <code>"same"</code> results in padding evenly to the left/right or up/down
of the input such that output has the same height/width dimension as the
input.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, time, ..., channels)&#8288;</code> while <code>channels_first</code>
corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, time, channels, ...)&#8288;</code>. It
defaults to the <code>image_data_format</code> value found in your Keras config file
at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it will be
&quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>An integer or list of n integers, specifying the
dilation rate to use for dilated convolution. Currently, specifying any
<code>dilation_rate</code> value != 1 is incompatible with specifying any <code>strides</code>
value != 1.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. By default hyperbolic tangent
activation function is applied (<code>tanh(x)</code>).</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent step.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used for
the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean. If TRUE, add 1 to the bias of the forget gate at
initialization. Use in combination with <code>bias_initializer="zeros"</code>. This
is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al., 2015</a></p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the <code>recurrent_kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the output
sequence, or the full sequence. (default FALSE)</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_return_state">return_state</code></td>
<td>
<p>Boolean Whether to return the last state in addition to the
output. (default FALSE)</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, process the input sequence
backwards.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each sample
at index i in a batch will be used as initial state for the sample of
index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear
transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for
the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_conv_lstm_3d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to an LSTM layer, but the input transformations
and recurrent transformations are both convolutional.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D">https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D</a>
</p>
</li></ul>


<hr>
<h2 id='layer_cropping_1d'>Cropping layer for 1D input (e.g. temporal sequence).</h2><span id='topic+layer_cropping_1d'></span>

<h3>Description</h3>

<p>It crops along the time dimension (axis 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_cropping_1d(
  object,
  cropping = c(1L, 1L),
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_cropping_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cropping_1d_+3A_cropping">cropping</code></td>
<td>
<p>int or list of int (length 2) How many units should be
trimmed off at the beginning and end of the cropping dimension (axis 1). If
a single int is provided, the same value will be used for both.</p>
</td></tr>
<tr><td><code id="layer_cropping_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_cropping_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_cropping_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_cropping_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape <code style="white-space: pre;">&#8288;(batch, axis_to_crop, features)&#8288;</code>
</p>


<h3>Output shape</h3>

<p>3D tensor with shape <code style="white-space: pre;">&#8288;(batch, cropped_axis, features)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_cropping_2d'>Cropping layer for 2D input (e.g. picture).</h2><span id='topic+layer_cropping_2d'></span>

<h3>Description</h3>

<p>It crops along spatial dimensions, i.e. width and height.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_cropping_2d(
  object,
  cropping = list(c(0L, 0L), c(0L, 0L)),
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_cropping_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cropping_2d_+3A_cropping">cropping</code></td>
<td>
<p>int, or list of 2 ints, or list of 2 lists of 2 ints.
</p>

<ul>
<li><p> If int: the same symmetric cropping is applied to width and height.
</p>
</li>
<li><p> If list of 2 ints: interpreted as two different symmetric cropping values for
height and width: <code style="white-space: pre;">&#8288;(symmetric_height_crop, symmetric_width_crop)&#8288;</code>.
</p>
</li>
<li><p> If list of 2 lists of 2 ints: interpreted as <code style="white-space: pre;">&#8288;((top_crop, bottom_crop), (left_crop,   right_crop))&#8288;</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cropping_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_cropping_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_cropping_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_cropping_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_cropping_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>4D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, cropped_rows, cropped_cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, cropped_rows, cropped_cols)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_cropping_3d'>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</h2><span id='topic+layer_cropping_3d'></span>

<h3>Description</h3>

<p>Cropping layer for 3D data (e.g. spatial or spatio-temporal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_cropping_3d(
  object,
  cropping = list(c(1L, 1L), c(1L, 1L), c(1L, 1L)),
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_cropping_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cropping_3d_+3A_cropping">cropping</code></td>
<td>
<p>int, or list of 3 ints, or list of 3 lists of 2 ints.
</p>

<ul>
<li><p> If int: the same symmetric cropping
is applied to depth, height, and width.
</p>
</li>
<li><p> If list of 3 ints:
interpreted as two different
symmetric cropping values for depth, height, and width:
<code style="white-space: pre;">&#8288;(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)&#8288;</code>.
</p>
</li>
<li><p> If list of 3 list of 2 ints:
interpreted as
<code style="white-space: pre;">&#8288;((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop))&#8288;</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cropping_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_cropping_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_cropping_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_cropping_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_cropping_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>5D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop, depth)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>:
<code style="white-space: pre;">&#8288;(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>5D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, first_cropped_axis, second_cropped_axis, third_cropped_axis, depth)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_cudnn_gru'>(Deprecated) Fast GRU implementation backed by <a href="https://developer.nvidia.com/cudnn">CuDNN</a>.</h2><span id='topic+layer_cudnn_gru'></span>

<h3>Description</h3>

<p>Can only be run on GPU, with the TensorFlow backend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_cudnn_gru(
  object,
  units,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  stateful = FALSE,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_cudnn_gru_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_return_state">return_state</code></td>
<td>
<p>Boolean (default FALSE). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_cudnn_gru_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1412.3555v1">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_lstm">layer_cudnn_lstm</a>()</code>,
<code><a href="#topic+layer_gru">layer_gru</a>()</code>,
<code><a href="#topic+layer_lstm">layer_lstm</a>()</code>,
<code><a href="#topic+layer_rnn">layer_rnn</a>()</code>,
<code><a href="#topic+layer_simple_rnn">layer_simple_rnn</a>()</code>
</p>

<hr>
<h2 id='layer_cudnn_lstm'>(Deprecated) Fast LSTM implementation backed by <a href="https://developer.nvidia.com/cudnn">CuDNN</a>.</h2><span id='topic+layer_cudnn_lstm'></span>

<h3>Description</h3>

<p>Can only be run on GPU, with the TensorFlow backend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_cudnn_lstm(
  object,
  units,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  stateful = FALSE,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_cudnn_lstm_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean. If TRUE, add 1 to the bias of the forget
gate at initialization. Setting it to true will also force
<code>bias_initializer="zeros"</code>. This is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al.</a></p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_return_state">return_state</code></td>
<td>
<p>Boolean (default FALSE). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_cudnn_lstm_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li> <p><a href="http://www.bioinf.jku.at/publications/older/2604.pdf">Long short-term memory</a> (original 1997 paper)
</p>
</li>
<li> <p><a href="https://www.cs.toronto.edu/~graves/preprint.pdf">Supervised sequence labeling with recurrent neural networks</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_gru">layer_cudnn_gru</a>()</code>,
<code><a href="#topic+layer_gru">layer_gru</a>()</code>,
<code><a href="#topic+layer_lstm">layer_lstm</a>()</code>,
<code><a href="#topic+layer_rnn">layer_rnn</a>()</code>,
<code><a href="#topic+layer_simple_rnn">layer_simple_rnn</a>()</code>
</p>

<hr>
<h2 id='layer_dense'>Add a densely-connected NN layer to an output</h2><span id='topic+layer_dense'></span>

<h3>Description</h3>

<p>Implements the operation: <code>output = activation(dot(input, kernel) + bias)</code>
where <code>activation</code> is the element-wise activation function passed as the
<code>activation</code> argument, <code>kernel</code> is a weights matrix created by the layer, and
<code>bias</code> is a bias vector created by the layer (only applicable if <code>use_bias</code>
is <code>TRUE</code>). Note: if the input to the layer has a rank greater than 2, then
it is flattened prior to the initial dot product with <code>kernel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_dense(
  object,
  units,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_dense_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_dense_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_activation">activation</code></td>
<td>
<p>Name of activation function to use. If you don't specify
anything, no activation is applied (ie. &quot;linear&quot; activation: a(x) = x).</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_use_bias">use_bias</code></td>
<td>
<p>Whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_dense_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input and Output Shapes</h3>

<p>Input shape: nD tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, ..., input_dim)&#8288;</code>. The most
common situation would be a 2D input with shape <code style="white-space: pre;">&#8288;(batch_size, input_dim)&#8288;</code>.
</p>
<p>Output shape: nD tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, ..., units)&#8288;</code>. For
instance, for a 2D input with shape <code style="white-space: pre;">&#8288;(batch_size, input_dim)&#8288;</code>, the output
would have shape <code style="white-space: pre;">&#8288;(batch_size, unit)&#8288;</code>.
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_dense_features'>Constructs a DenseFeatures.</h2><span id='topic+layer_dense_features'></span>

<h3>Description</h3>

<p>A layer that produces a dense Tensor based on given feature_columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_dense_features(
  object,
  feature_columns,
  name = NULL,
  trainable = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_dense_features_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An iterable containing the FeatureColumns to use as
inputs to your model. All items should be instances of classes derived from
<code>DenseColumn</code> such as <code>numeric_column</code>, <code>embedding_column</code>, <code>bucketized_column</code>,
<code>indicator_column</code>. If you have categorical features, you can wrap them with an
<code>embedding_column</code> or <code>indicator_column</code>. See <code>tfestimators::feature_columns()</code>.</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_dense_features_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_depthwise_conv_1d'>Depthwise 1D convolution</h2><span id='topic+layer_depthwise_conv_1d'></span>

<h3>Description</h3>

<p>Depthwise 1D convolution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_depthwise_conv_1d(
  object,
  kernel_size,
  strides = 1L,
  padding = "valid",
  depth_multiplier = 1L,
  data_format = NULL,
  dilation_rate = 1L,
  activation = NULL,
  use_bias = TRUE,
  depthwise_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  depthwise_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  depthwise_constraint = NULL,
  bias_constraint = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_depthwise_conv_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer, specifying the height and width of the 1D
convolution window. Can be a single integer to specify the same value for
all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_strides">strides</code></td>
<td>
<p>An integer, specifying the strides of the convolution along the
height and width. Can be a single integer to specify the same value for
all spatial dimensions. Specifying any stride value != 1 is incompatible
with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_padding">padding</code></td>
<td>
<p>one of <code>'valid'</code> or <code>'same'</code> (case-insensitive). <code>"valid"</code> means no
padding. <code>"same"</code> results in padding with zeros evenly to the left/right
or up/down of the input such that output has the same height/width
dimension as the input.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_depth_multiplier">depth_multiplier</code></td>
<td>
<p>The number of depthwise convolution output channels for
each input channel. The total number of depthwise convolution output
channels will be equal to <code>filters_in * depth_multiplier</code>.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>"channels_last"</code> (default) or <code>"channels_first"</code>.
The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch_size, height, width, channels)&#8288;</code> while
<code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch_size, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in
your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then
it will be 'channels_last'.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>A single integer, specifying the dilation rate to use for
dilated convolution. Currently, specifying any <code>dilation_rate</code> value != 1
is incompatible with specifying any stride value != 1.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything, no
activation is applied (see <code>?activation_relu</code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_depthwise_initializer">depthwise_initializer</code></td>
<td>
<p>Initializer for the depthwise kernel matrix (see
<code><a href="#topic+initializer_glorot_uniform">initializer_glorot_uniform</a></code>). If NULL, the default initializer
(<code>"glorot_uniform"</code>) will be used.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector (see
<code>keras.initializers</code>). If NULL, the default initializer ('zeros') will be
used.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_depthwise_regularizer">depthwise_regularizer</code></td>
<td>
<p>Regularizer function applied to the depthwise kernel
matrix (see  <code><a href="#topic+regularizer_l1">regularizer_l1()</a></code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector (see
<code><a href="#topic+regularizer_l1">regularizer_l1()</a></code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its 'activation') (see  <code><a href="#topic+regularizer_l1">regularizer_l1()</a></code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_depthwise_constraint">depthwise_constraint</code></td>
<td>
<p>Constraint function applied to the depthwise kernel
matrix (see <code><a href="#topic+constraint_maxnorm">constraint_maxnorm()</a></code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector (see
<code><a href="#topic+constraint_maxnorm">constraint_maxnorm()</a></code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_1d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depthwise convolution is a type of convolution in which each input channel is
convolved with a different kernel (called a depthwise kernel). You
can understand depthwise convolution as the first step in a depthwise
separable convolution.
</p>
<p>It is implemented via the following steps:
</p>

<ul>
<li><p> Split the input into individual channels.
</p>
</li>
<li><p> Convolve each channel with an individual depthwise kernel with
<code>depth_multiplier</code> output channels.
</p>
</li>
<li><p> Concatenate the convolved outputs along the channels axis.
</p>
</li></ul>

<p>Unlike a regular 1D convolution, depthwise convolution does not mix
information across different input channels.
</p>
<p>The <code>depth_multiplier</code> argument determines how many filter are applied to one
input channel. As such, it controls the amount of output channels that are
generated per input channel in the depthwise step.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv1D">https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv1D</a>
</p>
</li></ul>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_depthwise_conv_2d'>Depthwise separable 2D convolution.</h2><span id='topic+layer_depthwise_conv_2d'></span>

<h3>Description</h3>

<p>Depthwise Separable convolutions consists in performing just the first step
in a depthwise spatial convolution (which acts on each input channel
separately). The <code>depth_multiplier</code> argument controls how many output
channels are generated per input channel in the depthwise step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_depthwise_conv_2d(
  object,
  kernel_size,
  strides = c(1, 1),
  padding = "valid",
  depth_multiplier = 1,
  data_format = NULL,
  dilation_rate = c(1, 1),
  activation = NULL,
  use_bias = TRUE,
  depthwise_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  depthwise_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  depthwise_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_depthwise_conv_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 2 integers, specifying the width and
height of the 2D convolution window. Can be a single integer to specify the
same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 2 integers, specifying the strides of
the convolution along the width and height. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_depth_multiplier">depth_multiplier</code></td>
<td>
<p>The number of depthwise convolution output channels
for each input channel. The total number of depthwise convolution output
channels will be equal to <code>filters_in * depth_multiplier</code>.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of 2 integers, specifying the
dilation rate to use for dilated convolution. Can be a single integer to
specify the same value for all spatial dimensions. Currently, specifying
any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride
value != 1.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_depthwise_initializer">depthwise_initializer</code></td>
<td>
<p>Initializer for the depthwise kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_depthwise_regularizer">depthwise_regularizer</code></td>
<td>
<p>Regularizer function applied to the depthwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_depthwise_constraint">depthwise_constraint</code></td>
<td>
<p>Constraint function applied to the depthwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_depthwise_conv_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_discretization'>A preprocessing layer which buckets continuous features by ranges.</h2><span id='topic+layer_discretization'></span>

<h3>Description</h3>

<p>A preprocessing layer which buckets continuous features by ranges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_discretization(
  object,
  bin_boundaries = NULL,
  num_bins = NULL,
  epsilon = 0.01,
  output_mode = "int",
  sparse = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_discretization_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_discretization_+3A_bin_boundaries">bin_boundaries</code></td>
<td>
<p>A list of bin boundaries. The leftmost and rightmost bins
will always extend to <code>-Inf</code> and <code>Inf</code>, so <code>bin_boundaries = c(0., 1., 2.)</code>
generates bins <code style="white-space: pre;">&#8288;(-Inf, 0.)&#8288;</code>, <code style="white-space: pre;">&#8288;[0., 1.)&#8288;</code>, <code style="white-space: pre;">&#8288;[1., 2.)&#8288;</code>, and <code style="white-space: pre;">&#8288;[2., +Inf)&#8288;</code>. If
this option is set, <code>adapt</code> should not be called.</p>
</td></tr>
<tr><td><code id="layer_discretization_+3A_num_bins">num_bins</code></td>
<td>
<p>The integer number of bins to compute. If this option is set,
<code>adapt</code> should be called to learn the bin boundaries.</p>
</td></tr>
<tr><td><code id="layer_discretization_+3A_epsilon">epsilon</code></td>
<td>
<p>Error tolerance, typically a small fraction close to zero (e.g.
0.01). Higher values of epsilon increase the quantile approximation, and
hence result in more unequal buckets, but could improve performance
and resource consumption.</p>
</td></tr>
<tr><td><code id="layer_discretization_+3A_output_mode">output_mode</code></td>
<td>
<p>Specification for the output of the layer. Defaults to
<code>"int"</code>.  Values can be <code>"int"</code>, <code>"one_hot"</code>, <code>"multi_hot"</code>, or
<code>"count"</code> configuring the layer as follows:
</p>

<ul>
<li> <p><code>"int"</code>: Return the discretized bin indices directly.
</p>
</li>
<li> <p><code>"one_hot"</code>: Encodes each individual element in the input into an
array the same size as <code>num_bins</code>, containing a 1 at the input's bin
index. If the last dimension is size 1, will encode on that
dimension.  If the last dimension is not size 1, will append a new
dimension for the encoded output.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Encodes each sample in the input into a single array
the same size as <code>num_bins</code>, containing a 1 for each bin index
index present in the sample. Treats the last dimension as the sample
dimension, if input shape is <code style="white-space: pre;">&#8288;(..., sample_length)&#8288;</code>, output shape
will be <code style="white-space: pre;">&#8288;(..., num_tokens)&#8288;</code>.
</p>
</li>
<li> <p><code>"count"</code>: As <code>"multi_hot"</code>, but the int array contains a count of
the number of times the bin index appeared in the sample.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_discretization_+3A_sparse">sparse</code></td>
<td>
<p>Boolean. Only applicable to <code>"one_hot"</code>, <code>"multi_hot"</code>,
and <code>"count"</code> output modes. If <code>TRUE</code>, returns a <code>SparseTensor</code> instead of
a dense <code>Tensor</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="layer_discretization_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer will place each element of its input data into one of several
contiguous ranges and output an integer index indicating which range each
element was placed in.
</p>
<p>Input shape:
Any <code>tf.Tensor</code> or <code>tf.RaggedTensor</code> of dimension 2 or higher.
</p>
<p>Output shape:
Same as input shape.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+adapt">adapt()</a></code>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Discretization">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Discretization</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/numerical/discretization">https://keras.io/api/layers/preprocessing_layers/numerical/discretization</a>
</p>
</li></ul>

<p>Other numerical features preprocessing layers: 
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_dot'>Layer that computes a dot product between samples in two tensors.</h2><span id='topic+layer_dot'></span>

<h3>Description</h3>

<p>Layer that computes a dot product between samples in two tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_dot(inputs, ..., axes, normalize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_dot_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_dot_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
<tr><td><code id="layer_dot_+3A_axes">axes</code></td>
<td>
<p>Integer or list of integers, axis or axes along which to take the
dot product.</p>
</td></tr>
<tr><td><code id="layer_dot_+3A_normalize">normalize</code></td>
<td>
<p>Whether to L2-normalize samples along the dot product axis
before taking the dot product. If set to TRUE, then the output of the dot
product is the cosine proximity between the two samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>inputs</code> is supplied: A tensor, the dot product of the samples
from the inputs. If <code>inputs</code> is missing, a keras layer instance is
returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/dot">https://www.tensorflow.org/api_docs/python/tf/keras/layers/dot</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/dot/">https://keras.io/api/layers/merging_layers/dot/</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_average">layer_average</a>()</code>,
<code><a href="#topic+layer_concatenate">layer_concatenate</a>()</code>,
<code><a href="#topic+layer_maximum">layer_maximum</a>()</code>,
<code><a href="#topic+layer_minimum">layer_minimum</a>()</code>,
<code><a href="#topic+layer_multiply">layer_multiply</a>()</code>,
<code><a href="#topic+layer_subtract">layer_subtract</a>()</code>
</p>

<hr>
<h2 id='layer_dropout'>Applies Dropout to the input.</h2><span id='topic+layer_dropout'></span>

<h3>Description</h3>

<p>Dropout consists in randomly setting a fraction <code>rate</code> of input units to 0 at
each update during training time, which helps prevent overfitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_dropout(
  object,
  rate,
  noise_shape = NULL,
  seed = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_dropout_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_dropout_+3A_rate">rate</code></td>
<td>
<p>float between 0 and 1. Fraction of the input units to drop.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_noise_shape">noise_shape</code></td>
<td>
<p>1D integer tensor representing the shape of the binary
dropout mask that will be multiplied with the input. For instance, if your
inputs have shape <code style="white-space: pre;">&#8288;(batch_size, timesteps, features)&#8288;</code> and you want the
dropout mask to be the same for all timesteps, you can use
<code>noise_shape=c(batch_size, 1, features)</code>.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_seed">seed</code></td>
<td>
<p>integer to use as random seed.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_dropout_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>
<p>Other dropout layers: 
<code><a href="#topic+layer_spatial_dropout_1d">layer_spatial_dropout_1d</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_2d">layer_spatial_dropout_2d</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_3d">layer_spatial_dropout_3d</a>()</code>
</p>

<hr>
<h2 id='layer_embedding'>Turns positive integers (indexes) into dense vectors of fixed size</h2><span id='topic+layer_embedding'></span>

<h3>Description</h3>

<p>Turns positive integers (indexes) into dense vectors of fixed size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_embedding(
  object,
  input_dim,
  output_dim,
  embeddings_initializer = "uniform",
  embeddings_regularizer = NULL,
  activity_regularizer = NULL,
  embeddings_constraint = NULL,
  mask_zero = FALSE,
  input_length = NULL,
  sparse = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_embedding_+3A_object">object</code></td>
<td>
<p>Layer or Model object</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_input_dim">input_dim</code></td>
<td>
<p>Integer. Size of the vocabulary,
i.e. maximum integer index + 1.</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_output_dim">output_dim</code></td>
<td>
<p>Integer. Dimension of the dense embedding.</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_embeddings_initializer">embeddings_initializer</code></td>
<td>
<p>Initializer for the <code>embeddings</code>
matrix (see <code>keras.initializers</code>).</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_embeddings_regularizer">embeddings_regularizer</code>, <code id="layer_embedding_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to
the <code>embeddings</code> matrix or to the activations (see <code>keras.regularizers</code>).</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_embeddings_constraint">embeddings_constraint</code></td>
<td>
<p>Constraint function applied to
the <code>embeddings</code> matrix (see <code>keras.constraints</code>).</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_mask_zero">mask_zero</code></td>
<td>
<p>Boolean, whether or not the input value 0 is a special
&quot;padding&quot; value that should be masked out. This is useful when using
recurrent layers which may take variable length input. If this is
<code>TRUE</code>, then all subsequent layers in the model need to support masking
or an exception will be raised. If mask_zero is set to TRUE, as a
consequence, index 0 cannot be used in the vocabulary (input_dim should
equal size of vocabulary + 1).</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_input_length">input_length</code></td>
<td>
<p>Length of input sequences, when it is constant.
This argument is required if you are going to connect
<code>Flatten</code> then <code>Dense</code> layers upstream
(without it, the shape of the dense outputs cannot be computed).</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_sparse">sparse</code></td>
<td>
<p>If TRUE, calling this layer returns a <code>tf.SparseTensor</code>. If FALSE,
the layer returns a dense <code>tf.Tensor</code>. For an entry with no features in
a sparse tensor (entry with value 0), the embedding vector of index 0 is
returned by default.</p>
</td></tr>
<tr><td><code id="layer_embedding_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, <code>list(4L, 20L) -&gt; list(c(0.25, 0.1), c(0.6, -0.2))</code>.
</p>
<p>This layer can only be used on positive integer inputs of a fixed range. The
<code>layer_text_vectorization()</code>, <code>layer_string_lookup()</code>,
and <code>layer_integer_lookup()</code> preprocessing layers can help prepare
inputs for an <code>Embedding</code> layer.
</p>
<p>This layer accepts <code>tf.Tensor</code>, <code>tf.RaggedTensor</code> and <code>tf.SparseTensor</code>
input.
</p>


<h3>Input shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, sequence_length)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, sequence_length, output_dim)&#8288;</code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers">https://keras.io/api/layers</a>
</p>
</li></ul>


<hr>
<h2 id='layer_flatten'>Flattens an input</h2><span id='topic+layer_flatten'></span>

<h3>Description</h3>

<p>Flatten a given input, does not affect the batch size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_flatten(
  object,
  data_format = NULL,
  input_shape = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_flatten_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_flatten_+3A_data_format">data_format</code></td>
<td>
<p>A string. one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs. The purpose
of this argument is to preserve weight ordering when switching a model from
one data format to another. <code>channels_last</code> corresponds to inputs with
shape <code style="white-space: pre;">&#8288;(batch, ..., channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs
with shape <code style="white-space: pre;">&#8288;(batch, channels, ...)&#8288;</code>. It defaults to the <code>image_data_format</code>
value found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you
never set it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_flatten_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_flatten_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_flatten_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_flatten_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_flatten_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_gaussian_dropout'>Apply multiplicative 1-centered Gaussian noise.</h2><span id='topic+layer_gaussian_dropout'></span>

<h3>Description</h3>

<p>As it is a regularization layer, it is only active at training time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_gaussian_dropout(object, rate, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_gaussian_dropout_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_gaussian_dropout_+3A_rate">rate</code></td>
<td>
<p>float, drop probability (as with <code>Dropout</code>). The multiplicative
noise will have standard deviation <code>sqrt(rate / (1 - rate))</code>.</p>
</td></tr>
<tr><td><code id="layer_gaussian_dropout_+3A_seed">seed</code></td>
<td>
<p>Integer, optional random seed to enable deterministic behavior.</p>
</td></tr>
<tr><td><code id="layer_gaussian_dropout_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>Arbitrary. Use the keyword argument <code>input_shape</code> (list
of integers, does not include the samples axis) when using this layer as
the first layer in a model.
</p>


<h3>Output shape</h3>

<p>Same shape as input.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014</a>
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianDropout">https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianDropout</a>
</p>
</li></ul>

<p>Other noise layers: 
<code><a href="#topic+layer_alpha_dropout">layer_alpha_dropout</a>()</code>,
<code><a href="#topic+layer_gaussian_noise">layer_gaussian_noise</a>()</code>
</p>

<hr>
<h2 id='layer_gaussian_noise'>Apply additive zero-centered Gaussian noise.</h2><span id='topic+layer_gaussian_noise'></span>

<h3>Description</h3>

<p>This is useful to mitigate overfitting (you could see it as a form of random
data augmentation). Gaussian Noise (GS) is a natural choice as corruption
process for real valued inputs. As it is a regularization layer, it is only
active at training time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_gaussian_noise(object, stddev, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_gaussian_noise_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_gaussian_noise_+3A_stddev">stddev</code></td>
<td>
<p>float, standard deviation of the noise distribution.</p>
</td></tr>
<tr><td><code id="layer_gaussian_noise_+3A_seed">seed</code></td>
<td>
<p>Integer, optional random seed to enable deterministic behavior.</p>
</td></tr>
<tr><td><code id="layer_gaussian_noise_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>Arbitrary. Use the keyword argument <code>input_shape</code> (list
of integers, does not include the samples axis) when using this layer as
the first layer in a model.
</p>


<h3>Output shape</h3>

<p>Same shape as input.
</p>


<h3>See Also</h3>

<p>Other noise layers: 
<code><a href="#topic+layer_alpha_dropout">layer_alpha_dropout</a>()</code>,
<code><a href="#topic+layer_gaussian_dropout">layer_gaussian_dropout</a>()</code>
</p>

<hr>
<h2 id='layer_global_average_pooling_1d'>Global average pooling operation for temporal data.</h2><span id='topic+layer_global_average_pooling_1d'></span>

<h3>Description</h3>

<p>Global average pooling operation for temporal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_global_average_pooling_1d(
  object,
  data_format = "channels_last",
  keepdims = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_global_average_pooling_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_global_average_pooling_1d_+3A_data_format">data_format</code></td>
<td>
<p>One of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs.</p>
</td></tr>
<tr><td><code id="layer_global_average_pooling_1d_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the spatial dimensions or not. If
<code>keepdims</code> is <code>FALSE</code> (default), the rank of the tensor is reduced for
spatial dimensions. If <code>keepdims</code> is <code>TRUE</code>, the spatial dimensions are
retained with length 1. The behavior is the same as for <code>tf.reduce_mean</code> or
<code>np.mean</code>.</p>
</td></tr>
<tr><td><code id="layer_global_average_pooling_1d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, steps, features)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_global_average_pooling_2d'>Global average pooling operation for spatial data.</h2><span id='topic+layer_global_average_pooling_2d'></span>

<h3>Description</h3>

<p>Global average pooling operation for spatial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_global_average_pooling_2d(
  object,
  data_format = NULL,
  keepdims = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_global_average_pooling_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_global_average_pooling_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_global_average_pooling_2d_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the spatial dimensions or not. If
<code>keepdims</code> is <code>FALSE</code> (default), the rank of the tensor is reduced for
spatial dimensions. If <code>keepdims</code> is <code>TRUE</code>, the spatial dimensions are
retained with length 1. The behavior is the same as for <code>tf.reduce_mean</code> or
<code>np.mean</code>.</p>
</td></tr>
<tr><td><code id="layer_global_average_pooling_2d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_global_average_pooling_3d'>Global Average pooling operation for 3D data.</h2><span id='topic+layer_global_average_pooling_3d'></span>

<h3>Description</h3>

<p>Global Average pooling operation for 3D data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_global_average_pooling_3d(
  object,
  data_format = NULL,
  keepdims = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_global_average_pooling_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_global_average_pooling_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_global_average_pooling_3d_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the spatial dimensions or not. If
<code>keepdims</code> is <code>FALSE</code> (default), the rank of the tensor is reduced for
spatial dimensions. If <code>keepdims</code> is <code>TRUE</code>, the spatial dimensions are
retained with length 1. The behavior is the same as for <code>tf.reduce_mean</code> or
<code>np.mean</code>.</p>
</td></tr>
<tr><td><code id="layer_global_average_pooling_3d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_global_max_pooling_1d'>Global max pooling operation for temporal data.</h2><span id='topic+layer_global_max_pooling_1d'></span>

<h3>Description</h3>

<p>Global max pooling operation for temporal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_global_max_pooling_1d(
  object,
  data_format = "channels_last",
  keepdims = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_global_max_pooling_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_global_max_pooling_1d_+3A_data_format">data_format</code></td>
<td>
<p>One of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs.</p>
</td></tr>
<tr><td><code id="layer_global_max_pooling_1d_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the spatial dimensions or not. If
<code>keepdims</code> is <code>FALSE</code> (default), the rank of the tensor is reduced for
spatial dimensions. If <code>keepdims</code> is <code>TRUE</code>, the spatial dimensions are
retained with length 1. The behavior is the same as for <code>tf.reduce_mean</code> or
<code>np.mean</code>.</p>
</td></tr>
<tr><td><code id="layer_global_max_pooling_1d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, steps, features)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_global_max_pooling_2d'>Global max pooling operation for spatial data.</h2><span id='topic+layer_global_max_pooling_2d'></span>

<h3>Description</h3>

<p>Global max pooling operation for spatial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_global_max_pooling_2d(object, data_format = NULL, keepdims = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_global_max_pooling_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_global_max_pooling_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_global_max_pooling_2d_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the spatial dimensions or not. If
<code>keepdims</code> is <code>FALSE</code> (default), the rank of the tensor is reduced for
spatial dimensions. If <code>keepdims</code> is <code>TRUE</code>, the spatial dimensions are
retained with length 1. The behavior is the same as for <code>tf.reduce_mean</code> or
<code>np.mean</code>.</p>
</td></tr>
<tr><td><code id="layer_global_max_pooling_2d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_global_max_pooling_3d'>Global Max pooling operation for 3D data.</h2><span id='topic+layer_global_max_pooling_3d'></span>

<h3>Description</h3>

<p>Global Max pooling operation for 3D data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_global_max_pooling_3d(object, data_format = NULL, keepdims = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_global_max_pooling_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_global_max_pooling_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_global_max_pooling_3d_+3A_keepdims">keepdims</code></td>
<td>
<p>A boolean, whether to keep the spatial dimensions or not. If
<code>keepdims</code> is <code>FALSE</code> (default), the rank of the tensor is reduced for
spatial dimensions. If <code>keepdims</code> is <code>TRUE</code>, the spatial dimensions are
retained with length 1. The behavior is the same as for <code>tf.reduce_mean</code> or
<code>np.mean</code>.</p>
</td></tr>
<tr><td><code id="layer_global_max_pooling_3d_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>2D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_gru'>Gated Recurrent Unit - Cho et al.</h2><span id='topic+layer_gru'></span>

<h3>Description</h3>

<p>There are two variants. The default one is based on 1406.1078v3 and
has reset gate applied to hidden state before matrix multiplication. The
other one is based on original 1406.1078v1 and has the order reversed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_gru(
  object,
  units,
  activation = "tanh",
  recurrent_activation = "sigmoid",
  use_bias = TRUE,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  unroll = FALSE,
  time_major = FALSE,
  reset_after = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_gru_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_gru_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. Default: hyperbolic tangent
(<code>tanh</code>). If you pass <code>NULL</code>, no activation is applied
(ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent
step.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_return_state">return_state</code></td>
<td>
<p>Boolean (default FALSE). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, process the input
sequence backwards and return the reversed sequence.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_unroll">unroll</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the network will be unrolled,
else a symbolic loop will be used. Unrolling can speed-up a RNN, although
it tends to be more memory-intensive. Unrolling is only suitable for short
sequences.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_time_major">time_major</code></td>
<td>
<p>If True, the inputs and outputs will be in shape
<code style="white-space: pre;">&#8288;[timesteps, batch, feature]&#8288;</code>, whereas in the False case, it will be
<code style="white-space: pre;">&#8288;[batch, timesteps, feature]&#8288;</code>. Using <code>time_major = TRUE</code> is a bit more
efficient because it avoids transposes at the beginning and end of the RNN
calculation. However, most TensorFlow data is batch-major, so by default
this function accepts input and emits output in batch-major form.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_reset_after">reset_after</code></td>
<td>
<p>GRU convention (whether to apply reset gate after or
before matrix multiplication). FALSE = &quot;before&quot; (default),
TRUE = &quot;after&quot; (CuDNN compatible).</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop
for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_gru_+3A_...">...</code></td>
<td>
<p>Standard Layer args.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The second variant is compatible with CuDNNGRU (GPU-only) and allows
inference on CPU. Thus it has separate biases for <code>kernel</code> and
<code>recurrent_kernel</code>. Use <code>reset_after = TRUE</code> and
<code>recurrent_activation = "sigmoid"</code>.
</p>


<h3>Input shapes</h3>

<p>N-D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, timesteps, ...)&#8288;</code>,
or <code style="white-space: pre;">&#8288;(timesteps, batch_size, ...)&#8288;</code> when <code>time_major = TRUE</code>.
</p>


<h3>Output shape</h3>


<ul>
<li><p> if <code>return_state</code>: a list of tensors. The first tensor is
the output. The remaining tensors are the last states,
each with shape <code style="white-space: pre;">&#8288;(batch_size, state_size)&#8288;</code>, where <code>state_size</code>
could be a high dimension tensor shape.
</p>
</li>
<li><p> if <code>return_sequences</code>: N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, timesteps, output_size]&#8288;</code>, where <code>output_size</code> could be a high dimension tensor shape, or
<code style="white-space: pre;">&#8288;[timesteps, batch_size, output_size]&#8288;</code> when <code>time_major</code> is <code>TRUE</code>
</p>
</li>
<li><p> else, N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, output_size]&#8288;</code>, where
<code>output_size</code> could be a high dimension tensor shape.
</p>
</li></ul>



<h3>Masking</h3>

<p>This layer supports masking for input data with a variable number of
timesteps. To introduce masks to your data, use
<code><a href="#topic+layer_embedding">layer_embedding()</a></code> with the <code>mask_zero</code> parameter set to <code>TRUE</code>.
</p>


<h3>Statefulness in RNNs</h3>

<p>You can set RNN layers to be 'stateful', which means that the states computed
for the samples in one batch will be reused as initial states for the samples
in the next batch. This assumes a one-to-one mapping between samples in
different successive batches.
</p>
<p>For intuition behind statefulness, there is a helpful blog post here:
<a href="https://philipperemy.github.io/keras-stateful-lstm/">https://philipperemy.github.io/keras-stateful-lstm/</a>
</p>
<p>To enable statefulness:
</p>

<ul>
<li><p> Specify <code>stateful = TRUE</code> in the layer constructor.
</p>
</li>
<li><p> Specify a fixed batch size for your model. For sequential models,
pass <code>batch_input_shape = list(...)</code> to the first layer in your model.
For functional models with 1 or more Input layers, pass
<code>batch_shape = list(...)</code> to all the first layers in your model.
This is the expected shape of your inputs <em>including the batch size</em>.
It should be a list of integers, e.g. <code>list(32, 10, 100)</code>.
For dimensions which can vary (are not known ahead of time),
use <code>NULL</code> in place of an integer, e.g. <code>list(32, NULL, NULL)</code>.
</p>
</li>
<li><p> Specify <code>shuffle = FALSE</code> when calling <code>fit()</code>.
</p>
</li></ul>

<p>To reset the states of your model, call <code>layer$reset_states()</code> on either
a specific layer, or on your entire model.
</p>


<h3>Initial State of RNNs</h3>

<p>You can specify the initial state of RNN layers symbolically by calling them
with the keyword argument <code>initial_state.</code> The value of initial_state should
be a tensor or list of tensors representing the initial state of the RNN
layer.
</p>
<p>You can specify the initial state of RNN layers numerically by calling
<code>reset_states</code> with the named argument <code>states.</code> The value of <code>states</code> should
be an array or list of arrays representing the initial state of the RNN
layer.
</p>


<h3>Passing external constants to RNNs</h3>

<p>You can pass &quot;external&quot; constants to the cell using the <code>constants</code> named
argument of <code style="white-space: pre;">&#8288;RNN$__call__&#8288;</code> (as well as <code>RNN$call</code>) method. This requires that the
<code>cell$call</code> method accepts the same keyword argument <code>constants</code>. Such constants
can be used to condition the cell transformation on additional static inputs
(not changing over time), a.k.a. an attention mechanism.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1412.3555v1">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/guide/keras/rnn">https://www.tensorflow.org/guide/keras/rnn</a>
</p>
</li></ul>

<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_gru">layer_cudnn_gru</a>()</code>,
<code><a href="#topic+layer_cudnn_lstm">layer_cudnn_lstm</a>()</code>,
<code><a href="#topic+layer_lstm">layer_lstm</a>()</code>,
<code><a href="#topic+layer_rnn">layer_rnn</a>()</code>,
<code><a href="#topic+layer_simple_rnn">layer_simple_rnn</a>()</code>
</p>

<hr>
<h2 id='layer_gru_cell'>Cell class for the GRU layer</h2><span id='topic+layer_gru_cell'></span>

<h3>Description</h3>

<p>Cell class for the GRU layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_gru_cell(
  units,
  activation = "tanh",
  recurrent_activation = "sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  reset_after = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_gru_cell_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. Default: hyperbolic tangent
(<code>tanh</code>). If you pass <code>NULL</code>, no activation is applied
(ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent step.
Default: sigmoid (<code>sigmoid</code>). If you pass <code>NULL</code>, no activation is
applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, (default <code>TRUE</code>), whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix,
used for the linear transformation of the inputs. Default:
<code>glorot_uniform</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code>
weights matrix, used for the linear transformation of the recurrent state.
Default: <code>orthogonal</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector. Default: <code>zeros</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code> weights
matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the <code>recurrent_kernel</code>
weights matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
linear transformation of the inputs. Default: 0.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for
the linear transformation of the recurrent state. Default: 0.</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_reset_after">reset_after</code></td>
<td>
<p>GRU convention (whether to apply reset gate after or
before matrix multiplication). FALSE = &quot;before&quot;,
TRUE = &quot;after&quot; (default and CuDNN compatible).</p>
</td></tr>
<tr><td><code id="layer_gru_cell_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://www.tensorflow.org/guide/keras/rnn">the Keras RNN API guide</a>
for details about the usage of RNN API.
</p>
<p>This class processes one step within the whole time sequence input, whereas
<code>tf.keras.layer.GRU</code> processes the whole sequence.
</p>
<p>For example:
</p>
<div class="sourceCode r"><pre>inputs &lt;- k_random_uniform(c(32, 10, 8))
output &lt;- inputs %&gt;% layer_rnn(layer_gru_cell(4))
output$shape  # TensorShape([32, 4])

rnn &lt;- layer_rnn(cell = layer_gru_cell(4),
                 return_sequence = TRUE,
                 return_state = TRUE)
c(whole_sequence_output, final_state) %&lt;-% rnn(inputs)
whole_sequence_output$shape # TensorShape([32, 10, 4])
final_state$shape           # TensorShape([32, 4])
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell">https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell</a>
</p>
</li></ul>

<p>Other RNN cell layers: 
<code><a href="#topic+layer_lstm_cell">layer_lstm_cell</a>()</code>,
<code><a href="#topic+layer_simple_rnn_cell">layer_simple_rnn_cell</a>()</code>,
<code><a href="#topic+layer_stacked_rnn_cells">layer_stacked_rnn_cells</a>()</code>
</p>

<hr>
<h2 id='layer_hashing'>A preprocessing layer which hashes and bins categorical features.</h2><span id='topic+layer_hashing'></span>

<h3>Description</h3>

<p>A preprocessing layer which hashes and bins categorical features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_hashing(
  object,
  num_bins,
  mask_value = NULL,
  salt = NULL,
  output_mode = "int",
  sparse = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_hashing_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_hashing_+3A_num_bins">num_bins</code></td>
<td>
<p>Number of hash bins. Note that this includes the <code>mask_value</code> bin,
so the effective number of bins is <code>(num_bins - 1)</code> if <code>mask_value</code> is
set.</p>
</td></tr>
<tr><td><code id="layer_hashing_+3A_mask_value">mask_value</code></td>
<td>
<p>A value that represents masked inputs, which are mapped to
index 0. Defaults to NULL, meaning no mask term will be added and the
hashing will start at index 0.</p>
</td></tr>
<tr><td><code id="layer_hashing_+3A_salt">salt</code></td>
<td>
<p>A single unsigned integer or NULL.
If passed, the hash function used will be SipHash64, with these values
used as an additional input (known as a &quot;salt&quot; in cryptography).
These should be non-zero. Defaults to <code>NULL</code> (in that
case, the FarmHash64 hash function is used). It also supports
list of 2 unsigned integer numbers, see reference paper for details.</p>
</td></tr>
<tr><td><code id="layer_hashing_+3A_output_mode">output_mode</code></td>
<td>
<p>Specification for the output of the layer. Defaults to
<code>"int"</code>.  Values can be <code>"int"</code>, <code>"one_hot"</code>, <code>"multi_hot"</code>, or
<code>"count"</code> configuring the layer as follows:
</p>

<ul>
<li> <p><code>"int"</code>: Return the integer bin indices directly.
</p>
</li>
<li> <p><code>"one_hot"</code>: Encodes each individual element in the input into an
array the same size as <code>num_bins</code>, containing a 1 at the input's bin
index. If the last dimension is size 1, will encode on that
dimension.  If the last dimension is not size 1, will append a new
dimension for the encoded output.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Encodes each sample in the input into a single array
the same size as <code>num_bins</code>, containing a 1 for each bin index
index present in the sample. Treats the last dimension as the sample
dimension, if input shape is <code style="white-space: pre;">&#8288;(..., sample_length)&#8288;</code>, output shape
will be <code style="white-space: pre;">&#8288;(..., num_tokens)&#8288;</code>.
</p>
</li>
<li> <p><code>"count"</code>: As <code>"multi_hot"</code>, but the int array contains a count of
the number of times the bin index appeared in the sample.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_hashing_+3A_sparse">sparse</code></td>
<td>
<p>Boolean. Only applicable to <code>"one_hot"</code>, <code>"multi_hot"</code>,
and <code>"count"</code> output modes. If <code>TRUE</code>, returns a <code>SparseTensor</code> instead of
a dense <code>Tensor</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="layer_hashing_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer transforms single or multiple categorical inputs to hashed output.
It converts a sequence of int or string to a sequence of int. The stable hash
function uses <code style="white-space: pre;">&#8288;tensorflow::ops::Fingerprint&#8288;</code> to produce the same output
consistently across all platforms.
</p>
<p>This layer uses <a href="https://github.com/google/farmhash">FarmHash64</a> by default,
which provides a consistent hashed output across different platforms and is
stable across invocations, regardless of device and context, by mixing the
input bits thoroughly.
</p>
<p>If you want to obfuscate the hashed output, you can also pass a random <code>salt</code>
argument in the constructor. In that case, the layer will use the
<a href="https://github.com/google/highwayhash">SipHash64</a> hash function, with
the <code>salt</code> value serving as additional input to the hash function.
</p>
<p><strong>Example (FarmHash64)</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3)
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[1],
#          [0],
#          [1],
#          [1],
#          [2]])&gt;
</pre></div>
<p><strong>Example (FarmHash64) with a mask value</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3, mask_value='')
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[1],
#          [1],
#          [0],
#          [2],
#          [2]])&gt;
</pre></div>
<p><strong>Example (SipHash64)</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3, salt=c(133, 137))
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[1],
#          [2],
#          [1],
#          [0],
#          [2]])&gt;
</pre></div>
<p><strong>Example (Siphash64 with a single integer, same as <code style="white-space: pre;">&#8288;salt=[133, 133]&#8288;</code>)</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3, salt=133)
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[0],
#          [0],
#          [2],
#          [1],
#          [0]])&gt;
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/categorical/hashing/">https://keras.io/api/layers/preprocessing_layers/categorical/hashing/</a>
</p>
</li></ul>

<p>Other categorical features preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_input'>Input layer</h2><span id='topic+layer_input'></span>

<h3>Description</h3>

<p>Layer to be used as an entry point into a graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_input(
  shape = NULL,
  batch_shape = NULL,
  name = NULL,
  dtype = NULL,
  sparse = FALSE,
  tensor = NULL,
  ragged = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_input_+3A_shape">shape</code></td>
<td>
<p>Shape, not including the batch size. For instance,
<code>shape=c(32)</code> indicates that the expected input will be batches
of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_input_+3A_batch_shape">batch_shape</code></td>
<td>
<p>Shape, including the batch size. For instance,
<code>shape = c(10,32)</code> indicates that the expected input will be batches
of 10 32-dimensional vectors. <code>batch_shape = list(NULL, 32)</code> indicates
batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_input_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_input_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_input_+3A_sparse">sparse</code></td>
<td>
<p>Boolean, whether the placeholder created is meant to be sparse.</p>
</td></tr>
<tr><td><code id="layer_input_+3A_tensor">tensor</code></td>
<td>
<p>Existing tensor to wrap into the <code>Input</code> layer. If set, the
layer will not create a placeholder tensor.</p>
</td></tr>
<tr><td><code id="layer_input_+3A_ragged">ragged</code></td>
<td>
<p>A boolean specifying whether the placeholder to be created is
ragged. Only one of 'ragged' and 'sparse' can be <code>TRUE</code> In this case, values
of 'NULL' in the 'shape' argument represent ragged dimensions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_integer_lookup'>A preprocessing layer which maps integer features to contiguous ranges.</h2><span id='topic+layer_integer_lookup'></span>

<h3>Description</h3>

<p>A preprocessing layer which maps integer features to contiguous ranges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_integer_lookup(
  object,
  max_tokens = NULL,
  num_oov_indices = 1L,
  mask_token = NULL,
  oov_token = -1L,
  vocabulary = NULL,
  vocabulary_dtype = "int64",
  idf_weights = NULL,
  invert = FALSE,
  output_mode = "int",
  sparse = FALSE,
  pad_to_max_tokens = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_integer_lookup_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_max_tokens">max_tokens</code></td>
<td>
<p>Maximum size of the vocabulary for this layer. This should
only be specified when adapting the vocabulary or when setting
<code>pad_to_max_tokens = TRUE</code>. If <code>NULL</code>, there is no cap on the size of the
vocabulary. Note that this size includes the OOV and mask tokens.
Defaults to <code>NULL.</code></p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_num_oov_indices">num_oov_indices</code></td>
<td>
<p>The number of out-of-vocabulary tokens to use. If this
value is more than 1, OOV inputs are modulated to determine their OOV
value. If this value is 0, OOV inputs will cause an error when calling
the layer. Defaults to 1.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_mask_token">mask_token</code></td>
<td>
<p>An integer token that represents masked inputs. When
<code>output_mode</code> is <code>"int"</code>, the token is included in vocabulary and mapped
to index 0. In other output modes, the token will not appear in the
vocabulary and instances of the mask token in the input will be dropped.
If set to <code>NULL</code>, no mask term will be added. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_oov_token">oov_token</code></td>
<td>
<p>Only used when <code>invert</code> is <code>TRUE</code>. The token to return for OOV
indices. Defaults to -1.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_vocabulary">vocabulary</code></td>
<td>
<p>Optional. Either an array of integers or a string path to a
text file. If passing an array, can pass a list, list, 1D numpy array,
or 1D tensor containing the integer vocabulary terms. If passing a file
path, the file should contain one line per term in the vocabulary. If
this argument is set, there is no need to <code>adapt()</code> the layer.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_vocabulary_dtype">vocabulary_dtype</code></td>
<td>
<p>The dtype of the vocabulary terms, for example
<code>"int64"</code> or <code>"int32"</code>. Defaults to <code>"int64"</code>.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_idf_weights">idf_weights</code></td>
<td>
<p>Only valid when <code>output_mode</code> is <code>"tf_idf"</code>. A list, list,
1D numpy array, or 1D tensor or the same length as the vocabulary,
containing the floating point inverse document frequency weights, which
will be multiplied by per sample term counts for the final <code>tf_idf</code>
weight. If the <code>vocabulary</code> argument is set, and <code>output_mode</code> is
<code>"tf_idf"</code>, this argument must be supplied.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_invert">invert</code></td>
<td>
<p>Only valid when <code>output_mode</code> is <code>"int"</code>. If TRUE, this layer will
map indices to vocabulary items instead of mapping vocabulary items to
indices. Default to FALSE.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_output_mode">output_mode</code></td>
<td>
<p>Specification for the output of the layer. Defaults to
<code>"int"</code>.  Values can be <code>"int"</code>, <code>"one_hot"</code>, <code>"multi_hot"</code>, <code>"count"</code>,
or <code>"tf_idf"</code> configuring the layer as follows:
</p>

<ul>
<li> <p><code>"int"</code>: Return the vocabulary indices of the input tokens.
</p>
</li>
<li> <p><code>"one_hot"</code>: Encodes each individual element in the input into an
array the same size as the vocabulary, containing a 1 at the element
index. If the last dimension is size 1, will encode on that
dimension.  If the last dimension is not size 1, will append a new
dimension for the encoded output.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Encodes each sample in the input into a single array
the same size as the vocabulary, containing a 1 for each vocabulary
term present in the sample. Treats the last dimension as the sample
dimension, if input shape is (..., sample_length), output shape will
be (..., num_tokens).
</p>
</li>
<li> <p><code>"count"</code>: As <code>"multi_hot"</code>, but the int array contains a count of
the number of times the token at that index appeared in the sample.
</p>
</li>
<li> <p><code>"tf_idf"</code>: As <code>"multi_hot"</code>, but the TF-IDF algorithm is applied to
find the value in each token slot.
For <code>"int"</code> output, any shape of input and output is supported. For all
other output modes, currently only output up to rank 2 is supported.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_sparse">sparse</code></td>
<td>
<p>Boolean. Only applicable when <code>output_mode</code> is <code>"multi_hot"</code>,
<code>"count"</code>, or <code>"tf_idf"</code>. If <code>TRUE</code>, returns a <code>SparseTensor</code> instead of a
dense <code>Tensor</code>. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_pad_to_max_tokens">pad_to_max_tokens</code></td>
<td>
<p>Only applicable when <code>output_mode</code> is <code>"multi_hot"</code>,
<code>"count"</code>, or <code>"tf_idf"</code>. If <code>TRUE</code>, the output will have its feature axis
padded to <code>max_tokens</code> even if the number of unique tokens in the
vocabulary is less than max_tokens, resulting in a tensor of shape
<code style="white-space: pre;">&#8288;[batch_size, max_tokens]&#8288;</code> regardless of vocabulary size. Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="layer_integer_lookup_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer maps a set of arbitrary integer input tokens into indexed integer
output via a table-based vocabulary lookup. The layer's output indices will
be contiguously arranged up to the maximum vocab size, even if the input
tokens are non-continguous or unbounded. The layer supports multiple options
for encoding the output via <code>output_mode</code>, and has optional support for
out-of-vocabulary (OOV) tokens and masking.
</p>
<p>The vocabulary for the layer must be either supplied on construction or
learned via <code>adapt()</code>. During <code>adapt()</code>, the layer will analyze a data set,
determine the frequency of individual integer tokens, and create a
vocabulary from them. If the vocabulary is capped in size, the most frequent
tokens will be used to create the vocabulary and all others will be treated
as OOV.
</p>
<p>There are two possible output modes for the layer.  When <code>output_mode</code> is
<code>"int"</code>, input integers are converted to their index in the vocabulary (an
integer).  When <code>output_mode</code> is <code>"multi_hot"</code>, <code>"count"</code>, or <code>"tf_idf"</code>,
input integers are encoded into an array where each dimension corresponds to
an element in the vocabulary.
</p>
<p>The vocabulary can optionally contain a mask token as well as an OOV token
(which can optionally occupy multiple indices in the vocabulary, as set
by <code>num_oov_indices</code>).
The position of these tokens in the vocabulary is fixed. When <code>output_mode</code>
is <code>"int"</code>, the vocabulary will begin with the mask token at index <code>0</code>,
followed by OOV indices, followed by the rest of the vocabulary. When
<code>output_mode</code> is <code>"multi_hot"</code>, <code>"count"</code>, or <code>"tf_idf"</code> the vocabulary will
begin with OOV indices and instances of the mask token will be dropped.
</p>
<p>For an overview and full list of preprocessing layers, see the preprocessing
<a href="https://www.tensorflow.org/guide/keras/preprocessing_layers">guide</a>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+adapt">adapt()</a></code>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup">https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup">https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup</a>
</p>
</li></ul>

<p>Other categorical features preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_lambda'>Wraps arbitrary expression as a layer</h2><span id='topic+layer_lambda'></span>

<h3>Description</h3>

<p>Wraps arbitrary expression as a layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_lambda(
  object,
  f,
  output_shape = NULL,
  mask = NULL,
  arguments = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_lambda_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_lambda_+3A_f">f</code></td>
<td>
<p>The function to be evaluated. Takes input tensor as first
argument.</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_output_shape">output_shape</code></td>
<td>
<p>Expected output shape from the function (not required
when using TensorFlow back-end).</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_mask">mask</code></td>
<td>
<p>mask</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_arguments">arguments</code></td>
<td>
<p>optional named list of keyword arguments to be passed to the
function.</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_lambda_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>Arbitrary. Use the keyword argument input_shape (list
of integers, does not include the samples axis) when using this layer as
the first layer in a model.
</p>


<h3>Output shape</h3>

<p>Arbitrary (based on tensor returned from the function)
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_layer_normalization'>Layer normalization layer (Ba et al., 2016).</h2><span id='topic+layer_layer_normalization'></span>

<h3>Description</h3>

<p>Normalize the activations of the previous layer for each given example in a
batch independently, rather than across a batch like Batch Normalization. i.e.
applies a transformation that maintains the mean activation within each example
close to 0 and the activation standard deviation close to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_layer_normalization(
  object,
  axis = -1,
  epsilon = 0.001,
  center = TRUE,
  scale = TRUE,
  beta_initializer = "zeros",
  gamma_initializer = "ones",
  beta_regularizer = NULL,
  gamma_regularizer = NULL,
  beta_constraint = NULL,
  gamma_constraint = NULL,
  trainable = TRUE,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_layer_normalization_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_axis">axis</code></td>
<td>
<p>Integer or List/Tuple. The axis or axes to normalize across.
Typically this is the features axis/axes. The left-out axes are typically
the batch axis/axes. This argument defaults to -1, the last dimension in
the input.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_epsilon">epsilon</code></td>
<td>
<p>Small float added to variance to avoid dividing by zero.
Defaults to 1e-3</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_center">center</code></td>
<td>
<p>If True, add offset of beta to normalized tensor. If False,
beta is ignored. Defaults to True.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_scale">scale</code></td>
<td>
<p>If True, multiply by gamma. If False, gamma is not used.
Defaults to True. When the next layer is linear (also e.g. nn.relu), this
can be disabled since the scaling will be done by the next layer.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_beta_initializer">beta_initializer</code></td>
<td>
<p>Initializer for the beta weight. Defaults to zeros.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_gamma_initializer">gamma_initializer</code></td>
<td>
<p>Initializer for the gamma weight. Defaults to ones.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_beta_regularizer">beta_regularizer</code></td>
<td>
<p>Optional regularizer for the beta weight.
None by default.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_gamma_regularizer">gamma_regularizer</code></td>
<td>
<p>Optional regularizer for the gamma weight.
None by default.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_beta_constraint">beta_constraint</code></td>
<td>
<p>Optional constraint for the beta weight. None by default.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_gamma_constraint">gamma_constraint</code></td>
<td>
<p>Optional constraint for the gamma weight.
None by default.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_trainable">trainable</code></td>
<td>
<p>Boolean, if True the variables will be marked as trainable.
Defaults to True.</p>
</td></tr>
<tr><td><code id="layer_layer_normalization_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a tensor inputs, moments are calculated and normalization is performed
across the axes specified in axis.
</p>

<hr>
<h2 id='layer_locally_connected_1d'>Locally-connected layer for 1D inputs.</h2><span id='topic+layer_locally_connected_1d'></span>

<h3>Description</h3>

<p><code>layer_locally_connected_1d()</code> works similarly to <code><a href="#topic+layer_conv_1d">layer_conv_1d()</a></code> , except
that weights are unshared, that is, a different set of filters is applied at
each different patch of the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_locally_connected_1d(
  object,
  filters,
  kernel_size,
  strides = 1L,
  padding = "valid",
  data_format = NULL,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  implementation = 1L,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_locally_connected_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number output of filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of a single integer, specifying the
length of the 1D convolution window.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of a single integer, specifying the stride
length of the convolution. Specifying any stride value != 1 is incompatible
with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_padding">padding</code></td>
<td>
<p>Currently only supports <code>"valid"</code> (case-insensitive). <code>"same"</code>
may be supported in the future.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_implementation">implementation</code></td>
<td>
<p>either 1, 2, or 3. 1 loops over input spatial locations
to perform the forward pass. It is memory-efficient but performs a lot of
(small) ops. 2 stores layer weights in a dense but sparsely-populated 2D
matrix and implements the forward pass as a single matrix-multiply. It uses
a lot of RAM but performs few (large) ops. 3 stores layer weights in a
sparse tensor and implements the forward pass as a single sparse
matrix-multiply. How to choose: 1: large, dense models, 2: small models, 3:
large, sparse models, where &quot;large&quot; stands for large input/output
activations (i.e. many <code style="white-space: pre;">&#8288;filters, input_filters, large input_size, output_size&#8288;</code>),
and &quot;sparse&quot; stands for few connections between inputs and outputs, i.e.
small ratio <code>filters * input_filters * kernel_size / (input_size * strides)</code>,
where inputs to and outputs of the layer are assumed to have shapes
<code style="white-space: pre;">&#8288;(input_size, input_filters)&#8288;</code>, <code style="white-space: pre;">&#8288;(output_size, filters)&#8288;</code> respectively.
It is recommended to benchmark each in the setting of interest to pick the
most efficient one (in terms of speed and memory usage). Correct choice of
implementation can lead to dramatic speed improvements (e.g. 50X),
potentially at the expense of RAM. Also, only <code>padding="valid"</code> is
supported by <code>implementation=1</code>.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, steps, input_dim)&#8288;</code>
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, new_steps, filters)&#8288;</code> <code>steps</code> value might have changed due to padding or strides.
</p>


<h3>See Also</h3>

<p>Other locally connected layers: 
<code><a href="#topic+layer_locally_connected_2d">layer_locally_connected_2d</a>()</code>
</p>

<hr>
<h2 id='layer_locally_connected_2d'>Locally-connected layer for 2D inputs.</h2><span id='topic+layer_locally_connected_2d'></span>

<h3>Description</h3>

<p><code>layer_locally_connected_2d</code> works similarly to <code><a href="#topic+layer_conv_2d">layer_conv_2d()</a></code>, except
that weights are unshared, that is, a different set of filters is applied at
each different patch of the input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_locally_connected_2d(
  object,
  filters,
  kernel_size,
  strides = c(1L, 1L),
  padding = "valid",
  data_format = NULL,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  implementation = 1L,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_locally_connected_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number output of filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 2 integers, specifying the width and
height of the 2D convolution window. Can be a single integer to specify the
same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 2 integers, specifying the strides of
the convolution along the width and height. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_padding">padding</code></td>
<td>
<p>Currently only supports <code>"valid"</code> (case-insensitive). <code>"same"</code>
may be supported in the future.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, width, height, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, width, height)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_implementation">implementation</code></td>
<td>
<p>either 1, 2, or 3. 1 loops over input spatial locations
to perform the forward pass. It is memory-efficient but performs a lot of
(small) ops. 2 stores layer weights in a dense but sparsely-populated 2D
matrix and implements the forward pass as a single matrix-multiply. It uses
a lot of RAM but performs few (large) ops. 3 stores layer weights in a
sparse tensor and implements the forward pass as a single sparse
matrix-multiply. How to choose: 1: large, dense models, 2: small models, 3:
large, sparse models, where &quot;large&quot; stands for large input/output
activations (i.e. many <code style="white-space: pre;">&#8288;filters, input_filters, large input_size, output_size&#8288;</code>),
and &quot;sparse&quot; stands for few connections between inputs and outputs, i.e.
small ratio <code>filters * input_filters * kernel_size / (input_size * strides)</code>,
where inputs to and outputs of the layer are assumed to have shapes
<code style="white-space: pre;">&#8288;(input_size, input_filters)&#8288;</code>, <code style="white-space: pre;">&#8288;(output_size, filters)&#8288;</code> respectively.
It is recommended to benchmark each in the setting of interest to pick the
most efficient one (in terms of speed and memory usage). Correct choice of
implementation can lead to dramatic speed improvements (e.g. 50X),
potentially at the expense of RAM. Also, only <code>padding="valid"</code> is
supported by <code>implementation=1</code>.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_locally_connected_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, channels, rows, cols)&#8288;</code>
if data_format='channels_first' or 4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, rows, cols, channels)&#8288;</code> if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, filters, new_rows, new_cols)&#8288;</code> if data_format='channels_first' or 4D tensor with shape:
<code style="white-space: pre;">&#8288;(samples, new_rows, new_cols, filters)&#8288;</code> if data_format='channels_last'.
<code>rows</code> and <code>cols</code> values might have changed due to padding.
</p>


<h3>See Also</h3>

<p>Other locally connected layers: 
<code><a href="#topic+layer_locally_connected_1d">layer_locally_connected_1d</a>()</code>
</p>

<hr>
<h2 id='layer_lstm'>Long Short-Term Memory unit - Hochreiter 1997.</h2><span id='topic+layer_lstm'></span>

<h3>Description</h3>

<p>For a step-by-step description of the algorithm, see <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">this tutorial</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_lstm(
  object,
  units,
  activation = "tanh",
  recurrent_activation = "sigmoid",
  use_bias = TRUE,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  time_major = FALSE,
  unroll = FALSE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_lstm_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_lstm_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. Default: hyperbolic tangent
(<code>tanh</code>). If you pass <code>NULL</code>, no activation is applied
(ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent
step.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_return_state">return_state</code></td>
<td>
<p>Boolean (default FALSE). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, process the input
sequence backwards and return the reversed sequence.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_time_major">time_major</code></td>
<td>
<p>If True, the inputs and outputs will be in shape
<code style="white-space: pre;">&#8288;[timesteps, batch, feature]&#8288;</code>, whereas in the False case, it will be
<code style="white-space: pre;">&#8288;[batch, timesteps, feature]&#8288;</code>. Using <code>time_major = TRUE</code> is a bit more
efficient because it avoids transposes at the beginning and end of the RNN
calculation. However, most TensorFlow data is batch-major, so by default
this function accepts input and emits output in batch-major form.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_unroll">unroll</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the network will be unrolled,
else a symbolic loop will be used. Unrolling can speed-up a RNN, although
it tends to be more memory-intensive. Unrolling is only suitable for short
sequences.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean. If TRUE, add 1 to the bias of the forget
gate at initialization. Setting it to true will also force
<code>bias_initializer="zeros"</code>. This is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al.</a></p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop
for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_lstm_+3A_...">...</code></td>
<td>
<p>Standard Layer args.</p>
</td></tr>
</table>


<h3>Input shapes</h3>

<p>N-D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, timesteps, ...)&#8288;</code>,
or <code style="white-space: pre;">&#8288;(timesteps, batch_size, ...)&#8288;</code> when <code>time_major = TRUE</code>.
</p>


<h3>Output shape</h3>


<ul>
<li><p> if <code>return_state</code>: a list of tensors. The first tensor is
the output. The remaining tensors are the last states,
each with shape <code style="white-space: pre;">&#8288;(batch_size, state_size)&#8288;</code>, where <code>state_size</code>
could be a high dimension tensor shape.
</p>
</li>
<li><p> if <code>return_sequences</code>: N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, timesteps, output_size]&#8288;</code>, where <code>output_size</code> could be a high dimension tensor shape, or
<code style="white-space: pre;">&#8288;[timesteps, batch_size, output_size]&#8288;</code> when <code>time_major</code> is <code>TRUE</code>
</p>
</li>
<li><p> else, N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, output_size]&#8288;</code>, where
<code>output_size</code> could be a high dimension tensor shape.
</p>
</li></ul>



<h3>Masking</h3>

<p>This layer supports masking for input data with a variable number of
timesteps. To introduce masks to your data, use
<code><a href="#topic+layer_embedding">layer_embedding()</a></code> with the <code>mask_zero</code> parameter set to <code>TRUE</code>.
</p>


<h3>Statefulness in RNNs</h3>

<p>You can set RNN layers to be 'stateful', which means that the states computed
for the samples in one batch will be reused as initial states for the samples
in the next batch. This assumes a one-to-one mapping between samples in
different successive batches.
</p>
<p>For intuition behind statefulness, there is a helpful blog post here:
<a href="https://philipperemy.github.io/keras-stateful-lstm/">https://philipperemy.github.io/keras-stateful-lstm/</a>
</p>
<p>To enable statefulness:
</p>

<ul>
<li><p> Specify <code>stateful = TRUE</code> in the layer constructor.
</p>
</li>
<li><p> Specify a fixed batch size for your model. For sequential models,
pass <code>batch_input_shape = list(...)</code> to the first layer in your model.
For functional models with 1 or more Input layers, pass
<code>batch_shape = list(...)</code> to all the first layers in your model.
This is the expected shape of your inputs <em>including the batch size</em>.
It should be a list of integers, e.g. <code>list(32, 10, 100)</code>.
For dimensions which can vary (are not known ahead of time),
use <code>NULL</code> in place of an integer, e.g. <code>list(32, NULL, NULL)</code>.
</p>
</li>
<li><p> Specify <code>shuffle = FALSE</code> when calling <code>fit()</code>.
</p>
</li></ul>

<p>To reset the states of your model, call <code>layer$reset_states()</code> on either
a specific layer, or on your entire model.
</p>


<h3>Initial State of RNNs</h3>

<p>You can specify the initial state of RNN layers symbolically by calling them
with the keyword argument <code>initial_state.</code> The value of initial_state should
be a tensor or list of tensors representing the initial state of the RNN
layer.
</p>
<p>You can specify the initial state of RNN layers numerically by calling
<code>reset_states</code> with the named argument <code>states.</code> The value of <code>states</code> should
be an array or list of arrays representing the initial state of the RNN
layer.
</p>


<h3>Passing external constants to RNNs</h3>

<p>You can pass &quot;external&quot; constants to the cell using the <code>constants</code> named
argument of <code style="white-space: pre;">&#8288;RNN$__call__&#8288;</code> (as well as <code>RNN$call</code>) method. This requires that the
<code>cell$call</code> method accepts the same keyword argument <code>constants</code>. Such constants
can be used to condition the cell transformation on additional static inputs
(not changing over time), a.k.a. an attention mechanism.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="http://www.bioinf.jku.at/publications/older/2604.pdf">Long short-term memory</a> (original 1997 paper)
</p>
</li>
<li> <p><a href="https://www.cs.toronto.edu/~graves/preprint.pdf">Supervised sequence labeling with recurrent neural networks</a>
</p>
</li>
<li> <p><a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/guide/keras/rnn">https://www.tensorflow.org/guide/keras/rnn</a>
</p>
</li></ul>

<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_gru">layer_cudnn_gru</a>()</code>,
<code><a href="#topic+layer_cudnn_lstm">layer_cudnn_lstm</a>()</code>,
<code><a href="#topic+layer_gru">layer_gru</a>()</code>,
<code><a href="#topic+layer_rnn">layer_rnn</a>()</code>,
<code><a href="#topic+layer_simple_rnn">layer_simple_rnn</a>()</code>
</p>
<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_gru">layer_cudnn_gru</a>()</code>,
<code><a href="#topic+layer_cudnn_lstm">layer_cudnn_lstm</a>()</code>,
<code><a href="#topic+layer_gru">layer_gru</a>()</code>,
<code><a href="#topic+layer_rnn">layer_rnn</a>()</code>,
<code><a href="#topic+layer_simple_rnn">layer_simple_rnn</a>()</code>
</p>

<hr>
<h2 id='layer_lstm_cell'>Cell class for the LSTM layer</h2><span id='topic+layer_lstm_cell'></span>

<h3>Description</h3>

<p>Cell class for the LSTM layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_lstm_cell(
  units,
  activation = "tanh",
  recurrent_activation = "sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_lstm_cell_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. Default: hyperbolic tangent
(<code>tanh</code>). If you pass <code>NULL</code>, no activation is applied (ie. &quot;linear&quot;
activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent step.
Default: sigmoid (<code>sigmoid</code>). If you pass <code>NULL</code>, no activation is applied
(ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, (default <code>TRUE</code>), whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used for
the linear transformation of the inputs. Default: <code>glorot_uniform</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.
Default: <code>orthogonal</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector. Default: <code>zeros</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean (default <code>TRUE</code>). If TRUE, add 1 to the bias of
the forget gate at initialization. Setting it to true will also force
<code>bias_initializer="zeros"</code>. This is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al.</a></p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code> weights
matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to
the <code>recurrent_kernel</code> weights matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the <code>recurrent_kernel</code>
weights matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear
transformation of the inputs. Default: 0.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for
the linear transformation of the recurrent state. Default: 0.</p>
</td></tr>
<tr><td><code id="layer_lstm_cell_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://www.tensorflow.org/guide/keras/rnn">the Keras RNN API guide</a>
for details about the usage of RNN API.
</p>
<p>This class processes one step within the whole time sequence input, whereas
<code>tf$keras$layer$LSTM</code> processes the whole sequence.
</p>
<p>For example:
</p>
<div class="sourceCode r"><pre>inputs &lt;- k_random_normal(c(32, 10, 8))
rnn &lt;- layer_rnn(cell = layer_lstm_cell(units = 4))
output &lt;- rnn(inputs)
dim(output) # (32, 4)

rnn &lt;- layer_rnn(cell = layer_lstm_cell(units = 4),
                 return_sequences = TRUE,
                 return_state = TRUE)
c(whole_seq_output, final_memory_state, final_carry_state) %&lt;-% rnn(inputs)

dim(whole_seq_output)   # (32, 10, 4)
dim(final_memory_state) # (32, 4)
dim(final_carry_state)  # (32, 4)
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell">https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell</a>
</p>
</li></ul>

<p>Other RNN cell layers: 
<code><a href="#topic+layer_gru_cell">layer_gru_cell</a>()</code>,
<code><a href="#topic+layer_simple_rnn_cell">layer_simple_rnn_cell</a>()</code>,
<code><a href="#topic+layer_stacked_rnn_cells">layer_stacked_rnn_cells</a>()</code>
</p>

<hr>
<h2 id='layer_masking'>Masks a sequence by using a mask value to skip timesteps.</h2><span id='topic+layer_masking'></span>

<h3>Description</h3>

<p>For each timestep in the input tensor (dimension #1 in the tensor), if all
values in the input tensor at that timestep are equal to <code>mask_value</code>, then
the timestep will be masked (skipped) in all downstream layers (as long as
they support masking). If any downstream layer does not support masking yet
receives such an input mask, an exception will be raised.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_masking(
  object,
  mask_value = 0,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_masking_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_masking_+3A_mask_value">mask_value</code></td>
<td>
<p>float, mask value</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_masking_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_max_pooling_1d'>Max pooling operation for temporal data.</h2><span id='topic+layer_max_pooling_1d'></span>

<h3>Description</h3>

<p>Max pooling operation for temporal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_max_pooling_1d(
  object,
  pool_size = 2L,
  strides = NULL,
  padding = "valid",
  data_format = "channels_last",
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_max_pooling_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_pool_size">pool_size</code></td>
<td>
<p>Integer, size of the max pooling windows.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_strides">strides</code></td>
<td>
<p>Integer, or NULL. Factor by which to downscale. E.g. 2 will
halve the input. If NULL, it will default to <code>pool_size</code>.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of &quot;channels_last&quot; (default) or
&quot;channels_first&quot;. The ordering of the dimensions in the inputs.
channels_last corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, steps, features)&#8288;</code>
while channels_first corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, features, steps)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input Shape</h3>

<p>If data_format='channels_last': 3D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, steps, features)&#8288;</code>.
If data_format='channels_first': 3D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, features, steps)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>If data_format='channels_last': 3D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, downsampled_steps, features)&#8288;</code>.
If data_format='channels_first': 3D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, features, downsampled_steps)&#8288;</code>.
</p>


<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_max_pooling_2d'>Max pooling operation for spatial data.</h2><span id='topic+layer_max_pooling_2d'></span>

<h3>Description</h3>

<p>Max pooling operation for spatial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_max_pooling_2d(
  object,
  pool_size = c(2L, 2L),
  strides = NULL,
  padding = "valid",
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_max_pooling_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_pool_size">pool_size</code></td>
<td>
<p>integer or list of 2 integers, factors by which to downscale
(vertical, horizontal). (2, 2) will halve the input in both spatial
dimension. If only one integer is specified, the same window length will be
used for both dimensions.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_strides">strides</code></td>
<td>
<p>Integer, list of 2 integers, or NULL. Strides values. If NULL,
it will default to <code>pool_size</code>.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, pooled_rows, pooled_cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, pooled_rows, pooled_cols)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_3d">layer_max_pooling_3d</a>()</code>
</p>

<hr>
<h2 id='layer_max_pooling_3d'>Max pooling operation for 3D data (spatial or spatio-temporal).</h2><span id='topic+layer_max_pooling_3d'></span>

<h3>Description</h3>

<p>Max pooling operation for 3D data (spatial or spatio-temporal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_max_pooling_3d(
  object,
  pool_size = c(2L, 2L, 2L),
  strides = NULL,
  padding = "valid",
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_max_pooling_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_pool_size">pool_size</code></td>
<td>
<p>list of 3 integers, factors by which to downscale (dim1,
dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each
dimension.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_strides">strides</code></td>
<td>
<p>list of 3 integers, or NULL. Strides values.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_padding">padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_max_pooling_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>


<ul>
<li><p> If <code>data_format='channels_last'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format='channels_first'</code>: 5D tensor with shape: <code style="white-space: pre;">&#8288;(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other pooling layers: 
<code><a href="#topic+layer_average_pooling_1d">layer_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_average_pooling_2d">layer_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_average_pooling_3d">layer_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_1d">layer_global_average_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_2d">layer_global_average_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_average_pooling_3d">layer_global_average_pooling_3d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_1d">layer_global_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_2d">layer_global_max_pooling_2d</a>()</code>,
<code><a href="#topic+layer_global_max_pooling_3d">layer_global_max_pooling_3d</a>()</code>,
<code><a href="#topic+layer_max_pooling_1d">layer_max_pooling_1d</a>()</code>,
<code><a href="#topic+layer_max_pooling_2d">layer_max_pooling_2d</a>()</code>
</p>

<hr>
<h2 id='layer_maximum'>Layer that computes the maximum (element-wise) a list of inputs.</h2><span id='topic+layer_maximum'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_maximum(inputs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_maximum_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_maximum_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the element-wise maximum of the inputs. If <code>inputs</code> is
missing, a keras layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/maximum">https://www.tensorflow.org/api_docs/python/tf/keras/layers/maximum</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Maximum">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Maximum</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/maximum">https://keras.io/api/layers/merging_layers/maximum</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_average">layer_average</a>()</code>,
<code><a href="#topic+layer_concatenate">layer_concatenate</a>()</code>,
<code><a href="#topic+layer_dot">layer_dot</a>()</code>,
<code><a href="#topic+layer_minimum">layer_minimum</a>()</code>,
<code><a href="#topic+layer_multiply">layer_multiply</a>()</code>,
<code><a href="#topic+layer_subtract">layer_subtract</a>()</code>
</p>

<hr>
<h2 id='layer_minimum'>Layer that computes the minimum (element-wise) a list of inputs.</h2><span id='topic+layer_minimum'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_minimum(inputs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_minimum_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_minimum_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the element-wise maximum of the inputs. If <code>inputs</code> is
missing, a keras layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/minimum">https://www.tensorflow.org/api_docs/python/tf/keras/layers/minimum</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Minimum">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Minimum</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/minimum">https://keras.io/api/layers/merging_layers/minimum</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_average">layer_average</a>()</code>,
<code><a href="#topic+layer_concatenate">layer_concatenate</a>()</code>,
<code><a href="#topic+layer_dot">layer_dot</a>()</code>,
<code><a href="#topic+layer_maximum">layer_maximum</a>()</code>,
<code><a href="#topic+layer_multiply">layer_multiply</a>()</code>,
<code><a href="#topic+layer_subtract">layer_subtract</a>()</code>
</p>

<hr>
<h2 id='layer_multi_head_attention'>MultiHeadAttention layer</h2><span id='topic+layer_multi_head_attention'></span>

<h3>Description</h3>

<p>This is an implementation of multi-headed attention based on &quot;Attention is all
you Need&quot;. If query, key, value are the same, then this is self-attention.
Each timestep in query attends to the corresponding sequence in key, and returns
a fixed-width vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_multi_head_attention(
  inputs,
  num_heads,
  key_dim,
  value_dim = NULL,
  dropout = 0,
  use_bias = TRUE,
  output_shape = NULL,
  attention_axes = NULL,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_multi_head_attention_+3A_inputs">inputs</code></td>
<td>
<p>List of the following tensors:
</p>

<ul>
<li><p> query: Query Tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tq, dim]&#8288;</code>.
</p>
</li>
<li><p> value: Value Tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code>.
</p>
</li>
<li><p> key: Optional key Tensor of shape <code style="white-space: pre;">&#8288;[batch_size, Tv, dim]&#8288;</code>. If not
given, will use value for both key and value, which is the most common
case.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_num_heads">num_heads</code></td>
<td>
<p>Number of attention heads.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_key_dim">key_dim</code></td>
<td>
<p>Size of each attention head for query and key.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_value_dim">value_dim</code></td>
<td>
<p>Size of each attention head for value.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_dropout">dropout</code></td>
<td>
<p>Dropout probability.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the dense layers use bias vectors/matrices.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_output_shape">output_shape</code></td>
<td>
<p>The expected shape of an output tensor, besides the batch and sequence dims. If not specified, projects back to the key feature dim.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_attention_axes">attention_axes</code></td>
<td>
<p>axes over which the attention is applied. None means attention over all axes, but batch, heads, and features.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for dense layer kernels.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for dense layer biases.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer for dense layer kernels.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer for dense layer biases.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer for dense layer activity.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint for dense layer kernels.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint for dense layer kernels.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_...">...</code></td>
<td>
<p>Other arguments passed to the layer. Eg, <code>name</code>, <code>training</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer first projects query, key and value. These are (effectively) a list
of tensors of length num_attention_heads, where the corresponding shapes are
<code style="white-space: pre;">&#8288;[batch_size, , key_dim]&#8288;</code>, <code style="white-space: pre;">&#8288;[batch_size, , key_dim]&#8288;</code>, <code style="white-space: pre;">&#8288;[batch_size, , value_dim]&#8288;</code>.
</p>
<p>Then, the query and key tensors are dot-producted and scaled. These are softmaxed
to obtain attention probabilities. The value tensors are then interpolated by
these probabilities, then concatenated back to a single tensor.
</p>
<p>Finally, the result tensor with the last dimension as value_dim can take an
linear projection and return.
</p>


<h3>Value</h3>


<ul>
<li><p> attention_output: The result of the computation, of shape <code style="white-space: pre;">&#8288;[B, T, E]&#8288;</code>, where
T is for target sequence shapes and E is the query input last dimension if
output_shape is None. Otherwise, the multi-head outputs are project to the
shape specified by output_shape.
</p>
</li>
<li><p> attention_scores: (Optional) multi-head attention coeffients over attention axes.
</p>
</li></ul>



<h3>Call arguments</h3>


<ul>
<li><p> query: Query Tensor of shape <code style="white-space: pre;">&#8288;[B, T, dim]&#8288;</code>.
</p>
</li>
<li><p> value: Value Tensor of shape <code style="white-space: pre;">&#8288;[B, S, dim]&#8288;</code>.
</p>
</li>
<li><p> key: Optional key Tensor of shape <code style="white-space: pre;">&#8288;[B, S, dim]&#8288;</code>. If not given, will use value
for both key and value, which is the most common case.
</p>
</li>
<li><p> attention_mask: a boolean mask of shape <code style="white-space: pre;">&#8288;[B, T, S]&#8288;</code>, that prevents attention
to certain positions.
</p>
</li>
<li><p> return_attention_scores: A boolean to indicate whether the output should be
attention output if TRUE, or (attention_output, attention_scores) if FALSE.
Defaults to FALSE.
</p>
</li>
<li><p> training: Python boolean indicating whether the layer should behave in
training mode (adding dropout) or in inference mode (no dropout). Defaults
to either using the training mode of the parent layer/model, or FALSE
(inference) if there is no parent layer.
</p>
</li></ul>


<hr>
<h2 id='layer_multiply'>Layer that multiplies (element-wise) a list of inputs.</h2><span id='topic+layer_multiply'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_multiply(inputs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_multiply_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_multiply_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the element-wise product of the inputs. If <code>inputs</code> is
missing, a keras layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/multiply">https://www.tensorflow.org/api_docs/python/tf/keras/layers/multiply</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/multiply">https://keras.io/api/layers/merging_layers/multiply</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_average">layer_average</a>()</code>,
<code><a href="#topic+layer_concatenate">layer_concatenate</a>()</code>,
<code><a href="#topic+layer_dot">layer_dot</a>()</code>,
<code><a href="#topic+layer_maximum">layer_maximum</a>()</code>,
<code><a href="#topic+layer_minimum">layer_minimum</a>()</code>,
<code><a href="#topic+layer_subtract">layer_subtract</a>()</code>
</p>

<hr>
<h2 id='layer_normalization'>A preprocessing layer which normalizes continuous features.</h2><span id='topic+layer_normalization'></span>

<h3>Description</h3>

<p>A preprocessing layer which normalizes continuous features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_normalization(
  object,
  axis = -1L,
  mean = NULL,
  variance = NULL,
  invert = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_normalization_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_normalization_+3A_axis">axis</code></td>
<td>
<p>Integer, list of integers, or NULL. The axis or axes that should
have a separate mean and variance for each index in the shape. For
example, if shape is <code style="white-space: pre;">&#8288;(NULL, 5)&#8288;</code> and <code>axis=1</code>, the layer will track 5
separate mean and variance values for the last axis. If <code>axis</code> is set to
<code>NULL</code>, the layer will normalize all elements in the input by a scalar
mean and variance. Defaults to -1, where the last axis of the input is
assumed to be a feature dimension and is normalized per index. Note that
in the specific case of batched scalar inputs where the only axis is the
batch axis, the default will normalize each index in the batch
separately. In this case, consider passing <code>axis = NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_normalization_+3A_mean">mean</code></td>
<td>
<p>The mean value(s) to use during normalization. The passed value(s)
will be broadcast to the shape of the kept axes above; if the value(s)
cannot be broadcast, an error will be raised when this layer's <code>build()</code>
method is called.</p>
</td></tr>
<tr><td><code id="layer_normalization_+3A_variance">variance</code></td>
<td>
<p>The variance value(s) to use during normalization. The passed
value(s) will be broadcast to the shape of the kept axes above; if the
value(s) cannot be broadcast, an error will be raised when this layer's
<code>build()</code> method is called.</p>
</td></tr>
<tr><td><code id="layer_normalization_+3A_invert">invert</code></td>
<td>
<p>If <code>TRUE</code>, this layer will apply the inverse transformation
to its inputs: it would turn a normalized input back into its
original form.</p>
</td></tr>
<tr><td><code id="layer_normalization_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer will shift and scale inputs into a distribution centered around 0
with standard deviation 1. It accomplishes this by precomputing the mean and
variance of the data, and calling <code>(input - mean) / sqrt(var)</code> at runtime.
</p>
<p>The mean and variance values for the layer must be either supplied on
construction or learned via <code>adapt()</code>. <code>adapt()</code> will compute the mean and
variance of the data and store them as the layer's weights. <code>adapt()</code> should
be called before <code>fit()</code>, <code>evaluate()</code>, or <code>predict()</code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+adapt">adapt()</a></code>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/numerical/normalization">https://keras.io/api/layers/preprocessing_layers/numerical/normalization</a>
</p>
</li></ul>

<p>Other numerical features preprocessing layers: 
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_permute'>Permute the dimensions of an input according to a given pattern</h2><span id='topic+layer_permute'></span>

<h3>Description</h3>

<p>Permute the dimensions of an input according to a given pattern
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_permute(
  object,
  dims,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_permute_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_permute_+3A_dims">dims</code></td>
<td>
<p>List of integers. Permutation pattern, does not include the
samples dimension. Indexing starts at 1. For instance, <code style="white-space: pre;">&#8288;(2, 1)&#8288;</code> permutes
the first and second dimension of the input.</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_permute_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input and Output Shapes</h3>

<p>Input shape: Arbitrary
</p>
<p>Output shape: Same as the input shape, but with the dimensions re-ordered
according to the specified pattern.
</p>


<h3>Note</h3>

<p>Useful for e.g. connecting RNNs and convnets together.
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_random_brightness'>A preprocessing layer which randomly adjusts brightness during training</h2><span id='topic+layer_random_brightness'></span>

<h3>Description</h3>

<p>A preprocessing layer which randomly adjusts brightness during training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_brightness(
  object,
  factor,
  value_range = c(0, 255),
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_brightness_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_brightness_+3A_factor">factor</code></td>
<td>
<p>Float or a list of 2 floats between -1.0 and 1.0. The
factor is used to determine the lower bound and upper bound of the
brightness adjustment. A float value will be chosen randomly between
the limits. When -1.0 is chosen, the output image will be black, and
when 1.0 is chosen, the image will be fully white. When only one float
is provided, eg, 0.2, then -0.2 will be used for lower bound and 0.2
will be used for upper bound.</p>
</td></tr>
<tr><td><code id="layer_random_brightness_+3A_value_range">value_range</code></td>
<td>
<p>Optional list of 2 floats for the lower and upper limit
of the values of the input data. Defaults to <code style="white-space: pre;">&#8288;[0.0, 255.0]&#8288;</code>. Can be changed
to e.g. <code style="white-space: pre;">&#8288;[0.0, 1.0]&#8288;</code> if the image input has been scaled before this layer.
The brightness adjustment will be scaled to this range, and the
output values will be clipped to this range.</p>
</td></tr>
<tr><td><code id="layer_random_brightness_+3A_seed">seed</code></td>
<td>
<p>optional integer, for fixed RNG behavior.</p>
</td></tr>
<tr><td><code id="layer_random_brightness_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer will randomly increase/reduce the brightness for the input RGB
images. At inference time, the output will be identical to the input.
Call the layer with <code>training=TRUE</code> to adjust the brightness of the input.
</p>
<p>Note that different brightness adjustment factors
will be apply to each the images in the batch.
</p>
<p>For an overview and full list of preprocessing layers, see the preprocessing
<a href="https://www.tensorflow.org/guide/keras/preprocessing_layers">guide</a>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers">https://keras.io/api/layers</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_contrast'>Adjust the contrast of an image or images by a random factor</h2><span id='topic+layer_random_contrast'></span>

<h3>Description</h3>

<p>Adjust the contrast of an image or images by a random factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_contrast(object, factor, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_contrast_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_contrast_+3A_factor">factor</code></td>
<td>
<p>a positive float represented as fraction of value, or a list of
size 2 representing lower and upper bound. When represented as a single
float, lower = upper. The contrast factor will be randomly picked between
<code style="white-space: pre;">&#8288;[1.0 - lower, 1.0 + upper]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_random_contrast_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_contrast_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Contrast is adjusted independently for each channel of each image during
training.
</p>
<p>For each channel, this layer computes the mean of the image pixels in the
channel and then adjusts each component <code>x</code> of each pixel to
<code>(x - mean) * contrast_factor + mean</code>.
</p>
<p>Input shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format.
</p>
<p>Output shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/">https://keras.io/api/layers/preprocessing_layers/</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_crop'>Randomly crop the images to target height and width</h2><span id='topic+layer_random_crop'></span>

<h3>Description</h3>

<p>Randomly crop the images to target height and width
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_crop(object, height, width, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_crop_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_crop_+3A_height">height</code></td>
<td>
<p>Integer, the height of the output shape.</p>
</td></tr>
<tr><td><code id="layer_random_crop_+3A_width">width</code></td>
<td>
<p>Integer, the width of the output shape.</p>
</td></tr>
<tr><td><code id="layer_random_crop_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_crop_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer will crop all the images in the same batch to the same cropping
location.
By default, random cropping is only applied during training. At inference
time, the images will be first rescaled to preserve the shorter side, and
center cropped. If you need to apply random cropping at inference time,
set <code>training</code> to <code>TRUE</code> when calling the layer.
</p>
<p>Input shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format.
</p>
<p>Output shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., target_height, target_width, channels)&#8288;</code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomCrop">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomCrop</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_crop">https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_crop</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_flip'>Randomly flip each image horizontally and vertically</h2><span id='topic+layer_random_flip'></span>

<h3>Description</h3>

<p>Randomly flip each image horizontally and vertically
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_flip(object, mode = "horizontal_and_vertical", seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_flip_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_flip_+3A_mode">mode</code></td>
<td>
<p>String indicating which flip mode to use. Can be <code>"horizontal"</code>,
<code>"vertical"</code>, or <code>"horizontal_and_vertical"</code>. Defaults to
<code>"horizontal_and_vertical"</code>. <code>"horizontal"</code> is a left-right flip and
<code>"vertical"</code> is a top-bottom flip.</p>
</td></tr>
<tr><td><code id="layer_random_flip_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_flip_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer will flip the images based on the <code>mode</code> attribute.
During inference time, the output will be identical to input. Call the layer
with <code>training = TRUE</code> to flip the input.
</p>
<p>Input shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format.
</p>
<p>Output shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_flip">https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_flip</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_height'>Randomly vary the height of a batch of images during training</h2><span id='topic+layer_random_height'></span>

<h3>Description</h3>

<p>Randomly vary the height of a batch of images during training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_height(
  object,
  factor,
  interpolation = "bilinear",
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_height_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_height_+3A_factor">factor</code></td>
<td>
<p>A positive float (fraction of original height), or a list of size 2
representing lower and upper bound for resizing vertically. When
represented as a single float, this value is used for both the upper and
lower bound. For instance, <code>factor = c(0.2, 0.3)</code> results in an output with
height changed by a random amount in the range <code style="white-space: pre;">&#8288;[20%, 30%]&#8288;</code>.
<code>factor = c(-0.2, 0.3)</code> results in an output with height changed by a random
amount in the range <code style="white-space: pre;">&#8288;[-20%, +30%]&#8288;</code>. <code>factor=0.2</code> results in an output with
height changed by a random amount in the range <code style="white-space: pre;">&#8288;[-20%, +20%]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_random_height_+3A_interpolation">interpolation</code></td>
<td>
<p>String, the interpolation method. Defaults to <code>"bilinear"</code>.
Supports <code>"bilinear"</code>, <code>"nearest"</code>, <code>"bicubic"</code>, <code>"area"</code>,
<code>"lanczos3"</code>, <code>"lanczos5"</code>, <code>"gaussian"</code>, <code>"mitchellcubic"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_height_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_height_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adjusts the height of a batch of images by a random factor. The input
should be a 3D (unbatched) or 4D (batched) tensor in the <code>"channels_last"</code>
image data format.
</p>
<p>By default, this layer is inactive during inference.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomHeight">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomHeight</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/">https://keras.io/api/layers/preprocessing_layers/</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_rotation'>Randomly rotate each image</h2><span id='topic+layer_random_rotation'></span>

<h3>Description</h3>

<p>Randomly rotate each image
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_rotation(
  object,
  factor,
  fill_mode = "reflect",
  interpolation = "bilinear",
  seed = NULL,
  fill_value = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_rotation_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_rotation_+3A_factor">factor</code></td>
<td>
<p>a float represented as fraction of 2 Pi, or a list of size 2
representing lower and upper bound for rotating clockwise and
counter-clockwise. A positive values means rotating counter clock-wise,
while a negative value means clock-wise. When represented as a single
float, this value is used for both the upper and lower bound. For
instance, <code>factor = c(-0.2, 0.3)</code> results in an output rotation by a random
amount in the range <code style="white-space: pre;">&#8288;[-20% * 2pi, 30% * 2pi]&#8288;</code>. <code>factor = 0.2</code> results in an
output rotating by a random amount in the range <code style="white-space: pre;">&#8288;[-20% * 2pi, 20% * 2pi]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_random_rotation_+3A_fill_mode">fill_mode</code></td>
<td>
<p>Points outside the boundaries of the input are filled according
to the given mode (one of <code style="white-space: pre;">&#8288;{"constant", "reflect", "wrap", "nearest"}&#8288;</code>).
</p>

<ul>
<li> <p><em>reflect</em>: <code style="white-space: pre;">&#8288;(d c b a | a b c d | d c b a)&#8288;</code> The input is extended by
reflecting about the edge of the last pixel.
</p>
</li>
<li> <p><em>constant</em>: <code style="white-space: pre;">&#8288;(k k k k | a b c d | k k k k)&#8288;</code> The input is extended by
filling all values beyond the edge with the same constant value k = 0.
</p>
</li>
<li> <p><em>wrap</em>: <code style="white-space: pre;">&#8288;(a b c d | a b c d | a b c d)&#8288;</code> The input is extended by
wrapping around to the opposite edge.
</p>
</li>
<li> <p><em>nearest</em>: <code style="white-space: pre;">&#8288;(a a a a | a b c d | d d d d)&#8288;</code> The input is extended by the
nearest pixel.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_rotation_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: <code>"nearest"</code>,
<code>"bilinear"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_rotation_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_rotation_+3A_fill_value">fill_value</code></td>
<td>
<p>a float represents the value to be filled outside the boundaries
when <code>fill_mode="constant"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_rotation_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, random rotations are only applied during training.
At inference time, the layer does nothing. If you need to apply random
rotations at inference time, set <code>training</code> to TRUE when calling the layer.
</p>
<p>Input shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format
</p>
<p>Output shape:
3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">&#8288;(..., height, width, channels)&#8288;</code>, in <code>"channels_last"</code> format
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/">https://keras.io/api/layers/preprocessing_layers/</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_translation'>Randomly translate each image during training</h2><span id='topic+layer_random_translation'></span>

<h3>Description</h3>

<p>Randomly translate each image during training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_translation(
  object,
  height_factor,
  width_factor,
  fill_mode = "reflect",
  interpolation = "bilinear",
  seed = NULL,
  fill_value = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_translation_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_height_factor">height_factor</code></td>
<td>
<p>a float represented as fraction of value, or a list of size
2 representing lower and upper bound for shifting vertically. A negative
value means shifting image up, while a positive value means shifting image
down. When represented as a single positive float, this value is used for
both the upper and lower bound. For instance, <code>height_factor = c(-0.2, 0.3)</code>
results in an output shifted by a random amount in the range
<code style="white-space: pre;">&#8288;[-20%, +30%]&#8288;</code>.
<code>height_factor = 0.2</code> results in an output height shifted by a random amount
in the range <code style="white-space: pre;">&#8288;[-20%, +20%]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_width_factor">width_factor</code></td>
<td>
<p>a float represented as fraction of value, or a list of size 2
representing lower and upper bound for shifting horizontally. A negative
value means shifting image left, while a positive value means shifting
image right. When represented as a single positive float, this value is
used for both the upper and lower bound. For instance,
<code>width_factor = c(-0.2, 0.3)</code> results in an output shifted left by 20%, and
shifted right by 30%. <code>width_factor = 0.2</code> results in an output height
shifted left or right by 20%.</p>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_fill_mode">fill_mode</code></td>
<td>
<p>Points outside the boundaries of the input are filled according
to the given mode (one of <code style="white-space: pre;">&#8288;{"constant", "reflect", "wrap", "nearest"}&#8288;</code>).
</p>

<ul>
<li> <p><em>reflect</em>: <code style="white-space: pre;">&#8288;(d c b a | a b c d | d c b a)&#8288;</code> The input is extended by
reflecting about the edge of the last pixel.
</p>
</li>
<li> <p><em>constant</em>: <code style="white-space: pre;">&#8288;(k k k k | a b c d | k k k k)&#8288;</code> The input is extended by
filling all values beyond the edge with the same constant value k = 0.
</p>
</li>
<li> <p><em>wrap</em>: <code style="white-space: pre;">&#8288;(a b c d | a b c d | a b c d)&#8288;</code> The input is extended by
wrapping around to the opposite edge.
</p>
</li>
<li> <p><em>nearest</em>: <code style="white-space: pre;">&#8288;(a a a a | a b c d | d d d d)&#8288;</code> The input is extended by the
nearest pixel.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: <code>"nearest"</code>,
<code>"bilinear"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_fill_value">fill_value</code></td>
<td>
<p>a float represents the value to be filled outside the boundaries
when <code>fill_mode="constant"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_translation_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomTranslation">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomTranslation</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/">https://keras.io/api/layers/preprocessing_layers/</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_width'>Randomly vary the width of a batch of images during training</h2><span id='topic+layer_random_width'></span>

<h3>Description</h3>

<p>Randomly vary the width of a batch of images during training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_width(
  object,
  factor,
  interpolation = "bilinear",
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_width_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_width_+3A_factor">factor</code></td>
<td>
<p>A positive float (fraction of original height), or a list of size 2
representing lower and upper bound for resizing vertically. When
represented as a single float, this value is used for both the upper and
lower bound. For instance, <code>factor = c(0.2, 0.3)</code> results in an output with
width changed by a random amount in the range <code style="white-space: pre;">&#8288;[20%, 30%]&#8288;</code>. <code style="white-space: pre;">&#8288;factor=(-0.2, 0.3)&#8288;</code> results in an output with width changed by a random amount in the
range <code style="white-space: pre;">&#8288;[-20%, +30%]&#8288;</code>. <code>factor = 0.2</code> results in an output with width changed
by a random amount in the range <code style="white-space: pre;">&#8288;[-20%, +20%]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_random_width_+3A_interpolation">interpolation</code></td>
<td>
<p>String, the interpolation method. Defaults to <code>bilinear</code>.
Supports <code>"bilinear"</code>, <code>"nearest"</code>, <code>"bicubic"</code>, <code>"area"</code>, <code>"lanczos3"</code>,
<code>"lanczos5"</code>, <code>"gaussian"</code>, <code>"mitchellcubic"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_width_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_width_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adjusts the width of a batch of images by a random factor. The input
should be a 3D (unbatched) or 4D (batched) tensor in the <code>"channels_last"</code>
image data format.
</p>
<p>By default, this layer is inactive during inference.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomWidth">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomWidth</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/">https://keras.io/api/layers/preprocessing_layers/</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_random_zoom'>A preprocessing layer which randomly zooms images during training.</h2><span id='topic+layer_random_zoom'></span>

<h3>Description</h3>

<p>This layer will randomly zoom in or out on each axis of an image
independently, filling empty space according to fill_mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_random_zoom(
  object,
  height_factor,
  width_factor = NULL,
  fill_mode = "reflect",
  interpolation = "bilinear",
  seed = NULL,
  fill_value = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_random_zoom_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_height_factor">height_factor</code></td>
<td>
<p>a float represented as fraction of value, or a list of size
2 representing lower and upper bound for zooming vertically. When
represented as a single float, this value is used for both the upper and
lower bound. A positive value means zooming out, while a negative value
means zooming in. For instance, <code>height_factor = c(0.2, 0.3)</code> result in an
output zoomed out by a random amount in the range <code style="white-space: pre;">&#8288;[+20%, +30%]&#8288;</code>.
<code>height_factor = c(-0.3, -0.2)</code> result in an output zoomed in by a random
amount in the range <code style="white-space: pre;">&#8288;[+20%, +30%]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_width_factor">width_factor</code></td>
<td>
<p>a float represented as fraction of value, or a list of size 2
representing lower and upper bound for zooming horizontally. When
represented as a single float, this value is used for both the upper and
lower bound. For instance, <code>width_factor = c(0.2, 0.3)</code> result in an output
zooming out between 20% to 30%. <code>width_factor = c(-0.3, -0.2)</code> result in an
output zooming in between 20% to 30%. Defaults to <code>NULL</code>, i.e., zooming
vertical and horizontal directions by preserving the aspect ratio.</p>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_fill_mode">fill_mode</code></td>
<td>
<p>Points outside the boundaries of the input are filled according
to the given mode (one of <code style="white-space: pre;">&#8288;{"constant", "reflect", "wrap", "nearest"}&#8288;</code>).
</p>

<ul>
<li> <p><em>reflect</em>: <code style="white-space: pre;">&#8288;(d c b a | a b c d | d c b a)&#8288;</code> The input is extended by
reflecting about the edge of the last pixel.
</p>
</li>
<li> <p><em>constant</em>: <code style="white-space: pre;">&#8288;(k k k k | a b c d | k k k k)&#8288;</code> The input is extended by
filling all values beyond the edge with the same constant value k = 0.
</p>
</li>
<li> <p><em>wrap</em>: <code style="white-space: pre;">&#8288;(a b c d | a b c d | a b c d)&#8288;</code> The input is extended by
wrapping around to the opposite edge.
</p>
</li>
<li> <p><em>nearest</em>: <code style="white-space: pre;">&#8288;(a a a a | a b c d | d d d d)&#8288;</code> The input is extended by the
nearest pixel.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: <code>"nearest"</code>,
<code>"bilinear"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_seed">seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_fill_value">fill_value</code></td>
<td>
<p>a float represents the value to be filled outside the boundaries
when <code>fill_mode="constant"</code>.</p>
</td></tr>
<tr><td><code id="layer_random_zoom_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/">https://keras.io/api/layers/preprocessing_layers/</a>
</p>
</li></ul>

<p>Other image augmentation layers: 
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_repeat_vector'>Repeats the input n times.</h2><span id='topic+layer_repeat_vector'></span>

<h3>Description</h3>

<p>Repeats the input n times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_repeat_vector(
  object,
  n,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_repeat_vector_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_repeat_vector_+3A_n">n</code></td>
<td>
<p>integer, repetition factor.</p>
</td></tr>
<tr><td><code id="layer_repeat_vector_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_repeat_vector_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_repeat_vector_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_repeat_vector_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>2D tensor of shape <code style="white-space: pre;">&#8288;(num_samples, features)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>3D tensor of shape <code style="white-space: pre;">&#8288;(num_samples, n, features)&#8288;</code>.
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_reshape">layer_reshape</a>()</code>
</p>

<hr>
<h2 id='layer_rescaling'>Multiply inputs by <code>scale</code> and adds <code>offset</code></h2><span id='topic+layer_rescaling'></span>

<h3>Description</h3>

<p>Multiply inputs by <code>scale</code> and adds <code>offset</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_rescaling(object, scale, offset = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_rescaling_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_rescaling_+3A_scale">scale</code></td>
<td>
<p>Float, the scale to apply to the inputs.</p>
</td></tr>
<tr><td><code id="layer_rescaling_+3A_offset">offset</code></td>
<td>
<p>Float, the offset to apply to the inputs.</p>
</td></tr>
<tr><td><code id="layer_rescaling_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For instance:
</p>

<ol>
<li><p> To rescale an input in the <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code> range
to be in the <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> range, you would pass <code>scale=1./255</code>.
</p>
</li>
<li><p> To rescale an input in the <code style="white-space: pre;">&#8288;[0, 255]&#8288;</code> range to be in the <code style="white-space: pre;">&#8288;[-1, 1]&#8288;</code> range,
you would pass <code style="white-space: pre;">&#8288;scale = 1/127.5, offset = -1&#8288;</code>.
</p>
</li></ol>

<p>The rescaling is applied both during training and inference.
</p>
<p>Input shape:
Arbitrary.
</p>
<p>Output shape:
Same as input.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling">https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling</a>
</p>
</li></ul>

<p>Other image preprocessing layers: 
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_reshape'>Reshapes an output to a certain shape.</h2><span id='topic+layer_reshape'></span>

<h3>Description</h3>

<p>Reshapes an output to a certain shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_reshape(
  object,
  target_shape,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_reshape_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_reshape_+3A_target_shape">target_shape</code></td>
<td>
<p>List of integers, does not include the samples dimension
(batch size).</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_input_shape">input_shape</code></td>
<td>
<p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_reshape_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input and Output Shapes</h3>

<p>Input shape: Arbitrary, although all dimensions in the input shaped must be
fixed.
</p>
<p>Output shape: <code style="white-space: pre;">&#8288;(batch_size,) + target_shape&#8288;</code>.
</p>


<h3>See Also</h3>

<p>Other core layers: 
<code><a href="#topic+layer_activation">layer_activation</a>()</code>,
<code><a href="#topic+layer_activity_regularization">layer_activity_regularization</a>()</code>,
<code><a href="#topic+layer_attention">layer_attention</a>()</code>,
<code><a href="#topic+layer_dense">layer_dense</a>()</code>,
<code><a href="#topic+layer_dense_features">layer_dense_features</a>()</code>,
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_flatten">layer_flatten</a>()</code>,
<code><a href="#topic+layer_input">layer_input</a>()</code>,
<code><a href="#topic+layer_lambda">layer_lambda</a>()</code>,
<code><a href="#topic+layer_masking">layer_masking</a>()</code>,
<code><a href="#topic+layer_permute">layer_permute</a>()</code>,
<code><a href="#topic+layer_repeat_vector">layer_repeat_vector</a>()</code>
</p>

<hr>
<h2 id='layer_resizing'>Image resizing layer</h2><span id='topic+layer_resizing'></span>

<h3>Description</h3>

<p>Image resizing layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_resizing(
  object,
  height,
  width,
  interpolation = "bilinear",
  crop_to_aspect_ratio = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_resizing_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_resizing_+3A_height">height</code></td>
<td>
<p>Integer, the height of the output shape.</p>
</td></tr>
<tr><td><code id="layer_resizing_+3A_width">width</code></td>
<td>
<p>Integer, the width of the output shape.</p>
</td></tr>
<tr><td><code id="layer_resizing_+3A_interpolation">interpolation</code></td>
<td>
<p>String, the interpolation method. Defaults to <code>"bilinear"</code>.
Supports <code>"bilinear"</code>, <code>"nearest"</code>, <code>"bicubic"</code>, <code>"area"</code>, <code>"lanczos3"</code>,
<code>"lanczos5"</code>, <code>"gaussian"</code>, and <code>"mitchellcubic"</code>.</p>
</td></tr>
<tr><td><code id="layer_resizing_+3A_crop_to_aspect_ratio">crop_to_aspect_ratio</code></td>
<td>
<p>If TRUE, resize the images without aspect
ratio distortion. When the original aspect ratio differs from the target
aspect ratio, the output image will be cropped so as to return the largest
possible window in the image (of size <code style="white-space: pre;">&#8288;(height, width)&#8288;</code>) that matches
the target aspect ratio. By default (<code>crop_to_aspect_ratio = FALSE</code>),
aspect ratio may not be preserved.</p>
</td></tr>
<tr><td><code id="layer_resizing_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Resize the batched image input to target height and width. The input should
be a 4D (batched) or 3D (unbatched) tensor in <code>"channels_last"</code> format.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Resizing">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Resizing</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing">https://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing</a>
</p>
</li></ul>

<p>Other image preprocessing layers: 
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_rnn'>Base class for recurrent layers</h2><span id='topic+layer_rnn'></span>

<h3>Description</h3>

<p>Base class for recurrent layers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_rnn(
  object,
  cell,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  unroll = FALSE,
  time_major = FALSE,
  ...,
  zero_output_for_mask = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_rnn_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_rnn_+3A_cell">cell</code></td>
<td>
<p>A RNN cell instance or a list of RNN cell instances.
A RNN cell is a class that has:
</p>

<ul>
<li><p> A <code>call(input_at_t, states_at_t)</code> method, returning
<code style="white-space: pre;">&#8288;(output_at_t, states_at_t_plus_1)&#8288;</code>. The call method of the
cell can also take the optional argument <code>constants</code>, see
section &quot;Note on passing external constants&quot; below.
</p>
</li>
<li><p> A <code>state_size</code> attribute. This can be a single integer
(single state) in which case it is the size of the recurrent
state. This can also be a list of integers (one size per state).
The <code>state_size</code> can also be TensorShape or list of
TensorShape, to represent high dimension state.
</p>
</li>
<li><p> A <code>output_size</code> attribute. This can be a single integer or a
TensorShape, which represent the shape of the output. For backward
compatible reason, if this attribute is not available for the
cell, the value will be inferred by the first element of the
<code>state_size</code>.
</p>
</li>
<li><p> A <code>get_initial_state(inputs=NULL, batch_size=NULL, dtype=NULL)</code>
method that creates a tensor meant to be fed to <code>call()</code> as the
initial state, if the user didn't specify any initial state via other
means. The returned initial state should have a shape of
<code style="white-space: pre;">&#8288;[batch_size, cell$state_size]&#8288;</code>. The cell might choose to create a
tensor full of zeros, or full of other values based on the cell's
implementation.
<code>inputs</code> is the input tensor to the RNN layer, which should
contain the batch size as first dimension (<code>inputs$shape[1]</code>),
and also dtype (<code>inputs$dtype</code>). Note that
the <code>shape[1]</code> might be <code>NULL</code> during the graph construction. Either
the <code>inputs</code> or the pair of <code>batch_size</code> and <code>dtype</code> are provided.
<code>batch_size</code> is a scalar tensor that represents the batch size
of the inputs. <code>dtype</code> is <code>tf.DType</code> that represents the dtype of
the inputs.
For backward compatibility, if this method is not implemented
by the cell, the RNN layer will create a zero filled tensor with the
size of <code style="white-space: pre;">&#8288;[batch_size, cell$state_size]&#8288;</code>.
In the case that <code>cell</code> is a list of RNN cell instances, the cells
will be stacked on top of each other in the RNN, resulting in an
efficient stacked RNN.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_rnn_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean (default <code>FALSE</code>). Whether to return the last
output in the output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_return_state">return_state</code></td>
<td>
<p>Boolean (default <code>FALSE</code>). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default <code>FALSE</code>).
If <code>TRUE</code>, process the input sequence backwards and return the
reversed sequence.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default <code>FALSE</code>). If <code>TRUE</code>, the last state
for each sample at index <code>i</code> in a batch will be used as initial
state for the sample of index <code>i</code> in the following batch.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_unroll">unroll</code></td>
<td>
<p>Boolean (default <code>FALSE</code>).
If TRUE, the network will be unrolled, else a symbolic loop will be used.
Unrolling can speed-up a RNN, although it tends to be more
memory-intensive. Unrolling is only suitable for short sequences.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_time_major">time_major</code></td>
<td>
<p>The shape format of the <code>inputs</code> and <code>outputs</code> tensors.
If <code>TRUE</code>, the inputs and outputs will be in shape
<code style="white-space: pre;">&#8288;(timesteps, batch, ...)&#8288;</code>, whereas in the FALSE case, it will be
<code style="white-space: pre;">&#8288;(batch, timesteps, ...)&#8288;</code>. Using <code>time_major = TRUE</code> is a bit more
efficient because it avoids transposes at the beginning and end of the
RNN calculation. However, most TensorFlow data is batch-major, so by
default this function accepts input and emits output in batch-major
form.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
<tr><td><code id="layer_rnn_+3A_zero_output_for_mask">zero_output_for_mask</code></td>
<td>
<p>Boolean (default <code>FALSE</code>).
Whether the output should use zeros for the masked timesteps. Note that
this field is only used when <code>return_sequences</code> is TRUE and mask is
provided. It can useful if you want to reuse the raw output sequence of
the RNN without interference from the masked timesteps, eg, merging
bidirectional RNNs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://www.tensorflow.org/guide/keras/rnn">the Keras RNN API guide</a>
for details about the usage of RNN API.
</p>


<h3>Call arguments</h3>


<ul>
<li> <p><code>inputs</code>: Input tensor.
</p>
</li>
<li> <p><code>mask</code>: Binary tensor of shape <code style="white-space: pre;">&#8288;[batch_size, timesteps]&#8288;</code> indicating whether
a given timestep should be masked. An individual <code>TRUE</code> entry indicates
that the corresponding timestep should be utilized, while a <code>FALSE</code>
entry indicates that the corresponding timestep should be ignored.
</p>
</li>
<li> <p><code>training</code>: R or Python Boolean indicating whether the layer should behave in
training mode or in inference mode. This argument is passed to the cell
when calling it. This is for use with cells that use dropout.
</p>
</li>
<li> <p><code>initial_state</code>: List of initial state tensors to be passed to the first
call of the cell.
</p>
</li>
<li> <p><code>constants</code>: List of constant tensors to be passed to the cell at each
timestep.
</p>
</li></ul>



<h3>Input shapes</h3>

<p>N-D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, timesteps, ...)&#8288;</code>,
or <code style="white-space: pre;">&#8288;(timesteps, batch_size, ...)&#8288;</code> when <code>time_major = TRUE</code>.
</p>


<h3>Output shape</h3>


<ul>
<li><p> if <code>return_state</code>: a list of tensors. The first tensor is
the output. The remaining tensors are the last states,
each with shape <code style="white-space: pre;">&#8288;(batch_size, state_size)&#8288;</code>, where <code>state_size</code>
could be a high dimension tensor shape.
</p>
</li>
<li><p> if <code>return_sequences</code>: N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, timesteps, output_size]&#8288;</code>, where <code>output_size</code> could be a high dimension tensor shape, or
<code style="white-space: pre;">&#8288;[timesteps, batch_size, output_size]&#8288;</code> when <code>time_major</code> is <code>TRUE</code>
</p>
</li>
<li><p> else, N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, output_size]&#8288;</code>, where
<code>output_size</code> could be a high dimension tensor shape.
</p>
</li></ul>



<h3>Masking</h3>

<p>This layer supports masking for input data with a variable number of
timesteps. To introduce masks to your data, use
<code><a href="#topic+layer_embedding">layer_embedding()</a></code> with the <code>mask_zero</code> parameter set to <code>TRUE</code>.
</p>


<h3>Statefulness in RNNs</h3>

<p>You can set RNN layers to be 'stateful', which means that the states computed
for the samples in one batch will be reused as initial states for the samples
in the next batch. This assumes a one-to-one mapping between samples in
different successive batches.
</p>
<p>For intuition behind statefulness, there is a helpful blog post here:
<a href="https://philipperemy.github.io/keras-stateful-lstm/">https://philipperemy.github.io/keras-stateful-lstm/</a>
</p>
<p>To enable statefulness:
</p>

<ul>
<li><p> Specify <code>stateful = TRUE</code> in the layer constructor.
</p>
</li>
<li><p> Specify a fixed batch size for your model. For sequential models,
pass <code>batch_input_shape = list(...)</code> to the first layer in your model.
For functional models with 1 or more Input layers, pass
<code>batch_shape = list(...)</code> to all the first layers in your model.
This is the expected shape of your inputs <em>including the batch size</em>.
It should be a list of integers, e.g. <code>list(32, 10, 100)</code>.
For dimensions which can vary (are not known ahead of time),
use <code>NULL</code> in place of an integer, e.g. <code>list(32, NULL, NULL)</code>.
</p>
</li>
<li><p> Specify <code>shuffle = FALSE</code> when calling <code>fit()</code>.
</p>
</li></ul>

<p>To reset the states of your model, call <code>layer$reset_states()</code> on either
a specific layer, or on your entire model.
</p>


<h3>Initial State of RNNs</h3>

<p>You can specify the initial state of RNN layers symbolically by calling them
with the keyword argument <code>initial_state.</code> The value of initial_state should
be a tensor or list of tensors representing the initial state of the RNN
layer.
</p>
<p>You can specify the initial state of RNN layers numerically by calling
<code>reset_states</code> with the named argument <code>states.</code> The value of <code>states</code> should
be an array or list of arrays representing the initial state of the RNN
layer.
</p>


<h3>Passing external constants to RNNs</h3>

<p>You can pass &quot;external&quot; constants to the cell using the <code>constants</code> named
argument of <code style="white-space: pre;">&#8288;RNN$__call__&#8288;</code> (as well as <code>RNN$call</code>) method. This requires that the
<code>cell$call</code> method accepts the same keyword argument <code>constants</code>. Such constants
can be used to condition the cell transformation on additional static inputs
(not changing over time), a.k.a. an attention mechanism.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/guide/keras/rnn">https://www.tensorflow.org/guide/keras/rnn</a>
</p>
</li></ul>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/recurrent_layers/rnn">https://keras.io/api/layers/recurrent_layers/rnn</a>
</p>
</li>
<li> <p><code>reticulate::py_help(keras$layers$RNN)</code>
</p>
</li></ul>

<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_gru">layer_cudnn_gru</a>()</code>,
<code><a href="#topic+layer_cudnn_lstm">layer_cudnn_lstm</a>()</code>,
<code><a href="#topic+layer_gru">layer_gru</a>()</code>,
<code><a href="#topic+layer_lstm">layer_lstm</a>()</code>,
<code><a href="#topic+layer_simple_rnn">layer_simple_rnn</a>()</code>
</p>

<hr>
<h2 id='layer_separable_conv_1d'>Depthwise separable 1D convolution.</h2><span id='topic+layer_separable_conv_1d'></span>

<h3>Description</h3>

<p>Separable convolutions consist in first performing a depthwise spatial
convolution (which acts on each input channel separately) followed by a
pointwise convolution which mixes together the resulting output channels. The
<code>depth_multiplier</code> argument controls how many output channels are generated
per input channel in the depthwise step. Intuitively, separable convolutions
can be understood as a way to factorize a convolution kernel into two smaller
kernels, or as an extreme version of an Inception block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_separable_conv_1d(
  object,
  filters,
  kernel_size,
  strides = 1,
  padding = "valid",
  data_format = "channels_last",
  dilation_rate = 1,
  depth_multiplier = 1,
  activation = NULL,
  use_bias = TRUE,
  depthwise_initializer = "glorot_uniform",
  pointwise_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  depthwise_regularizer = NULL,
  pointwise_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  depthwise_constraint = NULL,
  pointwise_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_separable_conv_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 2 integers, specifying the width and
height of the 2D convolution window. Can be a single integer to specify the
same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 2 integers, specifying the strides of
the convolution along the width and height. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of 2 integers, specifying the
dilation rate to use for dilated convolution. Can be a single integer to
specify the same value for all spatial dimensions. Currently, specifying
any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride
value != 1.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_depth_multiplier">depth_multiplier</code></td>
<td>
<p>The number of depthwise convolution output channels
for each input channel. The total number of depthwise convolution output
channels will be equal to <code>filters_in * depth_multiplier</code>.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_depthwise_initializer">depthwise_initializer</code></td>
<td>
<p>Initializer for the depthwise kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_pointwise_initializer">pointwise_initializer</code></td>
<td>
<p>Initializer for the pointwise kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_depthwise_regularizer">depthwise_regularizer</code></td>
<td>
<p>Regularizer function applied to the depthwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_pointwise_regularizer">pointwise_regularizer</code></td>
<td>
<p>Regularizer function applied to the pointwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_depthwise_constraint">depthwise_constraint</code></td>
<td>
<p>Constraint function applied to the depthwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_pointwise_constraint">pointwise_constraint</code></td>
<td>
<p>Constraint function applied to the pointwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, channels, steps)&#8288;</code>
if data_format='channels_first' or 3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, steps, channels)&#8288;</code>
if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, filters, new_steps)&#8288;</code>
if data_format='channels_first' or 3D tensor with shape:
<code style="white-space: pre;">&#8288;(batch, new_steps, filters)&#8288;</code> if data_format='channels_last'.
<code>new_steps</code> values might have changed due to padding or strides.
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_separable_conv_2d'>Separable 2D convolution.</h2><span id='topic+layer_separable_conv_2d'></span>

<h3>Description</h3>

<p>Separable convolutions consist in first performing a depthwise spatial
convolution (which acts on each input channel separately) followed by a
pointwise convolution which mixes together the resulting output channels. The
<code>depth_multiplier</code> argument controls how many output channels are generated
per input channel in the depthwise step. Intuitively, separable convolutions
can be understood as a way to factorize a convolution kernel into two smaller
kernels, or as an extreme version of an Inception block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_separable_conv_2d(
  object,
  filters,
  kernel_size,
  strides = c(1, 1),
  padding = "valid",
  data_format = NULL,
  dilation_rate = 1,
  depth_multiplier = 1,
  activation = NULL,
  use_bias = TRUE,
  depthwise_initializer = "glorot_uniform",
  pointwise_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  depthwise_regularizer = NULL,
  pointwise_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  depthwise_constraint = NULL,
  pointwise_constraint = NULL,
  bias_constraint = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_separable_conv_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_filters">filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the
number of output filters in the convolution).</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer or list of 2 integers, specifying the width and
height of the 2D convolution window. Can be a single integer to specify the
same value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_strides">strides</code></td>
<td>
<p>An integer or list of 2 integers, specifying the strides of
the convolution along the width and height. Can be a single integer to
specify the same value for all spatial dimensions. Specifying any stride
value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_padding">padding</code></td>
<td>
<p>one of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_dilation_rate">dilation_rate</code></td>
<td>
<p>an integer or list of 2 integers, specifying the
dilation rate to use for dilated convolution. Can be a single integer to
specify the same value for all spatial dimensions. Currently, specifying
any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride
value != 1.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_depth_multiplier">depth_multiplier</code></td>
<td>
<p>The number of depthwise convolution output channels
for each input channel. The total number of depthwise convolution output
channels will be equal to <code>filters_in * depth_multiplier</code>.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. If you don't specify anything,
no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_depthwise_initializer">depthwise_initializer</code></td>
<td>
<p>Initializer for the depthwise kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_pointwise_initializer">pointwise_initializer</code></td>
<td>
<p>Initializer for the pointwise kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_depthwise_regularizer">depthwise_regularizer</code></td>
<td>
<p>Regularizer function applied to the depthwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_pointwise_regularizer">pointwise_regularizer</code></td>
<td>
<p>Regularizer function applied to the pointwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_depthwise_constraint">depthwise_constraint</code></td>
<td>
<p>Constraint function applied to the depthwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_pointwise_constraint">pointwise_constraint</code></td>
<td>
<p>Constraint function applied to the pointwise
kernel matrix.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_input_shape">input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_batch_input_shape">batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_separable_conv_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(batch, channels, rows, cols)&#8288;</code>
if data_format='channels_first' or 4D tensor with shape: <code style="white-space: pre;">&#8288;(batch, rows, cols, channels)&#8288;</code> if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(batch, filters, new_rows, new_cols)&#8288;</code> if data_format='channels_first' or 4D tensor with shape:
<code style="white-space: pre;">&#8288;(batch, new_rows, new_cols, filters)&#8288;</code> if data_format='channels_last'.
<code>rows</code> and <code>cols</code> values might have changed due to padding.
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_simple_rnn'>Fully-connected RNN where the output is to be fed back to input.</h2><span id='topic+layer_simple_rnn'></span>

<h3>Description</h3>

<p>Fully-connected RNN where the output is to be fed back to input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_simple_rnn(
  object,
  units,
  activation = "tanh",
  use_bias = TRUE,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  unroll = FALSE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_simple_rnn_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. Default: hyperbolic tangent
(<code>tanh</code>). If you pass <code>NULL</code>, no activation is applied
(ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_return_sequences">return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the
output sequence, or the full sequence.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_return_state">return_state</code></td>
<td>
<p>Boolean (default FALSE). Whether to return the last state
in addition to the output.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_go_backwards">go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, process the input
sequence backwards and return the reversed sequence.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_stateful">stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each
sample at index i in a batch will be used as initial state for the sample
of index i in the following batch.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_unroll">unroll</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the network will be unrolled,
else a symbolic loop will be used. Unrolling can speed-up a RNN, although
it tends to be more memory-intensive. Unrolling is only suitable for short
sequences.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used
for the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code>
weights matrix.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_activity_regularizer">activity_regularizer</code></td>
<td>
<p>Regularizer function applied to the output of the
layer (its &quot;activation&quot;)..</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the
linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop
for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_+3A_...">...</code></td>
<td>
<p>Standard Layer args.</p>
</td></tr>
</table>


<h3>Input shapes</h3>

<p>N-D tensor with shape <code style="white-space: pre;">&#8288;(batch_size, timesteps, ...)&#8288;</code>,
or <code style="white-space: pre;">&#8288;(timesteps, batch_size, ...)&#8288;</code> when <code>time_major = TRUE</code>.
</p>


<h3>Output shape</h3>


<ul>
<li><p> if <code>return_state</code>: a list of tensors. The first tensor is
the output. The remaining tensors are the last states,
each with shape <code style="white-space: pre;">&#8288;(batch_size, state_size)&#8288;</code>, where <code>state_size</code>
could be a high dimension tensor shape.
</p>
</li>
<li><p> if <code>return_sequences</code>: N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, timesteps, output_size]&#8288;</code>, where <code>output_size</code> could be a high dimension tensor shape, or
<code style="white-space: pre;">&#8288;[timesteps, batch_size, output_size]&#8288;</code> when <code>time_major</code> is <code>TRUE</code>
</p>
</li>
<li><p> else, N-D tensor with shape <code style="white-space: pre;">&#8288;[batch_size, output_size]&#8288;</code>, where
<code>output_size</code> could be a high dimension tensor shape.
</p>
</li></ul>



<h3>Masking</h3>

<p>This layer supports masking for input data with a variable number of
timesteps. To introduce masks to your data, use
<code><a href="#topic+layer_embedding">layer_embedding()</a></code> with the <code>mask_zero</code> parameter set to <code>TRUE</code>.
</p>


<h3>Statefulness in RNNs</h3>

<p>You can set RNN layers to be 'stateful', which means that the states computed
for the samples in one batch will be reused as initial states for the samples
in the next batch. This assumes a one-to-one mapping between samples in
different successive batches.
</p>
<p>For intuition behind statefulness, there is a helpful blog post here:
<a href="https://philipperemy.github.io/keras-stateful-lstm/">https://philipperemy.github.io/keras-stateful-lstm/</a>
</p>
<p>To enable statefulness:
</p>

<ul>
<li><p> Specify <code>stateful = TRUE</code> in the layer constructor.
</p>
</li>
<li><p> Specify a fixed batch size for your model. For sequential models,
pass <code>batch_input_shape = list(...)</code> to the first layer in your model.
For functional models with 1 or more Input layers, pass
<code>batch_shape = list(...)</code> to all the first layers in your model.
This is the expected shape of your inputs <em>including the batch size</em>.
It should be a list of integers, e.g. <code>list(32, 10, 100)</code>.
For dimensions which can vary (are not known ahead of time),
use <code>NULL</code> in place of an integer, e.g. <code>list(32, NULL, NULL)</code>.
</p>
</li>
<li><p> Specify <code>shuffle = FALSE</code> when calling <code>fit()</code>.
</p>
</li></ul>

<p>To reset the states of your model, call <code>layer$reset_states()</code> on either
a specific layer, or on your entire model.
</p>


<h3>Initial State of RNNs</h3>

<p>You can specify the initial state of RNN layers symbolically by calling them
with the keyword argument <code>initial_state.</code> The value of initial_state should
be a tensor or list of tensors representing the initial state of the RNN
layer.
</p>
<p>You can specify the initial state of RNN layers numerically by calling
<code>reset_states</code> with the named argument <code>states.</code> The value of <code>states</code> should
be an array or list of arrays representing the initial state of the RNN
layer.
</p>


<h3>Passing external constants to RNNs</h3>

<p>You can pass &quot;external&quot; constants to the cell using the <code>constants</code> named
argument of <code style="white-space: pre;">&#8288;RNN$__call__&#8288;</code> (as well as <code>RNN$call</code>) method. This requires that the
<code>cell$call</code> method accepts the same keyword argument <code>constants</code>. Such constants
can be used to condition the cell transformation on additional static inputs
(not changing over time), a.k.a. an attention mechanism.
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/guide/keras/rnn">https://www.tensorflow.org/guide/keras/rnn</a>
</p>
</li></ul>

<p>Other recurrent layers: 
<code><a href="#topic+layer_cudnn_gru">layer_cudnn_gru</a>()</code>,
<code><a href="#topic+layer_cudnn_lstm">layer_cudnn_lstm</a>()</code>,
<code><a href="#topic+layer_gru">layer_gru</a>()</code>,
<code><a href="#topic+layer_lstm">layer_lstm</a>()</code>,
<code><a href="#topic+layer_rnn">layer_rnn</a>()</code>
</p>

<hr>
<h2 id='layer_simple_rnn_cell'>Cell class for SimpleRNN</h2><span id='topic+layer_simple_rnn_cell'></span>

<h3>Description</h3>

<p>Cell class for SimpleRNN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_simple_rnn_cell(
  units,
  activation = "tanh",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_simple_rnn_cell_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_activation">activation</code></td>
<td>
<p>Activation function to use.
Default: hyperbolic tangent (<code>tanh</code>).
If you pass <code>NULL</code>, no activation is applied
(ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, (default <code>TRUE</code>), whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix,
used for the linear transformation of the inputs. Default:
<code>glorot_uniform</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code>
weights matrix, used for the linear transformation of the recurrent state.
Default: <code>orthogonal</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector. Default: <code>zeros</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code> weights
matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the <code>recurrent_kernel</code>
weights matrix. Default: <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector. Default:
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear
transformation of the inputs. Default: 0.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for
the linear transformation of the recurrent state. Default: 0.</p>
</td></tr>
<tr><td><code id="layer_simple_rnn_cell_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://www.tensorflow.org/guide/keras/rnn">the Keras RNN API guide</a>
for details about the usage of RNN API.
</p>
<p>This class processes one step within the whole time sequence input, whereas
<code>tf.keras.layer.SimpleRNN</code> processes the whole sequence.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell">https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers">https://keras.io/api/layers</a>
</p>
</li></ul>

<p>Other RNN cell layers: 
<code><a href="#topic+layer_gru_cell">layer_gru_cell</a>()</code>,
<code><a href="#topic+layer_lstm_cell">layer_lstm_cell</a>()</code>,
<code><a href="#topic+layer_stacked_rnn_cells">layer_stacked_rnn_cells</a>()</code>
</p>

<hr>
<h2 id='layer_spatial_dropout_1d'>Spatial 1D version of Dropout.</h2><span id='topic+layer_spatial_dropout_1d'></span>

<h3>Description</h3>

<p>This version performs the same function as Dropout, however it drops entire
1D feature maps instead of individual elements. If adjacent frames within
feature maps are strongly correlated (as is normally the case in early
convolution layers) then regular dropout will not regularize the activations
and will otherwise just result in an effective learning rate decrease. In
this case, <code>layer_spatial_dropout_1d</code> will help promote independence between
feature maps and should be used instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_spatial_dropout_1d(
  object,
  rate,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_spatial_dropout_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_spatial_dropout_1d_+3A_rate">rate</code></td>
<td>
<p>float between 0 and 1. Fraction of the input units to drop.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(samples, timesteps, channels)&#8288;</code>
</p>


<h3>Output shape</h3>

<p>Same as input
</p>


<h3>References</h3>

<p>- <a href="https://arxiv.org/abs/1411.4280">Efficient Object Localization Using Convolutional Networks</a>
</p>


<h3>See Also</h3>

<p>Other dropout layers: 
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_2d">layer_spatial_dropout_2d</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_3d">layer_spatial_dropout_3d</a>()</code>
</p>

<hr>
<h2 id='layer_spatial_dropout_2d'>Spatial 2D version of Dropout.</h2><span id='topic+layer_spatial_dropout_2d'></span>

<h3>Description</h3>

<p>This version performs the same function as Dropout, however it drops entire
2D feature maps instead of individual elements. If adjacent pixels within
feature maps are strongly correlated (as is normally the case in early
convolution layers) then regular dropout will not regularize the activations
and will otherwise just result in an effective learning rate decrease. In
this case, <code>layer_spatial_dropout_2d</code> will help promote independence between
feature maps and should be used instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_spatial_dropout_2d(
  object,
  rate,
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_spatial_dropout_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_spatial_dropout_2d_+3A_rate">rate</code></td>
<td>
<p>float between 0 and 1. Fraction of the input units to drop.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_2d_+3A_data_format">data_format</code></td>
<td>
<p>'channels_first' or 'channels_last'. In 'channels_first'
mode, the channels dimension (the depth) is at index 1, in 'channels_last'
mode is it at index 3. It defaults to the <code>image_data_format</code> value found
in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it,
then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, channels, rows, cols)&#8288;</code>
if data_format='channels_first' or 4D tensor with shape: <code style="white-space: pre;">&#8288;(samples, rows, cols, channels)&#8288;</code> if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>Same as input
</p>


<h3>References</h3>

<p>- <a href="https://arxiv.org/abs/1411.4280">Efficient Object Localization Using Convolutional Networks</a>
</p>


<h3>See Also</h3>

<p>Other dropout layers: 
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_1d">layer_spatial_dropout_1d</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_3d">layer_spatial_dropout_3d</a>()</code>
</p>

<hr>
<h2 id='layer_spatial_dropout_3d'>Spatial 3D version of Dropout.</h2><span id='topic+layer_spatial_dropout_3d'></span>

<h3>Description</h3>

<p>This version performs the same function as Dropout, however it drops entire
3D feature maps instead of individual elements. If adjacent voxels within
feature maps are strongly correlated (as is normally the case in early
convolution layers) then regular dropout will not regularize the activations
and will otherwise just result in an effective learning rate decrease. In
this case, <code>layer_spatial_dropout_3d</code> will help promote independence between
feature maps and should be used instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_spatial_dropout_3d(
  object,
  rate,
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_spatial_dropout_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_spatial_dropout_3d_+3A_rate">rate</code></td>
<td>
<p>float between 0 and 1. Fraction of the input units to drop.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_3d_+3A_data_format">data_format</code></td>
<td>
<p>'channels_first' or 'channels_last'. In 'channels_first'
mode, the channels dimension (the depth) is at index 1, in 'channels_last'
mode is it at index 4. It defaults to the <code>image_data_format</code> value found
in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it,
then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_spatial_dropout_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>5D tensor with shape: <code style="white-space: pre;">&#8288;(samples, channels, dim1, dim2, dim3)&#8288;</code> if data_format='channels_first' or 5D tensor with shape: <code style="white-space: pre;">&#8288;(samples, dim1, dim2, dim3, channels)&#8288;</code> if data_format='channels_last'.
</p>


<h3>Output shape</h3>

<p>Same as input
</p>


<h3>References</h3>

<p>- <a href="https://arxiv.org/abs/1411.4280">Efficient Object Localization Using Convolutional Networks</a>
</p>


<h3>See Also</h3>

<p>Other dropout layers: 
<code><a href="#topic+layer_dropout">layer_dropout</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_1d">layer_spatial_dropout_1d</a>()</code>,
<code><a href="#topic+layer_spatial_dropout_2d">layer_spatial_dropout_2d</a>()</code>
</p>

<hr>
<h2 id='layer_stacked_rnn_cells'>Wrapper allowing a stack of RNN cells to behave as a single cell</h2><span id='topic+layer_stacked_rnn_cells'></span>

<h3>Description</h3>

<p>Used to implement efficient stacked RNNs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_stacked_rnn_cells(cells, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_stacked_rnn_cells_+3A_cells">cells</code></td>
<td>
<p>List of RNN cell instances.</p>
</td></tr>
<tr><td><code id="layer_stacked_rnn_cells_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells">https://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells</a>
</p>
</li></ul>

<p>Other RNN cell layers: 
<code><a href="#topic+layer_gru_cell">layer_gru_cell</a>()</code>,
<code><a href="#topic+layer_lstm_cell">layer_lstm_cell</a>()</code>,
<code><a href="#topic+layer_simple_rnn_cell">layer_simple_rnn_cell</a>()</code>
</p>

<hr>
<h2 id='layer_string_lookup'>A preprocessing layer which maps string features to integer indices.</h2><span id='topic+layer_string_lookup'></span>

<h3>Description</h3>

<p>A preprocessing layer which maps string features to integer indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_string_lookup(
  object,
  max_tokens = NULL,
  num_oov_indices = 1L,
  mask_token = NULL,
  oov_token = "[UNK]",
  vocabulary = NULL,
  idf_weights = NULL,
  encoding = "utf-8",
  invert = FALSE,
  output_mode = "int",
  sparse = FALSE,
  pad_to_max_tokens = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_string_lookup_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_max_tokens">max_tokens</code></td>
<td>
<p>Maximum size of the vocabulary for this layer. This should
only be specified when adapting the vocabulary or when setting
<code>pad_to_max_tokens = TRUE</code>. If NULL, there is no cap on the size of the
vocabulary. Note that this size includes the OOV and mask tokens.
Defaults to NULL.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_num_oov_indices">num_oov_indices</code></td>
<td>
<p>The number of out-of-vocabulary tokens to use. If this
value is more than 1, OOV inputs are hashed to determine their OOV
value. If this value is 0, OOV inputs will cause an error when calling
the layer. Defaults to 1.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_mask_token">mask_token</code></td>
<td>
<p>A token that represents masked inputs. When <code>output_mode</code> is
<code>"int"</code>, the token is included in vocabulary and mapped to index 0. In
other output modes, the token will not appear in the vocabulary and
instances of the mask token in the input will be dropped. If set to
NULL, no mask term will be added. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_oov_token">oov_token</code></td>
<td>
<p>Only used when <code>invert</code> is <code>TRUE</code>. The token to return for OOV
indices. Defaults to <code>"[UNK]"</code>.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_vocabulary">vocabulary</code></td>
<td>
<p>Optional. Either an array of strings or a string path to a
text file. If passing an array, can pass a character vector or
or 1D tensor containing the string vocabulary terms. If passing a file
path, the file should contain one line per term in the vocabulary. If
this argument is set, there is no need to <code>adapt()</code> the layer.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_idf_weights">idf_weights</code></td>
<td>
<p>Only valid when <code>output_mode</code> is <code>"tf_idf"</code>.
An array, or 1D tensor or the same length as the vocabulary,
containing the floating point inverse document frequency weights, which
will be multiplied by per sample term counts for the final <code>tf_idf</code>
weight. If the <code>vocabulary</code> argument is set, and <code>output_mode</code> is
<code>"tf_idf"</code>, this argument must be supplied.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_encoding">encoding</code></td>
<td>
<p>Optional. The text encoding to use to interpret the input
strings. Defaults to <code>"utf-8"</code>.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_invert">invert</code></td>
<td>
<p>Only valid when <code>output_mode</code> is <code>"int"</code>. If <code>TRUE</code>, this layer will
map indices to vocabulary items instead of mapping vocabulary items to
indices. Default to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_output_mode">output_mode</code></td>
<td>
<p>Specification for the output of the layer. Defaults to
<code>"int"</code>.  Values can be <code>"int"</code>, <code>"one_hot"</code>, <code>"multi_hot"</code>, <code>"count"</code>,
or <code>"tf_idf"</code> configuring the layer as follows:
</p>

<ul>
<li> <p><code>"int"</code>: Return the raw integer indices of the input tokens.
</p>
</li>
<li> <p><code>"one_hot"</code>: Encodes each individual element in the input into an
array the same size as the vocabulary, containing a 1 at the element
index. If the last dimension is size 1, will encode on that
dimension. If the last dimension is not size 1, will append a new
dimension for the encoded output.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Encodes each sample in the input into a single array
the same size as the vocabulary, containing a 1 for each vocabulary
term present in the sample. Treats the last dimension as the sample
dimension, if input shape is (..., sample_length), output shape will
be (..., num_tokens).
</p>
</li>
<li> <p><code>"count"</code>: As <code>"multi_hot"</code>, but the int array contains a count of
the number of times the token at that index appeared in the sample.
</p>
</li>
<li> <p><code>"tf_idf"</code>: As <code>"multi_hot"</code>, but the TF-IDF algorithm is applied to
find the value in each token slot.
For <code>"int"</code> output, any shape of input and output is supported. For all
other output modes, currently only output up to rank 2 is supported.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_sparse">sparse</code></td>
<td>
<p>Boolean. Only applicable when <code>output_mode</code> is <code>"multi_hot"</code>,
<code>"count"</code>, or <code>"tf_idf"</code>. If <code>TRUE</code>, returns a <code>SparseTensor</code> instead of a
dense <code>Tensor</code>. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_pad_to_max_tokens">pad_to_max_tokens</code></td>
<td>
<p>Only applicable when <code>output_mode</code> is <code>"multi_hot"</code>,
<code>"count"</code>, or <code>"tf_idf"</code>. If TRUE, the output will have its feature axis
padded to <code>max_tokens</code> even if the number of unique tokens in the
vocabulary is less than max_tokens, resulting in a tensor of shape
<code style="white-space: pre;">&#8288;[batch_size, max_tokens]&#8288;</code> regardless of vocabulary size. Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="layer_string_lookup_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer translates a set of arbitrary strings into integer output via a
table-based vocabulary lookup. This layer will perform no splitting or
transformation of input strings. For a layer than can split and tokenize
natural language, see the <code>layer_text_vectorization()</code> layer.
</p>
<p>The vocabulary for the layer must be either supplied on construction or
learned via <code>adapt()</code>. During <code>adapt()</code>, the layer will analyze a data set,
determine the frequency of individual strings tokens, and create a
vocabulary from them. If the vocabulary is capped in size, the most frequent
tokens will be used to create the vocabulary and all others will be treated
as out-of-vocabulary (OOV).
</p>
<p>There are two possible output modes for the layer.
When <code>output_mode</code> is <code>"int"</code>,
input strings are converted to their index in the vocabulary (an integer).
When <code>output_mode</code> is <code>"multi_hot"</code>, <code>"count"</code>, or <code>"tf_idf"</code>, input strings
are encoded into an array where each dimension corresponds to an element in
the vocabulary.
</p>
<p>The vocabulary can optionally contain a mask token as well as an OOV token
(which can optionally occupy multiple indices in the vocabulary, as set
by <code>num_oov_indices</code>).
The position of these tokens in the vocabulary is fixed. When <code>output_mode</code>
is <code>"int"</code>, the vocabulary will begin with the mask token (if set), followed
by OOV indices, followed by the rest of the vocabulary. When <code>output_mode</code>
is <code>"multi_hot"</code>, <code>"count"</code>, or <code>"tf_idf"</code> the vocabulary will begin with
OOV indices and instances of the mask token will be dropped.
</p>
<p>For an overview and full list of preprocessing layers, see the preprocessing
<a href="https://www.tensorflow.org/guide/keras/preprocessing_layers">guide</a>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+adapt">adapt()</a></code>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup">https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup">https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup</a>
</p>
</li></ul>

<p>Other categorical features preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>
</p>
<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_text_vectorization">layer_text_vectorization</a>()</code>
</p>

<hr>
<h2 id='layer_subtract'>Layer that subtracts two inputs.</h2><span id='topic+layer_subtract'></span>

<h3>Description</h3>

<p>It takes as input a list of tensors of size 2, both of the same shape, and
returns a single tensor, (<code>inputs[[1]] - inputs[[2]]</code>), also of the same
shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_subtract(inputs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_subtract_+3A_inputs">inputs</code></td>
<td>
<p>A input tensor, or list of two input tensors. Can be missing.</p>
</td></tr>
<tr><td><code id="layer_subtract_+3A_...">...</code></td>
<td>
<p>Unnamed args are treated as additional <code>inputs</code>. Named arguments are passed on as standard layer arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor, the difference of the inputs. If <code>inputs</code> is missing, a
keras layer instance is returned.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/subtract">https://www.tensorflow.org/api_docs/python/tf/keras/layers/subtract</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/merging_layers/subtract">https://keras.io/api/layers/merging_layers/subtract</a>
</p>
</li></ul>

<p>Other merge layers: 
<code><a href="#topic+layer_average">layer_average</a>()</code>,
<code><a href="#topic+layer_concatenate">layer_concatenate</a>()</code>,
<code><a href="#topic+layer_dot">layer_dot</a>()</code>,
<code><a href="#topic+layer_maximum">layer_maximum</a>()</code>,
<code><a href="#topic+layer_minimum">layer_minimum</a>()</code>,
<code><a href="#topic+layer_multiply">layer_multiply</a>()</code>
</p>

<hr>
<h2 id='layer_text_vectorization'>A preprocessing layer which maps text features to integer sequences.</h2><span id='topic+layer_text_vectorization'></span><span id='topic+get_vocabulary'></span><span id='topic+set_vocabulary'></span>

<h3>Description</h3>

<p>A preprocessing layer which maps text features to integer sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_text_vectorization(
  object,
  max_tokens = NULL,
  standardize = "lower_and_strip_punctuation",
  split = "whitespace",
  ngrams = NULL,
  output_mode = "int",
  output_sequence_length = NULL,
  pad_to_max_tokens = FALSE,
  vocabulary = NULL,
  ...
)

get_vocabulary(object, include_special_tokens = TRUE)

set_vocabulary(object, vocabulary, idf_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_text_vectorization_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_max_tokens">max_tokens</code></td>
<td>
<p>The maximum size of the vocabulary for this layer. If NULL,
there is no cap on the size of the vocabulary. Note that this vocabulary
contains 1 OOV token, so the effective number of tokens is <code style="white-space: pre;">&#8288;(max_tokens - 1 - (1 if output_mode == "int" else 0))&#8288;</code>.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_standardize">standardize</code></td>
<td>
<p>Optional specification for standardization to apply to the
input text. Values can be NULL (no standardization),
<code>"lower_and_strip_punctuation"</code> (lowercase and remove punctuation) or a
Callable. Default is <code>"lower_and_strip_punctuation"</code>.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_split">split</code></td>
<td>
<p>Optional specification for splitting the input text. Values can be
NULL (no splitting), <code>"whitespace"</code> (split on ASCII whitespace), or a
Callable. The default is <code>"whitespace"</code>.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_ngrams">ngrams</code></td>
<td>
<p>Optional specification for ngrams to create from the possibly-split
input text. Values can be NULL, an integer or list of integers; passing
an integer will create ngrams up to that integer, and passing a list of
integers will create ngrams for the specified values in the list. Passing
NULL means that no ngrams will be created.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_output_mode">output_mode</code></td>
<td>
<p>Optional specification for the output of the layer. Values can
be <code>"int"</code>, <code>"multi_hot"</code>, <code>"count"</code> or <code>"tf_idf"</code>, configuring the layer
as follows:
</p>

<ul>
<li> <p><code>"int"</code>: Outputs integer indices, one integer index per split string
token. When <code>output_mode == "int"</code>, 0 is reserved for masked
locations; this reduces the vocab size to
<code>max_tokens - 2</code> instead of <code>max_tokens - 1</code>.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Outputs a single int array per batch, of either
vocab_size or max_tokens size, containing 1s in all elements where the
token mapped to that index exists at least once in the batch item.
</p>
</li>
<li> <p><code>"count"</code>: Like <code>"multi_hot"</code>, but the int array contains a count of
the number of times the token at that index appeared in the
batch item.
</p>
</li>
<li> <p><code>"tf_idf"</code>: Like <code>"multi_hot"</code>, but the TF-IDF algorithm is applied to
find the value in each token slot.
For <code>"int"</code> output, any shape of input and output is supported. For all
other output modes, currently only rank 1 inputs (and rank 2 outputs after
splitting) are supported.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_output_sequence_length">output_sequence_length</code></td>
<td>
<p>Only valid in INT mode. If set, the output will have
its time dimension padded or truncated to exactly <code>output_sequence_length</code>
values, resulting in a tensor of shape
<code style="white-space: pre;">&#8288;(batch_size, output_sequence_length)&#8288;</code> regardless of how many tokens
resulted from the splitting step. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_pad_to_max_tokens">pad_to_max_tokens</code></td>
<td>
<p>Only valid in  <code>"multi_hot"</code>, <code>"count"</code>, and <code>"tf_idf"</code>
modes. If TRUE, the output will have its feature axis padded to
<code>max_tokens</code> even if the number of unique tokens in the vocabulary is less
than max_tokens, resulting in a tensor of shape <code style="white-space: pre;">&#8288;(batch_size, max_tokens)&#8288;</code>
regardless of vocabulary size. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_vocabulary">vocabulary</code></td>
<td>
<p>Optional for <code>layer_text_vectorization()</code>. Either an array
of strings or a string path to a text file. If passing an array, can pass
an R list or character vector, 1D numpy array, or 1D tensor containing the
string vocabulary terms. If passing a file path, the file should contain
one line per term in the vocabulary. If vocabulary is set (either by
passing <code>layer_text_vectorization(vocabulary = ...)</code> or by calling
<code style="white-space: pre;">&#8288;set_vocabulary(layer, vocabulary = ...&#8288;</code>), there is no need to <code>adapt()</code>
the layer.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_include_special_tokens">include_special_tokens</code></td>
<td>
<p>If True, the returned vocabulary will include
the padding and OOV tokens, and a term's index in the vocabulary will equal
the term's index when calling the layer. If False, the returned vocabulary
will not include any padding or OOV tokens.</p>
</td></tr>
<tr><td><code id="layer_text_vectorization_+3A_idf_weights">idf_weights</code></td>
<td>
<p>An R vector, 1D numpy array, or 1D tensor of inverse
document frequency weights with equal length to vocabulary. Must be set if
output_mode is &quot;tf_idf&quot;. Should not be set otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer has basic options for managing text in a Keras model. It
transforms a batch of strings (one example = one string) into either a list of
token indices (one example = 1D tensor of integer token indices) or a dense
representation (one example = 1D tensor of float values representing data
about the example's tokens).
</p>
<p>The vocabulary for the layer must be either supplied on construction or
learned via <code>adapt()</code>. When this layer is adapted, it will analyze the
dataset, determine the frequency of individual string values, and create a
vocabulary from them. This vocabulary can have unlimited size or be capped,
depending on the configuration options for this layer; if there are more
unique values in the input than the maximum vocabulary size, the most
frequent terms will be used to create the vocabulary.
</p>
<p>The processing of each example contains the following steps:
</p>

<ol>
<li><p> Standardize each example (usually lowercasing + punctuation stripping)
</p>
</li>
<li><p> Split each example into substrings (usually words)
</p>
</li>
<li><p> Recombine substrings into tokens (usually ngrams)
</p>
</li>
<li><p> Index tokens (associate a unique int value with each token)
</p>
</li>
<li><p> Transform each example using this index, either into a vector of ints or
a dense float vector.
</p>
</li></ol>

<p>Some notes on passing callables to customize splitting and normalization for
this layer:
</p>

<ol>
<li><p> Any callable can be passed to this Layer, but if you want to serialize
this object you should only pass functions that are registered Keras
serializables (see <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/register_keras_serializable"><code>tf$keras$utils$register_keras_serializable</code></a>
for more details).
</p>
</li>
<li><p> When using a custom callable for <code>standardize</code>, the data received
by the callable will be exactly as passed to this layer. The callable
should return a tensor of the same shape as the input.
</p>
</li>
<li><p> When using a custom callable for <code>split</code>, the data received by the
callable will have the 1st dimension squeezed out - instead of
<code>matrix(c("string to split", "another string to split"))</code>, the Callable will
see <code>c("string to split", "another string to split")</code>. The callable should
return a Tensor with the first dimension containing the split tokens -
in this example, we should see something like <code>list(c("string", "to", "split"), c("another", "string", "to", "split"))</code>. This makes the callable
site natively compatible with <code>tf$strings$split()</code>.
</p>
</li></ol>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+adapt">adapt()</a></code>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization">https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/text/text_vectorization">https://keras.io/api/layers/preprocessing_layers/text/text_vectorization</a>
</p>
</li></ul>

<p>Other preprocessing layers: 
<code><a href="#topic+layer_category_encoding">layer_category_encoding</a>()</code>,
<code><a href="#topic+layer_center_crop">layer_center_crop</a>()</code>,
<code><a href="#topic+layer_discretization">layer_discretization</a>()</code>,
<code><a href="#topic+layer_hashing">layer_hashing</a>()</code>,
<code><a href="#topic+layer_integer_lookup">layer_integer_lookup</a>()</code>,
<code><a href="#topic+layer_normalization">layer_normalization</a>()</code>,
<code><a href="#topic+layer_random_brightness">layer_random_brightness</a>()</code>,
<code><a href="#topic+layer_random_contrast">layer_random_contrast</a>()</code>,
<code><a href="#topic+layer_random_crop">layer_random_crop</a>()</code>,
<code><a href="#topic+layer_random_flip">layer_random_flip</a>()</code>,
<code><a href="#topic+layer_random_height">layer_random_height</a>()</code>,
<code><a href="#topic+layer_random_rotation">layer_random_rotation</a>()</code>,
<code><a href="#topic+layer_random_translation">layer_random_translation</a>()</code>,
<code><a href="#topic+layer_random_width">layer_random_width</a>()</code>,
<code><a href="#topic+layer_random_zoom">layer_random_zoom</a>()</code>,
<code><a href="#topic+layer_rescaling">layer_rescaling</a>()</code>,
<code><a href="#topic+layer_resizing">layer_resizing</a>()</code>,
<code><a href="#topic+layer_string_lookup">layer_string_lookup</a>()</code>
</p>

<hr>
<h2 id='layer_unit_normalization'>Unit normalization layer</h2><span id='topic+layer_unit_normalization'></span>

<h3>Description</h3>

<p>Unit normalization layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_unit_normalization(object, axis = -1L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_unit_normalization_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_unit_normalization_+3A_axis">axis</code></td>
<td>
<p>Integer or list. The axis or axes to normalize across. Typically
this is the features axis or axes. The left-out axes are typically the
batch axis or axes. Defaults to <code>-1</code>, the last dimension in
the input.</p>
</td></tr>
<tr><td><code id="layer_unit_normalization_+3A_...">...</code></td>
<td>
<p>standard layer arguments.
</p>
<div class="sourceCode r"><pre>data &lt;- as_tensor(1:6, shape = c(2, 3), dtype = "float32")
normalized_data &lt;- data %&gt;% layer_unit_normalization()
for(row in 1:2)
  normalized_data[row, ] %&gt;%
  { sum(.^2) } %&gt;%
  print()
# tf.Tensor(0.9999999, shape=(), dtype=float32)
# tf.Tensor(1.0, shape=(), dtype=float32)
</pre></div></td></tr>
</table>


<h3>Details</h3>

<p>Normalize a batch of inputs so that each input in the batch has a L2 norm
equal to 1 (across the axes specified in <code>axis</code>).
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/UnitNormalization">https://www.tensorflow.org/api_docs/python/tf/keras/layers/UnitNormalization</a>
</p>
</li></ul>


<hr>
<h2 id='layer_upsampling_1d'>Upsampling layer for 1D inputs.</h2><span id='topic+layer_upsampling_1d'></span>

<h3>Description</h3>

<p>Repeats each temporal step <code>size</code> times along the time axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_upsampling_1d(
  object,
  size = 2L,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_upsampling_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_upsampling_1d_+3A_size">size</code></td>
<td>
<p>integer. Upsampling factor.</p>
</td></tr>
<tr><td><code id="layer_upsampling_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_upsampling_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_upsampling_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_upsampling_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, steps, features)&#8288;</code>.
</p>


<h3>Output shape</h3>

<p>3D tensor with shape: <code style="white-space: pre;">&#8288;(batch, upsampled_steps, features)&#8288;</code>.
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_upsampling_2d'>Upsampling layer for 2D inputs.</h2><span id='topic+layer_upsampling_2d'></span>

<h3>Description</h3>

<p>Repeats the rows and columns of the data by <code>size[[0]]</code> and <code>size[[1]]</code> respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_upsampling_2d(
  object,
  size = c(2L, 2L),
  data_format = NULL,
  interpolation = "nearest",
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_upsampling_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_size">size</code></td>
<td>
<p>int, or list of 2 integers. The upsampling factors for rows and
columns.</p>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_interpolation">interpolation</code></td>
<td>
<p>A string, one of <code>nearest</code> or <code>bilinear</code>.
Note that CNTK does not support yet the <code>bilinear</code> upscaling
and that with Theano, only <code style="white-space: pre;">&#8288;size=(2, 2)&#8288;</code> is possible.</p>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_upsampling_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>4D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, upsampled_rows, upsampled_cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, upsampled_rows, upsampled_cols)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_upsampling_3d'>Upsampling layer for 3D inputs.</h2><span id='topic+layer_upsampling_3d'></span>

<h3>Description</h3>

<p>Repeats the 1st, 2nd and 3rd dimensions of the data by <code>size[[0]]</code>, <code>size[[1]]</code> and
<code>size[[2]]</code> respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_upsampling_3d(
  object,
  size = c(2L, 2L, 2L),
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_upsampling_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_upsampling_3d_+3A_size">size</code></td>
<td>
<p>int, or list of 3 integers. The upsampling factors for dim1, dim2
and dim3.</p>
</td></tr>
<tr><td><code id="layer_upsampling_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_upsampling_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_upsampling_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_upsampling_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_upsampling_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>5D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, dim1, dim2, dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, dim1, dim2, dim3)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>5D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_zero_padding_1d'>Zero-padding layer for 1D input (e.g. temporal sequence).</h2><span id='topic+layer_zero_padding_1d'></span>

<h3>Description</h3>

<p>Zero-padding layer for 1D input (e.g. temporal sequence).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_zero_padding_1d(
  object,
  padding = 1L,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_zero_padding_1d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_zero_padding_1d_+3A_padding">padding</code></td>
<td>
<p>int, or list of int (length 2)
</p>

<ul>
<li><p> If int: How many zeros to add at the beginning and end of the padding dimension (axis 1).
</p>
</li>
<li><p> If list of int (length 2): How many zeros to add at the beginning and at the end of the padding dimension (<code style="white-space: pre;">&#8288;(left_pad, right_pad)&#8288;</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_zero_padding_1d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_zero_padding_1d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_1d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_1d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>3D tensor with shape <code style="white-space: pre;">&#8288;(batch, axis_to_pad, features)&#8288;</code>
</p>


<h3>Output shape</h3>

<p>3D tensor with shape <code style="white-space: pre;">&#8288;(batch, padded_axis, features)&#8288;</code>
</p>


<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_zero_padding_2d'>Zero-padding layer for 2D input (e.g. picture).</h2><span id='topic+layer_zero_padding_2d'></span>

<h3>Description</h3>

<p>This layer can add rows and columns of zeros at the top, bottom, left and
right side of an image tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_zero_padding_2d(
  object,
  padding = c(1L, 1L),
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_zero_padding_2d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_zero_padding_2d_+3A_padding">padding</code></td>
<td>
<p>int, or list of 2 ints, or list of 2 lists of 2 ints.
</p>

<ul>
<li><p> If int: the same symmetric padding is applied to width and height.
</p>
</li>
<li><p> If list of 2 ints: interpreted as two different symmetric padding values for height
and width: <code style="white-space: pre;">&#8288;(symmetric_height_pad, symmetric_width_pad)&#8288;</code>.
</p>
</li>
<li><p> If list of 2 lists of 2 ints: interpreted as <code style="white-space: pre;">&#8288;((top_pad, bottom_pad), (left_pad, right_pad))&#8288;</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_zero_padding_2d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, height, width, channels)&#8288;</code> while <code>channels_first</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, height, width)&#8288;</code>. It defaults to the <code>image_data_format</code> value
found in your Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set
it, then it will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_2d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_zero_padding_2d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_2d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_2d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>4D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, rows, cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, rows, cols)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>4D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, padded_rows, padded_cols, channels)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, channels, padded_rows, padded_cols)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_3d">layer_zero_padding_3d</a>()</code>
</p>

<hr>
<h2 id='layer_zero_padding_3d'>Zero-padding layer for 3D data (spatial or spatio-temporal).</h2><span id='topic+layer_zero_padding_3d'></span>

<h3>Description</h3>

<p>Zero-padding layer for 3D data (spatial or spatio-temporal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_zero_padding_3d(
  object,
  padding = c(1L, 1L, 1L),
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_zero_padding_3d_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_zero_padding_3d_+3A_padding">padding</code></td>
<td>
<p>int, or list of 3 ints, or list of 3 lists of 2 ints.
</p>

<ul>
<li><p> If int: the same symmetric padding is applied to width and height.
</p>
</li>
<li><p> If list of 3 ints: interpreted as three different symmetric padding values:
<code style="white-space: pre;">&#8288;(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)&#8288;</code>.
</p>
</li>
<li><p> If list of 3 lists of 2 ints: interpreted as <code style="white-space: pre;">&#8288;((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))&#8288;</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="layer_zero_padding_3d_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or
<code>channels_first</code>. The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape <code style="white-space: pre;">&#8288;(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)&#8288;</code> while <code>channels_first</code> corresponds
to inputs with shape <code style="white-space: pre;">&#8288;(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)&#8288;</code>. It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code style="white-space: pre;">&#8288;~/.keras/keras.json&#8288;</code>. If you never set it, then it
will be &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_3d_+3A_batch_size">batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td></tr>
<tr><td><code id="layer_zero_padding_3d_+3A_name">name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_3d_+3A_trainable">trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td></tr>
<tr><td><code id="layer_zero_padding_3d_+3A_weights">weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td></tr>
</table>


<h3>Input shape</h3>

<p>5D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad, depth)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)&#8288;</code>
</p>
</li></ul>



<h3>Output shape</h3>

<p>5D tensor with shape:
</p>

<ul>
<li><p> If <code>data_format</code> is <code>"channels_last"</code>: <code style="white-space: pre;">&#8288;(batch, first_padded_axis, second_padded_axis, third_axis_to_pad, depth)&#8288;</code>
</p>
</li>
<li><p> If <code>data_format</code> is <code>"channels_first"</code>: <code style="white-space: pre;">&#8288;(batch, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)&#8288;</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other convolutional layers: 
<code><a href="#topic+layer_conv_1d">layer_conv_1d</a>()</code>,
<code><a href="#topic+layer_conv_1d_transpose">layer_conv_1d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_2d">layer_conv_2d</a>()</code>,
<code><a href="#topic+layer_conv_2d_transpose">layer_conv_2d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_3d">layer_conv_3d</a>()</code>,
<code><a href="#topic+layer_conv_3d_transpose">layer_conv_3d_transpose</a>()</code>,
<code><a href="#topic+layer_conv_lstm_2d">layer_conv_lstm_2d</a>()</code>,
<code><a href="#topic+layer_cropping_1d">layer_cropping_1d</a>()</code>,
<code><a href="#topic+layer_cropping_2d">layer_cropping_2d</a>()</code>,
<code><a href="#topic+layer_cropping_3d">layer_cropping_3d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_1d">layer_depthwise_conv_1d</a>()</code>,
<code><a href="#topic+layer_depthwise_conv_2d">layer_depthwise_conv_2d</a>()</code>,
<code><a href="#topic+layer_separable_conv_1d">layer_separable_conv_1d</a>()</code>,
<code><a href="#topic+layer_separable_conv_2d">layer_separable_conv_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_1d">layer_upsampling_1d</a>()</code>,
<code><a href="#topic+layer_upsampling_2d">layer_upsampling_2d</a>()</code>,
<code><a href="#topic+layer_upsampling_3d">layer_upsampling_3d</a>()</code>,
<code><a href="#topic+layer_zero_padding_1d">layer_zero_padding_1d</a>()</code>,
<code><a href="#topic+layer_zero_padding_2d">layer_zero_padding_2d</a>()</code>
</p>

<hr>
<h2 id='learning_rate_schedule_cosine_decay'>A LearningRateSchedule that uses a cosine decay schedule</h2><span id='topic+learning_rate_schedule_cosine_decay'></span>

<h3>Description</h3>

<p>A LearningRateSchedule that uses a cosine decay schedule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_rate_schedule_cosine_decay(
  initial_learning_rate,
  decay_steps,
  alpha = 0,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_rate_schedule_cosine_decay_+3A_initial_learning_rate">initial_learning_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> Tensor or a
R number. The initial learning rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_+3A_decay_steps">decay_steps</code></td>
<td>
<p>A scalar <code>int32</code> or <code>int64</code> <code>Tensor</code> or an R number.
Number of steps to decay over.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_+3A_alpha">alpha</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> Tensor or an R number.
Minimum learning rate value as a fraction of initial_learning_rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_+3A_name">name</code></td>
<td>
<p>String. Optional name of the operation.  Defaults to
'CosineDecay'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://arxiv.org/abs/1608.03983">Loshchilov &amp; Hutter, ICLR2016</a>,
SGDR: Stochastic Gradient Descent with Warm Restarts.
</p>
<p>When training a model, it is often useful to lower the learning rate as
the training progresses. This schedule applies a cosine decay function
to an optimizer step, given a provided initial learning rate.
It requires a <code>step</code> value to compute the decayed learning rate. You can
just pass a TensorFlow variable that you increment at each training step.
</p>
<p>The schedule is a 1-arg callable that produces a decayed learning
rate when passed the current optimizer step. This can be useful for changing
the learning rate value across different invocations of optimizer functions.
It is computed as:
</p>
<div class="sourceCode r"><pre>decayed_learning_rate &lt;- function(step) {
  step &lt;- min(step, decay_steps)
  cosine_decay = &lt;- 0.5 * (1 + cos(pi * step / decay_steps))
  decayed &lt;- (1 - alpha) * cosine_decay + alpha
  initial_learning_rate * decayed
}
</pre></div>
<p>Example usage:
</p>
<div class="sourceCode R"><pre>decay_steps &lt;- 1000
lr_decayed_fn &lt;-
  learning_rate_schedule_cosine_decay(initial_learning_rate, decay_steps)
</pre></div>
<p>You can pass this schedule directly into a keras Optimizer
as the <code>learning_rate</code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay</a>
</p>
</li></ul>


<hr>
<h2 id='learning_rate_schedule_cosine_decay_restarts'>A LearningRateSchedule that uses a cosine decay schedule with restarts</h2><span id='topic+learning_rate_schedule_cosine_decay_restarts'></span>

<h3>Description</h3>

<p>A LearningRateSchedule that uses a cosine decay schedule with restarts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_rate_schedule_cosine_decay_restarts(
  initial_learning_rate,
  first_decay_steps,
  t_mul = 2,
  m_mul = 1,
  alpha = 0,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_initial_learning_rate">initial_learning_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> Tensor or an R
number. The initial learning rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_first_decay_steps">first_decay_steps</code></td>
<td>
<p>A scalar <code>int32</code> or <code>int64</code> <code>Tensor</code> or an R
number. Number of steps to decay over.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_t_mul">t_mul</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an R number. Used
to derive the number of iterations in the i-th period.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_m_mul">m_mul</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an R number. Used
to derive the initial learning rate of the i-th period.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_alpha">alpha</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> Tensor or an R number. Minimum
learning rate value as a fraction of the initial_learning_rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_cosine_decay_restarts_+3A_name">name</code></td>
<td>
<p>String. Optional name of the operation.  Defaults to
'SGDRDecay'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="https://arxiv.org/abs/1608.03983">Loshchilov &amp; Hutter, ICLR2016</a>,
SGDR: Stochastic Gradient Descent with Warm Restarts.
</p>
<p>When training a model, it is often useful to lower the learning rate as
the training progresses. This schedule applies a cosine decay function with
restarts to an optimizer step, given a provided initial learning rate.
It requires a <code>step</code> value to compute the decayed learning rate. You can
just pass a TensorFlow variable that you increment at each training step.
</p>
<p>The schedule is a 1-arg callable that produces a decayed learning
rate when passed the current optimizer step. This can be useful for changing
the learning rate value across different invocations of optimizer functions.
</p>
<p>The learning rate multiplier first decays
from 1 to <code>alpha</code> for <code>first_decay_steps</code> steps. Then, a warm
restart is performed. Each new warm restart runs for <code>t_mul</code> times more
steps and with <code>m_mul</code> times initial learning rate as the new learning rate.
</p>
<p>You can pass this schedule directly into a keras Optimizer
as the <code>learning_rate</code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecayRestarts">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecayRestarts</a>
</p>
</li></ul>


<hr>
<h2 id='learning_rate_schedule_exponential_decay'>A LearningRateSchedule that uses an exponential decay schedule</h2><span id='topic+learning_rate_schedule_exponential_decay'></span>

<h3>Description</h3>

<p>A LearningRateSchedule that uses an exponential decay schedule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_rate_schedule_exponential_decay(
  initial_learning_rate,
  decay_steps,
  decay_rate,
  staircase = FALSE,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_rate_schedule_exponential_decay_+3A_initial_learning_rate">initial_learning_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or a R
number. The initial learning rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_exponential_decay_+3A_decay_steps">decay_steps</code></td>
<td>
<p>A scalar <code>int32</code> or <code>int64</code> <code>Tensor</code> or an R number. Must
be positive.  See the decay computation above.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_exponential_decay_+3A_decay_rate">decay_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an R number.
The decay rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_exponential_decay_+3A_staircase">staircase</code></td>
<td>
<p>Boolean.  If <code>TRUE</code> decay the learning rate at discrete
intervals.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_exponential_decay_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_exponential_decay_+3A_name">name</code></td>
<td>
<p>String. Optional name of the operation.  Defaults to
'ExponentialDecay'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When training a model, it is often useful to lower the learning rate as
the training progresses. This schedule applies an exponential decay function
to an optimizer step, given a provided initial learning rate.
</p>
<p>The schedule is a 1-arg callable that produces a decayed learning
rate when passed the current optimizer step. This can be useful for changing
the learning rate value across different invocations of optimizer functions.
It is computed as:
</p>
<div class="sourceCode r"><pre>decayed_learning_rate &lt;- function(step)
  initial_learning_rate * decay_rate ^ (step / decay_steps)
</pre></div>
<p>If the argument <code>staircase</code> is <code>TRUE</code>, then <code>step / decay_steps</code> is
an integer division (<code>%/%</code>) and the decayed learning rate follows a
staircase function.
</p>
<p>You can pass this schedule directly into a optimizer
as the learning rate (see example)
Example: When fitting a Keras model, decay every 100000 steps with a base
of 0.96:
</p>
<div class="sourceCode R"><pre>initial_learning_rate &lt;- 0.1
lr_schedule &lt;- learning_rate_schedule_exponential_decay(
    initial_learning_rate,
    decay_steps = 100000,
    decay_rate = 0.96,
    staircase = TRUE)

model %&gt;% compile(
  optimizer= optimizer_sgd(learning_rate = lr_schedule),
  loss = 'sparse_categorical_crossentropy',
  metrics = 'accuracy')

model %&gt;% fit(data, labels, epochs = 5)
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay</a>
</p>
</li></ul>


<hr>
<h2 id='learning_rate_schedule_inverse_time_decay'>A LearningRateSchedule that uses an inverse time decay schedule</h2><span id='topic+learning_rate_schedule_inverse_time_decay'></span>

<h3>Description</h3>

<p>A LearningRateSchedule that uses an inverse time decay schedule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_rate_schedule_inverse_time_decay(
  initial_learning_rate,
  decay_steps,
  decay_rate,
  staircase = FALSE,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_rate_schedule_inverse_time_decay_+3A_initial_learning_rate">initial_learning_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an
R number. The initial learning rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_inverse_time_decay_+3A_decay_steps">decay_steps</code></td>
<td>
<p>A scalar <code>int32</code> or <code>int64</code> <code>Tensor</code> or an R number. How
often to apply decay.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_inverse_time_decay_+3A_decay_rate">decay_rate</code></td>
<td>
<p>An R number. The decay rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_inverse_time_decay_+3A_staircase">staircase</code></td>
<td>
<p>Boolean. Whether to apply decay in a discrete staircase, as
opposed to continuous, fashion.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_inverse_time_decay_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_inverse_time_decay_+3A_name">name</code></td>
<td>
<p>String.  Optional name of the operation.  Defaults to
'InverseTimeDecay'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When training a model, it is often useful to lower the learning rate as
the training progresses. This schedule applies the inverse decay function
to an optimizer step, given a provided initial learning rate.
It requires a <code>step</code> value to compute the decayed learning rate. You can
just pass a TensorFlow variable that you increment at each training step.
</p>
<p>The schedule is a 1-arg callable that produces a decayed learning
rate when passed the current optimizer step. This can be useful for changing
the learning rate value across different invocations of optimizer functions.
It is computed as:
</p>
<div class="sourceCode R"><pre>decayed_learning_rate &lt;- function(step) {
  initial_learning_rate / (1 + decay_rate * step / decay_step)
}
</pre></div>
<p>or, if <code>staircase</code> is <code>TRUE</code>, as:
</p>
<div class="sourceCode R"><pre>decayed_learning_rate function(step) {
 initial_learning_rate / (1 + decay_rate * floor(step / decay_step))
}
</pre></div>
<p>You can pass this schedule directly into a keras Optimizer
as the <code>learning_rate</code>.
</p>
<p>Example: Fit a Keras model when decaying <code>1/t</code> with a rate of <code>0.5</code>:
</p>
<div class="sourceCode R"><pre>...
initial_learning_rate &lt;- 0.1
decay_steps &lt;- 1.0
decay_rate &lt;- 0.5
learning_rate_fn &lt;- learning_rate_schedule_inverse_time_decay(
  initial_learning_rate, decay_steps, decay_rate)

model %&gt;%
  compile(optimizer = optimizer_sgd(learning_rate = learning_rate_fn),
          loss = 'sparse_categorical_crossentropy',
          metrics = 'accuracy')

model %&gt;% fit(data, labels, epochs = 5)
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay</a>
</p>
</li></ul>


<hr>
<h2 id='learning_rate_schedule_piecewise_constant_decay'>A LearningRateSchedule that uses a piecewise constant decay schedule</h2><span id='topic+learning_rate_schedule_piecewise_constant_decay'></span>

<h3>Description</h3>

<p>A LearningRateSchedule that uses a piecewise constant decay schedule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_rate_schedule_piecewise_constant_decay(
  boundaries,
  values,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_rate_schedule_piecewise_constant_decay_+3A_boundaries">boundaries</code></td>
<td>
<p>A list of <code>Tensor</code>s or R numerics with strictly increasing
entries, and with all elements having the same type as the optimizer step.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_piecewise_constant_decay_+3A_values">values</code></td>
<td>
<p>A list of <code>Tensor</code>s or R numerics that specifies the
values for the intervals defined by <code>boundaries</code>. It should have one more
element than <code>boundaries</code>, and all elements should have the same type.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_piecewise_constant_decay_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_piecewise_constant_decay_+3A_name">name</code></td>
<td>
<p>A string. Optional name of the operation. Defaults to
'PiecewiseConstant'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a 1-arg callable to compute the piecewise constant
when passed the current optimizer step. This can be useful for changing the
learning rate value across different invocations of optimizer functions.
</p>
<p>Example: use a learning rate that's 1.0 for the first 100001 steps, 0.5
for the next 10000 steps, and 0.1 for any additional steps.
</p>
<div class="sourceCode R"><pre>step &lt;- tf$Variable(0, trainable=FALSE)
boundaries &lt;- as.integer(c(100000, 110000))
values &lt;- c(1.0, 0.5, 0.1)
learning_rate_fn &lt;- learning_rate_schedule_piecewise_constant_decay(
    boundaries, values)

# Later, whenever we perform an optimization step, we pass in the step.
learning_rate &lt;- learning_rate_fn(step)
</pre></div>
<p>You can pass this schedule directly into a keras Optimizer
as the <code>learning_rate</code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay</a>
</p>
</li></ul>


<hr>
<h2 id='learning_rate_schedule_polynomial_decay'>A LearningRateSchedule that uses a polynomial decay schedule</h2><span id='topic+learning_rate_schedule_polynomial_decay'></span>

<h3>Description</h3>

<p>A LearningRateSchedule that uses a polynomial decay schedule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learning_rate_schedule_polynomial_decay(
  initial_learning_rate,
  decay_steps,
  end_learning_rate = 1e-04,
  power = 1,
  cycle = FALSE,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_initial_learning_rate">initial_learning_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an
R number.  The initial learning rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_decay_steps">decay_steps</code></td>
<td>
<p>A scalar <code>int32</code> or <code>int64</code> <code>Tensor</code> or an R number.
Must be positive.  See the decay computation above.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_end_learning_rate">end_learning_rate</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an
R number.  The minimal end learning rate.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_power">power</code></td>
<td>
<p>A scalar <code>float32</code> or <code>float64</code> <code>Tensor</code> or an R number.
The power of the polynomial. Defaults to linear, 1.0.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_cycle">cycle</code></td>
<td>
<p>A boolean,
whether or not it should cycle beyond decay_steps.</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td></tr>
<tr><td><code id="learning_rate_schedule_polynomial_decay_+3A_name">name</code></td>
<td>
<p>String.  Optional name of the operation. Defaults to
'PolynomialDecay'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is commonly observed that a monotonically decreasing learning rate, whose
degree of change is carefully chosen, results in a better performing model.
This schedule applies a polynomial decay function to an optimizer step,
given a provided <code>initial_learning_rate</code>, to reach an <code>end_learning_rate</code>
in the given <code>decay_steps</code>.
</p>
<p>It requires a <code>step</code> value to compute the decayed learning rate. You
can just pass a TensorFlow variable that you increment at each training
step.
</p>
<p>The schedule is a 1-arg callable that produces a decayed learning rate
when passed the current optimizer step. This can be useful for changing the
learning rate value across different invocations of optimizer functions.
It is computed as:
</p>
<div class="sourceCode R"><pre>decayed_learning_rate &lt;- function(step) {
  step &lt;- min(step, decay_steps)
  ((initial_learning_rate - end_learning_rate) *
      (1 - step / decay_steps) ^ (power)
    ) + end_learning_rate
}
</pre></div>
<p>If <code>cycle</code> is <code>TRUE</code> then a multiple of <code>decay_steps</code> is used, the first one
that is bigger than <code>step</code>.
</p>
<div class="sourceCode python"><pre>decayed_learning_rate &lt;- function(step) {
  decay_steps &lt;- decay_steps * ceiling(step / decay_steps)
  ((initial_learning_rate - end_learning_rate) *
      (1 - step / decay_steps) ^ (power)
    ) + end_learning_rate
}
</pre></div>
<p>You can pass this schedule directly into a keras Optimizer
as the <code>learning_rate</code>.
</p>
<p>Example: Fit a model while decaying from 0.1 to 0.01 in 10000 steps using
sqrt (i.e. power=0.5):
</p>
<div class="sourceCode R"><pre>...
starter_learning_rate &lt;- 0.1
end_learning_rate &lt;- 0.01
decay_steps &lt;- 10000
learning_rate_fn &lt;- learning_rate_schedule_polynomial_decay(
  starter_learning_rate, decay_steps, end_learning_rate, power = 0.5)

model %&gt;%
  compile(optimizer = optimizer_sgd(learning_rate = learning_rate_fn),
          loss = 'sparse_categorical_crossentropy',
          metrics = 'accuracy')

model %&gt;% fit(data, labels, epochs = 5)
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay</a>
</p>
</li></ul>


<hr>
<h2 id='loss_cosine_proximity'>(Deprecated) loss_cosine_proximity</h2><span id='topic+loss_cosine_proximity'></span>

<h3>Description</h3>

<p><code>loss_cosine_proximity</code> is deprecated and will be removed in a future
version. It has been renamed to <code>loss_cosine_similarity</code>().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_cosine_proximity(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_cosine_proximity_+3A_...">...</code></td>
<td>
<p>passed on to <code><a href="#topic+loss_cosine_similarity">loss_cosine_similarity()</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='loss-functions'>Loss functions</h2><span id='topic+loss-functions'></span><span id='topic+loss_binary_crossentropy'></span><span id='topic++22binary_crossentropy+22+2C'></span><span id='topic++22BinaryCrossentropy+22'></span><span id='topic+loss_categorical_crossentropy'></span><span id='topic+loss_categorical_hinge'></span><span id='topic+loss_cosine_similarity'></span><span id='topic+loss_hinge'></span><span id='topic+loss_huber'></span><span id='topic+loss_kullback_leibler_divergence'></span><span id='topic+loss_kl_divergence'></span><span id='topic+loss_logcosh'></span><span id='topic+loss_mean_absolute_error'></span><span id='topic+loss_mean_absolute_percentage_error'></span><span id='topic+loss_mean_squared_error'></span><span id='topic+loss_mean_squared_logarithmic_error'></span><span id='topic+loss_poisson'></span><span id='topic+loss_sparse_categorical_crossentropy'></span><span id='topic+loss_squared_hinge'></span>

<h3>Description</h3>

<p>Loss functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_binary_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  label_smoothing = 0,
  axis = -1L,
  ...,
  reduction = "auto",
  name = "binary_crossentropy"
)

loss_categorical_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  label_smoothing = 0L,
  axis = -1L,
  ...,
  reduction = "auto",
  name = "categorical_crossentropy"
)

loss_categorical_hinge(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "categorical_hinge"
)

loss_cosine_similarity(
  y_true,
  y_pred,
  axis = -1L,
  ...,
  reduction = "auto",
  name = "cosine_similarity"
)

loss_hinge(y_true, y_pred, ..., reduction = "auto", name = "hinge")

loss_huber(
  y_true,
  y_pred,
  delta = 1,
  ...,
  reduction = "auto",
  name = "huber_loss"
)

loss_kullback_leibler_divergence(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "kl_divergence"
)

loss_kl_divergence(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "kl_divergence"
)

loss_logcosh(y_true, y_pred, ..., reduction = "auto", name = "log_cosh")

loss_mean_absolute_error(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "mean_absolute_error"
)

loss_mean_absolute_percentage_error(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "mean_absolute_percentage_error"
)

loss_mean_squared_error(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "mean_squared_error"
)

loss_mean_squared_logarithmic_error(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "mean_squared_logarithmic_error"
)

loss_poisson(y_true, y_pred, ..., reduction = "auto", name = "poisson")

loss_sparse_categorical_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  axis = -1L,
  ...,
  reduction = "auto",
  name = "sparse_categorical_crossentropy"
)

loss_squared_hinge(
  y_true,
  y_pred,
  ...,
  reduction = "auto",
  name = "squared_hinge"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss-functions_+3A_y_true">y_true</code></td>
<td>
<p>Ground truth values. shape = <code style="white-space: pre;">&#8288;[batch_size, d1, .. dN]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_y_pred">y_pred</code></td>
<td>
<p>The predicted values. shape = <code style="white-space: pre;">&#8288;[batch_size, d1, .. dN]&#8288;</code>.
(Tensor of the same shape as <code>y_true</code>)</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_from_logits">from_logits</code></td>
<td>
<p>Whether <code>y_pred</code> is expected to be a logits tensor. By
default we assume that <code>y_pred</code> encodes a probability distribution.</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_label_smoothing">label_smoothing</code></td>
<td>
<p>Float in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. If <code style="white-space: pre;">&#8288;&gt; 0&#8288;</code> then smooth the labels.
For example, if <code>0.1</code>, use <code>0.1 / num_classes</code> for non-target labels and
<code>0.9 + 0.1 / num_classes</code> for target labels.</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_axis">axis</code></td>
<td>
<p>The axis along which to compute crossentropy (the features axis).
Axis is 1-based (e.g, first axis is <code>axis=1</code>). Defaults to <code>-1</code> (the last axis).</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the Python callable (for forward
and backwards compatibility).</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_reduction">reduction</code></td>
<td>
<p>Only applicable if <code>y_true</code> and <code>y_pred</code> are missing. Type
of <code>keras$losses$Reduction</code> to apply to loss. Default value is <code>AUTO</code>.
<code>AUTO</code> indicates that the reduction option will be determined by the usage
context. For almost all cases this defaults to <code>SUM_OVER_BATCH_SIZE</code>. When
used with <code>tf$distribute$Strategy</code>, outside of built-in training loops such
as <code>compile</code> and <code>fit</code>, using <code>AUTO</code> or <code>SUM_OVER_BATCH_SIZE</code> will raise an
error. Please see this custom training <a href="https://www.tensorflow.org/tutorials/distribute/custom_training">tutorial</a> for more
details.</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_name">name</code></td>
<td>
<p>Only applicable if <code>y_true</code> and <code>y_pred</code> are missing. Optional
name for the Loss instance.</p>
</td></tr>
<tr><td><code id="loss-functions_+3A_delta">delta</code></td>
<td>
<p>A float, the point where the Huber loss function changes from a
quadratic to linear.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Loss functions for model training. These are typically supplied in
the <code>loss</code> parameter of the <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model()</a></code>
function.
</p>


<h3>Value</h3>

<p>If called with <code>y_true</code> and <code>y_pred</code>, then the corresponding loss is
evaluated and the result returned (as a tensor). Alternatively, if <code>y_true</code>
and <code>y_pred</code> are missing, then a callable is returned that will compute the
loss function and, by default, reduce the loss to a scalar tensor; see the
<code>reduction</code> parameter for details. (The callable is a typically a class
instance that inherits from <code>keras$losses$Loss</code>).
</p>


<h3>binary_crossentropy</h3>

<p>Computes the binary crossentropy loss.
</p>
<p><code>label_smoothing</code> details: Float in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. If <code style="white-space: pre;">&#8288;&gt; 0&#8288;</code> then smooth the labels
by squeezing them towards 0.5 That is, using <code>1. - 0.5 * label_smoothing</code>
for the target class and <code>0.5 * label_smoothing</code> for the non-target class.
</p>


<h3>categorical_crossentropy</h3>

<p>Computes the categorical crossentropy loss.
</p>
<p>When using the categorical_crossentropy loss, your targets should be in
categorical format (e.g. if you have 10 classes, the target for each sample
should be a 10-dimensional vector that is all-zeros except for a 1 at the
index corresponding to the class of the sample). In order to convert
integer targets into categorical targets, you can use the Keras utility
function <code><a href="#topic+to_categorical">to_categorical()</a></code>:
</p>
<p><code>categorical_labels &lt;- to_categorical(int_labels, num_classes = NULL)</code>
</p>


<h3>huber</h3>

<p>Computes Huber loss value.
For each value x in <code>error = y_true - y_pred</code>:
</p>
<div class="sourceCode"><pre>loss = 0.5 * x^2                  if |x| &lt;= d
loss = d * |x| - 0.5 * d^2        if |x| &gt; d
</pre></div>
<p>where d is <code>delta</code>. See: https://en.wikipedia.org/wiki/Huber_loss
</p>


<h3>log_cosh</h3>

<p>Logarithm of the hyperbolic cosine of the prediction error.
</p>
<p><code>log(cosh(x))</code> is approximately equal to <code>(x ** 2) / 2</code> for small <code>x</code> and
to <code>abs(x) - log(2)</code> for large <code>x</code>. This means that 'logcosh' works mostly
like the mean squared error, but will not be so strongly affected by the
occasional wildly incorrect prediction. However, it may return NaNs if the
intermediate value <code>cosh(y_pred - y_true)</code> is too large to be represented
in the chosen precision.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model()</a></code>,
<code><a href="#topic+loss_binary_crossentropy">loss_binary_crossentropy()</a></code>
</p>

<hr>
<h2 id='make_sampling_table'>Generates a word rank-based probabilistic sampling table.</h2><span id='topic+make_sampling_table'></span>

<h3>Description</h3>

<p>Generates a word rank-based probabilistic sampling table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_sampling_table(size, sampling_factor = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_sampling_table_+3A_size">size</code></td>
<td>
<p>Int, number of possible words to sample.</p>
</td></tr>
<tr><td><code id="make_sampling_table_+3A_sampling_factor">sampling_factor</code></td>
<td>
<p>The sampling factor in the word2vec formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Used for generating the <code>sampling_table</code> argument for <code><a href="#topic+skipgrams">skipgrams()</a></code>.
<code>sampling_table[[i]]</code> is the probability of sampling the word i-th most common
word in a dataset (more common words should be sampled less frequently, for balance).
</p>
<p>The sampling probabilities are generated according to the sampling distribution used in word2vec:
</p>
<p><code>p(word) = min(1, sqrt(word_frequency / sampling_factor) / (word_frequency / sampling_factor))</code>
</p>
<p>We assume that the word frequencies follow Zipf's law (s=1) to derive a
numerical approximation of frequency(rank):
</p>
<p><code>frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))</code>
</p>
<p>where <code>gamma</code> is the Euler-Mascheroni constant.
</p>


<h3>Value</h3>

<p>An array of length <code>size</code> where the ith entry is the
probability that a word of rank i should be sampled.
</p>


<h3>Note</h3>

<p>The word2vec formula is: p(word) = min(1,
sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))
</p>


<h3>See Also</h3>

<p>Other text preprocessing: 
<code><a href="#topic+pad_sequences">pad_sequences</a>()</code>,
<code><a href="#topic+skipgrams">skipgrams</a>()</code>,
<code><a href="#topic+text_hashing_trick">text_hashing_trick</a>()</code>,
<code><a href="#topic+text_one_hot">text_one_hot</a>()</code>,
<code><a href="#topic+text_to_word_sequence">text_to_word_sequence</a>()</code>
</p>

<hr>
<h2 id='Metric'>Metric</h2><span id='topic+Metric'></span>

<h3>Description</h3>

<p>A <code>Metric</code> object encapsulates metric logic and state that can be used to
track model performance during training. It is what is returned by the family
of metric functions that start with prefix <code style="white-space: pre;">&#8288;metric_*&#8288;</code>.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="Metric_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="Metric_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>Usage with <code>compile</code></h3>

<div class="sourceCode r"><pre>model %&gt;% compile(
  optimizer = 'sgd',
  loss = 'mse',
  metrics = list(metric_SOME_METRIC(), metric_SOME_OTHER_METRIC())
)
</pre></div>


<h3>Standalone usage</h3>

<div class="sourceCode r"><pre>m &lt;- metric_SOME_METRIC()
for (e in seq(epochs)) {
  for (i in seq(train_steps)) {
    c(y_true, y_pred, sample_weight = NULL) %&lt;-% ...
    m$update_state(y_true, y_pred, sample_weight)
  }
  cat('Final epoch result: ', as.numeric(m$result()), "\n")
  m$reset_state()
}
</pre></div>


<h3>Custom Metric (subclass)</h3>

<p>To be implemented by subclasses:
</p>

<ul>
<li> <p><code>initialize()</code>: All state variables should be created in this method by calling <code>self$add_weight()</code> like:
</p>
<div class="sourceCode"><pre>self$var &lt;- self$add_weight(...)
</pre></div>
</li>
<li> <p><code>update_state()</code>: Has all updates to the state variables like:
</p>
<div class="sourceCode"><pre>self$var$assign_add(...)
</pre></div>
</li>
<li> <p><code>result()</code>: Computes and returns a value for the metric from the state variables.
</p>
</li></ul>

<p>Example custom metric subclass:
</p>
<div class="sourceCode R"><pre>metric_binary_true_positives &lt;- new_metric_class(
  classname = "BinaryTruePositives",
  initialize = function(name = 'binary_true_positives', ...) {
    super$initialize(name = name, ...)
    self$true_positives &lt;-
      self$add_weight(name = 'tp', initializer = 'zeros')
  },

  update_state = function(y_true, y_pred, sample_weight = NULL) {
    y_true &lt;- k_cast(y_true, "bool")
    y_pred &lt;- k_cast(y_pred, "bool")

    values &lt;- y_true &amp; y_pred
    values &lt;- k_cast(values, self$dtype)
    if (!is.null(sample_weight)) {
      sample_weight &lt;- k_cast(sample_weight, self$dtype)
      sample_weight &lt;- tf$broadcast_to(sample_weight, values$shape)
      values &lt;- values * sample_weight
    }
    self$true_positives$assign_add(tf$reduce_sum(values))
  },

  result = function()
    self$true_positives
)
model %&gt;% compile(..., metrics = list(metric_binary_true_positives()))
</pre></div>
<p>The same <code>metric_binary_true_positives</code> could be built with <code style="white-space: pre;">&#8288;%py_class%&#8288;</code> like
this:
</p>
<div class="sourceCode"><pre>metric_binary_true_positives(keras$metrics$Metric) %py_class% {
  initialize &lt;- &lt;same-as-above&gt;,
  update_state &lt;- &lt;same-as-above&gt;,
  result &lt;- &lt;same-as-above&gt;
}
</pre></div>

<hr>
<h2 id='metric_accuracy'>Calculates how often predictions equal labels</h2><span id='topic+metric_accuracy'></span>

<h3>Description</h3>

<p>Calculates how often predictions equal labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_accuracy(..., name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_accuracy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_accuracy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_accuracy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This metric creates two local variables, <code>total</code> and <code>count</code> that are used to
compute the frequency with which <code>y_pred</code> matches <code>y_true</code>. This frequency is
ultimately returned as <code style="white-space: pre;">&#8288;binary accuracy&#8288;</code>: an idempotent operation that simply
divides <code>total</code> by <code>count</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_auc'>Approximates the AUC (Area under the curve) of the ROC or PR curves</h2><span id='topic+metric_auc'></span>

<h3>Description</h3>

<p>Approximates the AUC (Area under the curve) of the ROC or PR curves
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_auc(
  ...,
  num_thresholds = 200L,
  curve = "ROC",
  summation_method = "interpolation",
  thresholds = NULL,
  multi_label = FALSE,
  num_labels = NULL,
  label_weights = NULL,
  from_logits = FALSE,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_auc_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>(Optional) Defaults to 200. The number of thresholds toa
use when discretizing the roc curve. Values must be &gt; 1.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_curve">curve</code></td>
<td>
<p>(Optional) Specifies the name of the curve to be computed, 'ROC'
(default) or 'PR' for the Precision-Recall-curve.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_summation_method">summation_method</code></td>
<td>
<p>(Optional) Specifies the <a href="https://en.wikipedia.org/wiki/Riemann_sum">Riemann summation method</a> used. 'interpolation' (default)
applies mid-point summation scheme for <code>ROC</code>. For PR-AUC, interpolates
(true/false) positives but not the ratio that is precision (see Davis &amp;
Goadrich 2006 for details); 'minoring' applies left summation for
increasing intervals and right summation for decreasing intervals;
'majoring' does the opposite.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) A list of floating point values to use as the
thresholds for discretizing the curve. If set, the <code>num_thresholds</code>
parameter is ignored. Values should be in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. Endpoint thresholds equal
to <code style="white-space: pre;">&#8288;{-epsilon, 1+epsilon}&#8288;</code> for a small positive epsilon value will be
automatically included with these to correctly handle predictions equal to
exactly 0 or 1.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_multi_label">multi_label</code></td>
<td>
<p>boolean indicating whether multilabel data should be
treated as such, wherein AUC is computed separately for each label and then
averaged across labels, or (when FALSE) if the data should be flattened
into a single label before AUC computation. In the latter case, when
multilabel data is passed to AUC, each label-prediction pair is treated as
an individual data point. Should be set to FALSE for multi-class data.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_num_labels">num_labels</code></td>
<td>
<p>(Optional) The number of labels, used when <code>multi_label</code> is
TRUE. If <code>num_labels</code> is not specified, then state variables get created on
the first call to <code>update_state</code>.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_label_weights">label_weights</code></td>
<td>
<p>(Optional) list, array, or tensor of non-negative
weights used to compute AUCs for multilabel data. When <code>multi_label</code> is
TRUE, the weights are applied to the individual label AUCs when they are
averaged to produce the multi-label AUC. When it's FALSE, they are used to
weight the individual label predictions in computing the confusion matrix
on the flattened data. Note that this is unlike class_weights in that
class_weights weights the example depending on the value of its label,
whereas label_weights depends only on the index of that label before
flattening; therefore <code>label_weights</code> should not be used for multi-class
data.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_from_logits">from_logits</code></td>
<td>
<p>boolean indicating whether the predictions (<code>y_pred</code> in
<code>update_state</code>) are probabilities or sigmoid logits. As a rule of thumb,
when using a keras loss, the <code>from_logits</code> constructor argument of the loss
should match the AUC <code>from_logits</code> constructor argument.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_auc_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AUC (Area under the curve) of the ROC (Receiver operating
characteristic; default) or PR (Precision Recall) curves are quality measures
of binary classifiers. Unlike the accuracy, and like cross-entropy losses,
ROC-AUC and PR-AUC evaluate all the operational points of a model.
</p>
<p>This class approximates AUCs using a Riemann sum. During the metric
accumulation phrase, predictions are accumulated within predefined buckets by
value. The AUC is then computed by interpolating per-bucket averages. These
buckets define the evaluated operational points.
</p>
<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>,
<code>false_positives</code> and <code>false_negatives</code> that are used to compute the AUC. To
discretize the AUC curve, a linearly spaced set of thresholds is used to
compute pairs of recall and precision values. The area under the ROC-curve is
therefore computed using the height of the recall values by the false
positive rate, while the area under the PR-curve is the computed using the
height of the precision values by the recall.
</p>
<p>This value is ultimately returned as <code>auc</code>, an idempotent operation that
computes the area under a discretized curve of precision versus recall values
(computed using the aforementioned variables). The <code>num_thresholds</code> variable
controls the degree of discretization with larger numbers of thresholds more
closely approximating the true AUC. The quality of the approximation may vary
dramatically depending on <code>num_thresholds</code>. The <code>thresholds</code> parameter can be
used to manually specify thresholds which split the predictions more evenly.
</p>
<p>For a best approximation of the real AUC, <code>predictions</code> should be distributed
approximately uniformly in the range <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> (if <code>from_logits=FALSE</code>). The
quality of the AUC approximation may be poor if this is not the case. Setting
<code>summation_method</code> to 'minoring' or 'majoring' can help quantify the error in
the approximation by providing lower or upper bound estimate of the AUC.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1. Use <code>sample_weight</code> of 0
to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_binary_accuracy'>Calculates how often predictions match binary labels</h2><span id='topic+metric_binary_accuracy'></span>

<h3>Description</h3>

<p>Calculates how often predictions match binary labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_binary_accuracy(
  y_true,
  y_pred,
  threshold = 0.5,
  ...,
  name = "binary_accuracy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_binary_accuracy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_binary_accuracy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_binary_accuracy_+3A_threshold">threshold</code></td>
<td>
<p>(Optional) Float representing the threshold for deciding
whether prediction values are 1 or 0.</p>
</td></tr>
<tr><td><code id="metric_binary_accuracy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_binary_accuracy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_binary_accuracy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This metric creates two local variables, <code>total</code> and <code>count</code> that are used to
compute the frequency with which <code>y_pred</code> matches <code>y_true</code>. This frequency is
ultimately returned as <code style="white-space: pre;">&#8288;binary accuracy&#8288;</code>: an idempotent operation that simply
divides <code>total</code> by <code>count</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_binary_crossentropy'>Computes the crossentropy metric between the labels and predictions</h2><span id='topic+metric_binary_crossentropy'></span>

<h3>Description</h3>

<p>Computes the crossentropy metric between the labels and predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_binary_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  label_smoothing = 0,
  axis = -1L,
  ...,
  name = "binary_crossentropy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_binary_crossentropy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>(Optional) Whether output is expected to be a logits tensor.
By default, we consider that output encodes a probability distribution.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_label_smoothing">label_smoothing</code></td>
<td>
<p>(Optional) Float in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. When &gt; 0, label values are
smoothed, meaning the confidence on label values are relaxed.
e.g. <code>label_smoothing = 0.2</code> means that we will use a value of <code>0.1</code> for
label <code>0</code> and <code>0.9</code> for label <code>1</code>&quot;.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_axis">axis</code></td>
<td>
<p>(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_binary_crossentropy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the crossentropy metric class to be used when there are only two
label classes (0 and 1).
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_categorical_accuracy'>Calculates how often predictions match one-hot labels</h2><span id='topic+metric_categorical_accuracy'></span>

<h3>Description</h3>

<p>Calculates how often predictions match one-hot labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_categorical_accuracy(
  y_true,
  y_pred,
  ...,
  name = "categorical_accuracy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_categorical_accuracy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_categorical_accuracy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_categorical_accuracy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_categorical_accuracy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_categorical_accuracy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can provide logits of classes as <code>y_pred</code>, since argmax of
logits and probabilities are same.
</p>
<p>This metric creates two local variables, <code>total</code> and <code>count</code> that are used to
compute the frequency with which <code>y_pred</code> matches <code>y_true</code>. This frequency is
ultimately returned as <code style="white-space: pre;">&#8288;categorical accuracy&#8288;</code>: an idempotent operation that
simply divides <code>total</code> by <code>count</code>.
</p>
<p><code>y_pred</code> and <code>y_true</code> should be passed in as vectors of probabilities, rather
than as labels. If necessary, use <code>tf.one_hot</code> to expand <code>y_true</code> as a vector.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_categorical_crossentropy'>Computes the crossentropy metric between the labels and predictions</h2><span id='topic+metric_categorical_crossentropy'></span>

<h3>Description</h3>

<p>Computes the crossentropy metric between the labels and predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_categorical_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  label_smoothing = 0,
  axis = -1L,
  ...,
  name = "categorical_crossentropy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_categorical_crossentropy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>(Optional) Whether output is expected to be a logits tensor.
By default, we consider that output encodes a probability distribution.</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_label_smoothing">label_smoothing</code></td>
<td>
<p>(Optional) Float in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. When &gt; 0, label values are
smoothed, meaning the confidence on label values are relaxed. e.g.
<code>label_smoothing=0.2</code> means that we will use a value of <code>0.1</code> for label
<code>0</code> and <code>0.9</code> for label <code>1</code>&quot;</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_axis">axis</code></td>
<td>
<p>(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_categorical_crossentropy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the crossentropy metric class to be used when there are multiple
label classes (2 or more). Here we assume that labels are given as a <code>one_hot</code>
representation. eg., When labels values are <code>c(2, 0, 1)</code>:
</p>
<div class="sourceCode"><pre> y_true = rbind(c(0, 0, 1),
                c(1, 0, 0),
                c(0, 1, 0))`
</pre></div>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_categorical_hinge'>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code></h2><span id='topic+metric_categorical_hinge'></span>

<h3>Description</h3>

<p>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_categorical_hinge(..., name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_categorical_hinge_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_categorical_hinge_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_categorical_hinge_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_cosine_proximity'>(Deprecated) metric_cosine_proximity</h2><span id='topic+metric_cosine_proximity'></span>

<h3>Description</h3>

<p><code>metric_cosine_proximity()</code> is deprecated and will be removed in a future
version. Please update your code to use <code>metric_cosine_similarity()</code> if
possible. If you need the actual function and not a Metric object, (e.g,
because you are using the intermediate computed values in a custom training
loop before reduction), please use <code>loss_cosine_similarity()</code> or
<code>tensorflow::tf$compat$v1$keras$metrics$cosine_proximity()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_cosine_proximity(y_true, y_pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_cosine_proximity_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_cosine_proximity_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
</table>

<hr>
<h2 id='metric_cosine_similarity'>Computes the cosine similarity between the labels and predictions</h2><span id='topic+metric_cosine_similarity'></span>

<h3>Description</h3>

<p>Computes the cosine similarity between the labels and predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_cosine_similarity(
  ...,
  axis = -1L,
  name = "cosine_similarity",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_cosine_similarity_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_cosine_similarity_+3A_axis">axis</code></td>
<td>
<p>(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.</p>
</td></tr>
<tr><td><code id="metric_cosine_similarity_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_cosine_similarity_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<div class="sourceCode"><pre>cosine similarity = (a . b) / ||a|| ||b||
</pre></div>
<p>See: <a href="https://en.wikipedia.org/wiki/Cosine_similarity">Cosine Similarity</a>.
</p>
<p>This metric keeps the average cosine similarity between <code>predictions</code> and
<code>labels</code> over a stream of data.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>Note</h3>

<p>If you want to compute the cosine_similarity for each case in a
mini-batch you can use <code>loss_cosine_similarity()</code>.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_false_negatives'>Calculates the number of false negatives</h2><span id='topic+metric_false_negatives'></span>

<h3>Description</h3>

<p>Calculates the number of false negatives
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_false_negatives(..., thresholds = NULL, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_false_negatives_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_false_negatives_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) Defaults to 0.5. A float value or a
list of float threshold values in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. A threshold is compared
with prediction values to determine the truth value of predictions
(i.e., above the threshold is <code>TRUE</code>, below is <code>FALSE</code>). One metric
value is generated for each threshold value.</p>
</td></tr>
<tr><td><code id="metric_false_negatives_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_false_negatives_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>sample_weight</code> is given, calculates the sum of the weights of
false negatives. This metric creates one local variable, <code>accumulator</code>
that is used to keep track of the number of false negatives.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_false_positives'>Calculates the number of false positives</h2><span id='topic+metric_false_positives'></span>

<h3>Description</h3>

<p>Calculates the number of false positives
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_false_positives(..., thresholds = NULL, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_false_positives_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_false_positives_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) Defaults to 0.5. A float value or a
list of float threshold values in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. A threshold is compared
with prediction values to determine the truth value of predictions
(i.e., above the threshold is <code>true</code>, below is <code>false</code>). One metric
value is generated for each threshold value.</p>
</td></tr>
<tr><td><code id="metric_false_positives_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_false_positives_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>sample_weight</code> is given, calculates the sum of the weights of
false positives. This metric creates one local variable, <code>accumulator</code>
that is used to keep track of the number of false positives.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_hinge'>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code></h2><span id='topic+metric_hinge'></span>

<h3>Description</h3>

<p><code>y_true</code> values are expected to be -1 or 1. If binary (0 or 1) labels are
provided we will convert them to -1 or 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_hinge(y_true, y_pred, ..., name = "hinge", dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_hinge_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_hinge_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_hinge_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_hinge_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_hinge_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<div class="sourceCode"><pre>loss = tf$reduce_mean(tf$maximum(1 - y_true * y_pred, 0L), axis=-1L)
</pre></div>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_kullback_leibler_divergence'>Computes Kullback-Leibler divergence</h2><span id='topic+metric_kullback_leibler_divergence'></span>

<h3>Description</h3>

<p>Computes Kullback-Leibler divergence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_kullback_leibler_divergence(
  y_true,
  y_pred,
  ...,
  name = "kullback_leibler_divergence",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_kullback_leibler_divergence_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_kullback_leibler_divergence_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_kullback_leibler_divergence_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_kullback_leibler_divergence_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_kullback_leibler_divergence_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<div class="sourceCode"><pre>metric = y_true * log(y_true / y_pred)
</pre></div>
<p>See: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_logcosh_error'>Computes the logarithm of the hyperbolic cosine of the prediction error</h2><span id='topic+metric_logcosh_error'></span>

<h3>Description</h3>

<p><code>logcosh = log((exp(x) + exp(-x))/2)</code>, where x is the error (<code>y_pred - y_true</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_logcosh_error(..., name = "logcosh", dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_logcosh_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_logcosh_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_logcosh_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean'>Computes the (weighted) mean of the given values</h2><span id='topic+metric_mean'></span>

<h3>Description</h3>

<p>Computes the (weighted) mean of the given values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean(..., name = "mean", dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, if values is <code>c(1, 3, 5, 7)</code> then the mean is 4.
If the weights were specified as <code>c(1, 1, 0, 0)</code> then the mean would be 2.
</p>
<p>This metric creates two variables, <code>total</code> and <code>count</code> that are used to
compute the average of <code>values</code>. This average is ultimately returned as <code>mean</code>
which is an idempotent operation that simply divides <code>total</code> by <code>count</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>Note</h3>

<p>Unlike most other metrics, this only takes a single tensor as input to update state.
</p>
<p>Example usage with <code>compile()</code>:
</p>
<div class="sourceCode"><pre>model$add_metric(metric_mean(name='mean_1')(outputs))
model %&gt;% compile(optimizer='sgd', loss='mse')
</pre></div>
<p>Example standalone usage:
</p>
<div class="sourceCode"><pre>m  &lt;- metric_mean()
m$update_state(c(1, 3, 5, 7))
m$result()

m$reset_state()
m$update_state(c(1, 3, 5, 7), sample_weight=c(1, 1, 0, 0))
m$result()
as.numeric(m$result())
</pre></div>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_absolute_error'>Computes the mean absolute error between the labels and predictions</h2><span id='topic+metric_mean_absolute_error'></span>

<h3>Description</h3>

<p>Computes the mean absolute error between the labels and predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_absolute_error(
  y_true,
  y_pred,
  ...,
  name = "mean_absolute_error",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_absolute_error_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_error_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>loss = mean(abs(y_true - y_pred), axis=-1)</code>
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_absolute_percentage_error'>Computes the mean absolute percentage error between <code>y_true</code> and <code>y_pred</code></h2><span id='topic+metric_mean_absolute_percentage_error'></span>

<h3>Description</h3>

<p>Computes the mean absolute percentage error between <code>y_true</code> and <code>y_pred</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_absolute_percentage_error(
  y_true,
  y_pred,
  ...,
  name = "mean_absolute_percentage_error",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_absolute_percentage_error_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_percentage_error_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_percentage_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_percentage_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_absolute_percentage_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>loss = 100 * mean(abs((y_true - y_pred) / y_true), axis=-1)</code>
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_iou'>Computes the mean Intersection-Over-Union metric</h2><span id='topic+metric_mean_iou'></span>

<h3>Description</h3>

<p>Computes the mean Intersection-Over-Union metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_iou(..., num_classes, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_iou_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_iou_+3A_num_classes">num_classes</code></td>
<td>
<p>The possible number of labels the prediction task can have.
This value must be provided, since a confusion matrix of <code>dim</code>
<code>c(num_classes, num_classes)</code> will be allocated.</p>
</td></tr>
<tr><td><code id="metric_mean_iou_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_iou_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mean Intersection-Over-Union is a common evaluation metric for semantic image
segmentation, which first computes the IOU for each semantic class and then
computes the average over classes. IOU is defined as follows:
</p>
<div class="sourceCode"><pre>  IOU = true_positive / (true_positive + false_positive + false_negative)
</pre></div>
<p>The predictions are accumulated in a confusion matrix, weighted by
<code>sample_weight</code> and the metric is then calculated from it.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_relative_error'>Computes the mean relative error by normalizing with the given values</h2><span id='topic+metric_mean_relative_error'></span>

<h3>Description</h3>

<p>Computes the mean relative error by normalizing with the given values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_relative_error(..., normalizer, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_relative_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_relative_error_+3A_normalizer">normalizer</code></td>
<td>
<p>The normalizer values with same shape as predictions.</p>
</td></tr>
<tr><td><code id="metric_mean_relative_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_relative_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This metric creates two local variables, <code>total</code> and <code>count</code> that are used to
compute the mean relative error. This is weighted by <code>sample_weight</code>, and
it is ultimately returned as <code>mean_relative_error</code>:
an idempotent operation that simply divides <code>total</code> by <code>count</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>
<div class="sourceCode"><pre>metric = mean(|y_pred - y_true| / normalizer)
</pre></div>
<p>For example:
</p>
<div class="sourceCode"><pre>m = metric_mean_relative_error(normalizer=c(1, 3, 2, 3))
m$update_state(c(1, 3, 2, 3), c(2, 4, 6, 8))
 # result     = mean(c(1, 1, 4, 5) / c(1, 3, 2, 3)) = mean(c(1, 1/3, 2, 5/3))
 #            = 5/4 = 1.25
m$result()
</pre></div>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_squared_error'>Computes the mean squared error between labels and predictions</h2><span id='topic+metric_mean_squared_error'></span>

<h3>Description</h3>

<p>Computes the mean squared error between labels and predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_squared_error(
  y_true,
  y_pred,
  ...,
  name = "mean_squared_error",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_squared_error_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_error_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After computing the squared distance between the inputs, the mean value over
the last dimension is returned.
</p>
<p><code>loss = mean(square(y_true - y_pred), axis=-1)</code>
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_squared_logarithmic_error'>Computes the mean squared logarithmic error</h2><span id='topic+metric_mean_squared_logarithmic_error'></span>

<h3>Description</h3>

<p>Computes the mean squared logarithmic error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_squared_logarithmic_error(
  y_true,
  y_pred,
  ...,
  name = "mean_squared_logarithmic_error",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_squared_logarithmic_error_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_logarithmic_error_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_logarithmic_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_logarithmic_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_squared_logarithmic_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>loss = mean(square(log(y_true + 1) - log(y_pred + 1)), axis=-1)</code>
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_tensor'>Computes the element-wise (weighted) mean of the given tensors</h2><span id='topic+metric_mean_tensor'></span>

<h3>Description</h3>

<p>Computes the element-wise (weighted) mean of the given tensors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_tensor(..., shape = NULL, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_tensor_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_mean_tensor_+3A_shape">shape</code></td>
<td>
<p>(Optional) A list of integers, a list of integers, or a 1-D Tensor
of type int32. If not specified, the shape is inferred from the values at
the first call of update_state.</p>
</td></tr>
<tr><td><code id="metric_mean_tensor_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_tensor_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MeanTensor</code> returns a tensor with the same shape of the input tensors. The
mean value is updated by keeping local variables <code>total</code> and <code>count</code>. The
<code>total</code> tracks the sum of the weighted values, and <code>count</code> stores the sum of
the weighted counts.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_mean_wrapper'>Wraps a stateless metric function with the Mean metric</h2><span id='topic+metric_mean_wrapper'></span>

<h3>Description</h3>

<p>Wraps a stateless metric function with the Mean metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mean_wrapper(..., fn, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mean_wrapper_+3A_...">...</code></td>
<td>
<p>named arguments to pass on to <code>fn</code>.</p>
</td></tr>
<tr><td><code id="metric_mean_wrapper_+3A_fn">fn</code></td>
<td>
<p>The metric function to wrap, with signature <code>fn(y_true, y_pred, ...)</code>.</p>
</td></tr>
<tr><td><code id="metric_mean_wrapper_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mean_wrapper_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You could use this class to quickly build a mean metric from a function. The
function needs to have the signature <code>fn(y_true, y_pred)</code> and return a
per-sample loss array. <code>MeanMetricWrapper$result()</code> will return
the average metric value across all samples seen so far.
</p>
<p>For example:
</p>
<div class="sourceCode r"><pre>accuracy &lt;- function(y_true, y_pred)
  k_cast(y_true == y_pred, 'float32')

accuracy_metric &lt;- metric_mean_wrapper(fn = accuracy)

model %&gt;% compile(..., metrics=accuracy_metric)
</pre></div>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_poisson'>Computes the Poisson metric between <code>y_true</code> and <code>y_pred</code></h2><span id='topic+metric_poisson'></span>

<h3>Description</h3>

<p><code>metric = y_pred - y_true * log(y_pred)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_poisson(y_true, y_pred, ..., name = "poisson", dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_poisson_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_poisson_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_poisson_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_poisson_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_poisson_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_precision'>Computes the precision of the predictions with respect to the labels</h2><span id='topic+metric_precision'></span>

<h3>Description</h3>

<p>Computes the precision of the predictions with respect to the labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_precision(
  ...,
  thresholds = NULL,
  top_k = NULL,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_precision_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_precision_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) A float value or a list of float
threshold values in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. A threshold is compared with prediction values
to determine the truth value of predictions (i.e., above the threshold is
<code>true</code>, below is <code>false</code>). One metric value is generated for each threshold
value. If neither thresholds nor top_k are set, the default is to calculate
precision with <code>thresholds=0.5</code>.</p>
</td></tr>
<tr><td><code id="metric_precision_+3A_top_k">top_k</code></td>
<td>
<p>(Optional) Unset by default. An int value specifying the top-k
predictions to consider when calculating precision.</p>
</td></tr>
<tr><td><code id="metric_precision_+3A_class_id">class_id</code></td>
<td>
<p>(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval <code style="white-space: pre;">&#8288;[0, num_classes)&#8288;</code>, where
<code>num_classes</code> is the last dimension of predictions.</p>
</td></tr>
<tr><td><code id="metric_precision_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_precision_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The metric creates two local variables, <code>true_positives</code> and
<code>false_positives</code> that are used to compute the precision. This value is
ultimately returned as <code>precision</code>, an idempotent operation that simply
divides <code>true_positives</code> by the sum of <code>true_positives</code> and
<code>false_positives</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1. Use <code>sample_weight</code> of 0
to mask values.
</p>
<p>If <code>top_k</code> is set, we'll calculate precision as how often on average a class
among the top-k classes with the highest predicted values of a batch entry is
correct and can be found in the label for that entry.
</p>
<p>If <code>class_id</code> is specified, we calculate precision by considering only the
entries in the batch for which <code>class_id</code> is above the threshold and/or in
the top-k highest predictions, and computing the fraction of them for which
<code>class_id</code> is indeed a correct label.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_precision_at_recall'>Computes best precision where recall is &gt;= specified value</h2><span id='topic+metric_precision_at_recall'></span>

<h3>Description</h3>

<p>Computes best precision where recall is &gt;= specified value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_precision_at_recall(
  ...,
  recall,
  num_thresholds = 200L,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_precision_at_recall_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_precision_at_recall_+3A_recall">recall</code></td>
<td>
<p>A scalar value in range <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="metric_precision_at_recall_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>(Optional) Defaults to 200. The number of thresholds to
use for matching the given recall.</p>
</td></tr>
<tr><td><code id="metric_precision_at_recall_+3A_class_id">class_id</code></td>
<td>
<p>(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval <code style="white-space: pre;">&#8288;[0, num_classes)&#8288;</code>, where
<code>num_classes</code> is the last dimension of predictions.</p>
</td></tr>
<tr><td><code id="metric_precision_at_recall_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_precision_at_recall_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This metric creates four local variables, <code>true_positives</code>,
<code>true_negatives</code>, <code>false_positives</code> and <code>false_negatives</code> that are used to
compute the precision at the given recall. The threshold for the given recall
value is computed and used to evaluate the corresponding precision.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1. Use <code>sample_weight</code> of 0
to mask values.
</p>
<p>If <code>class_id</code> is specified, we calculate precision by considering only the
entries in the batch for which <code>class_id</code> is above the threshold predictions,
and computing the fraction of them for which <code>class_id</code> is indeed a correct
label.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_recall'>Computes the recall of the predictions with respect to the labels</h2><span id='topic+metric_recall'></span>

<h3>Description</h3>

<p>Computes the recall of the predictions with respect to the labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_recall(
  ...,
  thresholds = NULL,
  top_k = NULL,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_recall_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_recall_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) A float value or a list of float
threshold values in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. A threshold is compared with prediction values
to determine the truth value of predictions (i.e., above the threshold is
<code>true</code>, below is <code>false</code>). One metric value is generated for each threshold
value. If neither thresholds nor top_k are set, the default is to calculate
recall with <code>thresholds=0.5</code>.</p>
</td></tr>
<tr><td><code id="metric_recall_+3A_top_k">top_k</code></td>
<td>
<p>(Optional) Unset by default. An int value specifying the top-k
predictions to consider when calculating recall.</p>
</td></tr>
<tr><td><code id="metric_recall_+3A_class_id">class_id</code></td>
<td>
<p>(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval <code style="white-space: pre;">&#8288;[0, num_classes)&#8288;</code>, where
<code>num_classes</code> is the last dimension of predictions.</p>
</td></tr>
<tr><td><code id="metric_recall_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_recall_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This metric creates two local variables, <code>true_positives</code> and
<code>false_negatives</code>, that are used to compute the recall. This value is
ultimately returned as <code>recall</code>, an idempotent operation that simply divides
<code>true_positives</code> by the sum of <code>true_positives</code> and <code>false_negatives</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1. Use <code>sample_weight</code> of 0
to mask values.
</p>
<p>If <code>top_k</code> is set, recall will be computed as how often on average a class
among the labels of a batch entry is in the top-k predictions.
</p>
<p>If <code>class_id</code> is specified, we calculate recall by considering only the
entries in the batch for which <code>class_id</code> is in the label, and computing the
fraction of them for which <code>class_id</code> is above the threshold and/or in the
top-k predictions.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_recall_at_precision'>Computes best recall where precision is &gt;= specified value</h2><span id='topic+metric_recall_at_precision'></span>

<h3>Description</h3>

<p>Computes best recall where precision is &gt;= specified value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_recall_at_precision(
  ...,
  precision,
  num_thresholds = 200L,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_recall_at_precision_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_recall_at_precision_+3A_precision">precision</code></td>
<td>
<p>A scalar value in range <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="metric_recall_at_precision_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>(Optional) Defaults to 200. The number of thresholds to
use for matching the given precision.</p>
</td></tr>
<tr><td><code id="metric_recall_at_precision_+3A_class_id">class_id</code></td>
<td>
<p>(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval <code style="white-space: pre;">&#8288;[0, num_classes)&#8288;</code>, where
<code>num_classes</code> is the last dimension of predictions.</p>
</td></tr>
<tr><td><code id="metric_recall_at_precision_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_recall_at_precision_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a given score-label-distribution the required precision might
not be achievable, in this case 0.0 is returned as recall.
</p>
<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>,
<code>false_positives</code> and <code>false_negatives</code> that are used to compute the recall
at the given precision. The threshold for the given precision value is
computed and used to evaluate the corresponding recall.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1. Use <code>sample_weight</code> of 0
to mask values.
</p>
<p>If <code>class_id</code> is specified, we calculate precision by considering only the
entries in the batch for which <code>class_id</code> is above the threshold predictions,
and computing the fraction of them for which <code>class_id</code> is indeed a correct
label.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_root_mean_squared_error'>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code></h2><span id='topic+metric_root_mean_squared_error'></span>

<h3>Description</h3>

<p>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_root_mean_squared_error(..., name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_root_mean_squared_error_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_root_mean_squared_error_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_root_mean_squared_error_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_sensitivity_at_specificity'>Computes best sensitivity where specificity is &gt;= specified value</h2><span id='topic+metric_sensitivity_at_specificity'></span>

<h3>Description</h3>

<p>The sensitivity at a given specificity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_sensitivity_at_specificity(
  ...,
  specificity,
  num_thresholds = 200L,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_sensitivity_at_specificity_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_sensitivity_at_specificity_+3A_specificity">specificity</code></td>
<td>
<p>A scalar value in range <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="metric_sensitivity_at_specificity_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>(Optional) Defaults to 200. The number of thresholds to
use for matching the given specificity.</p>
</td></tr>
<tr><td><code id="metric_sensitivity_at_specificity_+3A_class_id">class_id</code></td>
<td>
<p>(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval <code style="white-space: pre;">&#8288;[0, num_classes)&#8288;</code>, where
<code>num_classes</code> is the last dimension of predictions.</p>
</td></tr>
<tr><td><code id="metric_sensitivity_at_specificity_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_sensitivity_at_specificity_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Sensitivity</code> measures the proportion of actual positives that are correctly
identified as such <code>(tp / (tp + fn))</code>. <code>Specificity</code> measures the proportion of
actual negatives that are correctly identified as such <code>(tn / (tn + fp))</code>.
</p>
<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>,
<code>false_positives</code> and <code>false_negatives</code> that are used to compute the
sensitivity at the given specificity. The threshold for the given specificity
value is computed and used to evaluate the corresponding sensitivity.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1. Use <code>sample_weight</code> of 0
to mask values.
</p>
<p>If <code>class_id</code> is specified, we calculate precision by considering only the
entries in the batch for which <code>class_id</code> is above the threshold predictions,
and computing the fraction of them for which <code>class_id</code> is indeed a correct
label.
</p>
<p>For additional information about specificity and sensitivity, see <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">the following</a>.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_sparse_categorical_accuracy'>Calculates how often predictions match integer labels</h2><span id='topic+metric_sparse_categorical_accuracy'></span>

<h3>Description</h3>

<p>Calculates how often predictions match integer labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_sparse_categorical_accuracy(
  y_true,
  y_pred,
  ...,
  name = "sparse_categorical_accuracy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_sparse_categorical_accuracy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_accuracy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_accuracy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_accuracy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_accuracy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<div class="sourceCode r"><pre>acc = k_dot(sample_weight, y_true == k_argmax(y_pred, axis=2))
</pre></div>
<p>You can provide logits of classes as <code>y_pred</code>, since argmax of
logits and probabilities are same.
</p>
<p>This metric creates two local variables, <code>total</code> and <code>count</code> that are used to
compute the frequency with which <code>y_pred</code> matches <code>y_true</code>. This frequency is
ultimately returned as <code style="white-space: pre;">&#8288;sparse categorical accuracy&#8288;</code>: an idempotent operation
that simply divides <code>total</code> by <code>count</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_sparse_categorical_crossentropy'>Computes the crossentropy metric between the labels and predictions</h2><span id='topic+metric_sparse_categorical_crossentropy'></span>

<h3>Description</h3>

<p>Computes the crossentropy metric between the labels and predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_sparse_categorical_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  axis = -1L,
  ...,
  name = "sparse_categorical_crossentropy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>(Optional) Whether output is expected to be a logits tensor.
By default, we consider that output encodes a probability distribution.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_axis">axis</code></td>
<td>
<p>(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_sparse_categorical_crossentropy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use this crossentropy metric when there are two or more label classes.
We expect labels to be provided as integers. If you want to provide labels
using <code>one-hot</code> representation, please use <code>CategoricalCrossentropy</code> metric.
There should be <code style="white-space: pre;">&#8288;# classes&#8288;</code> floating point values per feature for <code>y_pred</code>
and a single floating point value per feature for <code>y_true</code>.
</p>
<p>In the snippet below, there is a single floating point value per example for
<code>y_true</code> and <code style="white-space: pre;">&#8288;# classes&#8288;</code> floating pointing values per example for <code>y_pred</code>.
The shape of <code>y_true</code> is <code style="white-space: pre;">&#8288;[batch_size]&#8288;</code> and the shape of <code>y_pred</code> is
<code style="white-space: pre;">&#8288;[batch_size, num_classes]&#8288;</code>.
</p>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_sparse_top_k_categorical_accuracy'>Computes how often integer targets are in the top <code>K</code> predictions</h2><span id='topic+metric_sparse_top_k_categorical_accuracy'></span>

<h3>Description</h3>

<p>Computes how often integer targets are in the top <code>K</code> predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_sparse_top_k_categorical_accuracy(
  y_true,
  y_pred,
  k = 5L,
  ...,
  name = "sparse_top_k_categorical_accuracy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_sparse_top_k_categorical_accuracy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_sparse_top_k_categorical_accuracy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_sparse_top_k_categorical_accuracy_+3A_k">k</code></td>
<td>
<p>(Optional) Number of top elements to look at for computing accuracy.
Defaults to 5.</p>
</td></tr>
<tr><td><code id="metric_sparse_top_k_categorical_accuracy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_sparse_top_k_categorical_accuracy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_sparse_top_k_categorical_accuracy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_specificity_at_sensitivity'>Computes best specificity where sensitivity is &gt;= specified value</h2><span id='topic+metric_specificity_at_sensitivity'></span>

<h3>Description</h3>

<p>Computes best specificity where sensitivity is &gt;= specified value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_specificity_at_sensitivity(
  ...,
  sensitivity,
  num_thresholds = 200L,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_specificity_at_sensitivity_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_specificity_at_sensitivity_+3A_sensitivity">sensitivity</code></td>
<td>
<p>A scalar value in range <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="metric_specificity_at_sensitivity_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>(Optional) Defaults to 200. The number of thresholds to
use for matching the given sensitivity.</p>
</td></tr>
<tr><td><code id="metric_specificity_at_sensitivity_+3A_class_id">class_id</code></td>
<td>
<p>(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval <code style="white-space: pre;">&#8288;[0, num_classes)&#8288;</code>, where
<code>num_classes</code> is the last dimension of predictions.</p>
</td></tr>
<tr><td><code id="metric_specificity_at_sensitivity_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_specificity_at_sensitivity_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Sensitivity</code> measures the proportion of actual positives that are correctly
identified as such <code>(tp / (tp + fn))</code>.
<code>Specificity</code> measures the proportion of actual negatives that are correctly
identified as such <code>(tn / (tn + fp))</code>.
</p>
<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>,
<code>false_positives</code> and <code>false_negatives</code> that are used to compute the
specificity at the given sensitivity. The threshold for the given sensitivity
value is computed and used to evaluate the corresponding specificity.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>
<p>If <code>class_id</code> is specified, we calculate precision by considering only the
entries in the batch for which <code>class_id</code> is above the threshold predictions,
and computing the fraction of them for which <code>class_id</code> is indeed a correct
label.
</p>
<p>For additional information about specificity and sensitivity, see
<a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">the following</a>.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_squared_hinge'>Computes the squared hinge metric</h2><span id='topic+metric_squared_hinge'></span>

<h3>Description</h3>

<p><code>y_true</code> values are expected to be -1 or 1. If binary (0 or 1) labels are
provided we will convert them to -1 or 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_squared_hinge(y_true, y_pred, ..., name = "squared_hinge", dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_squared_hinge_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_squared_hinge_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_squared_hinge_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_squared_hinge_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_squared_hinge_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_sum'>Computes the (weighted) sum of the given values</h2><span id='topic+metric_sum'></span>

<h3>Description</h3>

<p>Computes the (weighted) sum of the given values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_sum(..., name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_sum_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_sum_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_sum_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, if values is <code>c(1, 3, 5, 7)</code> then the sum is 16.
If the weights were specified as <code>c(1, 1, 0, 0)</code> then the sum would be 4.
</p>
<p>This metric creates one variable, <code>total</code>, that is used to compute the sum of
<code>values</code>. This is ultimately returned as <code>sum</code>.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.  Use <code>sample_weight</code> of 0
to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_top_k_categorical_accuracy'>Computes how often targets are in the top <code>K</code> predictions</h2><span id='topic+metric_top_k_categorical_accuracy'></span>

<h3>Description</h3>

<p>Computes how often targets are in the top <code>K</code> predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_top_k_categorical_accuracy(
  y_true,
  y_pred,
  k = 5L,
  ...,
  name = "top_k_categorical_accuracy",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_top_k_categorical_accuracy_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric_top_k_categorical_accuracy_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric_top_k_categorical_accuracy_+3A_k">k</code></td>
<td>
<p>(Optional) Number of top elements to look at for computing accuracy.
Defaults to 5.</p>
</td></tr>
<tr><td><code id="metric_top_k_categorical_accuracy_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_top_k_categorical_accuracy_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_top_k_categorical_accuracy_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_true_negatives'>Calculates the number of true negatives</h2><span id='topic+metric_true_negatives'></span>

<h3>Description</h3>

<p>Calculates the number of true negatives
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_true_negatives(..., thresholds = NULL, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_true_negatives_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_true_negatives_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) Defaults to 0.5. A float value or a
list of float threshold values in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. A threshold is compared
with prediction values to determine the truth value of predictions
(i.e., above the threshold is <code>true</code>, below is <code>false</code>). One metric
value is generated for each threshold value.</p>
</td></tr>
<tr><td><code id="metric_true_negatives_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_true_negatives_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>sample_weight</code> is given, calculates the sum of the weights of
true negatives. This metric creates one local variable, <code>accumulator</code>
that is used to keep track of the number of true negatives.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_positives">metric_true_positives</a>()</code>
</p>

<hr>
<h2 id='metric_true_positives'>Calculates the number of true positives</h2><span id='topic+metric_true_positives'></span>

<h3>Description</h3>

<p>Calculates the number of true positives
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_true_positives(..., thresholds = NULL, name = NULL, dtype = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_true_positives_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric_true_positives_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) Defaults to 0.5. A float value or a
list of float threshold values in <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code>. A threshold is compared
with prediction values to determine the truth value of predictions
(i.e., above the threshold is <code>true</code>, below is <code>false</code>). One metric
value is generated for each threshold value.</p>
</td></tr>
<tr><td><code id="metric_true_positives_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_true_positives_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>sample_weight</code> is given, calculates the sum of the weights of
true positives. This metric creates one local variable, <code>true_positives</code>
that is used to keep track of the number of true positives.
</p>
<p>If <code>sample_weight</code> is <code>NULL</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.
</p>


<h3>Value</h3>

<p>A (subclassed) <code>Metric</code> instance that can be passed directly to
<code>compile(metrics = )</code>, or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>


<h3>See Also</h3>

<p>Other metrics: 
<code><a href="#topic+custom_metric">custom_metric</a>()</code>,
<code><a href="#topic+metric_accuracy">metric_accuracy</a>()</code>,
<code><a href="#topic+metric_auc">metric_auc</a>()</code>,
<code><a href="#topic+metric_binary_accuracy">metric_binary_accuracy</a>()</code>,
<code><a href="#topic+metric_binary_crossentropy">metric_binary_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_accuracy">metric_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_categorical_crossentropy">metric_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_categorical_hinge">metric_categorical_hinge</a>()</code>,
<code><a href="#topic+metric_cosine_similarity">metric_cosine_similarity</a>()</code>,
<code><a href="#topic+metric_false_negatives">metric_false_negatives</a>()</code>,
<code><a href="#topic+metric_false_positives">metric_false_positives</a>()</code>,
<code><a href="#topic+metric_hinge">metric_hinge</a>()</code>,
<code><a href="#topic+metric_kullback_leibler_divergence">metric_kullback_leibler_divergence</a>()</code>,
<code><a href="#topic+metric_logcosh_error">metric_logcosh_error</a>()</code>,
<code><a href="#topic+metric_mean">metric_mean</a>()</code>,
<code><a href="#topic+metric_mean_absolute_error">metric_mean_absolute_error</a>()</code>,
<code><a href="#topic+metric_mean_absolute_percentage_error">metric_mean_absolute_percentage_error</a>()</code>,
<code><a href="#topic+metric_mean_iou">metric_mean_iou</a>()</code>,
<code><a href="#topic+metric_mean_relative_error">metric_mean_relative_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_error">metric_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_mean_squared_logarithmic_error">metric_mean_squared_logarithmic_error</a>()</code>,
<code><a href="#topic+metric_mean_tensor">metric_mean_tensor</a>()</code>,
<code><a href="#topic+metric_mean_wrapper">metric_mean_wrapper</a>()</code>,
<code><a href="#topic+metric_poisson">metric_poisson</a>()</code>,
<code><a href="#topic+metric_precision">metric_precision</a>()</code>,
<code><a href="#topic+metric_precision_at_recall">metric_precision_at_recall</a>()</code>,
<code><a href="#topic+metric_recall">metric_recall</a>()</code>,
<code><a href="#topic+metric_recall_at_precision">metric_recall_at_precision</a>()</code>,
<code><a href="#topic+metric_root_mean_squared_error">metric_root_mean_squared_error</a>()</code>,
<code><a href="#topic+metric_sensitivity_at_specificity">metric_sensitivity_at_specificity</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_accuracy">metric_sparse_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_sparse_categorical_crossentropy">metric_sparse_categorical_crossentropy</a>()</code>,
<code><a href="#topic+metric_sparse_top_k_categorical_accuracy">metric_sparse_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_specificity_at_sensitivity">metric_specificity_at_sensitivity</a>()</code>,
<code><a href="#topic+metric_squared_hinge">metric_squared_hinge</a>()</code>,
<code><a href="#topic+metric_sum">metric_sum</a>()</code>,
<code><a href="#topic+metric_top_k_categorical_accuracy">metric_top_k_categorical_accuracy</a>()</code>,
<code><a href="#topic+metric_true_negatives">metric_true_negatives</a>()</code>
</p>

<hr>
<h2 id='metric-or-Metric'>metric-or-Metric</h2><span id='topic+metric-or-Metric'></span>

<h3>Description</h3>

<p>metric-or-Metric
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric-or-Metric_+3A_y_true">y_true</code></td>
<td>
<p>Tensor of true targets.</p>
</td></tr>
<tr><td><code id="metric-or-Metric_+3A_y_pred">y_pred</code></td>
<td>
<p>Tensor of predicted targets.</p>
</td></tr>
<tr><td><code id="metric-or-Metric_+3A_...">...</code></td>
<td>
<p>Passed on to the underlying metric. Used for forwards and backwards compatibility.</p>
</td></tr>
<tr><td><code id="metric-or-Metric_+3A_axis">axis</code></td>
<td>
<p>(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.</p>
</td></tr>
<tr><td><code id="metric-or-Metric_+3A_name">name</code></td>
<td>
<p>(Optional) string name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric-or-Metric_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) data type of the metric result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>y_true</code> and <code>y_pred</code> are missing, a (subclassed) <code>Metric</code>
instance is returned. The <code>Metric</code> object can be passed directly to
<code>compile(metrics = )</code> or used as a standalone object. See <code>?Metric</code> for
example usage.
</p>
<p>Alternatively, if called with <code>y_true</code> and <code>y_pred</code> arguments, then the
computed case-wise values for the mini-batch are returned directly.
</p>

<hr>
<h2 id='model_from_saved_model'>Load a Keras model from the Saved Model format</h2><span id='topic+model_from_saved_model'></span>

<h3>Description</h3>

<p>Load a Keras model from the Saved Model format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_from_saved_model(saved_model_path, custom_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_from_saved_model_+3A_saved_model_path">saved_model_path</code></td>
<td>
<p>a string specifying the path to the SavedModel directory.</p>
</td></tr>
<tr><td><code id="model_from_saved_model_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Optional dictionary mapping string names to custom classes
or functions (e.g. custom loss functions).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a Keras model.
</p>


<h3>Note</h3>

<p>This functionality is experimental and only works with TensorFlow
version &gt;= &quot;2.0&quot;.
</p>


<h3>See Also</h3>

<p>Other saved_model: 
<code><a href="#topic+model_to_saved_model">model_to_saved_model</a>()</code>
</p>

<hr>
<h2 id='model_to_json'>Model configuration as JSON</h2><span id='topic+model_to_json'></span><span id='topic+model_from_json'></span>

<h3>Description</h3>

<p>Save and re-load models configurations as JSON. Note that the representation
does not include the weights, only the architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_to_json(object)

model_from_json(json, custom_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_to_json_+3A_object">object</code></td>
<td>
<p>Model object to save</p>
</td></tr>
<tr><td><code id="model_to_json_+3A_json">json</code></td>
<td>
<p>JSON with model configuration</p>
</td></tr>
<tr><td><code id="model_to_json_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Optional named list mapping names to custom classes or
functions to be considered during deserialization.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+model_to_yaml">model_to_yaml</a>()</code>,
<code><a href="#topic+save_model_hdf5">save_model_hdf5</a>()</code>,
<code><a href="#topic+save_model_tf">save_model_tf</a>()</code>,
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5</a>()</code>,
<code><a href="#topic+serialize_model">serialize_model</a>()</code>
</p>

<hr>
<h2 id='model_to_saved_model'>(Deprecated) Export to Saved Model format</h2><span id='topic+model_to_saved_model'></span>

<h3>Description</h3>

<p>(Deprecated) Export to Saved Model format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_to_saved_model(
  model,
  saved_model_path,
  custom_objects = NULL,
  as_text = FALSE,
  input_signature = NULL,
  serving_only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_to_saved_model_+3A_model">model</code></td>
<td>
<p>A Keras model to be saved. If the model is subclassed, the flag
<code>serving_only</code> must be set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="model_to_saved_model_+3A_saved_model_path">saved_model_path</code></td>
<td>
<p>a string specifying the path to the SavedModel directory.</p>
</td></tr>
<tr><td><code id="model_to_saved_model_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Optional dictionary mapping string names to custom classes
or functions (e.g. custom loss functions).</p>
</td></tr>
<tr><td><code id="model_to_saved_model_+3A_as_text">as_text</code></td>
<td>
<p>bool, <code>FALSE</code> by default. Whether to write the SavedModel proto in text
format. Currently unavailable in serving-only mode.</p>
</td></tr>
<tr><td><code id="model_to_saved_model_+3A_input_signature">input_signature</code></td>
<td>
<p>A possibly nested sequence of <code>tf.TensorSpec</code> objects, used to
specify the expected model inputs. See tf.function for more details.</p>
</td></tr>
<tr><td><code id="model_to_saved_model_+3A_serving_only">serving_only</code></td>
<td>
<p>bool, <code>FALSE</code> by default. When this is true, only the
prediction graph is saved.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the <code>saved_model_path</code>.
</p>


<h3>Note</h3>

<p>This functionality is experimental and only works with TensorFlow
version &gt;= &quot;2.0&quot;.
</p>


<h3>See Also</h3>

<p>Other saved_model: 
<code><a href="#topic+model_from_saved_model">model_from_saved_model</a>()</code>
</p>

<hr>
<h2 id='model_to_yaml'>Model configuration as YAML</h2><span id='topic+model_to_yaml'></span><span id='topic+model_from_yaml'></span>

<h3>Description</h3>

<p>Save and re-load models configurations as YAML Note that the representation
does not include the weights, only the architecture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_to_yaml(object)

model_from_yaml(yaml, custom_objects = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_to_yaml_+3A_object">object</code></td>
<td>
<p>Model object to save</p>
</td></tr>
<tr><td><code id="model_to_yaml_+3A_yaml">yaml</code></td>
<td>
<p>YAML with model configuration</p>
</td></tr>
<tr><td><code id="model_to_yaml_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Optional named list mapping names to custom classes or
functions to be considered during deserialization.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+model_to_json">model_to_json</a>()</code>,
<code><a href="#topic+save_model_hdf5">save_model_hdf5</a>()</code>,
<code><a href="#topic+save_model_tf">save_model_tf</a>()</code>,
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5</a>()</code>,
<code><a href="#topic+serialize_model">serialize_model</a>()</code>
</p>

<hr>
<h2 id='multi_gpu_model'>(Deprecated) Replicates a model on different GPUs.</h2><span id='topic+multi_gpu_model'></span>

<h3>Description</h3>

<p>(Deprecated) Replicates a model on different GPUs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_gpu_model(model, gpus = NULL, cpu_merge = TRUE, cpu_relocation = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi_gpu_model_+3A_model">model</code></td>
<td>
<p>A Keras model instance. To avoid OOM errors,
this model could have been built on CPU, for instance
(see usage example below).</p>
</td></tr>
<tr><td><code id="multi_gpu_model_+3A_gpus">gpus</code></td>
<td>
<p><code>NULL</code> to use all available GPUs (default). Integer &gt;= 2 or
list of integers, number of GPUs or list of GPU IDs on which to create
model replicas.</p>
</td></tr>
<tr><td><code id="multi_gpu_model_+3A_cpu_merge">cpu_merge</code></td>
<td>
<p>A boolean value to identify whether to force
merging model weights under the scope of the CPU or not.</p>
</td></tr>
<tr><td><code id="multi_gpu_model_+3A_cpu_relocation">cpu_relocation</code></td>
<td>
<p>A boolean value to identify whether to
create the model's weights under the scope of the CPU.
If the model is not defined under any preceding device
scope, you can still rescue it by activating this option.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Specifically, this function implements single-machine
multi-GPU data parallelism. It works in the following way:
</p>

<ul>
<li><p> Divide the model's input(s) into multiple sub-batches.
</p>
</li>
<li><p> Apply a model copy on each sub-batch. Every model copy
is executed on a dedicated GPU.
</p>
</li>
<li><p> Concatenate the results (on CPU) into one big batch.
</p>
</li></ul>

<p>E.g. if your <code>batch_size</code> is 64 and you use <code>gpus=2</code>,
then we will divide the input into 2 sub-batches of 32 samples,
process each sub-batch on one GPU, then return the full
batch of 64 processed samples.
</p>
<p>This induces quasi-linear speedup on up to 8 GPUs.
</p>
<p>This function is only available with the TensorFlow backend
for the time being.
</p>


<h3>Value</h3>

<p>A Keras model object which can be used just like the initial
<code>model</code> argument, but which distributes its workload on multiple GPUs.
</p>


<h3>Model Saving</h3>

<p>To save the multi-gpu model, use <code><a href="#topic+save_model_hdf5">save_model_hdf5()</a></code> or
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5()</a></code> with the template model (the argument you
passed to <code>multi_gpu_model</code>), rather than the model returned
by <code>multi_gpu_model</code>.
</p>


<h3>Note</h3>

<p>This function is deprecated and has been removed from tensorflow on
2020-04-01. To distribute your training across all available GPUS,
you can use <code>tensorflow::tf$distribute$MirroredStrategy()</code>
by creating your model like this:
</p>
<div class="sourceCode r"><pre>strategy &lt;- tensorflow::tf$distribute$MirroredStrategy()
with(strategy$scope(), {
  model &lt;- application_xception(
    weights = NULL,
    input_shape = c(height, width, 3),
    classes = num_classes
})
</pre></div>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

library(keras)
library(tensorflow)

num_samples &lt;- 1000
height &lt;- 224
width &lt;- 224
num_classes &lt;- 1000

# Instantiate the base model (or "template" model).
# We recommend doing this with under a CPU device scope,
# so that the model's weights are hosted on CPU memory.
# Otherwise they may end up hosted on a GPU, which would
# complicate weight sharing.
with(tf$device("/cpu:0"), {
  model &lt;- application_xception(
    weights = NULL,
    input_shape = c(height, width, 3),
    classes = num_classes
  )
})

# Replicates the model on 8 GPUs.
# This assumes that your machine has 8 available GPUs.
parallel_model &lt;- multi_gpu_model(model, gpus = 8)
parallel_model %&gt;% compile(
  loss = "categorical_crossentropy",
  optimizer = "rmsprop"
)

# Generate dummy data.
x &lt;- array(runif(num_samples * height * width*3),
           dim = c(num_samples, height, width, 3))
y &lt;- array(runif(num_samples * num_classes),
           dim = c(num_samples, num_classes))

# This `fit` call will be distributed on 8 GPUs.
# Since the batch size is 256, each GPU will process 32 samples.
parallel_model %&gt;% fit(x, y, epochs = 20, batch_size = 256)

# Save model via the template model (which shares the same weights):
model %&gt;% save_model_hdf5("my_model.h5")

## End(Not run)

</code></pre>

<hr>
<h2 id='new_learning_rate_schedule_class'>Create a new learning rate schedule type</h2><span id='topic+new_learning_rate_schedule_class'></span>

<h3>Description</h3>

<p>Create a new learning rate schedule type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_learning_rate_schedule_class(
  classname,
  ...,
  initialize = NULL,
  call,
  get_config = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="new_learning_rate_schedule_class_+3A_classname">classname</code></td>
<td>
<p>string</p>
</td></tr>
<tr><td><code id="new_learning_rate_schedule_class_+3A_...">...</code></td>
<td>
<p>methods and properties of the schedule class</p>
</td></tr>
<tr><td><code id="new_learning_rate_schedule_class_+3A_initialize">initialize</code>, <code id="new_learning_rate_schedule_class_+3A_get_config">get_config</code></td>
<td>
<p>Additional recommended methods to implement.
</p>

<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule</a>
</p>
</li></ul>
</td></tr>
<tr><td><code id="new_learning_rate_schedule_class_+3A_call">call</code></td>
<td>
<p>function which takes a step argument (scalar integer tensor, the
current training step count, and returns the new learning rate). For
tracking additional state, objects <code>self</code> and <code>private</code> are automatically
injected into the scope of the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>LearningRateSchedule</code> class generator.
</p>

<hr>
<h2 id='new_metric_class'>Define new keras types</h2><span id='topic+new_metric_class'></span><span id='topic+new_loss_class'></span><span id='topic+new_callback_class'></span><span id='topic+new_model_class'></span><span id='topic+new_layer_class'></span><span id='topic+mark_active'></span>

<h3>Description</h3>

<p>These functions can be used to make custom objects that fit in the family of
existing keras types. For example, <code>new_layer_class()</code> will return a class
constructor, an object that behaves like other layer functions such as
<code>layer_dense()</code>. <code>new_callback_class()</code> will return an object that behaves
similarly to other callback functions, like
<code>callback_reduce_lr_on_plateau()</code>, and so on. All arguments with a default
<code>NULL</code> value are optional methods that can be provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_metric_class(classname, ..., initialize, update_state, result)

new_loss_class(classname, ..., call = NULL)

new_callback_class(
  classname,
  ...,
  on_epoch_begin = NULL,
  on_epoch_end = NULL,
  on_train_begin = NULL,
  on_train_end = NULL,
  on_batch_begin = NULL,
  on_batch_end = NULL,
  on_predict_batch_begin = NULL,
  on_predict_batch_end = NULL,
  on_predict_begin = NULL,
  on_predict_end = NULL,
  on_test_batch_begin = NULL,
  on_test_batch_end = NULL,
  on_test_begin = NULL,
  on_test_end = NULL,
  on_train_batch_begin = NULL,
  on_train_batch_end = NULL
)

new_model_class(
  classname,
  ...,
  initialize = NULL,
  call = NULL,
  train_step = NULL,
  predict_step = NULL,
  test_step = NULL,
  compute_loss = NULL,
  compute_metrics = NULL
)

new_layer_class(
  classname,
  ...,
  initialize = NULL,
  build = NULL,
  call = NULL,
  get_config = NULL
)

mark_active(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="new_metric_class_+3A_classname">classname</code></td>
<td>
<p>The classname as a string. Convention is for the classname
to be a CamelCase version of the constructor.</p>
</td></tr>
<tr><td><code id="new_metric_class_+3A_...">...</code></td>
<td>
<p>Additional fields and methods for the new type.</p>
</td></tr>
<tr><td><code id="new_metric_class_+3A_initialize">initialize</code>, <code id="new_metric_class_+3A_build">build</code>, <code id="new_metric_class_+3A_call">call</code>, <code id="new_metric_class_+3A_get_config">get_config</code>, <code id="new_metric_class_+3A_on_epoch_begin">on_epoch_begin</code>, <code id="new_metric_class_+3A_on_epoch_end">on_epoch_end</code>, <code id="new_metric_class_+3A_on_train_begin">on_train_begin</code>, <code id="new_metric_class_+3A_on_train_end">on_train_end</code>, <code id="new_metric_class_+3A_on_batch_begin">on_batch_begin</code>, <code id="new_metric_class_+3A_on_batch_end">on_batch_end</code>, <code id="new_metric_class_+3A_on_predict_batch_begin">on_predict_batch_begin</code>, <code id="new_metric_class_+3A_on_predict_batch_end">on_predict_batch_end</code>, <code id="new_metric_class_+3A_on_predict_begin">on_predict_begin</code>, <code id="new_metric_class_+3A_on_predict_end">on_predict_end</code>, <code id="new_metric_class_+3A_on_test_batch_begin">on_test_batch_begin</code>, <code id="new_metric_class_+3A_on_test_batch_end">on_test_batch_end</code>, <code id="new_metric_class_+3A_on_test_begin">on_test_begin</code>, <code id="new_metric_class_+3A_on_test_end">on_test_end</code>, <code id="new_metric_class_+3A_on_train_batch_begin">on_train_batch_begin</code>, <code id="new_metric_class_+3A_on_train_batch_end">on_train_batch_end</code>, <code id="new_metric_class_+3A_update_state">update_state</code>, <code id="new_metric_class_+3A_result">result</code>, <code id="new_metric_class_+3A_train_step">train_step</code>, <code id="new_metric_class_+3A_predict_step">predict_step</code>, <code id="new_metric_class_+3A_test_step">test_step</code>, <code id="new_metric_class_+3A_compute_loss">compute_loss</code>, <code id="new_metric_class_+3A_compute_metrics">compute_metrics</code></td>
<td>
<p>Optional methods that can be overridden.</p>
</td></tr>
<tr><td><code id="new_metric_class_+3A_x">x</code></td>
<td>
<p>A function that should be converted to an active property of the class type.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mark_active()</code> is a decorator that can be used to indicate functions that
should become active properties of the class instances.
</p>


<h3>Value</h3>

<p>A new class generator object that inherits from the appropriate Keras
base class.
</p>

<hr>
<h2 id='normalize'>Normalize a matrix or nd-array</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Normalize a matrix or nd-array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x, axis = -1, order = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>Matrix or array to normalize</p>
</td></tr>
<tr><td><code id="normalize_+3A_axis">axis</code></td>
<td>
<p>Axis along which to normalize. Axis indexes are 1-based
(pass -1 to select the last axis).</p>
</td></tr>
<tr><td><code id="normalize_+3A_order">order</code></td>
<td>
<p>Normalization order (e.g. 2 for L2 norm)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A normalized copy of the array.
</p>

<hr>
<h2 id='optimizer_adadelta'>Optimizer that implements the Adadelta algorithm</h2><span id='topic+optimizer_adadelta'></span>

<h3>Description</h3>

<p>Optimizer that implements the Adadelta algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_adadelta(
  learning_rate = 0.001,
  rho = 0.95,
  epsilon = 1e-07,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "Adadelta",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_adadelta_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial value for the learning rate:
either a floating point value,
or a <code>tf.keras.optimizers.schedules.LearningRateSchedule</code> instance.
Defaults to 0.001.
Note that <code>Adadelta</code> tends to benefit from higher initial learning rate
values compared to other optimizers.
To match the exact form in the original paper, use 1.0.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_rho">rho</code></td>
<td>
<p>A <code>Tensor</code> or a floating point value. The decay rate. Defaults to
0.95.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_epsilon">epsilon</code></td>
<td>
<p>Small floating point value used to maintain numerical stability.
Defaults to 1e-7.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_adadelta_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adadelta optimization is a stochastic gradient descent method that is based
on adaptive learning rate per dimension to address two drawbacks:
</p>

<ul>
<li><p> The continual decay of learning rates throughout training.
</p>
</li>
<li><p> The need for a manually selected global learning rate.
</p>
</li></ul>

<p>Adadelta is a more robust extension of Adagrad that adapts learning rates
based on a moving window of gradient updates, instead of accumulating all
past gradients. This way, Adadelta continues learning even when many updates
have been done. Compared to Adagrad, in the original version of Adadelta you
don't have to set an initial learning rate. In this version, the initial
learning rate can be set, as in most other Keras optimizers.
</p>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_adagrad'>Optimizer that implements the Adagrad algorithm</h2><span id='topic+optimizer_adagrad'></span>

<h3>Description</h3>

<p>Optimizer that implements the Adagrad algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_adagrad(
  learning_rate = 0.001,
  initial_accumulator_value = 0.1,
  epsilon = 1e-07,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "Adagrad",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_adagrad_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial value for the learning rate:
either a floating point value,
or a <code>tf.keras.optimizers.schedules.LearningRateSchedule</code> instance.
Defaults to 0.001.
Note that <code>Adagrad</code> tends to benefit from higher initial learning rate
values compared to other optimizers.
To match the exact form in the original paper, use 1.0.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_initial_accumulator_value">initial_accumulator_value</code></td>
<td>
<p>Floating point value.
Starting value for the accumulators (per-parameter momentum values).
Must be non-negative.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_epsilon">epsilon</code></td>
<td>
<p>Small floating point value used to maintain numerical stability.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_adagrad_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adagrad is an optimizer with parameter-specific learning rates,
which are adapted relative to how frequently a parameter gets
updated during training. The more updates a parameter receives,
the smaller the updates.
</p>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_adam'>Optimizer that implements the Adam algorithm</h2><span id='topic+optimizer_adam'></span>

<h3>Description</h3>

<p>Optimizer that implements the Adam algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_adam(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  amsgrad = FALSE,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "Adam",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_adam_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A <code>tf.Tensor</code>, floating point value, a schedule that is a
<code>tf.keras.optimizers.schedules.LearningRateSchedule</code>, or a callable
that takes no arguments and returns the actual value to use. The
learning rate. Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor, or a callable
that takes no arguments and returns the actual value to use. The
exponential decay rate for the 1st moment estimates. Defaults to 0.9.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor, or a callable
that takes no arguments and returns the actual value to use. The
exponential decay rate for the 2nd moment estimates. Defaults to 0.999.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability. This epsilon is
&quot;epsilon hat&quot; in the Kingma and Ba paper (in the formula just before
Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to
1e-7.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_amsgrad">amsgrad</code></td>
<td>
<p>Boolean. Whether to apply AMSGrad variant of this algorithm from
the paper &quot;On the Convergence of Adam and beyond&quot;. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_adam_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adam optimization is a stochastic gradient descent method that is based on
adaptive estimation of first-order and second-order moments.
</p>
<p>According to
<a href="https://arxiv.org/abs/1412.6980">Kingma et al., 2014</a>,
the method is &quot;<em>computationally
efficient, has little memory requirement, invariant to diagonal rescaling of
gradients, and is well suited for problems that are large in terms of
data/parameters</em>&quot;.
</p>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_adamax'>Optimizer that implements the Adamax algorithm</h2><span id='topic+optimizer_adamax'></span>

<h3>Description</h3>

<p>Optimizer that implements the Adamax algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_adamax(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "Adamax",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_adamax_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A <code>tf.Tensor</code>, floating point value, a schedule that is a
<code>tf.keras.optimizers.schedules.LearningRateSchedule</code>, or a callable
that takes no arguments and returns the actual value to use. The
learning rate. Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay
rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay
rate for the exponentially weighted infinity norm.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_adamax_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adamax, a variant of Adam based on the infinity norm, is a first-order
gradient-based optimization method. Due to its capability of adjusting the
learning rate based on data characteristics, it is suited to learn
time-variant process, e.g., speech data with dynamically changed noise
conditions. Default parameters follow those provided in the paper (see
references below).
</p>
<p>Initialization:
</p>
<div class="sourceCode python"><pre>m = 0  # Initialize initial 1st moment vector
u = 0  # Initialize the exponentially weighted infinity norm
t = 0  # Initialize timestep
</pre></div>
<p>The update rule for parameter <code>w</code> with gradient <code>g</code> is described at the end
of section 7.1 of the paper (see the referenece section):
</p>
<div class="sourceCode python"><pre>t += 1
m = beta1 * m + (1 - beta) * g
u = max(beta2 * u, abs(g))
current_lr = learning_rate / (1 - beta1 ** t)
w = w - current_lr * m / (u + epsilon)
</pre></div>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adamax">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adamax</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_ftrl'>Optimizer that implements the FTRL algorithm</h2><span id='topic+optimizer_ftrl'></span>

<h3>Description</h3>

<p>Optimizer that implements the FTRL algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_ftrl(
  learning_rate = 0.001,
  learning_rate_power = -0.5,
  initial_accumulator_value = 0.1,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0,
  l2_shrinkage_regularization_strength = 0,
  beta = 0,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "Ftrl",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_ftrl_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A <code>Tensor</code>, floating point value, a schedule that is a
<code>tf.keras.optimizers.schedules.LearningRateSchedule</code>, or a callable that
takes no arguments and returns the actual value to use. The learning
rate.  Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_learning_rate_power">learning_rate_power</code></td>
<td>
<p>A float value, must be less or equal to zero.
Controls how the learning rate decreases during training. Use zero for a
fixed learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_initial_accumulator_value">initial_accumulator_value</code></td>
<td>
<p>The starting value for accumulators. Only zero
or positive values are allowed.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_l1_regularization_strength">l1_regularization_strength</code></td>
<td>
<p>A float value, must be greater than or equal
to zero. Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_l2_regularization_strength">l2_regularization_strength</code></td>
<td>
<p>A float value, must be greater than or equal
to zero. Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_l2_shrinkage_regularization_strength">l2_shrinkage_regularization_strength</code></td>
<td>
<p>A float value, must be greater than
or equal to zero. This differs from L2 above in that the L2 above is a
stabilization penalty, whereas this L2 shrinkage is a magnitude penalty.
When input is sparse shrinkage will only happen on the active weights.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_beta">beta</code></td>
<td>
<p>A float value, representing the beta value from the paper. Defaults
to 0.0.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_ftrl_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Follow The Regularized Leader&quot; (FTRL) is an optimization algorithm
developed at Google for click-through rate prediction in the early 2010s. It
is most suitable for shallow models with large and sparse feature spaces.
The algorithm is described by
<a href="https://research.google.com/pubs/archive/41159.pdf">McMahan et al., 2013</a>.
The Keras version has support for both online L2 regularization
(the L2 regularization described in the paper
above) and shrinkage-type L2 regularization
(which is the addition of an L2 penalty to the loss function).
</p>
<p>Initialization:
</p>
<div class="sourceCode python"><pre>n = 0
sigma = 0
z = 0
</pre></div>
<p>Update rule for one variable <code>w</code>:
</p>
<div class="sourceCode python"><pre>prev_n = n
n = n + g ** 2
sigma = (n ** -lr_power - prev_n ** -lr_power) / lr
z = z + g - sigma * w
if abs(z) &lt; lambda_1:
  w = 0
else:
  w = (sgn(z) * lambda_1 - z) / ((beta + sqrt(n)) / alpha + lambda_2)
</pre></div>
<p>Notation:
</p>

<ul>
<li> <p><code>lr</code> is the learning rate
</p>
</li>
<li> <p><code>g</code> is the gradient for the variable
</p>
</li>
<li> <p><code>lambda_1</code> is the L1 regularization strength
</p>
</li>
<li> <p><code>lambda_2</code> is the L2 regularization strength
</p>
</li>
<li> <p><code>lr_power</code> is the power to scale n.
</p>
</li></ul>

<p>Check the documentation for the <code>l2_shrinkage_regularization_strength</code>
parameter for more details when shrinkage is enabled, in which case gradient
is replaced with a gradient with shrinkage.
</p>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_nadam'>Optimizer that implements the Nadam algorithm</h2><span id='topic+optimizer_nadam'></span>

<h3>Description</h3>

<p>Optimizer that implements the Nadam algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_nadam(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "Nadam",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_nadam_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A <code>tf.Tensor</code>, floating point value, a schedule that is a
<code>tf.keras.optimizers.schedules.LearningRateSchedule</code>, or a callable
that takes no arguments and returns the actual value to use. The
learning rate. Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor, or a callable
that takes no arguments and returns the actual value to use. The
exponential decay rate for the 1st moment estimates. Defaults to 0.9.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor, or a callable
that takes no arguments and returns the actual value to use. The
exponential decay rate for the 2nd moment estimates. Defaults to 0.999.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability. This epsilon is
&quot;epsilon hat&quot; in the Kingma and Ba paper (in the formula just before
Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to
1e-7.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_nadam_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Much like Adam is essentially RMSprop with momentum, Nadam is Adam with
Nesterov momentum.
</p>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_rmsprop'>Optimizer that implements the RMSprop algorithm</h2><span id='topic+optimizer_rmsprop'></span>

<h3>Description</h3>

<p>Optimizer that implements the RMSprop algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_rmsprop(
  learning_rate = 0.001,
  rho = 0.9,
  momentum = 0,
  epsilon = 1e-07,
  centered = FALSE,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = 100L,
  jit_compile = TRUE,
  name = "RMSprop",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_rmsprop_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Initial value for the learning rate:
either a floating point value,
or a <code>tf.keras.optimizers.schedules.LearningRateSchedule</code> instance.
Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_rho">rho</code></td>
<td>
<p>float, defaults to 0.9. Discounting factor for the old gradients.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_momentum">momentum</code></td>
<td>
<p>float, defaults to 0.0. If not 0.0., the optimizer tracks the
momentum value, with a decay rate equals to <code>1 - momentum</code>.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability. This epsilon is
&quot;epsilon hat&quot; in the Kingma and Ba paper (in the formula just before
Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to
1e-7.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_centered">centered</code></td>
<td>
<p>Boolean. If <code>TRUE</code>, gradients are normalized by the estimated
variance of the gradient; if FALSE, by the uncentered second moment.
Setting this to <code>TRUE</code> may help with training, but is slightly more
expensive in terms of computation and memory. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_rmsprop_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The gist of RMSprop is to:
</p>

<ul>
<li><p> Maintain a moving (discounted) average of the square of gradients
</p>
</li>
<li><p> Divide the gradient by the root of this average
</p>
</li></ul>

<p>This implementation of RMSprop uses plain momentum, not Nesterov momentum.
</p>
<p>The centered version additionally maintains a moving average of the
gradients, and uses that average to estimate the variance.
</p>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_sgd">optimizer_sgd</a>()</code>
</p>

<hr>
<h2 id='optimizer_sgd'>Gradient descent (with momentum) optimizer</h2><span id='topic+optimizer_sgd'></span>

<h3>Description</h3>

<p>Gradient descent (with momentum) optimizer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_sgd(
  learning_rate = 0.01,
  momentum = 0,
  nesterov = FALSE,
  amsgrad = FALSE,
  weight_decay = NULL,
  clipnorm = NULL,
  clipvalue = NULL,
  global_clipnorm = NULL,
  use_ema = FALSE,
  ema_momentum = 0.99,
  ema_overwrite_frequency = NULL,
  jit_compile = TRUE,
  name = "SGD",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_sgd_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A <code>Tensor</code>, floating point value, or a schedule that is a
<code>tf.keras.optimizers.schedules.LearningRateSchedule</code>, or a callable
that takes no arguments and returns the actual value to use. The
learning rate. Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_momentum">momentum</code></td>
<td>
<p>float hyperparameter &gt;= 0 that accelerates gradient descent in
the relevant direction and dampens oscillations. Defaults to 0, i.e.,
vanilla gradient descent.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_nesterov">nesterov</code></td>
<td>
<p>boolean. Whether to apply Nesterov momentum.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_amsgrad">amsgrad</code></td>
<td>
<p>ignored.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_weight_decay">weight_decay</code></td>
<td>
<p>Float, defaults to NULL. If set, weight decay is applied.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_clipnorm">clipnorm</code></td>
<td>
<p>Float. If set, the gradient of each weight is individually
clipped so that its norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_clipvalue">clipvalue</code></td>
<td>
<p>Float. If set, the gradient of each weight is clipped to be no
higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_global_clipnorm">global_clipnorm</code></td>
<td>
<p>Float. If set, the gradient of all weights is clipped so
that their global norm is no higher than this value.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_use_ema">use_ema</code></td>
<td>
<p>Boolean, defaults to FALSE. If TRUE, exponential moving average
(EMA) is applied. EMA consists of computing an exponential moving
average of the weights of the model (as the weight values change after
each training batch), and periodically overwriting the weights with
their moving average.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_ema_momentum">ema_momentum</code></td>
<td>
<p>Float, defaults to 0.99. Only used if <code>use_ema=TRUE</code>. This is  # noqa: E501
the momentum to use when computing the EMA of the model's weights:
<code>new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value</code>.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_ema_overwrite_frequency">ema_overwrite_frequency</code></td>
<td>
<p>Int or NULL, defaults to NULL. Only used if
<code>use_ema=TRUE</code>. Every <code>ema_overwrite_frequency</code> steps of iterations, we
overwrite the model variable by its moving average. If NULL, the optimizer  # noqa: E501
does not overwrite model variables in the middle of training, and you
need to explicitly overwrite the variables at the end of training
by calling <code>optimizer.finalize_variable_values()</code> (which updates the model  # noqa: E501
variables in-place). When using the built-in <code>fit()</code> training loop, this
happens automatically after the last epoch, and you don't need to do
anything.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_jit_compile">jit_compile</code></td>
<td>
<p>Boolean, defaults to TRUE. If TRUE, the optimizer will use XLA  # noqa: E501
compilation. If no GPU device is found, this flag will be ignored.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_name">name</code></td>
<td>
<p>String. The name to use
for momentum accumulator weights created by
the optimizer.</p>
</td></tr>
<tr><td><code id="optimizer_sgd_+3A_...">...</code></td>
<td>
<p>Used for backward and forward compatibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Update rule for parameter <code>w</code> with gradient <code>g</code> when <code>momentum</code> is 0:
</p>
<div class="sourceCode python"><pre>w = w - learning_rate * g
</pre></div>
<p>Update rule when <code>momentum</code> is larger than 0:
</p>
<div class="sourceCode python"><pre>velocity = momentum * velocity - learning_rate * g
w = w + velocity
</pre></div>
<p>When <code>nesterov=TRUE</code>, this rule becomes:
</p>
<div class="sourceCode python"><pre>velocity = momentum * velocity - learning_rate * g
w = w + momentum * velocity - learning_rate * g
</pre></div>


<h3>Value</h3>

<p>Optimizer for use with <code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a></code>.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD</a>
</p>
</li></ul>

<p>Other optimizers: 
<code><a href="#topic+optimizer_adadelta">optimizer_adadelta</a>()</code>,
<code><a href="#topic+optimizer_adagrad">optimizer_adagrad</a>()</code>,
<code><a href="#topic+optimizer_adam">optimizer_adam</a>()</code>,
<code><a href="#topic+optimizer_adamax">optimizer_adamax</a>()</code>,
<code><a href="#topic+optimizer_ftrl">optimizer_ftrl</a>()</code>,
<code><a href="#topic+optimizer_nadam">optimizer_nadam</a>()</code>,
<code><a href="#topic+optimizer_rmsprop">optimizer_rmsprop</a>()</code>
</p>

<hr>
<h2 id='pad_sequences'>Pads sequences to the same length</h2><span id='topic+pad_sequences'></span>

<h3>Description</h3>

<p>Pads sequences to the same length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pad_sequences(
  sequences,
  maxlen = NULL,
  dtype = "int32",
  padding = "pre",
  truncating = "pre",
  value = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pad_sequences_+3A_sequences">sequences</code></td>
<td>
<p>List of lists where each element is a sequence</p>
</td></tr>
<tr><td><code id="pad_sequences_+3A_maxlen">maxlen</code></td>
<td>
<p>int, maximum length of all sequences</p>
</td></tr>
<tr><td><code id="pad_sequences_+3A_dtype">dtype</code></td>
<td>
<p>type of the output sequences</p>
</td></tr>
<tr><td><code id="pad_sequences_+3A_padding">padding</code></td>
<td>
<p>'pre' or 'post', pad either before or after each sequence.</p>
</td></tr>
<tr><td><code id="pad_sequences_+3A_truncating">truncating</code></td>
<td>
<p>'pre' or 'post', remove values from sequences larger than
maxlen either in the beginning or in the end of the sequence</p>
</td></tr>
<tr><td><code id="pad_sequences_+3A_value">value</code></td>
<td>
<p>float, padding value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function transforms a list of <code>num_samples</code> sequences (lists
of integers) into a matrix of shape <code style="white-space: pre;">&#8288;(num_samples, num_timesteps)&#8288;</code>.
<code>num_timesteps</code> is either the <code>maxlen</code> argument if provided, or the length
of the longest sequence otherwise.
</p>
<p>Sequences that are shorter than <code>num_timesteps</code> are padded with <code>value</code> at
the end.
</p>
<p>Sequences longer than <code>num_timesteps</code> are truncated so that they fit the
desired length. The position where padding or truncation happens is
determined by the arguments <code>padding</code> and <code>truncating</code>, respectively.
</p>
<p>Pre-padding is the default.
</p>


<h3>Value</h3>

<p>Matrix with dimensions (number_of_sequences, maxlen)
</p>


<h3>See Also</h3>

<p>Other text preprocessing: 
<code><a href="#topic+make_sampling_table">make_sampling_table</a>()</code>,
<code><a href="#topic+skipgrams">skipgrams</a>()</code>,
<code><a href="#topic+text_hashing_trick">text_hashing_trick</a>()</code>,
<code><a href="#topic+text_one_hot">text_one_hot</a>()</code>,
<code><a href="#topic+text_to_word_sequence">text_to_word_sequence</a>()</code>
</p>

<hr>
<h2 id='plot.keras_training_history'>Plot training history</h2><span id='topic+plot.keras_training_history'></span>

<h3>Description</h3>

<p>Plots metrics recorded during training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras_training_history'
plot(
  x,
  y,
  metrics = NULL,
  method = c("auto", "ggplot2", "base"),
  smooth = getOption("keras.plot.history.smooth", TRUE),
  theme_bw = getOption("keras.plot.history.theme_bw", FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.keras_training_history_+3A_x">x</code></td>
<td>
<p>Training history object returned from
<code>fit.keras.engine.training.Model()</code>.</p>
</td></tr>
<tr><td><code id="plot.keras_training_history_+3A_y">y</code></td>
<td>
<p>Unused.</p>
</td></tr>
<tr><td><code id="plot.keras_training_history_+3A_metrics">metrics</code></td>
<td>
<p>One or more metrics to plot (e.g. <code>c('loss', 'accuracy')</code>).
Defaults to plotting all captured metrics.</p>
</td></tr>
<tr><td><code id="plot.keras_training_history_+3A_method">method</code></td>
<td>
<p>Method to use for plotting. The default &quot;auto&quot; will use
<span class="pkg">ggplot2</span> if available, and otherwise will use base graphics.</p>
</td></tr>
<tr><td><code id="plot.keras_training_history_+3A_smooth">smooth</code></td>
<td>
<p>Whether a loess smooth should be added to the plot, only
available for the <code>ggplot2</code> method. If the number of epochs is smaller
than ten, it is forced to false.</p>
</td></tr>
<tr><td><code id="plot.keras_training_history_+3A_theme_bw">theme_bw</code></td>
<td>
<p>Use <code>ggplot2::theme_bw()</code> to plot the history in
black and white.</p>
</td></tr>
<tr><td><code id="plot.keras_training_history_+3A_...">...</code></td>
<td>
<p>Additional parameters to pass to the <code><a href="base.html#topic+plot">plot()</a></code> method.</p>
</td></tr>
</table>

<hr>
<h2 id='plot.keras.engine.training.Model'>Plot a Keras model</h2><span id='topic+plot.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Plot a Keras model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
plot(
  x,
  show_shapes = FALSE,
  show_dtype = FALSE,
  show_layer_names = TRUE,
  ...,
  rankdir = "TB",
  expand_nested = FALSE,
  dpi = 96,
  layer_range = NULL,
  show_layer_activations = FALSE,
  to_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.keras.engine.training.Model_+3A_x">x</code></td>
<td>
<p>A Keras model instance</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_show_shapes">show_shapes</code></td>
<td>
<p>whether to display shape information.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_show_dtype">show_dtype</code></td>
<td>
<p>whether to display layer dtypes.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_show_layer_names">show_layer_names</code></td>
<td>
<p>whether to display layer names.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>passed on to <code>keras$utils$plot_model()</code>. Used for forward and
backward compatibility.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_rankdir">rankdir</code></td>
<td>
<p>a string specifying the format of the plot: <code>'TB'</code> creates a
vertical plot; <code>'LR'</code> creates a horizontal plot. (argument passed to PyDot)</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_expand_nested">expand_nested</code></td>
<td>
<p>Whether to expand nested models into clusters.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_dpi">dpi</code></td>
<td>
<p>Dots per inch. Increase this value if the image text appears
excessively pixelated.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_layer_range">layer_range</code></td>
<td>
<p><code>list</code> containing two character strings, which is the
starting layer name and ending layer name (both inclusive) indicating the
range of layers for which the plot will be generated. It also accepts regex
patterns instead of exact name. In such case, start predicate will be the
first element it matches to <code>layer_range[1]</code> and the end predicate will be
the last element it matches to <code>layer_range[2]</code>. By default <code>NULL</code> which
considers all layers of model. Note that you must pass range such that the
resultant subgraph must be complete.</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_show_layer_activations">show_layer_activations</code></td>
<td>
<p>Display layer activations (only for layers that
have an <code>activation</code> property).</p>
</td></tr>
<tr><td><code id="plot.keras.engine.training.Model_+3A_to_file">to_file</code></td>
<td>
<p>File name of the plot image. If <code>NULL</code> (the default), the
model is drawn on the default graphics device. Otherwise, a file is saved.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for it's side effects.
</p>


<h3>Raises</h3>

<p>ValueError: if <code>plot_model</code> is called before the model is
built, unless a <code style="white-space: pre;">&#8288;input_shape = &#8288;</code> argument was supplied to
<code>keras_model_sequential()</code>.
</p>


<h3>Requirements</h3>

<p>This function requires pydot and graphviz.
<code>pydot</code> is by default installed by <code>install_keras()</code>, but if you installed
tensorflow by other means, you can install pydot directly with :
</p>
<div class="sourceCode"><pre>reticulate::py_install("pydot", pip = TRUE)
</pre></div>
<p>In a conda environment, you can install graphviz with:
</p>
<div class="sourceCode"><pre>reticulate::conda_install(packages = "graphviz")
# Restart the R session after install.
</pre></div>
<p>Otherwise you can install graphviz from here:
<a href="https://graphviz.gitlab.io/download/">https://graphviz.gitlab.io/download/</a>
</p>

<hr>
<h2 id='pop_layer'>Remove the last layer in a model</h2><span id='topic+pop_layer'></span>

<h3>Description</h3>

<p>Remove the last layer in a model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pop_layer(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pop_layer_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='predict_generator'>(Deprecated) Generates predictions for the input samples from a data generator.</h2><span id='topic+predict_generator'></span>

<h3>Description</h3>

<p>The generator should return the same kind of data as accepted by
<code>predict_on_batch()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_generator(
  object,
  generator,
  steps,
  max_queue_size = 10,
  workers = 1,
  verbose = 0,
  callbacks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_generator_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
<tr><td><code id="predict_generator_+3A_generator">generator</code></td>
<td>
<p>Generator yielding batches of input samples.</p>
</td></tr>
<tr><td><code id="predict_generator_+3A_steps">steps</code></td>
<td>
<p>Total number of steps (batches of samples) to yield from
<code>generator</code> before stopping.</p>
</td></tr>
<tr><td><code id="predict_generator_+3A_max_queue_size">max_queue_size</code></td>
<td>
<p>Maximum size for the generator queue. If unspecified,
<code>max_queue_size</code> will default to 10.</p>
</td></tr>
<tr><td><code id="predict_generator_+3A_workers">workers</code></td>
<td>
<p>Maximum number of threads to use for parallel processing. Note that
parallel processing will only be performed for native Keras generators (e.g.
<code>flow_images_from_directory()</code>) as R based generators must run on the main thread.</p>
</td></tr>
<tr><td><code id="predict_generator_+3A_verbose">verbose</code></td>
<td>
<p>verbosity mode, 0 or 1.</p>
</td></tr>
<tr><td><code id="predict_generator_+3A_callbacks">callbacks</code></td>
<td>
<p>List of callbacks to apply during prediction.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numpy array(s) of predictions.
</p>


<h3>Raises</h3>

<p>ValueError: In case the generator yields data in an invalid
format.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='predict_on_batch'>Returns predictions for a single batch of samples.</h2><span id='topic+predict_on_batch'></span>

<h3>Description</h3>

<p>Returns predictions for a single batch of samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_on_batch(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_on_batch_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
<tr><td><code id="predict_on_batch_+3A_x">x</code></td>
<td>
<p>Input data (vector, matrix, or array). You can also
pass a <code>tfdataset</code> or a generator returning a list with <code style="white-space: pre;">&#8288;(inputs, targets)&#8288;</code> or
<code style="white-space: pre;">&#8288;(inputs, targets, sample_weights)&#8288;</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>array of predictions.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='predict_proba'>(Deprecated) Generates probability or class probability predictions for the input samples.</h2><span id='topic+predict_proba'></span><span id='topic+predict_classes'></span>

<h3>Description</h3>

<p>These functions were removed in Tensorflow version 2.6. See details for how to update your code:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_proba(object, x, batch_size = NULL, verbose = 0, steps = NULL)

predict_classes(object, x, batch_size = NULL, verbose = 0, steps = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_proba_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
<tr><td><code id="predict_proba_+3A_x">x</code></td>
<td>
<p>Input data (vector, matrix, or array). You can also
pass a <code>tfdataset</code> or a generator returning a list with <code style="white-space: pre;">&#8288;(inputs, targets)&#8288;</code> or
<code style="white-space: pre;">&#8288;(inputs, targets, sample_weights)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="predict_proba_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer. If unspecified, it will default to 32.</p>
</td></tr>
<tr><td><code id="predict_proba_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode, 0, 1, 2, or &quot;auto&quot;. &quot;auto&quot; defaults to 1
for for most cases and defaults to <code>verbose=2</code> when used with
ParameterServerStrategy or with interactive logging disabled.</p>
</td></tr>
<tr><td><code id="predict_proba_+3A_steps">steps</code></td>
<td>
<p>Total number of steps (batches of samples) before declaring the
evaluation round finished. The default <code>NULL</code> is equal to the number of
samples in your dataset divided by the batch size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>How to update your code:
</p>
<p><code>predict_proba()</code>: use <code>predict()</code> directly.
</p>
<p><code>predict_classes()</code>:
</p>

<ul>
<li><p> If your model does multi-class classification:
(e.g. if it uses a <code>softmax</code> last-layer activation).
</p>
</li></ul>

<div class="sourceCode r"><pre>     model %&gt;% predict(x) %&gt;% k_argmax()
</pre></div>

<ul>
<li><p> if your model does binary classification
(e.g. if it uses a <code>sigmoid</code> last-layer activation).
</p>
</li></ul>

<div class="sourceCode r"><pre>     model %&gt;% predict(x) %&gt;% `&gt;`(0.5) %&gt;% k_cast("int32")
</pre></div>
<p>The input samples are processed batch by batch.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='predict.keras.engine.training.Model'>Generate predictions from a Keras model</h2><span id='topic+predict.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Generates output predictions for the input samples, processing the samples in
a batched way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
predict(
  object,
  x,
  batch_size = NULL,
  verbose = "auto",
  steps = NULL,
  callbacks = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.keras.engine.training.Model_+3A_object">object</code></td>
<td>
<p>Keras model</p>
</td></tr>
<tr><td><code id="predict.keras.engine.training.Model_+3A_x">x</code></td>
<td>
<p>Input data (vector, matrix, or array). You can also
pass a <code>tfdataset</code> or a generator returning a list with <code style="white-space: pre;">&#8288;(inputs, targets)&#8288;</code> or
<code style="white-space: pre;">&#8288;(inputs, targets, sample_weights)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="predict.keras.engine.training.Model_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer. If unspecified, it will default to 32.</p>
</td></tr>
<tr><td><code id="predict.keras.engine.training.Model_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode, 0, 1, 2, or &quot;auto&quot;. &quot;auto&quot; defaults to 1
for for most cases and defaults to <code>verbose=2</code> when used with
ParameterServerStrategy or with interactive logging disabled.</p>
</td></tr>
<tr><td><code id="predict.keras.engine.training.Model_+3A_steps">steps</code></td>
<td>
<p>Total number of steps (batches of samples) before declaring the
evaluation round finished. Ignored with the default value of <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="predict.keras.engine.training.Model_+3A_callbacks">callbacks</code></td>
<td>
<p>List of callbacks to apply during prediction.</p>
</td></tr>
<tr><td><code id="predict.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector, matrix, or array of predictions
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3C+3E+25'></span><span id='topic+use_python'></span><span id='topic+use_virtualenv'></span><span id='topic+use_condaenv'></span><span id='topic+array_reshape'></span><span id='topic+tuple'></span><span id='topic+use_session_with_seed'></span><span id='topic+tensorboard'></span><span id='topic+evaluate'></span><span id='topic+export_savedmodel'></span><span id='topic+shape'></span><span id='topic+as_tensor'></span><span id='topic+flags'></span><span id='topic+flag_numeric'></span><span id='topic+flag_integer'></span><span id='topic+flag_string'></span><span id='topic+flag_boolean'></span><span id='topic+run_dir'></span><span id='topic+fit'></span><span id='topic+compile'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+compile">compile</a></code>, <code><a href="generics.html#topic+fit">fit</a></code></p>
</dd>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+compound">%&lt;&gt;%</a></code></p>
</dd>
<dt>reticulate</dt><dd><p><code><a href="reticulate.html#topic+array_reshape">array_reshape</a></code>, <code><a href="reticulate.html#topic+tuple">tuple</a></code>, <code><a href="reticulate.html#topic+use_python">use_condaenv</a></code>, <code><a href="reticulate.html#topic+use_python">use_python</a></code>, <code><a href="reticulate.html#topic+use_python">use_virtualenv</a></code></p>
</dd>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+as_tensor">as_tensor</a></code>, <code><a href="tensorflow.html#topic+evaluate">evaluate</a></code>, <code><a href="tensorflow.html#topic+export_savedmodel">export_savedmodel</a></code>, <code><a href="tensorflow.html#topic+shape">shape</a></code>, <code><a href="tensorflow.html#topic+tensorboard">tensorboard</a></code>, <code><a href="tensorflow.html#topic+use_session_with_seed">use_session_with_seed</a></code></p>
</dd>
<dt>tfruns</dt><dd><p><code><a href="tfruns.html#topic+flags">flag_boolean</a></code>, <code><a href="tfruns.html#topic+flags">flag_integer</a></code>, <code><a href="tfruns.html#topic+flags">flag_numeric</a></code>, <code><a href="tfruns.html#topic+flags">flag_string</a></code>, <code><a href="tfruns.html#topic+flags">flags</a></code>, <code><a href="tfruns.html#topic+run_dir">run_dir</a></code></p>
</dd>
</dl>

<hr>
<h2 id='regularizer_l1'>L1 and L2 regularization</h2><span id='topic+regularizer_l1'></span><span id='topic+regularizer_l2'></span><span id='topic+regularizer_l1_l2'></span>

<h3>Description</h3>

<p>L1 and L2 regularization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regularizer_l1(l = 0.01)

regularizer_l2(l = 0.01)

regularizer_l1_l2(l1 = 0.01, l2 = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regularizer_l1_+3A_l">l</code></td>
<td>
<p>Regularization factor.</p>
</td></tr>
<tr><td><code id="regularizer_l1_+3A_l1">l1</code></td>
<td>
<p>L1 regularization factor.</p>
</td></tr>
<tr><td><code id="regularizer_l1_+3A_l2">l2</code></td>
<td>
<p>L2 regularization factor.</p>
</td></tr>
</table>

<hr>
<h2 id='regularizer_orthogonal'>A regularizer that encourages input vectors to be orthogonal to each other</h2><span id='topic+regularizer_orthogonal'></span>

<h3>Description</h3>

<p>A regularizer that encourages input vectors to be orthogonal to each other
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regularizer_orthogonal(factor = 0.01, mode = "rows", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regularizer_orthogonal_+3A_factor">factor</code></td>
<td>
<p>Float. The regularization factor. The regularization penalty will
be proportional to <code>factor</code> times the mean of the dot products between
the L2-normalized rows (if <code>mode="rows"</code>, or columns if <code>mode="columns"</code>)
of the inputs, excluding the product of each row/column with itself.
Defaults to 0.01.</p>
</td></tr>
<tr><td><code id="regularizer_orthogonal_+3A_mode">mode</code></td>
<td>
<p>String, one of <code style="white-space: pre;">&#8288;{"rows", "columns"}&#8288;</code>. Defaults to <code>"rows"</code>. In rows
mode, the regularization effect seeks to make the rows of the input
orthogonal to each other. In columns mode, it seeks to make the columns
of the input orthogonal to each other.</p>
</td></tr>
<tr><td><code id="regularizer_orthogonal_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_dense(
  units = 4,
  kernel_regularizer = regularizer_orthogonal(factor = 0.01))
</pre></div></td></tr>
</table>


<h3>Details</h3>

<p>It can be applied to either the rows of a matrix (<code>mode="rows"</code>) or its
columns (<code>mode="columns"</code>). When applied to a <code>Dense</code> kernel of shape
<code style="white-space: pre;">&#8288;(input_dim, units)&#8288;</code>, rows mode will seek to make the feature vectors
(i.e. the basis of the output space) orthogonal to each other.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/OrthogonalRegularizer">https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/OrthogonalRegularizer</a>
</p>
</li></ul>


<hr>
<h2 id='reset_states'>Reset the states for a layer</h2><span id='topic+reset_states'></span>

<h3>Description</h3>

<p>Reset the states for a layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reset_states(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reset_states_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other layer methods: 
<code><a href="#topic+count_params">count_params</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_input_at">get_input_at</a>()</code>,
<code><a href="#topic+get_weights">get_weights</a>()</code>
</p>

<hr>
<h2 id='save_model_hdf5'>Save/Load models using HDF5 files</h2><span id='topic+save_model_hdf5'></span><span id='topic+load_model_hdf5'></span>

<h3>Description</h3>

<p>Save/Load models using HDF5 files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_model_hdf5(object, filepath, overwrite = TRUE, include_optimizer = TRUE)

load_model_hdf5(filepath, custom_objects = NULL, compile = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_model_hdf5_+3A_object">object</code></td>
<td>
<p>Model object to save</p>
</td></tr>
<tr><td><code id="save_model_hdf5_+3A_filepath">filepath</code></td>
<td>
<p>File path</p>
</td></tr>
<tr><td><code id="save_model_hdf5_+3A_overwrite">overwrite</code></td>
<td>
<p>Overwrite existing file if necessary</p>
</td></tr>
<tr><td><code id="save_model_hdf5_+3A_include_optimizer">include_optimizer</code></td>
<td>
<p>If <code>TRUE</code>, save optimizer's state.</p>
</td></tr>
<tr><td><code id="save_model_hdf5_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Mapping class names (or function names) of custom
(non-Keras) objects to class/functions (for example, custom metrics
or custom loss functions). This mapping can be done with the dict()
function of reticulate.</p>
</td></tr>
<tr><td><code id="save_model_hdf5_+3A_compile">compile</code></td>
<td>
<p>Whether to compile the model after loading.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following components of the model are saved:
</p>

<ul>
<li><p> The model architecture, allowing to re-instantiate the model.
</p>
</li>
<li><p> The model weights.
</p>
</li>
<li><p> The state of the optimizer, allowing to resume training exactly where you
left off.
This allows you to save the entirety of the state of a model
in a single file.
</p>
</li></ul>

<p>Saved models can be reinstantiated via <code>load_model_hdf5()</code>. The model returned by
<code>load_model_hdf5()</code> is a compiled model ready to be used (unless the saved model
was never compiled in the first place or <code>compile = FALSE</code> is specified).
</p>
<p>As an alternative to providing the <code>custom_objects</code> argument, you can
execute the definition and persistence of your model using the
<code><a href="#topic+with_custom_object_scope">with_custom_object_scope()</a></code> function.
</p>


<h3>Note</h3>

<p>The <code><a href="#topic+serialize_model">serialize_model()</a></code> function enables saving Keras models to
R objects that can be persisted across R sessions.
</p>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+model_to_json">model_to_json</a>()</code>,
<code><a href="#topic+model_to_yaml">model_to_yaml</a>()</code>,
<code><a href="#topic+save_model_tf">save_model_tf</a>()</code>,
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5</a>()</code>,
<code><a href="#topic+serialize_model">serialize_model</a>()</code>
</p>

<hr>
<h2 id='save_model_tf'>Save/Load models using SavedModel format</h2><span id='topic+save_model_tf'></span><span id='topic+load_model_tf'></span>

<h3>Description</h3>

<p>Save/Load models using SavedModel format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_model_tf(
  object,
  filepath,
  overwrite = TRUE,
  include_optimizer = TRUE,
  signatures = NULL,
  options = NULL
)

load_model_tf(filepath, custom_objects = NULL, compile = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_model_tf_+3A_object">object</code></td>
<td>
<p>Model object to save</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_filepath">filepath</code></td>
<td>
<p>File path</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_overwrite">overwrite</code></td>
<td>
<p>Overwrite existing file if necessary</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_include_optimizer">include_optimizer</code></td>
<td>
<p>If <code>TRUE</code>, save optimizer's state.</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_signatures">signatures</code></td>
<td>
<p>Signatures to save with the SavedModel. Please see the signatures
argument in <code>tf$saved_model$save</code> for details.</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_options">options</code></td>
<td>
<p>Optional <code>tf$saved_model$SaveOptions</code> object that specifies options
for saving to SavedModel</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Mapping class names (or function names) of custom
(non-Keras) objects to class/functions (for example, custom metrics
or custom loss functions). This mapping can be done with the dict()
function of reticulate.</p>
</td></tr>
<tr><td><code id="save_model_tf_+3A_compile">compile</code></td>
<td>
<p>Whether to compile the model after loading.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+model_to_json">model_to_json</a>()</code>,
<code><a href="#topic+model_to_yaml">model_to_yaml</a>()</code>,
<code><a href="#topic+save_model_hdf5">save_model_hdf5</a>()</code>,
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5</a>()</code>,
<code><a href="#topic+serialize_model">serialize_model</a>()</code>
</p>

<hr>
<h2 id='save_model_weights_hdf5'>Save/Load model weights using HDF5 files</h2><span id='topic+save_model_weights_hdf5'></span><span id='topic+load_model_weights_hdf5'></span>

<h3>Description</h3>

<p>Save/Load model weights using HDF5 files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_model_weights_hdf5(object, filepath, overwrite = TRUE)

load_model_weights_hdf5(
  object,
  filepath,
  by_name = FALSE,
  skip_mismatch = FALSE,
  reshape = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_model_weights_hdf5_+3A_object">object</code></td>
<td>
<p>Model object to save/load</p>
</td></tr>
<tr><td><code id="save_model_weights_hdf5_+3A_filepath">filepath</code></td>
<td>
<p>Path to the file</p>
</td></tr>
<tr><td><code id="save_model_weights_hdf5_+3A_overwrite">overwrite</code></td>
<td>
<p>Whether to silently overwrite any existing
file at the target location</p>
</td></tr>
<tr><td><code id="save_model_weights_hdf5_+3A_by_name">by_name</code></td>
<td>
<p>Whether to load weights by name or by topological order.</p>
</td></tr>
<tr><td><code id="save_model_weights_hdf5_+3A_skip_mismatch">skip_mismatch</code></td>
<td>
<p>Logical, whether to skip loading of layers
where there is a mismatch in the number of weights, or a mismatch in the
shape of the weight (only valid when <code>by_name = FALSE</code>).</p>
</td></tr>
<tr><td><code id="save_model_weights_hdf5_+3A_reshape">reshape</code></td>
<td>
<p>Reshape weights to fit the layer when the correct number
of values are present but the shape does not match.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weight file has:
</p>

<ul>
<li> <p><code>layer_names</code> (attribute), a list of strings (ordered names of model layers).
</p>
</li>
<li><p> For every layer, a <code>group</code> named <code>layer.name</code>
</p>
</li>
<li><p> For every such layer group, a group attribute <code>weight_names</code>, a list of strings
(ordered names of weights tensor of the layer).
</p>
</li>
<li><p> For every weight in the layer, a dataset storing the weight value, named after
the weight tensor.
</p>
</li></ul>

<p>For <code>load_model_weights()</code>, if <code>by_name</code> is <code>FALSE</code> (default) weights are
loaded based on the network's topology, meaning the architecture should be
the same as when the weights were saved. Note that layers that don't have
weights are not taken into account in the topological ordering, so adding
or removing layers is fine as long as they don't have weights.
</p>
<p>If <code>by_name</code> is <code>TRUE</code>, weights are loaded into layers only if they share
the same name. This is useful for fine-tuning or transfer-learning models
where some of the layers have changed.
</p>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+model_to_json">model_to_json</a>()</code>,
<code><a href="#topic+model_to_yaml">model_to_yaml</a>()</code>,
<code><a href="#topic+save_model_hdf5">save_model_hdf5</a>()</code>,
<code><a href="#topic+save_model_tf">save_model_tf</a>()</code>,
<code><a href="#topic+serialize_model">serialize_model</a>()</code>
</p>

<hr>
<h2 id='save_model_weights_tf'>Save model weights in the SavedModel format</h2><span id='topic+save_model_weights_tf'></span><span id='topic+load_model_weights_tf'></span>

<h3>Description</h3>

<p>Save model weights in the SavedModel format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_model_weights_tf(object, filepath, overwrite = TRUE)

load_model_weights_tf(
  object,
  filepath,
  by_name = FALSE,
  skip_mismatch = FALSE,
  reshape = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_model_weights_tf_+3A_object">object</code></td>
<td>
<p>Model object to save/load</p>
</td></tr>
<tr><td><code id="save_model_weights_tf_+3A_filepath">filepath</code></td>
<td>
<p>Path to the file</p>
</td></tr>
<tr><td><code id="save_model_weights_tf_+3A_overwrite">overwrite</code></td>
<td>
<p>Whether to silently overwrite any existing
file at the target location</p>
</td></tr>
<tr><td><code id="save_model_weights_tf_+3A_by_name">by_name</code></td>
<td>
<p>Whether to load weights by name or by topological order.</p>
</td></tr>
<tr><td><code id="save_model_weights_tf_+3A_skip_mismatch">skip_mismatch</code></td>
<td>
<p>Logical, whether to skip loading of layers
where there is a mismatch in the number of weights, or a mismatch in the
shape of the weight (only valid when <code>by_name = FALSE</code>).</p>
</td></tr>
<tr><td><code id="save_model_weights_tf_+3A_reshape">reshape</code></td>
<td>
<p>Reshape weights to fit the layer when the correct number
of values are present but the shape does not match.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When saving in TensorFlow format, all objects referenced by the network
are saved in the same format as <code>tf.train.Checkpoint</code>, including any Layer instances
or Optimizer instances assigned to object attributes. For networks constructed from
inputs and outputs using <code>tf.keras.Model(inputs, outputs)</code>, Layer instances used by
the network are tracked/saved automatically. For user-defined classes which inherit
from <code>tf.keras.Model</code>, Layer instances must be assigned to object attributes,
typically in the constructor.
</p>
<p>See the documentation of <code>tf.train.Checkpoint</code> and <code>tf.keras.Model</code> for details.
</p>

<hr>
<h2 id='save_text_tokenizer'>Save a text tokenizer to an external file</h2><span id='topic+save_text_tokenizer'></span><span id='topic+load_text_tokenizer'></span>

<h3>Description</h3>

<p>Enables persistence of text tokenizers alongside saved models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_text_tokenizer(object, filename)

load_text_tokenizer(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_text_tokenizer_+3A_object">object</code></td>
<td>
<p>Text tokenizer fit with <code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer()</a></code></p>
</td></tr>
<tr><td><code id="save_text_tokenizer_+3A_filename">filename</code></td>
<td>
<p>File to save/load</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You should always use the same text tokenizer for training and
prediction. In many cases however prediction will occur in another
session with a version of the model loaded via <code><a href="#topic+load_model_hdf5">load_model_hdf5()</a></code>.
</p>
<p>In this case you need to save the text tokenizer object after training
and then reload it prior to prediction.
</p>


<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer</a>()</code>,
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix</a>()</code>,
<code><a href="#topic+text_tokenizer">text_tokenizer</a>()</code>,
<code><a href="#topic+texts_to_matrix">texts_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_sequences">texts_to_sequences</a>()</code>,
<code><a href="#topic+texts_to_sequences_generator">texts_to_sequences_generator</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# vectorize texts then save for use in prediction
tokenizer &lt;- text_tokenizer(num_words = 10000) %&gt;%
fit_text_tokenizer(tokenizer, texts)
save_text_tokenizer(tokenizer, "tokenizer")

# (train model, etc.)

# ...later in another session
tokenizer &lt;- load_text_tokenizer("tokenizer")

# (use tokenizer to preprocess data for prediction)


## End(Not run)

</code></pre>

<hr>
<h2 id='sequences_to_matrix'>Convert a list of sequences into a matrix.</h2><span id='topic+sequences_to_matrix'></span>

<h3>Description</h3>

<p>Convert a list of sequences into a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequences_to_matrix(
  tokenizer,
  sequences,
  mode = c("binary", "count", "tfidf", "freq")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sequences_to_matrix_+3A_tokenizer">tokenizer</code></td>
<td>
<p>Tokenizer</p>
</td></tr>
<tr><td><code id="sequences_to_matrix_+3A_sequences">sequences</code></td>
<td>
<p>List of sequences (a sequence is a list of integer word indices).</p>
</td></tr>
<tr><td><code id="sequences_to_matrix_+3A_mode">mode</code></td>
<td>
<p>one of &quot;binary&quot;, &quot;count&quot;, &quot;tfidf&quot;, &quot;freq&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix
</p>


<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer</a>()</code>,
<code><a href="#topic+save_text_tokenizer">save_text_tokenizer</a>()</code>,
<code><a href="#topic+text_tokenizer">text_tokenizer</a>()</code>,
<code><a href="#topic+texts_to_matrix">texts_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_sequences">texts_to_sequences</a>()</code>,
<code><a href="#topic+texts_to_sequences_generator">texts_to_sequences_generator</a>()</code>
</p>

<hr>
<h2 id='sequential_model_input_layer'>sequential_model_input_layer</h2><span id='topic+sequential_model_input_layer'></span>

<h3>Description</h3>

<p>sequential_model_input_layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequential_model_input_layer(
  input_shape = NULL,
  batch_size = NULL,
  dtype = NULL,
  input_tensor = NULL,
  sparse = NULL,
  name = NULL,
  ragged = NULL,
  type_spec = NULL,
  ...,
  input_layer_name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sequential_model_input_layer_+3A_input_shape">input_shape</code></td>
<td>
<p>an integer vector of dimensions (not including the batch
axis), or a <code>tf$TensorShape</code> instance (also not including the batch axis).</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_batch_size">batch_size</code></td>
<td>
<p>Optional input batch size (integer or NULL).</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_dtype">dtype</code></td>
<td>
<p>Optional datatype of the input. When not provided, the Keras
default float type will be used.</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_input_tensor">input_tensor</code></td>
<td>
<p>Optional tensor to use as layer input. If set, the layer
will use the <code>tf$TypeSpec</code> of this tensor rather than creating a new
placeholder tensor.</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_sparse">sparse</code></td>
<td>
<p>Boolean, whether the placeholder created is meant to be sparse.
Default to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_ragged">ragged</code></td>
<td>
<p>Boolean, whether the placeholder created is meant to be ragged.
In this case, values of 'NULL' in the 'shape' argument represent ragged
dimensions. For more information about <code>RaggedTensors</code>, see this
<a href="https://www.tensorflow.org/guide/ragged_tensor">guide</a>. Default to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_type_spec">type_spec</code></td>
<td>
<p>A <code>tf$TypeSpec</code> object to create Input from. This
<code>tf$TypeSpec</code> represents the entire batch. When provided, all other args
except name must be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code>keras$layers$InputLayer</code>.</p>
</td></tr>
<tr><td><code id="sequential_model_input_layer_+3A_input_layer_name">input_layer_name</code>, <code id="sequential_model_input_layer_+3A_name">name</code></td>
<td>
<p>Optional name of the input layer (string).</p>
</td></tr>
</table>

<hr>
<h2 id='serialize_model'>Serialize a model to an R object</h2><span id='topic+serialize_model'></span><span id='topic+unserialize_model'></span>

<h3>Description</h3>

<p>Model objects are external references to Keras objects which cannot be saved
and restored across R sessions. The <code>serialize_model()</code> and
<code>unserialize_model()</code> functions provide facilities to convert Keras models to
R objects for persistence within R data files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>serialize_model(model, include_optimizer = TRUE)

unserialize_model(model, custom_objects = NULL, compile = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="serialize_model_+3A_model">model</code></td>
<td>
<p>Keras model or R &quot;raw&quot; object containing serialized Keras model.</p>
</td></tr>
<tr><td><code id="serialize_model_+3A_include_optimizer">include_optimizer</code></td>
<td>
<p>If <code>TRUE</code>, save optimizer's state.</p>
</td></tr>
<tr><td><code id="serialize_model_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Mapping class names (or function names) of custom
(non-Keras) objects to class/functions (for example, custom metrics
or custom loss functions). This mapping can be done with the dict()
function of reticulate.</p>
</td></tr>
<tr><td><code id="serialize_model_+3A_compile">compile</code></td>
<td>
<p>Whether to compile the model after loading.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>serialize_model()</code> returns an R &quot;raw&quot; object containing an hdf5
version of the Keras model. <code>unserialize_model()</code> returns a Keras model.
</p>


<h3>Note</h3>

<p>The <code><a href="#topic+save_model_hdf5">save_model_hdf5()</a></code> function enables saving Keras models to
external hdf5 files.
</p>


<h3>See Also</h3>

<p>Other model persistence: 
<code><a href="#topic+get_weights">get_weights</a>()</code>,
<code><a href="#topic+model_to_json">model_to_json</a>()</code>,
<code><a href="#topic+model_to_yaml">model_to_yaml</a>()</code>,
<code><a href="#topic+save_model_hdf5">save_model_hdf5</a>()</code>,
<code><a href="#topic+save_model_tf">save_model_tf</a>()</code>,
<code><a href="#topic+save_model_weights_hdf5">save_model_weights_hdf5</a>()</code>
</p>

<hr>
<h2 id='skipgrams'>Generates skipgram word pairs.</h2><span id='topic+skipgrams'></span>

<h3>Description</h3>

<p>Generates skipgram word pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skipgrams(
  sequence,
  vocabulary_size,
  window_size = 4,
  negative_samples = 1,
  shuffle = TRUE,
  categorical = FALSE,
  sampling_table = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skipgrams_+3A_sequence">sequence</code></td>
<td>
<p>A word sequence (sentence), encoded as a list of word indices
(integers). If using a <code>sampling_table</code>, word indices are expected to match
the rank of the words in a reference dataset (e.g. 10 would encode the
10-th most frequently occuring token). Note that index 0 is expected to be
a non-word and will be skipped.</p>
</td></tr>
<tr><td><code id="skipgrams_+3A_vocabulary_size">vocabulary_size</code></td>
<td>
<p>Int, maximum possible word index + 1</p>
</td></tr>
<tr><td><code id="skipgrams_+3A_window_size">window_size</code></td>
<td>
<p>Int, size of sampling windows (technically half-window).
The window of a word <code>w_i</code> will be <code style="white-space: pre;">&#8288;[i-window_size, i+window_size+1]&#8288;</code></p>
</td></tr>
<tr><td><code id="skipgrams_+3A_negative_samples">negative_samples</code></td>
<td>
<p>float &gt;= 0. 0 for no negative (i.e. random) samples. 1
for same number as positive samples.</p>
</td></tr>
<tr><td><code id="skipgrams_+3A_shuffle">shuffle</code></td>
<td>
<p>whether to shuffle the word couples before returning them.</p>
</td></tr>
<tr><td><code id="skipgrams_+3A_categorical">categorical</code></td>
<td>
<p>bool. if <code>FALSE</code>, labels will be integers (eg. <code style="white-space: pre;">&#8288;[0, 1, 1 .. ]&#8288;</code>),
if <code>TRUE</code> labels will be categorical eg. <code style="white-space: pre;">&#8288;[[1,0],[0,1],[0,1] .. ]&#8288;</code></p>
</td></tr>
<tr><td><code id="skipgrams_+3A_sampling_table">sampling_table</code></td>
<td>
<p>1D array of size <code>vocabulary_size</code> where the entry i
encodes the probabibily to sample a word of rank i.</p>
</td></tr>
<tr><td><code id="skipgrams_+3A_seed">seed</code></td>
<td>
<p>Random seed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function transforms a list of word indexes (lists of integers)
into lists of words of the form:
</p>

<ul>
<li><p> (word, word in the same window), with label 1 (positive samples).
</p>
</li>
<li><p> (word, random word from the vocabulary), with label 0 (negative samples).
</p>
</li></ul>

<p>Read more about Skipgram in this gnomic paper by Mikolov et al.:
<a href="https://arxiv.org/pdf/1301.3781v3.pdf">Efficient Estimation of Word Representations in Vector Space</a>
</p>


<h3>Value</h3>

<p>List of <code>couples</code>, <code>labels</code> where:
</p>

<ul>
<li> <p><code>couples</code> is a list of 2-element integer vectors: <code style="white-space: pre;">&#8288;[word_index, other_word_index]&#8288;</code>.
</p>
</li>
<li> <p><code>labels</code> is an integer vector of 0 and 1, where 1 indicates that <code>other_word_index</code>
was found in the same window as <code>word_index</code>, and 0 indicates that <code>other_word_index</code>
was random.
</p>
</li>
<li><p> if <code>categorical</code> is set to <code>TRUE</code>, the labels are categorical, ie. 1 becomes <code style="white-space: pre;">&#8288;[0,1]&#8288;</code>,
and 0 becomes <code style="white-space: pre;">&#8288;[1, 0]&#8288;</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other text preprocessing: 
<code><a href="#topic+make_sampling_table">make_sampling_table</a>()</code>,
<code><a href="#topic+pad_sequences">pad_sequences</a>()</code>,
<code><a href="#topic+text_hashing_trick">text_hashing_trick</a>()</code>,
<code><a href="#topic+text_one_hot">text_one_hot</a>()</code>,
<code><a href="#topic+text_to_word_sequence">text_to_word_sequence</a>()</code>
</p>

<hr>
<h2 id='summary.keras.engine.training.Model'>Print a summary of a Keras model</h2><span id='topic+summary.keras.engine.training.Model'></span><span id='topic+format.keras.engine.training.Model'></span><span id='topic+print.keras.engine.training.Model'></span>

<h3>Description</h3>

<p>Print a summary of a Keras model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'keras.engine.training.Model'
summary(object, ...)

## S3 method for class 'keras.engine.training.Model'
format(
  x,
  line_length = width - (11L * show_trainable),
  positions = NULL,
  expand_nested = FALSE,
  show_trainable = x$built &amp;&amp; as.logical(length(x$non_trainable_weights)),
  ...,
  compact = TRUE,
  width = getOption("width")
)

## S3 method for class 'keras.engine.training.Model'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.keras.engine.training.Model_+3A_object">object</code>, <code id="summary.keras.engine.training.Model_+3A_x">x</code></td>
<td>
<p>Keras model instance</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_...">...</code></td>
<td>
<p>for <code>summary()</code> and <code>print()</code>, passed on to <code>format()</code>. For
<code>format()</code>, passed on to <code>model$summary()</code>.</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_line_length">line_length</code></td>
<td>
<p>Total length of printed lines</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_positions">positions</code></td>
<td>
<p>Relative or absolute positions of log elements in each line.
If not provided, defaults to <code>c(0.33, 0.55, 0.67, 1.0)</code>.</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_expand_nested">expand_nested</code></td>
<td>
<p>Whether to expand the nested models. If not provided,
defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_show_trainable">show_trainable</code></td>
<td>
<p>Whether to show if a layer is trainable. If not
provided, defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_compact">compact</code></td>
<td>
<p>Whether to remove white-space only lines from the model
summary. (Default <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="summary.keras.engine.training.Model_+3A_width">width</code></td>
<td>
<p>the column width to use for printing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>format()</code> returns a length 1 character vector. <code>print()</code> returns the
model object invisibly. <code>summary()</code> returns the output of <code>format()</code>
invisibly after printing it.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+train_on_batch">train_on_batch</a>()</code>
</p>

<hr>
<h2 id='text_dataset_from_directory'>Generate a <code>tf.data.Dataset</code> from text files in a directory</h2><span id='topic+text_dataset_from_directory'></span>

<h3>Description</h3>

<p>Generate a <code>tf.data.Dataset</code> from text files in a directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text_dataset_from_directory(
  directory,
  labels = "inferred",
  label_mode = "int",
  class_names = NULL,
  batch_size = 32L,
  max_length = NULL,
  shuffle = TRUE,
  seed = NULL,
  validation_split = NULL,
  subset = NULL,
  follow_links = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text_dataset_from_directory_+3A_directory">directory</code></td>
<td>
<p>Directory where the data is located.
If <code>labels</code> is &quot;inferred&quot;, it should contain
subdirectories, each containing text files for a class.
Otherwise, the directory structure is ignored.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_labels">labels</code></td>
<td>
<p>Either &quot;inferred&quot;
(labels are generated from the directory structure),
NULL (no labels),
or a list of integer labels of the same size as the number of
text files found in the directory. Labels should be sorted according
to the alphanumeric order of the text file paths
(obtained via <code>os.walk(directory)</code> in Python).</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_label_mode">label_mode</code></td>
<td>

<ul>
<li> <p><code>'int'</code>: means that the labels are encoded as integers
(e.g. for <code>sparse_categorical_crossentropy</code> loss).
</p>
</li>
<li> <p><code>'categorical'</code> means that the labels are
encoded as a categorical vector
(e.g. for <code>categorical_crossentropy</code> loss).
</p>
</li>
<li> <p><code>'binary'</code> means that the labels (there can be only 2)
are encoded as <code>float32</code> scalars with values 0 or 1
(e.g. for <code>binary_crossentropy</code>).
</p>
</li>
<li> <p><code>NULL</code> (no labels).
</p>
</li></ul>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_class_names">class_names</code></td>
<td>
<p>Only valid if <code>labels</code> is <code>"inferred"</code>. This is the explicit
list of class names (must match names of subdirectories). Used
to control the order of the classes
(otherwise alphanumerical order is used).</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of the batches of data. Default: <code>32</code>.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_max_length">max_length</code></td>
<td>
<p>Maximum size of a text string. Texts longer than this will
be truncated to <code>max_length</code>.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_shuffle">shuffle</code></td>
<td>
<p>Whether to shuffle the data. Default: <code>TRUE</code>.
If set to <code>FALSE</code>, sorts the data in alphanumeric order.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_seed">seed</code></td>
<td>
<p>Optional random seed for shuffling and transformations.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_validation_split">validation_split</code></td>
<td>
<p>Optional float between 0 and 1,
fraction of data to reserve for validation.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_subset">subset</code></td>
<td>
<p>One of &quot;training&quot; or &quot;validation&quot;.
Only used if <code>validation_split</code> is set.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_follow_links">follow_links</code></td>
<td>
<p>Whether to visits subdirectories pointed to by symlinks.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="text_dataset_from_directory_+3A_...">...</code></td>
<td>
<p>For future compatibility (unused presently).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If your directory structure is:
</p>
<div class="sourceCode"><pre>main_directory/
...class_a/
......a_text_1.txt
......a_text_2.txt
...class_b/
......b_text_1.txt
......b_text_2.txt
</pre></div>
<p>Then calling <code>text_dataset_from_directory(main_directory, labels = 'inferred')</code>
will return a <code>tf.data.Dataset</code> that yields batches of texts from
the subdirectories <code>class_a</code> and <code>class_b</code>, together with labels
0 and 1 (0 corresponding to <code>class_a</code> and 1 corresponding to <code>class_b</code>).
</p>
<p>Only <code>.txt</code> files are supported at this time.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory">https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory</a>
</p>
</li></ul>


<hr>
<h2 id='text_hashing_trick'>Converts a text to a sequence of indexes in a fixed-size hashing space.</h2><span id='topic+text_hashing_trick'></span>

<h3>Description</h3>

<p>Converts a text to a sequence of indexes in a fixed-size hashing space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text_hashing_trick(
  text,
  n,
  hash_function = NULL,
  filters = "!\"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n",
  lower = TRUE,
  split = " "
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text_hashing_trick_+3A_text">text</code></td>
<td>
<p>Input text (string).</p>
</td></tr>
<tr><td><code id="text_hashing_trick_+3A_n">n</code></td>
<td>
<p>Dimension of the hashing space.</p>
</td></tr>
<tr><td><code id="text_hashing_trick_+3A_hash_function">hash_function</code></td>
<td>
<p>if <code>NULL</code> uses the Python <code>hash()</code> function. Otherwise can be <code>'md5'</code> or
any function that takes in input a string and returns an int. Note that
<code>hash</code> is not a stable hashing function, so it is not consistent across
different runs, while <code>'md5'</code> is a stable hashing function.</p>
</td></tr>
<tr><td><code id="text_hashing_trick_+3A_filters">filters</code></td>
<td>
<p>Sequence of characters to filter out such as
punctuation. Default includes basic punctuation, tabs, and newlines.</p>
</td></tr>
<tr><td><code id="text_hashing_trick_+3A_lower">lower</code></td>
<td>
<p>Whether to convert the input to lowercase.</p>
</td></tr>
<tr><td><code id="text_hashing_trick_+3A_split">split</code></td>
<td>
<p>Sentence split marker (string).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two or more words may be assigned to the same index, due to possible
collisions by the hashing function.
</p>


<h3>Value</h3>

<p>A list of integer word indices (unicity non-guaranteed).
</p>


<h3>See Also</h3>

<p>Other text preprocessing: 
<code><a href="#topic+make_sampling_table">make_sampling_table</a>()</code>,
<code><a href="#topic+pad_sequences">pad_sequences</a>()</code>,
<code><a href="#topic+skipgrams">skipgrams</a>()</code>,
<code><a href="#topic+text_one_hot">text_one_hot</a>()</code>,
<code><a href="#topic+text_to_word_sequence">text_to_word_sequence</a>()</code>
</p>

<hr>
<h2 id='text_one_hot'>One-hot encode a text into a list of word indexes in a vocabulary of size n.</h2><span id='topic+text_one_hot'></span>

<h3>Description</h3>

<p>One-hot encode a text into a list of word indexes in a vocabulary of size n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text_one_hot(
  input_text,
  n,
  filters = "!\"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n",
  lower = TRUE,
  split = " ",
  text = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text_one_hot_+3A_input_text">input_text</code></td>
<td>
<p>Input text (string).</p>
</td></tr>
<tr><td><code id="text_one_hot_+3A_n">n</code></td>
<td>
<p>Size of vocabulary (integer)</p>
</td></tr>
<tr><td><code id="text_one_hot_+3A_filters">filters</code></td>
<td>
<p>Sequence of characters to filter out such as
punctuation. Default includes basic punctuation, tabs, and newlines.</p>
</td></tr>
<tr><td><code id="text_one_hot_+3A_lower">lower</code></td>
<td>
<p>Whether to convert the input to lowercase.</p>
</td></tr>
<tr><td><code id="text_one_hot_+3A_split">split</code></td>
<td>
<p>Sentence split marker (string).</p>
</td></tr>
<tr><td><code id="text_one_hot_+3A_text">text</code></td>
<td>
<p>for compatibility purpose. use <code>input_text</code> instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of integers in <code style="white-space: pre;">&#8288;[1, n]&#8288;</code>. Each integer encodes a word (unicity
non-guaranteed).
</p>


<h3>See Also</h3>

<p>Other text preprocessing: 
<code><a href="#topic+make_sampling_table">make_sampling_table</a>()</code>,
<code><a href="#topic+pad_sequences">pad_sequences</a>()</code>,
<code><a href="#topic+skipgrams">skipgrams</a>()</code>,
<code><a href="#topic+text_hashing_trick">text_hashing_trick</a>()</code>,
<code><a href="#topic+text_to_word_sequence">text_to_word_sequence</a>()</code>
</p>

<hr>
<h2 id='text_to_word_sequence'>Convert text to a sequence of words (or tokens).</h2><span id='topic+text_to_word_sequence'></span>

<h3>Description</h3>

<p>Convert text to a sequence of words (or tokens).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text_to_word_sequence(
  text,
  filters = "!\"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n",
  lower = TRUE,
  split = " "
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text_to_word_sequence_+3A_text">text</code></td>
<td>
<p>Input text (string).</p>
</td></tr>
<tr><td><code id="text_to_word_sequence_+3A_filters">filters</code></td>
<td>
<p>Sequence of characters to filter out such as
punctuation. Default includes basic punctuation, tabs, and newlines.</p>
</td></tr>
<tr><td><code id="text_to_word_sequence_+3A_lower">lower</code></td>
<td>
<p>Whether to convert the input to lowercase.</p>
</td></tr>
<tr><td><code id="text_to_word_sequence_+3A_split">split</code></td>
<td>
<p>Sentence split marker (string).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Words (or tokens)
</p>


<h3>See Also</h3>

<p>Other text preprocessing: 
<code><a href="#topic+make_sampling_table">make_sampling_table</a>()</code>,
<code><a href="#topic+pad_sequences">pad_sequences</a>()</code>,
<code><a href="#topic+skipgrams">skipgrams</a>()</code>,
<code><a href="#topic+text_hashing_trick">text_hashing_trick</a>()</code>,
<code><a href="#topic+text_one_hot">text_one_hot</a>()</code>
</p>

<hr>
<h2 id='text_tokenizer'>Text tokenization utility</h2><span id='topic+text_tokenizer'></span>

<h3>Description</h3>

<p>Vectorize a text corpus, by turning each text into either a sequence of
integers (each integer being the index of a token in a dictionary) or into a
vector where the coefficient for each token could be binary, based on word
count, based on tf-idf...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text_tokenizer(
  num_words = NULL,
  filters = "!\"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n",
  lower = TRUE,
  split = " ",
  char_level = FALSE,
  oov_token = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text_tokenizer_+3A_num_words">num_words</code></td>
<td>
<p>the maximum number of words to keep, based on word
frequency. Only the most common <code>num_words</code> words will be kept.</p>
</td></tr>
<tr><td><code id="text_tokenizer_+3A_filters">filters</code></td>
<td>
<p>a string where each element is a character that will be
filtered from the texts. The default is all punctuation, plus tabs and line
breaks, minus the ' character.</p>
</td></tr>
<tr><td><code id="text_tokenizer_+3A_lower">lower</code></td>
<td>
<p>boolean. Whether to convert the texts to lowercase.</p>
</td></tr>
<tr><td><code id="text_tokenizer_+3A_split">split</code></td>
<td>
<p>character or string to use for token splitting.</p>
</td></tr>
<tr><td><code id="text_tokenizer_+3A_char_level">char_level</code></td>
<td>
<p>if <code>TRUE</code>, every character will be treated as a token</p>
</td></tr>
<tr><td><code id="text_tokenizer_+3A_oov_token">oov_token</code></td>
<td>
<p><code>NULL</code> or string If given, it will be added to 'word_index&ldquo;
and used to replace out-of-vocabulary words during text_to_sequence calls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, all punctuation is removed, turning the texts into
space-separated sequences of words (words maybe include the ' character).
These sequences are then split into lists of tokens. They will then be
indexed or vectorized. <code>0</code> is a reserved index that won't be assigned to any
word.
</p>


<h3>Attributes</h3>

<p>The tokenizer object has the following attributes:
</p>

<ul>
<li> <p><code>word_counts</code> &mdash; named list mapping words to the number of times they appeared
on during fit. Only set after <code>fit_text_tokenizer()</code> is called on the tokenizer.
</p>
</li>
<li> <p><code>word_docs</code> &mdash; named list mapping words to the number of documents/texts they
appeared on during fit. Only set after <code>fit_text_tokenizer()</code> is called on the tokenizer.
</p>
</li>
<li> <p><code>word_index</code> &mdash; named list mapping words to their rank/index (int). Only set
after <code>fit_text_tokenizer()</code> is called on the tokenizer.
</p>
</li>
<li> <p><code>document_count</code> &mdash; int. Number of documents (texts/sequences) the tokenizer
was trained on. Only set after <code>fit_text_tokenizer()</code> is called on the tokenizer.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer</a>()</code>,
<code><a href="#topic+save_text_tokenizer">save_text_tokenizer</a>()</code>,
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_matrix">texts_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_sequences">texts_to_sequences</a>()</code>,
<code><a href="#topic+texts_to_sequences_generator">texts_to_sequences_generator</a>()</code>
</p>

<hr>
<h2 id='texts_to_matrix'>Convert a list of texts to a matrix.</h2><span id='topic+texts_to_matrix'></span>

<h3>Description</h3>

<p>Convert a list of texts to a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>texts_to_matrix(tokenizer, texts, mode = c("binary", "count", "tfidf", "freq"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="texts_to_matrix_+3A_tokenizer">tokenizer</code></td>
<td>
<p>Tokenizer</p>
</td></tr>
<tr><td><code id="texts_to_matrix_+3A_texts">texts</code></td>
<td>
<p>Vector/list of texts (strings).</p>
</td></tr>
<tr><td><code id="texts_to_matrix_+3A_mode">mode</code></td>
<td>
<p>one of &quot;binary&quot;, &quot;count&quot;, &quot;tfidf&quot;, &quot;freq&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix
</p>


<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer</a>()</code>,
<code><a href="#topic+save_text_tokenizer">save_text_tokenizer</a>()</code>,
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix</a>()</code>,
<code><a href="#topic+text_tokenizer">text_tokenizer</a>()</code>,
<code><a href="#topic+texts_to_sequences">texts_to_sequences</a>()</code>,
<code><a href="#topic+texts_to_sequences_generator">texts_to_sequences_generator</a>()</code>
</p>

<hr>
<h2 id='texts_to_sequences'>Transform each text in texts in a sequence of integers.</h2><span id='topic+texts_to_sequences'></span>

<h3>Description</h3>

<p>Only top &quot;num_words&quot; most frequent words will be taken into account.
Only words known by the tokenizer will be taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>texts_to_sequences(tokenizer, texts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="texts_to_sequences_+3A_tokenizer">tokenizer</code></td>
<td>
<p>Tokenizer</p>
</td></tr>
<tr><td><code id="texts_to_sequences_+3A_texts">texts</code></td>
<td>
<p>Vector/list of texts (strings).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer</a>()</code>,
<code><a href="#topic+save_text_tokenizer">save_text_tokenizer</a>()</code>,
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix</a>()</code>,
<code><a href="#topic+text_tokenizer">text_tokenizer</a>()</code>,
<code><a href="#topic+texts_to_matrix">texts_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_sequences_generator">texts_to_sequences_generator</a>()</code>
</p>

<hr>
<h2 id='texts_to_sequences_generator'>Transforms each text in texts in a sequence of integers.</h2><span id='topic+texts_to_sequences_generator'></span>

<h3>Description</h3>

<p>Only top &quot;num_words&quot; most frequent words will be taken into account.
Only words known by the tokenizer will be taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>texts_to_sequences_generator(tokenizer, texts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="texts_to_sequences_generator_+3A_tokenizer">tokenizer</code></td>
<td>
<p>Tokenizer</p>
</td></tr>
<tr><td><code id="texts_to_sequences_generator_+3A_texts">texts</code></td>
<td>
<p>Vector/list of texts (strings).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generator which yields individual sequences
</p>


<h3>See Also</h3>

<p>Other text tokenization: 
<code><a href="#topic+fit_text_tokenizer">fit_text_tokenizer</a>()</code>,
<code><a href="#topic+save_text_tokenizer">save_text_tokenizer</a>()</code>,
<code><a href="#topic+sequences_to_matrix">sequences_to_matrix</a>()</code>,
<code><a href="#topic+text_tokenizer">text_tokenizer</a>()</code>,
<code><a href="#topic+texts_to_matrix">texts_to_matrix</a>()</code>,
<code><a href="#topic+texts_to_sequences">texts_to_sequences</a>()</code>
</p>

<hr>
<h2 id='time_distributed'>This layer wrapper allows to apply a layer to every temporal slice of an input</h2><span id='topic+time_distributed'></span>

<h3>Description</h3>

<p>This layer wrapper allows to apply a layer to every temporal slice of an input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>time_distributed(object, layer, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="time_distributed_+3A_object">object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li><p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li><p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li><p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="time_distributed_+3A_layer">layer</code></td>
<td>
<p>a <code>tf.keras.layers.Layer</code> instance.</p>
</td></tr>
<tr><td><code id="time_distributed_+3A_...">...</code></td>
<td>
<p>standard layer arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Every input should be at least 3D, and the dimension of index one of the
first input will be considered to be the temporal dimension.
</p>
<p>Consider a batch of 32 video samples, where each sample is a 128x128 RGB image
with <code>channels_last</code> data format, across 10 timesteps.
The batch input shape is <code style="white-space: pre;">&#8288;(32, 10, 128, 128, 3)&#8288;</code>.
</p>
<p>You can then use <code>TimeDistributed</code> to apply the same <code>Conv2D</code> layer to each
of the 10 timesteps, independently:
</p>
<div class="sourceCode R"><pre>input &lt;- layer_input(c(10, 128, 128, 3))
conv_layer &lt;- layer_conv_2d(filters = 64, kernel_size = c(3, 3))
output &lt;- input %&gt;% time_distributed(conv_layer)
output$shape # TensorShape([None, 10, 126, 126, 64])
</pre></div>
<p>Because <code>TimeDistributed</code> applies the same instance of <code>Conv2D</code> to each of the
timestamps, the same set of weights are used at each timestamp.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed">https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed</a>
</p>
</li></ul>

<p>Other layer wrappers: 
<code><a href="#topic+bidirectional">bidirectional</a>()</code>
</p>

<hr>
<h2 id='timeseries_dataset_from_array'>Creates a dataset of sliding windows over a timeseries provided as array</h2><span id='topic+timeseries_dataset_from_array'></span>

<h3>Description</h3>

<p>Creates a dataset of sliding windows over a timeseries provided as array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeseries_dataset_from_array(
  data,
  targets,
  sequence_length,
  sequence_stride = 1L,
  sampling_rate = 1L,
  batch_size = 128L,
  shuffle = FALSE,
  ...,
  seed = NULL,
  start_index = NULL,
  end_index = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timeseries_dataset_from_array_+3A_data">data</code></td>
<td>
<p>array or eager tensor
containing consecutive data points (timesteps).
The first axis is expected to be the time dimension.</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_targets">targets</code></td>
<td>
<p>Targets corresponding to timesteps in <code>data</code>.
<code>targets[i]</code> should be the target
corresponding to the window that starts at index <code>i</code>
(see example 2 below).
Pass NULL if you don't have target data (in this case the dataset will
only yield the input data).</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_sequence_length">sequence_length</code></td>
<td>
<p>Length of the output sequences (in number of timesteps).</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_sequence_stride">sequence_stride</code></td>
<td>
<p>Period between successive output sequences.
For stride <code>s</code>, output samples would
start at index <code>data[i]</code>, <code>data[i + s]</code>, <code>data[i + (2 * s)]</code>, etc.</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_sampling_rate">sampling_rate</code></td>
<td>
<p>Period between successive individual timesteps
within sequences. For rate <code>r</code>, timesteps
<code style="white-space: pre;">&#8288;data[i], data[i + r], ... data[i + sequence_length]&#8288;</code>
are used for create a sample sequence.</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of timeseries samples in each batch
(except maybe the last one).</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_shuffle">shuffle</code></td>
<td>
<p>Whether to shuffle output samples,
or instead draw them in chronological order.</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_...">...</code></td>
<td>
<p>For backwards and forwards compatibility, ignored presently.</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_seed">seed</code></td>
<td>
<p>Optional int; random seed for shuffling.</p>
</td></tr>
<tr><td><code id="timeseries_dataset_from_array_+3A_start_index">start_index</code>, <code id="timeseries_dataset_from_array_+3A_end_index">end_index</code></td>
<td>
<p>Optional int (1 based); data points earlier
than <code>start_index</code> or later then <code>end_index</code> will not be used
in the output sequences. This is useful to reserve part of the
data for test or validation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes in a sequence of data-points gathered at
equal intervals, along with time series parameters such as
length of the sequences/windows, spacing between two sequence/windows, etc.,
to produce batches of timeseries inputs and targets.
</p>


<h3>Value</h3>

<p>A <code>tf.data.Dataset</code> instance. If <code>targets</code> was passed, the
dataset yields batches of two items: <code style="white-space: pre;">&#8288;(batch_of_sequences, batch_of_targets)&#8288;</code>. If not, the dataset yields only
<code>batch_of_sequences</code>.
</p>


<h3>Example 1</h3>

<p>Consider indices <code>0:99</code>. With <code>sequence_length=10</code>, <code>sampling_rate=2</code>,
<code>sequence_stride=3</code>, <code>shuffle=FALSE</code>, the dataset will yield batches of
sequences composed of the following indices:
</p>
<div class="sourceCode"><pre>First sequence:  0  2  4  6  8 10 12 14 16 18
Second sequence: 3  5  7  9 11 13 15 17 19 21
Third sequence:  6  8 10 12 14 16 18 20 22 24
...
Last sequence:   78 80 82 84 86 88 90 92 94 96
</pre></div>
<p>In this case the last 3 data points are discarded since no full sequence
can be generated to include them (the next sequence would have started
at index 81, and thus its last step would have gone over 99).
</p>


<h3>Example 2</h3>

<p>Temporal regression.
</p>
<p>Consider an array <code>data</code> of scalar values, of shape <code>(steps)</code>.
To generate a dataset that uses the past 10
timesteps to predict the next timestep, you would use:
</p>
<div class="sourceCode R"><pre>steps &lt;- 100
# data is integer seq with some noise
data &lt;- array(1:steps + abs(rnorm(steps, sd = .25)))
inputs_data &lt;- head(data, -10) # drop last 10
targets &lt;- tail(data, -10)    # drop first 10
dataset &lt;- timeseries_dataset_from_array(
  inputs_data, targets, sequence_length=10)
library(tfdatasets)
dataset_iterator &lt;- as_iterator(dataset)
repeat {
  batch &lt;- iter_next(dataset_iterator)
  if(is.null(batch)) break
  c(input, target) %&lt;-% batch
  stopifnot(exprs = {
    # First sequence: steps [1-10]
    # Corresponding target: step 11
    all.equal(as.array(input[1, ]), data[1:10])
    all.equal(as.array(target[1]), data[11])

    all.equal(as.array(input[2, ]), data[2:11])
    all.equal(as.array(target[2]), data[12])

    all.equal(as.array(input[3, ]), data[3:12])
    all.equal(as.array(target[3]), data[13])
  })
}
</pre></div>


<h3>Example 3</h3>

<p>Temporal regression for many-to-many architectures.
</p>
<p>Consider two arrays of scalar values <code>X</code> and <code>Y</code>,
both of shape <code>(100)</code>. The resulting dataset should consist of samples with
20 timestamps each. The samples should not overlap.
To generate a dataset that uses the current timestamp
to predict the corresponding target timestep, you would use:
</p>
<div class="sourceCode R"><pre>X &lt;- seq(100)
Y &lt;- X*2

sample_length &lt;- 20
input_dataset &lt;- timeseries_dataset_from_array(
  X, NULL, sequence_length=sample_length, sequence_stride=sample_length)
target_dataset &lt;- timeseries_dataset_from_array(
  Y, NULL, sequence_length=sample_length, sequence_stride=sample_length)

library(tfdatasets)
dataset_iterator &lt;-
  zip_datasets(input_dataset, target_dataset) %&gt;%
  as_array_iterator()
while(!is.null(batch &lt;- iter_next(dataset_iterator))) {
  c(inputs, targets) %&lt;-% batch
  stopifnot(
    all.equal(inputs[1,], X[1:sample_length]),
    all.equal(targets[1,], Y[1:sample_length]),
    # second sample equals output timestamps 20-40
    all.equal(inputs[2,], X[(1:sample_length) + sample_length]),
    all.equal(targets[2,], Y[(1:sample_length) + sample_length])
  )
}
</pre></div>


<h3>Example</h3>

<div class="sourceCode"><pre>int_sequence &lt;- seq(20)

dummy_dataset &lt;- timeseries_dataset_from_array(
  data = head(int_sequence, -3), # drop last 3
  targets = tail(int_sequence, -3), # drop first 3
  sequence_length = 3,
  start_index = 3,
  end_index = 9,
  batch_size = 2
)

library(tfdatasets)
dummy_dataset_iterator &lt;- as_array_iterator(dummy_dataset)

repeat {
  batch &lt;- iter_next(dummy_dataset_iterator)
  if (is.null(batch)) # iterator exhausted
    break
  c(inputs, targets) %&lt;-% batch
  for (r in 1:nrow(inputs))
    cat(sprintf("input: [ %s ]  target: %s\n",
                paste(inputs[r,], collapse = " "), targets[r]))
  cat("---------------------------\n") # demark batchs
}
</pre></div>
<p>Will give output like:
</p>
<div class="sourceCode"><pre>input: [ 3 4 5 ]  target: 6
input: [ 4 5 6 ]  target: 7
---------------------------
input: [ 5 6 7 ]  target: 8
input: [ 6 7 8 ]  target: 9
---------------------------
input: [ 7 8 9 ]  target: 10
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array">https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array</a>
</p>
</li></ul>


<hr>
<h2 id='timeseries_generator'>Utility function for generating batches of temporal data.</h2><span id='topic+timeseries_generator'></span>

<h3>Description</h3>

<p>Utility function for generating batches of temporal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeseries_generator(
  data,
  targets,
  length,
  sampling_rate = 1,
  stride = 1,
  start_index = 0,
  end_index = NULL,
  shuffle = FALSE,
  reverse = FALSE,
  batch_size = 128
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timeseries_generator_+3A_data">data</code></td>
<td>
<p>Object containing consecutive data points (timesteps). The data
should be 2D, and axis 1 is expected to be the time dimension.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_targets">targets</code></td>
<td>
<p>Targets corresponding to timesteps in <code>data</code>.
It should have same length as <code>data</code>.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_length">length</code></td>
<td>
<p>Length of the output sequences (in number of timesteps).</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_sampling_rate">sampling_rate</code></td>
<td>
<p>Period between successive individual timesteps
within sequences. For rate <code>r</code>, timesteps <code>data[i]</code>, <code>data[i-r]</code>, ... <code>data[i - length]</code>
are used for create a sample sequence.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_stride">stride</code></td>
<td>
<p>Period between successive output sequences.
For stride <code>s</code>, consecutive output samples would
be centered around <code>data[i]</code>, <code>data[i+s]</code>, <code>data[i+2*s]</code>, etc.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_start_index">start_index</code>, <code id="timeseries_generator_+3A_end_index">end_index</code></td>
<td>
<p>Data points earlier than <code>start_index</code>
or later than <code>end_index</code> will not be used in the output sequences.
This is useful to reserve part of the data for test or validation.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_shuffle">shuffle</code></td>
<td>
<p>Whether to shuffle output samples,
or instead draw them in chronological order.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_reverse">reverse</code></td>
<td>
<p>Boolean: if <code>true</code>, timesteps in each output sample will be
in reverse chronological order.</p>
</td></tr>
<tr><td><code id="timeseries_generator_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of timeseries samples in each batch
(except maybe the last one).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object that can be passed to generator based training
functions (e.g. <code><a href="#topic+fit_generator">fit_generator()</a></code>).ma
</p>

<hr>
<h2 id='to_categorical'>Converts a class vector (integers) to binary class matrix.</h2><span id='topic+to_categorical'></span>

<h3>Description</h3>

<p>Converts a class vector (integers) to binary class matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_categorical(y, num_classes = NULL, dtype = "float32")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_categorical_+3A_y">y</code></td>
<td>
<p>Class vector to be converted into a matrix (integers from 0 to num_classes).</p>
</td></tr>
<tr><td><code id="to_categorical_+3A_num_classes">num_classes</code></td>
<td>
<p>Total number of classes.</p>
</td></tr>
<tr><td><code id="to_categorical_+3A_dtype">dtype</code></td>
<td>
<p>The data type expected by the input, as a string</p>
</td></tr>
</table>


<h3>Details</h3>

<p>E.g. for use with <code><a href="#topic+loss_categorical_crossentropy">loss_categorical_crossentropy()</a></code>.
</p>


<h3>Value</h3>

<p>A binary matrix representation of the input.
</p>

<hr>
<h2 id='train_on_batch'>Single gradient update or model evaluation over one batch of samples.</h2><span id='topic+train_on_batch'></span><span id='topic+test_on_batch'></span>

<h3>Description</h3>

<p>Single gradient update or model evaluation over one batch of samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_on_batch(object, x, y, class_weight = NULL, sample_weight = NULL)

test_on_batch(object, x, y, sample_weight = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_on_batch_+3A_object">object</code></td>
<td>
<p>Keras model object</p>
</td></tr>
<tr><td><code id="train_on_batch_+3A_x">x</code></td>
<td>
<p>input data, as an array or list of arrays (if the model has multiple
inputs).</p>
</td></tr>
<tr><td><code id="train_on_batch_+3A_y">y</code></td>
<td>
<p>labels, as an array.</p>
</td></tr>
<tr><td><code id="train_on_batch_+3A_class_weight">class_weight</code></td>
<td>
<p>named list mapping classes to a weight value, used for
scaling the loss function (during training only).</p>
</td></tr>
<tr><td><code id="train_on_batch_+3A_sample_weight">sample_weight</code></td>
<td>
<p>sample weights, as an array.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Scalar training or test loss (if the model has no metrics) or list of scalars
(if the model computes other metrics). The property <code>model$metrics_names</code>
will give you the display labels for the scalar outputs.
</p>


<h3>See Also</h3>

<p>Other model functions: 
<code><a href="#topic+compile.keras.engine.training.Model">compile.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate.keras.engine.training.Model">evaluate.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+evaluate_generator">evaluate_generator</a>()</code>,
<code><a href="#topic+fit.keras.engine.training.Model">fit.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+fit_generator">fit_generator</a>()</code>,
<code><a href="#topic+get_config">get_config</a>()</code>,
<code><a href="#topic+get_layer">get_layer</a>()</code>,
<code><a href="#topic+keras_model">keras_model</a>()</code>,
<code><a href="#topic+keras_model_sequential">keras_model_sequential</a>()</code>,
<code><a href="#topic+multi_gpu_model">multi_gpu_model</a>()</code>,
<code><a href="#topic+pop_layer">pop_layer</a>()</code>,
<code><a href="#topic+predict.keras.engine.training.Model">predict.keras.engine.training.Model</a>()</code>,
<code><a href="#topic+predict_generator">predict_generator</a>()</code>,
<code><a href="#topic+predict_on_batch">predict_on_batch</a>()</code>,
<code><a href="#topic+predict_proba">predict_proba</a>()</code>,
<code><a href="#topic+summary.keras.engine.training.Model">summary.keras.engine.training.Model</a>()</code>
</p>

<hr>
<h2 id='use_implementation'>Select a Keras implementation and backend</h2><span id='topic+use_implementation'></span><span id='topic+use_backend'></span>

<h3>Description</h3>

<p>Select a Keras implementation and backend
</p>


<h3>Usage</h3>

<pre><code class='language-R'>use_implementation(implementation = c("keras", "tensorflow"))

use_backend(backend = c("tensorflow", "cntk", "theano", "plaidml"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="use_implementation_+3A_implementation">implementation</code></td>
<td>
<p>One of &quot;keras&quot; or &quot;tensorflow&quot; (defaults to &quot;keras&quot;).</p>
</td></tr>
<tr><td><code id="use_implementation_+3A_backend">backend</code></td>
<td>
<p>One of &quot;tensorflow&quot;, &quot;cntk&quot;, or &quot;theano&quot; (defaults
to &quot;tensorflow&quot;)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Keras has multiple implementations (the original keras implementation
and the implementation native to TensorFlow) and supports multiple
backends (&quot;tensorflow&quot;, &quot;cntk&quot;, &quot;theano&quot;, and &quot;plaidml&quot;). These functions allow
switching between the various implementations and backends.
</p>
<p>The functions should be called after <code>library(keras)</code> and before calling
other functions within the package (see below for an example).
</p>
<p>The default implementation and backend should be suitable for most
use cases. The &quot;tensorflow&quot; implementation is useful when using Keras
in conjunction with TensorFlow Estimators (the <span class="pkg">tfestimators</span>
R package).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# use the tensorflow implementation
library(keras)
use_implementation("tensorflow")

# use the cntk backend
library(keras)
use_backend("theano")

## End(Not run)

</code></pre>

<hr>
<h2 id='with_custom_object_scope'>Provide a scope with mappings of names to custom objects</h2><span id='topic+with_custom_object_scope'></span>

<h3>Description</h3>

<p>Provide a scope with mappings of names to custom objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>with_custom_object_scope(objects, expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="with_custom_object_scope_+3A_objects">objects</code></td>
<td>
<p>Named list of objects</p>
</td></tr>
<tr><td><code id="with_custom_object_scope_+3A_expr">expr</code></td>
<td>
<p>Expression to evaluate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are many elements of Keras models that can be customized with
user objects (e.g. losses, metrics, regularizers, etc.). When
loading saved models that use these functions you typically
need to explicitily map names to user objects via the <code>custom_objects</code>
parmaeter.
</p>
<p>The <code>with_custom_object_scope()</code> function provides an alternative that
lets you create a named alias for a user object that applies to an entire
block of code, and is automatically recognized when loading saved models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# define custom metric
metric_top_3_categorical_accuracy &lt;-
  custom_metric("top_3_categorical_accuracy", function(y_true, y_pred) {
    metric_top_k_categorical_accuracy(y_true, y_pred, k = 3)
  })

with_custom_object_scope(c(top_k_acc = sparse_top_k_cat_acc), {

  # ...define model...

  # compile model (refer to "top_k_acc" by name)
  model %&gt;% compile(
    loss = "binary_crossentropy",
    optimizer = optimizer_nadam(),
    metrics = c("top_k_acc")
  )

  # save the model
  save_model_hdf5("my_model.h5")

  # loading the model within the custom object scope doesn't
  # require explicitly providing the custom_object
  load_model_hdf5("my_model.h5")
})

## End(Not run)

</code></pre>

<hr>
<h2 id='zip_lists'>zip lists</h2><span id='topic+zip_lists'></span>

<h3>Description</h3>

<p>This is conceptually similar to <code>zip()</code> in Python, or R functions
<code>purrr::transpose()</code> and <code>data.table::transpose()</code> (albeit, accepting
elements in <code>...</code> instead of a single list), with one crucial difference: if
the provided objects are named, then matching is done by names, not
positions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zip_lists(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zip_lists_+3A_...">...</code></td>
<td>
<p>R lists or atomic vectors, optionally named.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All arguments supplied must be of the same length. If positional matching is
required, then all arguments provided must be unnamed. If matching by names,
then all arguments must have the same set of names, but they can be in
different orders.
</p>


<h3>Value</h3>

<p>A inverted list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gradients &lt;- list("grad_for_wt_1", "grad_for_wt_2", "grad_for_wt_3")
weights &lt;- list("weight_1", "weight_2", "weight_3")
str(zip_lists(gradients, weights))
str(zip_lists(gradient = gradients, weight = weights))

names(gradients) &lt;- names(weights) &lt;- paste0("layer_", 1:3)
str(zip_lists(gradients, weights[c(3, 1, 2)]))

names(gradients) &lt;- paste0("gradient_", 1:3)
try(zip_lists(gradients, weights)) # error, names don't match
# call unname directly for positional matching
str(zip_lists(unname(gradients), unname(weights)))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
