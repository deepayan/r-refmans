<!DOCTYPE html><html lang="en"><head><title>Help for package bioacoustics</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bioacoustics}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bioacoustics-package'><p>bioacoustics: detect and extract automatically acoustic features in Zero-Crossing files and audio recordings</p></a></li>
<li><a href='#.parse.timestamp'><p>Internal function</p></a></li>
<li><a href='#blob_detection'><p>Blob detection of a region of interest into a spectrographic representation of the recording</p></a></li>
<li><a href='#file_checks'><p>Internal function</p></a></li>
<li><a href='#file_type_guess'><p>Internal function</p></a></li>
<li><a href='#fspec'><p>Generate spectrograms</p></a></li>
<li><a href='#guano_md'><p>Read GUANO metadata in audio file</p></a></li>
<li><a href='#metadata'><p>Extract metadata</p></a></li>
<li><a href='#mp3_to_wav'><p>Convert MP3 to WAV</p></a></li>
<li><a href='#myotis'><p>Audio recording of myotis species from United-Kingdom</p></a></li>
<li><a href='#plot_zc'><p>Generate spectrogram for Zero-Crossing files</p></a></li>
<li><a href='#read_audio'><p>Decode audio files</p></a></li>
<li><a href='#read_mp3'><p>Read MP3 files</p></a></li>
<li><a href='#read_wac'><p>Read WAC files from Wildlife Acoustics recorders</p></a></li>
<li><a href='#read_wav'><p>Read WAV files</p></a></li>
<li><a href='#read_zc'><p>Read Zero-Crossing files</p></a></li>
<li><a href='#rotate90'><p>Rotate 90Â° clockwise</p></a></li>
<li><a href='#spectro'><p>Plot a spectrogram</p></a></li>
<li><a href='#threshold_detection'><p>Amplitude threshold detector above Signal to Noise Ratio (SNR)</p></a></li>
<li><a href='#to_dB'><p>Convert to dB</p></a></li>
<li><a href='#write_zc'><p>Write Zero-Crossing files</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyse Audio Recordings and Automatically Extract Animal
Vocalizations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.8</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jean Marchal &lt;jean.marchal@wavx.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains all the necessary tools to process audio recordings of
             various formats (e.g., WAV, WAC, MP3, ZC), filter noisy files, 
             display audio signals, detect and extract automatically acoustic
             features for further analysis such as classification.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11, fftw3, GNU make</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Imports:</td>
<td>htmltools, graphics, grDevices, methods, moments, Rcpp (&ge;
0.12.13), stringr, tools, tuneR (&ge; 1.3.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, rmarkdown</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/wavx/bioacoustics/">https://github.com/wavx/bioacoustics/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/wavx/bioacoustics/issues/">https://github.com/wavx/bioacoustics/issues/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Biarch:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-08 14:49:10 UTC; jean</td>
</tr>
<tr>
<td>Author:</td>
<td>Jean Marchal [aut, cre],
  Francois Fabianek [aut],
  Christopher Scott [aut],
  Chris Corben [ctb, cph] (Read ZC files, original C code),
  David Riggs [ctb, cph] (Read GUANO metadata, original R code),
  Peter Wilson [ctb, cph] (Read ZC files, original R code),
  Wildlife Acoustics, inc. [ctb, cph] (Read WAC files, original C code),
  Jordan Biserkov [ctb],
  WavX, inc. [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-08 15:30:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='bioacoustics-package'>bioacoustics: detect and extract automatically acoustic features in Zero-Crossing files and audio recordings</h2><span id='topic+bioacoustics'></span><span id='topic+bioacoustics-package'></span>

<h3>Description</h3>

<p>bioacoustics contains all the necessary functions to read Zero-Crossing files and audio recordings of various formats,
filter noisy files, display audio signals, detect and extract automatically acoustic features
for further analysis such as species identification based on classification of animal vocalizations.
</p>


<h3>Details</h3>

<p>bioacoustics is subdivided into three main components:
</p>

<ul>
<li><p> Read, write and manipulate acoustic recordings.
</p>
</li>
<li><p> Display what's inside acoustic recordings, whether to plot or just extract metadata.
</p>
</li>
<li><p> Analyse audio recordings in batch in search of specific vocalizations and extract acoustic features.
</p>
</li></ul>

<p>To learn more about bioacoustics, start with the introduction vignette:
'vignette(&quot;introduction&quot;, package = &quot;bioacoustics&quot;)'
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jean Marchal <a href="mailto:jean.marchal@wavx.ca">jean.marchal@wavx.ca</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Francois Fabianek <a href="mailto:francois.fabianek@wavx.ca">francois.fabianek@wavx.ca</a>
</p>
</li>
<li><p> Christopher Scott
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Chris Corben <a href="mailto:chris@hoarybat.com">chris@hoarybat.com</a> (Read ZC files, original C code) [contributor, copyright holder]
</p>
</li>
<li><p> David Riggs <a href="mailto:driggs@myotisoft.com">driggs@myotisoft.com</a> (Read GUANO metadata, original R code) [contributor, copyright holder]
</p>
</li>
<li><p> Peter Wilson <a href="mailto:peter@peterwilson.id.au">peter@peterwilson.id.au</a> (Read ZC files, original R code) [contributor, copyright holder]
</p>
</li>
<li><p>  Wildlife Acoustics, inc. (Read WAC files, original C code) [contributor, copyright holder]
</p>
</li>
<li><p> Jordan Biserkov [contributor]
</p>
</li>
<li><p>  WavX, inc. [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/wavx/bioacoustics/">https://github.com/wavx/bioacoustics/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/wavx/bioacoustics/issues/">https://github.com/wavx/bioacoustics/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='.parse.timestamp'>Internal function</h2><span id='topic+.parse.timestamp'></span>

<h3>Description</h3>

<p>Parse ISO 8601 subset timestamps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.parse.timestamp(str)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".parse.timestamp_+3A_str">str</code></td>
<td>
<p>a string</p>
</td></tr>
</table>

<hr>
<h2 id='blob_detection'>Blob detection of a region of interest into a spectrographic representation of the recording</h2><span id='topic+blob_detection'></span>

<h3>Description</h3>

<p>This function is a modified version of the Bat classify software developed by Christopher Scott (2014).
It combines several algorithms for detection, filtering and audio feature extraction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blob_detection(
  wave,
  channel = "left",
  time_exp = 1,
  min_dur = 1.5,
  max_dur = 80,
  min_area = 40,
  min_TBE = 20,
  max_TBE = 1000,
  EDG = 0.9,
  LPF,
  HPF = 16000,
  FFT_size = 256,
  FFT_overlap = 0.875,
  blur = 2,
  bg_substract = 20,
  contrast_boost = 20,
  settings = FALSE,
  acoustic_feat = TRUE,
  metadata = FALSE,
  spectro_dir = NULL,
  time_scale = 0.1,
  ticks = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blob_detection_+3A_wave">wave</code></td>
<td>
<p>either a path to a file, or a <a href="tuneR.html#topic+Wave">Wave</a> object.
</p>
<p>Audio files will be automatically decoded internally using the function <a href="#topic+read_audio">read_audio</a>.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_channel">channel</code></td>
<td>
<p>character. Channel to keep for analysis in a stereo recording: 'left' or 'right'.
Do not need to be specified for mono recordings, recordings with more than two channels are not
yet supported. Default setting is 'left'.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_time_exp">time_exp</code></td>
<td>
<p>integer. Time expansion factor of the recording.
Set to 1 for real-time recording or above for time expanded recording. Default setting is 1.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_min_dur">min_dur</code></td>
<td>
<p>numeric. Minimum duration threshold in milliseconds (ms).
Extracted audio events shorter than this threshold are ignored. Default setting is 1.5 ms.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_max_dur">max_dur</code></td>
<td>
<p>numeric. Maximum duration threshold in milliseconds (ms).
Extracted audio events longer than this threshold are ignored. The default setting is 80 ms.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_min_area">min_area</code></td>
<td>
<p>integer. Minimum area threshold in number of pixels.
Extracted segments with an area shorter than this threshold are discarded.
Default setting is 40 pixels.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_min_tbe">min_TBE</code></td>
<td>
<p>numeric. Minimum time window between two audio events in milliseconds (ms). If the time interval between two
successive audio events is shorter than this window, they are ignored. The default setting is 20 ms.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_max_tbe">max_TBE</code></td>
<td>
<p>numeric. Maximum time window between two audio events in milliseconds (ms). If the time interval between two
successive audio events is longer than this window, they are ignored. The default setting is 1000 ms.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_edg">EDG</code></td>
<td>
<p>numeric. Exponential Decay Gain from 0 to 1. Sets the degree of temporal masking at the end of each audio event.
This filter avoids extracting noise or echoes at the end of the audio event. The default setting is 0.996.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_lpf">LPF</code></td>
<td>
<p>integer. Low-Pass Filter (Hz). Frequencies above the cutoff are greatly attenuated.
Default is set internally at the Nyquist frequency of the recording.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_hpf">HPF</code></td>
<td>
<p>integer. High-Pass Filter (Hz). Frequencies below the cutoff are greatly attenuated.
Default setting is 16000 Hz. A default of 1000 Hz is recommended for most bird vocalizations.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_fft_size">FFT_size</code></td>
<td>
<p>integer. Size of the Fast Fourrier Transform (FFT) window. Default setting is 256.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_fft_overlap">FFT_overlap</code></td>
<td>
<p>numeric. Percentage of overlap between two FFT windows (from 0 to 1). Default setting is 0.875.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_blur">blur</code></td>
<td>
<p>integer. Gaussian smoothing function for blurring the spectrogram of the audio event to reduce image noise.
Default setting is 2.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_bg_substract">bg_substract</code></td>
<td>
<p>integer. Foreground extraction with a mean filter applied on the spectrogram of the audio even for image denoising.
Default setting is 20.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_contrast_boost">contrast_boost</code></td>
<td>
<p>integer. Edge contrast enhancement filter of the spectrogram of the audio event to improve its apparent sharpness.
Default setting is 20.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_settings">settings</code></td>
<td>
<p>logical. <code>TRUE</code> or <code>FALSE</code>. Save on a list the parameters set with the threshold_detection function.
Default setting is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_acoustic_feat">acoustic_feat</code></td>
<td>
<p>logical. <code>TRUE</code> or <code>FALSE</code>. Extracts the acoustic and signal quality parameters from each audio event in a data frame.
The sequences of smoothed amplitude (dB) and frequency (Hz) bins of each audio event, temporal values (in ms)
of the beginning and the end of each audio event are also extracted in separate lists. Default setting is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_metadata">metadata</code></td>
<td>
<p>logical. <code>TRUE</code> or <code>FALSE</code>. Extracts on a list the metadata embedded with the Wave file
GUANO metadata extraction is not -yet- implemented. Default setting is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_spectro_dir">spectro_dir</code></td>
<td>
<p>character (path) or <code>NULL</code>. Generate an HTML page with the spectrograms numbered by order
of detection in the recording. Spectrograms are generated as individual .PNG files and stored in the
'spectro_dir/spectrograms' subdirectory. The R working directory is used if <code>spectro_dir</code> is <code>NULL</code>.
<code>spectro_dir</code> is set to <code>NULL</code> by default.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_time_scale">time_scale</code></td>
<td>
<p>numeric. Time resolution of the spectrogram in milliseconds (ms) per pixel (px). Default setting is 0.1 ms for bat echolocation calls.
A default of 2 ms/px is recommended for most bird vocalizations.</p>
</td></tr>
<tr><td><code id="blob_detection_+3A_ticks">ticks</code></td>
<td>
<p>either logical or numeric. If <code>TRUE</code> tickmarks are drawn on the (frequency)
y-axis and their positions are computed automatically. If numeric, sets the
lower and upper limits of the tickmarks and their interval (in Hz). Default setting is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(myotis)
Output &lt;- blob_detection(myotis, time_exp = 10, contrast_boost = 30, bg_substract = 30)
Output$data

</code></pre>

<hr>
<h2 id='file_checks'>Internal function</h2><span id='topic+file_checks'></span>

<h3>Description</h3>

<p>Performs various check on files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>file_checks(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="file_checks_+3A_file">file</code></td>
<td>
<p>path to a file</p>
</td></tr>
</table>

<hr>
<h2 id='file_type_guess'>Internal function</h2><span id='topic+file_type_guess'></span>

<h3>Description</h3>

<p>Determine the file extension
</p>


<h3>Usage</h3>

<pre><code class='language-R'>file_type_guess(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="file_type_guess_+3A_file">file</code></td>
<td>
<p>path to a file</p>
</td></tr>
</table>

<hr>
<h2 id='fspec'>Generate spectrograms</h2><span id='topic+fspec'></span>

<h3>Description</h3>

<p>This function returns the spectrographic representation of a time wave in the absolute scale or in decibels (dB) using the Fast Fourier transform (FFT).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fspec(
  wave,
  channel = "left",
  FFT_size = 256,
  FFT_overlap = 0.875,
  FFT_win = "hann",
  LPF,
  HPF = 0,
  tlim = NULL,
  flim = NULL,
  rotate = FALSE,
  to_dB = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fspec_+3A_wave">wave</code></td>
<td>
<p>a <a href="tuneR.html#topic+Wave">Wave</a> object.</p>
</td></tr>
<tr><td><code id="fspec_+3A_channel">channel</code></td>
<td>
<p>character. Channel to keep for analysis in a stereo recording: &quot;left&quot; or &quot;right&quot;. Default setting is left.</p>
</td></tr>
<tr><td><code id="fspec_+3A_fft_size">FFT_size</code></td>
<td>
<p>integer. Size of the Fast Fourrier Transform (FFT) window. Default setting is 256.</p>
</td></tr>
<tr><td><code id="fspec_+3A_fft_overlap">FFT_overlap</code></td>
<td>
<p>numeric. Percentage of overlap between two FFT windows (from 0 to 1). Default setting is 0.875.</p>
</td></tr>
<tr><td><code id="fspec_+3A_fft_win">FFT_win</code></td>
<td>
<p>character. Specify the type of FFT window: &quot;hann&quot;, &quot;blackman4&quot;, or &quot;blackman7&quot;.
Default setting is &quot;hann&quot;.</p>
</td></tr>
<tr><td><code id="fspec_+3A_lpf">LPF</code></td>
<td>
<p>integer. Low-Pass Filter (Hz). Frequencies above the cutoff are greatly attenuated.
Default setting is the Nyquist frequency of the recording.</p>
</td></tr>
<tr><td><code id="fspec_+3A_hpf">HPF</code></td>
<td>
<p>integer. High-Pass Filter (Hz). Frequencies below the cutoff are greatly attenuated.
Default setting is 0 Hz.</p>
</td></tr>
<tr><td><code id="fspec_+3A_tlim">tlim</code></td>
<td>
<p>numeric. Specify the time limits on the X-axis in seconds (s).
Default setting is <code>NULL</code>, i.e no time limits.</p>
</td></tr>
<tr><td><code id="fspec_+3A_flim">flim</code></td>
<td>
<p>numeric. Specify the frequency limits on the Y-axis in Hz. Default
setting is <code>NULL</code>, i.e. frequency limits are equal to <code>c(0, LPF)</code>.</p>
</td></tr>
<tr><td><code id="fspec_+3A_rotate">rotate</code></td>
<td>
<p>logical. Should the matrix be rotated 90Â° counter clockwise ?
Default setting is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fspec_+3A_to_db">to_dB</code></td>
<td>
<p>logical. Convert magnitude values to decibels (dB)? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of amplitude or decibel (dB) values in the time / frequency domain.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(myotis)
image(fspec(myotis, tlim = c(1, 2), rotate = TRUE))

</code></pre>

<hr>
<h2 id='guano_md'>Read GUANO metadata in audio file</h2><span id='topic+guano_md'></span>

<h3>Description</h3>

<p>Read GUANO metadata in audio file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>guano_md(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="guano_md_+3A_file">file</code></td>
<td>
<p>Path to a wav file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of named metadata fields
</p>

<hr>
<h2 id='metadata'>Extract metadata</h2><span id='topic+metadata'></span><span id='topic+metadata.character'></span><span id='topic+metadata.blob_detection'></span><span id='topic+metadata.threshold_detection'></span><span id='topic+metadata.zc'></span><span id='topic+metadata.Wave'></span>

<h3>Description</h3>

<p>Extract metadata
</p>
<p>Extract metadata from Zero-Crossing files
</p>
<p>Extract metadata from a Wave object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metadata(x, ...)

## S3 method for class 'character'
metadata(x, file_type = c(file_type_guess(x), "wav", "zc"), ...)

## S3 method for class 'blob_detection'
metadata(x, ...)

## S3 method for class 'threshold_detection'
metadata(x, ...)

## S3 method for class 'zc'
metadata(x, ...)

## S3 method for class 'Wave'
metadata(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metadata_+3A_x">x</code></td>
<td>
<p>an object for which metadata will be extracted</p>
</td></tr>
<tr><td><code id="metadata_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="metadata_+3A_file_type">file_type</code></td>
<td>
<p>type of file to read metadata from. Wav and Zero-Crossing files are currently supported.</p>
</td></tr>
</table>

<hr>
<h2 id='mp3_to_wav'>Convert MP3 to WAV</h2><span id='topic+mp3_to_wav'></span>

<h3>Description</h3>

<p>Convert an MP3 file to a Wave file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mp3_to_wav(file, output_dir = dirname(file), delete = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mp3_to_wav_+3A_file">file</code></td>
<td>
<p>path to a MP3 file.</p>
</td></tr>
<tr><td><code id="mp3_to_wav_+3A_output_dir">output_dir</code></td>
<td>
<p>where to save the converted Wave file.
The Wave file is saved by default to the MP3 file location.</p>
</td></tr>
<tr><td><code id="mp3_to_wav_+3A_delete">delete</code></td>
<td>
<p>delete the original MP3 file ?</p>
</td></tr>
</table>

<hr>
<h2 id='myotis'>Audio recording of myotis species from United-Kingdom</h2><span id='topic+myotis'></span><span id='topic+zc'></span>

<h3>Description</h3>

<p>The myotis dataset is a Wave file of 19.73 seconds, 16 bits, mono, 10x time expanded recording with a sampling rate at 50000 Hz.
It contains 20 echolocation calls of several species from the Myotis genus.
The recording was made in United-Kingdom with a D500X bat detector from Pettersson Elektronik AB.
</p>
<p>The zc dataset is a Zero-Crossing file of 16384 dots containing a sequence of 24 echolocation calls of a hoary bat (Lasiurus cinereus).
This ZC recording was made in Gatineau Park, Quebec, eastern Canada, during the summer 2017 with a Walkabout bat detector from Titley Scientific.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myotis

zc
</code></pre>


<h3>Format</h3>

<p><a href="tuneR.html#topic+Wave">Wave</a> object
</p>
<p>Zero-Crossing object
</p>

<hr>
<h2 id='plot_zc'>Generate spectrogram for Zero-Crossing files</h2><span id='topic+plot_zc'></span>

<h3>Description</h3>

<p>Generate spectrogram for Zero-Crossing files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_zc(
  x,
  LPF = 125000,
  HPF = 16000,
  tlim = c(0, Inf),
  flim = c(HPF, LPF),
  ybar = TRUE,
  ybar.lty = 2,
  ybar.col = "gray",
  dot.size = 0.3,
  dot.col = "red",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_zc_+3A_x">x</code></td>
<td>
<p>an object of class 'zc'.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_lpf">LPF</code></td>
<td>
<p>numeric. Low-Pass Filter (Hz). Frequencies above the cutoff are
greatly attenuated. Default is set to 125000 Hz.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_hpf">HPF</code></td>
<td>
<p>numeric. High-Pass Filter (Hz). Frequencies below the cutoff are
greatly attenuated. Default setting is 16000 Hz.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_tlim">tlim</code></td>
<td>
<p>numeric. Time limits of the plot in seconds (s). Default setting
is set to <code>c(0, Inf)</code>.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_flim">flim</code></td>
<td>
<p>numeric. Frequency limits of plot in Hz. Default setting is set
to <code>c(HPF, LPF)</code></p>
</td></tr>
<tr><td><code id="plot_zc_+3A_ybar">ybar</code></td>
<td>
<p>should horizontal scale bars be plotted. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_ybar.lty">ybar.lty</code></td>
<td>
<p>line type of the horizontal scale bars.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_ybar.col">ybar.col</code></td>
<td>
<p>color of the horizontal scale bars.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_dot.size">dot.size</code></td>
<td>
<p>dot size.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_dot.col">dot.col</code></td>
<td>
<p>dot color.</p>
</td></tr>
<tr><td><code id="plot_zc_+3A_...">...</code></td>
<td>
<p>not currently implemented.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(zc)
plot_zc(zc)
</code></pre>

<hr>
<h2 id='read_audio'>Decode audio files</h2><span id='topic+read_audio'></span>

<h3>Description</h3>

<p>Read audio files into a <a href="tuneR.html#topic+Wave">Wave</a> object. WAV, WAC and MP3 files are
currently supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_audio(file, time_exp = 1, from = NULL, to = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_audio_+3A_file">file</code></td>
<td>
<p>a <a href="tuneR.html#topic+Wave">Wave</a>, WAC or MP3 recording containing animal vocalizations.</p>
</td></tr>
<tr><td><code id="read_audio_+3A_time_exp">time_exp</code></td>
<td>
<p>integer. Time expansion factor of the recording.
Set to 1 for real-time recording or above for time expanded recording. Default setting is 1.</p>
</td></tr>
<tr><td><code id="read_audio_+3A_from">from</code></td>
<td>
<p>optional. Numeric. Where to start reading the recording, in seconds (s).</p>
</td></tr>
<tr><td><code id="read_audio_+3A_to">to</code></td>
<td>
<p>optional. Numeric. Where to end reading the recording, in seconds (s).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tuneR.html#topic+Wave">Wave</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

filepath &lt;- system.file("extdata", "recording.wav", package = "bioacoustics")
read_audio(filepath)


</code></pre>

<hr>
<h2 id='read_mp3'>Read MP3 files</h2><span id='topic+read_mp3'></span>

<h3>Description</h3>

<p>A thin wrapped around <a href="tuneR.html#topic+readMP3">readMP3</a> from the package tuneR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_mp3(file, time_exp = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_mp3_+3A_file">file</code></td>
<td>
<p>a MP3 file.</p>
</td></tr>
<tr><td><code id="read_mp3_+3A_time_exp">time_exp</code></td>
<td>
<p>integer. Time expansion factor of the recording.
Set to 1 for real-time recording or above for time expanded recording. Default setting is 1.</p>
</td></tr>
<tr><td><code id="read_mp3_+3A_...">...</code></td>
<td>
<p>currently not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tuneR.html#topic+Wave">Wave</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
filepath &lt;- system.file("extdata", "recording.mp3", package = "bioacoustics")
read_mp3(filepath)


</code></pre>

<hr>
<h2 id='read_wac'>Read WAC files from Wildlife Acoustics recorders</h2><span id='topic+read_wac'></span>

<h3>Description</h3>

<p>Convert a Wildlife Acoustics' proprietary compressed WAC file into a <a href="tuneR.html#topic+Wave">Wave</a> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_wac(file, time_exp = 1, write_wav = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_wac_+3A_file">file</code></td>
<td>
<p>a WAC file.</p>
</td></tr>
<tr><td><code id="read_wac_+3A_time_exp">time_exp</code></td>
<td>
<p>integer. Time expansion factor of the recording.
Set to 1 for real-time recording or above for time expanded recording. Default setting is 1.</p>
</td></tr>
<tr><td><code id="read_wac_+3A_write_wav">write_wav</code></td>
<td>
<p>optional folder path where WAV files will be written.</p>
</td></tr>
<tr><td><code id="read_wac_+3A_...">...</code></td>
<td>
<p>currently not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tuneR.html#topic+Wave">Wave</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
filepath &lt;- system.file("extdata", "recording_20170716_230503.wac", package = "bioacoustics")
read_wac(filepath)


</code></pre>

<hr>
<h2 id='read_wav'>Read WAV files</h2><span id='topic+read_wav'></span>

<h3>Description</h3>

<p>A thin wrapped around <a href="tuneR.html#topic+readWave">readWave</a> from the package tuneR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_wav(file, time_exp = 1, from = NULL, to = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_wav_+3A_file">file</code></td>
<td>
<p>a WAV file.</p>
</td></tr>
<tr><td><code id="read_wav_+3A_time_exp">time_exp</code></td>
<td>
<p>integer. Time expansion factor of the recording.
Set to 1 for real-time recording or above for time expanded recording. Default setting is 1.</p>
</td></tr>
<tr><td><code id="read_wav_+3A_from">from</code></td>
<td>
<p>optional. Numeric. Where to start reading the recording, in seconds (s).</p>
</td></tr>
<tr><td><code id="read_wav_+3A_to">to</code></td>
<td>
<p>optional. Numeric. Where to end reading the recording, in seconds (s).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tuneR.html#topic+Wave">Wave</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
filepath &lt;- system.file("extdata", "recording.wav", package = "bioacoustics")
read_wav(filepath)


</code></pre>

<hr>
<h2 id='read_zc'>Read Zero-Crossing files</h2><span id='topic+read_zc'></span>

<h3>Description</h3>

<p>Read Zero-Crossing files (.zc, .#) from various bat recorders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_zc(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_zc_+3A_file">file</code></td>
<td>
<p>a Zero-Crossing file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class 'zc'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
zc &lt;- read_zc("file")

## End(Not run)

</code></pre>

<hr>
<h2 id='rotate90'>Rotate 90Â° clockwise</h2><span id='topic+rotate90'></span>

<h3>Description</h3>

<p>Rotate a matrix 90Â° clockwise
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rotate90(m)
</code></pre>

<hr>
<h2 id='spectro'>Plot a spectrogram</h2><span id='topic+spectro'></span>

<h3>Description</h3>

<p>Plot a spectrogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectro(
  wave,
  channel = "left",
  FFT_size = 256,
  FFT_overlap = 0.875,
  FFT_win = "hann",
  LPF,
  HPF = 0,
  tlim = NULL,
  flim = NULL,
  ticks_y = NULL,
  col = gray.colors(25, 1, 0)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spectro_+3A_wave">wave</code></td>
<td>
<p>a <a href="tuneR.html#topic+Wave">Wave</a> object.</p>
</td></tr>
<tr><td><code id="spectro_+3A_channel">channel</code></td>
<td>
<p>character. Channel to keep for analysis in a stereo recording: &quot;left&quot; or &quot;right&quot;. Default setting is left.</p>
</td></tr>
<tr><td><code id="spectro_+3A_fft_size">FFT_size</code></td>
<td>
<p>integer. Size of the Fast Fourrier Transform (FFT) window. Default setting is 256.</p>
</td></tr>
<tr><td><code id="spectro_+3A_fft_overlap">FFT_overlap</code></td>
<td>
<p>numeric. Percentage of overlap between two FFT windows (from 0 to 1). Default setting is 0.875.</p>
</td></tr>
<tr><td><code id="spectro_+3A_fft_win">FFT_win</code></td>
<td>
<p>character. Specify the type of FFT window: &quot;hann&quot;, &quot;blackman4&quot;, or &quot;blackman7&quot;.
Default setting is &quot;hann&quot;.</p>
</td></tr>
<tr><td><code id="spectro_+3A_lpf">LPF</code></td>
<td>
<p>integer. Low-Pass Filter (Hz). Frequencies above the cutoff are greatly attenuated.
Default setting is the Nyquist frequency of the recording.</p>
</td></tr>
<tr><td><code id="spectro_+3A_hpf">HPF</code></td>
<td>
<p>integer. High-Pass Filter (Hz). Frequencies below the cutoff are greatly attenuated.
Default setting is 0 Hz.</p>
</td></tr>
<tr><td><code id="spectro_+3A_tlim">tlim</code></td>
<td>
<p>numeric. Specify the time limits on the X-axis in seconds (s).
Default setting is <code>NULL</code>, i.e no time limits.</p>
</td></tr>
<tr><td><code id="spectro_+3A_flim">flim</code></td>
<td>
<p>numeric. Specify the frequency limits on the Y-axis in Hz. Default
setting is <code>NULL</code>, i.e. frequency limits are equal to <code>c(0, LPF)</code>.</p>
</td></tr>
<tr><td><code id="spectro_+3A_ticks_y">ticks_y</code></td>
<td>
<p>numeric. Whether tickmarks should be drawn on the frequency Y-axis or not.
The lower and upper bounds of the tickmarks and their intervals (in Hz) has to be specified.
Default setting is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="spectro_+3A_col">col</code></td>
<td>
<p>set the colors for the amplitude scale (dB) of the spectrogram.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(myotis)
spectro(myotis, tlim = c(1, 2))

</code></pre>

<hr>
<h2 id='threshold_detection'>Amplitude threshold detector above Signal to Noise Ratio (SNR)</h2><span id='topic+threshold_detection'></span>

<h3>Description</h3>

<p>This function is a modified version of the Bat Bioacoustics freeware developed by Christopher Scott (2012).
It combines several detection, filtering and audio feature extraction algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threshold_detection(
  wave,
  threshold = 14,
  channel = "left",
  time_exp = 1,
  min_dur = 1.5,
  max_dur = 80,
  min_TBE = 20,
  max_TBE = 1000,
  EDG = 0.996,
  LPF,
  HPF = 16000,
  FFT_size = 256,
  FFT_overlap = 0.875,
  start_thr = 40,
  end_thr = 20,
  SNR_thr = 10,
  angle_thr = 40,
  duration_thr = 80,
  NWS = 100,
  KPE = 1e-05,
  KME = 1e-05,
  settings = FALSE,
  acoustic_feat = TRUE,
  metadata = FALSE,
  spectro_dir = NULL,
  time_scale = 0.1,
  ticks = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="threshold_detection_+3A_wave">wave</code></td>
<td>
<p>either a path to a file, or a <a href="tuneR.html#topic+Wave">Wave</a> object.
</p>
<p>Audio files will be automatically decoded internally using the function <a href="#topic+read_audio">read_audio</a>.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_threshold">threshold</code></td>
<td>
<p>integer. Sensitivity of the audio event detection function (peak-picking algorithm) in dB.
A threshold value of 14 dB above SNR is recommended. Higher values increase the risk of leaving audio events undetected (false negative).
In a noisy recording (low SNR) this sensitivity threshold may be set at 12 dB,
but a value below 10 dB is not recommended. Default setting is 14 dB above SNR.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_channel">channel</code></td>
<td>
<p>character. Channel to keep for analysis in a stereo recording: 'left' or 'right'.
Do not need to be specified for mono recordings, recordings with more than two channels are not
yet supported. Default setting is 'left'.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_time_exp">time_exp</code></td>
<td>
<p>integer. Time expansion factor of the recording.
Set to 1 for real-time recording or above for time expanded recording. Default setting is 1.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_min_dur">min_dur</code></td>
<td>
<p>numeric. Minimum duration threshold in milliseconds (ms).
Extracted audio events shorter than this threshold are ignored. Default setting is 1.5 ms.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_max_dur">max_dur</code></td>
<td>
<p>numeric. Maximum duration threshold in milliseconds (ms).
Extracted audio events longer than this threshold are ignored. The default setting is 80 ms.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_min_tbe">min_TBE</code></td>
<td>
<p>numeric. Minimum time window between two audio events in milliseconds (ms). If the time interval between two
successive audio events is shorter than this window, they are ignored. The default setting is 20 ms.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_max_tbe">max_TBE</code></td>
<td>
<p>numeric. Maximum time window between two audio events in milliseconds (ms). If the time interval between two
successive audio events is longer than this window, they are ignored. The default setting is 1000 ms.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_edg">EDG</code></td>
<td>
<p>numeric. Exponential Decay Gain from 0 to 1. Sets the degree of temporal masking at the end of each audio event.
This filter avoids extracting noise or echoes at the end of the audio event. The default setting is 0.996.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_lpf">LPF</code></td>
<td>
<p>integer. Low-Pass Filter (Hz). Frequencies above the cutoff are greatly attenuated.
Default is set internally at the Nyquist frequency of the recording.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_hpf">HPF</code></td>
<td>
<p>integer. High-Pass Filter (Hz). Frequencies below the cutoff are greatly attenuated.
Default setting is 16000 Hz. A default of 1000 Hz is recommended for most bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_fft_size">FFT_size</code></td>
<td>
<p>integer. Size of the Fast Fourrier Transform (FFT) window. Default setting is 256.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_fft_overlap">FFT_overlap</code></td>
<td>
<p>numeric. Percentage of overlap between two FFT windows (from 0 to 1). Default setting is 0.875.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_start_thr">start_thr</code></td>
<td>
<p>integer. Right to left amplitude threshold (dB) for audio event extraction, from the audio event centroid.
The last FFT where the amplitude level is equal or above this threshold is considered the start of the audio event.
Default setting is 40 dB. 20 dB is recommended for extracting bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_end_thr">end_thr</code></td>
<td>
<p>integer. Left to right amplitude threshold (dB) for audio event extraction, from the audio event centroid.
The last FFT where the amplitude level is equal or above this threshold is considered the end of the audio event.
Default setting is 20 dB. 30 dB is recommended for extracting bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_snr_thr">SNR_thr</code></td>
<td>
<p>integer. SNR threshold (dB) at which the extraction of the audio event stops.
Default setting is 10 dB. 8 dB is recommended for bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_angle_thr">angle_thr</code></td>
<td>
<p>integer. Angle threshold (Â°) at which the audio event extraction stops.
Default setting is 40Â°. 125Â° is recommended for extracting bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_duration_thr">duration_thr</code></td>
<td>
<p>integer. Maximum duration threshold in milliseconds (ms) after which the monitoring of the background noise is resumed.
Default setting is 80 ms for bat echolocation calls. A higher threshold value is recommended for extracting bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_nws">NWS</code></td>
<td>
<p>integer. Length of the time window used for background noise estimation in the recording (ms).
A longer window size is less sensitive to local variations in the background noise.
Default setting is 100 ms.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_kpe">KPE</code></td>
<td>
<p>numeric. Set the Process Error parameter of the Kalman filter.
Default setting is 1e-05.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_kme">KME</code></td>
<td>
<p>numeric. Set the Measurement Error parameter of the Kalman filter.
Default setting is 1e-05.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_settings">settings</code></td>
<td>
<p>logical. <code>TRUE</code> or <code>FALSE</code>. Save on a list the parameters set with the threshold_detection function.
Default setting is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_acoustic_feat">acoustic_feat</code></td>
<td>
<p>logical. <code>TRUE</code> or <code>FALSE</code>. Extracts the acoustic and signal quality parameters from each audio event in a data frame.
The sequences of smoothed amplitude (dB) and frequency (Hz) bins of each audio event, temporal values (in ms)
of the beginning and the end of each audio event are also extracted in separate lists. Default setting is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_metadata">metadata</code></td>
<td>
<p>logical. <code>TRUE</code> or <code>FALSE</code>. Extracts on a list the metadata embedded with the Wave file
GUANO metadata extraction is not -yet- implemented. Default setting is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_spectro_dir">spectro_dir</code></td>
<td>
<p>character (path) or <code>NULL</code>. Generate an HTML page with the spectrograms numbered by order
of detection in the recording. Spectrograms are generated as individual .PNG files and stored in the
'spectro_dir/spectrograms' subdirectory. The R working directory is used if <code>spectro_dir</code> is <code>NULL</code>.
<code>spectro_dir</code> is set to <code>NULL</code> by default.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_time_scale">time_scale</code></td>
<td>
<p>numeric. Time resolution of the spectrogram in milliseconds (ms) per pixel (px). Default setting is 0.1 ms for bat echolocation calls.
A default of 2 ms/px is recommended for most bird vocalizations.</p>
</td></tr>
<tr><td><code id="threshold_detection_+3A_ticks">ticks</code></td>
<td>
<p>either logical or numeric. If <code>TRUE</code> tickmarks are drawn on the (frequency)
y-axis and their positions are computed automatically. If numeric, sets the
lower and upper limits of the tickmarks and their interval (in Hz). Default setting is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class 'bioacoustics_output'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(myotis)
Output &lt;- threshold_detection(myotis, time_exp = 10, HPF = 16000, LPF = 200000)
Output$data

</code></pre>

<hr>
<h2 id='to_dB'>Convert to dB</h2><span id='topic+to_dB'></span>

<h3>Description</h3>

<p>Convert amplitude to decibel (dB) values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_dB(x, ref = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="to_dB_+3A_x">x</code></td>
<td>
<p>numeric. Vector of amplitude values (V1).</p>
</td></tr>
<tr><td><code id="to_dB_+3A_ref">ref</code></td>
<td>
<p>numeric. Reference value (V0) to calculate the ratio (V1/V0).</p>
</td></tr>
</table>

<hr>
<h2 id='write_zc'>Write Zero-Crossing files</h2><span id='topic+write_zc'></span>

<h3>Description</h3>

<p>Write Zero-Crossing files (.zc, .#)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_zc(zc, filename)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_zc_+3A_zc">zc</code></td>
<td>
<p>an object of class 'zc'.</p>
</td></tr>
<tr><td><code id="write_zc_+3A_filename">filename</code></td>
<td>
<p>path or connection to write.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(zc)
filename &lt;- tempfile()
write_zc(zc, filename = filename)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
