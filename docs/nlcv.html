<!DOCTYPE html><html><head><title>Help for package nlcv</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nlcv}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#compareOrig'><p>function to compare the original matrix of correct classes to</p>
each component of the output object for a certain classifier</a></li>
<li><a href='#confusionMatrix.nlcv'><p>compute a confusion matrix for the optimal number of features for a given</p>
technique used in the nested loop cross validation</a></li>
<li><a href='#inTrainingSample'><p>Function to define a learning sample based on balanced sampling</p></a></li>
<li><a href='#limmaTwoGroups'><p>Wrapper around limma for the comparison of two groups</p></a></li>
<li><a href='#mcrPlot'><p>Misclassification Rate Plot</p></a></li>
<li><a href='#nlcv'><p>Nested Loop Cross-Validation</p></a></li>
<li><a href='#nlcvRF_R'><p>nlcv results on random data with random forest feature selection</p></a></li>
<li><a href='#nlcvRF_SHS'><p>nlcv results on strong hetero signal data with random forest feature selection</p></a></li>
<li><a href='#nlcvRF_SS'><p>nlcv results on strong signal data a with random forest feature selection</p></a></li>
<li><a href='#nlcvRF_WHS'><p>nlcv results on weak signal data with random forest feature selection</p></a></li>
<li><a href='#nlcvRF_WS'><p>nlcv results on weak hetero signal data with random forest feature selection</p></a></li>
<li><a href='#nlcvTT_R'><p>nlcv results on random data with t-test feature selection</p></a></li>
<li><a href='#nlcvTT_SHS'><p>nlcv results on strong hetero signal data with t-test feature selection</p></a></li>
<li><a href='#nlcvTT_SS'><p>nlcv results on strong signal data a with t-test feature selection</p></a></li>
<li><a href='#nlcvTT_WHS'><p>nlcv results on weak signal data with t-test feature selection</p></a></li>
<li><a href='#nlcvTT_WS'><p>nlcv results on weak hetero signal data with t-test feature selection</p></a></li>
<li><a href='#nldaI'><p>new MLInterfaces schema for lda from MASS</p></a></li>
<li><a href='#pamrI'><p>Instance of a learnerSchema for pamr models</p></a></li>
<li><a href='#pamrIconverter'><p>convert from <code>pamrML</code> to <code>classifierOutput</code></p></a></li>
<li><a href='#pamrML'><p>Wrapper function around the pamr.* functions</p></a></li>
<li><a href='#pamrTrain'><p>Function providing a formula interface to pamr.train</p></a></li>
<li><a href='#predict.pamrML'><p>predict <code>pamrML</code> object</p></a></li>
<li><a href='#print.nlcvConfusionMatrix'><p>print object <code>nlcvConfusionMatrix</code></p></a></li>
<li><a href='#print.pamrML'><p>print <code>pamrML</code> object</p></a></li>
<li><a href='#print.summary.mcrPlot'><p><code>print</code> function for <code>summary.mcrPlot</code> object</p></a></li>
<li><a href='#rankDistributionPlot'><p>Plot the Distribution of Ranks of Features Across nlcv Runs</p></a></li>
<li><a href='#rocPlot'><p>Produce a ROC plot for a classification model belonging to a given technique</p>
and with a given number of features.</a></li>
<li><a href='#scoresPlot'><p>Function to Plot a Scores Plot</p></a></li>
<li><a href='#summary.mcrPlot'><p><code>summary</code> function for <code>mcrPlot</code> object</p></a></li>
<li><a href='#topTable-methods'><p>Methods for topTable</p></a></li>
<li><a href='#xtable.confusionMatrix'><p>xtable method for confusionMatrix objects</p></a></li>
<li><a href='#xtable.summary.mcrPlot'><p>xtable method for summary.mcrPlot objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nested Loop Cross Validation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-06-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Willem Talloen, Tobias Verbeke                                                                                                             </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Laure Cougnaud &lt;laure.cougnaud@openanalytics.eu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Nested loop cross validation for classification purposes for misclassification error rate estimation.
  The package supports several methodologies for feature selection: random forest, Student t-test, limma, 
  and provides an interface to the following classification methods in the 'MLInterfaces' package: linear, 
  quadratic discriminant analyses, random forest, bagging, prediction analysis for microarray, generalized 
  linear model, support vector machine (svm and ksvm). Visualizations to assess the quality of
  the classifier are included: plot of the ranks of the features, scores plot for a specific 
  classification algorithm and number of features, misclassification rate 
  for the different number of features and classification algorithms tested and ROC plot.
  For further details about the methodology, please check:
  Markus Ruschhaupt, Wolfgang Huber, Annemarie Poustka, and Ulrich Mansmann (2004) 
  &lt;<a href="https://doi.org/10.2202%2F1544-6115.1078">doi:10.2202/1544-6115.1078</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), a4Core, MLInterfaces (&ge; 1.22.0), xtable</td>
</tr>
<tr>
<td>Imports:</td>
<td>limma, MASS, methods, graphics, Biobase, multtest,
RColorBrewer, pamr, randomForest, ROCR, ipred, e1071, kernlab</td>
</tr>
<tr>
<td>Suggests:</td>
<td>RUnit, ALL</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1.9000</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-06-29 21:29:20 UTC; lcougnaud</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-06-29 21:49:59 UTC</td>
</tr>
</table>
<hr>
<h2 id='compareOrig'>function to compare the original matrix of correct classes to
each component of the output object for a certain classifier</h2><span id='topic+compareOrig'></span>

<h3>Description</h3>

<p>function to compare the original matrix of correct classes to
each component of the output object for a certain classifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareOrig(nlcvObj, techn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compareOrig_+3A_nlcvobj">nlcvObj</code></td>
<td>
<p>return of the <code><a href="#topic+nlcv">nlcv</a></code> function</p>
</td></tr>
<tr><td><code id="compareOrig_+3A_techn">techn</code></td>
<td>
<p>technique for which the comparison to correct classes should be made</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with for each number of features selected,
a matrix of logical values indicating whether the classifier results
correspond (TRUE) or not (FALSE) to the original values to be classified
</p>

<hr>
<h2 id='confusionMatrix.nlcv'>compute a confusion matrix for the optimal number of features for a given
technique used in the nested loop cross validation</h2><span id='topic+confusionMatrix.nlcv'></span>

<h3>Description</h3>

<p>The observed and predicted classes are cross-tabulated for a given
classification technique used in the nested loop cross validation.  The
predicted class that is used to construct the confusion matrix is the class
that was predicted most of the time (<code class="reqn">&gt;= 50\%</code>) across all runs
of the nested loop.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nlcv'
confusionMatrix(x, tech, proportions = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusionMatrix.nlcv_+3A_x">x</code></td>
<td>
<p>object for which a confusionMatrix should be produced, e.g.  one
produced by the <code>nlcv</code> function; for the print method, it is the object
to be printed</p>
</td></tr>
<tr><td><code id="confusionMatrix.nlcv_+3A_tech">tech</code></td>
<td>
<p>string indicating the classification technique for which the
confusion matrix should be returned</p>
</td></tr>
<tr><td><code id="confusionMatrix.nlcv_+3A_proportions">proportions</code></td>
<td>
<p>logical indicating whether the cells of the matrix should
contain proportions (<code>TRUE</code>) or raw counts (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="confusionMatrix.nlcv_+3A_...">...</code></td>
<td>
<p>Dots argument to pass additional parameters to the
<code>confusionMatrix</code> or <code>print</code> methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>confusionMatrix</code> produces an object of class
<code>confusionMatrix</code> which directly inherits from the <code>ftable</code> class
(representing the confusion matrix)
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>

<hr>
<h2 id='inTrainingSample'>Function to define a learning sample based on balanced sampling</h2><span id='topic+inTrainingSample'></span>

<h3>Description</h3>

<p>This function takes in a factor with class labels of the total dataset,
draws a sample (balanced with respect to the different levels of the factor)
and returns a logical vector indicating whether the observation is in the
learning sample (<code>TRUE</code>) or not (<code>FALSE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inTrainingSample(y, propTraining = 2/3, classdist = c("balanced",
  "unbalanced"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inTrainingSample_+3A_y">y</code></td>
<td>
<p>factor with the class labels for the total data set</p>
</td></tr>
<tr><td><code id="inTrainingSample_+3A_proptraining">propTraining</code></td>
<td>
<p>proportion of the data that should be in a training set;
the default value is 2/3.</p>
</td></tr>
<tr><td><code id="inTrainingSample_+3A_classdist">classdist</code></td>
<td>
<p>distribution of classes; allows to indicate whether your
distribution 'balanced' or 'unbalanced'. The sampling strategy for each run
is adapted accordingly.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector indicating for each observation in <code>y</code> whether
the observation is in the learning sample (<code>TRUE</code>) or not
(<code>FALSE</code>)
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ### this example demonstrates the logic of sampling in case of unbalanced distribution of classes
  y &lt;- factor(c(rep("A", 21), rep("B", 80)))
  
  nlcv:::inTrainingSample(y, 2/3, "unbalanced") 
  table(y[nlcv:::inTrainingSample(y, 2/3, "unbalanced")])  # should be 14, 14 (for A, B resp.)
  table(y[!nlcv:::inTrainingSample(y, 2/3, "unbalanced")]) # should be 7, 66  (for A, B resp.) 

</code></pre>

<hr>
<h2 id='limmaTwoGroups'>Wrapper around limma for the comparison of two groups</h2><span id='topic+limmaTwoGroups'></span>

<h3>Description</h3>

<p>Wrapper around limma for the comparison of two groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>limmaTwoGroups(object, group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="limmaTwoGroups_+3A_object">object</code></td>
<td>
<p>object of class ExpressionSet</p>
</td></tr>
<tr><td><code id="limmaTwoGroups_+3A_group">group</code></td>
<td>
<p>string indicating the variable defining the two groups to be
compared</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Basically, the wrapper combines the <code>lmFit</code>, <code>eBayes</code> and
<code>topTable</code> steps
</p>


<h3>Value</h3>

<p><code>topTable</code> output for the second (i.e. slope) coefficient of
the linear model.
</p>


<h3>Author(s)</h3>

<p>Tobias Verbeke
</p>


<h3>References</h3>

<p>Smyth, G. K. (2004). Linear models and empirical Bayes methods
for assessing differential expression in microarray experiments.
<em>Statistical Applications in Genetics and Molecular Biology</em>, Vol. 3,
No. 1, Article 3.
</p>
<p><a href="http://www.bepress.com/sagmb/vol3/iss1/art3">http://www.bepress.com/sagmb/vol3/iss1/art3</a>
</p>

<hr>
<h2 id='mcrPlot'>Misclassification Rate Plot</h2><span id='topic+mcrPlot'></span>

<h3>Description</h3>

<p>plots for each classification technique and a given number of features used
the mean misclassification rate (mcr) and its standard error across all runs
of the nested loop cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcrPlot(nlcvObj, plot = TRUE, optimalDots = TRUE, rescale = FALSE, layout = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcrPlot_+3A_nlcvobj">nlcvObj</code></td>
<td>
<p>Object of class 'nlcv' as produced by the <code>nlcv</code>
function</p>
</td></tr>
<tr><td><code id="mcrPlot_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>FALSE</code>, nothing is plotted.</p>
</td></tr>
<tr><td><code id="mcrPlot_+3A_optimaldots">optimalDots</code></td>
<td>
<p>Boolean indicating whether dots should be displayed on a
panel below the graph to mark the optimal number of features for a given
classification technique</p>
</td></tr>
<tr><td><code id="mcrPlot_+3A_rescale">rescale</code></td>
<td>
<p>if <code>TRUE</code>, the upper limit of y-axis is dependent on the
data (maximum mcr value); defaults to <code>FALSE</code> which implies limits
<code>c(0,1)</code></p>
</td></tr>
<tr><td><code id="mcrPlot_+3A_layout">layout</code></td>
<td>
<p>boolean indicating whether <code>mcrPlot</code> should prespecify a
layout for a single plot (default, <code>TRUE</code>) or whetherl the user takes
care of the layout (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="mcrPlot_+3A_...">...</code></td>
<td>
<p>Dots argument to pass additional graphical parameters (such as
<code>main</code>) to the <code>plot</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An MCR plot is output to the device of choice. The dots represent
the mean MCR across runs. The vertical lines below and above the dots
represent the standard deviation of the MCR values across runs.
</p>
<p>Below the plot coloured solid dots (one for each classification technique)
indicate for which number of features a given technique reached its minimum
MCR.
</p>
<p>The function invisibly returns an object of class <code>mcrPlot</code> which is a
list with components:
</p>

<ul>
<li><p>meanMcrMatrixmatrix with for each number of
features (rows) and classification technique (columns) the mean of the MCR
values across all runs of the nlcv procedure.
</p>
</li>
<li><p>sdMcrMatrixmatrix
with for each number of features (rows) and classification technique
(columns) the sd of the MCR values across all runs of the nlcv procedure.
</p>
</li></ul>

<p>The <code>summary</code> method for the <code>mcrPlot</code> object returns a matrix
with for each classification technique, the optimal number of features as
well as the associated mean MCR and standard deviation of the MCR values.
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlcv">nlcv</a></code>
</p>

<hr>
<h2 id='nlcv'>Nested Loop Cross-Validation</h2><span id='topic+nlcv'></span>

<h3>Description</h3>

<p>This function first proceeds to a feature selection and then applies five
different classification algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcv(eset, classVar = "type", nRuns = 2, propTraining = 2/3,
  classdist = c("balanced", "unbalanced"), nFeatures = c(2, 3, 5, 7, 10, 15,
  20, 25, 30, 35), fsMethod = c("randomForest", "t.test", "limma", "none"),
  classifMethods = c("dlda", "randomForest", "bagg", "pam", "svm"),
  fsPar = NULL, initialGenes = seq(length.out = nrow(eset)),
  geneID = "ID", storeTestScores = FALSE, verbose = FALSE, seed = 123)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlcv_+3A_eset">eset</code></td>
<td>
<p>ExpressionSet object containing the genes to classify</p>
</td></tr>
<tr><td><code id="nlcv_+3A_classvar">classVar</code></td>
<td>
<p>String giving the name of the variable containing the
observed class labels, should be contained in the phenoData of <code>eset</code></p>
</td></tr>
<tr><td><code id="nlcv_+3A_nruns">nRuns</code></td>
<td>
<p>Number of runs for the outer loop of the cross-validation</p>
</td></tr>
<tr><td><code id="nlcv_+3A_proptraining">propTraining</code></td>
<td>
<p>Proportion of the observations to be assigned to the
training set. By default <code>propTraining = 2/3</code>.</p>
</td></tr>
<tr><td><code id="nlcv_+3A_classdist">classdist</code></td>
<td>
<p>distribution of classes; allows to indicate whether your
distribution is 'balanced' or 'unbalanced'. The sampling strategy for each run
is adapted accordingly.</p>
</td></tr>
<tr><td><code id="nlcv_+3A_nfeatures">nFeatures</code></td>
<td>
<p>Numeric vector with the number of features to be selected
from the features kept by the feature selection method. For each number n
specified in this vector the classification algorithms will be run using
only the top n features.</p>
</td></tr>
<tr><td><code id="nlcv_+3A_fsmethod">fsMethod</code></td>
<td>
<p>Feature selection method; one of <code>"randomForest"</code> (default),
<code>"t.test"</code>, <code>"limma"</code> or <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="nlcv_+3A_classifmethods">classifMethods</code></td>
<td>
<p>character vector with the classification methods to be
used in the analysis; elements can be chosen among 
<code>"dlda"</code>, <code>"randomForest"</code>, <code>"bagg"</code>, <code>"pam"</code>
<code>"svm"</code>, <code>"glm"</code>, <code>"lda"</code>, <code>"nlda"</code>, <code>"dlda"</code>, <code>"ksvm"</code>.
The first 5 methods are selected by default</p>
</td></tr>
<tr><td><code id="nlcv_+3A_fspar">fsPar</code></td>
<td>
<p>List of further parameters to pass to the feature selection
method; currently the default for <code>"randomForest"</code> is an empty
<code>list()</code> whereas for <code>"t.test"</code>, one can specify the particular
test to be used (the default being <code>list(test = "f"</code>).</p>
</td></tr>
<tr><td><code id="nlcv_+3A_initialgenes">initialGenes</code></td>
<td>
<p>Initial subset of genes in the ExpressionSet on which to
apply the nested loop cross validation procedure. By default all genes are
selected.</p>
</td></tr>
<tr><td><code id="nlcv_+3A_geneid">geneID</code></td>
<td>
<p>string representing the name of the gene ID variable in the
fData of the expression set to use; this argument was added for people who
use e.g. both Entrez IDs and Ensemble gene IDs</p>
</td></tr>
<tr><td><code id="nlcv_+3A_storetestscores">storeTestScores</code></td>
<td>
<p>should the test scores be stored in the <code>nlcv</code>
object? Defaults to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="nlcv_+3A_verbose">verbose</code></td>
<td>
<p>Should the output be verbose (<code>TRUE</code>) or not
(<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="nlcv_+3A_seed">seed</code></td>
<td>
<p>integer with seed, set at the start of the cross-validation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result is an object of class 'nlcv'. It is a list with two
components, <code>output</code> and <code>features</code>.
</p>
<p>De <code>output</code> component is a list of five components, one for each
classification algorithm used. Each of these components has as many
components as there are elements in the <code>nFeatures</code> vector. These
components contain both the error rates for each run (component
<code>errorRate</code>) and the predicted labels for each run (character matrix
<code>labelsMat</code>).
</p>
<p>The <code>features</code> list is a list with as many components as there are
runs. For each run, a named vector is given with the variable importance
measure for each gene. For t test based feature selection, P-values are
used; for random forest based feature selection the variable importance
measure is given.
</p>


<h3>Note</h3>

<p>The variable importance measure used is the third column of the output
returned by the <code>randomForest</code> function.
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>

<hr>
<h2 id='nlcvRF_R'>nlcv results on random data with random forest feature selection</h2><span id='topic+nlcvRF_R'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with random forest on a randomly generated dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvRF_R
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvRF_SHS'>nlcv results on strong hetero signal data with random forest feature selection</h2><span id='topic+nlcvRF_SHS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with random forest on a dataset with strong hetero signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvRF_SHS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvRF_SS'>nlcv results on strong signal data a with random forest feature selection</h2><span id='topic+nlcvRF_SS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with random forest on a dataset with strong signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvRF_SS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvRF_WHS'>nlcv results on weak signal data with random forest feature selection</h2><span id='topic+nlcvRF_WHS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with random forest on a weak signal dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvRF_WHS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvRF_WS'>nlcv results on weak hetero signal data with random forest feature selection</h2><span id='topic+nlcvRF_WS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with random forest on a weak hetero signal dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvRF_WS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvTT_R'>nlcv results on random data with t-test feature selection</h2><span id='topic+nlcvTT_R'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with t-test on a randomly generated dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvTT_R
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvTT_SHS'>nlcv results on strong hetero signal data with t-test feature selection</h2><span id='topic+nlcvTT_SHS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with t-test on a dataset with strong hetero signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvTT_SHS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvTT_SS'>nlcv results on strong signal data a with t-test feature selection</h2><span id='topic+nlcvTT_SS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with t-test on a dataset with strong signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvTT_SS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvTT_WHS'>nlcv results on weak signal data with t-test feature selection</h2><span id='topic+nlcvTT_WHS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with t-test on a weak signal dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvTT_WHS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nlcvTT_WS'>nlcv results on weak hetero signal data with t-test feature selection</h2><span id='topic+nlcvTT_WS'></span>

<h3>Description</h3>

<p>This data set contains the <a href="#topic+nlcv">nlcv</a> results of 
selection of features with t-test on a weak hetero signal dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlcvTT_WS
</code></pre>


<h3>Format</h3>

<p><code>nlcv</code> object</p>

<hr>
<h2 id='nldaI'>new MLInterfaces schema for lda from MASS</h2><span id='topic+nldaI'></span>

<h3>Description</h3>

<p>This interface keeps track of the predictions on the training and test set,
contrary to the ldaI interface that is made available in the MLInterfaces
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nldaI
</code></pre>


<h3>Format</h3>

<p>An object of class <code>learnerSchema</code> of length 1.</p>


<h3>Details</h3>

<p>nldaI is an object of class 'learnerSchema' and can be used as such in calls
to MLearn (from MLInterfaces).
</p>


<h3>See Also</h3>

<p>See Also <code><a href="MLInterfaces.html#topic+ldaI">ldaI</a></code>
</p>

<hr>
<h2 id='pamrI'>Instance of a learnerSchema for pamr models</h2><span id='topic+pamrI'></span>

<h3>Description</h3>

<p>This object is an instance of the learnerSchema object and will be typically
used as the <code>method</code> argument of an <code>MLearn</code> call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pamrI
</code></pre>


<h3>Format</h3>

<p>An object of class <code>learnerSchema</code> of length 1.</p>


<h3>Author(s)</h3>

<p>Tobias Verbeke
</p>


<h3>See Also</h3>

<p><code><a href="MLInterfaces.html#topic+MLearn">MLearn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(120)
  x &lt;- matrix(rnorm(1000*20), ncol=20)
  y &lt;- sample(c(1:4), size=20, replace=TRUE)
  alldf &lt;- cbind.data.frame(t(x), y)

  # assure it is a factor (otherwise error message)
  alldf$y &lt;- factor(alldf$y) 
  library(MLInterfaces)
  (mlobj &lt;- MLearn(y ~ .,
      data = alldf,
      .method = pamrI,
      trainInd = 1:15))
</code></pre>

<hr>
<h2 id='pamrIconverter'>convert from <code>pamrML</code> to <code>classifierOutput</code></h2><span id='topic+pamrIconverter'></span>

<h3>Description</h3>

<p>convert from <code>pamrML</code> to <code>classifierOutput</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pamrIconverter(obj, data, trainInd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pamrIconverter_+3A_obj">obj</code></td>
<td>
<p>object as returned by pamrML i.e. of class <code>pamrML</code></p>
</td></tr>
<tr><td><code id="pamrIconverter_+3A_data">data</code></td>
<td>
<p>original data used as input for MLearn</p>
</td></tr>
<tr><td><code id="pamrIconverter_+3A_trainind">trainInd</code></td>
<td>
<p>training indices used as input to MLearn</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>classifierOutput</code>
</p>

<hr>
<h2 id='pamrML'>Wrapper function around the pamr.* functions</h2><span id='topic+pamrML'></span>

<h3>Description</h3>

<p>The pamrML functions are wrappers around <code>pamr.train</code> and
<code>pamr.predict</code> that provide a more classical R modelling interface than
the original versions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pamrML(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pamrML_+3A_formula">formula</code></td>
<td>
<p>model formula</p>
</td></tr>
<tr><td><code id="pamrML_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="pamrML_+3A_...">...</code></td>
<td>
<p>argument for the <code>parmTrain</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The name of the response variable is kept as an attribute in the
<code>pamrML</code> object to allow for predict methods that can be easily used
for writing converter functions for use in the <code>MLInterfaces</code>
framework.
</p>


<h3>Value</h3>

<p>For <code>pamrML</code> an object of class <code>pamrML</code> which adds an
attribute to the original object returned by <code>pamr.train</code> (or
<code>pamrTrain</code>).
</p>
<p>The <code>print</code> method lists the names of the different components of the
<code>pamrML</code> object.
</p>
<p>The <code>predict</code> method returns a vector of predicted values
</p>


<h3>Author(s)</h3>

<p>Tobias Verbeke
</p>


<h3>See Also</h3>

<p><code><a href="pamr.html#topic+pamr.train">pamr.train</a></code>, <code><a href="pamr.html#topic+pamr.predict">pamr.predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(120)
  x &lt;- matrix(rnorm(1000*20), ncol=20)
  y &lt;- sample(c(1:4), size=20, replace=TRUE)
  # for original pam
  mydata &lt;- list(x=x, y=y)
  mytraindata &lt;- list(x=x[,1:15],y=factor(y[1:15]))
  mytestdata &lt;-  list(x = x[,16:20], y = factor(y[16:20]))

  # for formula-based methods including pamrML
  alldf &lt;- cbind.data.frame(t(mydata$x), y)
  traindf &lt;- cbind.data.frame(t(mytraindata$x), y = mytraindata$y)
  testdf &lt;- cbind.data.frame(t(mytestdata$x), y = mytestdata$y)

  ### create pamrML object
  pamrMLObj &lt;- pamrML(y ~ ., traindf)
  pamrMLObj

  ### test predict method
  predict(object = pamrMLObj, newdata = testdf, 
      threshold = 1) # threshold compulsory
</code></pre>

<hr>
<h2 id='pamrTrain'>Function providing a formula interface to pamr.train</h2><span id='topic+pamrTrain'></span>

<h3>Description</h3>

<p>Function that provides a classical R modelling interface, using a
<code>formula</code> and <code>data</code> argument
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pamrTrain(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pamrTrain_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="pamrTrain_+3A_data">data</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="pamrTrain_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code>pamr.train</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object that is perfectly identical to the object returned by
<code>pamr.train</code>
</p>


<h3>Author(s)</h3>

<p>Tobias Verbeke
</p>


<h3>See Also</h3>

<p><code><a href="pamr.html#topic+pamr.train">pamr.train</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(120)
  x &lt;- matrix(rnorm(1000*20), ncol=20)
  y &lt;- sample(c(1:4), size=20, replace=TRUE)
  alldf &lt;- cbind.data.frame(t(x), y)
  pamrTrain(y ~ ., alldf)
</code></pre>

<hr>
<h2 id='predict.pamrML'>predict <code>pamrML</code> object</h2><span id='topic+predict.pamrML'></span>

<h3>Description</h3>

<p>predict <code>pamrML</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pamrML'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.pamrML_+3A_object">object</code></td>
<td>
<p><code>pamrML</code> object</p>
</td></tr>
<tr><td><code id="predict.pamrML_+3A_newdata">newdata</code></td>
<td>
<p>new data</p>
</td></tr>
<tr><td><code id="predict.pamrML_+3A_...">...</code></td>
<td>
<p>additional parameters for the pamr.predict function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>output of the <code>pamr.predict</code> function
</p>

<hr>
<h2 id='print.nlcvConfusionMatrix'>print object <code>nlcvConfusionMatrix</code></h2><span id='topic+print.nlcvConfusionMatrix'></span>

<h3>Description</h3>

<p>print object <code>nlcvConfusionMatrix</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nlcvConfusionMatrix'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.nlcvConfusionMatrix_+3A_x">x</code></td>
<td>
<p>object of class <code>nlcvConfusionMatrix</code></p>
</td></tr>
<tr><td><code id="print.nlcvConfusionMatrix_+3A_...">...</code></td>
<td>
<p>additional parameters for the <code>print</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no returned value, the object is printed in the output
</p>

<hr>
<h2 id='print.pamrML'>print <code>pamrML</code> object</h2><span id='topic+print.pamrML'></span>

<h3>Description</h3>

<p>print <code>pamrML</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pamrML'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pamrML_+3A_x">x</code></td>
<td>
<p>object of class <code>pamrML</code></p>
</td></tr>
<tr><td><code id="print.pamrML_+3A_...">...</code></td>
<td>
<p>additional parameters for the <code>print</code> function</p>
</td></tr>
</table>

<hr>
<h2 id='print.summary.mcrPlot'><code>print</code> function for <code>summary.mcrPlot</code> object</h2><span id='topic+print.summary.mcrPlot'></span>

<h3>Description</h3>

<p><code>print</code> function for <code>summary.mcrPlot</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.mcrPlot'
print(x, digits = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.mcrPlot_+3A_x">x</code></td>
<td>
<p>Object of class 'summary.mcrPlot' as produced by the function of
the same name</p>
</td></tr>
<tr><td><code id="print.summary.mcrPlot_+3A_digits">digits</code></td>
<td>
<p>number of digits to be passed to the default print method</p>
</td></tr>
<tr><td><code id="print.summary.mcrPlot_+3A_...">...</code></td>
<td>
<p>additional parameters for the <code>print.default</code> function</p>
</td></tr>
</table>

<hr>
<h2 id='rankDistributionPlot'>Plot the Distribution of Ranks of Features Across nlcv Runs</h2><span id='topic+rankDistributionPlot'></span>

<h3>Description</h3>

<p>This plot offers an overview of the distribution of the ranks of the n
best-ranked features. The order of the features is determined by the median
rank of the feature across all nlcv runs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankDistributionPlot(nlcvObj, n = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankDistributionPlot_+3A_nlcvobj">nlcvObj</code></td>
<td>
<p>object of class <code>nlcv</code> as produced by the <code>nlcv</code>
function</p>
</td></tr>
<tr><td><code id="rankDistributionPlot_+3A_n">n</code></td>
<td>
<p>number of features for whicht the distribution should be displayed</p>
</td></tr>
<tr><td><code id="rankDistributionPlot_+3A_...">...</code></td>
<td>
<p>additional arguments to the boxplot functions (such as
<code>main</code>, <code>sub</code>, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For each of the n features, a boxplot is displayed.
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{

  data(nlcvRF_SS)
  rankDistributionPlot(nlcvRF_SS, n = 9)
}
</code></pre>

<hr>
<h2 id='rocPlot'>Produce a ROC plot for a classification model belonging to a given technique
and with a given number of features.</h2><span id='topic+rocPlot'></span>

<h3>Description</h3>

<p>Produce a ROC plot for a classification model belonging to a given technique
and with a given number of features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rocPlot(nlcvObj, tech, nfeat, main = NULL, globalAUCcol = "#FF9900", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rocPlot_+3A_nlcvobj">nlcvObj</code></td>
<td>
<p>object of class 'nlcv' as produced by the nlcv function</p>
</td></tr>
<tr><td><code id="rocPlot_+3A_tech">tech</code></td>
<td>
<p>technique; character of length one; one of 'dlda', 'lda',
'nlda', 'qda', 'glm', 'randomForest', 'bagg', 'pam', 'svm' or 'ksvm'</p>
</td></tr>
<tr><td><code id="rocPlot_+3A_nfeat">nfeat</code></td>
<td>
<p>number of features used in the classification model; numeric of
length one</p>
</td></tr>
<tr><td><code id="rocPlot_+3A_main">main</code></td>
<td>
<p>main title to be used for the ROC plot</p>
</td></tr>
<tr><td><code id="rocPlot_+3A_globalauccol">globalAUCcol</code></td>
<td>
<p>color for the global AUC (defaults to '#FF9900')</p>
</td></tr>
<tr><td><code id="rocPlot_+3A_...">...</code></td>
<td>
<p>further arguments for the plot call (such as sub e.g.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ROC plot is drawn to the current device
</p>


<h3>Author(s)</h3>

<p>Tobias Verbeke
</p>

<hr>
<h2 id='scoresPlot'>Function to Plot a Scores Plot</h2><span id='topic+scoresPlot'></span>

<h3>Description</h3>

<p>Function to plot, for a given nested loop cross-validation object, a given
classification technique and a given number of features used for the
classification, the scores plot. This plot diplays the proportion of
correctly-classified per sample across all runs of the nested loop
cross-validation. The class membership of the samples is displayed using a
colored strip (with legend below the plot).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoresPlot(nlcvObj, tech, nfeat, plot = TRUE, barPlot = FALSE,
  layout = TRUE, main = NULL, sub = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoresPlot_+3A_nlcvobj">nlcvObj</code></td>
<td>
<p>Object of class 'nlcv' as produced by the <code>nlcv</code>
function</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_tech">tech</code></td>
<td>
<p>string denoting the classification technique used; one of
'dlda', 'bagg', 'pam', 'rf', or 'svm'.</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_nfeat">nfeat</code></td>
<td>
<p>integer giving the number of features; this number should be
part of the initial set of number of features that was specified during the
nested loop cross-validation (<code>nFeatures</code> argument of the <code>nlcv</code>
function)</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_plot">plot</code></td>
<td>
<p>logical.  If <code>FALSE</code>, nothing is plotted.</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_barplot">barPlot</code></td>
<td>
<p>Should a barplot be drawn (<code>TRUE</code>) or the alternative
MCREstimate-type scores plot (the default, <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_layout">layout</code></td>
<td>
<p>boolean indicating whether <code>mcrPlot</code> should prespecify a
layout for a single plot (default, <code>TRUE</code>) or whetherl the user takes
care of the layout (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_main">main</code></td>
<td>
<p>Main title for the scores plot; if not supplied, 'Scores Plot'
is used as a default</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_sub">sub</code></td>
<td>
<p>Subtitle for the scores plot; if not supplied, the classification
technique and the chosen number of features are displayed</p>
</td></tr>
<tr><td><code id="scoresPlot_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters to pass to the plot function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scores plot is displayed (for the device specified).
</p>
<p>The function invisibly returns a named vector containing (for each sample)
the proportion of times the sample was correctly classified (for a given
technique and a given number of features used).
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>

<hr>
<h2 id='summary.mcrPlot'><code>summary</code> function for <code>mcrPlot</code> object</h2><span id='topic+summary.mcrPlot'></span>

<h3>Description</h3>

<p><code>summary</code> function for <code>mcrPlot</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mcrPlot'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mcrPlot_+3A_object">object</code></td>
<td>
<p>Object of class 'mcrPlot' as produced by the function of the
same name</p>
</td></tr>
<tr><td><code id="summary.mcrPlot_+3A_...">...</code></td>
<td>
<p>additional arguments, not used here</p>
</td></tr>
</table>

<hr>
<h2 id='topTable-methods'>Methods for topTable</h2><span id='topic+topTable-methods'></span><span id='topic+topTable'></span><span id='topic+topTable+2Cnlcv-method'></span>

<h3>Description</h3>

<p>Methods for topTable. topTable extracts the top n most important features
for a given classification or regression procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'nlcv'
topTable(fit, n = 5, method = "percentage")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="topTable-methods_+3A_fit">fit</code></td>
<td>
<p>object resulting from a classification or regression procedure</p>
</td></tr>
<tr><td><code id="topTable-methods_+3A_n">n</code></td>
<td>
<p>number of features that one wants to extract from a table that
ranks all features according to their importance in the classification or
regression model</p>
</td></tr>
<tr><td><code id="topTable-methods_+3A_method">method</code></td>
<td>
<p>method used to rank the features; one of <code>percentage</code>
(percentage of runs the feature is selected in the top n), <code>meanrank</code>
(mean rank of the feature across runs) or <code>medianrank</code> (median rank of
the feature across runs); <code>percentage</code> is the default method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The top n features are extracted across all runs of the nested loop
cross-validation. After ranking on their frequency of selection, the top n
are retained and returned.
</p>


<h3>Value</h3>

<p>a data frame of one column (<code>percentage</code>) with percentages
reflecting the frequency of selection of a feature in the top n across all
runs; the features are sorted on decreasing frequency.
</p>


<h3>Methods</h3>


<p>nlcv
</p>
<dl>
<dt>fit = &quot;nlcv&quot;</dt><dd><p>nlcv objects are produced by <code>nlcv</code></p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  data(nlcvRF_SS)
  topTable(nlcvRF_SS, n = 7, method = "medianrank")
</code></pre>

<hr>
<h2 id='xtable.confusionMatrix'>xtable method for confusionMatrix objects</h2><span id='topic+xtable.confusionMatrix'></span>

<h3>Description</h3>

<p>xtable method for confusionMatrix objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'confusionMatrix'
xtable(x, caption = NULL, label = NULL,
  align = NULL, digits = NULL, display = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xtable.confusionMatrix_+3A_x">x</code></td>
<td>
<p>object of class 'confusionMatrix' as produced by the
<code>confusionMatrix</code></p>
</td></tr>
<tr><td><code id="xtable.confusionMatrix_+3A_caption">caption</code></td>
<td>
<p>LaTeX caption, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.confusionMatrix_+3A_label">label</code></td>
<td>
<p>LaTeX label, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.confusionMatrix_+3A_align">align</code></td>
<td>
<p>alignment specification, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.confusionMatrix_+3A_digits">digits</code></td>
<td>
<p>number of digits to display, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.confusionMatrix_+3A_display">display</code></td>
<td>
<p>format of the columns, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.confusionMatrix_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>xtable</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>LaTeX table representing the confusion matrix
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>


<h3>See Also</h3>

<p><code><a href="caret.html#topic+confusionMatrix">confusionMatrix</a></code>, <code><a href="xtable.html#topic+xtable">xtable</a></code>
</p>

<hr>
<h2 id='xtable.summary.mcrPlot'>xtable method for summary.mcrPlot objects</h2><span id='topic+xtable.summary.mcrPlot'></span>

<h3>Description</h3>

<p>xtable method for summary.mcrPlot objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.mcrPlot'
xtable(x, caption = NULL, label = NULL,
  align = NULL, digits = NULL, display = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xtable.summary.mcrPlot_+3A_x">x</code></td>
<td>
<p>object of class 'summary.mcrPlot' as produced by the
<code>summary.mcrPlot</code></p>
</td></tr>
<tr><td><code id="xtable.summary.mcrPlot_+3A_caption">caption</code></td>
<td>
<p>LaTeX caption, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.summary.mcrPlot_+3A_label">label</code></td>
<td>
<p>LaTeX label, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.summary.mcrPlot_+3A_align">align</code></td>
<td>
<p>alignment specification, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.summary.mcrPlot_+3A_digits">digits</code></td>
<td>
<p>number of digits to display, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.summary.mcrPlot_+3A_display">display</code></td>
<td>
<p>format of the columns, see the <code>xtable</code> help page</p>
</td></tr>
<tr><td><code id="xtable.summary.mcrPlot_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>xtable</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>LaTeX table representing the summary of the mcrPlot output, i.e.
the optimal number of features, the mean MCR and the standard deviation on
the MCR for each of the classification methods used.
</p>


<h3>Author(s)</h3>

<p>Willem Talloen and Tobias Verbeke
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.mcrPlot">summary.mcrPlot</a></code>, <code><a href="#topic+mcrPlot">mcrPlot</a></code>,
<code><a href="xtable.html#topic+xtable">xtable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  data(nlcvRF_SS)
  mp &lt;- mcrPlot(nlcvRF_SS, plot = FALSE)
  smp &lt;- summary(mp)
  xtable(smp)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
