<!DOCTYPE html><html><head><title>Help for package finnts</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {finnts}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ensemble_models'><p>Ensemble Models</p></a></li>
<li><a href='#final_models'><p>Final Models</p></a></li>
<li><a href='#forecast_time_series'><p>Finn Forecast Framework</p></a></li>
<li><a href='#get_forecast_data'><p>Get Final Forecast Data</p></a></li>
<li><a href='#get_prepped_data'><p>Get Prepped Data</p></a></li>
<li><a href='#get_prepped_models'><p>Get Prepped Model Info</p></a></li>
<li><a href='#get_run_info'><p>Get run info</p></a></li>
<li><a href='#get_trained_models'><p>Get Final Trained Models</p></a></li>
<li><a href='#list_models'><p>List all available models</p></a></li>
<li><a href='#prep_data'><p>Prep Data</p></a></li>
<li><a href='#prep_models'><p>Prep Models</p></a></li>
<li><a href='#set_run_info'><p>Set up finnts submission</p></a></li>
<li><a href='#train_models'><p>Train Individual Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Microsoft Finance Time Series Forecasting Framework</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Automated time series forecasting developed by Microsoft Finance. The Microsoft Finance Time 
    Series Forecasting Framework, aka Finn, can be used to forecast any component of the income 
    statement, balance sheet, or any other area of interest by finance. Any numerical quantity over time, 
    Finn can be used to forecast it. While it can be applied outside of the finance domain, Finn was built 
    to meet the needs of financial analysts to better forecast their businesses within a company, and has 
    a lot of built in features that are specific to the needs of financial forecasters. Happy forecasting!</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://microsoft.github.io/finnts/">https://microsoft.github.io/finnts/</a>,
<a href="https://github.com/microsoft/finnts">https://github.com/microsoft/finnts</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/microsoft/finnts/issues">https://github.com/microsoft/finnts/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli, Cubist, dials, digest, doParallel, dplyr, earth, feasts,
foreach, fs, generics, glue, glmnet, gtools, hts, kernlab,
lubridate, magrittr, methods, parallel, parsnip, plyr, purrr,
recipes, rsample, rules, snakecase, stringr, tibble, tidyr,
tidyselect, timetk, tune, vroom, workflows</td>
</tr>
<tr>
<td>Suggests:</td>
<td>arrow (&ge; 8.0.0), AzureStor, Boruta, corrr, knitr,
Microsoft365R, notebookutils, qs, reactable, rmarkdown,
sparklyr, testthat (&ge; 3.0.0), vip</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0), modeltime</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-30 18:00:33 UTC; mitokic</td>
</tr>
<tr>
<td>Author:</td>
<td>Mike Tokic <a href="https://orcid.org/0000-0002-7630-7055"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Aadharsh Kannan <a href="https://orcid.org/0000-0002-6475-8211"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mike Tokic &lt;mftokic@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-01 09:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ensemble_models'>Ensemble Models</h2><span id='topic+ensemble_models'></span>

<h3>Description</h3>

<p>Create ensemble model forecasts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ensemble_models(
  run_info,
  parallel_processing = NULL,
  inner_parallel = FALSE,
  num_cores = NULL,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ensemble_models_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function</p>
</td></tr>
<tr><td><code id="ensemble_models_+3A_parallel_processing">parallel_processing</code></td>
<td>
<p>Default of NULL runs no parallel processing and
forecasts each individual time series one after another. 'local_machine'
leverages all cores on current machine Finn is running on. 'spark'
runs time series in parallel on a spark cluster in Azure Databricks or
Azure Synapse.</p>
</td></tr>
<tr><td><code id="ensemble_models_+3A_inner_parallel">inner_parallel</code></td>
<td>
<p>Run components of forecast process inside a specific
time series in parallel. Can only be used if parallel_processing is
set to NULL or 'spark'.</p>
</td></tr>
<tr><td><code id="ensemble_models_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to run when parallel processing is set up.
Used when running parallel computations on local machine or within Azure.
Default of NULL uses total amount of cores on machine minus one. Can't
be greater than number of cores on machine minus 1.</p>
</td></tr>
<tr><td><code id="ensemble_models_+3A_seed">seed</code></td>
<td>
<p>Set seed for random number generator. Numeric value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Ensemble model outputs are written to disk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    Date &gt;= "2013-01-01",
    Date &lt;= "2015-06-01",
    id == "M750"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3
)

prep_models(run_info,
  models_to_run = c("arima", "glmnet"),
  num_hyperparameters = 2
)

train_models(run_info,
  run_global_models = FALSE
)

ensemble_models(run_info)

</code></pre>

<hr>
<h2 id='final_models'>Final Models</h2><span id='topic+final_models'></span>

<h3>Description</h3>

<p>Select Best Models and Prep Final Outputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>final_models(
  run_info,
  average_models = TRUE,
  max_model_average = 3,
  weekly_to_daily = TRUE,
  parallel_processing = NULL,
  inner_parallel = FALSE,
  num_cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="final_models_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function.</p>
</td></tr>
<tr><td><code id="final_models_+3A_average_models">average_models</code></td>
<td>
<p>If TRUE, create simple averages of individual models.</p>
</td></tr>
<tr><td><code id="final_models_+3A_max_model_average">max_model_average</code></td>
<td>
<p>Max number of models to average together. Will
create model averages for 2 models up until input value or max number of
models ran.</p>
</td></tr>
<tr><td><code id="final_models_+3A_weekly_to_daily">weekly_to_daily</code></td>
<td>
<p>If TRUE, convert a week forecast down to day by
evenly splitting across each day of week. Helps when aggregating
up to higher temporal levels like month or quarter.</p>
</td></tr>
<tr><td><code id="final_models_+3A_parallel_processing">parallel_processing</code></td>
<td>
<p>Default of NULL runs no parallel processing and
forecasts each individual time series one after another. 'local_machine'
leverages all cores on current machine Finn is running on. 'spark'
runs time series in parallel on a spark cluster in Azure Databricks or
Azure Synapse.</p>
</td></tr>
<tr><td><code id="final_models_+3A_inner_parallel">inner_parallel</code></td>
<td>
<p>Run components of forecast process inside a specific
time series in parallel. Can only be used if parallel_processing is
set to NULL or 'spark'.</p>
</td></tr>
<tr><td><code id="final_models_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to run when parallel processing is set up.
Used when running parallel computations on local machine or within Azure.
Default of NULL uses total amount of cores on machine minus one. Can't be
greater than number of cores on machine minus 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Final model outputs are written to disk.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    Date &gt;= "2013-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3
)

prep_models(run_info,
  models_to_run = c("arima", "ets"),
  back_test_scenarios = 3
)

train_models(run_info,
  run_global_models = FALSE
)

final_models(run_info)

</code></pre>

<hr>
<h2 id='forecast_time_series'>Finn Forecast Framework</h2><span id='topic+forecast_time_series'></span>

<h3>Description</h3>

<p>Calls the Finn forecast framework to automatically forecast any historical time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forecast_time_series(
  run_info = NULL,
  input_data,
  combo_variables,
  target_variable,
  date_type,
  forecast_horizon,
  external_regressors = NULL,
  hist_start_date = NULL,
  hist_end_date = NULL,
  combo_cleanup_date = NULL,
  fiscal_year_start = 1,
  clean_missing_values = TRUE,
  clean_outliers = FALSE,
  back_test_scenarios = NULL,
  back_test_spacing = NULL,
  modeling_approach = "accuracy",
  forecast_approach = "bottoms_up",
  parallel_processing = NULL,
  inner_parallel = FALSE,
  num_cores = NULL,
  target_log_transformation = FALSE,
  negative_forecast = FALSE,
  fourier_periods = NULL,
  lag_periods = NULL,
  rolling_window_periods = NULL,
  recipes_to_run = NULL,
  pca = NULL,
  models_to_run = NULL,
  models_not_to_run = NULL,
  run_global_models = NULL,
  run_local_models = TRUE,
  run_ensemble_models = NULL,
  average_models = TRUE,
  max_model_average = 3,
  feature_selection = FALSE,
  weekly_to_daily = TRUE,
  seed = 123,
  run_model_parallel = FALSE,
  return_data = TRUE,
  run_name = "finnts_forecast"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forecast_time_series_+3A_run_info">run_info</code></td>
<td>
<p>Run info using <code><a href="#topic+set_run_info">set_run_info()</a></code></p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_input_data">input_data</code></td>
<td>
<p>A data frame or tibble of historical time series data. Can also include external regressors for both
historical and future data.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_combo_variables">combo_variables</code></td>
<td>
<p>List of column headers within input data to be used to separate individual time series.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_target_variable">target_variable</code></td>
<td>
<p>The column header formatted as a character value within input data you want to forecast.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_date_type">date_type</code></td>
<td>
<p>The date granularity of the input data. Finn accepts the following as a character string
day, week, month, quarter, year.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_forecast_horizon">forecast_horizon</code></td>
<td>
<p>Number of periods to forecast into the future.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_external_regressors">external_regressors</code></td>
<td>
<p>List of column headers within input data to be used as features in multivariate models.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_hist_start_date">hist_start_date</code></td>
<td>
<p>Date value of when your input_data starts. Default of NULL is to use earliest date value in
input_data.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_hist_end_date">hist_end_date</code></td>
<td>
<p>Date value of when your input_data ends.Default of NULL is to use the latest date value in
input_data.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_combo_cleanup_date">combo_cleanup_date</code></td>
<td>
<p>Date value to remove individual time series that don't contain non-zero values after
that specified date. Default of NULL is to not remove any time series and attempt to forecast all of them.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_fiscal_year_start">fiscal_year_start</code></td>
<td>
<p>Month number of start of fiscal year of input data, aids in building out date features.
Formatted as a numeric value. Default of 1 assumes fiscal year starts in January.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_clean_missing_values">clean_missing_values</code></td>
<td>
<p>If TRUE, cleans missing values. Only impute values for missing data within an
existing series, and does not add new values onto the beginning or end, but does provide a value of 0 for said
values. Turned off when running hierarchical forecasts.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_clean_outliers">clean_outliers</code></td>
<td>
<p>If TRUE, outliers are cleaned and inputted with values more in line with historical data</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_back_test_scenarios">back_test_scenarios</code></td>
<td>
<p>Number of specific back test folds to run when determining the best model.
Default of NULL will automatically choose the number of back tests to run based on historical data size,
which tries to always use a minimum of 80% of the data when training a model.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_back_test_spacing">back_test_spacing</code></td>
<td>
<p>Number of periods to move back for each back test scenario. Default of NULL moves back 1
period at a time for year, quarter, and month data. Moves back 4 for week and 7 for day data.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_modeling_approach">modeling_approach</code></td>
<td>
<p>How Finn should approach your data. Current default and only option is 'accuracy'. In the
future this could evolve to other areas like optimizing for interpretability over accuracy.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_forecast_approach">forecast_approach</code></td>
<td>
<p>How the forecast is created. The default of 'bottoms_up' trains models for each individual
time series. 'grouped_hierarchy' creates a grouped time series to forecast at while 'standard_hierarchy' creates
a more traditional hierarchical time series to forecast, both based on the hts package.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_parallel_processing">parallel_processing</code></td>
<td>
<p>Default of NULL runs no parallel processing and
forecasts each individual time series one after another. 'local_machine'
leverages all cores on current machine Finn is running on. 'spark'
runs time series in parallel on a spark cluster in Azure Databricks or
Azure Synapse.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_inner_parallel">inner_parallel</code></td>
<td>
<p>Run components of forecast process inside a specific
time series in parallel. Can only be used if parallel_processing is
set to NULL or 'spark'.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to run when parallel processing is set up. Used when running parallel computations
on local machine or within Azure. Default of NULL uses total amount of cores on machine minus one. Can't be greater
than number of cores on machine minus 1.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_target_log_transformation">target_log_transformation</code></td>
<td>
<p>If TRUE, log transform target variable before training models.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_negative_forecast">negative_forecast</code></td>
<td>
<p>If TRUE, allow forecasts to dip below zero.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_fourier_periods">fourier_periods</code></td>
<td>
<p>List of values to use in creating fourier series as features. Default of NULL automatically chooses
these values based on the date_type.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_lag_periods">lag_periods</code></td>
<td>
<p>List of values to use in creating lag features. Default of NULL automatically chooses these values
based on date_type.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_rolling_window_periods">rolling_window_periods</code></td>
<td>
<p>List of values to use in creating rolling window features. Default of NULL automatically
chooses these values based on date type.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_recipes_to_run">recipes_to_run</code></td>
<td>
<p>List of recipes to run on multivariate models that can run different recipes. A value of NULL runs
all recipes, but only runs the R1 recipe for weekly and daily date types, and also for global models to prevent memory issues.
A value of &quot;all&quot; runs all recipes, regardless of date type or if it's a local/global model. A list like c(&quot;R1&quot;) or c(&quot;R2&quot;)
would only run models with the R1 or R2 recipe.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_pca">pca</code></td>
<td>
<p>If TRUE, run principle component analysis on any lagged features to speed up model run time. Default of NULL runs
PCA on day and week date types across all local multivariate models, and also for global models across all date types.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_models_to_run">models_to_run</code></td>
<td>
<p>List of models to run. Default of NULL runs all models.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_models_not_to_run">models_not_to_run</code></td>
<td>
<p>List of models not to run, overrides values in models_to_run. Default of NULL doesn't turn off
any model.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_run_global_models">run_global_models</code></td>
<td>
<p>If TRUE, run multivariate models on the entire data set (across all time series) as a global model.
Can be override by models_not_to_run. Default of NULL runs global models for all date types except week and day.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_run_local_models">run_local_models</code></td>
<td>
<p>If TRUE, run models by individual time series as local models.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_run_ensemble_models">run_ensemble_models</code></td>
<td>
<p>If TRUE, run ensemble models. Default of NULL runs ensemble models only for quarter and month
date types.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_average_models">average_models</code></td>
<td>
<p>If TRUE, create simple averages of individual models.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_max_model_average">max_model_average</code></td>
<td>
<p>Max number of models to average together. Will create model averages for 2 models up until input value
or max number of models ran.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_feature_selection">feature_selection</code></td>
<td>
<p>Implement feature selection before model training</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_weekly_to_daily">weekly_to_daily</code></td>
<td>
<p>If TRUE, convert a week forecast down to day by evenly splitting across each day of week. Helps when aggregating
up to higher temporal levels like month or quarter.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_seed">seed</code></td>
<td>
<p>Set seed for random number generator. Numeric value.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_run_model_parallel">run_model_parallel</code></td>
<td>
<p>If TRUE, runs model training in parallel, only works when parallel_processing is set to
'local_machine' or 'spark'. Recommended to use a value of FALSE and leverage
inner_parallel for new features.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_return_data">return_data</code></td>
<td>
<p>If TRUE, return the forecast results. Used to be backwards compatible
with previous finnts versions. Recommended to use a value of FALSE and leverage
<code><a href="#topic+get_forecast_data">get_forecast_data()</a></code> for new features.</p>
</td></tr>
<tr><td><code id="forecast_time_series_+3A_run_name">run_name</code></td>
<td>
<p>Name used when submitting jobs to external compute like Azure Batch. Formatted as a character string.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of three separate data sets: the future forecast, the back test results, and the best model per time series.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

run_info &lt;- set_run_info()

finn_forecast &lt;- forecast_time_series(
  run_info = run_info,
  input_data = m750 %&gt;% dplyr::rename(Date = date),
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3,
  back_test_scenarios = 6,
  run_model_parallel = FALSE,
  models_to_run = c("arima", "ets", "snaive"),
  return_data = FALSE
)

fcst_tbl &lt;- get_forecast_data(run_info)

models_tbl &lt;- get_trained_models(run_info)

</code></pre>

<hr>
<h2 id='get_forecast_data'>Get Final Forecast Data</h2><span id='topic+get_forecast_data'></span>

<h3>Description</h3>

<p>Get Final Forecast Data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_forecast_data(run_info, return_type = "df")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_forecast_data_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function</p>
</td></tr>
<tr><td><code id="get_forecast_data_+3A_return_type">return_type</code></td>
<td>
<p>return type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>table of final forecast results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    id == "M2",
    Date &gt;= "2012-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3,
  recipes_to_run = "R1"
)

prep_models(run_info,
  models_to_run = c("arima", "ets"),
  num_hyperparameters = 1
)

train_models(run_info,
  run_local_models = TRUE
)

final_models(run_info,
  average_models = FALSE
)

fcst_tbl &lt;- get_forecast_data(run_info)

</code></pre>

<hr>
<h2 id='get_prepped_data'>Get Prepped Data</h2><span id='topic+get_prepped_data'></span>

<h3>Description</h3>

<p>Get Prepped Data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_prepped_data(run_info, recipe, return_type = "df")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_prepped_data_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function</p>
</td></tr>
<tr><td><code id="get_prepped_data_+3A_recipe">recipe</code></td>
<td>
<p>recipe to return. Either a value of &quot;R1&quot; or &quot;R2&quot;</p>
</td></tr>
<tr><td><code id="get_prepped_data_+3A_return_type">return_type</code></td>
<td>
<p>return type</p>
</td></tr>
</table>


<h3>Value</h3>

<p>table of prepped data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    id == "M2",
    Date &gt;= "2012-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3,
  recipes_to_run = "R1"
)

R1_prepped_data_tbl &lt;- get_prepped_data(run_info,
  recipe = "R1"
)

</code></pre>

<hr>
<h2 id='get_prepped_models'>Get Prepped Model Info</h2><span id='topic+get_prepped_models'></span>

<h3>Description</h3>

<p>Get Prepped Model Info
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_prepped_models(run_info)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_prepped_models_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>table with data related to model workflows, hyperparameters, and back testing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    id == "M2",
    Date &gt;= "2012-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3,
  recipes_to_run = "R1"
)

prep_models(run_info,
  models_to_run = c("arima", "ets"),
  num_hyperparameters = 1
)

prepped_models_tbl &lt;- get_prepped_models(run_info = run_info)

</code></pre>

<hr>
<h2 id='get_run_info'>Get run info</h2><span id='topic+get_run_info'></span>

<h3>Description</h3>

<p>Lets you get all of the logging associated with a specific experiment or run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_run_info(
  experiment_name = NULL,
  run_name = NULL,
  storage_object = NULL,
  path = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_run_info_+3A_experiment_name">experiment_name</code></td>
<td>
<p>Name used to group similar runs under a
single experiment name.</p>
</td></tr>
<tr><td><code id="get_run_info_+3A_run_name">run_name</code></td>
<td>
<p>Name to distinguish one run of Finn from another.
The current time in UTC is appended to the run name to ensure
a unique run name is created.</p>
</td></tr>
<tr><td><code id="get_run_info_+3A_storage_object">storage_object</code></td>
<td>
<p>Used to store outputs during a run to other
storage services in Azure. Could be a storage container object from
the 'AzureStor' package to connect to ADLS blob storage or a
OneDrive/SharePoint object from the 'Microsoft365R' package to connect
to a OneDrive folder or SharePoint site. Default of NULL will save outputs
to the local file system.</p>
</td></tr>
<tr><td><code id="get_run_info_+3A_path">path</code></td>
<td>
<p>String showing what file path the outputs should be written to.
Default of NULL will write the outputs to a temporary directory within R,
which will delete itself after the R session closes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame of run log information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
run_info &lt;- set_run_info(
  experiment_name = "finn_forecast",
  run_name = "test_run"
)

run_info_tbl &lt;- get_run_info(
  experiment_name = "finn_forecast"
)

</code></pre>

<hr>
<h2 id='get_trained_models'>Get Final Trained Models</h2><span id='topic+get_trained_models'></span>

<h3>Description</h3>

<p>Get Final Trained Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_trained_models(run_info)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_trained_models_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>table of final trained models
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    id == "M2",
    Date &gt;= "2012-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3,
  recipes_to_run = "R1"
)

prep_models(run_info,
  models_to_run = c("arima", "ets"),
  num_hyperparameters = 1
)

train_models(run_info,
  run_global_models = FALSE,
  run_local_models = TRUE
)

final_models(run_info,
  average_models = FALSE
)

models_tbl &lt;- get_trained_models(run_info)

</code></pre>

<hr>
<h2 id='list_models'>List all available models</h2><span id='topic+list_models'></span>

<h3>Description</h3>

<p>List all available models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_models()
</code></pre>


<h3>Value</h3>

<p>list of models
</p>

<hr>
<h2 id='prep_data'>Prep Data</h2><span id='topic+prep_data'></span>

<h3>Description</h3>

<p>Preps data with various feature engineering recipes to create features before training models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_data(
  run_info,
  input_data,
  combo_variables,
  target_variable,
  date_type,
  forecast_horizon,
  external_regressors = NULL,
  hist_start_date = NULL,
  hist_end_date = NULL,
  combo_cleanup_date = NULL,
  fiscal_year_start = 1,
  clean_missing_values = TRUE,
  clean_outliers = FALSE,
  box_cox = TRUE,
  stationary = TRUE,
  forecast_approach = "bottoms_up",
  parallel_processing = NULL,
  num_cores = NULL,
  target_log_transformation = FALSE,
  fourier_periods = NULL,
  lag_periods = NULL,
  rolling_window_periods = NULL,
  recipes_to_run = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prep_data_+3A_run_info">run_info</code></td>
<td>
<p>Run info using <code><a href="#topic+set_run_info">set_run_info()</a></code></p>
</td></tr>
<tr><td><code id="prep_data_+3A_input_data">input_data</code></td>
<td>
<p>A standard data frame, tibble, or spark data frame using sparklyr of historical time series data.
Can also include external regressors for both historical and future data.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_combo_variables">combo_variables</code></td>
<td>
<p>List of column headers within input data to be used to separate individual time series.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_target_variable">target_variable</code></td>
<td>
<p>The column header formatted as a character value within input data you want to forecast.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_date_type">date_type</code></td>
<td>
<p>The date granularity of the input data. Finn accepts the following as a character string:
day, week, month, quarter, year.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_forecast_horizon">forecast_horizon</code></td>
<td>
<p>Number of periods to forecast into the future.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_external_regressors">external_regressors</code></td>
<td>
<p>List of column headers within input data to be used as features in multivariate models.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_hist_start_date">hist_start_date</code></td>
<td>
<p>Date value of when your input_data starts. Default of NULL uses earliest date value in
input_data.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_hist_end_date">hist_end_date</code></td>
<td>
<p>Date value of when your input_data ends. Default of NULL uses the latest date value in
input_data.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_combo_cleanup_date">combo_cleanup_date</code></td>
<td>
<p>Date value to remove individual time series that don't contain non-zero values after
that specified date. Default of NULL is to not remove any time series and attempt to forecast all time series.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_fiscal_year_start">fiscal_year_start</code></td>
<td>
<p>Month number of start of fiscal year of input data, aids in building out date features.
Formatted as a numeric value. Default of 1 assumes fiscal year starts in January.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_clean_missing_values">clean_missing_values</code></td>
<td>
<p>If TRUE, cleans missing values. Only impute values for missing data within an
existing series, and does not add new values onto the beginning or end, but does provide a value of 0 for said
values.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_clean_outliers">clean_outliers</code></td>
<td>
<p>If TRUE, outliers are cleaned and inputted with values more in line with historical data.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_box_cox">box_cox</code></td>
<td>
<p>Apply box-cox transformation to normalize variance in data</p>
</td></tr>
<tr><td><code id="prep_data_+3A_stationary">stationary</code></td>
<td>
<p>Apply differencing to make data stationary</p>
</td></tr>
<tr><td><code id="prep_data_+3A_forecast_approach">forecast_approach</code></td>
<td>
<p>How the forecast is created. The default of 'bottoms_up' trains models for each individual
time series. Value of 'grouped_hierarchy' creates a grouped time series to forecast at while 'standard_hierarchy' creates
a more traditional hierarchical time series to forecast, both based on the hts package.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_parallel_processing">parallel_processing</code></td>
<td>
<p>Default of NULL runs no parallel processing and forecasts each individual time series
one after another. Value of 'local_machine' leverages all cores on current machine Finn is running on.
Value of 'spark' runs time series in parallel on a spark cluster in Azure Databricks/Synapse.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to run when parallel processing is set up. Used when running parallel computations
on local machine or within Azure. Default of NULL uses total amount of cores on machine minus one. Can't be greater
than number of cores on machine minus 1.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_target_log_transformation">target_log_transformation</code></td>
<td>
<p>If TRUE, log transform target variable before training models.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_fourier_periods">fourier_periods</code></td>
<td>
<p>List of values to use in creating fourier series as features. Default of NULL automatically chooses
these values based on the date_type.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_lag_periods">lag_periods</code></td>
<td>
<p>List of values to use in creating lag features. Default of NULL automatically chooses these values
based on date_type.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_rolling_window_periods">rolling_window_periods</code></td>
<td>
<p>List of values to use in creating rolling window features. Default of NULL automatically
chooses these values based on date_type.</p>
</td></tr>
<tr><td><code id="prep_data_+3A_recipes_to_run">recipes_to_run</code></td>
<td>
<p>List of recipes to run on multivariate models that can run different recipes. A value of NULL runs
all recipes, but only runs the R1 recipe for weekly and daily date types. A value of &quot;all&quot; runs all recipes, regardless
of date type. A list like c(&quot;R1&quot;) or c(&quot;R2&quot;) would only run models with the R1 or R2 recipe.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return object. Feature engineered data is written to disk based on the output locations provided in
<code><a href="#topic+set_run_info">set_run_info()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    Date &gt;= "2013-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3,
  recipes_to_run = "R1"
)

</code></pre>

<hr>
<h2 id='prep_models'>Prep Models</h2><span id='topic+prep_models'></span>

<h3>Description</h3>

<p>Preps various aspects of run before training models. Things like train/test
splits, creating hyperparameters, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_models(
  run_info,
  back_test_scenarios = NULL,
  back_test_spacing = NULL,
  models_to_run = NULL,
  models_not_to_run = NULL,
  run_ensemble_models = TRUE,
  pca = NULL,
  num_hyperparameters = 10,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prep_models_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_back_test_scenarios">back_test_scenarios</code></td>
<td>
<p>Number of specific back test folds to run when
determining the best model. Default of NULL will automatically choose
the number of back tests to run based on historical data size,
which tries to always use a minimum of 80% of the data when training a model.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_back_test_spacing">back_test_spacing</code></td>
<td>
<p>Number of periods to move back for each back
test scenario. Default of NULL moves back 1 period at a time for year,
quarter, and month data. Moves back 4 for week and 7 for day data.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_models_to_run">models_to_run</code></td>
<td>
<p>List of models to run. Default of NULL runs all models.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_models_not_to_run">models_not_to_run</code></td>
<td>
<p>List of models not to run, overrides values in
models_to_run. Default of NULL doesn't turn off any model.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_run_ensemble_models">run_ensemble_models</code></td>
<td>
<p>If TRUE, prep for ensemble models.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_pca">pca</code></td>
<td>
<p>If TRUE, run principle component analysis on any lagged features
to speed up model run time. Default of NULL runs PCA on day and week
date types across all local multivariate models, and also for global models
across all date types.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_num_hyperparameters">num_hyperparameters</code></td>
<td>
<p>number of hyperparameter combinations to test
out on validation data for model tuning.</p>
</td></tr>
<tr><td><code id="prep_models_+3A_seed">seed</code></td>
<td>
<p>Set seed for random number generator. Numeric value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Writes outputs related to model prep to disk.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    Date &gt;= "2012-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3
)

prep_models(run_info,
  models_to_run = c("arima", "ets", "glmnet")
)

</code></pre>

<hr>
<h2 id='set_run_info'>Set up finnts submission</h2><span id='topic+set_run_info'></span>

<h3>Description</h3>

<p>Creates list object of information helpful in logging information
about your run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_run_info(
  experiment_name = "finn_fcst",
  run_name = "finn_fcst",
  storage_object = NULL,
  path = NULL,
  data_output = "csv",
  object_output = "rds",
  add_unique_id = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_run_info_+3A_experiment_name">experiment_name</code></td>
<td>
<p>Name used to group similar runs under a
single experiment name.</p>
</td></tr>
<tr><td><code id="set_run_info_+3A_run_name">run_name</code></td>
<td>
<p>Name to distinguish one run of Finn from another.
The current time in UTC is appended to the run name to ensure
a unique run name is created.</p>
</td></tr>
<tr><td><code id="set_run_info_+3A_storage_object">storage_object</code></td>
<td>
<p>Used to store outputs during a run to other
storage services in Azure. Could be a storage container object from
the 'AzureStor' package to connect to ADLS blob storage or a
OneDrive/SharePoint object from the 'Microsoft365R' package to connect
to a OneDrive folder or SharePoint site. Default of NULL will save outputs
to the local file system.</p>
</td></tr>
<tr><td><code id="set_run_info_+3A_path">path</code></td>
<td>
<p>String showing what file path the outputs should be written to.
Default of NULL will write the outputs to a temporary directory within R,
which will delete itself after the R session closes.</p>
</td></tr>
<tr><td><code id="set_run_info_+3A_data_output">data_output</code></td>
<td>
<p>String value describing the file type for data outputs.
Default will write data frame outputs as csv files. The other option
of 'parquet' will instead write parquet files.</p>
</td></tr>
<tr><td><code id="set_run_info_+3A_object_output">object_output</code></td>
<td>
<p>String value describing the file type for object
outputs. Default will write object outputs like trained models as
rds files. The other option of 'qs' will instead serialize R objects
as qs files by using the 'qs' package.</p>
</td></tr>
<tr><td><code id="set_run_info_+3A_add_unique_id">add_unique_id</code></td>
<td>
<p>Add a unique id to end of run_name based on submission time.
Set to FALSE to supply your own unique run name, which is helpful in
multistage ML pipelines.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of run information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
run_info &lt;- set_run_info(
  experiment_name = "test_exp",
  run_name = "test_run_1"
)

</code></pre>

<hr>
<h2 id='train_models'>Train Individual Models</h2><span id='topic+train_models'></span>

<h3>Description</h3>

<p>Train Individual Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_models(
  run_info,
  run_global_models = FALSE,
  run_local_models = TRUE,
  global_model_recipes = c("R1"),
  feature_selection = FALSE,
  negative_forecast = FALSE,
  parallel_processing = NULL,
  inner_parallel = FALSE,
  num_cores = NULL,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_models_+3A_run_info">run_info</code></td>
<td>
<p>run info using the <code><a href="#topic+set_run_info">set_run_info()</a></code> function</p>
</td></tr>
<tr><td><code id="train_models_+3A_run_global_models">run_global_models</code></td>
<td>
<p>If TRUE, run multivariate models on the entire data
set (across all time series) as a global model. Can be override by
models_not_to_run. Default of NULL runs global models for all date types
except week and day.</p>
</td></tr>
<tr><td><code id="train_models_+3A_run_local_models">run_local_models</code></td>
<td>
<p>If TRUE, run models by individual time series as
local models.</p>
</td></tr>
<tr><td><code id="train_models_+3A_global_model_recipes">global_model_recipes</code></td>
<td>
<p>Recipes to use in global models.</p>
</td></tr>
<tr><td><code id="train_models_+3A_feature_selection">feature_selection</code></td>
<td>
<p>Implement feature selection before model training</p>
</td></tr>
<tr><td><code id="train_models_+3A_negative_forecast">negative_forecast</code></td>
<td>
<p>If TRUE, allow forecasts to dip below zero.</p>
</td></tr>
<tr><td><code id="train_models_+3A_parallel_processing">parallel_processing</code></td>
<td>
<p>Default of NULL runs no parallel processing and
forecasts each individual time series one after another. 'local_machine'
leverages all cores on current machine Finn is running on. 'spark'
runs time series in parallel on a spark cluster in Azure Databricks or
Azure Synapse.</p>
</td></tr>
<tr><td><code id="train_models_+3A_inner_parallel">inner_parallel</code></td>
<td>
<p>Run components of forecast process inside a specific
time series in parallel. Can only be used if parallel_processing is
set to NULL or 'spark'.</p>
</td></tr>
<tr><td><code id="train_models_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to run when parallel processing is set up.
Used when running parallel computations on local machine or within Azure.
Default of NULL uses total amount of cores on machine minus one. Can't be
greater than number of cores on machine minus 1.</p>
</td></tr>
<tr><td><code id="train_models_+3A_seed">seed</code></td>
<td>
<p>Set seed for random number generator. Numeric value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>trained model outputs are written to disk.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data_tbl &lt;- timetk::m4_monthly %&gt;%
  dplyr::rename(Date = date) %&gt;%
  dplyr::mutate(id = as.character(id)) %&gt;%
  dplyr::filter(
    Date &gt;= "2013-01-01",
    Date &lt;= "2015-06-01"
  )

run_info &lt;- set_run_info()

prep_data(run_info,
  input_data = data_tbl,
  combo_variables = c("id"),
  target_variable = "value",
  date_type = "month",
  forecast_horizon = 3
)

prep_models(run_info,
  models_to_run = c("arima", "glmnet"),
  num_hyperparameters = 2,
  back_test_scenarios = 6,
  run_ensemble_models = FALSE
)

train_models(run_info)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
