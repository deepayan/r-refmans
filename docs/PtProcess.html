<!DOCTYPE html><html><head><title>Help for package PtProcess</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PtProcess}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Change Log'><p>Changes Made to the Package</p></a></li>
<li><a href='#distribution'><p>General Notes on Distribution Fitting</p></a></li>
<li><a href='#dpareto'><p>Pareto and Tapered Pareto Distributions</p></a></li>
<li><a href='#etas_gif'>
<p>Ground Intensity for ETAS Model</p></a></li>
<li><a href='#gif'><p>General Notes on Ground Intensity Functions</p></a></li>
<li><a href='#HiddenMarkov-internal'><p>Internally Used Functions</p></a></li>
<li><a href='#linksrm'><p>Linked Stress Release Model Object</p></a></li>
<li><a href='#linksrm_convert'>
<p>Parameter Conversion for Linked Stress Release Model</p></a></li>
<li><a href='#linksrm_gif'>
<p>Ground Intensity for Linked Stress Release Model</p></a></li>
<li><a href='#logLik'><p>Log Likelihood of a Point Process Model</p></a></li>
<li><a href='#makeSOCKcluster'><p>Parallel Processing: Transition Functions</p></a></li>
<li><a href='#marks'><p>Mark Distributions</p></a></li>
<li><a href='#mpp'><p>Marked Point Process Object</p></a></li>
<li><a href='#neglogLik'><p>Negative Log-Likelihood</p></a></li>
<li><a href='#NthChina'><p>Historical Earthquakes of North China</p></a></li>
<li><a href='#Ogata'>
<p>Ogata's ETAS Test Data</p></a></li>
<li><a href='#Phuket'><p>Phuket Earthquake and Aftershock Sequence</p></a></li>
<li><a href='#plot'><p>Plot Point Process Ground Intensity Function</p></a></li>
<li><a href='#PtProcess-package'><p>Overview of PtProcess Package</p></a></li>
<li><a href='#residuals'><p>Residuals of a Point Process Model</p></a></li>
<li><a href='#simple_gif'>
<p>Non-Homogeneous Poisson Processes</p></a></li>
<li><a href='#simulate'><p>Simulate a Point Process</p></a></li>
<li><a href='#srm_gif'>
<p>Conditional Intensity for Stress Release Model</p></a></li>
<li><a href='#summary'><p>Summary of a Point Process Model</p></a></li>
<li><a href='#Tangshan'><p>Tangshan Earthquake and Aftershock Sequence</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>3.3-16</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-05-02</td>
</tr>
<tr>
<td>Title:</td>
<td>Time Dependent Point Process Modelling</td>
</tr>
<tr>
<td>Author:</td>
<td>David Harte</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Harte &lt;d.s.harte@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits and analyses time dependent marked point process models with an emphasis on earthquake modelling. For a more detailed introduction to the package, see the topic "PtProcess". A list of recent changes can be found in the topic "Change Log".</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel</td>
</tr>
<tr>
<td>LazyData:</td>
<td>no</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.statsresearch.co.nz/dsh/sslib/">https://www.statsresearch.co.nz/dsh/sslib/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-02 06:44:30 UTC; david</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-03 18:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Change+20Log'>Changes Made to the Package</h2><span id='topic+Changes'></span>

<h3>Description</h3>

<p>This page contains a listing of recent changes made to functions, and known general problems.
</p>


<h3>Recent Changes</h3>


<ol>
<li><p> Version 3 contains major changes, and code that worked in Version 2 will no longer work in Version 3. The models included in Version 2 are also contained in Version 3, but the framework has been extended so that the original models can now contain a variety of mark distributions. This has been achieved by giving a more general structure and utilising the object orientated aspects of the <span class="rlang"><b>R</b></span> language. <em>Examples are given below that show how models were defined in Version 2 and how the corresponding models are now defined in Version 3.</em> (28 Apr 2008)
</p>
</li>
<li><p> Naming changes to the <code>*.cif</code> functions. In Version 2, these were referred to as &ldquo;conditional intensity functions&rdquo;, which is really a slightly more general class. In keeping with Daley &amp; Vere-Jones (2003) we now call them ground intensity functions, with a suffix of &ldquo;gif&rdquo;. Further, the dot has been replaced by an underscore, e.g. <code>etas.cif</code> to <code>etas_gif</code>. This is to lessen the possibility of future conflicts with object orientated naming conventions in the <span class="rlang"><b>R</b></span> language. (28 Apr 2008)
</p>
</li>
<li><p> Arguments <code>eval.pts</code> and <code>t.plus</code> in the ground intensity functions have been renamed to <code>evalpts</code> and <code>tplus</code>, respectively. This is to lessen the possibility of future conflicts with object orientated naming conventions in the <span class="rlang"><b>R</b></span> language. (28 Apr 2008)
</p>
</li>
<li> <p><code><a href="#topic+logLik">logLik</a></code>: the log-likelihood calculated in package Versions before Version 3 did not have the sum over the mark density term (see topic <code><a href="#topic+logLik">logLik</a></code>, under &ldquo;Details&rdquo;). This term can also be excluded in this Version of the package by placing <code>NULL</code> for the mark density in the <code><a href="#topic+mpp">mpp</a></code> object, see example below. (28 Apr 2008)
</p>
</li>
<li><p> Version 2 had a framework to assign prior densities to the estimated parameters. This has not been retained in Version 3. However, some of the features like holding a parameter at a fixed value, and restricting it to an open or closed interval can be achieved in Version 3; see <code><a href="#topic+neglogLik">neglogLik</a></code> for further details. (28 Apr 2008)
</p>
</li>
<li> <p><code><a href="#topic+neglogLik">neglogLik</a></code>: the format of this function has been changed to be consistent with that in package <span class="pkg">HiddenMarkov</span>. Argument <code>updatep</code> renamed as <code>pmap</code>. (07 Aug 2008)
</p>
</li>
<li> <p><code><a href="#topic+simulate">simulate</a></code>: manual page revised to include more information about controlling the length of the simulated series. (18 Nov 2008)
</p>
</li>
<li> <p><code><a href="#topic+mpp">mpp</a></code>: example modified due to warning messages caused by negative <code class="reqn">\lambda_g(t|{\cal H}_t)</code>. (18 Nov 2008)
</p>
</li>
<li> <p><code><a href="#topic+marks">marks</a></code>: manual page revised to include more information. (18 Nov 2008)
</p>
</li>
<li> <p><code><a href="#topic+mpp">mpp</a></code>: fuller description to argument <code>marks</code> on manual page. (19 Nov 2008)
</p>
</li>
<li> <p><code><a href="#topic+Phuket">Phuket</a></code>: new dataset added. (4 Dec 2008)
</p>
</li>
<li> <p><code><a href="#topic+linksrm_gif">linksrm_gif</a></code>, <code><a href="#topic+marks">marks</a></code>: remove some LaTeX specific formatting to be compatible with <span class="rlang"><b>R</b></span> 2.9.0. (26 Jan 2009)
</p>
</li>
<li> <p><code><a href="#topic+Phuket">Phuket</a></code>: clarify magnitude scale used in the dataset. (11 Jul 2009)
</p>
</li>
<li><p> Attribute <code>type</code> is no longer required on the <code><a href="#topic+gif">gif</a></code> functions, removed. (7 Oct 2009)
</p>
</li>
<li> <p><code><a href="#topic+logLik">logLik</a></code>, <code><a href="#topic+neglogLik">neglogLik</a></code>: Parallel processing support, using package <span class="pkg">snow</span>, has been added. (8 Oct 2009)
</p>
</li>
<li> <p><code><a href="#topic+plot">plot</a></code>: Correct hyperlink to generic plot function. (10 Oct 2009)
</p>
</li>
<li> <p><code>etas_normal0</code>: New function. Test version of a spatial ETAS conditional intensity function. (12 Oct 2009)
</p>
</li>
<li> <p><code><a href="#topic+logLik">logLik</a></code>: Fixed bug when using parallel processing on only two nodes. (22 Oct 2009)
</p>
</li>
<li><p> Tidied HTML representation of equations in manual pages. Removal of &ldquo;synopsis&rdquo; on manual pages of functions with multiple forms of usage. (26 Jan 2010)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mpp">logLik.mpp</a></code>, <code><a href="#topic+summary.mpp">summary.mpp</a></code>: Changed to <code><a href="base.html#topic+inherits">inherits</a></code> to determine class. (27 Jan 2010)
</p>
</li>
<li> <p><code><a href="#topic+Phuket">Phuket</a></code>: Additional data, until the beginning of 2009, have been added. The magnitude is now the maximum of the body wave and surface wave magnitudes, <code class="reqn">m_b</code> and <code class="reqn">M_s</code>, respectively. Earlier it was simply <code class="reqn">m_b</code>. (01 Feb 2010)
</p>
</li>
<li> <p><code><a href="#topic+simulate.linksrm">simulate.linksrm</a></code>, <code><a href="#topic+simulate.mpp">simulate.mpp</a></code>, <code><a href="#topic+logLik.mpp">logLik.mpp</a></code>: Inconsistency in nomenclature between &ldquo;mark&rdquo; and &ldquo;marks&rdquo;, will standardise on the plural. (07 May 2010)
</p>
</li>
<li> <p><code><a href="#topic+simulate.mpp">simulate.mpp</a></code>: Two bugs: <br />
<code>use &lt;- (data[, "time"] &lt; TT[1])</code> changed to <code>use &lt;- (data[, "time"] &lt;= TT[1])</code>, <br />
and <code>else data &lt;- data[use, c("time", "magnitude")]</code> changed to <br />
<code>else data &lt;- data[use, ]</code>. (18 Jun 2010)
</p>
</li>
<li> <p><code>etas_normal0</code>: Errors in some terms involving <code>beta</code>. (18 Jun 2010)
</p>
</li>
<li><p> Minor citation and reference inclusion changes to manual pages. (19 Jul 2010)
</p>
</li>
<li> <p><code><a href="#topic+simulate.mpp">simulate.mpp</a></code>: Bug fix on 18 June 2010 induced another bug;<br />
<code>data &lt;- rbind(data, newevent)</code> changed to<br />
<code>data &lt;- rbind(data[, names(newevent)], newevent)</code>. (11 Dec 2010)
</p>
</li>
<li><p> Implement very basic NAMESPACE. (5 Nov 2011)
</p>
</li>
<li><p> List functions explicitly in NAMESPACE; &ldquo;<code>LazyData: no</code>&rdquo; and &ldquo;<code>ZipData: no</code>&rdquo; in DESCRIPTION file. (9 Dec 2011)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mpp">logLik.mpp</a></code>: Enable one to specify the relative CPU speeds of the nodes when parallel processing. (9 Dec 2011)
</p>
</li>
<li> <p><code><a href="#topic+mpp">mpp</a></code> and <code>etas_normal0</code>: Restrict the number of iterations in examples on manual pages to minimise time during package checks. (13 Dec 2011)
</p>
</li>
<li> <p><code><a href="#topic+residuals">residuals</a></code> and <code><a href="#topic+linksrm">linksrm</a></code>: Include example using cusum of residuals on manual page. (15 Dec 2011)
</p>
</li>
<li> <p><code><a href="#topic+dpareto">dpareto</a></code>, <code><a href="#topic+dtappareto">dtappareto</a></code>, <code><a href="#topic+ltappareto">ltappareto</a></code> (etc): Include parameter consistency checks. (6 Jan 2014)
</p>
</li>
<li> <p><code><a href="#topic+etas_gif">etas_gif</a></code>: Documentation example error: <code>marks=list(rmagn_mark, rmagn_mark)</code> should be <code>marks=list(dmagn_mark, NULL)</code>. (23 Jan 2014)
</p>
</li>
<li> <p><code>linksrm1_gif</code>: Function deleted, alternative discussed on manual page of <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>. (19 Mar 2014)
</p>
</li>
<li><p> Correct html problem in &lsquo;<span class="file">inst/doc/index.html</span>&rsquo;. (14 Aug 2014)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mpp">logLik.mpp</a></code>: Call to <code>clusterApply</code> changed to <code>snow::clusterApply</code>. (20 Aug 2014)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mpp">logLik.mpp</a></code>: The package <span class="pkg">snow</span> has been superseded by <span class="pkg">parallel</span>. Change <code>snow</code> to <code>parallel</code>, also in file &lsquo;<span class="file">DESCRIPTION</span>&rsquo;. (15 Oct 2014)
</p>
</li>
<li> <p><code><a href="#topic+makeSOCKcluster">makeSOCKcluster</a></code>: This function is in <span class="pkg">snow</span> but not in <span class="pkg">parallel</span>. This function points to the closest eqivalent in <span class="pkg">parallel</span>, <code><a href="parallel.html#topic+makePSOCKcluster">makePSOCKcluster</a></code>. <code><a href="#topic+makeSOCKcluster">makeSOCKcluster</a></code> will eventually become deprecated. Was added to the export list in file &lsquo;<span class="file">NAMESPACE</span>&rsquo; too. (15 Oct 2014)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mpp">logLik.mpp</a></code>, <code><a href="#topic+neglogLik">neglogLik</a></code>: Update consistent with changes from <span class="pkg">snow</span> to <span class="pkg">parallel</span>. (17 Oct 2014)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mpp">logLik.mpp</a></code>: Change <code>require(parallel)</code> to <code>requireNamespace("parallel")</code>. (21 Jan 2015)
</p>
</li>
<li><p> Added to NAMESPACE: <br />
<code>importFrom(graphics, plot)</code> <br />
<code>importFrom(stats, dexp, integrate, logLik, pnorm,</code> <br />
<code>           qexp, rexp, runif, simulate, ts)</code> <br />
(03 Jul 2015)
</p>
</li>
<li> <p><code><a href="#topic+PtProcess">PtProcess</a></code>: Add DOI to some references, rename topic to appear first in table of contents. (16 Oct 2015)
</p>
</li>
<li> <p><code><a href="#topic+plot.mpp">plot.mpp</a></code>: Activate argument <code>ylim</code>. (17 Aug 2016)
</p>
</li>
<li> <p><code>etas_normal0</code>: This has been removed. Adding a spatial dimension requires more generality in other package functions like <code><a href="#topic+logLik.mpp">logLik.mpp</a></code>. For a reasonable amount of generality, it requires the addition of new model class, currently under development. (01 Sep 2016)
</p>
</li>
<li> <p><code><a href="#topic+simulate.mpp">simulate.mpp</a></code>: Did not allow argument <code>marks = list(NULL, NULL)</code> in <code><a href="#topic+mpp">mpp</a></code> object. <br /> <code>simulate.mpp</code> now tests to see if <code>NULL</code> marks. (17 Nov 2017)
</p>
</li>
<li> <p><code><a href="#topic+fourier_gif">fourier_gif</a></code>: Example added on manual page with <code>NULL</code> marks. (17 Nov 2017)
</p>
</li>
<li> <p><code><a href="#topic+Phuket">Phuket</a></code>: Hyperlink to data source updated, others updated to https where possible. (24 Apr 2021)
</p>
</li></ol>


<h3>Future Development</h3>


<ol>
<li><p> Currently spatial versions of the ETAS model are being written and tested.
</p>
</li>
<li><p> In the model object, allow one to alternatively specify the <code>name</code> of the gif function.
</p>
</li>
<li><p> Function <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>: Use of <code>St1</code> and <code>St2</code>. Is there a tidier way? Also utilise this feature in <code><a href="#topic+srm_gif">srm_gif</a></code>.
</p>
</li>
<li><p> Want a generic function, possibly called <code>forecast</code>, to produce probability forecasts. This would be based on simulating empirical probability distributions.
</p>
</li>
<li><p> Want a function like <code><a href="#topic+linksrm_convert">linksrm_convert</a></code> to map between the two main parametrisations of the ETAS model.
</p>
</li>
<li><p> Add general forms of the truncated exponential and gamma distributions as marks for the magnitude of the event.
</p>
</li>
<li><p> A tidy way to pass the values of the <code>gif</code> function into the mark distributions, if required.
</p>
</li></ol>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    SRM: magnitude is iid exponential with bvalue=1
#    simulate and calculate the log-likelihood

TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-1.5, 0.01, 0.8, bvalue*log(10))

#   --- Old Method ---
# x &lt;- pp.sim(NULL, params[1:3], srm.cif, TT, seed=5, magn.sim=1)
# print(pp.LL(x, srm.cif, params[1:3], TT))
# [1] -601.3941

#   --- New Method, no mark density ---
x1 &lt;- mpp(data=NULL,
          gif=srm_gif,
          marks=list(NULL, rexp_mark),
          params=params,
          gmap=expression(params[1:3]),
          mmap=expression(params[4]),
          TT=TT)
x1 &lt;- simulate(x1, seed=5)
print(logLik(x1))

#  An advantage of the object orientated format is that it
#  simplifies further analysis, e.g. plot intensity function:
plot(x1)
#  plot the residual process:
plot(residuals(x1))

#---------------------------------------------------
#    SRM: magnitude is iid exponential with bvalue=1
#    simulate then estimate parameters from data

#   --- Old Method ---
# TT &lt;- c(0, 1000)
# bvalue &lt;- 1
# params &lt;- c(-2.5, 0.01, 0.8)
#
# x &lt;- pp.sim(NULL, params, srm.cif, TT, seed=5, magn.sim=1)
#
# posterior &lt;- make.posterior(x, srm.cif, TT)
#
# neg.posterior &lt;- function(params){
#     x &lt;- -posterior(params)
#     if (is.infinite(x) | is.na(x)) return(1e15)
#     else return(x)
# }
#
# z &lt;- nlm(neg.posterior, params, typsize=abs(params),
#          iterlim=1000, print.level=2)
#
# print(z$estimate)
# [1] -2.83900091  0.01242595  0.78880647

#   --- New Method, no mark density ---
#   maximise only SRM parameters (like old method)

TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

x1 &lt;- mpp(data=NULL,
          gif=srm_gif,
          marks=list(dexp_mark, rexp_mark),
          params=params,
          gmap=expression(params[1:3]),
          mmap=expression(params[4]),
          TT=TT)
#  note that dexp_mark above is not used below
#  and could alternatively be replaced by NULL

x1 &lt;- simulate(x1, seed=5)

#  maximise only SRM parameters
onlysrm &lt;- function(y, p){
    #  maps srm parameters into model object
    #  the exp rate for magnitudes is unchanged
    y$params[1:3] &lt;- p
    return(y)
}

params &lt;- c(-2.5, 0.01, 0.8)

z1 &lt;- nlm(neglogLik, params, object=x1, pmap=onlysrm,
          print.level=2, iterlim=500, typsize=abs(params))
print(z1$estimate)
</code></pre>

<hr>
<h2 id='distribution'>General Notes on Distribution Fitting</h2><span id='topic+distribution'></span>

<h3>Description</h3>

<p>This page contains general notes about fitting probability distributions to datasets.
</p>


<h3>Details</h3>

<p>We give examples of how the maximum likelihood parameters can be estimated using standard optimisation routines provided in the <span class="rlang"><b>R</b></span> software (<code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code>). We simply numerically maximise the sum of the logarithms of the density evaluated at each of the data points, i.e. log-likelihood function. In fact, by default, the two mentioned optimizers find the <em>minimum</em>, and hence we minimise the negative log-likelihood function.
</p>
<p>Both optimization routines require initial starting values. The optimisation function <code><a href="stats.html#topic+optim">optim</a></code> uses a grid search technique, and is therefore more robust to poor starting values. The function <code><a href="stats.html#topic+nlm">nlm</a></code> uses derivatives and the Hessian to determine the size and direction of the next step, which is generally more sensitive to poor initial values, but faster in the neighbourhood of the solution. One possible strategy is to start with <code><a href="stats.html#topic+optim">optim</a></code> and then use its solution as a starting value for <code><a href="stats.html#topic+nlm">nlm</a></code>. This is done below in the example for the tapered Pareto distribution.
</p>
<p>The function <code><a href="stats.html#topic+nlm">nlm</a></code> numerically calculates the Hessian and derivatives, by default. If the surface is very flat, the numerical error involved may be larger in size than the actual gradient. In this case the process will work better if analytic derivatives are supplied. This is done in the tapered Pareto example below. Alternatively, one could simply use the Newton-Raphson algorithm (again, see the tapered Pareto example below).
</p>
<p>We also show that parameters can be constrained to be positive (or negative) by transforming the parameters with the exponential function during the maximisation procedure. Similarly, parameters can be restricted to a finite interval by using a modified logit transform during the maximisation procedure. The advantage of using these transformations is that the entire real line is mapped onto the positive real line or the required finite interval, respectively; and further, they are differentiable and monotonic. This eliminates the &ldquo;hard&rdquo; boundaries which are sometimes enforced by using a penalty function when the estimation procedure strays into the forbidden region. The addition of such penalty functions causes the function that is being optimised to be non-differentiable at the boundaries, which can cause considerable problems with the optimisation routines.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    Random number generation method
RNGkind("Mersenne-Twister", "Inversion")
set.seed(5)

#--------------------------------------------
#    Exponential Distribution

#    simulate a sample
p &lt;- 1
x &lt;- rexp(n=1000, rate=p)

#    Transform to a log scale so that -infty &lt; log(p) &lt; infty.
#    Hence no hard boundary, and p &gt; 0.
#    If LL is beyond machine precision, LL &lt;- 1e20.

neg.LL &lt;- function(logp, data){
    x &lt;- -sum(log(dexp(data, rate=exp(logp))))
    if (is.infinite(x)) x &lt;- 1e20
    return(x)
}

p0 &lt;- 5
logp0 &lt;- log(p0)
z &lt;- nlm(neg.LL, logp0, print.level=0, data=x)
print(exp(z$estimate))

#    Compare to closed form solution
print(exp(z$estimate)-1/mean(x))

#--------------------------------------------
#    Normal Distribution

#    simulate a sample
x &lt;- rnorm(n=1000, mean=0, sd=1)

neg.LL &lt;- function(p, data){
    x &lt;- -sum(log(dnorm(data, mean=p[1], sd=exp(p[2]))))
    if (is.infinite(x)) x &lt;- 1e20
    return(x)
}

p0 &lt;- c(2, log(2))
z &lt;- nlm(neg.LL, p0, print.level=0, data=x)
p1 &lt;- c(z$estimate[1], exp(z$estimate[2]))
print(p1)

#    Compare to closed form solution
print(p1 - c(mean(x), sd(x)))

#--------------------------------------------
#    Gamma Distribution
#    shape &gt; 0 and rate &gt; 0
#    use exponential function to ensure above constraints

#    simulate a sample
x &lt;- rgamma(n=2000, shape=1, rate=5)

neg.LL &lt;- function(p, data){
    #   give unreasonable values a very high neg LL, i.e. low LL
    if (any(exp(p) &gt; 1e15)) x &lt;- 1e15
    else{
        x &lt;- -sum(log(dgamma(data, shape=exp(p[1]), rate=exp(p[2]))))
        if (is.infinite(x)) x &lt;- 1e15
    }
    return(x)
}

p0 &lt;- c(2, 2)
z &lt;- optim(p0, neg.LL, data=x)
print(exp(z$par))

z &lt;- nlm(neg.LL, p0, print.level=0, data=x)
print(exp(z$estimate))

#--------------------------------------------
#    Beta Distribution
#    shape1 &gt; 0 and shape2 &gt; 0
#    use exponential function to ensure above constraints

#    simulate a sample
x &lt;- rbeta(n=5000, shape1=0.5, shape2=0.2)

#    exclude those where x=0
x &lt;- x[x!=1]

neg.LL &lt;- function(p, data)
    -sum(log(dbeta(data, shape1=exp(p[1]), shape2=exp(p[2]))))

p0 &lt;- log(c(0.1, 0.1))

z &lt;- optim(p0, neg.LL, data=x)
print(exp(z$par))

z &lt;- nlm(neg.LL, p0, typsize=c(0.01, 0.01), print.level=0, data=x)
print(exp(z$estimate))

#--------------------------------------------
#    Weibull Distribution
#    shape &gt; 0 and scale &gt; 0
#    use exponential function to ensure above constraints

#    simulate a sample
x &lt;- rweibull(n=2000, shape=2, scale=1)

neg.LL &lt;- function(p, data)
    -sum(log(dweibull(data, shape=exp(p[1]), scale=exp(p[2]))))

p0 &lt;- log(c(0.1, 0.1))
z &lt;- optim(p0, neg.LL, data=x)
print(exp(z$par))

#--------------------------------------------
#    Pareto Distribution
#    lambda &gt; 0
#    Use exponential function to enforce constraint

#    simulate a sample
x &lt;- rpareto(n=2000, lambda=2, a=1)

neg.LL &lt;- function(p, data){
    #   give unreasonable values a very high neg LL, i.e. low LL
    if (exp(p) &gt; 1e15) x &lt;- 1e15
    else x &lt;- -sum(log(dpareto(data, lambda=exp(p), a=1)))
    if (is.infinite(x)) x &lt;- 1e15
    return(x)
}

p0 &lt;- log(0.1)
z &lt;- nlm(neg.LL, p0, print.level=0, data=x)
print(exp(z$estimate))

#--------------------------------------------
#    Tapered Pareto Distribution
#    lambda &gt; 0  and  theta &gt; 0

# simulate a sample
x &lt;- rtappareto(n=2000, lambda=2, theta=4, a=1) 

neg.LL &lt;- function(p, data){
    x &lt;- -ltappareto(data, lambda=p[1], theta=p[2], a=1)
    attr(x, "gradient") &lt;- -attr(x, "gradient")
    attr(x, "hessian") &lt;- -attr(x, "hessian")
    return(x)
}

#   use optim to get approx initial value 
p0 &lt;- c(3, 5)
z1 &lt;- optim(p0, neg.LL, data=x) 
p1 &lt;- z1$par
print(p1)
print(neg.LL(p1, x))

#   nlm with analytic gradient and hessian
z2 &lt;- nlm(neg.LL, p1, data=x, hessian=TRUE) 
p2 &lt;- z2$estimate
print(z2)

#    Newton Raphson Method
p3 &lt;- p1
iter &lt;- 0
repeat{
    LL &lt;- ltappareto(data=x, lambda=p3[1], theta=p3[2], a=1)
    p3 &lt;- p3 - as.numeric(solve(attr(LL,"hessian")) %*% 
                 matrix(attr(LL,"gradient"), ncol=1))
    iter &lt;- iter + 1
    if ((max(abs(attr(LL,"gradient"))) &lt; 1e-8) |
        (iter &gt; 100)) break
}
print(iter)
print(LL)
print(p3)
</code></pre>

<hr>
<h2 id='dpareto'>Pareto and Tapered Pareto Distributions</h2><span id='topic+dpareto'></span><span id='topic+ppareto'></span><span id='topic+qpareto'></span><span id='topic+rpareto'></span><span id='topic+dtappareto'></span><span id='topic+ltappareto'></span><span id='topic+ptappareto'></span><span id='topic+qtappareto'></span><span id='topic+rtappareto'></span>

<h3>Description</h3>

<p>Density, cumulative probability, quantiles and random number generation for the Pareto and tapered Pareto distributions with shape parameter <code class="reqn">\lambda</code>, tapering parameter <code class="reqn">\theta</code> and range <code class="reqn">a \le x &lt; \infty</code>; and log-likelihood of the tapered Pareto distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpareto(x, lambda, a, log=FALSE)
ppareto(q, lambda, a, lower.tail=TRUE, log.p=FALSE)
qpareto(p, lambda, a, lower.tail=TRUE, log.p=FALSE)
rpareto(n, lambda, a)

dtappareto(x, lambda, theta, a, log=FALSE)
ltappareto(data, lambda, theta, a)
ptappareto(q, lambda, theta, a, lower.tail=TRUE, log.p=FALSE)
qtappareto(p, lambda, theta, a, lower.tail=TRUE, log.p=FALSE,
           tol=1e-8)
rtappareto(n, lambda, theta, a)

ltappareto(data, lambda, theta, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpareto_+3A_x">x</code>, <code id="dpareto_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_data">data</code></td>
<td>
<p>vector of sample data.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_n">n</code></td>
<td>
<p>number of observations to simulate.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_lambda">lambda</code></td>
<td>
<p>shape parameter, see Details below.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_theta">theta</code></td>
<td>
<p>tapering parameter, see Details below..</p>
</td></tr>
<tr><td><code id="dpareto_+3A_a">a</code></td>
<td>
<p>the random variable takes values on the interval <code class="reqn">a \le x &lt; \infty</code>. This is a scalar and is assumed to be a constant for all values in a given function call.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_log">log</code>, <code id="dpareto_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities <code>p</code> are given as <code>log(p)</code>.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are <code class="reqn">\Pr\{X \le x\}</code>, otherwise, <code class="reqn">\Pr\{X &gt; x\}</code>.</p>
</td></tr>
<tr><td><code id="dpareto_+3A_tol">tol</code></td>
<td>
<p>convergence criteria for the Newton Raphson algorithm for solving the quantiles of the tapered Pareto distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For all functions except <code>ltappareto</code>, arguments <code>lambda</code> and <code>theta</code> can either be scalars or vectors of the same length as <code>x</code>, <code>p</code>, or <code>q</code>. If a scalar, then this value is assumed to hold over all cases. If a vector, then the values are assumed to have a one to one relationship with the values in <code>x</code>, <code>p</code>, or <code>q</code>. The argument <code>a</code> is a scalar.
</p>
<p>In the case of <code>ltappareto</code>, all <code>data</code> are assumed to be drawn from the same distribution and hence <code>lambda</code>, <code>theta</code> and <code>a</code> are all scalars.
</p>
<p>Let <code class="reqn">Y</code> be an exponential random variable with parameter <code class="reqn">\lambda &gt; 0</code>. Then the distribution function of <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">
F_Y(y) = \Pr\{Y &lt; y \} = 1 - \exp(-\lambda y),
</code>
</p>

<p>and the density function is
</p>
<p style="text-align: center;"><code class="reqn">
f_Y(y) = \lambda \exp(-\lambda y).
</code>
</p>

<p>Further, the mean and variance of the distribution of <code class="reqn">Y</code> is <code class="reqn">1/\lambda</code> and <code class="reqn">1/\lambda^2</code>, respectively.
</p>
<p>Now transform <code class="reqn">Y</code> as
</p>
<p style="text-align: center;"><code class="reqn">
X = a \exp(Y),
</code>
</p>

<p>where <code class="reqn">a&gt;0</code>. Then <code class="reqn">X</code> is a Pareto random variable with shape parameter <code class="reqn">\lambda</code> and distribution function
</p>
<p style="text-align: center;"><code class="reqn">
F_X(x) = \Pr\{X &lt; x \} = 1 - \left( \frac{a}{x} \right)^\lambda,
</code>
</p>

<p>where <code class="reqn">a \le x &lt; \infty</code>, and density function
</p>
<p style="text-align: center;"><code class="reqn">
f_X(x) = \frac{\lambda}{a} \left( \frac{a}{x} \right)^{\lambda+1}.
</code>
</p>

<p>We simulate the Pareto deviates by generating exponential deviates, and then transforming as described above.
</p>
<p>As above, let <code class="reqn">X</code> be Pareto with shape parameter <code class="reqn">\lambda</code>, and define <code class="reqn">W - a</code> to be exponential with parameter <code class="reqn">1/\theta</code>, i.e.
</p>
<p style="text-align: center;"><code class="reqn">
\Pr\{X &gt; x\} = \left( \frac{a}{x} \right)^\lambda
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
\Pr\{W &gt; w\} = \exp\left( \frac{a - w}{\theta} \right),
</code>
</p>

<p>where <code class="reqn">a \le w &lt; \infty</code>. Say we sample one independent value from each of the distributions <code class="reqn">X</code> and <code class="reqn">W</code>, then
</p>
<p style="text-align: center;"><code class="reqn">
\Pr\{X &gt; z\ \&amp;\ W &gt; z\} = \Pr\{X &gt; z\} \Pr\{ W &gt; z\} = \left( \frac{a}{z} \right)^\lambda \exp\left( \frac{a - z}{\theta} \right).
</code>
</p>

<p>We say that <code class="reqn">Z</code> has a tapered Pareto distribution if it has the above distribution, i.e.
</p>
<p style="text-align: center;"><code class="reqn">
F_Z(z) = \Pr\{Z &lt; z\} = 1- \left( \frac{a}{z} \right)^\lambda \exp\left( \frac{a - z}{\theta} \right).
</code>
</p>

<p>The above relationship shows that a tapered Pareto deviate can be simulated by generating independent values of <code class="reqn">X</code> and <code class="reqn">W</code>, and then letting <code class="reqn">Z = \min(X, W)</code>. This minimum has the effect of &ldquo;tapering&rdquo; the tail of the Pareto distribution.
</p>
<p>The tapered Pareto variable <code class="reqn">Z</code> has density
</p>
<p style="text-align: center;"><code class="reqn">
f_Z(z) = \left( \frac{\lambda}{z} + \frac{1}{\theta} \right) \left( \frac{a}{z} \right)^\lambda \exp\left( \frac{a - z}{\theta} \right).
</code>
</p>

<p>Given a sample of data <code class="reqn">z_1, z_2, \cdots, z_n</code>, we write the log-likelihood as
</p>
<p style="text-align: center;"><code class="reqn">
\log L = \sum_{i=1}^n \log f_Z(z_i).
</code>
</p>

<p>Hence the gradients are calculated as
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial \log L}{\partial \lambda} = \theta \sum_{i=1}^n \frac{1}{\lambda \theta + z_i} - \sum_{i=1}^n \log(z_i/a)
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial \log L}{\partial \theta} = \frac{-1}{\theta} \sum_{i=1}^n \frac{z_i}{\lambda \theta + z_i} - \frac{1}{\theta^2} \sum_{i=1}^n (a - z_i).
</code>
</p>

<p>Further, the Hessian is calculated using
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial^2 \log L}{\partial \lambda^2} = -\theta^2 \sum_{i=1}^n \frac{1}{(\lambda \theta + z_i)^2},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
\frac{\partial^2 \log L}{\partial \theta^2} = \frac{1}{\theta^2} \sum_{i=1}^n \frac{z_i(2\lambda\theta + z_i)}{(\lambda \theta + z_i)^2} - \frac{2}{\theta^3} \sum_{i=1}^n (a - z_i),
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\partial^2 \log L}{\partial \theta \, \partial \lambda} = \frac{\partial^2 \log L}{\partial \lambda \, \partial \theta} = \sum_{i=1}^n \frac{z_i}{(\lambda \theta + z_i)^2}.
</code>
</p>

<p>See the section &ldquo;Seismological Context&rdquo; (below), which outlines its application in Seismology.
</p>


<h3>Value</h3>

<p><code>dpareto</code> and <code>dtappareto</code> give the densities; <code>ppareto</code> and <code>ptappareto</code> give the distribution functions; <code>qpareto</code> and <code>qtappareto</code> give the quantile functions; and <code>rpareto</code> and <code>rtappareto</code> generate random deviates.
</p>
<p><code>ltappareto</code> returns the log-likelihood of a sample using the tapered Pareto distribution. It also calculates, using analytic expressions (see &ldquo;Details&rdquo;), the derivatives and Hessian which are attached to the log-likelihood value as the attributes <code>"gradient"</code> and <code>"hessian"</code>, respectively.
</p>


<h3>Seismological Context</h3>

<p>The Gutenberg-Richter (GR) Law says that if we plot the base 10 logarithm of the number of events with magnitude greater than <code class="reqn">M</code> (vertical axis) against <code class="reqn">M</code> (horizontal axis), there should be a straight line. This is equivalent to magnitudes having an exponential distribution.
</p>
<p>Assume that the magnitude cutoff is <code class="reqn">M_0</code>, and let <code class="reqn">Y = M - M_0</code>. Given that <code class="reqn">Y</code> has an exponential distribution with parameter <code class="reqn">\lambda</code>, it follows that
</p>
<p style="text-align: center;"><code class="reqn">
\log_{10} \left( 1 - F_Y(y) \right) = \frac{-\lambda y}{\log_e 10}.
</code>
</p>

<p>The coefficient <code class="reqn">\lambda/(\log_e 10)</code> is often referred to as the <code class="reqn">b</code>-value, and its negative value is the slope of the line in the GR plot.
</p>
<p>Now define <code class="reqn">S</code> as
</p>
<p style="text-align: center;"><code class="reqn">
S = 10^{\gamma (M - M_0)} = 10^{\gamma Y}.
</code>
</p>

<p>When <code class="reqn">\gamma = 0.75</code>, <code class="reqn">S</code> is the &ldquo;stress&rdquo;; and when <code class="reqn">\gamma = 1.5</code>, <code class="reqn">S</code> is the &ldquo;seismic moment&rdquo;. Still assuming that <code class="reqn">Y</code> is exponential with parameter <code class="reqn">\lambda</code>, then <code class="reqn">Y \gamma \log_e 10</code> is also exponential with parameter <code class="reqn">\lambda/(\gamma \log_e 10)</code>. Hence, by noting that <code class="reqn">S</code> can be rewritten as
</p>
<p style="text-align: center;"><code class="reqn">
S = \exp\{ Y \gamma \log_e 10 \},
</code>
</p>

<p>it is seen that <code class="reqn">S</code> is Pareto with parameter <code class="reqn">\lambda/(\gamma \log_e 10)</code>, and <code class="reqn">1 \le S &lt; \infty</code>.
</p>
<p>While the empirical distribution of magnitudes appears to follow an exponential distribution for smaller events, it provides a poor approximation for larger events. This is because it is not physically possible to have events with magnitudes much greater than about 9.5. Consequently, the tail of the Pareto distribution will also be too long. Hence the tapered Pareto distribution provides a more realistic description.
</p>


<h3>See Also</h3>

<p>See <code><a href="stats.html#topic+dexp">dexp</a></code> for the exponential distribution. Generalisations of the exponential distribution are the gamma distribution <code><a href="stats.html#topic+dgamma">dgamma</a></code> and the Weibull distribution <code><a href="stats.html#topic+dweibull">dweibull</a></code>.
</p>
<p>See the topic <code><a href="#topic+distribution">distribution</a></code> for examples of estimating parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    Simulate and plot histogram with density for Pareto Distribution

a0 &lt;- 2
lambda0 &lt;- 2
x &lt;- rpareto(1000, lambda=lambda0, a=a0)
x0 &lt;- seq(a0, max(x)+0.1, length=100)
hist(x, freq=FALSE, breaks=x0, xlim=range(x0),
     main="Pareto Distribution")
points(x0, dpareto(x0, lambda0, a0), type="l", col="red")

#-----------------------------------------------
#    Calculate probabilities and quantiles for Pareto Distribution

a0 &lt;- 2
lambda0 &lt;- 2
prob &lt;- ppareto(seq(a0, 8), lambda0, a0)
quan &lt;- qpareto(prob, lambda0, a0)
print(quan)

#-----------------------------------------------
#    Simulate and plot histogram with density for tapered Pareto Distribution

a0 &lt;- 2
lambda0 &lt;- 2
theta0 &lt;- 3
x &lt;- rtappareto(1000, lambda=lambda0, theta=theta0, a=a0)
x0 &lt;- seq(a0, max(x)+0.1, length=100)
hist(x, freq=FALSE, breaks=x0, xlim=range(x0),
     main="Tapered Pareto Distribution")
points(x0, dtappareto(x0, lambda0, theta0, a0), type="l", col="red")

#-----------------------------------------------
#    Calculate probabilities and quantiles for tapered Pareto Distribution

a0 &lt;- 2
lambda0 &lt;- 2
theta0 &lt;- 3
prob &lt;- ptappareto(seq(a0, 8), lambda0, theta0, a0)
quan &lt;- qtappareto(prob, lambda0, theta0, a0)
print(quan)

#-----------------------------------------------
#    Calculate log-likelihood for tapered Pareto Distribution
#    note the Hessian and gradient attributes

a0 &lt;- 2
lambda0 &lt;- 2
theta0 &lt;- 3
x &lt;- rtappareto(1000, lambda=lambda0, theta=theta0, a=a0)
LL &lt;- ltappareto(x, lambda=lambda0, theta=theta0, a=a0)
print(LL)

</code></pre>

<hr>
<h2 id='etas_gif'>
Ground Intensity for ETAS Model
</h2><span id='topic+etas_gif'></span>

<h3>Description</h3>

<p>This function calculates the value of the ground intensity of a time-magnitude Epidemic Type Aftershock Sequence (ETAS) model. Spatial coordinates of the events are not taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>etas_gif(data, evalpts, params, TT=NA, tplus=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="etas_gif_+3A_data">data</code></td>
<td>

<p>a data frame containing the event history, where each row represents one event. There must be columns named <code>"time"</code>, usually the number of days from some origin; and <code>"magnitude"</code> which is the event magnitude less the magnitude threshold, i.e. <code class="reqn">M_i - M_0</code>.
</p>
</td></tr>
<tr><td><code id="etas_gif_+3A_evalpts">evalpts</code></td>
<td>

<p>a <code><a href="base.html#topic+vector">vector</a></code>, <code><a href="base.html#topic+matrix">matrix</a></code> or <code><a href="base.html#topic+data.frame">data.frame</a></code>. If a vector, the elements will be assumed to represent the required evaluation times. Other objects must include a column named <code>"time"</code> that can be referred to as <code>evalpts[,"time"]</code>, at which the intensity function will be evaluated.
</p>
</td></tr>
<tr><td><code id="etas_gif_+3A_params">params</code></td>
<td>

<p>vector of parameter values in the following order: <code class="reqn">(\mu, A, \alpha, c, p)</code>.
</p>
</td></tr>
<tr><td><code id="etas_gif_+3A_tt">TT</code></td>
<td>

<p>vector of length 2, being the time interval over which the integral of the ground intensity function is to be evaluated.
</p>
</td></tr>
<tr><td><code id="etas_gif_+3A_tplus">tplus</code></td>
<td>
<p>logical, <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is evaluated as <code class="reqn">\lambda_g(t^+|{\cal H}_t)</code> if <code>TRUE</code>, else <code class="reqn">\lambda_g(t^-|{\cal H}_t)</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The ETAS model was proposed by Ogata (1988, 1998, 1999) for the modelling of earthquake mainshock-aftershock sequences. The form of the ground intensity function used here is given by
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t|{\cal H}_t) = \mu + A \sum_{i : t_i &lt; t} e^{\alpha(M_i - M_0)} \left( 1 + \frac{t-t_i}{c} \right)^{-p},
</code>
</p>

<p>where <code class="reqn">t_i</code> denotes the event times and the summation is taken over those <code class="reqn">i</code> such that <code class="reqn">t_i &lt; t</code>.
</p>


<h3>Value</h3>

<p>Two usages are as follows.
</p>
<pre>
etas_gif(data, evalpts, params, tplus=FALSE)
etas_gif(data, evalpts=NULL, params, TT)
</pre>
<p>The first usage returns a vector containing the values of <code class="reqn">\lambda_g(t)</code> evaluated at the specified points. In the second usage, it returns the value of the integral.
</p>


<h3>Function Attributes</h3>


<dl>
<dt><code>rate</code></dt><dd><p>is <code>"decreasing"</code>.</p>
</dd>
</dl>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>See Also</h3>

<p>General details about the structure of ground intensity functions are given in the topic <code><a href="#topic+gif">gif</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Tangshan: ground intensity and magnitude time plots

data(Tangshan)
p &lt;- c(0.007, 2.3, 0.98, 0.008, 0.94)
bvalue &lt;- 1
TT &lt;- c(0, 4018)

x &lt;- mpp(data=Tangshan,
         gif=etas_gif,
         marks=list(dexp_mark, NULL),
         params=p,
         gmap=expression(params),
         mmap=expression(bvalue*log(10)),
         TT=TT)

par.default &lt;- par(mfrow=c(1,1), mar=c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(2,1), mar=c(4.1, 4.1, 0.5, 1))

plot(x, log=TRUE, xlab="")

plot(Tangshan$time, Tangshan$magnitude+4, type="h",
     xlim=c(0, 4018),
     xlab="Days Since 1 January 1974", ylab="Magnitude")

par(par.default)
</code></pre>

<hr>
<h2 id='gif'>General Notes on Ground Intensity Functions</h2><span id='topic+gif'></span>

<h3>Description</h3>

<p>This page contains general notes about the required structure of ground intensity functions (including those that are not conditional on their history) to be used with this package.
</p>


<h3>Forms of Usage</h3>

<p>The usage of a ground intensity function takes two forms, one to evaluate the <code>gif</code> at specified <code>evalpts</code>, or to evaluate the integral of the <code>gif</code> on the interval <code>TT</code>, each shown below, respectively.
<br />
<code>gif(data, evalpts, params, tplus=FALSE)</code>
<br />
<code>gif(data, NULL, params, TT)</code>
</p>


<h3>Arguments</h3>

<p>All ground intensity functions should be defined to contain the following arguments, in the order below, even though they may not be required (see Details below).
</p>

<dl>
<dt><code>data</code></dt><dd><p>a data frame containing the history of the process, denoted below as <code class="reqn"> {\cal H}_t</code>. It should contain all variables that are required to evaluate the <code>gif</code> function, though can contain others too. No history is represented as <code>NULL</code>.</p>
</dd>
<dt><code>evalpts</code></dt><dd><p>a object containing the values at which the <code>gif</code> function is to be evaluated, consistent with what is required by the <code>gif</code> function.</p>
</dd>
<dt><code>params</code></dt><dd><p>vector containing values of the parameters required by the <code>gif</code> function.</p>
</dd>
<dt><code>TT</code></dt><dd><p>vector of length 2, being the time interval over which the integral of the ground intensity function is to be evaluated.</p>
</dd>
<dt><code>tplus</code></dt><dd><p>logical, <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is evaluated as <code class="reqn">\lambda_g(t^+|{\cal H}_t)</code> if <code>TRUE</code>, else <code class="reqn">\lambda_g(t^-|{\cal H}_t)</code>. It is important if a &ldquo;jump&rdquo; occurs at <code class="reqn">t</code>.</p>
</dd>
</dl>


<h3>Details</h3>

<p>Note that the <code>gif</code> functions not only evaluate values of <code class="reqn">\lambda_g(t_i|{\cal H}_t)</code>, but also the integral. The value of the ground intensity function is returned at each time point specified in <code>evalpts</code> when <code>TT==NA</code>. If <code>TT</code> is not missing, the integral between <code>TT[1]</code> and <code>TT[2]</code> of the ground intensity function is calculated. In this last situation, anything assigned to the argument <code>evalpts</code> will have no effect.
</p>
<p>At the moment, we have the following types of processes: those jump processes that are conditional on their history (<code><a href="#topic+etas_gif">etas_gif</a></code>, <code><a href="#topic+srm_gif">srm_gif</a></code>, <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>), and non-homogeneous Poisson processes that are not conditional on their history (<code><a href="#topic+simple_gif">simple_gif</a></code>). Another case is where we have a collection of point like &ldquo;regions&rdquo; (or lattice nodes), each with their own ground intensity function, but where each is also dependent on what is happening in the other regions (<code><a href="#topic+linksrm_gif">linksrm_gif</a></code>).
</p>
<p>Functions have been given an attribute &ldquo;rate&rdquo;, taking the values of <code>"bounded"</code>, <code>"decreasing"</code> or <code>"increasing"</code>. This is used within the simulation function <code><a href="#topic+simulate.mpp">simulate.mpp</a></code> which uses the thinning method. This method requires a knowledge of the maximum of <code class="reqn">\lambda_g(t|{\cal H}_t)</code> in a given interval. The argument <code>tplus</code> is also used by the simulation routine, where it is necessary to determine the value of the intensity immediately after a simulated event.
</p>


<h3>Value</h3>

<p>The returned value is either <code class="reqn">\lambda_g(t_i|{\cal H}_t)</code>, where the <code class="reqn">t_i</code> are specified within <code>evalpts</code>; or
</p>
<p style="text-align: center;"><code class="reqn">\int \lambda_g(t|{\cal H}_t) dt</code>
</p>

<p>where the limits of the integral are specified by the function argument <code>TT</code>.
</p>


<h3>Function Attributes</h3>

<p>Each function should have some of the following attributes if it is to be used in conjunction with <code><a href="#topic+residuals.mpp">residuals.mpp</a></code> or <code><a href="#topic+simulate.mpp">simulate.mpp</a></code>:
</p>

<dl>
<dt><code>rate</code></dt><dd><p>must be specified if the default method for <code><a href="#topic+simulate.mpp">simulate.mpp</a></code> is to be used. Takes the values <code>"bounded"</code>, <code>"decreasing"</code> or <code>"increasing"</code>; see Details.</p>
</dd>
<dt><code>regions</code></dt><dd><p>an expression giving the number of regions; required with <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+etas_gif">etas_gif</a></code>, <code><a href="#topic+expfourier_gif">expfourier_gif</a></code>, <code><a href="#topic+exppoly_gif">exppoly_gif</a></code>, <code><a href="#topic+fourier_gif">fourier_gif</a></code>, <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>, <code><a href="#topic+poly_gif">poly_gif</a></code>, <code><a href="#topic+simple_gif">simple_gif</a></code>, <code><a href="#topic+srm_gif">srm_gif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Ogata's Data: ground intensity function
#  evaluate lambda_g(t) at certain times

data(Ogata)

p &lt;- c(0.02, 70.77, 0.47, 0.002, 1.25)
times &lt;- sort(c(seq(0, 800, 0.5), Ogata$time))
TT &lt;- c(0, 800)

plot(times, log(etas_gif(Ogata, times, params=p)), type="l",
     ylab=expression(paste(log, " ", lambda[g](t))),
     xlab=expression(t), xlim=TT)

#  Evaluate the integral
#   The first form below is where the arguments are in their
#   default positions, the 2nd is where they are not, hence
#   their names must be specified

print(etas_gif(Ogata, NULL, p, TT))
#  or
print(etas_gif(Ogata, params=p, TT=TT))
</code></pre>

<hr>
<h2 id='HiddenMarkov-internal'>Internally Used Functions</h2><span id='topic+print.summary.mpp'></span>

<h3>Description</h3>

<p>This page lists internally used functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.mpp'
print(x, ...)
</code></pre>

<hr>
<h2 id='linksrm'>Linked Stress Release Model Object</h2><span id='topic+linksrm'></span>

<h3>Description</h3>

<p>Creates a point process model object with class <code>"linksrm"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linksrm(data, gif, marks, params, gmap, mmap, TT)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linksrm_+3A_data">data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> containing the history of the process, denoted below as <code class="reqn"> {\cal H}_t</code>. It should contain all variables that are required to evaluate the <code>gif</code> function and the mark distribution, though can contain others too. No history is represented as <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="linksrm_+3A_gif">gif</code></td>
<td>
<p>ground intensity function. At this stage, this can only be <code><a href="#topic+linksrm_gif">linksrm_gif</a></code> or modifications of that function; see &ldquo;Details&rdquo; below.</p>
</td></tr>
<tr><td><code id="linksrm_+3A_marks">marks</code></td>
<td>
<p>mark distribution. See topic <code><a href="#topic+marks">marks</a></code> for further details.</p>
</td></tr>
<tr><td><code id="linksrm_+3A_params">params</code></td>
<td>
<p>numeric vector of <em>all</em> model parameters.</p>
</td></tr>
<tr><td><code id="linksrm_+3A_gmap">gmap</code></td>
<td>
<p><code><a href="base.html#topic+expression">expression</a></code>, maps the model parameters (<code>params</code>) into the parameter sub-space of the ground intensity function; see &ldquo;Details&rdquo; below.</p>
</td></tr>
<tr><td><code id="linksrm_+3A_mmap">mmap</code></td>
<td>
<p><code><a href="base.html#topic+expression">expression</a></code>, maps the model parameters (<code>params</code>) into the parameter sub-space of the mark distribution; see &ldquo;Details&rdquo; below.</p>
</td></tr>
<tr><td><code id="linksrm_+3A_tt">TT</code></td>
<td>
<p>vector of length 2, being the time interval over which the integral of the ground intensity function is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linked stress release model has a slightly peculiar structure which makes it difficult to fit into the <code><a href="#topic+mpp">mpp</a></code> class. While the region should be thought of as a mark, it is completely defined by the function <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>, and hence from the programming perspective the <code>region</code> mark is really tied in with the <code>gif</code> function. Hence at the moment, the linked stress release model is treated as a special case. There may be other models that could be grouped into this class.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(-1.5, -1.5, 0.01, 0.03, 2, -0.5, 0.2, 1, 1*log(10), 3)
TT &lt;- c(0, 1000)

rexptrunc_mark &lt;- function(ti, data, params){
    x &lt;- rexp(n=1, params[1])
    x[x &gt; params[2]] &lt;- params[2]
    names(x) &lt;- "magnitude"
    return(x)
}

x &lt;- linksrm(data=NULL,
             gif=linksrm_gif,
             marks=list(NULL, rexptrunc_mark),
             params=p,
             gmap=expression(params[1:8]),
             mmap=expression(params[9:10]),
             TT=TT)

x &lt;- simulate(x, seed=5)
print(logLik(x))

#   estimate parameters
temp_map &lt;- function(y, p){
    #    map only gif parameters into model object
    y$params[1:8] &lt;- p
    return(y)
}

weight &lt;- c(0.1, 0.1, 0.005, 0.005, 0.1, 0.1, 0.1, 0.1)

#   see manual page for linksrm_gif for modifications to
#   make calculations faster

#   for testing, restrict to 5 iterations
z &lt;- nlm(neglogLik, p[1:8], object=x, pmap=temp_map,
         hessian=TRUE, gradtol=1e-08, steptol=1e-10,
         print.level=2, iterlim=5, typsize=weight)

param.names &lt;- c("a1", "a2", "b1", "b2", "c11", "c12", "c21", "c22")
param.est &lt;- cbind(p[1:8], z$estimate, sqrt(diag(solve(z$hessian))))
dimnames(param.est) &lt;- list(param.names,
                            c("Actual", "Estimate", "StdErr"))
print(param.est)

#   place parameter estimates into model object
x &lt;- temp_map(x, z$estimate)

#   plot ground intensity function
par.default &lt;- par(mfrow=c(2,1), mar=c(4.1, 4.1, 0.5, 1))
x$gif &lt;- linksrm_gif
plot(x, 1, xlab="")
plot(x, 2)
par(par.default)

#   plot "residuals" for each region
tau &lt;- residuals(x)
par(mfrow=c(2,1))
for (i in 1:2){
    plot(tau[[i]], ylab="Transformed Time",
         xlab="Event Number", main=paste("Region", i))
    abline(a=0, b=1, lty=2, col="red")
}

#   plot cusum of "residuals" for each region
for (i in 1:2){
    plot(tau[[i]] - 1:length(tau[[i]]), ylab="Cusum of Transformed Time",
         xlab="Event Number", main=paste("Region", i))
    abline(h=0, lty=2, col="red")
}

par(mfrow=c(1,1))
</code></pre>

<hr>
<h2 id='linksrm_convert'>
Parameter Conversion for Linked Stress Release Model
</h2><span id='topic+linksrm_convert'></span>

<h3>Description</h3>

<p>Converts parameter values between two different parameterisations (described in Details below) of the linked stress release model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linksrm_convert(params, abc=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linksrm_convert_+3A_params">params</code></td>
<td>

<p>a vector of parameter values of length <code class="reqn">n^2+2n</code>, where <code class="reqn">n</code> is the number of regions in the model.
</p>
</td></tr>
<tr><td><code id="linksrm_convert_+3A_abc">abc</code></td>
<td>

<p>logical. If <code>TRUE</code> (default), then the input value of params is that of the <code>abc</code> parameterisation. See Details for further explanation.
</p>
</td></tr></table>


<h3>Details</h3>

<p>If <code>abc == TRUE</code>, the conditional intensity for the <code class="reqn">i</code>th region is assumed to have the form
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t,i | {\cal H}_t) = \exp\left\{ a_i + b_i\left[t - \sum_{j=1}^n c_{ij} S_j(t)\right]\right\}
</code>
</p>

<p>with <code>params</code><code class="reqn"> = (a_1, \cdots, a_n, b_1, \cdots, b_n, c_{11}, c_{12}, c_{13}, \cdots, c_{nn})</code>.
</p>
<p>If <code>abc == FALSE</code>, the conditional intensity for the <code class="reqn">i</code>th region is assumed to have the form
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t,i | {\cal H}_t) = \exp\left\{ \alpha_i + \nu_i\left[\rho_i t - \sum_{j=1}^n \theta_{ij} S_j(t)\right]\right\}
</code>
</p>

<p>where <code class="reqn">\theta_{ii}=1</code> for all <code class="reqn">i</code>, <code class="reqn">n = \sqrt{\code{length(params)} + 1} - 1</code>, and 
<code>params</code></p>
<p style="text-align: center;"><code class="reqn"> = (\alpha_1, \cdots, \alpha_n, \nu_1, \cdots, \nu_n, \rho_1, \cdots, \rho_n, \theta_{12}, \theta_{13}, \cdots, \theta_{1n}, \theta_{21}, \theta_{23}, \cdots, \theta_{n,n-1}).</code>
</p>



<h3>Value</h3>

<p>A list object with the following components is returned:
</p>
<table>
<tr><td><code>params</code></td>
<td>

<p>vector as specified in the function call.
</p>
</td></tr>
<tr><td><code>a</code></td>
<td>

<p>vector of length <code class="reqn">n</code> as in the <code>abc</code> parameterisation.
</p>
</td></tr>
<tr><td><code>b</code></td>
<td>

<p>vector of length <code class="reqn">n</code> as in the <code>abc</code> parameterisation.
</p>
</td></tr>
<tr><td><code>c</code></td>
<td>

<p>n by <code class="reqn">n</code> matrix as in the <code>abc</code> parameterisation.
</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>

<p>vector of length <code class="reqn">n</code> as in the alternative parameterisation.
</p>
</td></tr>
<tr><td><code>nu</code></td>
<td>

<p>vector of length <code class="reqn">n</code> as in the alternative parameterisation.
</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>

<p>vector of length <code class="reqn">n</code> as in the alternative parameterisation.
</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>

<p>n by <code class="reqn">n</code> matrix with ones on the diagonal as in the alternative parameterisation.
</p>
</td></tr></table>


<h3>See Also</h3>

<p><code><a href="#topic+linksrm_gif">linksrm_gif</a></code>
</p>

<hr>
<h2 id='linksrm_gif'>
Ground Intensity for Linked Stress Release Model
</h2><span id='topic+linksrm_gif'></span>

<h3>Description</h3>

<p>Calculates the value of the ground intensity of a Linked Stress Release Model (LSRM). This model allows for multiple linked regions, where the stress can be transferred between the regions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linksrm_gif(data, evalpts, params, TT=NA, tplus=FALSE, eta=0.75)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linksrm_gif_+3A_data">data</code></td>
<td>

<p>a data frame containing the event history, where each row represents one event. There must be columns named <code>"time"</code>, usually the number of days from some origin; <code>"magnitude"</code> which is the event magnitude less the magnitude threshold, i.e. <code class="reqn">M_k - M_0</code>; and <code>"region"</code> which are consecutively numbered starting at 1.
</p>
</td></tr>
<tr><td><code id="linksrm_gif_+3A_evalpts">evalpts</code></td>
<td>

<p>a <code><a href="base.html#topic+matrix">matrix</a></code> or <code><a href="base.html#topic+data.frame">data.frame</a></code>. It must include two columns named <code>"time"</code> and <code>"region"</code> that can be referred to as <code>evalpts[,"time"]</code> and <code>evalpts[,"region"]</code>, respectively. The function will be evaluated at these points.
</p>
</td></tr>
<tr><td><code id="linksrm_gif_+3A_params">params</code></td>
<td>

<p>vector of parameters of length <code class="reqn">n^2+2n</code>, where <code class="reqn">n</code> is the number of regions, for the proposed LSRM in the following order:
</p>
<p style="text-align: center;"><code class="reqn">
(a_1, \cdots, a_n, b_1, \cdots, b_n, c_{11}, c_{12}, c_{13}, \cdots, c_{nn}).
</code>
</p>

</td></tr>
<tr><td><code id="linksrm_gif_+3A_tt">TT</code></td>
<td>

<p>vector of length 2, being the time interval over which the integral of the ground intensity function is to be evaluated.
</p>
</td></tr>
<tr><td><code id="linksrm_gif_+3A_tplus">tplus</code></td>
<td>
<p>logical, <code class="reqn">\lambda_g(t,i|{\cal H}_t)</code> is evaluated as <code class="reqn">\lambda_g(t^+,i|{\cal H}_t)</code> if <code>TRUE</code>, else <code class="reqn">\lambda_g(t^-,i|{\cal H}_t)</code>.
</p>
</td></tr>
<tr><td><code id="linksrm_gif_+3A_eta">eta</code></td>
<td>
<p>a scalar used in the stress calculations, see Details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ground intensity for the <code class="reqn">i</code>th region is assumed to have the form
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t,i | {\cal H}_t) = \exp\left\{ a_i + b_i\left[t - \sum_{j=1}^n c_{ij} S_j(t)\right]\right\}
</code>
</p>

<p>with <code>params</code><code class="reqn">= \code{c}(a_1, \cdots, a_n, b_1, \cdots, b_n, c_{11}, c_{12}, c_{13}, \cdots, c_{nn})</code>; and
</p>
<p style="text-align: center;"><code class="reqn">
S_j(t) = \sum_k 10^{\eta(M_k-M_0)},
</code>
</p>

<p>where the summation is taken over those events in region <code class="reqn">j</code> with time <code class="reqn">t_k &lt; t</code>. This model has been discussed by Bebbington &amp; Harte (2001, 2003). The default value of <code class="reqn">\eta = \code{eta} = 0.75</code>.
</p>


<h3>Value</h3>

<p>Two usages are as follows.
</p>
<pre>
linksrm_gif(data, evalpts, params, tplus=FALSE, eta=0.75)
linksrm_gif(data, evalpts=NULL, params, TT, eta=0.75)
</pre>
<p>The first usage returns a vector containing the values of <code class="reqn">\lambda_g(t,i)</code> evaluated at the specified &ldquo;time-region&rdquo; points. In the second usage, it returns a vector containing the value of the integral for each region.
</p>


<h3>Function Attributes</h3>


<dl>
<dt><code>rate</code></dt><dd><p>is <code>"increasing"</code>.</p>
</dd>
<dt><code>regions</code></dt><dd><p>is <code>expression(sqrt(length(params) + 1) - 1)</code>.</p>
</dd>
</dl>


<h3>Modify Function to Decrease Calculation Time</h3>

<p>The function <code>linksrm_gif</code> calculates the stress reduction matrices <code>St1</code> and <code>St2</code> every time that the function is called. Ideally, these should be calculated once and be included within the model object. Currently, the structure of the model object is not sufficiently flexible. However, the user can create a new function to calculate <code>St1</code> and <code>St2</code> once. This will only work if the event <em>history</em> is not changing between successive calls (e.g. parameter estimation). However, in a simulation, the history changes with the addition of each new event, and in this situation <code>St1</code> and <code>St2</code> need to be calculated with every function call.
</p>
<p>The modified function, as described below, will write the objects <code>St1</code> and <code>St2</code> to a temporary database (position 2 in the search path). Consequently, it cannot be defined within the package itself because this violates the CRAN rules. The function <code>linksrm_gif</code> contains markers indicating the beginning and ending of the parts where <code>St1</code> and <code>St2</code> are calculated. The modified function is made by editing the function <code>linksrm_gif</code>. We firstly <code><a href="base.html#topic+deparse">deparse</a></code> the function <code>linksrm_gif</code> (i.e. put the contents into a character vector). We initially create a temporary database called <code>PtProcess.tmp</code> in which to write <code>St1</code> and <code>St2</code>. We then search for the line numbers that mark the beginning and ending of the parts where <code>St1</code> and <code>St2</code> are calculated. We replace the beginning of each with a conditional statement so that the contents are only run if these two objects do not already exist. We then <code><a href="base.html#topic+parse">parse</a></code> the lines of code in the character vector back into a function, and call this new function <code>linksrm1_gif</code>. The same thing can be achieved by dumping <code>linksrm_gif</code> to a text file and editing manually.
</p>
<pre>
#   define linksrm1_gif by modifying linksrm_gif

#   put function linksrm_gif into a character vector
tmp &lt;- deparse(linksrm_gif)

#   remove "if (FALSE)" lines
linenum &lt;- grep("if \(FALSE\)", tmp)
tmp &lt;- tmp[-linenum]

#   attach new database at pos=2 in search path called PtProcess.tmp
linenum &lt;- grep("attach new database to search path", tmp)
tmp[linenum] &lt;- "if (!any(search()==\"PtProcess.tmp\")) attach(NULL,
                      pos=2L, name=\"PtProcess.tmp\", warn.conflicts=TRUE)"

#   calc St1 if St1 does not exist
linenum &lt;- grep("this loop calculates St1", tmp)
tmp[linenum] &lt;- "if (!exists(\"St1\", mode = \"numeric\")) {"
linenum &lt;- grep("assign statement for St1", tmp)
tmp[linenum] &lt;- "assign(\"St1\", St1, pos=\"PtProcess.tmp\")"
linenum &lt;- grep("end loop St1", tmp)
tmp[linenum] &lt;- "}"


#   calc St2 if St2 does not exist
linenum &lt;- grep("this loop calculates St2", tmp)
tmp[linenum] &lt;- "if (!exists(\"St2\", mode = \"numeric\")) {"
linenum &lt;- grep("assign statement for St2", tmp)
tmp[linenum] &lt;- "assign(\"St2\", St2, pos=\"PtProcess.tmp\")"
linenum &lt;- grep("end loop St2", tmp)
tmp[linenum] &lt;- "}"

linksrm1_gif &lt;- eval(parse(text=tmp))
</pre>
<p><em>Warning</em>: The function <code>linksrm1_gif</code> checks to see whether the matrices <code>St1</code> and <code>St2</code> exist. If so, these existing matrices are used, and new ones are not calculated. Therefore when using <code>linksrm1_gif</code> for parameter estimation, one <b>must</b> check for the existence of such matrices, and delete upon starting to fit a new model:
</p>
<pre>
if (exists("St1")) rm(St1)
if (exists("St2")) rm(St2)
</pre>
<p>or detach the database as <code>detach(2)</code>. The objects <code>St1</code> and <code>St2</code> will exist for the duration of the current R session, so should be deleted when no longer required.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>See Also</h3>

<p>General details about the structure of ground intensity functions are given in the topic <code><a href="#topic+gif">gif</a></code>.
</p>

<hr>
<h2 id='logLik'>Log Likelihood of a Point Process Model</h2><span id='topic+logLik'></span><span id='topic+logLik.mpp'></span><span id='topic+logLik.linksrm'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood of a point process. Provides methods for the generic function <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpp'
logLik(object, SNOWcluster=NULL, ...)
## S3 method for class 'linksrm'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+mpp">mpp</a>"</code> or <code>"<a href="#topic+linksrm">linksrm</a>"</code>.</p>
</td></tr>
<tr><td><code id="logLik_+3A_snowcluster">SNOWcluster</code></td>
<td>
<p>an object of class <code>"cluster"</code> created by the package <span class="pkg">parallel</span>; default is <code>NULL</code>. Enables parallel processing if not <code>NULL</code>. See &ldquo;Parallel Processing&rdquo; below for further details.</p>
</td></tr>
<tr><td><code id="logLik_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of the log-likelihood.
</p>


<h3>Parallel Processing</h3>

<p>Parallel processing can be enabled to calculate the term <code class="reqn">\sum_i \log \lambda_g(t_i|{\cal H}_{t_i})</code>. Generally, the amount of computational work involved in calculating <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is much greater if there are more events in the process history prior to <code class="reqn">t</code> than in the case where there are fewer events. Given <code class="reqn">m</code> nodes, the required evaluation points are divided into <code class="reqn">m</code> groups, taking into account the amount of &ldquo;history&rdquo; prior to each event and the CPU speed of the node (see below).
</p>
<p>We have assumed that communication between nodes is fairly slow, and hence it is best to allocate the work in large chunks and minimise communication. If the dataset is small, then the time taken to allocate the work to the various nodes may in fact take more time than simply using one processor to perform all of the calculations.
</p>
<p>The required steps in initiating parallel processing are as follows.
</p>
<pre>
#   load the "parallel" package
library(parallel)

#   define the SNOW cluster object, e.g. a SOCK cluster
#   where each node has the same R installation.
cl &lt;- makeSOCKcluster(c("localhost", "horoeka.localdomain", 
                        "horoeka.localdomain", "localhost"))

#   A more general setup: Totara is Fedora, Rimu is Debian:
#   Use 2 processors on Totara, 1 on Rimu:
totara  &lt;- list(host="localhost",
                rscript="/usr/lib/R/bin/Rscript",
                snowlib="/usr/lib/R/library")
rimu    &lt;- list(host="rimu.localdomain",
                rscript="/usr/lib/R/bin/Rscript",
                snowlib="/usr/local/lib/R/site-library")
cl &lt;- makeCluster(list(totara, totara, rimu), type="SOCK")

#   NOTE: THE STATEMENTS ABOVE WERE APPROPRIATE FOR THE snow PACKAGE.
#   I HAVE NOT YET TESTED THEM USING THE parallel PACKAGE.

#   Relative CPU speeds of the nodes can be added as an attribute
#   Say rimu runs at half the speed of totara
#   (default assumes all run at same speed)
attr(cl, "cpu.spd") &lt;- c(1, 1, 0.5)

#   then define the required model object, e.g. see topic "mpp"
#   say the model object is called x

#   then calculate the log-likelihood as
print(logLik(x, SNOWcluster=cl))

#   stop the R jobs on the slave machines
stopCluster(cl)
</pre>
<p>Note that the communication method does not need to be <code>SOCKS</code>; see the <span class="pkg">parallel</span> package documentation, topic <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, for other options. Further, if some nodes are on other machines, the firewalls may need to be tweaked. The master machine initiates the <span class="rlang"><b>R</b></span> jobs on the slave machines by communicating through port 22 (use of security keys are needed rather than passwords), and subsequent communications use random ports. This port can be fixed, see <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    SRM: magnitude iid exponential with bvalue=1

TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

#   calculate log-likelihood excluding the mark density term
x1 &lt;- mpp(data=NULL,
          gif=srm_gif,
          marks=list(NULL, rexp_mark),
          params=params,
          gmap=expression(params[1:3]),
          mmap=expression(params[4]),
          TT=TT)
x1 &lt;- simulate(x1, seed=5)
print(logLik(x1))

#   calculate log-likelihood including the mark density term
x2 &lt;- mpp(data=x1$data,
          gif=srm_gif,
          marks=list(dexp_mark, rexp_mark),
          params=params,
          gmap=expression(params[1:3]),
          mmap=expression(params[4]),
          TT=TT)
print(logLik(x2))

#  contribution from magnitude marks
print(sum(dexp(x1$data$magnitude, rate=bvalue*log(10), log=TRUE)))
</code></pre>

<hr>
<h2 id='makeSOCKcluster'>Parallel Processing: Transition Functions</h2><span id='topic+makeSOCKcluster'></span>

<h3>Description</h3>

<p>Package <span class="pkg">snow</span> has become deprecated and replaced by <span class="pkg">parallel</span>. Some functions in <span class="pkg">snow</span> used by package <span class="pkg">PtProcess</span> do not appear in <span class="pkg">parallel</span> under the same name. Below are transition functions to map some functions in <span class="pkg">snow</span> to the most comparable functions in <span class="pkg">parallel</span>. These transition functions will ultimately be deprecated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeSOCKcluster(names, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeSOCKcluster_+3A_names">names</code></td>
<td>
<p>character vector of node names.</p>
</td></tr>
<tr><td><code id="makeSOCKcluster_+3A_...">...</code></td>
<td>
<p>cluster option specifications.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+makeSOCKcluster">makeSOCKcluster</a></code> calls <code><a href="parallel.html#topic+makePSOCKcluster">makePSOCKcluster</a></code>.
</p>

<hr>
<h2 id='marks'>Mark Distributions</h2><span id='topic+marks'></span><span id='topic+dexp_mark'></span><span id='topic+rexp_mark'></span>

<h3>Description</h3>

<p>Contains densities and random number generators for some example mark distributions. The mark distributions can be multi-dimensional. Users can write their own functions, and general rules are given under &ldquo;Details&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dexp_mark(x, data, params)
rexp_mark(ti, data, params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="marks_+3A_ti">ti</code></td>
<td>
<p>scalar, time of an event.</p>
</td></tr>
<tr><td><code id="marks_+3A_x">x</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> of mark values at given times, often a subset of the history.</p>
</td></tr>
<tr><td><code id="marks_+3A_data">data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> containing the history of the process, denoted below as <code class="reqn"> {\cal H}_t</code>.</p>
</td></tr>
<tr><td><code id="marks_+3A_params">params</code></td>
<td>
<p>numeric vector of parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The example functions listed under &ldquo;Usage&rdquo; calculate the <em>logarithm</em> of the (mark) density and simulate earthquake magnitudes assuming an exponential distribution that is independent of the history of the process. This corresponds to the Gutenberg-Richter law. They assume that the history contains a variable named <code>"magnitude"</code>.
</p>
<p>All mark densities and random number generators must have the three arguments as shown in the examples above. Multi-parameter distributions have their parameters specified as a vector in the <code>params</code> argument. Other ancillary data or information can be passed into the function non formally, though one needs to be careful about possible conflict with names of other objects.
</p>


<h3>Value</h3>

<p>Mark density functions must return a vector with length being equal to the number of rows in <code>x</code>. Each element contains the <em>logarithm</em> of the joint density of the marks corresponding to each time (row) in <code>x</code>.
</p>
<p>The random number generator simulates each mark for a <em>single value</em> of <code>ti</code>. It must return a <code><a href="base.html#topic+list">list</a></code> of simulated marks corresponding to the specified time <code>ti</code>. Further, the list must have its elements named the same as those in the history. Note that each component in the list will be of length one. A list is used (rather than a vector) because it allows marks to be character as well as numeric.
</p>


<h3>Example 1</h3>

<p>This is an example where the density of the magnitude distribution is dependent on the value of the ground intensity function (assumed to be <code>etas_gif</code>), and in this case, the history of the process. The history is assumed to contain a variable named <code>"magnitude"</code>. In this mark distribution, it is assumed that after large events, there is a deficit of smaller magnitude events with more larger magnitude events. It has seven parameters with parameters <code class="reqn">p_1, \cdots, p_5</code> relating to <code>etas_gif</code>. It assumes that the magnitude distribution is gamma (<code><a href="stats.html#topic+GammaDist">GammaDist</a></code>), with a shape parameter given by
</p>
<p style="text-align: center;"><code class="reqn">
\mbox{shape} = 1 + \sqrt{\lambda_g(t|{\cal H}_t)} \ p_7 \,,
</code>
</p>

<p>where <code class="reqn">p_7</code> (<code class="reqn">p_7 &gt; 0</code>) is a free estimable parameter, and parameter <code class="reqn">p_6</code> is the scale parameter. Hence when <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is small, the magnitude distribution returns to an approximate exponential distribution with an approximate rate of <code class="reqn">p_6</code> (i.e. Gutenberg Richter law).
</p>
<pre>
    dexample1_mark &lt;- function(x, data, params){
        lambda &lt;- etas_gif(data, x[,"time"], params=params[1:5])
        y &lt;- dgamma(x[,"magnitude"], rate=params[6], 
                    shape=1+sqrt(lambda)*params[7], log=TRUE)
        return(y)
    }

    rexample1_mark &lt;- function(ti, data, params){
        #  Gamma distribution
        #  exponential density when params[7]=0
        lambda &lt;- etas_gif(data, ti, params=params[1:5])
        y &lt;- rgamma(1, shape=1+sqrt(lambda)*params[7],
                    rate=params[6])
        return(list(magnitude=y))
    }
</pre>


<h3>Example 2</h3>

<p>This an example of a 3-D mark distribution. Each component is independent of each other and the history, hence the arguments <code>ti</code> and <code>data</code> are not utilised in the functions. The history is assumed to contain the three variables <code>"magnitude"</code>,  <code>"longitude"</code> and <code>"latitude"</code>. The event magnitudes are assumed to have an exponential distribution with rate <code>params[1]</code>, and the longitudes and latitudes to have normal distributions with means <code>params[2]</code> and <code>params[3]</code>, respectively.
</p>
<pre>
    dexample2_mark &lt;- function(x, data, params)
        return(dexp(x[,"magnitude"], rate=params[1], log=TRUE) +
               dnorm(x[,"longitude"], mean=params[2], log=TRUE) +
               dnorm(x[,"latitude"], mean=params[3], log=TRUE))

    rexample2_mark &lt;- function(ti, data, params)
        return(list(magnitude=rexp(1, rate=params[1]),
                    longitude=rnorm(1, mean=params[2]),
                    latitude=rnorm(1, mean=params[3])))
</pre>

<hr>
<h2 id='mpp'>Marked Point Process Object</h2><span id='topic+mpp'></span>

<h3>Description</h3>

<p>Creates a marked point process model object with class <code>"mpp"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mpp(data, gif, marks, params, gmap, mmap, TT)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mpp_+3A_data">data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> containing the history of the process, denoted below as <code class="reqn"> {\cal H}_t</code>. It should contain all variables that are required to evaluate the <code>gif</code> function and the mark distribution, though can contain others too. No history is represented as <code><a href="base.html#topic+NULL">NULL</a></code>.</p>
</td></tr>
<tr><td><code id="mpp_+3A_gif">gif</code></td>
<td>
<p>ground intensity function. See topic <code><a href="#topic+gif">gif</a></code> for further details.</p>
</td></tr>
<tr><td><code id="mpp_+3A_marks">marks</code></td>
<td>
<p>a <code><a href="base.html#topic+list">list</a></code> containing the mark distribution. The first component (i.e. <code>marks[[1]]</code>) is the mark density and the second (i.e. <code>marks[[2]]</code>) is the random number generator. If either of these functions are not required, the particular component can be set to <code><a href="base.html#topic+NULL">NULL</a></code>. See topic <code><a href="#topic+marks">marks</a></code> for further details.</p>
</td></tr>
<tr><td><code id="mpp_+3A_params">params</code></td>
<td>
<p>numeric vector of <em>all</em> model parameters.</p>
</td></tr>
<tr><td><code id="mpp_+3A_gmap">gmap</code></td>
<td>
<p><code><a href="base.html#topic+expression">expression</a></code>, maps the model parameters (<code>params</code>) into the parameter sub-space of the ground intensity function; see &ldquo;Details&rdquo; below.</p>
</td></tr>
<tr><td><code id="mpp_+3A_mmap">mmap</code></td>
<td>
<p><code><a href="base.html#topic+expression">expression</a></code>, maps the model parameters (<code>params</code>) into the parameter sub-space of the mark distribution; see &ldquo;Details&rdquo; below.</p>
</td></tr>
<tr><td><code id="mpp_+3A_tt">TT</code></td>
<td>
<p>vector of length 2, being the time interval over which the integral of the ground intensity function is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\lambda_g(t|{\cal H}_t)</code> denote the ground intensity function and <code class="reqn">f(y|{\cal H}_t)</code> denote the joint mark densities, where <code class="reqn">y \in {\cal Y}</code>. The log-likelihood of a marked point process is given by
</p>
<p style="text-align: center;"><code class="reqn">
\log L = \sum_i \log \lambda_g(t_i|{\cal H}_{t_i}) + \sum_i \log f(y_i|{\cal H}_{t_i}) - \int \lambda_g(t|{\cal H}_t) dt,
</code>
</p>

<p>where the summation is taken over those events contained in the interval <code>(TT[1], TT[2])</code>, and the integral is also taken over that interval. However, all events in the data frame <code>data</code> before <code class="reqn">t</code>, even those before <code>TT[1]</code>, form the history of the process <code class="reqn"> {\cal H}_t</code>. This allows an initial period for the process to reach a &ldquo;steady state&rdquo; or &ldquo;equilibrium&rdquo;.
</p>
<p>The parameter spaces of the ground intensity function and mark distribution are not necessarily disjoint, and can have common parameters. Hence, when the model parameters are estimated, these relationships must be known, and are specified by the arguments <code>gmap</code> and <code>mmap</code>. The mapping expressions can also contain arithmetic expressions. The <code class="reqn">i</code>th element in the <code>params</code> argument is addressed in the expressions as <code>params[i]</code>. Here is an example of a five parameter model, where the <code>gif</code> has 4 parameters, and the mark distribution has 2, with mappings specified as:
</p>
<pre>
    gmap = expression(c(params[1:3], exp(params[4]+params[5])))

    mmap = expression(c(log(params[2]/3), params[5]))
</pre>
<p>Note the inclusion of the combine (<code><a href="base.html#topic+c">c</a></code>) function, because the <code><a href="base.html#topic+expression">expression</a></code> must create a vector of parameters. Care must be taken specifying these expressions as they are embedded directly into the code of various functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Tangshan)

#   increment magnitudes a fraction so none are zero
Tangshan[,"magnitude"] &lt;- Tangshan[,"magnitude"] + 0.01

dmagn_mark &lt;- function(x, data, params){
    #  Gamma distribution
    #  exponential density when params[7]=0
    #   See topic "marks" for further discussion
    lambda &lt;- etas_gif(data, x[,"time"], params=params[1:5])
    y &lt;- dgamma(x[,"magnitude"], shape=1+sqrt(lambda)*params[7],
                rate=params[6], log=TRUE)
    return(y)
}

TT &lt;- c(0, 4018)
# params &lt;- c(0.0067, 1.1025, 1.0794, 0.0169, 0.9506, 1.9159, 0.4704)
params &lt;- c(0.007, 1.1, 1.08, 0.02, 0.95, 1.92, 0.47)

x &lt;- mpp(data=Tangshan,
         gif=etas_gif,
         marks=list(dmagn_mark, NULL),
         params=params,
         gmap=expression(params[1:5]),
         mmap=expression(params[1:7]),
         TT=TT)

allmap &lt;- function(y, p){
    #    one to one mapping, all p positive
    y$params &lt;- exp(p)
    return(y)
}

#    Parameters must be positive. Transformed so that nlm
#    can use entire real line (no boundary problems, see
#    topic "neglogLik" for further explanation).
#    Argument "iterlim" has been restricted to 2 to avoid
#    excessive time in package checks, set much larger to
#    ensure convergence.
z &lt;- nlm(neglogLik, log(params), object=x, pmap=allmap,
         print.level=2, iterlim=2, typsize=abs(params))

x1 &lt;- allmap(x, z$estimate)

#    print parameter estimates
print(x1$params)

print(logLik(x))
print(logLik(x1))
plot(x1, log=TRUE)
</code></pre>

<hr>
<h2 id='neglogLik'>Negative Log-Likelihood</h2><span id='topic+neglogLik'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood multiplied by negative one. It is in a format that can be used with the functions <code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neglogLik(params, object, pmap = NULL, SNOWcluster=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neglogLik_+3A_params">params</code></td>
<td>
<p>a vector of revised parameter values.</p>
</td></tr>
<tr><td><code id="neglogLik_+3A_object">object</code></td>
<td>
<p>an object of class <code>"<a href="#topic+mpp">mpp</a>"</code>.</p>
</td></tr>
<tr><td><code id="neglogLik_+3A_pmap">pmap</code></td>
<td>
<p>a user provided function mapping the revised parameter values <code>params</code> into the appropriate locations in <code>object</code>. If <code>NULL</code> (default), an untransformed one to one mapping is used.</p>
</td></tr>
<tr><td><code id="neglogLik_+3A_snowcluster">SNOWcluster</code></td>
<td>
<p>an object of class <code>"cluster"</code> created by the package <span class="pkg">parallel</span>; default is <code>NULL</code>. Enables parallel processing if not <code>NULL</code>. See <code><a href="#topic+logLik">logLik</a></code> for further details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used with the two functions <code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code> (see &ldquo;Examples&rdquo; below) to maximise the likelihood function of a model specified in <code>object</code>. Both <code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code> are <em>minimisers</em>, hence the &ldquo;negative&rdquo; log-likelihood. The topic <code><a href="#topic+distribution">distribution</a></code> gives examples of their use in the relatively easy situation of fitting standard probability distributions to data assuming independence.
</p>
<p>The maximisation of the model likelihood function can be restricted to be over a subset of the model parameters. Other parameters will then be fixed at the values stored in the model <code>object</code>. Let <code class="reqn">\Theta_0</code> denote the full model parameter space, and let <code class="reqn">\Theta</code> denote the parameter sub-space (<code class="reqn">\Theta \subseteq \Theta_0</code>) over which the likelihood function is to be maximised. The argument <code>params</code> contains values in <code class="reqn">\Theta</code>, and <code>pmap</code> is assigned a function that maps these values into the full model parameter space <code class="reqn">\Theta_0</code>. See &ldquo;Examples&rdquo; below.
</p>
<p>The mapping function assigned to <code>pmap</code> can also be made to impose restrictions on the domain of the parameter space <code class="reqn">\Theta</code> so that the minimiser cannot jump to values such that <code class="reqn">\Theta \not\subseteq \Theta_0</code>. For example, if a particular parameter must be positive, one can work with a transformed parameter that can take any value on the real line, with the model parameter being the exponential of this transformed parameter. Similarly a modified logit like transform can be used to ensure that parameter values remain within a fixed interval with finite boundaries. Examples of these situations can be found in the topic <code><a href="#topic+distribution">distribution</a></code> and the &ldquo;Examples&rdquo; below.
</p>


<h3>Value</h3>

<p>Value of the log-likelihood times negative one.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nlm">nlm</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    SRM: magnitude is iid exponential with bvalue=1
#    maximise exponential mark density too

TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

x &lt;- mpp(data=NULL,
         gif=srm_gif,
         marks=list(dexp_mark, rexp_mark),
         params=params,
         gmap=expression(params[1:3]),
         mmap=expression(params[4]),
         TT=TT)
x &lt;- simulate(x, seed=5)

allmap &lt;- function(y, p){
    #    map all parameters into model object
    #    transform exponential param so it is positive
    y$params[1:3] &lt;- p[1:3]
    y$params[4] &lt;- exp(p[4])
    return(y)
}

params &lt;- c(-2.5, 0.01, 0.8, log(bvalue*log(10)))

z &lt;- nlm(neglogLik, params, object=x, pmap=allmap,
         print.level=2, iterlim=500, typsize=abs(params))
print(z$estimate)

#   these should be the same:
print(exp(z$estimate[4]))
print(1/mean(x$data$magnitude))
</code></pre>

<hr>
<h2 id='NthChina'>Historical Earthquakes of North China</h2><span id='topic+NthChina'></span>

<h3>Description</h3>

<p>Contains 65 large historical earthquakes in North China between 1480 and 1997, as given by Bebbington &amp; Harte (2003). Events are divided into 4 regions using the regionalisations given by Zheng &amp; Vere-Jones (1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NthChina)
</code></pre>


<h3>Format</h3>

<p>A data frame with 65 rows, each representing an earthquake event, with the following variables:
</p>

<dl>
<dt>time</dt><dd><p>number of years since 1480 AD.</p>
</dd>
<dt>latitude</dt><dd><p>number of degrees north.</p>
</dd>
<dt>longitude</dt><dd><p>number of degrees east.</p>
</dd>
<dt>magnitude</dt><dd><p>number of magnitude units <em>above</em> 6.</p>
</dd>
<dt>region</dt><dd><p>1, 2, 3, or 4; being the region of the event.</p>
</dd>
</dl>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>

<hr>
<h2 id='Ogata'>
Ogata's ETAS Test Data
</h2><span id='topic+Ogata'></span>

<h3>Description</h3>

<p>A data frame containing the test data from Utsu and Ogata's (1997) software contained in the file testetas.dat. The first column is named <code>"time"</code>, and the second column is named <code>"magnitude"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Ogata)
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows (earthquake events) in the time interval (0, 800). It contains the following variables:
</p>

<dl>
<dt>time</dt><dd><p>number of time units since time zero.</p>
</dd>
<dt>magnitude</dt><dd><p>number of magnitude units <em>above</em> 3.5.</p>
</dd>
</dl>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ogata)
plot(Ogata$time, Ogata$magnitude + 3.5, type="h")
</code></pre>

<hr>
<h2 id='Phuket'>Phuket Earthquake and Aftershock Sequence</h2><span id='topic+Phuket'></span>

<h3>Description</h3>

<p>The Phuket earthquake occurred on 26 December 2004 at 00:58:53.45 GMT. The <code>Phuket</code> data frame contains this event and its aftershock sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Phuket)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>latitude</dt><dd><p>number of degrees north.</p>
</dd>
<dt>longitude</dt><dd><p>number of degrees east.</p>
</dd>
<dt>depth</dt><dd><p>depth of event in kilometres.</p>
</dd>
<dt>mb</dt><dd><p>body wave magnitude (<code class="reqn">m_b</code>) rounded to one decimal place.</p>
</dd>
<dt>Ms</dt><dd><p>surface wave magnitude (<code class="reqn">M_s</code>) rounded to one decimal place.</p>
</dd>
<dt>magnitude</dt><dd><p>event magnitude (<code class="reqn">\max(m_b, M_s)</code>) rounded to one decimal place.</p>
</dd>
<dt>year</dt><dd><p>year of event (numeric vector).</p>
</dd>
<dt>month</dt><dd><p>month of event, 1 ... 12 (numeric vector).</p>
</dd>
<dt>day</dt><dd><p>day of event, 1 ... 31 (numeric vector).</p>
</dd>
<dt>hour</dt><dd><p>hour of event, 0 ... 23 (numeric vector).</p>
</dd>
<dt>minute</dt><dd><p>minute of event, 0 ... 59 (numeric vector).</p>
</dd>
<dt>second</dt><dd><p>second of event, 0 ... 59 (numeric vector).</p>
</dd>
<dt>time</dt><dd><p>number of days (and fractions) from midnight on 1 January 2004.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The <code>Phuket</code> data frame contains those events (1248) from the PDE Catalogue, within the spatial region <code class="reqn">89^\circ</code>E&ndash;<code class="reqn">105^\circ</code>E and <code class="reqn">5^\circ</code>S&ndash;<code class="reqn">16^\circ</code>N, with magnitude 5 or greater, occurring between midnight on 1 January 2004 and midnight on 1 January 2009 (1827 days later). The body wave magnitudes are determined by the amplitude of the initial primary wave, and these magnitudes tend to saturate for higher values. Consequently, the tabulated <code>magnitude</code> is taken as the maximum of the body wave magnitude (<code class="reqn">m_b</code>) and surface wave magnitude (<code class="reqn">M_s</code>).</p>


<h3>Source</h3>

<p>The data were extracted from the PDE (Preliminary Determination of Epicentres) catalogue provided by the US Geological Survey (<a href="https://earthquake.usgs.gov/data/comcat/catalog/us/">https://earthquake.usgs.gov/data/comcat/catalog/us/</a>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Phuket)
print(Phuket[1:10,])
</code></pre>

<hr>
<h2 id='plot'>Plot Point Process Ground Intensity Function</h2><span id='topic+plot'></span><span id='topic+plot.mpp'></span><span id='topic+plot.linksrm'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="graphics.html#topic+plot">plot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpp'
plot(x, log=FALSE, ...)
## S3 method for class 'linksrm'
plot(x, region, log=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>an object with class <code>"<a href="#topic+mpp">mpp</a>"</code> or <code>"<a href="#topic+linksrm">linksrm</a>"</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_region">region</code></td>
<td>
<p>scalar, specifies the required region.</p>
</td></tr>
<tr><td><code id="plot_+3A_log">log</code></td>
<td>
<p>plot <code class="reqn">\log \lambda_g(t|{\cal H}_t)</code>, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ogata)

p &lt;- c(0.02, 70.77, 0.47, 0.002, 1.25)
TT &lt;- c(0, 800)
bvalue &lt;- 1

#   Note that the plot function does not utilise the
#   information about mark distributions, hence these
#   arguments can be NULL

x &lt;- mpp(data=Ogata,
         gif=etas_gif,
         marks=list(NULL, NULL),
         params=p,
         gmap=expression(params[1:5]),
         mmap=NULL,
         TT=TT)

plot(x, log=TRUE)
</code></pre>

<hr>
<h2 id='PtProcess-package'>Overview of PtProcess Package</h2><span id='topic+PtProcess-package'></span><span id='topic+PtProcess'></span>

<h3>Description</h3>

<p>This topic gives an introductory overview to the package <span class="pkg">PtProcess</span>. Links are given to follow up topics where more detail can be found.
</p>


<h3>Introduction</h3>

<p>This package contains routines for the fitting of <em>time dependent</em> point process models, particularly marked processes with &ldquo;jumps&rdquo;. These models have particular application to earthquake data. A detailed theoretical background to these and other point process models can be found in Daley &amp; Vere-Jones (2003, 2008). An overview of the package structure is given by Harte (2010).
</p>
<p>The direction of the development of the package has been influenced by our research on the application of point process models to seismology. The package was originally written for S-PLUS, being part of the Statistical Seismology Library (Harte, 1998; Brownrigg &amp; Harte, 2005). The package <span class="pkg">ptproc</span> by Peng (2002, 2003) analyses multi-dimensional point process models, and the package <span class="pkg">spatstat</span> by Baddeley et al (2005, 2005a, 2008) analyses spatial point processes.
</p>
<p><em>The topic <code><a href="#topic+Changes">Changes</a></code> lists recent changes made to the package. Version 3 of the package has some major changes from Version 2, and code for Version 2 will not work in Version 3 without modification. Some examples giving the old code and the required new code are given in the topic <code><a href="#topic+Changes">Changes</a></code>. Changes made in Version 3 enable one to fit a more general class of model.</em>
</p>


<h3>Classes of Point Process Models Analysed</h3>

<p>The classes of models currently fitted by the package are listed below. Each are defined within an object that contains the data, current parameter values, and other model characteristics.
</p>

<dl>
<dt>Marked Point Process Model:</dt><dd>
<p>is described under the topic <code><a href="#topic+mpp">mpp</a></code>. This model can be simulated or fitted to data by defining the required model structure within an object of class <code>"<a href="#topic+mpp">mpp</a>"</code>.</p>
</dd>
<dt>Linked Stress Release Model:</dt><dd>
<p>is described under the topic <code><a href="#topic+linksrm">linksrm</a></code>. This model is slightly peculiar, and doesn't fit naturally in the <code>mpp</code> framework.</p>
</dd>
</dl>



<h3>Main Tasks Performed by the Package</h3>

<p>The main tasks performed by the package are listed below. These can be achieved by calling the appropriate generic function.
</p>

<dl>
<dt>Simulation:</dt><dd><p>can be performed by the function <code><a href="#topic+simulate">simulate</a></code>.</p>
</dd>
<dt>Parameter Estimation:</dt><dd><p>can be achieved by using the function <code><a href="#topic+neglogLik">neglogLik</a></code>.</p>
</dd>
<dt>Model Residuals:</dt><dd><p>can be calculated with the function <code><a href="#topic+residuals">residuals</a></code>.</p>
</dd>
<dt>Model Summary:</dt><dd><p>can be extracted with the function <code><a href="#topic+summary">summary</a></code>.</p>
</dd>
<dt>Log-Likelihood:</dt><dd><p>can be calculated with the function <code><a href="#topic+logLik">logLik</a></code>.</p>
</dd>
<dt>Ground Intensity Plot:</dt><dd><p>can be performed by the function <code><a href="#topic+plot">plot</a></code>.</p>
</dd>
</dl>

<p>The method function conforms to the following naming convention, for example, the function <code><a href="#topic+logLik.mpp">logLik.mpp</a></code> provides the method to calculate the log-likelihood for <code><a href="#topic+mpp">mpp</a></code> objects. The function code can be viewed by entering <code>PtProcess:::logLik.mpp</code> on the <span class="rlang"><b>R</b></span> command line.
</p>
<p>If you want to modify such a function, <code><a href="base.html#topic+dump">dump</a></code> the code to your local directory, modify in a text editor, then use <code><a href="base.html#topic+source">source</a></code> at the beginning of your program script, but after <code>library(PtProcess)</code>. Your modified version will then be used in preference to the version in the <span class="pkg">PtProcess</span> package.
</p>


<h3>Organisation of Topics in the Package</h3>


<dl>
<dt>Cited References:</dt><dd><p>anywhere in the manual are only listed within this topic.</p>
</dd>
<dt>General Documentation:</dt><dd><p>topics summarising general structure are indexed under the keyword &ldquo;documentation&rdquo; in the Index.</p>
</dd>
</dl>



<h3>Acknowledgements</h3>

<p>The package is based on an S-PLUS package which was commenced at Victoria University of Wellington in 1996. Contributions and suggestions have been made by many, including: Mark Bebbington, Ray Brownrigg, Edwin Choi, Robert Davies, Michael Eglinton, Dongfeng Li, Li Ma, Alistair Merrifield, Andrew Tokeley, David Vere-Jones, Wenzheng Yang, Leon Young, Irina Zhdanova and Jiancang Zhuang.
</p>


<h3>References</h3>

<p>Aalen, O.O. &amp; Hoem, J.M. (1978). Random time changes for multivariate counting processes. <em>Scandinavian Journal of Statistics</em> <b>5</b>, 81&ndash;101. doi: <a href="https://doi.org/10.1080/03461238.1978.10419480">10.1080/03461238.1978.10419480</a>
</p>
<p>Baddeley, A. (2008). <em>Open source software for spatial statistics.</em> URL: <a href="http://spatstat.org/">http://spatstat.org/</a>.
</p>
<p>Baddeley, A. &amp; Turner, R. (2005). Spatstat: an R package for analyzing spatial point patterns. <em>Journal of Statistical Software</em> <b>12(6)</b>, 1&ndash;42. doi: <a href="https://doi.org/10.18637/jss.v012.i06">10.18637/jss.v012.i06</a>
</p>
<p>Baddeley, A.; Turner, R.; Moller, J. &amp; Hazelton, M. (2005a). Residual analysis for spatial point processes (with discussion). <em>J. R. Statist. Soc. B</em> <b>67(5)</b>, 617&ndash;666. doi: <a href="https://doi.org/10.1111/j.1467-9868.2005.00519.x">10.1111/j.1467-9868.2005.00519.x</a>
</p>
<p>Bebbington, M.S. &amp; Harte, D.S. (2001). On the statistics of the linked stress release model. <em>Journal of Applied Probability</em> <b>38A</b>, 176&ndash;187. doi: <a href="https://doi.org/10.1239/jap/1085496600">10.1239/jap/1085496600</a>
</p>
<p>Bebbington, M.S. &amp; Harte, D.S. (2003). The linked stress release model for spatio-temporal seismicity: formulations, procedures and applications. <em>Geophysical Journal International</em> <b>154</b>, 925&ndash;946. doi: <a href="https://doi.org/10.1046/j.1365-246X.2003.02015.x">10.1046/j.1365-246X.2003.02015.x</a>
</p>
<p>Brownrigg, R. &amp; Harte, D.S. (2005). Using <span class="rlang"><b>R</b></span> for statistical seismology. <em><span class="rlang"><b>R</b></span> News</em> <b>5(1)</b>, 31&ndash;35. URL: <a href="https://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf">https://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf</a>.
</p>
<p>Daley, D.J. &amp; Vere-Jones, D. (2003). <em>An Introduction to the Theory of Point Processes. Volume I: Elementary Theory and Methods. Second Edition.</em> Springer-Verlag, New York. doi: <a href="https://doi.org/10.1007/b97277">10.1007/b97277</a>
</p>
<p>Daley, D.J. &amp; Vere-Jones, D. (2008). <em>An Introduction to the Theory of Point Processes. Volume II: General Theory and Structure. Second Edition.</em> Springer-Verlag, New York. doi: <a href="https://doi.org/10.1007/978-0-387-49835-5">10.1007/978-0-387-49835-5</a>
</p>
<p>Harte, D. (1998). Documentation for the Statistical Seismology Library. School of Mathematical and Computing Sciences Research Report No. 98&ndash;10 (Updated Edition June 1999), Victoria University of Wellington. (ISSN 1174&ndash;4545)
</p>
<p>Harte, D. (2010). PtProcess: An <span class="rlang"><b>R</b></span> package for modelling marked point processes indexed by time. <em>Journal of Statistical Software</em> <b>35(8)</b>, 1&ndash;32. doi: <a href="https://doi.org/10.18637/jss.v035.i08">10.18637/jss.v035.i08</a>
</p>
<p>Kagan, Y. &amp; Schoenberg, F. (2001). Estimation of the upper cutoff parameter for the tapered Pareto distribution. <em>Journal of Applied Probability</em> <b>38A</b>, 158&ndash;175. doi: <a href="https://doi.org/10.1239/jap/1085496599">10.1239/jap/1085496599</a>
</p>
<p>Lewis, P.A.W. &amp; Shedler, G.S. (1979). Simulation of nonhomogeneous Poisson processes by thinning. <em>Naval Research Logistics Quarterly</em> <b>26(3)</b>, 403&ndash;413. doi: <a href="https://doi.org/10.1002/nav.3800260304">10.1002/nav.3800260304</a>
</p>
<p>Ogata, Y. (1981). On Lewis' simulation method for point processes. <em>IEEE Transactions on Information Theory</em> <b>27(1)</b>, 23&ndash;31. doi: <a href="https://doi.org/10.1109/TIT.1981.1056305">10.1109/TIT.1981.1056305</a>
</p>
<p>Ogata, Y. (1988). Statistical models for earthquake occurrences and residual analysis for point processes. <em>J. Amer. Statist. Assoc.</em> <b>83(401)</b>, 9&ndash;27. doi: <a href="https://doi.org/10.2307/2288914">10.2307/2288914</a>
</p>
<p>Ogata, Y. (1998). Space-time point-process models for earthquake occurrences. <em>Ann. Instit. Statist. Math.</em> <b>50(2)</b>, 379&ndash;402. doi: <a href="https://doi.org/10.1023/A:1003403601725">10.1023/A:1003403601725</a>
</p>
<p>Ogata, Y. (1999). Seismicity analysis through point-process modeling: a review. <em>Pure and Applied Geophysics</em> <b>155</b>, 471&ndash;507. doi: <a href="https://doi.org/10.1007/s000240050275">10.1007/s000240050275</a>
</p>
<p>Ogata, Y. &amp; Zhuang, J.C. (2006). Space-time ETAS models and an improved extension. <em>Tectonophysics</em> <b>413(1-2)</b>, 13&ndash;23. doi: <a href="https://doi.org/10.1016/j.tecto.2005.10.016">10.1016/j.tecto.2005.10.016</a>
</p>
<p>Peng, R. (2002). Multi-dimensional Point Process Models. Package &ldquo;ptproc&rdquo;, URL: <a href="http://www.biostat.jhsph.edu/~rpeng/">http://www.biostat.jhsph.edu/~rpeng/</a>.
</p>
<p>Peng, R. (2003). Multi-dimensional point process models in R. <em>Journal of Statistical Software</em> <b>8(16)</b>, 1&ndash;27. doi: <a href="https://doi.org/10.18637/jss.v008.i16">10.18637/jss.v008.i16</a>
</p>
<p>Reid, H.F. (1910). The mechanism of the earthquake. In <em>The California Earthquake of April 18, 1906, Report of the State Earthquake Investigation Commission</em> <b>2</b>, 16&ndash;28. Carnegie Institute of Washington, Washington D.C.
</p>
<p>Utsu, T. and Ogata, Y. (1997). Statistical analysis of seismicity. In: <em>Algorithms for Earthquake Statistics and Prediction</em> (Edited by: J.H. Healy, V.I. Keilis-Borok and W.H.K. Lee), pp 13&ndash;94.  IASPEI, Menlo Park CA.
</p>
<p>Vere-Jones, D. (1978). Earthquake prediction - a statistician's view. <em>Journal of Physics of the Earth</em> <b>26</b>, 129&ndash;146. doi: <a href="https://doi.org/10.4294/jpe1952.26.129">10.4294/jpe1952.26.129</a>
</p>
<p>Vere-Jones, D.; Robinson, R. &amp; Yang, W. (2001). Remarks on the accelerated moment release model: problems of model formulation, simulation and estimation. <em>Geophysical Journal International</em> <b>144(3)</b>, 517&ndash;531. doi: <a href="https://doi.org/10.1046/j.1365-246x.2001.01348.x">10.1046/j.1365-246x.2001.01348.x</a>
</p>
<p>Zheng, X.-G. &amp; Vere-Jones, D. (1991). Application of stress release models to historical earthquakes from North China. <em>Pure and Applied Geophysics</em> <b>135(4)</b>, 559&ndash;576. doi: <a href="https://doi.org/10.1007/BF01772406">10.1007/BF01772406</a>
</p>
<p>Zhuang, J.C. (2006). Second-order residual analysis of spatiotemporal point processes and applications in model evaluation. <em>J. R. Statist. Soc. B</em> <b>68(4)</b>, 635&ndash;653. doi: <a href="https://doi.org/10.1111/j.1467-9868.2006.00559.x">10.1111/j.1467-9868.2006.00559.x</a>
</p>

<hr>
<h2 id='residuals'>Residuals of a Point Process Model</h2><span id='topic+residuals'></span><span id='topic+residuals.mpp'></span><span id='topic+residuals.linksrm'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="stats.html#topic+residuals">residuals</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpp'
residuals(object, ...)
## S3 method for class 'linksrm'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals_+3A_object">object</code></td>
<td>
<p>an object with class <code><a href="#topic+mpp">mpp</a></code> or <code><a href="#topic+linksrm">linksrm</a></code>.</p>
</td></tr>
<tr><td><code id="residuals_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">t_i</code> be the times of the observed events. Then the transformed times are defined as
</p>
<p style="text-align: center;"><code class="reqn">
\tau_i = \int_0^{t_i} \lambda_g(t|{\cal H}_t) dt.
</code>
</p>

<p>If the proposed point process model is correct, then the transformed time points will form a stationary Poisson process with rate parameter one. A plot of transformed time points versus the cumulative number of events should then roughly follow the straight line <code class="reqn">y = x</code>. Significant departures from this line indicate a weakness in the model. Further details can be found in Ogata (1988) and Aalen &amp; Hoem (1978).
</p>
<p>See Baddeley et al (2005) and Zhuang (2006) for extensions of these methodologies.
</p>


<h3>Value</h3>

<p>Returns a time series object with class &quot;<code><a href="stats.html#topic+ts">ts</a></code>&quot; in the case of <code><a href="#topic+mpp">mpp</a></code>. In the case of <code><a href="#topic+linksrm">linksrm</a></code> a list is returned with the number of components being equal to the number of regions, and with each component being a time series object.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

x &lt;- mpp(data=NULL,
         gif=srm_gif,
         marks=list(NULL, rexp_mark),
         params=params,
         gmap=expression(params[1:3]),
         mmap=expression(params[4]),
         TT=TT)
x &lt;- simulate(x, seed=5)

tau &lt;- residuals(x)

plot(tau, ylab="Transformed Time", xlab="Event Number")
abline(a=0, b=1, lty=2, col="red")

#   represent as a cusum
plot(tau - 1:length(tau), ylab="Cusum of Transformed Time", xlab="Event Number")
abline(h=0, lty=2, col="red")
</code></pre>

<hr>
<h2 id='simple_gif'>
Non-Homogeneous Poisson Processes
</h2><span id='topic+expfourier_gif'></span><span id='topic+exppoly_gif'></span><span id='topic+fourier_gif'></span><span id='topic+poly_gif'></span><span id='topic+simple_gif'></span>

<h3>Description</h3>

<p>The functions listed here are intensity functions that are not conditional on the history of the process. Each has exactly the same &ldquo;Usage&rdquo; and calling format (see section &ldquo;Value&rdquo;) as the function <code>simple_gif</code>. They are: <code>expfourier_gif</code>, <code>exppoly_gif</code>, <code>fourier_gif</code>, <code>poly_gif</code>, and <code>simple_gif</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple_gif(data, evalpts, params, TT=NA, tplus=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simple_gif_+3A_data">data</code></td>
<td>

<p><code>NULL</code> or a data frame. The contents of this object are not used by these functions, though they retain this argument for consistency with other <code><a href="#topic+gif">gif</a></code> functions.</p>
</td></tr>
<tr><td><code id="simple_gif_+3A_evalpts">evalpts</code></td>
<td>

<p>a <code><a href="base.html#topic+vector">vector</a></code>, <code><a href="base.html#topic+matrix">matrix</a></code> or <code><a href="base.html#topic+data.frame">data.frame</a></code>. If a vector, the elements will be assumed to represent the required evaluation times. Other objects must include a column named <code>"time"</code> that can be referred to as <code>evalpts[,"time"]</code>, at which the intensity function will be evaluated.
</p>
</td></tr>
<tr><td><code id="simple_gif_+3A_params">params</code></td>
<td>

<p>vector of parameter values as required by the particular intensity function, see Details below.
</p>
</td></tr>
<tr><td><code id="simple_gif_+3A_tt">TT</code></td>
<td>

<p>vector of length 2, being the time interval over which the integral of the intensity function is to be evaluated.
</p>
</td></tr>
<tr><td><code id="simple_gif_+3A_tplus">tplus</code></td>
<td>
<p>logical, <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is evaluated as <code class="reqn">\lambda_g(t^+|{\cal H}_t)</code> if <code>TRUE</code>, else <code class="reqn">\lambda_g(t^-|{\cal H}_t)</code>. Included for compatibility with others conditional intensity functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The models are parameterised as follows.
</p>

<dl>
<dt><code>expfourier_gif</code></dt><dd>
<p>The vector of parameters is
</p>
<p style="text-align: center;"><code class="reqn">
(p, a_0, a_1, a_2, \cdots, a_n, b_1, b_2, \cdots, b_n)
</code>
</p>

<p>and the intensity function is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t) = \exp\left\{a_0 + \sum_{j=1}^n a_j\cos\left(\frac{2j\pi t}{p}\right) + \sum_{j=1}^n b_j\sin\left(\frac{2j\pi t}{p}\right)\right\}.
</code>
</p>

<p>The length of <code>params</code> is <code class="reqn">2n + 2</code>, and determines the order of the fitted Fourier series. The numbers of specified sine and cosine coefficients must be the same. The integral is evaluated using numerical integration, using the <span class="rlang"><b>R</b></span> function <code><a href="stats.html#topic+integrate">integrate</a></code>.
</p>
</dd>
<dt><code>exppoly_gif</code></dt><dd>
<p>The vector of parameters is
<code class="reqn">
(b_0, b_1, b_2, \cdots, b_n)
</code>
and the intensity function is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t) = \exp\left\{b_0 + \sum_{j=1}^n b_j t^j \right\}.
</code>
</p>

<p>The length of <code>params</code> determines the order of the fitted polynomial. The integral is evaluated using numerical integration, using the <span class="rlang"><b>R</b></span> function <code><a href="stats.html#topic+integrate">integrate</a></code>.
</p>
</dd>
<dt><code>fourier_gif</code></dt><dd>
<p>The Fourier intensity function is the same as <code>expfourier_gif</code>, except the intensity function omits the exponential, and the integration is performed explicitly.
</p>
</dd>
<dt><code>poly_gif</code></dt><dd>
<p>The polynomial intensity function is the same as <code>exppoly_gif</code>, except the intensity function omits the exponential, and the integration is performed explicitly.
</p>
</dd>
<dt><code>simple_gif</code></dt><dd>
<p>The intensity function is <code class="reqn">\lambda_g(t) = a + b t^g</code> and the vector of parameters is <code class="reqn">(a, b, g)</code>.
</p>
</dd>
</dl>


<h3>Value</h3>

<p>Two usages are as follows.
</p>
<pre>
simple_gif(data, evalpts, params, tplus=FALSE)
simple_gif(data, evalpts=NULL, params, TT=NA)
</pre>
<p>The first usage returns a vector containing the values of <code class="reqn">\lambda_g(t)</code> evaluated at the specified points. In the second usage, it returns the value of the integral.
</p>


<h3>Function Attributes</h3>


<dl>
<dt><code>rate</code></dt><dd><p>is <code>"bounded"</code>.</p>
</dd>
</dl>


<h3>See Also</h3>

<p>General details about the structure of conditional intensity functions are given in the topic <code><a href="#topic+gif">gif</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>expfourier_gif(NULL, c(1.1,1.2,1.3), c(2,3,1,2,3,4), TT=NA)
#  Evaluates:  lambda_g(t) = exp(3 + 1*cos(2*pi*t/2) + 2*cos(4*pi*t/2) +
#                                3*sin(2*pi*t/2) + 4*sin(4*pi*t/2))
#  lambda_g(1.1) = 162.56331
#  lambda_g(1.2) = 127.72599
#  lambda_g(1.3) =  23.83979

expfourier_gif(NULL, NULL, c(2,3,1,2,3,4), TT=c(3,4))
#  Let:  lambda_g(t) = exp(3 + 1*cos(2*pi*t/2) + 2*cos(4*pi*t/2) +
#                              3*sin(2*pi*t/2) + 4*sin(4*pi*t/2))
#  Evaluates: integral_3^4 lambda_g(t) dt = 46.21920


#--------------------------------------------------------
#   Plot intensity function: lambda(t) = 3 + 3*sin(t)
#   on interval (0, 6*pi), no marks

params &lt;- c(2*pi, 3, 0, 3)
TT &lt;- c(0, 6*pi)
x &lt;- seq(TT[1], TT[2], length.out=500)

plot(x, fourier_gif(NULL, x, params, TT=NA),
     ylim=c(0, 6), type="l", axes=FALSE,
     xlab="t",
     ylab=expression(lambda(t) == 3 + 3*phantom(.)*plain(sin)*phantom(.)*t),
     main="Sinusoidal Intensity Function", font.main=1)
abline(h=params[2], lty=2, col="red")
box()
axis(2)
axis(1, at=0, labels=0)
axis(1, at=2*pi, labels=expression(2*pi))
axis(1, at=4*pi, labels=expression(4*pi))
axis(1, at=6*pi, labels=expression(6*pi))

#   Now define a model object
#   note NULL "marks" argument, see manual page for "mpp"
z &lt;- mpp(data=NULL,
         gif=fourier_gif,
         marks=list(NULL, NULL),
         params=params,
         gmap=expression(params),
         mmap=NULL,
         TT=TT)

#   Simulate event times
z &lt;- simulate(z, seed=3, max.rate=6)

#   Plot simulated times on sine curve
x &lt;- z$data$time
points(x, fourier_gif(NULL, x, params, TT=NA), col="blue", lwd=5)

#   Number of simulated events
print(nrow(z$data))

#   Estimate parameters based on simulated data
parmap &lt;- function(y, p){
    #    fix parameters 1 and 3
    y$params &lt;- c(2*pi, p[1], 0, p[2])
    return(y)
}

initial &lt;- c(3, 3)
y &lt;- nlm(neglogLik, initial, object=z, pmap=parmap,
         print.level=2, iterlim=20, stepmax=0.1)
print(y$estimate)
</code></pre>

<hr>
<h2 id='simulate'>Simulate a Point Process</h2><span id='topic+simulate'></span><span id='topic+simulate.mpp'></span><span id='topic+simulate.linksrm'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="stats.html#topic+simulate">simulate</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpp'
simulate(object, nsim=1, seed=NULL, max.rate=NA,
         stop.condition=NULL, ...)
## S3 method for class 'linksrm'
simulate(object, nsim=1, seed=NULL, max.rate=NA,
         stop.condition=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+mpp">mpp</a>"</code> or <code>"<a href="#topic+linksrm">linksrm</a>"</code>.</p>
</td></tr>
<tr><td><code id="simulate_+3A_nsim">nsim</code></td>
<td>
<p>has no effect, and is only included for compatibility with the generic function <code><a href="stats.html#topic+simulate">simulate</a></code>. See section &ldquo;Length of Simulated Series&rdquo; below for control information.</p>
</td></tr>
<tr><td><code id="simulate_+3A_seed">seed</code></td>
<td>
<p>seed for the random number generator.</p>
</td></tr>
<tr><td><code id="simulate_+3A_max.rate">max.rate</code></td>
<td>
<p>maximum rate, only used if the attribute of <code>object$gif</code> is <code>"bounded"</code>. It is the maximum value of <code>object$gif</code> on the simulation interval <code>object$TT</code>.</p>
</td></tr>
<tr><td><code id="simulate_+3A_stop.condition">stop.condition</code></td>
<td>
<p>a function returning a logical value. It is called after the addition of each simulated event. The simulation continues until either <code>object$TT[2]</code> is exceeded or <code>stopping.condition</code> returns <code>TRUE</code>. See section &ldquo;Length of Simulated Series&rdquo; below for further information.</p>
</td></tr>
<tr><td><code id="simulate_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>thinning method</em> (Ogata, 1981; Lewis &amp; Shedler, 1979) is used to simulate a point process with specified ground intensity function. The method involves calculating an upper bound for the intensity function, simulating a value for the time to the next <em>possible</em> event using a rate equal to this upper bound, and then calculating the intensity at this simulated point; hence these &ldquo;events&rdquo; are simulated too frequently. The ratio of this rate with the upper bound is compared with a uniform random number to randomly determine whether the simulated time is retained or not (i.e. thinned).
</p>
<p>The functions need to calculate an upper bound for the intensity function. The ground intensity functions will usually be discontinuous at event times, but may be monotonically increasing or decreasing at other times. The ground intensity functions have an attribute called <code>rate</code> with values of <code>"bounded"</code>, <code>"increasing"</code> or <code>"decreasing"</code>. This information is used to determine the required upper bounded.
</p>
<p>The function <code>simulate.linksrm</code> is currently only used in conjunction with <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>, or a variation of that function. It expects the <code>gif</code> function to have an attribute called <code>regions</code>, which may be an expression, being the number of regions. The method used by the function <code>simulate.linksrm</code> also assumes that the function is &ldquo;increasing&rdquo; (i.e. rate, summed over all regions, apart from discontinuous jumps), hence a positive tectonic input over the whole system.
</p>


<h3>Value</h3>

<p>The returned value is an object of the same class as <code>object</code>. It will contain all events prior to <code>object$TT[1]</code> in <code>object$data</code> and all subsequently simulated events. Variables (columns) in <code>object$data</code> will be restricted to <code>"time"</code> and those for which a mark is simulated.
</p>


<h3>Length of Simulated Series</h3>

<p>The interval of time over which events are simulated is determined by <code>object$TT</code>. Simulation starts at <code>object$TT[1]</code> and stops at <code>object$TT[2]</code>. The &ldquo;current&rdquo; dataset will consist of all events prior to <code>object$TT[1]</code> in <code>object</code>, plus subsequently simulated events. A more complicated stopping condition can be formulated by using the argument <code>stop.condition</code>.
</p>
<p>The argument <code>stop.condition</code> can be assigned a function that returns a logical value. The assigned function is a function of the &ldquo;current&rdquo; dataset. It is executed near the bottom of <code>simulate.mpp</code> (check by printing the function). Simulation will then continue until either the stopping condition has been met or the current time exceeds <code>object$TT[2]</code>.
</p>
<p>For example, we may want to simulate until the first earthquake with a magnitude of 8. Assume that the current dataset contains a variable with name <code>"magnitude"</code> (untransformed). We would then assign <code>Inf</code> to <code>object$TT[2]</code>, and write this condition as a function:
</p>
<pre>
    stop.cond &lt;- function(data){
        n &lt;- nrow(data)
        #   most recent event is the nth
        return(data$magnitude[n] &gt;= 8)
    }
</pre>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

x &lt;- mpp(data=NULL,
         gif=srm_gif,
         marks=list(NULL, rexp_mark),
         params=params,
         gmap=expression(params[1:3]),
         mmap=expression(params[4]),
         TT=TT)
x &lt;- simulate(x, seed=5)

y &lt;- hist(x$data$magnitude, xlab="Magnitude", main="")

#   overlay with an exponential density
magn &lt;- seq(0, 3, length.out=100)
points(magn, nrow(x$data)*(y$breaks[2]-y$breaks[1])*
             dexp(magn, rate=1/mean(x$data$magnitude)),
       col="red", type="l")
</code></pre>

<hr>
<h2 id='srm_gif'>
Conditional Intensity for Stress Release Model
</h2><span id='topic+srm_gif'></span>

<h3>Description</h3>

<p>This function calculates the value of the conditional intensity of a Stress Release Model (SRM). Spatial coordinates of the events are not taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>srm_gif(data, evalpts, params, TT=NA, tplus=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="srm_gif_+3A_data">data</code></td>
<td>

<p>a data frame containing the event history, where each row represents one event. There must be columns named &ldquo;time&rdquo;, usually the number of days from some origin; and &ldquo;magnitude&rdquo; which is the event magnitude less the magnitude threshold, i.e. <code class="reqn">M_i - M_0</code>.
</p>
</td></tr>
<tr><td><code id="srm_gif_+3A_evalpts">evalpts</code></td>
<td>

<p>a <code><a href="base.html#topic+vector">vector</a></code>, <code><a href="base.html#topic+matrix">matrix</a></code> or <code><a href="base.html#topic+data.frame">data.frame</a></code>. If a vector, the elements will be assumed to represent the required evaluation times. Other objects must include a column named <code>"time"</code> that can be referred to as <code>evalpts[,"time"]</code>, at which the intensity function will be evaluated.
</p>
</td></tr>
<tr><td><code id="srm_gif_+3A_params">params</code></td>
<td>

<p>vector of parameters for the proposed SRM model in the order <code class="reqn">(a, b, c)</code>.
</p>
</td></tr>
<tr><td><code id="srm_gif_+3A_tt">TT</code></td>
<td>

<p>vector of length 2, being the time interval over which the integral of the conditional intensity function is to be evaluated.
</p>
</td></tr>
<tr><td><code id="srm_gif_+3A_tplus">tplus</code></td>
<td>
<p>logical, <code class="reqn">\lambda_g(t|{\cal H}_t)</code> is evaluated as <code class="reqn">\lambda_g(t^+|{\cal H}_t)</code> if <code>TRUE</code>, else <code class="reqn">\lambda_g(t^-|{\cal H}_t)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Vere-Jones (1978) proposed the stress release model, being a stochastic version of elastic rebound theory (Reid, 1910). The SRM assumes a deterministic increase in stress over time, and a stochastic release through earthquake events. The conditional intensity function is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_g(t) = \exp\{a + b[t - cS(t)]\},
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
S(t) = \sum_i 10^{0.75(M_i-M_0)}
</code>
</p>

<p>and the summation is taken over those <code class="reqn">i</code> such that <code class="reqn">t_i &lt; t</code>, where <code class="reqn">t_i</code> denotes the event times.
</p>


<h3>Value</h3>

<p>Two usages are as follows.
</p>
<pre>
srm_gif(data, evalpts, params, tplus=FALSE)
srm_gif(data, evalpts=NULL, params, TT)
</pre>
<p>The first usage returns a vector containing the values of <code class="reqn">\lambda_g(t)</code> evaluated at the specified points. In the second usage, it returns the value of the integral.
</p>


<h3>Function Attributes</h3>


<dl>
<dt><code>rate</code></dt><dd><p>is <code>"increasing"</code>.</p>
</dd>
</dl>


<h3>Problems and Inconsistencies</h3>

<p>Runs much slower than <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>. Should set up matrices <code>St1</code> and <code>St2</code> as in <code><a href="#topic+linksrm_gif">linksrm_gif</a></code>.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+PtProcess">PtProcess</a> manual page.
</p>


<h3>See Also</h3>

<p>General details about the structure of conditional intensity functions are given in the topic <code><a href="#topic+gif">gif</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Treating North China as one region

data(NthChina)
p &lt;- c(-2.46, 0.0113, 0.851)
times &lt;- seq(0, 517, 0.5)

par.default &lt;- par(mfrow=c(2,1), mar=c(4.1, 4.1, 0.5, 1))
plot(times+1480, srm_gif(NthChina, times, params=p), type="l",
     ylab=expression(lambda[g](t)),
     xlab="", xlim=c(1480, 2000))
plot(NthChina$time+1480, NthChina$magnitude+6, type="h",
     xlim=c(1480, 2000), ylim=c(5.8, 8.6),
     xlab="Year", ylab="Magnitude")

par(par.default)
</code></pre>

<hr>
<h2 id='summary'>Summary of a Point Process Model</h2><span id='topic+summary'></span><span id='topic+summary.mpp'></span><span id='topic+summary.linksrm'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpp'
summary(object, ...)
## S3 method for class 'linksrm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+mpp">mpp</a>"</code> or <code>"<a href="#topic+linksrm">linksrm</a>"</code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list object with a reduced number of components, mainly the parameter values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TT &lt;- c(0, 1000)
bvalue &lt;- 1
params &lt;- c(-2.5, 0.01, 0.8, bvalue*log(10))

x &lt;- mpp(data=NULL,
         gif=srm_gif,
         marks=list(NULL, rexp_mark),
         params=params,
         gmap=expression(params[1:3]),
         mmap=expression(params[4]),
         TT=TT)
x &lt;- simulate(x, seed=5)

print(summary(x))
</code></pre>

<hr>
<h2 id='Tangshan'>Tangshan Earthquake and Aftershock Sequence</h2><span id='topic+Tangshan'></span>

<h3>Description</h3>

<p>The Tangshan earthquake occurred on 28 July 1976 at 03:42:53, with a magnitude of 7.9. The <code>Tangshan</code> data frame contains those events (455) from the Beijing Catalogue, within 100 km of the epicentre and with magnitude 4 or greater, from the beginning of 1974 to the end of 1984.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Tangshan)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>latitude</dt><dd><p>number of degrees north.</p>
</dd>
<dt>longitude</dt><dd><p>number of degrees east.</p>
</dd>
<dt>magnitude</dt><dd><p>number of magnitude units <em>above</em> 4.</p>
</dd>
<dt>year</dt><dd><p>year of event (numeric vector).</p>
</dd>
<dt>month</dt><dd><p>month of event, 1 ... 12 (numeric vector).</p>
</dd>
<dt>day</dt><dd><p>day of event, 1 ... 31 (numeric vector).</p>
</dd>
<dt>hour</dt><dd><p>hour of event, 0 ... 23 (numeric vector).</p>
</dd>
<dt>minute</dt><dd><p>minute of event, 0 ... 59 (numeric vector).</p>
</dd>
<dt>second</dt><dd><p>second of event, 0 ... 59 (numeric vector).</p>
</dd>
<dt>time</dt><dd><p>number of days (and fractions) from the beginning of 1974.</p>
</dd>
</dl>



<h3>Source</h3>

<p>These data originate from the Beijing Catalogue which is administered by the China Seismological Bureau, Beijing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Tangshan)
print(Tangshan[1:10,])
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
