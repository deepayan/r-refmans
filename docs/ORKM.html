<!DOCTYPE html><html lang="en"><head><title>Help for package ORKM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ORKM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ORKM-package'>
<p>The Online Regularized K-Means Clustering Algorithm</p></a></li>
<li><a href='#cora_view1'>
<p>The first view of Cora data set.</p></a></li>
<li><a href='#cora_view2'>
<p>The second view of Cora data set.</p></a></li>
<li><a href='#cora_view3'>
<p>The third view of Cora data set.</p></a></li>
<li><a href='#cora_view4'>
<p>The fourth view of Cora data set.</p></a></li>
<li><a href='#cornell_cites'>
<p>The first view of Cornell data set.</p></a></li>
<li><a href='#cornell_content'>
<p>The second view of Cornell data set.</p></a></li>
<li><a href='#cornell_inbound'>
<p>The third view of   Cornell data set.</p></a></li>
<li><a href='#cornell_outbound'>
<p>The fourth view of   Cornell data set.</p></a></li>
<li><a href='#DMC'><p>Deep matrix clustering algorithm for multi-view data</p></a></li>
<li><a href='#INDEX'><p>Caculate the indication on the functions</p></a></li>
<li><a href='#KMeans'><p>K-means clustering algorithm for multi/single view data</p></a></li>
<li><a href='#labelcora'>
<p>True clustering labels for Cora data set.</p></a></li>
<li><a href='#labelcornell'>
<p>True clustering labels for Cornell data set.</p></a></li>
<li><a href='#labelTexas'>
<p>True clustering labels for Texas data set.</p></a></li>
<li><a href='#labelWashington'>
<p>True clustering labels for Washington data set.</p></a></li>
<li><a href='#labelWisconsin'>
<p>True clustering labels for  Wisconsin data set.</p></a></li>
<li><a href='#movie_1'>
<p>The first view of Movie data set.</p></a></li>
<li><a href='#movie_2'>
<p>The second view of Movie data set.</p></a></li>
<li><a href='#OGD'><p>Online gradient descent algorithm for online single-view data clustering</p></a></li>
<li><a href='#OMU'><p>Online multiplicative update algorithm for online multi-view data clustering</p></a></li>
<li><a href='#ORKMeans'><p>Online regularized K-means clustering algorithm for online multi-view data</p></a></li>
<li><a href='#PKMeans'>
<p>Power K-means clustering algorithm for single view data</p></a></li>
<li><a href='#QCM'>
<p>The QCM data set with K=5.</p></a></li>
<li><a href='#RKMeans'>
<p>Regularized K-means clustering algorithm for multi-view data</p></a></li>
<li><a href='#seed'>
<p>A single-view data set named Seeds.</p></a></li>
<li><a href='#sobar'>
<p>A single-view data set named Sobar.</p></a></li>
<li><a href='#texas_cites'>
<p>The first view of  Texas data set.</p></a></li>
<li><a href='#texas_content'>
<p>The second view of  Texas dataset.</p></a></li>
<li><a href='#texas_inbound'>
<p>The third view of  Texas data set.</p></a></li>
<li><a href='#texas_outbound'>
<p>The fourth view of  Texas data set.</p></a></li>
<li><a href='#turelabel'>
<p>Ture label of Movie data set.</p></a></li>
<li><a href='#Washington_cites'>
<p>The third view of Washington data set.</p></a></li>
<li><a href='#Washington_content'>
<p>The second view of  Washington data set.</p></a></li>
<li><a href='#Washington_inbound'>
<p>The third view of  Washington data set.</p></a></li>
<li><a href='#Washington_outbound'>
<p>The fourth view of   Washington data set.</p></a></li>
<li><a href='#Wisconsin_cites'>
<p>The first view of   Wisconsin data set.</p></a></li>
<li><a href='#Wisconsin_content'>
<p>The second view of Wisconsin data set.</p></a></li>
<li><a href='#Wisconsin_inbound'>
<p>The third view of  Wisconsin data set.</p></a></li>
<li><a href='#Wisconsin_outbound'>
<p>The fourth view of  Wisconsin data set.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>The Online Regularized K-Means Clustering Algorithm</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-5-5</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Algorithm of online regularized k-means to deal with online multi(single) view data.
 The philosophy of the package is described in Guo G. (2020) 
 &lt;<a href="https://doi.org/10.1080%2F02331888.2020.1823979">doi:10.1080/02331888.2020.1823979</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Guangbao Guo <a href="https://orcid.org/0000-0002-4115-6218"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Miao Yu [aut],
  Haoyue Song [aut],
  Ruiling Niu [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Guangbao Guo &lt;ggb11111111@163.com&gt;</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, Matrix, stats,</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-05 19:28:49 UTC; 14482</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-05 21:50:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='ORKM-package'>
The Online Regularized K-Means Clustering Algorithm
</h2><span id='topic+ORKM-package'></span><span id='topic+ORKM'></span>

<h3>Description</h3>

<p>Algorithm of online regularized k-means to deal with online multi(single) view data.
 The philosophy of the package is described in Guo G. (2020) 
 &lt;doi:10.1080/02331888.2020.1823979&gt;. 
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ORKM</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> The Online Regularized K-Means Clustering Algorithm</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-5-5</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.8.0.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person("Guangbao", "Guo",role = c("aut", "cre"),
           email = "ggb11111111@163.com",
          comment =  c(ORCID = "0000-0002-4115-6218")),
                 person("Miao", "Yu", role="aut"),
 person("Haoyue", "Song", role="aut"),
 person("Ruiling", "Niu", role="aut"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Algorithm of online regularized k-means to deal with online multi(single) view data.
 The philosophy of the package is described in Guo G. (2020) 
 &lt;doi:10.1080/02331888.2020.1823979&gt;. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> MIT + file LICENSE</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
Roxygen: </td><td style="text-align: left;"> list(markdown = TRUE)</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 7.2.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Guangbao Guo [aut, cre] (0000-0002-4115-6218), 
            Miao Yu [aut],
            Haoyue Song [aut],
            Ruiling Niu [aut] </td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Guangbao Guo &lt;ggb11111111@163.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> testthat (&gt;= 3.0.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> MASS,
Matrix,
stats,</td>
</tr>
<tr>
 <td style="text-align: left;">
Config/testthat/edition: </td><td style="text-align: left;"> 3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
DMC                     Deep matrix clustering algorithm for multi-view
                        data
INDEX                   Caculate the indication on the functions
KMeans                  K-means clustering algorithm for multi/single
                        view data
OGD                     Online gradient descent algorithm for online
                        single-view data clustering
OMU                     Online multiplicative update algorithm for
                        online multi-view data clustering
ORKM-package            The Online Regularized K-Means Clustering
                        Algorithm
ORKMeans                Online regularized K-means clustering algorithm
                        for online multi-view data
PKMeans                 Power K-means clustering algorithm for single
                        view data
QCM                     The QCM data set with K=5.
RKMeans                 Regularized K-means clustering algorithm for
                        multi-view data
Washington_cites        The third view of Washington data set.
Washington_content      The second view of Washington data set.
Washington_inbound      The third view of Washington data set.
Washington_outbound     The fourth view of Washington data set.
Wisconsin_cites         The first view of Wisconsin data set.
Wisconsin_content       The second view of Wisconsin data set.
Wisconsin_inbound       The third view of Wisconsin data set.
Wisconsin_outbound      The fourth view of Wisconsin data set.
cora_view1              The first view of Cora data set.
cora_view2              The second view of Cora data set.
cora_view3              The third view of Cora data set.
cora_view4              The fourth view of Cora data set.
cornell_cites           The first view of Cornell data set.
cornell_content         The second view of Cornell data set.
cornell_inbound         The third view of Cornell data set.
cornell_outbound        The fourth view of Cornell data set.
labelTexas              True clustering labels for Texas data set.
labelWashington         True clustering labels for Washington data set.
labelWisconsin          True clustering labels for Wisconsin data set.
labelcora               True clustering labels for Cora data set.
labelcornell            True clustering labels for Cornell data set.
movie_1                 The first view of Movie data set.
movie_2                 The second view of Movie data set.
seed                    A single-view data set named Seeds.
sobar                   A single-view data set named Sobar.
texas_cites             The first view of Texas data set.
texas_content           The second view of Texas dataset.
texas_inbound           The third view of Texas data set.
texas_outbound          The fourth view of Texas data set.
turelabel               Ture label of Movie data set.
</pre>
<p>You can use this package for online multi-view clustering, the dataset and real labels are also provided in the package. 
</p>


<h3>Author(s)</h3>

<p>Guangbao Guo [aut, cre] (0000-0002-4115-6218), 
            Miao Yu [aut],
            Haoyue Song [aut],
            Ruiling Niu [aut] 
</p>
<p>Maintainer: Guangbao Guo &lt;ggb11111111@163.com&gt;
</p>


<h3>References</h3>

<p>Guangbao Guo, Miao Yu, Guoqi Qian, (2023), Orkm: Online Regularized k-Means Clustering for Online Multi-View Data.
</p>


<h3>See Also</h3>

<p>https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4484209
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
library(Matrix)  
  yita=0.5;V=2;chushi=100;K=3;r=0.5;max.iter=10;n1=n2=n3=70;gamma=0.1;alpha=0.98;epsilon=1
  X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
  Xv&lt;-c(X1,X2,X3)
  data&lt;-matrix(Xv,n1+n2+n3,2)
  data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
  truere=data[,2]
  X&lt;-matrix(data[,1],n1+n2+n3,1) 
  lamda1&lt;-0.2;lamda2&lt;-0.8
  lamda&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
  sol.svd &lt;- svd(lamda)
  U1&lt;-sol.svd$u
  D1&lt;-sol.svd$d
  V1&lt;-sol.svd$v
  C1&lt;-t(U1)
  Y1&lt;-C1/D1
  view&lt;-V1
  view1&lt;-matrix(view[1,])
  view2&lt;-matrix(view[2,])
  X1&lt;-matrix(view1,n1+n2+n3,1)
  X2&lt;-matrix(view2,n1+n2+n3,1)
  ORKMeans(X=X1,K=K,V=V,r=r,chushi=chushi,yita=yita,gamma=gamma,epsilon=epsilon,
max.iter=max.iter,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='cora_view1'>
The first view of Cora data set. 
</h2><span id='topic+cora_view1'></span>

<h3>Description</h3>

<p>This data matrix is the first view of the multi-view data set called Cora, the keyword view.  Cora data set is a multi-view data set of machine learning papers with 4 views, a sample size of nearly 3000 and a number of features of 1500, with a number of clusters of K=4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cora_view1")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:2708, 1:2708] 0 0 0 0 0 0 0 0 1 0 ...
</p>


<h3>Details</h3>

<p>Cora data set includes keyword view, inbound, outbound link view, and citation network view. It takes the form of a sparse matrix. It has 2708 samples and 2708 features.
</p>


<h3>Source</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>References</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cora_view1); str(cora_view1) 
</code></pre>

<hr>
<h2 id='cora_view2'>
The second view of Cora data set.
</h2><span id='topic+cora_view2'></span>

<h3>Description</h3>

<p>This data matrix is the second view of Cora data set. It called the citation network view and the form of a sparse matrix. It has 2708 samples and 1433 features. Cora data set is a multi-view data set of machine learning papers with 4 views, a sample size of nearly 3000 and a number of features of 1500, with a number of clusters of K=4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cora_view2")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:2708, 1:1433] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>The second view of Cora data set.
</p>


<h3>Source</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>References</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cora_view2); str(cora_view2) 
</code></pre>

<hr>
<h2 id='cora_view3'>
The third view of Cora data set.
</h2><span id='topic+cora_view3'></span>

<h3>Description</h3>

<p>This data matrix is the third view of Cora data set. It called the inbound link view and the form of a sparse matrix. It has 2708 samples and 2708 features.  Cora data set is a multi-view data set of machine learning papers with 4 views, a sample size of nearly 3000 and a number of features of 1500, with a number of clusters of K=4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cora_view3")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:2708, 1:2708] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>The third view of Cora data set.
</p>


<h3>Source</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>References</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cora_view3); str(cora_view3) 
</code></pre>

<hr>
<h2 id='cora_view4'>
The fourth view of Cora data set.
</h2><span id='topic+cora_view4'></span>

<h3>Description</h3>

<p>The fourth view(outbound view) of Cora data set.  Cora data set is a multi-view data set of machine learning papers with 4 views, a sample size of nearly 3000 and a number of features of 1500, with a number of clusters of K=4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cora_view4")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:2708, 1:2708] 0 0 0 0 0 0 0 0 1 0 ...
</p>


<h3>Details</h3>

<p>The fourth view of Cora data set.
</p>


<h3>Source</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>References</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cora_view4); str(cora_view4) 
</code></pre>

<hr>
<h2 id='cornell_cites'>
The first view of Cornell data set.
</h2><span id='topic+cornell_cites'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data, Cornell data set,   Texas data set,  Washington dataset, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cornell_cites")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:195, 1:195] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Cornell data set contains four views with a number of clusters of 5. This data set is the first view with a sample size of 195 and a number of features of 195.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cornell_cites)
## maybe str(cornell_cites) ; plot(cornell_cites) ...
</code></pre>

<hr>
<h2 id='cornell_content'>
The second view of Cornell data set.
</h2><span id='topic+cornell_content'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data, Cornell data set,  Texas data set,   Washington data set, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cornell_content")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:195, 1:1703] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Cornell data set contains four views with a number of clusters of 5. This data set is the second view with a sample size of 195 and a number of features of 1703.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cornell_content)
## maybe str(cornell_content) ; plot(cornell_content) ...
</code></pre>

<hr>
<h2 id='cornell_inbound'>
The third view of   Cornell data set.
</h2><span id='topic+cornell_inbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,   Cornell data set,   Texas data set,  Washington dataset, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cornell_inbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:195, 1:195] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Cornell data set contains four views with a number of clusters of 5. This data set is the third view with a sample size of 195 and a number of features of 195.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cornell_inbound)
## maybe str(cornell_inbound) ; plot(cornell_inbound) ...
</code></pre>

<hr>
<h2 id='cornell_outbound'>
The fourth view of   Cornell data set.
</h2><span id='topic+cornell_outbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and    Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("cornell_outbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:195, 1:195] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Cornell data set contains four views with a number of clusters of 5. This data set is the fourth view with a sample size of 195 and a number of features of 195.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cornell_outbound)
## maybe str(cornell_outbound) ; plot(cornell_outbound) ...
</code></pre>

<hr>
<h2 id='DMC'>Deep matrix clustering algorithm for multi-view data</h2><span id='topic+DMC'></span>

<h3>Description</h3>

<p>This algorithm decomposes the multi-view data matrix into representative subspaces layer by layer, and generates a cluster at each layer. To enhance the diversity between the generated clusters, new redundant quantifiers arising from the proximity between samples in these subspaces are minimised. An iterative optimisation process is further introduced to simultaneously seek multiple clusters with quality and diversity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DMC(X, K, V, r, lamda, truere, max.iter, method = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DMC_+3A_x">X</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="DMC_+3A_k">K</code></td>
<td>
<p>number of cluster</p>
</td></tr>
<tr><td><code id="DMC_+3A_v">V</code></td>
<td>
<p>number of view</p>
</td></tr>
<tr><td><code id="DMC_+3A_r">r</code></td>
<td>
<p>first banlance parameter</p>
</td></tr>
<tr><td><code id="DMC_+3A_lamda">lamda</code></td>
<td>
<p>second balance parameter</p>
</td></tr>
<tr><td><code id="DMC_+3A_truere">truere</code></td>
<td>
<p>true cluster result</p>
</td></tr>
<tr><td><code id="DMC_+3A_max.iter">max.iter</code></td>
<td>
<p>max iter</p>
</td></tr>
<tr><td><code id="DMC_+3A_method">method</code></td>
<td>
<p>caculate the index of NMI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NMI,Alpha1,center,result
</p>


<h3>Author(s)</h3>

<p>Miao Yu
</p>


<h3>Examples</h3>

<pre><code class='language-R'> library(MASS)   
 V=2;lamda=0.5;K=3;r=0.5;max.iter=10;n1=n2=n3=70
 X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
 Xv&lt;-c(X1,X2,X3)
 data&lt;-matrix(Xv,n1+n2+n3,2)
 data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
 truere=data[,2]
 X&lt;-matrix(data[,1],n1+n2+n3,1) 
 lamda1&lt;-0.2;lamda2&lt;-0.8
 lamda0&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
 sol.svd &lt;- svd(lamda0)
 U1&lt;-sol.svd$u
 D1&lt;-sol.svd$d
 V1&lt;-sol.svd$v
 C1&lt;-t(U1)%*%t(X)
 Y1&lt;-C1/D1
 view&lt;-V1%*%Y1
 view1&lt;-matrix(view[1,])
 view2&lt;-matrix(view[2,])
 X1&lt;-matrix(view1,n1+n2+n3,1)
 X2&lt;-matrix(view2,n1+n2+n3,1)
 DMC(X=X1,K=K,V=V,lamda=lamda,r=r,max.iter=max.iter,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='INDEX'>Caculate the indication on the functions
</h2><span id='topic+INDEX'></span>

<h3>Description</h3>

<p>This function contains the calculation of five clustering effect evaluation metrics, specifically, Purity, NMI, F-score, RI, Precision and Recall, which are used to evaluate the clustering effect of the above functions, method=0 purity;method=1,precision; method=2,recall; method=3, F-score; method=4, RI.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>INDEX(vec1, vec2, method = 0, mybeta = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="INDEX_+3A_vec1">vec1</code></td>
<td>
<p>algorithm cluster result</p>
</td></tr>
<tr><td><code id="INDEX_+3A_vec2">vec2</code></td>
<td>
<p>true cluster result</p>
</td></tr>
<tr><td><code id="INDEX_+3A_method">method</code></td>
<td>
<p>Calculate the selection of indicators.</p>
</td></tr>
<tr><td><code id="INDEX_+3A_mybeta">mybeta</code></td>
<td>
<p>caculate the index </p>
</td></tr>
</table>


<h3>Value</h3>

<p>accuracy
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P1&lt;-c(1,1,1,2,3,2,1);truelabel&lt;-c(1,1,1,2,2,2,3)
INDEX(P1,truelabel,method=0);INDEX(P1,truelabel,method=2)
</code></pre>

<hr>
<h2 id='KMeans'>K-means clustering algorithm for multi/single view data</h2><span id='topic+KMeans'></span>

<h3>Description</h3>

<p>The K-means clustering algorithm is a common clustering algorithm that divides a data set into K clusters, with each cluster represented using the mean of all samples within the cluster, referring to that mean as the j-cluster centre. The algorithm is unsupervised learning, where the categories are not known in advance and similar objects are automatically grouped into the same cluster. The K-means algorithm achieves clustering by calculating the distance between each point and the centre of mass of different clusters and assigning it to the nearest cluster. The algorithm is simple and easy to implement, but is susceptible to the initial centre of mass, the possibility of empty clusters, and the possibility of convergence to local minima. Clustering applications can be used to discover different groups of users, allowing for tasks such as precision marketing, document segmentation, finding people in the same circle in social networks, and handling anomalous data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KMeans(X, K, V, r, max.iter, truere, method = 0)
</code></pre>


<h3>Arguments</h3>

  
<table role = "presentation">
<tr><td><code id="KMeans_+3A_x">X</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="KMeans_+3A_k">K</code></td>
<td>
<p>number of cluster</p>
</td></tr>
<tr><td><code id="KMeans_+3A_v">V</code></td>
<td>
<p>number of view</p>
</td></tr>
<tr><td><code id="KMeans_+3A_r">r</code></td>
<td>
<p>balance parameter</p>
</td></tr>
<tr><td><code id="KMeans_+3A_truere">truere</code></td>
<td>
<p>true cluster result</p>
</td></tr>
<tr><td><code id="KMeans_+3A_max.iter">max.iter</code></td>
<td>
<p>max iter</p>
</td></tr>
<tr><td><code id="KMeans_+3A_method">method</code></td>
<td>
<p>caculate the index of NMI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NMI,weight,center,result
</p>


<h3>Author(s)</h3>

<p>Miao Yu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(MASS)
  library(Matrix)   
  V=2;K=3;r=0.5;max.iter=10;n1=n2=n3=70
  X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
  Xv&lt;-c(X1,X2,X3)
  data&lt;-matrix(Xv,n1+n2+n3,2)
  data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
  truere=data[,2]
  X&lt;-matrix(data[,1],n1+n2+n3,1) 
  lamda1&lt;-0.2;lamda2&lt;-0.8
  lamda&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
  sol.svd &lt;- svd(lamda)
  U1&lt;-sol.svd$u
  D1&lt;-sol.svd$d
  V1&lt;-sol.svd$v
  C1&lt;-t(U1)
  Y1&lt;-C1/D1
  view&lt;-V1
  view1&lt;-matrix(view[1,])
  view2&lt;-matrix(view[2,])
  X1&lt;-matrix(view1,n1+n2+n3,1)
  X2&lt;-matrix(view2,n1+n2+n3,1)
  KMeans(X=X1,K=K,V=V,r=r,max.iter=max.iter,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='labelcora'>
True clustering labels for Cora data set.
</h2><span id='topic+labelcora'></span>

<h3>Description</h3>

<p>True clustering labels for the Cora dataset, which can be applied to 4 views.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("labelcora")</code></pre>


<h3>Format</h3>

<p>The format is:
chr [1:2708] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;3&quot; &quot;4&quot; &quot;4&quot; &quot;5&quot; &quot;1&quot; &quot;1&quot; &quot;5&quot; &quot;1&quot; &quot;6&quot; &quot;4&quot; &quot;7&quot; ...
</p>


<h3>Details</h3>

<p>True clustering labels for the Cora dataset, which can be applied to 4 views.
</p>


<h3>Source</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>References</h3>

<p>http://www.cs.umd.edu/projects/linqs/projects/lbc/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(labelcora)
</code></pre>

<hr>
<h2 id='labelcornell'>
True clustering labels for Cornell data set.
</h2><span id='topic+labelcornell'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data, Cornell data set, Texas data set,  Washington data set, and Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("labelcornell")</code></pre>


<h3>Format</h3>

<p>The format is:
int [1:195, 1] 1 1 2 3 3 3 2 4 3 3 ...
- attr(*, &quot;dimnames&quot;)=List of 2
..$ : NULL
..$ : chr &quot;V1&quot;
</p>


<h3>Details</h3>

<p>Cornell dat aset contains four views with a number of clusters of 5. You can use this true label to calculate your clustering accuracy.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(labelcornell)
## maybe str(labelcornell) ; plot(labelcornell) ...
</code></pre>

<hr>
<h2 id='labelTexas'>
True clustering labels for Texas data set.
</h2><span id='topic+labelTexas'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data, Cornell data set,  Texas data set, Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("labelTexas")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:187] 1 2 3 1 4 3 3 3 4 1 ...
</p>


<h3>Details</h3>

<p>Texas data set contains four views with a number of clusters of 5. You can use this true label to calculate your clustering accuracy.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(labelTexas)
## maybe str(labelTexas) ; plot(labelTexas) ...
</code></pre>

<hr>
<h2 id='labelWashington'>
True clustering labels for Washington data set.
</h2><span id='topic+labelWashington'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("labelWashington")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:230] 1 2 2 2 2 2 2 2 2 2 ...
</p>


<h3>Details</h3>

<p>Washington data set contains four views with a number of clusters of 5. You can use this true label to calculate your clustering accuracy.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(labelWashington)
## maybe str(labelWashington) ; plot(labelWashington) ...
</code></pre>

<hr>
<h2 id='labelWisconsin'>
True clustering labels for  Wisconsin data set.
</h2><span id='topic+labelWisconsin'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell dataset,  Texas dataset,   Washington dataset, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("labelWisconsin")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:265] 1 2 3 3 1 1 1 1 1 1 ...
</p>


<h3>Details</h3>

<p>Wisconsin data set contains four views with a number of clusters of 5. You can use this true label to calculate your clustering accuracy.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(labelWisconsin)
## maybe str(labelWisconsin) ; plot(labelWisconsin) ...
</code></pre>

<hr>
<h2 id='movie_1'>
The first view of Movie data set.
</h2><span id='topic+movie_1'></span>

<h3>Description</h3>

<p>The first view(keyword view) of Movie data set. Movie data set contains 2 views, each containing 1878 variables from 617 instances, and the number of clusters to be clustered is K = 17. The number of clusters is large, so it is difficult to cluster. The data set was extracted from IMDb and the main objective was to to find the movie genres, combined from two view matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("movie_1")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:617, 1:1878] 1 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>The first view of Movie dataset.
</p>


<h3>Source</h3>

<p>https://lig-membres.imag.fr/grimal/data.html.
</p>


<h3>References</h3>

<p>C. Grimal. the multi-view movie data set. 2010. URL https://lig-membres.imag.fr/grimal/data.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(movie_1); str(movie_1) 
</code></pre>

<hr>
<h2 id='movie_2'>
The second view of Movie data set.
</h2><span id='topic+movie_2'></span>

<h3>Description</h3>

<p>The second view(participant view) of Movie data set.  Movie data set contains 2 views, each containing 1878 variables from 617 instances, and the number of clusters to be clustered is K = 17. The number of clusters is large, so it is difficult to cluster. The data set was extracted from IMDb and the main objective was to to find the movie genres, combined from two view matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("movie_2")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:617, 1:1398] 1 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>The second view of Movie data set.
</p>


<h3>Source</h3>

<p>https://lig-membres.imag.fr/grimal/data.html.
</p>


<h3>References</h3>

<p>C. Grimal. the multi-view movie data set. 2010. URL https://lig-membres.imag.fr/grimal/data.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(movie_2); str(movie_2) 
</code></pre>

<hr>
<h2 id='OGD'>Online gradient descent algorithm for online single-view data clustering</h2><span id='topic+OGD'></span>

<h3>Description</h3>

<p>Online gradient descent is an optimisation algorithm in machine learning for when the amount of data is too large to process all the data at the same time. In this algorithm, the model parameters are updated based on a single training sample, rather than using the entire training set. The direction of each update is determined by the direction of the gradient of the current sample, and the local or global extremes of the gradient descent algorithm depend on the order of the sampled samples. Compared to Batch Gradient Descent (BGD) algorithm, online gradient descent algorithms can process data streams and update the model as they process the data, and are therefore more efficient for large-scale data. However, online gradient descent algorithm should only be used if the data stream is continuously present and updated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OGD(X, K, gamma, max.m, chushi, yita, epsilon, truere, method = 0)
</code></pre>


<h3>Arguments</h3>

  
<table role = "presentation">
<tr><td><code id="OGD_+3A_x">X</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="OGD_+3A_k">K</code></td>
<td>
<p>number of cluster</p>
</td></tr>
<tr><td><code id="OGD_+3A_gamma">gamma</code></td>
<td>
<p>step size</p>
</td></tr>
<tr><td><code id="OGD_+3A_yita">yita</code></td>
<td>
<p>the regularized parameter</p>
</td></tr>
<tr><td><code id="OGD_+3A_truere">truere</code></td>
<td>
<p>true cluster result</p>
</td></tr>
<tr><td><code id="OGD_+3A_max.m">max.m</code></td>
<td>
<p>max iter</p>
</td></tr>
<tr><td><code id="OGD_+3A_epsilon">epsilon</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="OGD_+3A_chushi">chushi</code></td>
<td>
<p>the initial value</p>
</td></tr>
<tr><td><code id="OGD_+3A_method">method</code></td>
<td>
<p>caculate the index of NMI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>result,NMI,M
</p>


<h3>Author(s)</h3>

<p>Miao Yu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>yita=0.5;V=2;K=3;chushi=100;epsilon=1;gamma=0.1;max.m=10;n1=n2=n3=70
 X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
 Xv&lt;-c(X1,X2,X3)
 data&lt;-matrix(Xv,n1+n2+n3,2)
 data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
 X&lt;-matrix(data[,1],n1+n2+n3,1) 
 truere=data[,2]
 lamda1&lt;-0.2;lamda2&lt;-0.8
 lamda&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
 sol.svd &lt;- svd(lamda)
  U1&lt;-sol.svd$u
 D1&lt;-sol.svd$d
 V1&lt;-sol.svd$v
 C1&lt;-t(U1)
 Y1&lt;-C1/D1
 view&lt;-V1
 view1&lt;-matrix(view[1,])
 view2&lt;-matrix(view[2,])
 X1&lt;-matrix(view1,n1+n2+n3,1)
 X2&lt;-matrix(view2,n1+n2+n3,1)
 OGD(X=X1,K=K,gamma=gamma,max.m=max.m,chushi=chushi,
yita=yita,epsilon=epsilon,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='OMU'>Online multiplicative update algorithm for online multi-view data clustering</h2><span id='topic+OMU'></span>

<h3>Description</h3>

<p>This algorithm integrates the multiplicative normalization factor as an additional term in the original additivity update rule, which usually has approximately opposite direction. Thus, the improved iteration rule can be easily converted to a multiplicative version. After each iteration After each iteration, non-negativity is maintained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OMU(X,K,V,chushi,yita,r,max.iter,epsilon,truere,method=0)
</code></pre>


<h3>Arguments</h3>

  
<table role = "presentation">
<tr><td><code id="OMU_+3A_x">X</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="OMU_+3A_k">K</code></td>
<td>
<p>number of cluster</p>
</td></tr>
<tr><td><code id="OMU_+3A_v">V</code></td>
<td>
<p>number of view</p>
</td></tr>
<tr><td><code id="OMU_+3A_chushi">chushi</code></td>
<td>
<p>the initial value</p>
</td></tr>
<tr><td><code id="OMU_+3A_yita">yita</code></td>
<td>
<p>the regularized parameter</p>
</td></tr>
<tr><td><code id="OMU_+3A_r">r</code></td>
<td>
<p>banlance parameter</p>
</td></tr>
<tr><td><code id="OMU_+3A_max.iter">max.iter</code></td>
<td>
<p>max iter</p>
</td></tr>
<tr><td><code id="OMU_+3A_epsilon">epsilon</code></td>
<td>
<p>epsilon</p>
</td></tr>
<tr><td><code id="OMU_+3A_truere">truere</code></td>
<td>
<p>true cluster result</p>
</td></tr>
<tr><td><code id="OMU_+3A_method">method</code></td>
<td>
<p>caculate the index of NMI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NMI,result,M
</p>


<h3>Examples</h3>

<pre><code class='language-R'> yita=0.5;V=2;chushi=100;K=3;r=0.5;max.iter=10;n1=n2=n3=70;epsilon=1
 X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
 Xv&lt;-c(X1,X2,X3)
 data&lt;-matrix(Xv,n1+n2+n3,2)
 data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
 truere=data[,2]
 X&lt;-matrix(data[,1],n1+n2+n3,1) 
 lamda1&lt;-0.2;lamda2&lt;-0.8
 lamda&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
 sol.svd &lt;- svd(lamda)
 U1&lt;-sol.svd$u
 D1&lt;-sol.svd$d
 V1&lt;-sol.svd$v
 C1&lt;-t(U1)%*%t(X)
 Y1&lt;-C1/D1
 view&lt;-V1%*%Y1
 view1&lt;-matrix(view[1,])
 view2&lt;-matrix(view[2,])
 X1&lt;-matrix(view1,n1+n2+n3,1)
 X2&lt;-matrix(view2,n1+n2+n3,1)
 OMU(X=X1,K=K,V=V,chushi=chushi,yita=yita,r=r,max.iter=max.iter,
epsilon=epsilon,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='ORKMeans'>Online regularized K-means clustering algorithm for online multi-view data</h2><span id='topic+ORKMeans'></span>

<h3>Description</h3>

<p>For the online clustering problem, this function proposes the Online Regularized K-means Clustering (ORKMC) method to deal with online multi-view data. Firstly, for the clustering problem of multi-view data, a non-negative matrix decomposition is used as the starting point of the model to find the indicator matrix and cluster centres of each cluster; for online updating, a projected gradient descent method is proposed to perform online updating to improve the accuracy and speed of data clustering; for the overfitting phenomenon, regularisation is proposed to avoid the above problem. In addition, since the choice of regularization parameters is extremely important to the effectiveness of the ORKMC algorithm, the choice of regularization parameters varies in different datasets. In this paper, a suitable range of regularisation parameters and model parameters is given. The effectiveness of the ORKMC algorithm is tested through an extensive study of multi-view/single-view data. The validity of the ORKMC algorithm is tested through an extensive study of multi-view/single-view data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ORKMeans(X,K,V,chushi,r,yita,gamma,alpha,epsilon,truere,max.iter,method=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ORKMeans_+3A_x">X</code></td>
<td>

<p>is the online single/multi-view data matrix
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_k">K</code></td>
<td>

<p>is the number of cluster 
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_v">V</code></td>
<td>

<p>is the view of X
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_chushi">chushi</code></td>
<td>

<p>is the initial value for online
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_yita">yita</code></td>
<td>

<p>is the regularized parameter
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_r">r</code></td>
<td>

<p>is the banlance parameter
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_gamma">gamma</code></td>
<td>

<p>is the step size 
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_alpha">alpha</code></td>
<td>

<p>is the caculated the weight of view 
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_epsilon">epsilon</code></td>
<td>

<p>is the epsilon 
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_truere">truere</code></td>
<td>

<p>is the ture label in data set
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_max.iter">max.iter</code></td>
<td>

<p>is the max iter
</p>
</td></tr>
<tr><td><code id="ORKMeans_+3A_method">method</code></td>
<td>

<p>is the caluate the NMI
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NMI,weight,center,result
</p>


<h3>Author(s)</h3>

<p>Miao Yu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
library(Matrix)  
  yita=0.5;V=2;chushi=100;K=3;r=0.5;max.iter=10;n1=n2=n3=70;gamma=0.1;alpha=0.98;epsilon=1
  X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
  Xv&lt;-c(X1,X2,X3)
  data&lt;-matrix(Xv,n1+n2+n3,2)
  data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
  truere=data[,2]
  X&lt;-matrix(data[,1],n1+n2+n3,1) 
  lamda1&lt;-0.2;lamda2&lt;-0.8
  lamda&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
  sol.svd &lt;- svd(lamda)
  U1&lt;-sol.svd$u
  D1&lt;-sol.svd$d
  V1&lt;-sol.svd$v
  C1&lt;-t(U1)
  Y1&lt;-C1/D1
  view&lt;-V1
  view1&lt;-matrix(view[1,])
  view2&lt;-matrix(view[2,])
  X1&lt;-matrix(view1,n1+n2+n3,1)
  X2&lt;-matrix(view2,n1+n2+n3,1)
  ORKMeans(X=X1,K=K,V=V,r=r,chushi=chushi,yita=yita,gamma=gamma,epsilon=epsilon,
max.iter=max.iter,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='PKMeans'>
Power K-means clustering algorithm for single view data
</h2><span id='topic+PKMeans'></span>

<h3>Description</h3>

<p>The power K-means algorithm is a generalization of the Lloyd algorithm, which approximates the ordinary K-means algorithm by a majorization-minimization method with the descent properties and lower complexity of the Lloyd algorithm. The power K-means embeds the K-means problem into a series of better performing problems. These smooth intermediate problems have a smoother objective function and tend to guide the clustering to find a global minimum with the K-means as the objective. The method has the same iteration complexity as Lloyd's algorithm, reduces sensitivity to initialization, and greatly improves algorithm performance in the high-dimensional case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PKMeans(X, K, yitapower, sm, max.m, truere, method = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PKMeans_+3A_x">X</code></td>
<td>

<p>is the data matrix
</p>
</td></tr>
<tr><td><code id="PKMeans_+3A_k">K</code></td>
<td>

<p>is the number of cluster 
</p>
</td></tr>
<tr><td><code id="PKMeans_+3A_yitapower">yitapower</code></td>
<td>

<p>is the regularized parameter
</p>
</td></tr>
<tr><td><code id="PKMeans_+3A_sm">sm</code></td>
<td>

<p>is the banlance parameter
</p>
</td></tr>
<tr><td><code id="PKMeans_+3A_max.m">max.m</code></td>
<td>

<p>is the max iter
</p>
</td></tr>
<tr><td><code id="PKMeans_+3A_truere">truere</code></td>
<td>

<p>is the ture label in data set
</p>
</td></tr>
<tr><td><code id="PKMeans_+3A_method">method</code></td>
<td>

<p>is the caluate the NMI
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>center,NMI,result
</p>


<h3>Author(s)</h3>

<p>Miao Yu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)   
  yitapower=0.5;K=3;sm=0.5;max.m=100;n1=n2=n3=70
  X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
  Xv&lt;-c(X1,X2,X3)
  data&lt;-matrix(Xv,n1+n2+n3,2)
  data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
  truere=data[,2]
  X11&lt;-matrix(data[,1],n1+n2+n3,1) 
  PKMeans(X=X11,K=K,yitapower=yitapower,sm=sm,max.m=max.m,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='QCM'>
The QCM data set with K=5.
</h2><span id='topic+QCM'></span>

<h3>Description</h3>

<p>Five different QCM gas sensors were used and five different gas measurements were made for each sensor (1-octanol, 1-propanol, 2-butanol, 2-propanol and 1-isobutanol).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("QCM")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:125, 1:15] -10.06 -9.69 -12.07 -14.21 -16.57 ...
</p>


<h3>Details</h3>

<p>The QCM data set with K=5.
</p>


<h3>Source</h3>

<p>https://www.sciencedirect.com/science/article/pii/S2215098619303337.
</p>


<h3>References</h3>

<p>M. F. Adak, P. Lieberzeit, P. Jarujamrus, and N. Yumusak. Classification of alcohols obtained by qcm sensors with different characteristics using abc based neural network. Engineering Science and Technology, an International Journal, 23(3):463â€“469, 2020. ISSN 2215-0986. doi: https://doi.
org/10.1016/j.jestch.2019.06.011. URL https://www.sciencedirect.com/science/article/pii/S2215098619303337.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(QCM); str(QCM) 
</code></pre>

<hr>
<h2 id='RKMeans'>
Regularized K-means clustering algorithm for multi-view data
</h2><span id='topic+RKMeans'></span>

<h3>Description</h3>

<p>This function improves the regularized K-means clustering (RKMC) algorithm for the multi-view data clustering problem. Specifically, the regularisation term is added to the K-means algorithm to avoid overfitting of the data. Numerical analysis shows that the RKMC algorithm significantly improves the clustering performance compared to other methods. In addition, in order to reveal the structure of real data as realistically as possible, improve the clustering accuracy of high-dimensional data, and balance the weights of each view, the RKMC algorithm assigns a series of learnable weight values to each view, thus reflecting the relationship and compatibility of each view more flexibly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RKMeans(X, K, V, yita, r, max.iter, truere, method = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RKMeans_+3A_x">X</code></td>
<td>

<p>is the data matrix
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_k">K</code></td>
<td>

<p>is the number of cluster
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_v">V</code></td>
<td>

<p>is the view of X
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_yita">yita</code></td>
<td>

<p>is the regularized parameter
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_r">r</code></td>
<td>

<p>is the banlance parameter
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_max.iter">max.iter</code></td>
<td>

<p>is the max iter
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_truere">truere</code></td>
<td>

<p>is the ture label in data set
</p>
</td></tr>
<tr><td><code id="RKMeans_+3A_method">method</code></td>
<td>

<p>is the caluate the NMI
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NMI,weight,center,result
</p>


<h3>Author(s)</h3>

<p>Miao Yu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(MASS) 
  library(Matrix)  
  yita=0.5;V=2;K=3;r=0.5;max.iter=10;n1=n2=n3=70
  X1&lt;-rnorm(n1,20,2);X2&lt;-rnorm(n2,25,1.5);X3&lt;-rnorm(n3,30,2) 
  Xv&lt;-c(X1,X2,X3)
  data&lt;-matrix(Xv,n1+n2+n3,2)
  data[1:70,2]&lt;-1;data[71:140,2]&lt;-2;data[141:210,2]&lt;-3
  X&lt;-matrix(data[,1],n1+n2+n3,1) 
  truere=data[,2]
  lamda1&lt;-0.2;lamda2&lt;-0.8
  lamda&lt;-matrix(c(lamda1,lamda2),nrow=1,ncol=2)
  sol.svd &lt;- svd(lamda)
  U1&lt;-sol.svd$u
  D1&lt;-sol.svd$d
  V1&lt;-sol.svd$v
  C1&lt;-t(U1)
  Y1&lt;-C1/D1
  view&lt;-V1
  view1&lt;-matrix(view[1,])
  view2&lt;-matrix(view[2,])
  X1&lt;-matrix(view1,n1+n2+n3,1)
  X2&lt;-matrix(view2,n1+n2+n3,1)
  RKMeans(X=X1,K=K,V=V,yita=yita,r=r,max.iter=max.iter,truere=truere,method=0)
</code></pre>

<hr>
<h2 id='seed'>
A single-view data set named Seeds.
</h2><span id='topic+seed'></span>

<h3>Description</h3>

<p>The Seeds data set holds data on the area, circumference, compaction, seed length, seed width, asymmetry factor, length of the ventral groove of the seed and category data for different varieties of wheat seeds. The data set contains a total of 210 records, 7 features, and one label, which is divided into 3 categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("seed")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:210, 1:8] 15.3 14.9 14.3 13.8 16.1 ...
</p>


<h3>Details</h3>

<p>A single-view data set named seed.
</p>


<h3>Source</h3>

<p>http://archive.ics.uci.edu/ml/datasets/seeds
</p>


<h3>References</h3>

<p>http://archive.ics.uci.edu/ml/datasets/seeds
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(seed); str(seed) 
</code></pre>

<hr>
<h2 id='sobar'>
A single-view data set named Sobar.
</h2><span id='topic+sobar'></span>

<h3>Description</h3>

<p>A single-view data set named Sobar.  Sobar data set is a behavioural risk data set for cervical cancer, which has a number of clusters of 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("sobar")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:72, 1:20] 10 10 10 10 8 10 10 8 10 7 ...
</p>


<h3>Details</h3>

<p>A single-view data set named sobar.
</p>


<h3>Source</h3>

<p>http://archive.ics.uci.edu/ml/datasets/Cervical+Cancer+Behavior+Risk
</p>


<h3>References</h3>

<p>http://archive.ics.uci.edu/ml/datasets/Cervical+Cancer+Behavior+Risk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sobar); str(sobar) 
</code></pre>

<hr>
<h2 id='texas_cites'>
The first view of  Texas data set.
</h2><span id='topic+texas_cites'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set, Texas data set,  Washington data set, and Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("texas_cites")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:187, 1:187] 0 1 1 1 0 1 1 0 1 0 ...
</p>


<h3>Details</h3>

<p>Texas data set contains four views with a number of clusters of 5. This data set is the first view with a sample size of 187 and a number of features of 187.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(texas_cites)
## maybe str(texas_cites) ; plot(texas_cites) ...
</code></pre>

<hr>
<h2 id='texas_content'>
The second view of  Texas dataset.
</h2><span id='topic+texas_content'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,   Cornell dataset,  Texas dataset,   Washington dataset, and  Wisconsin dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("texas_content")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:187, 1:1703] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Texas data set contains four views with a number of clusters of 5. This data set is the second view with a sample size of 187 and a number of features of 1703.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(texas_content)
## maybe str(texas_content) ; plot(texas_content) ...
</code></pre>

<hr>
<h2 id='texas_inbound'>
The third view of  Texas data set.
</h2><span id='topic+texas_inbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("texas_inbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:187, 1:187] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Texas data set contains four views with a number of clusters of 5. This data set is the third view with a sample size of 187 and a number of features of 187.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(texas_inbound)
## maybe str(texas_inbound) ; plot(texas_inbound) ...
</code></pre>

<hr>
<h2 id='texas_outbound'>
The fourth view of  Texas data set.
</h2><span id='topic+texas_outbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("texas_outbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:187, 1:187] 0 1 1 1 0 1 1 0 1 0 ...
</p>


<h3>Details</h3>

<p>Texas data set contains four views with a number of clusters of 5. This data set is the fourth view with a sample size of 187 and a number of features of 187.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(texas_outbound)
## maybe str(texas_outbound) ; plot(texas_outbound) ...
</code></pre>

<hr>
<h2 id='turelabel'>
Ture label of Movie data set.
</h2><span id='topic+turelabel'></span>

<h3>Description</h3>

<p>Ture label of Movie data set. You can use it to calculate the accuracy of the clustering results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("turelabel")</code></pre>


<h3>Format</h3>

<p>A data frame with 617 observations on the following variable.
</p>

<dl>
<dt><code>V1</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Ture label of Movie data set.
</p>


<h3>Source</h3>

<p>https://lig-membres.imag.fr/grimal/data.html.
</p>


<h3>References</h3>

<p>C. Grimal. the multi-view movie data set. 2010. URL https://lig-membres.imag.fr/grimal/data.html.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(turelabel)
## maybe str(turelabel) ; plot(turelabel) ...
</code></pre>

<hr>
<h2 id='Washington_cites'>
The third view of Washington data set.
</h2><span id='topic+Washington_cites'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Washington_cites")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:230, 1:230] 2 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Washington data set contains four views with a number of clusters of 5. This data set is the third view with a sample size of 230 and a number of features of 230.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Washington_cites)
## maybe str(Washington_cites) ; plot(Washington_cites) ...
</code></pre>

<hr>
<h2 id='Washington_content'>
The second view of  Washington data set.
</h2><span id='topic+Washington_content'></span>

<h3>Description</h3>

<p>Webkb dataset contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,   Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Washington_content")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:230, 1:1703] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Washington data set contains four views with a number of clusters of 5. This data set is the second view with a sample size of 230 and a number of features of 1703.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Washington_content)
## maybe str(Washington_content) ; plot(Washington_content) ...
</code></pre>

<hr>
<h2 id='Washington_inbound'>
The third view of  Washington data set.
</h2><span id='topic+Washington_inbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Washington_inbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:230, 1:230] 1 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Washington data set contains four views with a number of clusters of 5. This data set is the third view with a sample size of 230 and a number of features of 230.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Washington_inbound)
## maybe str(Washington_inbound) ; plot(Washington_inbound) ...
</code></pre>

<hr>
<h2 id='Washington_outbound'>
The fourth view of   Washington data set.
</h2><span id='topic+Washington_outbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Washington_outbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:230, 1:230] 1 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Washington data set contains four views with a number of clusters of 5. This data set is the fourth view with a sample size of 230 and a number of features of 230.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Washington_outbound)
## maybe str(Washington_outbound) ; plot(Washington_outbound) ...
</code></pre>

<hr>
<h2 id='Wisconsin_cites'>
The first view of   Wisconsin data set.
</h2><span id='topic+Wisconsin_cites'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Wisconsin_cites")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:265, 1:265] 0 1 0 1 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Wisconsin data set contains four views with a number of clusters of 5. This data set is the first view with a sample size of 265 and a number of features of 265.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Wisconsin_cites)
## maybe str(Wisconsin_cites) ; plot(Wisconsin_cites) ...
</code></pre>

<hr>
<h2 id='Wisconsin_content'>
The second view of Wisconsin data set.
</h2><span id='topic+Wisconsin_content'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data, Cornell data set,  Texas data set,  Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Wisconsin_content")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:265, 1:1703] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Wisconsin data set contains four views with a number of clusters of 5. This data set is the second view with a sample size of 265 and a number of features of 1703.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Wisconsin_content)
## maybe str(Wisconsin_content) ; plot(Wisconsin_content) ...
</code></pre>

<hr>
<h2 id='Wisconsin_inbound'>
The third view of  Wisconsin data set.
</h2><span id='topic+Wisconsin_inbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,  Cornell data set,   Texas data set,  Washington data set, and   Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Wisconsin_inbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:265, 1:265] 0 1 0 1 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Wisconsin data set contains four views with a number of clusters of 5. This data set is the third view with a sample size of 265 and a number of features of 265.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Wisconsin_inbound)
## maybe str(Wisconsin_inbound) ; plot(Wisconsin_inbound) ...
</code></pre>

<hr>
<h2 id='Wisconsin_outbound'>
The fourth view of  Wisconsin data set.
</h2><span id='topic+Wisconsin_outbound'></span>

<h3>Description</h3>

<p>Webkb data set contains web pages from four universities, with the corresponding clusters categorised as Professor, Student, Program, or Other pages. The data set contains four subsets of data,   Cornell data set,  Texas data set, Washington data set, and  Wisconsin data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Wisconsin_outbound")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:265, 1:265] 0 0 0 0 0 0 0 0 0 0 ...
</p>


<h3>Details</h3>

<p>Wisconsin data set contains four views with a number of clusters of 5. This data set is the fourth view with a sample size of 265 and a number of features of 265.
</p>


<h3>Source</h3>

<p>http://www.cs.cmu.edu/~webkb/
</p>


<h3>References</h3>

<p>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam and S. Slattery. Learning to Extract Symbolic Knowledge from the World Wide Web. Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Wisconsin_outbound)
## maybe str(Wisconsin_outbound) ; plot(Wisconsin_outbound) ...
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
