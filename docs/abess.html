<!DOCTYPE html><html lang="en"><head><title>Help for package abess</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {abess}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abess-package'><p>abess: Fast Best Subset Selection</p></a></li>
<li><a href='#abess.default'><p>Adaptive best subset selection (for generalized linear model)</p></a></li>
<li><a href='#abesspca'><p>Adaptive best subset selection for principal component analysis</p></a></li>
<li><a href='#abessrpca'><p>Adaptive best subset selection for robust principal component analysis</p></a></li>
<li><a href='#coef.abess'><p>Extract Model Coefficients from a fitted &quot;<code>abess</code>&quot; object.</p></a></li>
<li><a href='#coef.abesspca'><p>Extract Sparse Loadings from a fitted &quot;<code>abesspca</code>&quot; object.</p></a></li>
<li><a href='#coef.abessrpca'><p>Extract sparse component from a fitted &quot;<code>abessrpca</code>&quot; object.</p></a></li>
<li><a href='#deviance.abess'><p>Extract the deviance from a fitted &quot;<code>abess</code>&quot; object.</p></a></li>
<li><a href='#extract'><p>Extract one model from a fitted &quot;<code>abess</code>&quot; object.</p></a></li>
<li><a href='#generate.data'><p>Generate simulated data</p></a></li>
<li><a href='#generate.matrix'><p>Generate matrix composed of a sparse matrix and low-rank matrix</p></a></li>
<li><a href='#generate.spc.matrix'><p>Generate matrix with sparse principal component</p></a></li>
<li><a href='#plot.abess'><p>Creat plot from a fitted &quot;<code>abess</code>&quot; object</p></a></li>
<li><a href='#plot.abesspca'><p>Creat plot from a fitted &quot;<code>abess</code>&quot; object</p></a></li>
<li><a href='#plot.abessrpca'><p>Creat plot from a fitted &quot;<code>abessrpca</code>&quot; object</p></a></li>
<li><a href='#predict.abess'><p>Make predictions from a fitted &quot;<code>abess</code>&quot; object.</p></a></li>
<li><a href='#print.abess'><p>Print method for a fitted &quot;<code>abess</code>&quot; object</p></a></li>
<li><a href='#print.abesspca'><p>Print method for a fitted &quot;<code>abesspca</code>&quot; object</p></a></li>
<li><a href='#print.abessrpca'><p>Print method for a fitted &quot;<code>abessrpca</code>&quot; object</p></a></li>
<li><a href='#trim32'><p>The Bardet-Biedl syndrome Gene expression data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Best Subset Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.9</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-09</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jin Zhu &lt;zhuj37@mail2.sysu.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Extremely efficient toolkit for solving the best subset selection problem <a href="https://www.jmlr.org/papers/v23/21-1060.html">https://www.jmlr.org/papers/v23/21-1060.html</a>. This package is its R interface. The package implements and generalizes algorithms designed in &lt;<a href="https://doi.org/10.1073%2Fpnas.2014241117">doi:10.1073/pnas.2014241117</a>&gt; that exploits a novel sequencing-and-splicing technique to guarantee exact support recovery and globally optimal solution in polynomial times for linear model. It also supports best subset selection for logistic regression, Poisson regression, Cox proportional hazard model, Gamma regression, multiple-response regression, multinomial logistic regression, ordinal regression, (sequential) principal component analysis, and robust principal component analysis. The other valuable features such as the best subset of group selection &lt;<a href="https://doi.org/10.1287%2Fijoc.2022.1241">doi:10.1287/ijoc.2022.1241</a>&gt; and sure independence screening &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2008.00674.x">doi:10.1111/j.1467-9868.2008.00674.x</a>&gt; are also provided.  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a> | file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, MASS, methods, Matrix</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/abess-team/abess">https://github.com/abess-team/abess</a>,
<a href="https://abess-team.github.io/abess/">https://abess-team.github.io/abess/</a>,
<a href="https://abess.readthedocs.io">https://abess.readthedocs.io</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/abess-team/abess/issues">https://github.com/abess-team/abess/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-09 05:12:40 UTC; zhujin</td>
</tr>
<tr>
<td>Author:</td>
<td>Jin Zhu <a href="https://orcid.org/0000-0001-8550-5822"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Zezhi Wang [aut],
  Liyuan Hu [aut],
  Junhao Huang [aut],
  Kangkang Jiang [aut],
  Yanhang Zhang [aut],
  Borui Tang [aut],
  Shiyun Lin [aut],
  Junxian Zhu [aut],
  Canhong Wen [aut],
  Heping Zhang <a href="https://orcid.org/0000-0002-0688-4076"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Xueqin Wang <a href="https://orcid.org/0000-0001-5205-9950"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  spectra contributors [cph] (Spectra implementation)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-09 06:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='abess-package'>abess: Fast Best Subset Selection</h2><span id='topic+abess-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>Extremely efficient toolkit for solving the best subset selection problem <a href="https://www.jmlr.org/papers/v23/21-1060.html">https://www.jmlr.org/papers/v23/21-1060.html</a>. This package is its R interface. The package implements and generalizes algorithms designed in <a href="https://doi.org/10.1073/pnas.2014241117">doi:10.1073/pnas.2014241117</a> that exploits a novel sequencing-and-splicing technique to guarantee exact support recovery and globally optimal solution in polynomial times for linear model. It also supports best subset selection for logistic regression, Poisson regression, Cox proportional hazard model, Gamma regression, multiple-response regression, multinomial logistic regression, ordinal regression, (sequential) principal component analysis, and robust principal component analysis. The other valuable features such as the best subset of group selection <a href="https://doi.org/10.1287/ijoc.2022.1241">doi:10.1287/ijoc.2022.1241</a> and sure independence screening <a href="https://doi.org/10.1111/j.1467-9868.2008.00674.x">doi:10.1111/j.1467-9868.2008.00674.x</a> are also provided.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jin Zhu <a href="mailto:zhuj37@mail2.sysu.edu.cn">zhuj37@mail2.sysu.edu.cn</a> (<a href="https://orcid.org/0000-0001-8550-5822">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Zezhi Wang <a href="mailto:homura@mail.ustc.edu.cn">homura@mail.ustc.edu.cn</a>
</p>
</li>
<li><p> Liyuan Hu <a href="mailto:huly5@mail2.sysu.edu.cn">huly5@mail2.sysu.edu.cn</a>
</p>
</li>
<li><p> Junhao Huang <a href="mailto:huangjh256@mail2.sysu.edu.cn">huangjh256@mail2.sysu.edu.cn</a>
</p>
</li>
<li><p> Kangkang Jiang <a href="mailto:jiangkk3@mail2.sysu.edu.cn">jiangkk3@mail2.sysu.edu.cn</a>
</p>
</li>
<li><p> Yanhang Zhang <a href="mailto:zhangyh98@ruc.edu.cn">zhangyh98@ruc.edu.cn</a>
</p>
</li>
<li><p> Borui Tang <a href="mailto:tangborui@mail.ustc.edu.cn">tangborui@mail.ustc.edu.cn</a>
</p>
</li>
<li><p> Shiyun Lin <a href="mailto:shiyunlin@stu.pku.edu.cn">shiyunlin@stu.pku.edu.cn</a>
</p>
</li>
<li><p> Junxian Zhu <a href="mailto:adaizjx@163.com">adaizjx@163.com</a>
</p>
</li>
<li><p> Canhong Wen <a href="mailto:wencanhong@gmail.com">wencanhong@gmail.com</a>
</p>
</li>
<li><p> Heping Zhang <a href="mailto:heping.zhang@yale.edu">heping.zhang@yale.edu</a> (<a href="https://orcid.org/0000-0002-0688-4076">ORCID</a>)
</p>
</li>
<li><p> Xueqin Wang <a href="mailto:wangxq20@ustc.edu.cn">wangxq20@ustc.edu.cn</a> (<a href="https://orcid.org/0000-0001-5205-9950">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> spectra contributors (Spectra implementation) [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/abess-team/abess">https://github.com/abess-team/abess</a>
</p>
</li>
<li> <p><a href="https://abess-team.github.io/abess/">https://abess-team.github.io/abess/</a>
</p>
</li>
<li> <p><a href="https://abess.readthedocs.io">https://abess.readthedocs.io</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/abess-team/abess/issues">https://github.com/abess-team/abess/issues</a>
</p>
</li></ul>


<hr>
<h2 id='abess.default'>Adaptive best subset selection (for generalized linear model)</h2><span id='topic+abess.default'></span><span id='topic+abess'></span><span id='topic+abess.formula'></span>

<h3>Description</h3>

<p>Adaptive best-subset selection for regression,
(multi-class) classification, counting-response, censored-response,
positive response, multi-response modeling in polynomial times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
abess(
  x,
  y,
  family = c("gaussian", "binomial", "poisson", "cox", "mgaussian", "multinomial",
    "gamma", "ordinal"),
  tune.path = c("sequence", "gsection"),
  tune.type = c("gic", "ebic", "bic", "aic", "cv"),
  weight = NULL,
  normalize = NULL,
  fit.intercept = TRUE,
  beta.low = -.Machine$double.xmax,
  beta.high = .Machine$double.xmax,
  c.max = 2,
  support.size = NULL,
  gs.range = NULL,
  lambda = 0,
  always.include = NULL,
  group.index = NULL,
  init.active.set = NULL,
  splicing.type = 2,
  max.splicing.iter = 20,
  screening.num = NULL,
  important.search = NULL,
  warm.start = TRUE,
  nfolds = 5,
  foldid = NULL,
  cov.update = FALSE,
  newton = c("exact", "approx"),
  newton.thresh = 1e-06,
  max.newton.iter = NULL,
  early.stop = FALSE,
  ic.scale = 1,
  num.threads = 0,
  seed = 1,
  ...
)

## S3 method for class 'formula'
abess(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="abess.default_+3A_x">x</code></td>
<td>
<p>Input matrix, of dimension <code class="reqn">n \times p</code>; each row is an observation
vector and each column is a predictor/feature/variable.
Can be in sparse matrix format (inherit from class <code>"dgCMatrix"</code> in package <code>Matrix</code>).</p>
</td></tr>
<tr><td><code id="abess.default_+3A_y">y</code></td>
<td>
<p>The response variable, of <code>n</code> observations.
For <code>family = "binomial"</code> should have two levels.
For <code>family="poisson"</code>, <code>y</code> should be a vector with positive integer.
For <code>family = "cox"</code>, <code>y</code> should be a <code>Surv</code> object returned
by the <code>survival</code> package (recommended) or
a two-column matrix with columns named <code>"time"</code> and <code>"status"</code>.
For <code>family = "mgaussian"</code>, <code>y</code> should be a matrix of quantitative responses.
For <code>family = "multinomial"</code> or <code>"ordinal"</code>, <code>y</code> should be a factor of at least three levels.
Note that, for either <code>"binomial"</code>, <code>"ordinal"</code> or <code>"multinomial"</code>,
if y is presented as a numerical vector, it will be coerced into a factor.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_family">family</code></td>
<td>
<p>One of the following models:
<code>"gaussian"</code> (continuous response),
<code>"binomial"</code> (binary response),
<code>"poisson"</code> (non-negative count),
<code>"cox"</code> (left-censored response),
<code>"mgaussian"</code> (multivariate continuous response),
<code>"multinomial"</code> (multi-class response),
<code>"ordinal"</code> (multi-class ordinal response),
<code>"gamma"</code> (positive continuous response).
Depending on the response. Any unambiguous substring can be given.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_tune.path">tune.path</code></td>
<td>
<p>The method to be used to select the optimal support size. For
<code>tune.path = "sequence"</code>, we solve the best subset selection problem for each size in <code>support.size</code>.
For <code>tune.path = "gsection"</code>, we solve the best subset selection problem with support size ranged in <code>gs.range</code>,
where the specific support size to be considered is determined by golden section.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_tune.type">tune.type</code></td>
<td>
<p>The type of criterion for choosing the support size.
Available options are <code>"gic"</code>, <code>"ebic"</code>, <code>"bic"</code>, <code>"aic"</code> and <code>"cv"</code>.
Default is <code>"gic"</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_weight">weight</code></td>
<td>
<p>Observation weights. When <code>weight = NULL</code>,
we set <code>weight = 1</code> for each observation as default.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_normalize">normalize</code></td>
<td>
<p>Options for normalization.
<code>normalize = 0</code> for no normalization.
<code>normalize = 1</code> for subtracting the means of the columns of <code>x</code> and <code>y</code>, and also
normalizing the columns of <code>x</code> to have <code class="reqn">\sqrt n</code> norm.
<code>normalize = 2</code> for subtracting the mean of columns of <code>x</code> and
scaling the columns of <code>x</code> to have <code class="reqn">\sqrt n</code> norm.
<code>normalize = 3</code> for scaling the columns of <code>x</code> to have <code class="reqn">\sqrt n</code> norm.
If <code>normalize = NULL</code>, <code>normalize</code> will be set <code>1</code> for <code>"gaussian"</code> and <code>"mgaussian"</code>,
<code>3</code> for <code>"cox"</code>. Default is <code>normalize = NULL</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_fit.intercept">fit.intercept</code></td>
<td>
<p>A boolean value indicating whether to fit an intercept.
We assume the data has been centered if <code>fit.intercept = FALSE</code>.
Default: <code>fit.intercept = FALSE</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_beta.low">beta.low</code></td>
<td>
<p>A single value specifying the lower bound of <code class="reqn">\beta</code>. Default is <code>-.Machine$double.xmax</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_beta.high">beta.high</code></td>
<td>
<p>A single value specifying the upper bound of <code class="reqn">\beta</code>. Default is <code>.Machine$double.xmax</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_c.max">c.max</code></td>
<td>
<p>an integer splicing size. Default is: <code>c.max = 2</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_support.size">support.size</code></td>
<td>
<p>An integer vector representing the alternative support sizes.
Only used for <code>tune.path = "sequence"</code>. Default is <code>0:min(n, round(n/(log(log(n))log(p))))</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_gs.range">gs.range</code></td>
<td>
<p>A integer vector with two elements.
The first element is the minimum model size considered by golden-section,
the later one is the maximum one. Default is <code>gs.range = c(1, min(n, round(n/(log(log(n))log(p)))))</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_lambda">lambda</code></td>
<td>
<p>A single lambda value for regularized best subset selection. Default is 0.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_always.include">always.include</code></td>
<td>
<p>An integer vector containing the indexes of variables that should always be included in the model.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_group.index">group.index</code></td>
<td>
<p>A vector of integers indicating the which group each variable is in.
For variables in the same group, they should be located in adjacent columns of <code>x</code>
and their corresponding index in <code>group.index</code> should be the same.
Denote the first group as <code>1</code>, the second <code>2</code>, etc.
If you do not fit a model with a group structure,
please set <code>group.index = NULL</code> (the default).</p>
</td></tr>
<tr><td><code id="abess.default_+3A_init.active.set">init.active.set</code></td>
<td>
<p>A vector of integers indicating the initial active set.
Default: <code>init.active.set = NULL</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_splicing.type">splicing.type</code></td>
<td>
<p>Optional type for splicing.
If <code>splicing.type = 1</code>, the number of variables to be spliced is
<code>c.max</code>, ..., <code>1</code>; if <code>splicing.type = 2</code>,
the number of variables to be spliced is <code>c.max</code>, <code>c.max/2</code>, ..., <code>1</code>.
(Default: <code>splicing.type = 2</code>.)</p>
</td></tr>
<tr><td><code id="abess.default_+3A_max.splicing.iter">max.splicing.iter</code></td>
<td>
<p>The maximum number of performing splicing algorithm.
In most of the case, only a few times of splicing iteration can guarantee the convergence.
Default is <code>max.splicing.iter = 20</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_screening.num">screening.num</code></td>
<td>
<p>An integer number. Preserve <code>screening.num</code> number of predictors with the largest
marginal maximum likelihood estimator before running algorithm.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_important.search">important.search</code></td>
<td>
<p>An integer number indicating the number of
important variables to be splicing.
When <code>important.search</code> <code class="reqn">\ll</code> <code>p</code> variables,
it would greatly reduce runtimes. Default: <code>important.search = 128</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_warm.start">warm.start</code></td>
<td>
<p>Whether to use the last solution as a warm start. Default is <code>warm.start = TRUE</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds in cross-validation. Default is <code>nfolds = 5</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_foldid">foldid</code></td>
<td>
<p>an optional integer vector of values between 1, ..., nfolds identifying what fold each observation is in.
The default <code>foldid = NULL</code> would generate a random foldid.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_cov.update">cov.update</code></td>
<td>
<p>A logical value only used for <code>family = "gaussian"</code>. If <code>cov.update = TRUE</code>,
use a covariance-based implementation; otherwise, a naive implementation.
The naive method is more computational efficient than covariance-based method when <code class="reqn">p &gt;&gt; n</code> and <code>important.search</code> is much large than its default value.
Default: <code>cov.update = FALSE</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_newton">newton</code></td>
<td>
<p>A character specify the Newton's method for fitting generalized linear models,
it should be either <code>newton = "exact"</code> or <code>newton = "approx"</code>.
If <code>newton = "exact"</code>, then the exact hessian is used,
while <code>newton = "approx"</code> uses diagonal entry of the hessian,
and can be faster (especially when <code>family = "cox"</code>).</p>
</td></tr>
<tr><td><code id="abess.default_+3A_newton.thresh">newton.thresh</code></td>
<td>
<p>a numeric value for controlling positive convergence tolerance.
The Newton's iterations converge when <code class="reqn">|dev - dev_{old}|/(|dev| + 0.1)&lt;</code> <code>newton.thresh</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_max.newton.iter">max.newton.iter</code></td>
<td>
<p>a integer giving the maximal number of Newton's iteration iterations.
Default is <code>max.newton.iter = 10</code> if <code>newton = "exact"</code>, and <code>max.newton.iter = 60</code> if <code>newton = "approx"</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_early.stop">early.stop</code></td>
<td>
<p>A boolean value decide whether early stopping.
If <code>early.stop = TRUE</code>, algorithm will stop if the last tuning value less than the existing one.
Default: <code>early.stop = FALSE</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_ic.scale">ic.scale</code></td>
<td>
<p>A non-negative value used for multiplying the penalty term
in information criterion. Default: <code>ic.scale = 1</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_num.threads">num.threads</code></td>
<td>
<p>An integer decide the number of threads to be
concurrently used for cross-validation (i.e., <code>tune.type = "cv"</code>).
If <code>num.threads = 0</code>, then all of available cores will be used.
Default: <code>num.threads = 0</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_seed">seed</code></td>
<td>
<p>Seed to be used to divide the sample into cross-validation folds.
Default is <code>seed = 1</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;<code>formula</code>&quot;:
a symbolic description of the model to be fitted.
The details of model specification are given in the &quot;Details&quot; section of &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot;.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables in the <code>formula</code>.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="abess.default_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates
what should happen when the data contain <code>NA</code>s.
Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Best-subset selection aims to find a small subset of predictors,
so that the resulting model is expected to have the most desirable prediction accuracy.
Best-subset selection problem under the support size <code class="reqn">s</code> is
</p>
<p style="text-align: center;"><code class="reqn">\min_\beta -2 \log L(\beta) \;\;{\rm s.t.}\;\; \|\beta\|_0 \leq s,</code>
</p>

<p>where <code class="reqn">L(\beta)</code> is arbitrary convex functions. In
the GLM case, <code class="reqn">\log L(\beta)</code> is the log-likelihood function; in the Cox
model, <code class="reqn">\log L(\beta)</code> is the log partial-likelihood function.
The best subset selection problem is solved by the splicing algorithm in this package, see Zhu (2020) for details.
Under mild conditions, the algorithm exactly solve this problem in polynomial time.
This algorithm exploits the idea of sequencing and splicing to reach a stable solution in finite steps when <code class="reqn">s</code> is fixed.
The parameters <code>c.max</code>, <code>splicing.type</code> and <code>max.splicing.iter</code> allow user control the splicing technique flexibly.
On the basis of our numerical experiment results, we assign properly parameters to the these parameters as the default
such that the precision and runtime are well balanced, we suggest users keep the default values unchanged.
Please see <a href="https://abess-team.github.io/abess/articles/v10-algorithm.html">this online page</a> for more details about the splicing algorithm.
</p>
<p>To find the optimal support size <code class="reqn">s</code>,
we provide various criterion like GIC, AIC, BIC and cross-validation error to determine it.
More specifically, the sequence of models implied by <code>support.size</code> are fit by the splicing algorithm.
And the solved model with least information criterion or cross-validation error is the optimal model.
The sequential searching for the optimal model is somehow time-wasting.
A faster strategy is golden section (GS), which only need to specify <code>gs.range</code>.
More details about GS is referred to Zhang et al (2021).
</p>
<p>It is worthy to note that the parameters <code>newton</code>, <code>max.newton.iter</code> and <code>newton.thresh</code> allows
user control the parameter estimation in non-gaussian models.
The parameter estimation procedure use Newton method or approximated Newton method (only consider the diagonal elements in the Hessian matrix).
Again, we suggest to use the default values unchanged because the same reason for the parameter <code>c.max</code>.
</p>
<p><code>abess</code> support some well-known advanced statistical methods to analyze data, including
</p>

<ul>
<li><p> sure independent screening: helpful for ultra-high dimensional predictors (i.e., <code class="reqn">p \gg n</code>). Use the parameter <code>screening.num</code> to retain the marginally most important predictors. See Fan et al (2008) for more details.
</p>
</li>
<li><p> best subset of group selection: helpful when predictors have group structure. Use the parameter <code>group.index</code> to specify the group structure of predictors. See Zhang et al (2021) for more details.
</p>
</li>
<li> <p><code class="reqn">l_2</code> regularization best subset selection: helpful when signal-to-ratio is relatively small. Use the parameter <code>lambda</code> to control the magnitude of the regularization term.
</p>
</li>
<li><p> nuisance selection: helpful when the prior knowledge of important predictors is available. Use the parameter <code>always.include</code> to retain the important predictors.
</p>
</li></ul>

<p>The arbitrary combination of the four methods are definitely support.
Please see <a href="https://abess-team.github.io/abess/articles/v07-advancedFeatures.html">online vignettes</a> for more details about the advanced features support by <code>abess</code>.
</p>


<h3>Value</h3>

<p>A S3 <code>abess</code> class object, which is a <code>list</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>A <code class="reqn">p</code>-by-<code>length(support.size)</code> matrix of coefficients for univariate family, stored in column format;
while a list of <code>length(support.size)</code> coefficients matrix (with size <code class="reqn">p</code>-by-<code>ncol(y)</code>) for multivariate family.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>An intercept vector of length <code>length(support.size)</code> for univariate family;
while a list of <code>length(support.size)</code> intercept vector (with size <code>ncol(y)</code>) for multivariate family.</p>
</td></tr>
<tr><td><code>dev</code></td>
<td>
<p>the deviance of length <code>length(support.size)</code>.</p>
</td></tr>
<tr><td><code>tune.value</code></td>
<td>
<p>A value of tuning criterion of length <code>length(support.size)</code>.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>The number of sample used for training.</p>
</td></tr>
<tr><td><code>nvars</code></td>
<td>
<p>The number of variables used for training.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>Type of the model.</p>
</td></tr>
<tr><td><code>tune.path</code></td>
<td>
<p>The path type for tuning parameters.</p>
</td></tr>
<tr><td><code>support.size</code></td>
<td>
<p>The actual <code>support.size</code> values used.
Note that it is not necessary the same as the input
if the later have non-integer values or duplicated values.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>The effective degree of freedom.
It is the same as <code>support.size</code> when <code>lambda = 0</code>.</p>
</td></tr>
<tr><td><code>best.size</code></td>
<td>
<p>The best support size selected by the tuning value.</p>
</td></tr>
<tr><td><code>tune.type</code></td>
<td>
<p>The criterion type for tuning parameters.</p>
</td></tr>
<tr><td><code>tune.path</code></td>
<td>
<p>The strategy for tuning parameters.</p>
</td></tr>
<tr><td><code>screening.vars</code></td>
<td>
<p>The character vector specify the feature
selected by feature screening.
It would be an empty character vector if <code>screening.num = 0</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The original call to <code>abess</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jin Zhu, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang
</p>


<h3>References</h3>

<p>A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; <a href="https://doi.org/10.1073/pnas.2014241117">doi:10.1073/pnas.2014241117</a>
</p>
<p>A Splicing Approach to Best Subset of Groups Selection. Zhang, Yanhang, Junxian Zhu, Jin Zhu, and Xueqin Wang (2023). INFORMS Journal on Computing, 35:1, 104-119. <a href="https://doi.org/10.1287/ijoc.2022.1241">doi:10.1287/ijoc.2022.1241</a>
</p>
<p>abess: A Fast Best-Subset Selection Library in Python and R. Zhu Jin, Xueqin Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Shiyun Lin, and Junxian Zhu. Journal of Machine Learning Research 23, no. 202 (2022): 1-7.
</p>
<p>Sure independence screening for ultrahigh dimensional feature space. Fan, J. and Lv, J. (2008), Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70: 849-911. <a href="https://doi.org/10.1111/j.1467-9868.2008.00674.x">doi:10.1111/j.1467-9868.2008.00674.x</a>
</p>
<p>Targeted Inference Involving High-Dimensional Data Using Nuisance Penalized Regression. Qiang Sun &amp; Heping Zhang (2020). Journal of the American Statistical Association, <a href="https://doi.org/10.1080/01621459.2020.1737079">doi:10.1080/01621459.2020.1737079</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(abess)
Sys.setenv("OMP_THREAD_LIMIT" = 2)
n &lt;- 100
p &lt;- 20
support.size &lt;- 3

################ linear model ################
dataset &lt;- generate.data(n, p, support.size)
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]])
## helpful generic functions:
print(abess_fit)
coef(abess_fit, support.size = 3)
predict(abess_fit,
  newx = dataset[["x"]][1:10, ],
  support.size = c(3, 4)
)
str(extract(abess_fit, 3))
deviance(abess_fit)
plot(abess_fit)
plot(abess_fit, type = "tune")

################ logistic model ################
dataset &lt;- generate.data(n, p, support.size, family = "binomial")
## allow cross-validation to tuning
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  family = "binomial", tune.type = "cv"
)
abess_fit

################ poisson model ################
dataset &lt;- generate.data(n, p, support.size, family = "poisson")
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  family = "poisson", tune.type = "cv"
)
abess_fit

################ Cox model ################
dataset &lt;- generate.data(n, p, support.size, family = "cox")
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  family = "cox", tune.type = "cv"
)

################ Multivariate gaussian model ################
dataset &lt;- generate.data(n, p, support.size, family = "mgaussian")
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  family = "mgaussian", tune.type = "cv"
)
plot(abess_fit, type = "l2norm")

################ Multinomial model (multi-classification) ################
dataset &lt;- generate.data(n, p, support.size, family = "multinomial")
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  family = "multinomial", tune.type = "cv"
)
predict(abess_fit,
  newx = dataset[["x"]][1:10, ],
  support.size = c(3, 4), type = "response"
)

################ Ordinal regression  ################
dataset &lt;- generate.data(n, p, support.size, family = "ordinal", class.num = 4)
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  family = "ordinal", tune.type = "cv"
)
coef &lt;- coef(abess_fit, support.size = abess_fit[["best.size"]])[[1]]
predict(abess_fit,
  newx = dataset[["x"]][1:10, ],
  support.size = c(3, 4), type = "response"
)

########## Best group subset selection #############
dataset &lt;- generate.data(n, p, support.size)
group_index &lt;- rep(1:10, each = 2)
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]], group.index = group_index)
str(extract(abess_fit))

################ Golden section searching ################
dataset &lt;- generate.data(n, p, support.size)
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]], tune.path = "gsection")
abess_fit

################ Feature screening ################
p &lt;- 1000
dataset &lt;- generate.data(n, p, support.size)
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]],
  screening.num = 100
)
str(extract(abess_fit))

################ Sparse predictor ################
require(Matrix)
p &lt;- 1000
dataset &lt;- generate.data(n, p, support.size)
dataset[["x"]][abs(dataset[["x"]]) &lt; 1] &lt;- 0
dataset[["x"]] &lt;- Matrix(dataset[["x"]])
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]])
str(extract(abess_fit))


################  Formula interface  ################
data("trim32")
abess_fit &lt;- abess(y ~ ., data = trim32)
abess_fit

</code></pre>

<hr>
<h2 id='abesspca'>Adaptive best subset selection for principal component analysis</h2><span id='topic+abesspca'></span>

<h3>Description</h3>

<p>Adaptive best subset selection for principal component analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abesspca(
  x,
  type = c("predictor", "gram"),
  sparse.type = c("fpc", "kpc"),
  cor = FALSE,
  kpc.num = NULL,
  support.size = NULL,
  gs.range = NULL,
  tune.path = c("sequence", "gsection"),
  tune.type = c("gic", "aic", "bic", "ebic", "cv"),
  nfolds = 5,
  foldid = NULL,
  ic.scale = 1,
  c.max = NULL,
  always.include = NULL,
  group.index = NULL,
  screening.num = NULL,
  splicing.type = 1,
  max.splicing.iter = 20,
  warm.start = TRUE,
  num.threads = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="abesspca_+3A_x">x</code></td>
<td>
<p>A matrix object. It can be either a predictor matrix
where each row is an observation and each column is a predictor or
a sample covariance/correlation matrix.
If <code>x</code> is a predictor matrix, it can be in sparse matrix format
(inherit from class <code>"dgCMatrix"</code> in package <code>Matrix</code>).</p>
</td></tr>
<tr><td><code id="abesspca_+3A_type">type</code></td>
<td>
<p>If <code>type = "predictor"</code>, <code>x</code> is considered as the predictor matrix.
If <code>type = "gram"</code>, <code>x</code> is considered as a sample covariance or correlation matrix.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_sparse.type">sparse.type</code></td>
<td>
<p>If <code>sparse.type = "fpc"</code>, then best subset selection performs on the first principal component;
If <code>sparse.type = "kpc"</code>, then best subset selection would be sequentially performed on the first <code>kpc.num</code> number of principal components.
If <code>kpc.num</code> is supplied, the default is <code>sparse.type = "kpc"</code>; otherwise, is <code>sparse.type = "fpc"</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_cor">cor</code></td>
<td>
<p>A logical value. If <code>cor = TRUE</code>, perform PCA on the correlation matrix;
otherwise, the covariance matrix.
This option is available only if <code>type = "predictor"</code>.
Default: <code>cor = FALSE</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_kpc.num">kpc.num</code></td>
<td>
<p>A integer decide the number of principal components to be sequentially considered.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_support.size">support.size</code></td>
<td>
<p>It is a flexible input. If it is an integer vector.
It represents the support sizes to be considered for each principal component.
If it is a <code>list</code> object containing <code>kpc.num</code> number of integer vectors,
the i-th principal component consider the support size specified in the i-th element in the <code>list</code>.
Only used for <code>tune.path = "sequence"</code>.
The default is <code>support.size = NULL</code>, and some rules in details section are used to specify <code>support.size</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_gs.range">gs.range</code></td>
<td>
<p>A integer vector with two elements.
The first element is the minimum model size considered by golden-section,
the later one is the maximum one. Default is <code>gs.range = c(1, min(n, round(n/(log(log(n))log(p)))))</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_tune.path">tune.path</code></td>
<td>
<p>The method to be used to select the optimal support size. For
<code>tune.path = "sequence"</code>, we solve the best subset selection problem for each size in <code>support.size</code>.
For <code>tune.path = "gsection"</code>, we solve the best subset selection problem with support size ranged in <code>gs.range</code>,
where the specific support size to be considered is determined by golden section.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_tune.type">tune.type</code></td>
<td>
<p>The type of criterion for choosing the support size.
Available options are <code>"gic"</code>, <code>"ebic"</code>, <code>"bic"</code>, <code>"aic"</code> and <code>"cv"</code>.
Default is <code>"gic"</code>.
<code>tune.type = "cv"</code> is available only when <code>type = "predictor"</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds in cross-validation. Default is <code>nfolds = 5</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_foldid">foldid</code></td>
<td>
<p>an optional integer vector of values between 1, ..., nfolds identifying what fold each observation is in.
The default <code>foldid = NULL</code> would generate a random foldid.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_ic.scale">ic.scale</code></td>
<td>
<p>A non-negative value used for multiplying the penalty term
in information criterion. Default: <code>ic.scale = 1</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_c.max">c.max</code></td>
<td>
<p>an integer splicing size. The default of <code>c.max</code> is the maximum of 2 and <code>max(support.size) / 2</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_always.include">always.include</code></td>
<td>
<p>An integer vector containing the indexes of variables that should always be included in the model.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_group.index">group.index</code></td>
<td>
<p>A vector of integers indicating the which group each variable is in.
For variables in the same group, they should be located in adjacent columns of <code>x</code>
and their corresponding index in <code>group.index</code> should be the same.
Denote the first group as <code>1</code>, the second <code>2</code>, etc.
If you do not fit a model with a group structure,
please set <code>group.index = NULL</code> (the default).</p>
</td></tr>
<tr><td><code id="abesspca_+3A_screening.num">screening.num</code></td>
<td>
<p>An integer number. Preserve <code>screening.num</code> number of predictors with the largest
marginal maximum likelihood estimator before running algorithm.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_splicing.type">splicing.type</code></td>
<td>
<p>Optional type for splicing.
If <code>splicing.type = 1</code>, the number of variables to be spliced is
<code>c.max</code>, ..., <code>1</code>; if <code>splicing.type = 2</code>,
the number of variables to be spliced is <code>c.max</code>, <code>c.max/2</code>, ..., <code>1</code>.
Default: <code>splicing.type = 1</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_max.splicing.iter">max.splicing.iter</code></td>
<td>
<p>The maximum number of performing splicing algorithm.
In most of the case, only a few times of splicing iteration can guarantee the convergence.
Default is <code>max.splicing.iter = 20</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_warm.start">warm.start</code></td>
<td>
<p>Whether to use the last solution as a warm start. Default is <code>warm.start = TRUE</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_num.threads">num.threads</code></td>
<td>
<p>An integer decide the number of threads to be
concurrently used for cross-validation (i.e., <code>tune.type = "cv"</code>).
If <code>num.threads = 0</code>, then all of available cores will be used.
Default: <code>num.threads = 0</code>.</p>
</td></tr>
<tr><td><code id="abesspca_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adaptive best subset selection for principal component analysis (abessPCA) aim
to solve the non-convex optimization problem:
</p>
<p style="text-align: center;"><code class="reqn">-\arg\min_{v} v^\top \Sigma v, s.t.\quad v^\top v=1, \|v\|_0 \leq s, </code>
</p>

<p>where <code class="reqn">s</code> is support size.
Here, <code class="reqn">\Sigma</code> is covariance matrix, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">\Sigma = \frac{1}{n} X^{\top} X.</code>
</p>

<p>A generic splicing technique is implemented to
solve this problem.
By exploiting the warm-start initialization, the non-convex optimization
problem at different support size (specified by <code>support.size</code>)
can be efficiently solved.
</p>
<p>The abessPCA can be conduct sequentially for each component.
Please see the multiple principal components Section on the <a href="https://abess-team.github.io/abess/articles/v08-sPCA.html">website</a>
for more details about this function.
For <code>abesspca</code> function, the arguments <code>kpc.num</code> control the number of components to be consider.
</p>
<p>When <code>sparse.type = "fpc"</code> but <code>support.size</code> is not supplied,
it is set as <code>support.size = 1:min(ncol(x), 100)</code> if <code>group.index = NULL</code>;
otherwise, <code>support.size = 1:min(length(unique(group.index)), 100)</code>.
When <code>sparse.type = "kpc"</code> but <code>support.size</code> is not supplied,
then for 20\
it is set as <code>min(ncol(x), 100)</code> if <code>group.index = NULL</code>;
otherwise, <code>min(length(unique(group.index)), 100)</code>.
</p>


<h3>Value</h3>

<p>A S3 <code>abesspca</code> class object, which is a <code>list</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>coef</code></td>
<td>
<p>A <code class="reqn">p</code>-by-<code>length(support.size)</code> loading matrix of sparse principal components (PC),
where each row is a variable and each column is a support size;</p>
</td></tr>
<tr><td><code>nvars</code></td>
<td>
<p>The number of variables.</p>
</td></tr>
<tr><td><code>sparse.type</code></td>
<td>
<p>The same as input.</p>
</td></tr>
<tr><td><code>support.size</code></td>
<td>
<p>The actual support.size values used. Note that it is not necessary the same as the input if the later have non-integer values or duplicated values.</p>
</td></tr>
<tr><td><code>ev</code></td>
<td>
<p>A vector with size <code>length(support.size)</code>. It records the cumulative sums of explained variance at each support size.</p>
</td></tr>
<tr><td><code>tune.value</code></td>
<td>
<p>A value of tuning criterion of length <code>length(support.size)</code>.</p>
</td></tr>
<tr><td><code>kpc.num</code></td>
<td>
<p>The number of principal component being considered.</p>
</td></tr>
<tr><td><code>var.pc</code></td>
<td>
<p>The variance of principal components obtained by performing standard PCA.</p>
</td></tr>
<tr><td><code>cum.var.pc</code></td>
<td>
<p>Cumulative sums of <code>var.pc</code>.</p>
</td></tr>
<tr><td><code>var.all</code></td>
<td>
<p>If <code>sparse.type = "fpc"</code>,
it is the total standard deviations of all principal components.</p>
</td></tr>
<tr><td><code>pev</code></td>
<td>
<p>A vector with the same length as <code>ev</code>. It records the percent of explained variance (compared to <code>var.all</code>) at each support size.</p>
</td></tr>
<tr><td><code>pev.pc</code></td>
<td>
<p>It records the percent of explained variance (compared to <code>var.pc</code>) at each support size.</p>
</td></tr>
<tr><td><code>tune.type</code></td>
<td>
<p>The criterion type for tuning parameters.</p>
</td></tr>
<tr><td><code>tune.path</code></td>
<td>
<p>The strategy for tuning parameters.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The original call to <code>abess</code>.</p>
</td></tr>
</table>
<p>It is worthy to note that, if <code>sparse.type == "kpc"</code>, the <code>coef</code>, <code>support.size</code>, <code>ev</code>, <code>tune.value</code>, <code>pev</code> and <code>pev.pc</code> in list are <code>list</code> objects.
</p>


<h3>Note</h3>

<p>Some parameters not described in the Details Section is explained in the document for <code><a href="#topic+abess">abess</a></code>
because the meaning of these parameters are very similar.
</p>


<h3>Author(s)</h3>

<p>Jin Zhu, Junxian Zhu, Ruihuang Liu, Junhao Huang, Xueqin Wang
</p>


<h3>References</h3>

<p>A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; <a href="https://doi.org/10.1073/pnas.2014241117">doi:10.1073/pnas.2014241117</a>
</p>
<p>Sparse principal component analysis. Hui Zou, Hastie Trevor, and Tibshirani Robert. Journal of computational and graphical statistics 15.2 (2006): 265-286. <a href="https://doi.org/10.1198/106186006X113430">doi:10.1198/106186006X113430</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abesspca">print.abesspca</a></code>,
<code><a href="#topic+coef.abesspca">coef.abesspca</a></code>,
<code><a href="#topic+plot.abesspca">plot.abesspca</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(abess)
Sys.setenv("OMP_THREAD_LIMIT" = 2)

## predictor matrix input:
head(USArrests)
pca_fit &lt;- abesspca(USArrests)
pca_fit
plot(pca_fit)

## covariance matrix input:
cov_mat &lt;- stats::cov(USArrests) * (nrow(USArrests) - 1) / nrow(USArrests)
pca_fit &lt;- abesspca(cov_mat, type = "gram")
pca_fit

## robust covariance matrix input:
rob_cov &lt;- MASS::cov.rob(USArrests)[["cov"]]
rob_cov &lt;- (rob_cov + t(rob_cov)) / 2
pca_fit &lt;- abesspca(rob_cov, type = "gram")
pca_fit

## K-component principal component analysis
pca_fit &lt;- abesspca(USArrests,
  sparse.type = "kpc",
  support.size = 1:4
)
coef(pca_fit)
plot(pca_fit)
plot(pca_fit, "coef")

## select support size via cross-validation ##
n &lt;- 500
p &lt;- 50
support_size &lt;- 3
dataset &lt;- generate.spc.matrix(n, p, support_size, snr = 20)
spca_fit &lt;- abesspca(dataset[["x"]], tune.type = "cv", nfolds = 5)
plot(spca_fit, type = "tune")

</code></pre>

<hr>
<h2 id='abessrpca'>Adaptive best subset selection for robust principal component analysis</h2><span id='topic+abessrpca'></span>

<h3>Description</h3>

<p>Decompose a matrix into the summation of
low-rank matrix and sparse matrix via the best subset selection approach
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abessrpca(
  x,
  rank,
  support.size = NULL,
  tune.path = c("sequence", "gsection"),
  gs.range = NULL,
  tune.type = c("gic", "aic", "bic", "ebic"),
  ic.scale = 1,
  lambda = 0,
  always.include = NULL,
  group.index = NULL,
  c.max = NULL,
  splicing.type = 2,
  max.splicing.iter = 1,
  warm.start = TRUE,
  important.search = NULL,
  max.newton.iter = 1,
  newton.thresh = 0.001,
  num.threads = 0,
  seed = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="abessrpca_+3A_x">x</code></td>
<td>
<p>A matrix object.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_rank">rank</code></td>
<td>
<p>A positive integer value specify the rank of the low-rank matrix.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_support.size">support.size</code></td>
<td>
<p>An integer vector representing the alternative support sizes. 
Only used for <code>tune.path = "sequence"</code>. 
Strongly suggest its minimum value larger than <code>min(dim(x))</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_tune.path">tune.path</code></td>
<td>
<p>The method to be used to select the optimal support size. For
<code>tune.path = "sequence"</code>, we solve the best subset selection problem for each size in <code>support.size</code>.
For <code>tune.path = "gsection"</code>, we solve the best subset selection problem with support size ranged in <code>gs.range</code>,
where the specific support size to be considered is determined by golden section.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_gs.range">gs.range</code></td>
<td>
<p>A integer vector with two elements.
The first element is the minimum model size considered by golden-section,
the later one is the maximum one. Default is <code>gs.range = c(1, min(n, round(n/(log(log(n))log(p)))))</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_tune.type">tune.type</code></td>
<td>
<p>The type of criterion for choosing the support size. 
Available options are &quot;gic&quot;, &quot;ebic&quot;, &quot;bic&quot; and &quot;aic&quot;. 
Default is &quot;gic&quot;.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_ic.scale">ic.scale</code></td>
<td>
<p>A non-negative value used for multiplying the penalty term
in information criterion. Default: <code>ic.scale = 1</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_lambda">lambda</code></td>
<td>
<p>A single lambda value for regularized best subset selection. Default is 0.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_always.include">always.include</code></td>
<td>
<p>An integer vector containing the indexes of variables that should always be included in the model.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_group.index">group.index</code></td>
<td>
<p>A vector of integers indicating the which group each variable is in.
For variables in the same group, they should be located in adjacent columns of <code>x</code>
and their corresponding index in <code>group.index</code> should be the same.
Denote the first group as <code>1</code>, the second <code>2</code>, etc.
If you do not fit a model with a group structure,
please set <code>group.index = NULL</code> (the default).</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_c.max">c.max</code></td>
<td>
<p>an integer splicing size. Default is: <code>c.max = 2</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_splicing.type">splicing.type</code></td>
<td>
<p>Optional type for splicing.
If <code>splicing.type = 1</code>, the number of variables to be spliced is
<code>c.max</code>, ..., <code>1</code>; if <code>splicing.type = 2</code>,
the number of variables to be spliced is <code>c.max</code>, <code>c.max/2</code>, ..., <code>1</code>.
(Default: <code>splicing.type = 2</code>.)</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_max.splicing.iter">max.splicing.iter</code></td>
<td>
<p>The maximum number of performing splicing algorithm.
In most of the case, only a few times of splicing iteration can guarantee the convergence.
Default is <code>max.splicing.iter = 20</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_warm.start">warm.start</code></td>
<td>
<p>Whether to use the last solution as a warm start. Default is <code>warm.start = TRUE</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_important.search">important.search</code></td>
<td>
<p>An integer number indicating the number of
important variables to be splicing.
When <code>important.search</code> <code class="reqn">\ll</code> <code>p</code> variables,
it would greatly reduce runtimes. Default: <code>important.search = 128</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_max.newton.iter">max.newton.iter</code></td>
<td>
<p>a integer giving the maximal number of Newton's iteration iterations.
Default is <code>max.newton.iter = 10</code> if <code>newton = "exact"</code>, and <code>max.newton.iter = 60</code> if <code>newton = "approx"</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_newton.thresh">newton.thresh</code></td>
<td>
<p>a numeric value for controlling positive convergence tolerance.
The Newton's iterations converge when <code class="reqn">|dev - dev_{old}|/(|dev| + 0.1)&lt;</code> <code>newton.thresh</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_num.threads">num.threads</code></td>
<td>
<p>An integer decide the number of threads to be
concurrently used for cross-validation (i.e., <code>tune.type = "cv"</code>).
If <code>num.threads = 0</code>, then all of available cores will be used.
Default: <code>num.threads = 0</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_seed">seed</code></td>
<td>
<p>Seed to be used to divide the sample into cross-validation folds.
Default is <code>seed = 1</code>.</p>
</td></tr>
<tr><td><code id="abessrpca_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adaptive best subset selection for robust principal component analysis aim to find two latent matrices <code class="reqn">L</code> and <code class="reqn">S</code> such that the original matrix <code class="reqn">X</code> can be appropriately approximated:
</p>
<p style="text-align: center;"><code class="reqn">x = L + S + N,</code>
</p>
 
<p>where <code class="reqn">L</code> is a low-rank matrix, <code class="reqn">S</code> is a sparse matrix, <code class="reqn">N</code> is a dense noise matrix. 
Generic splicing technique can be employed to solve this problem by iteratively improve the quality of the estimation of <code class="reqn">S</code>. 
</p>
<p>For a given support set <code class="reqn">\Omega</code>, the optimization problem: 
</p>
<p style="text-align: center;"><code class="reqn">\min_S \| x - L - S\|_F^2 \;\;{\rm s.t.}\;\; S_{ij} = 0 {\rm for } (i, j) \in \Omega^c,</code>
</p>

<p>still a non-convex optimization problem. We use the hard-impute algorithm proposed in one of the reference to solve this problem. 
The hard-impute algorithm is an iterative algorithm, people can set <code>max.newton.iter</code> and <code>newton.thresh</code> to 
control the solution precision of the optimization problem. 
(Here, the name of the two parameters are somehow abused to make the parameters cross functions have an unified name.) 
According to our experiments, 
we assign properly parameters to the two parameter as the default such that the precision and runtime are well balanced, 
we suggest users keep the default values unchanged.
</p>


<h3>Value</h3>

<p>A S3 <code>abessrpca</code> class object, which is a <code>list</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>S</code></td>
<td>
<p>A list with <code>length(support.size)</code> elements,
each of which is a sparse matrix estimation;</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>The low rank matrix estimation.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>The number of sample used for training.</p>
</td></tr>
<tr><td><code>nvars</code></td>
<td>
<p>The number of variables used for training.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>The rank of matrix <code>L</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>The loss of objective function.</p>
</td></tr>
<tr><td><code>tune.value</code></td>
<td>
<p>A value of tuning criterion of length <code>length(support.size)</code>.</p>
</td></tr>
<tr><td><code>support.size</code></td>
<td>
<p>The actual support.size values used.
Note that it is not necessary the same as the input if the later have non-integer values or duplicated values.</p>
</td></tr>
<tr><td><code>tune.type</code></td>
<td>
<p>The criterion type for tuning parameters.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The original call to <code>abessrpca</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Some parameters not described in the Details Section is explained in the document for <code><a href="#topic+abess">abess</a></code> 
because the meaning of these parameters are very similar. 
</p>
<p>At present, <code class="reqn">l_2</code> regularization and group selection are not support, 
and thus, set <code>lambda</code> and <code>group.index</code> have no influence on the output. 
This feature will coming soon.
</p>


<h3>References</h3>

<p>A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; <a href="https://doi.org/10.1073/pnas.2014241117">doi:10.1073/pnas.2014241117</a>
</p>
<p>Emmanuel J. Candès, Xiaodong Li, Yi Ma, and John Wright. 2011. Robust principal component analysis? Journal of the ACM. 58, 3, Article 11 (May 2011), 37 pages. <a href="https://doi.org/10.1145/1970392.1970395">doi:10.1145/1970392.1970395</a>
</p>
<p>Mazumder, Rahul, Trevor Hastie, and Robert Tibshirani. Spectral regularization algorithms for learning large incomplete matrices. The Journal of Machine Learning Research 11 (2010): 2287-2322.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(abess)
Sys.setenv("OMP_THREAD_LIMIT" = 2)
n &lt;- 30
p &lt;- 30
true_S_size &lt;- 60
true_L_rank &lt;- 2
dataset &lt;- generate.matrix(n, p, support.size = true_S_size, rank = true_L_rank)
res &lt;- abessrpca(dataset[["x"]], rank = true_L_rank, support.size = 50:70)
print(res)
coef(res)
plot(res, type = "tune")
plot(res, type = "loss")
plot(res, type = "S")

</code></pre>

<hr>
<h2 id='coef.abess'>Extract Model Coefficients from a fitted &quot;<code>abess</code>&quot; object.</h2><span id='topic+coef.abess'></span>

<h3>Description</h3>

<p>This function provides estimated
coefficients from a fitted &quot;<code>abess</code>&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abess'
coef(object, support.size = NULL, sparse = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.abess_+3A_object">object</code></td>
<td>
<p>An &quot;<code>abess</code>&quot; project.</p>
</td></tr>
<tr><td><code id="coef.abess_+3A_support.size">support.size</code></td>
<td>
<p>An integer vector specifies
the coefficient fitted at given <code>support.size</code>.
If <code>support.size = NULL</code>, then all coefficients would be returned.
Default: <code>support.size = NULL</code>.</p>
</td></tr>
<tr><td><code id="coef.abess_+3A_sparse">sparse</code></td>
<td>
<p>A logical value, specifying whether the coefficients should be
presented as sparse matrix or not. Default: <code>sparse = TRUE</code>.</p>
</td></tr>
<tr><td><code id="coef.abess_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A coefficient matrix when fitting an univariate model including gaussian, binomial, poisson, and cox;
otherwise, a list containing coefficient matrices.
For a coefficient matrix, each row is a variable, and each column is a support size.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>

<hr>
<h2 id='coef.abesspca'>Extract Sparse Loadings from a fitted &quot;<code>abesspca</code>&quot; object.</h2><span id='topic+coef.abesspca'></span>

<h3>Description</h3>

<p>This function provides estimated
coefficients from a fitted &quot;<code>abesspca</code>&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abesspca'
coef(object, support.size = NULL, kpc = NULL, sparse = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.abesspca_+3A_object">object</code></td>
<td>
<p>An &quot;<code>abesspca</code>&quot; project.</p>
</td></tr>
<tr><td><code id="coef.abesspca_+3A_support.size">support.size</code></td>
<td>
<p>An integer vector specifies
the coefficient fitted at given <code>support.size</code>.
If <code>support.size = NULL</code>, then all coefficients would be returned.
Default: <code>support.size = NULL</code>.
This parameter is omitted if <code>sparse.type = "kpc"</code>.</p>
</td></tr>
<tr><td><code id="coef.abesspca_+3A_kpc">kpc</code></td>
<td>
<p>An integer vector specifies
the coefficient fitted at given principal component.
If <code>kpc = NULL</code>, then all coefficients would be returned.
Default: <code>kpc = NULL</code>.
This parameter is omitted if <code>sparse.type = "fpc"</code>.</p>
</td></tr>
<tr><td><code id="coef.abesspca_+3A_sparse">sparse</code></td>
<td>
<p>A logical value, specifying whether the coefficients should be
presented as sparse matrix or not. Default: <code>sparse = TRUE</code>.</p>
</td></tr>
<tr><td><code id="coef.abesspca_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with <code>length(support.size)</code> columns.
Each column corresponds to a sparse loading for the first principal component,
where the number of non-zeros entries depends on the <code>support.size</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abesspca">print.abesspca</a></code>,
<code><a href="#topic+coef.abesspca">coef.abesspca</a></code>,
<code><a href="#topic+plot.abesspca">plot.abesspca</a></code>.
</p>

<hr>
<h2 id='coef.abessrpca'>Extract sparse component from a fitted &quot;<code>abessrpca</code>&quot; object.</h2><span id='topic+coef.abessrpca'></span>

<h3>Description</h3>

<p>This function provides estimated
coefficients from a fitted &quot;<code>abessrpca</code>&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abessrpca'
coef(object, support.size = NULL, sparse = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.abessrpca_+3A_object">object</code></td>
<td>
<p>An &quot;<code>abessrpca</code>&quot; project.</p>
</td></tr>
<tr><td><code id="coef.abessrpca_+3A_support.size">support.size</code></td>
<td>
<p>An integer vector specifies
the sparse matrix fitted at given <code>support.size</code> to be returned.
If <code>support.size = NULL</code>, then the sparse matrix with 
the least tuning value would be returned.
Default: <code>support.size = NULL</code>.</p>
</td></tr>
<tr><td><code id="coef.abessrpca_+3A_sparse">sparse</code></td>
<td>
<p>A logical value, specifying whether the coefficients should be
presented as sparse matrix or not. Default: <code>sparse = TRUE</code>.</p>
</td></tr>
<tr><td><code id="coef.abessrpca_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with <code>length(support.size)</code> number of dgCMatrix,
each of which is the estimation the sparse component.
</p>

<hr>
<h2 id='deviance.abess'>Extract the deviance from a fitted &quot;<code>abess</code>&quot; object.</h2><span id='topic+deviance.abess'></span>

<h3>Description</h3>

<p>Similar to other deviance methods,
which returns deviance from a fitted &quot;<code>abess</code>&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abess'
deviance(object, type = c("standard", "gic", "ebic", "bic", "aic"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deviance.abess_+3A_object">object</code></td>
<td>
<p>A &quot;<code>abess</code>&quot; object.</p>
</td></tr>
<tr><td><code id="deviance.abess_+3A_type">type</code></td>
<td>
<p>The type of deviance.
One of the following: <code>"standard"</code>,
<code>"gic"</code>, <code>"ebic"</code>, <code>"bic"</code> and <code>"aic"</code>.
Default is <code>"standard"</code>.</p>
</td></tr>
<tr><td><code id="deviance.abess_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>

<hr>
<h2 id='extract'>Extract one model from a fitted &quot;<code>abess</code>&quot; object.</h2><span id='topic+extract'></span><span id='topic+extract.abess'></span>

<h3>Description</h3>

<p>Extract the fixed-support-size
model's information such as the selected
predictors, coefficient estimation, and so on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract(object, support.size = NULL, ...)

## S3 method for class 'abess'
extract(object, support.size = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_+3A_object">object</code></td>
<td>
<p>An &quot;<code>abess</code>&quot; project.</p>
</td></tr>
<tr><td><code id="extract_+3A_support.size">support.size</code></td>
<td>
<p>An integer value specifies
the model size fitted at given <code>support.size</code>.
If <code>support.size = NULL</code>, then the model with
the best tuning value would be returned.
Default: <code>support.size = NULL</code>.</p>
</td></tr>
<tr><td><code id="extract_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> object including the following components:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>A <code class="reqn">p</code>-by-1 matrix of sparse matrix, stored in column format.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>The fitted intercept value.</p>
</td></tr>
<tr><td><code>support.size</code></td>
<td>
<p>The <code>support.size</code> used in the function.</p>
</td></tr>
<tr><td><code>support.beta</code></td>
<td>
<p>The <code>support.size</code>-length vector of fitted
coefficients on the support set.</p>
</td></tr>
<tr><td><code>support.vars</code></td>
<td>
<p>The character vector gives
variables in the support set.</p>
</td></tr>
<tr><td><code>tune.value</code></td>
<td>
<p>The tuning value of the model.</p>
</td></tr>
<tr><td><code>dev</code></td>
<td>
<p>The deviance of the model.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>

<hr>
<h2 id='generate.data'>Generate simulated data</h2><span id='topic+generate.data'></span>

<h3>Description</h3>

<p>Generate simulated data under the
generalized linear model and Cox proportional hazard model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.data(
  n,
  p,
  support.size = NULL,
  rho = 0,
  family = c("gaussian", "binomial", "poisson", "cox", "mgaussian", "multinomial",
    "gamma", "ordinal"),
  beta = NULL,
  cortype = 1,
  snr = 10,
  sigma = NULL,
  weibull.shape = 1,
  uniform.max = 1,
  y.dim = 3,
  class.num = 3,
  seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.data_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_p">p</code></td>
<td>
<p>The number of predictors of interest.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_support.size">support.size</code></td>
<td>
<p>The number of nonzero coefficients in the underlying regression
model. Can be omitted if <code>beta</code> is supplied.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_rho">rho</code></td>
<td>
<p>A parameter used to characterize the pairwise correlation in
predictors. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_family">family</code></td>
<td>
<p>The distribution of the simulated response. <code>"gaussian"</code> for
univariate quantitative response, <code>"binomial"</code> for binary classification response,
<code>"poisson"</code> for counting response, <code>"cox"</code> for left-censored response,
<code>"mgaussian"</code> for multivariate quantitative response,
<code>"mgaussian"</code> for multi-classification response, 
<code>"ordinal"</code> for ordinal response.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_beta">beta</code></td>
<td>
<p>The coefficient values in the underlying regression model.
If it is supplied, <code>support.size</code> would be omitted.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_cortype">cortype</code></td>
<td>
<p>The correlation structure.
<code>cortype = 1</code> denotes the independence structure,
where the covariance matrix has <code class="reqn">(i,j)</code> entry equals <code class="reqn">I(i \neq j)</code>.
<code>cortype = 2</code> denotes the exponential structure,
where the covariance matrix has <code class="reqn">(i,j)</code> entry equals <code class="reqn">rho^{|i-j|}</code>.
<code>cortype = 3</code> denotes the constant structure,
where the non-diagonal entries of covariance
matrix are <code class="reqn">rho</code> and diagonal entries are 1.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_snr">snr</code></td>
<td>
<p>A numerical value controlling the signal-to-noise ratio (SNR). The SNR is defined as
as the variance of <code class="reqn">x\beta</code> divided
by the variance of a gaussian noise: <code class="reqn">\frac{Var(x\beta)}{\sigma^2}</code>.
The gaussian noise <code class="reqn">\epsilon</code> is set with mean 0 and variance.
The noise is added to the linear predictor <code class="reqn">\eta</code> = <code class="reqn">x\beta</code>. Default is <code>snr = 10</code>.
Note that this arguments's effect is overridden if <code>sigma</code> is supplied with a non-null value.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_sigma">sigma</code></td>
<td>
<p>The variance of the gaussian noise. Default <code>sigma = NULL</code> implies it is determined by <code>snr</code>.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_weibull.shape">weibull.shape</code></td>
<td>
<p>The shape parameter of the Weibull distribution.
It works only when <code>family = "cox"</code>.
Default: <code>weibull.shape = 1</code>.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_uniform.max">uniform.max</code></td>
<td>
<p>A parameter controlling censored rate.
A large value implies a small censored rate;
otherwise, a large censored rate.
It works only when <code>family = "cox"</code>.
Default is <code>uniform.max = 1</code>.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_y.dim">y.dim</code></td>
<td>
<p>Response's Dimension. It works only when <code>family = "mgaussian"</code>. Default: <code>y.dim = 3</code>.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_class.num">class.num</code></td>
<td>
<p>The number of class. It works only when <code>family = "multinomial"</code>. Default: <code>class.num = 3</code>.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_seed">seed</code></td>
<td>
<p>random seed. Default: <code>seed = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>family = "gaussian"</code>, the data model is
</p>
<p style="text-align: center;"><code class="reqn">Y = X \beta + \epsilon.</code>
</p>

<p>The underlying regression coefficient <code class="reqn">\beta</code> has
uniform distribution [m, 100m] and <code class="reqn">m=5 \sqrt{2log(p)/n}.</code>
</p>
<p>For <code>family= "binomial"</code>, the data model is </p>
<p style="text-align: center;"><code class="reqn">Prob(Y = 1) = \exp(X
\beta + \epsilon)/(1 + \exp(X \beta + \epsilon)).</code>
</p>

<p>The underlying regression coefficient <code class="reqn">\beta</code> has
uniform distribution [2m, 10m] and <code class="reqn">m = 5 \sqrt{2log(p)/n}.</code>
</p>
<p>For <code>family = "poisson"</code>, the data is modeled to have
an exponential distribution:
</p>
<p style="text-align: center;"><code class="reqn">Y = Exp(\exp(X \beta + \epsilon)).</code>
</p>

<p>The underlying regression coefficient <code class="reqn">\beta</code> has
uniform distribution [2m, 10m] and <code class="reqn">m = \sqrt{2log(p)/n}/3.</code>
</p>
<p>For <code>family = "gamma"</code>, the data is modeled to have
a gamma distribution:
</p>
<p style="text-align: center;"><code class="reqn">Y = Gamma(X \beta + \epsilon + 10, shape),</code>
</p>

<p>where <code class="reqn">shape</code> is shape parameter in a gamma distribution.
The underlying regression coefficient <code class="reqn">\beta</code> has
uniform distribution [2m, 100m] and <code class="reqn">m = \sqrt{2log(p)/n}.</code>
</p>
<p>For <code>family = "ordinal"</code>, the data is modeled to have
an ordinal distribution.
</p>
<p>For <code>family = "cox"</code>, the model for failure time <code class="reqn">T</code> is
</p>
<p style="text-align: center;"><code class="reqn">T = (-\log(U / \exp(X \beta)))^{1/weibull.shape},</code>
</p>

<p>where <code class="reqn">U</code> is a uniform random variable with range [0, 1].
The centering time <code class="reqn">C</code> is generated from
uniform distribution <code class="reqn">[0, uniform.max]</code>,
then we define the censor status as
<code class="reqn">\delta = I(T \le C)</code> and observed time as <code class="reqn">R = \min\{T, C\}</code>.
The underlying regression coefficient <code class="reqn">\beta</code> has
uniform distribution [2m, 10m],
where <code class="reqn">m = 5 \sqrt{2log(p)/n}</code>.
</p>
<p>For <code>family = "mgaussian"</code>, the data model is
</p>
<p style="text-align: center;"><code class="reqn">Y = X \beta + E.</code>
</p>

<p>The non-zero values of regression matrix <code class="reqn">\beta</code> are sampled from
uniform distribution [m, 100m] and <code class="reqn">m=5 \sqrt{2log(p)/n}.</code>
</p>
<p>For <code>family= "multinomial"</code>, the data model is </p>
<p style="text-align: center;"><code class="reqn">Prob(Y = 1) = \exp(X \beta + E)/(1 + \exp(X \beta + E)).</code>
</p>

<p>The non-zero values of regression coefficient <code class="reqn">\beta</code> has
uniform distribution [2m, 10m] and <code class="reqn">m = 5 \sqrt{2log(p)/n}.</code>
</p>
<p>In the above models, <code class="reqn">\epsilon \sim N(0, \sigma^2 )</code> and <code class="reqn">E \sim MVN(0, \sigma^2 \times I_{q \times q})</code>,
where <code class="reqn">\sigma^2</code> is determined by the <code>snr</code> and q is <code>y.dim</code>.
</p>


<h3>Value</h3>

<p>A <code>list</code> object comprising:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>Design matrix of predictors.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Response variable.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The coefficients used in the underlying regression model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jin Zhu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Generate simulated data
n &lt;- 200
p &lt;- 20
support.size &lt;- 5
dataset &lt;- generate.data(n, p, support.size)
str(dataset)
</code></pre>

<hr>
<h2 id='generate.matrix'>Generate matrix composed of a sparse matrix and low-rank matrix</h2><span id='topic+generate.matrix'></span>

<h3>Description</h3>

<p>Generate simulated matrix that is the superposition of
a low-rank component and a sparse component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.matrix(
  n,
  p,
  rank = NULL,
  support.size = NULL,
  beta = NULL,
  snr = Inf,
  sigma = NULL,
  seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.matrix_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_p">p</code></td>
<td>
<p>The number of predictors of interest.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_rank">rank</code></td>
<td>
<p>The rank of low-rank matrix.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_support.size">support.size</code></td>
<td>
<p>The number of nonzero coefficients in the underlying regression
model. Can be omitted if <code>beta</code> is supplied.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_beta">beta</code></td>
<td>
<p>The coefficient values in the underlying regression model.
If it is supplied, <code>support.size</code> would be omitted.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_snr">snr</code></td>
<td>
<p>A positive value controlling the signal-to-noise ratio (SNR).
A larger SNR implies the identification of sparse matrix is much easier.
Default <code>snr = Inf</code> enforces no noise exists.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_sigma">sigma</code></td>
<td>
<p>A numerical value supplied the variance of the gaussian noise. 
Default <code>sigma = NULL</code> implies it is determined by <code>snr</code>.</p>
</td></tr>
<tr><td><code id="generate.matrix_+3A_seed">seed</code></td>
<td>
<p>random seed. Default: <code>seed = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The low rank matrix <code class="reqn">L</code> is generated by <code class="reqn">L = UV</code>, where
<code class="reqn">U</code> is an <code class="reqn">n</code>-by-<code class="reqn">rank</code> matrix and
<code class="reqn">V</code> is a <code class="reqn">rank</code>-by-<code class="reqn">p</code> matrix.
Each element in <code class="reqn">U</code> (or <code class="reqn">V</code>) are i.i.d. drawn from <code class="reqn">N(0, 1/n)</code>.
</p>
<p>The sparse matrix <code class="reqn">S</code> is an <code class="reqn">n</code>-by-<code class="reqn">rank</code> matrix.
It is generated by choosing a support set of size
<code>support.size</code> uniformly at random.
The non-zero entries in <code class="reqn">S</code> are independent Bernoulli (-1, +1) entries.
</p>
<p>The noise matrix <code class="reqn">N</code> is an <code class="reqn">n</code>-by-<code class="reqn">rank</code> matrix,
the elements in <code class="reqn">N</code> are i.i.d. gaussian random variable
with standard deviation <code class="reqn">\sigma</code>.
</p>
<p>The SNR is defined as
as the variance of vectorized matrix <code class="reqn">L + S</code> divided
by <code class="reqn">\sigma^2</code>.
</p>
<p>The matrix <code class="reqn">x</code> is the superposition of <code class="reqn">L</code>, <code class="reqn">S</code>, <code class="reqn">N</code>:
</p>
<p style="text-align: center;"><code class="reqn">x = L + S + N.</code>
</p>



<h3>Value</h3>

<p>A <code>list</code> object comprising:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>An <code class="reqn">n</code>-by-<code class="reqn">p</code> matrix.</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>The latent low rank matrix.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>The latent sparse matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jin Zhu
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulated data
n &lt;- 30
p &lt;- 20
dataset &lt;- generate.matrix(n, p)

stats::heatmap(as.matrix(dataset[["S"]]),
  Rowv = NA,
  Colv = NA,
  scale = "none",
  col = grDevices::cm.colors(256),
  frame.plot = TRUE,
  margins = c(2.4, 2.4)
)

</code></pre>

<hr>
<h2 id='generate.spc.matrix'>Generate matrix with sparse principal component</h2><span id='topic+generate.spc.matrix'></span>

<h3>Description</h3>

<p>Generate simulated matrix that its principal component are
sparse linear combination of its columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.spc.matrix(
  n,
  p,
  support.size = 3,
  snr = 20,
  sigma = NULL,
  sparse.loading = NULL,
  seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate.spc.matrix_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="generate.spc.matrix_+3A_p">p</code></td>
<td>
<p>The number of predictors of interest.</p>
</td></tr>
<tr><td><code id="generate.spc.matrix_+3A_support.size">support.size</code></td>
<td>
<p>A integer specify the number of non-zero entries in the first column of loading matrix.</p>
</td></tr>
<tr><td><code id="generate.spc.matrix_+3A_snr">snr</code></td>
<td>
<p>A positive value controlling the signal-to-noise ratio (SNR).
A larger SNR implies the identification of sparse matrix is much easier.
Default <code>snr = Inf</code> enforces no noise exists.</p>
</td></tr>
<tr><td><code id="generate.spc.matrix_+3A_sigma">sigma</code></td>
<td>
<p>A numerical vector with length <code>p</code> specify the standard deviation of each columns.
Default <code>sigma = NULL</code> implies it is determined by <code>snr</code>. 
If it is supplied, <code>support.size</code> would be omit.</p>
</td></tr>
<tr><td><code id="generate.spc.matrix_+3A_sparse.loading">sparse.loading</code></td>
<td>
<p>A <code>p</code>-by-<code>p</code> sparse orthogonal matrix. 
If it is supplied, <code>support.size</code> would be omit.</p>
</td></tr>
<tr><td><code id="generate.spc.matrix_+3A_seed">seed</code></td>
<td>
<p>random seed. Default: <code>seed = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods for generating the matrix is detailedly described in the APPENDIX A: Data generation Section in Schipper et al (2021).
</p>


<h3>Value</h3>

<p>A <code>list</code> object comprising:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>An <code class="reqn">n</code>-by-<code class="reqn">p</code> matrix.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>The sparse loading matrix used to generate x.</p>
</td></tr>
<tr><td><code>support.size</code></td>
<td>
<p>A vector recording the number of non-zero entries in each .</p>
</td></tr>
</table>


<h3>References</h3>

<p>Model selection techniques for sparse weight-based principal component analysis. de Schipper, Niek C and Van Deun, Katrijn. Journal of Chemometrics. 2021. <a href="https://doi.org/10.1002/cem.3289">doi:10.1002/cem.3289</a>.
</p>

<hr>
<h2 id='plot.abess'>Creat plot from a fitted &quot;<code>abess</code>&quot; object</h2><span id='topic+plot.abess'></span>

<h3>Description</h3>

<p>Produces a coefficient/deviance/tuning-value plot
for a fitted &quot;abess&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abess'
plot(
  x,
  type = c("coef", "l2norm", "dev", "dev.ratio", "tune"),
  label = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abess_+3A_x">x</code></td>
<td>
<p>A &quot;<code>abess</code>&quot; object.</p>
</td></tr>
<tr><td><code id="plot.abess_+3A_type">type</code></td>
<td>
<p>The type of terms to be plot in the y-axis.
One of the following: <code>"coef"</code> (i.e., coefficients),
<code>"l2norm"</code> (i.e., L2-norm of coefficients),
<code>"dev"</code> (i.e., deviance),
and <code>"tune"</code> (i.e., tuning value).
Default is <code>"coef"</code>.</p>
</td></tr>
<tr><td><code id="plot.abess_+3A_label">label</code></td>
<td>
<p>A logical value.
If <code>label = TRUE</code> (the default),
label the curves with variable sequence numbers.</p>
</td></tr>
<tr><td><code id="plot.abess_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Note</h3>

<p>If <code>family = "mgaussian"</code>, <code>family = "ordinal"</code> or <code>family = "multinomial"</code>,
a coefficient plot is produced for
each dimension of multivariate response.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- generate.data(100, 20, 3)
abess_fit &lt;- abess(dataset[["x"]], dataset[["y"]])
plot(abess_fit)
plot(abess_fit, type = "l2norm")
plot(abess_fit, type = "dev")
plot(abess_fit, type = "tune")
</code></pre>

<hr>
<h2 id='plot.abesspca'>Creat plot from a fitted &quot;<code>abess</code>&quot; object</h2><span id='topic+plot.abesspca'></span>

<h3>Description</h3>

<p>Produces a coefficient/deviance/tuning-value plot
for a fitted &quot;abess&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abesspca'
plot(x, type = c("pev", "coef", "tune"), label = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abesspca_+3A_x">x</code></td>
<td>
<p>A &quot;<code>abess</code>&quot; object.</p>
</td></tr>
<tr><td><code id="plot.abesspca_+3A_type">type</code></td>
<td>
<p>The type of terms to be plot in the y-axis.
One of the following:
<code>"pev"</code> (i.e., percent of explained variance),
<code>"coef"</code> (i.e., coefficients),
and <code>"tune"</code> (i.e., tuning value).
Default is <code>"coef"</code>.</p>
</td></tr>
<tr><td><code id="plot.abesspca_+3A_label">label</code></td>
<td>
<p>A logical value.
If <code>label = TRUE</code> (the default),
label the curves with variable sequence numbers.</p>
</td></tr>
<tr><td><code id="plot.abesspca_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Note</h3>

<p>If <code>family = "mgaussian"</code> or <code>family = "multinomial"</code>,
a coefficient plot is produced for
each dimension of multivariate response.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abesspca">print.abesspca</a></code>,
<code><a href="#topic+coef.abesspca">coef.abesspca</a></code>,
<code><a href="#topic+plot.abesspca">plot.abesspca</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>abess_fit &lt;- abesspca(USArrests, support.size = 1:4, sparse.type = "kpc")
plot(abess_fit)
plot(abess_fit, type = "coef")
plot(abess_fit, type = "tune")
</code></pre>

<hr>
<h2 id='plot.abessrpca'>Creat plot from a fitted &quot;<code>abessrpca</code>&quot; object</h2><span id='topic+plot.abessrpca'></span>

<h3>Description</h3>

<p>Produces a sparse-matrix/loss/tuning-value plot
for a fitted &quot;<code>abessrpca</code>&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abessrpca'
plot(x, type = c("S", "loss", "tune"), support.size = NULL, label = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abessrpca_+3A_x">x</code></td>
<td>
<p>A &quot;<code>abessrpca</code>&quot; object.</p>
</td></tr>
<tr><td><code id="plot.abessrpca_+3A_type">type</code></td>
<td>
<p>The plot type.
One of the following:
<code>"S"</code> (i.e., a heatmap for the sparse matrix estimation),
<code>"loss"</code> (i.e., a support.size versus loss plot),
and <code>"tune"</code> (i.e., , a support.size versus tuning value plot).
Default is <code>"coef"</code>.</p>
</td></tr>
<tr><td><code id="plot.abessrpca_+3A_support.size">support.size</code></td>
<td>
<p>An integer vector specifies
the sparse matrix fitted at given <code>support.size</code> to be returned.
If <code>support.size = NULL</code>, then the sparse matrix with 
the least tuning value would be returned.
Default: <code>support.size = NULL</code>.</p>
</td></tr>
<tr><td><code id="plot.abessrpca_+3A_label">label</code></td>
<td>
<p>A logical value.
If <code>label = TRUE</code> (the default),
label the curves with variable sequence numbers.</p>
</td></tr>
<tr><td><code id="plot.abessrpca_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code> 
or <code>stats::heatmap</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='predict.abess'>Make predictions from a fitted &quot;<code>abess</code>&quot; object.</h2><span id='topic+predict.abess'></span>

<h3>Description</h3>

<p>Make predictions from a fitted &quot;<code>abess</code>&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abess'
predict(object, newx, type = c("link", "response"), support.size = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.abess_+3A_object">object</code></td>
<td>
<p>An &quot;<code>abess</code>&quot; project.</p>
</td></tr>
<tr><td><code id="predict.abess_+3A_newx">newx</code></td>
<td>
<p>New data used for prediction. If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.abess_+3A_type">type</code></td>
<td>
<p><code>type = "link"</code> gives the linear predictors for <code>"binomial"</code>,
<code>"poisson"</code> or <code>"cox"</code> models; for <code>"gaussian"</code> models it gives the
fitted values. <code>type = "response"</code> gives the fitted probabilities for
<code>"binomial"</code> and <code>"ordinal"</code>, fitted mean for <code>"poisson"</code> and the fitted relative-risk for
<code>"cox"</code>; for <code>"gaussian"</code>, <code>type = "response"</code> is equivalent to <code>type = "link"</code>.</p>
</td></tr>
<tr><td><code id="predict.abess_+3A_support.size">support.size</code></td>
<td>
<p>An integer value specifies
the model size fitted at given <code>support.size</code>.
If <code>support.size = NULL</code>, then the model with
the best tuning value would be returned.
Default: <code>support.size = NULL</code>.</p>
</td></tr>
<tr><td><code id="predict.abess_+3A_...">...</code></td>
<td>
<p>Additional arguments affecting the predictions produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on the types of family.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>

<hr>
<h2 id='print.abess'>Print method for a fitted &quot;<code>abess</code>&quot; object</h2><span id='topic+print.abess'></span>

<h3>Description</h3>

<p>Prints the fitted model and returns it invisibly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abess'
print(x, digits = max(5, getOption("digits") - 5), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abess_+3A_x">x</code></td>
<td>
<p>A &quot;<code>abess</code>&quot; object.</p>
</td></tr>
<tr><td><code id="print.abess_+3A_digits">digits</code></td>
<td>
<p>Minimum number of significant digits to be used.</p>
</td></tr>
<tr><td><code id="print.abess_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Print a <code>data.frame</code> with three columns:
the first column is support size of model;
the second column is deviance of model;
the last column is the tuning value of the certain tuning type.
</p>


<h3>Value</h3>

<p>No return value, called for side effects
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abess">print.abess</a></code>,
<code><a href="#topic+predict.abess">predict.abess</a></code>,
<code><a href="#topic+coef.abess">coef.abess</a></code>,
<code><a href="#topic+extract.abess">extract.abess</a></code>,
<code><a href="#topic+plot.abess">plot.abess</a></code>,
<code><a href="#topic+deviance.abess">deviance.abess</a></code>.
</p>

<hr>
<h2 id='print.abesspca'>Print method for a fitted &quot;<code>abesspca</code>&quot; object</h2><span id='topic+print.abesspca'></span>

<h3>Description</h3>

<p>Prints the fitted model and returns it invisibly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abesspca'
print(x, digits = max(5, getOption("digits") - 5), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abesspca_+3A_x">x</code></td>
<td>
<p>A &quot;<code>abesspca</code>&quot; object.</p>
</td></tr>
<tr><td><code id="print.abesspca_+3A_digits">digits</code></td>
<td>
<p>Minimum number of significant digits to be used.</p>
</td></tr>
<tr><td><code id="print.abesspca_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Print a <code>data.frame</code> with three columns:
the first column is support size of model;
the second column is the explained variance of model;
the last column is the percent of explained variance of model.
</p>


<h3>Value</h3>

<p>No return value, called for side effects
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.abesspca">print.abesspca</a></code>,
<code><a href="#topic+coef.abesspca">coef.abesspca</a></code>,
<code><a href="#topic+plot.abesspca">plot.abesspca</a></code>.
</p>

<hr>
<h2 id='print.abessrpca'>Print method for a fitted &quot;<code>abessrpca</code>&quot; object</h2><span id='topic+print.abessrpca'></span>

<h3>Description</h3>

<p>Prints the fitted model and returns it invisibly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abessrpca'
print(x, digits = max(5, getOption("digits") - 5), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abessrpca_+3A_x">x</code></td>
<td>
<p>A &quot;<code>abessrpca</code>&quot; object.</p>
</td></tr>
<tr><td><code id="print.abessrpca_+3A_digits">digits</code></td>
<td>
<p>Minimum number of significant digits to be used.</p>
</td></tr>
<tr><td><code id="print.abessrpca_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Print a <code>data.frame</code> with three columns:
the first column is support size of model;
the second column is the explained variance of model;
the last column is the percent of explained variance of model.
</p>


<h3>Value</h3>

<p>No return value, called for side effects
</p>

<hr>
<h2 id='trim32'>The Bardet-Biedl syndrome Gene expression data</h2><span id='topic+trim32'></span>

<h3>Description</h3>

<p>Gene expression data (500 gene probes for 120 samples) from the microarray experiments of mammalianeye tissue samples of Scheetz et al. (2006).
</p>


<h3>Format</h3>

<p>A data frame with 120 rows and 501 variables, where the first variable is the expression level of TRIM32 gene,
and the remaining 500 variables are 500 gene probes.
</p>


<h3>Details</h3>

<p>In this study, laboratory rats (Rattus norvegicus) were studied to learn about gene expression and regulation in the mammalian eye.
Inbred rat strains were crossed and tissue extracted from the eyes of 120 animals from the F2 generation. Microarrays were used to measure levels of RNA expression in the isolated eye tissues of each subject.
Of the 31,000 different probes, 18,976 were detected at a sufficient level to be considered expressed in the mammalian eye.
For the purposes of this analysis, we treat one of those genes, Trim32, as the outcome.
Trim32 is known to be linked with a genetic disorder called Bardet-Biedl Syndrome (BBS): the mutation (P130S) in Trim32 gives rise to BBS.
</p>


<h3>Note</h3>

<p>This data set contains 120 samples with 500 predictors. The 500 predictors are features with maximum marginal correlation to Trim32 gene.
</p>


<h3>References</h3>

<p>T. Scheetz, k. Kim, R. Swiderski, A. Philp, T. Braun, K. Knudtson, A. Dorrance, G. DiBona, J. Huang, T. Casavant, V. Sheffield, E. Stone. Regulation of gene expression in the mammalian eye and its relevance to eye disease. Proceedings of the National Academy of Sciences of the United States of America, 2006.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
