<!DOCTYPE html><html lang="en"><head><title>Help for package ecotrends</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ecotrends}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ecotrends-package'><p>ecotrends: Temporal Trends in Ecological Niche Models</p></a></li>
<li><a href='#getImportance'><p>Get variable importance</p></a></li>
<li><a href='#getModels'><p>Get models</p></a></li>
<li><a href='#getPerformance'><p>Get model performance</p></a></li>
<li><a href='#getPredictions'><p>Get predictions</p></a></li>
<li><a href='#getTrend'><p>Get trend</p></a></li>
<li><a href='#getVariables'><p>Get variables</p></a></li>
<li><a href='#pixelArea'><p>Average pixel area</p></a></li>
<li><a href='#varsAvailable'><p>Variables available</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Temporal Trends in Ecological Niche Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>A. Marcia Barbosa &lt;ana.marcia.barbosa@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes temporal trends in environmental suitability obtained from ecological niche models, based on a set of species presence point coordinates and predictor variables.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/AMBarbosa/ecotrends">https://github.com/AMBarbosa/ecotrends</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/AMBarbosa/ecotrends/issues">https://github.com/AMBarbosa/ecotrends/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>collinear (&ge; 2.0.0), fuzzySim (&ge; 4.26), maxnet, modEvA (&ge;
3.21), terra (&ge; 1.4-19), trend</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-03 17:11:43 UTC; marcia</td>
</tr>
<tr>
<td>Author:</td>
<td>A. Marcia Barbosa [aut, cre],
  João Alírio [aut],
  Nuno Garcia [aut],
  João Campos [aut],
  Ana Cláudia Teodoro [aut],
  Lia Bárbara Duarte [aut],
  Isabel Pôças [aut],
  Salvador Arenas-Castro [aut],
  Neftalí Sillero [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-05 13:20:19 UTC</td>
</tr>
</table>
<hr>
<h2 id='ecotrends-package'>ecotrends: Temporal Trends in Ecological Niche Models</h2><span id='topic+ecotrends'></span><span id='topic+ecotrends-package'></span>

<h3>Description</h3>

<p>Computes temporal trends in environmental suitability obtained from ecological niche models, based on a set of species presence point coordinates and predictor variables.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: A. Marcia Barbosa <a href="mailto:ana.marcia.barbosa@gmail.com">ana.marcia.barbosa@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> João Alírio
</p>
</li>
<li><p> Nuno Garcia
</p>
</li>
<li><p> João Campos
</p>
</li>
<li><p> Ana Cláudia Teodoro
</p>
</li>
<li><p> Lia Bárbara Duarte
</p>
</li>
<li><p> Isabel Pôças
</p>
</li>
<li><p> Salvador Arenas-Castro
</p>
</li>
<li><p> Neftalí Sillero
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/AMBarbosa/ecotrends">https://github.com/AMBarbosa/ecotrends</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/AMBarbosa/ecotrends/issues">https://github.com/AMBarbosa/ecotrends/issues</a>
</p>
</li></ul>


<hr>
<h2 id='getImportance'>Get variable importance</h2><span id='topic+getImportance'></span>

<h3>Description</h3>

<p>This function computes the permutation importance of each variable in each model, by shuffling each variable in turn (a given number of times) and computing the root mean squared difference between the actual model predictions and those obtained with the shuffled variable. Values are then normalized to a percentage by dividing each by the sum of all values and multiplying by 100. Note that &quot;importance&quot; is a vague concept which can be measured in many other different ways.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getImportance(
  mods,
  nper = 10,
  verbosity = 2,
  plot = TRUE,
  palette = "Dark2",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getImportance_+3A_mods">mods</code></td>
<td>
<p>output of <code><a href="#topic+getModels">getModels()</a></code>.</p>
</td></tr>
<tr><td><code id="getImportance_+3A_nper">nper</code></td>
<td>
<p>integer value (default 10; increase for more accurate but computationally intensive results) indicating the number of permutations for shuffling each variable.</p>
</td></tr>
<tr><td><code id="getImportance_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
<tr><td><code id="getImportance_+3A_plot">plot</code></td>
<td>
<p>logical value specifying whether to produce a line (spaghetti) plot of the mean importance of each variable along the periods. Note that this plot does not reflect the deviations around this mean, and that it may become hard to read if there are many variables or if their importances overlap.</p>
</td></tr>
<tr><td><code id="getImportance_+3A_palette">palette</code></td>
<td>
<p>argument to pass to <code><a href="grDevices.html#topic+hcl.colors">hcl.colors()</a></code> specifying the colours for the lines (if plot=TRUE). The default is &quot;Dark2&quot;; run hcl.pals() for other options.</p>
</td></tr>
<tr><td><code id="getImportance_+3A_...">...</code></td>
<td>
<p>additional arguments that can be passed to <code><a href="base.html#topic+plot">base::plot()</a></code>, e.g. 'main', 'xlab', 'ylab' or 'las'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the permutation importance (expressed as percentage) of each variable in each model replicate for each period, along with the cross-replicate mean and standard deviation. If plot=TRUE (the default), also a spaghetti plot of mean variable importance per period.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code>varImportance</code> in package <span class="pkg">predicts</span>; <code>bm_VariablesImportance</code> in package <span class="pkg">biomod2</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Several data prep steps required.
# See https://github.com/AMBarbosa/ecotrends for a full worked example.
</code></pre>

<hr>
<h2 id='getModels'>Get models</h2><span id='topic+getModels'></span>

<h3>Description</h3>

<p>This function computes <code><a href="maxnet.html#topic+maxnet">maxnet::maxnet()</a></code> ecological niche models for a set of time steps or periods (e.g. years), given a set of presence point coordinates and periodly environmental layers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getModels(
  occs,
  rasts,
  region = NULL,
  nbg = 10000,
  seed = NULL,
  bias = FALSE,
  collin = TRUE,
  maxcor = 0.75,
  maxvif = 5,
  classes = "default",
  regmult = 1,
  nreps = 10,
  test = 0.2,
  file = NULL,
  verbosity = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getModels_+3A_occs">occs</code></td>
<td>
<p>species occurrence coordinates (2 columns in this order: x, y or LONGitude, LATitude) in an object coercible to a data.frame (e.g. a data.frame, matrix, tibble, sf object or SpatVector of points), and in the same coordinate reference system as 'rasts'</p>
</td></tr>
<tr><td><code id="getModels_+3A_rasts">rasts</code></td>
<td>
<p>(multi-layer) SpatRaster with a time series of variables to use in the models. The layers should be ordered chronologically, and their names should be in the form &quot;varname [underscore] time&quot;, e.g. &quot;tmin_1985&quot; or &quot;tmin_1&quot; (with no more underscores than this), as in the output of <code><a href="#topic+getVariables">getVariables()</a></code>. Note that, if a variable has no spatial variation in a given time step or period, it is excluded (as it cannot have an effect) from that model, so in practice not all models will include the exact same set of variables. If verbosity &gt; 1, messages will report which variables were excluded from each period.</p>
</td></tr>
<tr><td><code id="getModels_+3A_region">region</code></td>
<td>
<p>optional SpatExtent or SpatVector polygon delimiting the region of 'rasts' within which to compute the models. The default is NULL, to use the entire extent of 'rasts' with pixel values. Note that 'region' should ideally include only reasonably surveyed areas that are accessible to the species, as pixels that don't overlap presence points are taken by Maxent as available and unoccupied.</p>
</td></tr>
<tr><td><code id="getModels_+3A_nbg">nbg</code></td>
<td>
<p>integer value indicating the maximum number of background pixels to select randomly for use in the models. The default is 10,000, or the total number of non-NA pixels in 'rasts' if that's less.</p>
</td></tr>
<tr><td><code id="getModels_+3A_seed">seed</code></td>
<td>
<p>optional integer value to pass to <code><a href="base.html#topic+set.seed">set.seed()</a></code> specifying the random seed to use for sampling the background pixels (if 'nbg' is smaller than the number of pixels in 'rasts') and for extracting the test samples (if nreps &gt; 0).</p>
</td></tr>
<tr><td><code id="getModels_+3A_bias">bias</code></td>
<td>
<p>argument to pass to <code><a href="fuzzySim.html#topic+selectAbsences">fuzzySim::selectAbsences()</a></code> specifying if/how the selection of unoccupied background points should be biased to incorporate survey effort. Can be TRUE to make selection more likely towards the vicinity of occurrence points (which may indicate that those areas have been surveyed); or a SpatRaster of weights (bias layer), with the same coordinate reference system as 'occs' and 'rasts', with higher values where selection should be proportionally more likely, and zero or NA where points should not be placed. Default FALSE.</p>
</td></tr>
<tr><td><code id="getModels_+3A_collin">collin</code></td>
<td>
<p>logical value indicating whether multicollinearity among the variables should be reduced prior to computing each model. The default is TRUE, in which case the <code><a href="collinear.html#topic+collinear">collinear::collinear()</a></code> function is used. Note that, if the collinearity structure varies among periods, the set of included variables may also vary. If verbosity &gt; 1, messages will report which variables were excluded from each period.</p>
</td></tr>
<tr><td><code id="getModels_+3A_maxcor">maxcor</code></td>
<td>
<p>numeric value to pass to <code><a href="collinear.html#topic+collinear">collinear::collinear()</a></code> (if collin = TRUE) indicating the maximum correlation allowed between any pair of predictor variables. The default is 0.75.</p>
</td></tr>
<tr><td><code id="getModels_+3A_maxvif">maxvif</code></td>
<td>
<p>numeric value to pass to <code><a href="collinear.html#topic+collinear">collinear::collinear()</a></code> (if collin = TRUE) indicating the maximum VIF allowed for selected predictor variables. The default is 5.</p>
</td></tr>
<tr><td><code id="getModels_+3A_classes">classes</code></td>
<td>
<p>character value to pass to <code><a href="maxnet.html#topic+maxnet">maxnet::maxnet.formula()</a></code> indicating the continuous feature classes desired. Can be &quot;default&quot; or any subset of &quot;lqpht&quot; (linear, quadratic, product, hinge, threshold) &ndash; for example, &quot;lqh&quot; for just linear, quadratic and hinge features. See References for guidance.</p>
</td></tr>
<tr><td><code id="getModels_+3A_regmult">regmult</code></td>
<td>
<p>numeric value to pass to <code><a href="maxnet.html#topic+maxnet">maxnet::maxnet()</a></code> indicating the constant to adjust regularization. The default is 1. See References for guidance.</p>
</td></tr>
<tr><td><code id="getModels_+3A_nreps">nreps</code></td>
<td>
<p>integer value indicating the number of train-test datasets for testing the models. The default is 10. With nreps = 0, there is no division of the dataset into train and test samples, so models are trained on the entire dataset for each period. If nreps &gt; 0, presences are randomly assigned to the train and test sample in each replicate (in the proportion defined by the 'test' argument), while the background remains the same.</p>
</td></tr>
<tr><td><code id="getModels_+3A_test">test</code></td>
<td>
<p>(if nreps &gt; 0) numeric value indicating the proportion of presences to set aside for testing each model. The default is 0.2, i.e. 20%.</p>
</td></tr>
<tr><td><code id="getModels_+3A_file">file</code></td>
<td>
<p>optional file name (including path, not including extension) if you want the output list of model objects to be saved on disk. If 'file' already exists in the working directory (meaning that models were already computed), models are imported from there.</p>
</td></tr>
<tr><td><code id="getModels_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of three elements:
</p>
<p>$models: a list of lists of model objects of class <a href="maxnet.html#topic+maxnet">maxnet::maxnet</a>. Each element of the list corresponds to a period (e.g. period), and each sub-element a replicate.
</p>
<p>$data: a data frame with the presences, remaining background points and their environmental values used in the model(s).
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Elith J., Phillips S.J., Hastie T., Dudik M., Chee Y.E., Yates, C.J. (2011) A Statistical Explanation of MaxEnt for Ecologists. Diversity and Distributions 17:43-57. http://dx.doi.org/10.1111/j.1472-4642.2010.00725.x
</p>
<p>Merow C., Smith M.J., Silander J.A. (2013) A practical guide to MaxEnt for modeling species' distributions: what it does, and why inputs and settings matter. Ecography 36:1058-1069. https://doi.org/10.1111/j.1600-0587.2013.07872.x
</p>


<h3>See Also</h3>

<p><code><a href="maxnet.html#topic+maxnet">maxnet::maxnet()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Several data prep steps required.
# See https://github.com/AMBarbosa/ecotrends for a full worked example.
</code></pre>

<hr>
<h2 id='getPerformance'>Get model performance</h2><span id='topic+getPerformance'></span>

<h3>Description</h3>

<p>Get model performance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPerformance(
  rasts,
  mods,
  metrics = c("AUC", "TSS"),
  plot = FALSE,
  verbosity = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPerformance_+3A_rasts">rasts</code></td>
<td>
<p>SpatRasterDataset output of <code><a href="#topic+getPredictions">getPredictions()</a></code>, or 'file' argument previously provided to <code><a href="#topic+getPredictions">getPredictions()</a></code></p>
</td></tr>
<tr><td><code id="getPerformance_+3A_mods">mods</code></td>
<td>
<p>output of <code><a href="#topic+getModels">getModels()</a></code></p>
</td></tr>
<tr><td><code id="getPerformance_+3A_metrics">metrics</code></td>
<td>
<p>character vector with the metrics to compute. Can be any subset of c(&quot;AUC&quot;, &quot;TSS&quot;), the latter computed at its optimal threshold. The default is both. Performance metrics are computed with presence against all background (using 'modEvA' package functions with pbg=TRUE), so they evaluate the capacity of distinguishing presence from random, rather than presence from absence pixels (Phillips et al., 2006).</p>
</td></tr>
<tr><td><code id="getPerformance_+3A_plot">plot</code></td>
<td>
<p>logical value indicating whether plots should also be produced to illustrate the performance metrics for each model. The default is FALSE; TRUE can be slow for large datasets.</p>
</td></tr>
<tr><td><code id="getPerformance_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a data frame of the performance evaluation results for each model.
</p>


<h3>References</h3>

<p>Phillips, S.J., Anderson, R.P., Schapire, R.E. (2006) Maximum entropy modeling of species geographic distributions. Ecological Modelling, 190: 231-259. https://doi.org/10.1016/j.ecolmodel.2005.03.026
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Several data prep steps required.
# See https://github.com/AMBarbosa/ecotrends for a full worked example.
</code></pre>

<hr>
<h2 id='getPredictions'>Get predictions</h2><span id='topic+getPredictions'></span>

<h3>Description</h3>

<p>Get predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPredictions(
  rasts,
  mods,
  region = NULL,
  type = "cloglog",
  clamp = TRUE,
  file = NULL,
  verbosity = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPredictions_+3A_rasts">rasts</code></td>
<td>
<p>(multi-layer) SpatRaster containing the variables (with the same names) used in the models.</p>
</td></tr>
<tr><td><code id="getPredictions_+3A_mods">mods</code></td>
<td>
<p>output of <code><a href="#topic+getModels">getModels()</a></code>.</p>
</td></tr>
<tr><td><code id="getPredictions_+3A_region">region</code></td>
<td>
<p>optional SpatExtent or SpatVector polygon delimiting the region of 'rasts' within which to compute the predictions. The default is NULL, to use the entire extent of 'rasts'. Note that predictions may be unreliable outside the 'region' used for <code><a href="#topic+getModels">getModels()</a></code>, as they are extrapolating beyond the analysed conditions.</p>
</td></tr>
<tr><td><code id="getPredictions_+3A_type">type</code></td>
<td>
<p>character value to pass to <code><a href="stats.html#topic+predict">predict()</a></code> indicating the type of response to compute. Can be &quot;cloglog&quot; (the default and currently recommended), &quot;logistic&quot; (previously but no longer recommended) (Phillips et al., 2017), &quot;exponential&quot;, or &quot;link&quot;.</p>
</td></tr>
<tr><td><code id="getPredictions_+3A_clamp">clamp</code></td>
<td>
<p>logical value to pass to <code><a href="stats.html#topic+predict">predict()</a></code> indicating whether predictors and features should be restricted to the range seen during model training. Default TRUE.</p>
</td></tr>
<tr><td><code id="getPredictions_+3A_file">file</code></td>
<td>
<p>optional folder name (including path within the working directory) if you want the prediction rasters to be saved to disk. If 'file' already exists in the working directory (meaning that predictions were already computed), predictions are imported from there.</p>
</td></tr>
<tr><td><code id="getPredictions_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a SpatRasterDataset with one sub-dataset per period, each of which is a (multilayer) SpatRaster with the predictions of each replicate (if there are replicates) for that period.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Phillips, S.J., Anderson, R.P., Dudik, M., Schapire, R.E., Blair, M.E., 2017. Opening the black box: an open-source release of Maxent. Ecography 40, 887-893. https://doi.org/10.1111/ecog.03049
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Several data prep steps required.
# See https://github.com/AMBarbosa/ecotrends for a full worked example.
</code></pre>

<hr>
<h2 id='getTrend'>Get trend</h2><span id='topic+getTrend'></span>

<h3>Description</h3>

<p>This function uses <code><a href="terra.html#topic+app">terra::app()</a></code> to apply the <code><a href="trend.html#topic+sens.slope">trend::sens.slope()</a></code> function to each pixel of a multi-layer time series SpatRaster, testing for a monotonic (either increasing or decreasing) linear trend in the raster values, as well as the confidence interval of the slope.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTrend(
  rasts,
  occs = NULL,
  alpha = 0.05,
  conf.level = 0.95,
  file = NULL,
  full = TRUE,
  verbosity = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTrend_+3A_rasts">rasts</code></td>
<td>
<p>multi-layer SpatRaster with the output of <code><a href="#topic+getPredictions">getPredictions()</a></code>, or another time series of values for which to detect a trend. Note that &gt;3 non-NA values (i.e. more than 3 time steps) are required for a trend to be computed. If there are &gt;1 replicates per year, their pixel-wise mean is computed prior to analysing the trend.</p>
</td></tr>
<tr><td><code id="getTrend_+3A_occs">occs</code></td>
<td>
<p>SpatVector of species occurrence points, or their spatial coordinates (2 columns in this order: x, y or LONGitude, LATitude) in an object coercible to a data.frame (e.g. a data.frame, matrix, tibble, sf object), and in the same coordinate reference system as 'rasts'. If provided, output pixels that do not overlap these points will be NA</p>
</td></tr>
<tr><td><code id="getTrend_+3A_alpha">alpha</code></td>
<td>
<p>numeric value indicating the threshold significance level for Sen's slope. Default 0.05. Pixels with p-value above this will have NA value in the output.</p>
</td></tr>
<tr><td><code id="getTrend_+3A_conf.level">conf.level</code></td>
<td>
<p>numeric value to pass to <code><a href="trend.html#topic+sens.slope">trend::sens.slope()</a></code> indicating the confidence level for the slope of the trend. Default 0.95.</p>
</td></tr>
<tr><td><code id="getTrend_+3A_file">file</code></td>
<td>
<p>optional file name (including path, not including extension) if you want the outputs raster(s) to be imported from or saved to disk.</p>
</td></tr>
<tr><td><code id="getTrend_+3A_full">full</code></td>
<td>
<p>logical value indicating whether to output a multi-layer raster with the full results of the Mann-Kendall test (namely the Tau value, p-value, S, and variance of S) and the results of Sen's slope calculation (slope estimate, p-value, upper and lower confidence limit). If set to FALSE, a single-layer raster will be returned with the (significant) Sen's slope values.</p>
</td></tr>
<tr><td><code id="getTrend_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If full=FALSE, a single-layer SpatRaster where each pixel (or each pixel with occurrence points, if 'occs' is not NULL) has the value of Sen's slope (positive if increasing, negative if decreasing), or NA if the trend is non-significant (i.e., if the p-value is larger than the specified 'alpha'). If full=TRUE (the default), additional layers are produced with associated statistics, including the lower and upper bounds of Sen's slope (given the input 'conf.level').
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>See Also</h3>

<p><code><a href="trend.html#topic+sens.slope">trend::sens.slope()</a></code>, <code><a href="trend.html#topic+mk.test">trend::mk.test()</a></code>, Kendall::MannKendall(), spatialEco::raster.kendall()
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Several data prep steps required.
# See https://github.com/AMBarbosa/ecotrends for a full worked example.
</code></pre>

<hr>
<h2 id='getVariables'>Get variables</h2><span id='topic+getVariables'></span>

<h3>Description</h3>

<p>This function downloads a specified time series of variables from a specified environmental data source, optionally (to save download time) within a specified region. Currently &quot;TerraClimate&quot; (Abatzoglou et al., 2018) is the only implemented data source.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getVariables(
  source = "TerraClimate",
  vars = varsAvailable(source)$vars,
  years = varsAvailable(source)$years,
  region = c(-180, 180, -90, 90),
  file = NULL,
  verbosity = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getVariables_+3A_source">source</code></td>
<td>
<p>source to import the raster variables from, e.g. &quot;TerraClimate&quot; (currently the only one implemented)</p>
</td></tr>
<tr><td><code id="getVariables_+3A_vars">vars</code></td>
<td>
<p>character vector of the names of the variables to be imported. Run varsAvailable() for options. The default is to download all available variables from the specified 'source'. Note that the download can take a long time, especially for many variables, long series of years, and/or large regions.</p>
</td></tr>
<tr><td><code id="getVariables_+3A_years">years</code></td>
<td>
<p>year range to get the variables from (e.g. 1979:2013). Note that the download can take a long time for long series of years.</p>
</td></tr>
<tr><td><code id="getVariables_+3A_region">region</code></td>
<td>
<p>optional length-four numeric vector (xmin, xmax, ymin, ymax geodetic coordinates in degrees), SpatExtent or SpatVector polygon delimiting the region of the world for which the variables should be downloaded. See ?getRegion for suggestions. The larger the region, the longer the download time.</p>
</td></tr>
<tr><td><code id="getVariables_+3A_file">file</code></td>
<td>
<p>optional file name (including the path, not including the filename extension) if you want the downloaded variable rasters to be saved on disk, in which case they are saved as a compressed multi-layer GeoTIFF. If 'file' already exists in the working directory, variables are imported from there.</p>
</td></tr>
<tr><td><code id="getVariables_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>multi-layer SpatRaster
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Abatzoglou, J.T., S.Z. Dobrowski, S.A. Parks, K.C. Hegewisch (2018) Terraclimate, a high-resolution global dataset of monthly climate and climatic water balance from 1958-2015. Scientific Data, 5, Article number: 170191. doi: 10.1038/sdata.2017.191(2018). Database URL: https://www.climatologylab.org/terraclimate.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varsAvailable">varsAvailable()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (interactive()) {

# note these downloads may take long!

vars &lt;- ecotrends::getVariables(vars = c("tmin", "tmax", "ppt", "pet", "ws"),
years = 1981:1990, region = terra::ext(-11, -4, 37, 45), file = paste0(tempdir(), "/variables"))

# tempdir() is here to comply with CRAN policy, but you should normally
# use a directory that you can access again when reopening R
# to avoid downloading the variables again every time

names(vars)

terra::plot(vars[[1:6]])

}

</code></pre>

<hr>
<h2 id='pixelArea'>Average pixel area</h2><span id='topic+pixelArea'></span>

<h3>Description</h3>

<p>This function uses the <code><a href="terra.html#topic+cellSize">terra::cellSize()</a></code> function to compute (and optionally map) the area covered by each (optionally non-NA) pixel in a raster map; and then it computes either the mean or the centroid pixel area in that map, for an idea of pixel size in that region. Pixel size can vary widely across latitudes, especially in unprojected longitude-latitude rasters, but also in rasters projected to other non-equal-area coordinate reference systems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pixelArea(
  rast,
  type = "mean",
  unit = "m",
  mask = TRUE,
  map = TRUE,
  verbosity = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pixelArea_+3A_rast">rast</code></td>
<td>
<p>SpatRaster for which to compute the pixel area</p>
</td></tr>
<tr><td><code id="pixelArea_+3A_type">type</code></td>
<td>
<p>character value indicating whether the output value should be the &quot;mean&quot; (default) or &quot;centroid&quot; pixel area</p>
</td></tr>
<tr><td><code id="pixelArea_+3A_unit">unit</code></td>
<td>
<p>numeric value indicating the units for the output value: either &quot;m&quot; (default) or &quot;km&quot; squared.</p>
</td></tr>
<tr><td><code id="pixelArea_+3A_mask">mask</code></td>
<td>
<p>logical value (default TRUE) indicating whether to consider only the areas of non-NA pixels</p>
</td></tr>
<tr><td><code id="pixelArea_+3A_map">map</code></td>
<td>
<p>logical value (default TRUE) indicating whether to also plot a map</p>
</td></tr>
<tr><td><code id="pixelArea_+3A_verbosity">verbosity</code></td>
<td>
<p>integer value indicating the amount of messages to display. The default is 2, for the maximum number of messages available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric value
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa, wrapping 'terra' functions by Robert H. Hijmans
</p>


<h3>See Also</h3>

<p><code><a href="terra.html#topic+cellSize">terra::cellSize()</a></code>, which this function wraps
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r &lt;- terra::rast(system.file("ex/elev.tif", package = "terra"))

pixelArea(r)

pixelArea(r, unit = "km")
</code></pre>

<hr>
<h2 id='varsAvailable'>Variables available</h2><span id='topic+varsAvailable'></span>

<h3>Description</h3>

<p>Variables available
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varsAvailable(source = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varsAvailable_+3A_source">source</code></td>
<td>
<p>the source database where to check available variables. By default (i.e. if left NULL), all implemented sources are used. Currently &quot;TerraClimate&quot; (https://www.climatologylab.org/terraclimate.html) is the only implemented source.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named nested list with one element per data source, each of which containing two elements: a character vector of the names of the variables available from that source, and an integer vector of the years for which those variables are available.
</p>


<h3>Author(s)</h3>

<p>A. Marcia Barbosa
</p>


<h3>References</h3>

<p>Abatzoglou, J.T., S.Z. Dobrowski, S.A. Parks, K.C. Hegewisch (2018) Terraclimate, a high-resolution global dataset of monthly climate and climatic water balance from 1958-2015. Scientific Data, 5, Article number: 170191. doi: 10.1038/sdata.2017.191(2018). Database URL: https://www.climatologylab.org/terraclimate.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getVariables">getVariables()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>varsAvailable()
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
