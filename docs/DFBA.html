<!DOCTYPE html><html><head><title>Help for package DFBA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DFBA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DFBA-package'><p>DFBA: Distribution-Free Bayesian Analysis</p></a></li>
<li><a href='#dfba_bayes_vs_t_power'><p>Simulated Distribution-Free Bayesian Power and <em>t</em> Power</p></a></li>
<li><a href='#dfba_beta_bayes_factor'><p>Bayes Factor for Posterior Beta Distribution</p></a></li>
<li><a href='#dfba_beta_contrast'><p>Bayesian Contrasts</p></a></li>
<li><a href='#dfba_beta_descriptive'><p>Descriptive Statistics for a Beta Distribution</p></a></li>
<li><a href='#dfba_binomial'><p>Bayesian Binomial Rate Parameter Inference</p></a></li>
<li><a href='#dfba_bivariate_concordance'><p>Bayesian Distribution-Free Correlation and Concordance</p></a></li>
<li><a href='#dfba_gamma'><p>Goodman-Kruskal Gamma</p></a></li>
<li><a href='#dfba_gamma_out-class'><p>Classes for DFBA</p></a></li>
<li><a href='#dfba_mann_whitney'><p>Independent Samples Test (Mann Whitney U)</p></a></li>
<li><a href='#dfba_mcnemar'><p>Bayesian Repeated-Measures McNemar Test for Change</p></a></li>
<li><a href='#dfba_median_test'><p>Bayesian Median Test</p></a></li>
<li><a href='#dfba_power_curve'><p>Power Curves</p></a></li>
<li><a href='#dfba_sign_test'><p>Bayesian Sign Test</p></a></li>
<li><a href='#dfba_sim_data'><p>Simulated Data Generator and Inferential Comparison</p></a></li>
<li><a href='#dfba_wilcoxon'><p>Repeated-Measures Test (Wilcoxon Signed-Ranks Test)</p></a></li>
<li><a href='#show+2Cdfba_beta_contrast_out-method'><p>Formats for Beta Contrasts</p></a></li>
<li><a href='#show+2Cdfba_beta_descriptive_out-method'><p>Formats for Beta Descriptive</p></a></li>
<li><a href='#show+2Cdfba_binomial_out-method'><p>Formats for Bayesian Binomial Test</p></a></li>
<li><a href='#show+2Cdfba_bivariate_concordance_out-method'><p>Formatted output for dfba_bivariate_concordance</p></a></li>
<li><a href='#show+2Cdfba_gamma_out-method'><p>Formatted output for dfba_gamma</p></a></li>
<li><a href='#show+2Cdfba_interval_BF_out-method'><p>Formats for Interval Bayes Factor</p></a></li>
<li><a href='#show+2Cdfba_mann_whitney_large_out-method'><p>Formats for large-n Mann Whitney</p></a></li>
<li><a href='#show+2Cdfba_mann_whitney_small_out-method'><p>Formats for small-n Mann Whitney</p></a></li>
<li><a href='#show+2Cdfba_mcnemar_out-method'><p>Format for Bayesian McNemar Test</p></a></li>
<li><a href='#show+2Cdfba_median_test_out-method'><p>Formats for Bayesian Median Test Output</p></a></li>
<li><a href='#show+2Cdfba_point_BF_out-method'><p>Formats for Point Bayes Factor</p></a></li>
<li><a href='#show+2Cdfba_power_curve_out-method'><p>Formats for power curve</p></a></li>
<li><a href='#show+2Cdfba_sign_test_out-method'><p>Formats for Bayesian Sign Test</p></a></li>
<li><a href='#show+2Cdfba_sim_data_out-method'><p>Format for Simulated Data Function</p></a></li>
<li><a href='#show+2Cdfba_t_power_out-method'><p>Bayesian vs. t Power Methods</p></a></li>
<li><a href='#show+2Cdfba_wilcoxon_large_out-method'><p>Formats for large-n Wilcoxon</p></a></li>
<li><a href='#show+2Cdfba_wilcoxon_small_out-method'><p>Formats for small-n Wilcoxon</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Distribution-Free Bayesian Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel H. Barch &lt;daniel.barch@tufts.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A set of functions to perform distribution-free Bayesian analyses. 
             Included are Bayesian analogues to the frequentist Mann-Whitney U 
             test, the Wilcoxon Signed-Ranks test, Kendall's Tau Rank 
             Correlation Coefficient, Goodman and Kruskal's Gamma, McNemar's
             Test, the binomial test, the sign test, the median test, as well as 
             distribution-free methods for testing contrasts among condition and 
             for computing Bayes factors for hypotheses. The package also
             includes procedures to estimate the power of distribution-free
             Bayesian tests based on data simulations using various probability 
             models for the data. The set of functions provide data analysts 
             with a set of Bayesian procedures that avoids requiring parametric 
             assumptions about measurement error and is robust to problem of 
             extreme outlier scores.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, graphics, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, bookdown, testthat (&ge; 3.0.0), vdiffr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-12 21:37:43 UTC; danielbarch</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel H. Barch [aut, cre],
  Richard A. Chechile [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-13 12:10:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='DFBA-package'>DFBA: Distribution-Free Bayesian Analysis</h2><span id='topic+DFBA'></span><span id='topic+DFBA-package'></span>

<h3>Description</h3>

<p>A set of functions to perform distribution-free Bayesian analyses. Included are Bayesian analogues to the frequentist Mann-Whitney U test, the Wilcoxon Signed-Ranks test, Kendall's Tau Rank Correlation Coefficient, Goodman and Kruskal's Gamma, McNemar's Test, the binomial test, the sign test, the median test, as well as distribution-free methods for testing contrasts among condition and for computing Bayes factors for hypotheses. The package also includes procedures to estimate the power of distribution-free Bayesian tests based on data simulations using various probability models for the data. The set of functions provide data analysts with a set of Bayesian procedures that avoids requiring parametric assumptions about measurement error and is robust to problem of extreme outlier scores.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Daniel H. Barch <a href="mailto:daniel.barch@tufts.edu">daniel.barch@tufts.edu</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Richard A. Chechile <a href="mailto:richard.chechile@tufts.edu">richard.chechile@tufts.edu</a>
</p>
</li></ul>


<hr>
<h2 id='dfba_bayes_vs_t_power'>Simulated Distribution-Free Bayesian Power and <em>t</em> Power</h2><span id='topic+dfba_bayes_vs_t_power'></span>

<h3>Description</h3>

<p>The function is a design tool for comparing Bayesian distribution-free
power versus frequentist <em>t</em> power for a range of sample sizes. Allows
for the stipulation of one of nine probability models for data generation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_bayes_vs_t_power(
  n_min = 20,
  delta,
  model,
  design,
  effect_crit = 0.95,
  shape1 = 1,
  shape2 = 1,
  samples = 1000,
  a0 = 1,
  b0 = 1,
  block_max = 0,
  hide_progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_n_min">n_min</code></td>
<td>
<p>Smallest desired value of sample size for power calculations (minimun 20; default is also 20)</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_delta">delta</code></td>
<td>
<p>Offset amount between the two variates</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_model">model</code></td>
<td>
<p>Theoretical probability model for the data. One of <code>"normal"</code>, <code>"weibull"</code>, <code>"cauchy"</code>, <code>"lognormal"</code>, <code>"chisquare"</code>, <code>"logistic"</code>, <code>"exponential"</code>, <code>"gumbel"</code>, or <code>"pareto"</code>.</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_design">design</code></td>
<td>
<p>Indicates the data structure. One of <code>"independent"</code> or <code>"paired"</code>.</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_effect_crit">effect_crit</code></td>
<td>
<p>Stipulated value for a significant differences for a <em>t</em>-test (1 - <em>p</em>), and the critical probability for the Bayesian alternative hypothesis for a Bayesian distribution-free analysis</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_shape1">shape1</code></td>
<td>
<p>The shape parameter for the condition 1 variate for the distribution indicated by the <code>model</code> input (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_shape2">shape2</code></td>
<td>
<p>The shape parameter for the condition 2 variate for the distribution indicated by the <code>model</code> input (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_samples">samples</code></td>
<td>
<p>Desired number of Monte Carlo data sets drawn to estimate the power (default is 1000)</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_block_max">block_max</code></td>
<td>
<p>The maximum size for a block effect (default is 0)</p>
</td></tr>
<tr><td><code id="dfba_bayes_vs_t_power_+3A_hide_progress">hide_progress</code></td>
<td>
<p>(Optional) If <code>TRUE</code>, hide percent progress while Monte Carlo sampling is running. (default is <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Researchers need to make experimental-design decisions such as the choice
about the sample size per condition and the decision of whether to use a
within-block design or an independent-groups design. These planning issues
arise regardless if one uses either a frequentist or a Bayesian approach to
statistical inference. In the DFBA package, there are a number of functions
to help users with these decisions. The <code>dfba_bayes_vs_t_power()</code> function
produces (a) the Bayesian power estimate from a distribution-free analysis
and (b) the corresponding frequentist power from a parametric <em>t</em>-test
for a set of 11 sample sizes ranging from <code>n_min</code> to <code>n_min + 50</code>
in steps of 5. These estimates are based on a number of different Monte-
Carlo-sampled data sets generated by the <code>dfba_sim_data()</code> function.
</p>
<p>For each data set, statistical tests are performed. If <code>design = "paired"</code>,
the frequentist <em>t</em>-test is a one-tailed test on the within-block
difference scores to assess the null hypothesis that the population mean for
<code>E</code> is greater than the population mean for <code>C</code>; if
<code>design = "independent"</code>, the frequentist <em>t</em>-test is the one-tailed
test to assess if there is a significant difference between the two
independent conditions (<em>i.e.</em> if the mean for condition 2 is
significantly greater than the condition 1 mean). If <code>design = "paired"</code>,
the Bayesian analysis assesses if the posterior probability for <code>phi_w &gt; .5</code>
from the Bayesian Wilcoxon test is greater than <code>effect_crit</code>; if
<code>design = "independent"</code>, the Bayesian analysis assesses if the posterior
probability for <code>omega_E &gt; .5</code> on a Bayesian Mann-Whitney test
is greater than <code>effect_crit</code>. The frequentist power is estimated by
the proportion of the data sets where a parametric <em>t</em>-test detects a
significant effect because the  upper-tail <em>t</em> value has a <em>p</em>-value
less than <code>1-effect_crit</code>. The Bayesian power is the proportion of the
data sets where a posterior probability for the alternative hypothesis is
greater than <code>effect_crit</code>. The default value for the
<code>effect_crit</code> argument is <code>effect_crit = .95</code>. The frequentist
<em>p</em>-value and the Bayesian posterior probability for the
alternative hypothesis are calculated using the <code>dfba_sim_data()</code>
function.
</p>
<p>The arguments for the <code>dfba_sim_data()</code> function are passed from the
<code>dfba_bayes_vs_t_power()</code> function. Besides the sample size <code>n</code>, there
are eight other arguments that are required by the <code>dfba_sim_data()</code>
function, which are passed from the <code>dfba_bayes_vs_t_power()</code> function:
</p>

<ul>
<li> <p><code>a0</code>
</p>
</li>
<li> <p><code>b0</code>
</p>
</li>
<li> <p><code>model</code>
</p>
</li>
<li> <p><code>design</code>
</p>
</li>
<li> <p><code>delta</code>
</p>
</li>
<li> <p><code>shape1</code>
</p>
</li>
<li> <p><code>shape2</code>
</p>
</li>
<li> <p><code>block_max</code>.
</p>
</li></ul>

<p>The <code>a0</code> and <code>b0</code> values are the respective first and second beta
shape parameters for the prior distribution needed for the Bayesian
distribution-free tests, which are ultimately done by calling either the
<code>dfba_wilcoxon()</code> function or by the <code>dfba_mann_whitney()</code> function.
</p>
<p>The <code>model</code> argument is one of the following strings:
</p>

<ul>
<li> <p><code>"normal"</code>
</p>
</li>
<li> <p><code>"weibull"</code>
</p>
</li>
<li> <p><code>"cauchy"</code>
</p>
</li>
<li> <p><code>"lognormal"</code>
</p>
</li>
<li> <p><code>"chisquare"</code>
</p>
</li>
<li> <p><code>"logistic"</code>
</p>
</li>
<li> <p><code>"exponential"</code>
</p>
</li>
<li> <p><code>"gumbel"</code>
</p>
</li>
<li> <p><code>"pareto"</code>
</p>
</li></ul>

<p>The <code>design</code> argument is either <code>"independent"</code> or <code>"paired"</code>,
and stipulates whether the two sets of scores are either independent or from
a common block such as for the case of two scores for the same person (<em>i.e.</em>,
one in each condition).
</p>
<p>The <code>shape1</code> and <code>shape2</code> arguments are values for the shape parameter
for the respective first and second condition, and their meaning
depends on the probability model. For <code>model="normal"</code>, these
parameters are the standard deviations of the two distributions. For
<code>model = "weibull"</code>, the parameters are the Weibull shape parameters.
For <code>model = "cauchy"</code>, the parameters are the scale factors for the
Cauchy distributions. For <code>model = "lognormal"</code>, the shape
parameters are the standard deviations for log(X). For <code>model = "chisquare"</code>,
the parameters are the degrees of freedom (<em>df</em>) for the two
distributions. For <code>model = "logistic"</code>, the parameters are the scale
factors for the distributions. For <code>model = "exponential"</code>, the parameters
are the rate parameters for the distributions.
</p>
<p>For the Gumbel distribution, the <code>E</code> variate is equal to
<code>delta - shape2*log(log(1/U))</code> where <code>U</code> is a random value sampled
from the uniform distribution on the interval <code>[.00001, .99999]</code>, and
the <code>C</code> variate is equal to <code>-shape1*log(log(1/U))</code> where <code>U</code>
is another score sampled from the uniform distribution. The <code>shape1</code> and
<code>shape2</code> arguments for <code>model = "gumbel"</code> are the scale parameters
for the distributions. The Pareto model is a distribution designed to account
for income distributions as studied by economists (Pareto, 1897). For the
Pareto distribution, the cumulative function is equal to <code>1-(x_m/x)^alpha</code>
where <code>x</code> is greater than <code>x_m</code> (Arnold, 1983). In the <code>E</code>
condition, <code>x_m = 1 + delta</code> and in the <code>C</code> condition <code>x_m = 1</code>.
The alpha parameter is 1.16 times the shape parameters <code>shape1</code> and
<code>shape2</code>. Since the default value for each shape parameter is 1, the
resulting alpha value of 1.16 is the default value. When alpha = 1.16, the
Pareto distribution approximates an income distribution that represents the
80-20 law where 20% of the population receives 80% of the income
(Hardy, 2010).
</p>
<p>The <code>block_max</code> argument provides for incorporating block effects in the
random sampling. The block effect for each score is a separate effect for the
block. The block effect B for a score is a random number drawn from a uniform
distribution on the interval <code>[0, block_max]</code>. When <code>design = "paired"</code>,
the same random block effect is added to the score in the first condition,
which is the random <code>C</code> value, and it is also added to the corresponding
paired value for the <code>E</code> variate. Thus, the pairing research design
eliminates the effect of block variation for the assessment of condition
differences. When <code>design = "independent"</code>, there are different block-effect
contributions to the <code>E</code> and <code>C</code> variates, which reduces the
discrimination of condition differences because it increases the variability
of the difference in the two variates. The user can study the effect of the
relative discriminability of detecting an effect of delta by adjusting the
value of the <code>block_max</code> argument. The default for <code>block_max</code> is 0,
but it can be altered to any non-negative real number.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>nsims</code></td>
<td>
<p>The number of Monte Carlo data sets; equal to the value of the <code>samples</code> argument</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Probability model for the data</p>
</td></tr>
<tr><td><code>design</code></td>
<td>
<p>The design for the data; one of <code>"independent"</code> or <code>"paired"</code></p>
</td></tr>
<tr><td><code>effect_crit</code></td>
<td>
<p>The criterion probability for considering a posterior probability for the hypothesis that <code>delta &gt; 0</code> to be a detection; it is also <code>1 - p_crit</code> for a frequentist <em>t</em>-test</p>
</td></tr>
<tr><td><code>deltav</code></td>
<td>
<p>The offset between the variates; equal to the <code>delta</code> argument</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the beta prior distribution</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the beta prior distribution</p>
</td></tr>
<tr><td><code>block_max</code></td>
<td>
<p>The maximum size of a block effect; equal to <code>block_max</code> argument</p>
</td></tr>
<tr><td><code>outputdf</code></td>
<td>
<p>A dataframe of possible sample sizes and the corresponding Bayesian and frequentist power values</p>
</td></tr>
</table>


<h3>References</h3>

<p>Arnold, B. C. (1983). Pareto Distribution. Fairland, MD:
International Cooperative Publishing House.
</p>
<p>Chechile, R. A. (2017). A Bayesian analysis for the Wilcoxon signed-rank
statistic. Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2017.1388402
</p>
<p>Chechile, R. A. (2020). A Bayesian analysis for the Mann-Whitney statistic.
Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2018.1549247
</p>
<p>Fishman, G. S. (1996) Monte Carlo: Concepts, Algorithms and Applications.
New York: Springer.
</p>
<p>Hardy, M. (2010). Pareto's Law. Mathematical Intelligencer,
32, 38-43.
</p>
<p>Johnson, N. L., Kotz S., and Balakrishnan, N. (1995). Continuous Univariate
Distributions, Vol. 1, New York: Wiley.
</p>
<p>Pareto, V. (1897). Cours d'Economie Politique. Vol. 2,
Lausanne: F. Rouge.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for details on the
parameters of the normal, Weibull, Cauchy, lognormal, chi-squared, logistic,
and exponential distributions.
</p>
<p><code><a href="#topic+dfba_wilcoxon">dfba_wilcoxon</a></code>
</p>
<p><code><a href="#topic+dfba_mann_whitney">dfba_mann_whitney</a></code>
</p>
<p><code><a href="#topic+dfba_sim_data">dfba_sim_data</a></code>  for further details about the data for two
conditions that differ in terms of their theoretical mean by an amount delta.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: these examples have long runtimes due to Monte Carlo sampling;
# please feel free to run them in the console.

# Examples for two data sets sampled from standard normal distributions with
# no blocking effect


dfba_bayes_vs_t_power(n_min = 40,
                      delta = .45,
                      model = "normal",
                      design = "paired",
                      samples = 250,
                      hide_progress = TRUE)

dfba_bayes_vs_t_power(n_min = 50,
                      delta = .45,
                      model = "weibull",
                      design = "independent",
                      samples = 250,
                      hide_progress = TRUE)

dfba_bayes_vs_t_power(n_min = 50,
                      delta = .45,
                      model = "weibull",
                      design = "paired",
                      shape1 = .8,
                      shape2 = .8,
                      samples = 250,
                      block_max = 2.3,
                      hide_progress = TRUE)


</code></pre>

<hr>
<h2 id='dfba_beta_bayes_factor'>Bayes Factor for Posterior Beta Distribution</h2><span id='topic+dfba_beta_bayes_factor'></span>

<h3>Description</h3>

<p>Given a beta posterior distribution and given a prior for the variate,
computes the Bayes factor for either point
or interval null hypotheses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_beta_bayes_factor(a_post, b_post, method, H0, a0 = 1, b0 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_beta_bayes_factor_+3A_a_post">a_post</code></td>
<td>
<p>The first shape parameter for the posterior beta distribution. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_beta_bayes_factor_+3A_b_post">b_post</code></td>
<td>
<p>The second shape parameter for the posterior beta distribution. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_beta_bayes_factor_+3A_method">method</code></td>
<td>
<p>One of <code>"interval"</code> if the null hypothesis is a range on the <code>[0,1]</code> interval or <code>"point"</code> if the null hypothesis is a single number in the <code>[0,1]</code> interval</p>
</td></tr>
<tr><td><code id="dfba_beta_bayes_factor_+3A_h0">H0</code></td>
<td>
<p>If method=&quot;interval&quot;, then the H0 input is vector of two values, which are lower and upper limits for the null hypothesis; if method=&quot;point&quot;, then the H0 input is single number, which is the null hypothesis value</p>
</td></tr>
<tr><td><code id="dfba_beta_bayes_factor_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_beta_bayes_factor_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution(default is 1). Must be positive and finite.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a binomial variate with <code>n1</code> successes and <code>n2</code> failures, the
Bayesian analysis for the population success rate parameter <code class="reqn">\phi</code> is
distributed as a beta density function with shape parameters <code>a_post</code>
and <code>b_post</code> for <code>a_post = n1 + a0</code> and <code>b_post = n2 + b0</code> where <code>a0</code>
and <code>b0</code> are the shape parameters for the prior beta distribution. It is
common for users to be interested in testing hypotheses about the population
<code class="reqn">\phi</code> parameter. The Bayes factor is useful to assess if either the null
or the alternative hypothesis are credible.
</p>
<p>There are two types of null hypotheses &ndash; an interval null hypothesis
and a point null hypothesis. For example, an interval null hypothesis
might be <code class="reqn">\phi \le .5</code> with the alternative hypothesis being <code class="reqn">\phi &gt; .5</code>,
whereas a point null hypothesis might be <code class="reqn">\phi = .5</code> with the alternative
being <code class="reqn">\phi \ne .5</code>. It is conventional to call the null hypothesis <code class="reqn">H_0</code>
and to call the alternative hypothesis <code class="reqn">H_1</code>. For frequentist null
hypothesis testing, <code class="reqn">H_0</code> is assumed to be true, to see if this
assumption is likely or not. With the frequentist approach the null
hypothesis cannot be proved since it was assumed in the first place.
With frequentist statistics, <code class="reqn">H_0</code> is thus either retained
as assumed or it is rejected. Unlike the frequentist approach,
Bayesian hypothesis testing does not assume either <code class="reqn">H_0</code> or <code class="reqn">H_1</code>; it
instead assumes a prior distribution for the population parameter
<code class="reqn">\phi</code>, and based on this assumption arrives at a posterior
distribution for the parameter given the data of <code>n1</code> and <code>n2</code> for the
binomial outcomes.
</p>
<p>There are two related Bayes factors - <code>BF10</code> and <code>BF01</code> where
<code>BF01 = 1/BF10</code>. When <code>BF10 &gt; 1</code>, there is more support for the
alternative hypothesis, whereas when <code>BF01 &gt; 1</code>, there is more support
for the null hypothesis. Thus, in Bayesian hypothesis testing it is possible
to build support for either <code>H_0</code> or <code>H_1</code>. In essence, the Bayes
factor is a measure of the relative strength of evidence. There is no
standard guideline for recommending a decision about the prevailing
hypothesis, but several statisticians have suggested criteria. Jeffreys
(1961) suggested that <code>BF &gt; 10</code> was <em>strong</em> and <code>BF &gt; 100</code>
was <em>decisive</em>; Kass and Raffrey (1995) suggested that <code>BF &gt; 20</code> was
<em>strong</em> and <code>BF &gt; 150</code> was <em>decisive</em>. Chechile (2020) argued
from a decision-theory framework for a third option for the user to decide
<em>not to decide</em> if the prevailing Bayes factor is not sufficiently large.
From this decision-making perspective, Chechile (2020) suggested that <code>BF &gt; 19</code>
was a <em>good bet - too good to disregard</em>, <code>BF &gt; 99</code> was <em>a strong</em>
<em>bet - irresponsible to avoid</em>, and <code>BF &gt; 20,001</code> was <em>virtually certain</em>.
Chechile also pointed out that despite the Bayes factor value there is often
some probability, however small, for either hypothesis. Ultimately, each
academic discipline has to set the standard for their field for the strength
of evidence. Yet even when the Bayes factor is below the user's threshold for
making claims about the hypotheses, the value of the Bayes factor from one
study can be nonetheless valuable to other researchers and might be combined
<em>via</em> a product rule in a meta-analysis. Thus, the value of the Bayes
factor has a descriptive utility.
</p>
<p>The Bayes factor <code>BF10</code> for an interval null is the ratio of the posterior
odds of <code class="reqn">H_1</code> to <code class="reqn">H_0</code> divided by the prior odds of <code class="reqn">H_1</code> to <code class="reqn">H_0</code>.
Also, the converse Bayes factor <code>BF01</code> is the ratio of posterior odds of
<code class="reqn">H_0</code> to <code class="reqn">H_1</code> divided by the prior odds of <code class="reqn">H_0</code> to <code class="reqn">H_1</code>;
hence <code>BF01 = 1/BF10</code>. If there is no change in the odds ratio as a
function of new data being collected, then <code>BF10 = BF01 = 1</code>. But, if
evidence is more likely for one of the hypotheses, then either <code>BF10</code> or
<code>BF01</code> will be greater than 1.
</p>
<p>The population parameter <code class="reqn">\phi</code> is distributed on the continuous interval
<code class="reqn">[0,1]</code>. The prior and posterior beta distribution are probability density
displays. Importantly, this means that no point has a nonzero probability
density, even as the probability mass for any mathematical point is zero.
For this reason, all point null hypotheses have a probability measure of
zero, but can have a probability density that can be different for prior and
posterior distributions. There still is a meaningful Bayes factor for a point
hypothesis. As described in Chechile (2020),
</p>
<p style="text-align: center;"><code class="reqn">BF10 = [p(H_1|D)/p(H_1)][p(H_0)/p(H_0|D)]</code>
</p>
<p> where <code class="reqn">D</code> denotes the data.
The first term in this equation is <code class="reqn">1/1 = 1</code>. But the second term is of
the form <code class="reqn">0/0</code>, which appears to undefined. However, by using L'Hospital's
rule, it can be proved that the term <code class="reqn">p(H_0)/p(H_0|D)</code> is the ratio of prior
probability density at the null point divided by the posterior probability
density. This method for finding the Bayes factor for a point is called the
Savage-Dickey method because of the separate contributions from both of those
statisticians (Dickey &amp; Lientz, 1970).
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>The string of either <code>"interval"</code> or <code>"point"</code> corresponding to the type of null hypothesis tested</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>The value for the posterior beta first shape parameter</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>The value for the posterior beta second shape parameter</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution</p>
</td></tr>
<tr><td><code>BF10</code></td>
<td>
<p>The Bayes factor for the alternative over the null hypothesis</p>
</td></tr>
<tr><td><code>BF01</code></td>
<td>
<p>The Bayes factor for the null over the alternative hypothesis</p>
</td></tr>
<tr><td><code>null_hypothesis</code></td>
<td>
<p>The value for the null hypothesis when <code>method = "point"</code></p>
</td></tr>
<tr><td><code>H0lower</code></td>
<td>
<p>The lower limit of the null hypothesis when <code>method = "interval"</code></p>
</td></tr>
<tr><td><code>H0upper</code></td>
<td>
<p>The upper limit of the null hypothesis when <code>method = "interval"</code></p>
</td></tr>
<tr><td><code>dpriorH0</code></td>
<td>
<p>The prior probability density for the null point when <code>method = "point"</code></p>
</td></tr>
<tr><td><code>dpostH0</code></td>
<td>
<p>The posterior probability density for the null point when <code>method = "point"</code></p>
</td></tr>
<tr><td><code>pH0</code></td>
<td>
<p>The prior probability for the null hypothesis when <code>method = "interval"</code></p>
</td></tr>
<tr><td><code>pH1</code></td>
<td>
<p>The prior probability for the alternative hypothesis when <code>method = "interval"</code></p>
</td></tr>
<tr><td><code>postH0</code></td>
<td>
<p>The posterior probability for the null hypothesis when <code>method = "interval"</code></p>
</td></tr>
<tr><td><code>postH1</code></td>
<td>
<p>The posterior probability for the alternative hypothesis when <code>method = "interval"</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R. A. (2020). Bayesian Statistics for Experimental Scientists:
A General Introduction Using Distribution-Free Methods. MIT Press.
</p>
<p>Dickey, J. M., &amp; Lientz, B. P. (1970). The weighted likelihood ratio, sharp
hypotheses about chance, the order of a Markov chain. The Annals of
Mathematical Statistics, 41, 214-226.
</p>
<p>Jeffreys, H. (1961). Theory of Probability (3rd ed.). Oxford: Oxford
University Press.
</p>
<p>Kass, R. E., &amp; Rafftery, A. E. (1995). Bayes factors. Journal of the American
Statistical Association, 90, 773-795.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examples with the default uniform prior
dfba_beta_bayes_factor(a_post = 17,
                       b_post = 5,
                       method = "interval",
                       H0 = c(0, .5)
                       )
dfba_beta_bayes_factor(a_post = 377,
                       b_post = 123,
                       method = "point",
                       H0 = .75)

# An example with the Jeffreys prior
dfba_beta_bayes_factor(a_post = 377.5,
                       b_post = 123.5,
                       method = "point",
                       H0 = .75,
                       a0 = .5,
                       b0 = .5
                       )


dfba_beta_bayes_factor(a_post = 273,
                       b_post = 278,
                       method = "interval",
                       H0 = c(.4975,
                              .5025)
                       )

</code></pre>

<hr>
<h2 id='dfba_beta_contrast'>Bayesian Contrasts</h2><span id='topic+dfba_beta_contrast'></span>

<h3>Description</h3>

<p>This function implements a Bayesian analysis of a linear contrast of
conditions when there are 2 or more independent conditions and where
the variate for each condition is a binomial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_beta_contrast(
  n1_vec,
  n2_vec,
  contrast_vec,
  a0_vec = rep(1, length(n1_vec)),
  b0_vec = rep(1, length(n1_vec)),
  prob_interval = 0.95,
  samples = 10000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_beta_contrast_+3A_n1_vec">n1_vec</code></td>
<td>
<p>A vector of length K that consists of the observed number of successes for the categorical variable in each of the K separate conditions</p>
</td></tr>
<tr><td><code id="dfba_beta_contrast_+3A_n2_vec">n2_vec</code></td>
<td>
<p>A vector of length K that consists of the observed number of failures for the  categorical variable in each of the K separate conditions</p>
</td></tr>
<tr><td><code id="dfba_beta_contrast_+3A_contrast_vec">contrast_vec</code></td>
<td>
<p>A vector of coefficients of a linear comparison among the conditions where the sum of all the coefficients must be 0 and the sum of the positive coefficients must be 1 and the sum of the negative coefficients must be -1</p>
</td></tr>
<tr><td><code id="dfba_beta_contrast_+3A_a0_vec">a0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>a0</code> shape parameters for the separate betas (the default values are 1)</p>
</td></tr>
<tr><td><code id="dfba_beta_contrast_+3A_b0_vec">b0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>b0</code> shape parameters for the separate betas (the default values are 1)</p>
</td></tr>
<tr><td><code id="dfba_beta_contrast_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired probability for equal-tail interval estimate on the contrast (default is 0.95)</p>
</td></tr>
<tr><td><code id="dfba_beta_contrast_+3A_samples">samples</code></td>
<td>
<p>The desired number of Monte Carlo samples taken from each posterior beta variate (default is 10000)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since the Bayesian analysis for each separate condition has a posterior beta
distribution with known shape parameters, the program approximates, <em>via</em>
Monte Carlo sampling, a linear contrast among the set of independent beta
distributions because the contrast of beta distributions is not a known
probability model.
</p>
<p>Given a binomial categorical variate for each of <code class="reqn">K</code> independent
conditions with <code class="reqn">K \ge 2</code>, the standard frequentist nonparametric
analysis is to do a <code class="reqn">\chi^2</code> test with <code class="reqn">K - 1</code> degrees of freedom
(Siegel &amp; Castellan, 1988). Hypothesis testing for the frequentist <code class="reqn">\chi^2</code>
test assesses the sharp-null hypothesis that the binomial success rate is
exactly equal in all the conditions. But this point-null hypothesis is not an
interesting question about the population success rate from a Bayesian
viewpoint because the probability of any single point hypothesis has a
probability measure value of zero (Chechile, 2020). Although it is possible
that the frequentist null hypothesis can be retained for small-<code class="reqn">n</code> studies,
the hypothesis itself is about the population in the case of unlimited sample
size, and surely for this limiting case it is almost certain that the
hypothesis is not exactly true. Thus, from the Bayesian framework, the point-
null hypothesis is not a good use of scientific effort and resources, and it
is more scientifically meaningful to assess a linear comparison of the
conditions, such as to assess if the population success rate in one condition
is greater than the success rate in another condition. An interval hypothesis
such as this has a meaningful probability value, as does the complimentary
hypothesis. If <code class="reqn">\phi_1</code> and <code class="reqn">\phi_2</code> are, respectively, the population
success rates for the binomials in conditions 1 and 2, then a meaningful
comparison might be to assess the probability distribution for <code class="reqn">\Delta = </code>
<code class="reqn">\phi_2 - \phi_1</code>. This example is a simple linear contrast with contrast
coefficient weights of -1 and 1, which are the multipliers for the two
population success rates. If the posterior interval estimate for the contrast
contains 0, then the hypothesis of <code class="reqn">\Delta = 0</code> has some credibility in light
of the given sample size. Thus, by estimating the distribution of <code class="reqn">\Delta</code>,
the user learns important information about condition differences. As another
example of a contrast, suppose there are three conditions where the first
condition is a standard control and the other two conditions are different
alternative conditions. In this case, a user might want to compare the
mean of the control data against the average of the two experimental-
condition means, <em>i.e.</em>, the contrast of
</p>
<p style="text-align: center;"><code class="reqn">\Delta = -1\phi_1 +.5\phi_2 + .5\phi_3.</code>
</p>

<p>In this second example, the coefficients of the contrast are <code class="reqn">[-1, +.5, +.5]</code>.
As a third example, the user might also be interested in a comparison where
the two experimental conditions are compared, <em>i.e.</em>, the contrast of
</p>
<p style="text-align: center;"><code class="reqn">\Delta = 0\phi_1 + 1\phi_2 - 1\phi_3.</code>
</p>

<p>For the <code>dfba_beta_contrast()</code> function, the user is required to
stipulate the coefficients of a contrast such that the sum of all the
coefficients is 0, the sum of the positive coefficients is 1, and the sum of
the negative coefficients is -1. This constraint on the coefficients forces
<code class="reqn">\Delta</code> to be on the <code class="reqn">[-1, +1]</code> interval.
</p>
<p>There is a standard Bayesian posterior for each condition, which is a beta
distribution (see Chechile (2020) for a detailed discussion of this
literature). In short, it is well known that the beta distribution is a
natural Bayesian conjugate function for Bernoulli random processes. Thus, a
prior beta distribution with shape parameters <code class="reqn">a_0</code> and <code class="reqn">b_0</code> results
(<em>via</em> Bayes's theorem) in a posterior beta with shape parameters <code class="reqn">a</code>
and <code class="reqn">b</code> where <code class="reqn">a = a_0 + n_1</code> and <code class="reqn">b = b_0 + n_2</code>, where <code class="reqn">n_1</code>
and <code class="reqn">n_2</code> are the respective successes and failures of the categorical
variable. While the Bayesian analysis of each beta distribution for the
separate conditions are known, a comparison among 2 or more separate beta
distributions is not distributed as a beta. The posterior mean of a linear
contrast of separate beta variates has a known mean regardless of the
correlations among the variates, but the distributional form of the contrast
of independent betas is not known in closed form. The distributional form is
important for ascertaining issues such as determining the probability that
the contrast is positive or specifying a probability interval for the
contrast. But, with the <code>dfba_beta_contrast()</code> function, these important
aspects of the Bayesian analysis are approximated via Monte Carlo simulation.
</p>
<p>The <code>samples</code> argument stipulates the number of random values to be
drawn from each of the <code class="reqn">K</code> posterior conditions. The default value for
<code>samples</code> is 10000. The default value of 10000 is also the minimum value
that can be selected (increased values of <code>samples</code> provide increased
precision). Posterior interval estimation and the Bayes factor for the
contrast are provided on the basis of the Monte Carlo sampling. If <code>samples</code>
is equal to <code class="reqn">N</code> and if <code class="reqn">\phi_1, \ldots, \phi_K</code> are the parameters
for the population success rates, then there are <code class="reqn">N</code> random values drawn
from each of <code class="reqn">\phi_i</code> parameters for <code class="reqn">i = 1, \ldots , K</code>. Given the
contrast coefficients stipulated in the arguments, there are <code class="reqn">N</code> delta random
posterior values where <code class="reqn">\Delta_j = \Psi_1\phi_{1j}+ \ldots +\Psi_i\phi_{Kj}</code> for
<code class="reqn">j = 1, \ldots, N</code>, where <code class="reqn">\Psi_i</code> are the contrast coefficients specified
in the <code>contrast_vec</code> argument. The Monte Carlo sampling from each posterior
beta with known shape parameters uses the <code>rbeta()</code> function. Thus, unlike
Bayesian procedures that employ Markov chain Monte Carlo algorithms, the
Monte Carlo sampling in the <code>dfba_beta_contrast()</code> function does not depend
on a burn-in process or a starting estimate. Thus, all the <code class="reqn">N</code> sampled
values are valid random samples. Repeated use of the <code>dfba_beta_contrast()</code>
function for the same input will naturally exhibit some random variation in
the interval estimate and in the Bayes factor for a contrast greater than 0.
However, the point estimate for the contrast does not depend on the Monte
Carlo sampling, and it is constant given the vectors for <code>n1_vec</code> and
<code>n2_vec</code> and given the same prior.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>Exact posterior mean estimate for the contrast</p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>The lower equal-tail limit for the contrast for the probability interval value specified by <code>prob_interval</code></p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>The upper equal-tail limit for the contrast for the probability interval value specified by <code>prob_interval</code></p>
</td></tr>
<tr><td><code>prob_positive_delta</code></td>
<td>
<p>Posterior probability that the contrast is positive</p>
</td></tr>
<tr><td><code>prior_positive_delta</code></td>
<td>
<p>Prior probability that the contrast is positive</p>
</td></tr>
<tr><td><code>bayes_factor</code></td>
<td>
<p>The Bayes factor for the posterior-to-prior odds for a positive contrast to a non-positive contrast</p>
</td></tr>
<tr><td><code>delta_quantiles</code></td>
<td>
<p>Quantile values (<code>probs = seq(0, 1, 0.01)</code>) for the posterior contrast from the Monte Carlo sampling</p>
</td></tr>
<tr><td><code>a_vec</code></td>
<td>
<p>A vector of length K that consists of the posterior <code>a</code> shape parameters for the separate posterior beta distributions</p>
</td></tr>
<tr><td><code>b_vec</code></td>
<td>
<p>A vector of length K that consists of the posterior <code>b</code> shape parameters for the separate posterior beta distributions</p>
</td></tr>
<tr><td><code>a0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>a0</code> shape parameters for the separate prior beta distributions</p>
</td></tr>
<tr><td><code>b0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>b0</code> shape parameters for the separate prior beta distributions</p>
</td></tr>
<tr><td><code>contrast_vec</code></td>
<td>
<p>A vector for the contrast coefficients for a linear comparison of posterior beta variates</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>The probability for the equal-tail estimate for the contrast (default is 0.95)</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>The number of Monte Carlo samples from the K separate posterior beta distributions</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R. A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Methods. Cambridge: MIT Press.
</p>
<p>Siegel, S. &amp; Castellan, N. J. (1988). Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw Hill.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Suppose there are four conditions from a factorial design
# where the conditions labels are A1B1, A2B1, A1B2, and A2B2
# where the frequencies for success for the binomial variate are:
n1_vec &lt;- c(22, 15, 13, 21)
# and the frequencies for failures per condition are:
n2_vec &lt;- c(18, 25, 27, 19)
# Let us test the following three orthogonal contrasts
contrast.B1vsB2 &lt;- c(.5, .5, -.5, -.5)
contrast.A1vsA2 &lt;- c(.5, -.5, .5, -.5)
contrast.ABinter &lt;- c(.5, -.5, -.5, .5)

dfba_beta_contrast(n1_vec = n1_vec,
                   n2_vec = n2_vec,
                   contrast_vec = contrast.B1vsB2)

dfba_beta_contrast(n1_vec,
                   n2_vec,
                   contrast_vec = contrast.A1vsA2)

dfba_beta_contrast(n1_vec,
                   n2_vec,
                   contrast_vec = contrast.ABinter)

# Plot the cumulative distribution for AB interaction
testABinteraction&lt;-dfba_beta_contrast(n1_vec,
                                      n2_vec,
                                      contrast_vec = contrast.ABinter)
plot(testABinteraction)
</code></pre>

<hr>
<h2 id='dfba_beta_descriptive'>Descriptive Statistics for a Beta Distribution</h2><span id='topic+dfba_beta_descriptive'></span>

<h3>Description</h3>

<p>Given the two shape parameters for a beta distribution, the function provides
central tendency statistics, interval limits, and density and cumulative
probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_beta_descriptive(a, b, prob_interval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_beta_descriptive_+3A_a">a</code></td>
<td>
<p>The first shape parameter for the beta distribution. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_beta_descriptive_+3A_b">b</code></td>
<td>
<p>The second shape parameter for the beta distribution. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_beta_descriptive_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired probability within interval limits (default is .95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function for a beta variate is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \begin{cases} Kx^{a-1}(1-x)^{b-1} &amp; \quad \textrm{if } 0 \le x \le 1, \\0 &amp; \quad \textrm{otherwise} \end{cases}</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">K = \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)}.</code>
</p>

<p>(Johnson, Kotz, &amp; Balakrishnan, 1995). The two shape parameters <code class="reqn">a</code> and <code class="reqn">b</code> must
be positive values.
</p>
<p>The <code>dfba_beta_descriptive()</code> function provides features
to complement the beta distribution functions available in the <strong>stats</strong>
package. The function provides the mean, median, mode, and variance for a
beta variate in terms of its two shape parameters.
</p>
<p>While the mean, variance, and median are straightforward, there are several
conditions that result in an undefined mode. When either (1) <code class="reqn">a = b = 1</code>,
(2)  <code class="reqn">a &lt; 1</code>, or (3) <code class="reqn">b &lt; 1</code>, the mode is undefined. For example,
when <code class="reqn">a = b = 1</code>, the function is the uniform distribution, which does not
have a modal value. The other cases above result in the density function
diverging at either <code class="reqn">x = 0</code> or <code class="reqn">x = 1</code>. The function returns a value of
<code>NA</code> for the mode for all the cases where a unique mode does not exist.
</p>
<p>For interval estimation, the function finds an equal-tail interval limits in
all cases, and it also provides the highest-density limits when there is a
well-defined mode. When the mode does not exist, the function returns <code>NA</code>
for the limits for the highest-density interval (HDI). For interval
estimation, the probability between the lower and upper limit is the
probability specified in the <code>prob_interval</code> input. The
<code>dfba_beta_descriptive()</code> output object includes a dataframe that has
density and cumulative probability information that can be used for plotting.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>a</code></td>
<td>
<p>The first beta shape parameter</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>The second beta shape parameter</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>The probability for interval estimates</p>
</td></tr>
<tr><td><code>x_mean</code></td>
<td>
<p>The mean of the distribution</p>
</td></tr>
<tr><td><code>x_median</code></td>
<td>
<p>The median of the distribution</p>
</td></tr>
<tr><td><code>x_mode</code></td>
<td>
<p>The mode for the distribution</p>
</td></tr>
<tr><td><code>x_variance</code></td>
<td>
<p>The variance for the distribution</p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>The equal-tail lower interval limit</p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>The equal-tail upper interval limit</p>
</td></tr>
<tr><td><code>hdi_lower</code></td>
<td>
<p>The lower limit for the highest-density interval</p>
</td></tr>
<tr><td><code>hdi_upper</code></td>
<td>
<p>The upper limit for the highest-density interval</p>
</td></tr>
<tr><td><code>outputdf</code></td>
<td>
<p>A dataframe of <code>x</code>, density, and cumulative probability for <code>x</code> from 0 to 1 in steps of .005</p>
</td></tr>
</table>


<h3>References</h3>

<p>Johnson, N. L., Kotz S., and Balakrishnan, N. (1995). <em>Continuous Univariate</em>
<em>Distributions</em>, Vol. 1, New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for additional details on
functions for the beta distribution in the <strong>stats</strong> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dfba_beta_descriptive(a = 38,
                      b = 55)

dfba_beta_descriptive(38,
                      55,
                      prob_interval=.99)

</code></pre>

<hr>
<h2 id='dfba_binomial'>Bayesian Binomial Rate Parameter Inference</h2><span id='topic+dfba_binomial'></span>

<h3>Description</h3>

<p>Given binomial frequency data, provides a Bayesian analysis for the
population binomial rate parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_binomial(n1, n2, a0 = 1, b0 = 1, prob_interval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_binomial_+3A_n1">n1</code></td>
<td>
<p>Integer number of binomial observations for a category 1 response (<em>e.g.</em>, the number of successes)</p>
</td></tr>
<tr><td><code id="dfba_binomial_+3A_n2">n2</code></td>
<td>
<p>Integer number of binomial observations for a category 2 response (<em>e.g.</em>, the number of failures)</p>
</td></tr>
<tr><td><code id="dfba_binomial_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution that corresponds to the population binomial parameter (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_binomial_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the population binomial rate parameter (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_binomial_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Probability within interval estimates for the population binomial rate parameter (default is .95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The binomial distribution with size = <code class="reqn">n</code> and probability = <code class="reqn">\phi</code> has
discrete probabilities
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \frac{n!}{z!(n - x!)}\phi^{x}(1-\phi)^{n-x}</code>
</p>

<p>where x is an integer from 0 to <code class="reqn">n</code> in steps of 1. The binomial model
assumes a Bernoulli process of independent trials where there are binary
outcomes that have the same probability (say, <code class="reqn">\phi</code>) for a response in
one of the two categories and a probability of <code class="reqn">1-\phi</code> for the other
category. Before any data are collected, there are <code class="reqn">n + 1</code> possible
values for <code class="reqn">x</code> number of outcomes in category 1 and <code class="reqn">n - x</code> number of
outcomes in category 2. The binomial distribution is a likelihood
distribution. A likelihood is the probability of an outcome given a specific
value for the population rate parameter. Yet for real applications, the
population parameter is not known. All that is known are the outcomes
observed from a set of binomial trials. The binomial inference problem is to
estimate the population <code class="reqn">\phi</code> parameter based on the sample data.
</p>
<p>The frequentist approach to statistics is based on the relative frequency
method of assigning probability values (Ellis, 1842). From this framework,
there are no probabilities for anything that does not have a relative
frequency (von Mises, 1957). In frequency theory, the <code class="reqn">\phi</code> parameter
does not have a relative frequency, so it cannot have a probability
distribution. From a frequentist framework, a value for the binomial rate
parameter is <em>assumed</em>, and there is a discrete distribution for the <code class="reqn">n + 1</code>
outcomes for <code class="reqn">x</code> from 0 to <code class="reqn">n</code>. The discrete likelihood distribution
has relative frequency over repeated experiments. Thus, for the frequentist
approach, <code class="reqn">x</code> is a random variable, and <code class="reqn">\phi</code> is an unknown fixed
constant. Frequency theory thus delibrately eschews the idea of the binomial
rate parameter having a probability distribution. Laplace (1774) had
previously employed a Bayesian approach of treating the <code class="reqn">\phi</code> parameter
as a random variable. Yet Ellis and other researchers within the frequentist
tradition delibrately rejected the Bayes/Laplace approach. For tests of a
null hypothesis of an assumed <code class="reqn">\phi</code> value, the frequentist approach either
continues to assume the null hypothesis or it rejects the null hypothesis
depending on the likelihood of the observed data plus the likelihood of more
extreme unobserved outcomes. The confidence interval is the range of <code class="reqn">\phi</code>
values where the null hypothesis of specific <code class="reqn">\phi</code> values would be
retained given the observed data (Clopper &amp; Pearson, 1934). However, the
frequentist confidence interval is not a probability interval since
population parameters cannot have a probability distribution with frequentist
methods. Frequentist statisticians were well aware (<em>e.g.</em>, Pearson, 1920)
that if the <code class="reqn">\phi</code> parameter had a distribution, then the Bayes/Laplace
approach would be correct.
</p>
<p>Bayesian statistics rejects the frequentist theoretical decisions as to what
are the fixed constants and what is the random variable that can take on a
range of values. From a Bayesian framework, probability is anything that
satisfies the Kolmogorov (1933) axioms, so probabilities need not be limited
to processes that have a relative frequency. Importantly, probability can be
a measure of information or knowledge provided that the probability
representation meets the Kolmogorov axioms (De Finetti, 1974). Given binomial
data, the population binomial rate parameter <code class="reqn">\phi</code> is unknown, so it is
represented with a probability distribution for its possible values. This
assumed distribution is the prior distribution. Furthermore, the quantity <code class="reqn">x</code>
for the likelihood distribution above is not a random variable once the
experiment has been conducted. If there are <code class="reqn">n_1</code> outcomes for category 1
and <code class="reqn">n_2 = n-n_1</code> outcomes in category 2, then these are fixed values.
While frequentist methods compute both the likelihood of the observed
outcome <em>and</em> the likelihood for unobserved outcomes that are more
extreme, in Bayesian inference it is <em>only</em> the likelihood of the observed
outcome that is computed. From the Bayesian perspective, the inclusion of
unobserved outcomes in the analysis violates the likelihood principle (Berger
&amp; Wolpert, 1988). A number of investigators have found paradoxes with
frequentist procedures when the likelihood principle is not used (<em>e.g.</em>,
Lindley &amp; Phillips, 1976; Chechile, 2020). The Bayesian practice of strictly
computing only the likelihood of the observed data produces the result that
the likelihood for the binomial is proportional to <code class="reqn">\phi^{n_1}(1 - \phi)^{n_2}</code>.
In Bayesian statistics, the proportionality constant is not needed because it
appears in both the numerator and the denominator of Bayes theorem and thus
cancels. See Chechile (2020) for more extensive comparisons between
frequentist and Bayesian approaches with a particular focus on the binomial
model.
</p>
<p>Given a beta distribution prior for the binomial <code class="reqn">\phi</code> parameter, it has
been shown that the resulting posterior distribution from Bayes theorem is
another member of the beta family of distributions (Lindley &amp; Phillips, 1976).
This property of the prior and posterior being in the same distributional
family is called <em>conjugacy</em>. The beta distribution is a natural Bayesian
conjugate function for all Bernoulli processes where the likelihood is
proportional to <code class="reqn">\phi^{n_1}(1 - \phi)^{n_2}</code> (Chechile, 2020).
The density function for a beta variate is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \begin{cases} Kx^{a-1}(1-x)^{b-1} &amp; \quad \textrm{if } 0 \le x \le 1, \\0 &amp; \quad \textrm{otherwise} \end{cases}</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">K = \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)}</code>
</p>

<p>(Johnson, Kotz, &amp; Balakrishnan, 1995). The two shape parameters <code class="reqn">a</code> and <code class="reqn">b</code>
must be positive values. If the beta prior shape parameters are a0 and b0,
then the posterior beta shape parameters are <code class="reqn">a_{post} = a_0 + n_1</code> and
<code class="reqn">b_{post} = b_0 + n_2</code>. The default prior for the <code>dfba_binomial()</code>
function is <code>a0 = b0 = 1</code>, which corresponds to the uniform prior.
</p>
<p>Thus, the Bayesian inference for the unknown binomial rate parameter <code class="reqn">phi</code>
is the posterior beta distribution with shape parameters of <code>a_post</code> and
<code>b_post</code>. The <code>dfba_binomial()</code> function calls the
<code>dfba_beta_descriptive()</code> function to find the centrality point estimates
(<em>i.e.</em>, the mean, median, and mode) and to find two interval estimates
that contain the probability specified in the <code>prob_interval</code> argument.
One interval has equal-tail probabilities and the other interval is the
highest-density interval. Users can use the <code>dfba_beta_bayes_factor()</code>
function to test hypotheses about the <code class="reqn">\phi</code> parameter.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>n1</code></td>
<td>
<p>Observed number of category 1 responses</p>
</td></tr>
<tr><td><code>n2</code></td>
<td>
<p>Observed number of category 2 responses</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>First shape parameter for the prior beta distribution of the binomial rate parameter</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Second shape parameter for the prior beta distribution of the binomial rate parameter</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>Probability within interval estimates for the population binomial rate parameter</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution for the binomial rate parameter</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution for the binomial rate parameter</p>
</td></tr>
<tr><td><code>phimean</code></td>
<td>
<p>Mean of the posterior beta distribution for the binomial rate parameter</p>
</td></tr>
<tr><td><code>phimedian</code></td>
<td>
<p>Median of the posterior beta distribution for the binomial rate parameter</p>
</td></tr>
<tr><td><code>phimode</code></td>
<td>
<p>Mode of the posterior beta distribution for the binomial rate parameter</p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>Lower limit for the posterior equal-tail interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>Upper limit for the posterior equal-tail interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td></tr>
<tr><td><code>hdi_lower</code></td>
<td>
<p>Lower limit for the posterior highest-density interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td></tr>
<tr><td><code>hdi_upper</code></td>
<td>
<p>Upper limit for the posterior highest-density interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td></tr>
</table>


<h3>References</h3>

<p>Berger, J. O., &amp; Wolpert, R. L. (1988). The Likelihood Principle (2nd ed.)
Hayward, CA: Institute of Mathematical Statistics.
</p>
<p>Chechile, R. A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Statistics. Cambridge: MIT Press.
</p>
<p>Clopper, C. J., &amp; Pearson, E. S. (1934). The use of confidence or fiducial
limits illustrated in the case of the binomial. Biometrika, 26, 404-413.
</p>
<p>De Finetti, B. (1974). Bayesianism: Its unifying role for both the
foundations and applications of statistics. International Statistical Review/
Revue Internationale de Statistique, 117-130.
</p>
<p>Ellis, R. L. (1842). On the foundations of the theory of probability.
Transactions of the Cambridge Philosophical Society, 8, 1-6.
</p>
<p>Johnson, N. L., Kotz S., and Balakrishnan, N. (1995). Continuous Univariate
Distributions, Vol. 1, New York: Wiley.
</p>
<p>Kolmogorov, A. N. (1933/1959). Grundbegriffe der Wahrcheinlichkeitsrechnung.
Berlin: Springer. English translation in 1959 as Foundations of the Theory of
Probability. New York: Chelsea.
</p>
<p>Laplace, P. S. (1774). Memoire sr la probabilite des causes par les
evenements. Oeuvres complete, 8,5-24.
</p>
<p>Lindley, D. V., &amp; Phillips, L. D. (1976). Inference for a Bernoulli process
(a Bayesian view). The American Statistician, 30, 112-119.
</p>
<p>Pearson, K. (1920). The fundamental problem of practical statistics.
Biometrika, 13(1), 1-16.
</p>
<p>von Mises, R. (1957). Probability, Statistics, and Truth. New York: Dover.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for details on the
functions included in the <strong>stats</strong> regarding the beta and the binomial
distributions.
</p>
<p><code><a href="#topic+dfba_beta_bayes_factor">dfba_beta_bayes_factor</a></code> for further documentation about the
Bayes factor and its interpretation.
</p>
<p><code><a href="#topic+dfba_beta_descriptive">dfba_beta_descriptive</a></code> for advanced Bayesian descriptive methods
for beta distributions
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example using defaults of a uniform prior and 95% interval estimates
dfba_binomial(n1 = 16,
              n2 = 2)

 # Example with the Jeffreys prior and 99% interval estimates
dfba_binomial(n1 = 16,
              n2 = 2,
              a0 = .5,
              b0 = .5,
              prob_interval = .99)

</code></pre>

<hr>
<h2 id='dfba_bivariate_concordance'>Bayesian Distribution-Free Correlation and Concordance</h2><span id='topic+dfba_bivariate_concordance'></span>

<h3>Description</h3>

<p>Given bivariate data, computes the sample number of concordant changes <code>nc</code>
between the two variates and the number of discordant changes <code>nd</code>.
Provides the frequentist <code>tau_A</code> correlation coefficient
<code>(nc-nd)/(nc+nd)</code>, and provides a Bayesian analysis of the population
concordance parameter <code>phi</code>: the limit of the proportion of concordance
changes between the variates.
For goodness-of-fit applications, provides a concordance measure that
corrects for the number of fitting parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_bivariate_concordance(
  x,
  y,
  a0 = 1,
  b0 = 1,
  prob_interval = 0.95,
  fitting.parameters = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_bivariate_concordance_+3A_x">x</code></td>
<td>
<p>Vector of x variable values</p>
</td></tr>
<tr><td><code id="dfba_bivariate_concordance_+3A_y">y</code></td>
<td>
<p>Vector of y variable values</p>
</td></tr>
<tr><td><code id="dfba_bivariate_concordance_+3A_a0">a0</code></td>
<td>
<p>First shape parameter for the prior beta distribution (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_bivariate_concordance_+3A_b0">b0</code></td>
<td>
<p>Second shape parameter for the prior beta distribution (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_bivariate_concordance_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired width for interval estimates (default is .95)</p>
</td></tr>
<tr><td><code id="dfba_bivariate_concordance_+3A_fitting.parameters">fitting.parameters</code></td>
<td>
<p>(Optional) If either x or y values are generated by a predictive model, the number of free parameters in the model (default is NULL)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The product-moment correlation depends on Gaussian assumptions about the
residuals in a regression analysis. It is not robust because it is strongly
influenced by any extreme outlier scores for either of the two variates. A
rank-based analysis can avoid both of these limitations. The <code>dfba_bivariate_concordance()</code>
function is focused on a nonparametric concordance metric for characterizing
the association between the two bivariate measures.
</p>
<p>To illustrate the nonparametric concepts of concordance and discordance,
consider a specific example where there are five paired scores with
</p>
<p style="text-align: center;"><code class="reqn">x = {3.8, 4.7, 4.7, 4.7, 11.8}</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">y = [5.9, -4.1, 7.3, 7.3, 38.9].</code>
</p>

<p>The ranks for the <code class="reqn">x</code> variate are <code class="reqn">1, 3, 3, 3, 5</code> and the corresponding
ranks for <code class="reqn">y</code> are <code class="reqn">2, 1, 3.5, 3.5, 5</code>, so the five points in terms of
their ranks are <code class="reqn">P_1 = (1, 2)</code>, <code class="reqn">P_2 = (3, 1)</code>, <code class="reqn">P_3 = (3, 3.5)</code>,
<code class="reqn">P_4 = (3, 3.5)</code> and <code class="reqn">P_5 = (5,5)</code>. The relationship between any two
of these points <em>Pi</em> and <em>Pj</em>, is either (1) concordant if the
sign of <code class="reqn">R_{xi} - R_{xj}</code> is the same as the sign of
<code class="reqn">R_{yi} - R_{yj}</code>, (2) discordant if signs are
different between <code class="reqn">R_{xi}-R_{xj}</code> and <code class="reqn">R_{yi}-R_{yj}</code>, or (3) null if
either <code class="reqn">R_{xi}=R_{xj}</code> or if <code class="reqn">R_{yi}=R_{yj}</code>. For the above example,
there are ten possible comparisons among the five points; six are concordant,
one is discordant, and there are three comparisons lost due to ties. In
general, given <code class="reqn">n</code> bivariate scores there are <code class="reqn">n(n-1)/2</code> total
possible comparisons. When there are ties in the <code class="reqn">x</code> variate, there is
a loss of <code class="reqn">T_x</code> comparisons, when there are ties in the <code class="reqn">y</code> variate,
there are <code class="reqn">T_y</code> lost comparisons. Ties in both <code class="reqn">x</code> and <code class="reqn">y</code> are denoted
<code class="reqn">T_{xy}</code>. The total number of possible comparisons,
accounting for ties, is therefore: </p>
<p style="text-align: center;"><code class="reqn">n(n-1)/2-T_x-T_y+T_{xy},</code>
</p>
<p> where <code class="reqn">T_{xy}</code>
is added to avoid double-counting of lost comparisons.
</p>
<p>In the above example, there are three lost comparisons due to ties in <code class="reqn">x</code>,
one lost comparison due to a tie in <code class="reqn">y</code>, and one comparison lost to a tie
in both the <code class="reqn">x</code> and <code class="reqn">y</code> variates. Thus, there are <code class="reqn">[(5*4)/2]-3-1+1=7</code>
comparisons for the above example. The <code class="reqn">\tau_A</code> correlation is defined as
<code class="reqn">(n_c-n_d)/(n_c+n_d)</code>, which is a value on the <code class="reqn">[-1,1]</code> interval. However,
it is important to note the original developer of the frequentist <code class="reqn">\tau</code>
correlation used a different coefficient that has come to be called
<code class="reqn">\tau_B</code>, which is given as
<code class="reqn">(n_c-n_d)/([(n*(n-1)/2)-Tx][(n*(n-1)/2)-Ty])^{.5}</code>. However, <code class="reqn">\tau_B</code>
does not properly correct for tied scores, which is unfortunate
because <code class="reqn">\tau_B</code> is the value returned by the <code>stats</code> function
<code>cor(..., method = "kendall")</code>. If there are no ties, then
<code class="reqn">T_x = T_y = T_{xy} = 0</code> and <code class="reqn">\tau_A = \tau_B</code>. But if there are ties,
then the proper coefficient is given by <code class="reqn">\tau_A</code>. The <code>dfba_bivariate_concordance()</code>
function provides the proper correction for tied scores and outputs a sample
estimate for <code class="reqn">\tau_A</code>.
</p>
<p>The focus for the Bayesian analysis is on the population proportion
of concordance, which is the limit of the ratio <code class="reqn">n_c/(n_c+n_d)</code>. This
proportion is a value on the <code class="reqn">[0,1]</code> interval, and it is called <code class="reqn">\phi</code> (Phi).
<code class="reqn">\phi</code> is also connected to the population <code class="reqn">\tau_A</code> because
<code class="reqn">\tau_A=(2\phi -1)</code>. Moreover, Chechile (2020) showed that the
likelihood function for observing <code class="reqn">n_c</code> concordant changes and <code class="reqn">n_d</code>
discordant changes is a censored Bernoulli process, so the likelihood is
proportional to <code class="reqn">(\phi^{n_c})((1-\phi)^{n_d})</code>. In Bayesian statistics, the
likelihood function is only specified as a proportional function because,
unlike in frequentist statistics, the likelihood of unobserved and more
extreme events are not computed. This idea is the <em>likelihood principle</em>,
and its violation can lead to paradoxes (Lindley &amp; Phillips, 1976). Also, the
likelihood need only be a proportional function because the proportionality
constant appears in both the numerator and denominator of Bayes theorem, so
it cancels out. If the prior for <code class="reqn">\phi</code> is a beta distribution, then it
follows that the posterior is also a beta distribution (<em>i.e.</em>, the beta
is a natural Bayesian conjugate function for Bernoulli processes). The
default prior for the <code>dfba_bivariate_concordance()</code> function is the flat prior (<em>i.e.</em>,
<code>a0 = 1</code> and <code>b0 = 1</code>).
</p>
<p>In the special case where the user has a model for predicting a variate in
terms of known quantities and where there are free-fitting parameters, the
<code>dfba_bivariate_concordance()</code> function's concordance parameter is a goodness-of-fit measure
for the scientific model. Thus, the bivariate pair are the observed value of
a variate along with the corresponding predicted score from the model. The
concordance proportion must be adjusted in these goodness-of-fit applications
to take into account the number of free parameters that were used
in the prediction model. Chechile and Barch (2021) argued that the fitting
parameters increases the number of concordant changes. Consequently, the
value for <code class="reqn">n_c</code> is downward-adjusted as a function of the number of free
parameters. The Chechile-Barch adjusted <code class="reqn">n_c</code> value for a case where there
are <code class="reqn">m</code> free fitting parameters is <code class="reqn">n_c-(n*m)+[m*(m+1)/2]</code>. As an example,
suppose that there are <code class="reqn">n = 20</code> scores, and the prediction equation has
<code class="reqn">m = 2</code> free parameters that result in creating a prediction for each
observed score (<em>i.e.</em>, there are 20 paired values of observed score <code>x</code>
and predicted score <code>y</code>), and further suppose that this model results in
<code class="reqn">n_c = 170</code> and <code class="reqn">n_d = 20</code>. The value of <code>n_d</code> is kept at 20, but
the number of concordant changes is reduced to <code class="reqn">170-(20*2)+(2*3/2) = 133.</code>
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>tau</code></td>
<td>
<p>Nonparametric Tau-A correlation</p>
</td></tr>
<tr><td><code>sample_p</code></td>
<td>
<p>Sample concordance proportion</p>
</td></tr>
<tr><td><code>nc</code></td>
<td>
<p>Number of concordant comparisons</p>
</td></tr>
<tr><td><code>nd</code></td>
<td>
<p>Number of discordant comparisons</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>The first shape parameter for the posterior beta distribution for the concordance proportion</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>The second shape parameter for the posterior beta distribution for the concordance proportion</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for the  concordance proportion</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the concordance proportion</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>The probability within the interval estimates for the phi parameter</p>
</td></tr>
<tr><td><code>post_median</code></td>
<td>
<p>Median of posterior distribution on phi</p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>Lower limit of the equal-tail interval with width specified by prob_interval</p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>Upper limit of the equal-tail interval with width specified by prob_interval</p>
</td></tr>
<tr><td><code>tau_star</code></td>
<td>
<p>Corrected tau_A to account for the number of free fitting parameter in goodness-of-fit applications</p>
</td></tr>
<tr><td><code>nc_star</code></td>
<td>
<p>The corrected number of concordant comparisons for a goodness-of-fit application when there is an integer value for <code>fitting.parameters</code></p>
</td></tr>
<tr><td><code>nd_star</code></td>
<td>
<p>The number of discordant comparison when there is an integer value for <code>fitting.parameters</code></p>
</td></tr>
<tr><td><code>sample_p_star</code></td>
<td>
<p>Correct proportion of concordant comparisons to account for free-fitting parameter for goodness-of-fit applications</p>
</td></tr>
<tr><td><code>a_post_star</code></td>
<td>
<p>Corrected value for the first shape parameter for the posterior for the concordance proportion when there are free fitting parameter for goodness-of-fit applications</p>
</td></tr>
<tr><td><code>b_post_star</code></td>
<td>
<p>The second shape parameter for the posterior distribution for the concordance proportion when there is a goodness-of-fit application</p>
</td></tr>
<tr><td><code>post_median_star</code></td>
<td>
<p>The posterior median for the concordance proportion when there is a goodness-of-fit application</p>
</td></tr>
<tr><td><code>eti_lower_star</code></td>
<td>
<p>Lower limit for the interval estimate when there is a goodness-of-fit application</p>
</td></tr>
<tr><td><code>eti_upper_star</code></td>
<td>
<p>Upper limt for the interval estimate when there is a goodness-of-fit application</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R.A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution_Free Statistics. Cambridge: MIT Press.
</p>
<p>Chechile, R.A., &amp; Barch, D.H. (2021). A distribution-free, Bayesian
goodness-of-fit method for assessing similar scientific prediction equations.
Journal of Mathematical Psychology. https://doi.org/10.1016/j.jmp.2021.102638
</p>
<p>Lindley, D. V., &amp; Phillips, L. D. (1976). Inference for a Bernoulli process
(a Bayesian view). The American Statistician, 30, 112-119.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

x &lt;- c(47, 39, 47, 42, 44, 46, 39, 37, 29, 42, 54, 33, 44, 31, 28, 49, 32, 37, 46, 55, 31)
y &lt;- c(36, 40, 49, 45, 30, 38, 39, 44, 27, 48, 49, 51, 27, 36, 30, 44, 42, 41, 35, 49, 33)

dfba_bivariate_concordance(x, y)

## A goodness-of-fit example for a hypothetical case of fitting data in a
## yobs vector with prediction model

p = seq(.05,.95,.05)
ypred= 17.332 - (50.261*p) + (48.308*p^2)

# Note the coefficients in the ypred equation were found first via a
# polynomial regression

yobs&lt;-c(19.805, 10.105, 9.396, 8.219, 6.110, 4.543, 5.864, 4.861, 6.136,
         5.789,  5.443, 5.548, 4.746, 6.484, 6.185, 6.202, 9.804, 9.332,
         14.408)

dfba_bivariate_concordance(x = yobs,
         y = ypred,
         fitting.parameters = 3)

</code></pre>

<hr>
<h2 id='dfba_gamma'>Goodman-Kruskal Gamma</h2><span id='topic+dfba_gamma'></span>

<h3>Description</h3>

<p>Given bivariate data in the form of either a rank-ordered table or a matrix,
returns the number of concordant and discordant changes between the variates,
the Goodman-Kruskal gamma statistic, and a Bayesian analysis of the
population concordance proportion parameter <em>phi</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_gamma(x, a0 = 1, b0 = 1, prob_interval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_gamma_+3A_x">x</code></td>
<td>
<p>Cross-tabulated matrix or table where cell [I, J] represents the frequency of observations where the rank of measure 1 is I and the rank of measure 2 is J.</p>
</td></tr>
<tr><td><code id="dfba_gamma_+3A_a0">a0</code></td>
<td>
<p>First shape parameter for the prior beta distribution (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_gamma_+3A_b0">b0</code></td>
<td>
<p>Second shape parameter for the prior beta distribution (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_gamma_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired width for interval estimates (default is 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For bivariate data where two measures are restricted on an ordinal scale,
such as when the two variates are ranked data over a limited set of integers,
then an ordered contingency table is often a convenient data representation.
For such a case the element in the <code class="reqn">[I, J]</code> cell of the matrix is the
frequency of occasions where one variate has a rank value of <code class="reqn">I</code> and the
corresponding rank for the other variate is <code class="reqn">J</code>. This situation is a
special case of the more general case where there are two continuous
bivariate measures. For the special case of a rank-order matrix with
frequencies, there is a distribution-free concordance correlation that is in
common usage: Goodman and Kruskal's gamma <code class="reqn">G</code> (Siegel &amp; Castellan, 1988).
</p>
<p>Chechile (2020) showed that Goodman and Kruskal's gamma is equivalent to the
more general <code class="reqn">\tau_A</code> nonparametric correlation coefficient.
Historically, gamma was considered a different metric from <code class="reqn">\tau</code> because
typically the version of <code class="reqn">\tau</code> in standard use was <code class="reqn">\tau_B</code>, which
is a flawed metric because it does not properly correct for ties. Note:
<code>cor(... ,method = "kendall")</code> returns the <code class="reqn">\tau_B</code> correlation, which
is incorrect when there are ties. The correct <code class="reqn">\tau_A</code> is computed by the
<code>dfba_bivariate_concordance()</code> function.
</p>
<p>The gamma statistic is equal to <code class="reqn">(n_c-n_d)/(n_c+n_d)</code>, where <code class="reqn">n_c</code> is
the number of occasions when the variates change in a concordant way and <code class="reqn">n_d</code>
is the number of occasions when the variates change in a discordant fashion.
The value of <code class="reqn">n_c</code> for an order matrix is the sum of terms for each <code class="reqn">[I, J]</code>
that are equal to <code class="reqn">n_{ij}N^{+}_{ij}</code>, where <code class="reqn">n_{ij}</code> is the frequency
for cell <code class="reqn">[I, J]</code> and <code class="reqn">N^{+}_{ij}</code> is the sum of a frequencies in the
matrix where the row value is greater than <code class="reqn">I</code> and where the column value is
greater than <code class="reqn">J</code>. The value <code class="reqn">n_d</code> is the sum of terms for each <code class="reqn">[I, J]</code> that
are <code class="reqn">n_{ij}N^{-}_{ij}</code>, where <code class="reqn">N^{-}_{ij}</code> is the sum of the frequencies
in the matrix where row value is greater than <code class="reqn">I</code> and the column value is
less than <code class="reqn">J</code>. The <code class="reqn">n_c</code> and <code class="reqn">n_d</code> values computed in this fashion
are, respectively, equal to <code class="reqn">n_c</code> and <code class="reqn">n_d</code> values found when the bivariate
measures are entered as paired vectors into the <code>dfba_bivariate_concordance()</code> function.
</p>
<p>As with the <code>dfba_bivariate_concordance()</code> function, the Bayesian analysis focuses on the
population concordance proportion phi <code class="reqn">(\phi)</code>; and <code class="reqn">G=2\phi-1</code>. The
likelihood function is proportional to <code class="reqn">\phi^{n_c}(1-\phi)^{n_d}</code>. The
prior distribution is a beta function, and the posterior distribution is the
conjugate beta where <code>a = a0 + nc</code> and
<code>b = b0 + nd</code>.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>gamma</code></td>
<td>
<p>Sample Goodman-Kruskal gamma statistic; equivalent to the sample rank correlation coefficient tau_A</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>First shape parameter for prior beta</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Second shape parameter for prior beta</p>
</td></tr>
<tr><td><code>sample_p</code></td>
<td>
<p>Sample estimate for proportion concordance <code>nc/(nc+nd)</code></p>
</td></tr>
<tr><td><code>nc</code></td>
<td>
<p>Number of concordant comparisons between the paired measures</p>
</td></tr>
<tr><td><code>nd</code></td>
<td>
<p>Number of discordant comparisons between the paired measures</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution for the phi parameter</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution for the phi parameter</p>
</td></tr>
<tr><td><code>post_median</code></td>
<td>
<p>Median of the posterior distribution for the phi concordance parameter</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>The probability of the interval estimate for the phi parameter</p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>Lower limit of the posterior equal-tail interval for the phi parameter where the width of the interval is specified by the <code>prob_interval</code> input</p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>Upper limit of the posterior equal-tail interval for the phi parameter where the width of the interval is specified by the <code>prob_interval</code> input</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R.A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Methods. Cambridge: MIT Press.
</p>
<p>Siegel, S., &amp; Castellan, N. J. (1988) Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw Hill.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfba_bivariate_concordance">dfba_bivariate_concordance</a></code> for a more extensive discussion about the <code class="reqn">\tau_A</code>
statistic and the flawed <code class="reqn">\tau_B</code> correlation
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with matrix input
N &lt;- matrix(c(38, 4, 5, 0, 6, 40, 1, 2, 4, 8, 20, 30),
            ncol = 4,
            byrow = TRUE)
colnames(N) &lt;- c('C1', 'C2', 'C3', 'C4')
rownames(N) &lt;- c('R1', 'R2', 'R3')
dfba_gamma(N)

# Sample problem with table input
NTable &lt;- as.table(N)
dfba_gamma(NTable)
</code></pre>

<hr>
<h2 id='dfba_gamma_out-class'>Classes for DFBA</h2><span id='topic+dfba_gamma_out-class'></span><span id='topic+dfba_bivariate_concordance_out-class'></span><span id='topic+dfba_bivariate_concordance_star_out-class'></span><span id='topic+dfba_mann_whitney_small_out-class'></span><span id='topic+dfba_mann_whitney_large_out-class'></span><span id='topic+dfba_wilcoxon_small_out-class'></span><span id='topic+dfba_wilcoxon_large_out-class'></span><span id='topic+dfba_t_power_out-class'></span><span id='topic+dfba_power_curve_out-class'></span><span id='topic+dfba_point_BF_out-class'></span><span id='topic+dfba_interval_BF_out-class'></span><span id='topic+dfba_beta_contrast_out-class'></span><span id='topic+dfba_sim_data_out-class'></span><span id='topic+dfba_mcnemar_out-class'></span><span id='topic+dfba_median_test_out-class'></span><span id='topic+dfba_beta_descriptive_out-class'></span><span id='topic+dfba_sign_test_out-class'></span><span id='topic+dfba_binomial_out-class'></span>

<h3>Description</h3>

<p>Classes for DFBA
</p>

<hr>
<h2 id='dfba_mann_whitney'>Independent Samples Test (Mann Whitney U)</h2><span id='topic+dfba_mann_whitney'></span>

<h3>Description</h3>

<p>Given two independent vectors <code>E</code> and <code>C</code>, the function computes
the sample Mann-Whitney <code class="reqn">U</code> statistics <code>U_E</code> and <code>U_C</code> and
provides a Bayesian analysis for the population parameter <code>omega_E</code>,
which is the population ratio of <code class="reqn">U_E/(U_E+U_C)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_mann_whitney(
  E,
  C,
  a0 = 1,
  b0 = 1,
  prob_interval = 0.95,
  samples = 30000,
  method = NULL,
  hide_progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_mann_whitney_+3A_e">E</code></td>
<td>
<p>Data for independent sample 1 (&quot;Experimental&quot;)</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_c">C</code></td>
<td>
<p>Data for independent sample 2 (&quot;Control&quot;)</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for <code>omega_E</code> (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for <code>omega_E</code> (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired probability value for the interval estimate for <code>omega_E</code> (default is 95%)</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_samples">samples</code></td>
<td>
<p>The number of Monte Carlo samples for <code>omega_E</code> when <code>method = "small"</code> (default is 30000)</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_method">method</code></td>
<td>
<p>(Optional) The method option is either &quot;small&quot; or &quot;large&quot;. The &quot;small&quot; algorithm is based on a discrete Monte Carlo solution for cases where n is typically less than 20. The &quot;large&quot; algorithm is based on beta approximation model for the posterior distribution for the omega_E parameter. This approximation is reasonable when n &gt; 19. Regardless of <code class="reqn">n</code>, the user can stipulate <code>method</code>. When the <code>method</code> argument is omitted, the program selects the appropriate procedure</p>
</td></tr>
<tr><td><code id="dfba_mann_whitney_+3A_hide_progress">hide_progress</code></td>
<td>
<p>(Optional) If <code>TRUE</code>, hide percent progress while Monte Carlo sampling is running when <code>method = SMALL</code>. (default is <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mann-Whitney <em>U</em> test is the frequentist nonparametric counterpart
to the independent-groups <code class="reqn">t</code>-test. The sample <code>U_E</code> statistic is
the number of times that the <em>E</em> variate is larger than the
<em>C</em> variate, whereas <code>U_C</code> is the converse number.
</p>
<p>This test uses only rank information, so it is robust with respect to
outliers, and it does not depend on the assumption of a normal model for the
variates. The Bayesian version for the Mann-Whitney is focused on the
population parameter <code>omega_E</code>, which is the population ratio
<code>U_E/(U_E+U_C)</code>.
</p>
<p>While the frequentist test effectively assumes the sharp null hypothesis that
<code>omega_E</code> is .5, the Bayesian analysis has a prior and posterior
distribution for <code>omega_E</code> on the [0, 1] interval. The prior is a beta
distribution with shape parameters <code>a0</code> and <code>b0</code>. The default is
the flat prior (<code class="reqn">a0 = b0 =</code> 1), but this prior can be altered by the
user.
</p>
<p>The <code>prob_interval</code> input is the value for probability interval estimates for
omega_E. There are two cases depending on the sample size for the <em>E</em>
and <em>C</em> variates. When the samples sizes are small, there is a discrete
approximation method used. In this case, the Bayesian analysis considers 200
discrete values for <code>omega_E</code> from .0025 to .9975 in steps of .005. For
each discrete value, a prior and a posterior probability are obtained. The
posterior probabilities are based on Monte Carlo sampling to approximate the
likelihood of obtaining the observed <code>U_E</code> and <code>U_C</code> values for each candidate
value for omega_E. For each candidate value for omega_E, the likelihood for
the observed sample U statistics does not depend on the true distributions of
the <em>E</em> and <em>C</em> variates in the population. For each candidate
<code>omega_E</code>, the software constructs two exponential variates that have
the same omega_E value. The argument <code>samples</code> specifies the number of
Monte Carlo samples used for each candidate value of <code>omega_E</code>.
</p>
<p>For large sample sizes of the <em>E</em> and <em>C</em> variates,
the Bayesian posterior distribution is closely approximated by a beta
distribution where the shape parameters are a function of the sample
<code>U_E</code> and <code>U_C</code> statistics. The large-sample beta approximation was
developed from extensive previous empirical studies designed to approximate
the quantiles of the discrete approach with the corresponding quantiles for a
particular beta distribution. The large-<em>n</em> solution also uses Lagrange
polynomials for interpolation. The large-<em>n</em> approximation is reasonably
accurate when <code class="reqn">n &gt; 19</code> for each condition. When the <code>method</code> input
is omitted, the function selects the appropriate procedure (<em>i.e.</em>,
either the discrete case for a small sample size or the large-<em>n</em>
approach). Nonetheless, the user can stipulate which method they desire
regardless of sample size by inputting either <code>method="small"</code> or
<code>method="large"</code>. The large-<em>n</em> solution is rapid compared
to the small-sample solution, so care should be executed when choosing the
<code>method="small"</code>, even for large sample sizes.
</p>
<p>Technical details of the analysis are explained in the Chechile (2020)
Communications in Statistics paper cited below.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>Emean</code></td>
<td>
<p>Mean of the independent sample 1 (&quot;Experimental&quot;) data</p>
</td></tr>
<tr><td><code>Cmean</code></td>
<td>
<p>Mean of the independent sample 1 (&quot;Control&quot;) data</p>
</td></tr>
<tr><td><code>n_E</code></td>
<td>
<p>Number of observations of the independent sample 1 (&quot;Experimental&quot;) data</p>
</td></tr>
<tr><td><code>n_C</code></td>
<td>
<p>Mean of observations of the independent sample 2 (&quot;Control&quot;) data</p>
</td></tr>
<tr><td><code>U_E</code></td>
<td>
<p>Total number of comparisons for which observations from independent sample 1 (&quot;Experimental&quot;) data exceed observations from independent sample 2 (&quot;Control&quot;) data)</p>
</td></tr>
<tr><td><code>U_C</code></td>
<td>
<p>Total number of comparisons for which observations from independent sample 2 (&quot;Control&quot;) data exceed observations from independent sample 1 (&quot;Experimental&quot;) data)</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>User-defined width of <code>omega_E</code> interval estimate (default is 0.95)</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>First shape parameter for the prior beta distribution</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Second shape parameter for the prior beta distribution</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>The number of desired Monte Carlo samples (default is 30000)</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>A character string indicating the calculation method used</p>
</td></tr>
<tr><td><code>omega_E</code></td>
<td>
<p>A vector of values representing candidate values for <code>omega_E</code> when <code>method = "small"</code></p>
</td></tr>
<tr><td><code>omegapost</code></td>
<td>
<p>A vector of values representing discrete probabilities for candidate values of <code>omega_E</code></p>
</td></tr>
<tr><td><code>priorvector</code></td>
<td>
<p>A vector of values representing prior discrete probabilities of candidate values of <code>omega_E</code> when <code>method = "small"</code></p>
</td></tr>
<tr><td><code>priorprH1</code></td>
<td>
<p>Prior probability of the alternative model that omega_E exceeds 0.5</p>
</td></tr>
<tr><td><code>prH1</code></td>
<td>
<p>Posterior probability of the alternative model that omega_E exceeds 0.5</p>
</td></tr>
<tr><td><code>BF10</code></td>
<td>
<p>Bayes Factor describing the relative increase in the posterior odds for the alternative model that <code>omega_E</code> exceeds 0.5 over the null model of <code>omega_E</code> less than or equal to 0.5</p>
</td></tr>
<tr><td><code>omegabar</code></td>
<td>
<p>Posterior mean estimate for <code>omega_E</code></p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>Lower limit of the equal-tail probability interval for <code>omega_E</code> with probability width indicated by <code>prob_interval</code></p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>Upper limit of the equal-tail probability interval for <code>omega_E</code> with probability width indicated by <code>prob_interval</code></p>
</td></tr>
<tr><td><code>hdi_lower</code></td>
<td>
<p>Lower limit of the highest-density probability interval for <code>omega_E</code> with probability width indicated by <code>prob_interval</code> when <code>method = "small"</code></p>
</td></tr>
<tr><td><code>hdi_upper</code></td>
<td>
<p>Upper limit of the highest-density probability interval for <code>omega_E</code> with probability width indicated by <code>prob_interval</code> when <code>method = "small"</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R.A. (2020). Bayesian Statistics for Experimental
Scientists: A General Introduction Using Distribution-Free Methods.
Cambridge: MIT Press.
</p>
<p>Chechile, R.A. (2020). A Bayesian analysis for the Mann-Whitney
statistic. Communications in Statistics &ndash; Theory and Methods 49(3): 670-696.
https://doi.org/10.1080/03610926.2018.1549247.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: examples with method = "small" have long runtimes due to Monte Carlo
# sampling; please feel free to run them in the console.

# Examples with large n per group
# The data for each condition are presorted only for the user convenience if
# checking the U stats by hand

groupA &lt;- c(43, 45, 47, 50, 54, 58, 60, 63, 69, 84, 85, 91, 99, 127, 130,
            147, 165, 175, 193, 228, 252, 276)
groupB &lt;- c(0, 01, 02, 03, 05, 14, 15, 23, 23, 25, 27, 32, 57, 105, 115, 158,
            161, 181, 203, 290)

dfba_mann_whitney(E = groupA,
                  C = groupB)

# The following uses a Jeffreys prior instead of a default flat prior:
dfba_mann_whitney(E = groupA,
                  C = groupB,
                  a0 = .5,
                  b0 =.5)

# The following also uses a Jeffreys prior but the analysis reverses the
# variates:
dfba_mann_whitney(E = groupB,
                  C = groupA,
                  a0 = .5,
                  b0 = .5)

# Note that BF10 from the above analysis is 1/BF10 from the original order
# of the variates.

# The next analysis constructs 99% interval estimates with the Jeffreys
# prior.

AB &lt;- dfba_mann_whitney(E = groupA,
                        C = groupB,
                        a0 = .5,
                        b0 = .5,
                        prob_interval=.99)

AB

# Plot with prior and posterior curves
plot(AB)

# Plot with posterior curve only
plot(AB,
     plot.prior = FALSE)

# Example with small n per group

groupC &lt;- c(96.49, 96.78, 97.26, 98.85, 99.75, 100.14, 101.15, 101.39,
            102.58, 107.22, 107.70, 113.26)
groupD &lt;- c(101.16, 102.09, 103.14, 104.70, 105.27, 108.22, 108.32, 108.51,
            109.88, 110.32, 110.55, 113.42)


dfba_mann_whitney(E = groupC,
                  C = groupD,
                  samples = 250,
                  hide_progress = TRUE)



</code></pre>

<hr>
<h2 id='dfba_mcnemar'>Bayesian Repeated-Measures McNemar Test for Change</h2><span id='topic+dfba_mcnemar'></span>

<h3>Description</h3>

<p>Given a randomized-block or repeated-measures design where the response is
coded as either 0 or 1, examines the subset of cases where there
is a change in the response between the two measurements and provides a
Bayesian analysis of the population change rate phi_rb <code class="reqn">(\phi_{rb})</code> between
the two measurements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_mcnemar(n_01, n_10, a0 = 1, b0 = 1, prob_interval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_mcnemar_+3A_n_01">n_01</code></td>
<td>
<p>The number of cases where the first response is 0 and the second response is 1.</p>
</td></tr>
<tr><td><code id="dfba_mcnemar_+3A_n_10">n_10</code></td>
<td>
<p>The number of cases where the first response is 1 and the second response is 0.</p>
</td></tr>
<tr><td><code id="dfba_mcnemar_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for the <code>phi_rb</code> parameter. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_mcnemar_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the <code>phi_rb</code> parameter. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_mcnemar_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired probability for interval estimates for <code>phi_rb</code> (default is .95).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sometimes, researchers are interested in the detection of a change in the
response rate pre- and post-treatment. The frequentist McNemar test is a
nonparametric test that examines the subset of binary categorical responses
where the response changes between the two tests (Siegel &amp; Castellan, 1988).
The frequentist test assumes the null hypothesis that the change rate is
0.5. Chechile (2020) pointed out that the subset of change cases are binomial
data, so a Bayesian analysis can be done for the population
response-switching rate <code class="reqn">\phi_{rb}</code> (styled <code>phi_rb</code> elsewhere in
the documentation for this function). Both the prior and posterior
distribution for <code class="reqn">\phi_{rb}</code> are beta distributions.
</p>
<p>The user should be aware that the McNemar test is a change-detection
assessment of a binary response. To illustrate this fact, consider the
hypothetical case of a sample of 50 people who evaluate two political
candidates before and after a debate. Suppose 26 people prefer Candidate
A both before and after the debate and 14 people prefer Candidate B both
before and after the debate, but 9 people switch their preference from
Candidate A to Candidate B and 1 person switches their preference from
Candidate B to Candidate A. Despite the fact that this sample has 50
participants, it is only the 10 people who switch their preference that are
being analyzed with the McNemar test. Among this subset, there is evidence
that Candidate B did better on the debate. Overall, support for Candidate A
in the whole sample fell from 35 out of 50 (70%) to 27 out of 50 (54%):
still a majority, but a smaller one than Candidate A enjoyed prior to the
debate.
</p>
<p>The <code>dfba_mcnemar()</code> function requires two inputs, <code>n_01</code> and
<code>n_10</code>, which are, respectively, the number of <code class="reqn">0 \to 1</code> changes
and the number of <code class="reqn">1 \to 0</code> switches in the binary responses between the
two tests. Since the cases where there is a switch are binomial trials,
the prior and posterior distributions for <code class="reqn">\phi_{rb}</code> are beta distributions.
The prior distribution shape parameters are <code>a0</code> and <code>b0</code>. The
default prior is a uniform distribution (<em>i.e.</em>, <code>a0 = b0 = 1</code>).
The <code>prob_interval</code> argument stipulates the probability within the
equal-tail interval limits for <code class="reqn">\phi_{rb}</code>. The default value for that
argument is <code>prob_interval =.95</code>.
</p>
<p>Besides computing the posterior mean, posterior median, equal-tail interval
limits, and the posterior probability that <code class="reqn">\phi_{rb} &gt; .5</code>, the function
also computes two Bayes factor values. One is the <em>point</em> Bayes factor <code>BF10</code>
against the null hypothesis that <code>phi_rb = 0.5</code>. The second Bayes
factor <code>BF10</code> is the <em>interval</em> Bayes factor against the null hypothesis
that <code class="reqn">\phi_{rb} \le 0.5</code>. If the interval Bayes factor BF10 is very low,
then there is support to some degree for the null hypothesis that
<code class="reqn">\phi_{rb} &lt; 0.5</code>. In this case the Bayes factor <code>BF01</code> in support of
the interval null hypothesis is given by <code>BF01 = 1/BF10</code>.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>n_01</code></td>
<td>
<p>The number of cases where the first response is 0 and the second response is 1</p>
</td></tr>
<tr><td><code>n_10</code></td>
<td>
<p>The number of cases where the first response is 1 and the second response is 0</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>Desired posterior probability within the equal-tail interval limits for <code>phi_rb</code></p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for the <code>phi_rb</code> parameter</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the <code>phi_rb</code> parameter</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution for the <code>phi_rb</code> parameter</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution for the <code>phi_rb</code> parameter</p>
</td></tr>
<tr><td><code>post_mean</code></td>
<td>
<p>Posterior mean for <code>phi_rb</code></p>
</td></tr>
<tr><td><code>post_median</code></td>
<td>
<p>Posterior median for <code>phi_rb</code></p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>Lower limit for the posterior equal-tail interval estimate for <code>phi_rb</code> that contains the probability defined in <code>prob_interval</code></p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>Upper limit for the posterior equal-tail interval estimate for phi_rb that contains the probability defined in <code>prob_interval</code></p>
</td></tr>
<tr><td><code>BF10point</code></td>
<td>
<p>The Bayes factor against the point null hypothesis that <code>phi_rb = .5</code></p>
</td></tr>
<tr><td><code>BF10interval</code></td>
<td>
<p>The Bayes factor against the interval null hypothesis that <code>phi_rb</code> is less than or equal to <code>.5</code></p>
</td></tr>
<tr><td><code>postH1</code></td>
<td>
<p>The posterior probability that <code>phi_rb &gt; .5</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R.A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Methods. Cambridge: MIT Press.
</p>
<p>Siegel, S., &amp; Castellan, N. J. (1988) Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw Hill.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfba_beta_bayes_factor">dfba_beta_bayes_factor</a></code> for further documentation about the
Bayes factor and its interpretation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examples with default value for a0, b0 and prob_interval

dfba_mcnemar(n_01 = 17,
             n_10 = 2)

## Using the Jeffreys prior and .99 equal-tail interval

dfba_mcnemar(n_01 = 17,
             n_10 = 2,
             a0 = .5,
             b0 = .5,
             prob_interval = .99)

</code></pre>

<hr>
<h2 id='dfba_median_test'>Bayesian Median Test</h2><span id='topic+dfba_median_test'></span>

<h3>Description</h3>

<p>Given two independent groups of continuous variables, performs a Bayesian
analysis of the likelihood of observing an above-median value from one of
the groups relative to expectation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_median_test(E, C, a0 = 1, b0 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_median_test_+3A_e">E</code></td>
<td>
<p>Numeric vector of values for the continuous measurements for group 1 (generically denoted <code>E</code> for <em>Experimental</em> group).</p>
</td></tr>
<tr><td><code id="dfba_median_test_+3A_c">C</code></td>
<td>
<p>Numeric vector of values for the continuous measurements for group 2 (generically denoted <code>C</code> for <em>Control</em> group).</p>
</td></tr>
<tr><td><code id="dfba_median_test_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for the binomial parameter <code>phi</code> (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_median_test_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the binomial parameter <code>phi</code> (default is 1). Must be positive and finite.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given continuous measurements <code class="reqn">E</code> and <code class="reqn">C</code> from two separate and
independent groups, a combined sample median value can be computed. For the
frequentist median test, a 2x2 table is created. Row 1 consists of the
frequencies of the above-median responses in terms of the two groups (<em>i.e.</em>,
<code>nEabove</code> and <code>nCabove</code>). Row 2 has the respective frequencies for the
values that are at or below the combined median (<em>i.e.</em>, <code>nEbelow</code> and
<code>nCbelow</code>). See Siegel &amp; Castellan (1988) for the details concerning the
frequentist median test.
</p>
<p>Chechile (2020) provided an alternative Bayesian analysis for the median-test
procedure of examining continuous data in terms of the categorization of the
values as being either above the combined median or not. The frequencies in
row 1 (above median response) are binomial frequencies in terms of the group
origin (<em>i.e.</em>, <code class="reqn">E</code> versus <code class="reqn">C</code>). From a Bayesian perspective, a
population-level <code class="reqn">\phi</code> parameter can be defined for the population
proportion of <code class="reqn">E</code> values that are above the combined sample median.
Similarly, the frequencies for the scores at or below the combined sample
median can also be examined; in that case, the corresponding population
proportion in the E condition must be <code class="reqn">1-\phi</code>. Thus, it is sufficient only
to examine the above-median frequencies to make an inference about the <code class="reqn">\phi</code>
parameter. Since this is a binomial problem, the prior and posterior
distributions for the population <code class="reqn">\phi</code> parameter belong to the beta family
of distributions. The default prior for this function is the uniform
distribution, <em>i.e</em>, <code>a0 = b0 = 1</code>. The posterior shape parameters
for <code class="reqn">\phi</code> are <code>a_post = a0 + nEabove</code> and
<code>b_post = b0 + nCabove</code>.
</p>
<p>Because the number of scores in groups <code class="reqn">E</code> and <code class="reqn">C</code> might be very
different, it is important to examine the <code class="reqn">\phi</code> parameter relative to an
expected base-rate value from the sample. For example, suppose that there are
<code>nE = 90</code> values from the <code class="reqn">E</code> group and <code>nC = 10</code> values from
the <code class="reqn">C</code> group. In this example, there are 50 scores that are above the
combined median (and no ties that would result in fewer than half of the
scores being greater than the median) that should be examined to see if <code class="reqn">\phi</code>
is greater than 0.9. If there were no difference between the <code class="reqn">E</code> and <code class="reqn">C</code>
conditions whatsoever in this hypothetical example, then about 90 percent of
the above-median values would be from the <code class="reqn">E</code> group. If the posterior
<code class="reqn">\phi</code> parameter were substantially above the group <code class="reqn">E</code> base rate,
then that would support the hypothesis that group <code class="reqn">E</code> has larger values
than group <code class="reqn">C</code> in the population.
</p>
<p>The <code>dfba_median_test()</code> provides the descriptive sample information for
the combined median as well as the entries for a table for the frequencies
for the <code class="reqn">E</code> and <code class="reqn">C</code> scores that are above the median, as well as the
frequencies for the <code class="reqn">E</code> and <code class="reqn">C</code> scores at or below the median. The
function also provides the prior and posterior probabilities that the <code class="reqn">E</code>
and <code class="reqn">C</code> groups exceeding their respective base rates for a value being
above the median. The function also evaluates the hypotheses that the <code class="reqn">E</code>
and <code class="reqn">C</code> response rates for the above-median responses exceeding their
base rate. Bayes factors are provided for these hypothesis.
</p>
<p>Because the Bayesian median test ignores the available rank-order
information, this procedure has less power than the Bayesian Mann-Whitney
analysis that can be computed for the same data. Nonetheless, sometimes
researchers are interested if condition differences are so strong that even a
lower power median test can detect the difference.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>median</code></td>
<td>
<p>The sample combined median for the <code>E</code> and <code>C</code> values</p>
</td></tr>
<tr><td><code>nE</code></td>
<td>
<p>The number of scores from group <code>E</code></p>
</td></tr>
<tr><td><code>nC</code></td>
<td>
<p>The number of scores from group <code>C</code></p>
</td></tr>
<tr><td><code>Ebaserate</code></td>
<td>
<p>The proportion nE/(nE+nC)</p>
</td></tr>
<tr><td><code>Cbaserate</code></td>
<td>
<p>The proportion nC/(nE+nC)</p>
</td></tr>
<tr><td><code>nEabove</code></td>
<td>
<p>Number of <code>E</code> responses above the median</p>
</td></tr>
<tr><td><code>nCabove</code></td>
<td>
<p>Number of <code>C</code> responses above the median</p>
</td></tr>
<tr><td><code>nEbelow</code></td>
<td>
<p>Number of <code>E</code> responses at or below median</p>
</td></tr>
<tr><td><code>nCbelow</code></td>
<td>
<p>Number of <code>C</code> response at or below median</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for the population binomial parameter</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the population binomial parameter</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>Posterior first shape parameter for the beta distribution for the probability that an above-median response is from the <code>E</code> group</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Posterior second shape parameter for the beta distribution for the probability that an above-median response is from the <code>E</code> group</p>
</td></tr>
<tr><td><code>postEhi</code></td>
<td>
<p>Posterior probability that an above-median response exceeds the <code>E</code> group base rate</p>
</td></tr>
<tr><td><code>postChi</code></td>
<td>
<p>Posterior probabilty that an above-median response exceeds the <code>C</code> group base rate</p>
</td></tr>
<tr><td><code>priorEhi</code></td>
<td>
<p>The probability that a beta prior distribution would exceed the <code>E</code> group base rate</p>
</td></tr>
<tr><td><code>priorChi</code></td>
<td>
<p>The probability that a beta prior distribution would exceed the <code>C</code> group base rate</p>
</td></tr>
<tr><td><code>BF10E</code></td>
<td>
<p>The Bayes factor in favor of the hypothesis that an above-median response from the <code>E</code> group is more probable than the <code>E</code> expected base rate</p>
</td></tr>
<tr><td><code>BF10C</code></td>
<td>
<p>The Bayes factor in favor of the hypothesis that an above-median response from the <code>C</code> group is more probable than the <code>C</code> group base rate</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R.A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Methods. Cambridge: MIT Press.
</p>
<p>Siegel, S., &amp; Castellan, N. J. (1988) Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw Hill.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfba_beta_bayes_factor">dfba_beta_bayes_factor</a></code> for further documentation about the
Bayes factor and its interpretation.
</p>
<p><code><a href="#topic+dfba_mann_whitney">dfba_mann_whitney</a></code> for a more powerful alternative Bayesian
analysis of the <code class="reqn">E</code> and <code class="reqn">C</code> values that use rank order information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example with the default uniform prior
group1 &lt;- c(12.90, 10.84, 22.67, 10.64, 10.67, 10.79, 13.55, 10.95, 12.19,
            12.76, 10.89, 11.02, 14.27, 13.98, 11.52, 13.49, 11.22, 15.07,
            15.74, 19.00)

group2 &lt;- c(4.63, 58.64, 5.07, 4.66, 4.13, 3.92, 3.39, 3.57, 3.56, 3.39)

dfba_median_test(E = group1,
                 C = group2)

## Example with the Jeffreys prior
dfba_median_test(group1,
                 group2,
                 a0 = .5,
                 b0 = .5)

</code></pre>

<hr>
<h2 id='dfba_power_curve'>Power Curves</h2><span id='topic+dfba_power_curve'></span>

<h3>Description</h3>

<p>This function is a design tool for comparing Bayesian distribution-free power
with frequentist <em>t</em> power for a range of delta values, which are the
separation values between two continuous variates that can be randomly sampled
from one of nine different probability models. The function provides a table
of power values for a fixed sample size value of <em>n</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_power_curve(
  n = 20,
  a0 = 1,
  b0 = 1,
  delta_step = 0.05,
  model,
  design,
  effect_crit = 0.95,
  shape1 = 1,
  shape2 = 1,
  block_max = 0,
  samples = 1000,
  hide_progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_power_curve_+3A_n">n</code></td>
<td>
<p>The sample size for both variates (default is 20)</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_delta_step">delta_step</code></td>
<td>
<p>The increment between successive delta values, which range from 0 to <code>20*delta_step</code> (default value is .05)</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_model">model</code></td>
<td>
<p>Theoretical probability model for the data. One of <code>"normal"</code>, <code>"weibull"</code>, <code>"cauchy"</code>, <code>"lognormal"</code>, <code>"chisquare"</code>, <code>"logistic"</code>, <code>"exponential"</code>, <code>"gumbel"</code>, or <code>"pareto"</code>.</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_design">design</code></td>
<td>
<p>Indicates the data structure. One of <code>"independent"</code> or <code>"paired"</code>.</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_effect_crit">effect_crit</code></td>
<td>
<p>Stipulated  value for a significant differences for a <em>t</em>-test (1 - <em>p</em>), and the critical probability for the Bayesian alternative hypothesis for a Bayesian distribution-free analysis</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_shape1">shape1</code></td>
<td>
<p>The shape parameter for the condition 1 variate for the distribution indicated by the <code>model</code> input (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_shape2">shape2</code></td>
<td>
<p>The shape parameter for the condition 2 variate for the distribution indicated by the <code>model</code> input (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_block_max">block_max</code></td>
<td>
<p>The maximum size for a block effect (default is 0)</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_samples">samples</code></td>
<td>
<p>Desired number of Monte Carlo data sets drawn to estimate the power (default is 1000)</p>
</td></tr>
<tr><td><code id="dfba_power_curve_+3A_hide_progress">hide_progress</code></td>
<td>
<p>(Optional) If <code>TRUE</code>, hide percent progress while Monte Carlo sampling is running. (default is <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Researchers need to make experimental-design decisions such as the choice
about the sample size per condition and the decision of whether to use a
within-block design or an independent-group design. These planning issues
arise regardless if one uses either a frequentist or Bayesian approach to
statistical inference. In the DFBA package there are a number of functions to
help users with these decisions. The <code>dfba_power_curve()</code> function
produces the Bayesian power estimate from a distribution-free analysis along
with the corresponding frequentist power from a parametric <em>t</em>-test, for
21 delta values, which range from 0 to <code>20*delta_step</code> where delta is the
separation between two random variates. The sample size for the power
estimates is the same value <code>n</code> in each condition. The power estimates
are based on a number of Monte Carlo sampled data sets generated by the
<code>dfba_sim_data()</code> function.
</p>
<p>For each data set, statistical tests are performed. If <code>design = "paired"</code>,
the frequentist <em>t</em>-test is a one-tailed test on the within-block
difference scores to assess the null hypothesis that the population mean for
<code>E</code> is greater than the population mean for <code>C</code>; if
<code>design = "independent"</code>, the frequentist <em>t</em>-test is the one-tailed
test to assess if there is a significant difference between the two
independent conditions (<em>i.e.</em> if the mean for condition 2 is signficantly
greater than the condition 1 mean). If <code>design = "paired"</code>, the Bayesian
analysis assesses if the posterior probability for <code>phi_w &gt; .5</code> on the
Bayesian Wilcoxon test is greater than <code>effect_crit</code>; if
<code>design = "independent"</code>, the Bayesian analysis assesses if the posterior
probability for <code>omega_E &gt; .5</code> on a Bayesian Mann-Whitney test is greater
than <code>effect_crit</code>. The frequentist power is estimated by the proportion
of the data sets where a parametric <em>t</em>-test detects a significant effect
because the  upper-tail <em>t</em> value has a <em>p</em>-value less than
<code>1-effect_crit</code>. The Bayesian power is the proportion of the data sets
where a posterior probability for the alternative hypothesis is greater than
<code>effect_crit</code>. The default value for the <code>effect_crit</code> argument is
.95. The frequentist <em>p</em>-value and the Bayesian posterior probability for
the alternative hypothesis are calculated using the <code>dfba_sim_data()</code>
function.
</p>
<p>The arguments for the <code>dfba_power_curve()</code> function are passed into the
<code>dfba_sim_data()</code> function. Besides the sample size <code>n</code>, there
are eight other arguments that are required by the <code>dfba_power_curve()</code>
function, which are passed into the <code>dfba_sim_data()</code> function:
</p>

<ul>
<li> <p><code>a0</code>
</p>
</li>
<li> <p><code>b0</code>
</p>
</li>
<li> <p><code>model</code>
</p>
</li>
<li> <p><code>design</code>
</p>
</li>
<li> <p><code>delta</code>
</p>
</li>
<li> <p><code>shape1</code>
</p>
</li>
<li> <p><code>shape2</code>
</p>
</li>
<li> <p><code>block_max</code>.
</p>
</li></ul>

<p>The <code>a0</code> and <code>b0</code> values are the respective first and second beta
shape parameters for the prior distribution needed for the Bayesian
distribution-free tests, which are ultimately done by calling either the
<code>dfba_wilcoxon()</code> function or by the <code>dfba_mann_whitney()</code>.
</p>
<p>The <code>model</code> argument is one of the following strings:
</p>

<ul>
<li> <p><code>"normal"</code>
</p>
</li>
<li> <p><code>"weibull"</code>
</p>
</li>
<li> <p><code>"cauchy"</code>
</p>
</li>
<li> <p><code>"lognormal"</code>
</p>
</li>
<li> <p><code>"chisquare"</code>
</p>
</li>
<li> <p><code>"logistic"</code>
</p>
</li>
<li> <p><code>"exponential"</code>
</p>
</li>
<li> <p><code>"gumbel"</code>
</p>
</li>
<li> <p><code>"pareto"</code>
</p>
</li></ul>

<p>The <code>design</code> argument is either <code>"independent"</code> or <code>"paired"</code>,
and stipulates whether the two sets of scores are either independent or from
a common block such as for the case of two scores for the same person (<em>i.e.</em>,
one in each condition).
</p>
<p>The <code>shape1</code> and <code>shape2</code> arguments are values for the shape parameter
for the respective first and second condition, and their meaning
depends on the probability model. For <code>model="normal"</code>, these
parameters are the standard deviations of the two distributions. For
<code>model = "weibull"</code>, the parameters are the Weibull shape parameters.
For <code>model = "cauchy"</code>, the parameters are the scale factors for the
Cauchy distributions. For <code>model = "lognormal"</code>, the shape
parameters are the standard deviations for log(X). For <code>model = "chisquare"</code>,
the parameters are the degrees of freedom (<em>df</em>) for the two
distributions. For <code>model = "logistic"</code>, the parameters are the scale
factors for the distributions. For <code>model = "exponential"</code>, the parameters
are the rate parameters for the distributions.
</p>
<p>For the Gumbel distribution, the <code>E</code> variate is equal to
<code>delta - shape2*log(log(1/U))</code> where <code>U</code> is a random value sampled
from the uniform distribution on the interval <code>[.00001, .99999]</code>, and
the <code>C</code> variate is equal to <code>-shape1*log(log(1/U))</code> where <code>U</code>
is another score sampled from the uniform distribution. The <code>shape1</code> and
<code>shape2</code> arguments for <code>model = "gumbel"</code> are the scale parameters
for the distributions. The Pareto model is a distribution designed to account
for income distributions as studied by economists (Pareto, 1897). For the
Pareto distribution, the cumulative function is equal to <code>1-(x_m/x)^alpha</code>
where <code>x</code> is greater than <code>x_m</code> (Arnold, 1983). In the <code>E</code>
condition, <code>x_m = 1 + delta</code> and in the <code>C</code> condition <code>x_m = 1</code>.
The alpha parameter is 1.16 times the shape parameters <code>shape1</code> and
<code>shape2</code>. Since the default value for each shape parameter is 1, the
resulting alpha value of 1.16 is the default value. When alpha = 1.16, the
Pareto distribution approximates an income distribution that represents the
80-20 law where 20% of the population receives 80% of the income
(Hardy, 2010).
</p>
<p>The <code>block_max</code> argument provides for incorporating block effects in the
random sampling. The block effect for each score is a separate effect for the
block. The block effect B for a score is a random number drawn from a uniform
distribution on the interval <code>[0, block_max]</code>. When <code>design = "paired"</code>,
the same random block effect is added to the score in the first condition,
which is the random <code>C</code> value, and it is also added to the corresponding
paired value for the <code>E</code> variate. Thus, the pairing research design
eliminates the effect of block variation for the assessment of condition
differences. When <code>design = "independent"</code>, there are different block-effect
contributions to the <code>E</code> and <code>C</code> variates, which reduces the
discrimination of condition differences because it increases the variability
of the difference in the two variates. The user can study the effect of the
relative discriminability of detecting an effect of delta by adjusting the
value of the <code>block_max</code> argument. The default for <code>block_max</code> is 0,
but it can be altered to any non-negative real number.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>The fixed sample size for each variate</p>
</td></tr>
<tr><td><code>nsims</code></td>
<td>
<p>The number of Monte Carlo data sets; equal to the value of the <code>samples</code> argument</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Probability model for the data</p>
</td></tr>
<tr><td><code>design</code></td>
<td>
<p>The design for the data; one of <code>"independent"</code> or <code>"paired"</code></p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the beta prior distribution for the Bayesian analysis</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the beta prior distribution for the Bayesian analysis</p>
</td></tr>
<tr><td><code>effect_crit</code></td>
<td>
<p>The criterion probability for considering a posterior probability for the alternative hypothesis to be a detection; it is also <code>1-p_crit</code> for a frequentist <em>t</em>-test</p>
</td></tr>
<tr><td><code>block_max</code></td>
<td>
<p>The maximum size of a block effect; equal to the <code>block_max</code> argument</p>
</td></tr>
<tr><td><code>delta_vec</code></td>
<td>
<p>Vector of the 21 delta offset values</p>
</td></tr>
<tr><td><code>Bayes_power</code></td>
<td>
<p>The vector of 21 Bayesian power values</p>
</td></tr>
<tr><td><code>t_power</code></td>
<td>
<p>The vector of 21 frequentist power from <em>t</em>-tests</p>
</td></tr>
<tr><td><code>outputdf</code></td>
<td>
<p>A dataframe for the Bayesian power and the corresponding frequentist <em>t</em> power as a function of delta</p>
</td></tr>
</table>


<h3>References</h3>

<p>Arnold, B. C. (1983). Pareto Distribution. Fairland, MD:
International Cooperative Publishing House.
</p>
<p>Chechile, R. A. (2017). A Bayesian analysis for the Wilcoxon signed-rank
statistic. Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2017.1388402
</p>
<p>Chechile, R. A. (2020). A Bayesian analysis for the Mann-Whitney statistic.
Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2018.1549247
</p>
<p>Fishman, G. S. (1996) Monte Carlo: Concepts, Algorithms and Applications.
New York: Springer.
</p>
<p>Hardy, M. (2010). Pareto's Law. Mathematical Intelligencer,
32, 38-43.
</p>
<p>Johnson, N. L., Kotz S., and Balakrishnan, N. (1995). Continuous Univariate
Distributions, Vol. 1, New York: Wiley.
</p>
<p>Pareto, V. (1897). Cours d'Economie Politique. Vol. 2,
Lausanne: F. Rouge.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for details on the
parameters of the normal, Weibull, Cauchy, lognormal, chi-squared, logistic,
and exponential distributions.
</p>
<p><code><a href="#topic+dfba_wilcoxon">dfba_wilcoxon</a></code>
</p>
<p><code><a href="#topic+dfba_mann_whitney">dfba_mann_whitney</a></code>
</p>
<p><code><a href="#topic+dfba_sim_data">dfba_sim_data</a></code>  for further details about the data for two
conditions that differ in terms of their theoretical mean by an amount delta.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note: these examples have long runtimes due to Monte Carlo sampling;
# please feel free to run them in the console.


dfba_power_curve(n = 85,
                 model = "normal",
                 design = "independent",
                 samples = 250,
                 hide_progress = TRUE)


dfba_power_curve(n = 85,
                 model = "normal",
                 design = "paired",
                 samples = 250,
                 hide_progress = TRUE)

# Using the Jeffreys prior rather than default flat prior

dfba_power_curve(n = 30,
                 model = "lognormal",
                 design = "independent",
                 a0 = .5,
                 b0 = .5,
                 delta_step = .06,
                 block_max = 3,
                 samples = 250,
                 hide_progress = TRUE)


</code></pre>

<hr>
<h2 id='dfba_sign_test'>Bayesian Sign Test</h2><span id='topic+dfba_sign_test'></span>

<h3>Description</h3>

<p>Given two paired continuous variates <code>Y1</code> and <code>Y2</code>, provides a
Bayesian sign test to assess the positivity rate for the difference
<code>Y1 - Y2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_sign_test(Y1, Y2, a0 = 1, b0 = 1, prob_interval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_sign_test_+3A_y1">Y1</code></td>
<td>
<p>Vector of the continuous measurements for one group</p>
</td></tr>
<tr><td><code id="dfba_sign_test_+3A_y2">Y2</code></td>
<td>
<p>Vector of the continuous values paired with the <code>Y1</code> vector for the values in a second group</p>
</td></tr>
<tr><td><code id="dfba_sign_test_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for the positive-sign rate parameter (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_sign_test_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the positive-sign rate parameter (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_sign_test_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired probability within interval limits for interval estimates of the positivity rate parameter (default is .95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given two paired continuous variates <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> for two
repeated measures, statistical tests for differences examine the difference
measure <code class="reqn">d = Y_1 - Y_2</code>. The <code class="reqn">t</code>-test is a conventional frequentist
parametric procedure to assess values of <code class="reqn">d</code>. There are also two common
frequentist nonparametric tests for assessing condition differences: the sign
test and the Wilcoxon signed-rank test. The sign test is less powerful than
the Wilcoxon signed-rank test (Siegel &amp; Castellan, 1988). The appeal of the
sign test, for some researchers, is that it is simple and - in some cases -
sufficient for demonstrating strong differences.
</p>
<p>The <code>dfba_sign_test()</code> function provides a Bayesian version of the sign
test (the function <code>dfba_wilcoxon()</code> provides the Bayesian signed-rank
test). While the Wilcoxon procedure uses both rank and sign information, the
sign test uses only sign information. The <code>dfba_sign_test()</code> function
finds the number of positive and negative <code class="reqn">d</code> values, which appear in the
output as <code>n_pos</code> and <code>n_neg</code>, respectively. Note that it is
standard both in the frequentist sign test and in the frequentist Wilcoxon
signed-rank procedure to remove the <code class="reqn">d</code> values that are zero. Consequently,
the signs for the nonzero <code class="reqn">d</code> values are binary, so the posterior is a
beta distribution with shape parameters <code class="reqn">a</code> - denoted in the output as
<code>a_post</code> and <code class="reqn">b</code> - denoted in the output as <code>b_post</code> - where
<code>a_post = a0 + n_pos</code> and <code>b_post = b0 + n_neg</code> and <code>a0</code> and <code>b0</code>
are the respective first and second beta shape parameters for the prior
distribution. The default prior is a uniform distribution <code>a0 = b0 = 1</code>.
</p>
<p>The function estimates the population rate for positive signs by calling
<code>dfba_beta_descriptive()</code> using the computed <code>a_post</code> and <code>b_post</code>
as arguments. Since interest in the sign test is focused on the null
hypothesis that the positivity rate is less than or equal to .5,
<code>dfba_sign_test()</code> calls <code>dfba_beta_bayes_factor()</code> to calculate the
prior and posterior probabilities for the alternative hypothesis that the
positivity rate is greater than .5. The output also includes the Bayes
factors <code>BF10</code> and <code>BF01</code>, where <code>BF01 = 1/BF10</code>. Large values
of <code>BF01</code> indicate support for the null hypothesis; large values of <code>BF10</code>
indicate support for the alternative hypothesis.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>Y1</code></td>
<td>
<p>Vector of continuous values for the first within-block group</p>
</td></tr>
<tr><td><code>Y2</code></td>
<td>
<p>Vector of continuous values for the second within-block group</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>First shape parameter for the prior beta distribution for the population parameter for the positivity rate</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Second shape parameter for the prior beta distribution for the population positivity rate</p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>The probability within the interval limits for the interval estimate of population positivity rate</p>
</td></tr>
<tr><td><code>n_pos</code></td>
<td>
<p>Sample number of positive differences</p>
</td></tr>
<tr><td><code>n_neg</code></td>
<td>
<p>Sample number of negative differences</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution for the population  positivity rate</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution for the population positivity rate for differences</p>
</td></tr>
<tr><td><code>phimean</code></td>
<td>
<p>Mean of the posterior distribution for the positivity rate parameter</p>
</td></tr>
<tr><td><code>phimedian</code></td>
<td>
<p>Median of the posterior distribution for the positivity rate parameter</p>
</td></tr>
<tr><td><code>phimode</code></td>
<td>
<p>Mode of the posterior distribution for the positivity rate parameter</p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>Lower limit of the equal-tail interval  estimate of the positivity rate parameter</p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>Upper limt of the equal-tail interval estimate of the positivity rate parameter</p>
</td></tr>
<tr><td><code>hdi_lower</code></td>
<td>
<p>Lower limit for the highest-density interval estimate of the positivity rate parameter</p>
</td></tr>
<tr><td><code>hdi_upper</code></td>
<td>
<p>Upper limit for the highest-density interval estimate of the positivity rate parameter</p>
</td></tr>
<tr><td><code>post_H1</code></td>
<td>
<p>Posterior probability that the positivity rate is greater than .5</p>
</td></tr>
<tr><td><code>prior_H1</code></td>
<td>
<p>Prior probability that the positivity rate is greater than .5</p>
</td></tr>
<tr><td><code>BF10</code></td>
<td>
<p>Bayes factor in favor of the alternative hypothesis that the positivity rate is greater than .5</p>
</td></tr>
<tr><td><code>BF01</code></td>
<td>
<p>Bayes factor in favor of the null hypothesis that the positivity rate is equal to or less than .5</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R. A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution_Free Methods. Cambridge, MIT Press.
</p>
<p>Siegel, S., &amp; Castellan, N. J. (1988). Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw Hill.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfba_beta_descriptive">dfba_beta_descriptive</a></code> for details on the descriptive statistics
in the output
</p>
<p><code><a href="#topic+dfba_beta_bayes_factor">dfba_beta_bayes_factor</a></code> for details on Bayes Factors calculated
on the basis of beta distributions
</p>
<p><code><a href="#topic+dfba_wilcoxon">dfba_wilcoxon</a></code> for an alternative, more powerful Bayesian
nonparametric test for evaluting repeated-measures data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
measure_1 &lt;- c(1.49, 0.64, 0.96, 2.34, 0.78, 1.29, 0.72, 1.52,
               0.62, 1.67, 1.19, 0.860)

measure_2 &lt;- c(0.53, 0.55, 0.58, 0.97, 0.60, 0.22, 0.05, 13.14,
               0.63, 0.33, 0.91, 0.37)

dfba_sign_test(Y1 = measure_1,
               Y2 = measure_2)

dfba_sign_test(measure_1,
               measure_2,
               a0 = .5,
               b0 = .5,
               prob_interval = .99)

</code></pre>

<hr>
<h2 id='dfba_sim_data'>Simulated Data Generator and Inferential Comparison</h2><span id='topic+dfba_sim_data'></span>

<h3>Description</h3>

<p>This function is designed to be called by other DFBA programs that compare
frequentist and Bayesian power. The function generates simulated data for two
conditions that can be from nine different probability models.
The program also computes the frequentist <em>p</em>-value from a <em>t</em>-test
on the generated data, and it computes the Bayesian posterior probability
from a distribution-free analysis of the difference between the two
conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_sim_data(
  n = 20,
  a0 = 1,
  b0 = 1,
  model,
  design,
  delta,
  shape1 = 1,
  shape2 = 1,
  block_max = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_sim_data_+3A_n">n</code></td>
<td>
<p>Number of values per condition</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution (default is 1). Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_model">model</code></td>
<td>
<p>Theoretical probability model for the data. One of <code>"normal"</code>, <code>"weibull"</code>, <code>"cauchy"</code>, <code>"lognormal"</code>, <code>"chisquare"</code>, <code>"logistic"</code>, <code>"exponential"</code>, <code>"gumbel"</code>, or <code>"pareto"</code></p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_design">design</code></td>
<td>
<p>Indicates the data structure. One of <code>"independent"</code> or <code>"paired"</code>.</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_delta">delta</code></td>
<td>
<p>Theoretical mean difference between conditions; the second condition minus the first condition</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_shape1">shape1</code></td>
<td>
<p>The shape parameter for condition 1 for the distribution indicated by <code>model</code> input (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_shape2">shape2</code></td>
<td>
<p>The shape parameter for condition 2 for the distribution indicated by <code>model</code> input (default is 1)</p>
</td></tr>
<tr><td><code id="dfba_sim_data_+3A_block_max">block_max</code></td>
<td>
<p>The maximum size for a block effect (default is 0)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Researchers need to make experimental-design decisions such as
the choice about the sample size per condition and the decision
to use a within-block design or an independent-group design. These
planning issues arise regardless if one uses either a frequentist
or Bayesian approach to statistical inference. In the DFBA package,
there are a number of functions to help users with these decisions.
</p>
<p>The <code>dfba_sim_data()</code> program is used along with other functions to
assess the relative power for detecting a condition difference of an
amount delta between two conditions. Delta is an input for the
<code>dfba_sim_data()</code> program, and it must be a nonnegative value.
Specifically, the <code>dfba_sim_data()</code> program generates two sets of data
that are randomly drawn from one of nine different theoretical
models. The input &lsquo;model&rsquo; stipulates the data generating probability
function. The input &lsquo;model&rsquo; is one of the following strings:
</p>

<ul>
<li> <p><code>"normal"</code>
</p>
</li>
<li> <p><code>"weibull"</code>
</p>
</li>
<li> <p><code>"cauchy"</code>
</p>
</li>
<li> <p><code>"lognormal"</code>
</p>
</li>
<li> <p><code>"chisquare"</code>
</p>
</li>
<li> <p><code>"logistic"</code>
</p>
</li>
<li> <p><code>"exponential"</code>
</p>
</li>
<li> <p><code>"gumbel"</code>
</p>
</li>
<li> <p><code>"pareto"</code>
</p>
</li></ul>

<p>For each model there are <code>n</code> continuous scores randomly sampled for each
condition, where <code>n</code> is a  user-specified input value. The <code>design</code>
argument is either <code>"independent"</code> or <code>"paired"</code>, and stipulates
whether the two sets of scores are either independent or from a common blocks
such as for the case of two scores for the same person (<em>i.e.</em>, one in
each condition).
</p>
<p>The <code>shape1</code> and <code>shape2</code> arguments are values for the shape parameter
for the respective first and second condition, and their meaning
depends on the probability model. For <code>model="normal"</code>, these
parameters are the standard deviations of the two distributions. For
<code>model = "weibull"</code>, the parameters are the Weibull shape parameters.
For <code>model = "cauchy"</code>, the parameters are the scale factors for the
Cauchy distributions. For <code>model = "lognormal"</code>, the shape
parameters are the standard deviations for log(X). For <code>model = "chisquare"</code>,
the parameters are the degrees of freedom (<em>df</em>) for the two
distributions. For <code>model = "logistic"</code>, the parameters are the scale
factors for the distributions. For <code>model = "exponential"</code>, the parameters
are the rate parameters for the distributions.
</p>
<p>For the Gumbel distribution, the <code>E</code> variate is equal to
<code>delta - shape2*log(log(1/U))</code> where <code>U</code> is a random value sampled
from the uniform distribution on the interval <code>[.00001, .99999]</code>, and
the <code>C</code> variate is equal to <code>-shape1*log(log(1/U))</code> where <code>U</code>
is another score sampled from the uniform distribution. The <code>shape1</code> and
<code>shape2</code> arguments for <code>model = "gumbel"</code> are the scale parameters
for the distributions. The Pareto model is a distribution designed to account
for income distributions as studied by economists (Pareto, 1897). For the
Pareto distribution, the cumulative function is equal to <code>1-(x_m/x)^alpha</code>
where <code>x</code> is greater than <code>x_m</code> (Arnold, 1983). In the <code>E</code>
condition, <code>x_m = 1 + delta</code> and in the <code>C</code> condition <code>x_m = 1</code>.
The alpha parameter is 1.16 times the shape parameters <code>shape1</code> and
<code>shape2</code>. Since the default value for each shape parameter is 1, the
resulting alpha value of 1.16 is the default value. When alpha = 1.16, the
Pareto distribution approximates an income distribution that represents the
80-20 law where 20% of the population receives 80% of the income
(Hardy, 2010).
</p>
<p>The <code>block_max</code> argument provides for incorporating block effects in the
random sampling. The block effect for each score is a separate effect for the
block. The block effect B for a score is a random number drawn from a uniform
distribution on the interval <code>[0, block_max]</code>. When <code>design = "paired"</code>,
the same random block effect is added to the score in the first condition,
which is the random <code>C</code> value, and it is also added to the corresponding
paired value for the <code>E</code> variate. Thus, the pairing research design
eliminates the effect of block variation for the assessment of condition
differences. When <code>design = "independent"</code>, there are different block-effect
contributions to the <code>E</code> and <code>C</code> variates, which reduces the
discrimination of condition differences because it increases the variability
of the difference in the two variates. The user can study the effect of the
relative discriminability of detecting an effect of delta by adjusting the
value of the <code>block_max</code> argument. The default for <code>block_max</code> is 0,
but it can be altered to any non-negative real number.
</p>
<p>The output from calling the <code>dfba_sim_data()</code> function are two
statistics that are based on the <em>n</em> scores generated in the two
conditions. One statistic is the frequentist <em>p</em>-value for rejecting the
null hypothesis that delta &lt;= 0 from a parametric <em>t</em>-test. The
<em>p</em>-value is the upper tail probability of the sample <em>t</em>-statistic
for either the paired <em>t</em>-test when <code>design = "paired"</code> or it is
the upper tail probability of the sample <em>t</em>-statistic for the two-group
<em>t</em>-test when <code>design = "independent"</code>. The second output statistic
is the Bayesian posterior probability for one of two possible nonparametric
tests. If <code>design = "paired"</code>, the <code>dfba_sim_sim()</code> function
calls the <code>dfba_wilcoxon()</code> function to ascertain the posterior
probability that <code>phi_w &gt; .5</code>. If <code>design = "independent"</code>, the
<code>dfba_sim_data()</code> function calls the <code>dfba_mann_whitney()</code> function
to estimate the posterior probability that <code>omega_E &gt; .5</code>. The arguments
<code>a0</code> and <code>b0</code> for the <code>dfba_sim_data()</code> function are passed
along to either the <code>dfba_wilcoxon()</code> function or the
<code>dfba_mann_whitney()</code> function. The default values are <code>a0 = b0 = 1</code>.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>pvalue</code></td>
<td>
<p>The upper tail of the sample t value for the test that delta &lt;= 0</p>
</td></tr>
<tr><td><code>prH1</code></td>
<td>
<p>Bayesian posterior probability either for the hypothesis that phi_w &gt; .5 from the nonparametric Wilcoxon test when <code>design = "paired"</code> or for the hypothesis that omega_E &gt; .5 from the Mann-Whitney test when <code>design = "independent"</code></p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Vector of length n of simulated values for condition 1</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>Vector of length n of simulated values for condition 2</p>
</td></tr>
<tr><td><code>design</code></td>
<td>
<p>The data structure indicated by the <code>design</code> argument. One of <code>"independent"</code> or <code>"paired"</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Random sampling for both the Gumbel and the Pareto distributions are
generated by the <code>dfba_sim_data()</code> function using the inverse transform
method (Fishman, 1996).
</p>


<h3>References</h3>

<p>Arnold, B. C. (1983). Pareto Distribution. Fairland, MD:
International Cooperative Publishing House.
</p>
<p>Chechile, R. A. (2017). A Bayesian analysis for the Wilcoxon signed-rank
statistic. Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2017.1388402.
</p>
<p>Chechile, R. A. (2020). A Bayesian analysis for the Mann- Whitney statistic.
Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2018.1549247.
</p>
<p>Fishman, G. S. (1996) Monte Carlo: Concepts, Algorithms and Applications.
New York: Springer.
</p>
<p>Hardy, M. (2010). Pareto's Law. Mathematical Intelligencer,
32, 38-43.
</p>
<p>Johnson, N. L., Kotz S., and Balakrishnan, N. (1995). Continuous Univariate
Distributions, Vol. 1, New York: Wiley.
</p>
<p>Pareto, V. (1897). Cours d'Economie Politique. Vol. 2,
Lausanne: F. Rouge.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Distributions">Distributions</a></code> for details on the
parameters of the normal, Weibull, Cauchy, lognormal, chi-squared, logistic,
and exponential distributions.
</p>
<p><code><a href="#topic+dfba_wilcoxon">dfba_wilcoxon</a></code>
</p>
<p><code><a href="#topic+dfba_mann_whitney">dfba_mann_whitney</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example of two paired normal distributions where the s.d. of the two
# conditions are 1 and 4.

dfba_sim_data(n = 50,
             model = "normal",
             design = "paired",
             delta = .4,
             shape1 = 1,
             shape2 = 4)

# Example of two independent Weibull variates with their shape parameters =.8
# and with a .25 offset

dfba_sim_data(n = 80,
              model = "weibull",
              design = "independent",
              delta = .25,
              shape1 = .8,
              shape2 = .8)

# Example of two independent Weibull variates with their shape
# parameters = .8 and with a .25 offset along with some block differences
# with the max block effect being 1.5

dfba_sim_data(n = 80,
             model = "weibull",
             design = "independent",
             delta = .25,
             shape1 = .8,
             shape2 = .8,
             block_max = 1.5)

# Example of two paired Cauchy variates with a .4 offset

dfba_sim_data(n = 50,
             model = "cauchy",
             design = "paired",
             delta = .4)
# Example of two paired Cauchy variates with a .4 offset where the Bayesian
# analysis uses the Jeffreys prior

dfba_sim_data(n = 50,
             a0 = .5,
             b0 = .5,
             model = "cauchy",
             design = "paired",
             delta=.4)

</code></pre>

<hr>
<h2 id='dfba_wilcoxon'>Repeated-Measures Test (Wilcoxon Signed-Ranks Test)</h2><span id='topic+dfba_wilcoxon'></span>

<h3>Description</h3>

<p>Given two continuous, paired variates <code>Y1</code> and <code>Y2</code>,
computes the sample <code>T_pos</code> and <code>T_neg</code> statistics for the Wilcoxon
signed-rank test and provides a Bayesian analysis for the population
sign-bias parameter <code>phi_w</code>, which is the population proportion of
positive differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfba_wilcoxon(
  Y1,
  Y2,
  a0 = 1,
  b0 = 1,
  prob_interval = 0.95,
  samples = 30000,
  method = NULL,
  hide_progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dfba_wilcoxon_+3A_y1">Y1</code></td>
<td>
<p>Numeric vector for one continuous variate</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_y2">Y2</code></td>
<td>
<p>Numeric vector for values paired with Y1 variate</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_a0">a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution for <code>phi_w</code>. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_b0">b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for <code>phi_w</code>. Must be positive and finite.</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_prob_interval">prob_interval</code></td>
<td>
<p>Desired probability for interval estimates of the sign bias parameter <code>phi_w</code> (default is 0.95)</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_samples">samples</code></td>
<td>
<p>When <code>method = "small"</code>, the number of desired Monte Carlo samples per candidate value for <code>phi_w</code> (default is 30000 per candidate phi)</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_method">method</code></td>
<td>
<p>(Optional) The method option is either <code>"small"</code> or <code>"large"</code>. The &quot;small&quot; algorithm is based on a discrete Monte Carlo solution for cases where <em>n</em> is typically less than 20. The <code>"large"</code> algorithm is based on beta approximation model for the posterior distribution for the <code>phi_w</code> parameter. This approximation is reasonable when <em>n</em> &gt; 19. Regardless of <em>n</em> the user can stipulate either method. When the <code>method</code> argument is omitted, the program selects the appropriate procedure.</p>
</td></tr>
<tr><td><code id="dfba_wilcoxon_+3A_hide_progress">hide_progress</code></td>
<td>
<p>(Optional) If <code>TRUE</code>, hide percent progress while Monte Carlo sampling is running when <code>method = SMALL</code>. (default is <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wilcoxon signed-rank test is the frequentist nonparametric counterpart to
the paired <em>t</em>-test. The procedure is based on the rank of the difference
scores <em>d</em> = <code>Y1</code> - <code>Y2</code>.
The ranking is initially done on the absolute value of the nonzero <code>d</code> values,
and each rank is then multiplied by the sign of the difference. Differences
equal to zero are dropped. Since the procedure is based on only ranks of the
differences, it is robust with respect to outliers in either the <code>Y1</code> or
<code>Y2</code> measures. The procedure does not depend on the assumption of a
normal distribution for the two continuous variates.
</p>
<p>The sample <code>T_pos</code> statistic is the sum of the ranks that have a positive
sign, whereas <code>T_neg</code> is the positive sum of the ranks that have a
negative value. Given <em>n</em> nonzero <em>d</em> scores, <code>T_pos</code> +
<code>T_neg</code> = <em>n</em>(<em>n</em> + 1)/2. Tied ranks are possible, especially
when there are <code>Y1</code> and <code>Y2</code> values that have low precision. In
such cases, the Wilcoxon statistics are rounded to the nearest integer.
</p>
<p>The Bayesian analysis is based on a parameter <code>phi_w</code>, which is the
population proportion for positive <em>d</em> scores. The default prior for <code>phi_w</code>
is a flat beta distribution with shape parameters <code>a0</code> = <code>b0</code> =1,
but the user can stipulate their preferred beta prior by assigning values for
<code>a0</code> and <code>b0</code>. The <code>prob_interval</code> input, which has a default
value of .95, is the value for interval estimates for the <code>phi_w</code>
parameter, but the user can alter this value if they prefer.
</p>
<p>There are two cases for the Bayesian analysis - one for a small number of
pairs and another for when there is a large number of pairs. The <code>method = small</code>
sample algorithm uses a discrete approximation where there are 200 candidate
values for phi_w, which are .0025 to .9975 in steps of .005. For each
candidate value for <code>phi_w</code>, there is a prior and posterior probability.
The posterior probability is based on Monte Carlo sampling to approximate the
likelihood for obtaining the observed  Wilcoxon statistics. That is, for each
candidate value for <code>phi_w</code>, thousands of Monte Carlo samples are
generated for the signs on the numbers (1,2, ..., n) where each number is
multiplied by the sign. The proportion of the samples that result in the
observed Wilcoxon statistics is an estimate for the likelihood value for that
candidate <code>phi_w</code>. The likelihood values along with the prior result in
a discrete posterior distribution for <code>phi_w</code>. The default for the
number of Monte Carlo samples per candidate <code>phi_w</code> is the input
quantity called <code>samples</code>. The default value for samples is 30000,
but this quantity can be altered by the user.
</p>
<p>Chechile (2018) empirically found that for large <em>n</em> there was a beta
distribution that approximated the quantiles of the discrete, small sample
approach. This approximation is reasonably accurate for <em>n</em> &gt; 24, and is
used when <code>method = "large"</code>.
</p>
<p>If the <code>method</code> argument is omitted, the function employs the method
that is appropriate given the sample size. Note: the <code>method = "small"</code>
algorithm is slower than the algorithm for <code>method = "large"</code>; for cases
where <em>n</em> &gt; 24, <code>method = "small"</code> and <code>method = "large"</code> will
produce similar estimates but the former method requires increased
processing time.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>T_pos</code></td>
<td>
<p>Sum of the positive ranks in the pairwise comparisons</p>
</td></tr>
<tr><td><code>T_neg</code></td>
<td>
<p>Sum of the negative ranks in the pairwise comparisons</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of nonzero differences for differences <code>d = Y1-Y2</code></p>
</td></tr>
<tr><td><code>prob_interval</code></td>
<td>
<p>User-defined probability for interval estimates for phi_w</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>The number of Monte Carlo samples per candidate phi_w for <code>method = "small"</code> (default is 30000)</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>A character string that is either <code>"small"</code> or <code>"large"</code> for the algorithm used (default is NULL)</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The first shape parameter for the beta prior distribution (default is 1)</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>The second shape parameter for the beta distribution prior (default is 1)</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution</p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution</p>
</td></tr>
<tr><td><code>phiv</code></td>
<td>
<p>The 200 candidate values for phi_w for <code>method = "small"</code></p>
</td></tr>
<tr><td><code>phipost</code></td>
<td>
<p>The discrete posterior distribution for phi_w when <code>method = "small"</code></p>
</td></tr>
<tr><td><code>priorprH1</code></td>
<td>
<p>The prior probability that phi_w &gt; .5</p>
</td></tr>
<tr><td><code>prH1</code></td>
<td>
<p>The posterior probability for phi_w &gt; .5</p>
</td></tr>
<tr><td><code>BF10</code></td>
<td>
<p>Bayes factor for the relative increase in the posterior odds for the alternative hypothesis that phi_w &gt; .5 over the null model for phi_w &lt;= .5</p>
</td></tr>
<tr><td><code>post_mean</code></td>
<td>
<p>The posterior mean for phi_w</p>
</td></tr>
<tr><td><code>cumulative_phi</code></td>
<td>
<p>The posterior cumulative distribution for phi_w when <code>method = "small"</code></p>
</td></tr>
<tr><td><code>hdi_lower</code></td>
<td>
<p>The lower limit for the posterior highest-density interval estimate for phi_w</p>
</td></tr>
<tr><td><code>hdi_upper</code></td>
<td>
<p>The upper limit for the posterior highest-density interval estimate for phi_w</p>
</td></tr>
<tr><td><code>a_post</code></td>
<td>
<p>The first shape parameter for a beta distribution model for phi_w when <code>method = "large"</code></p>
</td></tr>
<tr><td><code>b_post</code></td>
<td>
<p>The second shape parameter for a beta distribution model for phi_w when <code>method = "large"</code></p>
</td></tr>
<tr><td><code>post_median</code></td>
<td>
<p>The posterior median for phi_w when <code>method = "large"</code></p>
</td></tr>
<tr><td><code>eti_lower</code></td>
<td>
<p>The equal-tail lower limit for phi_w</p>
</td></tr>
<tr><td><code>eti_upper</code></td>
<td>
<p>The equal-tail upper limit for phi_w</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chechile, R.A. (2020). Bayesian Statistics for Experimental
Scientists: A General Introduction to Distribution-Free Methods.
Cambridge: MIT Press.
</p>
<p>Chechile, R. A. (2018) A Bayesian analysis for the Wilcoxon signed-rank
statistic. Communications in Statistics - Theory and Methods,
https://doi.org/10.1080/03610926.2017.1388402
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Examples with a small number of pairs



conditionA &lt;- c(1.49, 0.64, 0.96, 2.34, 0.78, 1.29, 0.72, 1.52, 0.62, 1.67,
                1.19, 0.86)
conditionB &lt;- c(0.53, 0.55, 0.58, 0.97, 0.60, 0.22, 0.05, 13.14, 0.63, 0.33,
                0.91, 0.37)

dfba_wilcoxon(Y1 = conditionA,
              Y2 = conditionB,
              samples = 250,
              hide_progress = TRUE)

# Examples with large sample size

E &lt;- c(6.45, 5.65, 4.34, 5.92, 2.84, 13.06, 6.61, 5.47, 4.49, 6.39, 6.63,
       3.55, 3.76, 5.61, 7.45, 6.41, 10.16, 6.26, 8.46, 2.29, 3.16, 5.68,
       4.13, 2.94, 4.87, 4.44, 3.13, 8.87)

C &lt;- c(2.89, 4.19, 3.22, 6.50, 3.10, 4.19, 5.13, 3.77, 2.71, 2.58, 7.59,
       2.68, 4.98, 2.35, 5.15, 8.46, 3.77, 8.83, 4.06, 2.50, 5.48, 2.80,
       8.89, 3.19, 9.36, 4.58, 2.94, 4.75)

BW&lt;-dfba_wilcoxon(Y1 = E,
                  Y2 = C)
BW
plot(BW)


</code></pre>

<hr>
<h2 id='show+2Cdfba_beta_contrast_out-method'>Formats for Beta Contrasts</h2><span id='topic+show+2Cdfba_beta_contrast_out-method'></span><span id='topic+plot+2Cdfba_beta_contrast_out-method'></span>

<h3>Description</h3>

<p>Formats for Beta Contrasts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_beta_contrast_out'
show(object)

## S4 method for signature 'dfba_beta_contrast_out'
plot(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_beta_contrast_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_beta_contrast_out-class">dfba_beta_contrast_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_beta_contrast_out-method_+3A_x">x</code></td>
<td>
<p>object An object of class <code><a href="#topic+dfba_beta_contrast_out-class">dfba_beta_contrast_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_beta_contrast_out-class">dfba_beta_contrast_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_beta_contrast_out-class">dfba_beta_contrast_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_beta_descriptive_out-method'>Formats for Beta Descriptive</h2><span id='topic+show+2Cdfba_beta_descriptive_out-method'></span><span id='topic+plot+2Cdfba_beta_descriptive_out-method'></span>

<h3>Description</h3>

<p>Formats for Beta Descriptive
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_beta_descriptive_out'
show(object)

## S4 method for signature 'dfba_beta_descriptive_out'
plot(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_beta_descriptive_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_beta_descriptive_out-class">dfba_beta_descriptive_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_beta_descriptive_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_beta_descriptive_out-class">dfba_beta_descriptive_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_beta_descriptive_out-class">dfba_beta_descriptive_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_beta_descriptive_out-class">dfba_beta_descriptive_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_binomial_out-method'>Formats for Bayesian Binomial Test</h2><span id='topic+show+2Cdfba_binomial_out-method'></span><span id='topic+plot+2Cdfba_binomial_out-method'></span>

<h3>Description</h3>

<p>Formats for Bayesian Binomial Test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_binomial_out'
show(object)

## S4 method for signature 'dfba_binomial_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_binomial_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_binomial_out-class">dfba_binomial_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_binomial_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_binomial_out-class">dfba_binomial_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_binomial_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_binomial_out-class">dfba_binomial_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_binomial_out-class">dfba_binomial_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_bivariate_concordance_out-method'>Formatted output for dfba_bivariate_concordance</h2><span id='topic+show+2Cdfba_bivariate_concordance_out-method'></span><span id='topic+show+2Cdfba_bivariate_concordance_star_out-method'></span><span id='topic+plot+2Cdfba_bivariate_concordance_out-method'></span><span id='topic+plot+2Cdfba_bivariate_concordance_star_out-method'></span>

<h3>Description</h3>

<p>Formatted output for dfba_bivariate_concordance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_bivariate_concordance_out'
show(object)

## S4 method for signature 'dfba_bivariate_concordance_star_out'
show(object)

## S4 method for signature 'dfba_bivariate_concordance_out'
plot(x, plot.prior = TRUE)

## S4 method for signature 'dfba_bivariate_concordance_star_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_bivariate_concordance_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_bivariate_concordance_star_out-class">dfba_bivariate_concordance_star_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_bivariate_concordance_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_bivariate_concordance_star_out-class">dfba_bivariate_concordance_star_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_bivariate_concordance_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_bivariate_concordance_out-class">dfba_bivariate_concordance_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_bivariate_concordance_star_out-class">dfba_bivariate_concordance_star_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_bivariate_concordance_out-class">dfba_bivariate_concordance_out</a></code>
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_bivariate_concordance_star_out-class">dfba_bivariate_concordance_star_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_gamma_out-method'>Formatted output for dfba_gamma</h2><span id='topic+show+2Cdfba_gamma_out-method'></span><span id='topic+plot+2Cdfba_gamma_out-method'></span>

<h3>Description</h3>

<p>Formatted output for dfba_gamma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_gamma_out'
show(object)

## S4 method for signature 'dfba_gamma_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_gamma_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_gamma_out-class">dfba_gamma_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_gamma_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_gamma_out-class">dfba_gamma_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_gamma_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_gamma_out-class">dfba_gamma_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_gamma_out-class">dfba_gamma_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_interval_BF_out-method'>Formats for Interval Bayes Factor</h2><span id='topic+show+2Cdfba_interval_BF_out-method'></span>

<h3>Description</h3>

<p>Formats for Interval Bayes Factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_interval_BF_out'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_interval_BF_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_interval_BF_out-class">dfba_interval_BF_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_interval_BF_out-class">dfba_interval_BF_out</a></code> are printed.
</p>

<hr>
<h2 id='show+2Cdfba_mann_whitney_large_out-method'>Formats for large-n Mann Whitney</h2><span id='topic+show+2Cdfba_mann_whitney_large_out-method'></span><span id='topic+plot+2Cdfba_mann_whitney_large_out-method'></span>

<h3>Description</h3>

<p>Formats for large-n Mann Whitney
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_mann_whitney_large_out'
show(object)

## S4 method for signature 'dfba_mann_whitney_large_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_mann_whitney_large_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_mann_whitney_large_out-class">dfba_mann_whitney_large_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_mann_whitney_large_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_mann_whitney_small_out-class">dfba_mann_whitney_small_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_mann_whitney_large_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_mann_whitney_large_out-class">dfba_mann_whitney_large_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_mann_whitney_small_out-class">dfba_mann_whitney_small_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_mann_whitney_small_out-method'>Formats for small-n Mann Whitney</h2><span id='topic+show+2Cdfba_mann_whitney_small_out-method'></span><span id='topic+plot+2Cdfba_mann_whitney_small_out-method'></span>

<h3>Description</h3>

<p>Formats for small-n Mann Whitney
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_mann_whitney_small_out'
show(object)

## S4 method for signature 'dfba_mann_whitney_small_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_mann_whitney_small_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_mann_whitney_small_out-class">dfba_mann_whitney_small_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_mann_whitney_small_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_mann_whitney_small_out-class">dfba_mann_whitney_small_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_mann_whitney_small_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_mann_whitney_small_out-class">dfba_mann_whitney_small_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_mann_whitney_small_out-class">dfba_mann_whitney_small_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_mcnemar_out-method'>Format for Bayesian McNemar Test</h2><span id='topic+show+2Cdfba_mcnemar_out-method'></span><span id='topic+plot+2Cdfba_mcnemar_out-method'></span>

<h3>Description</h3>

<p>Format for Bayesian McNemar Test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_mcnemar_out'
show(object)

## S4 method for signature 'dfba_mcnemar_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_mcnemar_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_mcnemar_out-class">dfba_mcnemar_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_mcnemar_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_mcnemar_out-class">dfba_mcnemar_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_mcnemar_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_mcnemar_out-class">dfba_mcnemar_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_mcnemar_out-class">dfba_mcnemar_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_median_test_out-method'>Formats for Bayesian Median Test Output</h2><span id='topic+show+2Cdfba_median_test_out-method'></span>

<h3>Description</h3>

<p>Formats for Bayesian Median Test Output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_median_test_out'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_median_test_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_median_test_out-class">dfba_median_test_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_median_test_out-class">dfba_median_test_out</a></code> are printed.
</p>

<hr>
<h2 id='show+2Cdfba_point_BF_out-method'>Formats for Point Bayes Factor</h2><span id='topic+show+2Cdfba_point_BF_out-method'></span>

<h3>Description</h3>

<p>Formats for Point Bayes Factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_point_BF_out'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_point_BF_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_point_BF_out-class">dfba_point_BF_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_point_BF_out-class">dfba_point_BF_out</a></code> are printed.
</p>

<hr>
<h2 id='show+2Cdfba_power_curve_out-method'>Formats for power curve</h2><span id='topic+show+2Cdfba_power_curve_out-method'></span><span id='topic+plot+2Cdfba_power_curve_out-method'></span>

<h3>Description</h3>

<p>Formats for power curve
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_power_curve_out'
show(object)

## S4 method for signature 'dfba_power_curve_out'
plot(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_power_curve_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_power_curve_out-class">dfba_power_curve_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_power_curve_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_power_curve_out-class">dfba_power_curve_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_power_curve_out-class">dfba_power_curve_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_power_curve_out-class">dfba_power_curve_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_sign_test_out-method'>Formats for Bayesian Sign Test</h2><span id='topic+show+2Cdfba_sign_test_out-method'></span><span id='topic+plot+2Cdfba_sign_test_out-method'></span>

<h3>Description</h3>

<p>Formats for Bayesian Sign Test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_sign_test_out'
show(object)

## S4 method for signature 'dfba_sign_test_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_sign_test_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_sign_test_out-class">dfba_sign_test_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_sign_test_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_sign_test_out-class">dfba_sign_test_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_sign_test_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_sign_test_out-class">dfba_sign_test_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_sign_test_out-class">dfba_sign_test_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_sim_data_out-method'>Format for Simulated Data Function</h2><span id='topic+show+2Cdfba_sim_data_out-method'></span><span id='topic+plot+2Cdfba_sim_data_out-method'></span>

<h3>Description</h3>

<p>Format for Simulated Data Function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_sim_data_out'
show(object)

## S4 method for signature 'dfba_sim_data_out'
plot(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_sim_data_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_sim_data_out-class">dfba_sim_data_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_sim_data_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_sim_data_out-class">dfba_sim_data_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_sim_data_out-class">dfba_sim_data_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_sim_data_out-class">dfba_sim_data_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_t_power_out-method'>Bayesian vs. t Power Methods</h2><span id='topic+show+2Cdfba_t_power_out-method'></span><span id='topic+plot+2Cdfba_t_power_out-method'></span>

<h3>Description</h3>

<p>Bayesian vs. t Power Methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_t_power_out'
show(object)

## S4 method for signature 'dfba_t_power_out'
plot(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_t_power_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_t_power_out-class">dfba_t_power_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_t_power_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_t_power_out-class">dfba_t_power_out</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_t_power_out-class">dfba_t_power_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_t_power_out-class">dfba_t_power_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_wilcoxon_large_out-method'>Formats for large-n Wilcoxon</h2><span id='topic+show+2Cdfba_wilcoxon_large_out-method'></span><span id='topic+plot+2Cdfba_wilcoxon_large_out-method'></span>

<h3>Description</h3>

<p>Formats for large-n Wilcoxon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_wilcoxon_large_out'
show(object)

## S4 method for signature 'dfba_wilcoxon_large_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_wilcoxon_large_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_wilcoxon_large_out-class">dfba_wilcoxon_large_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_wilcoxon_large_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_wilcoxon_large_out-class">dfba_wilcoxon_large_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_wilcoxon_large_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_wilcoxon_large_out-class">dfba_wilcoxon_large_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_wilcoxon_large_out-class">dfba_wilcoxon_large_out</a></code>
</p>

<hr>
<h2 id='show+2Cdfba_wilcoxon_small_out-method'>Formats for small-n Wilcoxon</h2><span id='topic+show+2Cdfba_wilcoxon_small_out-method'></span><span id='topic+plot+2Cdfba_wilcoxon_small_out-method'></span>

<h3>Description</h3>

<p>Formats for small-n Wilcoxon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'dfba_wilcoxon_small_out'
show(object)

## S4 method for signature 'dfba_wilcoxon_small_out'
plot(x, plot.prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2Cdfba_wilcoxon_small_out-method_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_wilcoxon_small_out-class">dfba_wilcoxon_small_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_wilcoxon_small_out-method_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+dfba_wilcoxon_small_out-class">dfba_wilcoxon_small_out</a></code></p>
</td></tr>
<tr><td><code id="show+2B2Cdfba_wilcoxon_small_out-method_+3A_plot.prior">plot.prior</code></td>
<td>
<p>Show prior distribution (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effect. Objects of class <code><a href="#topic+dfba_wilcoxon_small_out-class">dfba_wilcoxon_small_out</a></code> are printed.
</p>
<p>No return value, called for side effect. Method produces a plot of class <code><a href="#topic+dfba_wilcoxon_small_out-class">dfba_wilcoxon_small_out</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
