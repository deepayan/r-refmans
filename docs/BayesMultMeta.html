<!DOCTYPE html><html lang="en"><head><title>Help for package BayesMultMeta</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BayesMultMeta}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bayes_inference'><p>Summary statistics from a posterior distribution</p></a></li>
<li><a href='#BayesMultMeta'><p>Interface for the BayesMultMeta class</p></a></li>
<li><a href='#duplication_matrix'><p>Duplication matrix</p></a></li>
<li><a href='#MC_ranks'><p>Computes the ranks within the pooled draws of Markov chains</p></a></li>
<li><a href='#plot.BayesMultMeta'><p>Plot a BayesMultMeta object</p></a></li>
<li><a href='#sample_post_nor_jef_marg_mu'><p>Metropolis-Hastings algorithm for the normal distribution and the Jeffreys</p>
prior, where <code class="reqn">\mathbf{\mu}</code> is generated from the marginal posterior.</a></li>
<li><a href='#sample_post_nor_jef_marg_Psi'><p>Metropolis-Hastings algorithm for the normal distribution and the Jeffreys</p>
prior, where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal posterior.</a></li>
<li><a href='#sample_post_nor_ref_marg_mu'><p>Metropolis-Hastings algorithm for the normal distribution and the Berger and</p>
Bernardo reference prior, where <code class="reqn">\mathbf{\mu}</code> is generated from the
marginal posterior.</a></li>
<li><a href='#sample_post_nor_ref_marg_Psi'><p>Metropolis-Hastings algorithm for the normal distribution and the Berger and</p>
Bernardo reference prior, where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal
posterior.</a></li>
<li><a href='#sample_post_t_jef_marg_mu'><p>Metropolis-Hastings algorithm for the t-distribution and the Jeffreys prior,</p>
where <code class="reqn">\mathbf{\mu}</code> is generated from the marginal posterior.</a></li>
<li><a href='#sample_post_t_jef_marg_Psi'><p>Metropolis-Hastings algorithm for the t-distribution and the Jeffreys prior,</p>
where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal posterior.</a></li>
<li><a href='#sample_post_t_ref_marg_mu'><p>Metropolis-Hastings algorithm for the t-distribution and Berger and Bernardo</p>
reference prior, where <code class="reqn">\mathbf{\mu}</code> is generated from the marginal
posterior.</a></li>
<li><a href='#sample_post_t_ref_marg_Psi'><p>Metropolis-Hastings algorithm for the t-distribution and Berger and Bernardo</p>
reference prior, where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal
posterior.</a></li>
<li><a href='#split_rank_hatR'><p>Computes the split-<code class="reqn">\hat{R}</code> estimate based on the rank normalization</p></a></li>
<li><a href='#summary.BayesMultMeta'><p>Summary statistics from the posterior of a BayesMultMeta class</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Multivariate Meta-Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Olha Bodnar <a href="https://orcid.org/0000-0003-1359-3311"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Taras Bodnar <a href="https://orcid.org/0000-0001-7855-8221"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Erik Thorsén <a href="https://orcid.org/0000-0001-5992-1216"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Erik Thorsén &lt;erik.thorsen@math.su.se&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Objective Bayesian inference procedures for the parameters of the
    multivariate random effects model with application to multivariate
    meta-analysis. The posterior for the model parameters, namely the overall
    mean vector and the between-study covariance matrix, are assessed by
    constructing Markov chains based on the Metropolis-Hastings algorithms as
    developed in Bodnar and Bodnar (2021) (&lt;<a href="https://doi.org/10.48550/arXiv.2104.02105">doi:10.48550/arXiv.2104.02105</a>&gt;). The
    Metropolis-Hastings algorithm is designed under the assumption of the
    normal distribution and the t-distribution when the Berger and Bernardo
    reference prior and the Jeffreys prior are assigned to the model parameters.
    Convergence properties of the generated Markov chains are investigated by
    the rank plots and the split hat-R estimate based on the rank normalization,
    which are proposed in Vehtari et al. (2021) (&lt;<a href="https://doi.org/10.1214%2F20-BA1221">doi:10.1214/20-BA1221</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>Imports:</td>
<td>assertthat, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvmeta, gplots, testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-08 19:46:32 UTC; ethor</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-09 08:10:27 UTC</td>
</tr>
</table>
<hr>
<h2 id='bayes_inference'>Summary statistics from a posterior distribution</h2><span id='topic+bayes_inference'></span>

<h3>Description</h3>

<p>Given a univariate sample drawn from the posterior distribution, this
function computes the posterior mean, the posterior median, the posterior
standard deviation, and the limits of the <code class="reqn">(1-\alpha)</code> probability-symmetric
credible interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_inference(x, alp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bayes_inference_+3A_x">x</code></td>
<td>
<p>Univariate sample from the posterior distribution of a parameter.</p>
</td></tr>
<tr><td><code id="bayes_inference_+3A_alp">alp</code></td>
<td>
<p>Significance level used in the computation of the credible interval</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with summary statistics
</p>

<hr>
<h2 id='BayesMultMeta'>Interface for the BayesMultMeta class</h2><span id='topic+BayesMultMeta'></span>

<h3>Description</h3>

<p>The BayesMultMeta package implements two methods of constructing Markov
chains to assess the posterior distribution of the model parameters, namely
the overall mean vector <code class="reqn">\mathbf{\mu}</code> and the between-study covariance matrix
<code class="reqn">\mathbf{\Psi}</code>, of the generalized marginal multivariate random effects models.
The Bayesian inference procedures are performed when the model parameters are
endowed with the Berger and Bernardo reference prior
(Berger and Bernardo 1992) and the Jeffreys prior
(Jeffreys 1946). This is achieved by
constructing Markov chains using the Metropolis-Hastings algorithms developed
in (Bodnar and Bodnar 2021). The convergence
properties of the generated Markov chains are investigated by the rank plots
and the split-<code class="reqn">\hat{R}</code> estimate based on the rank normalization, which are
proposed in (Vehtari et al. 2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesMultMeta(X, U, N, burn_in, likelihood, prior, algorithm_version, d = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BayesMultMeta_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors
of dimension <code class="reqn">p</code></p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">pn \times pn</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_n">N</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_burn_in">burn_in</code></td>
<td>
<p>Number of burn-in samples</p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_likelihood">likelihood</code></td>
<td>
<p>Likelihood to use. It currently supports &quot;normal&quot; and
&quot;t&quot;.</p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_prior">prior</code></td>
<td>
<p>Prior to use. It currently supports &quot;reference&quot; and
&quot;jeffrey&quot;.</p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_algorithm_version">algorithm_version</code></td>
<td>
<p>One of &quot;mu&quot; or &quot;Psi&quot;. Both algorithms samples the
same quantities.</p>
</td></tr>
<tr><td><code id="BayesMultMeta_+3A_d">d</code></td>
<td>
<p>Degrees of freedom for the t-distribution when the &quot;t&quot; option is
used for the likelihood.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a BayesMultMeta class which contains simulations from the MCMC
inference procedure as well as many of the input parameters. The elements
'psi' and 'mu' in the list contains simulations from the posterior
distribution. All other elements are input parameters to the class.
</p>


<h3>References</h3>

<p>Berger JO, Bernardo JM (1992).
&ldquo;On the development of the reference prior method.&rdquo;
<em>Bayesian statistics</em>, <b>4</b>(4), 35&ndash;60.<br /><br /> Bodnar O, Bodnar T (2021).
&ldquo;Objective Bayesian meta-analysis based on generalized multivariate random effects model.&rdquo;
2104.02105.<br /><br /> Jeffreys H (1946).
&ldquo;An invariant form for the prior probability in estimation problems.&rdquo;
<em>Proceedings of the Royal Society of London Series A</em>, <b>186</b>(1007), 453-461.
doi: <a href="https://doi.org/10.1098/rspa.1946.0056">10.1098/rspa.1946.0056</a>.<br /><br /> Vehtari A, Gelman A, Simpson D, Carpenter B, BÃ¼rkner P (2021).
&ldquo;Rank-normalization, folding, and localization: An improved hatR for assessing convergence of MCMC (with Discussion).&rdquo;
<em>Bayesian analysis</em>, <b>16</b>(2), 667&ndash;718.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataREM&lt;-mvmeta::hyp
# Observation matrix X
X&lt;-t(cbind(dataREM$sbp,dataREM$dbp))
p&lt;-nrow(X)  # model dimension
n&lt;-ncol(X)  # sample size
# Matrix U
U&lt;-matrix(0,n*p,n*p)
for (i_n in 1:n) {
  Use&lt;-diag(c(dataREM$sbp_se[i_n],dataREM$dbp_se[i_n]))
  Corr_mat&lt;-matrix(c(1,dataREM$rho[i_n],dataREM$rho[i_n],1),p,p)
  U[(p*(i_n-1)+1):(p*i_n),(p*(i_n-1)+1):(p*i_n)]&lt;- Use%*%Corr_mat%*%Use
}

bmgmr_run &lt;- BayesMultMeta(X, U, 1e2, burn_in = 100,
                   likelihood = "normal", prior="jeffrey",
                   algorithm_version = "mu")
summary(bmgmr_run)
plot(bmgmr_run)

</code></pre>

<hr>
<h2 id='duplication_matrix'>Duplication matrix</h2><span id='topic+duplication_matrix'></span>

<h3>Description</h3>

<p>This function creates the duplication matrix of size <code class="reqn">p^2 \times p(p+1)/2</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplication_matrix(p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="duplication_matrix_+3A_p">p</code></td>
<td>
<p>Integer which specifies the dimension of the duplication matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of size <code class="reqn">p^2 \times p(p+1)/2</code>
</p>

<hr>
<h2 id='MC_ranks'>Computes the ranks within the pooled draws of Markov chains</h2><span id='topic+MC_ranks'></span>

<h3>Description</h3>

<p>The function computes the ranks within the pooled draws of Markov
chains. Average ranks are used for ties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MC_ranks(MC)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MC_ranks_+3A_mc">MC</code></td>
<td>
<p>An <code class="reqn">N \times M</code> matrix with N draws in each of M constructed
Markov chains.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with the ranks from the MCMC procedure
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataREM&lt;-mvmeta::hyp
# Observation matrix X
X&lt;-t(cbind(dataREM$sbp,dataREM$dbp))
p&lt;-nrow(X) # model dimension
n&lt;-ncol(X) # sample size
# Matrix U
U&lt;-matrix(0,n*p,n*p)
for (i_n in 1:n) {
  Use&lt;-diag(c(dataREM$sbp_se[i_n],dataREM$dbp_se[i_n]))
  Corr_mat&lt;-matrix(c(1,dataREM$rho[i_n],dataREM$rho[i_n],1),p,p)
  U[(p*(i_n-1)+1):(p*i_n),(p*(i_n-1)+1):(p*i_n)]&lt;- Use%*%Corr_mat%*%Use
}
# Generating M Markov chains for mu_1
M&lt;-4 # number of chains
MC &lt;-NULL
for (i in 1:M) {
chain &lt;-  BayesMultMeta(X, U, 1e2, burn_in = 1e2,
                          likelihood = "t", prior="jeffrey",
                          algorithm_version = "mu",d=3)
  MC&lt;- cbind(MC,chain$mu[1,])
}
ranks&lt;-MC_ranks(MC)
id_chain &lt;- 1
hist(ranks[,id_chain],breaks=25,prob=TRUE, labels = FALSE, border = "dark blue",
  col = "light blue", main = expression("Chain 1,"~mu[1]), xlab = expression(),
  ylab = expression(),cex.axis=1.2,cex.main=1.7,font=2)

</code></pre>

<hr>
<h2 id='plot.BayesMultMeta'>Plot a BayesMultMeta object</h2><span id='topic+plot.BayesMultMeta'></span>

<h3>Description</h3>

<p>This function produces the trace plots of the constructed Markov chains.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BayesMultMeta'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.BayesMultMeta_+3A_x">x</code></td>
<td>
<p>a BayesMultMeta object</p>
</td></tr>
<tr><td><code id="plot.BayesMultMeta_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, produces trace plots
</p>

<hr>
<h2 id='sample_post_nor_jef_marg_mu'>Metropolis-Hastings algorithm for the normal distribution and the Jeffreys
prior, where <code class="reqn">\mathbf{\mu}</code> is generated from the marginal posterior.</h2><span id='topic+sample_post_nor_jef_marg_mu'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code> under the
assumption of the normal distribution when the Jeffreys prior is employed.
At each step, the algorithm starts with generating a draw from the marginal
distribution of <code class="reqn">\mathbf{\mu}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_nor_jef_marg_mu(X, U, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_nor_jef_marg_mu_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_nor_jef_marg_mu_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_nor_jef_marg_mu_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_nor_jef_marg_Psi'>Metropolis-Hastings algorithm for the normal distribution and the Jeffreys
prior, where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal posterior.</h2><span id='topic+sample_post_nor_jef_marg_Psi'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the normal distribution when the Jeffreys prior is
employed. At each step, the algorithm starts with generating a draw from the
marginal distribution of <code class="reqn">\mathbf{\Psi}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_nor_jef_marg_Psi(X, U, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_nor_jef_marg_Psi_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_nor_jef_marg_Psi_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_nor_jef_marg_Psi_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_nor_ref_marg_mu'>Metropolis-Hastings algorithm for the normal distribution and the Berger and
Bernardo reference prior, where <code class="reqn">\mathbf{\mu}</code> is generated from the
marginal posterior.</h2><span id='topic+sample_post_nor_ref_marg_mu'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the normal distribution when the Berger and Bernardo
reference prior is employed. At each step, the algorithm starts with
generating a draw from the marginal distribution of <code class="reqn">\mathbf{\mu}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_nor_ref_marg_mu(X, U, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_nor_ref_marg_mu_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_nor_ref_marg_mu_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_nor_ref_marg_mu_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_nor_ref_marg_Psi'>Metropolis-Hastings algorithm for the normal distribution and the Berger and
Bernardo reference prior, where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal
posterior.</h2><span id='topic+sample_post_nor_ref_marg_Psi'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the normal distribution when the Berger and Bernardo
reference prior is employed. At each step, the algorithm starts with
generating a draw from the marginal distribution of <code class="reqn">\mathbf{\Psi}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_nor_ref_marg_Psi(X, U, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_nor_ref_marg_Psi_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_nor_ref_marg_Psi_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_nor_ref_marg_Psi_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_t_jef_marg_mu'>Metropolis-Hastings algorithm for the t-distribution and the Jeffreys prior,
where <code class="reqn">\mathbf{\mu}</code> is generated from the marginal posterior.</h2><span id='topic+sample_post_t_jef_marg_mu'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the t-distribution when the Jeffreys prior is
employed. At each step, the algorithm starts with generating a draw from the
marginal distribution of <code class="reqn">\mathbf{\mu}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_t_jef_marg_mu(X, U, d, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_t_jef_marg_mu_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_t_jef_marg_mu_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_t_jef_marg_mu_+3A_d">d</code></td>
<td>
<p>Degrees of freedom for the t-distribution</p>
</td></tr>
<tr><td><code id="sample_post_t_jef_marg_mu_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_t_jef_marg_Psi'>Metropolis-Hastings algorithm for the t-distribution and the Jeffreys prior,
where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal posterior.</h2><span id='topic+sample_post_t_jef_marg_Psi'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the t-distribution when the Jeffreys prior is
employed. At each step, the algorithm starts with generating a draw from the
marginal distribution of <code class="reqn">\mathbf{\Psi}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_t_jef_marg_Psi(X, U, d, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_t_jef_marg_Psi_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_t_jef_marg_Psi_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_t_jef_marg_Psi_+3A_d">d</code></td>
<td>
<p>Degrees of freedom for the t-distribution</p>
</td></tr>
<tr><td><code id="sample_post_t_jef_marg_Psi_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_t_ref_marg_mu'>Metropolis-Hastings algorithm for the t-distribution and Berger and Bernardo
reference prior, where <code class="reqn">\mathbf{\mu}</code> is generated from the marginal
posterior.</h2><span id='topic+sample_post_t_ref_marg_mu'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the t-distribution when the Berger and Bernardo prior
is employed. At each step, the algorithm starts with generating a draw from
the marginal distribution of <code class="reqn">\mathbf{\mu}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_t_ref_marg_mu(X, U, d, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_t_ref_marg_mu_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_t_ref_marg_mu_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_t_ref_marg_mu_+3A_d">d</code></td>
<td>
<p>Degrees of freedom for the t-distribution</p>
</td></tr>
<tr><td><code id="sample_post_t_ref_marg_mu_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='sample_post_t_ref_marg_Psi'>Metropolis-Hastings algorithm for the t-distribution and Berger and Bernardo
reference prior, where <code class="reqn">\mathbf{\Psi}</code> is generated from the marginal
posterior.</h2><span id='topic+sample_post_t_ref_marg_Psi'></span>

<h3>Description</h3>

<p>This function implements Metropolis-Hastings algorithm for drawing samples
from the posterior distribution of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>
under the assumption of the t-distribution when the Berger and Bernardo prior
is employed. At each step, the algorithm starts with generating a draw from
the marginal distribution of <code class="reqn">\mathbf{\Psi}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_post_t_ref_marg_Psi(X, U, d, Np)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_post_t_ref_marg_Psi_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix which contains <code class="reqn">n</code> observation vectors of
dimension <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="sample_post_t_ref_marg_Psi_+3A_u">U</code></td>
<td>
<p>A <code class="reqn">p n \times p n</code> block-diagonal matrix which contains the
covariance matrices of observation vectors.</p>
</td></tr>
<tr><td><code id="sample_post_t_ref_marg_Psi_+3A_d">d</code></td>
<td>
<p>Degrees of freedom for the t-distribution</p>
</td></tr>
<tr><td><code id="sample_post_t_ref_marg_Psi_+3A_np">Np</code></td>
<td>
<p>Length of the generated Markov chain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with the generated samples from the joint posterior distribution
of <code class="reqn">\mathbf{\mu}</code> and <code class="reqn">\mathbf{\Psi}</code>, where the values of
<code class="reqn">\mathbf{\Psi}</code> are presented by using the vec operator.
</p>

<hr>
<h2 id='split_rank_hatR'>Computes the split-<code class="reqn">\hat{R}</code> estimate based on the rank normalization</h2><span id='topic+split_rank_hatR'></span>

<h3>Description</h3>

<p>The function computes the split-<code class="reqn">\hat{R}</code> estimate based on the rank
normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_rank_hatR(MC)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="split_rank_hatR_+3A_mc">MC</code></td>
<td>
<p>An <code class="reqn">N \times M</code> matrix with N draws in each of M constructed
Markov chains.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a value with the the split-<code class="reqn">\hat{R}</code> estimate based on the rank
normalization
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataREM&lt;-mvmeta::hyp
# Observation matrix X
X&lt;-t(cbind(dataREM$sbp,dataREM$dbp))
p&lt;-nrow(X) # model dimension
n&lt;-ncol(X) # sample size
# Matrix U
U&lt;-matrix(0,n*p,n*p)
for (i_n in 1:n) {
  Use&lt;-diag(c(dataREM$sbp_se[i_n],dataREM$dbp_se[i_n]))
  Corr_mat&lt;-matrix(c(1,dataREM$rho[i_n],dataREM$rho[i_n],1),p,p)
  U[(p*(i_n-1)+1):(p*i_n),(p*(i_n-1)+1):(p*i_n)]&lt;- Use%*%Corr_mat%*%Use
}
# Generating M Markov chains for mu_1
M&lt;-4 # number of chains
MC &lt;-NULL
for (i in 1:M) {
  chain &lt;-  BayesMultMeta(X, U, 1e2, burn_in = 1e2,
                          likelihood = "t", prior="jeffrey",
                          algorithm_version = "mu",d=3)
  MC&lt;- cbind(MC,chain$mu[1,])
}
split_rank_hatR(MC)

</code></pre>

<hr>
<h2 id='summary.BayesMultMeta'>Summary statistics from the posterior of a BayesMultMeta class</h2><span id='topic+summary.BayesMultMeta'></span>

<h3>Description</h3>

<p>Summary statistics from the posterior of a BayesMultMeta class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BayesMultMeta'
summary(object, alpha = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.BayesMultMeta_+3A_object">object</code></td>
<td>
<p>BayesMultMeta class</p>
</td></tr>
<tr><td><code id="summary.BayesMultMeta_+3A_alpha">alpha</code></td>
<td>
<p>Significance level used in the computation of the credible interval.</p>
</td></tr>
<tr><td><code id="summary.BayesMultMeta_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with summary statistics
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
