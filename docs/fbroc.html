<!DOCTYPE html><html><head><title>Help for package fbroc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fbroc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#boot.paired.roc'><p>Bootstrap paired ROC curves</p></a></li>
<li><a href='#boot.roc'><p>Bootstrap ROC curve</p></a></li>
<li><a href='#boot.tpr.at.fpr'><p>Process bootstrapped TPR/FPR at thresholds matrix into TPR at FPR matrix</p></a></li>
<li><a href='#conf'><p>Generic S3 function to calculate confidence regions for ROC curves</p></a></li>
<li><a href='#conf.fbroc.paired.roc'><p>Generates confidence intervals for the difference in TPR between two predictors for a range of FPRs or vice versa</p></a></li>
<li><a href='#conf.fbroc.roc'><p>Generates confidence intervals for the TPR for a range of FPRs or vice versa</p></a></li>
<li><a href='#extract.roc'><p>Extracts one from two paired ROC curves from a <code>fbroc.paired.roc</code> object</p></a></li>
<li><a href='#fbroc'><p>fbroc: A package for fast bootstrap analysis and comparison of ROC curves</p></a></li>
<li><a href='#perf'><p>Generic S3 function to calculate performance estimates for ROC curves</p></a></li>
<li><a href='#perf.fbroc.paired.roc'><p>Calculate performance for paired bootstrapped ROC curves</p></a></li>
<li><a href='#perf.fbroc.roc'><p>Calculate performance for bootstrapped ROC curve</p></a></li>
<li><a href='#plot.fbroc.conf'><p>Plots function for object of classfbroc.conf</p></a></li>
<li><a href='#plot.fbroc.conf.paired'><p>Plots function for object of class <code>fbroc.conf.paired</code></p></a></li>
<li><a href='#plot.fbroc.paired.roc'><p>Plots a <code>fbroc.paired.roc</code> object</p></a></li>
<li><a href='#plot.fbroc.perf'><p>Plots ROC based performance metric as histogram</p></a></li>
<li><a href='#plot.fbroc.perf.paired'><p>Plots the difference between the bootstrapped performance estimate of the first and the second</p>
classifier.</a></li>
<li><a href='#plot.fbroc.roc'><p>Plots a <code>fbroc.roc</code> object</p></a></li>
<li><a href='#print.fbroc.perf'><p>Prints information about a <code>fbroc.perf</code> object</p></a></li>
<li><a href='#print.fbroc.perf.paired'><p>Prints information about a <code>fbroc.perf.paired</code> object</p></a></li>
<li><a href='#print.fbroc.roc'><p>Prints information about a <code>fbroc.roc</code> object</p></a></li>
<li><a href='#roc.examples'><p>Examples of predictions for ROC curve construction</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Algorithms to Bootstrap Receiver Operating Characteristics
Curves</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-03-24</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements a very fast C++ algorithm to quickly bootstrap receiver
    operating characteristics (ROC) curves and derived performance metrics,
    including the area under the curve (AUC) and the partial area under the curve as well as 
    the true and false positive rate. The analysis of paired receiver operating curves is supported as well,
    so that a comparison of two predictors is possible. You can also plot the
    results and calculate confidence intervals. On a typical desktop computer the time needed for 
    the calculation of 100000 bootstrap replicates given 500 observations requires time on the
    order of magnitude of one second.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.epeter-stats.de/roc-curve-analysis-with-fbroc/">http://www.epeter-stats.de/roc-curve-analysis-with-fbroc/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/erikpeter/fbroc/issues">http://github.com/erikpeter/fbroc/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0), ggplot2, methods, stats, utils</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-24 12:01:19 UTC; Erik</td>
</tr>
<tr>
<td>Author:</td>
<td>Erik Peter [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Erik Peter &lt;jerikpeter@googlemail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-24 12:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='boot.paired.roc'>Bootstrap paired ROC curves</h2><span id='topic+boot.paired.roc'></span>

<h3>Description</h3>

<p>Given two numerical predictors for the same outcome on the same set of samples, this functions
enables the bootstrapping of the paired ROC curves of the two prediction models. While bootstrapping
the same set of samples are used for both curves in each iteration, preserving the correlation
between the two models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.paired.roc(pred1, pred2, true.class, stratify = TRUE,
  n.boot = 1000, use.cache = FALSE, tie.strategy = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.paired.roc_+3A_pred1">pred1</code></td>
<td>
<p>Numerical predictions for the first classifier.</p>
</td></tr>
<tr><td><code id="boot.paired.roc_+3A_pred2">pred2</code></td>
<td>
<p>Numerical predictions for the second classifier.</p>
</td></tr>
<tr><td><code id="boot.paired.roc_+3A_true.class">true.class</code></td>
<td>
<p>A logical vector. TRUE indicates the sample belonging to the
positive class.</p>
</td></tr>
<tr><td><code id="boot.paired.roc_+3A_stratify">stratify</code></td>
<td>
<p>Logical. Indicates whether we use stratified bootstrap.
Default to TRUE. Non-stratified bootstrap is not yet implemented.</p>
</td></tr>
<tr><td><code id="boot.paired.roc_+3A_n.boot">n.boot</code></td>
<td>
<p>A number that will be coerced to integer. Specified the 
number of bootstrap replicates. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="boot.paired.roc_+3A_use.cache">use.cache</code></td>
<td>
<p>If true the bootstrapping results for the
ROC curve will be pre-cached. This increases speed when the object is used often, but also
takes up more memory.</p>
</td></tr>
<tr><td><code id="boot.paired.roc_+3A_tie.strategy">tie.strategy</code></td>
<td>
<p>How to handle ties. See details below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>fbroc.paired.roc</code>, containing the elements:
</p>
<table>
<tr><td><code>prediction1</code></td>
<td>
<p>Input predictions for first model.</p>
</td></tr>
<tr><td><code>prediction2</code></td>
<td>
<p>Input predictions for second model.</p>
</td></tr>
<tr><td><code>true.class</code></td>
<td>
<p>Input classes.</p>
</td></tr>
<tr><td><code>n.thresholds1</code></td>
<td>
<p>Number of thresholds of the first predictor.</p>
</td></tr>
<tr><td><code>n.thresholds2</code></td>
<td>
<p>Number of thresholds of the second predictor.</p>
</td></tr>
<tr><td><code>n.boot</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code>use.cache</code></td>
<td>
<p>Indicates if cache is used for this ROC object.</p>
</td></tr>
<tr><td><code>tie.strategy</code></td>
<td>
<p>Used setting how to handle ties in predictors.</p>
</td></tr>
<tr><td><code>n.pos</code></td>
<td>
<p>Number of positive observations.</p>
</td></tr>
<tr><td><code>n.neg</code></td>
<td>
<p>Number of negative observations.</p>
</td></tr>
<tr><td><code>roc1</code></td>
<td>
<p>A data.frame containing the thresholds of the first ROC curve and the TPR and FPR at these
thresholds.</p>
</td></tr>
<tr><td><code>roc2</code></td>
<td>
<p>A data.frame containing the thresholds of the second ROC curve and the TPR and FPR at these
thresholds.</p>
</td></tr>
<tr><td><code>auc1</code></td>
<td>
<p>The AUC of the first ROC curve.</p>
</td></tr>
<tr><td><code>auc2</code></td>
<td>
<p>The AUC of the second ROC curve.</p>
</td></tr>
<tr><td><code>boot.tpr1</code></td>
<td>
<p>If the cache is enabled, a matrix containing the bootstrapped TPR at the thresholds
for the first predictor.</p>
</td></tr>
<tr><td><code>boot.fpr1</code></td>
<td>
<p>If the cache is enabled, a matrix containing the bootstrapped FPR at the thresholds
for the first predictor.</p>
</td></tr>
<tr><td><code>boot.tpr2</code></td>
<td>
<p>If the cache is enabled, a matrix containing the bootstrapped TPR at the thresholds
for the second predictor.</p>
</td></tr>
<tr><td><code>boot.fpr2</code></td>
<td>
<p>If the cache is enabled, a matrix containing the bootstrapped FPR at the thresholds
for the second predictor.</p>
</td></tr>
</table>


<h3>Caching</h3>

<p>If you enable caching, <code>boot.roc</code> calculates the requested number of bootstrap samples and
saves the TPR and FPR values for each iteration. This can take up a sizable portion of memory,
but it speeds up subsequent operations. This can be useful if you plan to use the ROC curve
multiple <code>fbroc</code> functions.
</p>


<h3>Ties</h3>

<p>You can set this parameter to either 1 or 2. If your numerical predictor has no ties, both settings
will produce the same results. 
If you set <code>tie.strategy</code> to 1 the ROC curve is built by connecting the TPR/FPR pairs for
neighboring thresholds. A tie.strategy of 2 indicates that the TPR calculated at a specific FPR
is the best TPR at a FPR smaller than or equal than the FPR specified. Defaults to 2.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.roc">boot.roc</a></code>, 
<code><a href="#topic+plot.fbroc.paired.roc">plot.fbroc.paired.roc</a></code>,
<code><a href="#topic+perf.fbroc.paired.roc">perf.fbroc.paired.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
# Do not use cache
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier,
                          roc.examples$True.Class, n.boot = 500)
perf(example, "auc") # estimate difference in auc
perf(example, "tpr", fpr = 0.5) # estimate difference in TPR at a FPR of 50%
plot(example) # show plot
# Cached mode
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier,
                          roc.examples$True.Class, n.boot = 1000, use.cache = TRUE)
conf(example, conf.for = "tpr", steps = 10) # get confidence regions for TPR at FPR
conf(example, conf.for = "fpr", steps = 10) # get confidence regions for FPR at TPR
perf(example, "fpr", tpr = 0.9) # estimate difference in FPR at a TPR of 90%                     
</code></pre>

<hr>
<h2 id='boot.roc'>Bootstrap ROC curve</h2><span id='topic+boot.roc'></span>

<h3>Description</h3>

<p><code>boot.roc</code> calculates the ROC curve, initializes the settings
and calculates the bootstrap results for the true and false
positive rate at every relevant threshold. Missing values are removed with 
a warning prior to bootstrapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.roc(pred, true.class, stratify = TRUE, n.boot = 1000,
  use.cache = FALSE, tie.strategy = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.roc_+3A_pred">pred</code></td>
<td>
<p>A numeric vector. Contains predictions. <code>boot.roc</code> assumes
that a high prediction is evidence for the observation belonging to the
positive class.</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_true.class">true.class</code></td>
<td>
<p>A logical vector. TRUE indicates the sample belonging to the
positive class.</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_stratify">stratify</code></td>
<td>
<p>Logical. Indicates whether we use stratified bootstrap.
Default to TRUE. Non-stratified bootstrap is not yet implemented.</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_n.boot">n.boot</code></td>
<td>
<p>A number that will be coerced to integer. Specified the 
number of bootstrap replicates. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_use.cache">use.cache</code></td>
<td>
<p>If true the bootstrapping results for the
ROC curve will be pre-cached. This increases speed when the object is used often, but also
takes up more memory.</p>
</td></tr>
<tr><td><code id="boot.roc_+3A_tie.strategy">tie.strategy</code></td>
<td>
<p>How to handle ties. See details below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>fbroc.roc</code>, containing the elements:
</p>
<table>
<tr><td><code>prediction</code></td>
<td>
<p>Input predictions.</p>
</td></tr>
<tr><td><code>true.class</code></td>
<td>
<p>Input classes.</p>
</td></tr>
<tr><td><code>roc</code></td>
<td>
<p>A data.frame containing the thresholds of the ROC curve and the TPR and FPR at these
thresholds.</p>
</td></tr>
<tr><td><code>n.thresholds</code></td>
<td>
<p>Number of thresholds.</p>
</td></tr>
<tr><td><code>n.boot</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code>use.cache</code></td>
<td>
<p>Indicates if cache is used for this ROC object</p>
</td></tr>
<tr><td><code>tie.strategy</code></td>
<td>
<p>Used setting how to handle ties in predictors.</p>
</td></tr>
<tr><td><code>n.pos</code></td>
<td>
<p>Number of positive observations.</p>
</td></tr>
<tr><td><code>n.neg</code></td>
<td>
<p>Number of negative observations.</p>
</td></tr>
<tr><td><code>auc</code></td>
<td>
<p>The AUC of the original ROC curve.</p>
</td></tr>
<tr><td><code>boot.tpr</code></td>
<td>
<p>If the cache is enabled, a matrix containing the bootstrapped TPR at the thresholds.</p>
</td></tr>
<tr><td><code>boot.fpr</code></td>
<td>
<p>If the cache is enabled, a matrix containing the bootstrapped FPR at the thresholds.</p>
</td></tr>
</table>


<h3>Caching</h3>

<p>If you enable caching, <code>boot.roc</code> calculates the requested number of bootstrap samples and
saves the TPR and FPR values for each iteration. This can take up a sizable portion of memory,
but it speeds up subsequent operations. This can be useful if you plan to use the ROC curve
multiple <code>fbroc</code> functions.
</p>


<h3>Ties</h3>

<p>You can set this parameter to either 1 or 2. If your numerical predictor has no ties, both settings
will produce the same results. 
If you set <code>tie.strategy</code> to 1 the ROC curve is built by connecting the TPR/FPR pairs for
neighboring thresholds. A tie.strategy of 2 indicates that the TPR calculated at a specific FPR
is the best TPR at a FPR smaller than or equal than the FPR specified. Defaults to 2.
</p>


<h3>See Also</h3>

<p><a href="http://www.epeter-stats.de/roc-curves-and-ties/">http://www.epeter-stats.de/roc-curves-and-ties/</a>, <code><a href="#topic+plot.fbroc.roc">plot.fbroc.roc</a></code>, 
<code><a href="#topic+print.fbroc.roc">print.fbroc.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rep(c(TRUE, FALSE), each = 500)
x &lt;- rnorm(1000) + y
result.boot &lt;- boot.roc(x, y)
</code></pre>

<hr>
<h2 id='boot.tpr.at.fpr'>Process bootstrapped TPR/FPR at thresholds matrix into TPR at FPR matrix</h2><span id='topic+boot.tpr.at.fpr'></span>

<h3>Description</h3>

<p>Usually <code>fbroc</code> calculates the TPR and FPR at the thresholds of the ROC curve.
per bootstrap replicate. This can be calculated quickly, but is often not convenient
to work with. Therefore <code>boot.tpr.at.fpr</code> instead gets the TPR along a sequence
of different values for the FPR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.tpr.at.fpr(roc, steps = roc$n.neg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.tpr.at.fpr_+3A_roc">roc</code></td>
<td>
<p>Object of class <code>fbroc.roc</code>.</p>
</td></tr>
<tr><td><code id="boot.tpr.at.fpr_+3A_steps">steps</code></td>
<td>
<p>Number of discrete steps for the FPR at which the TPR is 
calculated. TPR confidence intervals are given for all FPRs in 
<code>seq(0, 1, by = (1 / steps))</code>. Defaults to <code>n.neg</code>, thus covering all possible values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix containing the TPR bootstrap replicates for the discrete
FPR steps.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.roc">boot.roc</a></code>
</p>

<hr>
<h2 id='conf'>Generic S3 function to calculate confidence regions for ROC curves</h2><span id='topic+conf'></span>

<h3>Description</h3>

<p>For using this on individual ROC curves as implemented by objects of class <code>fbroc.roc</code> see 
<code><a href="#topic+conf.fbroc.roc">conf.fbroc.roc</a></code>. For paired ROC curves (class <code>conf.paired.roc</code>) see 
<code><a href="#topic+conf.fbroc.paired.roc">conf.fbroc.paired.roc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf(roc, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf_+3A_roc">roc</code></td>
<td>
<p>The object for which to calculate the performance.</p>
</td></tr>
<tr><td><code id="conf_+3A_...">...</code></td>
<td>
<p>Further arguments to perf.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+conf.fbroc.roc">conf.fbroc.roc</a></code>, <code><a href="#topic+conf.fbroc.paired.roc">conf.fbroc.paired.roc</a></code>
</p>

<hr>
<h2 id='conf.fbroc.paired.roc'>Generates confidence intervals for the difference in TPR between two predictors for a range of FPRs or vice versa</h2><span id='topic+conf.fbroc.paired.roc'></span>

<h3>Description</h3>

<p>Calculates confidence intervals for the difference in TPR at different FPR values or vice versa. The stepsize
at which the TPR or FPR is calculated can be set as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.paired.roc'
conf(roc, conf.level = 0.95,
  conf.for = "TPR", steps = 250, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf.fbroc.paired.roc_+3A_roc">roc</code></td>
<td>
<p>An object of class <code>fbroc.paired.roc</code>.</p>
</td></tr>
<tr><td><code id="conf.fbroc.paired.roc_+3A_conf.level">conf.level</code></td>
<td>
<p>Confidence level to be used for the confidence intervals. Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="conf.fbroc.paired.roc_+3A_conf.for">conf.for</code></td>
<td>
<p>Use &quot;tpr&quot; to get confidence regions for the TPR at specific FPRs. Use &quot;fpr&quot;
instead for confidence regions for the FPR at specific TPRs.</p>
</td></tr>
<tr><td><code id="conf.fbroc.paired.roc_+3A_steps">steps</code></td>
<td>
<p>Number of discrete steps at which the requested rate and the confidence region is calculated.
Defaults to 250.</p>
</td></tr>
<tr><td><code id="conf.fbroc.paired.roc_+3A_...">...</code></td>
<td>
<p>Further arguments, that are not used at this time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing either discrete TPR steps and estimates and confidence bounds for
the difference FPR or vice versa, depending upon <code>conf.for</code>.
</p>


<h3>Details</h3>

<p>This function only gives estimates and confidence for the difference in the requested rate
(either True Positive Rate or False Positive Rate) between the first and the second classifier.
The values given are positive iff the first classifier has a higher rate. To get confidence regions
for either of the two underlying ROC curves use <code>conf</code> on the result of <code>extract.roc</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.paired.roc">boot.paired.roc</a></code>, <code><a href="#topic+conf.fbroc.roc">conf.fbroc.roc</a></code>,<code><a href="#topic+extract.roc">extract.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier,
                           roc.examples$True.Class, n.boot = 100)
conf(example, conf.for = "tpr", steps = 10) # get confidence regions for Delta TPR at FPR
conf(example, conf.for = "fpr", steps = 10) # get confidence regions for Delta FPR at TPR
</code></pre>

<hr>
<h2 id='conf.fbroc.roc'>Generates confidence intervals for the TPR for a range of FPRs or vice versa</h2><span id='topic+conf.fbroc.roc'></span>

<h3>Description</h3>

<p>Calculates confidence intervals for the TPR at different FPR values or vice versa. The stepsize
at which the TPR or FPR is calculated can be set as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.roc'
conf(roc, conf.level = 0.95, conf.for = "tpr",
  steps = 250, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf.fbroc.roc_+3A_roc">roc</code></td>
<td>
<p>Object of class <code>fbroc.roc</code>.</p>
</td></tr>
<tr><td><code id="conf.fbroc.roc_+3A_conf.level">conf.level</code></td>
<td>
<p>Confidence level to be used for the confidence intervals. Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="conf.fbroc.roc_+3A_conf.for">conf.for</code></td>
<td>
<p>Use &quot;tpr&quot; to get confidence regions for the TPR at specific FPRs. Use &quot;fpr&quot;
instead for confidence regions for the FPR at specific TPRs.</p>
</td></tr>
<tr><td><code id="conf.fbroc.roc_+3A_steps">steps</code></td>
<td>
<p>Number of discrete steps at which the requested rate and the confidence region is calculated.
Defaults to 250.</p>
</td></tr>
<tr><td><code id="conf.fbroc.roc_+3A_...">...</code></td>
<td>
<p>Further arguments, that are not used at this time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing either discrete TPR steps and estimates and confidence bounds for
FPR or vice versa, depending upon <code>conf.for</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.roc">boot.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.roc(roc.examples$Cont.Pred, roc.examples$True.Class,
                    n.boot = 100)
conf(example, conf.for = "tpr", steps = 10) # get confidence regions for TPR at FPR
conf(example, conf.for = "fpr", steps = 10) # get confidence regions for FPR at TPR
</code></pre>

<hr>
<h2 id='extract.roc'>Extracts one from two paired ROC curves from a <code>fbroc.paired.roc</code> object</h2><span id='topic+extract.roc'></span>

<h3>Description</h3>

<p>Given paired ROC curves it can be helpful to look at them in isolation as well. 
This functions allows the extraction of one of the paired ROC
curves as a <code>fbroc.roc</code> object without recalculating the ROC curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.roc(x, index)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract.roc_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.paired.roc</code>.</p>
</td></tr>
<tr><td><code id="extract.roc_+3A_index">index</code></td>
<td>
<p>A number specifying which of the two ROC curves should be returned. Needs to be 1 or 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>fbroc.roc</code> containing all data about the requested ROC curve
</p>


<h3>Note</h3>

<p>Due to the way the predictions are reordered internally, using use.cache to save the bootstrap
results for paired ROC curves and then extracting one of the two curves will not yield the same
values as when the ROC curve is bootstrapped as a single curve using <code>fbroc.roc</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.paired.roc">boot.paired.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier, 
                           roc.examples$True.Class, n.boot = 100)
roc1 &lt;- extract.roc(example, 1)
roc1.equivalent &lt;- boot.roc(roc.examples$Cont.Pred, roc.examples$True.Class, 
                            n.boot = 100)
print(identical(roc1, roc1.equivalent)) # roc1 and roc1.equivalent will be the same
# This does not hold when use.cache = TRUE. See the note above.
</code></pre>

<hr>
<h2 id='fbroc'>fbroc: A package for fast bootstrap analysis and comparison of ROC curves</h2><span id='topic+fbroc'></span><span id='topic+fbroc-package'></span>

<h3>Description</h3>

<p>Fbroc enables the fast bootstrap analysis and comparison of ROC curves for simulation
studies and shiny applications by using a fast
algorithm where the cost of a single bootstrap replicate is <code class="reqn">O(n)</code>, with 
n denoting the number of observations. The algorithm is implemented in C++ to further
increase the efficiency. On a typical desktop computer the time needed for the calculation of 
100000 bootstrap replicates given 500 observations requires time on the order of magnitude 
of one second. The ROC curve as used shows
the True Positive Rate (TPR) as a function of the False Positive Rate (FPR). The package also
support the analysis of paired ROC curves, where we compare two predictions given for the same
set of samples.
</p>


<h3>Important fbroc functions</h3>


<dl>
<dt><code><a href="#topic+boot.roc">boot.roc</a></code></dt><dd><p>Use <code>boot.roc</code> to bootstrap a ROC curve.</p>
</dd>
<dt><code><a href="#topic+boot.paired.roc">boot.paired.roc</a></code></dt><dd><p>Use <code>boot.paired.roc</code> to bootstrap two paired ROC curves.</p>
</dd>
<dt><code><a href="#topic+conf">conf</a></code></dt><dd><p>Calculate confidence regions for the ROC curve.</p>
</dd>
<dt><code><a href="#topic+perf">perf</a></code></dt><dd><p>Estimate performance and calculate confidence
intervals.</p>
</dd>
</dl>



<h3>Example Data</h3>

<p>fbroc also contains the example data set <a href="#topic+roc.examples">roc.examples</a>, 
which you can use to test the functionality of the
package. This data set contains simulated data and not an real application.
</p>


<h3>Details</h3>

<p>The algorithm works by first determining the critical thresholds of the ROC
curve - cutoffs at which the curve changes directions. Each observation is then linked
to the specific thresholds at which they first cause a change in the TPR
or FPR. Calculating this link and directly bootstrapping that link
allows us to construct the bootstrapped ROC
curve very quickly. Since multiple observation can be linked to the same
threshold, it is difficult to implement the algorithm efficiently in R. 
This is why <code>fbroc</code> implements it in C++.
<br /> <br />
When bootstrapping paired ROC curves, the packages takes care of using the same set of samples
for both predictors in each iteration of the bootstrap. This preserves the correlation structure
between both predictors.
<br /> <br />
All bootstrap confidence interval are based on the percentile method.
</p>


<h3>Notes</h3>

<p>Package <code>fbroc</code> is still in an early development stage. Currently it supports bootstrapping
the confidence region of single and paired ROC curves, as well as the AUC, partial AUC, 
the FPR at a fixed TPR and vice versa.
More sophisticated bootstrap confidence interval 
calculation and improved documentation will be added at a later time.
</p>


<h3>References</h3>

<p>Efron, B., &amp; Tibshirani, R. (1998). <em>An introduction to the bootstrap.</em>
Boca Raton, Fla: Chapman &amp; Hall/CRC.
</p>
<p>Donna Katzman McClish. (1989). <em>Analyzing a Portion of the ROC Curve.</em>
Medical Decision Making, <a href="http://mdm.sagepub.com/content/9/3/190.abstract">http://mdm.sagepub.com/content/9/3/190.abstract</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
# work with a single ROC curves
result.boot &lt;- boot.roc(roc.examples$Cont.Pred, roc.examples$True.Class, n.boot = 100)
plot(result.boot)
perf(result.boot, "auc")
perf(result.boot, "auc", conf.level = 0.99)
perf(result.boot, "tpr", conf.level = 0.95, fpr = 0.1)
conf(result.boot, steps = 10)
# work with paired ROC curves
result.boot &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier, 
                               roc.examples$True.Class, n.boot = 100)
plot(result.boot)
perf(result.boot, "auc")
perf(result.boot, "auc", conf.level = 0.99)
perf(result.boot, "tpr", conf.level = 0.95, fpr = 0.1)
conf(result.boot, steps = 10)
</code></pre>

<hr>
<h2 id='perf'>Generic S3 function to calculate performance estimates for ROC curves</h2><span id='topic+perf'></span>

<h3>Description</h3>

<p>For using this on individual ROC curves as implemented by objects of class <code>fbroc.roc</code> see 
<code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code>. For paired ROC curves (class <code>fbroc.paired.roc</code>) see 
<code><a href="#topic+perf.fbroc.paired.roc">perf.fbroc.paired.roc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perf(roc, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perf_+3A_roc">roc</code></td>
<td>
<p>The object for which to calculate the performance.</p>
</td></tr>
<tr><td><code id="perf_+3A_...">...</code></td>
<td>
<p>Further arguments to perf.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code>, <code><a href="#topic+perf.fbroc.paired.roc">perf.fbroc.paired.roc</a></code>
</p>

<hr>
<h2 id='perf.fbroc.paired.roc'>Calculate performance for paired bootstrapped ROC curves</h2><span id='topic+perf.fbroc.paired.roc'></span>

<h3>Description</h3>

<p>For a given metric this calculates the difference in performance between two paired predictors
stored in an object of class <code>fbroc.paired.roc</code> in addition to their individual performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.paired.roc'
perf(roc, metric = "auc", conf.level = 0.95,
  tpr = NULL, fpr = NULL, correct.partial.auc = TRUE,
  show.partial.auc.warning = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perf.fbroc.paired.roc_+3A_roc">roc</code></td>
<td>
<p>An object of class <code>fbroc.paired.roc</code>.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_metric">metric</code></td>
<td>
<p>A performance metric. Select &quot;auc&quot; for the AUC, &quot;partial.auc&quot; for the partial AUC, 
&quot;tpr&quot; for the TPR at a fixed FPR and &quot;fpr&quot; for the FPR at a fixed TPR.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_conf.level">conf.level</code></td>
<td>
<p>The confidence level of the confidence interval.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_tpr">tpr</code></td>
<td>
<p>The fixed TPR at which the FPR is to be evaluated when <code>fpr</code> is selected as metric.
If partial AUC is investigated, then an TPR interval over which the partial area is to be calculated.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_fpr">fpr</code></td>
<td>
<p>The fixed FPR at which the TPR is to be evaluated when <code>tpr</code> is selected as metric.
If partial AUC is investigated, then an FPR interval over which the partial area is to be calculated.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_correct.partial.auc">correct.partial.auc</code></td>
<td>
<p>Corrects partial AUC for easier interpretation using McClish correction.
Details are given below. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_show.partial.auc.warning">show.partial.auc.warning</code></td>
<td>
<p>Whether to give warnings for partial AUCs below 0.5. Defaults to
true.</p>
</td></tr>
<tr><td><code id="perf.fbroc.paired.roc_+3A_...">...</code></td>
<td>
<p>Further arguments, that are not used at this time.</p>
</td></tr>
</table>


<h3>Note on partial AUC correction</h3>

<p>The partial AUC is hard to interpret without considering the range on which it is calculated.
Not only does the partial AUC scale with the width of the interval over which it is calculated,
but it also depends on where the interval is located.
For example, if the ROC Curve is integrated over the FPR interval [0, 0.1] a completely random
and non-discrimate classifier would have a partial AUC of 0.05, but the same ROC curve integrated over
the interval [0.9, 1] would yield a partial AUC of 0.95.
</p>
<p>The correction by McClish produces a corrected partial AUC given by:
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{2} \Big(1 + \frac{\textrm{partialAUC} - \textrm{auc.min}}{\textrm{auc.max} 
- \textrm{auc.min}}\Big)</code>
</p>

<p>Here auc.min is the AUC achieved by the non-discriminate classifier and auc.max is the AUC
achieved by a perfect classifier. Thus, a non-discriminative classifier will always have an AUC
of 0.5 and a perfect one classifier will always have a partial AUCs of 1. 
</p>
<p>Unfortunately, the corrected partial AUC cannot be interpreted in a meaningful way if the curve
is below the non-discriminate classifier, producing corrected partial AUCs values below 0.5. 
For this reason, fbroc will give a warning if the bootstrap produces corrected 
partial AUC values below 0.5.
</p>


<h3>References</h3>

<p>Donna Katzman McClish. (1989). <em>Analyzing a Portion of the ROC Curve.</em>
Medical Decision Making, <a href="http://mdm.sagepub.com/content/9/3/190.abstract">http://mdm.sagepub.com/content/9/3/190.abstract</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier,
                               roc.examples$True.Class, n.boot = 100)
perf(example, metric = "auc")   
# Get difference in TPR at a FPR of 20%   
perf(example, metric = "tpr", fpr = 0.2)    
perf(example, metric = "partial.auc", fpr = c(0, 0.25), 
     show.partial.auc.warning = FALSE)                       
</code></pre>

<hr>
<h2 id='perf.fbroc.roc'>Calculate performance for bootstrapped ROC curve</h2><span id='topic+perf.fbroc.roc'></span>

<h3>Description</h3>

<p>Calculates different performance metric for ROC curves based on the bootstrap
results saved in an object of class <code>fbroc.roc</code>. Confidence intervals
are included.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.roc'
perf(roc, metric = "auc", conf.level = 0.95,
  tpr = NULL, fpr = NULL, correct.partial.auc = TRUE,
  show.partial.auc.warning = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perf.fbroc.roc_+3A_roc">roc</code></td>
<td>
<p>An object of class <code>fbroc.roc</code>.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_metric">metric</code></td>
<td>
<p>A performance metric. Select &quot;auc&quot; for the AUC, &quot;partial.auc&quot; for the partial AUC, 
&quot;tpr&quot; for the TPR at a fixed FPR and &quot;fpr&quot; for the FPR at a fixed TPR.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_conf.level">conf.level</code></td>
<td>
<p>The confidence level of the confidence interval.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_tpr">tpr</code></td>
<td>
<p>The fixed TPR at which the FPR is to be evaluated when <code>fpr</code> is selected as metric.
If partial AUC is investigated, then an TPR interval over which the partial area is to be calculated.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_fpr">fpr</code></td>
<td>
<p>The fixed FPR at which the TPR is to be evaluated when <code>tpr</code> is selected as metric.
If partial AUC is investigated, then an FPR interval over which the partial area is to be calculated.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_correct.partial.auc">correct.partial.auc</code></td>
<td>
<p>Corrects partial AUC for easier interpretation using McClish correction.
Details are given below. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_show.partial.auc.warning">show.partial.auc.warning</code></td>
<td>
<p>Whether to give warnings for partial AUCs below 0.5. Defaults to
true.</p>
</td></tr>
<tr><td><code id="perf.fbroc.roc_+3A_...">...</code></td>
<td>
<p>Further arguments, that are not used at this time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>fbroc.perf</code>, containing the elements:
</p>
<table>
<tr><td><code>Observed.Performance</code></td>
<td>
<p>The observed performance.</p>
</td></tr>
<tr><td><code>CI.Performance</code></td>
<td>
<p>Quantile based confidence interval for the performance.</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>
<p>Confidence level of the confidence interval.</p>
</td></tr>
<tr><td><code>metric</code></td>
<td>
<p>Used performance metric.</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>Parameters used to further specifiy metric, e.g. fixed TPR.</p>
</td></tr>
<tr><td><code>n.boot</code></td>
<td>
<p>Number of bootstrap replicates used.</p>
</td></tr>
<tr><td><code>boot.results</code></td>
<td>
<p>Performance in each bootstrap replicate.</p>
</td></tr>
</table>


<h3>Note on partial AUC correction</h3>

<p>The partial AUC is hard to interpret without considering the range on which it is calculated.
Not only does the partial AUC scale with the width of the interval over which it is calculated,
but it also depends on where the interval is located.
For example, if the ROC Curve is integrated over the FPR interval [0, 0.1] a completely random
and non-discrimate classifier would have a partial AUC of 0.05, but the same ROC curve integrated over
the interval [0.9, 1] would yield a partial AUC of 0.95.
</p>
<p>The correction by McClish produces a corrected partial AUC given by:
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{2} \Big(1 + \frac{\textrm{partialAUC} - \textrm{auc.min}}{\textrm{auc.max} 
- \textrm{auc.min}}\Big)</code>
</p>

<p>Here auc.min is the AUC achieved by the non-discriminate classifier and auc.max is the AUC
achieved by a perfect classifier. Thus, a non-discriminative classifier will always have an AUC
of 0.5 and a perfect one classifier will always have a partial AUCs of 1. 
</p>
<p>Unfortunately, the corrected partial AUC cannot be interpreted in a meaningful way if the curve
is below the non-discriminate classifier, producing corrected partial AUCs values below 0.5. 
For this reason, fbroc will give a warning if the bootstrap produces corrected 
partial AUC values below 0.5.
</p>


<h3>References</h3>

<p>Donna Katzman McClish. (1989). <em>Analyzing a Portion of the ROC Curve.</em>
Medical Decision Making, <a href="http://mdm.sagepub.com/content/9/3/190.abstract">http://mdm.sagepub.com/content/9/3/190.abstract</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.roc">boot.roc</a></code>, <code><a href="#topic+print.fbroc.perf">print.fbroc.perf</a></code>, 
<code><a href="#topic+plot.fbroc.perf">plot.fbroc.perf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rep(c(TRUE, FALSE), each = 100)
x &lt;- rnorm(200) + y
result.boot &lt;- boot.roc(x, y, n.boot = 100)
perf(result.boot, "auc")
perf(result.boot, "auc", conf.level = 0.99)
perf(result.boot, "partial.auc", fpr = c(0, 0.25), show.partial.auc.warning = FALSE)
</code></pre>

<hr>
<h2 id='plot.fbroc.conf'>Plots function for object of classfbroc.conf</h2><span id='topic+plot.fbroc.conf'></span>

<h3>Description</h3>

<p>Given an object of class <code>fbroc.conf</code> this function plots the contained estimates for 
the confidence region of the ROC curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.conf'
plot(x, col = "blue", fill = "royalblue1",
  print.plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fbroc.conf_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.conf</code> to be plotted.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf_+3A_col">col</code></td>
<td>
<p>Color of the curve to be drawn.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf_+3A_fill">fill</code></td>
<td>
<p>Fill of the confidence region.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf_+3A_print.plot">print.plot</code></td>
<td>
<p>Logical specifying whether the plot should be printed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot, so that the user can customize the plot further.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+conf.fbroc.roc">conf.fbroc.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.roc(roc.examples$Cont.Pred, roc.examples$True.Class, n.boot = 100)
# Confidence regions for TPR at specific FPR values
tpr.conf &lt;- conf(example, conf.for = "tpr", steps = 50) 
plot(tpr.conf)
# Confidence regions for FPR at specific TPR values
fpr.conf &lt;- conf(example, conf.for = "fpr", steps = 50) 
plot(fpr.conf) 
</code></pre>

<hr>
<h2 id='plot.fbroc.conf.paired'>Plots function for object of class <code>fbroc.conf.paired</code></h2><span id='topic+plot.fbroc.conf.paired'></span>

<h3>Description</h3>

<p>Given an object of class <code>fbroc.conf.paired</code> this function plots the contained estimates for 
the confidence region of the <em>difference</em> between the two individual ROC curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.conf.paired'
plot(x, col = "blue", fill = "royalblue1",
  print.plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fbroc.conf.paired_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.conf.paired</code> to be plotted.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf.paired_+3A_col">col</code></td>
<td>
<p>Color of the curve to be drawn.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf.paired_+3A_fill">fill</code></td>
<td>
<p>Fill of the confidence region.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf.paired_+3A_print.plot">print.plot</code></td>
<td>
<p>Logical specifying whether the plot should be printed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.conf.paired_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot, so that the user can customize the plot further.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+conf.fbroc.paired.roc">conf.fbroc.paired.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier,
                           roc.examples$True.Class, n.boot = 1000)
# Confidence regions for the difference in TPR at specific FPR values                           
tpr.conf &lt;- conf(example, conf.for = "tpr", steps = 50)
plot(tpr.conf)
# Confidence regions for the difference in FPR at specific TPR values 
fpr.conf &lt;- conf(example, conf.for = "fpr", steps = 50)
plot(fpr.conf) 
</code></pre>

<hr>
<h2 id='plot.fbroc.paired.roc'>Plots a <code>fbroc.paired.roc</code> object</h2><span id='topic+plot.fbroc.paired.roc'></span>

<h3>Description</h3>

<p>Plots a <code>fbroc.paired.roc</code> object and shows the two paired ROC curves. The confidence
regions for the ROC curves and the performance estimates and confidence bounds for a specified metric 
can also be included in the plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.paired.roc'
plot(x, col1 = "blue", fill1 = "dodgerblue",
  col2 = "darkgreen", fill2 = "seagreen1", print.plot = TRUE,
  show.conf = TRUE, conf.level = 0.95, steps = 250,
  show.metric = NULL, show.area = !show.conf, text.size.perf = 6,
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fbroc.paired.roc_+3A_x">x</code></td>
<td>
<p>An object of class  <code>fbroc.paired.roc</code>.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_col1">col1</code></td>
<td>
<p>Color in which the ROC curve of the first classifier is drawn.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_fill1">fill1</code></td>
<td>
<p>Color used for areas (confidence regions, AUCs and partial AUCs) belonging
to the first ROC curve.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_col2">col2</code></td>
<td>
<p>Color in which the ROC curve of the second classifier is drawn.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_fill2">fill2</code></td>
<td>
<p>Color used for areas (confidence regions, AUCs and partial AUCs) belonging
to the second ROC curve.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_print.plot">print.plot</code></td>
<td>
<p>Logical specifying whether the plot should be printed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_show.conf">show.conf</code></td>
<td>
<p>Logical specifying whether the confidence region should be
plotted.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_conf.level">conf.level</code></td>
<td>
<p>Confidence level of the confidence region.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_steps">steps</code></td>
<td>
<p>Number of discrete steps for the FPR at which the TPR is 
calculated. TPR confidence intervals are given for all FPRs in 
<code>seq(0, 1, by = (1 / steps))</code>. Defaults to 250.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_show.metric">show.metric</code></td>
<td>
<p>Character specifying which metric to display. See 
<code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code> for details. Defaults to <code>NULL</code>, which means
that no metric is displayed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_show.area">show.area</code></td>
<td>
<p>Whether to shade the AUC or partial AUC area. Defaults to !show.conf.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_text.size.perf">text.size.perf</code></td>
<td>
<p>Size of the text display when show.metric is set to <code>TRUE</code>.
Defaults to 6.</p>
</td></tr>
<tr><td><code id="plot.fbroc.paired.roc_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+perf.fbroc.paired.roc">perf.fbroc.paired.roc</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot, so that the user can customize the plot further.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.paired.roc">boot.paired.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier,
                           roc.examples$True.Class, n.boot = 100)
plot(example) # standard plot, no metric shown
plot(example, show.metric = "auc") # Include information about the AUC
plot(example, show.metric = "auc", show.conf = FALSE) # Show area instead
# Highlight TPR at an FPR of 20% 
plot(example, show.metric = "tpr", fpr = 0.2)    
plot(example, show.metric = "partial.auc", fpr = c(0.2, 0.4), 
     show.conf = FALSE, show.partial.auc.warning = FALSE) # Show area                  
</code></pre>

<hr>
<h2 id='plot.fbroc.perf'>Plots ROC based performance metric as histogram</h2><span id='topic+plot.fbroc.perf'></span>

<h3>Description</h3>

<p>Given an object of class <code>fbroc.perf</code> this function plots the results of
the bootstrap as a histogram. The confidence interval is also included by
default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.perf'
plot(x, bins = NULL, col = "white",
  fill = "lightblue", print.plot = TRUE, show.conf = TRUE,
  conf.text = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fbroc.perf_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.perf</code> to be plotted.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_bins">bins</code></td>
<td>
<p>Number of bins for histogram. Default value depends on the number of bootstrap
values and the number of unique bootstrap performance values.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_col">col</code></td>
<td>
<p>Color of outline of histogram bars. Defaults to white.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_fill">fill</code></td>
<td>
<p>Fill of histogram bars. Defaults to lightblue.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_print.plot">print.plot</code></td>
<td>
<p>Logical specifying whether the plot should be printed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_show.conf">show.conf</code></td>
<td>
<p>Logical specifying whether the confidence interval
should be displayed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_conf.text">conf.text</code></td>
<td>
<p>Logical specifying whether the confidence interval limits
should also be displayed as text.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot, so that the user can customize the plot further.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rep(c(TRUE, FALSE), each = 500)
x &lt;- rnorm(1000) + y
result.boot &lt;- boot.roc(x, y, n.boot = 1000)
result.perf &lt;- perf(result.boot, "auc")
plot(result.perf)
</code></pre>

<hr>
<h2 id='plot.fbroc.perf.paired'>Plots the difference between the bootstrapped performance estimate of the first and the second
classifier.</h2><span id='topic+plot.fbroc.perf.paired'></span>

<h3>Description</h3>

<p>Given an object of class <code>fbroc.perf.paired</code> this function plots the difference between the 
bootstrapped performance estimate of the first and the second classifier as a histogram. 
the bootstrap as an histogram. The confidence interval is also shown by
default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.perf.paired'
plot(x, bins = NULL, col = "white",
  fill = "lightblue", print.plot = TRUE, show.conf = TRUE,
  conf.text = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fbroc.perf.paired_+3A_x">x</code></td>
<td>
<p>An object of class <code>fbroc.perf.paired</code>.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_bins">bins</code></td>
<td>
<p>Number of bins for histogram. Default value depends on the number of bootstrap
values and the number of unique bootstrap performance values.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_col">col</code></td>
<td>
<p>Color of outline of histogram bars. Defaults to white.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_fill">fill</code></td>
<td>
<p>Fill of histogram bars. Defaults to lightblue.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_print.plot">print.plot</code></td>
<td>
<p>Logical specifying whether the plot should be printed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_show.conf">show.conf</code></td>
<td>
<p>Logical specifying whether the confidence interval
should be displayed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_conf.text">conf.text</code></td>
<td>
<p>Logical specifying whether the confidence interval limits
should also be displayed as text.</p>
</td></tr>
<tr><td><code id="plot.fbroc.perf.paired_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot, so that the user can customize the plot further.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perf.fbroc.paired.roc">perf.fbroc.paired.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(roc.examples)
example &lt;- boot.paired.roc(roc.examples$Cont.Pred, roc.examples$Cont.Pred.Outlier, 
                           roc.examples$True.Class, n.boot = 100)
auc.diff &lt;- perf(example, "auc")
plot(auc.diff)
</code></pre>

<hr>
<h2 id='plot.fbroc.roc'>Plots a <code>fbroc.roc</code> object</h2><span id='topic+plot.fbroc.roc'></span>

<h3>Description</h3>

<p>Plot a <code>fbroc.roc</code> object and shows the ROC curve. The confidence
region for the ROC curve and the result for a specified performance metric 
can also be included in the plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.roc'
plot(x, col = "blue", fill = "royalblue1",
  print.plot = TRUE, show.conf = TRUE, steps = 250,
  conf.level = 0.95, show.metric = NULL, text.size.perf = 6,
  show.area = !show.conf, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fbroc.roc_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.roc</code>.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_col">col</code></td>
<td>
<p>Color used for the curve. Defaults to blue.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_fill">fill</code></td>
<td>
<p>Color used for areas (confidence regions, AUCs and partial AUCs).</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_print.plot">print.plot</code></td>
<td>
<p>Logical specifying whether the plot should be printed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_show.conf">show.conf</code></td>
<td>
<p>Logical specifying whether the confidence region should be
plotted.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_steps">steps</code></td>
<td>
<p>Number of discrete steps for the FPR at which the TPR is 
calculated. TPR confidence intervals are given for all FPRs in 
<code>seq(0, 1, by = (1 / steps))</code>. Defaults to 250.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_conf.level">conf.level</code></td>
<td>
<p>Confidence level of the confidence region.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_show.metric">show.metric</code></td>
<td>
<p>Character specifying which metric to display. See 
<code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code> for details. Defaults to <code>NULL</code>, which means
that no metric is displayed.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_text.size.perf">text.size.perf</code></td>
<td>
<p>Size of the text display when show.metric is set to <code>TRUE</code>.
Defaults to 6.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_show.area">show.area</code></td>
<td>
<p>Whether to shade the AUC or partial AUC area. Defaults to !show.conf.</p>
</td></tr>
<tr><td><code id="plot.fbroc.roc_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot, so that the user can customize the plot further.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.roc">boot.roc</a></code>, <code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rep(c(TRUE, FALSE), each = 100)
x &lt;- rnorm(200) + y
result.boot &lt;- boot.roc(x, y, n.boot = 100)
plot(result.boot)
plot(result.boot, show.metric = "auc")
plot(result.boot, show.metric = "auc", show.conf = FALSE) # show area instead
plot(result.boot, show.metric = "tpr", fpr = 0.2)
plot(result.boot, show.metric = "partial.auc", fpr = c(0, 0.5),
     show.partial.auc.warning = FALSE)
plot(result.boot, show.metric = "partial.auc", fpr = c(0, 0.5), show.conf = FALSE,
     show.partial.auc.warning = FALSE)  # show area instead
</code></pre>

<hr>
<h2 id='print.fbroc.perf'>Prints information about a <code>fbroc.perf</code> object</h2><span id='topic+print.fbroc.perf'></span>

<h3>Description</h3>

<p>Prints the information about the bootstrap results for an object of class
<code>fbroc.perf</code>. This information includes the number of bootstrap
replicates, the metric used and the estimate with confidence interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.perf'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fbroc.perf_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.perf</code>.</p>
</td></tr>
<tr><td><code id="print.fbroc.perf_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character containing the text that is also printed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perf.fbroc.roc">perf.fbroc.roc</a></code>
</p>

<hr>
<h2 id='print.fbroc.perf.paired'>Prints information about a <code>fbroc.perf.paired</code> object</h2><span id='topic+print.fbroc.perf.paired'></span>

<h3>Description</h3>

<p>Prints the information about the bootstrap results for an object of class
<code>fbroc.perf.paired</code>. This information includes the number of bootstrap
replicates, the metric used and estimates for both the individual classifiers and the
difference in performance including confidence intervals. Finally, an estimate for the 
correlation between the performance estimates of the two classifiers is also given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.perf.paired'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fbroc.perf.paired_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.perf</code>.</p>
</td></tr>
<tr><td><code id="print.fbroc.perf.paired_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character containing the text that is also printed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perf.fbroc.paired.roc">perf.fbroc.paired.roc</a></code>
</p>

<hr>
<h2 id='print.fbroc.roc'>Prints information about a <code>fbroc.roc</code> object</h2><span id='topic+print.fbroc.roc'></span>

<h3>Description</h3>

<p>Prints the information about the bootstrap results for an object of class
<code>fbroc.roc</code>. This information includes the number of bootstrap
replicates, the time spent on bootstrapping, the AUC and the memory
usage of the object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbroc.roc'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.fbroc.roc_+3A_x">x</code></td>
<td>
<p>Object of class <code>fbroc.roc</code>.</p>
</td></tr>
<tr><td><code id="print.fbroc.roc_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character containing the text that is also printed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.roc">boot.roc</a></code>
</p>

<hr>
<h2 id='roc.examples'>Examples of predictions for ROC curve construction</h2><span id='topic+roc.examples'></span>

<h3>Description</h3>

<p>Contains simulated data that can be used as examples for generating ROC curves. Both a continuous
and a discrete predictor are included. For both cases there is a version with outliers and one
without.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roc.examples
</code></pre>


<h3>Format</h3>

<p>A data.frame with 160 rows and 5 variables:
</p>

<dl>
<dt>True.Class</dt><dd><p>True class label of the observation</p>
</dd>
<dt>Cont.Pred</dt><dd><p>Predictions for which the binormal model for ROC curves holds. Predictions for
both the positive and negative class follows a normal distribution with unit standard deviation
and means 2 and 0 respectively.</p>
</dd>
<dt>Cont.Pred.Outlier</dt><dd><p>Same as above, with some extreme outliers in the negative class.</p>
</dd>
<dt>Disc.Pred</dt><dd><p>Example of a discrete predictor. Predictions for the negative class are integer 
values between 1 and 8, positive samples have integer predictions between 7 and 14.</p>
</dd>
<dt>Disc.Pred.Outlier</dt><dd><p>Same as above, with some extreme outliers in the negative class.</p>
</dd>
</dl>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
