<!DOCTYPE html><html><head><title>Help for package pdfsearch</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pdfsearch}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#convert_tokens'><p>Ability to tokenize words.</p></a></li>
<li><a href='#heading_search'><p>Function to locate sections of pdf</p></a></li>
<li><a href='#keyword_directory'><p>Wrapper for keyword search function</p></a></li>
<li><a href='#keyword_search'><p>Search a pdf file for keywords</p></a></li>
<li><a href='#run_shiny'><p>Run Shiny Application Demo</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Title:</td>
<td>Search Tools for PDF Files</td>
</tr>
<tr>
<td>Description:</td>
<td>Includes functions for keyword search of pdf files. There is
    also a wrapper that includes searching of all files within a single
    directory.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>pdftools, tibble, tokenizers, stringi</td>
</tr>
<tr>
<td>Suggests:</td>
<td>shiny, testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brandon LeBeau &lt;lebebr01+pdfsearch@gmail.com&gt;</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lebebr01/pdfsearch">https://github.com/lebebr01/pdfsearch</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lebebr01/pdfsearch/issues">https://github.com/lebebr01/pdfsearch/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-01-09 19:08:00 UTC; lebeb</td>
</tr>
<tr>
<td>Author:</td>
<td>Brandon LeBeau [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-01-09 19:30:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='convert_tokens'>Ability to tokenize words.</h2><span id='topic+convert_tokens'></span>

<h3>Description</h3>

<p>Ability to tokenize words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_tokens(x, path = FALSE, split_pdf = FALSE,
  remove_hyphen = TRUE, token_function = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert_tokens_+3A_x">x</code></td>
<td>
<p>The text of the pdf file. This can be specified directly 
or the pdftools package is used to read the pdf file from a file path. 
To use the pdftools, the path argument must be set to TRUE.</p>
</td></tr>
<tr><td><code id="convert_tokens_+3A_path">path</code></td>
<td>
<p>An optional path designation for the location of the pdf to be 
converted to text. The pdftools package is used for this conversion.</p>
</td></tr>
<tr><td><code id="convert_tokens_+3A_split_pdf">split_pdf</code></td>
<td>
<p>TRUE/FALSE indicating whether to split the pdf using white 
space. This would be most useful with multicolumn pdf files. 
The split_pdf function attempts to recreate the column layout of the text 
into a single column starting with the left column and proceeding to the 
right.</p>
</td></tr>
<tr><td><code id="convert_tokens_+3A_remove_hyphen">remove_hyphen</code></td>
<td>
<p>TRUE/FALSE indicating whether hyphenated words should
be adjusted to combine onto a single line. Default is TRUE.</p>
</td></tr>
<tr><td><code id="convert_tokens_+3A_token_function">token_function</code></td>
<td>
<p>This is a function from the tokenizers package. Default
is the tokenize_words function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of character vectors containing the tokens. More detail can 
be found looking at the documentation of the tokenizers package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> file &lt;- system.file('pdf', '1610.00147.pdf', package = 'pdfsearch')
 convert_tokens(file, path = TRUE) 

</code></pre>

<hr>
<h2 id='heading_search'>Function to locate sections of pdf</h2><span id='topic+heading_search'></span>

<h3>Description</h3>

<p>The ability to extract the location of the text and separate by sections. 
The function will return the headings with their location in the pdf.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heading_search(x, headings, path = FALSE, pdf_toc = FALSE,
  full_line = FALSE, ignore_case = FALSE, split_pdf = FALSE,
  convert_sentence = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heading_search_+3A_x">x</code></td>
<td>
<p>Either the text of the pdf read in with the pdftools package or a 
path for the location of the pdf file.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_headings">headings</code></td>
<td>
<p>A character vector representing the headings to search for.
Can be NULL if pdf_toc = TRUE.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_path">path</code></td>
<td>
<p>An optional path designation for the location of the pdf to be 
converted to text. The pdftools package is used for this conversion.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_pdf_toc">pdf_toc</code></td>
<td>
<p>TRUE/FALSE whether the pdf_toc function should be used from
the <code>pdftools</code> package. This is most useful if the pdf has 
the table of contents embedded within the pdf.
Must specify path = TRUE if pdf_toc = TRUE.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_full_line">full_line</code></td>
<td>
<p>TRUE/FALSE indicating whether the headings should reside on
their own line. This can create problems with multiple column pdfs.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_ignore_case">ignore_case</code></td>
<td>
<p>TRUE/FALSE/vector of TRUE/FALSE, indicating whether the 
case of the keyword matters. 
Default is FALSE meaning that case of the headings keywords are literal. 
If a vector, must be same length as the headings vector.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_split_pdf">split_pdf</code></td>
<td>
<p>TRUE/FALSE indicating whether to split the pdf using white 
space. This would be most useful with multicolumn pdf files. 
The split_pdf function attempts to recreate the column layout of the text 
into a single column starting with the left column and proceeding to the 
right.</p>
</td></tr>
<tr><td><code id="heading_search_+3A_convert_sentence">convert_sentence</code></td>
<td>
<p>TRUE/FALSE indicating if individual lines of PDF file
should be collapsed into a single large paragraph to perform keyword 
searching. Default is FALSE</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>file &lt;- system.file('pdf', '1501.00450.pdf', package = 'pdfsearch')

heading_search(file, headings = c('abstract', 'introduction'),
  path = TRUE)

</code></pre>

<hr>
<h2 id='keyword_directory'>Wrapper for keyword search function</h2><span id='topic+keyword_directory'></span>

<h3>Description</h3>

<p>This will use the keyword_search function to loop over all pdf files in a 
directory. Includes the ability to include subdirectories as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keyword_directory(directory, keyword, split_pdf = FALSE,
  surround_lines = FALSE, ignore_case = FALSE, remove_hyphen = TRUE,
  token_results = TRUE, convert_sentence = TRUE,
  split_pattern = "\\p{WHITE_SPACE}{3,}", full_names = TRUE,
  file_pattern = ".pdf", recursive = FALSE, max_search = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keyword_directory_+3A_directory">directory</code></td>
<td>
<p>The directory to perform the search for pdf files to search.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_keyword">keyword</code></td>
<td>
<p>The keyword(s) to be used to search in the text. Multiple 
keywords can be specified with a character vector.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_split_pdf">split_pdf</code></td>
<td>
<p>TRUE/FALSE indicating whether to split the pdf using white 
space. This would be most useful with multicolumn pdf files. 
The split_pdf function attempts to recreate the column layout of the text 
into a single column starting with the left column and proceeding to the 
right.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_surround_lines">surround_lines</code></td>
<td>
<p>numeric/FALSE indicating whether the output should 
extract the surrouding lines of text in addition to the matching line. 
Default is FALSE, if not false, include a numeric number that indicates 
the additional number of surrounding lines that will be extracted.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_ignore_case">ignore_case</code></td>
<td>
<p>TRUE/FALSE/vector of TRUE/FALSE, indicating whether the 
case of the keyword matters. 
Default is FALSE meaning that case of the keyword is literal. If a vector, 
must be same length as the keyword vector.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_remove_hyphen">remove_hyphen</code></td>
<td>
<p>TRUE/FALSE indicating whether hyphenated words should
be adjusted to combine onto a single line. Default is TRUE.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_token_results">token_results</code></td>
<td>
<p>TRUE/FALSE indicating whether the results text returned
should be split into tokens. See the tokenizers package and 
<code><a href="#topic+convert_tokens">convert_tokens</a></code> for more details. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_convert_sentence">convert_sentence</code></td>
<td>
<p>TRUE/FALSE indicating if individual lines of PDF file
should be collapsed into a single large paragraph to perform keyword 
searching. Default is TRUE</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_split_pattern">split_pattern</code></td>
<td>
<p>Regular expression pattern used to split multicolumn 
PDF files using <code>stringi::stri_split_regex</code>. 
Default pattern is &quot;\pWHITE_SPACE3,&quot; which can be interpreted as: 
split based on three or more consecutive white space characters.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_full_names">full_names</code></td>
<td>
<p>TRUE/FALSE indicating if the full file path should be used.
Default is TRUE, see <code><a href="base.html#topic+list.files">list.files</a></code> for more details.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_file_pattern">file_pattern</code></td>
<td>
<p>An optional regular expression to select specific file
names. Only files that match the regular expression will be searched. 
Defaults to all pdfs, i.e. <code>".pdf"</code>. See <code><a href="base.html#topic+list.files">list.files</a></code> 
for more details.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_recursive">recursive</code></td>
<td>
<p>TRUE/FALSE indicating if subdirectories should be searched 
as well.
Default is FALSE, see <code><a href="base.html#topic+list.files">list.files</a></code> for more details.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_max_search">max_search</code></td>
<td>
<p>An optional numeric vector indicating the maximum number
of pdfs to search. Will only search the first n cases.</p>
</td></tr>
<tr><td><code id="keyword_directory_+3A_...">...</code></td>
<td>
<p>token_function to pass to <code><a href="#topic+convert_tokens">convert_tokens</a></code> 
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble data frame that contains the keyword, location of match, 
the line of text match, and optionally the tokens associated with the line
of text match. The output is combined (row binded) for all pdf input files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># find directory
directory &lt;- system.file('pdf', package = 'pdfsearch')

# do search over two files
keyword_directory(directory, 
       keyword = c('repeated measures', 'measurement error'),
       surround_lines = 1, full_names = TRUE)
       
# can also split pdfs
keyword_directory(directory, 
       keyword = c('repeated measures', 'measurement error'),
       split_pdf = TRUE, remove_hyphen = FALSE,
       surround_lines = 1, full_names = TRUE)


</code></pre>

<hr>
<h2 id='keyword_search'>Search a pdf file for keywords</h2><span id='topic+keyword_search'></span>

<h3>Description</h3>

<p>This uses the pdf_text from the pdftools package to perform keyword searches. 
Keyword locations indicating the line of the text as well as the page number 
that the keyword is found are returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keyword_search(x, keyword, path = FALSE, split_pdf = FALSE,
  surround_lines = FALSE, ignore_case = FALSE, remove_hyphen = TRUE,
  token_results = TRUE, heading_search = FALSE, heading_args = NULL,
  convert_sentence = TRUE, split_pattern = "\\p{WHITE_SPACE}{3,}",
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keyword_search_+3A_x">x</code></td>
<td>
<p>Either the text of the pdf read in with the pdftools package or a 
path for the location of the pdf file.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_keyword">keyword</code></td>
<td>
<p>The keyword(s) to be used to search in the text. Multiple 
keywords can be specified with a character vector.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_path">path</code></td>
<td>
<p>An optional path designation for the location of the pdf to be 
converted to text. The pdftools package is used for this conversion.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_split_pdf">split_pdf</code></td>
<td>
<p>TRUE/FALSE indicating whether to split the pdf using white 
space. This would be most useful with multicolumn pdf files. 
The split_pdf function attempts to recreate the column layout of the text 
into a single column starting with the left column and proceeding to the 
right.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_surround_lines">surround_lines</code></td>
<td>
<p>numeric/FALSE indicating whether the output should 
extract the surrouding lines of text in addition to the matching line. 
Default is FALSE, if not false, include a numeric number that indicates 
the additional number of surrounding lines that will be extracted.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_ignore_case">ignore_case</code></td>
<td>
<p>TRUE/FALSE/vector of TRUE/FALSE, indicating whether the 
case of the keyword matters. Default is FALSE meaning that case of the 
keyword is literal. If a vector, must be same length as the keyword 
vector.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_remove_hyphen">remove_hyphen</code></td>
<td>
<p>TRUE/FALSE indicating whether hyphenated words should
be adjusted to combine onto a single line. Default is TRUE.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_token_results">token_results</code></td>
<td>
<p>TRUE/FALSE indicating whether the results text returned
should be split into tokens. See the tokenizers package and 
<code><a href="#topic+convert_tokens">convert_tokens</a></code> for more details. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_heading_search">heading_search</code></td>
<td>
<p>TRUE/FALSE indicating whether to search for headings 
in the pdf.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_heading_args">heading_args</code></td>
<td>
<p>A list of arguments to pass on to the 
<code><a href="#topic+heading_search">heading_search</a></code> function. See <code><a href="#topic+heading_search">heading_search</a></code> 
for more details on arguments needed.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_convert_sentence">convert_sentence</code></td>
<td>
<p>TRUE/FALSE indicating if individual lines of PDF file
should be collapsed into a single large paragraph to perform keyword 
searching. Default is TRUE</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_split_pattern">split_pattern</code></td>
<td>
<p>Regular expression pattern used to split multicolumn 
PDF files using <code>stringi::stri_split_regex</code>. 
Default pattern is &quot;\pWHITE_SPACE3,&quot; which can be interpreted as: 
split based on three or more consecutive white space characters.</p>
</td></tr>
<tr><td><code id="keyword_search_+3A_...">...</code></td>
<td>
<p>token_function to pass to <code><a href="#topic+convert_tokens">convert_tokens</a></code> 
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble data frame that contains the keyword, location of match, 
the line of text match, and optionally the tokens associated with the line
of text match.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>file &lt;- system.file('pdf', '1501.00450.pdf', package = 'pdfsearch')

keyword_search(file, keyword = c('repeated measures', 'mixed effects'),
  path = TRUE)
  
# Add surrounding text
keyword_search(file, keyword = c('variance', 'mixed effects'),
  path = TRUE, surround_lines = 1)
  
# split pdf
keyword_search(file, keyword = c('repeated measures', 'mixed effects'),
  path = TRUE, split_pdf = TRUE, remove_hyphen = FALSE)

</code></pre>

<hr>
<h2 id='run_shiny'>Run Shiny Application Demo</h2><span id='topic+run_shiny'></span>

<h3>Description</h3>

<p>Function runs Shiny Application Demo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_shiny()
</code></pre>


<h3>Details</h3>

<p>This function does not take any arguments and will run the Shiny Application.
If running from RStudio, will open the application in the viewer, 
otherwise will use the default internet browser.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
run_shiny()


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
