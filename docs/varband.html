<!DOCTYPE html><html lang="en"><head><title>Help for package varband</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {varband}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ar_gen'><p>Generate an autoregressive model.</p></a></li>
<li><a href='#block_diag_gen'><p>Generate a model with block-diagonal structure</p></a></li>
<li><a href='#matimage'><p>Plot the sparsity pattern of a square matrix</p></a></li>
<li><a href='#sample_gen'><p>Generate random samples.</p></a></li>
<li><a href='#varband'><p>Compute the varband estimate for a fixed tuning parameter value with different penalty options.</p></a></li>
<li><a href='#varband_cv'><p>Perform nfolds-cross validation</p></a></li>
<li><a href='#varband_gen'><p>Generate a model with variable bandwidth.</p></a></li>
<li><a href='#varband_path'><p>Solve main optimization problem along a path of lambda</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Banding of Large Precision Matrices</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the variable banding procedure for modeling local dependence and estimating precision matrices that is introduced in Yu &amp; Bien (2016) and is available at <a href="https://arxiv.org/abs/1604.07451">https://arxiv.org/abs/1604.07451</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://github.com/hugogogo/varband">http://github.com/hugogogo/varband</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/hugogogo/varband/issues">http://github.com/hugogogo/varband/issues</a></td>
</tr>
<tr>
<td>Collate:</td>
<td>'model_gen.R' 'refit.R' 'varband_cv.R' 'varband_path.R'
'RcppExports.R' 'misc.R' 'utils.R'</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, stats, graphics</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-11-07 15:19:39 UTC; hugo</td>
</tr>
<tr>
<td>Author:</td>
<td>Guo Yu [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Guo Yu &lt;gy63@cornell.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-11-07 21:07:55</td>
</tr>
</table>
<hr>
<h2 id='ar_gen'>Generate an autoregressive model.</h2><span id='topic+ar_gen'></span>

<h3>Description</h3>

<p>Generate lower triangular matrix with strict bandwidth. See, e.g., Model 1 in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ar_gen(p, phi_vec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ar_gen_+3A_p">p</code></td>
<td>
<p>the dimension of L</p>
</td></tr>
<tr><td><code id="ar_gen_+3A_phi_vec">phi_vec</code></td>
<td>
<p>a K-dimensional vector for off-diagonal values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a p-by-p strictly banded lower triangular matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>true_ar &lt;- ar_gen(p = 50, phi = c(0.5, -0.4, 0.1))
</code></pre>

<hr>
<h2 id='block_diag_gen'>Generate a model with block-diagonal structure</h2><span id='topic+block_diag_gen'></span>

<h3>Description</h3>

<p>Generate a model with block-diagonal structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>block_diag_gen(p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="block_diag_gen_+3A_p">p</code></td>
<td>
<p>the dimension of L</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a p-by-p lower triangular matrix with block-diagonal structure from p/4-th row to 3p/4-th row
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
true_L_block_diag &lt;- block_diag_gen(p = 50)
</code></pre>

<hr>
<h2 id='matimage'>Plot the sparsity pattern of a square matrix</h2><span id='topic+matimage'></span>

<h3>Description</h3>

<p>Black, white and gray stand for positive, zero and negative respectively
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matimage(Mat, main = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matimage_+3A_mat">Mat</code></td>
<td>
<p>A matrix to plot.</p>
</td></tr>
<tr><td><code id="matimage_+3A_main">main</code></td>
<td>
<p>A plot title.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
p &lt;- 50
n &lt;- 50
phi &lt;- 0.4
true &lt;- varband_gen(p = p, block = 5)
matimage(true)
</code></pre>

<hr>
<h2 id='sample_gen'>Generate random samples.</h2><span id='topic+sample_gen'></span>

<h3>Description</h3>

<p>Generate <code>n</code> random samples from multivariate Gaussian distribution N(0, (L^TL)^-1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_gen(L, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_gen_+3A_l">L</code></td>
<td>
<p>p-dimensional inverse Cholesky factor of true covariance matrix.</p>
</td></tr>
<tr><td><code id="sample_gen_+3A_n">n</code></td>
<td>
<p>number of samples to generate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a n-by-p matrix with each row a random sample generated.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
true &lt;- varband_gen(p = 50, block = 5)
x &lt;- sample_gen(L = true, n = 100)
</code></pre>

<hr>
<h2 id='varband'>Compute the varband estimate for a fixed tuning parameter value with different penalty options.</h2><span id='topic+varband'></span>

<h3>Description</h3>

<p>Solves the main optimization problem in Yu &amp; Bien (2016):
</p>
<p style="text-align: center;"><code class="reqn">min_L -2 \sum_{r=1}^p L_{rr} + tr(SLL^T) + lam * \sum_{r=2}^p P_r(L_{r.})</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">P_r(L_{r.}) = \sum_{\ell = 2}^{r-1} \left(\sum_{m=1}^\ell w_{\ell m}^2 L_{rm}^2\right)^{1/2}</code>
</p>

<p>or </p>
<p style="text-align: center;"><code class="reqn">P_r(L_{r.}) = \sum_{\ell = 1}^{r-1} |L_{r\ell}|</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>varband(S, lambda, init, w = FALSE, lasso = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varband_+3A_s">S</code></td>
<td>
<p>The sample covariance matrix</p>
</td></tr>
<tr><td><code id="varband_+3A_lambda">lambda</code></td>
<td>
<p>Non-negative tuning parameter. Controls sparsity level.</p>
</td></tr>
<tr><td><code id="varband_+3A_init">init</code></td>
<td>
<p>Initial estimate of L. Default is a closed-form diagonal estimate of L.</p>
</td></tr>
<tr><td><code id="varband_+3A_w">w</code></td>
<td>
<p>Logical. Should we use weighted version of the penalty or not? If <code>TRUE</code>, we use general weight. If <code>FALSE</code>, use unweighted penalty. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="varband_+3A_lasso">lasso</code></td>
<td>
<p>Logical. Should we use l1 penalty instead of hierarchical group lasso penalty? Note that by using l1 penalty, we lose the banded structure in the resulting estimate. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function decomposes into p independent row problems,
each of which is solved by an ADMM algorithm.
see paper for more explanation.
</p>


<h3>Value</h3>

<p>Returns the variable banding estimate of L, where L^TL = Omega.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varband_path">varband_path</a></code> <code><a href="#topic+varband_cv">varband_cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 50
true &lt;- varband_gen(p = 50, block = 5)
x &lt;- sample_gen(L = true, n = n)
S &lt;- crossprod(scale(x, center = TRUE, scale = FALSE)) / n
init &lt;- diag(1/sqrt(diag(S)))
# unweighted estimate
L_unweighted &lt;- varband(S, lambda = 0.1, init, w = FALSE)
# weighted estimate
L_weighted &lt;- varband(S, lambda = 0.1, init, w = TRUE)
# lasso estimate
L_lasso &lt;- varband(S, lambda = 0.1, init, w = TRUE, lasso = TRUE)
</code></pre>

<hr>
<h2 id='varband_cv'>Perform nfolds-cross validation</h2><span id='topic+varband_cv'></span>

<h3>Description</h3>

<p>Select tuning parameter by cross validation according to the likelihood on testing data, with and without refitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varband_cv(x, w = FALSE, lasso = FALSE, lamlist = NULL, nlam = 60,
  flmin = 0.01, folds = NULL, nfolds = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varband_cv_+3A_x">x</code></td>
<td>
<p>A n-by-p sample matrix, each row is an observation of the p-dim random vector.</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_w">w</code></td>
<td>
<p>Logical. Should we use weighted version of the penalty or not? If <code>TRUE</code>, we use general weight. If <code>FALSE</code>, use unweighted penalty. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_lasso">lasso</code></td>
<td>
<p>Logical. Should we use l1 penalty instead of hierarchical group lasso penalty? Note that by using l1 penalty, we lose the banded structure in the resulting estimate. And when using l1 penalty, the becomes CSCS (Convex Sparse Cholesky Selection) introduced in Khare et al. (2016). Default value for <code>lasso</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_lamlist">lamlist</code></td>
<td>
<p>A list of non-negative tuning parameters <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_nlam">nlam</code></td>
<td>
<p>If lamlist is not provided, create a lamlist with length <code>nulam</code>. Default is 60.</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_flmin">flmin</code></td>
<td>
<p>If lamlist is not provided, create a lamlist with ratio of the smallest and largest lambda in the list equal to <code>flmin</code>. Default is 0.01.</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_folds">folds</code></td>
<td>
<p>Folds used in cross-validation</p>
</td></tr>
<tr><td><code id="varband_cv_+3A_nfolds">nfolds</code></td>
<td>
<p>If folds are not provided, create folds of size <code>nfolds</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list object containing </p>

<dl>
<dt>errs_fit: </dt><dd><p>A <code>nlam</code>-by-<code>nfolds</code> matrix of negative Gaussian log-likelihood values on the CV test data sets. <code>errs[i,j]</code> is negative Gaussian log-likelihood values incurred in using <code>lamlist[i]</code> on fold <code>j</code></p>
</dd></dl>
<p>.
</p>
<dl>
<dt>errs_refit: </dt><dd><p>A <code>nlam</code>-by-<code>nfolds</code> matrix of negative Gaussian log-likelihood values of the refitting.</p>
</dd>
<dt>folds: </dt><dd><p>Folds used in cross validation.</p>
</dd>
<dt>lamlist: </dt><dd><p><code>lambda</code> grid used in cross validation.</p>
</dd>
<dt>ibest_fit: </dt><dd><p>index of <code>lamlist</code> minimizing CV negative Gaussian log-likelihood.</p>
</dd>
<dt>ibest_refit: </dt><dd><p>index of <code>lamlist</code> minimizing refitting CV negative Gaussian log-likelihood.</p>
</dd>
<dt>i1se_fit: </dt><dd><p>Selected value of <code>lambda</code> using the one-standard-error rule.</p>
</dd>
<dt>i1se_refit: </dt><dd><p>Selected value of <code>lambda</code> of the refitting process using the one-standard-error rule.</p>
</dd>
<dt>L_fit: </dt><dd><p>Estimate of L corresponding to <code>ibest_fit</code>.</p>
</dd>
<dt>L_refit: </dt><dd><p>Refitted estimate of L corresponding to <code>ibest_refit</code>.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+varband">varband</a></code> <code><a href="#topic+varband_path">varband_path</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
p &lt;- 50
n &lt;- 50
true &lt;- varband_gen(p = p, block = 5)
x &lt;- sample_gen(L = true, n = n)
res_cv &lt;- varband_cv(x = x, w = FALSE, nlam = 40, flmin = 0.03)
</code></pre>

<hr>
<h2 id='varband_gen'>Generate a model with variable bandwidth.</h2><span id='topic+varband_gen'></span>

<h3>Description</h3>

<p>Generate lower triangular matrix with variable bandwidth. See, e.g., Model 2 and 3 in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varband_gen(p, block = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varband_gen_+3A_p">p</code></td>
<td>
<p>the dimension of L</p>
</td></tr>
<tr><td><code id="varband_gen_+3A_block">block</code></td>
<td>
<p>the number of block diagonal structures in the resulting model, assumed to divide p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a p-by-p lower triangular matrix with variable bandwidth
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
# small block size (big number of blocks)
true_small &lt;- varband_gen(p = 50, block = 10)
# large block size (small number of blocks)
true_large &lt;- varband_gen(p = 50, block = 2)
</code></pre>

<hr>
<h2 id='varband_path'>Solve main optimization problem along a path of lambda</h2><span id='topic+varband_path'></span>

<h3>Description</h3>

<p>Compute the varband estimates along a path of tuning parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varband_path(S, w = FALSE, lasso = FALSE, lamlist = NULL, nlam = 60,
  flmin = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varband_path_+3A_s">S</code></td>
<td>
<p>The sample covariance matrix</p>
</td></tr>
<tr><td><code id="varband_path_+3A_w">w</code></td>
<td>
<p>Logical. Should we use weighted version of the penalty or not? If <code>TRUE</code>, we use general weight. If <code>FALSE</code>, use unweighted penalty. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="varband_path_+3A_lasso">lasso</code></td>
<td>
<p>Logical. Should we use l1 penalty instead of hierarchical group lasso penalty? Note that by using l1 penalty, we lose the banded structure in the resulting estimate. And when using l1 penalty, the becomes CSCS (Convex Sparse Cholesky Selection) introduced in Khare et al. (2016). Default value for <code>lasso</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="varband_path_+3A_lamlist">lamlist</code></td>
<td>
<p>A list of non-negative tuning parameters <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="varband_path_+3A_nlam">nlam</code></td>
<td>
<p>If lamlist is not provided, create a lamlist with length <code>node</code>. Default is 60.</p>
</td></tr>
<tr><td><code id="varband_path_+3A_flmin">flmin</code></td>
<td>
<p>if lamlist is not provided, create a lamlist with ratio of the smallest and largest lambda in the list. Default is 0.01.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list object containing </p>

<dl>
<dt>path: </dt><dd><p>A array of dim (<code>p</code>, <code>p</code>, <code>nlam</code>) of estimates of L</p>
</dd>
<dt>lamlist: </dt><dd><p>a grid values of tuning parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+varband">varband</a></code> <code><a href="#topic+varband_cv">varband_cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 50
true &lt;- varband_gen(p = 50, block = 5)
x &lt;- sample_gen(L = true, n = n)
S &lt;- crossprod(scale(x, center = TRUE, scale = FALSE))/n
path_res &lt;- varband_path(S = S, w = FALSE, nlam = 40, flmin = 0.03)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
