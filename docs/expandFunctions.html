<!DOCTYPE html><html lang="en"><head><title>Help for package expandFunctions</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {expandFunctions}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#expandFunctions'><p>expandFunctions: a feature matrix builder</p></a></li>
<li><a href='#coefPlot'><p>Plots coefficients in an impulse response format</p></a></li>
<li><a href='#distMat'><p>Make a matrix with coefficients distributed as dist</p></a></li>
<li><a href='#easyLASSO'><p>Select and fit sparse linear model with LASSO</p></a></li>
<li><a href='#eDiff'><p>Matrix size-preserving diff function</p></a></li>
<li><a href='#eLag'><p>Convert vector into a matrix of lag columns</p></a></li>
<li><a href='#eMatrixOuter'><p>Extends eOuter to allow a matrix for the first argument</p></a></li>
<li><a href='#eOuter'><p>Extend outer product.</p></a></li>
<li><a href='#ePow'><p>Convert vector x into a matrix <code class="reqn">X_{ij} = {x_i}^j</code></p></a></li>
<li><a href='#eQuad'><p>Multivariate second order polynomial expansion.</p></a></li>
<li><a href='#eReplace'><p>Replace values in an R object coerible to a matrix</p></a></li>
<li><a href='#eTrim'><p>Remove padded rows from matrix X</p></a></li>
<li><a href='#freemanTukey'><p>Freeman-Tukey transform</p></a></li>
<li><a href='#lagshift'><p>Helper function for eLag.</p></a></li>
<li><a href='#polywrapper'><p>Generate special functions using orthonormal functions</p></a></li>
<li><a href='#rapt'><p>Expand an input matrix X using raptObj.</p></a></li>
<li><a href='#raptMake'><p>Define a Random Affine Projection Transformation (RAPT) object</p></a></li>
<li><a href='#reset.warnings'><p>Reset annoyingly persistent warning messages.</p></a></li>
<li><a href='#Ydiagnostics'><p>Informative plots for Y and Yhat</p></a></li>
<li><a href='#yyHatPlot'><p>Plot y and yHat on the same scale w/reference line</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-09-19</td>
</tr>
<tr>
<td>Title:</td>
<td>Feature Matrix Builder</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, stats, graphics, plyr, orthopolynom, polynom, glmnet</td>
</tr>
<tr>
<td>Description:</td>
<td>Generates feature matrix outputs from R object inputs
    using a variety of expansion functions.  The generated
    feature matrices have applications as inputs
    for a variety of machine learning algorithms.
    The expansion functions are based on coercing the input
    to a matrix, treating the columns as features and
    converting individual columns or combinations into blocks of
    columns.
    Currently these include expansion of columns by
    efficient sparse embedding by vectors of lags,
    quadratic expansion into squares and unique products,
    powers by vectors of degree,
    vectors of orthogonal polynomials functions,
    and block random affine projection transformations (RAPTs).
    The transformations are
    magrittr- and cbind-friendly, and can be used in a
    building block fashion.  For instance, taking the cos() of
    the output of the RAPT transformation generates a
    stationary kernel expansion via Bochner's theorem, and this
    expansion can then be cbind-ed with other features.
    Additionally, there are utilities for replacing features,
    removing rows with NAs,
    creating matrix samples of a given distribution,
    a simple wrapper for LASSO with CV,
    a Freeman-Tukey transform,
    generalizations of the outer function,
    matrix size-preserving discrete difference by row,
    plotting, etc.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-10-01 02:05:07 UTC; scott</td>
</tr>
<tr>
<td>Author:</td>
<td>Scott Miller [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Scott Miller &lt;sam3CRAN@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-10-01 15:05:50</td>
</tr>
</table>
<hr>
<h2 id='expandFunctions'>expandFunctions: a feature matrix builder</h2><span id='topic+expandFunctions'></span><span id='topic+expandFunctions-package'></span>

<h3>Description</h3>

<p>A variety of  functions for conversion of
vectors and matrices to other matrices to use as
features.  This allows one to quickly build feature structures
and apply various machine learning methods to those features
for exploration and pedantic purposes.
</p>


<h3>Details</h3>

<p>The <strong>expandFunctions</strong> package contains functions
that can be used to expand feature vectors and matrices into
larger feature matrices.  These functions include lag
embedding, special function univariate exansion, quadratic
expansion, and random vector projection.
</p>
<p>The general steps for feature generation for time domain data
(which subsumes multivariate data via lags) are:
</p>

<ul>
<li><p>Preprocess data - remove mean, transform, etc., to a
useful vector or matrix.
</p>
</li>
<li><p>If not a matrix, functionally expand vector into a matrix.
This is
typically done by lag embedding, but may also include STFT, wavelet
transforms, etc.
</p>
</li>
<li><p>Functionally expand matrices generated.
</p>
</li>
<li><p>Combine resulting matrices into a single feature matrix.
</p>
</li>
<li><p>Dimensional reduction, feature selection, and/or
feature extraction to reduce the number of features.
</p>
</li>
<li><p>Use machine learning method(s) on the resulting feature
matrix.
</p>
</li></ul>

<p>Most of the steps above are well supported in <span class="rlang"><b>R</b></span> on CRAN, but the
expansion steps tend to be scattered in a variety of packages,
poorly represented, or custom built by the user.  The
<strong>expandFunction</strong> package is intended
to collect many of these functions together in one place.
</p>
<p>Preprocessing almost always should include centering and scaling the
data.  However, it may also include a variety of transformations,
such as Freeman-Tukey, in order to make the vector fit
more closely to a given model (say, a linear model with Gaussian
noise).
</p>
<p>If the input isn't a time domain vector, but is instead already
in tabular form (for instance, Boston Housing Data),
the embedding step can be skipped.
</p>
<p>Dimension reduction is outside the scope of this package, but
is normally performed to reduce the variables that need handling,
reducing the memory used and speeding up the analysis.
</p>
<p>The package functions are &quot;magrittr-friendly&quot;, that is,
built so that they can be directly pipelined since X, the data,
is the first argument.
</p>
<p>Most functions are prefixed with &quot;e&quot; to help distinguish them
from being confused with similarly named functions.
</p>


<h3>Author(s)</h3>

<p>Scott Miller &lt;sam3CRAN@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Sunspot counts can be somewhat Gaussianized by the
# Freeman-Tukey transform.
x &lt;- freemanTukey(sunspot.month)
par(mfrow=c(1,1)) # just in case multiplots were left over.
plot(x,type="l")

# Embed x using eLag
# Since the base period of sunspots is 11*12 months,
# pick the lags to be fractions of this.
myLags &lt;- seq(from=0,to=200,by=1)
X &lt;- eTrim(eLag(x,myLags))
Y &lt;- X[,+1,drop=FALSE]
X &lt;- X[,-1,drop=FALSE]
# matplot(X,type="l",lty=1)

# OLS fitting on the lag feature set
lmObj &lt;- lm(y ~ .,data = data.frame(x=X,y=Y))
coefPlot(lmObj,type="b")
summary(lmObj)
Yhat &lt;- predict(lmObj, newdata = data.frame(x=X))
Ydiagnostics(Y,Yhat)

# LASSO fitting on the lag feature set
lassoObj &lt;- easyLASSO(X,Y,criterion="lambda.min")
coefPlot(lassoObj,type="b")
Yhat &lt;- predict(lassoObj,newx = X)
Ydiagnostics(Y,Yhat)

# Reduce the lag feature set using non-zero
# LASSO coefficients
useCoef &lt;- coef(lassoObj)[-1]!=0
myLags &lt;- seq(from=0,to=200,by=1)[c(TRUE,useCoef)]
X &lt;- eTrim(eLag(x,myLags))
Y &lt;- X[,+1,drop=FALSE]
X &lt;- X[,-1,drop=FALSE]

# OLS fitting on the reduced lag feature set
lmObj &lt;- lm(y ~ .,data = data.frame(x=X,y=Y))
summary(lmObj)
coefPlot(lmObj)
Yhat &lt;- predict(lmObj, newdata = data.frame(x=X))
Ydiagnostics(Y,Yhat)

# 1st nonlinear feature set
# Apply a few Chebyshev functions to the columns of the
# lag matrix. Note these exclude the constant values,
# but include the linear.
chebyFUN &lt;- polywrapper(basePoly=orthopolynom::chebyshev.t.polynomials,
                        kMax=5)
Z &lt;- eMatrixOuter(X,1:5,chebyFUN)

# OLS fitting on the 1st nonlinear feature set
lmObj &lt;- lm(y ~ .,data = data.frame(z=Z,y=Y))
summary(lmObj)
Yhat &lt;- predict(lmObj, newdata = data.frame(z=Z))
Ydiagnostics(Y,Yhat)

# LASSO fitting on the 1st nonlinear feature set
lassoObj &lt;- easyLASSO(Z,Y)
coefPlot(lassoObj)
Yhat &lt;- predict(lassoObj,newx = Z)
Ydiagnostics(Y,Yhat)

# 2nd nonlinear feature set
# Use eQuad as an alternative expansion of the lags
Z &lt;- eQuad(X)

# OLS fitting on the 2nd nonlinear feature set
lmObj &lt;- lm(y ~ .,data = data.frame(z=Z,y=Y))
summary(lmObj)
Yhat &lt;- predict(lmObj, newdata = data.frame(z=Z))
Ydiagnostics(Y,Yhat)

# LASSO fitting on the 2nd nonlinear feature set
lassoObj &lt;- easyLASSO(Z,Y)
coefPlot(lassoObj)
Yhat &lt;- predict(lassoObj,newx = Z)
Ydiagnostics(Y,Yhat)

## End(Not run)

</code></pre>

<hr>
<h2 id='coefPlot'>Plots coefficients in an impulse response format</h2><span id='topic+coefPlot'></span>

<h3>Description</h3>

<p>Given a model xObj for which coef(xObj)
returns a set of coefficients, plot the coefficients.
</p>
<p>The plots make it easier to compare which features are large,
which are set to zero, and how features change from run
to run in a graphical manner.
</p>
<p>If the fitting process is linear (e.g. lm, glmnet, etc.)
and the original features are appropriately ordered lags,
this will generate an impulse response.
</p>
<p>Any coefficients that are <em>exactly</em> zero (for instance,
set that way by LASSO) will appear as red X's; non-zero
points will be black O's.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefPlot(xObj, includeIntercept = FALSE, type = "h", main = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coefPlot_+3A_xobj">xObj</code></td>
<td>
<p>Output of a fitting model.</p>
</td></tr>
<tr><td><code id="coefPlot_+3A_includeintercept">includeIntercept</code></td>
<td>
<p>Should the 1st coefficient be plotted?
Default is FALSE.</p>
</td></tr>
<tr><td><code id="coefPlot_+3A_type">type</code></td>
<td>
<p>Graphics type.  Default is &quot;h&quot;, which
results in an impulse-like plot.</p>
</td></tr>
<tr><td><code id="coefPlot_+3A_main">main</code></td>
<td>
<p>&quot;main&quot; title; default is the relative
number of non-zero coefficients,
a measure of sparsity.</p>
</td></tr>
<tr><td><code id="coefPlot_+3A_...">...</code></td>
<td>
<p>Optional additional graphical parameters,
for instance to set ylim to a fixed value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If includeIntercept==TRUE, the intercept of the model
will be plotted as index 0.
</p>
<p>Changing the type using <code>type="b"</code>
will result in a parallel coordinate-like plot rather
than an impulse-like plot.  It is sometimes easier to
see the differences in coefficients with type=&quot;b&quot;
rather than type=&quot;h&quot;.
</p>


<h3>Value</h3>

<p>Invisibly returns TRUE.  Used for its
graphic side effects only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
nObs &lt;- 100
X &lt;- distMat(nObs,6)
A &lt;- cbind(c(1,0,-1,rep(0,3))) # Y will only depend on X[,1] and X[,3]
Y &lt;- X %*% A + 0.1*rnorm(nObs)
lassoObj &lt;- easyLASSO(X,Y)
Yhat &lt;- predict(lassoObj,newx=X)
yyHatPlot(Y,Yhat)
coef( lassoObj ) # Sparse coefficients
coefPlot( lassoObj )
coefPlot( lassoObj, includeIntercept=TRUE )
coefPlot( lassoObj, type="b" )
</code></pre>

<hr>
<h2 id='distMat'>Make a matrix with coefficients distributed as dist</h2><span id='topic+distMat'></span>

<h3>Description</h3>

<p>Generate a pXq matrix with coefficients drawn
from the univariate distribution dist with
options distOpt.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distMat(p, q, dist = rnorm, distOpt = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distMat_+3A_p">p</code></td>
<td>
<p>Number of rows</p>
</td></tr>
<tr><td><code id="distMat_+3A_q">q</code></td>
<td>
<p>Number of columns</p>
</td></tr>
<tr><td><code id="distMat_+3A_dist">dist</code></td>
<td>
<p>distribution of coefficients to draw from;
default is rnorm.</p>
</td></tr>
<tr><td><code id="distMat_+3A_distopt">distOpt</code></td>
<td>
<p>Named list of additional parameters for dist.
<em>Always omit the first parameter,n, of the
distribution sampling function</em>. Defaults may
be omitted if desired (see examples).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user may provide their own distribution function,
but note that the number of values to return, n,
<em>must</em> be the first argument, just as with
the built-in distributions.  The first argument does
not have to be named.
</p>


<h3>Value</h3>

<p>A pXq matrix with coefficients distributed
as dist with parameters defined in '...'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- distMat(10,2)
X &lt;- distMat(10,2,distOpt=list(mean=1,sd=2))
X &lt;- distMat(5,3,rnorm,list(mean=1,sd=2))
X &lt;- distMat(5,3,rnorm,list(sd=2))
X &lt;- distMat(50,3,rt,list(df=3))
</code></pre>

<hr>
<h2 id='easyLASSO'>Select and fit sparse linear model with LASSO</h2><span id='topic+easyLASSO'></span>

<h3>Description</h3>

<p>The purpose of this function is to make the process
of LASSO modelling as simple as possible.
</p>
<p>This is a simple wrapper on two glmnet functions
which, when given input matrix X and response vector
y, and a criterion for model selection, will
estimate the lambda parameter, and return the
LASSO results as a glmnet model.  This model
can then be used to find coefficients and predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>easyLASSO(X, y, criterion = "lambda.1se")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="easyLASSO_+3A_x">X</code></td>
<td>
<p>Predictor matrix, nXp, with n observations and p
features.</p>
</td></tr>
<tr><td><code id="easyLASSO_+3A_y">y</code></td>
<td>
<p>Response vector, or column or row matrix.  Must
have length n.</p>
</td></tr>
<tr><td><code id="easyLASSO_+3A_criterion">criterion</code></td>
<td>
<p>String describing which lambda criterion to
use in selecting a LASSO model.  Choices
currently are c(&quot;lambda.1se&quot;,&quot;lambda.min&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a glmnet model
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code> and
<code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
nObs &lt;- 100
X &lt;- distMat(nObs,6)
A &lt;- cbind(c(1,0,-1,rep(0,3)))
  # Y will only depend on X[,1] and X[,3]
Y &lt;- X %*% A + 0.1*rnorm(nObs)
lassoObj &lt;- easyLASSO(X=X,y=Y) # LASSO fitting
Yhat &lt;- predict(lassoObj,newx=X)
yyHatPlot(Y,Yhat)
coef( lassoObj ) # Sparse coefficients
coefPlot( lassoObj )
</code></pre>

<hr>
<h2 id='eDiff'>Matrix size-preserving diff function</h2><span id='topic+eDiff'></span>

<h3>Description</h3>

<p>Returns a matrix, the same size as the
input matrix X, containing the back difference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eDiff(X, pad = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eDiff_+3A_x">X</code></td>
<td>
<p>R object coercible to matrix</p>
</td></tr>
<tr><td><code id="eDiff_+3A_pad">pad</code></td>
<td>
<p>Pad the first row with this value;
the default is NA. 0 would be another value often
used in signal processing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix, the same size as the
input matrix X, containing the back difference by column.
The first row is filled with copies of pad.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eDiff( 1:8 )
eDiff( as.data.frame(1:8) )
eDiff( matrix(1:8,ncol=2) )
</code></pre>

<hr>
<h2 id='eLag'>Convert vector into a matrix of lag columns</h2><span id='topic+eLag'></span>

<h3>Description</h3>

<p>Convert vector into a matrix of lag columns
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eLag(x, colParamVector, pad = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eLag_+3A_x">x</code></td>
<td>
<p>Data <em>vector</em></p>
</td></tr>
<tr><td><code id="eLag_+3A_colparamvector">colParamVector</code></td>
<td>
<p>Vector of lags for embedding</p>
</td></tr>
<tr><td><code id="eLag_+3A_pad">pad</code></td>
<td>
<p>Scalar for padding embedding</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix whose columns are x lagged by the
corresponding values in colParamVector.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+embed">embed</a></code> and
<code><a href="tseriesChaos.html#topic+embedd">embedd</a></code>, which
are related functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eLag(1:6, 0:2)
eLag(1:6, 0:2, pad=0)
</code></pre>

<hr>
<h2 id='eMatrixOuter'>Extends eOuter to allow a matrix for the first argument</h2><span id='topic+eMatrixOuter'></span>

<h3>Description</h3>

<p>Extends eOuter to allow a matrix for the first argument
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eMatrixOuter(X, colParamVector, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eMatrixOuter_+3A_x">X</code></td>
<td>
<p>R object coercible to a matrix
the columns of this will be the
argument of FUN (see below).</p>
</td></tr>
<tr><td><code id="eMatrixOuter_+3A_colparamvector">colParamVector</code></td>
<td>
<p>Vector input which will be the second
argument of FUN (see below).</p>
</td></tr>
<tr><td><code id="eMatrixOuter_+3A_fun">FUN</code></td>
<td>
<p>Function which will be applied to
FUN(X[,i],colParamVector[j],...)</p>
</td></tr>
<tr><td><code id="eMatrixOuter_+3A_...">...</code></td>
<td>
<p>Additional arguments to FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a simple extension of eOuter which allows
the function eOuter(X[,i],colParamVector,FUN,...) for
i in the columns of X.
</p>


<h3>Value</h3>

<p>Returns a matrix with the matrics generated by eOuter
for each column column bound together.  This means that each
row of the returned matrix represents single observations (at
least as long as no lags are used).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(1:6,ncol=2)
temp &lt;- eMatrixOuter(A,0:2,FUN=`^`)
</code></pre>

<hr>
<h2 id='eOuter'>Extend outer product.</h2><span id='topic+eOuter'></span>

<h3>Description</h3>

<p>Extends outer {base} <code>outer(x,y,FUN)</code> to include functions
<code>FUN(x,y,...)</code> where the first argument of <code>FUN</code>
is a vector but the second argument must be a scalar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eOuter(x, y, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eOuter_+3A_x">x</code></td>
<td>
<p>Vector, with the same function as
in outer {base}.  Each value will
correspond to a row in the return matrix.</p>
</td></tr>
<tr><td><code id="eOuter_+3A_y">y</code></td>
<td>
<p>Vector.  Each
element in the vector corresponds
to a column in the return matrix.</p>
</td></tr>
<tr><td><code id="eOuter_+3A_fun">FUN</code></td>
<td>
<p>Function. x and y will
be the first and second arguments.  Unlike
<code>outer</code>, however, while a vector can be the
first argument, FUN might only allow
<em>one value</em> as the
second argument.  This means eOuter
can use lagshift, for instance, as FUN.</p>
</td></tr>
<tr><td><code id="eOuter_+3A_...">...</code></td>
<td>
<p>Additional parameters for FUN.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>outer has limitations; it only works with functions which
can take vector inputs for <em>both</em>
the first and second arguments, such as &quot;^&quot;.  As a result,
many functions cannot be used for FUN.  The function eOuter
gets around this limitation by additionally allowing functions
which accept a vector for the first argument, but only scalars
for the second argument.  It can be used everywhere
that <code>outer</code> can be used, but also when FUN is
limited in this way.
</p>


<h3>Value</h3>

<p>A matrix <code>Z</code> of size
<code>length(x) X length(y)</code>
containing <code>Z[,i]</code> with values <code>FUN(x,y[i],...)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+outer">outer</a></code> and <code><a href="#topic+ePow">ePow</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This implements a function similar to ePow
# FIXME: change ePow to use eOuter!!!
eOuter(1:6,0:2,FUN = `^`)
# Other functions of columns
eOuter(1:10,0:3,FUN = lagshift,lagMax=3,pad=NA)
# FIXME: Make function to allow polynomials to be used:
# eOuter(1:10,1:3,FUN = glaguerre.polynomials, alpha=0.5)
</code></pre>

<hr>
<h2 id='ePow'>Convert vector x into a matrix <code class="reqn">X_{ij} = {x_i}^j</code></h2><span id='topic+ePow'></span>

<h3>Description</h3>

<p>Convert vector x into a matrix <code class="reqn">X_{ij} = {x_i}^j</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ePow(x, colParamVector)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ePow_+3A_x">x</code></td>
<td>
<p>Data vector.</p>
</td></tr>
<tr><td><code id="ePow_+3A_colparamvector">colParamVector</code></td>
<td>
<p>Vector of column powers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix X of size length(x) X length(colParamVector)
</p>
<p style="text-align: center;"><code class="reqn">X_{ij} = {x_i}^j</code>
</p>



<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:6
ePow(x,0:2)
</code></pre>

<hr>
<h2 id='eQuad'>Multivariate second order polynomial expansion.</h2><span id='topic+eQuad'></span>

<h3>Description</h3>

<p>Expand matrix columns into linear, square, and unique product columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eQuad(X, FUN = `*`, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eQuad_+3A_x">X</code></td>
<td>
<p>vector or matrix.  If a vector, it will be converted to
a column matrix.  If it is desired that the squares
and products of a <em>vector</em> are computed, pass rbind(X)
instead of X, and thereby pass a row matrix.</p>
</td></tr>
<tr><td><code id="eQuad_+3A_fun">FUN</code></td>
<td>
<p>Binary function which forms the products of the columns.
By default, this is '*', but other <em>commuting</em> operators
or kernels can be used if desired.</p>
</td></tr>
<tr><td><code id="eQuad_+3A_...">...</code></td>
<td>
<p>Options for FUN.  Not needed if FUN doesn't have options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Form a matrix with columns composed of  into linear, square, and
product columns:
</p>
<p style="text-align: center;"><code class="reqn">[X | FUN(X[,i], X[,j])]</code>
</p>

<p>where <code class="reqn">i, j</code> are the unique combinations of <code class="reqn">i</code> and <code class="reqn">j</code>,
including <code class="reqn">i=j</code>.
</p>
<p>By default, the function used to form the squares and
products, FUN, is just conventional multiplication = '*', but any
<em>commuting</em> binary operator can be used.
</p>
<p>This particular expansion is often applied in
</p>

<ul>
<li><p>General Method of Data Handling (GMDH).
</p>
</li>
<li><p>Nonlinear Slow Feature Analysis (SFA).  Performing
a multivariate polynomial of second degree expansion
in all the features, then
performing <em>linear</em> SFA on the resulting expanded
feature matrix, is a very common approach, and in fact
is the default method in <code>sfa2 {rSFA}</code>.
</p>
</li></ul>



<h3>Value</h3>

<p><code class="reqn">[X,X^2,unique products of columns of X]</code>.  The unique
products are in row major upper right triangular order.
Thus, for X with columns 1:3, the order is
</p>
<p style="text-align: center;"><code class="reqn">X[,1]^2, X[,2]^2, X[,3]^2,
      X[,1]*X[,2], X[,1]*X[,3], X[,2]*X[,3]</code>
</p>



<h3>See Also</h3>

<p><code><a href="rSFA.html#topic+sfa2">sfa2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># # Examples
# eQuad(1:5)
# eQuad(matrix(1:12,ncol=3),FUN=`+`)
</code></pre>

<hr>
<h2 id='eReplace'>Replace values in an R object coerible to a matrix</h2><span id='topic+eReplace'></span>

<h3>Description</h3>

<p>Replace values in an R object coerible to a matrix.
It is useful for replacing NA with other values, etc.,
such as with padding values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eReplace(X, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eReplace_+3A_x">X</code></td>
<td>
<p>R object coercible to a matrix</p>
</td></tr>
<tr><td><code id="eReplace_+3A_a">a</code></td>
<td>
<p>Value to be replaced</p>
</td></tr>
<tr><td><code id="eReplace_+3A_b">b</code></td>
<td>
<p>Value to replace</p>
</td></tr>
</table>


<h3>Value</h3>

<p>X with all a's replaced with b's.  a may be NA
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+replace">replace</a></code>, which performs the same
operation on vectors, and on which this operation is based.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(1:6,ncol=2)
A &lt;- eReplace(A,1,NA)
A &lt;- eReplace(A,NA,-9999)
A &lt;- eReplace(A,-9999,0)
</code></pre>

<hr>
<h2 id='eTrim'>Remove padded rows from matrix X</h2><span id='topic+eTrim'></span>

<h3>Description</h3>

<p>Remove padded rows from matrix X
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eTrim(X, pad = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eTrim_+3A_x">X</code></td>
<td>
<p>R object coercible to matrix</p>
</td></tr>
<tr><td><code id="eTrim_+3A_pad">pad</code></td>
<td>
<p>Value representing padded elements.  By
default it is NA, but could be any value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10
x &lt;- rnorm(n)    # x vector
X &lt;- eLag(x,0:1) # X matrix
t &lt;- 1:n         # time vector
T &lt;- eLag(t,0:1) # time matrix; the column corresponding
                 # to 0 is the time for each row,
                 # even after trimming
matplot(X,type="l",lty=1)
X &lt;- eTrim(X)
T &lt;- eTrim(T)
matplot(x=T[,1],y=X,type="l",lty=1,
  xlab="Time")
</code></pre>

<hr>
<h2 id='freemanTukey'>Freeman-Tukey transform</h2><span id='topic+freemanTukey'></span>

<h3>Description</h3>

<p>This transform takes Poisson (count) information and
makes it more Gaussian, then z-scales (standardizes
by centering and scaling to var = 1) the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freemanTukey(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="freemanTukey_+3A_x">x</code></td>
<td>
<p>Data vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformed vector
</p>


<h3>References</h3>

<p>Taken from
<a href="https://en.wikipedia.org/wiki/Anscombe_transform">https://en.wikipedia.org/wiki/Anscombe_transform</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- freemanTukey(sunspot.month)
</code></pre>

<hr>
<h2 id='lagshift'>Helper function for eLag.</h2><span id='topic+lagshift'></span>

<h3>Description</h3>

<p>Generates shifted columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagshift(x, i, lagMax, pad)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lagshift_+3A_x">x</code></td>
<td>
<p>Input vector</p>
</td></tr>
<tr><td><code id="lagshift_+3A_i">i</code></td>
<td>
<p>Shift (integer)</p>
</td></tr>
<tr><td><code id="lagshift_+3A_lagmax">lagMax</code></td>
<td>
<p>Maximum lag that will be needed</p>
</td></tr>
<tr><td><code id="lagshift_+3A_pad">pad</code></td>
<td>
<p>Scalar used for padding.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector padded front and back with padding appropriate
for generating lag.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lagshift(1:3,0,1,NA)
</code></pre>

<hr>
<h2 id='polywrapper'>Generate special functions using orthonormal functions</h2><span id='topic+polywrapper'></span>

<h3>Description</h3>

<p>orthopolynom can be used to generate special functions,
but for expansion they should be modified.  As of this
writing, orthopolynom generates polynomials for
Chebyshev, Hermite, Legendre and many other functions,
their integrals and derivatives, and more.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polywrapper(basePoly = orthopolynom::chebyshev.t.polynomials, kMax = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="polywrapper_+3A_basepoly">basePoly</code></td>
<td>
<p>A polynomial list from orthopoly</p>
</td></tr>
<tr><td><code id="polywrapper_+3A_kmax">kMax</code></td>
<td>
<p>Integer.  The maximum order of the function
generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function polywrapper does 2 things:
</p>

<ul>
<li><p>Generate functions from polynomial coefficients.
</p>
</li>
<li><p>Uses x as the 1st argument, and the order as
the second; this means the generated functions can be
used in eOuter and eMatrixOuter.
</p>
</li></ul>

<p>The functions so generated can be used as simple special functions,
as well as being useful in feature building.
</p>
<p>Since the coefficients from orthopolynom are generated
by recursion, an upper limit of the function order
needs to be set when calling polywrapper.  This is the
main limitation of polywrapper.  Fortunately, since
the functions are compactly stored, kMax can be set
quite high if desired.  Note that usually the kMax
is known, and is relatively small.
</p>
<p>NB: The input x may need to be normalized.  orthopolynom
has the function scaleX for just such a purpose.
</p>


<h3>Value</h3>

<p>Function which is compatible with eOuter and eMatrixOuter
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate a Chebyshev function of the form
# chebyFUN(x,k), where x is the input and k is the order.
# In this case, k must be no more than 5 (since that
# is the value passed to kMax), although it is
# easy to set this to a higher order if desired.
chebyFUN &lt;- polywrapper(basePoly=orthopolynom::chebyshev.t.polynomials,
  kMax=5)
# Now the function chebyFUN
# can be used as any other function:
x &lt;- seq(-1,+1,0.01)
plot(x,chebyFUN(x,5),type="l")
eOuter(seq(-1,+1,0.01),0:3,chebyFUN)
</code></pre>

<hr>
<h2 id='rapt'>Expand an input matrix X using raptObj.</h2><span id='topic+rapt'></span>

<h3>Description</h3>

<p>Expand an input matrix X using
a Random Affine Projection Transformation (RAPT) object.
Such objects use random affine projection transformation to the
resulting matrix.  This allows RAPT objects serve as a basis
for a large number of kinds of expansions.  If p are the
number of features of X, and q are number of expanded features,
the applications fall into two broad categories:
</p>

<ul>
<li><p>p &gt; q using the Johnson-Lindenstrauss theorem:
</p>

<ul>
<li><p>Compressed sensing.
</p>
</li>
<li><p>Manifold learning.
</p>
</li>
<li><p>Dimension reduction.
</p>
</li>
<li><p>Graph embedding.
</p>
</li>
<li><p>...
</p>
</li></ul>


</li>
<li><p>p &lt; q using Bochner's theorem:
</p>

<ul>
<li><p>Approximate kernel projection.
</p>
</li>
<li><p>Fast approximate SVD.
</p>
</li>
<li><p>Estimation of dependence.
</p>
</li>
<li><p>...
</p>
</li></ul>


</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>rapt(X, raptObj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rapt_+3A_x">X</code></td>
<td>
<p>Input data matrix</p>
</td></tr>
<tr><td><code id="rapt_+3A_raptobj">raptObj</code></td>
<td>
<p>raptObj generated by raptMake</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes
</p>
<p style="text-align: center;"><code class="reqn">X W + b</code>
</p>

<p>where
</p>
<p>W = raptObj$W
</p>
<p>b = raptObj$b
</p>


<h3>Value</h3>

<p>A matrix of randomly (but repeatable) features.
</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma">https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma</a>,
<a href="https://en.wikipedia.org/wiki/Bochner%27s_theorem">https://en.wikipedia.org/wiki/Bochner%27s_theorem</a>
</p>


<h3>See Also</h3>

<p>Details of how the rapt object is built
are in <code><a href="#topic+raptMake">raptMake</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Toy problem
set.seed(1)
nObs &lt;- 100 # Number of observations
X &lt;- matrix(seq(-4,+4,length.out = nObs),ncol=1)
Ytrue &lt;- sin(5*X) + 2*cos(2*X) # True value Ytrue = g(X)
Y &lt;- Ytrue + rnorm(nObs) # Noisy measurement Y

# Standardize X
Xstd &lt;- scale(X)
attributes(Xstd) &lt;- attributes(X)

# Bochner (random Fourier) projection object
nDim &lt;- NCOL(X)
h &lt;- 10 # Estimated by goodness of fit Adj R^2.
  # Normally this would be fit by cross validation.
raptObj &lt;- raptMake(nDim,nDim*200,WdistOpt = list(sd=h),
                    bDistOpt=list(min=-pi,max=+pi))

# Apply raptObj to Xstd to generate features,
# keeping unaltered features Xstd as well.
Xrapt &lt;- cbind( Xstd, cos( rapt(Xstd,raptObj) ) )

# Standardize results
XraptStd &lt;- scale(Xrapt)
attributes(XraptStd) &lt;- attributes(Xrapt)

# A linear fitting of Y to the features XraptStd
lmObj &lt;- lm(Y ~ XraptStd)
summary(lmObj)

# Plot measurements (Y), predictions (Yhat),
# Kernel smoothing with Gaussian kernel and same bandwidth,
# true Y without noise.
Yhat &lt;- predict(lmObj)
plot (X,Y   ,main="Linear Fitting", ylim=c(-6,10))
lines(X,Yhat,col="red",lty=1,lwd=2)
grid(col="darkgray")
kFit &lt;- ksmooth(X,Y,kernel="normal",bandwidth=1/h)
lines(kFit$x,kFit$y,lty=1,col="green",lwd=2)
lines(X,Ytrue,lty=1,col="blue",lwd=2)
legend("topleft",
        legend=c("Noisy measurements",
                 "Estimated Y from RAPT",
                 "Estimated Y from Kernel Smooth",
                 "True Y"),
        col=1:4,
        pch=c( 1,NA,NA,NA),
        lty=c(NA, 1, 1, 1),
        lwd=2,
        bty="n")

# Fit sparse model w/LASSO and
# lambda criteria = 1 standard deviation.
# This avoids overgeneralization errors usually
# associated with fitting large numbers of features
# to relatively few data points.  It also improves
# the end effects, which are of paramount importance
# in high dimensional problems (since by the curse
# of dimensionality, almost all points are close an edge
# in high dimensional problems).
lassoObj &lt;- easyLASSO(XraptStd,Y)
Yhat &lt;- predict(lassoObj, newx = XraptStd)
# Use linear fit of prediction Yhat as goodness of fit.
summary(lm(Y ~ Yhat))

# Plot results of LASSO fitting
# These show LASSO does a better job fitting edges.
plot(X,Y,main="LASSO Fitting",ylim=c(-6,10))
lines(X,Yhat,col="red",lty=1,lwd=2)
grid(col="darkgray")
kFit &lt;- ksmooth(X,Y,kernel="normal",bandwidth=1/h)
lines(kFit$x,kFit$y,lty=1,col="green",lwd=2)
lines(X,Ytrue,lty=1,col="blue",lwd=2)
legend("topleft",
        legend=c("Noisy measurements",
                 "Estimated Y from RAPT",
                 "Estimated Y from Kernel Smooth",
                 "True Y"),
        col=1:4,
        pch=c( 1,NA,NA,NA),
        lty=c(NA, 1, 1, 1),
        lwd=2,
        bty="n")
</code></pre>

<hr>
<h2 id='raptMake'>Define a Random Affine Projection Transformation (RAPT) object</h2><span id='topic+raptMake'></span>

<h3>Description</h3>

<p>Create a Random Affine Projection Transformation (RAPT) object.
Such objects use random affine projection transformation to the
resulting matrix.  This allows RAPT objects serve as a basis
for a large number of kinds of expansions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>raptMake(p, q, Wdist = rnorm, WdistOpt = NULL, bDist = runif,
  bDistOpt = list(min = 0, max = 0))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="raptMake_+3A_p">p</code></td>
<td>
<p>Number of input features (columns of <code>X</code>).</p>
</td></tr>
<tr><td><code id="raptMake_+3A_q">q</code></td>
<td>
<p>Number of output features,</p>
</td></tr>
<tr><td><code id="raptMake_+3A_wdist">Wdist</code></td>
<td>
<p>W distribution function.  Coefficients for
the random projection matrix W are drawn from
this distribution.  The default is rnorm.</p>
</td></tr>
<tr><td><code id="raptMake_+3A_wdistopt">WdistOpt</code></td>
<td>
<p>List of optional parameters for Wdist.
If this is NULL (default),
then only defaults of the distribution
are used.</p>
</td></tr>
<tr><td><code id="raptMake_+3A_bdist">bDist</code></td>
<td>
<p>b distribution function.  Coefficients for
the offset vector b are drawn from this
distribution.   The default is runif.</p>
</td></tr>
<tr><td><code id="raptMake_+3A_bdistopt">bDistOpt</code></td>
<td>
<p>List of optional parameters for bDist.
If this is NULL
then only defaults of the distribution
are used.  The default is
<code>bDistOpt=list(min=0,max=0)</code>,
which results in b = 0, with no offset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This initializes a eRAPTobj, which holds all the
parameters needed to perform a random projection
transformation expansion (RAPT).
</p>
<p>An RAPT of X is defined as
</p>
<p style="text-align: center;"><code class="reqn">X W + b</code>
</p>

<p>where
</p>
<p>X is the input matrix
</p>
<p>W is a matrix of coefficients drawn from Wdist with
options WdistOpt
</p>
<p>b is a column matrix of coefficients drawn from bDist
with options bDistOpt
</p>
<p>If there is a need for multiple W or b distributions,
then make multiple raptObj.  This makes
each raptObj fairly simple, while allowing arbitrary
complexity through multiple expansion and composition.
</p>
<p>A simple way to get a linear feature, in addition
to the RAPT features, is to simply cbind the
original matrix X in with the raptObj matrix.
</p>


<h3>Value</h3>

<p>An expand object, which defines the following fields:
W       Input weighting matrix
b       Input offset matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>raptObj &lt;- raptMake(21,210,bDistOpt=list(min=-pi,max=+pi))
</code></pre>

<hr>
<h2 id='reset.warnings'>Reset annoyingly persistent warning messages.</h2><span id='topic+reset.warnings'></span>

<h3>Description</h3>

<p>Reset annoyingly persistent warning messages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reset.warnings()
</code></pre>


<h3>Value</h3>

<p>Returns TRUE invisibly.  Used for side effects only.
</p>


<h3>References</h3>

<p>This function is built around the snippet found here:
<a href="http://stackoverflow.com/questions/5725106/r-how-to-clear-all-warnings">http://stackoverflow.com/questions/5725106/r-how-to-clear-all-warnings</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## reset.warnings()
</code></pre>

<hr>
<h2 id='Ydiagnostics'>Informative plots for Y and Yhat</h2><span id='topic+Ydiagnostics'></span>

<h3>Description</h3>

<p>This function presents diagnostic plots of estimate Yhat
and response Y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ydiagnostics(Y, Yhat, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ydiagnostics_+3A_y">Y</code></td>
<td>
<p>R object representing response,
coercible to a vector.</p>
</td></tr>
<tr><td><code id="Ydiagnostics_+3A_yhat">Yhat</code></td>
<td>
<p>R object representing estimate,
coercible to a vector.
The length of Y and Yhat must be equal.</p>
</td></tr>
<tr><td><code id="Ydiagnostics_+3A_...">...</code></td>
<td>
<p>Options for <code><a href="stats.html#topic+cor">cor</a></code> function.
The defaults are use = &quot;everything&quot; and
method = &quot;pearson&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plots shown are:
</p>

<ul>
<li><p>Y vs Yhat.  Under a perfect noise-free fitting,
this would be a straight line with
the points lined up on the red line, and the
correlation wpuld be 1.0000.
</p>
</li>
<li><p>Y, Yhat and Y-Yhat (residual) time domain plots.
The time steps are in samples.
</p>
</li>
<li><p>These show the ACF for the original Y, the residual,
and |residual|.  The latter helps identify
nonlinearity in the residual.
</p>
</li></ul>



<h3>Value</h3>

<p>Invisibly returns TRUE; this routine
is only used for its graphical side effects
described in Details.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The order here looks backwards, but is chosen to
# simulate a typical pair - Yhat will normally have
# a smaller range than Y.
set.seed(2)
nObs &lt;- 100 # Number of observations
x &lt;- stats::filter(rnorm(nObs),c(-0.99),
     method="recursive")
x &lt;- x + (x^2) # Nonlinear component
myLags &lt;- 0:2
X &lt;- eTrim(eLag(x,myLags))
Y &lt;- X[,+1,drop=FALSE]
X &lt;- X[,-1,drop=FALSE]
lmObj &lt;- lm(Y ~ X)
Yhat &lt;- predict(lmObj)
Ydiagnostics(Y,Yhat)
</code></pre>

<hr>
<h2 id='yyHatPlot'>Plot y and yHat on the same scale w/reference line</h2><span id='topic+yyHatPlot'></span>

<h3>Description</h3>

<p>Plots y and yHat on the same scale as a
scatterplot with a 1:1 reference line in red.
This is useful for visually comparing actual
data y with estimates yHat, determining
outliers, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yyHatPlot(y, yHat, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="yyHatPlot_+3A_y">y</code></td>
<td>
<p>Vector or matrix coercible to vector. Typically
will be the quantity to be predicted.</p>
</td></tr>
<tr><td><code id="yyHatPlot_+3A_yhat">yHat</code></td>
<td>
<p>Vector or matrix coercible to vector, same
length as y.  Typically will be the prediction.</p>
</td></tr>
<tr><td><code id="yyHatPlot_+3A_...">...</code></td>
<td>
<p>Optional additional graph parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Normally only makes sense with vectors, column matrices,
or row matrices.
</p>


<h3>Value</h3>

<p>Returns invisibly - only used for graphic side effects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
nObs &lt;- 80
X &lt;- distMat(nObs,2)
A &lt;- cbind(c(1,-1))
Y &lt;- X %*% A + rnorm(nObs) # Response data
lmObj &lt;- lm(Y ~ X)
Yhat &lt;- predict(lmObj) # Estimated response
yyHatPlot(Y,Yhat)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
