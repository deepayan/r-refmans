<!DOCTYPE html><html><head><title>Help for package psychotools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {psychotools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anchor'><p>Anchor Methods for the Detection of Uniform DIF the Rasch Model</p></a></li>
<li><a href='#anchortest'>
<p>Anchor methods for the detection of uniform DIF in the Rasch model</p></a></li>
<li><a href='#as.list.itemresp'><p>Coercing Item Response Data</p></a></li>
<li><a href='#btmodel'><p>Bradley-Terry Model Fitting Function</p></a></li>
<li><a href='#ConspiracistBeliefs2016'><p>Generic Conspiracist Beliefs Scale (2016 Data)</p></a></li>
<li><a href='#covariates'><p>Extract/Set Covariates</p></a></li>
<li><a href='#curveplot'><p>Response Curve Plots for IRT Models</p></a></li>
<li><a href='#discrpar'><p>Extract Discrimination Parameters of Item Response Models</p></a></li>
<li><a href='#elementary_symmetric_functions'><p>Calculation of the Elementary Symmetric Functions and Their</p>
Derivatives</a></li>
<li><a href='#FirstNames'><p>Popularity of First Names</p></a></li>
<li><a href='#GermanParties2009'><p>Choice among German Political Parties</p></a></li>
<li><a href='#gpcmodel'><p>Generalized Partial Credit Model Fitting Function</p></a></li>
<li><a href='#guesspar'><p>Extract Guessing Parameters of Item Response Models</p></a></li>
<li><a href='#infoplot'><p>Information Plots for IRT Models</p></a></li>
<li><a href='#itempar'><p>Extract Item Parameters of Item Response Models</p></a></li>
<li><a href='#itemresp'><p>Data Structure for Item Response Data</p></a></li>
<li><a href='#labels+26lt+3B-'><p>Set Labels</p></a></li>
<li><a href='#MathExam14W'><p>Mathematics 101 Exam Results</p></a></li>
<li><a href='#MemoryDeficits'><p>Memory Deficits in Psychiatric Patients</p></a></li>
<li><a href='#mptmodel'><p>Multinomial Processing Tree (MPT) Model Fitting Function</p></a></li>
<li><a href='#mscale'><p>Extract/Replace Measurement Scale</p></a></li>
<li><a href='#nplmodel'><p>Parametric Logistic Model (n-PL) Fitting Function</p></a></li>
<li><a href='#PairClustering'><p>Pair Clustering Data in Klauer (2006)</p></a></li>
<li><a href='#paircomp'><p>Data Structure for Paired Comparisons</p></a></li>
<li><a href='#pcmodel'><p>Partial Credit Model Fitting Function</p></a></li>
<li><a href='#personpar'><p>Extract Person Parameters of Item Response Models</p></a></li>
<li><a href='#piplot'><p>Person-Item Plots for IRT Models</p></a></li>
<li><a href='#plot.btmodel'><p>Visualizing Bradley-Terry Models</p></a></li>
<li><a href='#plot.paircomp'><p>Plotting Paired Comparison Data</p></a></li>
<li><a href='#plot.raschmodel'><p>Visualizing IRT Models</p></a></li>
<li><a href='#predict.pcmodel'><p>Predict Methods for Item Response Models</p></a></li>
<li><a href='#print.itemresp'><p>Formatting Item Response Data</p></a></li>
<li><a href='#print.paircomp'><p>Formatting Paired Comparison Data</p></a></li>
<li><a href='#profileplot'><p>Profile Plots for IRT Models</p></a></li>
<li><a href='#raschmodel'><p>Rasch Model Fitting Function</p></a></li>
<li><a href='#regionplot'><p>Region Plots for IRT Models</p></a></li>
<li><a href='#rgpcm'><p>Simulate Data under a Generalized Partial Credit Model</p></a></li>
<li><a href='#rpcm'><p>Simulate Data under a Partial Credit Model</p></a></li>
<li><a href='#rpl'><p>Simulate Data under a Parametric Logistic IRT Model</p></a></li>
<li><a href='#rrm'><p>Simulate Data under a Rasch model</p></a></li>
<li><a href='#rrsm'><p>Simulate Data under a Rating Scale Model</p></a></li>
<li><a href='#rsmodel'><p>Rating Scale Model Fitting Function</p></a></li>
<li><a href='#Sim3PL'><p>Simulated Data for fitting a 3PL and 3PLu</p></a></li>
<li><a href='#SoundQuality'><p>Quality of Multichannel Reproduced Sound</p></a></li>
<li><a href='#SourceMonitoring'><p>Performance in a Source-Monitoring Experiment</p></a></li>
<li><a href='#StereotypeThreat'><p>Stereotype Threat in Dutch Differential Aptitude Test</p></a></li>
<li><a href='#subset.itemresp'><p>Subsetting Item Response Data</p></a></li>
<li><a href='#subset.paircomp'><p>Subsetting/Reordering Paired Comparison Data</p></a></li>
<li><a href='#summary.itemresp'><p>Summarizing and Visualizing Item Response Data</p></a></li>
<li><a href='#threshpar'><p>Extract Threshold Parameters of Item Response Models</p></a></li>
<li><a href='#upperpar'><p>Extract Upper Asymptote Parameters of Item Response Models</p></a></li>
<li><a href='#VerbalAggression'><p>Situation-Response Questionnaire on Verbal Aggression</p></a></li>
<li><a href='#worth'><p>Extract Worth Parameters</p></a></li>
<li><a href='#YouthGratitude'><p>Measuring Gratitude in Youth</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Psychometric Modeling Infrastructure</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-11</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Formula, likert, mirt, multcomp, sandwich</td>
</tr>
<tr>
<td>Description:</td>
<td>Infrastructure for psychometric modeling such as data classes (for
  item response data and paired comparisons), basic model fitting functions (for
  Bradley-Terry, Rasch, parametric logistic IRT, generalized partial credit,
  rating scale, multinomial processing tree models), extractor functions for
  different types of parameters (item, person, threshold, discrimination,
  guessing, upper asymptotes), unified inference and visualizations, and various
  datasets for illustration.  Intended as a common lightweight and efficient
  toolbox for psychometric modeling and a common building block for fitting
  psychometric mixture models in package "psychomix" and trees based on
  psychometric models in package "psychotree".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-11 08:06:11 UTC; zeileis</td>
</tr>
<tr>
<td>Author:</td>
<td>Achim Zeileis <a href="https://orcid.org/0000-0003-0918-3766"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Carolin Strobl <a href="https://orcid.org/0000-0003-0952-3230"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Florian Wickelmaier [aut],
  Basil Komboz [aut],
  Julia Kopf [aut],
  Lennart Schneider <a href="https://orcid.org/0000-0003-4152-5308"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Rudolf Debelak <a href="https://orcid.org/0000-0001-8900-2106"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Achim Zeileis &lt;Achim.Zeileis@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-11 08:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='anchor'>Anchor Methods for the Detection of Uniform DIF the Rasch Model</h2><span id='topic+anchor'></span><span id='topic+anchor.default'></span><span id='topic+anchor.formula'></span><span id='topic+print.anchor'></span><span id='topic+print.summary.anchor'></span><span id='topic+summary.anchor'></span>

<h3>Description</h3>

<p>The <code>anchor</code> function provides a variety of anchor
methods for the detection of uniform differential item functioning (DIF)
in the Rasch model between two pre-specified groups. These methods can
be divided in an anchor class that determines characteristics of the
anchor method and an anchor selection that determines the ranking order
of candidate anchor items. The aim of the <code>anchor</code> function is to
provide anchor items for DIF testing, e.g. with
<code><a href="#topic+anchortest">anchortest</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anchor(object, ...)
## Default S3 method:
anchor(object, object2,
  class = c("constant", "forward"), select = NULL,
  length = NULL, range = c(0.1, 0.8), ...)
## S3 method for class 'formula'
anchor(formula, data = NULL, subset = NULL,
  na.action = NULL, weights = NULL, model = raschmodel, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anchor_+3A_object">object</code>, <code id="anchor_+3A_object2">object2</code></td>
<td>
<p>Fitted model objects of class &ldquo;raschmodel&rdquo;
estimated via conditional maximum likelihood using <code><a href="#topic+raschmodel">raschmodel</a></code>.</p>
</td></tr>
<tr><td><code id="anchor_+3A_...">...</code></td>
<td>
<p>further arguments passed over to an internal call
of <code><a href="#topic+anchor.default">anchor.default</a></code> in the formula method. In the
default method, these additional arguments are currently not being used.</p>
</td></tr>
<tr><td><code id="anchor_+3A_class">class</code></td>
<td>
<p>character. Available anchor classes are the
<code>constant</code> anchor class implying a constant anchor length
defined by <code>length</code> and the iterative <code>forward</code> anchor
class, for an overview see Kopf et al. (2015a).</p>
</td></tr>
<tr><td><code id="anchor_+3A_select">select</code></td>
<td>
<p>character. Several anchor selection strategies are
available: <code>"MTT"</code>, <code>"MPT"</code>, <code>"MT"</code>, <code>"MP"</code>,
<code>"NST"</code>, <code>"AO"</code>, <code>"AOP"</code> based on
Kopf et al. (2015b) as well as <code>"Gini"</code>, <code>"CLF"</code>,
<code>"GiniT"</code>, <code>"CLFT"</code> based on Strobl et al. (2021).
The latter four can only be combined with <code>class = "constant"</code>
and <code>length = 1</code>. The default is <code>select = "Gini"</code> unless
either <code>length &gt; 1</code> where <code>"MPT"</code> is used
or <code>class = "forward"</code> where <code>"MTT"</code> is used. For more
details see below.</p>
</td></tr>
<tr><td><code id="anchor_+3A_length">length</code></td>
<td>
<p>integer. It pre-defines a maximum anchor length.
Per default, the <code>forward</code> anchor grows up to the proportion
of currently presumed DIF-free items specified in <code>range</code>
and the <code>constant</code> anchor class selects one anchor item,
unless an explicit limiting number is defined in <code>length</code>
by the user.</p>
</td></tr>
<tr><td><code id="anchor_+3A_range">range</code></td>
<td>
<p>numeric vector of length 2. The first element is
the percentage of first anchor candidates to be excluded for
consideration when the <code>forward</code> anchor class is used and the
second element determines a percentage of currently presumed DIF-free
items up to which the anchor from the <code>forward</code> anchor class is
allowed to grow.</p>
</td></tr>
<tr><td><code id="anchor_+3A_formula">formula</code></td>
<td>
<p>formula of type <code>y ~ x</code> where <code>y</code> specifies a
matrix of dichotomous item responses and <code>x</code> the grouping
variable, e.g., gender, for which DIF should be tested for.</p>
</td></tr>
<tr><td><code id="anchor_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables of the specified
<code>formula</code>.</p>
</td></tr>
<tr><td><code id="anchor_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating elements or rows to keep:
missing values are taken as false.</p>
</td></tr>
<tr><td><code id="anchor_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain missing values (<code>NA</code>s).</p>
</td></tr>
<tr><td><code id="anchor_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case weights).</p>
</td></tr>
<tr><td><code id="anchor_+3A_model">model</code></td>
<td>
<p>an IRT model fitting function with a suitable <code>itempar</code>
method, by default <code><a href="#topic+raschmodel">raschmodel</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The anchor methods provided consist of an anchor class that determines
characteristics of the anchor and an anchor selection that determines
the ranking order of candidate anchor items.
</p>
<p>In the <code>constant</code> anchor class, the anchor length is pre-defined by the
user within the argument <code>length</code>, defaulting to a length of one.
In contrast, the iterative <code>forward</code> class starts with a single anchor item and
includes items in the anchor as long as the anchor length is shorter
than a certain percentage of the number of items that do not display
statistically significant DIF (default: 0.8). Furthermore, a percentage 
of first anchor candidates is excluded from consideration (default: 0.1) 
and the user is allowed to set a maximum number of anchor items using the 
argument <code>length</code>. A detailed description of the anchor classes can be found
in Kopf et al. (2015a).
</p>
<p>In more recent work Strobl et al. (2021) suggest a simpler yet powerful 
anchor method based on inequality criteria like the Gini coefficient. A
similar approach based on the component loss function (CLF) was suggested
by Muthén &amp; Asparouhov (2014). These criteria can be shown to attain their
optimium for a single-anchor, thus correponding to a <code>constant</code> class of
<code>length</code> 1. Due to the simple structure in combination with good
empirical performance the Gini-based selection was made the default in
version 0.7-0 of the package.
</p>
<p>Both anchor classes require an explicit anchor selection strategy (as opposed to
the <code>all-other</code> anchor class which is therefore not included in the
function <code>anchor</code>). The anchor selection strategy determines the ranking order of
candidate anchor items. In case of two groups, each item <code class="reqn">j, j = 1,
\ldots, k</code> (where <code class="reqn">k</code> denotes the number of
items in the test) obtains a criterion value <code class="reqn">c_j</code> that is
defined by the anchor selection strategy. The ranking order is
determined by the rank of the criterion value
rank<code class="reqn">(c_j)</code>. 
</p>
<p>The criterion values <code class="reqn">c_j</code> for item <code class="reqn">j</code> from the different
anchor selection strategies are provided in the following equations:
<code class="reqn">d_j</code> denotes the difference of the item parameters,
<code class="reqn">t_j</code> the corresponding test statistic, and
<code class="reqn">p_j</code> the resulting p-values. In all cases, the anchor items
are given in parentheses. Furthermore,
<code class="reqn">\mathrm{Gini}(\cdot)</code> denotes the Gini inequality index,
<code class="reqn">\mathrm{CLF}(\cdot)</code> the component loss function (sum of square root values),
<code class="reqn">1(\cdot)</code> the indicator function,
<code class="reqn">\lceil 0.5\cdot k \rceil</code> the empirical 50% quantile,
and <code class="reqn">A_\mathrm{purified}</code> the anchor after purification steps.
More detailed descriptions are available in Strobl et al. (2021) and
Kopf et al. (2015b).
</p>
<p>Gini selection (of item parameter differences) by Strobl et al. (2021):
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{Gini} = - \mathrm{Gini} (\{ |d_1(j)|, \ldots, |d_k(j)| \}) </code>
</p>

<p>GiniT selection (of test statistics) similar to Strobl et al. (2021):
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{GiniT} = - \mathrm{Gini} (\{ |t_1(j)|, \ldots, |t_k(j)| \}) </code>
</p>

<p>CLF selection (of item parameter differences) by Muthén &amp; Asparouhov (2014):
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{CLF} = \mathrm{CLF} (\{ |d_1(j)|, \ldots, |d_k(j)| \}) </code>
</p>

<p>CLFT selection (of test statistics) similar to Muthén &amp; Asparouhov (2014):
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{CLFT} = \mathrm{CLF} (\{ |t_1(j)|, \ldots, |t_k(j)| \}) </code>
</p>

<p>All-other selection by Woods (2009), here abbreviated AO:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{AO} = | t_j (\{1,\ldots,k\}\setminus j) |</code>
</p>

<p>All-other purified selection by Wang et al. (2012), here abbreviated AOP:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{AOP} = | t_j ( A_\mathrm{purified} ) |</code>
</p>

<p>Number of significant threshold selection based on Wang et al. (2004), here abbreviated NST:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{NST} = \sum_{l \in \{1,\ldots,k\} \setminus j} 1 \left\{ p_j ( \{l\} )  \leq \alpha \right\}) |</code>
</p>

<p>Mean test statistic selection by Shih et al. (2009), here abbreviated MT:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{MT} = \frac{1}{k-1} \sum_{l \in \{1,\ldots,k\} \setminus j} \left| t_j ( \{l\}) \right| </code>
</p>

<p>Mean p-value selection by Kopf et al. (2015b), here abbreviated MP:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{MP} = - \frac{1}{k-1} \sum_{l \in \{1,\ldots,k\} \setminus j} p_j ( \{l\} ) </code>
</p>

<p>Mean test statistic threshold selection by Kopf et al. (2015b), here abbreviated MTT:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{MTT} = 
 \sum_{l \in \{1,\ldots,k\} \setminus j} 
1 \left\{ \left|  t_j ( \{l\} ) \right| &gt;  
 \left( \left| \frac{1}{k-1} \sum_{l \in \{ 1, \ldots, k \} \setminus j} 
t_j ( \{l\} ) \right|
\right)_{\left( \lceil 0.5\cdot k\rceil \right)}
  \right\} </code>
</p>

<p>Mean p-value threshold selection by Kopf et al. (2015b), here abbreviated MPT:
</p>
<p style="text-align: center;"><code class="reqn"> c_j^\mathrm{MPT} = 
 -  \sum_{l \in \{1,\ldots,k\} \setminus j} 
1 \left\{ p_j ( \{l\} ) &gt;  \left( 
\frac{1}{k-1} \sum_{l \in \{ 1, \ldots, k \} \setminus j} 
 p_j ( \{l\} )
 \right)_{ \left( \lceil 0.5\cdot k\rceil \right)}
  \right\} </code>
</p>

<p>Kopf et al. (2015b) recommend to combine the <code>class = "constant"</code> with
<code>select = "MPT"</code> and the <code>class = "forward"</code> with <code>select = "MTT"</code>,
respectively.
</p>
<p>The <code>all-other</code> anchor class (that assumes that DIF is balanced i.e. no 
group has an advantage in the test) is here
not considered as explicit anchor selection and, thus, not included
in the <code>anchor</code> function (but in the <code><a href="#topic+anchortest">anchortest</a></code>
function). Note that the <code>all-other</code> anchor class requires strong prior
knowledge that DIF is balanced.
</p>


<h3>Value</h3>

<p>An object of class <code>anchor</code>, i.e. a list including 
</p>
<table>
<tr><td><code>anchor_items</code></td>
<td>
<p>the integer index for the selected anchor items</p>
</td></tr>
<tr><td><code>ranking_order</code></td>
<td>
<p>a ranking order (integer index) of the candidate anchor items by their criterion values</p>
</td></tr>
<tr><td><code>criteria</code></td>
<td>
<p>the criterion values obtained in the anchor selection for each item (unsorted)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kopf J, Zeileis A, Strobl C (2015a).
A Framework for Anchor Methods and an Iterative Forward Approach for DIF Detection.
<em>Applied Psychological Measurement</em>, <b>39</b>(2), 83&ndash;103.
<a href="https://doi.org/10.1177/0146621614544195">doi:10.1177/0146621614544195</a>
</p>
<p>Kopf J, Zeileis A, Strobl C (2015b).
Anchor Selection Strategies for DIF Analysis: Review, Assessment, and New Approaches.
<em>Educational and Psychological Measurement</em>, <b>75</b>(1), 22&ndash;56.
<a href="https://doi.org/10.1177/0013164414529792">doi:10.1177/0013164414529792</a>
</p>
<p>Muthén B, Asparouhov T (2014).
IRT Studies of Many Groups: The Alignment Method.
<em>Frontiers in Psychology</em>, <b>5</b>, 978.
<a href="https://doi.org/10.3389/fpsyg.2014.00978">doi:10.3389/fpsyg.2014.00978</a>
</p>
<p>Shih CL, Wang WC (2009).
Differential Item Functioning Detection Using the Multiple Indicators, Multiple Causes Method with a Pure Short Anchor.
<em>Applied Psychological Measurement</em>, <b>33</b>(3), 184&ndash;199.
</p>
<p>Strobl C, Kopf J, Kohler L, von Oertzen T, Zeileis A (2021).
Anchor Point Selection: Scale Alignment Based on an Inequality Criterion.
<em>Applied Psychological Measurement</em>, <b>45</b>(3), 214&ndash;230.
<a href="https://doi.org/10.1177/0146621621990743">doi:10.1177/0146621621990743</a>
</p>
<p>Wang WC (2004).
Effects of Anchor Item Methods on the Detection of Differential Item Functioning within the Family of Rasch Models.
<em>Journal of Experimental Education</em>, <b>72</b>(3), 221&ndash;261.
</p>
<p>Wang WC, Shih CL, Sun GW (2012).
The DIF-Free-then-DIF Strategy for the Assessment of Differential Item Functioning.
<em>Educational and Psychological Measurement</em>, <b>72</b>(4), 687&ndash;708.
</p>
<p>Woods C (2009).
Empirical Selection of Anchors for Tests of Differential Item Functioning.
<em>Applied Psychological Measurement</em>, <b>33</b>(1), 42&ndash;57.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anchortest">anchortest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Verbal aggression data
data("VerbalAggression", package = "psychotools")

## Gini anchor (Strobl et al. 2021) for gender DIF in the self-to-blame situations
anchor(resp2[, 1:12] ~ gender , data = VerbalAggression)

## alternatively: based on fitted raschmodel objects
raschmodels &lt;- with(VerbalAggression, lapply(levels(gender), function(i) 
  raschmodel(resp2[gender == i, 1:12])))
anchor(raschmodels[[1]], raschmodels[[2]])

if(requireNamespace("multcomp")) {

## four anchor items from constant anchor class using MPT-selection (Kopf et al. 2015b)
anchor(object = raschmodels[[1]], object2 = raschmodels[[2]], 
  class = "constant", select = "MPT", length = 4)

## iterative forward anchor class using MTT-selection (Kopf et al. 2015b)
set.seed(1)
fanchor &lt;- anchor(object = raschmodels[[1]], object2 = raschmodels[[2]],
  class = "forward", select = "MTT", range = c(0.05, 1))
fanchor

## the same using the formula interface
set.seed(1)
fanchor2 &lt;- anchor(resp2[, 1:12] ~ gender , data = VerbalAggression,
  class = "forward", select = "MTT", range = c(0.05, 1))

## criteria really the same?
all.equal(fanchor$criteria, fanchor2$criteria, check.attributes = FALSE)
}
</code></pre>

<hr>
<h2 id='anchortest'>
Anchor methods for the detection of uniform DIF in the Rasch model
</h2><span id='topic+anchortest'></span><span id='topic+anchortest.default'></span><span id='topic+anchortest.formula'></span><span id='topic+print.anchortest'></span><span id='topic+print.summary.anchortest'></span><span id='topic+summary.anchortest'></span>

<h3>Description</h3>

<p>The <code>anchortest</code> function provides a Wald test (see,
e.g., Glas, Verhelst, 1995) for the detection of uniform differential
item functioning (DIF) in the Rasch model between two pre-specified
groups. A variety of anchor methods is available to build a common
scale necessary for the comparison of the item parameters in the Rasch
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anchortest(object, ...)
## Default S3 method:
anchortest(object, object2,
  class = c("constant", "forward", "all-other", "fixed"), select = NULL,
  test = TRUE, adjust = "none", length = NULL, range = c(0.1, 0.8), ...)
## S3 method for class 'formula'
anchortest(formula, data = NULL, subset = NULL,
  na.action = NULL, weights = NULL, model = raschmodel, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anchortest_+3A_object">object</code>, <code id="anchortest_+3A_object2">object2</code></td>
<td>
<p>Fitted model objects of class &ldquo;raschmodel&rdquo;
estimated via conditional maximum likelihood using <code><a href="#topic+raschmodel">raschmodel</a></code>.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_...">...</code></td>
<td>
<p>further arguments passed over to an internal call
of <code><a href="#topic+anchor.default">anchor.default</a></code> in the formula method. In the
default method, these additional arguments are currently not being used.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_class">class</code></td>
<td>
<p>character. Available anchor classes are the
<code>constant</code> anchor class implying a constant anchor length
defined by <code>length</code>, the iterative <code>forward</code> anchor class
that iteratively includes items in the anchor and
the <code>all-other</code> anchor class, for an overview see Kopf et al. (2015a).
Additionally, the class can be <code>fixed</code>, then <code>select</code>
needs to be the numeric index of the fixed selected anchor items.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_select">select</code></td>
<td>
<p>character or numeric. Several anchor selection strategies are
available, for details see <code><a href="#topic+anchor">anchor</a></code>.
Alternatively, for <code>class = "fixed"</code>, <code>select</code> needs to be the
numeric index of the fixed selected anchor items. Defaults are set such
that <code>class = "constant"</code> is combined with <code>select = "Gini"</code>
while <code>class = "forward"</code> is combined with <code>select = "MTT"</code>.
And if <code>select</code> is numeric, then <code>class = "fixed"</code> is used.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_test">test</code></td>
<td>
<p>logical. Should the Wald test be returned for the
intended anchor method as final DIF test?</p>
</td></tr>
<tr><td><code id="anchortest_+3A_adjust">adjust</code></td>
<td>
<p>character. Should the final DIF test be adjusted for
multiple testing? For the type of adjustment,
see <code><a href="multcomp.html#topic+summary.glht">summary.glht</a></code> and <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_length">length</code></td>
<td>
<p>integer. It pre-defines a maximum anchor length.
Per default, the <code>forward</code> anchor grows up to the proportion
of currently presumed DIF-free items specified in <code>range</code> and
the <code>constant</code> anchor class selects four anchor items, unless
an explicit limiting number is defined in <code>length</code> by the user.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_range">range</code></td>
<td>
<p>numeric vector of length 2. The first element is
the percentage of first anchor candidates to be excluded for
consideration when the <code>forward</code> anchor class is used and the
second element determines a percentage of currently presumed DIF-free
items up to which the anchor from the <code>forward</code> anchor class is
allowed to grow.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_formula">formula</code></td>
<td>
<p>formula of type <code>y ~ x</code> where <code>y</code> specifies a
matrix of dichotomous item responses and <code>x</code> the grouping
variable, e.g., gender, for which DIF should be tested for.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables of the specified
<code>formula</code>.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating elements or rows to keep:
missing values are taken as false.</p>
</td></tr>
<tr><td><code id="anchortest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain missing values (<code>NA</code>s).</p>
</td></tr>
<tr><td><code id="anchortest_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case weights).</p>
</td></tr>
<tr><td><code id="anchortest_+3A_model">model</code></td>
<td>
<p>an IRT model fitting function with a suitable <code>itempar</code>
method, by default <code><a href="#topic+raschmodel">raschmodel</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To conduct the Wald test (see, e.g., Glas, Verhelst, 1995) for uniform 
DIF in the Rasch model, the user needs to specify an anchor method. 
The anchor methods can be divided in an anchor class that determines 
characteristics of the anchor method and an anchor selection that 
determines the ranking order of candidate anchor items.
</p>
<p>Explicit anchor selection strategies are used in the <code>constant</code>
anchor class and in the iterative <code>forward</code> anchor class, for a
detailed description see <code><a href="#topic+anchor">anchor</a></code>. Since <code class="reqn">k-1</code>
parameters are free in the estimation, only <code class="reqn">k-1</code> estimated
standard errors result. Thus, the first anchor item obtains no DIF test
result and we report <code class="reqn">k-1</code> test results. This decision is
applied only to those methods that rely on an explicit anchor
selection strategy.
</p>
<p>In the <code>constant</code> anchor class, the anchor length is pre-defined
by the user within the argument <code>length</code>. The default is a single
anchor item. The iterative <code>forward</code> class starts with a single
anchor item and includes items in the anchor as long as the anchor
length is shorter than a certain percentage of the number of items that
do not display statistically significant DIF. The default proportion is
set to 0.8 in the argument <code>range</code>. Alternatively, the user is
allowed to set a maximum number of anchor items using the argument
<code>length</code>. Both anchor classes require an explicit anchor selection
strategy as opposed to the <code>all-other</code> anchor class.
</p>
<p>The <code>all-other</code> anchor class is here not considered as explicit
anchor selection and, thus, only included in the <code>anchortest</code>
function. For the <code>all-other</code> anchor class, the strategy is set to
<code>"none"</code>, since all items except for the item currently studied
for DIF are used as anchor. Thus, no explicit anchor selection strategy
is required and we report <code class="reqn">k</code> test results. Note that the <code>all-other</code> 
anchor class requires strong prior knowledge that DIF is balanced.
</p>
<p>See Strobl et al. (2021) and Kopf et al. (2015ab) for a detailed introduction. For convenience
a trivial <code>"fixed"</code> anchor class is provided where the <code>select</code>ed
anchor is given directly (e.g., as chosen by a practitioner or by some
other anchor selection method).
</p>


<h3>Value</h3>

<p>An object of class <code>anchor</code>, i.e. a list including
</p>
<table>
<tr><td><code>anchor_items</code></td>
<td>
<p>the anchor items for DIF analysis.</p>
</td></tr>
<tr><td><code>ranking_order</code></td>
<td>
<p>a ranking order of candidate anchor items.</p>
</td></tr>
<tr><td><code>criteria</code></td>
<td>
<p>the criterion values obtained by the respective anchor
selection.</p>
</td></tr>
<tr><td><code>anchored_item_parameters</code></td>
<td>
<p> the anchored item parameters using
the anchor items.</p>
</td></tr>
<tr><td><code>anchored_covariances</code></td>
<td>
<p>the anchored covariance matrices using
the anchor items.</p>
</td></tr>
<tr><td><code>final_tests</code></td>
<td>
<p>the final Wald test for uniform DIF detection if
intended.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Glas CAW, Verhelst ND (1995).
&ldquo;Testing the Rasch Model.&rdquo;
In Fischer GH, Molenaar IW (eds.),
<em>Rasch Models: Foundations, Recent Developments, and Applications</em>, chapter 5.
Springer-Verlag, New York.
</p>
<p>Kopf J, Zeileis A, Strobl C (2015a).
A Framework for Anchor Methods and an Iterative Forward Approach for DIF Detection.
<em>Applied Psychological Measurement</em>, <b>39</b>(2), 83&ndash;103.
<a href="https://doi.org/10.1177/0146621614544195">doi:10.1177/0146621614544195</a>
</p>
<p>Kopf J, Zeileis A, Strobl C (2015b).
Anchor Selection Strategies for DIF Analysis: Review, Assessment, and New Approaches.
<em>Educational and Psychological Measurement</em>, <b>75</b>(1), 22&ndash;56.
<a href="https://doi.org/10.1177/0013164414529792">doi:10.1177/0013164414529792</a>
</p>
<p>Strobl C, Kopf J, Kohler L, von Oertzen T, Zeileis A (2021).
Anchor Point Selection: Scale Alignment Based on an Inequality Criterion.
<em>Applied Psychological Measurement</em>, <b>45</b>(3), 214&ndash;230.
<a href="https://doi.org/10.1177/0146621621990743">doi:10.1177/0146621621990743</a>
</p>
<p>Wang WC (2004).
Effects of Anchor Item Methods on the Detection of Differential Item Functioning within the Family of Rasch Models.
<em>Journal of Experimental Education</em>, <b>72</b>(3), 221&ndash;261.
</p>
<p>Woods C (2009).
Empirical Selection of Anchors for Tests of Differential Item Functioning.
<em>Applied Psychological Measurement</em>, <b>33</b>(1), 42&ndash;57.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anchor">anchor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("multcomp")) {

o &lt;- options(digits = 4)

## Verbal aggression data
data("VerbalAggression", package = "psychotools")

## Rasch model for the self-to-blame situations; gender DIF test
raschmodels &lt;- with(VerbalAggression, lapply(levels(gender), function(i) 
  raschmodel(resp2[gender == i, 1:12])))

## single anchor from Gini selection (default)
gini1 &lt;- anchortest(object = raschmodels[[1]], object2 = raschmodels[[2]])
gini1
summary(gini1)

## four anchor items from constant anchor class using MPT selection
const1 &lt;- anchortest(object = raschmodels[[1]], object2 = raschmodels[[2]],
  class = "constant", select = "MPT", length = 4)
const1
summary(const1)

## iterative forward anchor class using MTT selection
set.seed(1)
forw1 &lt;- anchortest(object = raschmodels[[1]], object2 = raschmodels[[2]], 
  class = "forward", select = "MTT", test = TRUE,
  adjust = "none", range = c(0.05,1))
forw1

## DIF test with fixed given anchor (arbitrarily selected to be items 1 and 2)
anchortest(object = raschmodels[[1]], object2 = raschmodels[[2]], select = 1:2)

options(digits = o$digits)
}
</code></pre>

<hr>
<h2 id='as.list.itemresp'>Coercing Item Response Data</h2><span id='topic+is.itemresp'></span><span id='topic+as.list.itemresp'></span><span id='topic+as.character.itemresp'></span><span id='topic+as.data.frame.itemresp'></span><span id='topic+as.double.itemresp'></span><span id='topic+as.integer.itemresp'></span><span id='topic+as.matrix.itemresp'></span>

<h3>Description</h3>

<p>Coercing <code>"itemresp"</code> data objects to other classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'itemresp'
as.list(x, items = NULL, mscale = TRUE, df = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.list.itemresp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"itemresp"</code>.</p>
</td></tr>
<tr><td><code id="as.list.itemresp_+3A_items">items</code></td>
<td>
<p>character, integer, or logical for subsetting the items.</p>
</td></tr>
<tr><td><code id="as.list.itemresp_+3A_mscale">mscale</code></td>
<td>
<p>logical. Should the measurement scale labels be used
for creating factor levels? If <code>FALSE</code>, the values 0, 1, ...
are used.</p>
</td></tr>
<tr><td><code id="as.list.itemresp_+3A_df">df</code></td>
<td>
<p>logical. Should a data frame of factors be returned?
If <code>FALSE</code>, a plain list of factors is returned.</p>
</td></tr>
<tr><td><code id="as.list.itemresp_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>as.list</code> method coerces item response data to a list
(or data frame) of factors with factor levels either taken from
the <code>mscale(x)</code> or as the values 0, 1, ....
</p>
<p>The <code>as.data.frame</code> method returns a data frame with a single
column of class <code>"itemresp"</code>.
</p>
<p>Furthermore, <code>as.matrix</code>, <code>as.integer</code>, <code>as.double</code>
all return a matrix with the item responses coded as values 0, 1, ...
</p>
<p>The <code>as.character</code> method simply calls <code><a href="#topic+format.itemresp">format.itemresp</a></code>.
</p>
<p><code>is.itemresp</code> can be used to check wether a given object is of
class <code>"itemresp"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemresp">itemresp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## item responses from binary matrix
x &lt;- cbind(c(1, 0, 1, 0), c(1, 0, 0, 0), c(0, 1, 1, 1))
xi &lt;- itemresp(x)
## change mscale
mscale(xi) &lt;- c("-", "+")
xi

## coercion to list of factors with levels taken from mscale
as.list(xi)
## same but levels taken as integers 0, 1
as.list(xi, mscale = FALSE)
## only for first two items
as.list(xi, items = 1:2)
## result as data.frame
as.list(xi, df = TRUE)

## data frame with single itemresp column
as.data.frame(xi)

## integer matrix
as.matrix(xi)

## character vector
as.character(xi)

## check class of xi
is.itemresp(xi)
</code></pre>

<hr>
<h2 id='btmodel'>Bradley-Terry Model Fitting Function</h2><span id='topic+btmodel'></span><span id='topic+btReg.fit'></span><span id='topic+print.btmodel'></span><span id='topic+summary.btmodel'></span><span id='topic+print.summary.btmodel'></span><span id='topic+coef.btmodel'></span><span id='topic+worth.btmodel'></span><span id='topic+deviance.btmodel'></span><span id='topic+logLik.btmodel'></span><span id='topic+vcov.btmodel'></span><span id='topic+estfun.btmodel'></span>

<h3>Description</h3>

<p><code>btmodel</code> is a basic fitting function for simple Bradley-Terry models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>btmodel(y, weights = NULL, type = c("loglin", "logit"), ref = NULL,
  undecided = NULL, position = NULL, start = NULL, vcov = TRUE, estfun =
  FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="btmodel_+3A_y">y</code></td>
<td>
<p>paircomp object with the response.</p>
</td></tr>
<tr><td><code id="btmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case weights).</p>
</td></tr>
<tr><td><code id="btmodel_+3A_type">type</code></td>
<td>
<p>character. Should an auxiliary log-linear Poisson model or logistic
binomial be employed for estimation? The latter is not available if
undecided effects are estimated.</p>
</td></tr>
<tr><td><code id="btmodel_+3A_ref">ref</code></td>
<td>
<p>character or numeric. Which object parameter should be the reference
category, i.e., constrained to zero?</p>
</td></tr>
<tr><td><code id="btmodel_+3A_undecided">undecided</code></td>
<td>
<p>logical. Should an undecided parameter be estimated?</p>
</td></tr>
<tr><td><code id="btmodel_+3A_position">position</code></td>
<td>
<p>logical. Should a position effect be estimated?</p>
</td></tr>
<tr><td><code id="btmodel_+3A_start">start</code></td>
<td>
<p>numeric. Starting values when calling <code><a href="stats.html#topic+glm.fit">glm.fit</a></code>.</p>
</td></tr>
<tr><td><code id="btmodel_+3A_vcov">vcov</code></td>
<td>
<p>logical. Should the estimated variance-covariance be included in
the fitted model object?</p>
</td></tr>
<tr><td><code id="btmodel_+3A_estfun">estfun</code></td>
<td>
<p>logical. Should the empirical estimating functions (score/gradient
contributions) be included in the fitted model object?</p>
</td></tr>
<tr><td><code id="btmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>btmodel</code> provides a basic fitting function for Bradley-Terry models,
intended as a building block for fitting Bradley-Terry trees and
Bradley-Terry mixtures in the <span class="pkg">psychotree</span> package, respectively. While
<code>btmodel</code> is intended for individual paired-comparison data, the
<span class="pkg">eba</span> package provides functions for aggregate data.
</p>
<p><code>btmodel</code> returns an object of class <code>"btmodel"</code> for which
several basic methods are available, including <code>print</code>, <code>plot</code>,
<code>summary</code>, <code>coef</code>, <code>vcov</code>, <code>logLik</code>, <code>estfun</code>
and <code><a href="#topic+worth">worth</a></code>.
</p>


<h3>Value</h3>

<p><code>btmodel</code> returns an S3 object of class <code>"btmodel"</code>,
i.e., a list with components as follows.
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>paircomp object with the response</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated parameters on log-scale (without the first
parameter which is always constrained to be 0),</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of the parameters in the model,</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>number of estimated parameters,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>character for model type (see above),</p>
</td></tr>
<tr><td><code>ref</code></td>
<td>
<p>character for reference category (see above),</p>
</td></tr>
<tr><td><code>undecided</code></td>
<td>
<p>logical for estimation of undecided parameter (see above),</p>
</td></tr>
<tr><td><code>position</code></td>
<td>
<p>logical for estimation of position effect (see above),</p>
</td></tr>
<tr><td><code>labels</code></td>
<td>
<p>character labels of the objects compared,</p>
</td></tr>
<tr><td><code>estfun</code></td>
<td>
<p>empirical estimating function (also known as scores or gradient contributions).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+gpcmodel">gpcmodel</a></code>, <code><a href="#topic+rsmodel">rsmodel</a></code>,
<code><a href="#topic+raschmodel">raschmodel</a></code>, <code><a href="#topic+nplmodel">nplmodel</a></code>, the <span class="pkg">eba</span> package</p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## data
data("GermanParties2009", package = "psychotools")

## Bradley-Terry model
bt &lt;- btmodel(GermanParties2009$preference)
summary(bt)
plot(bt)

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='ConspiracistBeliefs2016'>Generic Conspiracist Beliefs Scale (2016 Data)</h2><span id='topic+ConspiracistBeliefs2016'></span>

<h3>Description</h3>

<p>Responses of 2449 persons to 15 five-point likert-rated items (0 = disagree to
4 = agree) measuring belief in conspiracy theories as well as responses on 2
covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ConspiracistBeliefs2016", package = "psychotools")</code></pre>


<h3>Format</h3>

<p>A data frame containing 2449 observations on 3 variables.
</p>

<dl>
<dt>resp</dt><dd><p>Item response matrix with 15 items (see details below).</p>
</dd>
<dt>area</dt><dd><p>Factor coding the area one lived in as a child (<code>"rural"</code>,
<code>"suburban"</code>, <code>"urban"</code>).</p>
</dd>
<dt>gender</dt><dd><p>Factor coding gender (<code>"male"</code>, <code>"female"</code>,
<code>"other"</code>).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The Open Source Psychometrics Project published this dataset collected online
in 2016. Persons responded to the Generic Conspiracist Beliefs (GCB) Scale
(Brotherton, French &amp; Pickering, 2013) as well as other additional questions
primarily for personal amusement. At the end of the test but before the
results were displayed, users were asked if they would allow their responses to
be saved for research. Only users who agreed are part of this dataset.
Individuals with age lower than 13 years were not recorded. Moreover, two
persons stating their age to be 5555 years or higher as well as 44 persons
with missing data in <code>area</code> or <code>gender</code> were excluded from this
dataset. The 15 items of the GCB Scale are:
</p>

<table>
<tr>
 <td style="text-align: right;">
  Q1:</td><td style="text-align: left;"> The government is involved in the murder of innocent citizens and/or
    well-known public figures, and keeps this a secret.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q2:</td><td style="text-align: left;"> The power held by heads of state is second to that of small unknown
    groups who really control world politics.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q3:</td><td style="text-align: left;"> Secret organizations communicate with extraterrestrials, but keep
    this fact from the public.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q4:</td><td style="text-align: left;"> The spread of certain viruses and/or diseases is the result of the
    deliberate, concealed efforts of some organization.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q5:</td><td style="text-align: left;"> Groups of scientists manipulate, fabricate, or suppress evidence in
    order to deceive the public.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q6:</td><td style="text-align: left;"> The government permits or perpetrates acts of terrorism on its own
    soil, disguising its involvement.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q7:</td><td style="text-align: left;"> A small, secret group of people is responsible for making all major
    world decisions, such as going to war.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q8:</td><td style="text-align: left;"> Evidence of alien contact is being concealed from the public.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q9:</td><td style="text-align: left;"> Technology with mind-control capacities is used on people without
    their knowledge.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q10:</td><td style="text-align: left;"> New and advanced technology which would harm current industry is
    being suppressed.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q11:</td><td style="text-align: left;">  The government uses people as patsies to hide its involvement in
    criminal activity.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q12:</td><td style="text-align: left;"> Certain significant events have been the result of the activity of a
    small group who secretly manipulate world events.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q13:</td><td style="text-align: left;"> Some UFO sightings and rumors are planned or staged in order to
    distract the public from real alien contact.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q14:</td><td style="text-align: left;"> Experiments involving new drugs or technologies are routinely
    carried out on the public without their knowledge or consent.</td>
</tr>
<tr>
 <td style="text-align: right;">
  Q15:</td><td style="text-align: left;"> A lot of important information is deliberately concealed from the
    public out of self-interest.
</td>
</tr>

</table>

<p>Additional information can be found online (see below) via inspecting the
codebook contained in &lsquo;<span class="file">GCBS.zip</span>&rsquo;.
</p>


<h3>Source</h3>

<p><a href="https://openpsychometrics.org/_rawdata/">https://openpsychometrics.org/_rawdata/</a>.</p>


<h3>References</h3>

<p>Brotherton R, French CC, Pickering AD (2013).
Measuring Belief in Conspiracy Theories: The Generic Conspiracist Beliefs
Scale.
<em>Frontiers in Psychology</em>, <b>4</b>, 279.
</p>
<p>Open Source Psychometrics Project (2016).
Data From: The Generic Conspiracist Beliefs Scale [Dataset].
Retrieved from <a href="https://openpsychometrics.org/_rawdata/">https://openpsychometrics.org/_rawdata/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpcmodel">gpcmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## overview
data("ConspiracistBeliefs2016", package = "psychotools")
str(ConspiracistBeliefs2016)

## response
plot(itemresp(ConspiracistBeliefs2016$resp))
## covariates
summary(ConspiracistBeliefs2016[, -1])
</code></pre>

<hr>
<h2 id='covariates'>Extract/Set Covariates</h2><span id='topic+covariates'></span><span id='topic+covariates+3C-'></span>

<h3>Description</h3>

<p>A generic function for extracting/setting covariates for an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  covariates(object, ...)
  covariates(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covariates_+3A_object">object</code></td>
<td>
<p>an object.</p>
</td></tr>
<tr><td><code id="covariates_+3A_...">...</code></td>
<td>
<p>arguments passed to methods.</p>
</td></tr>
<tr><td><code id="covariates_+3A_value">value</code></td>
<td>
<p>an object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## method for "paircomp" data
pc &lt;- paircomp(rbind(
  c(1,  1,  1), # a &gt; b, a &gt; c, b &gt; c
  c(1,  1, -1), # a &gt; b, a &gt; c, b &lt; c
  c(1, -1, -1), # a &gt; b, a &lt; c, b &lt; c
  c(1,  1,  1)))
covariates(pc)
covariates(pc) &lt;- data.frame(foo = factor(c(1, 2, 2), labels = c("foo", "bar")))
covariates(pc)
</code></pre>

<hr>
<h2 id='curveplot'>Response Curve Plots for IRT Models</h2><span id='topic+curveplot'></span>

<h3>Description</h3>

<p>Base graphics plotting function for response curve plot visualization of IRT
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  curveplot(object, ref = NULL, items = NULL, names = NULL,
    layout = NULL, xlim = NULL, ylim = c(0, 1), col = NULL,
    lty = NULL, main = NULL, xlab = "Latent trait",
    ylab = "Probability", add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="curveplot_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>"raschmodel"</code>,
<code>"rsmodel"</code>, <code>"pcmodel"</code>, <code>"nplmodel"</code> or <code>"gpcmodel"</code>.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_ref">ref</code></td>
<td>
<p>argument passed over to internal calls of <code><a href="stats.html#topic+predict">predict</a></code>.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_items">items</code></td>
<td>
<p>character or numeric, specifying the items for which response
curves should be visualized.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_names">names</code></td>
<td>
<p>character, specifying labels for the items.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_layout">layout</code></td>
<td>
<p>matrix, specifying how the response curve plots of different
items should be arranged.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_xlim">xlim</code>, <code id="curveplot_+3A_ylim">ylim</code></td>
<td>
<p>numeric, specifying the x and y axis limits.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_col">col</code></td>
<td>
<p>character, specifying the colors of the response curve lines. The
length of <code>col</code> should be the maximum number of available categories.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_lty">lty</code></td>
<td>
<p>numeric, specifying the line type of the response curve lines. The
length of <code>lty</code> should either be one or the maximum number of
available categories. In the first case, a single line type is used for all
category response curves. In the latter case, separate line types for each
category response curve are used.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_main">main</code></td>
<td>
<p>character, specifying the overall title of the plot.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_xlab">xlab</code>, <code id="curveplot_+3A_ylab">ylab</code></td>
<td>
<p>character, specifying the x and y axis labels.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_add">add</code></td>
<td>
<p>logical. If <code>TRUE</code>, new response curves are added to an
existing plot. Only possible when a single item is visualized.</p>
</td></tr>
<tr><td><code id="curveplot_+3A_...">...</code></td>
<td>
<p>further arguments passed to internal calls of
<code><a href="graphics.html#topic+matplot">matplot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response curve plot visualization illustrates the predicted probabilities
as a function of the ability parameter <code class="reqn">\theta</code> under a certain IRT model.
This type of visualization is sometimes also called item/category operating
curves or item/category characteristic curves.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regionplot">regionplot</a></code>, <code><a href="#topic+profileplot">profileplot</a></code>,
<code><a href="#topic+infoplot">infoplot</a></code>, <code><a href="#topic+piplot">piplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit Rasch, rating scale and partial credit model to verbal aggression data
rmmod &lt;- raschmodel(VerbalAggression$resp2)
rsmod &lt;- rsmodel(VerbalAggression$resp)
pcmod &lt;- pcmodel(VerbalAggression$resp)

## curve plots of the dichotomous RM
plot(rmmod, type = "curves")

## curve plots under the RSM for the first six items of the data set
plot(rsmod, type = "curves", items = 1:6)

## curve plots under the PCM for the first six items of the data set with
## custom labels
plot(pcmod, type = "curves", items = 1:6, names = paste("Item", 1:6))

## compare the predicted probabilities under the RSM and the PCM for a single
## item
plot(rsmod, type = "curves", item = 1)
plot(pcmod, type = "curves", item = 1, lty = 2, add = TRUE)
legend(x = "topleft", y = 1.0, legend = c("RSM", "PCM"), lty = 1:2, bty = "n")


if(requireNamespace("mirt")) {
## fit 2PL and generaliced partial credit model to verbal aggression data
twoplmod &lt;- nplmodel(VerbalAggression$resp2)
gpcmod &lt;- gpcmodel(VerbalAggression$resp)

## curve plots of the dichotomous 2PL
plot(twoplmod, type = "curves", xlim = c(-6, 6))

## curve plots under the GPCM for the first six items of the data set
plot(gpcmod, type = "curves", items = 1:6, xlim = c(-6, 6))
}

</code></pre>

<hr>
<h2 id='discrpar'>Extract Discrimination Parameters of Item Response Models</h2><span id='topic+discrpar'></span><span id='topic+discrpar.raschmodel'></span><span id='topic+discrpar.rsmodel'></span><span id='topic+discrpar.pcmodel'></span><span id='topic+discrpar.nplmodel'></span><span id='topic+discrpar.gpcmodel'></span><span id='topic+coef.discrpar'></span><span id='topic+print.discrpar'></span><span id='topic+vcov.discrpar'></span>

<h3>Description</h3>

<p>A class and generic function for representing and extracting the
discrimination parameters of a given item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  discrpar(object, ...)
  ## S3 method for class 'raschmodel'
discrpar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'rsmodel'
discrpar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'pcmodel'
discrpar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'nplmodel'
discrpar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'gpcmodel'
discrpar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discrpar_+3A_object">object</code></td>
<td>
<p>a fitted model object whose discrimination parameters should be
extracted.</p>
</td></tr>
<tr><td><code id="discrpar_+3A_ref">ref</code></td>
<td>
<p>a restriction to be used. Not used for models estimated via CML as
the discrimination parameters are fixed to 1 in <code>raschmodel</code>s,
<code>rsmodel</code>s and <code>pcmodel</code>s. For models estimated via MML
(<code>nplmodel</code>s and <code>gpcmodel</code>s), the parameters are by default
identified via the distributional parameters of the person parameters (mean and
variance of a normal distribution). Nevertheless, a restriction on the ratio
scale can be applied.</p>
</td></tr>
<tr><td><code id="discrpar_+3A_alias">alias</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the aliased parameters are
included in the return vector (and in the variance-covariance matrix if
<code>vcov</code> = TRUE). If <code>FALSE</code>, these parameters are removed. For
<code>raschmodel</code>s, <code>rsmodel</code>s and <code>pcmodel</code>s where all
discrimination parameters are fixed to 1, this means that an empty
numeric vector and an empty variance-covariance matrix is returned if
<code>alias</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="discrpar_+3A_vcov">vcov</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the variance-covariance
matrix of the discrimination parameters is attached as attribute
<code>vcov</code>.</p>
</td></tr>
<tr><td><code id="discrpar_+3A_...">...</code></td>
<td>
<p>further arguments which are currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>discrpar</code> is both, a class to represent discrimination parameters of
item response models as well as a generic function. The generic function can
be used to extract the discrimination parameters of a given item response
model.
</p>
<p>For objects of class <code>discrpar</code>, several methods to standard generic
functions exist: <code>print</code>, <code>coef</code>, <code>vcov</code>. <code>coef</code> and
<code>vcov</code> can be used to extract the discrimination parameters and their
variance-covariance matrix without additional attributes.
</p>


<h3>Value</h3>

<p>A named vector with discrimination parameters of class <code>discrpar</code> and
additional attributes <code>model</code> (the model name), <code>ref</code> (the items or
parameters used as restriction/for normalization), <code>alias</code> (either
<code>TRUE</code> or a named numeric vector with the aliased parameters not included
in the return value), and <code>vcov</code> (the estimated and adjusted
variance-covariance matrix).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+personpar">personpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>,
<code><a href="#topic+threshpar">threshpar</a></code>, <code><a href="#topic+guesspar">guesspar</a></code>, <code><a href="#topic+upperpar">upperpar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit Rasch model to verbal aggression data
rmod &lt;- raschmodel(VerbalAggression$resp2)

## extract the discrimination parameters
dp1 &lt;- discrpar(rmod)

## extract the standard errors
sqrt(diag(vcov(dp1)))

if(requireNamespace("mirt")) {
## fit 2PL to verbal aggression data
twoplmod &lt;- nplmodel(VerbalAggression$resp2)

## extract the discrimination parameters
dp2 &lt;- discrpar(twoplmod)

## this time with the first discrimination parameter being the reference
discrpar(twoplmod, ref = 1)

## extract the standard errors
sqrt(diag(vcov(dp2)))
}

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='elementary_symmetric_functions'>Calculation of the Elementary Symmetric Functions and Their
Derivatives</h2><span id='topic+elementary_symmetric_functions'></span>

<h3>Description</h3>

<p>Calculation of <code>elementary_symmetric_functions</code> (ESFs), their first and,
in the case of dichotomous items, second derivatives with sum or
difference algorithm for the Rasch, rating scale and partial credit
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elementary_symmetric_functions(par, order = 0L, log = TRUE,
  diff = FALSE, engine = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elementary_symmetric_functions_+3A_par">par</code></td>
<td>
<p>numeric vector or a list. Either a vector of item difficulty
parameters of dichotomous items (Rasch  model) or a list of
item-category parameters of polytomous items (rating scale and
partial credit model).</p>
</td></tr>
<tr><td><code id="elementary_symmetric_functions_+3A_order">order</code></td>
<td>
<p>integer between 0 and 2, specifying up to which derivative
the ESFs should be calculated. Please note, second order derivatives
are currently only possible for dichtomous items in an R
implementation <code>engine == "R".</code></p>
</td></tr>
<tr><td><code id="elementary_symmetric_functions_+3A_log">log</code></td>
<td>
<p>logical. Are the parameters given in <code>par</code> on log
scale? Primarily used for internal recursive calls of
<code>elementary_symmetric_functions</code>.</p>
</td></tr>  
<tr><td><code id="elementary_symmetric_functions_+3A_diff">diff</code></td>
<td>
<p>logical. Should the first and second derivatives (if
requested) of the ESFs calculated with sum (<code>FALSE</code>)
or difference algorithm (<code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="elementary_symmetric_functions_+3A_engine">engine</code></td>
<td>
<p>character, either <code>"C"</code> or <code>"R"</code>. If the
former, a C implementation is used to calculcate the ESFs and their
derivatives, otherwise (<code>"R"</code>) pure R code is used.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>Depending on the type of <code>par</code>, the elementary symmetric
functions for dichotomous (<code>par</code> is a numeric vector) or
polytomous items (<code>par</code> is a list) are calculated.
</p>
<p>For dichotomous items, the summation and difference algorithm
published in Liou (1994) is used. For calculating the second order
derivatives, the equations proposed by Jansens (1984) are employed.
</p>
<p>For polytomous items, the summation and difference algorithm published
by Fischer and Pococny (1994) is used (see also Fischer and Pococny,
1995).
</p>


<h3>Value</h3>

<p><code>elementary_symmetric_function</code> returns a list of length 1 + <code>order</code>.
</p>
<p>If <code>order = 0</code>, then the first (and only) element is a numeric
vector with the ESFs of order 0 to the maximum score possible with
the given parameters.
</p>
<p>If <code>order = 1</code>, the second element of the list contains a
matrix, with the rows corresponding to the possible scores and the
columns corresponding to the derivatives with respect to the i-th
parameter of <code>par</code>.
</p>
<p>For dichotomous items and <code>order = 2</code>, the third element of the
list contains an array with the second derivatives with respect to
every possible combination of two parameters given in <code>par</code>. The
rows of the individual matrices still correspond to the possibles
scores (orders) starting from zero.
</p>


<h3>References</h3>

<p>Liou M (1994).
More on the Computation of Higher-Order Derivatives of the Elementary Symmetric Functions in the Rasch Model.
<em>Applied Psychological Measurement</em>, <b>18</b>, 53&ndash;62.
</p>
<p>Jansen PGW (1984).
Computing the Second-Order Derivatives of the Symmetric Functions in the Rasch Model.
<em>Kwantitatieve Methoden</em>, <b>13</b>, 131&ndash;147.
</p>
<p>Fischer GH, and Ponocny I (1994).
An Extension of the Partial Credit Model with an Application to the Measurement of Change.
<em>Psychometrika</em>, <b>59</b>(2), 177&ndash;192.
</p>
<p>Fischer GH, and Ponocny I (1995).
&ldquo;Extended Rating Scale and Partial Credit Models for Assessing Change.&rdquo;
In Fischer GH, and Molenaar IW (eds.).
<em>Rasch Models: Foundations, Recent Developments, and Applications.</em> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 ## zero and first order derivatives of 100 dichotomous items
 di &lt;- rnorm(100)
 system.time(esfC &lt;- elementary_symmetric_functions(di, order = 1))
 
 ## again with R implementation
 system.time(esfR &lt;- elementary_symmetric_functions(di, order = 1,
 engine = "R"))

 ## are the results equal?
 all.equal(esfC, esfR)


 ## calculate zero and first order elementary symmetric functions
 ## for 10 polytomous items with three categories each.
 pi &lt;- split(rnorm(20), rep(1:10, each = 2))
 x &lt;- elementary_symmetric_functions(pi)

 ## use difference algorithm instead and compare results
 y &lt;- elementary_symmetric_functions(pi, diff = TRUE)
 all.equal(x, y)
</code></pre>

<hr>
<h2 id='FirstNames'>Popularity of First Names</h2><span id='topic+FirstNames'></span>

<h3>Description</h3>

<p>Preferences of 192 respondents choosing among six boys names with respect to
their popularity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("FirstNames")</code></pre>


<h3>Format</h3>

<p>A data frame containing 192 observations on 11 variables.
</p>

<dl>
<dt>preference</dt><dd><p>Paired comparison of class <code><a href="#topic+paircomp">paircomp</a></code>.
All 15 pairwise choices among six boys names: Tim, Lucas, Michael, Robin,
Benedikt, and Julius.</p>
</dd>
<dt>ordered.pref</dt><dd><p>Ordered paired comparison of class
<code><a href="#topic+paircomp">paircomp</a></code>. Same as <code>preference</code>, but within-pair order
is recognized.</p>
</dd>
<dt>gender</dt><dd><p>Factor coding gender.</p>
</dd>
<dt>age</dt><dd><p>Integer. Age of the respondents in years.</p>
</dd>
<dt>education</dt><dd><p>Ordered factor. Level of education: 1
Hauptschule with degree (Secondary General School), 2 and 3 Realschule
without and with degree (Intermediate Secondary School), 4 and 5
Gymnasium without and with degree (High School), 6 and 7 Studium without
and with degree (University).</p>
</dd>
<dt>children</dt><dd><p>Integer. Number of children.</p>
</dd>
<dt>state</dt><dd><p>Factor. State of Germany where participant grew up.</p>
</dd>
<dt>state.reg</dt><dd><p>Factor. The region (south, north-west, east) each state
belongs to.</p>
</dd>
<dt>fname</dt><dd><p>Factor. Participant's fist name(s). (Umlaute in Jörg and Jürgen
have been transliterated to Joerg and Juergen for portability of the data.)</p>
</dd>
<dt>interviewer</dt><dd><p>Factor. Interviewer id.</p>
</dd>
<dt>gender.int</dt><dd><p>Factor coding interviewer's gender.</p>
</dd>
</dl>



<h3>Details</h3>

<p>A survey was conducted at the Department of Psychology, Universität
Tübingen, in June 2009. The sample was stratified by gender and age (younger
versus older than 30 years) with 48 participants in each group.  The
interviewers were Psychology Master's students who collected the data for
course credits.
</p>
<p>Participants were presented with 15 pairs of boys names in random order. On
each trial, their task was to choose the name they would rather give to
their own child.  The pairs of boys names were read to the participants one
at a time.  A given participant compared each pair in one order only, hence
the NA's in <code>ordered.pref</code>.
</p>
<p>The names were selected to fall within the upper (Tim, Lucas), mid (Michael,
Robin) and lower (Benedikt, Julius) range of the top 100 of the most popular
boys names in Germany in the years from 1990 to 1999
(<a href="https://www.beliebte-vornamen.de/3778-1990er-jahre.htm">https://www.beliebte-vornamen.de/3778-1990er-jahre.htm</a>). The names
have either front (e, i) or back (o, u) vowels in the stressed syllables.
Phonology of the name and attractiveness of a person have been shown to be
related (Perfors, 2004; Hartung et al., 2009).
</p>


<h3>References</h3>

<p>Hartung F, Klenovsak D, Santiago dos Santos L, Strobl C, Zaefferer D (2009).
Are Tims Hot and Toms Not? Probing the Effect of Sound Symbolism on Perception of Facial Attractiveness.
Presented at the <em>31th Annual Meeting of the Cognitive Science Society</em>,
July 27&ndash;August 1, Amsterdam, The Netherlands.
</p>
<p>Perfors A (2004).
What's in a Name? The Effect of Sound Symbolism on Perception of Facial Attractiveness.
Presented at the <em>26th Annual Meeting of the Cognitive Science Society</em>,
August 5&ndash;7, Chicago, USA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paircomp">paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("FirstNames", package = "psychotools")
summary(FirstNames$preference)
covariates(FirstNames$preference)
</code></pre>

<hr>
<h2 id='GermanParties2009'>Choice among German Political Parties</h2><span id='topic+GermanParties2009'></span>

<h3>Description</h3>

<p>Preferences of 192 respondents choosing among five German political parties
and abstention from voting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("GermanParties2009")</code></pre>


<h3>Format</h3>

<p>A data frame containing 192 observations on 6 variables.
</p>

<dl>
<dt>preference</dt><dd><p>Paired comparison of class <code><a href="#topic+paircomp">paircomp</a></code>.
All 15 pairwise choices among five German parties and abstention from
voting.</p>
</dd>
<dt>ordered.pref</dt><dd><p>Ordered paired comparison of class
<code><a href="#topic+paircomp">paircomp</a></code>. Same as <code>preference</code>, but within-pair order
is recognized.</p>
</dd>
<dt>gender</dt><dd><p>Factor coding gender.</p>
</dd>
<dt>age</dt><dd><p>Integer. Age of the respondents in years.</p>
</dd>
<dt>education</dt><dd><p>Ordered factor. Level of education: 1 no degree, 2
Hauptschule (Secondary General School), 3 Realschule (Intermediate
Secondary School), 4 Gymnasium (High School), 5 Studium (University)</p>
</dd>
<dt>crisis</dt><dd><p>Factor. Do you feel affected by the economic crisis?</p>
</dd>
<dt>interviewer</dt><dd><p>Factor. Interviewer id.</p>
</dd>
</dl>



<h3>Details</h3>

<p>A survey was conducted at the Department of Psychology, Universität
Tübingen, in June 2009, three months before the German election. The sample
was stratified by gender and age (younger versus older than 30 years) with
48 participants in each group.
</p>
<p>The parties to be compared were Die Linke (socialists), Die Grünen
(ecologists), SPD (social democrats), CDU/CSU (conservatives), and FDP
(liberals). In addition, there was the option of abstaining from voting
(coded as <code>none</code>).
</p>
<p>Participants were presented with 15 pairs of options in random order. On
each trial, their task was to choose the party they would rather vote for at
an election for the German parliament. A given participant compared each
pair in one order only, hence the NA's in <code>ordered.pref</code>.
</p>
<p>In order to minimize response biases, the pairs of options were read to the
participants one at a time. Participants made their choices by crossing
either &ldquo;First Option&rdquo; or &ldquo;Second Option&rdquo; on an anonymous
response sheet.
</p>
<p>The interviewers were Psychology Master's students who collected the data
for course credits. Since they mainly interviewed people they knew, the
results are not representative of the political opinions in Germany. As far
as the winner of the survey (Die Grünen) is concerned, however, the results
agree with the outcome of the election for the Tübingen voters.
</p>
<p>The results of the election on September 27, 2009 (number of
so-called Zweitstimmen in percent) were:
</p>

<table>
<tr>
 <td style="text-align: left;">
             </td><td style="text-align: right;"> Germany </td><td style="text-align: right;"> Tübingen</td>
</tr>
<tr>
 <td style="text-align: left;">
  Die Linke  </td><td style="text-align: right;">    11.9 </td><td style="text-align: right;">      8.5</td>
</tr>
<tr>
 <td style="text-align: left;">
  Die Grünen </td><td style="text-align: right;">    10.7 </td><td style="text-align: right;">     27.9</td>
</tr>
<tr>
 <td style="text-align: left;">
  SPD        </td><td style="text-align: right;">    23.0 </td><td style="text-align: right;">     21.1</td>
</tr>
<tr>
 <td style="text-align: left;">
  CDU/CSU    </td><td style="text-align: right;">    33.8 </td><td style="text-align: right;">     23.0</td>
</tr>
<tr>
 <td style="text-align: left;">
  FDP        </td><td style="text-align: right;">    14.6 </td><td style="text-align: right;">     13.9</td>
</tr>
<tr>
 <td style="text-align: left;">
  Others     </td><td style="text-align: right;">     6.0 </td><td style="text-align: right;">      5.7</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>The voter turnout was 70.8 percent in Germany and 80.5 percent in Tübingen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paircomp">paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("GermanParties2009", package = "psychotools")
summary(GermanParties2009$preference)
</code></pre>

<hr>
<h2 id='gpcmodel'>Generalized Partial Credit Model Fitting Function</h2><span id='topic+gpcmodel'></span><span id='topic+print.gpcmodel'></span><span id='topic+summary.gpcmodel'></span><span id='topic+print.summary.gpcmodel'></span><span id='topic+coef.gpcmodel'></span><span id='topic+bread.gpcmodel'></span><span id='topic+estfun.gpcmodel'></span><span id='topic+logLik.gpcmodel'></span><span id='topic+vcov.gpcmodel'></span>

<h3>Description</h3>

<p><code>gpcmodel</code> is a basic fitting function for generalized partial credit
models providing a wrapper around <code><a href="mirt.html#topic+mirt">mirt</a></code> and
<code><a href="mirt.html#topic+multipleGroup">multipleGroup</a></code> relying on marginal maximum likelihood (MML)
estimation via the standard EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpcmodel(y, weights = NULL, impact = NULL, type = c("GPCM", "PCM"),
  grouppars = FALSE, vcov = TRUE, nullcats = "downcode", 
  start = NULL, method = "BFGS", maxit = 500, reltol = 1e-5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpcmodel_+3A_y">y</code></td>
<td>
<p>item response object that can be coerced (via <code><a href="base.html#topic+as.matrix">as.matrix</a></code>)
to a numeric matrix with scores 0, 1, ... Typically, either
already a matrix, data frame, or dedicated object of class
<code><a href="#topic+itemresp">itemresp</a></code>.</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case
weights)</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="gpcmodel_+3A_impact">impact</code></td>
<td>
<p>an optional <code>factor</code> allowing for grouping
the subjects (rows). If specified, a multiple-group model is fitted
to account for impact (see details below). By default, no impact is
modelled, i.e., a single-group model is used.</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_type">type</code></td>
<td>
<p>character string, specifying the type of model to be
estimated. In addition to the default GPCM (generalized partial credit model)
it is also possible to estimate a standard PCM (partial credit model)
by marginal maximum likelihood (MML).</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_grouppars">grouppars</code></td>
<td>
<p>logical. Should the estimated distributional group parameters
of a multiple group model be included in the model parameters?</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_vcov">vcov</code></td>
<td>
<p>logical or character specifying the type of variance-covariance
matrix (if any) computed for the final model. The default <code>vcov = TRUE</code>
corresponds to <code>vcov = "Oakes"</code>, see <code><a href="mirt.html#topic+mirt">mirt</a></code> for
further options. If set to <code>vcov = FALSE</code> (or <code>vcov = "none"</code>),
<code>vcov()</code> will return a matrix of <code>NA</code>s only.</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_nullcats">nullcats</code></td>
<td>
<p>character string, specifying how items with
null categories (i.e., categories not observed) should be treated. Currently
only <code>"downcode"</code> is available, i.e., all categories above a null category are
shifted down to close the observed gap(s).</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_start">start</code></td>
<td>
<p>an optional vector or list of starting values (see examples
below).</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_method">method</code>, <code id="gpcmodel_+3A_maxit">maxit</code>, <code id="gpcmodel_+3A_reltol">reltol</code></td>
<td>
<p>control parameters for the optimizer employed by
<code><a href="mirt.html#topic+mirt">mirt</a></code> for the EM algorithm.</p>
</td></tr>
<tr><td><code id="gpcmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="mirt.html#topic+mirt">mirt</a></code> or
<code><a href="mirt.html#topic+multipleGroup">multipleGroup</a></code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gpcmodel</code> provides a basic fitting function for generalized partial
credit models (GPCMs) providing a wrapper around <code><a href="mirt.html#topic+mirt">mirt</a></code> (and
<code><a href="mirt.html#topic+multipleGroup">multipleGroup</a></code>, respectively) relying on MML estimation via
the standard EM algorithm (Bock &amp; Aitkin, 1981). Models are estimated under the
slope/intercept parametrization, see e.g. Chalmers (2012). The probability of
person <code class="reqn">i</code> falling into category <code class="reqn">x_{ij}</code> of item <code class="reqn">j</code> out of all
categories <code class="reqn">p_{j}</code> is modelled as:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{ij} = x_{ij}|\theta_{i},a_{j},\boldsymbol{d_{j}}) =
  \frac{\exp{(x_{ij}a_{j}\theta_{i} + d_{jx_{ij}})}}{\displaystyle\sum_{k = 0} ^
  {p_{j}}\exp{(ka_{j}\theta_{i} + d_{jk})}}</code>
</p>

<p>Note that all <code class="reqn">d_{j0}</code> are fixed at 0. A reparametrization of the
intercepts to the classical IRT parametrization, see e.g. Muraki (1992), is
provided via <code><a href="#topic+threshpar">threshpar</a></code>.
</p>
<p>If an optional <code>impact</code> variable is supplied, a multiple-group model of
the following form is being fitted: Item parameters are fixed to be equal
across the whole sample. For the first group of the <code>impact</code> variable the
person parameters are fixed to follow the standard normal distribution. In the
remaining <code>impact</code> groups, the distributional parameters (mean and
variance of a normal distribution) of the person parameters are
estimated freely. See e.g. Baker &amp; Kim (2004, Chapter 11), Debelak &amp; Strobl
(2019), or Schneider et al. (2022) for further details. To improve convergence of the model fitting
algorithm, the first level of the <code>impact</code> variable should always correspond
to the largest group. If this is not the case, levels are re-ordered internally.
</p>
<p>If <code>grouppars</code> is set to <code>TRUE</code> the freely estimated distributional
group parameters (if any) are returned as part of the model parameters.
</p>
<p>Instead of the default GPCM, a standard partial credit model (PCM) can also
be estimated via MML by setting <code>type = "PCM"</code>. In this case all slopes
are restricted to be equal across all items.
</p>
<p><code>gpcmodel</code> returns an object of class <code>"gpcmodel"</code> for which
several basic methods are available, including <code>print</code>, <code>plot</code>,
<code>summary</code>, <code>coef</code>, <code>vcov</code>, <code>logLik</code>, <code>estfun</code>,
<code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>, and
<code><a href="#topic+personpar">personpar</a></code>.
</p>


<h3>Value</h3>

<p><code>gpcmodel</code> returns an S3 object of class <code>"gpcmodel"</code>, 
i.e., a list of the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated model parameters in slope/intercept parametrization,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of the model parameters,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>modified data, used for model-fitting, i.e., centralized so
that the first category is zero for all items, treated null categories as
specified via argument <code>"nullcats"</code> and without observations with zero
weight,</p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>logical vector of length <code>ncol(y)</code>, indicating
which items were used during estimation,</p>
</td></tr>
<tr><td><code>categories</code></td>
<td>
<p>list of length <code>ncol(y)</code>, containing integer
vectors starting from one to the number of categories minus one per
item,</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>n_org</code></td>
<td>
<p>original number of observations in <code>y</code>,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>logical indicating whether the data contain <code>NA</code>s,</p>
</td></tr>
<tr><td><code>nullcats</code></td>
<td>
<p>currently always <code>NULL</code> as eventual items with null
categories are handled via <code>"downcode"</code>,</p>
</td></tr>
<tr><td><code>impact</code></td>
<td>
<p>either <code>NULL</code> or the supplied <code>impact</code> variable
with the levels reordered in decreasing order (if this has not been the case
prior to fitting the model),</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>number of estimated (more precisely, returned) model parameters,</p>
</td></tr>
<tr><td><code>code</code></td>
<td>
<p>convergence code from <code>mirt</code>,</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>number of iterations used by <code>mirt</code>,</p>
</td></tr>
<tr><td><code>reltol</code></td>
<td>
<p>convergence threshold passed to <code>mirt</code>,</p>
</td></tr>
<tr><td><code>grouppars</code></td>
<td>
<p>the logical <code>grouppars</code> value,</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the <code>type</code> of model restriction specified,</p>
</td></tr>
<tr><td><code>mirt</code></td>
<td>
<p>the <code>mirt</code> object fitted internally,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>original function call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Baker FB, Kim SH (2004).
<em>Item Response Theory: Parameter Estimation Techniques</em>.
Chapman &amp; Hall/CRC, Boca Raton.
</p>
<p>Bock RD, Aitkin M (1981).
Marginal Maximum Likelihood Estimation of Item Parameters: Application of an EM Algorithm.
<em>Psychometrika</em>, <b>46</b>(4), 443&ndash;459.
</p>
<p>Chalmers RP (2012).
mirt: A Multidimensional Item Response Theory Package for the R Environment.
<em>Journal of Statistical Software</em>, <b>48</b>(6), 1&ndash;29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Debelak R, Strobl C (2019).
Investigating Measurement Invariance by Means of Parameter Instability Tests for 2PL and 3PL Models.
<em>Educational and Psychological Measurement</em>, <b>79</b>(2), 385&ndash;398.
<a href="https://doi.org/10.1177/0013164418777784">doi:10.1177/0013164418777784</a>
</p>
<p>Muraki E (1992).
A Generalized Partial Credit Model: Application of an EM Algorithm.
<em>Applied Psychological Measurement</em>, <b>16</b>(2), 159&ndash;176.
</p>
<p>Schneider L, Strobl C, Zeileis A, Debelak R (2022).
An R Toolbox for Score-Based Measurement Invariance Tests in IRT Models.
<em>Behavior Research Methods</em>, forthcoming.
<a href="https://doi.org/10.3758/s13428-021-01689-0">doi:10.3758/s13428-021-01689-0</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+rsmodel">rsmodel</a></code>, <code><a href="#topic+nplmodel">nplmodel</a></code>,
<code><a href="#topic+raschmodel">raschmodel</a></code>, <code><a href="#topic+btmodel">btmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("mirt")) {

o &lt;- options(digits = 4)

## mathematics 101 exam results
data("MathExam14W", package = "psychotools")

## generalized partial credit model
gpcm &lt;- gpcmodel(y = MathExam14W$credit)
summary(gpcm)

## how to specify starting values as a vector of model parameters
st &lt;- coef(gpcm)
gpcm &lt;- gpcmodel(y = MathExam14W$credit, start = st)
## or a list containing a vector of slopes and a list of intercept vectors
## itemwise
set.seed(0)
st &lt;- list(a = rlnorm(13, 0, 0.0625), d = replicate(13, rnorm(2, 0, 1), FALSE))
gpcm &lt;- gpcmodel(y = MathExam14W$credit, start = st)

## visualizations
plot(gpcm, type = "profile")
plot(gpcm, type = "regions")
plot(gpcm, type = "piplot")
plot(gpcm, type = "curves", xlim = c(-6, 6))
plot(gpcm, type = "information", xlim = c(-6, 6))
## visualizing the IRT parametrization
plot(gpcm, type = "curves", xlim = c(-6, 6), items = 1)
abline(v = threshpar(gpcm)[[1]])
abline(v = itempar(gpcm)[1], lty = 2)

options(digits = o$digits)
}
</code></pre>

<hr>
<h2 id='guesspar'>Extract Guessing Parameters of Item Response Models</h2><span id='topic+guesspar'></span><span id='topic+guesspar.raschmodel'></span><span id='topic+guesspar.rsmodel'></span><span id='topic+guesspar.pcmodel'></span><span id='topic+guesspar.nplmodel'></span><span id='topic+guesspar.gpcmodel'></span><span id='topic+coef.guesspar'></span><span id='topic+print.guesspar'></span><span id='topic+vcov.guesspar'></span>

<h3>Description</h3>

<p>A class and generic function for representing and extracting the
so-called guessing parameters of a given item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  guesspar(object, ...)
  ## S3 method for class 'raschmodel'
guesspar(object, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'rsmodel'
guesspar(object, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'pcmodel'
guesspar(object, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'nplmodel'
guesspar(object, alias = TRUE, logit = FALSE, vcov = TRUE, ...)
  ## S3 method for class 'gpcmodel'
guesspar(object, alias = TRUE, vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="guesspar_+3A_object">object</code></td>
<td>
<p>a fitted model object whose guessing parameters should be
extracted.</p>
</td></tr>
<tr><td><code id="guesspar_+3A_alias">alias</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the aliased parameters
are included in the return vector (and in the variance-covariance matrix if
<code>vcov</code> = TRUE). If <code>FALSE</code>, these parameters are removed. For
<code>raschmodel</code>s, <code>rsmodel</code>s, <code>pcmodel</code>s and <code>gpcmodel</code>s,
where all guessing parameters are fixed to 0, this means that an
empty numeric vector and an empty variance-covariace matrix is returned if
<code>alias</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="guesspar_+3A_logit">logit</code></td>
<td>
<p>logical. If a <code>nplmodel</code> of <code>type</code> <code>"3PL"</code> or
<code>"4PL"</code> model has been fit, the guessing parameters were estimated on the
logit scale. If <code>logit = FALSE</code>, these estimates and the
variance-covariance (if requested) are retransformed using the logistic
function and the delta method.</p>
</td></tr>
<tr><td><code id="guesspar_+3A_vcov">vcov</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the variance-covariance
matrix of the guessing parameters is attached as attribute
<code>vcov</code>.</p>
</td></tr>
<tr><td><code id="guesspar_+3A_...">...</code></td>
<td>
<p>further arguments which are currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>guesspar</code> is both, a class to represent guessing parameters of item
response models as well as a generic function. The generic function can be
used to extract the guessing parameters of a given item response model.
</p>
<p>For objects of class <code>guesspar</code>, several methods to standard generic
functions exist: <code>print</code>, <code>coef</code>, <code>vcov</code>. <code>coef</code> and
<code>vcov</code> can be used to extract the guessing parameters and their
variance-covariance matrix without additional attributes.
</p>


<h3>Value</h3>

<p>A named vector with guessing parameters of class <code>guesspar</code> and
additional attributes <code>model</code> (the model name), <code>alias</code> (either
<code>TRUE</code> or a named numeric vector with the aliased parameters not included
in the return value), <code>logit</code> (indicating whether the estimates are on the
logit scale or not), and <code>vcov</code> (the estimated and adjusted
variance-covariance matrix).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+personpar">personpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>,
<code><a href="#topic+threshpar">threshpar</a></code>, <code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+upperpar">upperpar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("mirt")) {

o &lt;- options(digits = 3)

## load simulated data
data("Sim3PL", package = "psychotools")

## fit 2PL to data simulated under the 3PL
twoplmod &lt;- nplmodel(Sim3PL$resp)

## extract the guessing parameters (all fixed at 0)
gp1 &lt;- guesspar(twoplmod)

## fit 3PL to data simulated under the 3PL
threeplmod &lt;- nplmodel(Sim3PL$resp, type = "3PL")

## extract the guessing parameters
gp2 &lt;- guesspar(threeplmod)

## extract the standard errors
sqrt(diag(vcov(gp2)))

## extract the guessing parameters on the logit scale
gp2_logit &lt;- guesspar(threeplmod, logit = TRUE)

## along with the delta transformed standard errors
sqrt(diag(vcov(gp2_logit)))

options(digits = o$digits)
}
</code></pre>

<hr>
<h2 id='infoplot'>Information Plots for IRT Models</h2><span id='topic+infoplot'></span>

<h3>Description</h3>

<p>Base graphics plotting function for information plot visualization of IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  infoplot(object, what = c("categories", "items", "test"),
    ref = NULL, items = NULL, names = NULL, layout = NULL, xlim = NULL,
    ylim = NULL, col = NULL, lty = NULL, lwd = NULL, main = NULL, legend = TRUE,
    xlab = "Latent trait", ylab = "Information", add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infoplot_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>"raschmodel"</code>,
<code>"rsmodel"</code>, <code>"pcmodel"</code>, <code>"nplmodel"</code> or <code>"gpcmodel"</code>.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_what">what</code></td>
<td>
<p>character, specifying the type of information to visualize.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_ref">ref</code></td>
<td>
<p>argument passed over to internal calls of <code><a href="stats.html#topic+predict">predict</a></code>.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_items">items</code></td>
<td>
<p>character or numeric, specifying the items for which information
curves should be visualized.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_names">names</code></td>
<td>
<p>character, specifying labels for the items.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_layout">layout</code></td>
<td>
<p>matrix, specifying how the item or category information curves
of different items should be arranged. If <code>null</code> and <code>what</code> is set
to <code>"items"</code>, the item information curves are overlayed within a single
plot.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_xlim">xlim</code>, <code id="infoplot_+3A_ylim">ylim</code></td>
<td>
<p>numeric, specifying the x and y axis limits.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_col">col</code></td>
<td>
<p>character, specifying the colors of the test, item or category
information curves.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_lty">lty</code></td>
<td>
<p>numeric, specifying the line type of the information curves.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_lwd">lwd</code></td>
<td>
<p>numeric, specifying the line width of the information curves.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_main">main</code></td>
<td>
<p>character, specifying the overall title of the plot.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_legend">legend</code></td>
<td>
<p>logical, specifying if a legend is drawn when multiple item
information curves are overlayed. The labels in the legend correspond to
the item names (which can be specified in the argument <code>names</code>).</p>
</td></tr>
<tr><td><code id="infoplot_+3A_xlab">xlab</code>, <code id="infoplot_+3A_ylab">ylab</code></td>
<td>
<p>character, specifying the x and y axis labels.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_add">add</code></td>
<td>
<p>logical. If <code>TRUE</code>, new information curves are added to
an existing plot. Only possible for a test or a single item information
curve.</p>
</td></tr>
<tr><td><code id="infoplot_+3A_...">...</code></td>
<td>
<p>further arguments passed to internal calls of
<code><a href="graphics.html#topic+matplot">matplot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The information plot visualization illustrates the test, item or category
information as a function of the ability parameter <code class="reqn">\theta</code> under a
certain IRT model. Further details on the computation of the displayed
information can be found on the help page of the function
<code><a href="#topic+predict.pcmodel">predict.pcmodel</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+curveplot">curveplot</a></code>, <code><a href="#topic+regionplot">regionplot</a></code>,
<code><a href="#topic+profileplot">profileplot</a></code>, <code><a href="#topic+piplot">piplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit Rasch and partial credit model to verbal aggression data
rmmod &lt;- raschmodel(VerbalAggression$resp2)
pcmod &lt;- pcmodel(VerbalAggression$resp)

## category information plots for all items under the dichotomous RM
plot(rmmod, type = "information", what = "categories")

## category information plots for all items under the PCM
plot(pcmod, type = "information", what = "categories")

## overlayed item information plots for the first six items of the
## data set under the PCM
plot(pcmod, type = "information", what = "items", items = 1:6)

## a comparison of the item information for the first six items under the
## dichotomous RM and the PCM
plot(pcmod, type = "information", what = "items", items = 1:6,
  xlim = c(-5, 5))
plot(rmmod, type = "information", what = "items", items = 1:6,
  lty = 2, add = TRUE)
legend(x = "topright", legend = c("PCM", "RM"), lty = 1:2, bty = "n")

## a comparison of the test information based on all items of the
## data set under the dichotomous RM and the PCM
plot(pcmod, type = "information", what = "test", items = 1:6, xlim = c(-5, 5))
plot(rmmod, type = "information", what = "test", items = 1:6, lty = 2,
  add = TRUE)
legend(x = "topright", legend = c("PCM", "RM"), lty = 1:2, bty = "n")

if(requireNamespace("mirt")) {
## fit 2PL to verbal aggression data
twoplmod &lt;- nplmodel(VerbalAggression$resp2)

## category information plots for all items under the dichotomous 2PL
plot(twoplmod, type = "information", what = "categories")
}
</code></pre>

<hr>
<h2 id='itempar'>Extract Item Parameters of Item Response Models</h2><span id='topic+itempar'></span><span id='topic+itempar.btmodel'></span><span id='topic+itempar.raschmodel'></span><span id='topic+itempar.rsmodel'></span><span id='topic+itempar.pcmodel'></span><span id='topic+itempar.nplmodel'></span><span id='topic+itempar.gpcmodel'></span><span id='topic+itempar.raschtree'></span><span id='topic+itempar.bttree'></span><span id='topic+coef.itempar'></span><span id='topic+print.itempar'></span><span id='topic+vcov.itempar'></span>

<h3>Description</h3>

<p>A class and generic function for representing and extracting the item
parameters of a given item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  itempar(object, ...)
  ## S3 method for class 'raschmodel'
itempar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'rsmodel'
itempar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'pcmodel'
itempar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'nplmodel'
itempar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'gpcmodel'
itempar(object, ref = NULL, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'btmodel'
itempar(object, ref = NULL, alias = TRUE, vcov = TRUE, log = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itempar_+3A_object">object</code></td>
<td>
<p>a fitted model or tree object whose item parameters should be extracted.</p>
</td></tr>
<tr><td><code id="itempar_+3A_ref">ref</code></td>
<td>
<p>a vector of labels or position indices of item parameters or a
contrast matrix which should be used as restriction/for normalization. If
<code>NULL</code> (the default) for all models except models estimated via MML,
all items are used (sum zero restriction). For models estimated via MML
(<code>nplmodel</code>s and <code>gpcmodel</code>s), the parameters are by default
identified via the distributional parameters of the person parameters (mean
and variance of a normal distribution). Nevertheless, a restriction on the
interval scale can be applied.</p>
</td></tr>
<tr><td><code id="itempar_+3A_alias">alias</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the aliased parameter is
included in the return vector (and in the variance-covariance matrix if
<code>vcov</code> = TRUE). If <code>FALSE</code>, it is removed. If the restriction
given in <code>ref</code> depends on several parameters, the first parameter of
the restriction specified is (arbitrarily) chosen to be removed if
<code>alias</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="itempar_+3A_vcov">vcov</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the (transformed)
variance-covariance matrix of the item parameters is attached as
attribute <code>vcov</code>. If <code>FALSE</code>, an <code>NA</code>-matrix is attached.</p>
</td></tr>
<tr><td><code id="itempar_+3A_log">log</code></td>
<td>
<p>logical. Whether to return the estimated model parameters
on the logit (<code>TRUE</code>) or preference scale (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="itempar_+3A_...">...</code></td>
<td>
<p>further arguments which are currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>itempar</code> is both, a class to represent item parameters of item
response models as well as a generic function. The generic function can be
used to extract the item parameters of a given item response model.
</p>
<p>For Rasch models and n-parameter logistic models, <code>itempar</code> returns the
estimated item difficulty parameters <code class="reqn">\hat{\beta}_{j}</code> under the
restriction specified in argument <code>ref</code>. For rating scale models,
<code>itempar</code> returns computed item location parameters <code class="reqn">\hat{\beta}_{j}</code>
under the restriction specified in argument <code>ref</code>. These are computed
from the estimated item-specific parameters <code class="reqn">\hat{\xi}_{j}</code> (who mark the
location of the first category of an item on the latent theta axis). For
partial credit models and generalized partial credit models, <code>itempar</code>
returns &lsquo;mean&rsquo; absolute item threshold parameters, <code class="reqn">\hat{\beta}_{j}
  = \frac{1}{p_{j}} \sum_{k = 1}^{p_{j}}\hat{\delta}_{jk}</code>, i.e., a single
parameter per item is returned which results as the mean of the absolute item
threshold parameters <code class="reqn">\hat{\delta}_{jk}</code> of this item. Based upon these
&lsquo;mean&rsquo; absolute item threshold parameters <code class="reqn">\hat{\beta}_{j}</code>, the
restriction specified in argument <code>ref</code> is applied. For all models, the
variance-covariance matrix of the returned item parameters is adjusted
according to the multivariate delta rule.
</p>
<p>For objects of class <code>itempar</code>, several methods to standard generic
functions exist: <code>print</code>, <code>coef</code>, <code>vcov</code>. <code>coef</code> and
<code>vcov</code> can be used to extract the estimated calculated item parameters
and their variance-covariance matrix without additional attributes. Based on
this Wald tests or confidence intervals can be easily computed, e.g., via
<code>confint</code>.
</p>
<p>Two-sample item-wise Wald tests for DIF in the item parameters can be
carried out using the function <code><a href="#topic+anchortest">anchortest</a></code>.
</p>


<h3>Value</h3>

<p>A named vector with item parameters of class <code>itempar</code> and additional
attributes <code>model</code> (the model name), <code>ref</code> (the items or parameters
used as restriction/for normalization), <code>alias</code> (either <code>FALSE</code> or a
named character vector with the removed aliased parameter, and <code>vcov</code>
(the adjusted covariance matrix of the estimates if <code>vcov = TRUE</code> or an
<code>NA</code>-matrix otherwise).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+personpar">personpar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>,
<code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+guesspar">guesspar</a></code>, <code><a href="#topic+upperpar">upperpar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit a Rasch model to dichotomized verbal aggression data
raschmod &lt;- raschmodel(VerbalAggression$resp2)

## extract item parameters with sum zero or use last two items as anchor
ip1 &lt;- itempar(raschmod)
ip2a &lt;- itempar(raschmod, ref = 23:24) # with position indices
ip2b &lt;- itempar(raschmod, ref = c("S4WantShout", "S4DoShout")) # with item label

ip1
ip2a

all.equal(ip2a, ip2b)

## extract vcov
vc1 &lt;- vcov(ip1)
vc2 &lt;- vcov(ip2a)

## adjusted standard errors,
## smaller with more items used as anchors
sqrt(diag(vc1))
sqrt(diag(vc2))

## Wald confidence intervals
confint(ip1)
confint(ip2a)

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='itemresp'>Data Structure for Item Response Data</h2><span id='topic+itemresp'></span><span id='topic+is.na.itemresp'></span><span id='topic+labels.itemresp'></span><span id='topic+labels+3C-.itemresp'></span><span id='topic+length.itemresp'></span><span id='topic+levels.itemresp'></span><span id='topic+mscale.itemresp'></span><span id='topic+mscale+3C-.itemresp'></span><span id='topic+names.itemresp'></span><span id='topic+names+3C-.itemresp'></span><span id='topic+rep.itemresp'></span><span id='topic+str.itemresp'></span><span id='topic+xtfrm.itemresp'></span>

<h3>Description</h3>

<p>A class for representing data from questionnaires
along with methods for many generic functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  itemresp(data, mscale = NULL, labels = NULL, names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemresp_+3A_data">data</code></td>
<td>
<p>matrix or data frame. A matrix or data frame with integer
values or factors where the rows correspond to subjects and the
columns to items. See below for details.</p>
</td></tr>
<tr><td><code id="itemresp_+3A_mscale">mscale</code></td>
<td>
<p>integer or character. A list of vectors (either integer
or character) giving the measurement scale.
See below for details. By default guessed from <code>data</code>.</p>
</td></tr>
<tr><td><code id="itemresp_+3A_labels">labels</code></td>
<td>
<p>character. A vector of character labels for the items.
By default, the column names of <code>data</code> are used or, if these are
not available, the string <code>"item"</code> along with numbers 1, 2, ...
is used.</p>
</td></tr>
<tr><td><code id="itemresp_+3A_names">names</code></td>
<td>
<p>character. A vector of names (or IDs) for the subjects. By default,
no subject names are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>itemresp</code> is designed for item response data of
<code class="reqn">n</code> subjects for <code class="reqn">k</code> items.
</p>
<p>The item responses should be coded in a matrix <code>data</code>
with <code class="reqn">n</code> rows (subjects) and <code class="reqn">k</code> columns (items). Alternatively,
<code>data</code> can be a data frame with <code class="reqn">n</code> rows (subjects) and
<code class="reqn">k</code> variables (items), which can be either factors or integer
valued vectors.
</p>
<p><code>mscale</code> provides the underlying measurement scale either as
integer or character vector(s). If all items are measured on the same
scale, <code>mscale</code> can be a vector. Alternatively, it can be
provided as a named list of vectors for each item. If the list
contains one unnamed element, this element will be used as the
measurement scale for items that have not been named. Integers or
characters not present in <code>mscale</code> but in <code>data</code> will be
replaced by <code>NA</code>. All items must be measured with at least 2
categories. By default, <code>mscale</code> is set to the full range of
observed values for all integer items (see example below) and the
corresponding levels for all factor items in <code>data</code>.
</p>
<p>Methods to standard generic functions include: <code>str</code>,
<code>length</code> (number of subjects), <code>dim</code> (number of subjects and
items), <code>is.na</code> (only <code>TRUE</code> if all item responses are
<code>NA</code> for a subject), <code>print</code> (see
<code><a href="#topic+print.itemresp">print.itemresp</a></code> for details), <code>summary</code> and
<code>plot</code> (see <code><a href="#topic+summary.itemresp">summary.itemresp</a></code> for details),
subsetting via <code>[</code> and <code>subset</code> (see
<code><a href="#topic+subset.itemresp">subset.itemresp</a></code> for details), <code>is.itemresp</code> and
various coercion functions to other classes (see
<code><a href="#topic+as.list.itemresp">as.list.itemresp</a></code> for details).
</p>
<p>Extracting/replacing properties is available through: <code>labels</code> for the item labels,
<code>mscale</code> for the measurement scale, <code>names</code> for subject names/IDs.
</p>


<h3>Value</h3>

<p><code>itemresp</code> returns an object of class <code>"itemresp"</code> which is
a matrix (<code>data</code> transformed to integers 0, 1, ...) plus an
attribute <code>"mscale"</code> as a named list for each item
(after being checked and potentially suitably coerced or transformed
to all integer or all character).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.itemresp">print.itemresp</a></code>, <code><a href="#topic+summary.itemresp">summary.itemresp</a></code>,
<code><a href="#topic+as.list.itemresp">as.list.itemresp</a></code>, <code><a href="#topic+subset.itemresp">subset.itemresp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## binary responses to three items, coded as matrix
x &lt;- cbind(c(1, 0, 1, 0), c(1, 0, 0, 0), c(0, 1, 1, 1))
## transformed to itemresp object
xi &lt;- itemresp(x)

## printing (see also ?print.itemresp)
print(xi)
print(xi, labels = TRUE)

## subsetting/indexing (see also ?subset.itemresp)
xi[2]
xi[c(TRUE, TRUE, FALSE, FALSE)]
subset(xi, items = 1:2)
dim(xi)
length(xi)

## summary/visualization (see also ?summary.itemresp)
summary(xi)
plot(xi)

## query/set measurement scale labels
## extract mscale (tries to collapse to vector)
mscale(xi)
## extract as list
mscale(xi, simplify = FALSE)
## replacement by list
mscale(xi) &lt;- list(item1 = c("no", "yes"),
  item2 = c("nay", "yae"), item3 = c("-", "+"))
xi
mscale(xi)
## replacement with partially named list plus default
mscale(xi) &lt;- list(item1 = c("n", "y"), 0:1)
mscale(xi)
## replacement by vector (if number of categories constant)
mscale(xi) &lt;- c("-", "+")
mscale(xi, simplify = FALSE)

## query/set item labels and subject names
labels(xi)
labels(xi) &lt;- c("i1", "i2", "i3")
names(xi)
names(xi) &lt;- c("John", "Joan", "Jen", "Jim")
print(xi, labels = TRUE)

## coercion (see also ?as.list.itemresp)
## to integer matrix
as.matrix(xi)
## to data frame with single itemresp column
as.data.frame(xi)
## to list of factors
as.list(xi)
## to data frame with factors
as.list(xi, df = TRUE)


## polytomous responses with missing values and unequal number of
## categories in a data frame
d &lt;- data.frame(
  q1 = c(-2, 1, -1, 0, NA, 1, NA),
  q2 = c(3, 5, 2, 5, NA, 2, 3),
  q3 = factor(c(1, 2, 1, 2, NA, 3, 2), levels = 1:3,
    labels = c("disagree", "neutral", "agree")))
di &lt;- itemresp(d)
di

## auto-completion of mscale: full range (-2, ..., 2) for q1, starting
## from smallest observed (negative) value (-2) to the same (positive)
## value (2), full (positive) range for q2, starting from smallest
## observed value (2) to largest observed value (5), missing category of
## 4 is detected, for q3 given factor levels are used
mscale(di)

## set mscale for q2 and add category 1, q1 and q3 are auto-completed:
di &lt;- itemresp(d, mscale = list(q2 = 1:5))

## is.na.itemresp - only true for observation 5 (all missing)
is.na(di)

## illustration for larger data set
data("VerbalAggression", package = "psychotools")
r &lt;- itemresp(VerbalAggression$resp[, 1:12])
str(r)
head(r)
plot(r)
summary(r)
prop.table(summary(r), 1)

## dichotomize response
r2 &lt;- r
mscale(r2) &lt;- c(0, 1, 1)
plot(r2)

## transform to "likert" package
if(require("likert")) {
lik &lt;- likert(as.data.frame(as.list(r)))
lik
plot(lik)
}
</code></pre>

<hr>
<h2 id='labels+26lt+3B-'>Set Labels</h2><span id='topic+labels+3C-'></span>

<h3>Description</h3>

<p>A generic function for setting labels for an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  labels(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="labels+2B26lt+2B3B-_+3A_object">object</code></td>
<td>
<p>an object.</p>
</td></tr>
<tr><td><code id="labels+2B26lt+2B3B-_+3A_value">value</code></td>
<td>
<p>an object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## method for "paircomp" data
pc &lt;- paircomp(rbind(
  c(1,  1,  1), # a &gt; b, a &gt; c, b &gt; c
  c(1,  1, -1), # a &gt; b, a &gt; c, b &lt; c
  c(1, -1, -1), # a &gt; b, a &lt; c, b &lt; c
  c(1,  1,  1)))
labels(pc)
labels(pc) &lt;- c("ah", "be", "ce")
pc
</code></pre>

<hr>
<h2 id='MathExam14W'>Mathematics 101 Exam Results</h2><span id='topic+MathExam14W'></span>

<h3>Description</h3>

<p>Responses of 729 students to 13 items in a written
exam of introductory mathematics along with several covariates. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("MathExam14W")</code></pre>


<h3>Format</h3>

<p>A data frame containing 729 observations on 9 variables.
</p>

<dl>
<dt>solved</dt><dd><p>Item response matrix (of class <code><a href="#topic+itemresp">itemresp</a></code>) with
values 1/0 coding solved correctly/other.</p>
</dd>
<dt>credits</dt><dd><p>Item response matrix (of class <code><a href="#topic+itemresp">itemresp</a></code>) with
values 2/1/0 coding solved correctly/incorrectly/not attempted.</p>
</dd>
<dt>nsolved</dt><dd><p>Integer. The number of items solved correctly.</p>
</dd>
<dt>tests</dt><dd><p>Integer. The number of online test exercises solved
correctly prior to the written exam.</p>
</dd>
<dt>gender</dt><dd><p>Factor indicating gender.</p>
</dd>
<dt>study</dt><dd><p>Factor indicating two different types of business/economics
degrees. Either the 3-year bachelor program (571) or the 4-year
diploma program (155).</p>
</dd>
<dt>semester</dt><dd><p>Integer. The number of semesters enrolled in the given
university program.</p>
</dd>
<dt>attempt</dt><dd><p>Factor. The number of times the course/exam has
been attempted (including the current attempt).</p>
</dd>
<dt>group</dt><dd><p>Factor indicating whether the students were in the
first or second batch (with somewhat different items) in the exam.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data provides individual end-term exam results from a Mathematics 101
course for first-year business and economics students at Universität Innsbruck.
The format of the course comprised biweekly online tests (26 numeric exercises,
conducted in OpenOLAT) and a written exam at the end of the semester (13
single-choice exercises with five answer alternatives). The course covers
basics of analysis, linear algebra, financial mathematics, and probability
calculus (where the latter is not assessed in this exam).
</p>
<p>In this exam, 729 students participated (out of 941 registered in the course).
To avoid cheating, all students received items with essentially the same questions
but different numbers (using the exams infrastructure of Zeileis et al. 2014).
Also, due to the large number of students two groups of students had to be formed
which received partially different items. The items which differed (namely 1, 5,
6, 7, 8, 9, 11, 12) varied in the setup/story, but not in the 
mathematical skills needed to solve the exercises. Prior to the exam,
the students could select themselves either into the first group (early in the morning)
or the second group (starting immediately after the end of the first group).
</p>
<p>Correctly solved items yield 100 percent of the associated points. Items
without correct solution can either be unanswered (0 percent) or receive an
incorrect answer (minus 25 percent) to discourage random guessing. In the examples
below, the items are mostly only considered as binary. Typically, students with
8 out of 13 correct answers passed the course.
</p>


<h3>Source</h3>

<p>Department of Statistics, Universität Innsbruck
</p>


<h3>References</h3>

<p>Zeileis A, Umlauf N, Leisch F (2014).
Flexible Generation of E-Learning Exams in R: Moodle Quizzes, OLAT Assessments, and Beyond.
<em>Journal of Statistical Software</em>, <b>58</b>(1), 1&ndash;36.
doi:10.18637/jss.v058.i01
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemresp">itemresp</a></code>, <code><a href="#topic+raschmodel">raschmodel</a></code>, <code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+anchortest">anchortest</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load data and exclude extreme scorers
data("MathExam14W", package = "psychotools")
MathExam14W &lt;- transform(MathExam14W,
  points = 2 * nsolved - 0.5 * rowSums(credits == 1)
)
me &lt;- subset(MathExam14W, nsolved &gt; 0 &amp; nsolved &lt; 13)


## item response data:
## solved (correct/other) or credits (correct/incorrect/not attempted)
par(mfrow = c(1, 2))
plot(me$solved)
plot(me$credits)

## PCA
pr &lt;- prcomp(me$solved, scale = TRUE)
names(pr$sdev) &lt;- 1:10
plot(pr, main = "", xlab = "Number of components")
biplot(pr, col = c("transparent", "black"), main = "",
  xlim = c(-0.065, 0.005), ylim = c(-0.04, 0.065))


## points achieved (and 50% threshold)
par(mfrow = c(1, 1))
hist(MathExam14W$points, breaks = -4:13 * 2 + 0.5,
  col = "lightgray", main = "", xlab = "Points")
abline(v = 12.5, lwd = 2, col = 2)


## Rasch and partial credit model
ram &lt;- raschmodel(me$solved)
pcm &lt;- pcmodel(me$credits)

## various types of graphics displays
plot(ram, type = "profile")
plot(pcm, type = "profile", add = TRUE, col = "blue")
plot(ram, type = "piplot")
plot(pcm, type = "piplot")
plot(ram, type = "region")
plot(pcm, type = "region")
plot(ram, type = "curves")
plot(pcm, type = "curves")



## test for differential item function with automatic anchoring
## passing vs. not passing students
at1 &lt;- anchortest(solved ~ factor(nsolved &lt;= 7), data = me,
  adjust = "single-step")
at1
plot(at1$final_tests)
## -&gt; "good" students discriminate somewhat more
## (quad/payflow/lagrange are slightly more difficult)

## group 1 vs. group 2
at2 &lt;- anchortest(solved ~ group, data = me, adjust = "single-step")
at2
plot(at2$final_tests)
## -&gt; quad/payflow/planning easier for group 1
## -&gt; hesse slightly easier for group 2

## bring out differences between groups 1 and 2
## by (anchored) item difficulty profiles
ram1 &lt;- raschmodel(subset(me, group == "1")$solved)
ram2 &lt;- raschmodel(subset(me, group == "2")$solved)
plot(ram1, parg = list(ref = at2$anchor_items), ylim = c(-2, 3))
plot(ram2, parg = list(ref = at2$anchor_items), add = TRUE, col = "blue")
legend("topleft", c("Group 1", "Group 2"), pch = 21,
  pt.bg = c("lightgray", "blue"), bty = "n")

</code></pre>

<hr>
<h2 id='MemoryDeficits'>Memory Deficits in Psychiatric Patients</h2><span id='topic+MemoryDeficits'></span>

<h3>Description</h3>

<p>Response frequencies of 96 patients who took part in a pair-clustering
experiment to assess their memory deficits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("MemoryDeficits")</code></pre>


<h3>Format</h3>

<p>A data frame containing 576 observations on 7 variables.
</p>

<dl>
<dt>ID</dt><dd><p>Participant ID.</p>
</dd>
<dt>group</dt><dd><p>Factor with four levels specifying patient or control group
of participant.</p>
</dd>
<dt>trial</dt><dd><p>Trial number from 1 to 6.</p>
</dd>
<dt>E1</dt><dd><p>Number of pairs recalled adjacently.</p>
</dd>
<dt>E2</dt><dd><p>Number of pairs recalled non-adjacently.</p>
</dd>
<dt>E3</dt><dd><p>Number of single pair members recalled.</p>
</dd>
<dt>E4</dt><dd><p>Number of non-recalled pairs.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Riefer, Knapp, Batchelder, Bamber and Manifold (2002) report a study on
memory deficits in schizophrenic (n = 29) and organic alcoholic (n = 21)
patients who were compared to two matched control groups (n = 25, n = 21).
Participants were presented with 20 pairs of semantically related words. In
a later memory test, they freely recalled the presented words. This
procedure was repeated for a total of six study and test trials. Responses
were classified into four categories: both words in a pair are recalled
adjacently (E1) or non-adjacently (E2), one word in a pair is recalled (E3),
neither word in a pair is recalled (E4).
</p>


<h3>Source</h3>

<p>The data were made available by William H. Batchelder.
</p>


<h3>References</h3>

<p>Riefer DM, Knapp BR, Batchelder WH, Bamber D, Manifold V (2002).
Cognitive Psychometrics: Assessing Storage and Retrieval Deficits in Special Populations with Multinomial Processing Tree Models.
<em>Psychological Assessment</em>, <b>14</b>, 184&ndash;201.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("MemoryDeficits", package = "psychotools")
aggregate(cbind(E1, E2, E3, E4) ~ trial + group, MemoryDeficits, sum)
</code></pre>

<hr>
<h2 id='mptmodel'>Multinomial Processing Tree (MPT) Model Fitting Function</h2><span id='topic+mptmodel'></span><span id='topic+coef.mptmodel'></span><span id='topic+confint.mptmodel'></span><span id='topic+deviance.mptmodel'></span><span id='topic+estfun.mptmodel'></span><span id='topic+logLik.mptmodel'></span><span id='topic+predict.mptmodel'></span><span id='topic+print.mptmodel'></span><span id='topic+summary.mptmodel'></span><span id='topic+print.summary.mptmodel'></span><span id='topic+vcov.mptmodel'></span><span id='topic+mptspec'></span><span id='topic+print.mptspec'></span><span id='topic+update.mptspec'></span>

<h3>Description</h3>

<p><code>mptmodel</code> is a basic fitting function for multinomial processing tree
(MPT) models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mptmodel(y, weights = NULL, spec, treeid = NULL,
  optimargs = list(control = list(reltol = .Machine$double.eps^(1/1.2),
                                  maxit = 1000),
                   init = NULL),
  start = NULL, vcov = TRUE, estfun = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mptmodel_+3A_y">y</code></td>
<td>
<p>matrix of response frequencies.</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case weights).</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_spec">spec</code></td>
<td>
<p>an object of class <code>mptspec</code>: typically result of a call to
<code><a href="#topic+mptspec">mptspec</a></code>. A symbolic description of the model to be fitted.</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_treeid">treeid</code></td>
<td>
<p>a factor that identifies each tree in a joint multinomial
model.</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_optimargs">optimargs</code></td>
<td>
<p>a list of arguments passed to the optimization function
(<code><a href="stats.html#topic+optim">optim</a></code>).</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_start">start</code></td>
<td>
<p>a vector of starting values for the parameter estimates between
zero and one.</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_vcov">vcov</code></td>
<td>
<p>logical. Should the estimated variance-covariance be included in
the fitted model object?</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_estfun">estfun</code></td>
<td>
<p>logical. Should the empirical estimating functions
(score/gradient contributions) be included in the fitted model object?</p>
</td></tr>
<tr><td><code id="mptmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mptmodel</code> provides a basic fitting function for multinomial processing
tree (MPT) models, intended as a building block for fitting MPT trees in the
<span class="pkg">psychotree</span> package. While <code>mptmodel</code> is intended for individual
response frequencies, the <span class="pkg">mpt</span> package provides functions for aggregate
data.
</p>
<p>MPT models are specified using the <code>mptspec</code> function. See the
documentation in the <span class="pkg">mpt</span> package for details.
</p>
<p><code>mptmodel</code> returns an object of class <code>"mptmodel"</code> for which
several basic methods are available, including <code>print</code>, <code>plot</code>,
<code>summary</code>, <code>coef</code>, <code>vcov</code>, <code>logLik</code>, <code>estfun</code>
and <code><a href="stats.html#topic+predict">predict</a></code>.
</p>


<h3>Value</h3>

<p><code>mptmodel</code> returns an S3 object of class <code>"mptmodel"</code>,
i.e., a list with components as follows:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>a matrix with the response frequencies,</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated parameters (for extraction, the <code>coef</code>
function is preferred),</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>number of estimated parameters,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>ysum</code></td>
<td>
<p>the aggregate response frequencies,</p>
</td></tr>
<tr><td><code>fitted</code>, <code>goodness.of.fit</code>, <code>...</code></td>
<td>
<p>see <code>mpt</code> in the <span class="pkg">mpt</span>
package.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+btmodel">btmodel</a></code>, <code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+gpcmodel">gpcmodel</a></code>,
<code><a href="#topic+rsmodel">rsmodel</a></code>, <code><a href="#topic+raschmodel">raschmodel</a></code>, <code><a href="#topic+nplmodel">nplmodel</a></code>,
<code><a href="#topic+mptspec">mptspec</a></code>, the <span class="pkg">mpt</span> package</p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## data
data("SourceMonitoring", package = "psychotools")

## source-monitoring MPT model
mpt1 &lt;- mptmodel(SourceMonitoring$y, spec = mptspec("SourceMon"))
summary(mpt1)
plot(mpt1)

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='mscale'>Extract/Replace Measurement Scale</h2><span id='topic+mscale'></span><span id='topic+mscale+3C-'></span>

<h3>Description</h3>

<p>Generic functions for extracting and replacing the measurement scale from an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  mscale(object, ...)
  mscale(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mscale_+3A_object">object</code></td>
<td>
<p>an object.</p>
</td></tr>
<tr><td><code id="mscale_+3A_...">...</code></td>
<td>
<p>arguments passed to methods.</p>
</td></tr>
<tr><td><code id="mscale_+3A_value">value</code></td>
<td>
<p>an object describing the measurement scale.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## methods for "paircomp" data
pc &lt;- paircomp(rbind(
  c(2,  1,  0),
  c(1,  1, -1),
  c(1, -2, -1),
  c(0,  0,  0)))
pc

## extract
mscale(pc)

## replace (collapse to &gt;/=/&lt; scale)
mscale(pc) &lt;- sign(mscale(pc))
pc


## similar for "itemresp" data
ir &lt;- itemresp(cbind(
  c(-1, 0, 1, 1, 0),
  c(0, 1, 2, 1, 2),
  c(1, 2, 1, 1, 3)))
ir

## extract
mscale(ir)

## replace (single scale for all items)
mscale(ir) &lt;- 1:3
ir
</code></pre>

<hr>
<h2 id='nplmodel'>Parametric Logistic Model (n-PL) Fitting Function</h2><span id='topic+nplmodel'></span><span id='topic+plmodel'></span><span id='topic+print.nplmodel'></span><span id='topic+summary.nplmodel'></span><span id='topic+print.summary.nplmodel'></span><span id='topic+coef.nplmodel'></span><span id='topic+confint.nplmodel'></span><span id='topic+bread.nplmodel'></span><span id='topic+estfun.nplmodel'></span><span id='topic+logLik.nplmodel'></span><span id='topic+vcov.nplmodel'></span>

<h3>Description</h3>

<p><code>nplmodel</code> is a basic fitting function for n-PL type parametric logistic IRT models
(2PL, 3PL, 3PLu, 4PL, Rasch/1PL), providing a wrapper around
<code><a href="mirt.html#topic+mirt">mirt</a></code> and <code><a href="mirt.html#topic+multipleGroup">multipleGroup</a></code> relying on
marginal maximum likelihood (MML) estimation via the standard EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nplmodel(y, weights = NULL, impact = NULL,
  type = c("2PL", "3PL", "3PLu", "4PL", "1PL", "RM"),
  grouppars = FALSE, vcov = TRUE, 
  start = NULL, method = "BFGS", maxit = 500, reltol = 1e-5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nplmodel_+3A_y">y</code></td>
<td>
<p>item response object that can be coerced (via <code><a href="base.html#topic+as.matrix">as.matrix</a></code>)
to a numeric matrix with scores 0, 1. Typically, either
already a matrix, data frame, or dedicated object of class
<code><a href="#topic+itemresp">itemresp</a></code>.</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case
weights).</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_impact">impact</code></td>
<td>
<p>an optional <code>factor</code> allowing for grouping
the subjects (rows). If specified, a multiple-group model is fitted
to account for impact (see details below). By default, no impact is
modelled, i.e., a single-group model is used.</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_type">type</code></td>
<td>
<p>character string, specifying the type of parametric logistic
IRT model to be estimated (see details below).</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_grouppars">grouppars</code></td>
<td>
<p>logical. Should the estimated distributional group parameters
of a multiple group model be included in the model parameters?</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_vcov">vcov</code></td>
<td>
<p>logical or character specifying the type of variance-covariance
matrix (if any) computed for the final model. The default <code>vcov = TRUE</code>
corresponds to <code>vcov = "Oakes"</code>, see <code><a href="mirt.html#topic+mirt">mirt</a></code> for
further options. If set to <code>vcov = FALSE</code> (or <code>vcov = "none"</code>),
<code>vcov()</code> will return a matrix of <code>NA</code>s only.</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_start">start</code></td>
<td>
<p>an optional vector or list of starting values (see examples
below).</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_method">method</code>, <code id="nplmodel_+3A_maxit">maxit</code>, <code id="nplmodel_+3A_reltol">reltol</code></td>
<td>
<p>control parameters for the optimizer employed
by <code><a href="mirt.html#topic+mirt">mirt</a></code> for the EM algorithm.</p>
</td></tr>
<tr><td><code id="nplmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="mirt.html#topic+mirt">mirt</a></code> or
<code><a href="mirt.html#topic+multipleGroup">multipleGroup</a></code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nplmodel</code> (<code>plmodel</code> for backward compatibility with earlier
<span class="pkg">psychotools</span> versions) provides a basic fitting function for n-PL type parametric logistic IRT
models (2PL, 3PL, 3PLu, 4PL, Rasch/1PL) providing a wrapper around
<code><a href="mirt.html#topic+mirt">mirt</a></code> and <code><a href="mirt.html#topic+multipleGroup">multipleGroup</a></code> relying on
MML estimation via the standard EM algorithm (Bock &amp; Aitkin, 1981). Models are
estimated under the slope/intercept parametrization, see e.g. Chalmers (2012).
The probability of person <code class="reqn">i</code> &lsquo;solving&rsquo; item <code class="reqn">j</code> is modelled as:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{ij} = 1|\theta_{i},a_{j},d_{j},g_{j},u_{j}) =
  g_{j} + \frac{(u_{j} - g_{j})}{1 + \exp{(-(a_{j}\theta_{i} + d_{j}))}}</code>
</p>

<p>A reparametrization of the intercepts to the classical IRT parametrization,
<code class="reqn">b_{j} = -\frac{d_{j}}{a_{j}}</code>, is provided via the corresponding
<code><a href="#topic+itempar">itempar</a></code> method.
</p>
<p>If an optional <code>impact</code> variable is supplied, a multiple-group model of
the following form is being fitted: Item parameters are fixed to be equal
across the whole sample. For the first group of the <code>impact</code> variable the
person parameters are fixed to follow the standard normal distribution. In the
remaining <code>impact</code> groups, the distributional parameters (mean and
variance of a normal distribution) of the person parameters are
estimated freely. See e.g. Baker &amp; Kim (2004, Chapter 11), Debelak &amp; Strobl
(2019), or Schneider et al. (2022) for further details. To improve convergence of the model fitting
algorithm, the first level of the <code>impact</code> variable should always correspond
to the largest group. If this is not the case, levels are re-ordered internally.
</p>
<p>If <code>grouppars</code> is set to <code>TRUE</code> the freely estimated distributional
group parameters (if any) are returned as part of the model parameters.
</p>
<p>By default, <code>type</code> is set to <code>"2PL"</code>. Therefore, all so-called
guessing parameters are fixed at 0 and all upper asymptotes are fixed at 1.
<code>"3PL"</code> results in all upper asymptotes being fixed at 1 and <code>"3PLu"</code>
results in all all guessing parameters being fixed at 0. <code>"4PL"</code> results
in a full estimated model as specified above. Finally, if <code>type</code> is set to
<code>"1PL"</code> (or equivalently <code>"RM"</code>), an MML-estimated Rasch model is
being fitted. This means that all slopes are restricted to be equal across all
items, all guessing parameters are fixed at 0 and all upper asymptotes are
fixed at 1.
</p>
<p>Note that internally, the so-called guessing parameters and upper asymptotes
are estimated on the logit scale (see also <code><a href="mirt.html#topic+mirt">mirt</a></code>).
Therefore, most of the basic methods below include a <code>logit</code> argument,
which can be set to <code>TRUE</code> or <code>FALSE</code> allowing for a retransformation
of the estimates and their variance-covariance matrix (if requested) using the
logistic function and the delta method if <code>logit = FALSE</code>.
</p>
<p><code>nplmodel</code> returns an object of class <code>"nplmodel"</code> for which
several basic methods are available, including <code>print</code>, <code>plot</code>,
<code>summary</code>, <code>coef</code>, <code>vcov</code>, <code>logLik</code>, <code>estfun</code>,
<code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>,
<code><a href="#topic+guesspar">guesspar</a></code>, <code><a href="#topic+upperpar">upperpar</a></code>, and <code><a href="#topic+personpar">personpar</a></code>.
</p>
<p>Finally, if <code>type</code> is set to <code>"1PL"</code>, a Rasch model is estimated. 
Here, a common slope parameter is estimated for all items, whereas the
person parameters are assumed to follow a standard normal distribution.
Please note that this variant of the Rasch model differs from the one used 
by <code><a href="mirt.html#topic+mirt">mirt</a></code>, which sets all slope parameters to 1, and 
estimates the variance of the person parameters instead. Both variants 
are mathematically equivalent and hence should lead to the same intercept parameter 
estimates. For numerical reasons, <code>nplmodel</code> and <code>mirt</code> 
can lead to slightly different item parameter estimates, though, under their 
respective default settings, in particular when some items are very easy 
or very difficult and the common slope parameter is large. A distinct advantage 
of the variant used by <code>nplmodel</code> is that it allows a direct 
comparison of the slope and intercept parameters with that estimated in more complex 
IRT models, such as the 2PL model. 
</p>


<h3>Value</h3>

<p><code>nplmodel</code> returns an S3 object of class <code>"nplmodel"</code>, 
i.e., a list of the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated model parameters in slope/intercept parametrization,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of the model parameters,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>modified data, used for model-fitting, i.e., without
observations with zero weight,</p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>logical vector of length <code>ncol(y)</code>, indicating
which items were used during estimation,</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>n_org</code></td>
<td>
<p>original number of observations in <code>y</code>,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>logical indicating whether the data contain <code>NA</code>s,</p>
</td></tr>
<tr><td><code>impact</code></td>
<td>
<p>either <code>NULL</code> or the supplied <code>impact</code> variable
with the levels reordered in decreasing order (if this has not been the case
prior to fitting the model),</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>number of estimated (more precisely, returned) model parameters,</p>
</td></tr>
<tr><td><code>code</code></td>
<td>
<p>convergence code from <code>mirt</code>,</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>number of iterations used by <code>mirt</code>,</p>
</td></tr>
<tr><td><code>reltol</code></td>
<td>
<p>convergence threshold passed to <code>mirt</code>,</p>
</td></tr>
<tr><td><code>grouppars</code></td>
<td>
<p>the logical <code>grouppars</code> value,</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the <code>type</code> of model restriction specified,</p>
</td></tr>
<tr><td><code>mirt</code></td>
<td>
<p>the <code>mirt</code> object fitted internally,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>original function call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Baker FB, Kim SH (2004).
<em>Item Response Theory: Parameter Estimation Techniques</em>.
Chapman &amp; Hall/CRC, Boca Raton.
</p>
<p>Bock RD, Aitkin M (1981).
Marginal Maximum Likelihood Estimation of Item Parameters: Application of an EM Algorithm.
<em>Psychometrika</em>, <b>46</b>(4), 443&ndash;459.
</p>
<p>Chalmers RP (2012).
mirt: A Multidimensional Item Response Theory Package for the R Environment.
<em>Journal of Statistical Software</em>, <b>48</b>(6), 1&ndash;29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Debelak R, Strobl C (2019).
Investigating Measurement Invariance by Means of Parameter Instability Tests for 2PL and 3PL Models.
<em>Educational and Psychological Measurement</em>, <b>79</b>(2), 385&ndash;398.
<a href="https://doi.org/10.1177/0013164418777784">doi:10.1177/0013164418777784</a>
</p>
<p>Schneider L, Strobl C, Zeileis A, Debelak R (2022).
An R Toolbox for Score-Based Measurement Invariance Tests in IRT Models.
<em>Behavior Research Methods</em>, forthcoming.
<a href="https://doi.org/10.3758/s13428-021-01689-0">doi:10.3758/s13428-021-01689-0</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+raschmodel">raschmodel</a></code>, <code><a href="#topic+gpcmodel">gpcmodel</a></code>,
<code><a href="#topic+rsmodel">rsmodel</a></code>, <code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+btmodel">btmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("mirt")) {

o &lt;- options(digits = 4)

## mathematics 101 exam results
data("MathExam14W", package = "psychotools")

## 2PL
twopl &lt;- nplmodel(y = MathExam14W$solved)
summary(twopl)

## how to specify starting values as a vector of model parameters
st &lt;- coef(twopl)
twopl &lt;- nplmodel(y = MathExam14W$solved, start = st)
## or a list containing a vector of slopes and a vector of intercepts
set.seed(0)
st &lt;- list(a = rlnorm(13, 0, 0.0625), d = rnorm(13, 0, 1))
twopl &lt;- nplmodel(y = MathExam14W$solved, start = st)

## visualizations
plot(twopl, type = "profile")
plot(twopl, type = "regions")
plot(twopl, type = "piplot")
plot(twopl, type = "curves", xlim = c(-6, 6))
plot(twopl, type = "information", xlim = c(-6, 6))
## visualizing the IRT parametrization
plot(twopl, type = "curves", xlim = c(-6, 6), items = 1)
abline(v = itempar(twopl)[1])
abline(h = 0.5, lty = 2)

## 2PL accounting for gender impact
table(MathExam14W$gender)
mtwopl &lt;- nplmodel(y = MathExam14W$solved, impact = MathExam14W$gender,
  grouppars = TRUE)
summary(mtwopl)
plot(mtwopl, type = "piplot")
## specifying starting values as a vector of model parameters, note that in
## this example impact is being modelled and therefore grouppars must be TRUE
## to get all model parameters
st &lt;- coef(mtwopl)
mtwopl &lt;- nplmodel(y = MathExam14W$solved, impact = MathExam14W$gender,
  start = st)
## or a list containing a vector of slopes, a vector of intercepts and a vector
## of means and a vector of variances as the distributional group parameters
set.seed(1)
st &lt;- list(a = rlnorm(13, 0, 0.0625), d = rnorm(13, 0, 1), m = 0, v = 1)
mtwopl &lt;- nplmodel(y = MathExam14W$solved, impact = MathExam14W$gender,
  start = st)

## MML estimated Rasch model (1PL)
rm &lt;- nplmodel(y = MathExam14W$solved, type = "1PL")
summary(rm)

options(digits = o$digits)
}
</code></pre>

<hr>
<h2 id='PairClustering'>Pair Clustering Data in Klauer (2006)</h2><span id='topic+PairClustering'></span>

<h3>Description</h3>

<p>Response frequencies of 63 participants who took part in a pair-clustering
experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PairClustering")</code></pre>


<h3>Format</h3>

<p>A data frame containing 126 observations on 8 variables.
</p>

<dl>
<dt>ID</dt><dd><p>Participant ID.</p>
</dd>
<dt>trial</dt><dd><p>Trial number, 1 or 2.</p>
</dd>
<dt>E1</dt><dd><p>Number of pairs recalled adjacently.</p>
</dd>
<dt>E2</dt><dd><p>Number of pairs recalled non-adjacently.</p>
</dd>
<dt>E3</dt><dd><p>Number of single pair members recalled.</p>
</dd>
<dt>E4</dt><dd><p>Number of non-recalled pairs.</p>
</dd>
<dt>F1</dt><dd><p>Number of recalled singleton words.</p>
</dd>
<dt>F2</dt><dd><p>Number of non-recalled singleton words.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Klauer (2006) reports a pair-clustering experiment with 63 participants,
who were presented with ten pairs of related words and five unrelated
singleton words. In a later memory test, they freely recalled the presented
words. This procedure was repeated for two study and test trials. For pairs,
responses were classified into four categories: both words in a pair are
recalled adjacently (E1) or non-adjacently (E2), one word in a pair is
recalled (E3), neither word in a pair is recalled (E4); for singletons, into
two categories: word recalled (F1), word not recalled (F2).
</p>


<h3>Source</h3>

<p>Stahl C, Klauer KC (2007).
HMMTree: A Computer Program for Latent-Class Hierarchical Multinomial Processing Tree Models.
<em>Behavior Research Methods</em>, <b>39</b>, 267&ndash;273.
</p>


<h3>References</h3>

<p>Klauer KC (2006).
Hierarchical Multinomial Processing Tree Models: A Latent-Class Approach.
<em>Psychometrika</em>, <b>71</b>, 1&ndash;31.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("PairClustering", package = "psychotools")
aggregate(cbind(E1, E2, E3, E4, F1, F2) ~ trial, PairClustering, sum)
</code></pre>

<hr>
<h2 id='paircomp'>Data Structure for Paired Comparisons</h2><span id='topic+paircomp'></span><span id='topic+length.paircomp'></span><span id='topic+c.paircomp'></span><span id='topic++5B.paircomp'></span><span id='topic+rep.paircomp'></span><span id='topic+xtfrm.paircomp'></span><span id='topic+as.character.paircomp'></span><span id='topic+as.data.frame.paircomp'></span><span id='topic+as.double.paircomp'></span><span id='topic+as.integer.paircomp'></span><span id='topic+as.matrix.paircomp'></span><span id='topic+covariates.paircomp'></span><span id='topic+covariates+3C-.paircomp'></span><span id='topic+labels.paircomp'></span><span id='topic+labels+3C-.paircomp'></span><span id='topic+names.paircomp'></span><span id='topic+names+3C-.paircomp'></span><span id='topic+mscale.paircomp'></span><span id='topic+mscale+3C-.paircomp'></span><span id='topic+str.paircomp'></span><span id='topic+summary.paircomp'></span><span id='topic+is.na.paircomp'></span>

<h3>Description</h3>

<p>A class for representing data from paired comparison experiments
along with methods for many generic functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  paircomp(data,
    labels = NULL, mscale = NULL, ordered = FALSE, covariates = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paircomp_+3A_data">data</code></td>
<td>
<p>matrix. A matrix with integer values where the rows correspond
to subjects and the columns to paired comparisons between objects. See
below for details.</p>
</td></tr>
<tr><td><code id="paircomp_+3A_labels">labels</code></td>
<td>
<p>character. A vector of character labels for the objects.
By default a suitable number of <code>letters</code> is used.</p>
</td></tr>
<tr><td><code id="paircomp_+3A_mscale">mscale</code></td>
<td>
<p>integer. A vector of integers giving the measurement scale.
See below for details. By default guessed from <code>data</code>.</p>
</td></tr>
<tr><td><code id="paircomp_+3A_ordered">ordered</code></td>
<td>
<p>logical. Does <code>data</code> contain both orderings of each
comparison?</p>
</td></tr>
<tr><td><code id="paircomp_+3A_covariates">covariates</code></td>
<td>
<p>data.frame. An optional data.frame with object covariates, i.e.,
it must have the same number of rows as the length of <code>labels</code>.
May be <code>NULL</code> (default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>paircomp</code> is designed for holding paired comparisons of
<code class="reqn">k</code> objects measured for <code class="reqn">n</code> subjects.
</p>
<p>The comparisons should be coded in an integer matrix <code>data</code>
with <code class="reqn">n</code> rows (subjects) and <code class="reqn">k \choose 2</code> columns
(unless <code>ordered = TRUE</code>, see below). The columns must be
ordered so that objects are sequentially compared with all
previous objects, i.e.: 1:2, 1:3, 2:3, 1:4, 2:4, 3:4, etc.  
Each column represents the results of a comparison for two particular
objects. Positive values signal that the first object was preferred,
negative values that the second was preferred, zero signals no
preference. Larger absolute values signal stronger preference.
</p>
<p><code>mscale</code> provides the underlying measurement scale. It must
be a symmetric sequence of integers of type <code>(-i):i</code> where
<code>i</code> must be at least <code>1</code>. However, it may exclude
<code>0</code> (i.e., forced choice).
</p>
<p>If <code>ordered = TRUE</code>, the order of comparison matters and
thus <code>data</code> is assumed to have twice as many columns. The
second half of columns then corresponds to the comparisons
2:1, 3:1, 3:2, 4:1, 4:2, 4:3, etc.
</p>


<h3>Value</h3>

<p><code>paircomp</code> returns an object of class <code>"paircomp"</code> which is
a matrix (essentially <code>data</code>) with all remaining arguments
of <code>paircomp</code> as attributes (after being
checked and potentially suitably coerced or transformed).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+subset.paircomp">subset.paircomp</a></code>, <code><a href="#topic+print.paircomp">print.paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## a simple paired comparison
pc &lt;- paircomp(rbind(
  c(1,  1,  1), # a &gt; b, a &gt; c, b &gt; c
  c(1,  1, -1), # a &gt; b, a &gt; c, b &lt; c
  c(1, -1, -1), # a &gt; b, a &lt; c, b &lt; c
  c(1,  1,  1)))

## basic methods
pc
str(pc)
summary(pc)
pc[2:3]
c(pc[2], pc[c(1, 4)])

## methods to extract/set attributes
labels(pc)
labels(pc) &lt;- c("ah", "be", "ce")
pc
mscale(pc)
covariates(pc)
covariates(pc) &lt;- data.frame(foo = factor(c(1, 2, 2), labels = c("foo", "bar")))
covariates(pc)
names(pc)
names(pc) &lt;- LETTERS[1:4]
pc

## reorder() and subset() both select a subset of
## objects and/or reorders the objects
reorder(pc, c("ce", "ah"))


## include paircomp object in a data.frame
## (i.e., with subject covariates)
dat &lt;- data.frame(
  x = rnorm(4),
  y = factor(c(1, 2, 1, 1), labels = c("hansi", "beppi")))
dat$pc &lt;- pc
dat


## formatting with long(er) labels and extended scale
pc2 &lt;- paircomp(rbind(
  c(4,  1,  0),
  c(1,  2, -1),
  c(1, -2, -1),
  c(0,  0,  -3)),
  labels = c("Nordrhein-Westfalen", "Schleswig-Holstein", "Baden-Wuerttemberg"))
## default: abbreviate
print(pc2)
print(pc2, abbreviate = FALSE)
print(pc2, abbreviate = FALSE, width = FALSE)


## paired comparisons with object covariates
pc3 &lt;- paircomp(rbind(
  c(2,  1,  0),
  c(1,  1, -1),
  c(1, -2, -1),
  c(0,  0,  0)),
  labels = c("New York", "Rio", "Tokyo"),
  covariates = data.frame(hemisphere = factor(c(1, 2, 1), labels = c("North", "South"))))
covariates(pc3)
</code></pre>

<hr>
<h2 id='pcmodel'>Partial Credit Model Fitting Function</h2><span id='topic+pcmodel'></span><span id='topic+PCModel.fit'></span><span id='topic+print.pcmodel'></span><span id='topic+summary.pcmodel'></span><span id='topic+print.summary.pcmodel'></span><span id='topic+coef.pcmodel'></span><span id='topic+bread.pcmodel'></span><span id='topic+estfun.pcmodel'></span><span id='topic+logLik.pcmodel'></span><span id='topic+vcov.pcmodel'></span>

<h3>Description</h3>

<p><code>pcmodel</code> is a basic fitting function for partial credit models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcmodel(y, weights = NULL, nullcats = c("keep", "downcode", "ignore"),
  start = NULL, reltol = 1e-10, deriv = c("sum", "diff"),
  hessian = TRUE, maxit = 100L, full = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcmodel_+3A_y">y</code></td>
<td>
<p>item response object that can be coerced (via <code><a href="base.html#topic+as.matrix">as.matrix</a></code>)
to a numeric matrix with scores 0, 1, ... Typically, either
already a matrix, data frame, or dedicated object of class
<code><a href="#topic+itemresp">itemresp</a></code>.</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case
weights).</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_deriv">deriv</code></td>
<td>
<p>character. If &quot;sum&quot; (the default), the first derivatives
of the elementary symmetric functions are calculated with the sum
algorithm. Otherwise (&quot;diff&quot;) the difference algorithm (faster but
numerically unstable) is used.</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_nullcats">nullcats</code></td>
<td>
<p>character string, specifying how items with
null categories (i.e., categories not observed) should be treated (see
details below).</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_start">start</code></td>
<td>
<p>an optional vector of starting values.</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_hessian">hessian</code></td>
<td>
<p>logical. Should the Hessian of the final model be computed?
If set to <code>FALSE</code>, the <code>vcov</code> method can only return <code>NA</code>s
and consequently no standard errors or tests are available in the
<code>summary</code>.</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_reltol">reltol</code>, <code id="pcmodel_+3A_maxit">maxit</code>, <code id="pcmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code id="pcmodel_+3A_full">full</code></td>
<td>
<p>logical. Should a full model object be returned? If set to <code>FALSE</code>,
no variance-covariance matrix and no matrix of estimating functions are computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pcmodel</code> provides a basic fitting function for partial
credit models, intended as a building block for fitting partial
credit trees. It estimates the partial credit model suggested
by Masters (1982) under the cumulative threshold parameterization,
i.e., the item-category parameters <code class="reqn">\eta_{jk} = \sum_{\ell =
      1}^{k}\delta_{jk}</code> are estimated by the the function <code>pcmodel</code>.
</p>
<p>Null categories, i.e., categories which have not been used, can be
problematic when estimating a partial credit model. Several strategies
have been suggested to cope with null categories.  <code>pcmodel</code>
allows to select from three possible strategies via the argument
<code>nullcats</code>. If <code>nullcats</code> is set to <code>"keep"</code> (the
default), the strategy suggested by Wilson &amp; Masters (1993) is used to
handle null categories. That basically means that the integrity of the
response framework is maintained, i.e., no category scores are
changed. This is not the case, when <code>nullcats</code> is set to
<code>"downcode"</code>. Then all categories above a null category are
shifted down to close the existing gap. In both cases (<code>"keep"</code>
and <code>"downcode"</code>) the number of estimated parameters is reduced
by the number of null categories. When <code>nullcats</code> is set to
<code>"ignore"</code>, these are literally ignored and a threshold parameter
is estimated during the optimization nevertheless. This strategy is
used by the related package <span class="pkg">eRm</span> when fitting partial credit
models via <code>eRm::PCM</code>.
</p>
<p><code>pcmodel</code> returns an object of class <code>"pcmodel"</code> for
which several basic methods are available, including <code>print</code>,
<code>plot</code>, <code>summary</code>, <code>coef</code>, <code>vcov</code>, <code>logLik</code>,
<code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>, <code>estfun</code>,
<code><a href="#topic+threshpar">threshpar</a></code>, and <code><a href="#topic+personpar">personpar</a></code>.
</p>


<h3>Value</h3>

<p><code>pcmodel</code> returns an S3 object of class <code>"pcmodel"</code>, 
i.e., a list the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of estimated item-category
parameters (without the first item-category parameter which is
constrained to 0),</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of the parameters in the model,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>modified data, used for model-fitting, i.e., cleaned for
items without variance, centralized so that the first category is
zero for all items, treated null categories as specified via
argument <code>"nullcats"</code> and without observations with zero
weight. Be careful, this is different than for objects of class
<code>"raschmodel"</code> or <code>"btmodel"</code>, where <code>data</code> contains
the <em>original</em> data,</p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>logical vector of length <code>ncol(dat)</code>, indicating
which items have variance (<code>TRUE</code>), i.e., are identified and
have been used for the estimation or not (<code>FALSE</code>),</p>
</td></tr>
<tr><td><code>categories</code></td>
<td>
<p>list of length <code>ncol(y)</code>, containing integer
vectors starting from one to the number of categories minus one per
item,</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>n_org</code></td>
<td>
<p>original number of observations in <code>y</code>,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>logical indicating whether the data contain NAs,</p>
</td></tr>
<tr><td><code>nullcats</code></td>
<td>
<p>either <code>NULL</code> or, if there have been null
categories, a list of length <code>ncol(y)</code> with logical vectors
specifying which categories are null categories (<code>TRUE</code>) or not
(<code>FALSE</code>),</p>
</td></tr>
<tr><td><code>esf</code></td>
<td>
<p>list of elementary symmetric functions and their
derivatives for estimated parameters,</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>number of estimated parameters,</p>
</td></tr>
<tr><td><code>code</code></td>
<td>
<p>convergence code from <code>optim</code>,</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>number of iterations used by <code>optim</code>,</p>
</td></tr>
<tr><td><code>reltol</code></td>
<td>
<p>tolerance passed to <code>optim</code>,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>original function call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Masters GN (1992).
A Rasch Model for Partial Credit Scoring.
<em>Psychometrika</em>, <b>47</b>(2), 149&ndash;174.
</p>
<p>Wilson M, Masters GN (1993).
The Partial Credit Model and Null Categories.
<em>Psychometrika</em>, <b>58</b>(1), 87&ndash;99.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpcmodel">gpcmodel</a></code>, <code><a href="#topic+rsmodel">rsmodel</a></code>, <code><a href="#topic+raschmodel">raschmodel</a></code>,
<code><a href="#topic+nplmodel">nplmodel</a></code>, <code><a href="#topic+btmodel">btmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## Verbal aggression data
data("VerbalAggression", package = "psychotools")

## Partial credit model for the other-to-blame situations
pcm &lt;- pcmodel(VerbalAggression$resp[, 1:12])
summary(pcm)

## visualizations
plot(pcm, type = "profile")
plot(pcm, type = "regions")
plot(pcm, type = "piplot")
plot(pcm, type = "curves")
plot(pcm, type = "information")

## Get data of situation 1 ('A bus fails to
## stop for me') and induce a null category in item 2.
pcd &lt;- VerbalAggression$resp[, 1:6, drop = FALSE]
pcd[pcd[, 2] == 1, 2] &lt;- NA

## fit pcm to these data, comparing downcoding and keeping strategy
pcm_va_keep  &lt;- pcmodel(pcd, nullcats = "keep")
pcm_va_down  &lt;- pcmodel(pcd, nullcats = "downcode")

plot(x = coef(pcm_va_keep), y = coef(pcm_va_down),
     xlab = "Threshold Parameters (Keeping)",
     ylab = "Threshold Parameters (Downcoding)",
     main = "Comparison of two null category strategies (I2 with null category)", 
     pch = rep(as.character(1:6), each = 2)[-3])
abline(b = 1, a = 0)

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='personpar'>Extract Person Parameters of Item Response Models</h2><span id='topic+personpar'></span><span id='topic+personpar.raschmodel'></span><span id='topic+personpar.rsmodel'></span><span id='topic+personpar.pcmodel'></span><span id='topic+personpar.nplmodel'></span><span id='topic+personpar.gpcmodel'></span><span id='topic+coef.personpar'></span><span id='topic+print.personpar'></span><span id='topic+vcov.personpar'></span>

<h3>Description</h3>

<p>A class and generic function for representing and estimating the person
parameters of a given item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>personpar(object, ...)
## S3 method for class 'raschmodel'
personpar(object, personwise = FALSE, ref = NULL,
  vcov = TRUE, interval = NULL, tol = 1e-8, ...)
## S3 method for class 'rsmodel'
personpar(object, personwise = FALSE, ref = NULL,
  vcov = TRUE, interval = NULL, tol = 1e-8, ...)
## S3 method for class 'pcmodel'
personpar(object, personwise = FALSE, ref = NULL,
  vcov = TRUE, interval = NULL, tol = 1e-8, ...)
## S3 method for class 'nplmodel'
personpar(object, personwise = FALSE, vcov = TRUE,
  interval = NULL, tol = 1e-6, method = "EAP", ...)
## S3 method for class 'gpcmodel'
personpar(object, personwise = FALSE, vcov = TRUE,
  interval = NULL, tol = 1e-6, method = "EAP", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="personpar_+3A_object">object</code></td>
<td>
<p>a fitted model object for which person parameters should be
returned/estimated.</p>
</td></tr>
<tr><td><code id="personpar_+3A_personwise">personwise</code></td>
<td>
<p>logical. Should the distributional parameters of the
latent person ability distribution be computed (default) or the person-wise
(individual) person parameters? See below for details.</p>
</td></tr>
<tr><td><code id="personpar_+3A_ref">ref</code></td>
<td>
<p>a vector of labels or position indices of item parameters or a
contrast matrix which should be used as restriction/for normalization. This
argument will be passed over to internal calls of <code>itempar</code>.</p>
</td></tr>
<tr><td><code id="personpar_+3A_vcov">vcov</code></td>
<td>
<p>logical. Should a covariance matrix be returned/estimated for the
person parameter estimates? See also details below.</p>
</td></tr>
<tr><td><code id="personpar_+3A_interval">interval</code></td>
<td>
<p>numeric vector of length two, specifying an interval for
<code><a href="stats.html#topic+uniroot">uniroot</a></code> or <code><a href="mirt.html#topic+fscores">fscores</a></code> to calculate
the person parameter estimates.</p>
</td></tr>
<tr><td><code id="personpar_+3A_tol">tol</code></td>
<td>
<p>numeric tolerance passed to <code><a href="stats.html#topic+uniroot">uniroot</a></code> or
<code><a href="mirt.html#topic+fscores">fscores</a></code>.</p>
</td></tr>
<tr><td><code id="personpar_+3A_method">method</code></td>
<td>
<p>type of estimation method being passed to
<code><a href="mirt.html#topic+fscores">fscores</a></code>.</p>
</td></tr>
<tr><td><code id="personpar_+3A_...">...</code></td>
<td>
<p>further arguments which are passed to <code><a href="stats.html#topic+optim">optim</a></code>
in case of <code>vcov = TRUE</code> or <code><a href="mirt.html#topic+fscores">fscores</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>personpar</code> is both a class to represent person parameters of item
response models as well as a generic function. The generic function can be
used to return/estimate the person parameters of a given item response model.
</p>
<p>By default, the function <code>personpar()</code> reports the distribution
parameters of the assumed person ability distribution. For models estimated by
marginal maximum likelihood estimation (MML) this is the mean/variance of the
underlying normal distribution, whereas for models estimated by conditional
maximum likelihood estimation (CML) this is a discrete distribution with one
estimation for each observed raw score in the data.
</p>
<p>Alternatively, when setting <code>personwise = TRUE</code>, the person parameter for
each person/subject in the underlying data set can be extracted. In the CML
case, this simply computes the raw score for each person and then extracts
the corresponding person parameter. In the MML case, this necessitates
(numerically) integrating out the individual person parameters (also known as
factor scores or latent trait estimates) based on the underlying normal
distribution.
</p>
<p>More specifically, the following algorithms are employed for obtaining the
distributional person parameters: </p>

<ul>
<li><p> In the MML case &ndash; i.e., for <code>nplmodel</code>s and <code>gpcmodel</code>s &ndash;
the distributional parameters are already part of the model specification.
In a single-group specification and in the reference group of a multi-group
specification the mean/variance parameters are fixed to 0/1. In the multi-group
case the remaining mean/variance parameters were already estimated along with
all other model parameters and simply need to be extracted. Analogously,
the corresponding variance-covariance matrix just needs to be extracted and
has zero covariances in the cells corresponding to fixed parameters.
</p>
</li>
<li><p> In the CML case &ndash; i.e., <code>raschmodel</code>s, <code>rsmodel</code>s, and <code>pcmodel</code>s &ndash;
the distributional parameters are estimated via <code>uniroot()</code> with the estimation
equations given by Hoijtink &amp; Boomsma (1995) as well as Andersen (1995). This
approach is fast and estimates for all possible raw scores are available. If
the covariance matrix of the estimated person parameters is requested
(<code>vcov = TRUE</code>), an additional call of <code>optim</code> is employed to
obtain the Hessian numerically. With this approach, person parameters are
available only for observed raw scores.
</p>
</li></ul>

<p>As already explained above, obtaining the person-wise (individual) person
paremeters (or ability estimates or factor scores) is straightforward in the
CML case. In the MML case, <code><a href="mirt.html#topic+fscores">fscores</a></code> is used, see Chalmers
(2012) for further details. If <code>personwise = TRUE</code>, the associated
variance-covariance matrix is not provided and simply a matrix with <code>NA</code>s
is returned. (The same is done for <code>vcov = FALSE</code>.)
</p>
<p>For objects of class <code>personpar</code>, several methods to standard generic
functions exist: <code>print</code>, <code>coef</code>, <code>vcov</code>. <code>coef</code> and
<code>vcov</code> can be used to extract the person parameters and covariance matrix
without additional attributes. Based on this Wald tests or confidence
intervals can be easily computed, e.g., via <code>confint</code>.
</p>


<h3>Value</h3>

<p>A named vector with person parmeters of class <code>personpar</code> and
additional attributes <code>"model"</code> (the model name), <code>"vcov"</code> (the
covariance matrix of the estimates if <code>vcov = TRUE</code> or an
<code>NA</code>-matrix otherwise) and <code>"type"</code> (the type of the parameters,
depending on <code>personwise</code>).
</p>


<h3>References</h3>

<p>Andersen EB (1995).
Polytomous Rasch Models and Their Estimation.
In Fischer GH, Molenaar IW (eds.).
<em>Rasch Models: Foundations, Recent Developments, and Applications</em>.
Springer, New York.
</p>
<p>Chalmers RP (2012).
mirt: A Multidimensional Item Response Theory Package for the R
Environment.
<em>Journal of Statistical Software</em>, <b>48</b>(6), 1&ndash;29.
</p>
<p>Hoijtink H, Boomsma A (1995).
On Person Parameter Estimation in the Dichotomous Rasch Model.
In Fischer GH, Molenaar IW (eds.).
<em>Rasch Models: Foundations, Recent Developments, and Applications</em>.
Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>,
<code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+guesspar">guesspar</a></code>, <code><a href="#topic+upperpar">upperpar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 3)

## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit a Rasch model to dichotomized verbal aggression data and
ram &lt;- raschmodel(VerbalAggression$resp2)

## extract person parameters
## (= parameters of the underlying ability distribution)
rap &lt;- personpar(ram)
rap

## extract variance-covariance matrix and standard errors
vc &lt;- vcov(rap)
sqrt(diag(vc))

## Wald confidence intervals
confint(rap)

## now match each person to person parameter with the corresponding raw score
personpar(ram, personwise = TRUE)[1:6]

## person parameters for RSM/PCM fitted to original polytomous data
rsm &lt;- rsmodel(VerbalAggression$resp)
pcm &lt;- pcmodel(VerbalAggression$resp)
cbind(personpar(rsm, vcov = FALSE), personpar(pcm, vcov = FALSE))

if(requireNamespace("mirt")) {
## fit a 2PL accounting for gender impact and
twoplm &lt;- nplmodel(VerbalAggression$resp2, impact = VerbalAggression$gender)

## extract the person parameters
## (= mean/variance parameters from the normal ability distribution)
twoplp &lt;- personpar(twoplm)
twoplp

## extract the standard errors
sqrt(diag(vcov(twoplp)))

## Wald confidence intervals
confint(twoplp)

## now look at the individual person parameters
## (integrated out over the normal ability distribution)
personpar(twoplm, personwise = TRUE)[1:6]
}

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='piplot'>Person-Item Plots for IRT Models</h2><span id='topic+piplot'></span>

<h3>Description</h3>

<p>Base graphics plotting function for person-item plot visualization of IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  piplot(object, pcol = NULL, histogram = TRUE, ref = NULL, items = NULL,
    xlim = NULL, names = NULL, labels = TRUE, main = "Person-Item Plot",
    xlab = "Latent trait", abbreviate = FALSE, cex.axis = 0.8, cex.text = 0.5,
    cex.points = 1.5, grid = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="piplot_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>"raschmodel"</code>,
<code>"rsmodel"</code>, <code>"pcmodel"</code>, <code>"nplmodel"</code> or <code>"gpcmodel"</code>.</p>
</td></tr>
<tr><td><code id="piplot_+3A_pcol">pcol</code></td>
<td>
<p>optional character (vector), specifying the color(s) used for the
person parameter plot.</p>
</td></tr>
<tr><td><code id="piplot_+3A_histogram">histogram</code></td>
<td>
<p>logical. For models estimated via MML (<code>nplmodel</code>s and
<code>gpcmodel</code>s), should a histogram of the person-wise (individual) person
parameters be drawn additionally to the normal distribution density of the
person parameters?</p>
</td></tr>
<tr><td><code id="piplot_+3A_ref">ref</code></td>
<td>
<p>argument passed over to internal calls of <code><a href="#topic+threshpar">threshpar</a></code>
and <code><a href="#topic+itempar">itempar</a></code>.</p>
</td></tr>
<tr><td><code id="piplot_+3A_items">items</code></td>
<td>
<p>character or numeric, specifying the items which should be
visualized in the person-item plot.</p>
</td></tr>
<tr><td><code id="piplot_+3A_xlim">xlim</code></td>
<td>
<p>numeric, specifying the x axis limits.</p>
</td></tr>
<tr><td><code id="piplot_+3A_names">names</code></td>
<td>
<p>character, specifying labels for the items.</p>
</td></tr>
<tr><td><code id="piplot_+3A_labels">labels</code></td>
<td>
<p>logical, whether to draw the number of the threshold as text
below the threshold.</p>
</td></tr>
<tr><td><code id="piplot_+3A_main">main</code></td>
<td>
<p>character, specifying the overall title of the plot.</p>
</td></tr>
<tr><td><code id="piplot_+3A_xlab">xlab</code></td>
<td>
<p>character, specifying the x axis labels.</p>
</td></tr>
<tr><td><code id="piplot_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or numeric, specifying whether object names are to
be abbreviated. If numeric, this controls the length of the abbreviation.</p>
</td></tr>
<tr><td><code id="piplot_+3A_cex.axis">cex.axis</code></td>
<td>
<p>numeric, the magnification to be used for the axis notation
relative to the current setting of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="piplot_+3A_cex.text">cex.text</code></td>
<td>
<p>numeric, the magnification to be used for the symbols
relative to the current setting of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="piplot_+3A_cex.points">cex.points</code></td>
<td>
<p>numeric, the magnification to be used for the points
relative to the current setting of <code>cex</code>.</p>
</td></tr>
<tr><td><code id="piplot_+3A_grid">grid</code></td>
<td>
<p>logical or color specification of horizontal grid lines. If set to
<code>FALSE</code> or <code>"transparent"</code> grid lines can be suppressed.</p>
</td></tr>
<tr><td><code id="piplot_+3A_...">...</code></td>
<td>
<p>further arguments passed to internal calls of
<code><a href="graphics.html#topic+lines">lines</a></code>, <code><a href="graphics.html#topic+points">points</a></code> and <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The person-item plot visualization illustrates the distribution of the person
parameters against the absolute item threshold parameters under a certain data
set and IRT model. For models estimated via MML (<code>nplmodel</code>s and
<code>gpcmodel</code>s), the normal distribution density of the person parameters is
drawn. If <code>histogram</code> is set to <code>TRUE</code> (the default), a histogram of
the person-wise (individual) person parameters is drawn additionally. If a
multiple group model has been fitted by supplying an <code>impact</code> variable,
multiple person parameter plots are drawn, each corresponding to a specific
level of this variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+curveplot">curveplot</a></code>, <code><a href="#topic+regionplot">regionplot</a></code>,
<code><a href="#topic+profileplot">profileplot</a></code>, <code><a href="#topic+infoplot">infoplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load verbal agression data
data("VerbalAggression", package = "psychotools")

## fit partial credit model to verbal aggression data
pcmod &lt;- pcmodel(VerbalAggression$resp)

## create a person-item plot visualization of the fitted PCM
plot(pcmod, type = "piplot")

## just visualize the first six items and the person parameter plot
plot(pcmod, type = "piplot", items = 1:6, pcol = "lightblue")


if(requireNamespace("mirt")) {
## fit generalized partial credit model to verbal aggression data
gpcmod &lt;- gpcmodel(VerbalAggression$resp)

## create a person-item plot visualization of the fitted GPCM
plot(gpcmod, type = "piplot")

## turn off the histogram and grid
plot(gpcmod, type = "piplot", histogram = FALSE, grid = FALSE)

## fit GPCM to verbal aggression data accounting for gender impact
mgpcmod &lt;- gpcmodel(VerbalAggression$resp, impact = VerbalAggression$gender)

## create a person-item plot visualization of the fitted GPCM
plot(mgpcmod, type = "piplot", pcol = c("darkgreen", "darkorange"))
}

</code></pre>

<hr>
<h2 id='plot.btmodel'>Visualizing Bradley-Terry Models</h2><span id='topic+plot.btmodel'></span>

<h3>Description</h3>

<p>Base graphics plotting function for Bradley-Terry models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'btmodel'
plot(x, worth = TRUE, index = TRUE, names = TRUE,
  ref = TRUE, abbreviate = FALSE, type = NULL, lty = NULL,
  xlab = "Objects", ylab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.btmodel_+3A_x">x</code></td>
<td>
<p>an object of class <code>"btmodel"</code>.</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_worth">worth</code></td>
<td>
<p>logical. Should worth parameters (or alternatively coefficients
on log-scale) be displayed?</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_index">index</code></td>
<td>
<p>logical. Should different indexes for different items be used?</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_names">names</code></td>
<td>
<p>logical. Should the names for the objects be displayed?</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_ref">ref</code></td>
<td>
<p>logical. Should a horizontal line for the reference level be drawn?
Alternatively, <code>ref</code> can also be numeric or character to employ
a reference level different from that stored in <code>x</code>.</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or numeric. Should object names be abbreviated?
If numeric this controls the length of the abbreviation.</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_type">type</code></td>
<td>
<p>plot type. Default is <code>"b"</code> if <code>index</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_lty">lty</code></td>
<td>
<p>line type.</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_xlab">xlab</code>, <code id="plot.btmodel_+3A_ylab">ylab</code></td>
<td>
<p>x and y axis labels.</p>
</td></tr>
<tr><td><code id="plot.btmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+btmodel">btmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## data
data("GermanParties2009", package = "psychotools")

## Bradley-Terry model
bt &lt;- btmodel(GermanParties2009$preference)
plot(bt)
plot(bt, worth = FALSE)
plot(bt, index = FALSE)
</code></pre>

<hr>
<h2 id='plot.paircomp'>Plotting Paired Comparison Data</h2><span id='topic+plot.paircomp'></span>

<h3>Description</h3>

<p>Plotting the frequency table from <code>"paircomp"</code> data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'paircomp'
plot(x, off = 0.05,
  xlab = "Proportion of comparisons", ylab = "", tol.xlab = 0.05,
  abbreviate = TRUE, hue = NULL, chroma = 40, luminance = 80,
  xlim = c(0, 1), ylim = NULL, xaxs = "i", yaxs = "i", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.paircomp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"paircomp"</code>.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_off">off</code></td>
<td>
<p>numeric. Offset between segments on the y-axis.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_xlab">xlab</code>, <code id="plot.paircomp_+3A_ylab">ylab</code></td>
<td>
<p>character. Axis labels.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_tol.xlab">tol.xlab</code></td>
<td>
<p>numeric. convenience tolerance parameter for x-axis annotation.
If the distance between two labels drops under this threshold, they
are plotted equidistantly.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or integer. Should object labels be abbreviated?
Alternative an integer with the desired abbreviation length. The default
is some heuristic based on the length of the labels.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_hue">hue</code></td>
<td>
<p>numeric. A vector of hues in [0, 360], recycled to the
number of objects compared in <code>x</code>. A sequential palette
is computed for each hue, see below.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_chroma">chroma</code></td>
<td>
<p>numeric. Maximum chroma in the palette.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_luminance">luminance</code></td>
<td>
<p>numeric. Minimum (and maximum) luminance in the
palette. If omitted, the maximum is set to 95.</p>
</td></tr>
<tr><td><code id="plot.paircomp_+3A_xlim">xlim</code>, <code id="plot.paircomp_+3A_ylim">ylim</code>, <code id="plot.paircomp_+3A_xaxs">xaxs</code>, <code id="plot.paircomp_+3A_yaxs">yaxs</code>, <code id="plot.paircomp_+3A_...">...</code></td>
<td>
<p>graphical arguments passed to
<code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> method creates a frequency table (using <code>summary</code>)
and visualizes this using a sort of spine plot with HCL-based
diverging palettes. See Zeileis, Hornik, Murrell (2009) for the
underlying ideas.
</p>


<h3>References</h3>

<p>Zeileis A, Hornik K, Murrell P (2009),
Escaping RGBland: Selecting Colors for Statistical Graphics.
<em>Computational Statistics &amp; Data Analysis</em>, <b>53</b>, 3259-3270.
<a href="https://doi.org/10.1016/j.csda.2008.11.033">doi:10.1016/j.csda.2008.11.033</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paircomp">paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("GermanParties2009", package = "psychotools")
par(mar = c(5, 6, 3, 6))
plot(GermanParties2009$preference, abbreviate = FALSE)
</code></pre>

<hr>
<h2 id='plot.raschmodel'>Visualizing IRT Models</h2><span id='topic+plot.raschmodel'></span><span id='topic+plot.rsmodel'></span><span id='topic+plot.pcmodel'></span><span id='topic+plot.nplmodel'></span><span id='topic+plot.gpcmodel'></span>

<h3>Description</h3>

<p>Base graphics plotting function for various IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'raschmodel'
plot(x,
  type = c("profile", "curves", "regions", "information", "piplot"), ...)
## S3 method for class 'rsmodel'
plot(x,
  type = c("regions", "profile", "curves", "information", "piplot"), ...)
## S3 method for class 'pcmodel'
plot(x,
  type = c("regions", "profile", "curves", "information", "piplot"), ...)
## S3 method for class 'nplmodel'
plot(x,
  type = c("regions", "profile", "curves", "information", "piplot"), ...)
## S3 method for class 'gpcmodel'
plot(x,
  type = c("regions", "profile", "curves", "information", "piplot"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.raschmodel_+3A_x">x</code></td>
<td>
<p>a fitted model object of class <code>"raschmodel"</code>,
<code>"rsmodel"</code>, <code>"pcmodel"</code>, <code>"nplmodel"</code> or <code>"gpcmodel"</code>.</p>
</td></tr>
<tr><td><code id="plot.raschmodel_+3A_type">type</code></td>
<td>
<p>character, specifying the type of plot to create.</p>
</td></tr>
<tr><td><code id="plot.raschmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed over to the specific plotting
function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+curveplot">curveplot</a></code>, <code><a href="#topic+regionplot">regionplot</a></code>,
<code><a href="#topic+profileplot">profileplot</a></code>, <code><a href="#topic+infoplot">infoplot</a></code>, <code><a href="#topic+piplot">piplot</a></code></p>

<hr>
<h2 id='predict.pcmodel'>Predict Methods for Item Response Models</h2><span id='topic+predict.pcmodel'></span><span id='topic+predict.rsmodel'></span><span id='topic+predict.raschmodel'></span><span id='topic+predict.gpcmodel'></span><span id='topic+predict.nplmodel'></span>

<h3>Description</h3>

<p>Prediction of (cumulated) response probabilities and responses based on fitted
item response models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcmodel'
predict(object, newdata = NULL, type = c("probability",
  "cumprobability", "mode", "median", "mean", "category-information",
  "item-information", "test-information"), ref = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.pcmodel_+3A_object">object</code></td>
<td>
<p>a fitted model object whose item parameters should be used for
prediction.</p>
</td></tr>
<tr><td><code id="predict.pcmodel_+3A_newdata">newdata</code></td>
<td>
<p>an optional (possibly named) vector of person parameters
used for prediction. If <code>NULL</code> (the default), the person parameters of
the subjects used to fit the model in <code>object</code> are used.</p>
</td></tr>
<tr><td><code id="predict.pcmodel_+3A_type">type</code></td>
<td>
<p>character of length one which determines the type of
prediction (see details below).</p>
</td></tr>
<tr><td><code id="predict.pcmodel_+3A_ref">ref</code></td>
<td>
<p>arguments passed over to internal calls of <code>itempar</code> or
<code>threshpar</code>. Not used for models estimated via MML.</p>
</td></tr>
<tr><td><code id="predict.pcmodel_+3A_...">...</code></td>
<td>
<p>further arguments which are currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depending on the value of <code>type</code> either probabilities, responses or
some form of information under the model specified in <code>object</code> are
returned:
</p>
<p>If <code>type</code> is <code>"probability"</code>, the category response probabilities
are returned.
</p>
<p>If <code>type</code> is <code>"cumprobability"</code>, the cumulated category response
probabilities are returned, i.e., <code class="reqn">P(X_{ij} \geq k)</code> with <code class="reqn">k</code>
corresponding to the categories of item <code class="reqn">j</code>.
</p>
<p>If <code>type</code> is <code>"mode"</code>, the most probable category response for a
given subject and item is returned.
</p>
<p>If <code>type</code> is <code>"median"</code>, the first category <code class="reqn">k</code> where
<code class="reqn">P(X_{ij} = k) \geq 0.5</code> is returned.
</p>
<p>If <code>type</code> is <code>"mean"</code>, the rounded expected category response,
i.e., <code class="reqn">E(X_{ij}|\theta_{i})</code>, is returned.
</p>
<p>If <code>type</code> is <code>"category-information"</code>, the item-category
information as suggested by Bock (1972) is returned.
</p>
<p>If <code>type</code> is <code>"item-information"</code>, the item information as
suggested by Samejima (1974) is returned.
</p>
<p>If <code>type</code> is <code>"test-information"</code>, the sum over the individual
item information values is returned.
</p>


<h3>Value</h3>

<p>A (possibly named) numeric matrix with rows corresponding to subjects and
columns corresponding to the whole test, the single items or categories. The
exact content depends on the value of <code>type</code> (see details above).
</p>


<h3>References</h3>

<p>Bock RD (1972).
Estimating Item Parameters and Latent Ability When Responses Are Scored in
Two or More Nominal Categories.
<em>Psychometrika</em>, <b>37</b>(1), 29&ndash;51.
</p>
<p>Samejima F (1974).
Normal Ogive Model on the Continuous Response Level in the Multidimensional
Latent Space.
<em>Psychometrika</em>, <b>39</b>(1), 111&ndash;121.
</p>


<h3>See Also</h3>

<p>The help page of the generic function <code><a href="stats.html#topic+predict">predict</a></code> and other
predict methods (e.g., <code><a href="stats.html#topic+predict.lm">predict.lm</a></code>, <code><a href="stats.html#topic+predict.glm">predict.glm</a></code>,
...)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit a partial credit model to first ten items
pcmod &lt;- pcmodel(VerbalAggression$resp[, 1:10])

## predicted response probabilities for each subject and category (the default)
head(predict(pcmod), 3)

## predicted mode (most probable category) for certain subjects whose person
## parameters are given via argument "newdata"
predict(pcmod, type = "mode",
  newdata = c("Sarah" = 1.2, "Michael" = 0.1, "Arnd" = -0.8))

## rounded expected category value for the same subjects
predict(pcmod, type = "mean",
  newdata = c("Sarah" = 1.2, "Michael" = 0.1, "Arnd" = -0.8))

## in the Rasch model mode, mean and median are the same
raschmod &lt;- raschmodel(VerbalAggression$resp2[, 1:10])
med &lt;- predict(raschmod, type = "median")
mn &lt;- predict(raschmod, type = "mean")
mod &lt;- predict(raschmod, type = "mode")

head(med, 3)

all.equal(med, mn)
all.equal(mod, mn)

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='print.itemresp'>Formatting Item Response Data</h2><span id='topic+print.itemresp'></span><span id='topic+format.itemresp'></span>

<h3>Description</h3>

<p>Fine control for formatting and printing <code>"itemresp"</code> data objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'itemresp'
format(x, sep = c(",", ":"), brackets = TRUE,
    abbreviate = NULL, mscale = TRUE, labels = FALSE,
    width = getOption("width") - 7L, ...)
  ## S3 method for class 'itemresp'
print(x, quote = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.itemresp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"itemresp"</code>.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_sep">sep</code></td>
<td>
<p>character. A character of length 2 (otherwise expanded/reduced)
for separating responses and items, respectively.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_brackets">brackets</code></td>
<td>
<p>logical or character. Either a logical (Should brackets be
wrapped around all responses for a single subject?) or a character of
length 2 with opening and ending symbol.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or integer. Should scale labels be abbreviated?
Alternatively, an integer with the desired abbreviation length. The default
is some heuristic based on the length of the labels.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_mscale">mscale</code></td>
<td>
<p>logical. Should mscale values be used for printing?
If <code>FALSE</code>, integers 0, 1, ... are used.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_labels">labels</code></td>
<td>
<p>logical. Should item labels be displayed?</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_width">width</code></td>
<td>
<p>integer or logical. Maximal width of the string for a subject.
If <code>FALSE</code> no maximal width is set.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions.</p>
</td></tr>
<tr><td><code id="print.itemresp_+3A_quote">quote</code></td>
<td>
<p>logical. Should quotes be printed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method just calls <code>format</code> (passing on all further
arguments) and then prints the resulting string.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemresp">itemresp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## item responses from binary matrix
x &lt;- cbind(c(1, 0, 1, 0), c(1, 0, 0, 0), c(0, 1, 1, 1))
xi &lt;- itemresp(x)
## change mscale
mscale(xi) &lt;- c("-", "+")
xi

## flexible formatting
## no/other brackets
print(xi, brackets = FALSE)
print(xi, brackets = c("&gt;&gt;", "&lt;&lt;"))

## include item labels (with different separators)
print(xi, labels = TRUE)
print(xi, labels = TRUE, sep = c(" | ", ": "))

## handling longer mscale categories
mscale(xi) &lt;- c("disagree", "agree")
print(xi)
print(xi, mscale = FALSE)
print(xi, abbreviate = FALSE)
print(xi, abbreviate = FALSE, width = 23)
print(xi, abbreviate = 2)
</code></pre>

<hr>
<h2 id='print.paircomp'>Formatting Paired Comparison Data</h2><span id='topic+print.paircomp'></span><span id='topic+format.paircomp'></span>

<h3>Description</h3>

<p>Fine control for formatting and printing objects of <code>"paircomp"</code> data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'paircomp'
format(x, sep = ", ", brackets = TRUE,
    abbreviate = NULL, width = getOption("width") - 7, ...)
  ## S3 method for class 'paircomp'
print(x, quote = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.paircomp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"paircomp"</code>.</p>
</td></tr>
<tr><td><code id="print.paircomp_+3A_sep">sep</code></td>
<td>
<p>character. A character for separating comparisons within subjects.</p>
</td></tr>
<tr><td><code id="print.paircomp_+3A_brackets">brackets</code></td>
<td>
<p>logical or character. Either a logical (Should brackets be
wrapped around all comparisons for a single subject?) or a character of
length two with opening and ending symbol.</p>
</td></tr>
<tr><td><code id="print.paircomp_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or integer. Should object labels be abbreviated?
Alternative an integer with the desired abbreviation length. The default
is some heuristic based on the length of the labels.</p>
</td></tr>
<tr><td><code id="print.paircomp_+3A_width">width</code></td>
<td>
<p>integer or logical. Maximal width of the string for a subject.
If <code>FALSE</code> no maximal width is set.</p>
</td></tr>
<tr><td><code id="print.paircomp_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions.</p>
</td></tr>
<tr><td><code id="print.paircomp_+3A_quote">quote</code></td>
<td>
<p>logical. Should quotes be printed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method just calls <code>format</code> (passing on all further
arguments) and then prints the resulting string.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paircomp">paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>pc2 &lt;- paircomp(rbind(
  c(4,  1,  0),
  c(1,  2, -1),
  c(1, -2, -1),
  c(0,  0,  -3)),
  labels = c("New York", "Rio", "Tokyo"))

print(pc2)
print(pc2, abbreviate = FALSE)
print(pc2, abbreviate = FALSE, width = 10)
</code></pre>

<hr>
<h2 id='profileplot'>Profile Plots for IRT Models</h2><span id='topic+profileplot'></span>

<h3>Description</h3>

<p>Base graphics plotting function for profile plot visualization of IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  profileplot(object,
    what = c("items", "thresholds", "discriminations", "guessings", "uppers"),
    parg = list(type = NULL, ref = NULL, alias = TRUE, logit = FALSE), index = TRUE,
    names = TRUE, main = NULL, abbreviate = FALSE, ref = TRUE,
    col = "lightgray", border = "black", pch = NULL, cex = 1,
    refcol = "lightgray", linecol = "black", lty = 2, ylim = NULL,
    xlab = NULL, ylab = NULL, add = FALSE, srt = 45, adj = c(1.1, 1.1),
    axes = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="profileplot_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>"raschmodel"</code>,
<code>"rsmodel"</code>, <code>"pcmodel"</code>, <code>"nplmodel"</code> or <code>"gpcmodel"</code>.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_what">what</code></td>
<td>
<p>character, specifying the type of parameters to be plotted.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_parg">parg</code></td>
<td>
<p>list of arguments passed over to internal calls of
<code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>, <code><a href="#topic+discrpar">discrpar</a></code>,
<code><a href="#topic+guesspar">guesspar</a></code>, or <code><a href="#topic+upperpar">upperpar</a></code>.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_index">index</code></td>
<td>
<p>logical, should different indexes for different items be used?</p>
</td></tr>
<tr><td><code id="profileplot_+3A_names">names</code></td>
<td>
<p>logical or character. If <code>TRUE</code>, the names of the items are
displayed on the x-axis. If <code>FALSE</code>, numbers of items are shown.
Alternatively a character vector of the same length as the number of items
can be supplied.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_main">main</code></td>
<td>
<p>character, specifying the overall title of the plot.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or numeric, specifying whether object names are to
be abbreviated. If numeric this controls the length of the abbreviation.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_ref">ref</code></td>
<td>
<p>logical, whether to draw a horizontal line for the reference level.
Only takes effect if argument <code>what</code> is <code>"items"</code> or
<code>"discriminations".</code></p>
</td></tr>
<tr><td><code id="profileplot_+3A_col">col</code>, <code id="profileplot_+3A_border">border</code>, <code id="profileplot_+3A_pch">pch</code>, <code id="profileplot_+3A_cex">cex</code></td>
<td>
<p>graphical appearance of plotting symbols. Can be
of the same length as the number of items, i.e., a different graphical
appearance is used for each item. If <code>what = "thresholds"</code>, <code>col</code>
and <code>pch</code> can be matrices with a number of columns equal to the number
of threshold parameters per item resulting in different symbols and colors
used for different threshold parameter profiles.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_refcol">refcol</code></td>
<td>
<p>character, specifying the line color for the reference line
(if <code>ref</code> is set to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="profileplot_+3A_linecol">linecol</code></td>
<td>
<p>character or numeric, specifying the line color to be used for
the profiles.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_lty">lty</code></td>
<td>
<p>numeric, specifying the line type for the profiles.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_ylim">ylim</code></td>
<td>
<p>numeric, specifying the y axis limits.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_xlab">xlab</code>, <code id="profileplot_+3A_ylab">ylab</code></td>
<td>
<p>character, specifying the x and y axis labels.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_add">add</code></td>
<td>
<p>logical. If <code>TRUE</code>, new plotted profiles are added to an
existing plot.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_srt">srt</code>, <code id="profileplot_+3A_adj">adj</code></td>
<td>
<p>numeric. Angle (<code>srt</code>) and adjustment (<code>adj</code>) in
case names (rather than numbers) are used as x-axis labels. These are
passed to <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="profileplot_+3A_axes">axes</code></td>
<td>
<p>logical. Should axes be drawn?</p>
</td></tr>
<tr><td><code id="profileplot_+3A_...">...</code></td>
<td>
<p>further arguments passed over to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The profile plot visualization illustrates profiles of specific estimated
parameters under a certain IRT model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+curveplot">curveplot</a></code>, <code><a href="#topic+regionplot">regionplot</a></code>,
<code><a href="#topic+infoplot">infoplot</a></code>, <code><a href="#topic+piplot">piplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit Rasch, rating scale and partial credit model to verbal aggression data
rmmod &lt;- raschmodel(VerbalAggression$resp2)
rsmod &lt;- rsmodel(VerbalAggression$resp)
pcmod &lt;- pcmodel(VerbalAggression$resp)

## profile plots of the item parameters of the three fitted IRT models
plot(rmmod, type = "profile", what = "items", col = 4)
plot(rsmod, type = "profile", what = "items", col = 2, add = TRUE)
plot(pcmod, type = "profile", what = "items", col = 3, add = TRUE)
legend(x = "topleft", legend = c("RM", "RSM", "PCM"), col = 1,
  bg = c(4, 2, 3), pch = 21, bty = "n")

## profile plots of the threshold parameters of type "mode"
plot(rmmod, type = "profile", what = "thresholds", parg = list(type = "mode"))
plot(rsmod, type = "profile", what = "thresholds", parg = list(type = "mode"))
plot(pcmod, type = "profile", what = "thresholds", parg = list(type = "mode"))

## profile plot of the discrimination parameters of the dichotomous RM
plot(rmmod, type = "profile", what = "discrimination")


if(requireNamespace("mirt")) {
## fit 2PL and generalized partial credit model to verbal aggression data
twoplmod &lt;- nplmodel(VerbalAggression$resp2)
gpcmod &lt;- gpcmodel(VerbalAggression$resp)

## profile plot of the discrimination parameters of a dichotomous 2PL
plot(twoplmod, type = "profile", what = "discrimination")

## profile plot of the item parameters of the 2PL and GPCM
plot(twoplmod, type = "profile", what = "items", col = 4)
plot(gpcmod, type = "profile", what = "items", col = 2, add = TRUE)
}

</code></pre>

<hr>
<h2 id='raschmodel'>Rasch Model Fitting Function</h2><span id='topic+raschmodel'></span><span id='topic+RaschModel.fit'></span><span id='topic+print.raschmodel'></span><span id='topic+summary.raschmodel'></span><span id='topic+print.summary.raschmodel'></span><span id='topic+coef.raschmodel'></span><span id='topic+bread.raschmodel'></span><span id='topic+estfun.raschmodel'></span><span id='topic+logLik.raschmodel'></span><span id='topic+vcov.raschmodel'></span>

<h3>Description</h3>

<p><code>raschmodel</code> is a basic fitting function for simple Rasch models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>raschmodel(y, weights = NULL, start = NULL, reltol = 1e-10,
  deriv = c("sum", "diff", "numeric"), hessian = TRUE,
  maxit = 100L, full = TRUE, gradtol = reltol, iterlim = maxit, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="raschmodel_+3A_y">y</code></td>
<td>
<p>item response object that can be coerced (via <code><a href="base.html#topic+as.matrix">as.matrix</a></code>)
to a binary 0/1 matrix (e.g., from class <code><a href="#topic+itemresp">itemresp</a></code>.</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case weights).</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_start">start</code></td>
<td>
<p>an optional vector of starting values.</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_deriv">deriv</code></td>
<td>
<p>character. Which type of derivatives should be used for computing
gradient and Hessian matrix? Analytical with sum algorithm (<code>"sum"</code>),
analytical with difference algorithm (<code>"diff"</code>, faster but numerically unstable),
or numerical.</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_hessian">hessian</code></td>
<td>
<p>logical. Should the Hessian of the final model be computed?
If set to <code>FALSE</code>, the <code>vcov</code> method can only return <code>NA</code>s
and consequently no standard errors or tests are available in the <code>summary</code>.</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_reltol">reltol</code>, <code id="raschmodel_+3A_maxit">maxit</code>, <code id="raschmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_full">full</code></td>
<td>
<p>logical. Should a full model object be returned? If set to <code>FALSE</code>,
no variance-covariance matrix and no matrix of estimating functions are computed.</p>
</td></tr>
<tr><td><code id="raschmodel_+3A_gradtol">gradtol</code>, <code id="raschmodel_+3A_iterlim">iterlim</code></td>
<td>
<p>numeric. For backward compatibility with previous versions
these arguments are mapped to <code>reltol</code> and <code>maxit</code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>raschmodel</code> provides a basic fitting function for simple Rasch models,
intended as a building block for fitting Rasch trees and Rasch mixtures
in the <span class="pkg">psychotree</span> and <span class="pkg">psychomix</span> packages, respectively.
</p>
<p><code>raschmodel</code> returns an object of class <code>"raschmodel"</code> for which
several basic methods are available, including <code>print</code>, <code>plot</code>,
<code>summary</code>, <code>coef</code>, <code>vcov</code>, <code>logLik</code>, <code>estfun</code>,
<code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>,
and <code><a href="#topic+personpar">personpar</a></code>.
</p>


<h3>Value</h3>

<p><code>raschmodel</code> returns an S3 object of class <code>"raschmodel"</code>, 
i.e., a list with the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated item difficulty parameters (without first item
parameter which is always constrained to be 0),</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of the parameters in the model,</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>number of estimated parameters,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the original data supplied (excluding columns without variance),</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>status indicator (0, 0/1, 1) of all original items,</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>logical indicating whether the data contains NAs,</p>
</td></tr>
<tr><td><code>elementary_symmetric_functions</code></td>
<td>
<p>List of elementary symmetric functions
for estimated parameters (up to order 2; or 1 in case of numeric derivatives),</p>
</td></tr>
<tr><td><code>code</code></td>
<td>
<p>convergence code from <code>optim</code>,</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>number of iterations used by <code>optim</code>,</p>
</td></tr>
<tr><td><code>reltol</code></td>
<td>
<p>tolerance passed to <code>optim</code>,</p>
</td></tr>
<tr><td><code>deriv</code></td>
<td>
<p>type of derivatives used for computing gradient and
Hessian matrix,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>original function call.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+nplmodel">nplmodel</a></code>, <code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+rsmodel">rsmodel</a></code>,
<code><a href="#topic+gpcmodel">gpcmodel</a></code>, <code><a href="#topic+btmodel">btmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## Verbal aggression data
data("VerbalAggression", package = "psychotools")

## Rasch model for the other-to-blame situations
m &lt;- raschmodel(VerbalAggression$resp2[, 1:12])
## IGNORE_RDIFF_BEGIN
summary(m)
## IGNORE_RDIFF_END

## visualizations
plot(m, type = "profile")
plot(m, type = "regions")
plot(m, type = "curves")
plot(m, type = "information")
plot(m, type = "piplot")

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='regionplot'>Region Plots for IRT Models</h2><span id='topic+regionplot'></span>

<h3>Description</h3>

<p>Base graphics plotting function for region plot visualization of IRT models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  regionplot(object, parg = list(type = NULL, ref = NULL, alias = TRUE),
    names = TRUE, main = NULL, xlab = "", ylab = "Latent trait", ylim = NULL,
    off = 0.1, col = NULL, linecol = 2, srt = 45, adj = c(1.1, 1.1),
    axes = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regionplot_+3A_object">object</code></td>
<td>
<p>a fitted model object of class <code>"raschmodel"</code>,
<code>"rsmodel"</code>, <code>"pcmodel"</code>, <code>"nplmodel"</code> or <code>"gpcmodel"</code>.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_parg">parg</code></td>
<td>
<p>list of arguments passed over to internal calls of
<code><a href="#topic+threshpar">threshpar</a></code>. See the help page of <code><a href="#topic+threshpar">threshpar</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_names">names</code></td>
<td>
<p>logical or character. If <code>TRUE</code>, the names of the items are
displayed on the x-axis. If <code>FALSE</code>, numbers of items are shown.
Alternatively a character vector of the same length as the number of items
can be supplied.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_main">main</code></td>
<td>
<p>character, specifying the overall title of the plot.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_xlab">xlab</code>, <code id="regionplot_+3A_ylab">ylab</code></td>
<td>
<p>character, specifying the x and y axis labels.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_ylim">ylim</code></td>
<td>
<p>numeric, specifying the y axis limits.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_off">off</code></td>
<td>
<p>numeric, the distance (in scale units) between two item
rectangles.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_col">col</code></td>
<td>
<p>character, list or function, specifying the colors of the regions.
Either a single vector with <code class="reqn">k</code> color names, a list with <code class="reqn">m</code>
elements and each element is a character vector with color names for the
regions of item <code class="reqn">j</code> or a color-generating function like, e.g.,
<code>gray.colors</code>, which is then directly used to create the color names.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_linecol">linecol</code></td>
<td>
<p>color for lines indicating &ldquo;hidden&rdquo; categories.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_srt">srt</code>, <code id="regionplot_+3A_adj">adj</code></td>
<td>
<p>numeric. Angle (<code>srt</code>) and adjustment (<code>adj</code>) in
case names (rather than numbers) are used as x-axis labels. These are
passed to <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="regionplot_+3A_axes">axes</code></td>
<td>
<p>logical. Should axes be drawn?</p>
</td></tr>
<tr><td><code id="regionplot_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The region plot visualization implemented here was already used by Van der
Linden and Hambleton (1997) in the context of IRT and has been called &quot;effect
plots&quot; by Fox &amp; Hong (2009). In our implementation, these plots show,
dependent on the chosen type of threshold parameters, different regions for
the categories of an item over the theta axis. If <code>type</code> is set to
<code>"modus"</code>, the cutpoints correspond to the threshold parameters and the
rectangles mark the theta regions where a category is the single most probable
category chosen with a certain value of the latent trait. If <code>type</code> is
set to <code>"median"</code>, the cutpoints correspond to the point on the theta
axis, where the cumulative probability to score in category <code class="reqn">k</code> or higher
is 0.5, i.e., <code class="reqn">P(X_{ij} \geq k) = 0.5</code>. If set to <code>"mean"</code>, the
cutpoints correspond to the point on the theta axis where the expected score
<code class="reqn">E(X_{ij})</code> is exactly between two categories, e.g., 0.5 for a dichotomous
item.
</p>
<p>If <code>type</code> is set to <code>"mode"</code> and there are unordered threshold
parameters, the location of the original threshold parameters are indicated by
red dashed lines.
</p>


<h3>References</h3>

<p>Fox J, Hong J (2009).
Effect Displays in R for Multinomial and Proportional-Odds Logit Models:
Extensions to the effects Package.
<em>Journal of Statistical Software</em>, <b>32</b>(1), 1&ndash;24.
</p>
<p>Van der Linden WJ, Hambleton RK (1997).
<em>Handbook of Modern Item Response Theory</em>.
Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+curveplot">curveplot</a></code>, <code><a href="#topic+profileplot">profileplot</a></code>,
<code><a href="#topic+infoplot">infoplot</a></code>, <code><a href="#topic+piplot">piplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit a Partial credit model to the items of the first other-to-blame
## situation: "A bus fails to stop for me"
pcm &lt;- pcmodel(VerbalAggression$resp[, 1:6])

## a region plot with modus as cutpoint and custom labels
lab &lt;- paste(rep(c("Curse", "Scold", "Shout"), each = 2),
  rep(c("Want", "Do"), 3 ), sep = "-")
plot(pcm, type = "regions", names = lab)

## compare the cutpoints (with ylim specified manually)
opar &lt;- par(no.readonly = TRUE)
ylim &lt;- c(-2, 2)
layout(matrix(1:3, ncol = 1))
plot(pcm, type = "regions", parg = list(type = "mode"),
  main = "Modus as Cutpoint", ylim = ylim) 
plot(pcm, type = "regions", parg = list(type = "median"),
  main = "Median as Cutpoint", ylim = ylim)
plot(pcm, type = "regions", parg = list(type = "mean"),
  main = "Mean as Cutpoint", ylim = ylim)
par(opar)

## PCM for full verbal aggression data set
pcm_va &lt;- pcmodel(VerbalAggression$resp)
plot(pcm_va, type = "regions")

if(requireNamespace("mirt")) {
## generalized partial credit model for full verbal aggression data set
gpcm_va &lt;- gpcmodel(VerbalAggression$resp)
plot(gpcm_va, type = "regions")
}
</code></pre>

<hr>
<h2 id='rgpcm'>Simulate Data under a Generalized Partial Credit Model</h2><span id='topic+rgpcm'></span>

<h3>Description</h3>

<p><code>rgpcm</code> simulates IRT data under a generalized partial credit model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgpcm(theta, a, b, nullcats = FALSE, return_setting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rgpcm_+3A_theta">theta</code></td>
<td>
<p>numeric vector of person parameters. Can also be a list, then a
list of length <code>length(theta)</code> is returned, containing multiple
simulated data sets.</p>
</td></tr>
<tr><td><code id="rgpcm_+3A_a">a</code></td>
<td>
<p>list of numerics of item discrimination parameters.</p>
</td></tr>
<tr><td><code id="rgpcm_+3A_b">b</code></td>
<td>
<p>list of numeric vectors of item threshold parameters.</p>
</td></tr>
<tr><td><code id="rgpcm_+3A_nullcats">nullcats</code></td>
<td>
<p>logical. Should null categories be allowed?</p>
</td></tr>
<tr><td><code id="rgpcm_+3A_return_setting">return_setting</code></td>
<td>
<p>logical. Should a list containing slots of &quot;a&quot;, &quot;b&quot;,
and &quot;theta&quot;, as well as the simulated data matrix &quot;data&quot; be
returned (default) or only the simulated data matrix?</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rgpcm</code> returns either a list of the following components:
</p>
<table>
<tr><td><code>a</code></td>
<td>
<p>list of numerics of item discrimination parameters used,</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>list of numeric vectors of item threshold parameters used,</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>numeric vector of person parameters used,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>numeric matrix containing the simulated data,</p>
</td></tr>
</table>
<p>or (if <code>return_setting = FALSE</code>) only the numeric matrix containing the
simulated data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpcm">rpcm</a></code>, <code><a href="#topic+rrsm">rrsm</a></code>, <code><a href="#topic+rpl">rpl</a></code>,
<code><a href="#topic+rrm">rrm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
## item responses under a GPCM (generalized partial credit model) from
## 6 persons with three different person parameters
## 8 items with different combinations of two or three threshold parameters
## and corresponding discrimination parameters
ppar &lt;- rep(-1:1, each = 2)
tpar &lt;- rep(list(-2:0, -1:1, 0:1, 0:2), each = 2)
dpar &lt;- rep(list(1, 2), each = 4)
sim &lt;- rgpcm(theta = ppar, a = dpar, b = tpar)

## simulated item response data along with setting parameters
sim

## print and plot corresponding item response object
iresp &lt;- itemresp(sim$data)
iresp
plot(iresp)
</code></pre>

<hr>
<h2 id='rpcm'>Simulate Data under a Partial Credit Model</h2><span id='topic+rpcm'></span>

<h3>Description</h3>

<p><code>rpcm</code> simulates IRT data under a partial credit model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpcm(theta, delta, nullcats = FALSE, return_setting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpcm_+3A_theta">theta</code></td>
<td>
<p>numeric vector of person parameters. Can also be a list, then a
list of length <code>length(theta)</code> is returned, containing multiple
simulated data sets.</p>
</td></tr>
<tr><td><code id="rpcm_+3A_delta">delta</code></td>
<td>
<p>list of numeric vectors of item threshold parameters.</p>
</td></tr>
<tr><td><code id="rpcm_+3A_nullcats">nullcats</code></td>
<td>
<p>logical. Should null categories be allowed?</p>
</td></tr>
<tr><td><code id="rpcm_+3A_return_setting">return_setting</code></td>
<td>
<p>logical. Should a list containing slots of &quot;delta&quot;,
and &quot;theta&quot;, as well as the simulated data matrix &quot;data&quot; be
returned (default) or only the simulated data matrix?</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rpcm</code> returns either a list of the following components:
</p>
<table>
<tr><td><code>delta</code></td>
<td>
<p>list of numeric vectors of item threshold parameters used,</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>numeric vector of person parameters used,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>numeric matrix containing the simulated data,</p>
</td></tr>
</table>
<p>or (if <code>return_setting = FALSE</code>) only the numeric matrix containing the
simulated data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rgpcm">rgpcm</a></code>, <code><a href="#topic+rrsm">rrsm</a></code>, <code><a href="#topic+rrm">rrm</a></code>,
<code><a href="#topic+rpl">rpl</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
## item responses under a partial credit model (PCM) with
## 6 persons with three different person parameters
## 8 items with different combinations of two or three threshold parameters
ppar &lt;- rep(-1:1, each = 2)
tpar &lt;- rep(list(-2:0, -1:1, 0:1, 0:2), each = 2)
sim &lt;- rpcm(theta = ppar, delta = tpar)

## simulated item response data along with setting parameters
sim

## print and plot corresponding item response object
iresp &lt;- itemresp(sim$data)
iresp
plot(iresp)
</code></pre>

<hr>
<h2 id='rpl'>Simulate Data under a Parametric Logistic IRT Model</h2><span id='topic+rpl'></span>

<h3>Description</h3>

<p><code>rpl</code> simulates IRT data under a parametric logistic IRT model of type
&quot;2PL&quot;, &quot;3PL&quot;, &quot;3PLu&quot;, &quot;4PL&quot;, and &quot;Rasch/1PL&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpl(theta, a = NULL, b, g = NULL, u = NULL, return_setting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpl_+3A_theta">theta</code></td>
<td>
<p>numeric vector of person parameters. Can also be a list, then a
list of length <code>length(theta)</code> is returned, containing multiple
simulated data matrices.</p>
</td></tr>
<tr><td><code id="rpl_+3A_a">a</code></td>
<td>
<p>numeric vector of item discrimination parameters. If <code>NULL</code>,
by default set to a vector of ones of length <code>length(b)</code>.</p>
</td></tr>
<tr><td><code id="rpl_+3A_b">b</code></td>
<td>
<p>numeric vector of item difficulty parameters.</p>
</td></tr>
<tr><td><code id="rpl_+3A_g">g</code></td>
<td>
<p>numeric vector of so-called item guessing parameters. If <code>NULL</code>,
by default set to a vector of zeroes of length <code>length(b)</code>.</p>
</td></tr>
<tr><td><code id="rpl_+3A_u">u</code></td>
<td>
<p>numeric vector of item upper asymptote parameters. If <code>NULL</code>,
by default set to a vector of ones of length <code>length(b)</code>.</p>
</td></tr>
<tr><td><code id="rpl_+3A_return_setting">return_setting</code></td>
<td>
<p>logical. Should a list containing slots of &quot;a&quot;, &quot;b&quot;,
&quot;g&quot;, &quot;u&quot;, and &quot;theta&quot;, as well as the simulated data matrix &quot;data&quot; be
returned (default) or only the simulated data matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rpl</code> returns either a list of the following components:
</p>
<table>
<tr><td><code>a</code></td>
<td>
<p>numeric vector of item discrimination parameters used,</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>numeric vector of item difficulty parameters used,</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>numeric vector of item guessing parameters used,</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>numeric vector of item upper asymptote parameters used,</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>numeric vector of person parameters used,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>numeric matrix containing the simulated data,</p>
</td></tr>
</table>
<p>or (if <code>return_setting = FALSE</code>) only the numeric matrix containing the
simulated data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrm">rrm</a></code>, <code><a href="#topic+rgpcm">rgpcm</a></code>, <code><a href="#topic+rpcm">rpcm</a></code>,
<code><a href="#topic+rrsm">rrsm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
## item responses under a 2PL (two-parameter logistic) model from
## 6 persons with three different person parameters
## 9 increasingly difficult items and corresponding discrimination parameters
## no guessing (= 0) and upper asymptote 1
ppar &lt;- rep(c(-2, 0, 2), each = 2)
ipar &lt;- seq(-2, 2, by = 0.5)
dpar &lt;- rep(c(0.5, 1, 1.5), each = 3)
sim &lt;- rpl(theta = ppar, a = dpar, b = ipar)

## simulated item response data along with setting parameters
sim

## print and plot corresponding item response object
iresp &lt;- itemresp(sim$data)
iresp
plot(iresp)
</code></pre>

<hr>
<h2 id='rrm'>Simulate Data under a Rasch model</h2><span id='topic+rrm'></span>

<h3>Description</h3>

<p><code>rrm</code> simulates IRT data under a Rasch model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrm(theta, beta, return_setting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrm_+3A_theta">theta</code></td>
<td>
<p>numeric vector of person parameters. Can also be a list, then a
list of length <code>length(theta)</code> is returned, containing multiple
simulated data matrices.</p>
</td></tr>
<tr><td><code id="rrm_+3A_beta">beta</code></td>
<td>
<p>numeric vector of item difficulty parameters.</p>
</td></tr>
<tr><td><code id="rrm_+3A_return_setting">return_setting</code></td>
<td>
<p>logical. Should a list containing slots of &quot;beta&quot;,
and &quot;theta&quot;, as well as the simulated data matrix &quot;data&quot; be
returned (default) or only the simulated data matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rrm</code> returns either a list of the following components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>numeric vector of item difficulty parameters used,</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>numeric vector of person parameters used,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>numeric matrix containing the simulated data,</p>
</td></tr>
</table>
<p>or (if <code>return_setting = FALSE</code>) only the numeric matrix containing the
simulated data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpl">rpl</a></code>, <code><a href="#topic+rpcm">rpcm</a></code>, <code><a href="#topic+rrsm">rrsm</a></code>,
<code><a href="#topic+rgpcm">rgpcm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
## item responses under a Rasch model from
## 6 persons with three different person parameters
## 9 increasingly difficult items
ppar &lt;- rep(-1:1, each = 2)
ipar &lt;- seq(-2, 2, by = 0.5)
sim &lt;- rrm(theta = ppar, beta = ipar)

## simulated item response data along with setting parameters
sim

## print and plot corresponding item response object
iresp &lt;- itemresp(sim$data)
iresp
plot(iresp)
</code></pre>

<hr>
<h2 id='rrsm'>Simulate Data under a Rating Scale Model</h2><span id='topic+rrsm'></span>

<h3>Description</h3>

<p><code>rrsm</code> simulates IRT data under a rating scale model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrsm(theta, beta, tau, nullcats = FALSE, return_setting = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrsm_+3A_theta">theta</code></td>
<td>
<p>numeric vector of person parameters. Can also be a list, then a
list of length <code>length(theta)</code> is returned, containing multiple
simulated data sets.</p>
</td></tr>
<tr><td><code id="rrsm_+3A_beta">beta</code></td>
<td>
<p>numeric vector of item difficulty parameters.</p>
</td></tr>
<tr><td><code id="rrsm_+3A_tau">tau</code></td>
<td>
<p>numeric vector of threshold parameters.</p>
</td></tr>
<tr><td><code id="rrsm_+3A_nullcats">nullcats</code></td>
<td>
<p>logical. Should null categories be allowed?</p>
</td></tr>
<tr><td><code id="rrsm_+3A_return_setting">return_setting</code></td>
<td>
<p>logical. Should a list containing slots of &quot;beta&quot;,
&quot;tau&quot;, and &quot;theta&quot;, as well as the simulated data matrix &quot;data&quot; be
returned (default) or only the simulated data matrix?</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rrsm</code> returns either a list of the following components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>numeric vector of item difficulty parameters used,</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>numeric vector of threshold parameters used,</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>numeric vector (or list) of person parameters used,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>numeric matrix containing the simulated data,</p>
</td></tr>
</table>
<p>or (if <code>return_setting = FALSE</code>) only the numeric matrix containing the
simulated data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpcm">rpcm</a></code>, <code><a href="#topic+rgpcm">rgpcm</a></code>, <code><a href="#topic+rrm">rrm</a></code>,
<code><a href="#topic+rpl">rpl</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
## item responses under a rating scale model (RSM) with
## 6 persons with three different person parameters
## 9 increasingly difficult items
## 3 different threshold parameters
ppar &lt;- rep(-1:1, each = 2)
ipar &lt;- seq(-2, 2, by = 0.5)
tpar &lt;- 0:2
sim &lt;- rrsm(theta = ppar, beta = ipar, tau = tpar)

## simulated item response data along with setting parameters
sim

## print and plot corresponding item response object
iresp &lt;- itemresp(sim$data)
iresp
plot(iresp)
</code></pre>

<hr>
<h2 id='rsmodel'>Rating Scale Model Fitting Function</h2><span id='topic+rsmodel'></span><span id='topic+RSModel.fit'></span><span id='topic+print.rsmodel'></span><span id='topic+summary.rsmodel'></span><span id='topic+print.summary.rsmodel'></span><span id='topic+coef.rsmodel'></span><span id='topic+bread.rsmodel'></span><span id='topic+estfun.rsmodel'></span><span id='topic+logLik.rsmodel'></span><span id='topic+vcov.rsmodel'></span>

<h3>Description</h3>

<p><code>rsmodel</code> is a basic fitting function for rating scale models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsmodel(y, weights = NULL, start = NULL, reltol = 1e-10,
  deriv = c("sum", "diff"), hessian = TRUE,
  maxit = 100L, full = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsmodel_+3A_y">y</code></td>
<td>
<p>item response object that can be coerced (via <code><a href="base.html#topic+as.matrix">as.matrix</a></code>)
to a numeric matrix with scores 0, 1, ... Typically, either
already a matrix, data frame, or dedicated object of class
<code><a href="#topic+itemresp">itemresp</a></code>.</p>
</td></tr>
<tr><td><code id="rsmodel_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights (interpreted as case
weights).</p>
</td></tr>
<tr><td><code id="rsmodel_+3A_deriv">deriv</code></td>
<td>
<p>character. If &quot;sum&quot; (the default), the first derivatives
of the elementary symmetric functions are calculated with the sum
algorithm. Otherwise (&quot;diff&quot;) the difference algorithm (faster but
numerically unstable) is used.</p>
</td></tr>
<tr><td><code id="rsmodel_+3A_start">start</code></td>
<td>
<p>an optional vector of starting values.</p>
</td></tr>
<tr><td><code id="rsmodel_+3A_hessian">hessian</code></td>
<td>
<p>logical. Should the Hessian of the final model be computed?
If set to <code>FALSE</code>, the <code>vcov</code> method can only return <code>NA</code>s
and consequently no standard errors or tests are available in the
<code>summary</code>.</p>
</td></tr>
<tr><td><code id="rsmodel_+3A_reltol">reltol</code>, <code id="rsmodel_+3A_maxit">maxit</code>, <code id="rsmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code id="rsmodel_+3A_full">full</code></td>
<td>
<p>logical. Should a full model object be returned? If set to <code>FALSE</code>,
no variance-covariance matrix and no matrix of estimating functions are computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rsmodel</code> provides a basic fitting function for rating scales models,
intended as a building block for fitting rating scale trees. It
estimates the rating scale model in the parametrization suggested by
Andrich (1978), i.e., item-specific parameters <code class="reqn">\xi_{j}</code> who mark
the location of the first absolute threshold of an item on the theta axis and
cumulative relative threshold parameters <code class="reqn">\kappa_{k}</code> are
estimated by the function <code>rsmodel</code>.
</p>
<p><code>rsmodel</code> returns an object of class <code>"rsmodel"</code> (and
class <code>"pcmodel"</code>) for which several basic methods are available,
including <code>print</code>, <code>plot</code>, <code>summary</code>, <code>coef</code>,
<code>vcov</code>, <code>logLik</code>, <code><a href="#topic+discrpar">discrpar</a></code>, <code>estfun</code>,
<code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+threshpar">threshpar</a></code>, and <code><a href="#topic+personpar">personpar</a></code>.
</p>


<h3>Value</h3>

<p><code>rsmodel</code> returns an S3 object of class <code>"rsmodel"</code>, 
i.e., a list with the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of estimated item-specific
parameters (without the first item parameter which is constrained
to 0) and estimated cumulative relative treshold parameters
(again without first threshold parameter which is also constrained to 0),</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of the parameters in the model,</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>modified data, used for model-fitting, i.e., cleaned for items without
variance, centralized so that the first category is zero for all items
and without observations with zero weight. Be careful, this is different than for
objects of class <code>"raschmodel"</code> or <code>"btmodel"</code>, where
<code>data</code> contains the <em>original</em> data,</p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>logical vector of length <code>ncol(y)</code>, which
indicates which items have variance (<code>TRUE</code>), i.e., are identified and have been
used for the estimation or not (<code>FALSE</code>),</p>
</td></tr>
<tr><td><code>categories</code></td>
<td>
<p>integer vector of length <code>ncol(y)</code>, which
contains the number of categories minus one per item,</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations (with non-zero weights),</p>
</td></tr>
<tr><td><code>n_org</code></td>
<td>
<p>original number of observations in <code>y</code>,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>logical indicating whether the data contains NAs,</p>
</td></tr>
<tr><td><code>esf</code></td>
<td>
<p>list of elementary symmetric functions and their
derivatives for estimated parameters,</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>number of estimated parameters,</p>
</td></tr>
<tr><td><code>code</code></td>
<td>
<p>convergence code from <code>optim</code>,</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>number of iterations used by <code>optim</code>,</p>
</td></tr>
<tr><td><code>reltol</code></td>
<td>
<p>tolerance passed to <code>optim</code>,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>original function call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Andrich D (1978).
Application of a Psychometric Rating Model to Ordered Categories Which Are Scored with Successive Integers.  
<em>Psychometrika</em>, <b>2</b>(4), 581&ndash;594.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcmodel">pcmodel</a></code>, <code><a href="#topic+gpcmodel">gpcmodel</a></code>, <code><a href="#topic+raschmodel">raschmodel</a></code>,
<code><a href="#topic+nplmodel">nplmodel</a></code>, <code><a href="#topic+btmodel">btmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## Verbal aggression data
data("VerbalAggression", package = "psychotools")

## Rating scale model for the other-to-blame situations
rsm &lt;- rsmodel(VerbalAggression$resp[, 1:12])
summary(rsm)

## visualizations
plot(rsm, type = "profile")
plot(rsm, type = "regions")
plot(rsm, type = "curves")
plot(rsm, type = "information")
plot(rsm, type = "piplot")

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='Sim3PL'>Simulated Data for fitting a 3PL and 3PLu</h2><span id='topic+Sim3PL'></span>

<h3>Description</h3>

<p>Simulated responses of 10000 persons to 10 dichotomous items under two
different simulation conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Sim3PL", package = "psychotools")</code></pre>


<h3>Format</h3>

<p>A data frame containing 10000 observations on 2 variables.
</p>

<dl>
<dt>resp</dt><dd><p>Item response matrix with 10 items (see details below).</p>
</dd>
<dt>resp2</dt><dd><p>Item response matrix with 10 items (see details below).</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data were simulated under the 3PL (<code>resp</code>) and 3PLu (<code>resp2</code>) (see
<code><a href="#topic+nplmodel">nplmodel</a></code>). For the 3PL scenario, the random number generator's
seed was set to 277. For the 3PLu scenario, the random number generator's seed
was set to 167. Person parameters <code class="reqn">\theta_{i}</code> of 10000 persons were drawn
from the standard normal distribution. Item difficulties <code class="reqn">b_{j}</code> of 10
items (under the classical IRT parametrization) were drawn from the standard
normal distribution. Item discrimination parameters <code class="reqn">a_{j}</code> were drawn
from a log-normal distribution with a mean of <code class="reqn">0</code> and a variance of
<code class="reqn">0.0625</code> on the log scale. For the 3PL, guessing parameters
<code class="reqn">g_{j}</code> were drawn from a uniform distribution with a lower limit of
<code class="reqn">0.1</code> and an upper limit of <code class="reqn">0.2</code>. For the 3PLu, upper asymptote
parameters <code class="reqn">u_{j}</code> were drawn from a uniform distribution with a lower
limit of <code class="reqn">0.8</code> and an upper limit of <code class="reqn">0.9</code>. In both scenarios, a
<code class="reqn">10000</code> x <code class="reqn">10</code> matrix based on realizations of a uniform distribution
with a lower limit of <code class="reqn">0</code> and an upper limit of <code class="reqn">1</code> was generated and
compared to a <code class="reqn">10000</code> x <code class="reqn">10</code> matrix based on the probability function
under the respective model. If the probability of person <code class="reqn">i</code> solving item
<code class="reqn">j</code> exceeded the corresponding realization of the uniform distribution,
this cell of the matrix was set to <code class="reqn">1</code>, e.g., person <code class="reqn">i</code> solved item
<code class="reqn">j</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nplmodel">nplmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## overview
data("Sim3PL", package = "psychotools")
str(Sim3PL)

## data generation
M &lt;- 10000
N &lt;- 10

## 3PL scenario
set.seed(277)
theta &lt;- rnorm(M, 0, 1)
a &lt;- rlnorm(N, 0, 0.25)
b &lt;- rnorm(N, 0, 1)
g &lt;- runif(N, 0.1, 0.2)
u &lt;- rep(1, N)
probs &lt;- matrix(g, M, N, byrow = TRUE) + matrix(u - g, M, N, byrow = TRUE) *
  plogis(matrix(a, M, N, byrow = TRUE) * outer(theta, b, "-"))
resp &lt;- (probs &gt; matrix(runif(M * N, 0, 1), M, N)) + 0
all.equal(resp, Sim3PL$resp, check.attributes = FALSE)

## 3PLu scenario
set.seed(167)
theta &lt;- rnorm(M, 0, 1)
a &lt;- rlnorm(N, 0, 0.25)
b &lt;- rnorm(N, 0, 1)
g &lt;- rep(0, N)
u &lt;- runif(N, 0.8, 0.9)
probs &lt;- matrix(g, M, N, byrow = TRUE) + matrix(u - g, M, N, byrow = TRUE) *
  plogis(matrix(a, M, N, byrow = TRUE) * outer(theta, b, "-"))
resp2 &lt;- (probs &gt; matrix(runif(M * N, 0, 1), M, N)) + 0
all.equal(resp2, Sim3PL$resp2, check.attributes = FALSE)
</code></pre>

<hr>
<h2 id='SoundQuality'>Quality of Multichannel Reproduced Sound</h2><span id='topic+SoundQuality'></span>

<h3>Description</h3>

<p>Paired comparison judgments of 40 selected listeners with respect to
eight audio reproduction modes and four types of music. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SoundQuality")</code></pre>


<h3>Format</h3>

<p>A data frame containing 783 observations on 6 variables.
</p>

<dl>
<dt>id</dt><dd><p>Factor. Listener ID.</p>
</dd>
<dt>time</dt><dd><p>Factor. Listening experiment before or after elicitation and
scaling of more specific auditory attributes.</p>
</dd>
<dt>progmat</dt><dd><p>Factor. The program material: Beethoven, Rachmaninov, Steely
Dan, Sting.</p>
</dd>
<dt>repet</dt><dd><p>The repetition within each time point.</p>
</dd>
<dt>session</dt><dd><p>The experimental session coding the presentation order of
the program material.</p>
</dd>
<dt>preference</dt><dd><p>Paired comparison of class <code><a href="#topic+paircomp">paircomp</a></code>.
Preferences for all 28 paired comparisons from 8 audio reproduction modes:
Mono, Phantom Mono, Stereo, Wide-Angle Stereo, 4-channel Matrix,
5-channel Upmix 1, 5-channel Upmix 2, and 5-channel Original.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data were collected within a series of experiments conducted at the
Sound Quality Research Unit (SQRU), Department of Acoustics, Aalborg
University, Denmark, between September 2004 and March 2005.
</p>
<p>The results of scaling listener preference and spatial and timbral auditory
attributes are reported in Choisel and Wickelmaier (2007).
</p>
<p>Details about the loudspeaker setup and calibration are given in Choisel and
Wickelmaier (2006).
</p>
<p>The attribute elicitation procedure is described in Wickelmaier and
Ellermeier (2007) and in Choisel and Wickelmaier (2006).
</p>
<p>The selection of listeners for the experiments is described in Wickelmaier
and Choisel (2005).
</p>
<p>An extended version of this data set, including judgments on spatial and
timbral auditory attributes and including listener variables, is available
via <code>data("soundquality", package = "eba")</code>.
</p>


<h3>References</h3>

<p>Choisel S, Wickelmaier F (2006).
Extraction of Auditory Features and Elicitation of Attributes for the Assessment of Multichannel Reproduced Sound.
<em>Journal of the Audio Engineering Society</em>, <b>54</b>(9), 815&ndash;826.
</p>
<p>Choisel S, Wickelmaier F (2007).
Evaluation of Multichannel Reproduced Sound: Scaling Auditory Attributes Underlying Listener Preference.
<em>Journal of the Acoustical Society of America</em>, <b>121</b>(1), 388&ndash;400. 
<a href="https://doi.org/10.1121/1.2385043">doi:10.1121/1.2385043</a>
</p>
<p>Wickelmaier F, Choisel S (2005).
Selecting Participants for Listening Tests of Multichannel Reproduced Sound.
Presented at the AES 118th Convention, May 28&ndash;31, Barcelona, Spain, convention paper 6483.
</p>
<p>Wickelmaier F, Ellermeier W (2007).
Deriving Auditory Features from Triadic Comparisons.
<em>Perception &amp; Psychophysics</em>, <b>69</b>(2), 287&ndash;297.
<a href="https://doi.org/10.3758/BF03193750">doi:10.3758/BF03193750</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paircomp">paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("SoundQuality", package = "psychotools")
summary(SoundQuality$preference)
ftable(xtabs(~ time + repet + progmat, data = SoundQuality))
</code></pre>

<hr>
<h2 id='SourceMonitoring'>Performance in a Source-Monitoring Experiment</h2><span id='topic+SourceMonitoring'></span>

<h3>Description</h3>

<p>Response frequencies of 128 participants who took part in a
source-monitoring experiment with two sources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SourceMonitoring")</code></pre>


<h3>Format</h3>

<p>A data frame containing 128 observations on four components.
</p>

<dl>
<dt>sources</dt><dd><p>Factor. Sources A and B.</p>
</dd>
<dt>age</dt><dd><p>Integer. Age of the respondents in years.</p>
</dd>
<dt>gender</dt><dd><p>Factor coding gender.</p>
</dd>
<dt>y</dt><dd><p>Matrix containing the response frequencies. The column names
indicate the nine response categories:
</p>

<table>
<tr>
 <td style="text-align: right;">
      <code>a.a</code> </td><td style="text-align: left;"> Number of source A items judged to be of source A.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>a.b</code> </td><td style="text-align: left;"> Number of source A items judged to be of source B.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>a.n</code> </td><td style="text-align: left;"> Number of source A items judged to be new.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>b.a</code> </td><td style="text-align: left;"> Number of source B items judged to be of source A.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>b.b</code> </td><td style="text-align: left;"> Number of source B items judged to be of source B.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>b.n</code> </td><td style="text-align: left;"> Number of source B items judged to be new.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>n.a</code> </td><td style="text-align: left;"> Number of new items judged to be of source A.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>n.b</code> </td><td style="text-align: left;"> Number of new items judged to be of source B.</td>
</tr>
<tr>
 <td style="text-align: right;">
      <code>n.n</code> </td><td style="text-align: left;"> Number of new items judged to be new.
    </td>
</tr>

</table>

</dd>
</dl>



<h3>Details</h3>

<p>In a source-monitoring experiment with two sources, participants study
items from two different sources, A and B. The final memory test consists
of A and B items along with new distractor items, N. Participants are
required to classify each item as A, B, or N.
</p>
<p>In an experiment at the Department of Psychology, University of Tuebingen
(Wickelmaier &amp; Zeileis, 2013, 2018), two source conditions were used in
the study phase: Half of the subjects had to read items either quietly
(source A = think) or aloud (source B = say). The other half had to write
items down (source A = write) or read them aloud (source B = say).
</p>
<p>The data were analyzed using the multinomial processing tree model of
source monitoring (Batchelder &amp; Riefer, 1990).
</p>


<h3>Source</h3>

<p>Wickelmaier F, Zeileis A (2013).
A First Implementation of Recursive Partitioning for Multinomial
Processing Tree Models.
Presented at the Psychoco 2013 International Workshop on Psychometric
Computing, February 14&ndash;15, Zurich, Switzerland. 
</p>


<h3>References</h3>

<p>Batchelder WH, Riefer DM (1990).
Multinomial Processing Tree Models of Source Monitoring.
<em>Psychological Review</em>, <b>97</b>, 548&ndash;564.
</p>
<p>Wickelmaier F, Zeileis A (2018).
Using Recursive Partitioning to Account for Parameter Heterogeneity in
Multinomial Processing Tree Models.
<em>Behavior Research Methods</em>, <b>50</b>(3), 1217&ndash;1233.
<a href="https://doi.org/10.3758/s13428-017-0937-z">doi:10.3758/s13428-017-0937-z</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("SourceMonitoring", package = "psychotools")
xtabs(~ gender + I(age &gt;= 30) + sources, SourceMonitoring)
</code></pre>

<hr>
<h2 id='StereotypeThreat'>Stereotype Threat in Dutch Differential Aptitude Test</h2><span id='topic+StereotypeThreat'></span>

<h3>Description</h3>

<p>Cross-section data from Differential Aptitude Test (DAT) among Dutch highschool
students, along with experimental conditions pertaining to stereotype threat.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("StereotypeThreat")</code></pre>


<h3>Format</h3>

<p>A data frame containing 295 observations on 11 variables.
</p>

<dl>
<dt>condition</dt><dd><p>Factor indicating experimental condition: <code>"control"</code> or
stereotype <code>"threat"</code>, for details see below.</p>
</dd>
<dt>ethnicity</dt><dd><p>Factor coding ethnicity: Dutch <code>"majority"</code> or <code>"minority"</code>.</p>
</dd>
<dt>numerical</dt><dd><p>Number of items solved in numerical ability subtest
(out of 14 complicated mathematical items).</p>
</dd>
<dt>abstract</dt><dd><p>Number of items solved in abstract reasoning subtest
(out of 18 items with a logical sequence of diagrams).</p>
</dd>
<dt>verbal</dt><dd><p>Number of items solved in verbal reasoning subtest
(out of 16 verbal analogy items).</p>
</dd>
<dt>gender</dt><dd><p>Factor indicating gender.</p>
</dd>
<dt>age</dt><dd><p>Age in years.</p>
</dd>
<dt>vintelligence</dt><dd><p>Numerical coding of the value of one's own intelligence.
Answer to: How important is your intelligence for you?
Range is from very important (<code>5</code>) to unimportant (<code>1</code>).</p>
</dd>
<dt>vgrades</dt><dd><p>Numerical coding of the value of getting good grades.  
Answer to: How much do you value getting good school grades?
Range is from a lot of value (<code>5</code>) to not so much value (<code>1</code>).</p>
</dd>
<dt>vprejudice</dt><dd><p>Numerical coding of the answer to: Do you think that people of your group are prejudiced against?
Range is from certainly (<code>5</code>) to not at all (<code>1</code>).</p>
</dd>
<dt>gpa</dt><dd><p>Numerical grade point average on 10-point scale (with 10 being the best grade).
It has 57 missing values as some schools were either unwilling to share the
data or did not provide it timely enough.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are taken from Study 1 of Wicherts et al. (2005) and have been used to study
stereotype threat on intelligence test performance among Dutch highschool students.
</p>
<p>On average, Dutch minority students attain lower educational levels compared to Dutch
majority students and studies have shown that minority students are often viewed as
less smart/educated. Conversely, minorities often feel discriminated against in scholastic
domains.
</p>
<p>Wicherts et al. (2005) administered an intelligence test consisting of three
subtests (for numerical ability, abstract reasoning, and verbal reasoning) and varied
the amount of stereotype threat related to ethnic minorities by changing the presentation
of the test. In the <code>"threat"</code> condition, the questions were declared to be part
of an intelligence test and also an ethnicity questionnaire was conducted prior to the DAT.
In the <code>"control"</code> condition, intelligence was not mentioned and no ethnicity
questionnaire was conducted.
</p>
<p>The variables <code>numerical</code>, <code>abstract</code>, and <code>verbal</code> can be used to assess
ability/intelligence. And the <code>vintelligence</code>, <code>vgrades</code>, <code>vprejudice</code>, and
<code>gpa</code> variables capture identification with the scholastic domain.
</p>
<p>See Wicherts et al. (2005) for details.
</p>


<h3>Source</h3>

<p>Provided by Jelte M. Wicherts.
</p>


<h3>References</h3>

<p>Wicherts JM, Conor VD, Hessen DJ (2005).
Stereotype Threat and Group Differences in Test Performance: A Question of Measurement Invariance.
<em>Journal of Personality and Social Psychology</em>, <b>89</b>(5), 696-716.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data: Load and include/order wrt group variable
data("StereotypeThreat", package = "psychotools")
StereotypeThreat &lt;- transform(StereotypeThreat, group = interaction(ethnicity, condition))
StereotypeThreat &lt;- StereotypeThreat[order(StereotypeThreat$group),]

## Exploratory analysis (Table 2, p. 703)
tab2 &lt;- with(StereotypeThreat, rbind(
   "#"         = tapply(numerical, group, length),
   "Numerical" = tapply(numerical, group, mean),
   "         " = tapply(numerical, group, sd),
   "Abstract " = tapply(abstract,  group, mean),
   "         " = tapply(abstract,  group, sd),
   "Verbal   " = tapply(verbal,    group, mean),
   "         " = tapply(verbal,    group, sd)))
round(tab2, digits = 2)

## Corresponding boxplots
plot(numerical ~ group, data = StereotypeThreat)
plot(abstract  ~ group, data = StereotypeThreat)
plot(verbal    ~ group, data = StereotypeThreat)

## MANOVA (p. 703)
m &lt;- lm(cbind(numerical, abstract, verbal) ~ ethnicity * condition, data = StereotypeThreat)
anova(m, update(m, . ~ . - ethnicity:condition))
## corresponding univariate results
printCoefmat(t(sapply(summary(m),
  function(x) x$coefficients["ethnicityminority:conditionthreat", ])))

## MGCFA (Table 3, p. 704)
## can be replicated using package lavaan
## Not run: 
## convenience function for multi-group CFA on this data
mgcfa &lt;- function(model, ...) cfa(model, data = StereotypeThreat,
  group = "group", likelihood = "wishart", start = "simple", ...)
		 
## list of all 9 models
m &lt;- vector("list", length = 9)
names(m) &lt;- c("m2", "m2a", "m3", "m3a", "m4", "m5", "m5a", "m5b", "m6")

## Step 2: Fix loadings across groups
f &lt;- 'ability =~ abstract + verbal + numerical'
m$m2 &lt;- mgcfa(f, group.equal = "loadings")

## Step 2a: Free numerical loading in group 4 (minority.threat)
f &lt;- 'ability =~ abstract + verbal + c(l1, l1, l1, l4) * numerical'
m$m2a &lt;- mgcfa(f, group.equal = "loadings")

## Step 3: Fix variances across groups
m$m3 &lt;- mgcfa(f, group.equal = c("loadings", "residuals"))

## Step 3a: Free numerical variance in group 4
f &lt;- c(f, 'numerical ~~ c(e1, e1, e1, e4) * numerical')
m$m3a &lt;- mgcfa(f, group.equal = c("loadings", "residuals"))

## Step 4: Fix latent variances within conditions
f &lt;- c(f, 'ability ~~ c(vmaj, vmin, vmaj, vmin) * ability')
m$m4 &lt;- mgcfa(f, group.equal = c("loadings", "residuals"))

## Step 5: Fix certain means, free others
f &lt;- c(f, 'numerical ~ c(na1, na1, na1, na4) * 1')
m$m5 &lt;- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))

## Step 5a: Free ability mean in group majority.control
f &lt;- c(f, 'abstract ~ c(ar1, ar2, ar2, ar2) * 1')
m$m5a &lt;- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))

## Step 5b: Free also ability mean in group minority.control
f &lt;- c(f[1:4], 'abstract ~ c(ar1, ar2, ar3, ar3) * 1')
m$m5b &lt;- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))

## Step 6: Different latent mean structure
f &lt;- c(f, 'ability ~  c(maj, min, maj, min) * 1 + c(0, NA, 0, NA) * 1')
m$m6 &lt;- mgcfa(f, group.equal = c("loadings", "residuals", "intercepts"))

## Extract measures of fit
tab &lt;- t(sapply(m, fitMeasures, c("chisq", "df", "pvalue", "rmsea", "cfi")))
tab &lt;- rbind("1" = c(0, 0, 1, 0, 1), tab)
tab &lt;- cbind(tab,
  delta_chisq = c(NA, abs(diff(tab[, "chisq"]))),
  delta_df = c(NA, diff(tab[, "df"])))
tab &lt;- cbind(tab, "pvalue2" = pchisq(tab[, "delta_chisq"],
  abs(tab[, "delta_df"]), lower.tail = FALSE))
tab &lt;- tab[, c(2, 1, 3, 7, 6, 8, 4, 5)]
round(tab, digits = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='subset.itemresp'>Subsetting Item Response Data</h2><span id='topic+subset.itemresp'></span><span id='topic+merge.itemresp'></span><span id='topic+c.itemresp'></span><span id='topic++5B.itemresp'></span>

<h3>Description</h3>

<p>Subsetting and combining <code>"itemresp"</code> data objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'itemresp'
subset(x, items = NULL, subjects = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset.itemresp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"itemresp"</code>.</p>
</td></tr>
<tr><td><code id="subset.itemresp_+3A_items">items</code></td>
<td>
<p>character, integer, or logical for subsetting the items.</p>
</td></tr>
<tr><td><code id="subset.itemresp_+3A_subjects">subjects</code></td>
<td>
<p>character, integer, or logical for subsetting the subjects.</p>
</td></tr>
<tr><td><code id="subset.itemresp_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>subset</code> method selects subsets of items and/or subjects in
item response data. Alternatively, the <code>[</code> method can be used
with the row index corresponding to subjects and the column index
corresponding to items. 
</p>
<p>The <code>c</code> method can be used to combine item response data from
different subjects for the same items
</p>
<p>The <code>merge</code> method can be used to combine item response data
from the same subjects for different items.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemresp">itemresp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## binary responses to three items, coded as matrix
x &lt;- cbind(c(1, 0, 1, 0), c(1, 0, 0, 0), c(0, 1, 1, 1))
xi &lt;- itemresp(x)

## subsetting/indexing
xi[2]
xi[-(3:4)]
xi[c(TRUE, TRUE, FALSE, FALSE)]
subset(xi, items = 1:2) # or xi[, 1:2]
subset(xi, items = -2, subjects = 2:3)

## combine two itemresp vectors for different subjects but the same items
xi12 &lt;- xi[1:2]
xi34 &lt;- xi[3:4]
c(xi12, xi34)

## combine two itemresp vectors for the same subjects but different items
## polytomous responses in a data frame
d &lt;- data.frame(q1 = c(-2, 1, -1, 0), q2 = factor(c(1, 3, 1, 3),
  levels = 1:3, labels = c("disagree", "neutral", "agree")))
di &lt;-itemresp(d)
merge(xi, di)

## if subjects have names/IDs, these are used for merging
names(xi) &lt;- c("John", "Joan", "Jen", "Jim")
names(di) &lt;-         c("Joan", "Jen", "Jim", "Jo")
merge(xi, di)
merge(xi, di, all = TRUE)
</code></pre>

<hr>
<h2 id='subset.paircomp'>Subsetting/Reordering Paired Comparison Data</h2><span id='topic+subset.paircomp'></span><span id='topic+reorder.paircomp'></span>

<h3>Description</h3>

<p>Selection of subsets of objects to be compared and/or reordering of  
objects in <code>"paircomp"</code> data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'paircomp'
reorder(x, labels, ...)
  ## S3 method for class 'paircomp'
subset(x, subset, select, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset.paircomp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"paircomp"</code>.</p>
</td></tr>
<tr><td><code id="subset.paircomp_+3A_labels">labels</code>, <code id="subset.paircomp_+3A_select">select</code></td>
<td>
<p>character or integer. Either a vector of
(at least two) elements of <code>labels(x)</code> or an integer
with their position. Partial string matching is enabled.</p>
</td></tr>
<tr><td><code id="subset.paircomp_+3A_subset">subset</code></td>
<td>
<p>currently not implemented. (Should be a specification
of subsets of subjects.)</p>
</td></tr>
<tr><td><code id="subset.paircomp_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>subset</code> method currently just calls the <code>reorder</code> method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paircomp">paircomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>pc &lt;- paircomp(rbind(
  c(1,  1,  1), # a &gt; b, a &gt; c, b &gt; c
  c(1,  1, -1), # a &gt; b, a &gt; c, b &lt; c
  c(1, -1, -1), # a &gt; b, a &lt; c, b &lt; c
  c(1,  1,  1)))
reorder(pc, c("c", "a"))
</code></pre>

<hr>
<h2 id='summary.itemresp'>Summarizing and Visualizing Item Response Data</h2><span id='topic+summary.itemresp'></span><span id='topic+plot.itemresp'></span>

<h3>Description</h3>

<p>Summarizing and visualizing <code>"itemresp"</code> data objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'itemresp'
summary(object, items = NULL, abbreviate = FALSE,
    mscale = TRUE, simplify = TRUE, sep = " ", ...)
  ## S3 method for class 'itemresp'
plot(x, xlab = "", ylab = "", items = NULL,
    abbreviate = FALSE, mscale = TRUE, sep = "\n", off = 2, axes = TRUE,
    names = TRUE, srt = 45, adj = c(1.1, 1.1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.itemresp_+3A_object">object</code>, <code id="summary.itemresp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"itemresp"</code>.</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_items">items</code></td>
<td>
<p>character or integer for subsetting the items to be
summarized/visualized. By default, all items are used.</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical or integer. Should scale labels be abbreviated?
Alternatively, an integer with the desired abbreviation length. The default
is some heuristic based on the length of the labels.</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_mscale">mscale</code></td>
<td>
<p>logical. Should mscale values be used for printing/plotting?
If <code>FALSE</code>, integers 0, 1, ... are used.</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_simplify">simplify</code></td>
<td>
<p>logical. Should the summary table be collapsed into
a matrix or returned as a list?</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_sep">sep</code></td>
<td>
<p>character. A character for separating item labels from
their corresponding scale labels (if any).</p>
</td></tr>   
<tr><td><code id="summary.itemresp_+3A_xlab">xlab</code>, <code id="summary.itemresp_+3A_ylab">ylab</code>, <code id="summary.itemresp_+3A_off">off</code>, <code id="summary.itemresp_+3A_axes">axes</code>, <code id="summary.itemresp_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="graphics.html#topic+spineplot">spineplot</a></code>.</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_names">names</code></td>
<td>
<p>logical or character. If <code>TRUE</code>, the names of 
the items are displayed on the x-axis. If <code>FALSE</code>, numbers of
items are shown. Alternatively a character vector of the same
length as the number of items can be supplied.</p>
</td></tr>
<tr><td><code id="summary.itemresp_+3A_srt">srt</code>, <code id="summary.itemresp_+3A_adj">adj</code></td>
<td>
<p>numeric. Angle (<code>srt</code>) and adjustment (<code>adj</code>)
in case names (rather than numbers) are used as x-axis labels.
These are passed to <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> method essentially just calls <code>summary</code> (passing on most further
arguments) and then visualizes the result as a <code>spineplot</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemresp">itemresp</a></code>, <code><a href="graphics.html#topic+spineplot">spineplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## summary/visualization for verbal aggression data
data("VerbalAggression", package = "psychotools")
r &lt;- itemresp(VerbalAggression$resp[, 1:6])
mscale(r) &lt;- c("no", "perhaps", "yes")
summary(r)
plot(r)

## modify formatting of mscale
summary(r, abbreviate = 1)
summary(r, mscale = FALSE)

## illustration for varying mscale across items
## merge with additional random binary response
b &lt;- itemresp(rep(c(-1, 1), length.out = length(r)),
  mscale = c(-1, 1), labels = "Dummy")
rb &lt;- merge(r[, 1:2], b)
head(rb, 2)
## summary has NAs for non-existent response categories
summary(rb)
summary(rb, mscale = FALSE)
plot(rb, srt = 25)
plot(rb, mscale = FALSE)
</code></pre>

<hr>
<h2 id='threshpar'>Extract Threshold Parameters of Item Response Models</h2><span id='topic+threshpar'></span><span id='topic+threshpar.raschmodel'></span><span id='topic+threshpar.rsmodel'></span><span id='topic+threshpar.pcmodel'></span><span id='topic+threshpar.nplmodel'></span><span id='topic+threshpar.gpcmodel'></span><span id='topic+coef.threshpar'></span><span id='topic+print.threshpar'></span>

<h3>Description</h3>

<p>A class and generic function for representing and extracting the item
threshold parameters of a given item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  threshpar(object, ...)
  ## S3 method for class 'raschmodel'
threshpar(object, type = c("mode", "median", "mean"),
    ref = NULL, alias = TRUE, relative = FALSE, cumulative = FALSE, vcov = TRUE,
    ...)
  ## S3 method for class 'rsmodel'
threshpar(object, type = c("mode", "median", "mean"),
    ref = NULL, alias = TRUE, relative = FALSE, cumulative = FALSE, vcov = TRUE,
    ...)
  ## S3 method for class 'pcmodel'
threshpar(object, type = c("mode", "median", "mean"),
    ref = NULL, alias = TRUE, relative = FALSE, cumulative = FALSE, vcov = TRUE,
    ...)
  ## S3 method for class 'nplmodel'
threshpar(object, type = c("mode", "median", "mean"),
    ref = NULL, alias = TRUE, relative = FALSE, cumulative = FALSE, vcov = TRUE,
    ...)
  ## S3 method for class 'gpcmodel'
threshpar(object, type = c("mode", "median", "mean"),
    ref = NULL, alias = TRUE, relative = FALSE, cumulative = FALSE, vcov = TRUE,
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="threshpar_+3A_object">object</code></td>
<td>
<p>a fitted model object whose threshold parameters should be
extracted.</p>
</td></tr>
<tr><td><code id="threshpar_+3A_type">type</code></td>
<td>
<p>character of length one which determines the type of
threshold parameters to return (see details below).</p>
</td></tr>
<tr><td><code id="threshpar_+3A_ref">ref</code></td>
<td>
<p>a vector of labels or position indices of (relative) threshold
parameters or a contrast matrix which should be used as restriction/for
normalization. For partial credit models, argument <code>ref</code> can also be a
list of contrasts. If <code>NULL</code> (the default), for all models except
models etimated via MML, the relative threshold parameters are centered
around their item-specific means and the absolute threshold parameters are
centered around their global mean. For models estimated via MML
(<code>nplmodel</code>s and <code>gpcmodel</code>s), the parameters are by default
identified via the distributional parameters of the person parameters (mean
and variance of a normal distribution). Nevertheless, a restriction on the
interval scale can be applied.</p>
</td></tr>
<tr><td><code id="threshpar_+3A_alias">alias</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the aliased parameter
is included in the return vector (and in the variance-covariance matrix if
<code>vcov</code> = TRUE). If <code>FALSE</code>, it is removed. If the restriction
given in <code>ref</code> depends on several parameters, the first parameter of
the restriction specified is (arbitrarily) chosen to be removed if
<code>alias</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="threshpar_+3A_relative">relative</code></td>
<td>
<p>logical. If set to <code>FALSE</code> (default), absolute item
threshold parameters are returned. If set to <code>TRUE</code>, relative item
threshold parameters with the contrast specified in argument <code>ref</code> are
returned.</p>
</td></tr>
<tr><td><code id="threshpar_+3A_cumulative">cumulative</code></td>
<td>
<p>logical. If set to <code>TRUE</code>, cumulative threshold
parameters are returned. These correspond to the cumulative sum over the
absolute or relative item threshold parameters (after the restriction given
in argument <code>ref</code> has been applied).</p>
</td></tr>
<tr><td><code id="threshpar_+3A_vcov">vcov</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the (transformed)
variance-covariance matrix of the (relative) threshold parameters is
attached as attribute <code>vcov</code>. If <code>FALSE</code>, a <code>NA</code>-matrix is
attached.</p>
</td></tr>
<tr><td><code id="threshpar_+3A_...">...</code></td>
<td>
<p>further arguments which are currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>threshpar</code> is both, a class to represent threshold parameters of item
response models as well as a generic function. The generic function can be
used to extract the threshold parameters of a given item response model.
</p>
<p>For objects of class <code>threshpar</code>, methods to standard generic functions
<code>print</code> and <code>coef</code> can be used to print and extract the threshold
parameters.
</p>
<p>Depending on argument <code>type</code>, different item threshold parameters are
returned. For <code>type = "mode"</code>, the returned item threshold parameters
correspond to the location on the theta axis where the probability of category
<code class="reqn">k</code> equals the probability of category <code class="reqn">k-1</code>. For Rasch and partial
credit models, item threshold parameters of this type correspond directly to
the estimated absolute item threshold parameters of these models. For
<code>type = "median"</code>, the returned item threshold parameters correspond to
the location on the theta axis where the probability of choosing category
<code class="reqn">k</code> or higher, i.e., <code class="reqn">P(X_{ij} &gt;= k)</code>, equals 0.5. For <code>type =
  "mean"</code>, the returned absolute item threshold parameters correspond to the
location on the theta axis where the expected category response is in the
middle between two categories, i.e. 0.5, 1.5, .... An illustration of
these threshold parameters can be found on page 104 in Masters &amp; Wright
(1995).
</p>


<h3>Value</h3>

<p>A named list with item threshold parameters of class <code>threshpar</code> and
additional attributes <code>model</code> (the model name), <code>type</code> (the type of
item threshold parameters returned, see details above), <code>ref</code> (the items
or parameters used as restriction/for normalization), <code>relative</code> (whether
relative or absolute item threshold parameters are returned),
<code>cumulative</code> (whether the cumulative item threshold parameters are
returned), <code>alias</code> (either <code>FALSE</code> or a named character vector or
list with the removed aliased parameters), and <code>vcov</code> (the estimated and
adjusted variance-covariance matrix).
</p>


<h3>References</h3>

<p>Masters GN, Wright BD (1997).
The Partial Credit Model.
In Van der Linden WJ, Hambleton RK (eds.).
<em>Handbook of Modern Item Response Theory</em>.
Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+personpar">personpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>, <code><a href="#topic+discrpar">discrpar</a></code>,
<code><a href="#topic+guesspar">guesspar</a></code>, <code><a href="#topic+upperpar">upperpar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## load verbal aggression data
data("VerbalAggression", package = "psychotools")

## fit a rasch model to dichotomized verbal aggression data
raschmod &lt;- raschmodel(VerbalAggression$resp2)

## extract threshold parameters with sum zero restriction
tr &lt;- threshpar(raschmod)
tr

## compare to item parameters (again with sum zero restriction)
ip &lt;- itempar(raschmod)
ip

all.equal(coef(tr), coef(ip))

## rating scale model example
rsmod &lt;- rsmodel(VerbalAggression$resp)
trmod &lt;- threshpar(rsmod, type = "mode")
trmed &lt;- threshpar(rsmod, type = "median")
trmn &lt;- threshpar(rsmod, type = "mean")

## compare different types of threshold parameters
cbind("Mode" = coef(trmod, type = "vector"),
 "Median" = coef(trmod, type = "vector"),
 "Mean" = coef(trmn, type = "vector"))

if(requireNamespace("mirt")) {
## fit a partial credit model and a generalized partial credit model
pcmod &lt;- pcmodel(VerbalAggression$resp)
gpcmod &lt;- gpcmodel(VerbalAggression$resp)

## extract the threshold parameters with different default restrictions and
## therefore incompareable scales
tp &lt;- threshpar(pcmod)
tg &lt;- threshpar(gpcmod)
plot(unlist(tp), unlist(tg), xlab = "PCM", ylab = "GPCM")
abline(a = 0, b = 1)

## extract the threshold parameters with the first as the reference leading
## to a compareable scale visualizing the differences due to different
## discrimination parameters
tp &lt;- threshpar(pcmod, ref = 1)
tg &lt;- threshpar(gpcmod, ref = 1)
plot(unlist(tp), unlist(tg), xlab = "PCM", ylab = "GPCM")
abline(a = 0, b = 1)

options(digits = o$digits)
}
</code></pre>

<hr>
<h2 id='upperpar'>Extract Upper Asymptote Parameters of Item Response Models</h2><span id='topic+upperpar'></span><span id='topic+upperpar.raschmodel'></span><span id='topic+upperpar.rsmodel'></span><span id='topic+upperpar.pcmodel'></span><span id='topic+upperpar.nplmodel'></span><span id='topic+upperpar.gpcmodel'></span><span id='topic+coef.upperpar'></span><span id='topic+print.upperpar'></span><span id='topic+vcov.upperpar'></span>

<h3>Description</h3>

<p>A class and generic function for representing and extracting the
upper asymptote parameters of a given item response model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  upperpar(object, ...)
  ## S3 method for class 'raschmodel'
upperpar(object, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'rsmodel'
upperpar(object, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'pcmodel'
upperpar(object, alias = TRUE, vcov = TRUE, ...)
  ## S3 method for class 'nplmodel'
upperpar(object, alias = TRUE, logit = FALSE, vcov = TRUE, ...)
  ## S3 method for class 'gpcmodel'
upperpar(object, alias = TRUE, vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="upperpar_+3A_object">object</code></td>
<td>
<p>a fitted model object whose upper asymptote parameters should be
extracted.</p>
</td></tr>
<tr><td><code id="upperpar_+3A_alias">alias</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the aliased parameters
are included in the return vector (and in the variance-covariance matrix
if <code>vcov</code> = TRUE). If <code>FALSE</code>, these parameters are removed. For
<code>raschmodel</code>s, <code>rsmodel</code>s, <code>pcmodel</code>s and <code>gpcmodel</code>s,
where all upper asymptote parameters are fixed to 1, this means
that an empty numeric vector and an empty variance-covariace matrix is
returned if <code>alias</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="upperpar_+3A_logit">logit</code></td>
<td>
<p>logical. If a <code>nplmodel</code> of <code>type</code> <code>"3PLu"</code> or
<code>"4PL"</code> model has been fit, the upper asymptote parameters were estimated
on the logit scale. If <code>logit = FALSE</code>, these estimates and the
variance-covariance (if requested) are retransformed using the logistic
function and the delta method.</p>
</td></tr>
<tr><td><code id="upperpar_+3A_vcov">vcov</code></td>
<td>
<p>logical. If <code>TRUE</code> (the default), the variance-covariance
matrix of the upper asymptote parameters is attached as attribute
<code>vcov</code>.</p>
</td></tr>
<tr><td><code id="upperpar_+3A_...">...</code></td>
<td>
<p>further arguments which are currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>upperpar</code> is both, a class to represent upper asymptote parameters of
item response models as well as a generic function. The generic function can
be used to extract the upper asymptote parameters of a given item response
model.
</p>
<p>For objects of class <code>upperpar</code>, several methods to standard generic
functions exist: <code>print</code>, <code>coef</code>, <code>vcov</code>. <code>coef</code> and
<code>vcov</code> can be used to extract the upper asymptote parameters and their
variance-covariance matrix without additional attributes.
</p>


<h3>Value</h3>

<p>A named vector with upper asymptote parameters of class <code>upperpar</code> and
additional attributes <code>model</code> (the model name), <code>alias</code> (either
<code>TRUE</code> or a named numeric vector with the aliased parameters not included
in the return value), <code>logit</code> (indicating whether the estimates are on the
logit scale or not), and <code>vcov</code> (the estimated and adjusted
variance-covariance matrix).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+personpar">personpar</a></code>, <code><a href="#topic+itempar">itempar</a></code>,
<code><a href="#topic+threshpar">threshpar</a></code>, <code><a href="#topic+discrpar">discrpar</a></code>, <code><a href="#topic+guesspar">guesspar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("mirt")) {

o &lt;- options(digits = 3)

## load simulated data
data("Sim3PL", package = "psychotools")

## fit 2PL to data simulated under the 3PLu
twoplmod &lt;- nplmodel(Sim3PL$resp2)

## extract the upper asymptote parameters (all fixed at 1)
up1 &lt;- upperpar(twoplmod)

## fit 3PLu to data simulated under the 3PLu
threeplmodu &lt;- nplmodel(Sim3PL$resp2, type = "3PLu")

## extract the upper asymptote parameters
up2 &lt;- upperpar(threeplmodu)

## extract the standard errors
sqrt(diag(vcov(up2)))

## extract the upper asymptote parameters on the logit scale
up2_logit &lt;- upperpar(threeplmodu, logit = TRUE)

## along with the delta transformed standard errors
sqrt(diag(vcov(up2_logit)))

options(digits = o$digits)
}
</code></pre>

<hr>
<h2 id='VerbalAggression'>Situation-Response Questionnaire on Verbal Aggression</h2><span id='topic+VerbalAggression'></span>

<h3>Description</h3>

<p>Responses of 316 subjects to 24 items describing possible
reactions to 4 different frustrating situations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("VerbalAggression")</code></pre>


<h3>Format</h3>

<p>A data frame containing 316 observations on 4 variables.
</p>

<dl>
<dt>resp</dt><dd><p>Item response matrix with values 0/1/2 coding no/perhaps/yes, respectively.</p>
</dd>
<dt>resp2</dt><dd><p>Dichotomized item response matrix with perhaps/yes merged to 1.</p>
</dd>
<dt>gender</dt><dd><p>Factor coding gender.</p>
</dd>
<dt>anger</dt><dd><p>Trait anger, assessed by the Dutch adaptation
of the state-trait anger scale (STAS).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The 24 items are constructed by factorial combination of four different
frustrating situations (see below), three possible verbally aggressive responses
(curse, scold, shout), and two behavioural models (want, do). The four situations are
</p>

<table>
<tr>
 <td style="text-align: right;">
  S1:</td><td style="text-align: left;"> A bus fails to stop for me.</td>
</tr>
<tr>
 <td style="text-align: right;">
  S2:</td><td style="text-align: left;"> I miss a train because a clerk gave me faulty information.</td>
</tr>
<tr>
 <td style="text-align: right;">
  S3:</td><td style="text-align: left;"> The grocery store closes just as I am about to enter.</td>
</tr>
<tr>
 <td style="text-align: right;">
  S4:</td><td style="text-align: left;"> The operator disconnects me when I used up my last 10 cents for a call.
</td>
</tr>

</table>

<p>Note that the first two situations are other-to-blame situations, and the latter two are self-to-blame
situations.
</p>
<p>The subjects were 316 first-year psychology students from a university in the Dutch
speaking part of Belgium. Participation was a partial fulfillment of the requirement
to participate in research. The sample consists of 73 males and 243 females,
reflecting the gender proportion among psychology students. The average
age was 18.4.
</p>


<h3>Source</h3>

<p>Online materials accompanying De Boeck and Wilson (2004).
</p>


<h3>References</h3>

<p>De Boeck, P., Wilson, M. (eds) (2004).
Explanatory Item Response Models: A Generalized Linear and Nonlinear Approach.
New York: Springer-Verlag.
</p>
<p>Smits, D.J.M., De Boeck, P., Vansteelandt, K. (2004).
The Inhibition of Verbally Aggressive Behaviour
<em>European Journal of Personality</em>, <b>18</b>, 537-555.
<a href="https://doi.org/10.1002/per.529">doi:10.1002/per.529</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+raschmodel">raschmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("VerbalAggression", package = "psychotools")

## Rasch model for the self-to-blame situations
m &lt;- raschmodel(VerbalAggression$resp2[, 1:12])
plot(m)

## IGNORE_RDIFF_BEGIN
summary(m)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='worth'>Extract Worth Parameters</h2><span id='topic+worth'></span>

<h3>Description</h3>

<p>Generic functions for extracting worth parameters from paired comparison models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  worth(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="worth_+3A_object">object</code></td>
<td>
<p>an object.</p>
</td></tr>
<tr><td><code id="worth_+3A_...">...</code></td>
<td>
<p>arguments passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since version 0.3-0, calls to <code>worth</code> are
internally passed over to <code>itempar</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+btmodel">btmodel</a></code>, <code><a href="#topic+raschmodel">raschmodel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>o &lt;- options(digits = 4)

## data
data("GermanParties2009", package = "psychotools")

## Bradley-Terry model
bt &lt;- btmodel(GermanParties2009$preference)

## worth parameters
worth(bt)

## or
itempar(bt)

options(digits = o$digits)
</code></pre>

<hr>
<h2 id='YouthGratitude'>Measuring Gratitude in Youth</h2><span id='topic+YouthGratitude'></span>

<h3>Description</h3>

<p>Cross-section data on several gratitude scales for children and adolescents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("YouthGratitude")</code></pre>


<h3>Format</h3>

<p>A data frame containing 1405 observations on 28 variables.
</p>

<dl>
<dt>id</dt><dd><p>Integer person ID.</p>
</dd>
<dt>age</dt><dd><p>Age in years (10&ndash;19 years).</p>
</dd>
<dt>agegroup</dt><dd><p>Factor coding of age with levels <code>"10-11"</code>, <code>"12-13"</code>,
<code>"14"</code>, <code>"15"</code>, <code>"16"</code>, <code>"17-19"</code>.</p>
</dd>
<dt>losd_1</dt><dd><p>Life has been good to me.</p>
</dd>
<dt>losd_2</dt><dd><p>There never seems to be enough to go around, and I never seem to get my share. (Reverse scored.)</p>
</dd>
<dt>losd_3</dt><dd><p>I really don't think that I've gotten all the good things that I deserve in life. (Reverse scored.)</p>
</dd>
<dt>losd_4</dt><dd><p>More bad things have happened to me in my life than I deserve. (Reverse scored.)</p>
</dd>
<dt>losd_5</dt><dd><p>Because of what I've gone through in my life, I really feel like the world owes me something. (Reverse scored.)</p>
</dd>
<dt>losd_6</dt><dd><p>For some reason I never seem to get the advantages that others get. (Reverse scored.)</p>
</dd>
<dt>sa_1</dt><dd><p>Oftentimes I have been overwhelmed at the beauty of nature.</p>
</dd>
<dt>sa_2</dt><dd><p>Every Fall I really enjoy watching the leaves change colors.</p>
</dd>
<dt>sa_3</dt><dd><p>I think that it's important to 'Stop and smell the roses.'</p>
</dd>
<dt>sa_4</dt><dd><p>I think that it's important to pause often to 'count my blessings.'</p>
</dd>
<dt>sa_5</dt><dd><p>I think it's important to enjoy the simple things in life.</p>
</dd>
<dt>sa_6</dt><dd><p>I think it's important to appreciate each day that you are alive.</p>
</dd>
<dt>ao_1</dt><dd><p>I couldn't have gotten where I am today without the help of many people.</p>
</dd>
<dt>ao_2</dt><dd><p>Although I think it's important to feel good about your accomplishments, I think that it's also important to remember how others have contributed to my accomplishments.</p>
</dd>
<dt>ao_3</dt><dd><p>Although I'm basically in control of my life, I can't help but think about all those who have supported me and helped me along the way.</p>
</dd>
<dt>ao_4</dt><dd><p>I feel deeply appreciative for the things others have done for me in my life.</p>
</dd>
<dt>gq6_1</dt><dd><p>I have so much in life to be thankful for.</p>
</dd>
<dt>gq6_2</dt><dd><p>If I had to list everything that I felt thankful for,
it would be a very long list.</p>
</dd>
<dt>gq6_3</dt><dd><p>When I look at the world, I don't see much to be thankful for.</p>
</dd>
<dt>gq6_4</dt><dd><p>I am thankful to a wide variety of people. (Reverse scored.)</p>
</dd>
<dt>gq6_5</dt><dd><p>As I get older I find myself more able to appreciate the people,
events, and situations that have been part of my life history.</p>
</dd>
<dt>gq6_6</dt><dd><p>Long amounts of time can go by before I feel gratitude to something or someone. (Reverse scored.)</p>
</dd>
<dt>gac_1</dt><dd><p>Grateful.</p>
</dd>
<dt>gac_2</dt><dd><p>Thankful.</p>
</dd>
<dt>gac_3</dt><dd><p>Appreciative.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The gratitude scales employed are:<br />
GRAT: Gratitude, Resentment, Appreciation Test (1&ndash;9).<br />
Short form with subscales LOSD (lack of a sense of deprivation),
SA (simple appreciation), and AO (appreciation for others).<br />
GQ-6: Gratitude Questionnaire-6 (1&ndash;7).<br />
GAC: Gratitude Adjective Checklist (1&ndash;5).
</p>
<p>The item <code>losd_1</code> has been omitted from all analyses in Froh et al. (2011)
because it loaded lowly on all factors. Hence <code>losd_1</code> is not listed in
Table B1 of Froh et al. (2011). Instead, the remaining items are labeled
<code>losd_1</code> to <code>losd_5</code>.
</p>


<h3>Source</h3>

<p>Provided by Jeff Froh and Jinyan Fan.
</p>


<h3>References</h3>

<p>Froh JJ, Fan J, Emmons RA, Bono G, Huebner ES, Watkins P (2011).
Measuring Gratitude in Youth: Assessing the Psychometric Properties of Adult Gratitude Scales in Children and Adolescents.
<em>Psychological Assessment</em>, <b>23</b>(2), 311&ndash;324.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("YouthGratitude", package = "psychotools")
summary(YouthGratitude)

## modeling can be carried out using package lavaan
## Not run: 
## remove cases with 'imputed' values (not in 1, ..., 9)
yg &lt;- YouthGratitude[apply(YouthGratitude[, 4:28], 1, function(x) all(x 

## GQ-6
gq6_congeneric &lt;- cfa(
  'f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
  data = yg, group = "agegroup", meanstructure = TRUE)
gq6_tauequivalent &lt;- cfa(
  'f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = "loadings")
gq6_parallel &lt;- cfa(
  'f1 =~ gq6_1 + gq6_2 + gq6_3 + gq6_4 + gq6_5',
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = c("loadings", "residuals", "lv.variances"))
anova(gq6_congeneric, gq6_tauequivalent, gq6_parallel)
t(sapply(
  list(gq6_congeneric, gq6_tauequivalent, gq6_parallel),
  function(m) fitMeasures(m)[c("chisq", "df", "cfi", "srmr")]
))

## GAC
gac_congeneric &lt;- cfa(
  'f1 =~ gac_1 + gac_2 + gac_3',
  data = yg, group = "agegroup", meanstructure = TRUE)
gac_tauequivalent &lt;- cfa(
  'f1 =~ gac_1 + gac_2 + gac_3',
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = "loadings")
gac_parallel &lt;- cfa(
  'f1 =~ gac_1 + gac_2 + gac_3',
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = c("loadings", "residuals", "lv.variances"))
anova(gac_congeneric, gac_tauequivalent, gac_parallel)
t(sapply(
  list(gac_congeneric, gac_tauequivalent, gac_parallel),
  function(m) fitMeasures(m)[c("chisq", "df", "cfi", "srmr")]
))

## GRAT
grat_congeneric &lt;- cfa(
  'f1 =~ losd_2 + losd_3 + losd_4 + losd_5 + losd_6
   f2 =~ sa_1 + sa_2 + sa_3 + sa_4 + sa_5 + sa_6
   f3 =~ ao_1 + ao_2 + ao_3 + ao_4',
  data = yg, group = "agegroup", meanstructure = TRUE)
grat_tauequivalent &lt;- cfa(
  'f1 =~ losd_2 + losd_3 + losd_4 + losd_5 + losd_6
   f2 =~ sa_1 + sa_2 + sa_3 + sa_4 + sa_5 + sa_6
   f3 =~ ao_1 + ao_2 + ao_3 + ao_4',
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = "loadings")
grat_parallel &lt;- cfa(
  'f1 =~ losd_2 + losd_3 + losd_4 + losd_5 + losd_6
   f2 =~ sa_1 + sa_2 + sa_3 + sa_4 + sa_5 + sa_6
   f3 =~ ao_1 + ao_2 + ao_3 + ao_4',
  data = yg, group = "agegroup", meanstructure = TRUE,
  group.equal = c("loadings", "residuals", "lv.variances"))
anova(grat_congeneric, grat_tauequivalent, grat_parallel)
t(sapply(
  list(grat_congeneric, grat_tauequivalent, grat_parallel),
  function(m) fitMeasures(m)[c("chisq", "df", "cfi", "srmr")]
))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
