<!DOCTYPE html><html lang="en"><head><title>Help for package RNAmf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RNAmf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ALC_RNAmf'><p>find the next point by ALC criterion</p></a></li>
<li><a href='#ALD_RNAmf'><p>find the next point by ALD criterion</p></a></li>
<li><a href='#ALM_RNAmf'><p>find the next point by ALM criterion</p></a></li>
<li><a href='#ALMC_RNAmf'><p>find the next point by ALMC criterion</p></a></li>
<li><a href='#NestedX'><p>Constructing the nested design sets for RNA model.</p></a></li>
<li><a href='#predict.RNAmf'><p>prediction of the RNAmf emulator with 2 or 3 fidelity levels.</p></a></li>
<li><a href='#RNAmf_three_level'><p>Fitting the model with three fidelity levels</p></a></li>
<li><a href='#RNAmf_two_level'><p>Fitting the Recursive non-additive model with two fidelity levels.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Recursive Non-Additive Emulator for Multi-Fidelity Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Junoh Heo &lt;heojunoh@msu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs RNA emulation and active learning proposed by Heo and Sung (2024) &lt;<a href="https://doi.org/10.1080%2F00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt; for multi-fidelity computer experiments. The RNA emulator is particularly useful when the simulations with different fidelity level are nonlinearly correlated. The hyperparameters in the model are estimated by maximum likelihood estimation. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>plgp, stats, lhs, doParallel, foreach</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-09 18:19:46 UTC; junoh</td>
</tr>
<tr>
<td>Author:</td>
<td>Junoh Heo [aut, cre],
  Chih-Li Sung [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-09 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ALC_RNAmf'>find the next point by ALC criterion</h2><span id='topic+ALC_RNAmf'></span>

<h3>Description</h3>

<p>The function acquires the new point by the Active learning Cohn (ALC) criterion.
It calculates the ALC criterion
<code class="reqn">\frac{\Delta \sigma_L^{2}(l,\bm{x})}{\sum^l_{j=1}C_j} =
\frac{\int_{\Omega} \sigma_L^{*2}(\bm{\xi})-\tilde{\sigma}_L^{*2}(\bm{\xi};l,\bm{x}){\rm{d}}\bm{\xi}}{\sum^l_{j=1}C_j}</code>,
where <code class="reqn">f_L</code> is the highest-fidelity simulation code,
<code class="reqn">\sigma_L^{*2}(\bm{\xi})</code> is the posterior variance of <code class="reqn">f_L(\bm{\xi})</code>,
<code class="reqn">C_j</code> is the simulation cost at fidelity level <code class="reqn">j</code>,
and <code class="reqn">\tilde{\sigma}_L^{*2}(\bm{\xi};l,\bm{x})</code> is the posterior variance
based on the augmented design combining the current design and a new input location <code class="reqn">\bm{x}</code>
at each fidelity level lower than or equal to <code class="reqn">l</code>.
The integration is approximated by MC integration using uniform reference samples.
</p>
<p>A new point is acquired on <code>Xcand</code>. If <code>Xcand=NULL</code> and <code>Xref=NULL</code>, a new point is acquired on unit hypercube <code class="reqn">[0,1]^d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ALC_RNAmf(Xref = NULL, Xcand = NULL, fit, mc.sample = 100,
cost = NULL, optim = TRUE, parallel = FALSE, ncore = 1, trace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ALC_RNAmf_+3A_xref">Xref</code></td>
<td>
<p>vector or matrix of reference location to approximate the integral of ALC. If <code>Xref=NULL</code>, <code class="reqn">100 \times d</code> points from 0 to 1 are generated by Latin hypercube design. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_xcand">Xcand</code></td>
<td>
<p>vector or matrix of candidate set which could be added into the current design only when <code>optim=FALSE</code>. <code>Xcand</code> is the set of the points where ALC criterion is evaluated. If <code>Xcand=NULL</code>, <code>Xref</code> is used. Default is <code>NULL</code>. See details.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_fit">fit</code></td>
<td>
<p>object of class <code>RNAmf</code>.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_mc.sample">mc.sample</code></td>
<td>
<p>a number of mc samples generated for the imputation through MC approximation. Default is <code>100</code>.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_cost">cost</code></td>
<td>
<p>vector of the costs for each level of fidelity. If <code>cost=NULL</code>, total costs at all levels would be 1. <code>cost</code> is encouraged to have a ascending order of positive value. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_optim">optim</code></td>
<td>
<p>logical indicating whether to optimize AL criterion by <code>optim</code>'s gradient-based <code>L-BFGS-B</code> method. If <code>optim=TRUE</code>, <code class="reqn">5 \times d</code> starting points are generated by Latin hypercube design for optimization. If <code>optim=FALSE</code>, AL criterion is optimized on the <code>Xcand</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_parallel">parallel</code></td>
<td>
<p>logical indicating whether to compute the AL criterion in parallel or not. If <code>parallel=TRUE</code>, parallel computation is utilized. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_ncore">ncore</code></td>
<td>
<p>a number of core for parallel. It is only used if <code>parallel=TRUE</code>. Default is 1.</p>
</td></tr>
<tr><td><code id="ALC_RNAmf_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether to print the computational time for each step. If <code>trace=TRUE</code>, the computation time for each step is printed. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Xref</code> plays a role of <code class="reqn">\bm{\xi}</code> to approximate the integration.
To impute the posterior variance based on the augmented design <code class="reqn">\tilde{\sigma}_L^{*2}(\bm{\xi};l,\bm{x})</code>,
MC approximation is used.
Due to the nested assumption, imputing <code class="reqn">y^{[s]}_{n_s+1}</code> for each <code class="reqn">1\leq s\leq l</code> by drawing samples
from the posterior distribution of <code class="reqn">f_s(\bm{x}^{[s]}_{n_s+1})</code>
based on the current design allows to compute <code class="reqn">\tilde{\sigma}_L^{*2}(\bm{\xi};l,\bm{x})</code>.
Inverse of covariance matrix is computed by the Sherman-Morrison formula.
For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>
<p>To search for the next acquisition <code class="reqn">\bm{x^*}</code> by maximizing AL criterion,
the gradient-based optimization can be used by <code>optim=TRUE</code>.
Firstly, <code class="reqn">\tilde{\sigma}_L^{*2}(\bm{\xi};l,\bm{x})</code> is computed on the
<code class="reqn">5 \times d</code> number of points.
After that, the point minimizing <code class="reqn">\tilde{\sigma}_L^{*2}(\bm{\xi};l,\bm{x})</code>
serves as a starting point of optimization by <code>L-BFGS-B</code> method.
Otherwise, when <code>optim=FALSE</code>, AL criterion is optimized only on <code>Xcand</code>.
</p>
<p>The point is selected by maximizing the ALC criterion:
<code class="reqn">\text{argmax}_{l\in\{1,\ldots,L\}; \bm{x} \in \Omega}
\frac{\Delta \sigma_L^{2}(l,\bm{x})}{\sum^l_{j=1}C_j}</code>.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>ALC</code>: list of ALC criterion integrated on <code>Xref</code> when each data point on <code>Xcand</code> is added at each level <code class="reqn">l</code> if <code>optim=FALSE</code>. If <code>optim=TRUE</code>, <code>ALC</code> returns <code>NULL</code>.
</p>
</li>
<li> <p><code>cost</code>: a copy of <code>cost</code>.
</p>
</li>
<li> <p><code>Xcand</code>: a copy of <code>Xcand</code>.
</p>
</li>
<li> <p><code>chosen</code>: list of chosen level and point.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lhs)
library(doParallel)
library(foreach)

### simulation costs ###
cost &lt;- c(1, 3)

### 1-d Perdikaris function in Perdikaris, et al. (2017) ###
# low-fidelity function
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

# high-fidelity function
f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### n=100 uniform test data ###
x &lt;- seq(0, 1, length.out = 100)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")

### predict ###
predy &lt;- predict(fit.RNAmf, x)$mu
predsig2 &lt;- predict(fit.RNAmf, x)$sig2

### active learning with optim=TRUE ###
alc.RNAmf.optim &lt;- ALC_RNAmf(
  Xref = x, Xcand = x, fit.RNAmf, cost = cost,
  optim = TRUE, parallel = TRUE, ncore = 2
)
print(alc.RNAmf.optim$time) # computation time of optim=TRUE

### active learning with optim=FALSE ###
alc.RNAmf &lt;- ALC_RNAmf(
  Xref = x, Xcand = x, fit.RNAmf, cost = cost,
  optim = FALSE, parallel = TRUE, ncore = 2
)
print(alc.RNAmf$time) # computation time of optim=FALSE

### visualize ALC ###
oldpar &lt;- par(mfrow = c(1, 2))
plot(x, alc.RNAmf$ALC$ALC1,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALC criterion augmented at the low-fidelity level",
  ylim = c(min(c(alc.RNAmf$ALC$ALC1, alc.RNAmf$ALC$ALC2)),
           max(c(alc.RNAmf$ALC$ALC1, alc.RNAmf$ALC$ALC2)))
)
plot(x, alc.RNAmf$ALC$ALC2,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALC criterion augmented at the high-fidelity level",
  ylim = c(min(c(alc.RNAmf$ALC$ALC1, alc.RNAmf$ALC$ALC2)),
           max(c(alc.RNAmf$ALC$ALC1, alc.RNAmf$ALC$ALC2)))
)
points(alc.RNAmf$chosen$Xnext,
  alc.RNAmf$ALC$ALC2[which(x == drop(alc.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
par(oldpar)

</code></pre>

<hr>
<h2 id='ALD_RNAmf'>find the next point by ALD criterion</h2><span id='topic+ALD_RNAmf'></span>

<h3>Description</h3>

<p>The function acquires the new point by the Active learning Decomposition (ALD) criterion.
It calculates the ALD criterion <code class="reqn">\frac{V_l(\bm{x})}{\sum^l_{j=1}C_j}</code>,
where <code class="reqn">V_l(\bm{x})</code> is the contribution of GP emulator
at each fidelity level <code class="reqn">l</code> and <code class="reqn">C_j</code> is the simulation cost at level <code class="reqn">j</code>.
For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>
<p>A new point is acquired on <code>Xcand</code>. If <code>Xcand=NULL</code>, a new point is acquired on unit hypercube <code class="reqn">[0,1]^d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ALD_RNAmf(Xcand = NULL, fit, mc.sample = 1000, cost = NULL,
optim = TRUE, parallel = FALSE, ncore = 1, trace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ALD_RNAmf_+3A_xcand">Xcand</code></td>
<td>
<p>vector or matrix of candidate set which could be added into the current design only used when <code>optim=FALSE</code>. <code>Xcand</code> is the set of the points where ALD criterion is evaluated. If <code>Xcand=NULL</code>, <code class="reqn">100 \times d</code> number of points from 0 to 1 are generated by Latin hypercube design. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_fit">fit</code></td>
<td>
<p>object of class <code>RNAmf</code>.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_mc.sample">mc.sample</code></td>
<td>
<p>a number of mc samples generated for the MC approximation. Default is <code>1000</code>.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_cost">cost</code></td>
<td>
<p>vector of the costs for each level of fidelity. If <code>cost=NULL</code>, total costs at all levels would be 1. <code>cost</code> is encouraged to have a ascending order of positive value. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_optim">optim</code></td>
<td>
<p>logical indicating whether to optimize AL criterion by <code>optim</code>'s gradient-based <code>L-BFGS-B</code> method. If <code>optim=TRUE</code>, <code class="reqn">5 \times d</code> starting points are generated by Latin hypercube design for optimization. If <code>optim=FALSE</code>, AL criterion is optimized on the <code>Xcand</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_parallel">parallel</code></td>
<td>
<p>logical indicating whether to compute the AL criterion in parallel or not. If <code>parallel=TRUE</code>, parallel computation is utilized. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_ncore">ncore</code></td>
<td>
<p>a number of core for parallel. It is only used if <code>parallel=TRUE</code>. Default is 1.</p>
</td></tr>
<tr><td><code id="ALD_RNAmf_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether to print the computational time for each step. If <code>trace=TRUE</code>, the computation time for each step is printed. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>ALD</code>: list of ALD criterion computed at each point of <code>Xcand</code> at each level if <code>optim=FALSE</code>. If <code>optim=TRUE</code>, <code>ALD</code> returns <code>NULL</code>.
</p>
</li>
<li> <p><code>cost</code>: a copy of <code>cost</code>.
</p>
</li>
<li> <p><code>Xcand</code>: a copy of <code>Xcand</code>.
</p>
</li>
<li> <p><code>chosen</code>: list of chosen level and point.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lhs)
library(doParallel)
library(foreach)

### simulation costs ###
cost &lt;- c(1, 3)

### 1-d Perdikaris function in Perdikaris, et al. (2017) ###
# low-fidelity function
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

# high-fidelity function
f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### n=100 uniform test data ###
x &lt;- seq(0, 1, length.out = 100)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")

### predict ###
predy &lt;- predict(fit.RNAmf, x)$mu
predsig2 &lt;- predict(fit.RNAmf, x)$sig2

### active learning with optim=TRUE ###
ald.RNAmf.optim &lt;- ALD_RNAmf(
  Xcand = x, fit.RNAmf, cost = cost,
  optim = TRUE, parallel = TRUE, ncore = 2
)
print(ald.RNAmf.optim$time) # computation time of optim=TRUE

### active learning with optim=FALSE ###
ald.RNAmf &lt;- ALD_RNAmf(
  Xcand = x, fit.RNAmf, cost = cost,
  optim = FALSE, parallel = TRUE, ncore = 2
)
print(ald.RNAmf$time) # computation time of optim=FALSE

### visualize ALD ###
oldpar &lt;- par(mfrow = c(1, 2))
plot(x, ald.RNAmf$ALD$ALD1,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALD criterion at the low-fidelity level",
  ylim = c(min(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)),
           max(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)))
)
points(ald.RNAmf$chosen$Xnext,
  ald.RNAmf$ALD$ALD1[which(x == drop(ald.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
plot(x, ald.RNAmf$ALD$ALD2,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALD criterion at the high-fidelity level",
  ylim = c(min(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)),
           max(c(ald.RNAmf$ALD$ALD1, ald.RNAmf$ALD$ALD2)))
)
par(oldpar)

</code></pre>

<hr>
<h2 id='ALM_RNAmf'>find the next point by ALM criterion</h2><span id='topic+ALM_RNAmf'></span>

<h3>Description</h3>

<p>The function acquires the new point by the Active learning MacKay (ALM) criterion.
It calculates the ALM criterion <code class="reqn">\frac{\sigma^{*2}_l(\bm{x})}{\sum^l_{j=1}C_j}</code>,
where <code class="reqn">\sigma^{*2}_l(\bm{x})</code> is the posterior predictive variance
at each fidelity level <code class="reqn">l</code> and <code class="reqn">C_j</code> is the simulation cost at level <code class="reqn">j</code>.
For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>
<p>A new point is acquired on <code>Xcand</code>. If <code>Xcand=NULL</code>, a new point is acquired on unit hypercube <code class="reqn">[0,1]^d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ALM_RNAmf(Xcand = NULL, fit, cost = NULL, optim = TRUE,
parallel = FALSE, ncore = 1, trace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ALM_RNAmf_+3A_xcand">Xcand</code></td>
<td>
<p>vector or matrix of candidate set which could be added into the current design only used when <code>optim=FALSE</code>. <code>Xcand</code> is the set of the points where ALM criterion is evaluated. If <code>Xcand=NULL</code>, <code class="reqn">100 \times d</code> number of points from 0 to 1 are generated by Latin hypercube design. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALM_RNAmf_+3A_fit">fit</code></td>
<td>
<p>object of class <code>RNAmf</code>.</p>
</td></tr>
<tr><td><code id="ALM_RNAmf_+3A_cost">cost</code></td>
<td>
<p>vector of the costs for each level of fidelity. If <code>cost=NULL</code>, total costs at all levels would be 1. <code>cost</code> is encouraged to have a ascending order of positive value. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALM_RNAmf_+3A_optim">optim</code></td>
<td>
<p>logical indicating whether to optimize AL criterion by <code>optim</code>'s gradient-based <code>L-BFGS-B</code> method. If <code>optim=TRUE</code>, <code class="reqn">5 \times d</code> starting points are generated by Latin hypercube design for optimization. If <code>optim=FALSE</code>, AL criterion is optimized on the <code>Xcand</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ALM_RNAmf_+3A_parallel">parallel</code></td>
<td>
<p>logical indicating whether to compute the AL criterion in parallel or not. If <code>parallel=TRUE</code>, parallel computation is utilized. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ALM_RNAmf_+3A_ncore">ncore</code></td>
<td>
<p>a number of core for parallel. It is only used if <code>parallel=TRUE</code>. Default is 1.</p>
</td></tr>
<tr><td><code id="ALM_RNAmf_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether to print the computational time for each step. If <code>trace=TRUE</code>, the computation time for each step is printed. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>ALM</code>: list of ALM criterion computed at each point of <code>Xcand</code> at each level if <code>optim=FALSE</code>. If <code>optim=TRUE</code>, <code>ALM</code> returns <code>NULL</code>.
</p>
</li>
<li> <p><code>cost</code>: a copy of <code>cost</code>.
</p>
</li>
<li> <p><code>Xcand</code>: a copy of <code>Xcand</code>.
</p>
</li>
<li> <p><code>chosen</code>: list of chosen level and point.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lhs)
library(doParallel)
library(foreach)

### simulation costs ###
cost &lt;- c(1, 3)

### 1-d Perdikaris function in Perdikaris, et al. (2017) ###
# low-fidelity function
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

# high-fidelity function
f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### n=100 uniform test data ###
x &lt;- seq(0, 1, length.out = 100)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")

### predict ###
predy &lt;- predict(fit.RNAmf, x)$mu
predsig2 &lt;- predict(fit.RNAmf, x)$sig2

### active learning with optim=TRUE ###
alm.RNAmf.optim &lt;- ALM_RNAmf(
  Xcand = x, fit.RNAmf, cost = cost,
  optim = TRUE, parallel = TRUE, ncore = 2
)
print(alm.RNAmf.optim$time) # computation time of optim=TRUE

### active learning with optim=FALSE ###
alm.RNAmf &lt;- ALM_RNAmf(
  Xcand = x, fit.RNAmf, cost = cost,
  optim = FALSE, parallel = TRUE, ncore = 2
)
print(alm.RNAmf$time) # computation time of optim=FALSE

### visualize ALM ###
oldpar &lt;- par(mfrow = c(1, 2))
plot(x, alm.RNAmf$ALM$ALM1,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALM criterion at the low-fidelity level",
  ylim = c(min(c(alm.RNAmf$ALM$ALM1, alm.RNAmf$ALM$ALM2)),
           max(c(alm.RNAmf$ALM$ALM1, alm.RNAmf$ALM$ALM2)))
)
points(alm.RNAmf$chosen$Xnext,
  alm.RNAmf$ALM$ALM1[which(x == drop(alm.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
plot(x, alm.RNAmf$ALM$ALM2,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALM criterion at the high-fidelity level",
  ylim = c(min(c(alm.RNAmf$ALM$ALM1, alm.RNAmf$ALM$ALM2)),
           max(c(alm.RNAmf$ALM$ALM1, alm.RNAmf$ALM$ALM2)))
)
par(oldpar)

</code></pre>

<hr>
<h2 id='ALMC_RNAmf'>find the next point by ALMC criterion</h2><span id='topic+ALMC_RNAmf'></span>

<h3>Description</h3>

<p>The function acquires the new point by the hybrid approach,
referred to as Active learning MacKay-Cohn (ALMC) criterion.
It finds the optimal input location <code class="reqn">\bm{x^*}</code>
by maximizing <code class="reqn">\sigma^{*2}_L(\bm{x})</code>,
the posterior predictive variance at the highest-fidelity level <code class="reqn">L</code>.
After selecting <code class="reqn">\bm{x^*}</code>,
it finds the optimal fidelity level by maximizing ALC criterion at <code class="reqn">\bm{x^*}</code>,
<code class="reqn">\text{argmax}_{l\in\{1,\ldots,L\}} \frac{\Delta \sigma_L^{2}(l,\bm{x^*})}{\sum^l_{j=1}C_j}</code>,
where <code class="reqn">C_j</code> is the simulation cost at level <code class="reqn">j</code>.
See <code><a href="#topic+ALC_RNAmf">ALC_RNAmf</a></code>.
For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>
<p>A new point is acquired on <code>Xcand</code>. If <code>Xcand=NULL</code> and <code>Xref=NULL</code>, a new point is acquired on unit hypercube <code class="reqn">[0,1]^d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ALMC_RNAmf(Xref = NULL, Xcand = NULL, fit, mc.sample = 100,
cost = NULL, optim = TRUE, parallel = FALSE, ncore = 1, trace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ALMC_RNAmf_+3A_xref">Xref</code></td>
<td>
<p>vector or matrix of reference location to approximate the integral of ALC. If <code>Xref=NULL</code>, <code class="reqn">100 \times d</code> points from 0 to 1 are generated by Latin hypercube design. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_xcand">Xcand</code></td>
<td>
<p>vector or matrix of candidate set which could be added into the current design only when <code>optim=FALSE</code>. <code>Xcand</code> is the set of the points where ALM criterion is evaluated. If <code>Xcand=NULL</code>, <code>Xref</code> is used. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_fit">fit</code></td>
<td>
<p>object of class <code>RNAmf</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_mc.sample">mc.sample</code></td>
<td>
<p>a number of mc samples generated for the imputation through MC approximation. Default is <code>100</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_cost">cost</code></td>
<td>
<p>vector of the costs for each level of fidelity. If <code>cost=NULL</code>, total costs at all levels would be 1. <code>cost</code> is encouraged to have a ascending order of positive value. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_optim">optim</code></td>
<td>
<p>logical indicating whether to optimize AL criterion by <code>optim</code>'s gradient-based <code>L-BFGS-B</code> method. If <code>optim=TRUE</code>, <code class="reqn">5 \times d</code> starting points are generated by Latin hypercube design for optimization. If <code>optim=FALSE</code>, AL criterion is optimized on the <code>Xcand</code>. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_parallel">parallel</code></td>
<td>
<p>logical indicating whether to compute the AL criterion in parallel or not. If <code>parallel=TRUE</code>, parallel computation is utilized. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_ncore">ncore</code></td>
<td>
<p>a number of core for parallel. It is only used if <code>parallel=TRUE</code>. Default is 1.</p>
</td></tr>
<tr><td><code id="ALMC_RNAmf_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether to print the computational time for each step. If <code>trace=TRUE</code>, the computation time for each step is printed. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>ALMC</code>: vector of ALMC criterion <code class="reqn"> \frac{\Delta \sigma_L^{2}(l,\bm{x^*})}{\sum^l_{j=1}C_j}</code> for <code class="reqn">1\leq l\leq L</code>.
</p>
</li>
<li> <p><code>ALM</code>: vector of ALM criterion computed at each point of <code>Xcand</code> at the highest fidelity level if <code>optim=FALSE</code>. If <code>optim=TRUE</code>, <code>ALM</code> returns <code>NULL</code>.
</p>
</li>
<li> <p><code>ALC</code>: list of ALC criterion integrated on <code>Xref</code> when each data point on <code>Xcand</code> is added at each level <code class="reqn">l</code> if <code>optim=FALSE</code>. If <code>optim=TRUE</code>, <code>ALC</code> returns <code>NULL</code>.
</p>
</li>
<li> <p><code>cost</code>: a copy of <code>cost</code>.
</p>
</li>
<li> <p><code>Xcand</code>: a copy of <code>Xcand</code>.
</p>
</li>
<li> <p><code>chosen</code>: list of chosen level and point.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lhs)
library(doParallel)
library(foreach)

### simulation costs ###
cost &lt;- c(1, 3)

### 1-d Perdikaris function in Perdikaris, et al. (2017) ###
# low-fidelity function
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

# high-fidelity function
f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### n=100 uniform test data ###
x &lt;- seq(0, 1, length.out = 100)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")

### predict ###
predy &lt;- predict(fit.RNAmf, x)$mu
predsig2 &lt;- predict(fit.RNAmf, x)$sig2

### active learning with optim=TRUE ###
almc.RNAmf.optim &lt;- ALMC_RNAmf(
  Xref = x, Xcand = x, fit.RNAmf, cost = cost,
  optim = TRUE, parallel = TRUE, ncore = 2
)
print(almc.RNAmf.optim$time) # computation time of optim=TRUE

### active learning with optim=FALSE ###
almc.RNAmf &lt;- ALMC_RNAmf(
  Xref = x, Xcand = x, fit.RNAmf, cost = cost,
  optim = FALSE, parallel = TRUE, ncore = 2
)
print(almc.RNAmf$time) # computation time of optim=FALSE

### visualize ALMC ###
oldpar &lt;- par(mfrow = c(1, 2))
plot(x, almc.RNAmf$ALM,
  type = "l", lty = 2,
  xlab = "x", ylab = "ALM criterion at the high-fidelity level"
)
points(almc.RNAmf$chosen$Xnext,
  almc.RNAmf$ALM[which(x == drop(almc.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
plot(x, almc.RNAmf$ALC$ALC1,
  type = "l", lty = 2,
  ylim = c(min(c(almc.RNAmf$ALC$ALC1, almc.RNAmf$ALC$ALC2)),
  max(c(almc.RNAmf$ALC$ALC1, almc.RNAmf$ALC$ALC2))),
  xlab = "x", ylab = "ALC criterion augmented at each level on the optimal input location"
)
lines(x, almc.RNAmf$ALC$ALC2, type = "l", lty = 2)
points(almc.RNAmf$chosen$Xnext,
  almc.RNAmf$ALC$ALC1[which(x == drop(almc.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
points(almc.RNAmf$chosen$Xnext,
  almc.RNAmf$ALC$ALC2[which(x == drop(almc.RNAmf$chosen$Xnext))],
  pch = 16, cex = 1, col = "red"
)
par(oldpar)

</code></pre>

<hr>
<h2 id='NestedX'>Constructing the nested design sets for RNA model.</h2><span id='topic+NestedX'></span>

<h3>Description</h3>

<p>The function constructs the nested design sets with two fidelity levels
<code class="reqn">\mathcal{X}_2 \subseteq \mathcal{X}_{1}</code> for <code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code> or
three fidelity levels <code class="reqn">\mathcal{X}_3 \subseteq \mathcal{X}_2 \subseteq \mathcal{X}_{1}</code>
for <code><a href="#topic+RNAmf_three_level">RNAmf_three_level</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NestedX(n, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NestedX_+3A_n">n</code></td>
<td>
<p>vector of the number of design points at each fidelity level <code class="reqn">l</code>. Thus, the vector must have a positive value <code class="reqn">n_1, n_2</code> or <code class="reqn">n_1, n_2, n_3</code> where <code class="reqn">n_1 &gt; n_2 &gt; n_3</code>.</p>
</td></tr>
<tr><td><code id="NestedX_+3A_d">d</code></td>
<td>
<p>constant of the dimension of the design.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure replace the points of lower level design <code class="reqn">\mathcal{X}_{l-1}</code>
to the closest points of higher level design <code class="reqn">\mathcal{X}_{l}</code>.
The length of the <code class="reqn">\mathcal{X}_{l-1}</code> could be larger than the user specified.
For details, see &quot;<a href="http://cran.nexr.com/web/packages/MuFiCokriging/MuFiCokriging.pdf"><code>NestedDesign</code></a>&quot;.
</p>


<h3>Value</h3>

<p>A list containing the design at each level, i.e., <code class="reqn">\mathcal{X}_{1}, \mathcal{X}_{2}</code> or <code class="reqn">\mathcal{X}_{1}, \mathcal{X}_{2}, \mathcal{X}_{3}</code>.
</p>


<h3>References</h3>

<p>L. Le Gratiet and J. Garnier (2014). Recursive co-kriging model for design of computer experiments
with multiple levels of fidelity. <em>International Journal for Uncertainty Quantification</em>, 4(5), 365-386;
<a href="https://doi.org/10.1615/Int.J.UncertaintyQuantification.2014006914">doi:10.1615/Int.J.UncertaintyQuantification.2014006914</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### number of design points ###
n1 &lt;- 30
n2 &lt;- 15

### dimension of the design ###
d &lt;- 2

### fix seed to reproduce the result ###
set.seed(1)

### generate the nested design ###
NX &lt;- NestedX(c(n1, n2), d)

### visualize nested design ###
plot(NX[[1]], col="red", pch=1, xlab="x1", ylab="x2")
points(NX[[2]], col="blue", pch=4)

</code></pre>

<hr>
<h2 id='predict.RNAmf'>prediction of the RNAmf emulator with 2 or 3 fidelity levels.</h2><span id='topic+predict.RNAmf'></span>

<h3>Description</h3>

<p>The function computes the posterior mean and variance of RNA models with two or three fidelity levels
by fitted model using <code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code> or <code><a href="#topic+RNAmf_three_level">RNAmf_three_level</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RNAmf'
predict(object, x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.RNAmf_+3A_object">object</code></td>
<td>
<p>a class <code>RNAmf</code> object fitted by <code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code> or <code><a href="#topic+RNAmf_three_level">RNAmf_three_level</a></code>.</p>
</td></tr>
<tr><td><code id="predict.RNAmf_+3A_x">x</code></td>
<td>
<p>vector or matrix of new input locations to predict.</p>
</td></tr>
<tr><td><code id="predict.RNAmf_+3A_...">...</code></td>
<td>
<p>for compatibility with generic method <code>predict</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From the model fitted by <code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code> or <code><a href="#topic+RNAmf_three_level">RNAmf_three_level</a></code>,
the posterior mean and variance are calculated based on the closed form expression derived by a recursive fashion.
The formulas depend on its kernel choices.
For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>


<h3>Value</h3>


<ul>
<li> <p><code>mu</code>: vector of predictive posterior mean.
</p>
</li>
<li> <p><code>sig2</code>: vector of predictive posterior variance.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code> or <code><a href="#topic+RNAmf_three_level">RNAmf_three_level</a></code> for the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### two levels example ###
library(lhs)

### Perdikaris function ###
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### n=100 uniform test data ###
x &lt;- seq(0, 1, length.out = 100)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")

### predict ###
predy &lt;- predict(fit.RNAmf, x)$mu
predsig2 &lt;- predict(fit.RNAmf, x)$sig2

### RMSE ###
print(sqrt(mean((predy - f2(x))^2)))

### visualize the emulation performance ###
plot(x, predy,
  type = "l", lwd = 2, col = 3, # emulator and confidence interval
  ylim = c(-2, 1)
)
lines(x, predy + 1.96 * sqrt(predsig2 * length(y2) / (length(y2) - 2)), col = 3, lty = 2)
lines(x, predy - 1.96 * sqrt(predsig2 * length(y2) / (length(y2) - 2)), col = 3, lty = 2)

curve(f2(x), add = TRUE, col = 1, lwd = 2, lty = 2) # high fidelity function

points(X1, y1, pch = 1, col = "red") # low-fidelity design
points(X2, y2, pch = 4, col = "blue") # high-fidelity design

### three levels example ###
### Branin function ###
branin &lt;- function(xx, l){
  x1 &lt;- xx[1]
  x2 &lt;- xx[2]
  if(l == 1){
    10*sqrt((-1.275*(1.2*x1+0.4)^2/pi^2+5*(1.2*x1+0.4)/pi+(1.2*x2+0.4)-6)^2 +
    (10-5/(4*pi))*cos((1.2*x1+0.4))+ 10) + 2*(1.2*x1+1.9) - 3*(3*(1.2*x2+2.4)-1) - 1 - 3*x2 + 1
  }else if(l == 2){
    10*sqrt((-1.275*(x1+2)^2/pi^2+5*(x1+2)/pi+(x2+2)-6)^2 +
    (10-5/(4*pi))*cos((x1+2))+ 10) + 2*(x1-0.5) - 3*(3*x2-1) - 1
  }else if(l == 3){
    (-1.275*x1^2/pi^2+5*x1/pi+x2-6)^2 + (10-5/(4*pi))*cos(x1)+ 10
  }
}

output.branin &lt;- function(x, l){
  factor_range &lt;- list("x1" = c(-5, 10), "x2" = c(0, 15))

  for(i in 1:length(factor_range)) x[i] &lt;- factor_range[[i]][1] + x[i] * diff(factor_range[[i]])
  branin(x[1:2], l)
}

### training data ###
n1 &lt;- 20; n2 &lt;- 15; n3 &lt;- 10

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2, n3), 2)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]
X3 &lt;- X[[3]]

### n1, n2 and n3 might be changed from NestedX ###
### assign n1, n2 and n3 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)
n3 &lt;- nrow(X3)

y1 &lt;- apply(X1,1,output.branin, l=1)
y2 &lt;- apply(X2,1,output.branin, l=2)
y3 &lt;- apply(X3,1,output.branin, l=3)

### n=10000 grid test data ###
x &lt;- as.matrix(expand.grid(seq(0, 1, length.out = 100),seq(0, 1, length.out = 100)))

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_three_level(X1, y1, X2, y2, X3, y3, kernel = "sqex")

### predict ###
pred.RNAmf &lt;- predict(fit.RNAmf, x)
predy &lt;- pred.RNAmf$mu
predsig2 &lt;- pred.RNAmf$sig2

### RMSE ###
print(sqrt(mean((predy - apply(x,1,output.branin, l=3))^2)))

### visualize the emulation performance ###
x1 &lt;- x2 &lt;- seq(0, 1, length.out = 100)
oldpar &lt;- par(mfrow=c(1,2))
image(x1, x2, matrix(apply(x,1,output.branin, l=3), ncol=100),
zlim=c(0,310), main="Branin function")
image(x1, x2, matrix(predy, ncol=100),
zlim=c(0,310), main="RNAmf prediction")
par(oldpar)

### predictive variance ###
print(predsig2)

</code></pre>

<hr>
<h2 id='RNAmf_three_level'>Fitting the model with three fidelity levels</h2><span id='topic+RNAmf_three_level'></span>

<h3>Description</h3>

<p>The function fits RNA models with designs of three fidelity levels.
The estimation method is based on MLE.
Possible kernel choices are squared exponential, Matern kernel with smoothness parameter 1.5 and 2.5.
The function returns fitted model by <code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code>, fitted model at level 3, whether constant mean or not, and kernel choice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RNAmf_three_level(X1, y1, X2, y2, X3, y3, kernel = "sqex", constant = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RNAmf_three_level_+3A_x1">X1</code></td>
<td>
<p>vector or matrix of input locations for the low fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_y1">y1</code></td>
<td>
<p>vector of response values for the low fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_x2">X2</code></td>
<td>
<p>vector or matrix of input locations for the medium fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_y2">y2</code></td>
<td>
<p>vector of response values for the medium fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_x3">X3</code></td>
<td>
<p>vector or matrix of input locations for the high fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_y3">y3</code></td>
<td>
<p>vector of response values for the high fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_kernel">kernel</code></td>
<td>
<p>character specifying kernel type to be used, to be chosen between <code>"sqex"</code>(squared exponential), <code>"matern1.5"</code>, or <code>"matern2.5"</code>. Default is <code>"sqex"</code>.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_constant">constant</code></td>
<td>
<p>logical indicating for constant mean of GP (<code>constant=TRUE</code>) or zero mean (<code>constant=FALSE</code>). Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="RNAmf_three_level_+3A_...">...</code></td>
<td>
<p>for compatibility with <code>optim</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider the model
<code class="reqn">\begin{cases}
&amp; f_1(\bm{x}) = W_1(\bm{x}),\\
&amp; f_l(\bm{x}) = W_l(\bm{x}, f_{l-1}(\bm{x})) \quad\text{for}\quad l=2,3,
\end{cases}</code>
where <code class="reqn">f_l</code> is the simulation code at fidelity level <code class="reqn">l</code>, and
<code class="reqn">W_l(\bm{x}) \sim GP(\alpha_l, \tau_l^2 K_l(\bm{x}, \bm{x}'))</code> is GP model.
Hyperparameters <code class="reqn">(\alpha_l, \tau_l^2, \bm{\theta_l})</code> are estimated by
maximizing the log-likelihood via an optimization algorithm &quot;L-BFGS-B&quot;.
For <code>constant=FALSE</code>, <code class="reqn">\alpha_l=0</code>.
</p>
<p>Covariance kernel is defined as:
<code class="reqn">K_l(\bm{x}, \bm{x}')=\prod^d_{j=1}\phi(x_j,x'_j;\theta_{lj})</code> with
<code class="reqn">\phi(x, x';\theta) = \exp \left( -\frac{ \left( x - x' \right)^2}{\theta}  \right)</code>
for squared exponential kernel; <code>kernel="sqex"</code>,
<code class="reqn">\phi(x,x';\theta) =\left( 1+\frac{\sqrt{3}|x- x'|}{\theta} \right) \exp \left( -\frac{\sqrt{3}|x- x'|}{\theta} \right)</code>
for Matern kernel with the smoothness parameter of 1.5; <code>kernel="matern1.5"</code> and
<code class="reqn">\phi(x, x';\theta) = \left( 1+\frac{\sqrt{5}|x-x'|}{\theta} +\frac{5(x-x')^2}{3\theta^2} \right) \exp \left( -\frac{\sqrt{5}|x-x'|}{\theta} \right)</code>
for Matern kernel with the smoothness parameter of 2.5; <code>kernel="matern2.5"</code>.
</p>
<p>For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>


<h3>Value</h3>


<ul>
<li> <p><code>fit.RNAmf_two_level</code>: a class <code>RNAmf</code> object fitted by <code>RNAmf_two_level</code>. It contains a list of <code class="reqn">\begin{cases} &amp; \text{\code{fit1} for } (X_1, y_1),\\ &amp; \text{\code{fit2} for } ((X_2, f_1(X_2)), y_2), \end{cases}</code>. See <code><a href="#topic+RNAmf_two_level">RNAmf_two_level</a></code>.
</p>
</li>
<li> <p><code>fit3</code>: list of fitted model for <code class="reqn">((X_2, f_2(X_3, f_1(X_3))), y_3)</code>.
</p>
</li>
<li> <p><code>constant</code>: copy of <code>constant</code>.
</p>
</li>
<li> <p><code>kernel</code>: copy of <code>kernel</code>.
</p>
</li>
<li> <p><code>level</code>: a level of the fidelity. It returns 3.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+predict.RNAmf">predict.RNAmf</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### three levels example ###
library(lhs)

### Branin function ###
branin &lt;- function(xx, l){
  x1 &lt;- xx[1]
  x2 &lt;- xx[2]
  if(l == 1){
    10*sqrt((-1.275*(1.2*x1+0.4)^2/pi^2+5*(1.2*x1+0.4)/pi+(1.2*x2+0.4)-6)^2 +
    (10-5/(4*pi))*cos((1.2*x1+0.4))+ 10) + 2*(1.2*x1+1.9) - 3*(3*(1.2*x2+2.4)-1) - 1 - 3*x2 + 1
  }else if(l == 2){
    10*sqrt((-1.275*(x1+2)^2/pi^2+5*(x1+2)/pi+(x2+2)-6)^2 +
    (10-5/(4*pi))*cos((x1+2))+ 10) + 2*(x1-0.5) - 3*(3*x2-1) - 1
  }else if(l == 3){
    (-1.275*x1^2/pi^2+5*x1/pi+x2-6)^2 + (10-5/(4*pi))*cos(x1)+ 10
  }
}

output.branin &lt;- function(x, l){
  factor_range &lt;- list("x1" = c(-5, 10), "x2" = c(0, 15))

  for(i in 1:length(factor_range)) x[i] &lt;- factor_range[[i]][1] + x[i] * diff(factor_range[[i]])
  branin(x[1:2], l)
}

### training data ###
n1 &lt;- 20; n2 &lt;- 15; n3 &lt;- 10

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2, n3), 2)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]
X3 &lt;- X[[3]]

### n1, n2 and n3 might be changed from NestedX ###
### assign n1, n2 and n3 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)
n3 &lt;- nrow(X3)

y1 &lt;- apply(X1,1,output.branin, l=1)
y2 &lt;- apply(X2,1,output.branin, l=2)
y3 &lt;- apply(X3,1,output.branin, l=3)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_three_level(X1, y1, X2, y2, X3, y3, kernel = "sqex")



</code></pre>

<hr>
<h2 id='RNAmf_two_level'>Fitting the Recursive non-additive model with two fidelity levels.</h2><span id='topic+RNAmf_two_level'></span>

<h3>Description</h3>

<p>The function fits RNA models with designs of two fidelity levels.
The estimation method is based on MLE.
Possible kernel choices are squared exponential, Matern kernel with smoothness parameter 1.5 and 2.5.
The function returns fitted model at level 1 and 2, whether constant mean or not, and kernel choice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex", constant = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RNAmf_two_level_+3A_x1">X1</code></td>
<td>
<p>vector or matrix of input locations for the low fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_two_level_+3A_y1">y1</code></td>
<td>
<p>vector of response values for the low fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_two_level_+3A_x2">X2</code></td>
<td>
<p>vector or matrix of input locations for the high fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_two_level_+3A_y2">y2</code></td>
<td>
<p>vector of response values for the high fidelity level.</p>
</td></tr>
<tr><td><code id="RNAmf_two_level_+3A_kernel">kernel</code></td>
<td>
<p>character specifying kernel type to be used, to be chosen between <code>"sqex"</code>(squared exponential), <code>"matern1.5"</code>, or <code>"matern2.5"</code>. Default is <code>"sqex"</code>.</p>
</td></tr>
<tr><td><code id="RNAmf_two_level_+3A_constant">constant</code></td>
<td>
<p>logical indicating for constant mean of GP (<code>constant=TRUE</code>) or zero mean (<code>constant=FALSE</code>). Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="RNAmf_two_level_+3A_...">...</code></td>
<td>
<p>for compatibility with <code>optim</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider the model
<code class="reqn">\begin{cases}
&amp; f_1(\bm{x}) = W_1(\bm{x}),\\
&amp; f_2(\bm{x}) = W_2(\bm{x}, f_1(\bm{x})),
\end{cases}</code>
where <code class="reqn">f_l</code> is the simulation code at fidelity level <code class="reqn">l</code>, and
<code class="reqn">W_l(\bm{x}) \sim GP(\alpha_l, \tau_l^2 K_l(\bm{x}, \bm{x}'))</code> is GP model.
Hyperparameters <code class="reqn">(\alpha_l, \tau_l^2, \bm{\theta_l})</code> are estimated by
maximizing the log-likelihood via an optimization algorithm &quot;L-BFGS-B&quot;.
For <code>constant=FALSE</code>, <code class="reqn">\alpha_l=0</code>.
</p>
<p>Covariance kernel is defined as:
<code class="reqn">K_l(\bm{x}, \bm{x}')=\prod^d_{j=1}\phi(x_j,x'_j;\theta_{lj})</code> with
<code class="reqn">\phi(x, x';\theta) = \exp \left( -\frac{ \left( x - x' \right)^2}{\theta}  \right)</code>
for squared exponential kernel; <code>kernel="sqex"</code>,
<code class="reqn">\phi(x,x';\theta) =\left( 1+\frac{\sqrt{3}|x- x'|}{\theta} \right) \exp \left( -\frac{\sqrt{3}|x- x'|}{\theta} \right)</code>
for Matern kernel with the smoothness parameter of 1.5; <code>kernel="matern1.5"</code> and
<code class="reqn">\phi(x, x';\theta) =  \left( 1+\frac{\sqrt{5}|x-x'|}{\theta} +\frac{5(x-x')^2}{3\theta^2} \right) \exp \left( -\frac{\sqrt{5}|x-x'|}{\theta} \right)</code>
for Matern kernel with the smoothness parameter of 2.5; <code>kernel="matern2.5"</code>.
</p>
<p>For details, see Heo and Sung (2024, &lt;<a href="https://doi.org/10.1080/00401706.2024.2376173">doi:10.1080/00401706.2024.2376173</a>&gt;).
</p>


<h3>Value</h3>


<ul>
<li> <p><code>fit1</code>: list of fitted model for <code class="reqn">(X_1, y_1)</code>.
</p>
</li>
<li> <p><code>fit2</code>: list of fitted model for <code class="reqn">((X_2, f_1(X_2)), y_2)</code>.
</p>
</li>
<li> <p><code>constant</code>: copy of <code>constant</code>.
</p>
</li>
<li> <p><code>kernel</code>: copy of <code>kernel</code>.
</p>
</li>
<li> <p><code>level</code>: a level of the fidelity. It returns 2.
</p>
</li>
<li> <p><code>time</code>: a scalar of the time for the computation.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+predict.RNAmf">predict.RNAmf</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### two levels example ###
library(lhs)

### Perdikaris function ###
f1 &lt;- function(x) {
  sin(8 * pi * x)
}

f2 &lt;- function(x) {
  (x - sqrt(2)) * (sin(8 * pi * x))^2
}

### training data ###
n1 &lt;- 13
n2 &lt;- 8

### fix seed to reproduce the result ###
set.seed(1)

### generate initial nested design ###
X &lt;- NestedX(c(n1, n2), 1)
X1 &lt;- X[[1]]
X2 &lt;- X[[2]]

### n1 and n2 might be changed from NestedX ###
### assign n1 and n2 again ###
n1 &lt;- nrow(X1)
n2 &lt;- nrow(X2)

y1 &lt;- f1(X1)
y2 &lt;- f2(X2)

### fit an RNAmf ###
fit.RNAmf &lt;- RNAmf_two_level(X1, y1, X2, y2, kernel = "sqex")


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
