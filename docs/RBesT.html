<!DOCTYPE html><html><head><title>Help for package RBesT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RBesT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RBesT-package'><p>R Bayesian Evidence Synthesis Tools</p></a></li>
<li><a href='#AS'><p>Ankylosing Spondylitis.</p></a></li>
<li><a href='#automixfit'><p>Automatic Fitting of Mixtures of Conjugate Distributions to a Sample</p></a></li>
<li><a href='#BinaryExactCI'><p>Exact Confidence interval for Binary Proportion</p></a></li>
<li><a href='#chains2sample'><p>Scrambles the order of a mcmc array object for usage as a mcmc</p>
sample. It is advisable to set order once per mcmc run, otherwise
correlations in the mcmc sample will be lost.</a></li>
<li><a href='#colitis'><p>Ulcerative Colitis.</p></a></li>
<li><a href='#colVars'><p>Fast column-wise calculation of unbiased variances</p></a></li>
<li><a href='#crohn'><p>Crohn's disease.</p></a></li>
<li><a href='#Curry'><p>Functional programming utilities</p></a></li>
<li><a href='#dBetaBinomial'><p>Beta-Binomial Probabilities</p></a></li>
<li><a href='#decision1S'><p>Decision Function for 1 Sample Designs</p></a></li>
<li><a href='#decision1S_boundary'><p>Decision Boundary for 1 Sample Designs</p></a></li>
<li><a href='#decision2S'><p>Decision Function for 2 Sample Designs</p></a></li>
<li><a href='#decision2S_boundary'><p>Decision Boundary for 2 Sample Designs</p></a></li>
<li><a href='#dlink+26lt+3B-'><p>Transform Densities with a link function</p></a></li>
<li><a href='#ess'><p>Effective Sample Size for a Conjugate Prior</p></a></li>
<li><a href='#fill'><p>Fill numeric objects</p></a></li>
<li><a href='#forest_plot'><p>Forest Plot</p></a></li>
<li><a href='#gMAP'><p>Meta-Analytic-Predictive Analysis for Generalized Linear Models</p></a></li>
<li><a href='#integrate_density_log'><p>internal function used for integration of densities which appears</p>
to be much more stable from -Inf to +Inf in the logit space while
the density to be integrated recieves inputs from 0 to 1 such that
the inverse distribution function must be used. The integral solved
is int_x dmix(mix,x) integrand(x) where integrand must be given as
log and we integrate over the support of mix.</a></li>
<li><a href='#knn'><p>k nearest neighbor algorithm for multi-variate data</p></a></li>
<li><a href='#likelihood'><p>Read and Set Likelihood to the Corresponding Conjugate Prior</p></a></li>
<li><a href='#lodds'><p>Logit (log-odds) and inverse-logit function.</p></a></li>
<li><a href='#log_inv_logit'><p>Numerically stable log of the inv_logit function</p></a></li>
<li><a href='#logLik.EM'><p>Extract log likelihood from fitted EM objects</p></a></li>
<li><a href='#mix'><p>Mixture Distributions</p></a></li>
<li><a href='#mixbeta'><p>Beta Mixture Density</p></a></li>
<li><a href='#mixcombine'><p>Combine Mixture Distributions</p></a></li>
<li><a href='#mixdiff'><p>Difference of mixture distributions</p></a></li>
<li><a href='#mixdist3'><p>Utility function to instantiate 2 parameter mixture densities.</p></a></li>
<li><a href='#mixfit'><p>Fit of Mixture Densities to Samples</p></a></li>
<li><a href='#mixgamma'><p>The Gamma Mixture Distribution</p></a></li>
<li><a href='#mixlink'><p>takes x and transforms it according to the defined link function of</p>
the mixture</a></li>
<li><a href='#mixmvnorm'><p>Multivariate Normal Mixture Density</p></a></li>
<li><a href='#mixnorm'><p>Normal Mixture Density</p></a></li>
<li><a href='#mixplot'><p>Plot mixture distributions</p></a></li>
<li><a href='#mixstanvar'><p>Mixture distributions as <code>brms</code> priors</p></a></li>
<li><a href='#oc1S'><p>Operating Characteristics for 1 Sample Design</p></a></li>
<li><a href='#oc2S'><p>Operating Characteristics for 2 Sample Design</p></a></li>
<li><a href='#plot.EM'><p>Diagnostic plots for EM fits</p></a></li>
<li><a href='#plot.gMAP'><p>Diagnostic plots for gMAP analyses</p></a></li>
<li><a href='#pos1S'><p>Probability of Success for a 1 Sample Design</p></a></li>
<li><a href='#pos2S'><p>Probability of Success for 2 Sample Design</p></a></li>
<li><a href='#postmix'><p>Conjugate Posterior Analysis</p></a></li>
<li><a href='#preddist'><p>Predictive Distributions for Mixture Distributions</p></a></li>
<li><a href='#predict.gMAP'><p>Predictions from gMAP analyses</p></a></li>
<li><a href='#robustify'><p>Robustify Mixture Priors</p></a></li>
<li><a href='#SimSum'><p>Summarize Arrays</p></a></li>
<li><a href='#support'><p>Support of Distributions</p></a></li>
<li><a href='#transplant'><p>Transplant.</p></a></li>
<li><a href='#uniroot_int'><p>Find root of univariate function of integers</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>R Bayesian Evidence Synthesis Tools</td>
</tr>
<tr>
<td>Description:</td>
<td>Tool-set to support Bayesian evidence synthesis.  This
    includes meta-analysis, (robust) prior derivation from historical
    data, operating characteristics and analysis (1 and 2 sample
    cases). Please refer to Weber et al. (2021) &lt;<a href="https://doi.org/10.18637%2Fjss.v100.i19">doi:10.18637/jss.v100.i19</a>&gt;
    for details on applying this package while Neuenschwander et al. (2010)
    &lt;<a href="https://doi.org/10.1177%2F1740774509356002">doi:10.1177/1740774509356002</a>&gt; and Schmidli et al. (2014)
    &lt;<a href="https://doi.org/10.1111%2Fbiom.12242">doi:10.1111/biom.12242</a>&gt; explain details on the methodology.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.7-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-02</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, Rcpp (&ge; 0.12.0), RcppParallel (&ge; 5.0.1), rstan (&ge;
2.26.0), rstantools (&ge; 2.3.1), assertthat, mvtnorm, Formula,
checkmate, bayesplot (&ge; 1.4.0), ggplot2, dplyr, stats, utils,
matrixStats, abind, rlang</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH (&ge; 1.72.0), Rcpp (&ge; 0.12.0), RcppEigen (&ge; 0.3.3.3.0),
RcppParallel (&ge; 5.0.1), rstan (&ge; 2.26.0), StanHeaders (&ge;
2.26.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>UseLTO:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://opensource.nibr.com/RBesT/">https://opensource.nibr.com/RBesT/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Novartis/RBesT/issues">https://github.com/Novartis/RBesT/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, testthat (&ge; 2.0.0), foreach, purrr,
rstanarm (&ge; 2.17.2), scales, tools, broom, tidyr, parallel,
brms, glue, ragg</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make, pandoc (&gt;= 1.12.3), pngquant, C++17</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-02 13:55:42 UTC; weberse2</td>
</tr>
<tr>
<td>Author:</td>
<td>Novartis Pharma AG [cph],
  Sebastian Weber [aut, cre],
  Beat Neuenschwander [ctb],
  Heinz Schmidli [ctb],
  Baldur Magnusson [ctb],
  Yue Li [ctb],
  Satrajit Roychoudhury [ctb],
  Trustees of Columbia University [cph] (R/stanmodels.R, configure,
    configure.win)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Weber &lt;sebastian.weber@novartis.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-08 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='RBesT-package'>R Bayesian Evidence Synthesis Tools</h2><span id='topic+RBesT'></span><span id='topic+RBesT-package'></span>

<h3>Description</h3>

<p>The RBesT tools are designed to support in the derivation of
parametric informative priors, asses design characeristics and
perform analyses. Supported endpoints include normal, binary and
Poisson.
</p>


<h3>Details</h3>

<p>For introductory material, please refer to the vignettes which include
</p>

<ul>
<li><p> Introduction (binary)
</p>
</li>
<li><p> Introduction (normal)
</p>
</li>
<li><p> Customizing RBesT Plots
</p>
</li>
<li><p> Robust MAP, advanced usage
</p>
</li></ul>

<p>The main function of the package is <code><a href="#topic+gMAP">gMAP</a></code>. See it's
help page for a detailed description of the statistical model.
</p>


<h3>Global Options</h3>


<table>
<tr>
 <td style="text-align: left;">
Option </td><td style="text-align: center;"> Default </td><td style="text-align: left;"> Description </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.warmup</code> </td><td style="text-align: center;"> 2000 </td><td style="text-align: left;"> MCMC warmup iterations </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.iter</code> </td><td style="text-align: center;"> 6000 </td><td style="text-align: left;"> total MCMC iterations </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.chains</code> </td><td style="text-align: center;"> 4 </td><td style="text-align: left;"> MCMC chains</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.thin</code> </td><td style="text-align: center;"> 4 </td><td style="text-align: left;"> MCMC thinning </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.control</code> </td><td style="text-align: center;"> <code>list(adapt_delta=0.99,</code> </td><td style="text-align: left;"> sets <code>control</code> argument for Stan call</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: center;"> <code>stepsize=0.01,</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: center;"> <code>max_treedepth=20)</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.ncp</code> </td><td style="text-align: center;"> 1 </td><td style="text-align: left;"> parametrization: 0=CP, 1=NCP, 2=Automatic  </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.init</code> </td><td style="text-align: center;"> 1 </td><td style="text-align: left;"> range of initial uniform [-1,1] is the default  </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.MC.rescale</code> </td><td style="text-align: center;"> <code>TRUE</code> </td><td style="text-align: left;"> Automatic rescaling of raw parameters  </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.verbose</code> </td><td style="text-align: center;"> <code>FALSE</code> </td><td style="text-align: left;"> requests outputs to be more verbose</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>RBesT.integrate_args</code> </td><td style="text-align: center;"> <code>list(lower=-Inf,</code> </td><td style="text-align: left;"> arguments passed to <code>integrate</code> for</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: center;"> <code>upper=Inf,</code> </td><td style="text-align: left;"> intergation of densities</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: center;"> <code>rel.tol=.Machine$double.eps^0.25,</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: center;"> <code>abs.tol=.Machine$double.eps^0.25,</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: center;"> <code>subdivisions=1E3)</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Version History</h3>

<p>See <code>NEWS.md</code> file.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Sebastian Weber <a href="mailto:sebastian.weber@novartis.com">sebastian.weber@novartis.com</a>
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Novartis Pharma AG [copyright holder]
</p>
</li>
<li><p> Beat Neuenschwander <a href="mailto:beat.neuenschwander@novartis.com">beat.neuenschwander@novartis.com</a> [contributor]
</p>
</li>
<li><p> Heinz Schmidli <a href="mailto:heinz.schmidli@novartis.com">heinz.schmidli@novartis.com</a> [contributor]
</p>
</li>
<li><p> Baldur Magnusson <a href="mailto:baldur.magnusson@novartis.com">baldur.magnusson@novartis.com</a> [contributor]
</p>
</li>
<li><p> Yue Li <a href="mailto:yue-1.li@novartis.com">yue-1.li@novartis.com</a> [contributor]
</p>
</li>
<li><p> Satrajit Roychoudhury <a href="mailto:satrajit.roychoudhury@novartis.com">satrajit.roychoudhury@novartis.com</a> [contributor]
</p>
</li>
<li><p> Trustees of Columbia University (R/stanmodels.R, configure, configure.win) [copyright holder]
</p>
</li></ul>



<h3>References</h3>

<p>Stan Development Team (2020). RStan: the R interface to Stan. R package version 2.19.3. https://mc-stan.org
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://opensource.nibr.com/RBesT/">https://opensource.nibr.com/RBesT/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/Novartis/RBesT/issues">https://github.com/Novartis/RBesT/issues</a>
</p>
</li></ul>


<hr>
<h2 id='AS'>Ankylosing Spondylitis.</h2><span id='topic+AS'></span>

<h3>Description</h3>

<p>Data set containing historical information for placebo for a phase
II trial of ankylosing spondylitis patients. The primary efficacy
endpoint was the percentage of patients with a 20
according to the Assessment of SpondyloArthritis international
Society criteria for improvement (ASAS20) at week 6.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AS
</code></pre>


<h3>Format</h3>

<p>A data frame with 8 rows and 3 variables:
</p>

<dl>
<dt>study</dt><dd><p>study</p>
</dd>
<dt>n</dt><dd><p>study size</p>
</dd>
<dt>r</dt><dd><p>number of events</p>
</dd>
</dl>



<h3>References</h3>

<p>Baeten D. et. al, <em>The Lancet</em>, 2013, (382), 9906, p 1705
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Setting up dummy sampling for fast execution of example
## Please use 4 chains and 20x more warmup &amp; iter in practice
.user_mc_options &lt;- options(RBesT.MC.warmup=50, RBesT.MC.iter=100,
                            RBesT.MC.chains=2, RBesT.MC.thin=1)

set.seed(34563)
map_AS &lt;- gMAP(cbind(r, n-r) ~ 1 | study,
               family=binomial,
               data=AS,
               tau.dist="HalfNormal", tau.prior=1,
               beta.prior=2)
## Recover user set sampling defaults
options(.user_mc_options)

</code></pre>

<hr>
<h2 id='automixfit'>Automatic Fitting of Mixtures of Conjugate Distributions to a Sample</h2><span id='topic+automixfit'></span>

<h3>Description</h3>

<p>Fitting a series of mixtures of conjugate distributions to a
<code>sample</code>, using Expectation-Maximization (EM). The number of
mixture components is specified by the vector <code>Nc</code>. First a
<code>Nc[1]</code> component mixture is fitted, then a <code>Nc[2]</code>
component mixture, and so on. The mixture providing the best AIC
value is then selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>automixfit(sample, Nc = seq(1, 4), k = 6, thresh = -Inf, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="automixfit_+3A_sample">sample</code></td>
<td>
<p>Sample to be fitted by a mixture distribution.</p>
</td></tr>
<tr><td><code id="automixfit_+3A_nc">Nc</code></td>
<td>
<p>Vector of mixture components to try out (default <code>seq(1,4)</code>).</p>
</td></tr>
<tr><td><code id="automixfit_+3A_k">k</code></td>
<td>
<p>Penalty parameter for AIC calculation (default 6)</p>
</td></tr>
<tr><td><code id="automixfit_+3A_thresh">thresh</code></td>
<td>
<p>The procedure stops if the difference of subsequent AIC values
is smaller than this threshold (default -Inf). Setting the threshold to 0
stops <code>automixfit</code> once the AIC becomes worse.</p>
</td></tr>
<tr><td><code id="automixfit_+3A_verbose">verbose</code></td>
<td>
<p>Enable verbose logging.</p>
</td></tr>
<tr><td><code id="automixfit_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="#topic+mixfit">mixfit</a></code>,
including <code>type</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>type</code> argument specifies the distribution of
the mixture components, and can be a normal, beta or gamma
distribution.
</p>
<p>The penalty parameter <code>k</code> is 2 for the standard AIC
definition. <em>Collet (2003)</em> suggested to use values in the
range from 2 to 6, where larger values of <code>k</code> penalize more
complex models. To favor mixtures with fewer components a value of
6 is used as default.
</p>


<h3>Value</h3>

<p>As result the best fitting mixture model is returned,
i.e. the model with lowest AIC. All other models are saved in the
attribute <code>models</code>.
</p>


<h3>References</h3>

<p>Collet D.
<em>Modeling Survival Data in Medical Research</em>.
2003; Chapman and Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># random sample of size 1000 from a mixture of 2 beta components
bm &lt;- mixbeta(beta1=c(0.4, 20, 90), beta2=c(0.6, 35, 65))
bmSamp &lt;- rmix(bm, 1000)

# fit with EM mixture models with up to 10 components and stop if
# AIC increases
bmFit &lt;- automixfit(bmSamp, Nc=1:10, thresh=0, type="beta")
bmFit

# advanced usage: find out about all discarded models
bmFitAll &lt;- attr(bmFit, "models")

sapply(bmFitAll, AIC, k=6)


</code></pre>

<hr>
<h2 id='BinaryExactCI'>Exact Confidence interval for Binary Proportion</h2><span id='topic+BinaryExactCI'></span>

<h3>Description</h3>

<p>This function calculates the exact confidendence interval for a
response rate presented by <code class="reqn">n</code> and <code class="reqn">r</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinaryExactCI(r, n, alpha = 0.05, drop = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinaryExactCI_+3A_r">r</code></td>
<td>
<p>Number of success or responder</p>
</td></tr>
<tr><td><code id="BinaryExactCI_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="BinaryExactCI_+3A_alpha">alpha</code></td>
<td>
<p>confidence level</p>
</td></tr>
<tr><td><code id="BinaryExactCI_+3A_drop">drop</code></td>
<td>
<p>Determines if <code><a href="base.html#topic+drop">drop</a></code> will be called on the result</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Confidence intervals are obtained by a procedure first given in 
Clopper and Pearson (1934). This guarantees that the confidence 
level is at least (1-<code class="reqn">\alpha</code>).
</p>
<p>Details can be found in the publication listed below.
</p>


<h3>Value</h3>

<p>100 (1-<code class="reqn">\alpha</code>)% exact confidence interval for given
response rate
</p>


<h3>References</h3>

<p>Clopper, C. J. &amp; Pearson, E. S. The use of confidence or
fiducial limits illustrated in the case of the binomial. Biometrika 1934.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BinaryExactCI(3,20,0.05)

</code></pre>

<hr>
<h2 id='chains2sample'>Scrambles the order of a mcmc array object for usage as a mcmc
sample. It is advisable to set order once per mcmc run, otherwise
correlations in the mcmc sample will be lost.</h2><span id='topic+chains2sample'></span>

<h3>Description</h3>

<p>Scrambles the order of a mcmc array object for usage as a mcmc
sample. It is advisable to set order once per mcmc run, otherwise
correlations in the mcmc sample will be lost.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chains2sample(chains, order, drop = TRUE)
</code></pre>

<hr>
<h2 id='colitis'>Ulcerative Colitis.</h2><span id='topic+colitis'></span>

<h3>Description</h3>

<p>Data set containing historical information for placebo arm of a
phase II proof-of-concept trial for the treatment of ulcerative
colitis. The primary outcome is remission at week 8 (binary).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colitis
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 rows and 3 variables:
</p>

<dl>
<dt>study</dt><dd><p>study</p>
</dd>
<dt>n</dt><dd><p>study size</p>
</dd>
<dt>r</dt><dd><p>number of events</p>
</dd>
</dl>



<h3>References</h3>

<p>Neuenschwander B, Capkun-Niggli G, Branson M,
Spiegelhalter DJ. Summarizing historical information on controls in
clinical trials. <em>Clin Trials</em>. 2010; 7(1):5-18
</p>

<hr>
<h2 id='colVars'>Fast column-wise calculation of unbiased variances</h2><span id='topic+colVars'></span>

<h3>Description</h3>

<p>Fast column-wise calculation of unbiased variances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colVars(a)
</code></pre>

<hr>
<h2 id='crohn'>Crohn's disease.</h2><span id='topic+crohn'></span>

<h3>Description</h3>

<p>Data set containing historical information for placebo arm of
relevant studies for the treatment of Crohn's disease. The primary
outcome is change from baseline in Crohn's Disease Activity Index
(CDAI) over a duration of 6 weeks. Standard deviation of change
from baseline endpoint is approximately 88.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crohn
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 rows and 3 variables:
</p>

<dl>
<dt>study</dt><dd><p>study</p>
</dd>
<dt>n</dt><dd><p>study size</p>
</dd>
<dt>y</dt><dd><p>mean CDAI change</p>
</dd>
</dl>



<h3>References</h3>

<p>Hueber W. et. al, <em>Gut</em>, 2012, 61(12):1693-1700
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Setting up dummy sampling for fast execution of example
## Please use 4 chains and 20x more warmup &amp; iter in practice
.user_mc_options &lt;- options(RBesT.MC.warmup=50, RBesT.MC.iter=100,
                            RBesT.MC.chains=2, RBesT.MC.thin=1)

set.seed(546346)
map_crohn &lt;- gMAP(cbind(y, y.se) ~ 1 | study,
                  family=gaussian,
                  data=transform(crohn, y.se=88/sqrt(n)),
                  weights=n,
                  tau.dist="HalfNormal", tau.prior=44,
                  beta.prior=cbind(0,88))
## Recover user set sampling defaults
options(.user_mc_options)

</code></pre>

<hr>
<h2 id='Curry'>Functional programming utilities</h2><span id='topic+Curry'></span>

<h3>Description</h3>

<p>function from functional
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Curry(FUN, ...)
</code></pre>

<hr>
<h2 id='dBetaBinomial'>Beta-Binomial Probabilities</h2><span id='topic+dBetaBinomial'></span>

<h3>Description</h3>

<p>Beta-Binomial Probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBetaBinomial(r, n, a, b, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dBetaBinomial_+3A_r">r</code>, <code id="dBetaBinomial_+3A_n">n</code></td>
<td>
<p>number of successes (responders) out of n</p>
</td></tr>
<tr><td><code id="dBetaBinomial_+3A_a">a</code>, <code id="dBetaBinomial_+3A_b">b</code></td>
<td>
<p>parameters of the Beta distribution for response probability</p>
</td></tr>
</table>


<h3>Details</h3>

<p>r,n,a,b can be scalar or vectors. If vectors are used, they must be of the same length
</p>

<hr>
<h2 id='decision1S'>Decision Function for 1 Sample Designs</h2><span id='topic+decision1S'></span><span id='topic+oc1Sdecision'></span>

<h3>Description</h3>

<p>The function sets up a 1 sample one-sided decision function with an
arbitrary number of conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision1S(pc = 0.975, qc = 0, lower.tail = TRUE)

oc1Sdecision(pc = 0.975, qc = 0, lower.tail = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision1S_+3A_pc">pc</code></td>
<td>
<p>Vector of critical cumulative probabilities.</p>
</td></tr>
<tr><td><code id="decision1S_+3A_qc">qc</code></td>
<td>
<p>Vector of respective critical values. Must match the length of <code>pc</code>.</p>
</td></tr>
<tr><td><code id="decision1S_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are <code class="reqn">P(X \leq x)</code>, otherwise, <code class="reqn">P(X &gt; x)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates a one-sided decision function which
takes two arguments. The first argument is expected to be a mixture
(posterior) distribution. This distribution is tested whether it
fulfills all the required threshold conditions specified with the
<code>pc</code> and <code>qc</code> arguments and returns 1 if all conditions
are met and 0 otherwise. Hence, for <code>lower.tail=TRUE</code>
condition <code class="reqn">i</code> is equivalent to
</p>
<p style="text-align: center;"><code class="reqn">P(\theta \leq q_{c,i}) &gt; p_{c,i}</code>
</p>

<p>and the decision function is implemented as indicator function on
the basis of the heavy-side step function <code class="reqn">H(x)</code> which is <code class="reqn">0</code>
for <code class="reqn">x \leq 0</code> and <code class="reqn">1</code> for <code class="reqn">x &gt; 0</code>. As all conditions
must be met, the final indicator function returns
</p>
<p style="text-align: center;"><code class="reqn">\Pi_i H_i(P(\theta \leq q_{c,i}) - p_{c,i} ).</code>
</p>

<p>When the second argument is set to <code>TRUE</code> a distance metric is
returned component-wise per defined condition as
</p>
<p style="text-align: center;"><code class="reqn"> D_i = \log(P(\theta &lt; q_{c,i})) - \log(p_{c,i}) .</code>
</p>

<p>These indicator functions can be used as input for 1-sample
boundary, OC or PoS calculations using <code><a href="#topic+oc1S">oc1S</a></code> or
<code><a href="#topic+pos1S">pos1S</a></code> .
</p>


<h3>Value</h3>

<p>The function returns a decision function which takes two
arguments. The first argument is expected to be a mixture
(posterior) distribution which is tested if the specified
conditions are met. The logical second argument determines if the
function acts as an indicator function or if the function returns
the distance from the decision boundary for each condition in
log-space, i.e. the distance is 0 at the decision boundary,
negative for a 0 decision and positive for a 1 decision.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>oc1Sdecision()</code>: Deprecated old function name. Please use
<code>decision1S</code> instead.
</p>
</li></ul>


<h3>References</h3>

<p>Neuenschwander B, Rouyrre N, Hollaender H, Zuber E,
Branson M. A proof of concept phase II non-inferiority
criterion. <em>Stat. in Med.</em>. 2011, 30:1618-1627
</p>


<h3>See Also</h3>

<p>Other design1S: 
<code><a href="#topic+decision1S_boundary">decision1S_boundary</a>()</code>,
<code><a href="#topic+oc1S">oc1S</a>()</code>,
<code><a href="#topic+pos1S">pos1S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# see Neuenschwander et al., 2011

# example is for a time-to-event trial evaluating non-inferiority
# using a normal approximation for the log-hazard ratio

# reference scale
s &lt;- 2
theta_ni &lt;- 0.4
theta_a &lt;- 0
alpha &lt;- 0.05
beta  &lt;- 0.2
za &lt;- qnorm(1-alpha)
zb &lt;- qnorm(1-beta)
n1 &lt;- round( (s * (za + zb)/(theta_ni - theta_a))^2 )  # n for which design was intended
nL &lt;- 233
c1 &lt;- theta_ni - za * s / sqrt(n1)

# flat prior
flat_prior &lt;- mixnorm(c(1,0,100), sigma=s)

# standard NI design
decA &lt;- decision1S(1 - alpha, theta_ni, lower.tail=TRUE)

# for double criterion with indecision point (mean estimate must be
# lower than this)
theta_c &lt;- c1

# double criterion design
# statistical significance (like NI design)
dec1 &lt;- decision1S(1-alpha, theta_ni, lower.tail=TRUE)
# require mean to be at least as good as theta_c
dec2 &lt;- decision1S(0.5, theta_c, lower.tail=TRUE)
# combination
decComb &lt;- decision1S(c(1-alpha, 0.5), c(theta_ni, theta_c), lower.tail=TRUE)

theta_eval  &lt;- c(theta_a, theta_c, theta_ni)

# we can display the decision function definition
decComb

# and use it to decide if a given distribution fulfills all
# criterions defined
# for the prior
decComb(flat_prior)
# or for a possible outcome of the trial
# here with HR of 0.8 for 40 events
decComb(postmix(flat_prior, m=log(0.8), n=40))


</code></pre>

<hr>
<h2 id='decision1S_boundary'>Decision Boundary for 1 Sample Designs</h2><span id='topic+decision1S_boundary'></span><span id='topic+decision1S_boundary.betaMix'></span><span id='topic+decision1S_boundary.normMix'></span><span id='topic+decision1S_boundary.gammaMix'></span>

<h3>Description</h3>

<p>Calculates the decision boundary for a 1 sample design. This is the
critical value at which the decision function will change from 0
(failure) to 1 (success).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision1S_boundary(prior, n, decision, ...)

## S3 method for class 'betaMix'
decision1S_boundary(prior, n, decision, ...)

## S3 method for class 'normMix'
decision1S_boundary(prior, n, decision, sigma, eps = 1e-06, ...)

## S3 method for class 'gammaMix'
decision1S_boundary(prior, n, decision, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision1S_boundary_+3A_prior">prior</code></td>
<td>
<p>Prior for analysis.</p>
</td></tr>
<tr><td><code id="decision1S_boundary_+3A_n">n</code></td>
<td>
<p>Sample size for the experiment.</p>
</td></tr>
<tr><td><code id="decision1S_boundary_+3A_decision">decision</code></td>
<td>
<p>One-sample decision function to use; see <code><a href="#topic+decision1S">decision1S</a></code>.</p>
</td></tr>
<tr><td><code id="decision1S_boundary_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="decision1S_boundary_+3A_sigma">sigma</code></td>
<td>
<p>The fixed reference scale. If left unspecified, the
default reference scale of the prior is assumed.</p>
</td></tr>
<tr><td><code id="decision1S_boundary_+3A_eps">eps</code></td>
<td>
<p>Support of random variables are determined as the
interval covering <code>1-eps</code> probability mass. Defaults to
<code class="reqn">10^{-6}</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specification of the 1 sample design (prior, sample
size and decision function, <code class="reqn">D(y)</code>), uniquely defines the
decision boundary
</p>
<p style="text-align: center;"><code class="reqn">y_c = \max_y\{D(y) = 1\},</code>
</p>

<p>which is the maximal value of <code class="reqn">y</code> whenever the decision <code class="reqn">D(y)</code>
function changes its value from 1 to 0 for a decision function
with <code>lower.tail=TRUE</code> (otherwise the definition is <code class="reqn">y_c =
\max_{y}\{D(y) = 0\}</code>). The decision
function may change at most at a single critical value as only
one-sided decision functions are supported. Here,
<code class="reqn">y</code> is defined for binary and Poisson endpoints as the sufficient
statistic <code class="reqn">y = \sum_{i=1}^{n} y_i</code> and for the normal
case as the mean <code class="reqn">\bar{y} = 1/n \sum_{i=1}^n y_i</code>.
</p>
<p>The convention for the critical value <code class="reqn">y_c</code> depends on whether
a left (<code>lower.tail=TRUE</code>) or right-sided decision function
(<code>lower.tail=FALSE</code>) is used. For <code>lower.tail=TRUE</code> the
critical value <code class="reqn">y_c</code> is the largest value for which the
decision is 1, <code class="reqn">D(y \leq y_c) = 1</code>, while for
<code>lower.tail=FALSE</code> then <code class="reqn">D(y &gt; y_c) = 1</code> holds. This is
aligned with the cumulative density function definition within R
(see for example <code><a href="stats.html#topic+pbinom">pbinom</a></code>).
</p>


<h3>Value</h3>

<p>Returns the critical value <code class="reqn">y_c</code>.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>decision1S_boundary(betaMix)</code>: Applies for binomial model with a mixture
beta prior. The calculations use exact expressions.
</p>
</li>
<li> <p><code>decision1S_boundary(normMix)</code>: Applies for the normal model with known
standard deviation <code class="reqn">\sigma</code> and a normal mixture prior for the
mean. As a consequence from the assumption of a known standard
deviation, the calculation discards sampling uncertainty of the
second moment. The function <code>decision1S_boundary</code> has an extra
argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>). The critical value
<code class="reqn">y_c</code> is searched in the region of probability mass
<code>1-eps</code> for <code class="reqn">y</code>.
</p>
</li>
<li> <p><code>decision1S_boundary(gammaMix)</code>: Applies for the Poisson model with a gamma
mixture prior for the rate parameter.  The function
<code>decision1S_boundary</code> takes an extra argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>)
which determines the region of probability mass <code>1-eps</code> where
the boundary is searched for <code class="reqn">y</code>.
</p>
</li></ul>


<h3>See Also</h3>

<p>Other design1S: 
<code><a href="#topic+decision1S">decision1S</a>()</code>,
<code><a href="#topic+oc1S">oc1S</a>()</code>,
<code><a href="#topic+pos1S">pos1S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# non-inferiority example using normal approximation of log-hazard
# ratio, see ?decision1S for all details
s &lt;- 2
flat_prior &lt;- mixnorm(c(1,0,100), sigma=s)
nL &lt;- 233
theta_ni &lt;- 0.4
theta_a &lt;- 0
alpha &lt;- 0.05
beta  &lt;- 0.2
za &lt;- qnorm(1-alpha)
zb &lt;- qnorm(1-beta)
n1 &lt;- round( (s * (za + zb)/(theta_ni - theta_a))^2 )
theta_c &lt;- theta_ni - za * s / sqrt(n1)

# double criterion design
# statistical significance (like NI design)
dec1 &lt;- decision1S(1-alpha, theta_ni, lower.tail=TRUE)
# require mean to be at least as good as theta_c
dec2 &lt;- decision1S(0.5, theta_c, lower.tail=TRUE)
# combination
decComb &lt;- decision1S(c(1-alpha, 0.5), c(theta_ni, theta_c), lower.tail=TRUE)

# critical value of double criterion design
decision1S_boundary(flat_prior, nL, decComb)

# ... is limited by the statistical significance ...
decision1S_boundary(flat_prior, nL, dec1)

# ... or the indecision point (whatever is smaller)
decision1S_boundary(flat_prior, nL, dec2)

</code></pre>

<hr>
<h2 id='decision2S'>Decision Function for 2 Sample Designs</h2><span id='topic+decision2S'></span><span id='topic+oc2Sdecision'></span>

<h3>Description</h3>

<p>The function sets up a 2 sample one-sided decision function with an
arbitrary number of conditions on the difference distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision2S(
  pc = 0.975,
  qc = 0,
  lower.tail = TRUE,
  link = c("identity", "logit", "log")
)

oc2Sdecision(
  pc = 0.975,
  qc = 0,
  lower.tail = TRUE,
  link = c("identity", "logit", "log")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision2S_+3A_pc">pc</code></td>
<td>
<p>Vector of critical cumulative probabilities of the
difference distribution.</p>
</td></tr>
<tr><td><code id="decision2S_+3A_qc">qc</code></td>
<td>
<p>Vector of respective critical values of the difference
distribution. Must match the length of <code>pc</code>.</p>
</td></tr>
<tr><td><code id="decision2S_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are <code class="reqn">P(X \leq x)</code>, otherwise, <code class="reqn">P(X &gt; x)</code>.</p>
</td></tr>
<tr><td><code id="decision2S_+3A_link">link</code></td>
<td>
<p>Enables application of a link function prior to
evaluating the difference distribution. Can take one of the values
<code>identity</code> (default), <code>logit</code> or <code>log</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a one-sided decision function on the
basis of the difference distribution in a 2 sample situation. To
support double criterion designs, see <em>Neuenschwander et al.,
2010</em>, an arbitrary number of criterions can be given. The decision
function demands that the probability mass below the critical value
<code>qc</code> of the difference <code class="reqn">\theta_1 - \theta_2</code> is at least
<code>pc</code>. Hence, for <code>lower.tail=TRUE</code> condition <code class="reqn">i</code> is
equivalent to
</p>
<p style="text-align: center;"><code class="reqn">P(\theta_1 - \theta_2 \leq q_{c,i}) &gt; p_{c,i}</code>
</p>

<p>and the decision function is implemented as indicator function
using the heavy-side step function <code class="reqn">H(x)</code> which is <code class="reqn">0</code> for
<code class="reqn">x \leq 0</code> and <code class="reqn">1</code> for <code class="reqn">x &gt; 0</code>. As all conditions must
be met, the final indicator function returns
</p>
<p style="text-align: center;"><code class="reqn">\Pi_i H_i(P(\theta_1 - \theta_2 \leq q_{c,i}) - p_{c,i} ),</code>
</p>

<p>which is <code class="reqn">1</code> if all conditions are met and <code class="reqn">0</code>
otherwise. For <code>lower.tail=FALSE</code> differences must be greater
than the given quantiles <code>qc</code>.
</p>
<p>Note that whenever a <code>link</code> other than <code>identity</code> is
requested, then the underlying densities are first transformed
using the link function and then the probabilties for the
differences are calculated in the transformed space. Hence, for a
binary endpoint the default <code>identity</code> link will calculate
risk differences, the <code>logit</code> link will lead to decisions
based on the differences in <code>logit</code>s corresponding to a
criterion based on the log-odds. The <code>log</code> link will evaluate
ratios instead of absolute differences which could be useful for a
binary endpoint or counting rates. The respective critical
quantiles <code>qc</code> must be given on the transformed scale.
</p>


<h3>Value</h3>

<p>The function returns a decision function which takes three
arguments. The first and second argument are expected to be mixture
(posterior) distributions from which the difference distribution is
formed and all conditions are tested. The third argument determines
if the function acts as an indicator function or if the function
returns the distance from the decision boundary for each condition
in log-space. That is, the distance is 0 at the decision boundary,
negative for a 0 decision and positive for a 1 decision.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>oc2Sdecision()</code>: Deprecated old function name. Please use
<code>decision2S</code> instead.
</p>
</li></ul>


<h3>References</h3>

<p>Gsponer T, Gerber F, Bornkamp B, Ohlssen D,
Vandemeulebroecke M, Schmidli H.A practical guide to Bayesian group
sequential designs. <em>Pharm. Stat.</em>. 2014; 13: 71-80
</p>


<h3>See Also</h3>

<p>Other design2S: 
<code><a href="#topic+decision2S_boundary">decision2S_boundary</a>()</code>,
<code><a href="#topic+oc2S">oc2S</a>()</code>,
<code><a href="#topic+pos2S">pos2S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# see Gsponer et al., 2010
priorT &lt;- mixnorm(c(1,   0, 0.001), sigma=88, param="mn")
priorP &lt;- mixnorm(c(1, -49, 20   ), sigma=88, param="mn")
# the success criteria is for delta which are larger than some
# threshold value which is why we set lower.tail=FALSE
successCrit  &lt;- decision2S(c(0.95, 0.5), c(0, 50), FALSE)
# the futility criterion acts in the opposite direction
futilityCrit &lt;- decision2S(c(0.90)     , c(40),    TRUE)

print(successCrit)
print(futilityCrit)

# consider decision for specific outcomes
postP_interim &lt;- postmix(priorP, n=10, m=-50)
postT_interim &lt;- postmix(priorT, n=20, m=-80)
futilityCrit( postP_interim, postT_interim )
successCrit(  postP_interim, postT_interim )

# Binary endpoint with double criterion decision on log-odds scale
# 95% certain positive difference and an odds ratio of 2 at least
decL2 &lt;- decision2S(c(0.95, 0.5), c(0, log(2)), lower.tail=FALSE, link="logit")
# 95% certain positive difference and an odds ratio of 3 at least
decL3 &lt;- decision2S(c(0.95, 0.5), c(0, log(3)), lower.tail=FALSE, link="logit")

# data scenario
post1 &lt;- postmix(mixbeta(c(1, 1, 1)), n=40, r=10)
post2 &lt;- postmix(mixbeta(c(1, 1, 1)), n=40, r=18)

# positive outcome and a median odds ratio of at least 2 ...
decL2(post2, post1)
# ... but not more than 3
decL3(post2, post1)

</code></pre>

<hr>
<h2 id='decision2S_boundary'>Decision Boundary for 2 Sample Designs</h2><span id='topic+decision2S_boundary'></span><span id='topic+decision2S_boundary.betaMix'></span><span id='topic+decision2S_boundary.normMix'></span><span id='topic+decision2S_boundary.gammaMix'></span>

<h3>Description</h3>

<p>The <code>decision2S_boundary</code> function defines a 2 sample design
(priors, sample sizes, decision function) for the calculation of
the decision boundary. A function is returned which calculates the
critical value of the first sample <code class="reqn">y_{1,c}</code> as a function of
the outcome in the second sample <code class="reqn">y_2</code>. At the decision
boundary, the decision function will change between 0 (failure) and
1 (success) for the respective outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision2S_boundary(prior1, prior2, n1, n2, decision, ...)

## S3 method for class 'betaMix'
decision2S_boundary(prior1, prior2, n1, n2, decision, eps, ...)

## S3 method for class 'normMix'
decision2S_boundary(
  prior1,
  prior2,
  n1,
  n2,
  decision,
  sigma1,
  sigma2,
  eps = 1e-06,
  Ngrid = 10,
  ...
)

## S3 method for class 'gammaMix'
decision2S_boundary(prior1, prior2, n1, n2, decision, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision2S_boundary_+3A_prior1">prior1</code></td>
<td>
<p>Prior for sample 1.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_prior2">prior2</code></td>
<td>
<p>Prior for sample 2.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_n1">n1</code>, <code id="decision2S_boundary_+3A_n2">n2</code></td>
<td>
<p>Sample size of the respective samples. Sample size <code>n1</code> must be greater than 0 while sample size <code>n2</code> must be greater or equal to 0.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_decision">decision</code></td>
<td>
<p>Two-sample decision function to use; see <code><a href="#topic+decision2S">decision2S</a></code>.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_eps">eps</code></td>
<td>
<p>Support of random variables are determined as the
interval covering <code>1-eps</code> probability mass. Defaults to
<code class="reqn">10^{-6}</code>.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_sigma1">sigma1</code></td>
<td>
<p>The fixed reference scale of sample 1. If left
unspecified, the default reference scale of the prior 1 is assumed.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_sigma2">sigma2</code></td>
<td>
<p>The fixed reference scale of sample 2. If left
unspecified, the default reference scale of the prior 2 is assumed.</p>
</td></tr>
<tr><td><code id="decision2S_boundary_+3A_ngrid">Ngrid</code></td>
<td>
<p>Determines density of discretization grid on which
decision function is evaluated (see below for more details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a 2 sample design the specification of the priors, the
sample sizes and the decision function, <code class="reqn">D(y_1,y_2)</code>, uniquely
defines the decision boundary
</p>
<p style="text-align: center;"><code class="reqn">D_1(y_2) = \max_{y_1}\{D(y_1,y_2) = 1\},</code>
</p>

<p>which is the critical value of <code class="reqn">y_{1,c}</code> conditional on the
value of <code class="reqn">y_2</code> whenever the decision <code class="reqn">D(y_1,y_2)</code> function
changes its value from 0 to 1 for a decision function with
<code>lower.tail=TRUE</code> (otherwise the definition is <code class="reqn">D_1(y_2) =
\max_{y_1}\{D(y_1,y_2) = 0\}</code>). The decision function may change at most at a single critical
value for given <code class="reqn">y_{2}</code> as only one-sided decision functions
are supported. Here, <code class="reqn">y_2</code> is defined for binary and Poisson
endpoints as the sufficient statistic <code class="reqn">y_2 = \sum_{i=1}^{n_2}
y_{2,i}</code> and for the normal case as the mean <code class="reqn">\bar{y}_2 = 1/n_2
\sum_{i=1}^{n_2} y_{2,i}</code>.
</p>


<h3>Value</h3>

<p>Returns a function with a single argument. This function
calculates in dependence of the outcome <code class="reqn">y_2</code> in sample 2 the
critical value <code class="reqn">y_{1,c}</code> for which the defined design will
change the decision from 0 to 1 (or vice versa, depending on the
decision function).
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>decision2S_boundary(betaMix)</code>: Applies for binomial model with a mixture
beta prior. The calculations use exact expressions.  If the
optional argument <code>eps</code> is defined, then an approximate method
is used which limits the search for the decision boundary to the
region of <code>1-eps</code> probability mass. This is useful for designs
with large sample sizes where an exact approach is very costly to
calculate.
</p>
</li>
<li> <p><code>decision2S_boundary(normMix)</code>: Applies for the normal model with known
standard deviation <code class="reqn">\sigma</code> and normal mixture priors for the
means. As a consequence from the assumption of a known standard
deviation, the calculation discards sampling uncertainty of the
second moment. The function has two extra arguments (with
defaults): <code>eps</code> (<code class="reqn">10^{-6}</code>) and <code>Ngrid</code> (10). The
decision boundary is searched in the region of probability mass
<code>1-eps</code>, respectively for <code class="reqn">y_1</code> and <code class="reqn">y_2</code>. The
continuous decision function is evaluated at a discrete grid, which
is determined by a spacing with <code class="reqn">\delta_2 =
\sigma_2/\sqrt{N_{grid}}</code>. Once the decision boundary is evaluated
at the discrete steps, a spline is used to inter-polate the
decision boundary at intermediate points.
</p>
</li>
<li> <p><code>decision2S_boundary(gammaMix)</code>: Applies for the Poisson model with a gamma
mixture prior for the rate parameter.  The function
<code>decision2S_boundary</code> takes an extra argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>) which
determines the region of probability mass <code>1-eps</code> where the
boundary is searched for <code class="reqn">y_1</code> and <code class="reqn">y_2</code>, respectively.
</p>
</li></ul>


<h3>See Also</h3>

<p>Other design2S: 
<code><a href="#topic+decision2S">decision2S</a>()</code>,
<code><a href="#topic+oc2S">oc2S</a>()</code>,
<code><a href="#topic+pos2S">pos2S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# see ?decision2S for details of example
priorT &lt;- mixnorm(c(1,   0, 0.001), sigma=88, param="mn")
priorP &lt;- mixnorm(c(1, -49, 20   ), sigma=88, param="mn")
# the success criteria is for delta which are larger than some
# threshold value which is why we set lower.tail=FALSE
successCrit  &lt;- decision2S(c(0.95, 0.5), c(0, 50), FALSE)
# the futility criterion acts in the opposite direction
futilityCrit &lt;- decision2S(c(0.90)     , c(40),    TRUE)

# success criterion boundary
successBoundary &lt;- decision2S_boundary(priorP, priorT, 10, 20, successCrit)

# futility criterion boundary
futilityBoundary &lt;- decision2S_boundary(priorP, priorT, 10, 20, futilityCrit)

curve(successBoundary(x), -25:25 - 49, xlab="y2", ylab="critical y1")
curve(futilityBoundary(x), lty=2, add=TRUE)

# hence, for mean in sample 2 of 10, the critical value for y1 is
y1c &lt;- futilityBoundary(-10)

# around the critical value the decision for futility changes
futilityCrit(postmix(priorP, m=y1c+1E-3, n=10), postmix(priorT, m=-10, n=20))
futilityCrit(postmix(priorP, m=y1c-1E-3, n=10), postmix(priorT, m=-10, n=20))

</code></pre>

<hr>
<h2 id='dlink+26lt+3B-'>Transform Densities with a link function</h2><span id='topic+dlink+3C-'></span>

<h3>Description</h3>

<p>One-to-one transforms (mixture) of densities using a link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlink(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dlink+2B26lt+2B3B-_+3A_object">object</code></td>
<td>
<p>Mixture density to apply link to.</p>
</td></tr>
<tr><td><code id="dlink+2B26lt+2B3B-_+3A_value">value</code></td>
<td>
<p>Link.
</p>
<p>Note: link functions are assumed to be order preserving, i.e. if
x_1 &lt; x_2 holds, then link(x_1) &lt; link(x_2).</p>
</td></tr>
</table>

<hr>
<h2 id='ess'>Effective Sample Size for a Conjugate Prior</h2><span id='topic+ess'></span><span id='topic+ess.betaMix'></span><span id='topic+ess.gammaMix'></span><span id='topic+ess.normMix'></span>

<h3>Description</h3>

<p>Calculates the Effective Sample Size (ESS) for a mixture prior. The
ESS indicates how many experimental units the prior is roughly
equivalent to.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ess(mix, method = c("elir", "moment", "morita"), ...)

## S3 method for class 'betaMix'
ess(mix, method = c("elir", "moment", "morita"), ..., s = 100)

## S3 method for class 'gammaMix'
ess(mix, method = c("elir", "moment", "morita"), ..., s = 100, eps = 1e-04)

## S3 method for class 'normMix'
ess(mix, method = c("elir", "moment", "morita"), ..., sigma, s = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ess_+3A_mix">mix</code></td>
<td>
<p>Prior (mixture of conjugate distributions).</p>
</td></tr>
<tr><td><code id="ess_+3A_method">method</code></td>
<td>
<p>Selects the used method. Can be either <code>elir</code>
(default), <code>moment</code> or <code>morita</code>.</p>
</td></tr>
<tr><td><code id="ess_+3A_...">...</code></td>
<td>
<p>Optional arguments applicable to specific methods.</p>
</td></tr>
<tr><td><code id="ess_+3A_s">s</code></td>
<td>
<p>For <code>morita</code> method large constant to ensure that the
prior scaled by this value is vague (default 100); see Morita
et al. (2008) for details.</p>
</td></tr>
<tr><td><code id="ess_+3A_eps">eps</code></td>
<td>
<p>Probability mass left out from the numerical integration
of the expected information for the Poisson-Gamma case of
Morita method (defaults to 1E-4).</p>
</td></tr>
<tr><td><code id="ess_+3A_sigma">sigma</code></td>
<td>
<p>reference scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ESS is calculated using either the expected local
information ratio (elir) <em>Neuenschwander et
al. (submitted)</em>, the moments approach or the method by
<em>Morita et al. (2008)</em>.
</p>
<p>The elir approach is the only ESS which fulfills predictive
consistency. The predictive consistency of the ESS requires that
the ESS of a prior is the same as averaging the posterior ESS after
a fixed amount of events over the prior predictive distribution
from which the number of forward simulated events is
subtracted. The elir approach results in ESS estimates which are
neither conservative nor liberal whereas the moments method yields
conservative and the morita method liberal results. See the example
section for a demonstration of predictive consistency.
</p>
<p>For the moments method the mean and standard deviation of the
mixture are calculated and then approximated by the conjugate
distribution with the same mean and standard deviation. For
conjugate distributions, the ESS is well defined. See the examples
for a step-wise calculation in the beta mixture case.
</p>
<p>The Morita method used here evaluates the mixture prior at the mode
instead of the mean as proposed originally by Morita. The method
may lead to very optimistic ESS values, especially if the mixture
contains many components. The calculation of the Morita approach
here follows the approach presented in Neuenschwander B. et all
(2019) which avoids the need for a minimization and does not
restrict the ESS to be an integer.
</p>


<h3>Value</h3>

<p>Returns the ESS of the prior as floating point number.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>ess(betaMix)</code>: ESS for beta mixtures.
</p>
</li>
<li> <p><code>ess(gammaMix)</code>: ESS for gamma mixtures.
</p>
</li>
<li> <p><code>ess(normMix)</code>: ESS for normal mixtures.
</p>
</li></ul>


<h3>Supported Conjugate Prior-Likelihood Pairs</h3>


<table>
<tr>
 <td style="text-align: left;">
<strong>Prior/Posterior</strong> </td><td style="text-align: center;"> <strong>Likelihood</strong> </td><td style="text-align: center;"> <strong>Predictive</strong> 
 </td><td style="text-align: center;"> <strong>Summaries</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
Beta </td><td style="text-align: center;"> Binomial </td><td style="text-align: center;"> Beta-Binomial </td><td style="text-align: center;"> <code>n</code>, <code>r</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Normal </td><td style="text-align: center;"> Normal (<em>fixed <code class="reqn">\sigma</code></em>) </td><td style="text-align: center;"> Normal </td><td style="text-align: center;"> <code>n</code>, <code>m</code>, <code>se</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Poisson </td><td style="text-align: center;"> Gamma-Poisson </td><td style="text-align: center;">  <code>n</code>, <code>m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Exponential </td><td style="text-align: center;"> Gamma-Exp (<em>not supported</em>) </td><td style="text-align: center;"> <code>n</code>, <code>m</code>
</td>
</tr>

</table>



<h3>References</h3>

<p>Morita S, Thall PF, Mueller P.
Determining the effective sample size of a parametric prior.
<em>Biometrics</em> 2008;64(2):595-602.
</p>
<p>Neuenschwander B, Weber S, Schmidli H, O'Hagen A.
Predictively Consistent Prior Effective Sample Sizes.
<em>pre-print</em> 2019; arXiv:1907.04185
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Conjugate Beta example
a &lt;- 5
b &lt;- 15
prior &lt;- mixbeta(c(1, a, b))

ess(prior)
(a+b)

# Beta mixture example
bmix &lt;- mixbeta(rob=c(0.2, 1, 1), inf=c(0.8, 10, 2))

ess(bmix, "elir")

ess(bmix, "moment")
# moments method is equivalent to
# first calculate moments
bmix_sum &lt;- summary(bmix)
# then calculate a and b of a matching beta
ab_matched &lt;- ms2beta(bmix_sum["mean"], bmix_sum["sd"])
# finally take the sum of a and b which are equivalent
# to number of responders/non-responders respectivley
round(sum(ab_matched))

ess(bmix, method="morita")

# Predictive consistency of elir

n_forward &lt;- 1E2
bmixPred &lt;- preddist(bmix, n=n_forward)
pred_samp &lt;- rmix(bmixPred, 1E3)
pred_ess &lt;- sapply(pred_samp, function(r) ess(postmix(bmix, r=r, n=n_forward), "elir") )
ess(bmix, "elir")
mean(pred_ess) - n_forward


# Normal mixture example
nmix &lt;- mixnorm(rob=c(0.5, 0, 2), inf=c(0.5, 3, 4), sigma=10)

ess(nmix, "elir")

ess(nmix, "moment")

## the reference scale determines the ESS
sigma(nmix) &lt;- 20
ess(nmix)

# Gamma mixture example
gmix &lt;- mixgamma(rob=c(0.3, 20, 4), inf=c(0.7, 50, 10))

ess(gmix) ## interpreted as appropriate for a Poisson likelihood (default)

likelihood(gmix) &lt;- "exp"
ess(gmix) ## interpreted as appropriate for an exponential likelihood


</code></pre>

<hr>
<h2 id='fill'>Fill numeric objects</h2><span id='topic+fill'></span>

<h3>Description</h3>

<p>Returns the numeric input object with the value given and respects
dimensionalty and type of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fill(x, value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fill_+3A_x">x</code></td>
<td>
<p>Input numeric object.</p>
</td></tr>
<tr><td><code id="fill_+3A_value">value</code></td>
<td>
<p>Value filled.</p>
</td></tr>
</table>

<hr>
<h2 id='forest_plot'>Forest Plot</h2><span id='topic+forest_plot'></span>

<h3>Description</h3>

<p>Creates a forest plot for <code><a href="#topic+gMAP">gMAP</a></code> analysis objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forest_plot(
  x,
  prob = 0.95,
  est = c("both", "MAP", "Mean", "none"),
  model = c("stratified", "both", "meta"),
  point_est = c("median", "mean"),
  size = 1.25,
  alpha = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forest_plot_+3A_x">x</code></td>
<td>
<p><code><a href="#topic+gMAP">gMAP</a></code> object.</p>
</td></tr>
<tr><td><code id="forest_plot_+3A_prob">prob</code></td>
<td>
<p>confidence interval width and probability mass of credible intervals.</p>
</td></tr>
<tr><td><code id="forest_plot_+3A_est">est</code></td>
<td>
<p>can be set to one of <code>both</code> (default), <code>MAP</code>, <code>Mean</code> or <code>none</code>. Controls which model estimates are to be included.</p>
</td></tr>
<tr><td><code id="forest_plot_+3A_model">model</code></td>
<td>
<p>controls which estimates are displayed per study. Either <code>stratified</code> (default), <code>both</code> or <code>meta</code>.</p>
</td></tr>
<tr><td><code id="forest_plot_+3A_point_est">point_est</code></td>
<td>
<p>shown point estimate. Either <code>median</code> (default) or <code>mean</code>.</p>
</td></tr>
<tr><td><code id="forest_plot_+3A_size">size</code></td>
<td>
<p>controls point and linesize.</p>
</td></tr>
<tr><td><code id="forest_plot_+3A_alpha">alpha</code></td>
<td>
<p>transparency of reference line. Setting <code>alpha=0</code>
suppresses the reference line.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates a forest plot suitable for
<code><a href="#topic+gMAP">gMAP</a></code> analyses. Note that the Meta-Analytic-Predictive
prior is included by default in the plot as opposed to only showing
the estimated model mean. See the examples below to obtain standard
forest plots.
</p>
<p>Also note that the plot internally flips the x and
y-axis. Therefore, if you want to manipulate the x-axis, you have
to give commands affecting the y-axis (see examples).
</p>


<h3>Value</h3>

<p>The function returns a <span class="pkg">ggplot2</span> plot object.
</p>


<h3>Customizing <span class="pkg">ggplot2</span> plots</h3>

<p>The returned plot is a <span class="pkg">ggplot2</span> object. Please refer to the
&quot;Customizing Plots&quot; vignette which is part of <span class="pkg">RBesT</span>
documentation for an introduction. For simple modifications (change
labels, add reference lines, ...) consider the commands found in
<code><a href="bayesplot.html#topic+bayesplot-helpers">bayesplot-helpers</a></code>. For more advanced
customizations please use the <span class="pkg">ggplot2</span> package directly. A
description of the most common tasks can be found in the
<a href="http://www.cookbook-r.com/Graphs/">R Cookbook</a> and a full
reference of available commands can be found at the
<a href="https://ggplot2.tidyverse.org/reference/">ggplot2 documentation
site</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gMAP">gMAP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># we consider the example AS MAP analysis
example(AS)

# default forest plot for a gMAP analysis
forest_plot(map_AS)

# standard forest plot (only stratified estimate and Mean)
forest_plot(map_AS, est=c("Mean"), model="stratified")

# to further customize these plots, first load bayesplot and ggplot2
library(bayesplot)
library(ggplot2)

# to make plots with red colors, big fonts for presentations, suppress
# the x axis label and add another title (with a subtitle)
color_scheme_set("red")
theme_set(theme_default(base_size=16))
forest_plot(map_AS, size=2) +
   yaxis_title(FALSE) +
     ggtitle("Ankylosing Spondylitis Forest Plot",
             subtitle="Control Group Response Rate")

# the defaults are set with
color_scheme_set("blue")
theme_set(theme_default(base_size=12))

</code></pre>

<hr>
<h2 id='gMAP'>Meta-Analytic-Predictive Analysis for Generalized Linear Models</h2><span id='topic+gMAP'></span><span id='topic+print.gMAP'></span><span id='topic+fitted.gMAP'></span><span id='topic+coef.gMAP'></span><span id='topic+as.matrix.gMAP'></span><span id='topic+summary.gMAP'></span>

<h3>Description</h3>

<p>Meta-Analytic-Predictive (MAP) analysis for generalized linear
models suitable for normal, binary, or Poisson data. Model
specification and overall syntax follows mainly
<code><a href="stats.html#topic+glm">glm</a></code> conventions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gMAP(
  formula,
  family = gaussian,
  data,
  weights,
  offset,
  tau.strata,
  tau.dist = c("HalfNormal", "TruncNormal", "Uniform", "Gamma", "InvGamma", "LogNormal",
    "TruncCauchy", "Exp", "Fixed"),
  tau.prior,
  tau.strata.pred = 1,
  beta.prior,
  prior_PD = FALSE,
  REdist = c("normal", "t"),
  t.df = 5,
  contrasts = NULL,
  iter = getOption("RBesT.MC.iter", 6000),
  warmup = getOption("RBesT.MC.warmup", 2000),
  thin = getOption("RBesT.MC.thin", 4),
  init = getOption("RBesT.MC.init", 1),
  chains = getOption("RBesT.MC.chains", 4),
  cores = getOption("mc.cores", 1L)
)

## S3 method for class 'gMAP'
print(x, digits = 3, probs = c(0.025, 0.5, 0.975), ...)

## S3 method for class 'gMAP'
fitted(object, type = c("response", "link"), probs = c(0.025, 0.5, 0.975), ...)

## S3 method for class 'gMAP'
coef(object, probs = c(0.025, 0.5, 0.975), ...)

## S3 method for class 'gMAP'
as.matrix(x, ...)

## S3 method for class 'gMAP'
summary(
  object,
  type = c("response", "link"),
  probs = c(0.025, 0.5, 0.975),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gMAP_+3A_formula">formula</code></td>
<td>
<p>the model formula describing the linear predictor
and encoding the grouping; see details</p>
</td></tr>
<tr><td><code id="gMAP_+3A_family">family</code></td>
<td>
<p>the family of distributions defining the statistical
model (<code>binomial</code>, <code>gaussian</code>, or <code>poisson</code>)</p>
</td></tr>
<tr><td><code id="gMAP_+3A_data">data</code></td>
<td>
<p>optional data frame containing the variables of the
model. If not found in <code>data</code>, the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_weights">weights</code></td>
<td>
<p>optional weight vector; see details below.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_offset">offset</code></td>
<td>
<p>offset term in statistical model used for Poisson
data</p>
</td></tr>
<tr><td><code id="gMAP_+3A_tau.strata">tau.strata</code></td>
<td>
<p>sets the exchangability stratum per study. That
is, it is expected that each study belongs to a single
stratum. Default is to assign all studies to stratum 1. See section
differential heterogeniety below.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_tau.dist">tau.dist</code></td>
<td>
<p>type of prior distribution for <code>tau</code>;
supported priors are <code>HalfNormal</code> (default),
<code>TruncNormal</code>, <code>Uniform</code>, <code>Gamma</code>, <code>InvGamma</code>,
<code>LogNormal</code>, <code>TruncCauchy</code>, <code>Exp</code> and <code>Fixed</code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_tau.prior">tau.prior</code></td>
<td>
<p>parameters of prior distribution for <code>tau</code>;
see section prior specification below.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_tau.strata.pred">tau.strata.pred</code></td>
<td>
<p>the index for the prediction stratum; default is 1.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_beta.prior">beta.prior</code></td>
<td>
<p>mean and standard deviation for normal priors of
regression coefficients, see section prior specification below.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_prior_pd">prior_PD</code></td>
<td>
<p>logical to indicate if the prior predictive distribution should be sampled (no conditioning on the data). Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_redist">REdist</code></td>
<td>
<p>type of random effects distribution. <code>Normal</code> (default) or <code>t</code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_t.df">t.df</code></td>
<td>
<p>degrees of freedom if random-effects distribution is <code>t</code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list; See <code>contrasts.arg</code> from
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_iter">iter</code></td>
<td>
<p>number of iterations (including warmup).</p>
</td></tr>
<tr><td><code id="gMAP_+3A_warmup">warmup</code></td>
<td>
<p>number of warmup iterations.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_thin">thin</code></td>
<td>
<p>period of saving samples.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_init">init</code></td>
<td>
<p>positive number to specify uniform range on
unconstrained space for random initialization. See
<code><a href="rstan.html#topic+stan">stan</a></code>.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_chains">chains</code></td>
<td>
<p>number of Markov chains.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel sampling of chains.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_x">x</code>, <code id="gMAP_+3A_object">object</code></td>
<td>
<p><code>gMAP</code> analysis object created by <code>gMAP</code> function</p>
</td></tr>
<tr><td><code id="gMAP_+3A_digits">digits</code></td>
<td>
<p>number of displayed significant digits.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_probs">probs</code></td>
<td>
<p>defines quantiles to be reported.</p>
</td></tr>
<tr><td><code id="gMAP_+3A_...">...</code></td>
<td>
<p>optional arguments are ignored</p>
</td></tr>
<tr><td><code id="gMAP_+3A_type">type</code></td>
<td>
<p>sets reported scale (<code>response</code> (default) or <code>link</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The meta-analytic-predictive (MAP) approach derives a prior from
historical data using a hierarchical model.  The statistical model is
formulated as a generalized linear mixed model for binary, normal
(with fixed <code class="reqn">\sigma</code>) and Poisson endpoints:
</p>
<p style="text-align: center;"><code class="reqn">y_{ih}|\theta_{ih} \sim f(y_{ih} | \theta_{ih})</code>
</p>

<p>Here, <code class="reqn">i=1,\ldots,N</code> is the index for observations, and
<code class="reqn">h=1,\ldots,H</code> is the index for the grouping (usually studies).
The model assumes the linear predictor for a transformed mean as
</p>
<p style="text-align: center;"><code class="reqn">g(\theta_{ih}; x_{ih},\beta) = x_{ih} \, \beta + \epsilon_h</code>
</p>

<p>with <code class="reqn">x_{ih}</code> being the row vector of <code class="reqn">k</code> covariates for
observation <code class="reqn">i</code>.  The variance component is assumed by default
normal
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_h \sim N(0,\tau^2), \qquad h=1,\ldots,H</code>
</p>

<p>Lastly, the Bayesian implementation assumes independent normal
priors for the <code class="reqn">k</code> regression coefficients and a prior for the
between-group standard deviation <code class="reqn">\tau</code> (see <code>taud.dist</code>
for available distributions).
</p>
<p>The MAP prior will then be derived from the above model as the
conditional distribution of <code class="reqn">\theta_{\star}</code> given the
available data and the vector of covariates <code class="reqn">x_{\star}</code>
defining the overall intercept
</p>
<p style="text-align: center;"><code class="reqn">\theta_{\star}| x_{\star},y .</code>
</p>

<p>A simple and common case arises for one observation (summary
statistic) per trial. For a normal endpoint, the model then simplifies
to the standard normal-normal hierarchical model. In the above
notation, <code class="reqn">i=h=1,\ldots,H</code> and
</p>
<p style="text-align: center;"><code class="reqn">y_h|\theta_h \sim N(\theta_h,s_h^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\theta_h = \mu + \epsilon_h</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_h \sim N(0,\tau^2),</code>
</p>

<p>where the more common <code class="reqn">\mu</code> is used for the only (intercept)
parameter <code class="reqn">\beta_1</code>. Since there are no covariates, the MAP
prior is simply <code class="reqn">Pr(\theta_{\star} |
y_1,\ldots,y_H)</code>.
</p>
<p>The hierarchical model is a compromise between the two extreme
cases of full pooling (<code class="reqn">\tau=0</code>, full borrowing, no
discounting) and no pooling (<code class="reqn">\tau=\infty</code>, no borrowing,
stratification). The information content of the
historical data grows with H (number of historical data items)
indefinitely for full pooling whereas no information is
gained in a stratified analysis. For a fixed
<code class="reqn">\tau</code>, the maximum effective sample
size of the MAP prior is <code class="reqn">n_\infty</code> (<code class="reqn">H\rightarrow
\infty</code>), which for a normal endpoint with fixed
<code class="reqn">\sigma</code> is
</p>
<p style="text-align: center;"><code class="reqn">n_\infty = \left(\frac{\tau^2}{\sigma^2}\right)^{-1},</code>
</p>

<p>(<em>Neuenschwander et al., 2010</em>). Hence, the ratio
<code class="reqn">\tau/\sigma</code> limits the amount of information a MAP prior is
equivalent to. This allows for a classification of <code class="reqn">\tau</code>
values in relation to <code class="reqn">\sigma</code>, which is crucial to define a
prior <code class="reqn">P_\tau</code>. The following classification is useful in a
clinical trial setting:
</p>

<table>
<tr>
 <td style="text-align: left;">
Heterogeneity </td><td style="text-align: center;"> <code class="reqn">\tau/\sigma</code> </td><td style="text-align: center;"> <code class="reqn">n_\infty</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
small </td><td style="text-align: center;"> 0.0625 </td><td style="text-align: center;"> 256 </td>
</tr>
<tr>
 <td style="text-align: left;">
moderate </td><td style="text-align: center;"> 0.125 </td><td style="text-align: center;"> 64 </td>
</tr>
<tr>
 <td style="text-align: left;">
substantial </td><td style="text-align: center;"> 0.25 </td><td style="text-align: center;"> 16 </td>
</tr>
<tr>
 <td style="text-align: left;">
large </td><td style="text-align: center;"> 0.5 </td><td style="text-align: center;"> 4 </td>
</tr>
<tr>
 <td style="text-align: left;">
very large </td><td style="text-align: center;"> 1.0 </td><td style="text-align: center;"> 1
</td>
</tr>

</table>

<p>The above formula for <code class="reqn">n_\infty</code> assumes a known
<code class="reqn">\tau</code>. This is unrealistic as the between-trial heterogeneity
parameter is often not well estimable, in particular if the number
of trials is small (H small). The above table helps to specify a
prior distribution for <code class="reqn">\tau</code> appropriate for the given context
which defines the crucial parameter <code class="reqn">\sigma</code>. For binary and
Poisson endpoints, normal approximations can be used to determine
<code class="reqn">\sigma</code>. See examples below for concrete cases.
</p>
<p>The design matrix <code class="reqn">X</code> is defined by the formula for the linear
predictor and is always of the form <code>response ~ predictor |
grouping</code>, which follows <code><a href="stats.html#topic+glm">glm</a></code>
conventions. The syntax has been extended to include a
specification of the grouping (for example study) factor of the
data with a horizontal bar, <code>|</code>. The bar separates the
optionally specified grouping level, i.e. in the binary endpoint
case <code>cbind(r, n-r) ~ 1 | study</code>. By default it is assumed
that each row corresponds to an individual group (for which an
individual parameter is estimated). Specifics for the different
endpoints are:
</p>

<dl>
<dt>normal</dt><dd><p><code>family=gaussian</code> assumes an identity link
function. The <code>response</code> should be given as matrix with two
columns with the first column being the observed mean value
<code class="reqn">y_{ih}</code> and the second column the standard error
<code class="reqn">se_{ih}</code> (of the mean). Additionally, it is recommended
to specify with the <code>weight</code> argument the number of units
which contributed to the (mean) measurement
<code class="reqn">y_{ih}</code>. This information is used to estimate
<code class="reqn">\sigma</code>.</p>
</dd>
<dt>binary</dt><dd><p><code>family=binomial</code> assumes a logit link
function. The <code>response</code> must be given as two-column matrix
with number of responders <code class="reqn">r</code> (first column) and non-responders
<code class="reqn">n-r</code> (second column).</p>
</dd>
<dt>Poisson</dt><dd><p><code>family=poisson</code> assumes a log link
function. The <code>response</code> is a vector of counts. The total
exposure times can be specified by an <code>offset</code>, which will be
linearly added to the linear predictor. The <code>offset</code> can be
given as part of the formula, <code>y ~ 1 + offset(log(exposure))</code>
or as the <code>offset</code> argument to <code>gMAP</code>. Note that the
exposure unit must be given as log-offset.</p>
</dd>
</dl>



<h3>Value</h3>

<p>The function returns a S3 object of type <code>gMAP</code>. See
the methods section below for applicable functions to query the
object.
</p>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>print(gMAP)</code>: displays a summary of the gMAP analysis.
</p>
</li>
<li> <p><code>fitted(gMAP)</code>: returns the quantiles of the posterior shrinkage
estimates for each data item used during the analysis of the given
<code>gMAP</code> object.
</p>
</li>
<li> <p><code>coef(gMAP)</code>: returns the quantiles of the predictive
distribution. User can choose with <code>type</code> if the result is on
the response or the link scale.
</p>
</li>
<li> <p><code>as.matrix(gMAP)</code>: extracts the posterior sample of the model.
</p>
</li>
<li> <p><code>summary(gMAP)</code>: returns the summaries of a gMAP.
analysis. Output is a <code>gMAPsummary</code> object, which is a list containing
</p>

<dl>
<dt><code>tau</code></dt><dd><p>posterior summary of the heterogeneity standard deviation</p>
</dd>
<dt><code>beta</code></dt><dd><p>posterior summary of the regression coefficients</p>
</dd>
<dt><code>theta.pred</code></dt><dd><p>summary of the predictive distribution (given in dependence on the <code>type</code> argument either on <code>response</code> or <code>link</code> scale)</p>
</dd>
<dt><code>theta</code></dt><dd><p>posterior summary of the mean estimate (also depends on the <code>type</code> argument)</p>
</dd>
</dl>

</li></ul>


<h3>Differential Discounting</h3>

<p>The above model assumes the same between-group standard deviation
<code class="reqn">\tau</code>, which implies that the data are equally relevant. This
assumption can be relaxed to more than one <code class="reqn">\tau</code>. That is,
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_h \sim N(0,\tau_{s(h)}^2)</code>
</p>

<p>where <code class="reqn">s(h)</code> assignes group <code class="reqn">h</code> to one of <code class="reqn">S</code>
between-group heterogeneity strata.
</p>
<p>For example, in a situation with two randomized and four
observational studies, one may want to assume <code class="reqn">\tau_1</code> (for
trials 1 and 2) and <code class="reqn">\tau_2</code> (for trials 3-6) for the
between-trial standard deviations of the control means. More
heterogeneity (less relevance) for the observational studies can
then be expressed by appropriate priors for <code class="reqn">\tau_1</code> and
<code class="reqn">\tau_2</code>. In this case, <code class="reqn">S=2</code> and the strata assignments
(see <code>tau.strata</code> argument) would be <code class="reqn">s(1)=s(2)=1,
s(3)=\ldots=s(6)=2</code>.
</p>


<h3>Prior Specification</h3>

<p>The prior distribution for the regression coefficients <code class="reqn">\beta</code>
is normal.
</p>

<ul>
<li><p> If a single number is given, then this is used as the standard
deviation and the default mean of 0 is used.
</p>
</li>
<li><p> If a vector is given, it must be of the same length
as number of covariates defined and is used as standard
deviation.
</p>
</li>
<li><p> If a matrix with a single row is given, its first row will be
used as mean and the second row will be used as standard deviation
for all regression coefficients.
</p>
</li>
<li><p> Lastly, a two-column matrix (mean and standard deviation columns)
with as many columns as regression coefficients can be given.
</p>
</li></ul>

<p>It is recommended to always specify a <code>beta.prior</code>. Per
default a mean of 0 is set. The standard deviation is set to 2 for
the binary case, to 100 * <code>sd(y)</code> for the normal case and to
<code>sd(log(y + 0.5 + offset))</code> for the Poisson case.
</p>
<p>For the between-trial heterogeniety <code class="reqn">\tau</code> prior, a dispersion
parameter must always be given for each exchangeability
stratum. For the different <code>tau.prior</code> distributions, two
parameters are needed out of which one is set to a default value if
applicable:
</p>

<table>
<tr>
 <td style="text-align: left;">
Prior </td><td style="text-align: center;"> <code class="reqn">a</code> </td><td style="text-align: center;"> <code class="reqn">b</code> </td><td style="text-align: left;"> default </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>HalfNormal</code>  </td><td style="text-align: center;"> <code class="reqn">\mu = 0</code> </td><td style="text-align: center;">  <code class="reqn">\sigma</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TruncNormal</code> </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;">  <code class="reqn">\sigma</code> </td><td style="text-align: left;"> <code class="reqn">\mu = 0</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Uniform</code>     </td><td style="text-align: center;"> a </td><td style="text-align: center;"> b </td><td style="text-align: left;"> a = 0 </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Gamma</code>       </td><td style="text-align: center;"> <code class="reqn">\alpha</code> </td><td style="text-align: center;"> <code class="reqn">\beta</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>InvGamma</code>    </td><td style="text-align: center;"> <code class="reqn">\alpha</code> </td><td style="text-align: center;"> <code class="reqn">\beta</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>LogNormal</code>   </td><td style="text-align: center;"> <code class="reqn">\mu_{\log}</code> </td><td style="text-align: center;"> <code class="reqn">\sigma_{\log}</code> </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>TruncCauchy</code> </td><td style="text-align: center;"> <code class="reqn">\mu</code> </td><td style="text-align: center;"> <code class="reqn">\sigma</code> </td><td style="text-align: left;"> <code class="reqn">\mu = 0</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Exp</code>         </td><td style="text-align: center;"> <code class="reqn">\beta</code> </td><td style="text-align: center;"> 0 </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Fixed</code>       </td><td style="text-align: center;"> a </td><td style="text-align: center;"> 0 </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>For a prior distribution with a default location parameter, a
vector of length equal to the number of exchangability strata can
be given. Otherwise, a two-column matrix with as many rows as
exchangability strata must be given, except for a single <code class="reqn">\tau</code>
stratum, for which a vector of length two defines the parameters a
and b.
</p>


<h3>Random seed</h3>

<p>The MAP analysis is performed using
Markov-Chain-Monte-Carlo (MCMC) in <code><a href="rstan.html#topic+rstan">rstan</a></code>. MCMC
is a stochastic algorithm. To obtain exactly reproducible results
you must use the <code><a href="base.html#topic+set.seed">set.seed</a></code> function
before calling <code>gMAP</code>. See <code><a href="#topic+RBesT-package">RBesT</a></code>
overview page for global options on setting further MCMC simulation
parameters.
</p>


<h3>References</h3>

<p>Neuenschwander B, Capkun-Niggli G, Branson M,
Spiegelhalter DJ. Summarizing historical information on controls in
clinical trials. <em>Clin Trials</em>. 2010; 7(1):5-18
</p>
<p>Schmidli H, Gsteiger S, Roychoudhury S, O'Hagan A, Spiegelhalter D,
Neuenschwander B.  Robust meta-analytic-predictive priors in
clinical trials with historical control information.
<em>Biometrics</em> 2014;70(4):1023-1032.
</p>
<p>Weber S, Li Y, Seaman III J.W., Kakizume T, Schmidli H. Applying
Meta-Analytic Predictive Priors with the R Bayesian evidence
synthesis tools. <em>JSS</em> 2021; 100(19):1-32
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.gMAP">plot.gMAP</a></code>, <code><a href="#topic+forest_plot">forest_plot</a></code>, <code><a href="#topic+automixfit">automixfit</a></code>, <code><a href="#topic+predict.gMAP">predict.gMAP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Setting up dummy sampling for fast execution of example
## Please use 4 chains and 20x more warmup &amp; iter in practice
.user_mc_options &lt;- options(RBesT.MC.warmup=50, RBesT.MC.iter=100,
                            RBesT.MC.chains=2, RBesT.MC.thin=1)

# Binary data example 1

# Mean response rate is ~0.25. For binary endpoints
# a conservative choice for tau is a HalfNormal(0,1) as long as
# the mean response rate is in the range of 0.2 to 0.8. For
# very small or large rates consider the n_infinity approach
# illustrated below.
# for exact reproducible results, the seed must be set
set.seed(34563)
map_AS &lt;- gMAP(cbind(r, n-r) ~ 1 | study,
               family=binomial,
               data=AS,
               tau.dist="HalfNormal", tau.prior=1,
               beta.prior=2)
print(map_AS)

# obtain numerical summaries
map_sum &lt;- summary(map_AS)
print(map_sum)
names(map_sum)
# [1] "tau"        "beta"       "theta.pred" "theta"
map_sum$theta.pred


# graphical model checks (returns list of ggplot2 plots)
map_checks &lt;- plot(map_AS)
# forest plot with shrinkage estimates
map_checks$forest_model
# density of MAP prior on response scale
map_checks$densityThetaStar
# density of MAP prior on link scale
map_checks$densityThetaStarLink


# obtain shrinkage estimates
fitted(map_AS)

# regression coefficients
coef(map_AS)

# finally fit MAP prior with parametric mixture
map_mix &lt;- mixfit(map_AS, Nc=2)
plot(map_mix)$mix


# optionally select number of components automatically via AIC
map_automix &lt;- automixfit(map_AS)
plot(map_automix)$mix


# Normal example 2, see normal vignette

# Prior considerations

# The general principle to derive a prior for tau can be based on the
# n_infinity concept as discussed in Neuenschwander et al., 2010.
# This assumes a normal approximation which applies for the colitis
# data set as:
p_bar &lt;- mean(with(colitis, r/n))
s &lt;- round(1/sqrt(p_bar * (1-p_bar)), 1)
# s is the approximate sampling standard deviation and a
# conservative prior is tau ~ HalfNormal(0,s/2)
tau_prior_sd &lt;- s/2

# Evaluate HalfNormal prior for tau
tau_cat &lt;- c(pooling=0
            ,small=0.0625
            ,moderate=0.125
            ,substantial=0.25
            ,large=0.5
            ,veryLarge=1
            ,stratified=Inf)
# Interval probabilites (basically saying we are assuming
# heterogeniety to be smaller than very large)
diff(2*pnorm(tau_cat * s, 0, tau_prior_sd))
# Cumulative probabilities as 1-F
1 - 2*(pnorm(tau_cat * s, 0, tau_prior_sd) - 0.5)

## Recover user set sampling defaults
options(.user_mc_options)

</code></pre>

<hr>
<h2 id='integrate_density_log'>internal function used for integration of densities which appears
to be much more stable from -Inf to +Inf in the logit space while
the density to be integrated recieves inputs from 0 to 1 such that
the inverse distribution function must be used. The integral solved
is int_x dmix(mix,x) integrand(x) where integrand must be given as
log and we integrate over the support of mix.</h2><span id='topic+integrate_density_log'></span>

<h3>Description</h3>

<p>integrate density in logit space and split by component such
that the quantile function of each component is used. This
ensures that the R implementation of the quantile function is
always used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integrate_density_log(
  log_integrand,
  mix,
  Lplower = -Inf,
  Lpupper = Inf,
  eps = 1e-09
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integrate_density_log_+3A_log_integrand">log_integrand</code></td>
<td>
<p>function to integrate over which must return the log(f)</p>
</td></tr>
<tr><td><code id="integrate_density_log_+3A_mix">mix</code></td>
<td>
<p>density over which to integrate</p>
</td></tr>
<tr><td><code id="integrate_density_log_+3A_lplower">Lplower</code></td>
<td>
<p>logit of lower cumulative density</p>
</td></tr>
<tr><td><code id="integrate_density_log_+3A_lpupper">Lpupper</code></td>
<td>
<p>logit of upper cumulative density</p>
</td></tr>
</table>

<hr>
<h2 id='knn'>k nearest neighbor algorithm for multi-variate data</h2><span id='topic+knn'></span>

<h3>Description</h3>

<p>k nearest neighbor algorithm for multi-variate data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn(X, K = 2, init, Ninit = 50, verbose = FALSE, tol, Niter.max = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knn_+3A_x">X</code></td>
<td>
<p>data matrix, i.e. observations X dimensions</p>
</td></tr>
<tr><td><code id="knn_+3A_k">K</code></td>
<td>
<p>number of clusters to use</p>
</td></tr>
<tr><td><code id="knn_+3A_init">init</code></td>
<td>
<p>list of p and mu used for initialization</p>
</td></tr>
<tr><td><code id="knn_+3A_ninit">Ninit</code></td>
<td>
<p>number of samples used per cluster if no init argument is given</p>
</td></tr>
<tr><td><code id="knn_+3A_verbose">verbose</code></td>
<td>
<p>allows print out of progress information; in verbose mode the cluster memberships are added to the output</p>
</td></tr>
<tr><td><code id="knn_+3A_tol">tol</code></td>
<td>
<p>smaller changes than tol in the objective function indicate convergence, if missing chosen automatically to be 1/5 of the smallest sample variance per dimension</p>
</td></tr>
<tr><td><code id="knn_+3A_niter.max">Niter.max</code></td>
<td>
<p>maximum number of admissible iterations</p>
</td></tr>
</table>

<hr>
<h2 id='likelihood'>Read and Set Likelihood to the Corresponding Conjugate Prior</h2><span id='topic+likelihood'></span><span id='topic+likelihood+3C-'></span>

<h3>Description</h3>

<p>Read and set the likelihood distribution corresponding to the conjugate prior distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likelihood(mix)

likelihood(mix) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="likelihood_+3A_mix">mix</code></td>
<td>
<p>Prior mixture distribution.</p>
</td></tr>
<tr><td><code id="likelihood_+3A_value">value</code></td>
<td>
<p>New likelihood. <strong>Should</strong> only be changed for Gamma priors as these are supported
with either Poisson (<code>value="poisson"</code>) or Exponential (<code>value="exp"</code>) likelihoods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the prior and posterior distributions are in the same family, then the prior distribution
is called a conjugate prior for the likelihood function.
</p>


<h3>Supported Conjugate Prior-Likelihood Pairs</h3>


<table>
<tr>
 <td style="text-align: left;">
<strong>Prior/Posterior</strong> </td><td style="text-align: center;"> <strong>Likelihood</strong> </td><td style="text-align: center;"> <strong>Predictive</strong> 
 </td><td style="text-align: center;"> <strong>Summaries</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
Beta </td><td style="text-align: center;"> Binomial </td><td style="text-align: center;"> Beta-Binomial </td><td style="text-align: center;"> <code>n</code>, <code>r</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Normal </td><td style="text-align: center;"> Normal (<em>fixed <code class="reqn">\sigma</code></em>) </td><td style="text-align: center;"> Normal </td><td style="text-align: center;"> <code>n</code>, <code>m</code>, <code>se</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Poisson </td><td style="text-align: center;"> Gamma-Poisson </td><td style="text-align: center;">  <code>n</code>, <code>m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Exponential </td><td style="text-align: center;"> Gamma-Exp (<em>not supported</em>) </td><td style="text-align: center;"> <code>n</code>, <code>m</code>
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>
# Gamma mixture
gmix &lt;- mixgamma(c(0.3, 20, 4), c(0.7, 50, 10))

# read out conjugate partner
likelihood(gmix)

ess(gmix)

# set conjugate partner
likelihood(gmix) &lt;- "exp"

# ... which changes the interpretation of the mixture
ess(gmix)
</code></pre>

<hr>
<h2 id='lodds'>Logit (log-odds) and inverse-logit function.</h2><span id='topic+lodds'></span><span id='topic+logit'></span><span id='topic+inv_logit'></span>

<h3>Description</h3>

<p>Calculates the logit (log-odds) and inverse-logit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(mu)

inv_logit(eta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lodds_+3A_mu">mu</code></td>
<td>
<p>A numeric object with probabilies, with values in the in
the range [0,1]. Missing values (NAs) are allowed.</p>
</td></tr>
<tr><td><code id="lodds_+3A_eta">eta</code></td>
<td>
<p>A numeric object with log-odds values, with values in
the range [-Inf,Inf]. Missing values (NAs) are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Values of mu equal to 0 or 1 will return -Inf or Inf
respectively.
</p>


<h3>Value</h3>

<p>A numeric object of the same type as mu and eta containing
the logits or inverse logit of the input values.  The logit and
inverse transformation equates to
</p>
<p style="text-align: center;"><code class="reqn">\mbox{logit}(\mu) = \log(\mu/(1-\mu))</code>
</p>

<p style="text-align: center;"><code class="reqn">\mbox{logit}^{-1}(\eta)= \exp(\eta)/(1 + \exp(\eta)).</code>
</p>



<h3>Examples</h3>

<pre><code class='language-R'>logit(0.2)
inv_logit(-1.386)

</code></pre>

<hr>
<h2 id='log_inv_logit'>Numerically stable log of the inv_logit function</h2><span id='topic+log_inv_logit'></span>

<h3>Description</h3>

<p>Numerically stable log of the inv_logit function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_inv_logit(mat)
</code></pre>

<hr>
<h2 id='logLik.EM'>Extract log likelihood from fitted EM objects</h2><span id='topic+logLik.EM'></span>

<h3>Description</h3>

<p>Extract log likelihood from fitted EM objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EM'
logLik(object, ...)
</code></pre>

<hr>
<h2 id='mix'>Mixture Distributions</h2><span id='topic+mix'></span><span id='topic+dmix'></span><span id='topic+pmix'></span><span id='topic+qmix'></span><span id='topic+rmix'></span><span id='topic++5B+5B.mix'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile
function and random number generation for supported mixture
distributions.  (d/p/q/r)mix are generic and work with any mixture
supported by BesT (see table below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmix(mix, x, log = FALSE)

pmix(mix, q, lower.tail = TRUE, log.p = FALSE)

qmix(mix, p, lower.tail = TRUE, log.p = FALSE)

rmix(mix, n)

## S3 method for class 'mix'
mix[[..., rescale = FALSE]]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mix_+3A_mix">mix</code></td>
<td>
<p>mixture distribution object</p>
</td></tr>
<tr><td><code id="mix_+3A_x">x</code>, <code id="mix_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="mix_+3A_log">log</code>, <code id="mix_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code> (not default), probabilities <code class="reqn">p</code> are given as <code class="reqn">\log(p)</code></p>
</td></tr>
<tr><td><code id="mix_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are <code class="reqn">P[X\leq x]</code> otherwise, <code class="reqn">P[X&gt;x]</code></p>
</td></tr>
<tr><td><code id="mix_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="mix_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length is taken to be the number
required</p>
</td></tr>
<tr><td><code id="mix_+3A_...">...</code></td>
<td>
<p>components to subset given mixture.</p>
</td></tr>
<tr><td><code id="mix_+3A_rescale">rescale</code></td>
<td>
<p>logical; if <code>TRUE</code>, mixture weights will be rescaled to sum to 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A mixture distribution is defined as a linear
superposition of <code class="reqn">K</code> densities of the same distributional
class. The mixture distributions supported have the form
</p>
<p style="text-align: center;"><code class="reqn">f(x,\mathbf{w},\mathbf{a},\mathbf{b}) = \sum_{k=1}^K w_k \, f_k(x,a_k,b_k).</code>
</p>

<p>The <code class="reqn">w_k</code> are the mixing coefficients which must sum to
<code class="reqn">1</code>. Moreover, each density <code class="reqn">f</code> is assumed to be
parametrized by two parameters such that each component <code class="reqn">k</code> is
defined by a triplet, <code class="reqn">(w_k,a_k,b_k)</code>.
</p>
<p>Individual mixture components can be extracted using the <code>[[</code>
operator, see examples below.
</p>
<p>The supported densities are normal, beta and gamma which can be
instantiated with <code><a href="#topic+mixnorm">mixnorm</a></code>, <code><a href="#topic+mixbeta">mixbeta</a></code>, or
<code><a href="#topic+mixgamma">mixgamma</a></code>, respectively. In addition, the respective
predictive distributions are supported. These can be obtained by
calling <code><a href="#topic+preddist">preddist</a></code> which returns appropriate normal,
beta-binomial or Poisson-gamma mixtures.
</p>
<p>For convenience a <code>summary</code> function is defined for all
mixtures. It returns the mean, standard deviation and the requested
quantiles which can be specified with the argument <code>probs</code>.
</p>


<h3>Value</h3>

<p><code>dmix</code> gives the weighted sum of the densities of each
component.
</p>
<p><code>pmix</code> calculates the distribution function by
evaluating the weighted sum of each components distribution
function.
</p>
<p><code>qmix</code> returns the quantile for the given <code>p</code>
by using that the distribution function is monotonous and hence a
gradient based minimization scheme can be used to find the matching
quantile <code>q</code>.
</p>
<p><code>rmix</code> generates a random sample of size
<code>n</code> by first sampling a latent component indicator in the
range <code class="reqn">1..K</code> for each draw and then the function samples from
each component a random draw using the respective sampling
function. The <code>rnorm</code> function returns the random draws as
numerical vector with an additional attribute <code>ind</code> which
gives the sampled component indicator.
</p>


<h3>Supported Conjugate Prior-Likelihood Pairs</h3>


<table>
<tr>
 <td style="text-align: left;">
<strong>Prior/Posterior</strong> </td><td style="text-align: center;"> <strong>Likelihood</strong> </td><td style="text-align: center;"> <strong>Predictive</strong> 
 </td><td style="text-align: center;"> <strong>Summaries</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
Beta </td><td style="text-align: center;"> Binomial </td><td style="text-align: center;"> Beta-Binomial </td><td style="text-align: center;"> <code>n</code>, <code>r</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Normal </td><td style="text-align: center;"> Normal (<em>fixed <code class="reqn">\sigma</code></em>) </td><td style="text-align: center;"> Normal </td><td style="text-align: center;"> <code>n</code>, <code>m</code>, <code>se</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Poisson </td><td style="text-align: center;"> Gamma-Poisson </td><td style="text-align: center;">  <code>n</code>, <code>m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Exponential </td><td style="text-align: center;"> Gamma-Exp (<em>not supported</em>) </td><td style="text-align: center;"> <code>n</code>, <code>m</code>
</td>
</tr>

</table>



<h3>See Also</h3>

<p><code><a href="#topic+plot.mix">plot.mix</a></code>
</p>
<p>Other mixdist: 
<code><a href="#topic+mixbeta">mixbeta</a>()</code>,
<code><a href="#topic+mixcombine">mixcombine</a>()</code>,
<code><a href="#topic+mixgamma">mixgamma</a>()</code>,
<code><a href="#topic+mixmvnorm">mixmvnorm</a>()</code>,
<code><a href="#topic+mixnorm">mixnorm</a>()</code>,
<code><a href="#topic+mixplot">mixplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a beta mixture
bm &lt;- mixbeta(weak=c(0.2, 2, 10), inf=c(0.4, 10, 100), inf2=c(0.4, 30, 80))

## extract the two most informative components
bm[[c(2,3)]]
## rescaling needed in order to plot
plot(bm[[c(2,3),rescale=TRUE]])

summary(bm)


</code></pre>

<hr>
<h2 id='mixbeta'>Beta Mixture Density</h2><span id='topic+mixbeta'></span><span id='topic+ms2beta'></span><span id='topic+mn2beta'></span><span id='topic+print.betaMix'></span><span id='topic+print.betaBinomialMix'></span><span id='topic+summary.betaMix'></span><span id='topic+summary.betaBinomialMix'></span>

<h3>Description</h3>

<p>The Beta mixture density and auxilary functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixbeta(..., param = c("ab", "ms", "mn"))

ms2beta(m, s, drop = TRUE)

mn2beta(m, n, drop = TRUE)

## S3 method for class 'betaMix'
print(x, ...)

## S3 method for class 'betaBinomialMix'
print(x, ...)

## S3 method for class 'betaMix'
summary(object, probs = c(0.025, 0.5, 0.975), ...)

## S3 method for class 'betaBinomialMix'
summary(object, probs = c(0.025, 0.5, 0.975), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixbeta_+3A_...">...</code></td>
<td>
<p>List of mixture components.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_param">param</code></td>
<td>
<p>Determines how the parameters in the list
are interpreted. See details.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_m">m</code></td>
<td>
<p>Vector of means of beta mixture components.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_s">s</code></td>
<td>
<p>Vector of standard deviations of beta mixture components.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_drop">drop</code></td>
<td>
<p>Delete the dimensions of an array which have only one level.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_n">n</code></td>
<td>
<p>Vector of number of observations.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_x">x</code></td>
<td>
<p>The mixture to print</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_object">object</code></td>
<td>
<p>Beta mixture object.</p>
</td></tr>
<tr><td><code id="mixbeta_+3A_probs">probs</code></td>
<td>
<p>Quantiles reported by the <code>summary</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each entry in the <code>...</code> argument list is expected to
be a triplet of numbers which defines the weight <code class="reqn">w_k</code>, first
and second parameter of the mixture component <code class="reqn">k</code>. A triplet
can optionally be named which will be used appropriately.
</p>
<p>The first and second parameter can be given in different
parametrizations which is set by the <code>param</code> option:
</p>

<dl>
<dt>ab</dt><dd><p>Natural parametrization of Beta density (<code>a</code>=shape1 and <code>b</code>=shape2). Default. </p>
</dd>
<dt>ms</dt><dd><p>Mean and standard deviation, <code class="reqn">m=a/(a+b)</code> and <code class="reqn">s=\sqrt{\frac{m(1-m)}{1+n}}</code>, where <code class="reqn">n=a+b</code> is the number of observations. Note that <code class="reqn">s</code> must be less than <code class="reqn">\sqrt{m(1-m)}</code>.</p>
</dd>
<dt>mn</dt><dd><p>Mean and number of observations, <code class="reqn">n=a+b</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p><code>mixbeta</code> returns a beta mixture with the specified mixture components. <code>ms2beta</code> and
<code>mn2beta</code> return the equivalent natural <code>a</code> and <code>b</code> parametrization given parameters <code>m</code>,
<code>s</code>, or <code>n</code>.
</p>


<h3>See Also</h3>

<p>Other mixdist: 
<code><a href="#topic+mixcombine">mixcombine</a>()</code>,
<code><a href="#topic+mixgamma">mixgamma</a>()</code>,
<code><a href="#topic+mixmvnorm">mixmvnorm</a>()</code>,
<code><a href="#topic+mixnorm">mixnorm</a>()</code>,
<code><a href="#topic+mixplot">mixplot</a></code>,
<code><a href="#topic+mix">mix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a beta mixture
bm &lt;- mixbeta(rob=c(0.2, 2, 10), inf=c(0.4, 10, 100), inf2=c(0.4, 30, 80))

# mean/standard deviation parametrization
bm2 &lt;- mixbeta(rob=c(0.2, 0.3, 0.2), inf=c(0.8, 0.4, 0.01), param="ms")

# mean/observations parametrization
bm3 &lt;- mixbeta(rob=c(0.2, 0.3, 5), inf=c(0.8, 0.4, 30), param="mn")

# even mixed is possible
bm4 &lt;- mixbeta(rob=c(0.2, mn2beta(0.3, 5)), inf=c(0.8, ms2beta(0.4, 0.1)))

# print methods are defined
bm4
print(bm4)

</code></pre>

<hr>
<h2 id='mixcombine'>Combine Mixture Distributions</h2><span id='topic+mixcombine'></span>

<h3>Description</h3>

<p>Combining mixture distributions of the same class to form a new mixture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixcombine(..., weight, rescale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixcombine_+3A_...">...</code></td>
<td>
<p>arbitrary number of mixtures with same distributional class.
Each component with values of mixture weight and model parameters.</p>
</td></tr>
<tr><td><code id="mixcombine_+3A_weight">weight</code></td>
<td>
<p>relative weight for each component in new mixture
distribution. The vector must be of the same length as input
mixtures components. The default value gives equal weight to each
component.</p>
</td></tr>
<tr><td><code id="mixcombine_+3A_rescale">rescale</code></td>
<td>
<p>boolean value indicates if the weights are
rescaled to sum to 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Combines mixtures of the same class of random
variable to form a new mixture distribution.
</p>


<h3>Value</h3>

<p>A R-object with the new mixture distribution.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+robustify">robustify</a></code>
</p>
<p>Other mixdist: 
<code><a href="#topic+mixbeta">mixbeta</a>()</code>,
<code><a href="#topic+mixgamma">mixgamma</a>()</code>,
<code><a href="#topic+mixmvnorm">mixmvnorm</a>()</code>,
<code><a href="#topic+mixnorm">mixnorm</a>()</code>,
<code><a href="#topic+mixplot">mixplot</a></code>,
<code><a href="#topic+mix">mix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># beta with two informative components
bm &lt;- mixbeta(inf=c(0.5, 10, 100), inf2=c(0.5, 30, 80))

# robustified with mixcombine, i.e. a 10% uninformative part added
unif &lt;- mixbeta(rob=c(1,1,1))
mixcombine(bm, unif, weight=c(9, 1))

</code></pre>

<hr>
<h2 id='mixdiff'>Difference of mixture distributions</h2><span id='topic+mixdiff'></span><span id='topic+dmixdiff'></span><span id='topic+pmixdiff'></span><span id='topic+qmixdiff'></span><span id='topic+rmixdiff'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile
function and random number generation for the difference of two mixture
distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmixdiff(mix1, mix2, x)

pmixdiff(mix1, mix2, q, lower.tail = TRUE)

qmixdiff(mix1, mix2, p, lower.tail = TRUE)

rmixdiff(mix1, mix2, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixdiff_+3A_mix1">mix1</code></td>
<td>
<p>first mixture density</p>
</td></tr>
<tr><td><code id="mixdiff_+3A_mix2">mix2</code></td>
<td>
<p>second mixture density</p>
</td></tr>
<tr><td><code id="mixdiff_+3A_x">x</code></td>
<td>
<p>vector of values for which density values are computed</p>
</td></tr>
<tr><td><code id="mixdiff_+3A_q">q</code></td>
<td>
<p>vector of quantiles for which cumulative probabilities are computed</p>
</td></tr>
<tr><td><code id="mixdiff_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are P[X &lt;= x], otherwise P[X &gt; x].</p>
</td></tr>
<tr><td><code id="mixdiff_+3A_p">p</code></td>
<td>
<p>vector of cumulative probabilities for which quantiles are computed</p>
</td></tr>
<tr><td><code id="mixdiff_+3A_n">n</code></td>
<td>
<p>size of random sample</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">x_1 \sim f_1(x_1)</code> and <code class="reqn">x_2 \sim
f_2(x_2)</code>, the density of the difference <code class="reqn">d
\equiv x_1 - x_2</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">f_d(d) = \int f_1(u) \, f_2(u - d) \, du.</code>
</p>

<p>The cumulative distribution function equates to
</p>
<p style="text-align: center;"><code class="reqn">F_d(d) = \int f_1(u) \, (1-F_2(u-d)) \, du.</code>
</p>

<p>Both integrals are performed over the full support of the
densities and use the numerical integration function
<code><a href="stats.html#topic+integrate">integrate</a></code>.
</p>


<h3>Value</h3>

<p>Respective density, quantile, cumulative density or random
numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# 1. Difference between two beta distributions, i.e. Pr( mix1 - mix2 &gt; 0)
mix1 &lt;- mixbeta(c(1, 11, 4))
mix2 &lt;- mixbeta(c(1, 8, 7))
pmixdiff(mix1, mix2, 0, FALSE)

# Interval probability, i.e. Pr( 0.3 &gt; mix1 - mix2 &gt; 0)
pmixdiff(mix1, mix2, 0.3) - pmixdiff(mix1, mix2, 0)

# 2. two distributions, one of them a mixture
m1 &lt;- mixbeta( c(1,30,50))
m2 &lt;- mixbeta( c(0.75,20,50),c(0.25,1,1))

# random sample of difference
set.seed(23434)
rM &lt;- rmixdiff(m1, m2, 1E4)

# histogram of random numbers and exact density
hist(rM,prob=TRUE,new=TRUE,nclass=40)
curve(dmixdiff(m1,m2,x), add=TRUE, n=51)

# threshold probabilities for difference, at 0 and 0.2
pmixdiff(m1, m2, 0)
mean(rM&lt;0)
pmixdiff(m1,m2,0.2)
mean(rM&lt;0.2)

# median of difference
mdn &lt;- qmixdiff(m1, m2, 0.5)
mean(rM&lt;mdn)

# 95%-interval
qmixdiff(m1, m2, c(0.025,0.975))
quantile(rM, c(0.025,0.975))

</code></pre>

<hr>
<h2 id='mixdist3'>Utility function to instantiate 2 parameter mixture densities.</h2><span id='topic+mixdist3'></span>

<h3>Description</h3>

<p>Utility function to instantiate 2 parameter mixture densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixdist3(...)
</code></pre>

<hr>
<h2 id='mixfit'>Fit of Mixture Densities to Samples</h2><span id='topic+mixfit'></span><span id='topic+mixfit.default'></span><span id='topic+mixfit.gMAP'></span><span id='topic+mixfit.gMAPpred'></span><span id='topic+mixfit.array'></span>

<h3>Description</h3>

<p>Expectation-Maximization (EM) based fitting of parametric mixture
densities to numerical samples. This provides a convenient approach
to approximate MCMC samples with a parametric mixture distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixfit(sample, type = c("norm", "beta", "gamma", "mvnorm"), thin, ...)

## Default S3 method:
mixfit(sample, type = c("norm", "beta", "gamma", "mvnorm"), thin, ...)

## S3 method for class 'gMAP'
mixfit(sample, type, thin, ...)

## S3 method for class 'gMAPpred'
mixfit(sample, type, thin, ...)

## S3 method for class 'array'
mixfit(sample, type, thin, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixfit_+3A_sample">sample</code></td>
<td>
<p>Sample to be fitted.</p>
</td></tr>
<tr><td><code id="mixfit_+3A_type">type</code></td>
<td>
<p>Mixture density to use. Can be either norm, beta or gamma.</p>
</td></tr>
<tr><td><code id="mixfit_+3A_thin">thin</code></td>
<td>
<p>Thinning applied to the sample. See description for default behavior.</p>
</td></tr>
<tr><td><code id="mixfit_+3A_...">...</code></td>
<td>
<p>Parameters passed to the low-level EM fitting functions. Parameter <code>Nc</code> is mandatory.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameters of EM fitting functions
</p>

<dl>
<dt>Nc</dt><dd><p>Number of mixture components. Required parameter.</p>
</dd>
<dt>mix_init</dt><dd><p>Initial mixture density. If missing (default) then a k-nearest-neighbor algorithm is used to find an initial mixture density.</p>
</dd>
<dt>Ninit</dt><dd><p>Number of data points used for initialization. Defaults to 50.</p>
</dd>
<dt>verbose</dt><dd><p>If set to <code>TRUE</code> the function will inform about fitting process</p>
</dd>
<dt>maxIter</dt><dd><p>Maximal number of iterations. Defaults to 500.</p>
</dd>
<dt>tol</dt><dd><p>Defines a convergence criteria as an upper bound for the change in the log-likelihood, i.e. once the derivative (with respect to iterations) of the log-likelihood falls below <code>tol</code>, the function declares convergence and stops.</p>
</dd>
<dt>eps</dt><dd><p>Must be a triplet of numbers which set the desired accuracy of the inferred parameters per mixture component. See below for a description of the parameters used during EM. EM is stopped once a running mean of the absolute difference between the last successive <code>Neps</code> estimates is below the given <code>eps</code> for all parameters. Defaults to 5E-3 for each parameter.</p>
</dd>
<dt>Neps</dt><dd><p>Number of iterations used for the running mean of parameter estimates to test for convergence. Defaults to 5.</p>
</dd>
<dt>constrain_gt1</dt><dd><p>Logical value controlling if the Beta EM constrains all parameters a &amp; b to be greater than 1. By default constraints are turned on (new since 1.6-0).</p>
</dd>
</dl>

<p>By default the EM convergence is declared when
the desired accuracy of the parameters has been reached over the last
<code>Neps</code> estimates. If <code>tol</code> and <code>Neps</code> is specified, then
whatever criterion is met first will stop the EM.
</p>
<p>The parameters per component <code class="reqn">k</code> used internally during fitting
are for the different EM procedures:
</p>

<dl>
<dt>normal</dt><dd><p><code class="reqn">logit(w_k), \mu_k, \log(\sigma_k)</code></p>
</dd>
<dt>beta</dt><dd><p><code class="reqn">logit(w_k), \log(a_k), \log(b_k)</code></p>
</dd>
<dt>constrained beta</dt><dd><p><code class="reqn">logit(w_k), \log(a_k-1), \log(b_k-1)</code></p>
</dd>
<dt>gamma</dt><dd><p><code class="reqn">logit(w_k), \log(\alpha_k), \log(\beta_k)</code></p>
</dd>
</dl>

<p><em>Note:</em> Whenever no <code>mix_init</code> argument is given,
the EM fitting routines assume that the data vector is given in
random order. If in the unlikely event that the EM gets caught in a
local extremum, then random reordering of the data vector may
alleviate the issue.
</p>


<h3>Value</h3>

<p>A mixture object according the requested <code>type</code> is
returned. The object has additional information attached, i.e. the
log-likelihood can be queried and diagnostic plots can be
generated. See links below.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>mixfit(default)</code>: Performs an EM fit for the given
sample. Thinning is applied only if thin is specified.
</p>
</li>
<li> <p><code>mixfit(gMAP)</code>: Fits the default predictive distribution from a
gMAP analysis. Automatically obtains the predictive distribution of
the intercept only case on the response scale mixture from the
<code><a href="#topic+gMAP">gMAP</a></code> object. For the binomial case a beta mixture,
for the gaussian case a normal mixture and for the Poisson case a
gamma mixture will be used. In the gaussian case, the resulting
normal mixture will set the reference scale to the estimated
sigma in <code><a href="#topic+gMAP">gMAP</a></code> call.
</p>
</li>
<li> <p><code>mixfit(gMAPpred)</code>: Fits a mixture density for each prediction from
the <code><a href="#topic+gMAP">gMAP</a></code> prediction.
</p>
</li>
<li> <p><code>mixfit(array)</code>: Fits a mixture density for an MCMC sample. It is
recommended to provide a thinning argument which roughly yields
independent draws (i.e. use <code><a href="stats.html#topic+acf">acf</a></code> to identify a
thinning lag with small auto-correlation). The input array is
expected to have 3 dimensions which are nested as iterations,
chains, and draws.
</p>
</li></ul>


<h3>References</h3>

<p>Dempster A.P., Laird N.M., Rubin D.B. Maximum
Likelihood from Incomplete Data via the EM Algorithm. <em>Journal
of the Royal Statistical Society, Series B</em> 1977; 39 (1): 1-38.
</p>


<h3>See Also</h3>

<p>Other EM: 
<code><a href="#topic+plot.EM">plot.EM</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bmix &lt;- mixbeta(rob=c(0.2, 1, 1), inf=c(0.8, 10, 2))

bsamp &lt;- rmix(bmix, 1000)

bfit &lt;- mixfit(bsamp, type="beta", Nc=2)

# diagnostic plots can easily by generated from the EM fit with
bfit.check &lt;- plot(bfit)

names(bfit.check)

# check convergence of parameters
bfit.check$mix
bfit.check$mixdens
bfit.check$mixecdf

# obtain the log-likelihood
logLik(bfit)

# or AIC
AIC(bfit)

</code></pre>

<hr>
<h2 id='mixgamma'>The Gamma Mixture Distribution</h2><span id='topic+mixgamma'></span><span id='topic+ms2gamma'></span><span id='topic+mn2gamma'></span><span id='topic+print.gammaMix'></span><span id='topic+print.gammaPoissonMix'></span><span id='topic+print.gammaExpMix'></span><span id='topic+summary.gammaMix'></span><span id='topic+summary.gammaPoissonMix'></span>

<h3>Description</h3>

<p>The gamma mixture density and auxiliary functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixgamma(..., param = c("ab", "ms", "mn"), likelihood = c("poisson", "exp"))

ms2gamma(m, s, drop = TRUE)

mn2gamma(m, n, likelihood = c("poisson", "exp"), drop = TRUE)

## S3 method for class 'gammaMix'
print(x, ...)

## S3 method for class 'gammaPoissonMix'
print(x, ...)

## S3 method for class 'gammaExpMix'
print(x, ...)

## S3 method for class 'gammaMix'
summary(object, probs = c(0.025, 0.5, 0.975), ...)

## S3 method for class 'gammaPoissonMix'
summary(object, probs = c(0.025, 0.5, 0.975), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixgamma_+3A_...">...</code></td>
<td>
<p>List of mixture components.</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_param">param</code></td>
<td>
<p>Determines how the parameters in the list are
interpreted. See details.</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_likelihood">likelihood</code></td>
<td>
<p>Defines with what likelihood the Gamma density is used (Poisson or Exp). Defaults to <code>poisson</code>.</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_m">m</code></td>
<td>
<p>Vector of means of the Gamma mixture components</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_s">s</code></td>
<td>
<p>Vector of standard deviations of the gamma mixture components,</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_drop">drop</code></td>
<td>
<p>Delete the dimensions of an array which have only one level.</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_n">n</code></td>
<td>
<p>Vector of sample sizes of the Gamma mixture components.</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_x">x</code></td>
<td>
<p>The mixture to print</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_object">object</code></td>
<td>
<p>Gamma mixture object.</p>
</td></tr>
<tr><td><code id="mixgamma_+3A_probs">probs</code></td>
<td>
<p>Quantiles reported by the <code>summary</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each entry in the <code>...</code> argument list is expected to
be a triplet of numbers which defines the weight <code class="reqn">w_k</code>, first
and second parameter of the mixture component <code class="reqn">k</code>. A triplet
can optionally be named which will be used appropriately.
</p>
<p>The first and second parameter can be given in different
parametrizations which is set by the <code>param</code> option:
</p>

<dl>
<dt>ab</dt><dd><p>Natural parametrization of Gamma density (<code>a</code>=shape and <code>b</code>=rate). Default. </p>
</dd>
<dt>ms</dt><dd><p>Mean and standard deviation, <code class="reqn">m=a/b</code> and <code class="reqn">s=\sqrt{a}/b</code>.</p>
</dd>
<dt>mn</dt><dd><p>Mean and number of observations. Translation to natural
parameter depends on the <code>likelihood</code> argument. For a Poisson
likelihood <code class="reqn">n=b</code> (and <code class="reqn">a=m \cdot n</code>), for an Exp
likelihood <code class="reqn">n=a</code> (and <code class="reqn">b=n/m</code>).</p>
</dd>
</dl>



<h3>Value</h3>

<p><code>mixgamma</code> returns a gamma mixture with the specified mixture components.
<code>ms2gamma</code> and
<code>mn2gamma</code> return the equivalent natural <code>a</code> and <code>b</code> parametrization given
parameters <code>m</code>, <code>s</code>, or <code>n</code>.
</p>


<h3>See Also</h3>

<p>Other mixdist: 
<code><a href="#topic+mixbeta">mixbeta</a>()</code>,
<code><a href="#topic+mixcombine">mixcombine</a>()</code>,
<code><a href="#topic+mixmvnorm">mixmvnorm</a>()</code>,
<code><a href="#topic+mixnorm">mixnorm</a>()</code>,
<code><a href="#topic+mixplot">mixplot</a></code>,
<code><a href="#topic+mix">mix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Gamma mixture with robust and informative component
gmix &lt;- mixgamma(rob=c(0.3, 20, 4), inf=c(0.7, 50, 10))

# objects can be printed
gmix
# or explicitly
print(gmix)

# summaries are defined
summary(gmix)

# sub-components may be extracted
# by component number
gmix[[2]]
# or component name
gmix[["inf"]]

# alternative mean and standard deviation parametrization
gmsMix &lt;- mixgamma(rob=c(0.5, 8, 0.5), inf=c(0.5, 9, 2), param="ms")

# or mean and number of observations parametrization
gmnMix &lt;- mixgamma(rob=c(0.2, 2, 1), inf=c(0.8, 2, 5), param="mn")

# and mixed parametrizations are also possible
gfmix &lt;- mixgamma(rob1=c(0.15, mn2gamma(2, 1)), rob2=c(0.15, ms2gamma(2, 5)), inf=c(0.7, 50, 10))
</code></pre>

<hr>
<h2 id='mixlink'>takes x and transforms it according to the defined link function of
the mixture</h2><span id='topic+mixlink'></span>

<h3>Description</h3>

<p>takes x and transforms it according to the defined link function of
the mixture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixlink(mix, x)
</code></pre>

<hr>
<h2 id='mixmvnorm'>Multivariate Normal Mixture Density</h2><span id='topic+mixmvnorm'></span><span id='topic+print.mvnormMix'></span><span id='topic+summary.mvnormMix'></span><span id='topic+sigma.mvnormMix'></span>

<h3>Description</h3>

<p>The multivariate normal mixture density and auxiliary
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixmvnorm(..., sigma, param = c("ms", "mn"))

## S3 method for class 'mvnormMix'
print(x, ...)

## S3 method for class 'mvnormMix'
summary(object, ...)

## S3 method for class 'mvnormMix'
sigma(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixmvnorm_+3A_...">...</code></td>
<td>
<p>List of mixture components.</p>
</td></tr>
<tr><td><code id="mixmvnorm_+3A_sigma">sigma</code></td>
<td>
<p>Reference covariance.</p>
</td></tr>
<tr><td><code id="mixmvnorm_+3A_param">param</code></td>
<td>
<p>Determines how the parameters in the list are
interpreted. See details.</p>
</td></tr>
<tr><td><code id="mixmvnorm_+3A_x">x</code></td>
<td>
<p>The mixture to print</p>
</td></tr>
<tr><td><code id="mixmvnorm_+3A_object">object</code></td>
<td>
<p>Multivariate normal mixture object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each entry in the <code>...</code> argument list is a numeric
vector defining one component of the mixture multivariate
normal distribution. The first entry of the component defining
vector is the weight of the mixture component followed by the
vector of means in each dimension and finally a specification
of the covariance matrix, which depends on the chosen
parametrization. The covariance matrix is expected to be given
as numeric vector in a column-major format, which is standard
conversion applied to matrices by the vector concatenation
function <code><a href="base.html#topic+c">c</a></code>. Please refer to the examples
section below.
</p>
<p>Each component defining vector can be specified in different ways
as determined by the <code>param</code> option:
</p>

<dl>
<dt>ms</dt><dd><p>Mean vector and covariance matrix <code>s</code>. Default.</p>
</dd>
<dt>mn</dt><dd><p>Mean vector and number of observations. <code>n</code> determines the covariance for each component via the relation <code class="reqn">\Sigma/n</code> with <code class="reqn">\Sigma</code> being the known reference covariance.</p>
</dd>
</dl>

<p>The reference covariance <code class="reqn">\Sigma</code> is the known covariance in
the normal-normal model (observation covariance). The function
<code>sigma</code> can be used to query the reference covariance and may
also be used to assign a new reference covariance, see examples
below. In case <code>sigma</code> is not specified, the user has to
supply <code>sigma</code> as argument to functions which require a
reference covariance.
</p>


<h3>Value</h3>

<p>Returns a multivariate normal mixture with the specified
mixture components.
</p>


<h3>See Also</h3>

<p>Other mixdist: 
<code><a href="#topic+mixbeta">mixbeta</a>()</code>,
<code><a href="#topic+mixcombine">mixcombine</a>()</code>,
<code><a href="#topic+mixgamma">mixgamma</a>()</code>,
<code><a href="#topic+mixnorm">mixnorm</a>()</code>,
<code><a href="#topic+mixplot">mixplot</a></code>,
<code><a href="#topic+mix">mix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
S &lt;- diag(c(1, 2)) %*% matrix(c(1, 0.5, 0.5, 1), 2, 2) %*% diag(c(1, 2)) 
mvnm1 &lt;- mixmvnorm(rob=c(0.2, c(0, 0), diag(c(5, 5))),
                   inf=c(0.8, c(0.5, 1), S/10), sigma=S)

print(mvnm1)
summary(mvnm1)

set.seed(657846)
mixSamp1 &lt;- rmix(mvnm1, 500)
colMeans(mixSamp1)


</code></pre>

<hr>
<h2 id='mixnorm'>Normal Mixture Density</h2><span id='topic+mixnorm'></span><span id='topic+sigma'></span><span id='topic+mn2norm'></span><span id='topic+print.normMix'></span><span id='topic+summary.normMix'></span><span id='topic+sigma.normMix'></span><span id='topic+sigma+3C-'></span>

<h3>Description</h3>

<p>The normal mixture density and auxiliary functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixnorm(..., sigma, param = c("ms", "mn"))

mn2norm(m, n, sigma, drop = TRUE)

## S3 method for class 'normMix'
print(x, ...)

## S3 method for class 'normMix'
summary(object, probs = c(0.025, 0.5, 0.975), ...)

## S3 method for class 'normMix'
sigma(object, ...)

sigma(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixnorm_+3A_...">...</code></td>
<td>
<p>List of mixture components.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_sigma">sigma</code></td>
<td>
<p>Reference scale.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_param">param</code></td>
<td>
<p>Determines how the parameters in the list are
interpreted. See details.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_m">m</code></td>
<td>
<p>Vector of means</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_n">n</code></td>
<td>
<p>Vector of sample sizes.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_drop">drop</code></td>
<td>
<p>Delete the dimensions of an array which have only one level.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_x">x</code></td>
<td>
<p>The mixture to print</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_object">object</code></td>
<td>
<p>Normal mixture object.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_probs">probs</code></td>
<td>
<p>Quantiles reported by the <code>summary</code> function.</p>
</td></tr>
<tr><td><code id="mixnorm_+3A_value">value</code></td>
<td>
<p>New value of the reference scale <code>sigma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each entry in the <code>...</code> argument list is expected to
be a triplet of numbers which defines the weight <code class="reqn">w_k</code>, first
and second parameter of the mixture component <code class="reqn">k</code>. A triplet
can optionally be named which will be used appropriately.
</p>
<p>The first and second parameter can be given in different
parametrizations which is set by the <code>param</code> option:
</p>

<dl>
<dt>ms</dt><dd><p>Mean and standard deviation. Default.</p>
</dd>
<dt>mn</dt><dd><p>Mean and number of observations. <code>n</code> determines <code>s</code> via the relation <code class="reqn">s=\sigma/\sqrt{n}</code> with <code class="reqn">\sigma</code> being the fixed reference scale.</p>
</dd>
</dl>

<p>The reference scale <code class="reqn">\sigma</code> is the fixed standard deviation in
the one-parameter normal-normal model (observation standard
deviation). The function <code>sigma</code> can be used to query the
reference scale and may also be used to assign a new reference
scale, see examples below. In case the <code>sigma</code> is not
specified, the user has to supply <code>sigma</code> as argument to
functions which require a reference scale.
</p>


<h3>Value</h3>

<p>Returns a normal mixture with the specified mixture
components. <code>mn2norm</code> returns the mean and standard deviation
given a mean and sample size parametrization.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>sigma(object) &lt;- value</code>: Allows to assign a new reference scale <code>sigma</code>.
</p>
</li></ul>


<h3>See Also</h3>

<p>Other mixdist: 
<code><a href="#topic+mixbeta">mixbeta</a>()</code>,
<code><a href="#topic+mixcombine">mixcombine</a>()</code>,
<code><a href="#topic+mixgamma">mixgamma</a>()</code>,
<code><a href="#topic+mixmvnorm">mixmvnorm</a>()</code>,
<code><a href="#topic+mixplot">mixplot</a></code>,
<code><a href="#topic+mix">mix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nm &lt;- mixnorm(rob=c(0.2, 0, 2), inf=c(0.8, 2, 2), sigma=5)

print(nm)
summary(nm)
plot(nm)

set.seed(57845)
mixSamp &lt;- rmix(nm, 500)
plot(nm, samp=mixSamp)

# support defined by quantiles
qmix(nm, c(0.01, 0.99))

# density function
dmix(nm, seq(-5,5,by=2))

# distribution function
pmix(nm, seq(-5,5,by=2))

# the reference scale can be changed (it determines the ESS)
ess(nm)

sigma(nm) &lt;- 10
ess(nm)
</code></pre>

<hr>
<h2 id='mixplot'>Plot mixture distributions</h2><span id='topic+mixplot'></span><span id='topic+plot.mix'></span><span id='topic+plot.mvnormMix'></span>

<h3>Description</h3>

<p>Plotting for mixture distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mix'
plot(x, prob = 0.99, fun = dmix, log = FALSE, comp = TRUE, size = 1.25, ...)

## S3 method for class 'mvnormMix'
plot(x, prob = 0.99, fun = dmix, log = FALSE, comp = TRUE, size = 1.25, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixplot_+3A_x">x</code></td>
<td>
<p>mixture distribution</p>
</td></tr>
<tr><td><code id="mixplot_+3A_prob">prob</code></td>
<td>
<p>defining lower and upper percentile of x-axis. Defaults to the 99% central probability mass.</p>
</td></tr>
<tr><td><code id="mixplot_+3A_fun">fun</code></td>
<td>
<p>function to plot which can be any of <code>dmix</code>, <code>qmix</code> or <code>pmix</code>.</p>
</td></tr>
<tr><td><code id="mixplot_+3A_log">log</code></td>
<td>
<p>log argument passed to the function specified in <code>fun</code>.</p>
</td></tr>
<tr><td><code id="mixplot_+3A_comp">comp</code></td>
<td>
<p>for the density function this can be set to <code>TRUE</code>
which will display colour-coded each mixture component of the
density in addition to the density.</p>
</td></tr>
<tr><td><code id="mixplot_+3A_size">size</code></td>
<td>
<p>controls the linesize in plots.</p>
</td></tr>
<tr><td><code id="mixplot_+3A_...">...</code></td>
<td>
<p>extra arguments passed on to the <code><a href="ggplot2.html#topic+qplot">qplot</a></code> call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plot function for mixture distribution objects. It shows
the density/quantile/cumulative distribution (corresponds to
<code>d/q/pmix</code> function) for some specific central probability
mass defined by <code>prob</code>. By default the x-axis is chosen to
show 99% of the probability density mass.
</p>


<h3>Value</h3>

<p>A <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code> object is returned.
</p>


<h3>Customizing <span class="pkg">ggplot2</span> plots</h3>

<p>The returned plot is a <span class="pkg">ggplot2</span> object. Please refer to the
&quot;Customizing Plots&quot; vignette which is part of <span class="pkg">RBesT</span>
documentation for an introduction. For simple modifications (change
labels, add reference lines, ...) consider the commands found in
<code><a href="bayesplot.html#topic+bayesplot-helpers">bayesplot-helpers</a></code>. For more advanced
customizations please use the <span class="pkg">ggplot2</span> package directly. A
description of the most common tasks can be found in the
<a href="http://www.cookbook-r.com/Graphs/">R Cookbook</a> and a full
reference of available commands can be found at the
<a href="https://ggplot2.tidyverse.org/reference/">ggplot2 documentation
site</a>.
</p>


<h3>See Also</h3>

<p>Other mixdist: 
<code><a href="#topic+mixbeta">mixbeta</a>()</code>,
<code><a href="#topic+mixcombine">mixcombine</a>()</code>,
<code><a href="#topic+mixgamma">mixgamma</a>()</code>,
<code><a href="#topic+mixmvnorm">mixmvnorm</a>()</code>,
<code><a href="#topic+mixnorm">mixnorm</a>()</code>,
<code><a href="#topic+mix">mix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># beta with two informative components
bm &lt;- mixbeta(inf=c(0.5, 10, 100), inf2=c(0.5, 30, 80))
plot(bm)
plot(bm, fun=pmix)

# for customizations of the plot we need to load ggplot2 first
library(ggplot2)

# show a histogram along with the density
plot(bm) + geom_histogram(data=data.frame(x=rmix(bm, 1000)),
                          aes(y=..density..), bins=50, alpha=0.4)


# note: we can also use bayesplot for histogram plots with a density ...
library(bayesplot)
mh &lt;- mcmc_hist(data.frame(x=rmix(bm, 1000)), freq=FALSE) +
         overlay_function(fun=dmix, args=list(mix=bm))
# ...and even add each component
for(k in 1:ncol(bm))
  mh &lt;- mh + overlay_function(fun=dmix, args=list(mix=bm[[k]]), linetype=I(2))
print(mh)


# normal mixture
nm &lt;- mixnorm(rob=c(0.2, 0, 2), inf=c(0.8, 6, 2), sigma=5)
plot(nm)
plot(nm, fun=qmix)

# obtain ggplot2 object and change title
pl &lt;- plot(nm)
pl + ggtitle("Normal 2-Component Mixture")

</code></pre>

<hr>
<h2 id='mixstanvar'>Mixture distributions as <code>brms</code> priors</h2><span id='topic+mixstanvar'></span>

<h3>Description</h3>

<p>Adapter function converting mixture distributions for
use with <code><a href="brms.html#topic+brm">brm</a></code> models via the
<code><a href="brms.html#topic+stanvar">stanvar</a></code> facility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixstanvar(..., verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixstanvar_+3A_...">...</code></td>
<td>
<p>List of mixtures to convert.</p>
</td></tr>
<tr><td><code id="mixstanvar_+3A_verbose">verbose</code></td>
<td>
<p>Enables printing of the mixture priors when chains
start to sample. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To declare mixture priors in a <code><a href="brms.html#topic+brm">brm</a></code>
model requires two steps: First, the mixture densities need to
be converted by the adapter function <code>mixstanvar</code> into a
<code>stanvars</code> object which is passed to the <code>stanvars</code>
argument of the <code><a href="brms.html#topic+brm">brm</a></code> function. Doing so
extends the Stan code and data generated by
<code><a href="brms.html#topic+brm">brm</a></code> such that the mixture densities can be
used as priors within the <code><a href="brms.html#topic+brm">brm</a></code> model. The
second step is to assign parameters of the
<code><a href="brms.html#topic+brm">brm</a></code> model to the mixture density as prior
using the <code><a href="brms.html#topic+set_prior">set_prior</a></code> command of <code>brms</code>.
</p>
<p>The adapter function translates the mixture distributions as
defined in <code>R</code> to the respective mixture distribution in
Stan. Within Stan the mixture distributions are named in
accordance to the <code>R</code> functions used to create the respective
mixture distributions. That is, a mixture density of normals
created by <code><a href="#topic+mixnorm">mixnorm</a></code> is referred to as
<code>mixnorm_lpdf</code> in Stan such that one can refer to the density
as <code>mixnorm</code> within the <code><a href="brms.html#topic+set_prior">set_prior</a></code>
functions (the suffix <code>_lpdf</code> is automatically added by
<code><a href="brms.html#topic+brm">brm</a></code>). The arguments to these mixture
distributions depend on the specific distribution type as follows:
</p>

<table>
<tr>
 <td style="text-align: center;">
Density </td><td style="text-align: left;"> Arguments </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>mixbeta(w, a, b)</code> </td><td style="text-align: left;"> <code>w</code> weights, <code>a</code> shapes, <code>b</code> shapes </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>mixgamma(w, a, b)</code> </td><td style="text-align: left;"> <code>w</code> weights, <code>a</code> shapes, <code>b</code> inverse scales </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>mixnorm(w, m, s)</code> </td><td style="text-align: left;"> <code>w</code> weights, <code>m</code> means, <code>s</code> standard deviations </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>mixmvnorm(w, m, sigma_L)</code> </td><td style="text-align: left;"> <code>w</code> weights, <code>m</code> means, <code>sigma_L</code> cholesky factors of covariances </td>
</tr>
<tr>
 <td style="text-align: center;">
</td>
</tr>

</table>

<p>These arguments to the mixture densities refer to the different
density parameters and are automatically extracted from the
mixtures when converted. Important here are the argument names as
these must be used to declare the mixture prior. For each mixture
to convert as part of the <code>...</code>  argument to <code>mixstanvar</code>
a label is determined using the name given in the list. In case no
name is given, then the name of the <code>R</code> object itself is
used. To declare a prior for a parameter the mixture distribution
must be used with it's arguments following the convention
<code>label_argument</code>. Please refer to the examples section for an
illustration.
</p>
<p><strong>Note:</strong> Models created by <code><a href="brms.html#topic+brm">brm</a></code> do use by
default a data-dependent centering of covariates leading to a shift
of the overall intercept. This is commonly not desirable in
applications of this functionality. It is therefore strongly
recommended to pass the option <code>center=FALSE</code> as argument to
the <code>brms</code> formula created with the <code><a href="brms.html#topic+bf">bf</a></code>
function as demonstrated with the example below.
</p>


<h3>Value</h3>

<p><code>stanvars</code> object to be used as argument to the
<code>stanvars</code> argument of a <code><a href="brms.html#topic+brm">brm</a></code> model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# The mixstanvar adapter requires the optional packages brms and glue
stopifnot(require("brms"), require("glue"))

# Assume we prefer a logistic regression MCMC analysis rather than a
# beta-binomial analysis for the responder endpoint of the ankylosing
# spondylitis (AS) example. Reasons to prefer a regression analysis is
# to allow for baseline covariate adjustments, for example.
map_AS_beta &lt;- mixbeta(c(0.62, 19.2, 57.8), c(0.38, 3.5, 9.4))

# First we need to convert the beta mixture to a respective mixture on
# the log odds scale and approximate it with a normal mixture density.
map_AS_samp &lt;- rmix(map_AS_beta, 1E4)
map_AS &lt;- mixfit(logit(map_AS_samp), type="norm", Nc=2)

# Trial results for placebo and secukinumab.
trial &lt;- data.frame(n=c(6, 24),
                    r=c(1, 15),
                    arm=factor(c("placebo", "secukinumab")))

# Define brms model such that the overall intercept corresponds to the
# placebo response rate on the logit scale. NOTE: The use of
# center=FALSE is required here as detailed in the note above.
model &lt;- bf(r | trials(n) ~ 1 + arm, family=binomial, center=FALSE)
# to obtain detailed information on the declared model parameters use
# get_prior(model, data=trial)
# declare model prior with reference to mixture normal map prior...
model_prior &lt;- prior(mixnorm(map_w, map_m, map_s), coef=Intercept) +
    prior(normal(0, 2), class=b)

# ... which must be made available to brms using the mixstanvar adapter.
# Note that the map_AS prior is labeled "map" as referred to in the
# previous prior declaration.
analysis &lt;- brm(model, data=trial, prior=model_prior,
                stanvars=mixstanvar(map=map_AS),
                seed=365634, refresh=0)

# Let's compare the logistic regression estimate for the probability
# of a positive treatment effect (secukinumab response rate exceeding
# the response rate of placebo) to the direct beta-binomial analysis:
hypothesis(analysis, "armsecukinumab &gt; 0")

post_secukinumab &lt;- postmix(mixbeta(c(1, 0.5, 1)), r=15, n=24)
post_placebo     &lt;- postmix(map_AS_beta, r=1, n=6)
pmixdiff(post_secukinumab,  post_placebo, 0, lower.tail=FALSE)
# The posterior probability for a positive treatment effect
# is very close to unity in both cases.

## End(Not run)
</code></pre>

<hr>
<h2 id='oc1S'>Operating Characteristics for 1 Sample Design</h2><span id='topic+oc1S'></span><span id='topic+oc1S.betaMix'></span><span id='topic+oc1S.normMix'></span><span id='topic+oc1S.gammaMix'></span>

<h3>Description</h3>

<p>The <code>oc1S</code> function defines a 1 sample design (prior, sample
size, decision function) for the calculation of the frequency at
which the decision is evaluated to 1 conditional on assuming
known parameters.  A function is returned which performs the actual
operating characteristics calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oc1S(prior, n, decision, ...)

## S3 method for class 'betaMix'
oc1S(prior, n, decision, ...)

## S3 method for class 'normMix'
oc1S(prior, n, decision, sigma, eps = 1e-06, ...)

## S3 method for class 'gammaMix'
oc1S(prior, n, decision, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oc1S_+3A_prior">prior</code></td>
<td>
<p>Prior for analysis.</p>
</td></tr>
<tr><td><code id="oc1S_+3A_n">n</code></td>
<td>
<p>Sample size for the experiment.</p>
</td></tr>
<tr><td><code id="oc1S_+3A_decision">decision</code></td>
<td>
<p>One-sample decision function to use; see <code><a href="#topic+decision1S">decision1S</a></code>.</p>
</td></tr>
<tr><td><code id="oc1S_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="oc1S_+3A_sigma">sigma</code></td>
<td>
<p>The fixed reference scale. If left unspecified, the
default reference scale of the prior is assumed.</p>
</td></tr>
<tr><td><code id="oc1S_+3A_eps">eps</code></td>
<td>
<p>Support of random variables are determined as the
interval covering <code>1-eps</code> probability mass. Defaults to
<code class="reqn">10^{-6}</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>oc1S</code> function defines a 1 sample design and
returns a function which calculates its operating
characteristics. This is the frequency with which the decision
function is evaluated to 1 under the assumption of a given true
distribution of the data defined by a known parameter
<code class="reqn">\theta</code>. The 1 sample design is defined by the prior, the
sample size and the decision function, <code class="reqn">D(y)</code>. These uniquely
define the decision boundary, see
<code><a href="#topic+decision1S_boundary">decision1S_boundary</a></code>.
</p>
<p>When calling the <code>oc1S</code> function, then internally the critical
value <code class="reqn">y_c</code> (using <code><a href="#topic+decision1S_boundary">decision1S_boundary</a></code>) is
calculated and a function is returns which can be used to
calculated the desired frequency which is evaluated as
</p>
<p style="text-align: center;"><code class="reqn"> F(y_c|\theta). </code>
</p>



<h3>Value</h3>

<p>Returns a function with one argument <code>theta</code> which
calculates the frequency at which the decision function is
evaluated to 1 for the defined 1 sample design. Note that the
returned function takes vectors arguments.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>oc1S(betaMix)</code>: Applies for binomial model with a mixture
beta prior. The calculations use exact expressions.
</p>
</li>
<li> <p><code>oc1S(normMix)</code>: Applies for the normal model with known
standard deviation <code class="reqn">\sigma</code> and a normal mixture prior for the
mean. As a consequence from the assumption of a known standard
deviation, the calculation discards sampling uncertainty of the
second moment. The function <code>oc1S</code> has an extra
argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>). The critical value
<code class="reqn">y_c</code> is searched in the region of probability mass
<code>1-eps</code> for <code class="reqn">y</code>.
</p>
</li>
<li> <p><code>oc1S(gammaMix)</code>: Applies for the Poisson model with a gamma
mixture prior for the rate parameter.  The function
<code>oc1S</code> takes an extra argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>)
which determines the region of probability mass <code>1-eps</code> where
the boundary is searched for <code class="reqn">y</code>.
</p>
</li></ul>


<h3>See Also</h3>

<p>Other design1S: 
<code><a href="#topic+decision1S_boundary">decision1S_boundary</a>()</code>,
<code><a href="#topic+decision1S">decision1S</a>()</code>,
<code><a href="#topic+pos1S">pos1S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# non-inferiority example using normal approximation of log-hazard
# ratio, see ?decision1S for all details
s &lt;- 2
flat_prior &lt;- mixnorm(c(1,0,100), sigma=s)
nL &lt;- 233
theta_ni &lt;- 0.4
theta_a &lt;- 0
alpha &lt;- 0.05
beta  &lt;- 0.2
za &lt;- qnorm(1-alpha)
zb &lt;- qnorm(1-beta)
n1 &lt;- round( (s * (za + zb)/(theta_ni - theta_a))^2 )
theta_c &lt;- theta_ni - za * s / sqrt(n1)

# standard NI design
decA &lt;- decision1S(1 - alpha, theta_ni, lower.tail=TRUE)

# double criterion design
# statistical significance (like NI design)
dec1 &lt;- decision1S(1-alpha, theta_ni, lower.tail=TRUE)
# require mean to be at least as good as theta_c
dec2 &lt;- decision1S(0.5, theta_c, lower.tail=TRUE)
# combination
decComb &lt;- decision1S(c(1-alpha, 0.5), c(theta_ni, theta_c), lower.tail=TRUE)

theta_eval  &lt;- c(theta_a, theta_c, theta_ni)

# evaluate different designs at two sample sizes
designA_n1  &lt;- oc1S(flat_prior, n1, decA)
designA_nL  &lt;- oc1S(flat_prior, nL, decA)
designC_n1  &lt;- oc1S(flat_prior, n1, decComb)
designC_nL  &lt;- oc1S(flat_prior, nL, decComb)

# evaluate designs at the key log-HR of positive treatment (HR&lt;1),
# the indecision point and the NI margin

designA_n1(theta_eval)
designA_nL(theta_eval)
designC_n1(theta_eval)
designC_nL(theta_eval)

# to understand further the dual criterion design it is useful to
# evaluate the criterions separatley:
# statistical significance criterion to warrant NI...
designC1_nL &lt;- oc1S(flat_prior, nL, dec1)
# ... or the clinically determined indifference point
designC2_nL &lt;- oc1S(flat_prior, nL, dec2)

designC1_nL(theta_eval)
designC2_nL(theta_eval)

# see also ?decision1S_boundary to see which of the two criterions
# will drive the decision


</code></pre>

<hr>
<h2 id='oc2S'>Operating Characteristics for 2 Sample Design</h2><span id='topic+oc2S'></span><span id='topic+oc2S.betaMix'></span><span id='topic+oc2S.normMix'></span><span id='topic+oc2S.gammaMix'></span>

<h3>Description</h3>

<p>The <code>oc2S</code> function defines a 2 sample design (priors, sample
sizes &amp; decision function) for the calculation of operating
characeristics. A function is returned which calculates the
calculates the frequency at which the decision function is
evaluated to 1 when assuming known parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oc2S(prior1, prior2, n1, n2, decision, ...)

## S3 method for class 'betaMix'
oc2S(prior1, prior2, n1, n2, decision, eps, ...)

## S3 method for class 'normMix'
oc2S(
  prior1,
  prior2,
  n1,
  n2,
  decision,
  sigma1,
  sigma2,
  eps = 1e-06,
  Ngrid = 10,
  ...
)

## S3 method for class 'gammaMix'
oc2S(prior1, prior2, n1, n2, decision, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oc2S_+3A_prior1">prior1</code></td>
<td>
<p>Prior for sample 1.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_prior2">prior2</code></td>
<td>
<p>Prior for sample 2.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_n1">n1</code>, <code id="oc2S_+3A_n2">n2</code></td>
<td>
<p>Sample size of the respective samples. Sample size <code>n1</code> must be greater than 0 while sample size <code>n2</code> must be greater or equal to 0.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_decision">decision</code></td>
<td>
<p>Two-sample decision function to use; see <code><a href="#topic+decision2S">decision2S</a></code>.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_eps">eps</code></td>
<td>
<p>Support of random variables are determined as the
interval covering <code>1-eps</code> probability mass. Defaults to
<code class="reqn">10^{-6}</code>.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_sigma1">sigma1</code></td>
<td>
<p>The fixed reference scale of sample 1. If left
unspecified, the default reference scale of the prior 1 is assumed.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_sigma2">sigma2</code></td>
<td>
<p>The fixed reference scale of sample 2. If left
unspecified, the default reference scale of the prior 2 is assumed.</p>
</td></tr>
<tr><td><code id="oc2S_+3A_ngrid">Ngrid</code></td>
<td>
<p>Determines density of discretization grid on which
decision function is evaluated (see below for more details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>oc2S</code> function defines a 2 sample design and
returns a function which calculates its operating
characteristics. This is the frequency with which the decision
function is evaluated to 1 under the assumption of a given true
distribution of the data defined by the known parameter
<code class="reqn">\theta_1</code> and <code class="reqn">\theta_2</code>. The 2 sample design is defined
by the priors, the sample sizes and the decision function,
<code class="reqn">D(y_1,y_2)</code>. These uniquely define the decision boundary , see
<code><a href="#topic+decision2S_boundary">decision2S_boundary</a></code>.
</p>
<p>Calling the <code>oc2S</code> function calculates the decision boundary
<code class="reqn">D_1(y_2)</code> (see <code><a href="#topic+decision2S_boundary">decision2S_boundary</a></code>) and returns
a function which can be used to calculate the desired frequency
which is evaluated as
</p>
<p style="text-align: center;"><code class="reqn"> \int f_2(y_2|\theta_2) F_1(D_1(y_2)|\theta_1) dy_2. </code>
</p>

<p>See below for examples and specifics for the supported mixture
priors.
</p>


<h3>Value</h3>

<p>Returns a function which when called with two arguments
<code>theta1</code> and <code>theta2</code> will return the frequencies at
which the decision function is evaluated to 1 whenever the data is
distributed according to the known parameter values in each
sample. Note that the returned function takes vector arguments.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>oc2S(betaMix)</code>: Applies for binomial model with a mixture
beta prior. The calculations use exact expressions.  If the
optional argument <code>eps</code> is defined, then an approximate method
is used which limits the search for the decision boundary to the
region of <code>1-eps</code> probability mass. This is useful for designs
with large sample sizes where an exact approach is very costly to
calculate.
</p>
</li>
<li> <p><code>oc2S(normMix)</code>: Applies for the normal model with known
standard deviation <code class="reqn">\sigma</code> and normal mixture priors for the
means. As a consequence from the assumption of a known standard
deviation, the calculation discards sampling uncertainty of the
second moment. The function has two extra arguments (with
defaults): <code>eps</code> (<code class="reqn">10^{-6}</code>) and <code>Ngrid</code> (10). The
decision boundary is searched in the region of probability mass
<code>1-eps</code>, respectively for <code class="reqn">y_1</code> and <code class="reqn">y_2</code>. The
continuous decision function is evaluated at a discrete grid, which
is determined by a spacing with <code class="reqn">\delta_2 =
\sigma_2/\sqrt{N_{grid}}</code>. Once the decision boundary is evaluated
at the discrete steps, a spline is used to inter-polate the
decision boundary at intermediate points.
</p>
</li>
<li> <p><code>oc2S(gammaMix)</code>: Applies for the Poisson model with a gamma
mixture prior for the rate parameter.  The function
<code>oc2S</code> takes an extra argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>) which
determines the region of probability mass <code>1-eps</code> where the
boundary is searched for <code class="reqn">y_1</code> and <code class="reqn">y_2</code>, respectively.
</p>
</li></ul>


<h3>References</h3>

<p>Schmidli H, Gsteiger S, Roychoudhury S, O'Hagan A, Spiegelhalter D, Neuenschwander B.
Robust meta-analytic-predictive priors in clinical trials with historical control information.
<em>Biometrics</em> 2014;70(4):1023-1032.
</p>


<h3>See Also</h3>

<p>Other design2S: 
<code><a href="#topic+decision2S_boundary">decision2S_boundary</a>()</code>,
<code><a href="#topic+decision2S">decision2S</a>()</code>,
<code><a href="#topic+pos2S">pos2S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example from Schmidli et al., 2014
dec &lt;- decision2S(0.975, 0, lower.tail=FALSE)

prior_inf &lt;- mixbeta(c(1, 4, 16))
prior_rob &lt;- robustify(prior_inf, weight=0.2, mean=0.5)
prior_uni &lt;- mixbeta(c(1, 1,  1))

N &lt;- 40
N_ctl &lt;- N - 20

# compare designs with different priors
design_uni &lt;- oc2S(prior_uni, prior_uni, N, N_ctl, dec)
design_inf &lt;- oc2S(prior_uni, prior_inf, N, N_ctl, dec)
design_rob &lt;- oc2S(prior_uni, prior_rob, N, N_ctl, dec)

# type I error
curve(design_inf(x,x), 0, 1)
curve(design_uni(x,x), lty=2, add=TRUE)
curve(design_rob(x,x), lty=3, add=TRUE)

# power
curve(design_inf(0.2+x,0.2), 0, 0.5)
curve(design_uni(0.2+x,0.2), lty=2, add=TRUE)
curve(design_rob(0.2+x,0.2), lty=3, add=TRUE)


</code></pre>

<hr>
<h2 id='plot.EM'>Diagnostic plots for EM fits</h2><span id='topic+plot.EM'></span>

<h3>Description</h3>

<p>Produce diagnostic plots of EM fits returned from <code><a href="#topic+mixfit">mixfit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EM'
plot(x, size = 1.25, link = c("identity", "logit", "log"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.EM_+3A_x">x</code></td>
<td>
<p>EM fit</p>
</td></tr>
<tr><td><code id="plot.EM_+3A_size">size</code></td>
<td>
<p>Optional argument passed to <code>ggplot2</code> routines
which control line thickness.</p>
</td></tr>
<tr><td><code id="plot.EM_+3A_link">link</code></td>
<td>
<p>Choice of an applied link function. Can take one of the
values <code>identity</code> (default), <code>logit</code> or <code>log</code>.</p>
</td></tr>
<tr><td><code id="plot.EM_+3A_...">...</code></td>
<td>
<p>Ignored.
</p>
<p>Overlays the fitted mixture density with a histogram and a density
plot of the raw sample fitted. Applying a link function can be
beneficial, for example a <code>logit</code> (<code>log</code>) link for beta
(gamma) mixtures obtained from a Binomial (Poisson)
<code><a href="#topic+gMAP">gMAP</a></code> analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code> plots for
diagnostics of the EM run. Detailed EM diagnostic plots are
included only if the global option <code>RBesT.verbose</code> is set to
<code>TRUE</code>. These include plots of the parameters of each
component vs the iteration. The plot of the mixture density with a
histogram and a density of the fitted sample is always returned.
</p>


<h3>Customizing <span class="pkg">ggplot2</span> plots</h3>

<p>The returned plot is a <span class="pkg">ggplot2</span> object. Please refer to the
&quot;Customizing Plots&quot; vignette which is part of <span class="pkg">RBesT</span>
documentation for an introduction. For simple modifications (change
labels, add reference lines, ...) consider the commands found in
<code><a href="bayesplot.html#topic+bayesplot-helpers">bayesplot-helpers</a></code>. For more advanced
customizations please use the <span class="pkg">ggplot2</span> package directly. A
description of the most common tasks can be found in the
<a href="http://www.cookbook-r.com/Graphs/">R Cookbook</a> and a full
reference of available commands can be found at the
<a href="https://ggplot2.tidyverse.org/reference/">ggplot2 documentation
site</a>.
</p>


<h3>See Also</h3>

<p>Other EM: 
<code><a href="#topic+mixfit">mixfit</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
bmix &lt;- mixbeta(rob=c(0.2, 1, 1), inf=c(0.8, 10, 2))
bsamp &lt;- rmix(bmix, 1000)
bfit &lt;- mixfit(bsamp, type="beta", Nc=2)
pl &lt;- plot(bfit)

print(pl$mixdens)
print(pl$mix)


# a number of additional plots are generated in verbose mode
.user_option &lt;- options(RBesT.verbose=TRUE)
pl_all &lt;- plot(bfit)

# recover previous user options
options(.user_option)

names(pl_all)
# [1] "mixdist" "a"   "b"   "w"   "m"   "N"   "Lm"  "lN"  "Lw"  "lli" "mixdens" "mixecdf" "mix"


</code></pre>

<hr>
<h2 id='plot.gMAP'>Diagnostic plots for gMAP analyses</h2><span id='topic+plot.gMAP'></span>

<h3>Description</h3>

<p>Diagnostic plots for gMAP analyses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gMAP'
plot(x, size = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gMAP_+3A_x">x</code></td>
<td>
<p><code><a href="#topic+gMAP">gMAP</a></code> object</p>
</td></tr>
<tr><td><code id="plot.gMAP_+3A_size">size</code></td>
<td>
<p>Controls line sizes of traceplots and forest plot.</p>
</td></tr>
<tr><td><code id="plot.gMAP_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates MCMC diagnostics and a forest plot (including
model estimates) for a <code><a href="#topic+gMAP">gMAP</a></code> analysis. For a
customized forest plot, please use the dedicated function
<code><a href="#topic+forest_plot">forest_plot</a></code>.
</p>


<h3>Value</h3>

<p>The function returns a list of <code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>
objects.
</p>


<h3>Customizing <span class="pkg">ggplot2</span> plots</h3>

<p>The returned plot is a <span class="pkg">ggplot2</span> object. Please refer to the
&quot;Customizing Plots&quot; vignette which is part of <span class="pkg">RBesT</span>
documentation for an introduction. For simple modifications (change
labels, add reference lines, ...) consider the commands found in
<code><a href="bayesplot.html#topic+bayesplot-helpers">bayesplot-helpers</a></code>. For more advanced
customizations please use the <span class="pkg">ggplot2</span> package directly. A
description of the most common tasks can be found in the
<a href="http://www.cookbook-r.com/Graphs/">R Cookbook</a> and a full
reference of available commands can be found at the
<a href="https://ggplot2.tidyverse.org/reference/">ggplot2 documentation
site</a>.
</p>

<hr>
<h2 id='pos1S'>Probability of Success for a 1 Sample Design</h2><span id='topic+pos1S'></span><span id='topic+pos1S.betaMix'></span><span id='topic+pos1S.normMix'></span><span id='topic+pos1S.gammaMix'></span>

<h3>Description</h3>

<p>The <code>pos1S</code> function defines a 1 sample design (prior, sample
size, decision function) for the calculation of the frequency at
which the decision is evaluated to 1 when assuming a distribution
for the parameter. A function is returned which performs the
actual operating characteristics calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pos1S(prior, n, decision, ...)

## S3 method for class 'betaMix'
pos1S(prior, n, decision, ...)

## S3 method for class 'normMix'
pos1S(prior, n, decision, sigma, eps = 1e-06, ...)

## S3 method for class 'gammaMix'
pos1S(prior, n, decision, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pos1S_+3A_prior">prior</code></td>
<td>
<p>Prior for analysis.</p>
</td></tr>
<tr><td><code id="pos1S_+3A_n">n</code></td>
<td>
<p>Sample size for the experiment.</p>
</td></tr>
<tr><td><code id="pos1S_+3A_decision">decision</code></td>
<td>
<p>One-sample decision function to use; see <code><a href="#topic+decision1S">decision1S</a></code>.</p>
</td></tr>
<tr><td><code id="pos1S_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="pos1S_+3A_sigma">sigma</code></td>
<td>
<p>The fixed reference scale. If left unspecified, the
default reference scale of the prior is assumed.</p>
</td></tr>
<tr><td><code id="pos1S_+3A_eps">eps</code></td>
<td>
<p>Support of random variables are determined as the
interval covering <code>1-eps</code> probability mass. Defaults to
<code class="reqn">10^{-6}</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>pos1S</code> function defines a 1 sample design and
returns a function which calculates its probability of success.
The probability of success is the frequency with which the decision
function is evaluated to 1 under the assumption of a given true
distribution of the data implied by a distirbution of the parameter
<code class="reqn">\theta</code>.
</p>
<p>Calling the <code>pos1S</code> function calculates the critical value
<code class="reqn">y_c</code> and returns a function which can be used to evaluate the
PoS for different predictive distributions and is evaluated as
</p>
<p style="text-align: center;"><code class="reqn"> \int F(y_c|\theta) p(\theta) d\theta, </code>
</p>

<p>where <code class="reqn">F</code> is the distribution function of the sampling
distribution and <code class="reqn">p(\theta)</code> specifies the assumed true
distribution of the parameter <code class="reqn">\theta</code>. The distribution
<code class="reqn">p(\theta)</code> is a mixture distribution and given as the
<code>mix</code> argument to the function.
</p>


<h3>Value</h3>

<p>Returns a function that takes as single argument
<code>mix</code>, which is the mixture distribution of the control
parameter. Calling this function with a mixture distribution then
calculates the PoS.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>pos1S(betaMix)</code>: Applies for binomial model with a mixture
beta prior. The calculations use exact expressions.
</p>
</li>
<li> <p><code>pos1S(normMix)</code>: Applies for the normal model with known
standard deviation <code class="reqn">\sigma</code> and a normal mixture prior for the
mean. As a consequence from the assumption of a known standard
deviation, the calculation discards sampling uncertainty of the
second moment. The function <code>pos1S</code> has an extra
argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>). The critical value
<code class="reqn">y_c</code> is searched in the region of probability mass
<code>1-eps</code> for <code class="reqn">y</code>.
</p>
</li>
<li> <p><code>pos1S(gammaMix)</code>: Applies for the Poisson model with a gamma
mixture prior for the rate parameter.  The function
<code>pos1S</code> takes an extra argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>)
which determines the region of probability mass <code>1-eps</code> where
the boundary is searched for <code class="reqn">y</code>.
</p>
</li></ul>


<h3>See Also</h3>

<p>Other design1S: 
<code><a href="#topic+decision1S_boundary">decision1S_boundary</a>()</code>,
<code><a href="#topic+decision1S">decision1S</a>()</code>,
<code><a href="#topic+oc1S">oc1S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# non-inferiority example using normal approximation of log-hazard
# ratio, see ?decision1S for all details
s &lt;- 2
flat_prior &lt;- mixnorm(c(1,0,100), sigma=s)
nL &lt;- 233
theta_ni &lt;- 0.4
theta_a &lt;- 0
alpha &lt;- 0.05
beta  &lt;- 0.2
za &lt;- qnorm(1-alpha)
zb &lt;- qnorm(1-beta)
n1 &lt;- round( (s * (za + zb)/(theta_ni - theta_a))^2 )
theta_c &lt;- theta_ni - za * s / sqrt(n1)

# assume we would like to conduct at an interim analysis
# of PoS after having observed 20 events with a HR of 0.8.
# We first need the posterior at the interim ...
post_ia &lt;- postmix(flat_prior, m=log(0.8), n=20)

# dual criterion
decComb &lt;- decision1S(c(1-alpha, 0.5), c(theta_ni, theta_c), lower.tail=TRUE)

# ... and we would like to know the PoS for a successful
# trial at the end when observing 10 more events
pos_ia &lt;- pos1S(post_ia, 10, decComb)

# our knowledge at the interim is just the posterior at
# interim such that the PoS is
pos_ia(post_ia)


</code></pre>

<hr>
<h2 id='pos2S'>Probability of Success for 2 Sample Design</h2><span id='topic+pos2S'></span><span id='topic+pos2S.betaMix'></span><span id='topic+pos2S.normMix'></span><span id='topic+pos2S.gammaMix'></span>

<h3>Description</h3>

<p>The <code>pos2S</code> function defines a 2 sample design (priors, sample
sizes &amp; decision function) for the calculation of the probability
of success. A function is returned which calculates the calculates
the frequency at which the decision function is evaluated to 1 when
parameters are distributed according to the given distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pos2S(prior1, prior2, n1, n2, decision, ...)

## S3 method for class 'betaMix'
pos2S(prior1, prior2, n1, n2, decision, eps, ...)

## S3 method for class 'normMix'
pos2S(
  prior1,
  prior2,
  n1,
  n2,
  decision,
  sigma1,
  sigma2,
  eps = 1e-06,
  Ngrid = 10,
  ...
)

## S3 method for class 'gammaMix'
pos2S(prior1, prior2, n1, n2, decision, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pos2S_+3A_prior1">prior1</code></td>
<td>
<p>Prior for sample 1.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_prior2">prior2</code></td>
<td>
<p>Prior for sample 2.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_n1">n1</code>, <code id="pos2S_+3A_n2">n2</code></td>
<td>
<p>Sample size of the respective samples. Sample size <code>n1</code> must be greater than 0 while sample size <code>n2</code> must be greater or equal to 0.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_decision">decision</code></td>
<td>
<p>Two-sample decision function to use; see <code><a href="#topic+decision2S">decision2S</a></code>.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_eps">eps</code></td>
<td>
<p>Support of random variables are determined as the
interval covering <code>1-eps</code> probability mass. Defaults to
<code class="reqn">10^{-6}</code>.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_sigma1">sigma1</code></td>
<td>
<p>The fixed reference scale of sample 1. If left
unspecified, the default reference scale of the prior 1 is assumed.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_sigma2">sigma2</code></td>
<td>
<p>The fixed reference scale of sample 2. If left
unspecified, the default reference scale of the prior 2 is assumed.</p>
</td></tr>
<tr><td><code id="pos2S_+3A_ngrid">Ngrid</code></td>
<td>
<p>Determines density of discretization grid on which
decision function is evaluated (see below for more details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>pos2S</code> function defines a 2 sample design and
returns a function which calculates its probability of success.
The probability of success is the frequency with which the decision
function is evaluated to 1 under the assumption of a given true
distribution of the data implied by a distirbution of the
parameters <code class="reqn">\theta_1</code> and <code class="reqn">\theta_2</code>.
</p>
<p>The calculation is analogous to the operating characeristics
<code><a href="#topic+oc2S">oc2S</a></code> with the difference that instead of assuming
known (point-wise) true parameter values a distribution is
specified for each parameter.
</p>
<p>Calling the <code>pos2S</code> function calculates the decision boundary
<code class="reqn">D_1(y_2)</code> and returns a function which can be used to evaluate the
PoS for different predictive distributions. It is evaluated as
</p>
<p style="text-align: center;"><code class="reqn"> \int\int\int f_2(y_2|\theta_2) \, p(\theta_2) \, F_1(D_1(y_2)|\theta_1) \, p(\theta_1) \, dy_2 d\theta_2 d\theta_1. </code>
</p>

<p>where <code class="reqn">F</code> is the distribution function of the sampling
distribution and <code class="reqn">p(\theta_1)</code> and <code class="reqn">p(\theta_2)</code> specifies
the assumed true distribution of the parameters <code class="reqn">\theta_1</code> and
<code class="reqn">\theta_2</code>, respectively. Each distribution <code class="reqn">p(\theta_1)</code>
and <code class="reqn">p(\theta_2)</code> is a mixture distribution and given as the
<code>mix1</code> and <code>mix2</code> argument to the function.
</p>
<p>For example, in the binary case an integration of the predictive
distribution, the BetaBinomial, instead of the binomial
distribution will be performed over the data space wherever the
decision function is evaluated to 1. All other aspects of the
calculation are as for the 2-sample operating characteristics, see
<code><a href="#topic+oc2S">oc2S</a></code>.
</p>


<h3>Value</h3>

<p>Returns a function which when called with two arguments
<code>mix1</code> and <code>mix2</code> will return the frequencies at
which the decision function is evaluated to 1. Each argument is
expected to be a mixture distribution representing the assumed true
distribution of the parameter in each group.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>pos2S(betaMix)</code>: Applies for binomial model with a mixture
beta prior. The calculations use exact expressions.  If the
optional argument <code>eps</code> is defined, then an approximate method
is used which limits the search for the decision boundary to the
region of <code>1-eps</code> probability mass. This is useful for designs
with large sample sizes where an exact approach is very costly to
calculate.
</p>
</li>
<li> <p><code>pos2S(normMix)</code>: Applies for the normal model with known
standard deviation <code class="reqn">\sigma</code> and normal mixture priors for the
means. As a consequence from the assumption of a known standard
deviation, the calculation discards sampling uncertainty of the
second moment. The function has two extra arguments (with
defaults): <code>eps</code> (<code class="reqn">10^{-6}</code>) and <code>Ngrid</code> (10). The
decision boundary is searched in the region of probability mass
<code>1-eps</code>, respectively for <code class="reqn">y_1</code> and <code class="reqn">y_2</code>. The
continuous decision function is evaluated at a discrete grid, which
is determined by a spacing with <code class="reqn">\delta_2 =
\sigma_2/\sqrt{N_{grid}}</code>. Once the decision boundary is evaluated
at the discrete steps, a spline is used to inter-polate the
decision boundary at intermediate points.
</p>
</li>
<li> <p><code>pos2S(gammaMix)</code>: Applies for the Poisson model with a gamma
mixture prior for the rate parameter.  The function
<code>pos2S</code> takes an extra argument <code>eps</code> (defaults to <code class="reqn">10^{-6}</code>) which
determines the region of probability mass <code>1-eps</code> where the
boundary is searched for <code class="reqn">y_1</code> and <code class="reqn">y_2</code>, respectively.
</p>
</li></ul>


<h3>See Also</h3>

<p>Other design2S: 
<code><a href="#topic+decision2S_boundary">decision2S_boundary</a>()</code>,
<code><a href="#topic+decision2S">decision2S</a>()</code>,
<code><a href="#topic+oc2S">oc2S</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# see ?decision2S for details of example
priorT &lt;- mixnorm(c(1,   0, 0.001), sigma=88, param="mn")
priorP &lt;- mixnorm(c(1, -49, 20   ), sigma=88, param="mn")
# the success criteria is for delta which are larger than some
# threshold value which is why we set lower.tail=FALSE
successCrit  &lt;- decision2S(c(0.95, 0.5), c(0, 50), FALSE)

# example interim outcome
postP_interim &lt;- postmix(priorP, n=10, m=-50)
postT_interim &lt;- postmix(priorT, n=20, m=-80)

# assume that mean -50 / -80 were observed at the interim for
# placebo control(n=10) / active treatment(n=20) which gives
# the posteriors
postP_interim
postT_interim

# then the PoS to succeed after another 20/30 patients is
pos_final &lt;- pos2S(postP_interim, postT_interim, 20, 30, successCrit)

pos_final(postP_interim, postT_interim)

</code></pre>

<hr>
<h2 id='postmix'>Conjugate Posterior Analysis</h2><span id='topic+postmix'></span><span id='topic+postmix.betaMix'></span><span id='topic+postmix.normMix'></span><span id='topic+postmix.gammaMix'></span>

<h3>Description</h3>

<p>Calculates the posterior distribution for data <code>data</code> given a prior
<code>priormix</code>, where the prior is a mixture of conjugate distributions. 
The posterior is then also a mixture of conjugate distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postmix(priormix, data, ...)

## S3 method for class 'betaMix'
postmix(priormix, data, n, r, ...)

## S3 method for class 'normMix'
postmix(priormix, data, n, m, se, ...)

## S3 method for class 'gammaMix'
postmix(priormix, data, n, m, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postmix_+3A_priormix">priormix</code></td>
<td>
<p>prior (mixture of conjugate distributions).</p>
</td></tr>
<tr><td><code id="postmix_+3A_data">data</code></td>
<td>
<p>individual data. If the individual data is not given, then
summary data has to be provided (see below).</p>
</td></tr>
<tr><td><code id="postmix_+3A_...">...</code></td>
<td>
<p>includes arguments which depend on the specific case, see description below.</p>
</td></tr>
<tr><td><code id="postmix_+3A_n">n</code></td>
<td>
<p>sample size.</p>
</td></tr>
<tr><td><code id="postmix_+3A_r">r</code></td>
<td>
<p>Number of successes.</p>
</td></tr>
<tr><td><code id="postmix_+3A_m">m</code></td>
<td>
<p>Sample mean.</p>
</td></tr>
<tr><td><code id="postmix_+3A_se">se</code></td>
<td>
<p>Sample standard error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A conjugate prior-likelihood pair has the convenient
property that the posterior is in the same distributional class as
the prior. This property also applies to mixtures of conjugate
priors. Let
</p>
<p style="text-align: center;"><code class="reqn">p(\theta;\mathbf{w},\mathbf{a},\mathbf{b})</code>
</p>

<p>denote a conjugate mixture prior density for data
</p>
<p style="text-align: center;"><code class="reqn">y|\theta \sim f(y|\theta),</code>
</p>

<p>where <code class="reqn">f(y|\theta)</code> is the likelihood. Then the posterior is
again a mixture with each component <code class="reqn">k</code> equal to the respective
posterior of the <code class="reqn">k</code>th prior component and updated weights
<code class="reqn">w'_k</code>,
</p>
<p style="text-align: center;"><code class="reqn">p(\theta;\mathbf{w'},\mathbf{a'},\mathbf{b'}|y) = \sum_{k=1}^K w'_k \, p_k(\theta;a'_k,b'_k|y).</code>
</p>

<p>The weight <code class="reqn">w'_k</code> for <code class="reqn">k</code>th component is determined by the
marginal likelihood of the new data <code class="reqn">y</code> under the <code class="reqn">k</code>th prior
distribution which is given by the predictive distribution of the
<code class="reqn">k</code>th component,
</p>
<p style="text-align: center;"><code class="reqn">w'_k \propto w_k \, \int p_k(\theta;a_k,b_k) \, f(y|\theta) \, d\theta \equiv w^\ast_k .</code>
</p>

<p>The final weight <code class="reqn">w'_k</code> is then given by appropriate
normalization, <code class="reqn">w'_k = w^\ast_k / \sum_{k=1}^K w^\ast_k</code>. In other words, the weight of
component <code class="reqn">k</code> is proportional to the likelihood that data
<code class="reqn">y</code> is generated from the respective component, i.e. the
marginal probability; for details, see for example <em>Schmidli
et al., 2015</em>.
</p>
<p><em>Note:</em> The prior weights <code class="reqn">w_k</code> are fixed, but the
posterior weights <code class="reqn">w'_k \neq w_k</code> still change due to the
changing normalization.
</p>
<p>The data <code class="reqn">y</code> can either be given as individual data or as
summary data (sufficient statistics). See below for details for the
implemented conjugate mixture prior densities.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>postmix(betaMix)</code>: Calculates the posterior beta mixture
distribution. The individual data vector is expected to be a vector
of 0 and 1, i.e. a series of Bernoulli experiments. Alternatively,
the sufficient statistics <code>n</code> and <code>r</code> can be given,
i.e. number of trials and successes, respectively.
</p>
</li>
<li> <p><code>postmix(normMix)</code>: Calculates the posterior normal mixture
distribution with the sampling likelihood being a normal with fixed
standard deviation. Either an individual data vector <code>data</code>
can be given or the sufficient statistics which are the standard
error <code>se</code> and sample mean <code>m</code>. If the sample size
<code>n</code> is used instead of the sample standard error, then the
reference scale of the prior is used to calculate the standard
error. Should standard error <code>se</code> and sample size <code>n</code> be
given, then the reference scale of the prior is updated; however it
is recommended to use the command <code><a href="#topic+sigma">sigma</a></code> to set the
reference standard deviation.
</p>
</li>
<li> <p><code>postmix(gammaMix)</code>: Calculates the posterior gamma mixture
distribution for Poisson and exponential likelihoods. Only the
Poisson case is supported in this version.
</p>
</li></ul>


<h3>Supported Conjugate Prior-Likelihood Pairs</h3>


<table>
<tr>
 <td style="text-align: left;">
<strong>Prior/Posterior</strong> </td><td style="text-align: center;"> <strong>Likelihood</strong> </td><td style="text-align: center;"> <strong>Predictive</strong> 
 </td><td style="text-align: center;"> <strong>Summaries</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
Beta </td><td style="text-align: center;"> Binomial </td><td style="text-align: center;"> Beta-Binomial </td><td style="text-align: center;"> <code>n</code>, <code>r</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Normal </td><td style="text-align: center;"> Normal (<em>fixed <code class="reqn">\sigma</code></em>) </td><td style="text-align: center;"> Normal </td><td style="text-align: center;"> <code>n</code>, <code>m</code>, <code>se</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Poisson </td><td style="text-align: center;"> Gamma-Poisson </td><td style="text-align: center;">  <code>n</code>, <code>m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Exponential </td><td style="text-align: center;"> Gamma-Exp (<em>not supported</em>) </td><td style="text-align: center;"> <code>n</code>, <code>m</code>
</td>
</tr>

</table>



<h3>References</h3>

<p>Schmidli H, Gsteiger S, Roychoudhury S, O'Hagan A, Spiegelhalter D, Neuenschwander B.
Robust meta-analytic-predictive priors in clinical trials with historical control information.
<em>Biometrics</em> 2014;70(4):1023-1032.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# binary example with individual data (1=event,0=no event), uniform prior
prior.unif &lt;- mixbeta(c(1, 1, 1))
data.indiv &lt;- c(1,0,1,1,0,1)
posterior.indiv &lt;- postmix(prior.unif, data.indiv) 
print(posterior.indiv)
# or with summary data (number of events and number of patients)
r &lt;- sum(data.indiv); n &lt;- length(data.indiv)
posterior.sum &lt;- postmix(prior.unif, n=n, r=r)
print(posterior.sum)

# binary example with robust informative prior and conflicting data
prior.rob &lt;- mixbeta(c(0.5,4,10),c(0.5,1,1))
posterior.rob &lt;- postmix(prior.rob, n=20, r=18)
print(posterior.rob)

# normal example with individual data
sigma &lt;- 88
prior.mean &lt;- -49
prior.se &lt;- sigma/sqrt(20)
prior &lt;- mixnorm(c(1,prior.mean,prior.se),sigma=sigma)
data.indiv &lt;- c(-46,-227,41,-65,-103,-22,7,-169,-69,90)
posterior.indiv &lt;- postmix(prior, data.indiv)
# or with summary data (mean and number of patients)
mn &lt;- mean(data.indiv); n &lt;- length(data.indiv)
posterior.sum &lt;- postmix(prior, m=mn, n=n)
print(posterior.sum)

</code></pre>

<hr>
<h2 id='preddist'>Predictive Distributions for Mixture Distributions</h2><span id='topic+preddist'></span><span id='topic+preddist.betaMix'></span><span id='topic+preddist.normMix'></span><span id='topic+preddist.gammaMix'></span><span id='topic+preddist.mvnormMix'></span>

<h3>Description</h3>

<p>Predictive distribution for mixture of conjugate distributions
(beta, normal, gamma).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preddist(mix, ...)

## S3 method for class 'betaMix'
preddist(mix, n = 1, ...)

## S3 method for class 'normMix'
preddist(mix, n = 1, sigma, ...)

## S3 method for class 'gammaMix'
preddist(mix, n = 1, ...)

## S3 method for class 'mvnormMix'
preddist(mix, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preddist_+3A_mix">mix</code></td>
<td>
<p>mixture distribution</p>
</td></tr>
<tr><td><code id="preddist_+3A_...">...</code></td>
<td>
<p>includes arguments which depend on the specific prior-likelihood pair, see description below.</p>
</td></tr>
<tr><td><code id="preddist_+3A_n">n</code></td>
<td>
<p>predictive sample size, set by default to 1</p>
</td></tr>
<tr><td><code id="preddist_+3A_sigma">sigma</code></td>
<td>
<p>The fixed reference scale of a normal mixture. If left
unspecified, the default reference scale of the mixture is
assumed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a mixture density (either a posterior or a prior)
</p>
<p style="text-align: center;"><code class="reqn">p(\theta,\mathbf{w},\mathbf{a},\mathbf{b})</code>
</p>

<p>and a data likelihood of
</p>
<p style="text-align: center;"><code class="reqn">y|\theta \sim f(y|\theta),</code>
</p>

<p>the predictive distribution of a one-dimensional summary <code class="reqn">y_n</code>
of $n$ future observations is distributed as
</p>
<p style="text-align: center;"><code class="reqn">y_n \sim \int p(\theta,\mathbf{w},\mathbf{a},\mathbf{b}) \, f(y_n|\theta) \, d\theta .</code>
</p>

<p>This distribution is the marginal distribution of the data under
the mixture density. For binary and Poisson data <code class="reqn">y_n =
\sum_{i=1}^n y_i</code> is the sum over future events. For normal data,
it is the mean<code class="reqn">\bar{y}_n = 1/n \sum_{i=1}^n y_i</code>.
</p>


<h3>Value</h3>

<p>The function returns for a normal, beta or gamma mixture
the matching predictive distribution for <code class="reqn">y_n</code>.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>preddist(betaMix)</code>: Obtain the matching predictive distribution
for a beta distribution, the BetaBinomial.
</p>
</li>
<li> <p><code>preddist(normMix)</code>: Obtain the matching predictive distribution
for a Normal with constant standard deviation. Note that the
reference scale of the returned Normal mixture is meaningless
as the individual components are updated appropriatley.
</p>
</li>
<li> <p><code>preddist(gammaMix)</code>: Obtain the matching predictive distribution
for a Gamma. Only Poisson likelihoods are supported.
</p>
</li>
<li> <p><code>preddist(mvnormMix)</code>: Multivariate normal mixtures predictive
densities are not (yet) supported.
</p>
</li></ul>


<h3>Supported Conjugate Prior-Likelihood Pairs</h3>


<table>
<tr>
 <td style="text-align: left;">
<strong>Prior/Posterior</strong> </td><td style="text-align: center;"> <strong>Likelihood</strong> </td><td style="text-align: center;"> <strong>Predictive</strong> 
 </td><td style="text-align: center;"> <strong>Summaries</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
Beta </td><td style="text-align: center;"> Binomial </td><td style="text-align: center;"> Beta-Binomial </td><td style="text-align: center;"> <code>n</code>, <code>r</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Normal </td><td style="text-align: center;"> Normal (<em>fixed <code class="reqn">\sigma</code></em>) </td><td style="text-align: center;"> Normal </td><td style="text-align: center;"> <code>n</code>, <code>m</code>, <code>se</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Poisson </td><td style="text-align: center;"> Gamma-Poisson </td><td style="text-align: center;">  <code>n</code>, <code>m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
Gamma </td><td style="text-align: center;"> Exponential </td><td style="text-align: center;"> Gamma-Exp (<em>not supported</em>) </td><td style="text-align: center;"> <code>n</code>, <code>m</code>
</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1: predictive distribution from uniform prior.
bm &lt;- mixbeta(c(1,1,1))
bmPred &lt;- preddist(bm, n=10)
# predictive proabilities and cumulative predictive probabilities
x &lt;- 0:10
d &lt;- dmix(bmPred, x)
names(d) &lt;- x
barplot(d)
cd &lt;- pmix(bmPred, x)
names(cd) &lt;- x
barplot(cd)
# median
mdn &lt;- qmix(bmPred,0.5)
mdn

# Example 2: 2-comp Beta mixture

bm &lt;- mixbeta( inf=c(0.8,15,50),rob=c(0.2,1,1))
plot(bm)
bmPred &lt;- preddist(bm,n=10)
plot(bmPred)
mdn &lt;- qmix(bmPred,0.5)
mdn
d &lt;- dmix(bmPred,x=0:10)

n.sim &lt;- 100000
r &lt;-  rmix(bmPred,n.sim)
d
table(r)/n.sim


# Example 3: 3-comp Normal mixture

m3 &lt;- mixnorm( c(0.50,-0.2,0.1),c(0.25,0,0.2), c(0.25,0,0.5), sigma=10)
print(m3)
summary(m3)
plot(m3)
predm3 &lt;- preddist(m3,n=2)
plot(predm3)
print(predm3)
summary(predm3)

</code></pre>

<hr>
<h2 id='predict.gMAP'>Predictions from gMAP analyses</h2><span id='topic+predict.gMAP'></span><span id='topic+print.gMAPpred'></span><span id='topic+summary.gMAPpred'></span><span id='topic+as.matrix.gMAPpred'></span>

<h3>Description</h3>

<p>Produces a sample of the predictive distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gMAP'
predict(
  object,
  newdata,
  type = c("response", "link"),
  probs = c(0.025, 0.5, 0.975),
  na.action = na.pass,
  thin,
  ...
)

## S3 method for class 'gMAPpred'
print(x, digits = 3, ...)

## S3 method for class 'gMAPpred'
summary(object, ...)

## S3 method for class 'gMAPpred'
as.matrix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gMAP_+3A_newdata">newdata</code></td>
<td>
<p>data.frame which must contain the same columns as
input into the gMAP analysis. If left out, then a posterior prediction for
the fitted data entries from the gMAP object is performed (shrinkage estimates).</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_type">type</code></td>
<td>
<p>sets reported scale (<code>response</code> (default) or <code>link</code>).</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_probs">probs</code></td>
<td>
<p>defines quantiles to be reported.</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_na.action">na.action</code></td>
<td>
<p>how to handle missings.</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_thin">thin</code></td>
<td>
<p>thinning applied is derived from the <code>gMAP</code> object.</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_x">x</code>, <code id="predict.gMAP_+3A_object">object</code></td>
<td>
<p>gMAP analysis object for which predictions are performed</p>
</td></tr>
<tr><td><code id="predict.gMAP_+3A_digits">digits</code></td>
<td>
<p>number of displayed significant digits.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions are made using the <code class="reqn">\tau</code> prediction
stratum of the gMAP object. For details on the syntax, please refer
to <code><a href="stats.html#topic+predict.glm">predict.glm</a></code> and the example below.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gMAP">gMAP</a></code>, <code><a href="stats.html#topic+predict.glm">predict.glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Setting up dummy sampling for fast execution of example
## Please use 4 chains and 20x more warmup &amp; iter in practice
.user_mc_options &lt;- options(RBesT.MC.warmup=50, RBesT.MC.iter=100,
                            RBesT.MC.chains=2, RBesT.MC.thin=1)

# create a fake data set with a covariate
trans_cov &lt;- transform(transplant, country=cut(1:11, c(0,5,8,Inf), c("CH", "US", "DE")))
set.seed(34246)
map &lt;- gMAP(cbind(r, n-r) ~ 1 + country | study,
            data=trans_cov,
            tau.dist="HalfNormal",
            tau.prior=1,
            # Note on priors: we make the overall intercept weakly-informative
            # and the regression coefficients must have tighter sd as these are
            # deviations in the default contrast parametrization
            beta.prior=rbind(c(0,2), c(0,1), c(0,1)),
            family=binomial,
            ## ensure fast example runtime
            thin=1, chains=1)

# posterior predictive distribution for each input data item (shrinkage estimates)
pred_cov &lt;- predict(map)
pred_cov

# extract sample as matrix
samp &lt;- as.matrix(pred_cov)

# predictive distribution for each input data item (if the input studies were new ones)
pred_cov_pred &lt;- predict(map, trans_cov)
pred_cov_pred


# a summary function returns the results as matrix
summary(pred_cov)

# obtain a prediction for new data with specific covariates
pred_new &lt;- predict(map, data.frame(country="CH", study=12))
pred_new

## Recover user set sampling defaults
options(.user_mc_options)

</code></pre>

<hr>
<h2 id='robustify'>Robustify Mixture Priors</h2><span id='topic+robustify'></span><span id='topic+robustify.betaMix'></span><span id='topic+robustify.gammaMix'></span><span id='topic+robustify.normMix'></span>

<h3>Description</h3>

<p>Add a non-informative component to a mixture prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robustify(priormix, weight, mean, n = 1, ...)

## S3 method for class 'betaMix'
robustify(priormix, weight, mean, n = 1, ...)

## S3 method for class 'gammaMix'
robustify(priormix, weight, mean, n = 1, ...)

## S3 method for class 'normMix'
robustify(priormix, weight, mean, n = 1, ..., sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="robustify_+3A_priormix">priormix</code></td>
<td>
<p>orior (mixture of conjugate distributions).</p>
</td></tr>
<tr><td><code id="robustify_+3A_weight">weight</code></td>
<td>
<p>weight given to the non-informative component (0 &lt; <code>weight</code> &lt; 1).</p>
</td></tr>
<tr><td><code id="robustify_+3A_mean">mean</code></td>
<td>
<p>mean of the non-informative component. It is recommended to set this parameter explicitly.</p>
</td></tr>
<tr><td><code id="robustify_+3A_n">n</code></td>
<td>
<p>number of observations the non-informative prior
corresponds to, defaults to 1.</p>
</td></tr>
<tr><td><code id="robustify_+3A_...">...</code></td>
<td>
<p>optional arguments are ignored.</p>
</td></tr>
<tr><td><code id="robustify_+3A_sigma">sigma</code></td>
<td>
<p>Sampling standard deviation for the case of Normal
mixtures.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is recommended to robustify informative priors derived
with <code><a href="#topic+gMAP">gMAP</a></code> using unit-information priors . This
protects against prior-data conflict, see for example
<em>Schmidli et al., 2015</em>.
</p>
<p>The procedure can be used with beta, gamma and normal mixture
priors. A unit-information prior (see <em>Kass and Wasserman,
1995</em>) corresponds to a prior which represents the observation of
n=1 at the null hypothesis. As the null is problem dependent we
<em>strongly recommend</em> to make use of the <code>mean</code> argument
accordingly. See below for the definition of the default mean.
</p>
<p>The weights of the mixture priors are rescaled to <code>(1-weight)</code>
while the non-informative prior is assigned the <code>weight</code>
given.
</p>


<h3>Value</h3>

<p>New mixture with an extra non-informative component named
<code>robust</code>.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>robustify(betaMix)</code>: The default <code>mean</code> is set to 1/2 which
represents no difference between the occurrence rates for one of the
two outcomes. As the uniform <code>Beta(1,1)</code> is more appropriate in
practical applications, <code>RBesT</code> uses <code>n+1</code> as the sample
size such that the default robust prior is the uniform instead of
the <code>Beta(1/2,1/2)</code> which strictly defined would be the unit
information prior in this case.
</p>
</li>
<li> <p><code>robustify(gammaMix)</code>: The default <code>mean</code> is set to the mean of the
prior mixture. It is strongly recommended to explicitly set the
mean to the location of the null hypothesis.
</p>
</li>
<li> <p><code>robustify(normMix)</code>: The default <code>mean</code> is set to the mean
of the prior mixture. It is strongly recommended to explicitly set
the mean to the location of the null hypothesis, which is very
often equal to 0. It is also recommended to explicitly set the
sampling standard deviation using the <code>sigma</code> argument.
</p>
</li></ul>


<h3>References</h3>

<p>Schmidli H, Gsteiger S, Roychoudhury S, O'Hagan A,
Spiegelhalter D, Neuenschwander B.  Robust meta-analytic-predictive
priors in clinical trials with historical control information.
<em>Biometrics</em> 2014;70(4):1023-1032.
</p>
<p>Kass RE, Wasserman L A Reference Bayesian Test for Nested
Hypotheses and its Relationship to the Schwarz Criterion <em>J
Amer Statist Assoc</em> 1995; 90(431):928-934.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixcombine">mixcombine</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bmix &lt;- mixbeta(inf1=c(0.2, 8, 3), inf2=c(0.8, 10, 2))
plot(bmix)
rbmix &lt;- robustify(bmix, weight=0.1, mean=0.5)
rbmix
plot(rbmix)

gmnMix &lt;- mixgamma(inf1=c(0.2, 2, 3), inf2=c(0.8, 2, 5), param="mn")
plot(gmnMix)
rgmnMix &lt;- robustify(gmnMix, weight=0.1, mean=2)
rgmnMix
plot(rgmnMix)

nm &lt;- mixnorm(inf1=c(0.2, 0.5, 0.7), inf2=c(0.8, 2, 1), sigma=2)
plot(nm)
rnMix &lt;- robustify(nm, weight=0.1, mean=0, sigma=2)
rnMix
plot(rnMix)

</code></pre>

<hr>
<h2 id='SimSum'>Summarize Arrays</h2><span id='topic+SimSum'></span>

<h3>Description</h3>

<p>The function calculates summary statistics from arbitrary arrays.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimSum(
  x,
  min.max = FALSE,
  n.sim = FALSE,
  probs = c(0.025, 0.5, 0.975),
  margin = ifelse(is.null(dim(x) | length(dim(x)) == 1), 2, length(dim(x)))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimSum_+3A_x">x</code></td>
<td>
<p>Object to summarize which can be a numerical vector, matrix or a multi-dimensional array</p>
</td></tr>
<tr><td><code id="SimSum_+3A_min.max">min.max</code></td>
<td>
<p>Enables to include minimum and maximum in the output.</p>
</td></tr>
<tr><td><code id="SimSum_+3A_n.sim">n.sim</code></td>
<td>
<p>Enables to include the number of observations in the output.</p>
</td></tr>
<tr><td><code id="SimSum_+3A_probs">probs</code></td>
<td>
<p>Quantiles to output.</p>
</td></tr>
<tr><td><code id="SimSum_+3A_margin">margin</code></td>
<td>
<p>Margin of the input array over which the summary function is applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates by default the mean, standard
deviation and the specified qantiles which are by default the
median and the 95
</p>
<p>If a mulit-dimensional array is specified as <code>x</code>, then the
function will by default calculate the summaries over the margin of
the largest dimension. For the case of a vector and a matrix, the
function will transpose the results for better readabiliy.
</p>

<hr>
<h2 id='support'>Support of Distributions</h2><span id='topic+support'></span>

<h3>Description</h3>

<p>Returns the support of a distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>support(mix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="support_+3A_mix">mix</code></td>
<td>
<p>Mixture distribution.</p>
</td></tr>
</table>

<hr>
<h2 id='transplant'>Transplant.</h2><span id='topic+transplant'></span>

<h3>Description</h3>

<p>Data set containing historical information for standard treatment
for a phase IV trial in de novo transplant patients. The primary
outcome is treament failure (binary).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transplant
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 rows and 3 variables:
</p>

<dl>
<dt>study</dt><dd><p>study</p>
</dd>
<dt>n</dt><dd><p>study size</p>
</dd>
<dt>r</dt><dd><p>number of events</p>
</dd>
</dl>



<h3>References</h3>

<p>Neuenschwander B, Capkun-Niggli G, Branson M,
Spiegelhalter DJ. Summarizing historical information on controls in
clinical trials. <em>Clin Trials</em>. 2010; 7(1):5-18
</p>

<hr>
<h2 id='uniroot_int'>Find root of univariate function of integers</h2><span id='topic+uniroot_int'></span>

<h3>Description</h3>

<p>Uses a bisectioning algorithm to search the give interval for a
change of sign and returns the integer which is closest to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniroot_int(
  f,
  interval,
  ...,
  f.lower = f(interval[1], ...),
  f.upper = f(interval[2], ...),
  maxIter = 1000
)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
