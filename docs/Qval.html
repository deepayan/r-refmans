<!DOCTYPE html><html><head><title>Help for package Qval</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Qval}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CDM'><p>Parameter estimation for cognitive diagnosis models (CDMs) by MMLE/EM or MMLE/BM algorithm.</p></a></li>
<li><a href='#fit'><p>Calculate data fit indeces</p></a></li>
<li><a href='#get.Mmatrix'><p>Calculate <code class="reqn">\mathbf{M}</code> matrix</p></a></li>
<li><a href='#get.PVAF'><p>Calculate <code class="reqn">PVAF</code></p></a></li>
<li><a href='#get.R2'><p>Calculate McFadden pseudo-<code class="reqn">R^{2}</code></p></a></li>
<li><a href='#getOSR'><p>Caculate over-specifcation rate (OSR)</p></a></li>
<li><a href='#getQRR'><p>Caculate Q-matrix recovery rate (QRR)</p></a></li>
<li><a href='#getTNR'><p>Calculate true negative rate (TNR)</p></a></li>
<li><a href='#getTPR'><p>Caculate true-positive rate (TPR)</p></a></li>
<li><a href='#getUSR'><p>Caculate under-specifcation rate (USR)</p></a></li>
<li><a href='#getVRR'><p>Caculate vector recovery ratio (VRR)</p></a></li>
<li><a href='#sim.data'><p>generate response data</p></a></li>
<li><a href='#sim.MQ'><p>Simulate mis-specifications</p></a></li>
<li><a href='#sim.Q'><p>generate a random Q-matrix</p></a></li>
<li><a href='#validation'><p>Perform Q-matrix validation methods</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The Q-Matrix Validation Methods Framework</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-02</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Haijiang Qin &lt;haijiang133@outlook.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provide a variety of Q-matrix validation methods for the generalized cognitive diagnosis models, including the method based on the generalized deterministic input, noisy, and gate model (G-DINA) by de la Torre (2011) &lt;<a href="https://doi.org/10.1007%2Fs11336-011-9207-7">doi:10.1007/s11336-011-9207-7</a>&gt; discrimination index (the GDI method) by de la Torre and Chiu (2016) &lt;<a href="https://doi.org/10.1007%2Fs11336-015-9467-8">doi:10.1007/s11336-015-9467-8</a>&gt;, the step-wise Wald test method (the Wald method) by Ma and de la Torre (2020) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12156">doi:10.1111/bmsp.12156</a>&gt;, the Hull method by Najera et al. (2021) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12228">doi:10.1111/bmsp.12228</a>&gt;, the multiple logistic regression‑based Q‑matrix validation method (the MLR-B method) by Tu et al. (2022) &lt;<a href="https://doi.org/10.3758%2Fs13428-022-01880-x">doi:10.3758/s13428-022-01880-x</a>&gt;. Different research methods during Q-matrix validating are available.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, GDINA, plyr, nloptr, Matrix, stats</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Collate:</td>
<td>'CDM.R' 'convex.R' 'cov.R' 'fit.R' 'GDI.R' 'Hull.R' 'MLR-B.R'
'MLR.R' 'MLRlasso.R' 'Mmatrix.R' 'OSR.R' 'P.R' 'Pattern.R'
'priority.R' 'PVAF.R' 'QRR.R' 'R2.R' 'sim.data.R' 'sim.MQ.R'
'sim.Q.R' 'TNR.R' 'TPR.R' 'USR.R' 'validation.R' 'VRR.R'
'Wald.R' 'Wald.test.R' 'zzz.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-02 05:03:06 UTC; Haiji</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Author:</td>
<td>Haijiang Qin [aut, cre, cph],
  Lei Guo [aut, cph]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-02 05:22:35 UTC</td>
</tr>
</table>
<hr>
<h2 id='CDM'>Parameter estimation for cognitive diagnosis models (CDMs) by MMLE/EM or MMLE/BM algorithm.</h2><span id='topic+CDM'></span>

<h3>Description</h3>

<p>A function to estimate parameters for cognitive diagnosis models by MMLE/EM (de la Torre, 2009; de la Torre, 2011)
or MMLE/BM (Ma &amp; Jiang, 2020) algorithm.The function imports various functions from the <code>GDINA</code> package,
parameter estimation for Cognitive Diagnostic Models was performed and extended. The <code>CDM</code> function not
only accomplishes parameter estimation for most commonly used models ( <code>GDINA</code>, <code>DINA</code>, <code>DINO</code>,
<code>ACDM</code>, <code>LLM</code>, or <code>rRUM</code>) but also facilitates parameter estimation for the <code>LCDM</code>
model (Henson, Templin, &amp; Willse, 2008; Tu et al., 2022). Furthermore, it incorporates Bayes modal estimation
(BM; Ma &amp; Jiang, 2020) to obtain more reliable estimation results, especially in small sample sizes.
The monotonic constraints are able to be satisfied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDM(
  Y,
  Q,
  model = "GDINA",
  method = "EM",
  mono.constraint = TRUE,
  maxitr = 2000,
  verbose = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CDM_+3A_y">Y</code></td>
<td>
<p>A required <code>N</code> × <code>I</code> matrix or data.frame consisting of the responses of <code>N</code> individuals
to × <code>I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_q">Q</code></td>
<td>
<p>A required binary <code>I</code> × <code>K</code> containing the attributes not required or required, 0 or 1, to
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code>i</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>, <code>"ACDM"</code>,
<code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_method">method</code></td>
<td>
<p>Type of mtehod to estimate CDMs' parameters; one out of <code>"EM"</code>, <code>"BM"</code>. Default = <code>"EM"</code>
However, <code>"BM"</code> is only avaible when <code>method = "GDINA"</code>. See details.</p>
</td></tr>
<tr><td><code id="CDM_+3A_mono.constraint">mono.constraint</code></td>
<td>
<p>Logical indicating whether monotonicity constraints should be fulfilled in estimation.
Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_maxitr">maxitr</code></td>
<td>
<p>A vector for each item or nonzero category, or a scalar which will be used for all items
to specify the maximum number of EM or BM cycles allowed. Default = <code>2000</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_verbose">verbose</code></td>
<td>
<p>Can be <code>0</code>, <code>1</code> or <code>2</code>, indicating to print no information, information
for current iteration, or information for all iterations. Default = <code>1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CDMs are statistical models that fully integrates cognitive structure variables, which define the response
probability of subjects on questions by assuming the mechanism of action between attributes. In the
dichotomous test, this probability is the probability of answering correctly. According to the specificity
or generality of CDM assumptions, it can be divided into reduced CDM and saturated CDM.
</p>
<p>Reduced CDMs possess special and strong assumptions about the mechanisms of attribute interactions, leading
to clear interactions between attributes. Representative reduced models include the Deterministic Input,
Noisy and Gate (DINA) model (Haertel, 1989; Junker &amp; Sijtsma, 2001; de la Torre &amp; Douglas, 2004), the
Deterministic Input, Noisy or Gate (DINO) model (Templin &amp; Henson, 2006), and the Additive Cognitive Diagnosis
Model (A-CDM; de la Torre, 2011), the reduced Reparametrized Unified Model (r-RUM; Hartz, 2002), among others.
Compared to reduced models, saturated models do not have strict assumptions about the mechanisms of attribute
interactions. When appropriate constraints are applied, they can be transformed into various reduced models
(Henson et al., 2008; de la Torre, 2011), such as the Log-Linear Cognitive Diagnosis Model (LCDM; Henson et
al., 2009) and the general Deterministic Input, Noisy and Gate model (G-DINA; de la Torre, 2011).
</p>
<p>The LCDM (Log-Linear Cognitive Diagnosis Model) is a saturated CDM fully proposed within the framework of
cognitive diagnosis. Unlike simplified models that only discuss the main effects of attributes, it also
considers the interactions between attributes, thus having more generalized assumptions about attributes.
Its definition of the probability of correct response is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   P(X_{pi}=1|\mathbf{\alpha}_{l}) =
   \frac{\exp(\lambda_{i0} + \mathbf{\lambda}_{i}^{T} \mathbf{h} (\mathbf{q_{i}}, \mathbf{\alpha_{l}}))}
   {1 + \exp(\lambda_{i0} + \mathbf{\lambda}_{i}^{T} \mathbf{h}(\mathbf{q_{i}}, \mathbf{\alpha_{l}}))}
</code>
</p>

<p style="text-align: center;"><code class="reqn">
   \mathbf{\lambda}_{i}^{T} \mathbf{h}(\mathbf{q_{i}}, \mathbf{\alpha_{l}}) =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}
   \lambda_{ik}\lambda_{ik'}\alpha_{lk}\alpha_{lk'} +
   \cdots + \lambda_{12 \cdots K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p>Where, <code class="reqn">P(X_{pi}=1|\mathbf{\alpha}_{l})</code> represents the probability of a subject with attribute mastery
pattern <code class="reqn">\mathbf{\alpha}_{l}</code>, where <code class="reqn">l=1,2,\cdots,L</code> and <code class="reqn">L=2^{K^\ast}</code>, correctly answering
item i.
Here, <code class="reqn">K^\ast</code> denotes the number of attributes in the collapsed q-vector, <code class="reqn">\lambda_{i0}</code> is the
intercept parameter, and <code class="reqn">\mathbf{\lambda}_{i}=(\lambda_{i1}, \lambda_{i2}, \cdots, \lambda_{i12},
\cdots, \lambda_{i12{\cdots}K^\ast})</code> represents the effect vector of the attributes. Specifically,
<code class="reqn">\lambda_{ik}</code> is the main effect of attribute <code class="reqn">k</code>, <code class="reqn">\lambda_{ikk'}</code> is the interaction effect between
attributes <code class="reqn">k</code> and <code class="reqn">k'</code>, and <code class="reqn">\lambda_{j12{\cdots}K}</code> represents the interaction effect of all attributes.
</p>
<p>The general Deterministic Input, Noisy and Gate model (G-DINA), proposed by de la Torre (2011), is a saturated
model that offers three types of link functions: identity link, log link, and logit link, which are defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{pi}=1|\mathbf{\alpha}_{l}) =
   \delta_{i0} + \sum_{k=1}^{K^\ast}\delta_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}\delta_{ik}\delta_{ik'}\alpha_{lk}\alpha_{lk'} +
   \cdots + \delta_{12{\cdots}K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p style="text-align: center;"><code class="reqn">log(P(X_{pi}=1|\mathbf{\alpha}_{l})) =
   v_{i0} + \sum_{k=1}^{K^\ast}v_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}v_{ik}v_{ik'}\alpha_{lk}\alpha_{lk'} +
   \cdots + v_{12{\cdots}K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p style="text-align: center;"><code class="reqn">logit(P(X_{pi}=1|\mathbf{\alpha}_{l})) =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}\lambda_{ik}\lambda_{ik'}\alpha_{lk}\alpha_{lk'} +
   \cdots + \lambda_{12{\cdots}K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p>Where <code class="reqn">\delta_{i0}</code>, <code class="reqn">v_{i0}</code>, and <code class="reqn">\lambda_{i0}</code> are the intercept parameters for the three
link functions, respectively; <code class="reqn">\delta_{ik}</code>, <code class="reqn">v_{ik}</code>, and <code class="reqn">\lambda_{ik}</code> are the main effect
parameters of <code class="reqn">\alpha_{lk}</code> for the three link functions, respectively; <code class="reqn">\delta_{ikk'}</code>, <code class="reqn">v_{ikk'}</code>,
and <code class="reqn">\lambda_{ikk'}</code> are the interaction effect parameters between <code class="reqn">\alpha_{lk}</code> and <code class="reqn">\alpha_{lk'}</code>
for the three link functions, respectively; and <code class="reqn">\delta_{i12{\cdots }K^\ast}</code>, <code class="reqn">v_{i12{\cdots}K^\ast}</code>,
and <code class="reqn">\lambda_{i12{\cdots}K^\ast}</code> are the interaction effect parameters of <code class="reqn">\alpha_{l1}{\cdots}\alpha_{lK^\ast}</code>
for the three link functions, respectively. It can be observed that when the logit link is adopted, the
G-DINA model is equivalent to the LCDM model.
</p>
<p>Specifically, the A-CDM can be formulated as:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{pi}=1|\mathbf{\alpha}_{l}) =
   \delta_{i0} + \sum_{k=1}^{K^\ast}\delta_{ik}\alpha_{lk}
</code>
</p>

<p>The RRUM, can be written as:
</p>
<p style="text-align: center;"><code class="reqn">log(P(X_{pi}=1|\mathbf{\alpha}_{l})) =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk}
</code>
</p>

<p>The item response function for LLM can be given by:
</p>
<p style="text-align: center;"><code class="reqn">logit(P(X_{pi}=1|\mathbf{\alpha}_{l})) =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk}
</code>
</p>

<p>In the DINA model, every item is characterized by two key parameters: guessing (g) and slip (s). Within
the traditional framework of DINA model parameterization, a latent variable <code class="reqn">\eta</code>, specific to
individual <code class="reqn">p</code> who has the attribute mastery pattern <code class="reqn">\alpha_{l}</code> and item <code class="reqn">i</code>, is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   \eta_{li}=\prod_{k=1}^{K}\alpha_{lk}^{q_{ik}}
</code>
</p>

<p>If individual <code class="reqn">p</code> who has the attribute mastery pattern <code class="reqn">\alpha_{l}</code> has acquired every attribute
required by item i, <code class="reqn">\eta_{pi}</code> is given a value of 1. If not, <code class="reqn">\eta_{pi}</code> is set to 0. The
DINA model's item response function can be concisely formulated as such:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{pi}=1|\mathbf{\alpha}_{l}) =
   (1-s_j)^{\eta_{li}}g_j^{(1-\eta_{li})} =
   \delta_{i0}+\delta_{i12{\cdots}K}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p>In contrast to the DINA model, the DINO model suggests that an individual can correctly respond to
an item if they have mastered at least one of the item's measured attributes. Additionally, like the
DINA model, the DINO model also accounts for parameters related to guessing and slipping. Therefore,
the main difference between DINO and DINA lies in their respective <code class="reqn">\eta_{pi}</code> formulations. The
DINO model can be given by:
</p>
<p style="text-align: center;"><code class="reqn">\eta_{li} = 1-\prod_{k=1}^{K}(1 - \alpha_{lk})^{q_{lk}}</code>
</p>



<h3>Value</h3>

<p>An object of class <code>CDM.obj</code> is a <code>list</code> containing the following components:
</p>
<table>
<tr><td><code>analysis.obj</code></td>
<td>
<p>An <code>GDINA</code> object gained from <code>GDINA</code> package or an <code>list</code> after BM algorithm,
depending on which estimation is used.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Individuals' attribute parameters caculated by EAP method (Huebner &amp; Wang, 2011)</p>
</td></tr>
<tr><td><code>P.alpha.Xi</code></td>
<td>
<p>Individual posterior</p>
</td></tr>
<tr><td><code>alpha.P</code></td>
<td>
<p>Individuals' marginal mastery probabilities matrix (Tu et al., 2022)</p>
</td></tr>
<tr><td><code>P.alpha</code></td>
<td>
<p>Attribute prior weights for calculating marginalized likelihood in the last iteration</p>
</td></tr>
<tr><td><code>model.fit</code></td>
<td>
<p>Some basic model-fit indeces, including <code class="reqn">Deviance</code>, <code class="reqn">npar</code>, <code class="reqn">AIC</code>, <code class="reqn">BIC</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J. (2009). DINA Model and Parameter Estimation: A Didactic. Journal of Educational and Behavioral Statistics, 34(1), 115-130. DOI: 10.3102/1076998607309474.
</p>
<p>de la Torre, J., &amp; Douglas, J. A. (2004). Higher-order latent trait models for cognitive diagnosis. Psychometrika, 69(3), 333-353. DOI: 10.1007/BF02295640.
</p>
<p>de la Torre, J. (2011). The Generalized DINA Model Framework. Psychometrika, 76(2), 179-199. DOI: 10.1007/s11336-011-9207-7.
</p>
<p>Haertel, E. H. (1989). Using restricted latent class models to map the skill structure of achievement items. Journal of Educational Measurement, 26(4), 301-323. DOI: 10.1111/j.1745-3984.1989.tb00336.x.
</p>
<p>Hartz, S. M. (2002). A Bayesian framework for the unified model for assessing cognitive abilities: Blending theory with practicality (Unpublished doctoral dissertation). University of Illinois at Urbana-Champaign.
</p>
<p>Henson, R. A., Templin, J. L., &amp; Willse, J. T. (2008). Defining a Family of Cognitive Diagnosis Models Using Log-Linear Models with Latent Variables. Psychometrika, 74(2), 191-210. DOI: 10.1007/s11336-008-9089-5.
</p>
<p>Huebner, A., &amp; Wang, C. (2011). A note on comparing examinee classification methods for cognitive diagnosis models. Educational and Psychological Measurement, 71, 407-419. DOI: 10.1177/0013164410388832.
</p>
<p>Junker, B. W., &amp; Sijtsma, K. (2001). Cognitive assessment models with few assumptions, and connections with nonparametric item response theory. Applied Psychological Measurement, 25(3), 258-272. DOI: 10.1177/01466210122032064.
</p>
<p>Ma, W., &amp; Jiang, Z. (2020). Estimating Cognitive Diagnosis Models in Small Samples: Bayes Modal Estimation and Monotonic Constraints. Applied Psychological Measurement, 45(2), 95-111. DOI: 10.1177/0146621620977681.
</p>
<p>Templin, J. L., &amp; Henson, R. A. (2006). Measurement of psychological disorders using cognitive diagnosis models. Psychological methods, 11(3), 287-305. DOI: 10.1037/1082-989X.11.3.287.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models: A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################################################################
#                           Example 1                          #
#            fit using MMLE/EM to fit the GDINA models         #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "GDINA", distribute = "horder")


## using MMLE/EM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "GDINA",
                       method = "EM", maxitr = 2000, verbose = 1)



################################################################
#                           Example 2                          #
#               fit using MMLE/BM to fit the DINA              #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "DINA", distribute = "horder")


## using MMLE/EM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "GDINA",
                       method = "BM", maxitr = 1000, verbose = 2)


################################################################
#                           Example 3                          #
#              fit using MMLE/EM to fit the ACDM               #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "ACDM", distribute = "horder")


## using MMLE/EM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "ACDM",
                       method = "EM", maxitr = 2000, verbose = 1)


</code></pre>

<hr>
<h2 id='fit'>Calculate data fit indeces</h2><span id='topic+fit'></span>

<h3>Description</h3>

<p>Calculate relative fit indices (-2LL, AIC, BIC, CAIC, SABIC) and absolute fit indices (<code class="reqn">M_2</code> test)
using the <code>testfit</code> function in the <code>GDINA</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit(Y, Q, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_+3A_y">Y</code></td>
<td>
<p>A required <code>N</code> × <code>I</code> matrix or data.frame consisting of the responses of <code>N</code>
individuals to <code>I</code> items. Missing values should be coded as NA.</p>
</td></tr>
<tr><td><code id="fit_+3A_q">Q</code></td>
<td>
<p>A required binary <code>I</code> × <code>K</code> matrix containing the attributes not required or required
, coded as 0 or 1, to master the items. The <code>i</code>th row of the matrix is a binary indicator vector
indicating which attributes are not required (coded as 0) and which attributes are required
(coded as 1) to master item <code>i</code>.</p>
</td></tr>
<tr><td><code id="fit_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>list</code>. The list contains various fit indices:
</p>
<table>
<tr><td><code>npar</code></td>
<td>
<p>The number of parameters.</p>
</td></tr>
<tr><td><code>-2LL</code></td>
<td>
<p>The Deviance.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>The Akaike information criterion.</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>The Bayesian information criterion.</p>
</td></tr>
<tr><td><code>CAIC</code></td>
<td>
<p>The consistent Akaike information criterion.</p>
</td></tr>
<tr><td><code>SABIC</code></td>
<td>
<p>The Sample size Adjusted BIC.</p>
</td></tr>
<tr><td><code>M2</code></td>
<td>
<p>A vector consisting of <code class="reqn">M_2</code> statistic, degrees of freedom, significance level, and <code class="reqn">RMSEA_2</code> (Liu, Tian, &amp; Xin, 2016).</p>
</td></tr>
<tr><td><code>SRMSR</code></td>
<td>
<p>The standardized root mean squared residual (SRMSR; Ravand &amp; Robitzsch, 2018).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Khaldi, R., Chiheb, R., &amp; Afa, A.E. (2018). Feed-forward and Recurrent Neural Networks for Time Series Forecasting: Comparative Study. In: Proceedings of the International Conference on Learning and Optimization Algorithms: Theory and Applications (LOPAL 18). Association for Computing Machinery, New York, NY, USA, Article 18, 1–6. DOI: 10.1145/3230905.3230946.
</p>
<p>Liu, Y., Tian, W., &amp; Xin, T. (2016). An application of M2 statistic to evaluate the fit of cognitive diagnostic models. Journal of Educational and Behavioral Statistics, 41, 3–26. DOI: 10.3102/1076998615621293.
</p>
<p>Ravand, H., &amp; Robitzsch, A. (2018). Cognitive diagnostic model of best choice: a study of reading comprehension. Educational Psychology, 38, 1255–1277. DOI: 10.1080/01443410.2018.1489524.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")

## calculate fit indices
fit.indices &lt;- fit(Y = example.data$dat, Q = example.Q, model = "GDINA")
print(fit.indices)

</code></pre>

<hr>
<h2 id='get.Mmatrix'>Calculate <code class="reqn">\mathbf{M}</code> matrix</h2><span id='topic+get.Mmatrix'></span>

<h3>Description</h3>

<p>Calculate <code class="reqn">\mathbf{M}</code> matrix for stauted CDMs (de la Torre, 2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.Mmatrix(K = NULL, pattern = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.Mmatrix_+3A_k">K</code></td>
<td>
<p>The number of attributes. Can be NULL if <code>pattern</code> is passed to the function and is not NULL.</p>
</td></tr>
<tr><td><code id="get.Mmatrix_+3A_pattern">pattern</code></td>
<td>
<p>The knowledge state matrix containing all possible attribute mastery pattern.
Can be gained from @seealso <code><a href="GDINA.html#topic+attributepattern">attributepattern</a></code>. Also can be NULL if <code>K</code>
is passed to the function and is not NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J. (2011). The Generalized DINA Model Framework. Psychometrika, 76(2), 179-199. DOI: 10.1007/s11336-011-9207-7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(Qval)

example.Mmatrix &lt;-  get.Mmatrix(K = 5)

</code></pre>

<hr>
<h2 id='get.PVAF'>Calculate <code class="reqn">PVAF</code></h2><span id='topic+get.PVAF'></span>

<h3>Description</h3>

<p>The function is able to caculate the proportion of variance accounted for (<code class="reqn">PVAF</code>) for all items
after fitting <code>CDM</code> or directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.PVAF(Y = NULL, Q = NULL, CDM.obj = NULL, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.PVAF_+3A_y">Y</code></td>
<td>
<p>A required <code>N</code> × <code>I</code> matrix or data.frame consisting of the responses of <code>N</code> individuals
to <code>I</code> items. Missing values should be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get.PVAF_+3A_q">Q</code></td>
<td>
<p>A required binary <code>I</code> × <code>K</code> matrix containing the attributes not required or required, coded
as 0 or 1, to master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating
which attributes are not required (coded as 0) and which attributes are required (coded as 1) to master item <code>i</code>.</p>
</td></tr>
<tr><td><code id="get.PVAF_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. Can can be NULL, but when it is not NULL, it enables
rapid verification of the Q-matrix without the need for parameter estimation.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="get.PVAF_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intrinsic essence of the GDI index (as denoted by <code class="reqn">\zeta_{2}</code>) is the weighted variance of
all <code class="reqn">2^{K\ast}</code> attribute mastery patterns' probabilities of correctly responding to
item <code class="reqn">i</code>, which can be computed as:
</p>
<p style="text-align: center;"><code class="reqn">
 \zeta^2 =
 \sum_{l=1}^{2^K} \pi_{l}{(P(X_{pi}=1|\mathbf{\alpha}_{l}) - P_{i}^{mean})}^2
</code>
</p>

<p>where <code class="reqn">\pi_{l}</code> represents the prior probability of mastery pattern <code class="reqn">l</code>;
<code class="reqn">P_{i}^{mean}=\sum_{k=1}^{2^K}\pi_{l}P(X_{pi}=1|\mathbf{\alpha}_{l})</code> is the weighted average of the correct
response probabilities across all attribute mastery patterns. When the q-vector
is correctly specified, the calculated <code class="reqn">\zeta^2</code> should be maximized, indicating
the maximum discrimination of the item.
</p>
<p>Theoretically, <code class="reqn">\zeta^{2}</code> is larger when <code class="reqn">\mathbf{q}_{i}</code> is either specified correctly or over-specified,
unlike when <code class="reqn">\mathbf{q}_{i}</code> is under-specified, and that when <code class="reqn">\mathbf{q}_{i}</code> is over-specified, <code class="reqn">\zeta^{2}</code>
is larger than but close to the value of <code class="reqn">\mathbf{q}_{i}</code> when specified correctly. The value of <code class="reqn">\zeta^{2}</code> continues to
increase slightly as the number of over-specified attributes increases, until <code class="reqn">\mathbf{q}_{i}</code> becomes <code class="reqn">\mathbf{q}_{i1:K}</code>.
Thus, <code class="reqn">\zeta^{2} / \zeta_{max}^{2}</code> is computed to indicate the proportion of variance accounted for by <code class="reqn">\mathbf{q}_{i}</code>
, called the <code class="reqn">PVAF</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>matrix</code>, which consisted of <code class="reqn">PVAF</code> for each item and each possible attribute mastery pattern.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J., &amp; Chiu, C. Y. (2016). A General Method of Empirical Q-matrix Validation. Psychometrika, 81(2), 253-273. DOI: 10.1007/s11336-015-9467-8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

## generate Q-matrix and data
K &lt;- 3
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")

## calculate PVAF directly
PVAF &lt;-get.PVAF(Y = example.data$dat, Q = example.Q)
print(PVAF)

## caculate PVAF after fitting CDM
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model="GDINA")
PVAF &lt;-get.PVAF(CDM.obj = example.CDM.obj)
print(PVAF)

</code></pre>

<hr>
<h2 id='get.R2'>Calculate McFadden pseudo-<code class="reqn">R^{2}</code></h2><span id='topic+get.R2'></span>

<h3>Description</h3>

<p>The function is able to calculate the McFadden pseudo-<code class="reqn">R^{2}</code> (<code class="reqn">R^{2}</code>) for all items after
fitting <code>CDM</code> or directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.R2(Y = NULL, Q = NULL, CDM.obj = NULL, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.R2_+3A_y">Y</code></td>
<td>
<p>A required <code>N</code> × <code>I</code> matrix or data.frame consisting of the responses of <code>N</code>
individuals to <code>I</code> items. Missing values should be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get.R2_+3A_q">Q</code></td>
<td>
<p>A required binary <code>I</code> × <code>K</code> matrix containing the attributes not required or required,
coded as 0 or 1, to master the items. The <code>i</code>th row of the matrix is a binary indicator vector
indicating which attributes are not required (coded as 0) and which attributes are required
(coded as 1) to master item <code>i</code>.</p>
</td></tr>
<tr><td><code id="get.R2_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. Can can be NULL, but when it is not NULL, it
enables rapid verification of the Q-matrix without the need for parameter estimation.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="get.R2_+3A_model">model</code></td>
<td>
<p>Type of model to fit; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The McFadden pseudo-<code class="reqn">R^{2}</code> ( McFadden in 1974) serves as a definitive model-fit index,
quantifying the proportion of variance explained by the observed responses. Comparable to the
squared multiple-correlation coefficient in linear statistical models, this coefficient of
determination finds its application in logistic regression models. Specifically, in the context
of the CDM, where probabilities of accurate item responses are predicted for each examinee,
the McFadden pseudo-<code class="reqn">R^{2}</code> provides a metric to assess the alignment between these predictions
and the actual responses observed. Its computation is straightforward, following the formula:
</p>
<p style="text-align: center;"><code class="reqn">
 R_{i}^{2} = 1 - \frac{\log(L_{im}}{\log(L_{i0})}
</code>
</p>

<p>where <code class="reqn">\log(L_{im}</code> is the log-likelihood of the model, and  <code class="reqn">\log(L_{i0})</code> is the log-likelihood of
the null model. If there were <code class="reqn">N</code> examinees taking a test comprising <code class="reqn">I</code> items, then <code class="reqn">\log(L_{im})</code>
would be computed as:
</p>
<p style="text-align: center;"><code class="reqn">
 \log(L_{im}) =
 \sum_{p}^{N} \log \sum_{l=1}^{2^{K^\ast}} \pi(\alpha_{l}^{\ast} | X_{p})
   P_{i}(\alpha_{l}^{\ast})^{X_{pi}} (1-P_{i}(\alpha_{l}^{\ast}))^{1-X_{pi}}
</code>
</p>

<p>where <code class="reqn">\pi(\alpha_{l}^{\ast} | X_{p})</code> is the posterior probability of examinee <code class="reqn">p</code> with attribute
profle <code class="reqn">\alpha_{l}^{\ast}</code> when their response vector is <code class="reqn">\mathbf{X}_{p}</code>, and <code class="reqn">X_{pi}</code> is
examinee <code class="reqn">p</code>'s response to item <code class="reqn">i</code>. Let <code class="reqn">X_{i}^{mean}</code> be the average probability of correctly responding
to item <code class="reqn">i</code> across all <code class="reqn">N</code> examinees; then <code class="reqn">\log(L_{i0}</code> could be computed as:
</p>
<p style="text-align: center;"><code class="reqn">
 \log(L_{i0}) =
 \sum_{p}^{N} \log {X_{i}^{mean}}^{X_{pi}} {(1-X_{i}^{mean})}^{1-X_{pi}}
</code>
</p>



<h3>Value</h3>

<p>An object of class <code>matrix</code>, which consisted of <code class="reqn">R^{2}</code> for each item and each possible attribute mastery pattern.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>McFadden, D. (1974). Conditional logit analysis of qualitative choice behavior. In P. Zarembka (Ed.), Frontiers in economics (pp.105–142). Academic Press.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing ft and parsimony to improve Q-matrix validation. British Journal of Mathematical and Statistical Psychology, 74, 110–130. DOI: 10.1111/bmsp.12228.
</p>
<p>Qin, H., &amp; Guo, L. (2023). Using machine learning to improve Q-matrix validation. Behavior Research Methods. DOI: 10.3758/s13428-023-02126-0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

## generate Q-matrix and data
K &lt;- 3
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")

## calculate PVAF directly
PVAF &lt;-get.PVAF(Y = example.data$dat, Q = example.Q)
print(PVAF)

## caculate PVAF after fitting CDM
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model="GDINA")
PVAF &lt;-get.PVAF(CDM.obj = example.CDM.obj)
print(PVAF)

</code></pre>

<hr>
<h2 id='getOSR'>Caculate over-specifcation rate (OSR)</h2><span id='topic+getOSR'></span>

<h3>Description</h3>

<p>Caculate over-specifcation rate (OSR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getOSR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getOSR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="getOSR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The OSR is defned as:
</p>
<p style="text-align: center;"><code class="reqn">
 OSR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} &lt; q_{ik}^{s})}{I × K}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code>k</code>th attribute of item <code>i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code>k</code>th attribute of item <code>i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (OSR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
OSR &lt;- getOSR(example.Q1, example.Q2)
print(OSR)

</code></pre>

<hr>
<h2 id='getQRR'>Caculate Q-matrix recovery rate (QRR)</h2><span id='topic+getQRR'></span>

<h3>Description</h3>

<p>Caculate Q-matrix recovery rate (QRR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getQRR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getQRR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="getQRR_+3A_q.sug">Q.sug</code></td>
<td>
<p>A The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Q-matrix recovery rate (QRR) provides information on overall performance, and is defned as:
</p>
<p style="text-align: center;"><code class="reqn">
 QRR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{s})}{I × K}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code class="reqn">Q.true</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the suggested Q-matrix(<code class="reqn">Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (QRR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
QRR &lt;- getQRR(example.Q1, example.Q2)
print(QRR)

</code></pre>

<hr>
<h2 id='getTNR'>Calculate true negative rate (TNR)</h2><span id='topic+getTNR'></span>

<h3>Description</h3>

<p>Calculate true negative rate (TNR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTNR(Q.true, Q.orig, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTNR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="getTNR_+3A_q.orig">Q.orig</code></td>
<td>
<p>The Q-matrix need to be validated.</p>
</td></tr>
<tr><td><code id="getTNR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TNR is defined as the proportion of correct elements which are correctly retained:
</p>
<p style="text-align: center;"><code class="reqn">
 TNR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{s} | q_{ik}^{t} \neq q_{ik}^{o})}
 {\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} \neq q_{ik}^{o})}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code>k</code>th attribute of item <code>i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{o}</code> denotes <code>k</code>th attribute of item <code>i</code> in the original Q-matrix(<code>Q.orig</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code>k</code>th attribute of item <code>i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (TNR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
example.Q3 &lt;- sim.MQ(example.Q1, 0.05)
TNR &lt;- getTNR(example.Q1, example.Q2, example.Q3)

print(TNR)

</code></pre>

<hr>
<h2 id='getTPR'>Caculate true-positive rate (TPR)</h2><span id='topic+getTPR'></span>

<h3>Description</h3>

<p>Caculate true-positive rate (TPR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTPR(Q.true, Q.orig, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTPR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="getTPR_+3A_q.orig">Q.orig</code></td>
<td>
<p>The Q-matrix need to be validated.</p>
</td></tr>
<tr><td><code id="getTPR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TPR is defned as the proportion of correct elements which are correctly retained:
</p>
<p style="text-align: center;"><code class="reqn">
 TPR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{s} | q_{ik}^{t} = q_{ik}^{o})}
 {\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{o})}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code>k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{o}</code> denotes <code>k</code>th attribute of item <code>i</code> in the original Q-matrix(<code>Q.orig</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code>k</code>th attribute of item <code>i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (TPR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
example.Q3 &lt;- sim.MQ(example.Q1, 0.05)
TPR &lt;- getTPR(example.Q1, example.Q2, example.Q3)

print(TPR)

</code></pre>

<hr>
<h2 id='getUSR'>Caculate under-specifcation rate (USR)</h2><span id='topic+getUSR'></span>

<h3>Description</h3>

<p>Caculate under-specifcation rate (USR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getUSR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getUSR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="getUSR_+3A_q.sug">Q.sug</code></td>
<td>
<p>A The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The USR is defned as:
</p>
<p style="text-align: center;"><code class="reqn">
 USR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} &gt; q_{ik}^{s})}{I × K}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code>k</code>th attribute of item <code>i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code>k</code>th attribute of item <code>i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (USR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
USR &lt;- getUSR(example.Q1, example.Q2)
print(USR)

</code></pre>

<hr>
<h2 id='getVRR'>Caculate vector recovery ratio (VRR)</h2><span id='topic+getVRR'></span>

<h3>Description</h3>

<p>Caculate vector recovery ratio (VRR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getVRR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getVRR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="getVRR_+3A_q.sug">Q.sug</code></td>
<td>
<p>A The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The VRR shows the ability of the validation method to recover q-vectors, and is determined by
</p>
<p style="text-align: center;"><code class="reqn">
 VRR =\frac{\sum_{i=1}^{I}I(\mathbf{q}_{i}^{t} = \mathbf{q}_{i}^{s})}{I}
</code>
</p>

<p>where <code class="reqn">\mathbf{q}_{i}^{t}</code> denotes the <code class="reqn">\mathbf{q}</code>-vector of item <code>i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">\mathbf{q}_{i}^{s}</code> denotes the <code class="reqn">\mathbf{q}</code>-vector of item <code>i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (VRR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
VRR &lt;- getVRR(example.Q1, example.Q2)
print(VRR)

</code></pre>

<hr>
<h2 id='sim.data'>generate response data</h2><span id='topic+sim.data'></span>

<h3>Description</h3>

<p>randomly generate response data matrix according to certen conditions,
including attributes distribution, item quality, sample size, Q-matrix and cognitive diagnosis models (CDMs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.data(
  Q = NULL,
  N = NULL,
  IQ = list(P0 = NULL, P1 = NULL),
  model = "GDINA",
  distribute = "uniform",
  control = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.data_+3A_q">Q</code></td>
<td>
<p>The Q-matrix. A random 30 × 5 Q-matrix (<code><a href="#topic+sim.Q">sim.Q</a></code>) will be used if NULL.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_n">N</code></td>
<td>
<p>Sample size. Default = 500.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_iq">IQ</code></td>
<td>
<p>A List contains tow I-length vectors: <code>P0</code> and <code>P1</code>.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_distribute">distribute</code></td>
<td>
<p>Attribute distributions; can be <code>"uniform"</code> for the uniform distribution,
<code>"mvnorm"</code> for the multivariate normal distribution (Chiu, Douglas, &amp; Li,
2009) and <code>"horder"</code> for the higher-order distribution (Tu et al., 2022).</p>
</td></tr>
<tr><td><code id="sim.data_+3A_control">control</code></td>
<td>
<p>A list of control parameters with elements:
</p>

<ul>
<li> <p><code>sigma</code>  A positive-definite symmetric matrix specifying the variance-covariance
matrix when <code>distribute = "mvnorm"</code>. Default = 0.5 (Chiu, Douglas, &amp; Li, 2009).
</p>
</li>
<li> <p><code>cutoffs</code>  A vector giving the cutoff for each attribute when <code>distribute = "mvnorm"</code>.
Default = <code class="reqn">k/(1+K)</code> (Chiu, Douglas, &amp; Li, 2009).
</p>
</li>
<li> <p><code>theta</code> A vector of length N representing the higher-order ability for each examinee.
By default, generate randomly from the normal distribution (Tu et al, 2022).
</p>
</li>
<li> <p><code>a</code> The slopes for the higher-order model when <code>distribute = "horder"</code>.
Default = 1.5 (Tu et al, 2022).
</p>
</li>
<li> <p><code>b</code> The intercepts when <code>distribute = "horder"</code>. By default, select equally spaced
values between -1.5 and 1.5 according to the number of attributes (Tu et al, 2022).
</p>
</li></ul>
</td></tr>
<tr><td><code id="sim.data_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating to print information or not. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>simGDINA</code>.
An <code>simGDINA</code> object gained by <code>simGDINA</code> function form <code>GDINA</code> package.
Elements that can be extracted using method extract include:
</p>
<table>
<tr><td><code>dat</code></td>
<td>
<p>An <code>N</code> × <code>I</code> simulated item response matrix.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>The Q-matrix.</p>
</td></tr>
<tr><td><code>attribute</code></td>
<td>
<p>An <code>N</code> × <code>K</code> matrix for inviduals' attribute patterns.</p>
</td></tr>
<tr><td><code>catprob.parm</code></td>
<td>
<p>A list of non-zero category success probabilities for each latent group.</p>
</td></tr>
<tr><td><code>delta.parm</code></td>
<td>
<p>A list of delta parameters.</p>
</td></tr>
<tr><td><code>higher.order.parm</code></td>
<td>
<p>Higher-order parameters.</p>
</td></tr>
<tr><td><code>mvnorm.parm</code></td>
<td>
<p>Multivariate normal distribution parameters.</p>
</td></tr>
<tr><td><code>LCprob.parm</code></td>
<td>
<p>A matrix of item/category success probabilities for each latent class.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Chiu, C.-Y., Douglas, J. A., &amp; Li, X. (2009). Cluster Analysis for Cognitive Diagnosis: Theory and Applications. Psychometrika, 74(4), 633-665. DOI: 10.1007/s11336-009-9125-0.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models:A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
################################################################
#                           Example 1                          #
#          generate data follow the uniform distrbution        #
################################################################
library(Qval)

set.seed(123)

K &lt;- 5
I &lt;- 10
Q &lt;- sim.Q(K, I)

IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

data &lt;- sim.data(Q = Q, N = 10, IQ=IQ, model = "GDINA", distribute = "uniform")

print(data$dat)

################################################################
#                           Example 2                          #
#          generate data follow the mvnorm distrbution         #
################################################################
set.seed(123)
K &lt;- 5
I &lt;- 10
Q &lt;- sim.Q(K, I)

IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

example_cutoffs &lt;- sample(qnorm(c(1:K)/(K+1)), ncol(Q))
data &lt;- sim.data(Q = Q, N = 10, IQ=IQ, model = "GDINA", distribute = "mvnorm",
                 control = list(sigma = 0.5, cutoffs = example_cutoffs))

print(data$dat)

#################################################################
#                            Example 3                          #
#           generate data follow the horder distrbution         #
#################################################################
set.seed(123)
K &lt;- 5
I &lt;- 10
Q &lt;- sim.Q(K, I)

IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

example_theta &lt;- rnorm(10, 0, 1)
example_b &lt;- seq(-1.5,1.5,length.out=K)
data &lt;- sim.data(Q = Q, N = 10, IQ=IQ, model = "GDINA", distribute = "horder",
                 control = list(theta = example_theta, a = 1.5, b = example_b))

print(data$dat)

</code></pre>

<hr>
<h2 id='sim.MQ'>Simulate mis-specifications</h2><span id='topic+sim.MQ'></span>

<h3>Description</h3>

<p>simulate certen <code class="reqn">rate</code> mis-specifications in the Q-matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.MQ(Q, rate, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.MQ_+3A_q">Q</code></td>
<td>
<p>The Q-matrix (<code><a href="#topic+sim.Q">sim.Q</a></code>) that need to simulate mis-specifications.</p>
</td></tr>
<tr><td><code id="sim.MQ_+3A_rate">rate</code></td>
<td>
<p>The pecentage of mis-specifications in the<code class="reqn">Q</code>.</p>
</td></tr>
<tr><td><code id="sim.MQ_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating to print information or not. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code class="reqn">matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

Q &lt;- sim.Q(5, 10)
print(Q)

MQ &lt;- sim.MQ(Q, 0.1)
print(MQ)

</code></pre>

<hr>
<h2 id='sim.Q'>generate a random Q-matrix</h2><span id='topic+sim.Q'></span>

<h3>Description</h3>

<p>generate a <code class="reqn">I</code> * <code class="reqn">K</code> Q-matrix randomly, which consisted of one-attribute q-vectors
(0.5), two-attribute q-vectors (0.25), and three-attribute q-vectors (0.25).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.Q(K, I)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.Q_+3A_k">K</code></td>
<td>
<p>The number of attributes of each item.</p>
</td></tr>
<tr><td><code id="sim.Q_+3A_i">I</code></td>
<td>
<p>The number of items.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code class="reqn">matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing fit and parsimony to improve Q-matrix validation. Br J Math Stat Psychol, 74 Suppl 1, 110-130. DOI: 10.1111/bmsp.12228.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

Q &lt;- sim.Q(5, 10)
print(Q)

</code></pre>

<hr>
<h2 id='validation'>Perform Q-matrix validation methods</h2><span id='topic+validation'></span>

<h3>Description</h3>

<p>This function uses generalized Q-matrix validation methods to validate the Q-matrix,
including commonly used methods such as GDI (de la Torre, &amp; Chiu, 2016; Najera, Sorrel,
&amp; Abad, 2019; Najera et al., 2020), Wald (Ma, &amp; de la Torre, 2020), Hull (Najera et al.,
2021), and MLR-B (Tu et al., 2022). It supports different iteration methods (test
level or item level; Najera et al., 2020; Najera et al., 2021; Tu et al., 2022) and
can apply various attribute search methods (ESA, SSA, PAA; de la Torre, 2008; Terzi, &amp;
de la Torre, 2018). More see details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validation(
  Y,
  Q,
  CDM.obj = NULL,
  model = "GDINA",
  method = "GDI",
  search.method = "PAA",
  maxitr = 1,
  iter.level = "test",
  eps = 0.95,
  criter = "PVAF",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validation_+3A_y">Y</code></td>
<td>
<p>A required <code>N</code> × <code>I</code> matrix or data.frame consisting of the responses of <code>N</code> individuals
to <code>I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_q">Q</code></td>
<td>
<p>A required binary <code>I</code> × <code>K</code> containing the attributes not required or required, 0 or 1,
to master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to
master item <code>i</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. When it is not NULL, it enables rapid verification
of the Q-matrix without the need for parameter estimation. @seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_model">model</code></td>
<td>
<p>Type of model to fit; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>
, <code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_method">method</code></td>
<td>
<p>The methods to validata Q-matrix, can be <code>"GDI"</code>, <code>"Wald"</code>, <code>"Hull"</code>, and
<code>"MLR-B"</code>. The <code>"model"</code> must be <code>"GDINA"</code> when <code>method = "Wald"</code>.
Default = <code>"GDI"</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_search.method">search.method</code></td>
<td>
<p>Character string specifying the search method to use during validation.
</p>

<dl>
<dt>&quot;SSA&quot;</dt><dd><p>for sequential search algorithm (see de la Torre, 2008; Terzi &amp; de la Torre, 2018). This option can be used when the <code>method</code> is <code>"GDI"</code> or <code>"MLR-B"</code>.</p>
</dd>
<dt>&quot;ESA&quot;</dt><dd><p>for exhaustive search algorithm. This option can be used when the <code>method</code> is any of <code>"GDI"</code>, <code>"Wald"</code>, <code>"Hull"</code>, or <code>"MLR-B"</code>.</p>
</dd>
<dt>&quot;PAA&quot;</dt><dd><p>for priority attribute algorithm.
This is the default option and can be used when the <code>method</code> is any of <code>"GDI"</code>, <code>"Wald"</code>, <code>"Hull"</code>, or <code>"MLR-B"</code>.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="validation_+3A_maxitr">maxitr</code></td>
<td>
<p>Number of max iterations. Default = <code>1</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_iter.level">iter.level</code></td>
<td>
<p>Can be <code>"item"</code> level or <code>"test"</code> level. Default = <code>"test"</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_eps">eps</code></td>
<td>
<p>Cut-off points of <code class="reqn">PVAF</code>, will work when the method is <code>"GDI"</code> or <code>"Wald"</code>.
Default = <code>0.95</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_criter">criter</code></td>
<td>
<p>The kind of fit-index value, can be <code class="reqn">R^2</code> for <code class="reqn">R_{McFadden}^2</code> @seealso <code><a href="#topic+get.R2">get.R2</a></code>
or <code class="reqn">PVAF</code> for the proportion of variance accounted for (<code class="reqn">PVAF</code>) @seealso <code><a href="#topic+get.PVAF">get.PVAF</a></code>.
Only when <code>method = "Hull"</code> works and default = <code>"PVAF"</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating to print iterative information or not. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>validation</code> is a <code>list</code> containing the following components:
</p>
<table>
<tr><td><code>Q.orig</code></td>
<td>
<p>The original Q-matrix that maybe contains some mis-specifications and need to be validate.</p>
</td></tr>
<tr><td><code>Q.sug</code></td>
<td>
<p>The Q-matrix that suggested by certain validation method.</p>
</td></tr>
<tr><td><code>priority</code></td>
<td>
<p>An <code>I</code> × <code>K</code> matrix that contains the priority of every attribute for
each item. Only when the <code>search.method</code> is <code>"PAA"</code>, the value is availble. See details.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iteration.</p>
</td></tr>
<tr><td><code>time.cost</code></td>
<td>
<p>The time that CPU cost to finish the function.</p>
</td></tr>
</table>


<h3>The GDI method</h3>

<p>The GDI method (de la Torre &amp; Chiu, 2016), as the first Q-matrix validation method
applicable to saturated models, serves as an important foundation for various mainstream
Q-matrix validation methods.
</p>
<p>The method calculates the proportion of variance accounted for (<code class="reqn">PVAF</code>; @seealso <code><a href="#topic+get.PVAF">get.PVAF</a></code>)
for all possible q-vectors for each item, selects the q-vector with a <code class="reqn">PVAF</code> just
greater than the cut-off point (or Epsilon, EPS) as the correction result, and the variance
<code class="reqn">\zeta^2</code> is the generalized discriminating index (GDI; de la Torre &amp; Chiu, 2016).
Therefore, the GDI method is also considered as a generalized extension of the <code class="reqn">delta</code>
method (de la Torre, 2008), which also takes maximizing discrimination as its basic idea.
In the GDI method, <code class="reqn">\zeta^2</code> is defined as the weighted variance of the correct
response probabilities across all mastery patterns, that is:
</p>
<p style="text-align: center;"><code class="reqn">
 \zeta^2 =
 \sum_{l=1}^{2^K} \pi_{l} {(P(X_{pi}=1|\mathbf{\alpha}_{l}) - P_{i}^{mean})}^2
</code>
</p>

<p>where <code class="reqn">\pi_{l}</code> represents the prior probability of mastery pattern <code class="reqn">l</code>;
<code class="reqn">P_{i}^{mean}=\sum_{k=1}^{K}\pi_{l}P(X_{pi}=1|\mathbf{\alpha}_{l})</code> is the weighted
average of the correct response probabilities across all attribute mastery patterns.
When the q-vector is correctly specified, the calculated <code class="reqn">\zeta^2</code> should be maximized,
indicating the maximum discrimination of the item. However, in reality, <code class="reqn">\zeta^2</code>
continues to increase when the q-vector is over-specified, and the more attributes that
are over-specified, the larger <code class="reqn">\zeta^2</code> becomes. The q-vector with all attributes set
to 1 (i.e., <code class="reqn">\mathbf{q}_{1:K}</code>) has the largest <code class="reqn">\zeta^2</code> (de la Torre, 2016).
This is because an increase in attributes in the q-vector leads to an increase in item
parameters, resulting in greater differences in correct response probabilities across
attribute patterns and, consequently, increased variance. However, this increase in
variance is spurious. Therefore, de la Torre et al. calculated <code class="reqn">PVAF = \frac{\zeta^2}{\zeta_{1:K}^2}</code>
to describe the degree to which the discrimination of the current q-vector explains
the maximum discrimination. They selected an appropriate <code class="reqn">PVAF</code> cut-off point to achieve
a balance between q-vector fit and parsimony. According to previous studies,
the <code class="reqn">PVAF</code> cut-off point is typically set at 0.95 (Ma &amp; de la Torre, 2020; Najera et al., 2021).
</p>


<h3>The Wald method</h3>

<p>The Wald method (Ma &amp; de la Torre, 2020) combines the Wald test with <code class="reqn">PVAF</code> to correct
the Q-matrix at the item level. Its basic logic is as follows: when correcting item <code class="reqn">i</code>,
the single attribute that maximizes the <code class="reqn">PVAF</code> value is added to a vector with all
attributes set to <code class="reqn">\mathbf{0}</code> (i.e., <code class="reqn">\mathbf{q} = (0, 0, \ldots, 0)</code>) as a starting point.
In subsequent iterations, attributes in this vector are continuously added or
removed through the Wald test. The correction process ends when the <code class="reqn">PVAF</code> exceeds the
cut-off point or when no further attribute changes occur. The Wald statistic follows an
asymptotic <code class="reqn">\chi^{2}</code> distribution with a degree of freedom of <code class="reqn">2^{K^\ast} - 1</code>.
</p>
<p>The calculation method is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   Wald = (\mathbf{R} \times P_{i}(\mathbf{\alpha}))^{'}
   (\mathbf{R} \times \mathbf{V}_{i} \times \mathbf{R})^{-1}
   (\mathbf{R} \times P_{i}(\mathbf{\alpha}))
</code>
</p>

<p><code class="reqn">\mathbf{R}</code> represents the restriction matrix; <code class="reqn">P_{i}(\mathbf{\alpha})</code> denotes
the vector of correct response probabilities for item <code class="reqn">i</code>; <code class="reqn">\mathbf{V}_i</code> is the
variance-covariance matrix of the correct response probabilities for item <code class="reqn">i</code>, which
can be obtained by multiplying the <code class="reqn">\mathbf{M}_i</code> matrix (de la Torre, 2011) with the
variance-covariance matrix of item parameters <code class="reqn">\mathbf{\Sigma}_i</code>, i.e.,
<code class="reqn">\mathbf{V}_i = \mathbf{M}_i \times \mathbf{\Sigma}_i</code>. The <code class="reqn">\mathbf{\Sigma}_i</code> can be
derived by inverting the information matrix. Using the the empirical cross-product information
matrix (de la Torre, 2011) to calculate <code class="reqn">\mathbf{\Sigma}_i</code>.
</p>
<p><code class="reqn">\mathbf{M}_i</code> is a <code class="reqn">2^{K^\ast} × 2^{K^\ast}</code> matrix that represents the relationship between
the parameters of item <code class="reqn">i</code> and the attribute mastery patterns. The rows represent different mastery
patterns, while the columns represent different item parameters.
</p>


<h3>The Hull method</h3>

<p>The Hull method (Najera et al., 2021) addresses the issue of the cut-off point in the GDI
method and demonstrates good performance in simulation studies. Najera et al. applied the
Hull method for determining the number of factors to retain in exploratory factor analysis
(Lorenzo-Seva et al., 2011) to the retention of attribute quantities in the q-vector, specifically
for Q-matrix validation. The Hull method aligns with the GDI approach in its philosophy
of seeking a balance between fit and parsimony. While GDI relies on a preset, arbitrary
cut-off point to determine this balance, the Hull method utilizes the most pronounced elbow
in the Hull plot to make this judgment. The the most pronounced elbow is determined using
the following formula:
</p>
<p style="text-align: center;"><code class="reqn">
   st = \frac{(f_k - f_{k-1}) / (np_k - np_{k-1})}{(f_{k+1} - f_k) / (np_{k+1} - np_k)}
</code>
</p>

<p>where <code class="reqn">f_k</code> represents the fit-index value (can be <code class="reqn">PVAF</code> @seealso <code><a href="#topic+get.PVAF">get.PVAF</a></code> or
<code class="reqn">R2</code> @seealso <code><a href="#topic+get.R2">get.R2</a></code>) when the q-vector contains <code class="reqn">k</code> attributes,
similarly, <code class="reqn">f_{k-1}</code> and <code class="reqn">f_{k+1}</code> represent the fit-index value when the q-vector contains <code class="reqn">k-1</code>
and <code class="reqn">k+1</code> attributes, respectively. <code class="reqn">{np}_k</code> denotes the number of parameters when the
q-vector has <code class="reqn">k</code> attributes, which is <code class="reqn">2^k</code> for a saturated model. Likewise, <code class="reqn">{np}_{k-1}</code>
and <code class="reqn">{np}_{k+1}</code> represent the number of parameters when the q-vector has <code class="reqn">k-1</code> and
<code class="reqn">k+1</code> attributes, respectively. The Hull method calculates the <code class="reqn">st</code> index for all possible q-vectors
and retains the q-vector with the maximum <code class="reqn">st</code> index as the corrected result.
Najera et al. (2021) removed any concave points from the Hull plot, and when only the first and
last points remained in the plot, the saturated q-vector was selected.
</p>


<h3>The MLR-B method</h3>

<p>The MLR-B method proposed by Tu et al. (2022) differs from the GDI, Wald and Hull method in that
it does not employ <code class="reqn">PVAF</code>. Instead, it directly uses the marginal probabilities of attribute mastery for
subjects to perform multivariate logistic regression on their observed scores. This approach assumes
all possible q-vectors and conducts <code class="reqn">2^K-1</code> regression modelings. After proposing regression equations
that exclude any insignificant regression coefficients, it selects the q-vector corresponding to
the equation with the minimum AIC fit as the validation result. The performance of this method in both the
LCDM and GDM models even surpasses that of the Hull method, making it an efficient and reliable
approach for Q-matrix correction.
</p>


<h3>Iterative procedure</h3>

<p>The iterative procedure that one modification at a time is item level iteration (<code>"item"</code>) in (Najera
et al., 2020, 2021), while the iterative procedure that the entire Q-matrix is modified at each iteration
is test level iteration (<code>"test"</code>) (Najera et al., 2020; Tu et al., 2022).
</p>
<p>The steps of the <code>item</code> level iterative procedure algorithm are as follows:
</p>

<dl>
<dt>Step1</dt><dd><p>Fit the <code>CDM</code> according to the item responses and the provisional Q-matrix (<code class="reqn">\mathbf{Q}^0</code>).</p>
</dd>
<dt>Step2</dt><dd><p>Validate the provisional Q-matrix and gain a suggested Q-matrix (<code class="reqn">\mathbf{Q}^1</code>).</p>
</dd>
<dt>Step3</dt><dd><p>for each item, <code class="reqn">PVAF_{0i}</code> as the <code class="reqn">PVAF</code> of the provisional q-vector specified in <code class="reqn">\mathbf{Q}^0</code>,
and <code class="reqn">PVAF_{1i}</code> as the <code class="reqn">PVAF</code> of the suggested q-vector in <code class="reqn">\mathbf{Q}^1</code>.</p>
</dd>
<dt>Step4</dt><dd><p>Calculate all items' <code class="reqn">\delta PVAF_{i}</code>, defined as <code class="reqn">\delta PVAF_{i} = |PVAF_{1i} - PVAF_{0i}|</code></p>
</dd>
<dt>Step5</dt><dd><p>Define the hit item as the item with the highest <code class="reqn">\delta PVAF_{i}</code>.</p>
</dd>
<dt>Step6</dt><dd><p>Update <code class="reqn">\mathbf{Q}^0</code> by changing the provisional q-vector by the suggested q-vector of the hit item.</p>
</dd>
<dt>Step7</dt><dd><p>Iterate over Steps 1 to 6 until <code class="reqn">\sum_{i=1}^{I} \delta PVAF_{i} = 0</code></p>
</dd>
</dl>

<p>The steps of the <code>test</code> level iterative procedure algorithm are as follows:
</p>

<dl>
<dt>Step1</dt><dd><p>Fit the <code>CDM</code> according to the item responses and the provisional Q-matrix (<code class="reqn">\mathbf{Q}^0</code>).</p>
</dd>
<dt>Step2</dt><dd><p>Validate the provisional Q-matrix and gain a suggested Q-matrix (<code class="reqn">\mathbf{Q}^1</code>).</p>
</dd>
<dt>Step3</dt><dd><p>Check whether <code class="reqn">\mathbf{Q}^1 = \mathbf{Q}^0</code>. If <code>TRUE</code>, terminate the iterative algorithm.
If <code>FALSE</code>, Update <code class="reqn">\mathbf{Q}^0</code> as <code class="reqn">\mathbf{Q}^1</code>.</p>
</dd>
<dt>Step4</dt><dd><p>Iterate over Steps 1 and 3 until one of conditions as follows is satisfied: 1. <code class="reqn">\mathbf{Q}^1 =
                 \mathbf{Q}^0</code>; 2. Reach the max iteration (<code>maxitr</code>); 3. <code class="reqn">\mathbf{Q}^1</code> does not satisfy
the condition that an attribute is measured by one item at least.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J., &amp; Chiu, C. Y. (2016). A General Method of Empirical Q-matrix Validation. Psychometrika, 81(2), 253-273. DOI: 10.1007/s11336-015-9467-8.
</p>
<p>de la Torre, J. (2008). An Empirically Based Method of Q-Matrix Validation for the DINA Model: Development and Applications. Journal of Education Measurement, 45(4), 343-362. DOI: 10.1111/j.1745-3984.2008.00069.x.
</p>
<p>Lorenzo-Seva, U., Timmerman, M. E., &amp; Kiers, H. A. (2011). The Hull method for selecting the number of common factors. Multivariate Behavioral Research, 46, 340–364. DOI: 10.1080/00273171.2011.564527.
</p>
<p>Ma, W., &amp; de la Torre, J. (2020). An empirical Q-matrix validation method for the sequential generalized DINA model. British Journal of Mathematical and Statistical Psychology, 73(1), 142-163. DOI: 10.1111/bmsp.12156.
</p>
<p>McFadden, D. (1974). Conditional logit analysis of qualitative choice behavior. In P. Zarembka (Ed.), Frontiers in economics (pp. 105–142). New York, NY: Academic Press.
</p>
<p>Najera, P., Sorrel, M. A., &amp; Abad, F. J. (2019). Reconsidering Cutoff Points in the General Method of Empirical Q-Matrix Validation. Educational and Psychological Measurement, 79(4), 727-753. DOI: 10.1177/0013164418822700.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2020). Improving Robustness in Q-Matrix Validation Using an Iterative and Dynamic Procedure. Applied Psychological Measurement, 44(6), 431-446. DOI: 10.1177/0146621620909904.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing fit and parsimony to improve Q-matrix validation. British Journal of Mathematical and Statistical Psychology, 74 Suppl 1, 110-130. DOI: 10.1111/bmsp.12228.
</p>
<p>Terzi, R., &amp; de la Torre, J. (2018). An Iterative Method for Empirically-Based Q-Matrix Validation. International Journal of Assessment Tools in Education, 248-262. DOI: 10.21449/ijate.40719.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models: A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################################################################
#                           Example 1                          #
#             The GDI method to validate Q-matrix              #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "GDINA", distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM model first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "GDI")


## also can validate the Q-matrix directly
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ)

## item level iteration
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        iter.level = "item", maxitr = 150)

## search method
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        search.method = "ESA")

## cut-off point
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        eps = 0.90)

## check QRR
print(getQRR(example.Q, Q.GDI.obj$Q.sug))




################################################################
#                           Example 2                          #
#             The Wald method to validate Q-matrix             #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.Wald.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "Wald")


## also can validate the Q-matrix directly
Q.Wald.obj &lt;- validation(example.data$dat, example.MQ, method = "Wald")

## check QRR
print(getQRR(example.Q, Q.Wald.obj$Q.sug))




################################################################
#                           Example 3                          #
#             The Hull method to validate Q-matrix             #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "Hull")


## also can validate the Q-matrix directly
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, method = "Hull")

## change PVAF to R2 as fit-index
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, method = "Hull", criter = "R2")

## check QRR
print(getQRR(example.Q, Q.Hull.obj$Q.sug))




################################################################
#                           Example 4                          #
#             The MLR-B method to validate Q-matrix            #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.MLR.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "MLR-B")


## also can validate the Q-matrix directly
Q.MLR.obj &lt;- validation(example.data$dat, example.MQ, method  = "MLR-B")

## check QRR
print(getQRR(example.Q, Q.Hull.obj$Q.sug))


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
