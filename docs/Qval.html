<!DOCTYPE html><html lang="en"><head><title>Help for package Qval</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Qval}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CDM'><p>Parameter estimation for cognitive diagnosis models (CDMs) by MMLE/EM or MMLE/BM algorithm.</p></a></li>
<li><a href='#extract'><p>Extract elements from objects of various classes</p></a></li>
<li><a href='#fit'><p>Calculate fit indeces</p></a></li>
<li><a href='#get.beta'><p>Calculate <code class="reqn">\beta</code></p></a></li>
<li><a href='#get.Mmatrix'><p>Calculate <code class="reqn">\mathbf{M}</code> matrix</p></a></li>
<li><a href='#get.priority'><p>Priority of Attribute</p></a></li>
<li><a href='#get.PVAF'><p>Calculate <code class="reqn">PVAF</code></p></a></li>
<li><a href='#get.R2'><p>Calculate McFadden pseudo-R2</p></a></li>
<li><a href='#get.Rmatrix'><p>Restriction matrix</p></a></li>
<li><a href='#parallel_iter'><p>A tool for the <code class="reqn">\beta</code> Method</p></a></li>
<li><a href='#plot.validation'><p>Hull Plot</p></a></li>
<li><a href='#print.CDM'><p>Print Method for CDM Objects</p></a></li>
<li><a href='#print.sim.data'><p>Print Method for sim.data Objects</p></a></li>
<li><a href='#print.validation'><p>Print Method for Validation Objects</p></a></li>
<li><a href='#sim.data'><p>generate response</p></a></li>
<li><a href='#sim.MQ'><p>Simulate mis-specifications in the Q-matrix</p></a></li>
<li><a href='#sim.Q'><p>generate a random Q-matrix</p></a></li>
<li><a href='#validation'><p>Perform Q-matrix validation methods</p></a></li>
<li><a href='#Wald.test'><p>the Wald test for two q-vectors</p></a></li>
<li><a href='#zOSR'><p>Calculate over-specifcation rate (OSR)</p></a></li>
<li><a href='#zQRR'><p>Calculate Q-matrix recovery rate (QRR)</p></a></li>
<li><a href='#zTNR'><p>Calculate true-negative rate (TNR)</p></a></li>
<li><a href='#zTPR'><p>Calculate true-positive rate (TPR)</p></a></li>
<li><a href='#zUSR'><p>Calculate under-specifcation rate (USR)</p></a></li>
<li><a href='#zVRR'><p>Calculate vector recovery ratio (VRR)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The Q-Matrix Validation Methods Framework</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-08</td>
</tr>
<tr>
<td>Author:</td>
<td>Haijiang Qin <a href="https://orcid.org/0009-0000-6721-5653"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Lei Guo <a href="https://orcid.org/0000-0002-8273-3587"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Haijiang Qin &lt;haijiang133@outlook.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provide a variety of Q-matrix validation methods for the generalized cognitive diagnosis models, including the method based on the generalized deterministic input, noisy, and gate model (G-DINA) by de la Torre (2011) &lt;<a href="https://doi.org/10.1007%2Fs11336-011-9207-7">doi:10.1007/s11336-011-9207-7</a>&gt; discrimination index (the GDI method) by de la Torre and Chiu (2016) &lt;<a href="https://doi.org/10.1007%2Fs11336-015-9467-8">doi:10.1007/s11336-015-9467-8</a>&gt;, the step-wise Wald test method (the Wald method) by Ma and de la Torre (2020) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12156">doi:10.1111/bmsp.12156</a>&gt;, the Hull method by Najera et al. (2021) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12228">doi:10.1111/bmsp.12228</a>&gt;, the multiple logistic regression‑based Q‑matrix validation method (the MLR-B method) by Tu et al. (2022) &lt;<a href="https://doi.org/10.3758%2Fs13428-022-01880-x">doi:10.3758/s13428-022-01880-x</a>&gt;, the beta method based on signal detection theory by Li and Chen (2024) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12371">doi:10.1111/bmsp.12371</a>&gt;  and Q-matrix validation based on relative fit index by Chen et la. (2013) &lt;<a href="https://doi.org/10.1111%2Fj.1745-3984.2012.00185.x">doi:10.1111/j.1745-3984.2012.00185.x</a>&gt;. Different research methods and iterative procedures during Q-matrix validating are available.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, GDINA, plyr, nloptr, MASS, Matrix, parallel, Rcpp,
stats</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Collate:</td>
<td>'CDM.R' 'IndexBeta.R' 'IndexPriority.R' 'IndexPVAF.R'
'IndexR2.R' 'MLR.R' 'MLRlasso.R' 'Mmatrix.R' 'QvalBeta.R'
'QvalGDI.R' 'QvalHull.R' 'QvalMLRB.R' 'QvalWald.R'
'Qvalindex.R' 'Qvalvalidation.R' 'RcppExports.R' 'Rmatrix.R'
'S3.R' 'sim.Q.R' 'sim.MQ.R' 'sim.data.R' 'plot.Hull.R'
'convex.R' 'fit.R' 'Wald.test.R' 'utils.R' 'zzz.R'</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://haijiangqin.com/Qval/">https://haijiangqin.com/Qval/</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-08 03:40:59 UTC; Haiji</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-08 04:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='CDM'>Parameter estimation for cognitive diagnosis models (CDMs) by MMLE/EM or MMLE/BM algorithm.</h2><span id='topic+CDM'></span>

<h3>Description</h3>

<p>A function to estimate parameters for cognitive diagnosis models by MMLE/EM (de la Torre, 2009; de la Torre, 2011)
or MMLE/BM (Ma &amp; Jiang, 2020) algorithm.The function imports various functions from the <code>GDINA</code> package,
parameter estimation for Cognitive Diagnostic Models (CDMs) was performed and extended. The <code>CDM</code> function not
only accomplishes parameter estimation for most commonly used models (e.g., <code>GDINA</code>, <code>DINA</code>, <code>DINO</code>,
<code>ACDM</code>, <code>LLM</code>, or <code>rRUM</code>). Furthermore, it incorporates Bayes modal estimation
(BM; Ma &amp; Jiang, 2020) to obtain more reliable estimation results, especially in small sample sizes.
The monotonic constraints are able to be satisfied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDM(
  Y,
  Q,
  model = "GDINA",
  method = "EM",
  mono.constraint = TRUE,
  maxitr = 2000,
  verbose = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CDM_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>, <code>"ACDM"</code>,
<code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_method">method</code></td>
<td>
<p>Type of method to estimate CDMs' parameters; one out of <code>"EM"</code> and <code>"BM"</code>. Default = <code>"EM"</code>. 
However, <code>"BM"</code> is only avaible when <code>method = "GDINA"</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_mono.constraint">mono.constraint</code></td>
<td>
<p>Logical indicating whether monotonicity constraints should be fulfilled in estimation.
Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_maxitr">maxitr</code></td>
<td>
<p>A vector for each item or nonzero category, or a scalar which will be used for all items
to specify the maximum number of EM or BM cycles allowed. Default = <code>2000</code>.</p>
</td></tr>
<tr><td><code id="CDM_+3A_verbose">verbose</code></td>
<td>
<p>Can be <code>0</code>, <code>1</code> or <code>2</code>, indicating to print no information, information
for current iteration, or information for all iterations. Default = <code>1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CDMs are statistical models that fully integrates cognitive structure variables, which define the response
probability of examinees on items by assuming the mechanism between attributes. In the
dichotomous test, this probability is the probability of answering correctly. According to the specificity
or generality of CDM assumptions, it can be divided into reduced CDM and saturated CDM.
</p>
<p>Reduced CDMs possess specific assumptions about the mechanisms of attribute interactions, leading
to clear interactions between attributes. Representative reduced models include the Deterministic Input,
Noisy and Gate (DINA) model (Haertel, 1989; Junker &amp; Sijtsma, 2001; de la Torre &amp; Douglas, 2004), the
Deterministic Input, Noisy or Gate (DINO) model (Templin &amp; Henson, 2006), and the Additive Cognitive Diagnosis
Model (A-CDM; de la Torre, 2011), the reduced Reparametrized Unified Model (rRUM; Hartz, 2002), among others.
Compared to reduced models, saturated models, such as the Log-Linear Cognitive Diagnosis Model (LCDM; Henson et
al., 2009) and the general Deterministic Input, Noisy and Gate model (G-DINA; de la Torre, 2011), 
do not have strict assumptions about the mechanisms of attribute interactions. When appropriate constraints 
are applied, saturated models can be transformed into various reduced models (Henson et al., 2008; de la Torre, 2011).
</p>
<p>The LCDM is a saturated CDM fully proposed within the framework of
cognitive diagnosis. Unlike reduced models that only discuss the main effects of attributes, it also
considers the interaction between attributes, thus having more generalized assumptions about attributes.
Its definition of the probability of correct response is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   P(X_{pi}=1|\boldsymbol{\alpha}_{l}) =
   \frac{\exp \left[\lambda_{i0} + \boldsymbol{\lambda}_{i}^{T} \boldsymbol{h} (\boldsymbol{q}_{i}, \boldsymbol{\alpha}_{l}) \right]}
   {1 + \exp \left[\lambda_{i0} + \boldsymbol{\lambda}_{i}^{T} \boldsymbol{h} (\boldsymbol{q}_{i}, \boldsymbol{\alpha}_{l}) \right]}
</code>
</p>

<p style="text-align: center;"><code class="reqn">
   \boldsymbol{\lambda}_{i}^{T} \boldsymbol{h}(\boldsymbol{q}_{i}, \boldsymbol{\alpha}_{l}) =
   \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}
   \lambda_{ikk'}\alpha_{lk}\alpha_{lk'} +
   \cdots + \lambda_{12 \cdots K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p>Where, <code class="reqn">P(X_{pi}=1|\boldsymbol{\alpha}_{l})</code> represents the probability of an examinee with attribute mastery
pattern <code class="reqn">\boldsymbol{\alpha}_{l}</code> (<code class="reqn">l=1,2,\cdots,L</code> and <code class="reqn">L=2^{K^\ast}</code>) correctly answering item i.
Here, <code class="reqn">K^\ast = \sum_{k=1}^{K} q_{ik}</code> denotes the number of attributes in the collapsed q-vector, <code class="reqn">\lambda_{i0}</code> is the
intercept parameter, and <code class="reqn">\boldsymbol{\lambda}_{i}=(\lambda_{i1}, \lambda_{i2}, \cdots, \lambda_{i12},
\cdots, \lambda_{i12{\cdots}K^\ast})</code> represents the effect vector of the attributes. Specifically,
<code class="reqn">\lambda_{ik}</code> is the main effect of attribute <code class="reqn">k</code>, <code class="reqn">\lambda_{ikk'}</code> is the interaction effect between
attributes <code class="reqn">k</code> and <code class="reqn">k'</code>, and <code class="reqn">\lambda_{j12{\cdots}K^\ast}</code> represents the interaction effect of all required attributes.
</p>
<p>The G-DINA, proposed by de la Torre (2011), is another saturated
model that offers three types of link functions: identity link, log link, and logit link, which are defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{pi}=1|\boldsymbol{\alpha}_{l}) =
   \delta_{i0} + \sum_{k=1}^{K^\ast}\delta_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}\delta_{ikk'}\alpha_{lk}\alpha_{lk'} +
   \cdots + \delta_{12{\cdots}K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p style="text-align: center;"><code class="reqn">log \left[P(X_{pi}=1|\boldsymbol{\alpha}_{l}) \right] =
   v_{i0} + \sum_{k=1}^{K^\ast}v_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}v_{ikk'}\alpha_{lk}\alpha_{lk'} +
   \cdots + v_{12{\cdots}K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p style="text-align: center;"><code class="reqn">logit \left[P(X_{pi}=1|\boldsymbol{\alpha}_{l}) \right] =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk} +\sum_{k=1}^{K^\ast-1}\sum_{k'=k+1}^{K^\ast}\lambda_{ikk'}\alpha_{lk}\alpha_{lk'} +
   \cdots + \lambda_{12{\cdots}K^\ast}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p>Where <code class="reqn">\delta_{i0}</code>, <code class="reqn">v_{i0}</code>, and <code class="reqn">\lambda_{i0}</code> are the intercept parameters for the three
link functions, respectively; <code class="reqn">\delta_{ik}</code>, <code class="reqn">v_{ik}</code>, and <code class="reqn">\lambda_{ik}</code> are the main effect
parameters of <code class="reqn">\alpha_{lk}</code> for the three link functions, respectively; <code class="reqn">\delta_{ikk'}</code>, <code class="reqn">v_{ikk'}</code>,
and <code class="reqn">\lambda_{ikk'}</code> are the interaction effect parameters between <code class="reqn">\alpha_{lk}</code> and <code class="reqn">\alpha_{lk'}</code>
for the three link functions, respectively; and <code class="reqn">\delta_{i12{\cdots }K^\ast}</code>, <code class="reqn">v_{i12{\cdots}K^\ast}</code>,
and <code class="reqn">\lambda_{i12{\cdots}K^\ast}</code> are the interaction effect parameters of <code class="reqn">\alpha_{l1}{\cdots}\alpha_{lK^\ast}</code>
for the three link functions, respectively. It can be observed that when the logit link is adopted, the
G-DINA model is equivalent to the LCDM model.
</p>
<p>Specifically, the A-CDM can be formulated as:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{pi}=1|\boldsymbol{\alpha}_{l}) =
   \delta_{i0} + \sum_{k=1}^{K^\ast}\delta_{ik}\alpha_{lk}
</code>
</p>

<p>The rRUM, can be written as:
</p>
<p style="text-align: center;"><code class="reqn">log \left[P(X_{pi}=1|\boldsymbol{\alpha}_{l}) \right] =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk}
</code>
</p>

<p>The item response function for the linear logistic model (LLM) can be given by:
</p>
<p style="text-align: center;"><code class="reqn">logit\left[P(X_{pi}=1|\boldsymbol{\alpha}_{l}) \right] =
   \lambda_{i0} + \sum_{k=1}^{K^\ast}\lambda_{ik}\alpha_{lk}
</code>
</p>

<p>In the DINA model, every item is characterized by two key parameters: guessing (g) and slip (s). Within
the traditional framework of DINA model parameterization, a latent variable <code class="reqn">\eta</code>, specific to
examinee <code class="reqn">p</code> who has the attribute mastery pattern <code class="reqn">\boldsymbol{\alpha}_{l}</code> and responses to <code class="reqn">i</code>, 
is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   \eta_{li}=\prod_{k=1}^{K}\alpha_{lk}^{q_{ik}}
</code>
</p>

<p>If examinee <code class="reqn">p</code> whose attribute mastery pattern is <code class="reqn">\boldsymbol{\alpha}_{l}</code> has acquired every attribute
required by item i, <code class="reqn">\eta_{pi}</code> is given a value of 1. If not, <code class="reqn">\eta_{pi}</code> is set to 0. The
DINA model's item response function can be concisely formulated as such:
</p>
<p style="text-align: center;"><code class="reqn">P(X_{pi}=1|\boldsymbol{\alpha}_{l}) =
   (1-s_j)^{\eta_{li}}g_j^{(1-\eta_{li})} =
   \delta_{i0}+\delta_{i12{\cdots}K}\prod_{k=1}^{K^\ast}\alpha_{lk}
</code>
</p>

<p><code class="reqn">(1-s_j)^{\eta_{li}}g_j^{(1-\eta_{li})}</code> is the original expression of the DINA model, while  
<code class="reqn">\delta_{i0}+\delta_{i12{\cdots}K}\prod_{k=1}^{K^\ast}\alpha_{lk}</code>  
is an equivalent form of the DINA model after adding constraints in the G-DINA model.  
Here, <code class="reqn">g_j = \delta_{i0}</code> and <code class="reqn">1-s_j = \delta_{i0}+\delta_{i12{\cdots}K}\prod_{k=1}^{K^\ast}\alpha_{lk}</code>.  
</p>
<p>In contrast to the DINA model, the DINO model suggests that an examinee can correctly respond to
an item if he/she have mastered at least one of the item's measured attributes. Additionally, like the
DINA model, the DINO model also accounts for parameters related to guessing and slipping. Therefore,
the main difference between DINO and DINA lies in their respective <code class="reqn">\eta_{li}</code> formulations. The
DINO model can be given by:
</p>
<p style="text-align: center;"><code class="reqn">\eta_{li} = 1-\prod_{k=1}^{K}(1 - \alpha_{lk})^{q_{lk}}</code>
</p>



<h3>Value</h3>

<p>An object of class <code>CDM</code> containing the following components:
</p>

<dl>
<dt>analysis.obj</dt><dd><p>An <code><a href="GDINA.html#topic+GDINA">GDINA</a></code> object gained from <code>GDINA</code> package or an 
<code>list</code> after BM algorithm, depending on which estimation is used.</p>
</dd>
<dt>alpha</dt><dd><p>Individuals' attribute parameters calculated by EAP method</p>
</dd>
<dt>P.alpha.Xi</dt><dd><p>Individual's posterior probability</p>
</dd>
<dt>alpha.P</dt><dd><p>Individuals' marginal mastery probabilities matrix</p>
</dd>
<dt>P.alpha</dt><dd><p>Attribute prior weights for calculating marginalized likelihood in the last iteration</p>
</dd>
<dt>model.fit</dt><dd><p>Some basic model-fit indeces, including <code>Deviance</code>, <code>npar</code>, <code>AIC</code>, <code>BIC</code>. @seealso <code><a href="#topic+fit">fit</a></code></p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J. (2009). DINA Model and Parameter Estimation: A Didactic. Journal of Educational and Behavioral Statistics, 34(1), 115-130. DOI: 10.3102/1076998607309474.
</p>
<p>de la Torre, J., &amp; Douglas, J. A. (2004). Higher-order latent trait models for cognitive diagnosis. Psychometrika, 69(3), 333-353. DOI: 10.1007/BF02295640.
</p>
<p>de la Torre, J. (2011). The Generalized DINA Model Framework. Psychometrika, 76(2), 179-199. DOI: 10.1007/s11336-011-9207-7.
</p>
<p>Haertel, E. H. (1989). Using restricted latent class models to map the skill structure of achievement items. Journal of Educational Measurement, 26(4), 301-323. DOI: 10.1111/j.1745-3984.1989.tb00336.x.
</p>
<p>Hartz, S. M. (2002). A Bayesian framework for the unified model for assessing cognitive abilities: Blending theory with practicality (Unpublished doctoral dissertation). University of Illinois at Urbana-Champaign.
</p>
<p>Henson, R. A., Templin, J. L., &amp; Willse, J. T. (2008). Defining a Family of Cognitive Diagnosis Models Using Log-Linear Models with Latent Variables. Psychometrika, 74(2), 191-210. DOI: 10.1007/s11336-008-9089-5.
</p>
<p>Huebner, A., &amp; Wang, C. (2011). A note on comparing examinee classification methods for cognitive diagnosis models. Educational and Psychological Measurement, 71, 407-419. DOI: 10.1177/0013164410388832.
</p>
<p>Junker, B. W., &amp; Sijtsma, K. (2001). Cognitive assessment models with few assumptions, and connections with nonparametric item response theory. Applied Psychological Measurement, 25(3), 258-272. DOI: 10.1177/01466210122032064.
</p>
<p>Ma, W., &amp; Jiang, Z. (2020). Estimating Cognitive Diagnosis Models in Small Samples: Bayes Modal Estimation and Monotonic Constraints. Applied Psychological Measurement, 45(2), 95-111. DOI: 10.1177/0146621620977681.
</p>
<p>Templin, J. L., &amp; Henson, R. A. (2006). Measurement of psychological disorders using cognitive diagnosis models. Psychological methods, 11(3), 287-305. DOI: 10.1037/1082-989X.11.3.287.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models: A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################################################################
#                           Example 1                          #
#            fit using MMLE/EM to fit the GDINA models         #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 3
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "GDINA", distribute = "horder")


## using MMLE/EM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "GDINA",
                       method = "EM", maxitr = 2000, verbose = 1)



################################################################
#                           Example 2                          #
#               fit using MMLE/BM to fit the DINA              #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "DINA", distribute = "horder")


## using MMLE/BM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "GDINA",
                       method = "BM", maxitr = 1000, verbose = 2)


################################################################
#                           Example 3                          #
#              fit using MMLE/EM to fit the ACDM               #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "ACDM", distribute = "horder")


## using MMLE/EM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "ACDM",
                       method = "EM", maxitr = 2000, verbose = 1)


</code></pre>

<hr>
<h2 id='extract'>Extract elements from objects of various classes</h2><span id='topic+extract'></span><span id='topic+extract.CDM'></span><span id='topic+extract.validation'></span><span id='topic+extract.sim.data'></span>

<h3>Description</h3>

<p>A generic function to extract elements from objects of class <code>CDM</code>, <code>validation</code> or <code>sim.data</code>.
</p>
<p>Objects which can be extracted from <code><a href="#topic+CDM">CDM</a></code> object include:
</p>

<dl>
<dt>analysis.obj</dt><dd><p>An <code>GDINA</code> object (@seealso <code><a href="GDINA.html#topic+GDINA">GDINA</a></code>) gained from <code>GDINA</code> package or an 
<code>list</code> after BM algorithm, depending on which estimation is used.</p>
</dd>
<dt>alpha</dt><dd><p>Individuals' attribute parameters calculated by EAP method</p>
</dd>
<dt>P.alpha.Xi</dt><dd><p>Individual's posterior probability</p>
</dd>
<dt>alpha.P</dt><dd><p>Individuals' marginal mastery probabilities matrix</p>
</dd>
<dt>P.alpha</dt><dd><p>Attribute prior weights for calculating marginalized likelihood in the last iteration</p>
</dd>
<dt>Deviance</dt><dd><p>deviance, or negative two times observed marginal log likelihood</p>
</dd>
<dt>npar</dt><dd><p>The number of parameters</p>
</dd>
<dt>AIC</dt><dd><p>AIC</p>
</dd>
<dt>BIC</dt><dd><p>BIC</p>
</dd>
</dl>

<p>Objects which can be extracted from <code><a href="#topic+validation">validation</a></code> object include:
</p>

<dl>
<dt>Q.orig</dt><dd><p>The original Q-matrix that maybe contain some mis-specifications and need to be validated.</p>
</dd>
<dt>Q.sug</dt><dd><p>The Q-matrix that suggested by certain validation method.</p>
</dd>
<dt>time.cost</dt><dd><p>The time that CPU cost to finish the validation.</p>
</dd>
<dt>process</dt><dd><p>A matrix that contains the modification process of each item during each iteration. 
Each row represents an iteration, and each column corresponds to the q-vector index of respective 
item. The order of the indices is consistent with the row number in the matrix generated by 
the <code><a href="GDINA.html#topic+attributepattern">attributepattern</a></code> function in the <code>GDINA</code> package. Only when 
<code>maxitr</code> &gt; 1, the value is available.</p>
</dd>
<dt>iter</dt><dd><p>The number of iteration. Only when <code>maxitr</code> &gt; 1, the value is available.</p>
</dd>
<dt>priority</dt><dd><p>An <code>I</code> × <code>K</code> matrix that contains the priority of every attribute for
each item. Only when the <code>search.method</code> is <code>"PAA"</code>, the value is available.</p>
</dd>
<dt>Hull.fit</dt><dd><p>A <code>list</code> containing all the information needed to plot the Hull plot, which is 
available only when <code>method</code> = <code>"Hull"</code>.</p>
</dd>
</dl>

<p>Objects which can be extracted from <code><a href="#topic+sim.data">sim.data</a></code> object include:
</p>

<dl>
<dt>dat</dt><dd><p>An <code>N</code> × <code>I</code> simulated item response matrix.</p>
</dd>
<dt>Q</dt><dd><p>The Q-matrix.</p>
</dd>
<dt>attribute</dt><dd><p>An <code>N</code> × <code>K</code> matrix for inviduals' attribute patterns.</p>
</dd>
<dt>catprob.parm</dt><dd><p>A list of non-zero category success probabilities for each attribute mastery pattern.</p>
</dd>
<dt>delta.parm</dt><dd><p>A list of delta parameters.</p>
</dd>
<dt>higher.order.parm</dt><dd><p>Higher-order parameters.</p>
</dd>
<dt>mvnorm.parm</dt><dd><p>Multivariate normal distribution parameters.</p>
</dd>
<dt>LCprob.parm</dt><dd><p>A matrix of item/category success probabilities for each attribute mastery pattern.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>extract(object, what, ...)

## S3 method for class 'CDM'
extract(object, what, ...)

## S3 method for class 'validation'
extract(object, what, ...)

## S3 method for class 'sim.data'
extract(object, what, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_+3A_object">object</code></td>
<td>
<p>objects from class <code>CDM</code>, <code>validation</code>, <code>sim.data</code></p>
</td></tr>
<tr><td><code id="extract_+3A_what">what</code></td>
<td>
<p>what to extract</p>
</td></tr>
<tr><td><code id="extract_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>extract(CDM)</code>: various elements of <code>CDM</code> object
</p>
</li>
<li> <p><code>extract(validation)</code>: various elements of <code>validation</code> object
</p>
</li>
<li> <p><code>extract(sim.data)</code>: various elements of <code>sim.data</code> object
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 3
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 1000, IQ = IQ,
                         model = "GDINA", distribute = "horder")
extract(example.data,"dat")


## using MMLE/EM to fit GDINA model
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model = "GDINA",
                       method = "EM", maxitr = 2000, verbose = 1)
extract(example.CDM.obj,"alpha")
extract(example.CDM.obj,"npar")

example.MQ &lt;- sim.MQ(example.Q, 0.1)
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ, model = "GDINA",
                       method = "EM", maxitr = 2000, verbose = 1)
                       
validation.obj &lt;- validation(example.data$dat, example.MQ, 
                             example.CDM.obj, method = "MLR-B", eps = 0.90)
extract(validation.obj,"Q.sug")

</code></pre>

<hr>
<h2 id='fit'>Calculate fit indeces</h2><span id='topic+fit'></span>

<h3>Description</h3>

<p>Calculate relative fit indices (-2LL, AIC, BIC, CAIC, SABIC) and absolute fit indices (<code class="reqn">M_2</code> test, <code class="reqn">RMSEA_2</code>, SRMSR) 
using the <code><a href="GDINA.html#topic+modelfit">modelfit</a></code> function in the <code>GDINA</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit(Y, Q, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="fit_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="fit_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>list</code>. The list contains various fit indices:
</p>

<dl>
<dt>npar</dt><dd><p>The number of parameters.</p>
</dd>
<dt>-2LL</dt><dd><p>The Deviance.</p>
</dd>
<dt>AIC</dt><dd><p>The Akaike information criterion.</p>
</dd>
<dt>BIC</dt><dd><p>The Bayesian information criterion.</p>
</dd>
<dt>CAIC</dt><dd><p>The consistent Akaike information criterion.</p>
</dd>
<dt>SABIC</dt><dd><p>The Sample-size Adjusted BIC.</p>
</dd>
<dt>M2</dt><dd><p>A vector consisting of <code class="reqn">M_2</code> statistic, degrees of freedom, significance level, and <code class="reqn">RMSEA_2</code> (Liu, Tian, &amp; Xin, 2016).</p>
</dd>
<dt>SRMSR</dt><dd><p>The standardized root mean squared residual (SRMSR; Ravand &amp; Robitzsch, 2018).</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Khaldi, R., Chiheb, R., &amp; Afa, A.E. (2018). Feed-forward and Recurrent Neural Networks for Time Series Forecasting: Comparative Study. In: Proceedings of the International Conference on Learning and Optimization Algorithms: Theory and Applications (LOPAL 18). Association for Computing Machinery, New York, NY, USA, Article 18, 1–6. DOI: 10.1145/3230905.3230946.
</p>
<p>Liu, Y., Tian, W., &amp; Xin, T. (2016). An application of M2 statistic to evaluate the fit of cognitive diagnostic models. Journal of Educational and Behavioral Statistics, 41, 3–26. DOI: 10.3102/1076998615621293.
</p>
<p>Ravand, H., &amp; Robitzsch, A. (2018). Cognitive diagnostic model of best choice: a study of reading comprehension. Educational Psychology, 38, 1255–1277. DOI: 10.1080/01443410.2018.1489524.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)

library(Qval)

## generate Q-matrix and data to fit
K &lt;- 5
I &lt;- 30
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")

## calculate fit indices
fit.indices &lt;- fit(Y = example.data$dat, Q = example.Q, model = "GDINA")
print(fit.indices)

</code></pre>

<hr>
<h2 id='get.beta'>Calculate <code class="reqn">\beta</code></h2><span id='topic+get.beta'></span>

<h3>Description</h3>

<p>The function is able to calculate the <code class="reqn">\beta</code> index for all items after fitting <code>CDM</code> or directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.beta(Y = NULL, Q = NULL, CDM.obj = NULL, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.beta_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get.beta_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="get.beta_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. Can be <code>NULL</code>, but when it is not <code>NULL</code>, it enables
rapid validation of the Q-matrix without the need for parameter estimation.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="get.beta_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For item <code class="reqn">i</code> with the q-vector of the <code class="reqn">c</code>-th (<code class="reqn">c = 1, 2, ..., 2^{K}</code>) type, the <code class="reqn">\beta</code> index is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   \beta_{ic} = \sum_{l=1}^{2^K} \left| \frac{r_{li}}{n_l} P_{ic}(\boldsymbol{\alpha}_{l}) - 
                \left(1 - \frac{r_{li}}{n_l}\right) \left[1 - P_{ic}(\boldsymbol{\alpha}_{l})\right] \right|
              = \sum_{l=1}^{2^K} \left| \frac{r_{li}}{n_l} - \left[1 - P_{ic}(\boldsymbol{\alpha}_{l}) \right] \right|
 </code>
</p>

<p>In the formula, <code class="reqn">r_{li}</code> represents the number of examinees in attribute mastery pattern <code class="reqn">\boldsymbol{\alpha}_{l}</code> who correctly 
answered item <code class="reqn">i</code>, while <code class="reqn">n_l</code> is the total number of examinees in attribute mastery pattern <code class="reqn">\boldsymbol{\alpha}_{l}</code>. 
<code class="reqn">P_{ic}(\boldsymbol{\alpha}_{l})</code> denotes the probability that an examinee in attribute mastery pattern <code class="reqn">\boldsymbol{\alpha}_{l}</code> answers 
item <code class="reqn">i</code> correctly when the q-vector for item <code class="reqn">i</code> is of the <code class="reqn">c</code>-th type. In fact, 
<code class="reqn">\frac{r_{li}}{n_l}</code> is the observed probability that an examinee in attribute mastery pattern <code class="reqn">\boldsymbol{\alpha}_{l}</code> answers 
item <code class="reqn">i</code> correctly, and <code class="reqn">\beta_{jc}</code> represents the difference between the actual proportion of 
correct answers for item <code class="reqn">i</code> in each attribute mastery pattern and the expected probability of answering the 
item incorrectly in that state. Therefore, to some extent, <code class="reqn">\beta_{jc}</code> can be considered as a measure 
of discriminability.
</p>


<h3>Value</h3>

<p>An object of class <code>matrix</code>, which consisted of <code class="reqn">\beta</code> index for each item and each possible attribute mastery pattern.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Li, J., &amp; Chen, P. (2024). A new Q-matrix validation method based on signal detection theory. British Journal of Mathematical and Statistical Psychology, 00, 1–33. DOI: 10.1111/bmsp.12371
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

## generate Q-matrix and data
K &lt;- 3
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

model &lt;- "DINA"
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = model, distribute = "horder")

## calculate beta directly
beta &lt;-get.beta(Y = example.data$dat, Q = example.Q, model = model)
print(beta)

## calculate beta after fitting CDM
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model=model)
beta &lt;-get.beta(CDM.obj = example.CDM.obj)
print(beta)

</code></pre>

<hr>
<h2 id='get.Mmatrix'>Calculate <code class="reqn">\mathbf{M}</code> matrix</h2><span id='topic+get.Mmatrix'></span>

<h3>Description</h3>

<p>Calculate <code class="reqn">\mathbf{M}</code> matrix for stauted CDMs (de la Torre, 2011). The <code class="reqn">\mathbf{M}</code> matrix is a matrix used to 
represent the interaction mechanisms between attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.Mmatrix(K = NULL, pattern = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.Mmatrix_+3A_k">K</code></td>
<td>
<p>The number of attributes. Can be <code>NULL</code> if the argument <code>pattern</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="get.Mmatrix_+3A_pattern">pattern</code></td>
<td>
<p>The attribute mastery pattern matrix containing all possible attribute mastery pattern.
Can be gained from <code><a href="GDINA.html#topic+attributepattern">attributepattern</a></code>. Also can be <code>NULL</code> if <code>K</code>
is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J. (2011). The Generalized DINA Model Framework. Psychometrika, 76(2), 179-199. DOI: 10.1007/s11336-011-9207-7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(Qval)

example.Mmatrix &lt;-  get.Mmatrix(K = 5)

</code></pre>

<hr>
<h2 id='get.priority'>Priority of Attribute</h2><span id='topic+get.priority'></span>

<h3>Description</h3>

<p>This function will provide the priorities of attributes for all items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.priority(Y = NULL, Q = NULL, CDM.obj = NULL, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.priority_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get.priority_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="get.priority_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. When it is not NULL, it enables rapid validation
of the Q-matrix without the need for parameter estimation. @seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="get.priority_+3A_model">model</code></td>
<td>
<p>Type of model to fit; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>
, <code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation of priorities is straightforward (Qin &amp; Guo, 2025): the priority of an attribute is the 
regression coefficient obtained from a LASSO multinomial logistic regression, with the attribute 
as the independent variable and the response data from the examinees as the dependent variable.  
The formula (Tu et al., 2022) is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
 \log[\frac{P(X_{pi} = 1 | \boldsymbol{\Lambda}_{p})}{P(X_{pi} = 0 | \boldsymbol{\Lambda}_{p})}] = 
 logit[P(X_{pi} = 1 | \boldsymbol{\Lambda}_{p})] = 
 \beta_{i0} + \beta_{i1} \Lambda_{p1} + \ldots + \beta_{ik} \Lambda_{pk} + \ldots + \beta_{iK} \Lambda_{pK}
</code>
</p>

<p>Where <code class="reqn">X_{pi}</code> represents the response of examinee <code class="reqn">p</code> on item <code class="reqn">i</code>,  
<code class="reqn">\boldsymbol{\Lambda}_{p}</code> denotes the marginal mastery probabilities of examinee <code class="reqn">p</code>  
(which can be obtained from the return value <code>alpha.P</code> of the <code><a href="#topic+CDM">CDM</a></code> function),  
<code class="reqn">\beta_{i0}</code> is the intercept term, and <code class="reqn">\beta_{ik}</code> represents the regression coefficient.  
</p>
<p>The LASSO loss function can be expressed as:
</p>
<p style="text-align: center;"><code class="reqn">l_{lasso}(\boldsymbol{X}_i | \boldsymbol{\Lambda}) = l(\boldsymbol{X}_i | \boldsymbol{\Lambda}) - \lambda |\boldsymbol{\beta}_i|</code>
</p>

<p>Where <code class="reqn">l_{lasso}(\boldsymbol{X}_i | \boldsymbol{\Lambda})</code> is the penalized likelihood,  
<code class="reqn">l(\boldsymbol{X}_i | \boldsymbol{\Lambda})</code> is the original likelihood,  
and <code class="reqn">\lambda</code> is the tuning parameter for penalization (a larger value imposes a stronger penalty on 
<code class="reqn">\boldsymbol{\beta}_i = [\beta_{i1}, \ldots, \beta_{ik}, \ldots, \beta_{iK}]</code>).  
The priority for attribute <code class="reqn">i</code> is defined as: <code class="reqn">\boldsymbol{priority}_i = \boldsymbol{\beta}_i = [\beta_{i1}, \ldots, \beta_{ik}, \ldots, \beta_{iK}]</code>
</p>


<h3>Value</h3>

<p>A matrix containing all attribute priorities.
</p>


<h3>References</h3>

<p>Qin, H., &amp; Guo, L. (2025). Priority attribute algorithm for Q-matrix validation: A didactic. Behavior Research Methods, 57(1), 31. DOI: 10.3758/s13428-024-02547-5.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models: A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
library(Qval)

## generate Q-matrix and data
K &lt;- 5
I &lt;- 20
IQ &lt;- list(
  P0 = runif(I, 0.1, 0.3),
  P1 = runif(I, 0.7, 0.9)
)


Q &lt;- sim.Q(K, I)
data &lt;- sim.data(Q = Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")
MQ &lt;- sim.MQ(Q, 0.1)

CDM.obj &lt;- CDM(data$dat, MQ)

priority &lt;- get.priority(data$dat, Q, CDM.obj)
head(priority)



</code></pre>

<hr>
<h2 id='get.PVAF'>Calculate <code class="reqn">PVAF</code></h2><span id='topic+get.PVAF'></span>

<h3>Description</h3>

<p>The function is able to calculate the proportion of variance accounted for (<code class="reqn">PVAF</code>) for all items
after fitting <code>CDM</code> or directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.PVAF(Y = NULL, Q = NULL, CDM.obj = NULL, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.PVAF_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get.PVAF_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="get.PVAF_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. Can can be <code>NULL</code>, but when it is not <code>NULL</code>, it enables
rapid verification of the Q-matrix without the need for parameter estimation.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="get.PVAF_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intrinsic essence of the GDI index (as denoted by <code class="reqn">\zeta_{2}</code>) is the weighted variance of
all <code class="reqn">2^{K\ast}</code> attribute mastery patterns' probabilities of correctly responding to
item <code class="reqn">i</code>, which can be computed as:
</p>
<p style="text-align: center;"><code class="reqn">
 \zeta^2 =
 \sum_{l=1}^{2^K} \pi_{l}{(P(X_{pi}=1|\boldsymbol{\alpha}_{l}) - \bar{P}_{i})}^2
</code>
</p>

<p>where <code class="reqn">\pi_{l}</code> represents the prior probability of mastery pattern <code class="reqn">l</code>;
<code class="reqn">\bar{P}_{i}=\sum_{k=1}^{2^K}\pi_{l}P(X_{pi}=1|\boldsymbol{\alpha}_{l})</code> is the weighted average of the correct
response probabilities across all attribute mastery patterns. When the q-vector
is correctly specified, the calculated <code class="reqn">\zeta^2</code> should be maximized, indicating
the maximum discrimination of the item.
</p>
<p>Theoretically, <code class="reqn">\zeta^{2}</code> is larger when <code class="reqn">\boldsymbol{q}_{i}</code> is either specified correctly or over-specified,
unlike when <code class="reqn">\boldsymbol{q}_{i}</code> is under-specified, and that when <code class="reqn">\boldsymbol{q}_{i}</code> is over-specified, <code class="reqn">\zeta^{2}</code>
is larger than but close to the value of <code class="reqn">\boldsymbol{q}_{i}</code> when specified correctly. The value of <code class="reqn">\zeta^{2}</code> continues to
increase slightly as the number of over-specified attributes increases, until <code class="reqn">\boldsymbol{q}_{i}</code> becomes <code class="reqn">\boldsymbol{q}_{i1:K}</code> 
(<code class="reqn">\boldsymbol{q}_{i1:K}</code> = [11...1]).
Thus, <code class="reqn">\zeta^{2} / \zeta_{max}^{2}</code> is computed to indicate the proportion of variance accounted for by <code class="reqn">\boldsymbol{q}_{i}</code>, 
called the <code class="reqn">PVAF</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>matrix</code>, which consisted of <code class="reqn">PVAF</code> for each item and each possible q-vector.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J., &amp; Chiu, C. Y. (2016). A General Method of Empirical Q-matrix Validation. Psychometrika, 81(2), 253-273. DOI: 10.1007/s11336-015-9467-8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

## generate Q-matrix and data
K &lt;- 3
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")

## calculate PVAF directly
PVAF &lt;-get.PVAF(Y = example.data$dat, Q = example.Q)
print(PVAF)

## calculate PVAF after fitting CDM
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model="GDINA")
PVAF &lt;-get.PVAF(CDM.obj = example.CDM.obj)
print(PVAF)

</code></pre>

<hr>
<h2 id='get.R2'>Calculate McFadden pseudo-R2</h2><span id='topic+get.R2'></span>

<h3>Description</h3>

<p>The function is able to calculate the McFadden pseudo-<code class="reqn">R^{2}</code> (<code class="reqn">R^{2}</code>) for all items after
fitting <code>CDM</code> or directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.R2(Y = NULL, Q = NULL, CDM.obj = NULL, model = "GDINA")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.R2_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="get.R2_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="get.R2_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. Can can be NULL, but when it is not NULL, it
enables rapid verification of the Q-matrix without the need for parameter estimation.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="get.R2_+3A_model">model</code></td>
<td>
<p>Type of model to fit; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The McFadden pseudo-<code class="reqn">R^{2}</code> (McFadden, 1974) serves as a definitive model-fit index,
quantifying the proportion of variance explained by the observed responses. Comparable to the
squared multiple-correlation coefficient in linear statistical models, this coefficient of
determination finds its application in logistic regression models. Specifically, in the context
of the CDM, where probabilities of accurate item responses are predicted for each examinee,
the McFadden pseudo-<code class="reqn">R^{2}</code> provides a metric to assess the alignment between these predictions
and the actual responses observed. Its computation is straightforward, following the formula:
</p>
<p style="text-align: center;"><code class="reqn">
 R_{i}^{2} = 1 - \frac{\log(L_{im})}{\log(L_{i0})}
</code>
</p>

<p>where <code class="reqn">\log(L_{im})</code> is the log-likelihood of the model, and  <code class="reqn">\log(L_{i0})</code> is the log-likelihood of
the null model. If there were <code class="reqn">N</code> examinees taking a test comprising <code class="reqn">I</code> items, then <code class="reqn">\log(L_{im})</code>
would be computed as:
</p>
<p style="text-align: center;"><code class="reqn">
 \log(L_{im}) =
 \sum_{p}^{N} \log \sum_{l=1}^{2^{K^\ast}} \pi(\boldsymbol{\alpha}_{l}^{\ast} | \boldsymbol{X}_{p})
   P_{i}(\boldsymbol{\alpha}_{l}^{\ast})^{X_{pi}} \left[ 1-P_{i}(\boldsymbol{\alpha}_{l}^{\ast}) \right] ^{(1-X_{pi})}
</code>
</p>

<p>where <code class="reqn">\pi(\boldsymbol{\alpha}_{l}^{\ast} | \boldsymbol{X}_{p})</code> is the posterior probability of examinee <code class="reqn">p</code> with attribute
mastery pattern <code class="reqn">\boldsymbol{\alpha}_{l}^{\ast}</code> when their response vector is <code class="reqn">\boldsymbol{X}_{p}</code>, and <code class="reqn">X_{pi}</code> is
examinee <code class="reqn">p</code>'s response to item <code class="reqn">i</code>. Let <code class="reqn">\bar{X}_{i}</code> be the average probability of correctly responding
to item <code class="reqn">i</code> across all <code class="reqn">N</code> examinees; then <code class="reqn">\log(L_{i0})</code> could be computed as:
</p>
<p style="text-align: center;"><code class="reqn">
 \log(L_{i0}) =
 \sum_{p}^{N} \log {\bar{X}_{i}}^{X_{pi}} {(1-\bar{X}_{i})}^{(1-X_{pi})}
</code>
</p>



<h3>Value</h3>

<p>An object of class <code>matrix</code>, which consisted of <code class="reqn">R^{2}</code> for each item and each possible attribute mastery pattern.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>McFadden, D. (1974). Conditional logit analysis of qualitative choice behavior. In P. Zarembka (Ed.), Frontiers in economics (pp.105–142). Academic Press.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing ft and parsimony to improve Q-matrix validation. British Journal of Mathematical and Statistical Psychology, 74, 110–130. DOI: 10.1111/bmsp.12228.
</p>
<p>Qin, H., &amp; Guo, L. (2023). Using machine learning to improve Q-matrix validation. Behavior Research Methods. DOI: 10.3758/s13428-023-02126-0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+validation">validation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

## generate Q-matrix and data
K &lt;- 3
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")

## calculate R2 directly
R2 &lt;-get.R2(Y = example.data$dat, Q = example.Q)
print(R2)

## calculate R2 after fitting CDM
example.CDM.obj &lt;- CDM(example.data$dat, example.Q, model="GDINA")
R2 &lt;-get.R2(CDM.obj = example.CDM.obj)
print(R2)

</code></pre>

<hr>
<h2 id='get.Rmatrix'>Restriction matrix</h2><span id='topic+get.Rmatrix'></span>

<h3>Description</h3>

<p>This function returns the restriction matrix (de la Torre, 2011; Ma &amp; de la Torre, 2020) based on two q-vectors, 
where the two q-vectors can only differ by one attribute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.Rmatrix(q1, q2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.Rmatrix_+3A_q1">q1</code></td>
<td>
<p>A q-vector</p>
</td></tr>
<tr><td><code id="get.Rmatrix_+3A_q2">q2</code></td>
<td>
<p>Another q-vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A restriction matrix
</p>


<h3>References</h3>

<p>de la Torre, J. (2011). The Generalized DINA Model Framework. Psychometrika, 76(2), 179-199. DOI: 10.1007/s11336-011-9207-7.
</p>
<p>Ma, W., &amp; de la Torre, J. (2020). An empirical Q-matrix validation method for the sequential generalized DINA model. British Journal of Mathematical and Statistical Psychology, 73(1), 142-163. DOI: 10.1111/bmsp.12156.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>q1 &lt;- c(1, 1, 0)
q2 &lt;- c(1, 1, 1)

Rmatrix &lt;- get.Rmatrix(q1, q2)

print(Rmatrix)


</code></pre>

<hr>
<h2 id='parallel_iter'>A tool for the <code class="reqn">\beta</code> Method</h2><span id='topic+parallel_iter'></span>

<h3>Description</h3>

<p>This function performs a single iteration of the <code class="reqn">\beta</code> method for one item's validation. It is designed 
to be used in parallel computing environments to speed up the validation process of the <code class="reqn">\beta</code> method. 
The function is a utility function for <code><a href="#topic+validation">validation</a></code>.
When the user calls the <code><a href="#topic+validation">validation</a></code> function with <code>method = "beta"</code>,  
<code><a href="#topic+parallel_iter">parallel_iter</a></code> runs automatically, so there is no need for the user to call <code><a href="#topic+parallel_iter">parallel_iter</a></code>.
It may seem that <code><a href="#topic+parallel_iter">parallel_iter</a></code>, as an internal function, could better serve users.  
However, we found that the <code>Qval</code> package must export it to resolve variable environment conflicts in R  
and enable parallel computation. Perhaps a better solution will be found in the future.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parallel_iter(
  i,
  Y,
  criter.index,
  P.alpha.Xi,
  P.alpha,
  pattern,
  ri,
  Ni,
  Q.pattern.ini,
  model,
  criter,
  search.method,
  P_GDINA,
  Q.beta,
  L,
  K,
  alpha.P,
  get.MLRlasso
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parallel_iter_+3A_i">i</code></td>
<td>
<p>An integer indicating the item number that needs to be validated.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_y">Y</code></td>
<td>
<p>A matrix of observed data used for validation.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_criter.index">criter.index</code></td>
<td>
<p>An integer representing the index of the criterion.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_p.alpha.xi">P.alpha.Xi</code></td>
<td>
<p>A matrix representing individual posterior probability.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_p.alpha">P.alpha</code></td>
<td>
<p>A vector of attribute prior weights.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_pattern">pattern</code></td>
<td>
<p>A matrix representing the attribute mastery patterns.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_ri">ri</code></td>
<td>
<p>A vector containing the number of examinees in each knowledge state who correctly answered item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_ni">Ni</code></td>
<td>
<p>A vector containing the total number of examinees in each knowledge state.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_q.pattern.ini">Q.pattern.ini</code></td>
<td>
<p>An integer representing the initial pattern order for the model.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_model">model</code></td>
<td>
<p>A model object used for fitting, such as the GDINA model.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_criter">criter</code></td>
<td>
<p>A character string specifying the fit criterion. Possible values are &quot;AIC&quot;, &quot;BIC&quot;, &quot;CAIC&quot;, or &quot;SABIC&quot;.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_search.method">search.method</code></td>
<td>
<p>A character string specifying the search method for model selection. Options include &quot;beta&quot;, &quot;ESA&quot;, &quot;SSA&quot;, or &quot;PAA&quot;.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_p_gdina">P_GDINA</code></td>
<td>
<p>A function that calculates probabilities for the GDINA model.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_q.beta">Q.beta</code></td>
<td>
<p>A Q-matrix used for validation.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_l">L</code></td>
<td>
<p>An integer representing the number of all attribute mastery patterns.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_k">K</code></td>
<td>
<p>An integer representing the number of attributes.</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_alpha.p">alpha.P</code></td>
<td>
<p>A matrix of individuals' marginal mastery probabilities (Tu et al., 2022).</p>
</td></tr>
<tr><td><code id="parallel_iter_+3A_get.mlrlasso">get.MLRlasso</code></td>
<td>
<p>A function for Lasso regression with multiple linear regression.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> containing the following components:
</p>

<dl>
<dt>fit.index.pre</dt><dd><p>The previous fit index value after applying the selected search method.</p>
</dd>
<dt>fit.index.cur</dt><dd><p>The current fit index value after applying the selected search method.</p>
</dd>
<dt>Q.pattern.cur</dt><dd><p>The pattern that corresponds to the optimal model configuration for the current iteration.</p>
</dd>
<dt>priority</dt><dd><p>The priority vector used in the PAA method, if applicable.</p>
</dd>
</dl>


<hr>
<h2 id='plot.validation'>Hull Plot</h2><span id='topic+plot.validation'></span>

<h3>Description</h3>

<p>This function can provide the Hull plot. The point suggested by the Hull method is marked in red.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'validation'
plot(x, i, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.validation_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+validation">validation</a></code> in which <code>method</code> = <code>"Hull"</code>.</p>
</td></tr>
<tr><td><code id="plot.validation_+3A_i">i</code></td>
<td>
<p>A numeric, which represents the item you want to plot Hull curve.</p>
</td></tr>
<tr><td><code id="plot.validation_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. This function is used for side effects (plotting).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
IQ &lt;- list(
  P0 = runif(I, 0.2, 0.4),
  P1 = runif(I, 0.6, 0.8)
)


Q &lt;- sim.Q(K, I)
data &lt;- sim.data(Q = Q, N = 500, IQ = IQ, model = "GDINA", distribute = "horder")
MQ &lt;- sim.MQ(Q, 0.1)

CDM.obj &lt;- CDM(data$dat, MQ)

############### ESA ###############
Hull.obj &lt;- validation(data$dat, MQ, CDM.obj, method = "Hull", search.method = "ESA") 

## plot Hull curve for item 20
plot(Hull.obj, 20)

############### PAA ###############
Hull.obj &lt;- validation(data$dat, MQ, CDM.obj, method = "Hull", search.method = "PAA") 

## plot Hull curve for item 20
plot(Hull.obj, 20)

 


</code></pre>

<hr>
<h2 id='print.CDM'>Print Method for CDM Objects</h2><span id='topic+print.CDM'></span>

<h3>Description</h3>

<p>This function prints the details of a <code><a href="#topic+CDM">CDM</a></code> object.
It outputs the call used to create the object, the version and the date of the <code>Qval</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CDM'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.CDM_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+CDM">CDM</a></code> object to be printed.</p>
</td></tr>
<tr><td><code id="print.CDM_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='print.sim.data'>Print Method for sim.data Objects</h2><span id='topic+print.sim.data'></span>

<h3>Description</h3>

<p>This function prints the details of a <code><a href="#topic+sim.data">sim.data</a></code> object.
It outputs the call used to create the object, the version and the date of the <code>Qval</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sim.data'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.sim.data_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+sim.data">sim.data</a></code> object to be printed.</p>
</td></tr>
<tr><td><code id="print.sim.data_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='print.validation'>Print Method for Validation Objects</h2><span id='topic+print.validation'></span>

<h3>Description</h3>

<p>This function prints the details of a <code><a href="#topic+validation">validation</a></code> object.
It outputs the call used to create the object, the version and the date of the <code>Qval</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'validation'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.validation_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+validation">validation</a></code> object to be printed.</p>
</td></tr>
<tr><td><code id="print.validation_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='sim.data'>generate response</h2><span id='topic+sim.data'></span>

<h3>Description</h3>

<p>randomly generate response matrix according to certain conditions,
including attributes distribution, item quality, sample size, Q-matrix and cognitive diagnosis models (CDMs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.data(
  Q = NULL,
  N = NULL,
  IQ = list(P0 = NULL, P1 = NULL),
  model = "GDINA",
  distribute = "uniform",
  control = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.data_+3A_q">Q</code></td>
<td>
<p>The Q-matrix. A random 30 × 5 Q-matrix (<code><a href="#topic+sim.Q">sim.Q</a></code>) will be used if <code>Q = NULL</code>.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_n">N</code></td>
<td>
<p>Sample size. Default = 500.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_iq">IQ</code></td>
<td>
<p>A list containing two <code class="reqn">I</code>-length vectors: <code>P0</code> and <code>P1</code>.
<code>P0</code> represents the probability of examinees who have not mastered any attributes  
(<code class="reqn">[00...0]</code>) correctly answering the item, while <code>P1</code> represents the probability  
of examinees who have mastered all attributes (<code class="reqn">[11...1]</code>) correctly answering the item.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_model">model</code></td>
<td>
<p>Type of model to be fitted; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>,
<code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>.</p>
</td></tr>
<tr><td><code id="sim.data_+3A_distribute">distribute</code></td>
<td>
<p>Attribute distributions; can be <code>"uniform"</code> for the uniform distribution,
<code>"mvnorm"</code> for the multivariate normal distribution (Chiu, Douglas, &amp; Li,
2009) and <code>"horder"</code> for the higher-order distribution (Tu et al., 2022).</p>
</td></tr>
<tr><td><code id="sim.data_+3A_control">control</code></td>
<td>
<p>A list of control parameters with elements:
</p>

<ul>
<li> <p><code>sigma</code>  A positive-definite symmetric matrix specifying the variance-covariance
matrix when <code>distribute = "mvnorm"</code>. Default = 0.5 (Chiu, Douglas, &amp; Li, 2009).
</p>
</li>
<li> <p><code>cutoffs</code>  A vector giving the cutoff for each attribute when <code>distribute = "mvnorm"</code>.
Default = <code class="reqn">k/(1+K)</code> (Chiu, Douglas, &amp; Li, 2009).
</p>
</li>
<li> <p><code>theta</code> A vector of length N representing the higher-order ability for each examinee.
By default, generate randomly from the standard normal distribution (Tu et al, 2022).
</p>
</li>
<li> <p><code>a</code> The slopes for the higher-order model when <code>distribute = "horder"</code>.
Default = 1.5 (Tu et al, 2022).
</p>
</li>
<li> <p><code>b</code> The intercepts when <code>distribute = "horder"</code>. By default, select equally spaced
values between -1.5 and 1.5 according to the number of attributes (Tu et al, 2022).
</p>
</li></ul>
</td></tr>
<tr><td><code id="sim.data_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating to print information or not. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>sim.data</code>.
An <code>sim.data</code> object initially gained by <code><a href="GDINA.html#topic+simGDINA">simGDINA</a></code> function form <code>GDINA</code> package.
Elements that can be extracted using method extract include:
</p>

<dl>
<dt>dat</dt><dd><p>An <code>N</code> × <code>I</code> simulated item response matrix.</p>
</dd>
<dt>Q</dt><dd><p>The Q-matrix.</p>
</dd>
<dt>attribute</dt><dd><p>An <code>N</code> × <code>K</code> matrix for inviduals' attribute patterns.</p>
</dd>
<dt>catprob.parm</dt><dd><p>A list of non-zero success probabilities for each attribute mastery pattern.</p>
</dd>
<dt>delta.parm</dt><dd><p>A list of delta parameters.</p>
</dd>
<dt>higher.order.parm</dt><dd><p>Higher-order parameters.</p>
</dd>
<dt>mvnorm.parm</dt><dd><p>Multivariate normal distribution parameters.</p>
</dd>
<dt>LCprob.parm</dt><dd><p>A matrix of success probabilities for each attribute mastery pattern.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Chiu, C.-Y., Douglas, J. A., &amp; Li, X. (2009). Cluster Analysis for Cognitive Diagnosis: Theory and Applications. Psychometrika, 74(4), 633-665. DOI: 10.1007/s11336-009-9125-0.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models:A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
################################################################
#                           Example 1                          #
#          generate data follow the uniform distrbution        #
################################################################
library(Qval)

set.seed(123)

K &lt;- 5
I &lt;- 10
Q &lt;- sim.Q(K, I)

IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

data &lt;- sim.data(Q = Q, N = 10, IQ=IQ, model = "GDINA", distribute = "uniform")

print(data$dat)

################################################################
#                           Example 2                          #
#          generate data follow the mvnorm distrbution         #
################################################################
set.seed(123)
K &lt;- 5
I &lt;- 10
Q &lt;- sim.Q(K, I)

IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

example_cutoffs &lt;- sample(qnorm(c(1:K)/(K+1)), ncol(Q))
data &lt;- sim.data(Q = Q, N = 10, IQ=IQ, model = "GDINA", distribute = "mvnorm",
                 control = list(sigma = 0.5, cutoffs = example_cutoffs))

print(data$dat)

#################################################################
#                            Example 3                          #
#           generate data follow the horder distrbution         #
#################################################################
set.seed(123)
K &lt;- 5
I &lt;- 10
Q &lt;- sim.Q(K, I)

IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)

example_theta &lt;- rnorm(10, 0, 1)
example_b &lt;- seq(-1.5,1.5,length.out=K)
data &lt;- sim.data(Q = Q, N = 10, IQ=IQ, model = "GDINA", distribute = "horder",
                 control = list(theta = example_theta, a = 1.5, b = example_b))

print(data$dat)

</code></pre>

<hr>
<h2 id='sim.MQ'>Simulate mis-specifications in the Q-matrix</h2><span id='topic+sim.MQ'></span>

<h3>Description</h3>

<p>simulate certen <code>rate</code> mis-specifications in the Q-matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.MQ(Q, rate, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.MQ_+3A_q">Q</code></td>
<td>
<p>The Q-matrix (<code><a href="#topic+sim.Q">sim.Q</a></code>) that need to simulate mis-specifications.</p>
</td></tr>
<tr><td><code id="sim.MQ_+3A_rate">rate</code></td>
<td>
<p>The ratio of mis-specifications in the Q-matrix.</p>
</td></tr>
<tr><td><code id="sim.MQ_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating to print information or not. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

Q &lt;- sim.Q(5, 10)
print(Q)

MQ &lt;- sim.MQ(Q, 0.1)
print(MQ)

</code></pre>

<hr>
<h2 id='sim.Q'>generate a random Q-matrix</h2><span id='topic+sim.Q'></span>

<h3>Description</h3>

<p>generate a <code class="reqn">I</code> × <code class="reqn">K</code> Q-matrix randomly, which consisted of one-attribute q-vectors
(50
This function ensures that the generated Q-matrix contains at least two identity matrices as a priority.
Therefore, this function must also satisfy the condition that the number of items (<code class="reqn">I</code>)  
must be at least twice the number of attributes (<code class="reqn">K</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.Q(K, I)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim.Q_+3A_k">K</code></td>
<td>
<p>The number of attributes of the Q-matrix.</p>
</td></tr>
<tr><td><code id="sim.Q_+3A_i">I</code></td>
<td>
<p>The number of items.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing fit and parsimony to improve Q-matrix validation. Br J Math Stat Psychol, 74 Suppl 1, 110-130. DOI: 10.1111/bmsp.12228.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

Q &lt;- sim.Q(5, 10)
print(Q)

</code></pre>

<hr>
<h2 id='validation'>Perform Q-matrix validation methods</h2><span id='topic+validation'></span>

<h3>Description</h3>

<p>This function uses generalized Q-matrix validation methods to validate the Q-matrix,
including commonly used methods such as GDI (de la Torre, &amp; Chiu, 2016; Najera, Sorrel,
&amp; Abad, 2019; Najera et al., 2020), Wald (Ma, &amp; de la Torre, 2020), Hull (Najera et al.,
2021), and MLR-B (Tu et al., 2022). It supports different iteration methods (test
level or item level; Najera et al., 2020; Najera et al., 2021; Tu et al., 2022) and
can apply various attribute search methods (ESA, SSA, PAA; de la Torre, 2008; Terzi, &amp;
de la Torre, 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validation(
  Y,
  Q,
  CDM.obj = NULL,
  par.method = "EM",
  mono.constraint = TRUE,
  model = "GDINA",
  method = "GDI",
  search.method = "PAA",
  iter.level = "no",
  maxitr = 1,
  eps = 0.95,
  alpha.level = 0.05,
  criter = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validation_+3A_y">Y</code></td>
<td>
<p>A required <code class="reqn">N</code> × <code class="reqn">I</code> matrix or <code>data.frame</code> consisting of the responses of <code>N</code> individuals
to <code class="reqn">N</code> × <code class="reqn">I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_q">Q</code></td>
<td>
<p>A required binary <code class="reqn">I</code> × <code class="reqn">K</code> matrix containing the attributes not required or required 
master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to master
item <code class="reqn">i</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. When it is not NULL, it enables rapid validation
of the Q-matrix without the need for parameter estimation. @seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_par.method">par.method</code></td>
<td>
<p>Type of mtehod to estimate CDMs' parameters; one out of <code>"EM"</code>, <code>"BM"</code>. Default = <code>"EM"</code>. 
However, <code>"BM"</code> is only available when <code>method = "GDINA"</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_mono.constraint">mono.constraint</code></td>
<td>
<p>Logical indicating whether monotonicity constraints should be fulfilled in estimation.
Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_model">model</code></td>
<td>
<p>Type of model to fit; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>
, <code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.
@seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_method">method</code></td>
<td>
<p>The methods to validata Q-matrix, can be <code>"GDI"</code>, <code>"Wald"</code>, <code>"Hull"</code>, 
<code>"MLR-B"</code> and <code>"beta"</code>. The <code>"model"</code> must be <code>"GDINA"</code> when 
<code>method = "Wald"</code>. Please note that the <code class="reqn">\beta</code> method has different meanings 
when applying different search algorithms. For more details, see section 'Search algorithm' below.
Default = <code>"GDI"</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_search.method">search.method</code></td>
<td>
<p>Character string specifying the search method to use during validation.
</p>

<dl>
<dt>&quot;ESA&quot;</dt><dd><p>for exhaustive search algorithm. Can not for the <code>"Wald"</code> method.</p>
</dd>
<dt>&quot;SSA&quot;</dt><dd><p>for sequential search algorithm (see de la Torre, 2008; Terzi &amp; de la Torre, 2018). 
It will be equal to <code>"forward"</code> when <code>method = "Wald"</code>.</p>
</dd>
<dt>&quot;PAA&quot;</dt><dd><p>for priority attribute algorithm. </p>
</dd>
<dt>&quot;stepwise&quot;</dt><dd><p>only for the <code>"Wald" method</code></p>
</dd>
<dt>&quot;beta&quot;</dt><dd><p>only for the <code>"beta" method</code></p>
</dd>
</dl>
</td></tr>
<tr><td><code id="validation_+3A_iter.level">iter.level</code></td>
<td>
<p>Can be <code>"no"</code>, <code>"item"</code> level, <code>"test.att"</code> or <code>"test"</code> level. Default = <code>"no"</code> and 
<code>"test.att"</code> can not for <code>"Wald"</code> and <code>"MLR-B"</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_maxitr">maxitr</code></td>
<td>
<p>Number of max iterations. Default = <code>1</code>.</p>
</td></tr>
<tr><td><code id="validation_+3A_eps">eps</code></td>
<td>
<p>Cut-off points of <code class="reqn">PVAF</code>, will work when the method is <code>"GDI"</code> or <code>"Wald"</code>.
Default = <code>0.95</code>. When <code>eps = 'logit'</code>, the predicted eps by Najera et al. (2019) will be used. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_alpha.level">alpha.level</code></td>
<td>
<p>alpha level for the wald test. Default = <code>0.05</code></p>
</td></tr>
<tr><td><code id="validation_+3A_criter">criter</code></td>
<td>
<p>The kind of fit-index value. When <code>method = "Hull"</code>, it can be <code>R2</code> for 
<code class="reqn">R_{McFadden}^2</code> @seealso <code><a href="#topic+get.R2">get.R2</a></code> or <code>'PVAF'</code> for the proportion of 
variance accounted for (<code class="reqn">PVAF</code>) @seealso <code><a href="#topic+get.PVAF">get.PVAF</a></code>. When 
<code>method = "beta"</code>, it can be <code>'AIC'</code>, <code>'BIC'</code>, <code>'CAIC'</code> or <code>'SABIC'</code>.
Default = <code>"PVAF"</code> for <code>'Hull'</code> and default = <code>"AIC"</code> for <code>'beta'</code>. See details.</p>
</td></tr>
<tr><td><code id="validation_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating to print iterative information or not. Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>validation</code> containing the following components:
</p>

<dl>
<dt>Q.orig</dt><dd><p>The original Q-matrix that maybe contain some mis-specifications and need to be validated.</p>
</dd>
<dt>Q.sug</dt><dd><p>The Q-matrix that suggested by certain validation method.</p>
</dd>
<dt>time.cost</dt><dd><p>The time that CPU cost to finish the function.</p>
</dd>
<dt>process</dt><dd><p>A matrix that contains the modification process of each question during each iteration. 
Each row represents an iteration, and each column corresponds to the q-vector index of the respective 
question. The order of the indices is consistent with the row numbering in the matrix generated by 
the <code><a href="GDINA.html#topic+attributepattern">attributepattern</a></code> function in the <code>GDINA</code> package. Only when 
<code>maxitr</code> &gt; 1, the, the value is available.</p>
</dd>
<dt>iter</dt><dd><p>The number of iteration. Only when <code>maxitr</code> &gt; 1, the value is available.</p>
</dd>
<dt>priority</dt><dd><p>An <code>I</code> × <code>K</code> matrix that contains the priority of every attribute for
each item. Only when the <code>search.method</code> is <code>"PAA"</code>, the value is available. See details.</p>
</dd>
<dt>Hull.fit</dt><dd><p>A <code>list</code> containing all the information needed to plot the Hull plot, which is 
available only when <code>method</code> = <code>"Hull"</code>.</p>
</dd>
</dl>



<h3>The GDI method</h3>

<p>The GDI method (de la Torre &amp; Chiu, 2016), as the first Q-matrix validation method
applicable to saturated models, serves as an important foundation for various mainstream
Q-matrix validation methods.
</p>
<p>The method calculates the proportion of variance accounted for (<code class="reqn">PVAF</code>; @seealso <code><a href="#topic+get.PVAF">get.PVAF</a></code>)
for all possible q-vectors for each item, selects the q-vector with a <code class="reqn">PVAF</code> just
greater than the cut-off point (or Epsilon, EPS) as the correction result, and the variance
<code class="reqn">\zeta^2</code> is the generalized discriminating index (GDI; de la Torre &amp; Chiu, 2016).
Therefore, the GDI method is also considered as a generalized extension of the <code class="reqn">delta</code>
method (de la Torre, 2008), which also takes maximizing discrimination as its basic idea.
In the GDI method, <code class="reqn">\zeta^2</code> is defined as the weighted variance of the correct
response probabilities across all mastery patterns, that is:
</p>
<p style="text-align: center;"><code class="reqn">
 \zeta^2 =
 \sum_{l=1}^{2^K} \pi_{l} \left[ P(X_{pi}=1|\boldsymbol{\alpha}_{l}) - \bar{P}_{i} \right]^2
</code>
</p>

<p>where <code class="reqn">\pi_{l}</code> represents the prior probability of mastery pattern <code class="reqn">l</code>;
<code class="reqn">\bar{P}_{i}=\sum_{k=1}^{K}\pi_{l}P(X_{pi}=1|\boldsymbol{\alpha}_{l})</code> is the weighted
average of the correct response probabilities across all attribute mastery patterns.
When the q-vector is correctly specified, the calculated <code class="reqn">\zeta^2</code> should be maximized,
indicating the maximum discrimination of the item. However, in reality, <code class="reqn">\zeta^2</code>
continues to increase when the q-vector is over-specified, and the more attributes that
are over-specified, the larger <code class="reqn">\zeta^2</code> becomes. The q-vector with all attributes set
to 1 (i.e., <code class="reqn">\boldsymbol{q}_{1:K}</code>) has the largest <code class="reqn">\zeta^2</code> (de la Torre, 2016).
This is because an increase in attributes in the q-vector leads to an increase in item
parameters, resulting in greater differences in correct response probabilities across
attribute patterns and, consequently, increased variance. However, this increase in
variance is spurious. Therefore, de la Torre et al. calculated <code class="reqn">PVAF = \frac{\zeta^2}{\zeta_{1:K}^2}</code>
to describe the degree to which the discrimination of the current q-vector explains
the maximum discrimination. They selected an appropriate <code class="reqn">PVAF</code> cut-off point to achieve
a balance between q-vector fit and parsimony. According to previous studies,
the <code class="reqn">PVAF</code> cut-off point is typically set at 0.95 (Ma &amp; de la Torre, 2020; Najera et al., 2021).
Najera et al. (2019) proposed using multinomial logistic regression to predict a more appropriate cut-off point for <code class="reqn">PVAF</code>. 
The cut-off point is denoted as <code class="reqn">eps</code>, and the predicted regression equation is as follows:
</p>
<p style="text-align: center;"><code class="reqn"> 
\log \left( \frac{eps}{1-eps} \right) 
   = \text{logit}(eps) 
   = -0.405 + 2.867 \cdot IQ + 4.840 \times 10^4 \cdot N - 3.316 \times 10^3 \cdot I
 </code>
</p>

<p>Where <code class="reqn">IQ</code> represents the question quality, calculated as the negative difference between the probability of an examinee 
with all attributes answering the question correctly and the probability of an examinee with no attributes answering the question correctly 
(<code class="reqn">IQ = - \left\{ P\left( \boldsymbol{1} \right) - \left[ 1 - P\left( \boldsymbol{0} \right) \right] \right\}</code>), 
and <code class="reqn">N</code> and <code class="reqn">I</code> represent the number of examinees and the number of questions, respectively.
</p>


<h3>The Wald method</h3>

<p>The Wald method (Ma &amp; de la Torre, 2020) combines the Wald test with <code class="reqn">PVAF</code> to correct
the Q-matrix at the item level. Its basic logic is as follows: when correcting item <code class="reqn">i</code>,
the single attribute that maximizes the <code class="reqn">PVAF</code> value is added to a vector with all
attributes set to <code class="reqn">\boldsymbol{0}</code> (i.e., <code class="reqn">\boldsymbol{q} = (0, 0, \ldots, 0)</code>) as a starting point.
In subsequent iterations, attributes in this vector are continuously added or
removed through the Wald test. The correction process ends when the <code class="reqn">PVAF</code> exceeds the
cut-off point or when no further attribute changes occur. The Wald statistic follows an
asymptotic <code class="reqn">\chi^{2}</code> distribution with a degree of freedom of <code class="reqn">2^{K^\ast} - 1</code>.
</p>
<p>The calculation method is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   Wald = \left[\boldsymbol{R} \times \boldsymbol{P}_{i}(\boldsymbol{\alpha})\right]^{'}
   (\boldsymbol{R} \times \boldsymbol{V}_{i} \times \boldsymbol{R})^{-1}
   \left[\boldsymbol{R} \times P_{i}(\boldsymbol{\alpha})\right]
</code>
</p>

<p><code class="reqn">\boldsymbol{R}</code> represents the restriction matrix (@seealso <code><a href="#topic+get.Rmatrix">get.Rmatrix</a></code>); 
<code class="reqn">\boldsymbol{P}_{i}(\boldsymbol{\alpha})</code> denotes
the vector of correct response probabilities for item <code class="reqn">i</code>; <code class="reqn">\boldsymbol{V}_i</code> is the
variance-covariance matrix of the correct response probabilities for item <code class="reqn">i</code>, which
can be obtained by multiplying the <code class="reqn">\boldsymbol{M}_i</code> matrix (de la Torre, 2011) with the
variance-covariance matrix of item parameters <code class="reqn">\boldsymbol{\Sigma}_i</code>, i.e.,
<code class="reqn">\boldsymbol{V}_i = \boldsymbol{M}_i \times \boldsymbol{\Sigma}_i</code>. The <code class="reqn">\boldsymbol{\Sigma}_i</code> can be
derived by inverting the information matrix. Using the the empirical cross-product information
matrix (de la Torre, 2011) to calculate <code class="reqn">\boldsymbol{\Sigma}_i</code>.
</p>
<p><code class="reqn">\boldsymbol{M}_i</code> is a <code class="reqn">2^{K^\ast} \times 2^{K^\ast}</code> matrix (@seealso <code><a href="#topic+get.Mmatrix">get.Mmatrix</a></code>) 
that represents the relationship between the parameters of item <code class="reqn">i</code> and the attribute mastery patterns. The 
rows represent different mastery patterns, while the columns represent different item parameters.
</p>


<h3>The Hull method</h3>

<p>The Hull method (Najera et al., 2021) addresses the issue of the cut-off point in the GDI
method and demonstrates good performance in simulation studies. Najera et al. applied the
Hull method for determining the number of factors to retain in exploratory factor analysis
(Lorenzo-Seva et al., 2011) to the retention of attribute quantities in the q-vector, specifically
for Q-matrix validation. The Hull method aligns with the GDI approach in its philosophy
of seeking a balance between fit and parsimony. While GDI relies on a preset, arbitrary
cut-off point to determine this balance, the Hull method utilizes the most pronounced elbow
in the Hull plot to make this judgment. The the most pronounced elbow is determined using
the following formula:
</p>
<p style="text-align: center;"><code class="reqn">
   st = \frac{(f_k - f_{k-1}) / (np_k - np_{k-1})}{(f_{k+1} - f_k) / (np_{k+1} - np_k)}
</code>
</p>

<p>where <code class="reqn">f_k</code> represents the fit-index value (can be <code class="reqn">PVAF</code> @seealso <code><a href="#topic+get.PVAF">get.PVAF</a></code> or
<code class="reqn">R2</code> @seealso <code><a href="#topic+get.R2">get.R2</a></code>) when the q-vector contains <code class="reqn">k</code> attributes,
similarly, <code class="reqn">f_{k-1}</code> and <code class="reqn">f_{k+1}</code> represent the fit-index value when the q-vector contains <code class="reqn">k-1</code>
and <code class="reqn">k+1</code> attributes, respectively. <code class="reqn">{np}_k</code> denotes the number of parameters when the
q-vector has <code class="reqn">k</code> attributes, which is <code class="reqn">2^k</code> for a saturated model. Likewise, <code class="reqn">{np}_{k-1}</code>
and <code class="reqn">{np}_{k+1}</code> represent the number of parameters when the q-vector has <code class="reqn">k-1</code> and
<code class="reqn">k+1</code> attributes, respectively. The Hull method calculates the <code class="reqn">st</code> index for all possible q-vectors
and retains the q-vector with the maximum <code class="reqn">st</code> index as the corrected result.
Najera et al. (2021) removed any concave points from the Hull plot, and when only the first and
last points remained in the plot, the saturated q-vector was selected.
</p>


<h3>The MLR-B method</h3>

<p>The MLR-B method proposed by Tu et al. (2022) differs from the GDI, Wald and Hull method in that
it does not employ <code class="reqn">PVAF</code>. Instead, it directly uses the marginal probabilities of attribute mastery for
examinees to perform multivariate logistic regression on their observed scores. This approach assumes
all possible q-vectors and conducts <code class="reqn">2^K-1</code> regression modelings. After proposing regression equations
that exclude any insignificant regression coefficients, it selects the q-vector corresponding to
the equation with the minimum <code class="reqn">AIC</code> value as the validation result. The performance of this method in both the
LCDM and GDM models even surpasses that of the Hull method (Tu et al., 2022), making it an efficient and reliable
approach for Q-matrix validation.
</p>


<h3>The <code class="reqn">\beta</code> method</h3>

<p>The <code class="reqn">\beta</code> method (Li &amp; Chen, 2024) addresses the Q-matrix validation problem from the 
perspective of signal detection theory. Signal detection theory posits that any stimulus is 
a signal embedded in noise, where the signal always overlaps with noise. The <code class="reqn">\beta</code> method 
treats the correct q-vector as the signal and other possible q-vectors as noise. The goal is 
to identify the signal from the noise, i.e., to correctly identify the q-vector. For item 
<code class="reqn">i</code> with the q-vector of the <code class="reqn">c</code>-th type, the <code class="reqn">\beta</code> index is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   \beta_{ic} = \sum_{l=1}^{2^K} \left| \frac{r_{li}}{n_l} P_{ic}(\boldsymbol{\alpha_l}) - 
                \left(1 - \frac{r_{li}}{n_l}\right) \left[1 - P_{ic}(\boldsymbol{\alpha_l})\right] \right|
              = \sum_{l=1}^{2^K} \left| \frac{r_{li}}{n_l} - \left[1 - P_{ic}(\boldsymbol{\alpha_l}) \right] \right|
 </code>
</p>

<p>In the formula, <code class="reqn">r_{li}</code> represents the number of examinees in knowledge state <code class="reqn">l</code> who correctly 
answered item <code class="reqn">i</code>, while <code class="reqn">n_l</code> is the total number of examinees in knowledge state <code class="reqn">l</code>. 
<code class="reqn">P_{ic}(\boldsymbol{\alpha_l})</code> denotes the probability that an examinee in knowledge state <code class="reqn">l</code> answers 
item <code class="reqn">i</code> correctly when the q-vector for item <code class="reqn">i</code> is of the <code class="reqn">c</code>-th type. In fact, 
<code class="reqn">\frac{r_{li}}{n_l}</code> is the observed probability that an examinee in knowledge state <code class="reqn">l</code> answers 
item <code class="reqn">i</code> correctly, and <code class="reqn">\beta_{jc}</code> represents the difference between the actual proportion of 
correct answers for item <code class="reqn">i</code> in each knowledge state and the expected probability of answering the 
item incorrectly in that state. Therefore, to some extent, <code class="reqn">\beta_{jc}</code> can be considered as a measure 
of discriminability, and the <code class="reqn">\beta</code> method posits that the correct q-vector maximizes <code class="reqn">\beta_{jc}</code>, 
i.e.:
</p>
<p style="text-align: center;"><code class="reqn">
   \boldsymbol{q}_i 
   = \arg\max_{\boldsymbol{q}} \left( \beta_{jc} : \boldsymbol{q} \in \left\{ \boldsymbol{q}_{ic}, 
       \, c = 1, 2, \dots, 2^{K} - 1 \right\} \right)
 </code>
</p>

<p>Therefore, essentially, <code class="reqn">\beta_{jc}</code> is an index similar to GDI. Both increase as the number of attributes 
in the q-vector increases. Unlike the GDI method, the <code class="reqn">\beta</code> method does not continue to compute 
<code class="reqn">\beta_{jc} / \beta_{j[11...1]}</code> but instead uses the minimum <code class="reqn">AIC</code> value to determine whether the attributes 
in the q-vector are sufficient. In Package Qval, <a href="parallel.html#topic+parLapply">parLapply</a> will be used to accelerate the <code class="reqn">\beta</code> method.
</p>
<p>Please note that the <code class="reqn">\beta</code> method has different meanings when applying different search algorithms. 
For more details, see section 'Search algorithm' below.
</p>


<h3>Iterative procedure</h3>

<p>The iterative procedure that one item modification at a time is item level iteration (<code> iter.level = "item"</code>) in (Najera
et al., 2020, 2021). The steps of the <code>item</code> level iterative procedure algorithm are as follows:
</p>

<dl>
<dt>Step1</dt><dd><p>Fit the <code>CDM</code> according to the item responses and the provisional Q-matrix (<code class="reqn">\boldsymbol{Q}^0</code>).</p>
</dd>
<dt>Step2</dt><dd><p>Validate the provisional Q-matrix and gain a suggested Q-matrix (<code class="reqn">\boldsymbol{Q}^1</code>).</p>
</dd>
<dt>Step3</dt><dd><p>for each item, <code class="reqn">PVAF_{0i}</code> as the <code class="reqn">PVAF</code> of the provisional q-vector specified in <code class="reqn">\boldsymbol{Q}^0</code>,
and <code class="reqn">PVAF_{1i}</code> as the <code class="reqn">PVAF</code> of the suggested q-vector in <code class="reqn">\boldsymbol{Q}^1</code>.</p>
</dd>
<dt>Step4</dt><dd><p>Calculate all items' <code class="reqn">\Delta PVAF_{i}</code>, defined as <code class="reqn">\Delta PVAF_{i} = |PVAF_{1i} - PVAF_{0i}|</code></p>
</dd>
<dt>Step5</dt><dd><p>Define the hit item as the item with the highest <code class="reqn">\Delta PVAF_{i}</code>.</p>
</dd>
<dt>Step6</dt><dd><p>Update <code class="reqn">\boldsymbol{Q}^0</code> by changing the provisional q-vector by the suggested q-vector of the hit item.</p>
</dd>
<dt>Step7</dt><dd><p>Iterate over Steps 1 to 6 until <code class="reqn">\sum_{i=1}^{I} \Delta PVAF_{i} = 0</code></p>
</dd>
</dl>

<p>When the Q-matrix validation method is <code>"MLR-B"</code> or <code>"Hull"</code> when <code>criter = "AIC"</code> or <code>criter = "R2"</code>, <code class="reqn">PVAF</code> is not used. 
In this case, the criterion for determining which item's index will be replaced is <code class="reqn">AIC</code> or <code class="reqn">R^2</code>, respectively.
</p>
<p>The iterative procedure that the entire Q-matrix is modified at each iteration
is test level iteration (<code> iter.level = "test"</code>) (Najera et al., 2020; Tu et al., 2022).
The steps of the <code>test</code> level iterative procedure algorithm are as follows:
</p>

<dl>
<dt>Step1</dt><dd><p>Fit the <code>CDM</code> according to the item responses and the provisional Q-matrix (<code class="reqn">\boldsymbol{Q}^0</code>).</p>
</dd>
<dt>Step2</dt><dd><p>Validate the provisional Q-matrix and gain a suggested Q-matrix (<code class="reqn">\boldsymbol{Q}^1</code>).</p>
</dd>
<dt>Step3</dt><dd><p>Check whether <code class="reqn">\boldsymbol{Q}^1 = \boldsymbol{Q}^0</code>. If <code>TRUE</code>, terminate the iterative algorithm.
If <code>FALSE</code>, Update <code class="reqn">\boldsymbol{Q}^0</code> as <code class="reqn">\boldsymbol{Q}^1</code>.</p>
</dd>
<dt>Step4</dt><dd><p>Iterate over Steps 1 and 3 until one of conditions as follows is satisfied: 1. <code class="reqn">\boldsymbol{Q}^1 =
                 \boldsymbol{Q}^0</code>; 2. Reach the maximum number of iterations (<code>maxitr</code>); 3. <code class="reqn">\boldsymbol{Q}^1</code> does not satisfy
the condition that an attribute is measured by one item at least.</p>
</dd>
</dl>

<p><code>iter.level = 'test.att'</code> will use a method called the test-attribute iterative procedure (Najera et al., 2021), which 
modifies all items in each iteration while following the principle of minimizing changes in the number of attributes.
Therefore, the test-attribute iterative procedure and the test-level iterative procedure follow the same process for large items.  
The key difference is that the test-attribute iterative procedure only allows minimal adjustments to the <code class="reqn">q</code>-vector in each iteration.  
For example, if the original <code class="reqn">q</code>-vector is <code class="reqn">[0010]</code> and the validation methods suggest <code class="reqn">[1110]</code>,  
the test-level iterative procedure can directly update the <code class="reqn">q</code>-vector to <code class="reqn">[1110]</code>.  
In contrast, the test-attribute iterative procedure can only make a gradual adjustment,  
first modifying the <code class="reqn">q</code>-vector to either <code class="reqn">[1010]</code> or <code class="reqn">[0110]</code>.  
As a result, the test-attribute iterative procedure is more cautious than the test-level iterative procedure  
and may require more iterations.
</p>


<h3>Search algorithm</h3>

<p>Three search algorithms are available: Exhaustive Search Algorithm (ESA), Sequential Search Algorithm (SSA), 
and Priority Attribute Algorithm (PAA). 
ESA is a brute-force algorithm. When validating the q-vector of a particular item, it traverses all possible 
q-vectors and selects the most appropriate one based on the chosen Q-matrix validation method. Since there are 
<code class="reqn">2^{K-1}</code> possible q-vectors with <code class="reqn">K</code> attributes, ESA requires <code class="reqn">2^{K-1}</code> searches for each item.
</p>
<p>SSA reduces the number of searches by adding one attribute at a time to the q-vector in a stepwise manner. 
Therefore, in the worst-case scenario, SSA requires <code class="reqn">K(K-1)/2</code> searches.
The detailed steps are as follows:
</p>

<dl>
<dt>Step 1</dt><dd><p>Define an empty q-vector <code class="reqn">\boldsymbol{q}^0=[00...0]</code> of length <code class="reqn">K</code>, 
where all elements are 0.</p>
</dd>
<dt>Step 2</dt><dd><p>Examine all single-attribute q-vectors, which are those formed by 
changing one of the 0s in <code class="reqn">\boldsymbol{q}^0</code> to 1. 
According to the criteria of the chosen Q-matrix validation method, 
select the optimal single-attribute q-vector, denoted as <code class="reqn">\boldsymbol{q}^1</code>.</p>
</dd>
<dt>Step 3</dt><dd><p>Examine all two-attribute q-vectors, which are those formed by changing 
one of the 0s in <code class="reqn">\boldsymbol{q}^1</code> to 1. According to the criteria of the 
chosen Q-matrix validation method, select the optimal two-attribute q-vector, 
denoted as <code class="reqn">\boldsymbol{q}^2</code>.</p>
</dd>
<dt>Step 4</dt><dd><p>Repeat this process until <code class="reqn">\boldsymbol{q}^K</code> is found, or the stopping criterion 
of the chosen Q-matrix validation method is met.</p>
</dd>
</dl>

<p>PAA is a highly efficient and concise algorithm that evaluates whether each attribute needs to be included in the 
q-vector based on the priority of the attributes. @seealso <code><a href="#topic+get.priority">get.priority</a></code>. Therefore, even in 
the worst-case scenario, PAA only requires <code class="reqn">K</code> searches. The detailed process is as follows:
</p>

<dl>
<dt>Step 1</dt><dd><p>Using the applicable CDM (e.g. the G-DINA model) to estimate the model parameters 
and obtain the marginal attribute mastery probabilities matrix <code class="reqn">\boldsymbol{\Lambda}</code></p>
</dd>
<dt>Step 2</dt><dd><p>Use LASSO regression to calculate the priority of each attribute in the q-vector for item <code class="reqn">i</code></p>
</dd>
<dt>Step 3</dt><dd><p>Check whether each attribute is included in the optimal q-vector based on the attribute 
priorities from high to low seriatim and output the final suggested q-vector according to the 
criteria of the chosen Q-matrix validation method.</p>
</dd>
</dl>

<p>The calculation of priorities is straightforward (Qin &amp; Guo, 2025): the priority of an attribute is the 
regression coefficient obtained from a LASSO multinomial logistic regression, with the attribute 
as the independent variable and the response data from the examinees as the dependent variable.  
The formula (Tu et al., 2022) is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
 \log[\frac{P(X_{pi} = 1 | \boldsymbol{\Lambda}_{p})}{P(X_{pi} = 0 | \boldsymbol{\Lambda}_{p})}] = 
 logit[P(X_{pi} = 1 | \boldsymbol{\Lambda}_{p})] = 
 \beta_{i0} + \beta_{i1} \Lambda_{p1} + \ldots + \beta_{ik} \Lambda_{pk} + \ldots + \beta_{iK} \Lambda_{pK}
</code>
</p>

<p>Where <code class="reqn">X_{pi}</code> represents the response of examinee <code class="reqn">p</code> on item <code class="reqn">i</code>,  
<code class="reqn">\boldsymbol{\Lambda}_{p}</code> denotes the marginal mastery probabilities of examinee <code class="reqn">p</code>  
(which can be obtained from the return value <code>alpha.P</code> of the <code><a href="#topic+CDM">CDM</a></code> function),  
<code class="reqn">\beta_{i0}</code> is the intercept term, and <code class="reqn">\beta_{ik}</code> represents the regression coefficient.  
</p>
<p>The LASSO loss function can be expressed as:
</p>
<p style="text-align: center;"><code class="reqn">l_{lasso}(\boldsymbol{X}_i | \boldsymbol{\Lambda}) = l(\boldsymbol{X}_i | \boldsymbol{\Lambda}) - \lambda |\boldsymbol{\beta}_i|</code>
</p>

<p>Where <code class="reqn">l_{lasso}(\boldsymbol{X}_i | \boldsymbol{\Lambda})</code> is the penalized likelihood,  
<code class="reqn">l(\boldsymbol{X}_i | \boldsymbol{\Lambda})</code> is the original likelihood,  
and <code class="reqn">\lambda</code> is the tuning parameter for penalization (a larger value imposes a stronger penalty on 
<code class="reqn">\boldsymbol{\beta}_i = [\beta_{i1}, \ldots, \beta_{ik}, \ldots, \beta_{iK}]</code>).  
The priority for attribute <code class="reqn">i</code> is defined as: <code class="reqn">\boldsymbol{priority}_i = \boldsymbol{\beta}_i = [\beta_{i1}, \ldots, \beta_{ik}, \ldots, \beta_{iK}]</code>
</p>
<p>It should be noted that the Wald method proposed by Ma and de la Torre (2020) uses a <code>"stepwise"</code> search approach. 
This approach involves incrementally adding or removing 1 from the q-vector and evaluating the significance of 
the change using the Wald test: 
1. If removing a 1 results in non-significance (indicating that the 1 is unnecessary), the 1 is removed from the q-vector; 
otherwise, the q-vector remains unchanged. 
2. If adding a 1 results in significance (indicating that the 1 is necessary), the 1 is added to the q-vector; 
otherwise, the q-vector remains unchanged.
The process stops when the q-vector no longer changes or when the PVAF reaches the preset cut-off point (i.e., 0.95).
Stepwise are unique search approach of the Wald method, and users should be aware of this. Since stepwise is 
inefficient and differs significantly from the extremely high efficiency of PAA, <code>Qval</code> package also provides <code>PAA</code> 
for q-vector search in the Wald method. When applying the PAA version of the Wald method, the search still 
examines whether each attribute is necessary (by checking if the Wald test reaches significance after adding the attribute) 
according to attribute priority. The search stops when no further necessary attributes are found or when the 
PVAF reaches the preset cut-off point (i.e., 0.95). The &quot;forward&quot; search approach is another search method 
available for the Wald method, which is equivalent to <code>"SSA"</code>. When <code>"Wald"</code> uses <code>search.method = "SSA"</code>, 
it means that the Wald method is employing the forward search approach. Its basic process is the same as <code>'stepwise'</code>, 
except that it does not remove elements from the q-vector. Therefore, the &quot;forward&quot; search approach is essentially equivalent to SSA.
</p>
<p>Please note that, since the <code class="reqn">\beta</code> method essentially selects q-vectors based on <code class="reqn">AIC</code>, even without using the iterative process, 
the <code class="reqn">\beta</code> method requires multiple parameter estimations to obtain the AIC values for different q-vectors. 
Therefore, the <code class="reqn">\beta</code> method is more time-consuming and computationally intensive compared to the other methods. 
Li and Chen (2024) introduced a specialized search approach for the <code class="reqn">\beta</code> method, which is referred to as the 
<code class="reqn">\beta</code> search (<code>search.method = 'beta'</code>). The number of searches required is <code class="reqn">2^{K-2} + K + 1</code>, and 
the specific steps are as follows:
</p>

<dl>
<dt>Step 1</dt><dd><p>For item <code class="reqn">i</code>, sequentially examine the <code class="reqn">\beta</code> values for each single-attribute q-vector, 
select the largest <code class="reqn">\beta_{most}</code> and the smallest <code class="reqn">\beta_{least}</code>, along with the corresponding 
attributes <code class="reqn">k_{most}</code> and <code class="reqn">k_{least}</code>. (K searches)</p>
</dd>
<dt>Step 2</dt><dd><p>Then, add all possible q-vectors (a total of <code class="reqn">2^K - 1</code>) containing attribute <code class="reqn">k_{most}</code> and 
not containing <code class="reqn">k_{least}</code> to the search space <code class="reqn">\boldsymbol{S}_i</code> (a total of <code class="reqn">2^{K-2}</code>)), and unconditionally 
add the saturated q-vector <code class="reqn">[11\ldots1]</code> to <code class="reqn">\boldsymbol{S}_i</code> to ensure that it is tested.</p>
</dd>
<dt>Step 3</dt><dd><p>Select the q-vector with the minimum AIC from <code class="reqn">\boldsymbol{S}_i</code> as the final output of the <code class="reqn">\beta</code> 
method. (The remaining <code class="reqn">2^{K-2} + 1</code> searches)</p>
</dd>
</dl>

<p>The <code>Qval</code> package also provides three search methods, ESA, SSA, and PAA, for the <code class="reqn">\beta</code> method. 
When the <code class="reqn">\beta</code> method applies these three search methods, Q-matrix validation can be completed without 
calculating any <code class="reqn">\beta</code> values, as the <code class="reqn">\beta</code> method essentially uses <code>AIC</code> for selecting q-vectors. 
For example, when applying ESA, the <code class="reqn">\beta</code> method does not need to perform Step 1 of the <code class="reqn">\beta</code> search 
and only needs to include all possible q-vectors (a total of <code class="reqn">2^K - 1</code>) in <code class="reqn">\boldsymbol{S}_i</code>, then outputs 
the corresponding q-vector based on the minimum <code class="reqn">AIC</code>. When applying SSA or PAA, the <code class="reqn">\beta</code> method also 
does not require any calculation of <code class="reqn">\beta</code> values. In this case, the <code class="reqn">\beta</code> method is consistent 
with the Q-matrix validation process described by Chen et al. (2013) using relative fit indices. Therefore, when 
the <code class="reqn">\beta</code> method does not use <code class="reqn">\beta</code> search, it is equivalent to the method of Chen et al. (2013). 
To better implement Chen et al. (2013)'s Q-matrix validation method using relative fit indices, the <code>Qval</code> 
package also provides <code class="reqn">BIC</code>, <code class="reqn">CAIC</code>, and <code class="reqn">SABIC</code> as alternatives to validate q-vectors, in addition 
to <code class="reqn">AIC</code>.
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>Chen, J., de la Torre, J., &amp; Zhang, Z. (2013). Relative and Absolute Fit Evaluation in Cognitive Diagnosis Modeling. Journal of Educational Measurement, 50(2), 123-140. DOI: 10.1111/j.1745-3984.2012.00185.x 
</p>
<p>de la Torre, J., &amp; Chiu, C. Y. (2016). A General Method of Empirical Q-matrix Validation. Psychometrika, 81(2), 253-273. DOI: 10.1007/s11336-015-9467-8.
</p>
<p>de la Torre, J. (2008). An Empirically Based Method of Q-Matrix Validation for the DINA Model: Development and Applications. Journal of Education Measurement, 45(4), 343-362. DOI: 10.1111/j.1745-3984.2008.00069.x.
</p>
<p>Li, J., &amp; Chen, P. (2024). A new Q-matrix validation method based on signal detection theory. British Journal of Mathematical and Statistical Psychology, 00, 1–33. DOI: 10.1111/bmsp.12371
</p>
<p>Lorenzo-Seva, U., Timmerman, M. E., &amp; Kiers, H. A. (2011). The Hull method for selecting the number of common factors. Multivariate Behavioral Research, 46, 340–364. DOI: 10.1080/00273171.2011.564527.
</p>
<p>Ma, W., &amp; de la Torre, J. (2020). An empirical Q-matrix validation method for the sequential generalized DINA model. British Journal of Mathematical and Statistical Psychology, 73(1), 142-163. DOI: 10.1111/bmsp.12156.
</p>
<p>McFadden, D. (1974). Conditional logit analysis of qualitative choice behavior. In P. Zarembka (Ed.), Frontiers in economics (pp. 105–142). New York, NY: Academic Press.
</p>
<p>Najera, P., Sorrel, M. A., &amp; Abad, F. J. (2019). Reconsidering Cutoff Points in the General Method of Empirical Q-Matrix Validation. Educational and Psychological Measurement, 79(4), 727-753. DOI: 10.1177/0013164418822700.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2020). Improving Robustness in Q-Matrix Validation Using an Iterative and Dynamic Procedure. Applied Psychological Measurement, 44(6), 431-446. DOI: 10.1177/0146621620909904.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing fit and parsimony to improve Q-matrix validation. British Journal of Mathematical and Statistical Psychology, 74 Suppl 1, 110-130. DOI: 10.1111/bmsp.12228.
</p>
<p>Qin, H., &amp; Guo, L. (2025). Priority attribute algorithm for Q-matrix validation: A didactic. Behavior Research Methods, 57(1), 31. DOI: 10.3758/s13428-024-02547-5.
</p>
<p>Terzi, R., &amp; de la Torre, J. (2018). An Iterative Method for Empirically-Based Q-Matrix Validation. International Journal of Assessment Tools in Education, 248-262. DOI: 10.21449/ijate.40719.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models: A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################################################################
#                           Example 1                          #
#             The GDI method to validate Q-matrix              #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "GDINA", distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM model first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "GDI")


## also can validate the Q-matrix directly
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ)

## item level iteration
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        iter.level = "item", maxitr = 150)

## search method
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        search.method = "ESA")

## cut-off point
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        eps = 0.90)

## check QRR
print(zQRR(example.Q, Q.GDI.obj$Q.sug))




################################################################
#                           Example 2                          #
#             The Wald method to validate Q-matrix             #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.Wald.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "Wald")


## also can validate the Q-matrix directly
Q.Wald.obj &lt;- validation(example.data$dat, example.MQ, method = "Wald")

## check QRR
print(zQRR(example.Q, Q.Wald.obj$Q.sug))




################################################################
#                           Example 3                          #
#             The Hull method to validate Q-matrix             #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "Hull")


## also can validate the Q-matrix directly
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, method = "Hull")

## change PVAF to R2 as fit-index
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, method = "Hull", criter = "R2")

## check QRR
print(zQRR(example.Q, Q.Hull.obj$Q.sug))




################################################################
#                           Example 4                          #
#             The MLR-B method to validate Q-matrix            #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.MLR.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "MLR-B")


## also can validate the Q-matrix directly
Q.MLR.obj &lt;- validation(example.data$dat, example.MQ, method  = "MLR-B")

## check QRR
print(zQRR(example.Q, Q.MLR.obj$Q.sug))



</code></pre>

<hr>
<h2 id='Wald.test'>the Wald test for two q-vectors</h2><span id='topic+Wald.test'></span>

<h3>Description</h3>

<p>This function flexibly provides the Wald test for any two q-vectors of a given item in the Q-matrix, 
but requires that the two q-vectors differ by only one attribute. Additionally, this function needs 
to accept a <code>CDM.obj</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Wald.test(CDM.obj, q1, q2, i = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Wald.test_+3A_cdm.obj">CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. @seealso <code><a href="#topic+CDM">CDM</a></code>.</p>
</td></tr>
<tr><td><code id="Wald.test_+3A_q1">q1</code></td>
<td>
<p>A q-vector</p>
</td></tr>
<tr><td><code id="Wald.test_+3A_q2">q2</code></td>
<td>
<p>Another q-vector</p>
</td></tr>
<tr><td><code id="Wald.test_+3A_i">i</code></td>
<td>
<p>the item needed to be validated</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">
   Wald = \left[\mathbf{R} \times P_{i}(\mathbf{\alpha})\right]^{'}
   (\mathbf{R} \times \mathbf{V}_{i} \times \mathbf{R})^{-1}
   \left[\mathbf{R} \times P_{i}(\mathbf{\alpha})\right]
</code>
</p>



<h3>Value</h3>

<p>An object of class <code>htest</code> containing the following components:
</p>

<dl>
<dt>statistic</dt><dd><p>The statistic of the Wald test.</p>
</dd>
<dt>parameter</dt><dd><p>the degrees of freedom for the Wald-statistic.</p>
</dd>
<dt>p.value</dt><dd><p>The p value</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)
set.seed(123)

K &lt;- 3
I &lt;- 20
N &lt;- 500
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
Q &lt;- sim.Q(K, I)
data &lt;- sim.data(Q = Q, N = N, IQ = IQ, model = "GDINA", distribute = "horder")

CDM.obj &lt;- CDM(data$dat, Q)

q1 &lt;- c(1, 0, 0)
q2 &lt;- c(1, 1, 0)

## Discuss whether there is a significant difference when 
## the q-vector of the 2nd item in the Q-matrix is q1 or q2.
Wald.test.obj &lt;- Wald.test(CDM.obj, q1, q2, i=2)

print(Wald.test.obj)


</code></pre>

<hr>
<h2 id='zOSR'>Calculate over-specifcation rate (OSR)</h2><span id='topic+zOSR'></span>

<h3>Description</h3>

<p>Calculate over-specifcation rate (OSR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zOSR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zOSR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="zOSR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The OSR is defned as:
</p>
<p style="text-align: center;"><code class="reqn">
 OSR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} &lt; q_{ik}^{s})}{I × K}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (OSR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
OSR &lt;- zOSR(example.Q1, example.Q2)
print(OSR)

</code></pre>

<hr>
<h2 id='zQRR'>Calculate Q-matrix recovery rate (QRR)</h2><span id='topic+zQRR'></span>

<h3>Description</h3>

<p>Calculate Q-matrix recovery rate (QRR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zQRR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zQRR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="zQRR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Q-matrix recovery rate (QRR) provides information on overall performance, and is defned as:
</p>
<p style="text-align: center;"><code class="reqn">
 QRR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{s})}{I × K}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code class="reqn">Q.true</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the suggested Q-matrix(<code class="reqn">Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (QRR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
QRR &lt;- zQRR(example.Q1, example.Q2)
print(QRR)

</code></pre>

<hr>
<h2 id='zTNR'>Calculate true-negative rate (TNR)</h2><span id='topic+zTNR'></span>

<h3>Description</h3>

<p>Calculate true-negative rate (TNR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zTNR(Q.true, Q.orig, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zTNR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="zTNR_+3A_q.orig">Q.orig</code></td>
<td>
<p>The Q-matrix need to be validated.</p>
</td></tr>
<tr><td><code id="zTNR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TNR is defined as the proportion of correct elements which are correctly retained:
</p>
<p style="text-align: center;"><code class="reqn">
 TNR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{s} | q_{ik}^{t} \neq q_{ik}^{o})}
 {\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} \neq q_{ik}^{o})}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{o}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the original Q-matrix(<code>Q.orig</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (TNR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
example.Q3 &lt;- sim.MQ(example.Q1, 0.05)
TNR &lt;- zTNR(example.Q1, example.Q2, example.Q3)

print(TNR)

</code></pre>

<hr>
<h2 id='zTPR'>Calculate true-positive rate (TPR)</h2><span id='topic+zTPR'></span>

<h3>Description</h3>

<p>Calculate true-positive rate (TPR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zTPR(Q.true, Q.orig, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zTPR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="zTPR_+3A_q.orig">Q.orig</code></td>
<td>
<p>The Q-matrix need to be validated.</p>
</td></tr>
<tr><td><code id="zTPR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TPR is defned as the proportion of correct elements which are correctly retained:
</p>
<p style="text-align: center;"><code class="reqn">
 TPR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{s} | q_{ik}^{t} = q_{ik}^{o})}
 {\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} = q_{ik}^{o})}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{o}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the original Q-matrix(<code>Q.orig</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (TPR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
example.Q3 &lt;- sim.MQ(example.Q1, 0.05)
TPR &lt;- zTPR(example.Q1, example.Q2, example.Q3)

print(TPR)

</code></pre>

<hr>
<h2 id='zUSR'>Calculate under-specifcation rate (USR)</h2><span id='topic+zUSR'></span>

<h3>Description</h3>

<p>Calculate under-specifcation rate (USR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zUSR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zUSR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="zUSR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The USR is defned as:
</p>
<p style="text-align: center;"><code class="reqn">
 USR = \frac{\sum_{i=1}^{I}\sum_{k=1}^{K}I(q_{ik}^{t} &gt; q_{ik}^{s})}{I × K}
</code>
</p>

<p>where <code class="reqn">q_{ik}^{t}</code> denotes the <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">q_{ik}^{s}</code> denotes <code class="reqn">k</code>th attribute of item <code class="reqn">i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (USR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
USR &lt;- zUSR(example.Q1, example.Q2)
print(USR)

</code></pre>

<hr>
<h2 id='zVRR'>Calculate vector recovery ratio (VRR)</h2><span id='topic+zVRR'></span>

<h3>Description</h3>

<p>Calculate vector recovery ratio (VRR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zVRR(Q.true, Q.sug)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zVRR_+3A_q.true">Q.true</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
<tr><td><code id="zVRR_+3A_q.sug">Q.sug</code></td>
<td>
<p>The Q-matrix that has being validated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The VRR shows the ability of the validation method to recover q-vectors, and is determined by
</p>
<p style="text-align: center;"><code class="reqn">
 VRR =\frac{\sum_{i=1}^{I}I(\mathbf{q}_{i}^{t} = \mathbf{q}_{i}^{s})}{I}
</code>
</p>

<p>where <code class="reqn">\mathbf{q}_{i}^{t}</code> denotes the <code class="reqn">\mathbf{q}</code>-vector of item <code class="reqn">i</code> in the true Q-matrix (<code>Q.true</code>),
<code class="reqn">\mathbf{q}_{i}^{s}</code> denotes the <code class="reqn">\mathbf{q}</code>-vector of item <code class="reqn">i</code> in the suggested Q-matrix(<code>Q.sug</code>),
and <code class="reqn">I(\cdot)</code> is the indicator function.
</p>


<h3>Value</h3>

<p>A numeric (VRR index).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(Qval)

set.seed(123)

example.Q1 &lt;- sim.Q(5, 30)
example.Q2 &lt;- sim.MQ(example.Q1, 0.1)
VRR &lt;- zVRR(example.Q1, example.Q2)
print(VRR)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
