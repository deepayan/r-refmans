<!DOCTYPE html><html lang="en"><head><title>Help for package copBasic</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {copBasic}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#copBasic-package'><p>Basic Theoretical Copula, Empirical Copula, and Various Utility Functions</p></a></li>
<li><a href='#aicCOP'><p>Akaike Information Criterion between a Fitted Coupla and an Empirical Copula</p></a></li>
<li><a href='#AMHcop'><p>The Ali&ndash;Mikhail&ndash;Haq Copula</p></a></li>
<li><a href='#asCOP'><p>Wrapper on a User-Level Formula to Become a Copula Function</p></a></li>
<li><a href='#bicCOP'><p>Bayesian Information Criterion between a Fitted Coupla and an Empirical Copula</p></a></li>
<li><a href='#bicoploc'><p>Analog to Line of Organic Correlation by Copula Diagonal</p></a></li>
<li><a href='#bilmoms'><p>Bivariate L-moments and L-comoments of a Copula</p></a></li>
<li><a href='#blomatrixCOP'><p>A Matrix of Blomqvist-like Betas of a Copula</p></a></li>
<li><a href='#blomCOP'><p>The Blomqvist Beta of a Copula</p></a></li>
<li><a href='#blomCOPss'><p>Blomqvist (Schmid&ndash;Schmidt) Betas of a Copula</p></a></li>
<li><a href='#breveCOP'><p>Add Asymmetry to a Copula</p></a></li>
<li><a href='#CIRCcop'><p>Copula of Circular Uniform Distribution</p></a></li>
<li><a href='#CLcop'><p>The Clayton Copula</p></a></li>
<li><a href='#coCOP'><p>The Co-Copula Function</p></a></li>
<li><a href='#composite1COP'><p>Composition of a Single Symmetric Copula with Two Compositing Parameters (Khoudraji Device with Pi Independence)</p></a></li>
<li><a href='#composite2COP'><p>Composition of Two Copulas with Two Compositing Parameters (Khoudraji Device)</p></a></li>
<li><a href='#composite3COP'><p>(Extended) Composition of Two Copulas with Four Compositing Parameters</p></a></li>
<li><a href='#convex2COP'><p>Convex Combination of Two Copulas</p></a></li>
<li><a href='#convexCOP'><p>Convex Combination of an Arbitrary Number of Copulas</p></a></li>
<li><a href='#COP'><p>The Copula</p></a></li>
<li><a href='#copBasic.fitpara'><p>A Single or Multi-Parameter Optimization Engine (Beta Version)</p></a></li>
<li><a href='#COPinv'><p>The Inverse of a Copula for V with respect to U</p></a></li>
<li><a href='#COPinv2'><p>The Inverse of a Copula for U with respect to V</p></a></li>
<li><a href='#densityCOP'><p>Density of a Copula</p></a></li>
<li><a href='#densityCOPplot'><p>Contour Density Plot of a Copula</p></a></li>
<li><a href='#derCOP'><p>Numerical Derivative of a Copula for V with respect to U</p></a></li>
<li><a href='#derCOP2'><p>Numerical Derivative of a Copula for U with respect to V</p></a></li>
<li><a href='#derCOPinv'><p>Numerical Derivative Inverse  of a Copula for V with respect to U</p></a></li>
<li><a href='#derCOPinv2'><p>Numerical Derivative Inverse of a Copula for U with respect to V</p></a></li>
<li><a href='#diagCOP'><p>The Diagonals of a Copula</p></a></li>
<li><a href='#diagCOPatf'><p>Numerical Rooting the Diagonal of a Copula</p></a></li>
<li><a href='#duCOP'><p>The Dual of a Copula Function</p></a></li>
<li><a href='#EMPIRcop'><p>The Bivariate Empirical Copula</p></a></li>
<li><a href='#EMPIRcopdf'><p>Data Frame Representation of the Bivariate Empirical Copula</p></a></li>
<li><a href='#EMPIRgrid'><p>Grid of the Bivariate Empirical Copula</p></a></li>
<li><a href='#EMPIRgridder'><p>Derivatives of the Grid of the Bivariate Empirical Copula for V with respect to U</p></a></li>
<li><a href='#EMPIRgridder2'><p>Derivatives of the Grid of the Bivariate Empirical Copula for U with respect to V</p></a></li>
<li><a href='#EMPIRgridderinv'><p>Derivative Inverses of the Grid of the Bivariate Empirical Copula for V with respect to U</p></a></li>
<li><a href='#EMPIRgridderinv2'><p>Derivative Inverses of the Grid of the Bivariate Empirical Copula for U with respect to V</p></a></li>
<li><a href='#EMPIRmed.regress'><p>Median Regression of the Grid of the Bivariate Empirical Copula for V with respect to U</p></a></li>
<li><a href='#EMPIRmed.regress2'><p>Median Regression of the Grid of the Bivariate Empirical Copula for U with respect to V</p></a></li>
<li><a href='#EMPIRqua.regress'><p>Quantile Regression of the Grid of the Bivariate Empirical Copula for V with respect to U</p></a></li>
<li><a href='#EMPIRqua.regress2'><p>Quantile Regression of the Grid of the Bivariate Empirical Copula for U with respect to V</p></a></li>
<li><a href='#EMPIRsim'><p>Simulate a Bivariate Empirical Copula</p></a></li>
<li><a href='#EMPIRsimv'><p>Simulate a Bivariate Empirical Copula For a Fixed Value of U</p></a></li>
<li><a href='#EuvCOP'><p>Expected value of U given V</p></a></li>
<li><a href='#EvuCOP'><p>Expected value of V given U</p></a></li>
<li><a href='#FGMcop'><p>The Generalized Farlie&ndash;Gumbel&ndash;Morgenstern Copula</p></a></li>
<li><a href='#footCOP'><p>The Spearman Footrule of a Copula</p></a></li>
<li><a href='#FRcop'><p>The Frank Copula</p></a></li>
<li><a href='#FRECHETcop'><p>The Fréchet Family Copula</p></a></li>
<li><a href='#gEVcop'><p>The Gaussian-based (Extreme Value) Copula</p></a></li>
<li><a href='#GHcop'><p>The Gumbel&ndash;Hougaard Extreme Value Copula</p></a></li>
<li><a href='#giniCOP'><p>The Gini Gamma of a Copula</p></a></li>
<li><a href='#GLcop'><p>The Galambos Extreme Value Copula (with Gamma Power Mixture [Joe/BB4] and Lower Extreme Value Limit)</p></a></li>
<li><a href='#glueCOP'><p>Gluing Two Copulas</p></a></li>
<li><a href='#gridCOP'><p>Compute a Copula on a Grid</p></a></li>
<li><a href='#hoefCOP'><p>The Hoeffding Phi of a Copula or Lp Distances (Independence, Radial Asymmetry, or Reflection Symmetry Forms)</p></a></li>
<li><a href='#HRcop'><p>The Hüsler&ndash;Reiss Extreme Value Copula</p></a></li>
<li><a href='#isCOP.LTD'><p>Is a Copula Left-Tail Decreasing</p></a></li>
<li><a href='#isCOP.permsym'><p>Is a Copula Permutation Symmetric</p></a></li>
<li><a href='#isCOP.PQD'><p>The Positively Quadrant Dependency State of a Copula</p></a></li>
<li><a href='#isCOP.radsym'><p>Is a Copula Radially Symmetric</p></a></li>
<li><a href='#isCOP.RTI'><p>Is a Copula Right-Tail Increasing</p></a></li>
<li><a href='#isfuncCOP'><p>Is a General Bivariate Function a Copula by Gridded Search?</p></a></li>
<li><a href='#JOcopB5'><p>The Joe/B5 Copula (B5)</p></a></li>
<li><a href='#joeskewCOP'><p>Joe's Nu-Skew and the copBasic Nu-Star of a Copula</p></a></li>
<li><a href='#joint.curvesCOP'><p>Compute Coordinates of the Marginal Probabilities given joint AND or OR Probabilities</p></a></li>
<li><a href='#joint.curvesCOP2'><p>Compute Coordinates of the Marginal Probabilities given joint AND or OR Probability</p></a></li>
<li><a href='#jointCOP'><p>Compute Equal Marginal Probabilities Given a Single Joint AND or OR Probability for a Copula</p></a></li>
<li><a href='#kfuncCOP'><p>The Kendall (Distribution) Function of a Copula</p></a></li>
<li><a href='#kfuncCOPinv'><p>The Inverse Kendall Function of a Copula</p></a></li>
<li><a href='#kfuncCOPlmoms'><p>The L-moments of the Kendall Function of a Copula</p></a></li>
<li><a href='#kullCOP'><p>Kullback&ndash;Leibler Divergence, Jeffrey Divergence, and Kullback&ndash;Leibler Sample Size</p></a></li>
<li><a href='#lcomCOP'><p>L-comoments and Bivariate L-moments of a Copula</p></a></li>
<li><a href='#lcomCOPpv'><p>Simulating the Sample Distribution(s) of L-correlation, L-coskew, and L-cokurtosis for a Copula</p></a></li>
<li><a href='#lcomoms2.ABcop2parameter'><p>Convert L-comoments to Parameters of Alpha-Beta Compositions of Two One-Parameter Copulas</p></a></li>
<li><a href='#lcomoms2.ABKGcop2parameter'><p>Convert L-comoments to Parameters of Alpha-Beta-Kappa-Gamma Compositions of Two One-Parameter Copulas</p></a></li>
<li><a href='#level.curvesCOP'><p>Compute and Plot Level Curves of a Copula V with respect to U</p></a></li>
<li><a href='#level.curvesCOP2'><p>Compute and Plot Level Curves of a Copula U with respect to V</p></a></li>
<li><a href='#level.setCOP'><p>Compute a Level Set of a Copula V with respect to U</p></a></li>
<li><a href='#level.setCOP2'><p>Compute a Level Set of a Copula U with respect to V</p></a></li>
<li><a href='#LzCOPpermsym'><p>Maximum Asymmetry Measure (or Vector) of a Copula by Exchangability</p></a></li>
<li><a href='#M'><p>The Fréchet&ndash;Hoeffding Upper-Bound Copula</p></a></li>
<li><a href='#M_N5p12b'><p>Shuffles of Upper-Bound Copula, Example 5.12b of Nelsen's Book</p></a></li>
<li><a href='#med.regressCOP'><p>Perform Median Regression using a Copula by Numerical Derivative Method for V with respect to U</p></a></li>
<li><a href='#med.regressCOP2'><p>Perform Median Regression using a Copula by Numerical Derivative Method for U with respect to V</p></a></li>
<li><a href='#mleCOP'><p>Maximum Pseudo-Log-Likelihood Estimation for Copula Parameter Estimation</p></a></li>
<li><a href='#N4212cop'><p>The Copula of Equation 4.2.12 of Nelsen's Book</p></a></li>
<li><a href='#ORDSUMcop'><p>Ordinal Sums of M-Copula</p></a></li>
<li><a href='#ORDSUWcop'><p>Ordinal Sums of W-Copula</p></a></li>
<li><a href='#P'><p>The Product (Independence) Copula</p></a></li>
<li><a href='#PARETOcop'><p>The Pareto Copula</p></a></li>
<li><a href='#PLACKETTcop'><p>The Plackett Copula</p></a></li>
<li><a href='#PLACKETTpar'><p>Estimate the Parameter of the Plackett Copula</p></a></li>
<li><a href='#PLACKETTsim'><p>Direct Simulation of a Plackett Copula</p></a></li>
<li><a href='#prod2COP'><p>The Product of Two Copulas</p></a></li>
<li><a href='#psepolar'><p>Pseudo-Polar Representation of Bivariate Data</p></a></li>
<li><a href='#PSP'><p>The Ratio of the Product Copula to Summation minus Product Copula</p></a></li>
<li><a href='#qua.regressCOP'><p>Perform Quantile Regression using a Copula by Numerical Derivative Method for V with respect to U</p></a></li>
<li><a href='#qua.regressCOP.draw'><p>Draw Quantile Regressions using a Copula by Numerical Derivative Method for V with respect to U or U with respect to V</p></a></li>
<li><a href='#qua.regressCOP2'><p>Perform Quantile Regression using a Copula by Numerical Derivative Method for U with respect to V</p></a></li>
<li><a href='#RAYcop'><p>The Rayleigh Copula</p></a></li>
<li><a href='#ReineckeWell266'><p>Porosity and Permeability Data for Well-266 of the Reinecke Oil Field, Horseshoe Atoll, Texas</p></a></li>
<li><a href='#ReineckeWells'><p>Porosity and Permeability Data for the Reinecke Oil Field, Horseshoe Atoll, Texas</p></a></li>
<li><a href='#RFcop'><p>The Raftery Copula</p></a></li>
<li><a href='#rhobevCOP'><p>A Dependence Measure for a Bivariate Extreme Value Copula based on the Expectation of the Product of Negated Log-Transformed Random Variables U and V</p></a></li>
<li><a href='#rhoCOP'><p>The Spearman Rho of a Copula</p></a></li>
<li><a href='#rmseCOP'><p>Root Mean Square Error between a Fitted Copula and an Empirical Copula</p></a></li>
<li><a href='#sectionCOP'><p>The Sections or Derivative of the Sections of a Copula</p></a></li>
<li><a href='#semicorCOP'><p>Lower and Upper Semi-Correlations of a Copula</p></a></li>
<li><a href='#simcomposite3COP'><p>Compute the L-comoments of a Four-Value Composited Copula by Simulation</p></a></li>
<li><a href='#simcompositeCOP'><p>Compute the L-comoments of a Two-Value Composited Copula by Simulation</p></a></li>
<li><a href='#simCOP'><p>Simulate a Copula by Numerical Derivative Method</p></a></li>
<li><a href='#simCOPmicro'><p>Simulate V from U through a Copula by Numerical Derivative Method</p></a></li>
<li><a href='#spectralmeas'><p>Estimation of the Spectral Measure</p></a></li>
<li><a href='#stabtaildepf'><p>Estimation of the Stable Tail Dependence Function</p></a></li>
<li><a href='#statTn'><p>The Tn Statistic of a Fitted Copula to an Empirical Copula</p></a></li>
<li><a href='#surCOP'><p>The Survival Copula</p></a></li>
<li><a href='#surfuncCOP'><p>The Joint Survival Function</p></a></li>
<li><a href='#tailconCOP'><p>The Tail Concentration Function of a Copula</p></a></li>
<li><a href='#taildepCOP'><p>The Lower- and Upper-Tail Dependency Parameters of a Copula</p></a></li>
<li><a href='#tailordCOP'><p>The Lower- and Upper-Tail Orders of a Copula</p></a></li>
<li><a href='#tauCOP'><p>The Kendall Tau and Concordance Function of a Copula</p></a></li>
<li><a href='#tEVcop'><p>The t-EV (Extreme Value) Copula</p></a></li>
<li><a href='#uvlmoms'><p>Bivariate Skewness after Joe (2014) or the Univariate L-moments of Combined U and V</p></a></li>
<li><a href='#vuongCOP'><p>The Vuong Procedure for Parametric Copula Comparison</p></a></li>
<li><a href='#W'><p>The Fréchet&ndash;Hoeffding Lower-Bound Copula</p></a></li>
<li><a href='#W_N5p12a'><p>Ordinal Sums of Lower-Bound Copula, Example 5.12a of Nelsen's Book</p></a></li>
<li><a href='#wolfCOP'><p>The Schweizer and Wolff Sigma of a Copula</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>General Bivariate Copula Theory and Many Utility Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-25</td>
</tr>
<tr>
<td>Description:</td>
<td>Extensive functions for bivariate copula (bicopula) computations and related operations 
 for bicopula theory. The lower, upper, product, and select other bicopula are implemented along 
 with operations including the diagonal, survival copula, dual of a copula, co-copula, and
 numerical bicopula density. Level sets, horizontal and vertical sections are supported. Numerical 
 derivatives and inverses of a bicopula are provided through which simulation is implemented. 
 Bicopula composition, convex combination, asymmetry extension, and products also are provided.
 Support extends to the Kendall Function as well as the Lmoments thereof. Kendall Tau,
 Spearman Rho and Footrule, Gini Gamma, Blomqvist Beta, Hoeffding Phi, Schweizer-
 Wolff Sigma, tail dependency, tail order, skewness, and bivariate Lmoments are implemented, and 
 positive/negative quadrant dependency, left (right) increasing (decreasing) are available. 
 Other features include Kullback-Leibler Divergence, Vuong Procedure, spectral measure, and 
 Lcomoments for inference, maximum likelihood, and AIC, BIC, and RMSE for goodness-of-fit. </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>William Asquith &lt;william.asquith@ttu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lmomco, randtoolbox</td>
</tr>
<tr>
<td>Suggests:</td>
<td>copula</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-25 14:47:02 UTC; wasquith</td>
</tr>
<tr>
<td>Author:</td>
<td>William Asquith <a href="https://orcid.org/0000-0002-7400-1861"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-25 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='copBasic-package'>Basic Theoretical Copula, Empirical Copula, and Various Utility Functions</h2><span id='topic+copBasic-package'></span>

<h3>Description</h3>

<p>The <span class="pkg">copBasic</span> package is oriented around <em>bivariate copula theory</em> and mathematical operations closely follow the recommended texts of Nelsen (2006) and Joe (2014) as well as select other references. Another recommended text is Salvadori <em>et al.</em> (2007) and Hofert <em>et al.</em> (2018) and are cited herein, but about half of that excellent book concerns univariate applications. The primal objective of <span class="pkg">copBasic</span> is to provide a study of numerous results shown by authoritative texts on copulas. It is intended that the package will help other copula students in self study, potential course work, and applied circumstances.
</p>
<p><b>Notes on copulas that are supported.</b> The author has focused on pedagogical aspects of copulas, and this package is a <em>diary</em> of sorts beginning in fall 2008. Originally, the author did not implement many copulas in the <span class="pkg">copBasic</span> in order to deliberately avoid redundancy to that support such as it exists on the <span class="rlang"><b>R</b></span> CRAN. Though as time has progressed, other copulas have been added occasionally based on needs of the user community, need to show some specific concept in the general theory, or test algorithms. For example, the Clayton copula (<code><a href="#topic+CLcop">CLcop</a></code>) was a late arriving addition the package (<em>c.</em>2017), which was added to assist a specific user; the Frank copula (<code><a href="#topic+FRcop">FRcop</a></code> was added in December 2024 because of an inquiry on using <span class="pkg">copBasic</span> for <em>vine copula</em> (see vine example under <code><a href="#topic+FRcop">FRcop</a></code>).
</p>
<p>The language and vocabulary of copulas are formidable even within the realm of <em>bivariate</em> or <em>bicopula</em> as design basis for the package. Often &ldquo;vocabulary&rdquo; words are often emphasized in <em>italics</em>, which is used extensively and usually near the opening of function-by-function documentation to identify vocabulary words, such as <em>survival copula</em> (see <code><a href="#topic+surCOP">surCOP</a></code>). This syntax tries to mimic and accentuate the terminology in Nelsen (2006), Joe (2014), and generally most other texts. Italics are used to draw connections between concepts.
</p>
<p>In conjunction with the summary of functions in <b>copBasic-package</b>, the extensive cross referencing to functions and expansive keyword indexing should be beneficial. The author had no experience with copulas prior to a chance happening upon Nelsen (2006) in <em>c.</em>2008. The <span class="pkg">copBasic</span> package is a personal <em>tour de force</em> in self-guided learning. Over time, this package and user's manual have been helpful to others.<br />
</p>
<p><b>Helpful Navigation of Copulas Implemented in the copBasic Package</b>
</p>
<p>Some entry points to the copulas implemented are listed in the <b>Table of Copulas</b>:
</p>

<table>
<tr>
 <td style="text-align: left;">
<b>Name</b> </td><td style="text-align: center;"> <b>Symbol</b> </td><td style="text-align: left;"> <b>Function</b> </td><td style="text-align: right;"> <b>Concept</b> </td>
</tr>
<tr>
 <td style="text-align: left;">
Lower-bounds copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{W}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+W">W</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Independence copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{\Pi}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+P">P</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Upper-bounds copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{M}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+M">M</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Fréchet Family copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{FF}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+FRECHETcop">FRECHETcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Ali--Mikhail--Haq copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{AMH}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+AMHcop">AMHcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Clayton copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{CL}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+CLcop">CLcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula of uniform circle </td><td style="text-align: center;"> <code class="reqn">\mathbf{CIRC}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+CIRCcop">CIRCcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Farlie--Gumbel--Morgenstern (generalized) </td><td style="text-align: center;"> <code class="reqn">\mathbf{FGM}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+FGMcop">FGMcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Frank </td><td style="text-align: center;"> <code class="reqn">\mathbf{FR}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+FRcop">FRcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Galambos copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{GL}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+GLcop">GLcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Gumbel--Hougaard copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{GH}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+GHcop">GHcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Hüsler--Reiss copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{HR}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+HRcop">HRcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Joe B5 (the &ldquo;Joe&rdquo;) copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{B5}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+JOcopB5">JOcopB5</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Nelsen eq.4-2-12 copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{N4212cop}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+N4212cop">N4212cop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Ordinal Sums by Copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}_\mathcal{J}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Pareto copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{PA}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+PLcop">PLcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Plackett copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{PL}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+PLcop">PLcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
PSP copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{PSP}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+PSP">PSP</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Raftery copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{RF}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+RFcop">RFcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Rayleigh copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{RAY}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+RAYcop">RAYcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
g-EV copula (Gaussian extreme value) </td><td style="text-align: center;"> <code class="reqn">\mathbf{gEV}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+gEVcop">gEVcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
t-EV copula (t-distribution extreme value) </td><td style="text-align: center;"> <code class="reqn">\mathbf{tEV}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+tEVcop">tEVcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>A few comments on notation herein are needed. A bold math typeface is used to represent a copula function or family such as <code class="reqn">\mathbf{\Pi}</code> (see <code><a href="#topic+P">P</a></code>) for the <em>independence copula</em>. The syntax <code class="reqn">\mathcal{R}\times\mathcal{R} \equiv \mathcal{R}^2</code> denotes the orthogonal domain of two real numbers, and <code class="reqn">[0,1]\times [0,1]</code> <code class="reqn">\equiv</code> <code class="reqn">\mathcal{I}\times\mathcal{I} \equiv \mathcal{I}^2</code> denotes the orthogonal domain on the unit square of probabilities. Limits of integration <code class="reqn">[0,1]</code> or <code class="reqn">[0,1]^2</code> involving copulas are thus shown as <code class="reqn">\mathcal{I}</code> and <code class="reqn">\mathcal{I}^2</code>, respectively.
</p>
<p>Random variables <code class="reqn">X</code> and <code class="reqn">Y</code> respectively denote the horizontal and vertical directions in <code class="reqn">\mathcal{R}^2</code>. Their probabilistic counterparts are uniformly distributed random variables on <code class="reqn">[0,1]</code>, are respectively denoted as <code class="reqn">U</code> and <code class="reqn">V</code>, and necessarily also are the respective directions in <code class="reqn">\mathcal{I}^2</code> (<code class="reqn">U</code> denotes the horizontal, <code class="reqn">V</code> denotes the vertical). Often realizations of these random variables are respectively <code class="reqn">x</code> and <code class="reqn">y</code> for <code class="reqn">X</code> and <code class="reqn">Y</code> and <code class="reqn">u</code> and <code class="reqn">v</code> for <code class="reqn">U</code> and <code class="reqn">V</code>.
</p>
<p>There is an obvious difference between nonexceedance probability <code class="reqn">F</code> and its complement, which is exceedance probability defined as <code class="reqn">1-F</code>. Both <code class="reqn">u</code> and <code class="reqn">v</code> herein are in nonexceedance probability. Arguments to many functions herein are <code>u</code> <code class="reqn">= u</code> and <code>v</code> <code class="reqn">= v</code> and are almost <em>exclusively nonexceedance</em> but there are instances for which the probability arguments are <code>u</code> <code class="reqn">= 1 - u = u'</code> and <code>v</code> <code class="reqn">= 1 - v = v'</code>.
</p>
<p>Several of the functions listed above are measures of &ldquo;bivariate association.&rdquo; Two of the measures (<em>Kendall Tau</em>, <code><a href="#topic+tauCOP">tauCOP</a></code>; <em>Spearman Rho</em>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>) are widely known. <span class="rlang"><b>R</b></span> provides native support for their sample estimation of course, but each function can be used to call the <code>cor()</code> function in <span class="rlang"><b>R</b></span> for parallelism to the other measures of this package. The other measures (<em>Blomqvist Beta</em>, <em>Gini Gamma</em>, <em>Hoeffding Phi</em>, <em>Schweizer&ndash;Wolff Sigma</em>, <em>Spearman Footrule</em>) support sample estimation by specially formed calls to their respective functions: <code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+hoefCOP">hoefCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>, and <code><a href="#topic+footCOP">footCOP</a></code>. Gini Gamma (<code><a href="#topic+giniCOP">giniCOP</a></code>) documentation (also <code><a href="#topic+joeskewCOP">joeskewCOP</a></code>) shows extensive use of theoretical and sample computations for these and other functions.<br /><br />
</p>
<p><b>Helpful Navigation of the copBasic Package</b>
</p>
<p>Some other entry points into the package are listed in the following table:
</p>

<table>
<tr>
 <td style="text-align: left;">
<b>Name</b> </td><td style="text-align: center;"> <b>Symbol</b> </td><td style="text-align: left;"> <b>Function</b> </td><td style="text-align: right;"> <b>Concept</b> </td>
</tr>
<tr>
 <td style="text-align: left;">
Copula  </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+COP">COP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
<code class="reqn">\cdots</code> </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+COP">COP</a></code><code>(..., reflect=*)</code> </td><td style="text-align: right;"> reflection</td>
</tr>
<tr>
 <td style="text-align: left;">
<code class="reqn">\cdots</code> </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+COP">COP</a></code><code>(..., reflect=*)</code> </td><td style="text-align: right;"> rotation</td>
</tr>
<tr>
 <td style="text-align: left;">
Survival copula </td><td style="text-align: center;"> <code class="reqn">\hat{\mathbf{C}}(u',v')</code> </td><td style="text-align: left;"> <code><a href="#topic+surCOP">surCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Joint survival function </td><td style="text-align: center;"> <code class="reqn">\overline{\mathbf{C}}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+surfuncCOP">surfuncCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Co-copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}^\star(u',v')</code> </td><td style="text-align: left;"> <code><a href="#topic+coCOP">coCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Dual of a copula </td><td style="text-align: center;"> <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+duCOP">duCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Primary copula diagonal  </td><td style="text-align: center;"> <code class="reqn">\delta(t)</code> </td><td style="text-align: left;"> <code><a href="#topic+diagCOP">diagCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Secondary copula diagonal  </td><td style="text-align: center;"> <code class="reqn">\delta^\star(t)</code> </td><td style="text-align: left;"> <code><a href="#topic+diagCOP">diagCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Inverse copula diagonal </td><td style="text-align: center;"> <code class="reqn">\delta^{(-1)}(f)</code> </td><td style="text-align: left;"> <code><a href="#topic+diagCOPatf">diagCOPatf</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Joint probability </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+jointCOP">jointCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Bivariate L-moments </td><td style="text-align: center;"> <code class="reqn">\delta^{[\ldots]}_{k;\mathbf{C}}</code> </td><td style="text-align: left;"> <code><a href="#topic+bilmoms">bilmoms</a></code> and <code><a href="#topic+lcomCOP">lcomCOP</a></code> </td><td style="text-align: right;"> bivariate moments</td>
</tr>
<tr>
 <td style="text-align: left;">
Bivariate L-comoments </td><td style="text-align: center;"> <code class="reqn">\tau^{[\ldots]}_{k;\mathbf{C}}</code> </td><td style="text-align: left;"> <code><a href="#topic+bilmoms">bilmoms</a></code> and <code><a href="#topic+lcomCOP">lcomCOP</a></code> </td><td style="text-align: right;"> bivariate moments</td>
</tr>
<tr>
 <td style="text-align: left;">
Blomqvist Beta </td><td style="text-align: center;"> <code class="reqn">\beta_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+blomCOP">blomCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Gini Gamma </td><td style="text-align: center;"> <code class="reqn">\gamma_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+giniCOP">giniCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Hoeffding Phi </td><td style="text-align: center;"> <code class="reqn">\Phi_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+hoefCOP">hoefCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Nu-Skew </td><td style="text-align: center;"> <code class="reqn">\nu_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+nuskewCOP">nuskewCOP</a></code> </td><td style="text-align: right;"> bivariate moments</td>
</tr>
<tr>
 <td style="text-align: left;">
Nu-Star (skew) </td><td style="text-align: center;"> <code class="reqn">\nu^\star_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+nustarCOP">nustarCOP</a></code> </td><td style="text-align: right;"> bivariate moments</td>
</tr>
<tr>
 <td style="text-align: left;">
Lp distance to independence </td><td style="text-align: center;">  <code class="reqn">\Phi_\mathbf{C} \rightarrow L_p</code> </td><td style="text-align: left;"> <code><a href="#topic+LpCOP">LpCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Permutation-Mu </td><td style="text-align: center;">  <code class="reqn">\mu_{\infty\mathbf{C}}^\mathrm{permsym}</code> </td><td style="text-align: left;"> <code><a href="#topic+LzCOPpermsym">LzCOPpermsym</a></code> </td><td style="text-align: right;"> permutation asymmetry</td>
</tr>
<tr>
 <td style="text-align: left;">
Kendall Tau </td><td style="text-align: center;"> <code class="reqn">\tau_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+tauCOP">tauCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Kendall Measure </td><td style="text-align: center;"> <code class="reqn">K_\mathbf{C}(z)</code> </td><td style="text-align: left;"> <code><a href="#topic+kmeasCOP">kmeasCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Kendall Function </td><td style="text-align: center;"> <code class="reqn">F_K(z)</code> </td><td style="text-align: left;"> <code><a href="#topic+kfuncCOP">kfuncCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Inverse Kendall Function </td><td style="text-align: center;"> <code class="reqn">F_K^{(-1)}(z)</code> </td><td style="text-align: left;"> <code><a href="#topic+kfuncCOPinv">kfuncCOPinv</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
An L-moment of <code class="reqn">F_K(z)</code> </td><td style="text-align: center;"> <code class="reqn">\lambda_r(F_K)</code> </td><td style="text-align: left;"><code><a href="#topic+kfuncCOPlmom">kfuncCOPlmom</a></code> </td><td style="text-align: right;"> L-moment theory</td>
</tr>
<tr>
 <td style="text-align: left;">
L-moments of <code class="reqn">F_K(z)</code> </td><td style="text-align: center;"> <code class="reqn">\lambda_r(F_K)</code> </td><td style="text-align: left;"> <code><a href="#topic+kfuncCOPlmoms">kfuncCOPlmoms</a></code> </td><td style="text-align: right;"> L-moment theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Semi-correlations (negatives) </td><td style="text-align: center;"> <code class="reqn">\rho_N^{-}(a)</code> </td><td style="text-align: left;"> <code><a href="#topic+semicorCOP">semicorCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Semi-correlations (positives) </td><td style="text-align: center;"> <code class="reqn">\rho_N^{+}(a)</code> </td><td style="text-align: left;"> <code><a href="#topic+semicorCOP">semicorCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Spearman Footrule </td><td style="text-align: center;"> <code class="reqn">\psi_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+footCOP">footCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Spearman Rho </td><td style="text-align: center;"> <code class="reqn">\rho_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+rhoCOP">rhoCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Schweizer--Wolff Sigma </td><td style="text-align: center;"> <code class="reqn">\sigma_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+wolfCOP">wolfCOP</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Density of a copula</td><td style="text-align: center;"> <code class="reqn">c(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+densityCOP">densityCOP</a></code> </td><td style="text-align: right;"> copula density</td>
</tr>
<tr>
 <td style="text-align: left;">
Density visualization </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+densityCOPplot">densityCOPplot</a></code> </td><td style="text-align: right;"> copula density</td>
</tr>
<tr>
 <td style="text-align: left;">
Empirical copula </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}_n(u,v)</code> </td><td style="text-align: left;"> <code><a href="#topic+EMPIRcop">EMPIRcop</a></code> </td><td style="text-align: right;"> copula</td>
</tr>
<tr>
 <td style="text-align: left;">
Empirical simulation </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+EMPIRsim">EMPIRsim</a></code> </td><td style="text-align: right;"> copula simulation</td>
</tr>
<tr>
 <td style="text-align: left;">
Empirical simulation </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+EMPIRsimv">EMPIRsimv</a></code> </td><td style="text-align: right;"> copula simulation</td>
</tr>
<tr>
 <td style="text-align: left;">
Empirical copulatic surface </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code> </td><td style="text-align: right;"> copulatic surface</td>
</tr>
<tr>
 <td style="text-align: left;">
Parametric copulatic surface </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+gridCOP">gridCOP</a></code> </td><td style="text-align: right;"> copulatic surface</td>
</tr>
<tr>
 <td style="text-align: left;">
Parametric simulation </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+simCOP">simCOP</a></code> or   <code><a href="#topic+rCOP">rCOP</a></code></td><td style="text-align: right;"> copula simulation</td>
</tr>
<tr>
 <td style="text-align: left;">
Parametric simulation </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> </td><td style="text-align: right;"> copula simulation</td>
</tr>
<tr>
 <td style="text-align: left;">
Maximum likelihood </td><td style="text-align: center;"> <code class="reqn">\mathcal{L}(\Theta_d)</code> </td><td style="text-align: left;"> <code><a href="#topic+mleCOP">mleCOP</a></code> </td><td style="text-align: right;"> copula fitting</td>
</tr>
<tr>
 <td style="text-align: left;">
Akaike information criterion </td><td style="text-align: center;"> <code class="reqn">\mathrm{AIC}_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+aicCOP">aicCOP</a></code> </td><td style="text-align: right;"> goodness-of-fit</td>
</tr>
<tr>
 <td style="text-align: left;">
Bayesian information criterion </td><td style="text-align: center;"> <code class="reqn">\mathrm{BIC}_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+bicCOP">bicCOP</a></code> </td><td style="text-align: right;"> goodness-of-fit</td>
</tr>
<tr>
 <td style="text-align: left;">
Root mean square error </td><td style="text-align: center;"> <code class="reqn">\mathrm{RMSE}_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+rmseCOP">rmseCOP</a></code> </td><td style="text-align: right;"> goodness-of-fit</td>
</tr>
<tr>
 <td style="text-align: left;">
Another goodness-of-fit </td><td style="text-align: center;"> <code class="reqn">T_n</code> </td><td style="text-align: left;"> <code><a href="#topic+statTn">statTn</a></code> </td><td style="text-align: right;"> goodness-of-fit</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Concerning <em>goodness-of-fit</em> and although not quite the same as copula properties (such as &ldquo;correlation&rdquo;) per se as the coefficients aforementioned in the prior paragraph, three goodness-of-fit metrics of a copula compared to the empirical copula, which are all based the <em>mean square error</em> (MSE), are <code><a href="#topic+aicCOP">aicCOP</a></code>, <code><a href="#topic+bicCOP">bicCOP</a></code>, and <code><a href="#topic+rmseCOP">rmseCOP</a></code>. This triad of functions is useful for making decisions on whether a copula is more favorable than another to a given dataset. However, because they are genetically related by using MSE and if these are used for copula fitting by minimization, the fits will be identical. A statement of &ldquo;not quite the same&rdquo; is made because the previously described copula properties are generally defined as types of deviations from other copulas (such as <code><a href="#topic+P">P</a></code>). Another goodness-of-fit statistic is <code><a href="#topic+statTn">statTn</a></code>, which is based on magnitude summation of fitted copula difference from the empirical copula. These four (<code><a href="#topic+aicCOP">aicCOP</a></code>, <code><a href="#topic+bicCOP">bicCOP</a></code>, <code><a href="#topic+rmseCOP">rmseCOP</a></code>, and <code><a href="#topic+statTn">statTn</a></code>) collectively are relative simple and readily understood measures. These bulk sample statistics are useful, but generally thought to not capture the nuances of tail behavior (<code><a href="#topic+semicorCOP">semicorCOP</a></code> and <code><a href="#topic+taildepCOP">taildepCOP</a></code> might be useful).
</p>
<p><em>Bivariate skewness</em> measures are supported in the functions <code><a href="#topic+joeskewCOP">joeskewCOP</a></code> (<code><a href="#topic+nuskewCOP">nuskewCOP</a></code> and <code><a href="#topic+nustarCOP">nustarCOP</a></code>) and <code><a href="#topic+uvlmoms">uvlmoms</a></code> (<code><a href="#topic+uvskew">uvskew</a></code>). Extensive discussion and example computations of bivariate skewness are provided in the <code><a href="#topic+joeskewCOP">joeskewCOP</a></code> documentation.  Lastly, so-called <em>bivariate L-moments</em> and <em>bivariate L-comoments</em> of a copula are directly computable in <code><a href="#topic+bilmoms">bilmoms</a></code> (though that function using Monte Carlo integration is deprecated) and <code><a href="#topic+lcomCOP">lcomCOP</a></code> (direct numerical integration). The <code><a href="#topic+lcomCOP">lcomCOP</a></code> function is the theoretical counterpart to the <em>sample L-comoments</em> provided in the <span class="pkg">lmomco</span> package.
</p>
<p>Bivariate random simulation methods by several functions are identified in the previous table. The <span class="pkg">copBasic</span> package explicitly uses only <em>conditional simulation</em> also known as the <em>conditional distribution method</em> for <em>random variate</em> generation following Nelsen (2006, pp. 40&ndash;41) (see also <code><a href="#topic+simCOPmicro">simCOPmicro</a></code>, <code><a href="#topic+simCOP">simCOP</a></code>). The <em>numerical derivatives</em> (<code><a href="#topic+derCOP">derCOP</a></code> and <code><a href="#topic+derCOP2">derCOP2</a></code>) and their <em>inversions</em> (<code><a href="#topic+derCOPinv">derCOPinv</a></code> and <code><a href="#topic+derCOPinv2">derCOPinv2</a></code>) represent the foundation of the conditional simulation. There are other methods in the literature and available in other <span class="rlang"><b>R</b></span> packages, and a comparison of some methods is made in the <b>Examples</b> section of the Gumbel&ndash;Hougaard copula (<code><a href="#topic+GHcop">GHcop</a></code>).
</p>
<p>Several functions in <span class="pkg">copBasic</span> make the distinction between <code class="reqn">V</code> with respect to (<em>wrt</em>) <code class="reqn">U</code> and <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code>, and a guide for the nomenclature involving <em>wrt</em> distinctions is listed in the following table:
</p>

<table>
<tr>
 <td style="text-align: left;">
<b>Name</b> </td><td style="text-align: center;"> <b>Symbol</b> </td><td style="text-align: left;"> <b>Function</b> </td><td style="text-align: right;"> <b>Concept</b> </td>
</tr>
<tr>
 <td style="text-align: left;">
Copula inversion </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> </td><td style="text-align: left;"> <code><a href="#topic+COPinv">COPinv</a></code> </td><td style="text-align: right;"> copula operator</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula inversion </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> </td><td style="text-align: left;"> <code><a href="#topic+COPinv2">COPinv2</a></code> </td><td style="text-align: right;"> copula operator</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula derivative </td><td style="text-align: center;"> <code class="reqn">\delta \mathbf{C}/\delta u</code> </td><td style="text-align: left;"> <code><a href="#topic+derCOP">derCOP</a></code> </td><td style="text-align: right;"> copula operator</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula derivative </td><td style="text-align: center;"> <code class="reqn">\delta \mathbf{C}/\delta v</code> </td><td style="text-align: left;"> <code><a href="#topic+derCOP2">derCOP2</a></code> </td><td style="text-align: right;"> copula operator</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula derivative inversion </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> </td><td style="text-align: left;"> <code><a href="#topic+derCOPinv">derCOPinv</a></code> </td><td style="text-align: right;"> copula operator</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula derivative inversion </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> </td><td style="text-align: left;"> <code><a href="#topic+derCOPinv2">derCOPinv2</a></code> </td><td style="text-align: right;"> copula operator</td>
</tr>
<tr>
 <td style="text-align: left;">
Joint curves </td><td style="text-align: center;"> <code class="reqn">t \mapsto \mathbf{C}(u=U, v)</code> </td><td style="text-align: left;"> <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Joint curves </td><td style="text-align: center;"> <code class="reqn">t \mapsto \mathbf{C}(u, v=V)</code> </td><td style="text-align: left;"> <code><a href="#topic+joint.curvesCOP2">joint.curvesCOP2</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Level curves </td><td style="text-align: center;"> <code class="reqn">t \mapsto \mathbf{C}(u=U, v)</code> </td><td style="text-align: left;"> <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Level curves </td><td style="text-align: center;"> <code class="reqn">t \mapsto \mathbf{C}(u, v=V)</code> </td><td style="text-align: left;"> <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Level set </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> </td><td style="text-align: left;"> <code><a href="#topic+level.setCOP">level.setCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Level set </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> </td><td style="text-align: left;"> <code><a href="#topic+level.setCOP2">level.setCOP2</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Median regression </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> </td><td style="text-align: left;"> <code><a href="#topic+med.regressCOP">med.regressCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Median regression </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> </td><td style="text-align: left;"> <code><a href="#topic+med.regressCOP2">med.regressCOP2</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Quantile regression </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> </td><td style="text-align: left;"> <code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Quantile regression </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> </td><td style="text-align: left;"> <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula section </td><td style="text-align: center;"> <code class="reqn">t \mapsto \mathbf{C}(t,a)</code> </td><td style="text-align: left;"> <code><a href="#topic+sectionCOP">sectionCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
Copula section </td><td style="text-align: center;"> <code class="reqn">t \mapsto \mathbf{C}(a,t)</code> </td><td style="text-align: left;"> <code><a href="#topic+sectionCOP">sectionCOP</a></code> </td><td style="text-align: right;"> copula theory</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The previous two tables do not include all of the myriad of special functions to support similar operations on <em>empirical copulas</em>. All empirical copula operators and utilities are prepended with <code>EMPIR</code> in the function name. An additional note concerning package nomenclature is that an appended &ldquo;<code>2</code>&rdquo; to a function name indicates <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> (<em>e.g.</em> <code><a href="#topic+EMPIRgridderinv2">EMPIRgridderinv2</a></code> for an inversion of the partial derivatives <code class="reqn">\delta \mathbf{C}/\delta v</code> across the grid of the empirical copula).
</p>
<p>Some additional functions to compute often salient features or characteristics of copulas or bivariate data, including functions for bivariate inference or goodness-of-fit, are listed in the following table:
</p>

<table>
<tr>
 <td style="text-align: left;">
<b>Name</b> </td><td style="text-align: center;"> <b>Symbol</b> </td><td style="text-align: left;"> <b>Function</b> </td><td style="text-align: right;"> <b>Concept</b> </td>
</tr>
<tr>
 <td style="text-align: left;">
Left-tail decreasing </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code>  </td><td style="text-align: left;"> <code><a href="#topic+isCOP.LTD">isCOP.LTD</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Left-tail decreasing </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code>  </td><td style="text-align: left;"> <code><a href="#topic+isCOP.LTD">isCOP.LTD</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Right-tail increasing </td><td style="text-align: center;"> <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code>  </td><td style="text-align: left;"> <code><a href="#topic+isCOP.RTI">isCOP.RTI</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Right-tail increasing </td><td style="text-align: center;"> <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code>  </td><td style="text-align: left;"> <code><a href="#topic+isCOP.RTI">isCOP.RTI</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Pseudo-polar representation </td><td style="text-align: center;"> <code class="reqn">(\widehat{S},\widehat{W})</code> </td><td style="text-align: left;"> <code><a href="#topic+psepolar">psepolar</a></code> </td><td style="text-align: right;"> extremal dependency</td>
</tr>
<tr>
 <td style="text-align: left;">
Tail concentration function </td><td style="text-align: center;"> <code class="reqn">q_\mathbf{C}(t)</code> </td><td style="text-align: left;"> <code><a href="#topic+tailconCOP">tailconCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Tail (lower) dependency </td><td style="text-align: center;"> <code class="reqn">\lambda^L_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+taildepCOP">taildepCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Tail (upper) dependency </td><td style="text-align: center;"> <code class="reqn">\lambda^U_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+taildepCOP">taildepCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Tail (lower) order </td><td style="text-align: center;"> <code class="reqn">\kappa^L_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+tailordCOP">tailordCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Tail (upper) order </td><td style="text-align: center;"> <code class="reqn">\kappa^U_\mathbf{C}</code> </td><td style="text-align: left;"> <code><a href="#topic+tailordCOP">tailordCOP</a></code> </td><td style="text-align: right;"> bivariate tail association</td>
</tr>
<tr>
 <td style="text-align: left;">
Neg'ly quadrant dependency </td><td style="text-align: center;"> NQD </td><td style="text-align: left;"> <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Pos'ly quadrant dependency </td><td style="text-align: center;"> PQD </td><td style="text-align: left;"> <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code> </td><td style="text-align: right;"> bivariate association</td>
</tr>
<tr>
 <td style="text-align: left;">
Permutation symmetry </td><td style="text-align: center;"> <code class="reqn">\mathrm{permsym}</code> </td><td style="text-align: left;"> <code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code> </td><td style="text-align: right;"> copula symmetry</td>
</tr>
<tr>
 <td style="text-align: left;">
Radial symmetry </td><td style="text-align: center;"> <code class="reqn">\mathrm{radsym}</code> </td><td style="text-align: left;"> <code><a href="#topic+isCOP.radsym">isCOP.radsym</a></code> </td><td style="text-align: right;"> copula symmetry</td>
</tr>
<tr>
 <td style="text-align: left;">
Skewness (Joe, 2014) </td><td style="text-align: center;"> <code class="reqn">\eta(p; \psi)</code> </td><td style="text-align: left;"> <code><a href="#topic+uvskew">uvskew</a></code> </td><td style="text-align: right;"> bivariate skewness</td>
</tr>
<tr>
 <td style="text-align: left;">
Kullback--Leibler Divergence </td><td style="text-align: center;"> <code class="reqn">\mathrm{KL}(f \mid g)</code> </td><td style="text-align: left;"> <code><a href="#topic+kullCOP">kullCOP</a></code> </td><td style="text-align: right;"> bivariate inference</td>
</tr>
<tr>
 <td style="text-align: left;">
KL sample size </td><td style="text-align: center;"> <code class="reqn">n_{f\!g}</code> </td><td style="text-align: left;"> <code><a href="#topic+kullCOP">kullCOP</a></code> </td><td style="text-align: right;"> bivariate inference</td>
</tr>
<tr>
 <td style="text-align: left;">
The Vuong Procedure </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+vuongCOP">vuongCOP</a></code> </td><td style="text-align: right;"> bivariate inference</td>
</tr>
<tr>
 <td style="text-align: left;">
Spectral measure </td><td style="text-align: center;"> <code class="reqn">H(w)</code> </td><td style="text-align: left;"> <code><a href="#topic+spectralmeas">spectralmeas</a></code> </td><td style="text-align: right;"> extremal dependency inference</td>
</tr>
<tr>
 <td style="text-align: left;">
Stable tail dependence </td><td style="text-align: center;"> <code class="reqn">\widehat{l}(x,y)</code> </td><td style="text-align: left;"> <code><a href="#topic+stabtaildepf">stabtaildepf</a></code> </td><td style="text-align: right;"> extremal dependency inference</td>
</tr>
<tr>
 <td style="text-align: left;">
L-comoments (samp. distr.) </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code> </td><td style="text-align: left;"> <code><a href="#topic+lcomCOPpv">lcomCOPpv</a></code> </td><td style="text-align: right;"> experimental bivariate inference</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The <b>Table of Probabilities</b> that follows lists important relations between various joint probability concepts, the copula, nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code>, and exceedance probabilities <code class="reqn">u'</code> and <code class="reqn">v'</code>. A compact summary of these probability relations has obvious usefulness. The notation <code class="reqn">[\ldots, \ldots]</code> is to read as <code class="reqn">[\ldots \mathrm{\ and\ } \ldots]</code>, and the <code class="reqn">[\ldots \mid  \ldots]</code> is to be read as <code class="reqn">[\ldots \mathrm{\ given\ } \ldots]</code>.
</p>

<table>
<tr>
 <td style="text-align: right;">
<b>Probability</b> </td><td style="text-align: center;"> <b>and</b> </td><td style="text-align: left;"> <b>Symbol Convention</b></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U \le u, V \le v\,]</code>     </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\mathbf{C}(u,v)</code> --- The copula, <code><a href="#topic+COP">COP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U &gt; u, V &gt; v\,]</code>         </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\hat{\mathbf{C}}(u',v')</code> --- The survival copula, <code><a href="#topic+surCOP">surCOP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U \le u, V &gt; v\,]</code>       </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">u - \mathbf{C}(u,v')</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U &gt; u, V \le v\,]</code>       </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">v - \mathbf{C}(u',v)</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U \le u \mid V \le v\,]</code> </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\mathbf{C}(u,v)/v</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,V \le v \mid U \le u\,]</code> </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\mathbf{C}(u,v)/u</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U \le u \mid V &gt; v\,]</code>   </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\bigl(u - \mathbf{C}(u,v)\bigr)/(1 - v)</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,V \le v \mid U &gt; u\,]</code>   </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\bigl(v - \mathbf{C}(u,v)\bigr)/(1 - u)</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U &gt; u \mid V &gt; v\,]</code>   </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\hat{\mathbf{C}}(u',v')/u' = \overline{\mathbf{C}}(u,v)/(1-u)</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,V &gt; v \mid U &gt; u\,]</code>   </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\hat{\mathbf{C}}(u',v')/v' = \overline{\mathbf{C}}(u,v)/(1-v)</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,V \le v \mid U = u\,]</code>   </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\delta \mathbf{C}(u,v)/\delta u</code> --- Partial derivative, <code><a href="#topic+derCOP">derCOP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U \le u \mid V = v\,]</code>   </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\delta \mathbf{C}(u,v)/\delta v</code> --- Partial derivative, <code><a href="#topic+derCOP2">derCOP2</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U &gt; u \mathrm{\ or\ } V &gt; v\,]</code>     </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\mathbf{C}^\star(u',v') = 1 - \mathbf{C}(u',v')</code> --- The co-copula, <code><a href="#topic+coCOP">coCOP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">\mathrm{Pr}[\,U \le u \mathrm{\ or\ } V \le v\,]</code> </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\tilde{\mathbf{C}}(u,v) = u + v - \mathbf{C}(u,v)</code> --- The dual of a copula, <code><a href="#topic+duCOP">duCOP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">E[\,U \mid V = v\,]</code> </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\int_0^1 (1 - \delta \mathbf{C}(u,v)/\delta v)\,\mathrm{d}u</code> --- Expectation of U given V, <code><a href="#topic+EuvCOP">EuvCOP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
<code class="reqn">E[\,V \mid U = u\,]</code> </td><td style="text-align: center;"> <code class="reqn">=</code> </td><td style="text-align: left;"> <code class="reqn">\int_0^1 (1 - \delta \mathbf{C}(u,v)/\delta u)\,\mathrm{d}v</code> --- Expectation of V given U, <code><a href="#topic+EvuCOP">EvuCOP</a></code></td>
</tr>
<tr>
 <td style="text-align: right;">
</td>
</tr>

</table>

<p>The function <code><a href="#topic+jointCOP">jointCOP</a></code> has considerable demonstration in its <b>Note</b> section of the <b>joint and</b> and <b>joint or</b> relations shown through simulation and counting scenarios. Also there is a demonstration in the <b>Note</b> section of function <code><a href="#topic+duCOP">duCOP</a></code> on application of the concepts of <b>joint and</b> conditions, <b>joint or</b> conditions, and importantly joint <b>mutually exclusive or</b> conditions.
</p>
<p><b>Copula Construction Methods</b>
</p>
<p>Permutation asymmetry can be added to a copula by <code><a href="#topic+breveCOP">breveCOP</a></code>. One, two, or more copulas can be &ldquo;composited,&rdquo; &ldquo;combined,&rdquo; or &ldquo;multiplied&rdquo; in interesting ways to create highly unique bivariate relations and as a result, complex dependence structures can be formed. The package provides three main functions for copula composition: <code><a href="#topic+composite1COP">composite1COP</a></code> composites a single copula with two compositing parameters (<em>Khoudraji device</em> with <em>independence</em>), <code><a href="#topic+composite2COP">composite2COP</a></code> (<em>Khoudraji device</em>) composites two copulas with two compositing parameters, and <code><a href="#topic+composite3COP">composite3COP</a></code> composites two copulas with four compositing parameters. Also two copulas can be combined through a weighted convex combination using <code><a href="#topic+convex2COP">convex2COP</a></code> with a single weighting parameter, and even <code class="reqn">N</code> number of copulas can be combined by weights using <code><a href="#topic+convexCOP">convexCOP</a></code>. So-called &ldquo;gluing&rdquo; two copula by a parameter is provided by <code><a href="#topic+glueCOP">glueCOP</a></code>. Multiplication of two copulas to form a third is supported by <code><a href="#topic+prod2COP">prod2COP</a></code>. All eight functions for compositing, combining, or multipling copulas are compatible with joint probability simulation (<code><a href="#topic+simCOP">simCOP</a></code>), measures of association (<em>e.g.</em> <code class="reqn">\rho_\mathbf{C}</code>), and presumably all other copula operations using <span class="pkg">copBasic</span> features. Finally, <em>ordinal sums</em> of copula are provided by <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code> and <code><a href="#topic+ORDSUWcop">ORDSUWcop</a></code> as particularly interesting methods of combining copulas.
</p>

<table>
<tr>
 <td style="text-align: center;">
<b>No. of copulas</b> </td><td style="text-align: center;"> <b>Combining Parameters</b> </td><td style="text-align: left;"> <b>Function</b> </td><td style="text-align: right;"> <b>Concept</b></td>
</tr>
<tr>
 <td style="text-align: center;">
1 </td><td style="text-align: center;"> <code class="reqn">\beta</code> </td><td style="text-align: left;"> <code><a href="#topic+breveCOP">breveCOP</a></code> </td><td style="text-align: right;"> adding permuation asymmetry</td>
</tr>
<tr>
 <td style="text-align: center;">
1 </td><td style="text-align: center;"> <code class="reqn">\alpha, \beta</code> </td><td style="text-align: left;"> <code><a href="#topic+composite1COP">composite1COP</a></code> </td><td style="text-align: right;"> copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
1 </td><td style="text-align: center;"> <code class="reqn">\alpha, \beta</code> </td><td style="text-align: left;"> <code><a href="#topic+khoudraji1COP">khoudraji1COP</a></code> </td><td style="text-align: right;"> copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
1 </td><td style="text-align: center;"> <code class="reqn">\alpha, \beta</code> </td><td style="text-align: left;"> <code><a href="#topic+khoudrajiPCOP">khoudrajiPCOP</a></code> </td><td style="text-align: right;"> copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: center;"> <code class="reqn">\alpha, \beta</code> </td><td style="text-align: left;"> <code><a href="#topic+composite2COP">composite2COP</a></code> </td><td style="text-align: right;"> copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: center;"> <code class="reqn">\alpha, \beta</code> </td><td style="text-align: left;"> <code><a href="#topic+khoudraji2COP">khoudraji2COP</a></code> </td><td style="text-align: right;"> copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: center;"> <code class="reqn">\alpha, \beta, \kappa, \gamma</code> </td><td style="text-align: left;"> <code><a href="#topic+composite3COP">composite3COP</a></code> </td><td style="text-align: right;"> copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: center;"> <code class="reqn">\alpha, (1-\alpha)</code> </td><td style="text-align: left;"> <code><a href="#topic+convex2COP">convex2COP</a></code> </td><td style="text-align: right;"> weighted copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
<code class="reqn">N</code> </td><td style="text-align: center;"> <code class="reqn">\omega_{i \in N}</code> </td><td style="text-align: left;"> <code><a href="#topic+convexCOP">convexCOP</a></code> </td><td style="text-align: right;"> weighted copula combination</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: center;"> <code class="reqn">\gamma</code> </td><td style="text-align: left;"> <code><a href="#topic+glueCOP">glueCOP</a></code> </td><td style="text-align: right;"> gluing of coupla</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: center;"> <code class="reqn">\bigl(\mathbf{C}_1 \ast \mathbf{C}_2 \bigr)</code> </td><td style="text-align: left;"> <code><a href="#topic+prod2COP">prod2COP</a></code> </td><td style="text-align: right;"> copula multiplication</td>
</tr>
<tr>
 <td style="text-align: center;">
<code class="reqn">N</code> </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}_{\mathcal{J}i}</code> for <code class="reqn">\mathcal{J}_{i \in N}</code> partitions </td><td style="text-align: left;"> <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code> </td><td style="text-align: right;"> <code><a href="#topic+M">M</a></code>-ordinal sums of copulas</td>
</tr>
<tr>
 <td style="text-align: center;">
<code class="reqn">N</code> </td><td style="text-align: center;"> <code class="reqn">\mathbf{C}_{\mathcal{J}i}</code> for <code class="reqn">\mathcal{J}_{i \in N}</code> partitions </td><td style="text-align: left;"> <code><a href="#topic+ORDSUWcop">ORDSUWcop</a></code> </td><td style="text-align: right;"> <code><a href="#topic+W">W</a></code>-ordinal sums of copulas</td>
</tr>
<tr>
 <td style="text-align: center;">
</td>
</tr>

</table>

<p><b>Useful Copula Relations by Visualization</b>
</p>
<p>There are a myriad of relations amongst variables computable through copulas, and these were listed in the <b>Table of Probabilities</b> earlier in this documentation. There is a script located in the <code>inst/doc</code> directory of the <span class="pkg">copBasic</span> sources titled <code>CopulaRelations_BaseFigure_inR.txt</code>. This script demonstrates, using the <code><a href="#topic+PSP">PSP</a></code> copula, relations between the copula (<code><a href="#topic+COP">COP</a></code>), survival copula (<code><a href="#topic+surCOP">surCOP</a></code>), joint survival function of a copula (<code><a href="#topic+surfuncCOP">surfuncCOP</a></code>), co-copula (<code><a href="#topic+coCOP">coCOP</a></code>), and dual of a copula function (<code><a href="#topic+duCOP">duCOP</a></code>). The script performs simulation and manual counts observations meeting various criteria in order to compute their <em>empirical probabilities</em>. The script produces a base figure, which after extending in editing software, is suitable for educational description and is provided at the end of this documentation.<br /><br />
</p>
<p><b>A Review of &ldquo;Return Periods&rdquo; using Copulas</b>
</p>
<p>Risk analyses of natural hazards are commonly expressed as <em>annual return periods</em> <code class="reqn">T</code> in years, which are defined for a nonexceedance probability <code class="reqn">q</code> as <code class="reqn">T = 1/(1-q)</code>. In bivariate analysis, there immediately emerge two types of return periods representing <code class="reqn">T_{q;\,\mathrm{coop}}</code> and <code class="reqn">T_{q;\,\mathrm{dual}}</code> conditions between nonexceedances of the two hazard sources (random variables) <code class="reqn">U</code> and <code class="reqn">V</code>. It is usual in many applications for <code class="reqn">T</code> to be expressed equivalently as a probability <code class="reqn">q</code> in common for both variables.
</p>
<p>Incidentally, the <code class="reqn">\mathrm{Pr}[\,U &gt; u \mid V &gt; v\,]</code> and <code class="reqn">\mathrm{Pr}[\,V &gt; v \mid U &gt; u\,]</code> probabilities also are useful for <em>conditional return period</em> computations following Salvadori <em>et al.</em> (2007, pp. 159&ndash;160) but are not further considered here. Also the <code class="reqn">F_K(w)</code> (<em>Kendall Function</em> or <em>Kendall Measure</em> of a copula) is the core tool for <em>secondary return period</em> computations (see <code><a href="#topic+kfuncCOP">kfuncCOP</a></code>).
</p>
<p>Let the copula <code class="reqn">\mathbf{C}(u,v; \Theta)</code> for nonexceedances <code class="reqn">u</code> and <code class="reqn">v</code> be set for some copula family (formula) by a parameter vector <code class="reqn">\Theta</code>. The copula family and parameters define the joint coupling (loosely meant the dependency/correlation) between hazards <code class="reqn">U</code> and <code class="reqn">V</code>. If &ldquo;failure&rdquo; occurs if <b>either</b> or <b>both</b> hazards <code class="reqn">U</code> and <code class="reqn">V</code> are at probability <code class="reqn">q</code> threshold (<code class="reqn">u = v = 1 - 1/T = q</code>) for <code class="reqn">T</code>-year return period, then the <b>real return period</b> of failure is defined using either the copula <code class="reqn">\mathbf{C}(q,q; \Theta)</code> or the <em>co-copula</em> <code class="reqn">\mathbf{C}^\star(q',q'; \Theta)</code> for exceedance probability <code class="reqn">q' = 1 - q</code> is
</p>
<p style="text-align: center;"><code class="reqn">T_{q;\,\mathrm{coop}} = \frac{1}{1 - \mathbf{C}(q, q; \Theta)} = \frac{1}{\mathbf{C}^\star(1-q, 1-q; \Theta)}\mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">T_{q;\,\mathrm{coop}} \equiv \frac{1}{\mathrm{cooperative\ risk}}\mbox{.}</code>
</p>

<p>Or in words, the hazard sources <b>collaborate</b> or <b>cooperate</b> to cause failure. If failure occurs,  however, if and only if <b>both</b> hazards <code class="reqn">U</code> and <code class="reqn">V</code> occur simultaneously (the hazards must &ldquo;dually work together&rdquo; or be &ldquo;conjunctive&rdquo;), then the <b>real return period</b> is defined using either the <em>dual of a copula (function)</em> <code class="reqn">\tilde{\mathbf{C}}(q,q; \Theta)</code>, the <em>joint survival function</em> <code class="reqn">\overline{\mathbf{C}}(q,q;\Theta)</code>, or <em>survival copula</em> <code class="reqn">\hat{\mathbf{C}}(q',q'; \Theta)</code> as
</p>
<p style="text-align: center;"><code class="reqn">T_{q;\,\mathrm{dual}} = \frac{1}{1 - \tilde{\mathbf{C}}(q,q; \Theta)} = \frac{1}{\overline{\mathbf{C}}(q,q;\Theta)} = \frac{1}{\hat{\mathbf{C}}(q',q';\Theta)} \mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">T_{q;\,\mathrm{dual}} \equiv \frac{1}{\mathrm{complement\ of\ dual\ protection}}\mbox{.}</code>
</p>

<p>Numerical demonstration is informative. Salvadori <em>et al.</em> (2007, p. 151) show for a <em>Gumbel&ndash;Hougaard copula</em> (<code><a href="#topic+GHcop">GHcop</a></code>) having <code class="reqn">\Theta =</code> 3.055 and <code class="reqn">T =</code> 1,000 years (<code class="reqn">q = 0.999</code>) that <code class="reqn">T_{q;\,\mathrm{coop}} = 797.1</code> years and that <code class="reqn">T_{q;\,\mathrm{dual}}</code> = 1,341.4 years, which means that average return periods between &ldquo;failures&rdquo; are
</p>
<p style="text-align: center;"><code class="reqn">T_{q;\,\mathrm{coop}} \le T \le T_{q;\,\mathrm{dual}}\mbox{\ and thus}</code>
</p>

<p style="text-align: center;"><code class="reqn">797.1 \le T \le 1314.4\mbox{\ years.}</code>
</p>

<p>With the following code, these bounding return-period values are readily computed and verified using the <code>prob2T()</code> function from the <span class="pkg">lmomco</span> package along with <span class="pkg">copBasic</span> functions <code><a href="#topic+COP">COP</a></code> (generic functional interface to a copula) and <code><a href="#topic+duCOP">duCOP</a></code> (<em>dual of a copula</em>):
</p>
<pre>
  q &lt;- lmomco::T2prob(1000)
  lmomco::prob2T(  COP(q,q, cop=GHcop, para=3.055)) #  797.110
  lmomco::prob2T(duCOP(q,q, cop=GHcop, para=3.055)) # 1341.438
</pre>
<p>An early source (in 2005) by some of those authors cited on p. 151 of Salvadori <em>et al.</em> (2007; their citation &ldquo;[67]&rdquo;) shows <code class="reqn">T_{q;\,\mathrm{dual}} = 798</code> years&mdash;a rounding error seems to have been committed. Finally just for reference, a Gumbel&ndash;Hougaard copula having <code class="reqn">\Theta = 3.055</code> corresponds to an analytical <em>Kendall Tau</em> (see <code><a href="#topic+GHcop">GHcop</a></code>) of <code class="reqn">\tau \approx 0.673</code>, which can be verified through numerical integration available from <code><a href="#topic+tauCOP">tauCOP</a></code> as:
</p>
<pre>
  tauCOP(cop=GHcop, para=3.055, brute=TRUE) # 0.6726542
</pre>
<p>Thus, a &ldquo;better understanding of the statistical characteristics of [multiple hazard sources] requires the study of their joint distribution&rdquo; (Salvadori <em>et al.</em>, 2007, p. 150).
</p>
<p><b>Interaction of copBasic to Copulas in Other Packages</b>
</p>
<p>Originally, the <span class="pkg">copBasic</span> package was not intended to be a port of the numerous bivariate copulas or over re-implementation other bivariate copulas available in <span class="rlang"><b>R</b></span> though as the package passed its 10th year in 2018, the original intent changed. It is useful to point out a demonstration showing an implementation of the <em>Gaussian copula</em> from the <span class="pkg">copula</span> package, which is shown in the <b>Note</b> section of <code><a href="#topic+med.regressCOP">med.regressCOP</a></code> in a circumstance of ordinary least squares linear regression compared to <em>median regression</em> of a copula as well as prediction limits of both regressions. Another demonstration in context of <em>maximum pseudo-log-likelihood estimation</em> of copula parameters is seen in the <b>Note</b> section <code><a href="#topic+mleCOP">mleCOP</a></code>, and also see &ldquo;<b>API to the copula package</b>&rdquo; or &ldquo;<b>package copula (comparison to)</b>&rdquo; entries in the Index of this user manual.
</p>
<p><img src="../help/figures/CopulaRelationsFigure4pkg.jpg" alt="CopulaRelationsFigure4pkg.jpg" />

</p>


<h3>Author(s)</h3>

<p>William Asquith <a href="mailto:william.asquith@ttu.edu">william.asquith@ttu.edu</a></p>


<h3>References</h3>

<p>Cherubini, U., Luciano, E., and Vecchiato, W., 2004, Copula methods in finance: Hoboken, NJ, Wiley, 293 p.
</p>
<p>Hernández-Maldonado, V., Díaz-Viera, M., and Erdely, A., 2012, A joint stochastic simulation method using the Bernstein copula as a flexible tool for modeling nonlinear dependence structures between petrophysical properties: Journal of Petroleum Science and Engineering, v. 90&ndash;91, pp. 112&ndash;123.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Hofert, M., Kojadinovic, I., Mächler,  M., and Yan, J., 2018, Elements of copula modeling with R: Dordrecht, Netherlands, Springer.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in nature&mdash;An approach using copulas: Dordrecht, Netherlands, Springer, Water Science and Technology Library 56, 292 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Nelsen (2006, p. 75, exer. 3.15b) provides for a nice test of copBasic features.
"mcdurv" &lt;- function(u,v, theta) {
   ifelse(u &gt; theta &amp; u &lt; 1-theta &amp; v &gt; theta &amp; v &lt; 1 - theta,
             return(M(u,v) - theta), # Upper bounds copula with a shift
             return(W(u,v)))         # Lower bounds copula
}
"MCDURV" &lt;- function(u,v, para=NULL) {
   if(is.null(para))         stop("need theta")
   if(para &lt; 0 | para &gt; 0.5) stop("theta ! in [0, 1/2]")
   return(asCOP(u, v, f=mcdurv, para))
}
"afunc" &lt;- function(t) { # a sample size = 1,000 hard wired
   return(cov(simCOP(n=1000, cop=MCDURV, para=t, ploton=FALSE, points=FALSE))[1,2])
}
set.seed(6234) # setup covariance based on parameter "t" and the "root" parameter
print(uniroot(afunc, c(0, 0.5))) # "t" by simulation = 0.1023742
# Nelsen reports that if theta appox. 0.103 then covariance of U and V is zero.
# So, one will have mutually completely dependent uncorrelated uniform variables!

# Let us check some familiar measures of association:
rhoCOP( cop=MCDURV, para=0.1023742) # Spearman Rho = 0.005854481 (near zero)
tauCOP( cop=MCDURV, para=0.1023742) # Kendall Tau  = 0.2648521
wolfCOP(cop=MCDURV, para=0.1023742) # S &amp; W Sigma  = 0.4690174 (less familiar)
D &lt;- simCOP(n=1000, cop=MCDURV, para=0.1023742) # Plot mimics Nelsen (2006, fig. 3.11)
# Lastly, open research problem. L-comoments (matrices) measure high dimension of
# variable comovements (see lmomco package)---"method of L-comoments" for estimation?
lmomco::lcomoms2(simCOP(n=1000, cop=MCDURV, para=0),   nmom=5) # Perfect neg. corr.
lmomco::lcomoms2(simCOP(n=1000, cop=MCDURV, para=0.1023742), nmom=5)
lmomco::lcomoms2(simCOP(n=1000, cop=MCDURV, para=0.5), nmom=5) # Perfect pos. corr.
# T2 (L-correlation), T3 (L-coskew), T4 (L-cokurtosis), and T5 matrices result. For
# Theta = 0 or 0.5 see the matrix symmetry with a sign change for L-coskew and T5 on
# the off diagonals (offdiags). See unities for T2. See near zero for offdiag terms
# in T2 near zero. But then see that T4 off diagonals are quite different from those
# for Theta 0.1024 relative to 0 or 0.5. As a result, T4 has captured a unique
# property of U vs V.
## End(Not run)
</code></pre>

<hr>
<h2 id='aicCOP'>Akaike Information Criterion between a Fitted Coupla and an Empirical Copula</h2><span id='topic+aicCOP'></span>

<h3>Description</h3>

<p>Compute the <em>Akaike information criterion</em> (AIC) <code class="reqn">\mathrm{AIC}_\mathbf{C}</code> (Chen and Guo, 2019, p. 29), which is computed using <em>mean square error</em> <code class="reqn">\mathrm{MSE}_\mathbf{C}</code> as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{MSE}_\mathbf{C} = \frac{1}{n}\sum_{i=1}^n \bigl(\mathbf{C}_n(u_i,v_i) - \mathbf{C}_{\Theta_m}(u_i, v_i)\bigr)^2\mbox{ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathrm{AIC}_\mathbf{C} = 2m + n\log(\mathrm{MSE}_\mathbf{C})\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}_n(u_i,v_i)</code> is the <em>empirical copula</em> (empirical joint probability) for the <code class="reqn">i</code>th observation, <code class="reqn">\mathbf{C}_{\Theta_m}(u_i, v_i)</code> is the fitted copula having <code class="reqn">m</code> parameters in <code class="reqn">\Theta</code>. The <code class="reqn">\mathbf{C}_n(u_i,v_i)</code> comes from <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>. The <code class="reqn">\mathrm{AIC}_\mathbf{C}</code> is in effect saying that the best copula will have its joint probabilities plotting on a 1:1 line with the empirical joint probabilities, which is an <code class="reqn">\mathrm{AIC}_\mathbf{C} = -\infty</code>. From the <code class="reqn">\mathrm{MSE}_\mathbf{C}</code> shown above, the root mean square error <code><a href="#topic+rmseCOP">rmseCOP</a></code> and Bayesian information criterion (BIC) <code><a href="#topic+bicCOP">bicCOP</a></code> can be computed. These goodness-of-fits can assist in deciding one copula favorability over another, and another goodness-of-fit using the absolute differences between <code class="reqn">\mathbf{C}_n(u,v)</code> and <code class="reqn">\mathbf{C}_{\Theta_m}(u, v)</code> is found under <code><a href="#topic+statTn">statTn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aicCOP(u, v=NULL, cop=NULL, para=NULL, m=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aicCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="aicCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; If not given, then a second column from argument <code>u</code> is attempted;</p>
</td></tr>
<tr><td><code id="aicCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="aicCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="aicCOP_+3A_m">m</code></td>
<td>
<p>The number of parameters in the copula, which is usually determined by length of <code>para</code> if <code>m=NA</code>, but some complex compositions of copulas are difficult to authoritatively probe for total parameter lengths and mixing coefficients; and</p>
</td></tr>
<tr><td><code id="aicCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to either copula (likely most commonly to the empirical copula).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\mathrm{AIC}_\mathbf{C}</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Chen, Lu, and Guo, Shenglian, 2019, Copulas and its application in hydrology and water resources: Springer Nature, Singapore, ISBN 978&ndash;981&ndash;13&ndash;0574&ndash;0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+bicCOP">bicCOP</a></code>, <code><a href="#topic+rmseCOP">rmseCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  S &lt;- simCOP(80, cop=GHcop, para=5) # Simulate some probabilities, but we
  # must then treat these as data and recompute empirical probabilities.
  U &lt;- lmomco::pp(S$U, sort=FALSE); V &lt;- lmomco::pp(S$V, sort=FALSE)
  # The parent distribution is Gumbel-Hougaard extreme value copula, but in practical
  # applications, we do not know that. Say we speculate that perhaps the Galambos extreme
  # value might be the parent; maximum likelihood is used to fit the single parameter.
  pGL  &lt;- mleCOP(  U,V, cop=GLcop, interval=c(0, 20))$par
  aics &lt;- c(aicCOP(U,V, cop=GLcop, para=pGL), aicCOP(U,V, cop=P), aicCOP(U,V, cop=PSP))
  names(aics) &lt;- c("GLcop", "P", "PSP")
  print(aics) # We will see that the first AIC is the smallest because the
  # Galambos has the nearest overall behavior than the P and PSP copulas.
## End(Not run)
</code></pre>

<hr>
<h2 id='AMHcop'>The Ali&ndash;Mikhail&ndash;Haq Copula</h2><span id='topic+AMHcop'></span>

<h3>Description</h3>

<p>The <em>Ali&ndash;Mikhail&ndash;Haq copula</em> (Nelsen, 2006, pp. 92&ndash;93, 172) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{AMH}(u,v) = \frac{uv}{1 - \Theta(1-u)(1-v)}\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [-1,+1)</code>, where the right boundary,
<code class="reqn">\Theta = 1</code>, can sometimes be considered valid according to Mächler (2014). The copula <code class="reqn">\Theta \rightarrow 0</code> becomes the <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>), and the parameter <code class="reqn">\Theta</code> is readily computed from a <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = \frac{3\Theta - 2}{3\Theta} -
                        \frac{2(1-\Theta)^2\log(1-\Theta)}{3\Theta^2}\mbox{,}</code>
</p>

<p>and by <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>), through Mächler (2014), by
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = \sum_{k=1}^\infty \frac{3\Theta^k}{{k + 2 \choose 2}^2}\mbox{.}</code>
</p>

<p>The support of <code class="reqn">\tau_\mathbf{C}</code> is <code class="reqn">[(5 - 8\log(2))/3, 1/3] </code> <code class="reqn">\approx</code> <code class="reqn">[-0.1817258, 0.3333333]</code> and the <code class="reqn">\rho_\mathbf{C}</code> is <code class="reqn">[33 - 48\log(2), 4\pi^2 - 39]</code> <code class="reqn">\approx</code> <code class="reqn">[-0.2710647, 0.4784176]</code>, which shows that this copula has a limited range of dependency. The infinite summation is easier to work with than
Nelsen (2006, p. 172) definition of
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = \frac{12(1+\Theta)}{\Theta^2}\mathrm{dilog}(1-\Theta)-
                        \frac{24(1-\Theta)}{\Theta^2}\log(1-\Theta)-
                        \frac{3(\Theta+12)}{\Theta}\mbox{,}</code>
</p>

<p>where the <code class="reqn">\mathrm{dilog(x)}</code> is the dilogarithm function defined by
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{dilog}(x) = \int_1^x \frac{\log(t)}{1-t}\,\mathrm{d}t\mbox{.}</code>
</p>

<p>The integral version has more nuances with approaches toward <code class="reqn">\Theta = 0</code> and <code class="reqn">\Theta = 1</code> than the infinite sum version.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AMHcop(u, v, para=NULL, rho=NULL, tau=NULL, fit=c("rho", "tau"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AMHcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="AMHcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="AMHcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula. However, if a second parameter is present, it is treated as a logical to reverse the copula (<code class="reqn">u + v - 1 + \mathbf{AMH}(1-u,1-v; \Theta)</code>);</p>
</td></tr>
<tr><td><code id="AMHcop_+3A_rho">rho</code></td>
<td>
<p>Optional Spearman Rho from which the parameter will be estimated and presence of <code>rho</code> trumps <code>tau</code>;</p>
</td></tr>
<tr><td><code id="AMHcop_+3A_tau">tau</code></td>
<td>
<p>Optional Kendall Tau from which the parameter will be estimated;</p>
</td></tr>
<tr><td><code id="AMHcop_+3A_fit">fit</code></td>
<td>
<p>If <code>para</code>, <code>rho</code>, and <code>tau</code> are all <code>NULL</code>, the the <code>u</code> and <code>v</code> represent the sample. The measure of association by the <code>fit</code> declaration will be computed and the parameter estimated subsequently. The <code>fit</code> has not other utility than to trigger which measure of association is computed internally by the <code>cor</code> function in <span class="rlang"><b>R</b></span>; and</p>
</td></tr>
<tr><td><code id="AMHcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned. Otherwise if <code>tau</code> is given, then the <code class="reqn">\Theta</code> is computed and a <code>list</code> having
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The parameter <code class="reqn">\Theta</code>, and</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Kendall Tau.</p>
</td></tr>
</table>
<p>and if <code>para=NULL</code> and <code>tau=NULL</code>, then the values within <code>u</code> and <code>v</code> are used to compute Kendall Tau and then compute the parameter, and these are returned in the aforementioned list.
</p>


<h3>Note</h3>

<p>Mächler (2014) reports on accurate computation of <code class="reqn">\tau_\mathbf{C}</code> and <code class="reqn">\rho_\mathbf{C}</code> for this copula for conditions of <code class="reqn">\Theta \rightarrow 0</code> and in particular derives the following equation, which does not have <code class="reqn">\Theta</code> in the denominator:
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = \sum_{k=1}^{\infty} \frac{3\Theta^k}{{k+2 \choose 2}^2}\mbox{.}</code>
</p>

<p>The <span class="pkg">copula</span> package provides a Taylor series expansion for <code class="reqn">\tau_\mathbf{C}</code> for small <code class="reqn">\Theta</code> in the <code>copula::tauAMH()</code>. This is demonstrated here between the implementation of <code class="reqn">\tau = 0</code> for parameter estimation in the <span class="pkg">copBasic</span> package to that in the more sophisticated implementation in the <span class="pkg">copula</span> package.
</p>
<pre>
  copula::tauAMH(AMHcop(tau=0)$para) # theta = -2.313076e-07
</pre>
<p>It is seen that the numerical approaches yield quite similar results for small <code class="reqn">\tau_\mathbf{C}</code>, and finally, a comparison to the <code class="reqn">\rho_\mathbf{C}</code> is informative:
</p>
<pre>
  rhoCOP(AMHcop, para=1E-9)    # 3.333333e-10 (two nested integrations)
  copula:::.rhoAmhCopula(1E-9) # 3.333333e-10 (cutoff based)
  theta &lt;- seq(-1,1, by=.0001)
  RHOa &lt;- sapply(theta, function(t) rhoCOP(AMHcop, para=t))
  RHOb &lt;- sapply(theta, function(t) copula:::.rhoAmhCopula(t))
  plot(10^theta, RHOa-RHOb, type="l", col=2)
</pre>
<p>The plot shows that the apparent differences are less than 1 part in 100 million&mdash;The <span class="pkg">copBasic</span> computation is radically slower though, but <code><a href="#topic+rhoCOP">rhoCOP</a></code> was designed for generality of copula family.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Mächler, Martin, 2014, Spearman's Rho for the AMH copula&mdash;A beautiful formula: copula package vignette, accessed on April 7, 2018, at <a href="https://CRAN.R-project.org/package=copula">https://CRAN.R-project.org/package=copula</a> under the vignette <em>rhoAMH-dilog.pdf</em>.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Pranesh, Kumar, 2010, Probability distributions and estimation of Ali&ndash;Mikhail&ndash;Haq copula: Applied Mathematical Sciences, v. 4, no. 14, p. 657&ndash;666.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+P">P</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  t &lt;- 0.9 # The Theta of the copula and we will compute Spearman Rho.
  di &lt;- integrate(function(t) log(t)/(1-t), lower=1, upper=(1-t))$value
  A &lt;- di*(1+t) - 2*log(1-t) + 2*t*log(1-t) - 3*t # Nelsen (2007, p. 172)
  rho &lt;- 12*A/t^2 - 3    # 0.4070369
  rhoCOP(AMHcop, para=t) # 0.4070369
  sum(sapply(1:100, function(k) 3*t^k/choose(k+2, 2)^2)) # Machler (2014)
  # 0.4070369 (see Note section, very many tens of terms are needed) 
## End(Not run)

## Not run: 
  layout(matrix(1:2, byrow=TRUE)) # Note: Kendall Tau is same on reversal.
  s &lt;- 2; set.seed(s); nsim &lt;- 10000
  UVn &lt;- simCOP(nsim, cop=AMHcop, para=c(-0.9, "FALSE" ), col=4)
  mtext("Normal definition [default]") # '2nd' parameter could be skipped
  set.seed(s) # seed used to keep Rho/Tau inside attainable limits
  UVr &lt;- simCOP(nsim, cop=AMHcop, para=c(-0.9, "TRUE"),   col=2)
  mtext("Reversed definition")
  AMHcop(UVn[,1], UVn[,2], fit="rho")$rho # -0.2581653
  AMHcop(UVr[,1], UVr[,2], fit="rho")$rho # -0.2570689
  rhoCOP(cop=AMHcop, para=-0.9)           # -0.2483124
  AMHcop(UVn[,1], UVn[,2], fit="tau")$tau # -0.1731904
  AMHcop(UVr[,1], UVr[,2], fit="tau")$tau # -0.1724820
  tauCOP(cop=AMHcop, para=-0.9)           # -0.1663313 
## End(Not run)
</code></pre>

<hr>
<h2 id='asCOP'>Wrapper on a User-Level Formula to Become a Copula Function</h2><span id='topic+asCOP'></span>

<h3>Description</h3>

<p>This function is intended to document and then to extend a simple API to end users to aid in implementation of other copulas for use within the <span class="pkg">copBasic</span> package. There is no need or requirement to use <code>asCOP</code> for almost all users. However, for the mathematical definition of some copulas, the <code>asCOP</code> function might help considerably. This is because there is a need for special treatment of <code class="reqn">u</code> and <code class="reqn">v</code> vectors of probability as each interacts with the vectorization implicit in <span class="rlang"><b>R</b></span>. The special treatment is needed because many copulas are based on the operators such as <code>min()</code> and <code>max()</code>. When numerical integration used by the <code>integrate()</code> function in <span class="rlang"><b>R</b></span> in some copula operators, such as <code><a href="#topic+tauCOP">tauCOP</a></code> for the <em>Kendall Tau</em> of a copula, special accommodation is needed related to the inherent vectorization in <span class="rlang"><b>R</b></span> and how <code>integrate()</code> works.
</p>
<p>Basically, the problem is that one can not strictly rely in all circumstances on what <span class="rlang"><b>R</b></span> does in terms of value recycling when <code class="reqn">u</code> and <code class="reqn">v</code> are of unequal lengths. The source code is straightforward. Simply put, if lengths of <code class="reqn">u</code> and <code class="reqn">v</code> are unity, then there is no concern, and even if the length of <code class="reqn">u</code> (say) is unity and <code class="reqn">v</code> is 21, then recycling of <code class="reqn">u</code> would often be okay. The real danger is when <code class="reqn">u</code> and <code class="reqn">v</code> have unequal lengths and those lengths are each greater than unity&mdash;the <span class="rlang"><b>R</b></span> treatment can not be universally relied upon with the various numerics herein involving optimization and nested numerical integration.
</p>
<p>The example shows how a formula definition of a copula that is not a copula already implemented by <span class="pkg">copBasic</span> is set into a function <code>deltacop</code> and then used inside another function <code>UsersCop</code> that will be the official copula that is compatible with a host of functions in <span class="pkg">copBasic</span>. The use of <code>asCOP</code> provides the length check necessary on <code class="reqn">u</code> and <code class="reqn">v</code>, and the argument <code>...</code> provides optional parameter support should the user's formula require more settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asCOP(u, v, f=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="asCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="asCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="asCOP_+3A_f">f</code></td>
<td>
<p>A function for which the user desires to make as a copula; and</p>
</td></tr>
<tr><td><code id="asCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the function <code>f</code> (such as parameters, if needed, for the copula in the form of a list).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Concerning Nelsen (2006, exer. 3.7, pp. 64--65)
  "trianglecop" &lt;- function(u,v, para=NULL, ...) {
     # If para is set, then the triangle is rotated 90d clockwise.
     if(! is.null(para) &amp;&amp; para == 1) { t &lt;- u; u &lt;- v; v &lt;- t }
     if(length(u) &gt; 1 | length(v) &gt; 1) stop("only scalars for this function")
     v2&lt;-v/2; if(0   &lt;= u    &amp;  u   &lt;= v2 &amp; v2 &lt;= 1/2) { return(u    )
     } else   if(0   &lt;= v2   &amp; v2   &lt;  u  &amp;  u &lt; 1-v2) { return(v2   )
     } else   if(1/2 &lt;= 1-v2 &amp; 1-v2 &lt;= u  &amp;  u &lt;= 1  ) { return(u+v-1)
     } else { stop("should not be here in logic") }
  }
  "UsersCop" &lt;- function(u,v, ...) { asCOP(u,v, f=trianglecop, ...) }
  n=20000; UV &lt;- simCOP(n=n, cop=UsersCop)
  # The a-d elements of the problem now follow:
  # (a) Pr[V = 1 - |2*U -1|] = 1 and Cov(U,V) = 0; so that two random variables
  # can be uncorrelated but each is perfectly predictable from the other
  mean(UV$V - (1 - abs(2*UV$U -1))) # near zero; Nelsen says == 0
  cov(UV$U, UV$V)                   # near zero; Nelsen says == 0

  # (b) Cop(m,n) = Cop(n,m); so that two random variables can be identically
  # distributed, uncorrelated, and not exchangeable
  EMPIRcop(0.95,0.17, para=UV) # = A
  EMPIRcop(0.17,0.95, para=UV) # = B; then A != B

  # (c) Pr[V - U &gt; 0] = 2/3; so that two random variables can be identically
  # distributed, but their difference need not be symmetric about zero
  tmp &lt;- (UV$V - UV$U) &gt; 0
  length(tmp[tmp == TRUE])/n # about 2/3; Nelsen says == 2/3
  # the prior two lines yield about 1/2 for independence copula P()

  # (d) Pr[X + Y &gt; 0] = 2/3; so that uniform random variables on (-1,1) can each
  # be symmetric about zero, but their sum need not be.
  tmp &lt;- ((2*UV$V - 1) + (2*UV$U - 1)) &gt; 0
  length(tmp[tmp == TRUE])/n # about 2/3; Nelsen says == 2/3 
## End(Not run)

## Not run: 
  # Concerning Nelsen (2006, exam. 3.10, p. 73)
  "shufflecop" &lt;- # assume scalar arguments for u and v
  function(u,v, para, ...) {
     m &lt;- para$mixer; subcop &lt;- para$subcop
     if(is.na(m) | m &lt;= 0 | m &gt;= 1) stop("m ! in [0,1]")
     if(u &lt;= m) { return(    subcop(1-m+u, v, para=para$para) -
                             subcop(1-m,   v, para=para$para))
     } else {     return(v - subcop(1-m,   v, para=para$para) +
                             subcop(u-m,   v, para=para$para))
     }
  }
  "UsersCop" &lt;- function(u,v, para=NULL) {
     asCOP(u,v, f=shufflecop, para=para)
  }
  n &lt;- 1000; u &lt;- runif(n)
  para &lt;- list(mixer=runif(1), subcop=W, para=20)
  v &lt;- sapply(1:n, function(i) {
      simCOPmicro(u[i], cop=UsersCop, para=para) } )
  plot(data.frame(U=u, V=v), pch=17, col=rgb(1,0,1,1),
     xlab="U, NONEXCEEDANCE PROBABILTY", ylab="V, NONEXCEEDANCE PROBABILITY")
  mtext("Shuffle Copula Nelsen (2006, exam. 3.10, p. 73)")

  # Concerning Nelsen (2006, exam. 5.14, p. 195)
  "deltacop" &lt;- function(u,v, ...) { min(c(u,v,(u^2+v^2)/2))     }
  "UsersCop" &lt;- function(u,v, ...) { asCOP(u,v, f=deltacop, ...) }
  isCOP.PQD(cop=UsersCop) # TRUE + Rho=0.288 and Tau=0.333 as Nelsen says
  isCOP.LTD(cop=UsersCop, wrtV=TRUE) # FALSE as Nelsen says
  isCOP.RTI(cop=UsersCop, wrtV=TRUE) # FALSE as Nelsen says 
## End(Not run)
</code></pre>

<hr>
<h2 id='bicCOP'>Bayesian Information Criterion between a Fitted Coupla and an Empirical Copula</h2><span id='topic+bicCOP'></span>

<h3>Description</h3>

<p>Compute the <em>Bayesian information criterion</em> (BIC) <code class="reqn">\mathrm{BIC}_\mathbf{C}</code> (Chen and Guo, 2019, p. 29), which is computed using <em>mean square error</em> <code class="reqn">\mathrm{MSE}_\mathbf{C}</code> as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{MSE}_\mathbf{C} = \frac{1}{n}\sum_{i=1}^n \bigl(\mathbf{C}_n(u_i,v_i) - \mathbf{C}_{\Theta_m}(u_i, v_i)\bigr)^2\mbox{ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathrm{BIC}_\mathbf{C} = m\log(n) + n\log(\mathrm{MSE}_\mathbf{C})\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}_n(u_i,v_i)</code> is the <em>empirical copula</em> (empirical joint probability) for the <code class="reqn">i</code>th observation, <code class="reqn">\mathbf{C}_{\Theta_m}(u_i, v_i)</code> is the fitted copula having <code class="reqn">m</code> parameters in <code class="reqn">\Theta</code>. The <code class="reqn">\mathbf{C}_n(u_i,v_i)</code> comes from <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>. The <code class="reqn">\mathrm{BIC}_\mathbf{C}</code> is in effect saying that the best copula will have its joint probabilities plotting on a 1:1 line with the empirical joint probabilities, which is an <code class="reqn">\mathrm{BIC}_\mathbf{C} = -\infty</code>. From the <code class="reqn">\mathrm{MSE}_\mathbf{C}</code> shown above, the root mean square error <code><a href="#topic+rmseCOP">rmseCOP</a></code> and Akaike information criterion (AIC) <code><a href="#topic+aicCOP">aicCOP</a></code> can be computed. These goodness-of-fits can assist in deciding on one copula favorability over another, and another goodness-of-fit using the absolute differences between <code class="reqn">\mathbf{C}_n(u,v)</code> and <code class="reqn">\mathbf{C}_{\Theta_m}(u, v)</code> is found under <code><a href="#topic+statTn">statTn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicCOP(u, v=NULL, cop=NULL, para=NULL, m=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bicCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="bicCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; If not given, then a second column from argument <code>u</code> is attempted;</p>
</td></tr>
<tr><td><code id="bicCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="bicCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="bicCOP_+3A_m">m</code></td>
<td>
<p>The number of parameters in the copula, which is usually determined by length of <code>para</code> if <code>m=NA</code>, but some complex compositions of copulas are difficult to authoritatively probe for total parameter lengths and mixing coefficients; and</p>
</td></tr>
<tr><td><code id="bicCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to either copula (likely most commonly to the empirical copula).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\mathrm{BIC}_\mathbf{C}</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Chen, Lu, and Guo, Shenglian, 2019, Copulas and its application in hydrology and water resources: Springer Nature, Singapore, ISBN 978&ndash;981&ndash;13&ndash;0574&ndash;0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+aicCOP">aicCOP</a></code>, <code><a href="#topic+rmseCOP">rmseCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
S &lt;- simCOP(80, cop=GHcop, para=5) # Simulate some probabilities, but we
# must then treat these as data and recompute empirical probabilities.
U &lt;- lmomco::pp(S$U, sort=FALSE); V &lt;- lmomco::pp(S$V, sort=FALSE)
# The parent distribution is Gumbel-Hougaard extreme value copula.
# But in practical application we don't know that but say we speculate that
# perhaps the Galambos extreme value might be the parent. Then maximum
# likelihood is used on that copula to fit the single parameter.
pGL &lt;- mleCOP(U,V, cop=GLcop, interval=c(0,20))$par

bics &lt;- c(bicCOP(U,V, cop=GLcop, para=pGL), bicCOP(U,V, cop=P), bicCOP(U,V, cop=PSP))
names(bics) &lt;- c("GLcop", "P", "PSP")
print(bics) # We will see that the first BIC is the smallest as the
# Galambos has the nearest overall behavior than the P and PSP copulas.
## End(Not run)
</code></pre>

<hr>
<h2 id='bicoploc'>Analog to Line of Organic Correlation by Copula Diagonal</h2><span id='topic+bicoploc'></span>

<h3>Description</h3>

<p><em>HIGHLY EXPERIMENTAL AND SUBJECT TO OVERHAUL OR REMOVAL</em>&mdash;Compute an analog to the <em>line of organic correlation</em> (<em>reduced major axis</em>) using the <em>diagonal</em> of a copula.
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le u, V \le v] = \mathbf{C}(u,v) = f\mbox{.}</code>
</p>

<p>The primary diagonal is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{\delta}_\mathbf{C}(t) = \mathbf{C}(t,t) = f\mbox{.}</code>
</p>

<p>Two diagnostic plots can be plotted by the arguments available for this function. The plot for <code class="reqn">(U,V)</code> coordinate nonexceedance probability domain along with the analyses involving the copula diagonal inversion comes first, which is followed by that for <code class="reqn">(X,Y)</code> coordinate domain along with the well-known line of organic correlation by the method of L-moments and such a &ldquo;line&rdquo; (could be a curve) by copula diagonal inversion.
</p>
<p>This much infrastructure written for flexibility in how a copula would interact for the purpose of estimation with moment preservation. The simple <code class="reqn">u = v</code> might be sufficient but let us have some flexibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicoploc(xp, yp=NULL, xout=NA, xpara=NULL, ypara=NULL, dtypex="nor", dtypey="nor",
         ctype=c("weibull", "hazen", "bernstein", "checkerboard"), kumaraswamy=TRUE,
         plotuv=TRUE, plotxy=TRUE, adduv=FALSE, addxy=FALSE, snv=FALSE, limout=TRUE,
         autoleg=TRUE, xleg="topleft", yleg=NULL, rugxy=TRUE, ruglwd=0.5,
         xlim=NULL, ylim=NULL, titleuv="", titlexy="", titlecex=1,
         a=0, ff=pnorm(seq(-5, +5, by=0.1)), locdigits=6,
         paracop=TRUE, verbose=TRUE, x=NULL, y=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bicoploc_+3A_xp">xp</code></td>
<td>
<p>Numeric vector giving paired data points of <code class="reqn">X</code>. If this is a matrix or data frame, then the first and second columns are extracted for the <code>xp</code> and <code>yp</code> internall;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_yp">yp</code></td>
<td>
<p>Optional numeric vector giving paired data points of <code class="reqn">Y</code> depending on the composition of <code>x</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_xout">xout</code></td>
<td>
<p>An optional set of numeric values specifying where interpolation through the diagonal inversion is to take place;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_xpara">xpara</code></td>
<td>
<p>An <span class="pkg">lmomco</span> package parameter object for the <code class="reqn">X</code> variable, which if not provided will trigger an method of L-moment parameter estimation for the distribution <code>dtypex</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_ypara">ypara</code></td>
<td>
<p>An <span class="pkg">lmomco</span> package parameter object for the <code class="reqn">Y</code> variable, which if not provided will trigger an method of L-moment parameter estimation for the distribution <code>dtypey</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_dtypex">dtypex</code></td>
<td>
<p>The <span class="pkg">lmomco</span> package distribution abbreviations (see <code>lmomco::dist.list()</code>) for the <code class="reqn">X</code> variable. If this argument is set <code>NULL</code> and <code>xpara</code> is given with an element of <code>type</code>, then that distribution type is assigned internally to <code>dtypex</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_dtypey">dtypey</code></td>
<td>
<p>The <span class="pkg">lmomco</span> package distribution abbreviations (see <code>lmomco::dist.list()</code>) for the <code class="reqn">Y</code> variable; If this argument is set <code>NULL</code> and <code>xpara</code> is given with an element of <code>type</code>, then that distribution type is assigned internally to <code>dtypex</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_ctype">ctype</code></td>
<td>
<p>Argument of the same name for the empirical copula for dispatch to <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>. The <code>1/n</code> form is disabled for <code>bicoploc</code> operations based on limited experiments. The first letter of the argument's value is extracted, converted to upper case, and used as the plotting character in the two diagnostic plots;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_kumaraswamy">kumaraswamy</code></td>
<td>
<p>A logical to trigger Kumaraswamy distribution smoothing of the copula diagonal inversion from the <em>empricial copula</em>. The Kumaraswamy distribution is a distribution having support <code class="reqn">[0,1]</code> with an explicit quantile function and takes the place of a Beta distribution (see <span class="pkg">lmomco</span> function <code>quakur()</code> for more details). The smoothing by Kumaraswamy will provide a continuous real number on the interval, which should insure no flat-lining as one rolls on to or off off the discrete interval provided by the empirical copula for expected sample sizes of the operations anticipated for the <code>bicoploc</code> function;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_plotuv">plotuv</code></td>
<td>
<p>A logical to trigger plotting of the analyses in the <code class="reqn">(U,V)</code> coordinate nonexceedance probability domain along with the analyses involving the copula diagonal inversion. If set true, then <code>adduv</code> is set false internally;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_plotxy">plotxy</code></td>
<td>
<p>A logical to trigger plotting of the analyses in the <code class="reqn">(X,Y)</code> coordinate domain along with the well-known line of organic correlation by the method of L-moments and such a &ldquo;line&rdquo;  (could be a curve) by copula diagonal inversion. If set true, then <code>addxy</code> is set false internally;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_adduv">adduv</code></td>
<td>
<p>A logical when set true will not call the <code>plot()</code> function for <code class="reqn">(U,V)</code> coordinate nonexceedance probability domain but the other graphical operations of lines and points will be called;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_addxy">addxy</code></td>
<td>
<p>A logical when set true will not call the <code>plot()</code> function for <code class="reqn">(X,Y)</code> coordinate domain but the other graphical operations of lines and points will be called;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_snv">snv</code></td>
<td>
<p>A logical when set true will plot the <code class="reqn">(U,V)</code> coordinate nonexceedance probability domain in units of standard normal variates;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_limout">limout</code></td>
<td>
<p>A logical when set true will plot the <code class="reqn">(X,Y)</code> coordinate domain with horizontal and vertical axis limits inflated to the <code>xout</code> and <code class="reqn">Y</code> predictions;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_autoleg">autoleg</code></td>
<td>
<p>A logical when set will draw a legend for the plots if the plots are requested;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_xleg">xleg</code></td>
<td>
<p>The value to become the argument <code>x</code> in the <code>legend()</code> call. The default setting is based on general assumption that this <code>bicoploc()</code> function is to be more commonly used in positive assocation circumstances between <code class="reqn">X</code> and <code class="reqn">Y</code> (positive Spearman Rho);</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_yleg">yleg</code></td>
<td>
<p>The value to become the argument <code>y</code> in the <code>legend()</code> call;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_rugxy">rugxy</code></td>
<td>
<p>Call <code>rug()</code> plotting operations on the <code class="reqn">X</code> and <code class="reqn">Y</code> values used in the parameter estimation of the parametric marginal distributions using the <code>xp</code> and <code>yp</code>, unless either or both have been overridden for the contents in <code>x</code> and (or) <code>y</code> arguments;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_ruglwd">ruglwd</code></td>
<td>
<p>The line wide passed into <code>rug()</code>. Because plotting of small and large sample sizes can make it difficult in the smaller samples to see the line, it is judged useful to explicitly have this setting as an declared argument;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_xlim">xlim</code></td>
<td>
<p>A numeric vector that if precisely of length 2 and no missing values therein, will override the horizontal limits of the <code>plotxy</code> plot of the <code class="reqn">(X,Y)</code> domain. Otherwise, the contents of <code>xlim</code>, if not null, are inserted into a range computation for the limits to apply;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_ylim">ylim</code></td>
<td>
<p>A numeric vector that if precisely of length 2 and no missing values therein, will override the vertical limits of the <code>plotxy</code> plot of the <code class="reqn">(X,Y)</code> domain. Otherwise, the contents of <code>ylim</code>, if not null, are inserted into a range computation for the limits to apply;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_titleuv">titleuv</code></td>
<td>
<p>An optional title for the <code class="reqn">(U,V)</code> domain plot;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_titlexy">titlexy</code></td>
<td>
<p>An optional title for the <code class="reqn">(X,Y)</code> domain plot;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_titlecex">titlecex</code></td>
<td>
<p>The character expansion factor for the titles;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_a">a</code></td>
<td>
<p>Value for the plotting-position formula for <code>lmomco::pp()</code>, default is <code>a=0</code>, which specifies <em>Weibull plotting positions</em>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_ff">ff</code></td>
<td>
<p>The nonexceedance joint probability of of the copula diagonal from which inversion computes the marginal nonexceedance probability values for <code class="reqn">u=v=t</code> as <code class="reqn">\mathbf{C}(t,t) = f</code> where <code>ff</code> is the variable notation for the joint probability <code class="reqn">f</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_locdigits">locdigits</code></td>
<td>
<p>Number of digits for rounding exclusive to the <code>loc</code> data frame produced in the returned list. The reasoning for this setting is that the expected application in practical circumstances will have discipline knowledge of the rounding depth suitable;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_paracop">paracop</code></td>
<td>
<p>A logical trigging the use of the parametric asymmetric copula fit by numerical optimization to the <code class="reqn">(U,V)</code> domain of the data (see <b>Details</b>);</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_verbose">verbose</code></td>
<td>
<p>Show messages of incremental progress with a incremental counter on the message;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_x">x</code></td>
<td>
<p>Numeric vector of <code class="reqn">X</code> values to be used in parameter estimation of the marginal parametric distribution if <code>xpara=NULL</code> and these values are internally replaced with <code>xp</code> (paired <code class="reqn">X</code>) if not otherwise specified. This provides the ability to insert an alternative and presumably longer vector of the entire <code class="reqn">X</code> sample without the restriction of individual values paired to the <code class="reqn">Y</code>. A feature unique to providing the <code>x</code> is that missing values can be and are removed on the fly prior to parameter estimation of the marginal distribution. The <code>x</code> can be specific independent of <code>y</code> or even at all for either. Absolutely no provision is made that <code>x</code> can be a matrix or data frame holding the <code>y</code>;</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_y">y</code></td>
<td>
<p>Numeric vector of <code class="reqn">Y</code> values to be used in parameter estimation of the marginal parametric distribution if <code>ypara=NULL</code> and these values are internally replaced with <code>yp</code> (paired <code class="reqn">Y</code>) if not otherwise specified. This provides the ability to insert an alternative and presumably longer vector of the entire <code class="reqn">Y</code> sample without the restriction of individual values paired to the <code class="reqn">X</code>. A feature unique to providing the <code>y</code> is that missing values can be and are removed on the fly prior to parameter estimation of the marginal distribution. The <code>x</code> can be specific independent of <code>y</code> or even at all for either; and</p>
</td></tr>
<tr><td><code id="bicoploc_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>ON THE USE OF AN PARAMETRIC ASYMMETRIC COPULA</em>&mdash;
</p>


<h3>Value</h3>

<p>Lists, vectors, and data frames for the computations and predictions are returned.
</p>
<table role = "presentation">
<tr><td><code>organic</code></td>
<td>
<p>A list containing a data frame of the predictions for <code>xout</code> by the conventional LOC (<code>locpair</code>) (see also <code>locsols$lmrloc</code>), the estimates by the L-moments of the parameters of the marginal distributions (<code>locpara</code>), the estimates by copula diagonal with Kumaraswamy smoothing (if requested) (<code>bicoploc</code>), and the predictions based solely on the empirical copula approximation for the diagonal (<code>bicoploc_emp</code>). The <code>bicoploc</code> and <code>bicoploc_emp</code> are equal to each other if Kumaraswamy was not used. The <code>bicoploc</code> is intended to be the official output from the <code>bicoploc()</code> function. The furthest right column is <code>bicoploc_cop</code> and represents the predicting values using a parametric copula as fit to the <code class="reqn">(U,V)</code> domain mapped into the <code class="reqn">(X,Y)</code> domain as explained elsewhere in this documentation or sources;</p>
</td></tr>
<tr><td><code>locsols</code></td>
<td>
<p>A list of solutions to the LOC based (1) (<code>locpair</code>) on the conventional definition on the paired data (<code>xp</code> and <code>yp</code>) with the finiteness check previously described by <code>lmomco::lmrloc()</code> and (2) (<code>locpara</code>) the LOC solution <em>not on the paired data</em> but extractable from the L-moments of the parameters for the marginal distributions. Certain permutations of available features will either have the two L-moment solutions equal, or just the slopes equal, or differing in both intercept and slope. The <code>lmrloc</code> list contains both L-moment and product moment estimation of the LOC to adhere precisely to <code>lmomco::lmrloc()</code> output;</p>
</td></tr>
<tr><td><code>xpara</code></td>
<td>
<p>The parameters of the marginal distribution in <code class="reqn">X</code> either as given in <code>xpara</code>, as estimated from <code>xp</code>, or estimated from <code>x</code> by the method of L-moments through the <span class="pkg">lmomco</span> package;</p>
</td></tr>
<tr><td><code>ypara</code></td>
<td>
<p>The parameters of the marginal distribution in <code class="reqn">Y</code> either as given in <code>ypara</code>, as estimated from <code>yp</code>, or estimated from <code>y</code> by the method of L-moments through the <span class="pkg">lmomco</span> package;</p>
</td></tr>
<tr><td><code>faqs</code></td>
<td>
<p>A named vector containing some numerical facts about the operations and principally the requisite sample sizes involved are reported here;</p>
</td></tr>
<tr><td><code>faqscop</code></td>
<td>
<p>A named vector containing some numerical facts about the operations involving the fitting of the parametric asymmetric copula (Plackett by default) to the <code class="reqn">(U,V)</code> domain; and</p>
</td></tr>
<tr><td><code>diag</code></td>
<td>
<p>A data frame containing information on the copula diagonal including the joint probability column <code>jtprob</code> (the <code>ff</code> as stand in for <code class="reqn">C(t,t) = f</code>), the <code class="reqn">u=v=t</code> in column <code>uv</code> by the Kumaraswamy smooth (if requested), and the solely empirical copula version in column <code>uv_emp</code>. If the Kumaraswamy smooth is not used, then <code>uv</code> and <code>uv_emp</code> will be equal to each other. The furthest right column is <code>uv_cop</code> and represents the values using a parametric copula as fit to the <code class="reqn">(U,V)</code> domain as explained elsewhere in this documentation or sources.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The use of a copula diagonal inversion for purposes of a line of organic correlation analog within the text-book literature and elsewhere is unknown to the developers (December 2023).
</p>
<p>Though <code>bicoploc</code> has extensive logic for working through the copula diagonal, if we know the parent distribution and we just have the marginal probabilities equal to each other (the diagonal), then we recover the moments of <code class="reqn">Y</code> simply with <code class="reqn">u = v</code>:
</p>
<pre>
  library(lmomco)
  ff    &lt;- c(0.0001, seq(0.001, 0.999, by=0.001), 0.9999)
  xpara &lt;- lmomco::vec2par(c(3, 0.6, -0.4), type="pe3")
  ypara &lt;- lmomco::vec2par(c(3, 0.4, +0.6), type="pe3")
  xx &lt;-   rlmomco(100000,  xpara)
  yy &lt;- approx(qlmomco(ff, xpara), qlmomco(ff, ypara), xout=xx)$y
  lmr2par(yy, type="aep4")$para
  #        mu     sigma     gamma
  # 2.9972742 0.3993914 0.5980866
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kruskal, W.H., 1953, On the uniqueness of the line of organic correlation: Biometrics, vol. 9, no. 1, pp. 47&ndash;58, <a href="https://doi.org/10.2307/3001632">doi:10.2307/3001632</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOPatf">diagCOPatf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># paracop set to FALSE in these examples for speed
set.seed(4); nsim &lt;- 50
X  &lt;- rnorm(nsim, mean=3, sd=0.6)
Y  &lt;- rnorm(nsim, mean=0, sd=0.2)
zz &lt;- bicoploc(X,Y, xout=c(2.5, 3.5, 4), dtypex="nor", dtypey="nor",   paracop=FALSE)
# cor(X,Y, method="spearman") # +0.0785114 POSITIVE

set.seed(1); nsim &lt;- 50
X  &lt;- rnorm(nsim, mean=3, sd=0.6)
Y  &lt;- rnorm(nsim, mean=0, sd=0.2)
zz &lt;- bicoploc(X,Y, xout=c(2.5, 3.5, 4), dtypex="nor", dtypey="nor",   paracop=FALSE)
# cor(X,Y, method="spearman") # -0.1351741 NEGATIVE

set.seed(1); nsim &lt;- 50
X  &lt;-           rnorm(nsim, mean=3, sd=0.6)
Y  &lt;- 0.843*X + rnorm(nsim, mean=0, sd=0.2)
zz &lt;- bicoploc(X,Y, xout=c(2.5, 3.5, 4), dtypex="nor", dtypey="nor",   paracop=FALSE)
# cor(X,Y, method="spearman") # for nsim=1E6 RHO=0.92367

set.seed(1); nsim &lt;- 50
X  &lt;-           lmomco::rlmomco(nsim, lmomco::vec2par(c(3, 0.6, +0.5), type="pe3"))
Y  &lt;- 0.3*X^2 + lmomco::rlmomco(nsim, lmomco::vec2par(c(0, 0.4, 0),    type="pe3"))
zz &lt;- bicoploc(X,Y, xout=c(2.5, 3.5, 4.5), dtypex="nor", dtypey="nor", paracop=FALSE)
# cor(X,Y, method="spearman") # for nsim=1E6 RHO=0.92366

set.seed(1); nsim &lt;- 50
X  &lt;-           lmomco::rlmomco(nsim, lmomco::vec2par(c(3, 0.6, +0.5), type="pe3"))
Y  &lt;- 0.3*X^2 + lmomco::rlmomco(nsim, lmomco::vec2par(c(0, 0.4, 0),    type="pe3"))
zz &lt;- bicoploc(X,Y, xout=c(2.5, 3.5, 4.5), dtypex="gev", dtypey="gev", paracop=FALSE)

## Not run: 
########################################################################################
# Image 800 samples in X and Y and though created as pairs, let us assume only
# 50 are actually paired for purposes of demonstration of specified parameters
# and (or) alternative x and y vectors providing the larger sample.
set.seed(1); nsim &lt;- 800; npair &lt;- 50
X  &lt;-           lmomco::rlmomco(nsim, lmomco::vec2par(c(3, 0.6, +0.5), type="pe3"))
Y  &lt;- 0.3*X^2 + rnorm(nsim, mean=0, sd=0.3)
ix &lt;- sample(seq_len(nsim), npair, replace=FALSE)
Xp &lt;- X[ix]; Yp &lt;- Y[ix]; dtypex &lt;- "gev"; dtypey &lt;- "gev"
xpara &lt;- lmomco::lmr2par(X, type=dtypex); ypara &lt;- lmomco::lmr2par(Y, type=dtypey)

# The next two bicoploc() calls produce identical results except for the density
# of data points along the axes for the rug plots. Ultimately, the same parameter
# estimates for the margins exists for both calls. The plotuv is disabled so that
# the user can tab between the two plotxy plots and see that they are the same.
zz &lt;- bicoploc(Xp,Yp, xout=c(2.5, 3.5, 4.5), ruglwd=0.9, plotuv=FALSE,
               xpara=xpara, ypara=ypara, dtypex=NULL, dtypey=NULL)
mtext("Example of specific xpara and ypara from larger sample", line=0.5)

zz &lt;- bicoploc(Xp,Yp, xout=c(2.5, 3.5, 4.5), ruglwd=0.9, plotuv=FALSE,
               xpara=xpara, ypara=ypara, dtypex=NULL, dtypey=NULL, x=X, y=Y)
mtext("Example of specific xpara and ypara from larger sample", line=0.5) #
## End(Not run)

## Not run: 
########################################################################################
set.seed(1); nsim &lt;- 50
UV &lt;- rCOP(nsim, cop=breveCOP, para=list(cop=W, alpha=0, beta=0))
X  &lt;- qnorm(UV[,1], mean=3, sd=0.6)
Y  &lt;- qnorm(UV[,2], mean=2, sd=0.2)
zz &lt;- bicoploc(X,Y, xout=c(1.5, 2.5, 3.5, 4), dtypex="nor", dtypey="nor")

set.seed(1); nsim &lt;- 50
UV &lt;- rCOP(nsim, cop=breveCOP, para=list(cop=W, alpha=0, beta=0.5))
X  &lt;- qnorm(UV[,1], mean=3, sd=0.6)
Y  &lt;- qnorm(UV[,2], mean=2, sd=0.2)
zz &lt;- bicoploc(X,Y, xout=c(1.5, 2.5, 3.5, 4), dtypex="nor", dtypey="nor")

set.seed(1); nsim &lt;- 50
UV &lt;- rCOP(nsim, cop=breveCOP, para=list(cop=M_N5p12b, para=3, alpha=0, beta=0.5))
X  &lt;- qnorm(UV[,1], mean=3, sd=0.6)^2
Y  &lt;- qnorm(UV[,2], mean=2, sd=0.2)
zz &lt;- bicoploc(X,Y, xout=c(1.5, 2.5, 3.5, 4), ylim=c(1,2.5),
                    xleg="bottomleft", dtypex="aep4", dtypey="nor")

# A TRUE COUNTER EXAMPLE? Are the 1-v operations not sufficient depending on
# rotation? Is the secondary diagonal of a copula useful? Is there something wrong
# with the reflection operations as implemented at the end of November 2023?
# Should negatives be turned into positives by reversing Y within the internal logic?
# The solution current at end of November 2023 seems proper.
set.seed(1); nsim &lt;- 500
para &lt;- list(cop1=W, para1=4, cop2=GHcop, para2=c(30,.6, .9), alpha=0, beta=0.1)
UV &lt;- rCOP(nsim, cop=composite2COP, para=para)
X  &lt;- -qexp(UV[,1], rate=10)+0.1 # Or the problem is a reflected exponential but the
Y  &lt;- qnorm(UV[,2], mean=2, sd=0.2)  # exp version in lmomco can not handle
zz &lt;- bicoploc(X,Y, xout=c(-0.05, 0, 0.2), dtypex="exp", dtypey="nor")
# Possibly, try another distribution.
zz &lt;- bicoploc(X,Y, xout=c(-0.3, -0.2, 0), ylim=c(1,4), dtypex="aep4", dtypey="nor") #
## End(Not run)

## Not run: 
########################################################################################
set.seed(1); nsim &lt;- 200; npair &lt;- 30
para &lt;- list(cop=PLcop, para=80, alpha=0.3, beta=0.05)
UV &lt;- rCOP(nsim, cop=composite1COP, para=para, resamv01=TRUE)
X  &lt;- lmomco::qlmomco(UV[,1], lmomco::vec2par(c(3, 0.6, +0.4), type="pe3"))
Y  &lt;- lmomco::qlmomco(UV[,2], lmomco::vec2par(c(3, 0.4, +0.0), type="pe3"))
ix &lt;- sample(seq_len(nsim), npair, replace=FALSE)
Xp &lt;- X[ix]; Yp &lt;- Y[ix]; dtypex &lt;- "pe3"; dtypey &lt;- "pe3"
xpara &lt;- lmomco::lmr2par(X, type=dtypex); ypara &lt;- lmomco::lmr2par(Y, type=dtypey)
plot(10^X, 10^Y, log="xy", las=1, pch=21, lwd=0.8, col="black", bg="white",
                 xlab="SOME RISK PHENOMENON IN X-DIRECTION",
                 ylab="SOME RISK PHENOMENON IN Y-DIRECTION")
xout &lt;- c(1.5, 2.5, 3.5, 4)
xlim &lt;- c(1.5, 4.5); ylim &lt;- c(1.8, 5.0)
zz &lt;- bicoploc(Xp,Yp, xout=xout,xpara=xpara,ypara=ypara,  xlim=xlim,ylim=ylim)

zz &lt;- bicoploc(Xp,Yp, xout=xout,xpara=xpara,ypara=ypara,  xlim=xlim,ylim=ylim,x=X,y=Y)
zz &lt;- bicoploc(Xp,Yp, xout=xout,dtypex="pe3",dtypey="pe3",xlim=xlim,ylim=ylim,x=X,y=Y)

zz &lt;- bicoploc(X, Y,  xout=xout,dtypex="pe3",dtypey="pe3",xlim=xlim,ylim=ylim)#
## End(Not run)
</code></pre>

<hr>
<h2 id='bilmoms'>Bivariate L-moments and L-comoments of a Copula</h2><span id='topic+bilmoms'></span>

<h3>Description</h3>

<p><b>Attention:</b> This function is deprecated in favor of <code><a href="#topic+lcomCOP">lcomCOP</a></code>, which uses only direct numerical <code>integrate()</code> on the integrals shown below. The <code>bilmoms</code> function is strictly based on Monte Carlo integration.
</p>
<p>Compute the <em>bivariate L-moments (ratios)</em> (<code class="reqn">\delta^{[\ldots]}_{k;\mathbf{C}}</code>) of a copula <code class="reqn">\mathbf{C}(u,v; \Theta)</code> and remap these into the <em>L-comoment</em> matrix counterparts (Serfling and Xiao, 2007; Asquith, 2011) including <em>L-correlation</em> (<em>Spearman Rho</em>), <em>L-coskew</em>, and <em>L-cokurtosis</em>.  As described by Brahimi <em>et al.</em> (2015), the first four bivariate L-moments <code class="reqn">\delta^{[12]}_k</code> for random variable <code class="reqn">X^{(1)}</code> or <code class="reqn">U</code> with respect to (<em>wrt</em>) random variable <code class="reqn">X^{(2)}</code> or <code class="reqn">V</code> are defined as
</p>
<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{1;\mathbf{C}} = 2\int\!\!\int_{\mathcal{I}^2}
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{2;\mathbf{C}} = \int\!\!\int_{\mathcal{I}^2}
(12v - 6)
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{3;\mathbf{C}} = \int\!\!\int_{\mathcal{I}^2}
(60v^2 - 60v + 12)
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{4;\mathbf{C}} = \int\!\!\int_{\mathcal{I}^2}
(280v^3 - 420v^2 + 180v - 20)
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{,}</code>
</p>

<p>where the bivariate L-moments are related to the L-comoment ratios by
</p>
<p style="text-align: center;"><code class="reqn">6\delta^{[12]}_k = \tau^{[12]}_{k+1}\mbox{\quad and \quad}6\delta^{[21]}_k = \tau^{[21]}_{k+1}\mbox{,}</code>
</p>

<p>where in otherwords, &ldquo;the third bivariate L-moment <code class="reqn">\delta^{[12]}_3</code> is one sixth the L-cokurtosis <code class="reqn">\tau^{[12]}_4</code>.&rdquo; The first four bivariate L-moments yield the first five L-comoments (there is no first order L-comoment ratio). The terms and nomenclature are not easy and also the English grammar adjective &ldquo;ratios&rdquo; is not always consistent in the literature. The <code class="reqn">\delta^{[\ldots]}_{k;\mathbf{C}}</code> are <b>ratios</b>, and the returned <code>bilcomoms</code> element by this function holds matrices for the marginal means, marginal L-scales and L-coscales, and then the <b>ratio</b> L-comoments.
</p>
<p>Similarly, the <code class="reqn">\delta^{[21]}_k</code> are computed by switching <code class="reqn">u \rightarrow v</code> in the polynomials within the above integrals multiplied to the copula in the system of equations with <code class="reqn">u</code>. In general, <code class="reqn">\delta^{[12]}_k \not= \delta^{[21]}_k</code> for <code class="reqn">k &gt; 1</code> unless in the case of <em>permutation symmetric</em> (<code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>) copulas. By theory, <code class="reqn">\delta^{[12]}_1 = \delta^{[21]}_1 = \rho_\mathbf{C}/6</code> where <code class="reqn">\rho_\mathbf{C}</code> is a <em>Spearman Rho</em> <code><a href="#topic+rhoCOP">rhoCOP</a></code>.
</p>
<p>The integral for <code class="reqn">\delta^{[12]}_{4;\mathbf{C}}</code> does not appear in Brahimi <em>et al.</em> (2015) but this and the other forms are verified in the <b>Examples</b> and discussion in <b>Note</b>. The four <code class="reqn">k \in [1,2,3,4]</code> for <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> and <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> comprise a full spectrum of system of seven (not eight) equations. One equation is lost because <code class="reqn">\delta^{[12]}_1 = \delta^{[21]}_1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bilmoms(cop=NULL, para=NULL, only.bilmoms=FALSE, n=1E5,
                  sobol=TRUE, scrambling=0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bilmoms_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="bilmoms_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="bilmoms_+3A_only.bilmoms">only.bilmoms</code></td>
<td>
<p>A logical to trigger return of the <code class="reqn">\delta_k</code> and skip L-comoment computation;</p>
</td></tr>
<tr><td><code id="bilmoms_+3A_n">n</code></td>
<td>
<p>The Monte Carlo integration size. The default seems to be at least an order of magnitude greater than needed for many applied problems;</p>
</td></tr>
<tr><td><code id="bilmoms_+3A_sobol">sobol</code></td>
<td>
<p>A logical trigging <em>Sobol sequences</em> for the Monte Carlo integration instead of the bivariate uniform distribution (independence). The Sobol sequences are dependent on the <code>sobol()</code> function of the <span class="pkg">randtoolbox</span> package, and the Sobol sequences canvas the <code class="reqn">\mathcal{I}^2</code> domain for smaller <code class="reqn">n</code> values than required if statistical independence is used for the Monte Carlo integration. Note, <span class="pkg">randtoolbox</span> at least at version 2.0.+ has &ldquo;scrambling&rdquo; of Sobol sequences temporarily disabled, and hence <code>scrambling=0</code> as default for <code>bilmoms</code>;</p>
</td></tr>
<tr><td><code id="bilmoms_+3A_scrambling">scrambling</code></td>
<td>
<p>The argument of the same name for <code>randtoolbox::sobol()</code>; and</p>
</td></tr>
<tr><td><code id="bilmoms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+densityCOP">densityCOP</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> of the bivariate L-moments is returned.
</p>
<table role = "presentation">
<tr><td><code>bilmomUV</code></td>
<td>
<p>The bivariate L-moments <code class="reqn">\delta^{[12]}_k</code> of <code class="reqn">U</code> with respect to <code class="reqn">V</code> for <code class="reqn">k \in [1,2,3,4]</code>;</p>
</td></tr>
<tr><td><code>bilmomVU</code></td>
<td>
<p>The bivariate L-moments <code class="reqn">\delta^{[21]}_k</code> of <code class="reqn">V</code> with respect to <code class="reqn">U</code> for <code class="reqn">k \in [1,2,3,4]</code>;</p>
</td></tr>
<tr><td><code>error.rho</code></td>
<td>
<p>An &ldquo;error&rdquo; term in units of <code class="reqn">\delta^{[12 \&amp; 21]}_1</code> used to judge whether the sample size for the Monte Carlo integration is sufficient based on a comparison to the <em>Spearman Rho</em> from direct numerical integration (not Monte Carlo based) using <code><a href="#topic+rhoCOP">rhoCOP</a></code> of the copula. Values for <code>error.rho</code> <code class="reqn">&lt; 1E{-}5</code> seem to be sufficient to judge whether <code>n</code> is large enough;</p>
</td></tr>
<tr><td><code>bilcomoms</code></td>
<td>
<p>If not <code>only.bilmoms</code>, another <span class="rlang"><b>R</b></span> <code>list</code> holding the L-comoments (see <b>Note</b>) computed by simple remapping of the <code class="reqn">\delta^{[\ldots]}_k</code> and parallel in structure to the function <code>lcomoms2()</code> of the <span class="pkg">lmomco</span> package; and</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the bivariate L-moments and bivariate L-comoments: &ldquo;bilmoms.&rdquo;</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The mapping of the bivariate L-moments to their L-comoment matrix counterparts is simple but nuances should be discussed and the meaning of the <code>error.rho</code> needs further description.  The extra effort to form L-comoment matrices (Serfling and Xiao, 2007; Asquith, 2011) is made so that output matches the structure of the sample L-comoment matrices from the <code>lcomoms2()</code> function of the <span class="pkg">lmomco</span> package.
</p>
<p>Concerning the triangular or tent-shaped copula of Nelsen (2006, exer. 3.7, pp. 64&ndash;65) for demonstration, simulate from the triangular copula a sample of size <code class="reqn">m = 20{,}000</code> and compute some sample L-comoments using the following CPU intensive code. The function <code><a href="#topic+asCOP">asCOP</a></code> completes the vectorization needed for non-Monte Carlo integration for <code><a href="#topic+rhoCOP">rhoCOP</a></code>.
</p>
<pre>
  "trianglecop" &lt;- function(u,v, para=NULL, ...) {
    # If para is set, then the triangle is rotated 90d clockwise.
    if(! is.null(para) &amp;&amp; para == 1) { t &lt;- u; u &lt;- v; v &lt;- t }
    if(length(u) &gt; 1 | length(v) &gt; 1) stop("only scalars for this function")
    v2&lt;-v/2; if(0   &lt;= u    &amp; u    &lt;= v2 &amp; v2 &lt;= 1/2) { return(u    )
    } else   if(0   &lt;=   v2 &amp;   v2 &lt;  u  &amp;  u &lt; 1-v2) { return(v2   )
    } else   if(1/2 &lt;= 1-v2 &amp; 1-v2 &lt;= u  &amp;  u &lt;= 1  ) { return(u+v-1)
    } else { stop("should not be here in logic") }
  }
  "TriCop" &lt;- function(u,v, ...) { asCOP(u,v, f=trianglecop, ...) }
  m=20000; SampleUV &lt;- simCOP(n=m, cop=TriCop, graphics=FALSE)
  samLC  &lt;- lcomoms2(SampleUV, nmom=5)
  theoLC &lt;- bilmoms(cop=TriCop)
</pre>
<p><em>The Error in Rho Computation</em>&mdash;The <code class="reqn">\rho_\mathbf{C}</code> of the copula by numerical integration is computed internally to <code>bilmoms</code> as
</p>
<pre>
  rhoC &lt;- rhoCOP(cop=TriCop) # -1.733858e-17
</pre>
<p>and used to compute the <code>error.rho</code> for <code>bilmoms</code> (see next code snippet). The  <code class="reqn">\rho_\mathbf{C}</code> is obviously zero for this copula. Therefore, the bivariate association of <code>TriCop</code> is zero and thus is an example of a perfectly dependent situation yet of zero correlation. The bivariate L-moments and L-comoments of this copula are computed as
</p>
<pre>
  mean(replicate(20, bilmoms(cop=TriCop)$error.rho)) # 7.650723e-06
</pre>
<p>where the <code>error.rho</code> is repeated trials appears firmly <code class="reqn">&lt;</code><code>1e-5</code>, which is near zero (<code class="reqn">\epsilon_\rho \approx 0</code>). The <code>error.rho</code> term is defined by taking the first bivariate L-moment and numerically integrated <code class="reqn">\rho_\mathbf{C}</code> through <code><a href="#topic+rhoCOP">rhoCOP</a></code> and computing the terms
</p>
<p style="text-align: center;"><code class="reqn">\epsilon^{[12]}_\rho = |\delta^{[12]}_{1;\mathbf{C}} - (\rho_\mathbf{C}/6)|\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon^{[21]}_\rho = |\delta^{[21]}_{1;\mathbf{C}} - (\rho_\mathbf{C}/6)|\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_\rho = \frac{\epsilon^{[12]}_\rho  + \epsilon^{[21]}_\rho}{2}\mbox{,}</code>
</p>

<p>where the <code>error.rho</code> <code class="reqn">=</code> <code class="reqn">\epsilon_\rho</code>, and values near zero are obviously favorable because this indicates that the Monte Carlo integration sample size <code class="reqn">n</code> argument is sufficiently large to effectively canvas the <code class="reqn">\mathcal{I}^2</code> domain. For the situation here, the theoretical <code class="reqn">\rho_\mathbf{C} = 0</code>, but for <code>n</code> <code class="reqn">= n = 100</code>, the <code>error.rho</code> <code class="reqn">\approx</code> 0.006 (<em>e.g.</em> <code>bilmoms(n=100,</code> <code>cop=TriCop)$error.rho</code>) through a 20-unit replication, which is a hint that 100 samples are not large enough and that should be obvious.
</p>
<p>The reasoning behind using the <code>error.rho</code> between conventional numerical integration and the Monte Carlo integration (<code>error.rho</code>) is that <code class="reqn">\rho_\mathbf{C}</code> is symmetrical. This choice of &ldquo;convergence&rdquo; assessment reduces somewhat the sample size needed for Monte Carlo integration into single number representing error.
</p>
<p><em>Discussion of Theoretical L-comoments</em>&mdash;The theoretical L-comoments in the format structure of the sample L-comoments by the <code>lcomoms2()</code> function of the <span class="pkg">lmomco</span> package are formed by the <code>bilmoms</code> function, and the theoretical values are shown below in sequence with details listed by L-comoment. Now we extract the L-comoment matrices and show the first L-comoment matrix (the matrix of the means):
</p>
<pre>
  theoLClcm &lt;- theoLC$bilcomoms
  print(theoLClcm$L1)
            [,1]      [,2]
  [1,] 0.4999939        NA
  [2,]        NA 0.5000032
</pre>
<p>where the diagonal should be filled with 1/2, if the <code class="reqn">n</code> is suitably large, because 1/2 is the mean of the marginal uniform random variables. By definition the secondary diagonal has <code>NA</code>s. The values shown above are extremely close supporting the idea that default <code class="reqn">n</code> is large enough. The matrix of means is otherwise uninformative.
</p>
<p>The second L-comoment matrix (L-scales and L-coscales) is
</p>
<pre>
  print(theoLClcm$L2)
                [,1]          [,2]
  [1,]  1.666677e-01 -3.466202e-06
  [2,] -3.466209e-06  1.666674e-01
</pre>
<p>where the diagonal should be filled with 1/6, if the <code class="reqn">n</code> is suitably large, because 1/6 is the univariate L-scale of the marginal uniform random variables. These values further support that default <code class="reqn">n</code> is large enough. The diagonal is computed from the univariate L-moments of the margins of the Monte Carlo-generated edges and is otherwise uninformative. The secondary diagonal is a rescaling of the <code class="reqn">\delta^{[\ldots]}_1</code> by the univariate L-moments of the margins to form L-coscales (nonratios). The copula is perfectly dependent but uncorrelated; so the secondary diagonal has near zeros.
</p>
<p>The second L-comoment ratio matrix (coefficient of L-variations and L-correlations) is
</p>
<pre>
  print(theoLClcm$T2)
                [,1]          [,2]
  [1,]  1.000000e+00 -2.079712e-05
  [2,] -2.079712e-05  1.000000e+00
</pre>
<p>where the diagonal by definition has unities (correlation is unity for a variable on itself) but the secondary diagonal for the L-correlations has near zeros because again the copula is uncorrelated, and the secondary diagonal is computed from the <code class="reqn">\delta^{[\ldots]}_1</code>. These L-correlations are the <em>Spearman Rho</em> values computed external to the algorithms within <code><a href="#topic+rhoCOP">rhoCOP</a></code>.
</p>
<p>The third L-comoment ratio matrix (L-skews and L-coskews) is
</p>
<pre>
  print(theoLClcm$T3)
                [,1]          [,2]
  [1,]  3.021969e-06 -2.829783e-05
  [2,] -7.501135e-01  4.518901e-06
</pre>
<p>where the diagonal by definition should have nero zeros because the univariate L-skew of a uniform variable is zero. These values further support that default <code class="reqn">n</code> is large enough.  The secondary diagonal holds L-coskews. The copula has L-coskew of <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> of numerically near zero (symmetry) but measurable asymmetry of L-coskew of <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> of <code class="reqn">\tau^{[21]}_3 \approx -0.75</code>.
</p>
<p>The fourth L-comoment ratio matrix (L-kurtosises and L-cokurtosises) is
</p>
<pre>
  print(theoLClcm$T4)
                [,1]          [,2]
  [1,] -2.623665e-06 -3.325177e-05
  [2,] -2.162954e-04 -2.811630e-06
</pre>
<p>where the diagonal by definition should have nero zeros because the univariate L-kurtosis of a uniform variable is zero&mdash;it has no peakedness. These values further support that default <code class="reqn">n</code> is large enough. The secondary diagonal holds L-cokurtosises and are near zero for this particular copula.
</p>
<p>The fifth L-comoment ratio matrix (unnamed) is
</p>
<pre>
  print(theoLClcm$T5)
               [,1]          [,2]
  [1,] 1.813344e-06 -1.296025e-04
  [2,] 1.246436e-01  1.475012e-06
</pre>
<p>where the diagonal by definition should have nero zeros because the univariate L-kurtosis of a uniform variable is zero&mdash;such a random variable has no asymmetry. These values further support that default <code class="reqn">n</code> is large enough. The secondary diagonal holds the fifth L-comoment ratios.  The copula has <code class="reqn">\tau^{[12]}_5 = 0</code> of <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> of numerically near zero (symmetry) but measurable fifth-order L-comoment asymmetry of <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> of <code class="reqn">\tau^{[21]}_5 \approx 0.125</code>.
</p>
<p><em>Comparison of Sample and Theoretical L-comoments</em>&mdash;The previous section shows theoretical values computed as <code class="reqn">\tau^{[21]}_3 \approx -0.75</code> and <code class="reqn">\tau^{[21]}_5 \approx 0.125</code> for the two L-comoments substantially away from zero. As sample L-comoments these values are <code>samLC$T3[2,1]</code> <code class="reqn">=</code> <code class="reqn">\hat\tau^{[21]}_3 \approx -0.751</code> and <code>samLC$T5[2,1]</code> <code class="reqn">=</code> <code class="reqn">\hat\tau^{[21]}_5 \approx 0.123</code>. CONCLUSION: <em>The sample L-comoment algorithms in the <span class="pkg">lmomco</span> package are validated.</em>
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Brahimi, B., Chebana, F., and Necir, A., 2015, Copula representation of bivariate L-moments&mdash;A new estimation method for multiparameter two-dimensional copula models: Statistics, v. 49, no. 3, pp. 497&ndash;521.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lcomCOP">lcomCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
bilmoms(cop=PSP, n=10000, para=NULL, sobol=TRUE)$bilcomoms$T3
# results: Tau3[12]=-0.132, Tau3[21]=-0.132 (Monte Carlo)
lcomCOP(cop=PSP, para=NULL, orders=3)
# results: Tau3[12]=-0.129, Tau3[21]=-0.129 (direct integration)
## End(Not run)

## Not run: 
# This stopped running sometime before June 2023. IS THIS IN COP()?
para &lt;- list(alpha=0.5, beta=0.93, para1=4.5, cop1=GLcop, cop2=PSP)
bilmoms(cop=composite2COP, n=10000, para=para, sobol=TRUE)$bilcomoms$T3
# results: Tau3[12]=0.154, Tau3[21]=-0.0691 (Monte Carlo)
lcomCOP(cop=composite2COP, para=para, orders=3)
# results: Tau3[12]=0.156, Tau3[21]=-0.0668 (direct integration)
## End(Not run)

## Not run: 
UVsim &lt;- simCOP(n=20000, cop=composite2COP, para=para, graphics=FALSE)
samLcom &lt;- lmomco::lcomoms2(UVsim, nmom=5) # sample algorithm
# results: Tau3[12]=0.1489, Tau3[21]=-0.0679 (simulation)
## End(Not run)
</code></pre>

<hr>
<h2 id='blomatrixCOP'>A Matrix of Blomqvist-like Betas of a Copula</h2><span id='topic+blomatrixCOP'></span><span id='topic+blomatrixCOPdec'></span><span id='topic+blomatrixCOPiqr'></span>

<h3>Description</h3>

<p>Compute the <em>Blomqvist-like Betas matrix</em> <code class="reqn">\beta^\circ_\mathbf{C}</code>-matrix of a copula, which is defined at presumably strategic points within <code class="reqn">\mathcal{I}^2</code>, as (for <code>as.blomCOPss=FALSE</code> argument)
</p>
<p style="text-align: center;"><code class="reqn">\beta^\circ_\mathbf{C} = \frac{\mathbf{C}(u^\circ,v^\circ)}{\mathbf{\Pi}(1/2, 1/2)} - 1\mbox{,}</code>
</p>

<p>where the <code class="reqn">u^\circ</code> and <code class="reqn">v^\circ</code> are of two types of gridded locations in <code class="reqn">\mathcal{I}^2</code> space and if <code class="reqn">u^\circ = 1/2</code> and <code class="reqn">v^\circ = 1/2</code>, then central location of the matrix is <em>Blomqvist Beta</em> (<code><a href="#topic+blomCOP">blomCOP</a></code>). The definition of <code class="reqn">\beta^\circ_\mathbf{C}</code> is such that the matrix is entirely zero for the <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>) (<code><a href="#topic+P">P</a></code>) when <code class="reqn">\mathbf{C}(u^\circ,v^\circ) = \mathbf{\Pi}(u,v)</code> at the medial location <code class="reqn">u,v=1/2</code>. Also, the definition here might be unique to the <span class="pkg">copBasic</span> package. The decile version (<code>blomatrixCOPdec</code>) of this function uses <code class="reqn">u^\circ \in (1, 5, 9) / 10</code> and <code class="reqn">v^\circ \in (1, 5, 9) / 10</code>. Whereas, the quartile version (<code>blomatrixCOPiqr</code>) of this function uses  <code class="reqn">u^\circ \in (25, 50, 75) / 100</code> and <code class="reqn">v^\circ \in (25, 50, 75)/100</code>. If <code>as.blomCOPss=TRUE</code> argument is set (<b>default operation</b>), then the coordinate locations in the matrix become the <code class="reqn">\beta^\diamond_\mathbf{C}</code> of <code><a href="#topic+blomCOPss">blomCOPss</a></code>. As a rule <code class="reqn">\beta^\circ_\mathbf{C} \ne \beta^\diamond_\mathbf{C}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blomatrixCOPdec(cop=NULL, para=NULL, as.sample=FALSE, as.blomCOPss=TRUE,
                  ctype=c("weibull", "hazen", "1/n",
                          "bernstein", "checkerboard"), ...)
blomatrixCOPiqr(cop=NULL, para=NULL, as.sample=FALSE, as.blomCOPss=TRUE,
                  ctype=c("weibull", "hazen", "1/n",
                          "bernstein", "checkerboard"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blomatrixCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="blomatrixCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="blomatrixCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the  <code class="reqn">\hat\beta^\circ_\mathbf{C}</code>-matrix at which point the <code>ctype</code> argument will be passed to multiple calls of <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>;</p>
</td></tr>
<tr><td><code id="blomatrixCOP_+3A_as.blomcopss">as.blomCOPss</code></td>
<td>
<p>A logical to trigger <code><a href="#topic+blomCOPss">blomCOPss</a></code> for each of the <code class="reqn">(u,v)</code> locations where for the <code><a href="#topic+blomCOPss">blomCOPss</a></code> calls (<code class="reqn">\beta^\diamond_\mathbf{C}(\mathbf{u}, \mathbf{v})</code>): <code class="reqn">u \mapsto (u,u) \mapsto \mathbf{u}</code> and  <code class="reqn">v  \mapsto (v,v) \mapsto \mathbf{v}</code>;</p>
</td></tr>
<tr><td><code id="blomatrixCOP_+3A_ctype">ctype</code></td>
<td>
<p>Argument of the same as <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>; and</p>
</td></tr>
<tr><td><code id="blomatrixCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The matrix for <code class="reqn">\beta^\circ_\mathbf{C}</code> is returned depending on whether the decile or quartile version has been called.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+blomCOPss">blomCOPss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>round(blomatrixCOPdec(cop=P), digits=8);     round(blomatrixCOPiqr(cop=P), digits=8)
#          U|V=0.10 U|V=0.50 U|V=0.90        #          U|V=0.25 U|V=0.50 U|V=0.75
# U|V=0.90        0        0        0        # U|V=0.75        0        0        0
# U|V=0.50        0        0        0        # U|V=0.50        0        0        0
# U|V=0.10        0        0        0        # U|V=0.25        0        0        0

round(blomatrixCOPdec(cop=PSP, as.blomCOPss=TRUE), digits=8)
#           U|V=0.10   U|V=0.50   U|V=0.90
# U|V=0.90 0.4736842  0.8181818  0.5153268
# U|V=0.50 0.8181818  0.3333333  0.6459330
# U|V=0.10 0.8901099  0.4736842  0.1708292

round(blomatrixCOPdec(cop=PSP, as.blomCOPss=FALSE), digits=8)
#            U|V=0.10   U|V=0.50  U|V=0.90
# U|V=0.90 0.09890110 0.81818182 4.2631579
# U|V=0.50 0.05263158 0.33333333 0.8181818
# U|V=0.10 0.01010101 0.05263158 0.0989011

## Not run: 
set.seed(1)
td &lt;- c(0.10, 0.50, 0.90)
UVn &lt;- simCOP(n=5000, cop=glueCOP, col=8,
          para=list(glue=0.4, cop1 =PLcop,           cop2=PLcop,
                             para1=PLpar(rho=-0.5), para2=PLpar(rho=+0.5)))
points(td, rep(td[3], 3), cex=2, lwd=2, pch=3, col="red")
points(td, rep(td[2], 3), cex=2, lwd=2, pch=3, col="red")
points(td, rep(td[1], 3), cex=2, lwd=2, pch=3, col="red")

print(blomatrixCOPdec(as.sample=TRUE, para=UVn, ctype="weibull"))
#             U|V=0.10 U|V=0.50 U|V=0.90
# U|V=0.90 -0.08222222   -0.580   -0.190
# U|V=0.50  0.30800000    0.112    0.264
# U|V=0.10  0.84000000    0.620    0.262

BMdn &lt;- blomatrixCOPdec(cop=glueCOP,
          para=list(glue=0.4,  cop1=PLcop,            cop2=PLcop,
                              para1=PLpar(rho=-0.5), para2=PLpar(rho=+0.5)))
print(round(BMdn, digits=8))
#             U|V=0.10   U|V=0.50   U|V=0.90
# U|V=0.90 -0.08110464 -0.5569028 -0.2053772
# U|V=0.50  0.33449815  0.1202744  0.2424668
# U|V=0.10  0.75217766  0.6013719  0.2424668 
## End(Not run)


## Not run: 
set.seed(1); nsim &lt;- 2000
para.pop &lt;- list( cop1=GHcop,             cop2=PLcop,  alpha=0.359,
                 para1=c(4.003, 1.099),  para2=0.882,   beta=0.292)
UVs &lt;- simCOP(nsim, cop=composite2COP, para=para.pop)
mtext("GIVEN THIS SAMPLE")
Rho &lt;- rhoCOP(as.sample=TRUE, para=UVs) # Spearman Rho
BMn &lt;- blomatrixCOPdec(as.sample=TRUE, para=UVs, ctype="weibull")

parafn &lt;- function(k) {
  c(exp(k[1])+1, exp(k[2]), exp(k[3]), pnorm(k[4]), pnorm(k[5]))
}
parafn_list &lt;- function(k) {
  k &lt;- parafn(k)
  list(cop1=GHcop, para1=c(k[1], k[2]), alpha=k[4],
       cop2=PLcop, para2=k[4],          beta=k[5])
}
BLOM_ofun &lt;- function(para, statmat=NULL, parafn=NULL, rho=NA) {
   para &lt;- parafn(para)
   new.para &lt;- list(cop1=GHcop, para1=para[1:2], alpha=para[4],
                    cop2=PLcop, para2=para[3],    beta=para[5])
   bm &lt;- blomatrixCOPdec(cop=composite2COP, para=new.para)
   err &lt;- sum((statmat - bm)^2) + (rhoCOP(cop=composite2COP, para=new.para) - rho)^2
   #print(c(para, err))
   return(err)
}

run1 &lt;- function(graphics=TRUE, nsim=0) {
  par.init &lt;- c(log(1), log(1), log(1), qnorm(0.5), qnorm(0.5))
  rt       &lt;- optim(par.init, BLOM_ofun, statmat=BMn, parafn=parafn, rho=Rho)
  para     &lt;- parafn(rt$par)
  para.fit &lt;- list(  cop1=GHcop,      cop2=PLcop,   alpha=para[4],
                    para1=para[1:2], para2=para[3],  beta=para[5])
  uv &lt;- simCOP(nsim, cop=composite2COP, para=para.fit, graphics=graphics, col=2)
  rmse &lt;- round(rmseCOP(uv[,1], uv[,2], ctype="weibull",
                        cop=composite2COP, para=para.fit), digits=8)
  if(graphics) mtext(paste0("RMSE(run1)=", rmse))
  return(list(rmse=rmse, para=para.fit))
}
system.time(RUN1 &lt;- run1(nsim=nsim))
par.init &lt;- c(log(RUN1$para$para1[1]), log(RUN1$para$para1[2]),
              log(RUN1$para$para2), qnorm(RUN1$para$alpha), qnorm(RUN1$para$beta))

RMSE_ofun &lt;- function(para, parafn=NULL) {
   para &lt;- parafn(para)
   new.para &lt;- list(cop1=GHcop, para1=para[1:2], alpha=para[4],
                    cop2=PLcop, para2=para[3],    beta=para[5])
   new.rmse &lt;- rmseCOP(UVs[,1], UVs[,2], cop=composite2COP, para=new.para)
   #print(c(para, new.rmse))
   return(new.rmse)
}
run2 &lt;- function(graphics=TRUE, nsim=0, par.init=NULL) {
  if(is.null(par.init)) {
    par.init &lt;- c(log(1), log(1), log(1), qnorm(0.5), qnorm(0.5))
  }
  rt       &lt;- optim(par.init, RMSE_ofun, parafn=parafn)
  para     &lt;- parafn(rt$par)
  para.fit &lt;- list(  cop1=GHcop,      cop2=PLcop,   alpha=para[4],
                    para1=para[1:2], para2=para[3],  beta=para[5])
  uv &lt;- simCOP(nsim, cop=composite2COP, para=para.fit, graphics=graphics, col=4)
  rmse &lt;- round(rmseCOP(uv[,1], uv[,2], ctype="weibull",
                        cop=composite2COP, para=para.fit), digits=8)
  if(graphics) mtext(paste0("RMSE(run2)=", rmse))
  return(list(rmse=rmse, para=para.fit))
}
system.time(RUN2.1 &lt;- run2(nsim=nsim, par.init=par.init))
system.time(RUN2.2 &lt;- run2(nsim=nsim, par.init=NULL    ))

GIVN &lt;- c(para.pop$alpha, para.pop$para1, para.pop$beta, para.pop$para2)
FIT1   &lt;- c(RUN1$para$alpha, RUN1$para$para1, RUN1$para$beta, RUN1$para$para2)
FIT1   &lt;- round(FIT1, digits=3)
FIT2.1 &lt;- c(RUN2.1$para$alpha, RUN2.1$para$para1, RUN2.1$para$beta, RUN2.1$para$para2)
FIT2.1 &lt;- round(FIT2.1, digits=3)
FIT2.2 &lt;- c(RUN2.2$para$alpha, RUN2.2$para$para1, RUN2.2$para$beta, RUN2.2$para$para2)
FIT2.2 &lt;- round(FIT2.2, digits=3)
nms    &lt;- c("what", "alpha", "para1_1", "para1_2", "beta", "para2")
GIVN   &lt;- c("given",   GIVN);  FIT2.1 &lt;- c("by_Blom1", FIT2.1)
FIT1   &lt;- c("by_RMSE", FIT1);  FIT2.2 &lt;- c("by_Blom2", FIT2.2)
names(GIVN)   &lt;- nms; names(FIT1)   &lt;- nms
names(FIT2.1) &lt;- nms; names(FIT2.2) &lt;- nms
RESL &lt;- cbind(data.frame(GIVN), data.frame(FIT1), data.frame(FIT2.1), data.frame(FIT2.2))
print(RESL) #
## End(Not run)
</code></pre>

<hr>
<h2 id='blomCOP'>The Blomqvist Beta of a Copula</h2><span id='topic+blomCOP'></span>

<h3>Description</h3>

<p>Compute the <em>Blomqvist Beta</em> <code class="reqn">\beta_\mathbf{C}</code> of a copula (Nelsen, 2006, p. 182), which is defined at the middle or center of <code class="reqn">\mathcal{I}^2</code> as
</p>
<p style="text-align: center;"><code class="reqn">\beta_\mathbf{C} = 4\times\mathbf{C}\biggl(\frac{1}{2},\frac{1}{2}\biggr) - 1\mbox{,}</code>
</p>

<p>where the <code class="reqn">u = v = 1/2</code> and thus shows that <code class="reqn">\beta_\mathbf{C}</code> is based on the <em>median joint probability</em>. The Blomqvist Beta is also called the <em>medial correlation coefficient</em>. Nelsen also reports that &ldquo;although, the Blomqvist Beta depends only on the copula only through its value at the center of <code class="reqn">\mathcal{I}^2</code>, but that [<code class="reqn">\beta_\mathbf{C}</code>] nevertheless often provides an accurate approximation to both <em>Spearman Rho</em> <code><a href="#topic+rhoCOP">rhoCOP</a></code> and <em>Kendall Tau</em> <code><a href="#topic+tauCOP">tauCOP</a></code>.&rdquo;  Kendall Tau <code class="reqn">\tau_\mathbf{C}</code>, <em>Gini Gamma</em> <code class="reqn">\gamma_\mathbf{C}</code>, and Spearman Rho <code class="reqn">\rho_\mathbf{C}</code> in relation to <code class="reqn">\beta_\mathbf{C}</code> satisfy the following inequalities (Nelsen, 2006, exer. 5.17, p. 185):
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{4}(1 + \beta_\mathbf{C})^2  - 1 \le \tau_\mathbf{C} \le 1 - \frac{1}{4}(1 - \beta_\mathbf{C})^2\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{3}{16}(1 + \beta_\mathbf{C})^3  - 1 \le \rho_\mathbf{C} \le 1 - \frac{3}{16}(1 - \beta_\mathbf{C})^3\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{3}{8}(1 + \beta_\mathbf{C})^2  - 1 \le \tau_\mathbf{C} \le 1 - \frac{3}{8}(1 - \beta_\mathbf{C})^2\mbox{.}</code>
</p>

<p>A curious aside (Joe, 2014, p. 164) about the <em>Gaussian copula</em> is that <em>Blomqvist Beta</em> is equal to <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>): <code class="reqn">\beta_\mathbf{C} = \tau_\mathbf{C}</code> (see <b>Note</b> in <code><a href="#topic+med.regressCOP">med.regressCOP</a></code> for a demonstration). Finally, a version of Blomqvist Beta defined outside the median is provided by <code><a href="#topic+blomCOPss">blomCOPss</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blomCOP(cop=NULL, para=NULL, as.sample=FALSE,
                  ctype=c("joe", "weibull", "hazen", "1/n",
                                 "bernstein", "checkerboard"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blomCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="blomCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="blomCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat\beta_\mathbf{C}</code> (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="blomCOP_+3A_ctype">ctype</code></td>
<td>
<p>Argument of the same as <code><a href="#topic+EMPIRcop">EMPIRcop</a></code> with the exception of the <code>"joe"</code> specific to the documentation here. The other choices trigger and are given over to the empirical copula; and</p>
</td></tr>
<tr><td><code id="blomCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula or down to <code><a href="#topic+EMPIRcop">EMPIRcop</a></code> if a sample version had been requested.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\beta_\mathbf{C}</code> or sample <code class="reqn">\hat\beta_n</code> is returned.
</p>


<h3>Note</h3>

<p>The sample <code class="reqn">\hat\beta_n</code> is most efficiently computed (Joe, 2014, p. 57) by
</p>
<p style="text-align: center;"><code class="reqn">\hat\beta_n = \frac{2}{n} \sum_{i=1}^{n} \mathbf{1}\biggl([r_{i1} - (1 + n)/2]\times
                                                          [r_{i2} - (1 + n)/2] \ge 0\biggr) -
                    1\mbox{,}</code>
</p>

<p>where <code class="reqn">r_{i1}, r_{i2}</code> are the ranks of the data for <code class="reqn">i = 1, \ldots n</code>, and <code class="reqn">\mathbf{1}(.)</code> is an <em>indicator function</em> scoring 1 if condition is true otherwise zero. However, the Joe sample estimator is not fully consistent (or vice versa) with the various versions of the empirical copula, <code class="reqn">\mathbf{C}_n</code>, (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>) (see the last example in <b>Examples</b>). Also, the nature of even and odd sample sizes controls how the median is computed and the issue of samples lying on the median lines in <code class="reqn">U</code> and <code class="reqn">V</code> (Genest <em>et al.</em>, 2013). The argument <code>ctype</code> supports triggers to the <code class="reqn">\mathbf{C}_n</code> in lieu of the Joe sample estimator shown in this documentation.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Genest, C., Carabarín-Aguirre, A., and Harvey, F., 2013, Copula parameter estimation using<br /> Blomqvist's beta: Journal de la Soci<code class="reqn">é</code>té Française de Statistique, v. 154, no. 1, pp. 5&ndash;24.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOPss">blomCOPss</a></code>, <code><a href="#topic+blomatrixCOPdec">blomatrixCOPdec</a></code>, <code><a href="#topic+blomatrixCOPiqr">blomatrixCOPiqr</a></code>,
<code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+hoefCOP">hoefCOP</a></code>,
<code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>,
<code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>blomCOP(cop=PSP) # 1/3 precisely

## Not run: 
# Nelsen (2006, exer. 5.17, p. 185) : All if(...) are TRUE
B &lt;- blomCOP(cop=N4212cop, para=2.2); Bp1 &lt;- 1 + B; Bm1 &lt;- 1 - B
G &lt;- giniCOP(cop=N4212cop, para=2.2); a &lt;- 1/4; b &lt;- 3/16; c &lt;- 3/8
R &lt;-  rhoCOP(cop=N4212cop, para=2.2)
K &lt;-  tauCOP(cop=N4212cop, para=2.2, brute=TRUE) # numerical issues without brute
if( a*Bp1^2 - 1 &lt;= K &amp; K &lt;= 1 - a*Bm1^2 ) print("TRUE") #
if( b*Bp1^3 - 1 &lt;= R &amp; R &lt;= 1 - b*Bm1^3 ) print("TRUE") #
if( c*Bp1^2 - 1 &lt;= G &amp; G &lt;= 1 - c*Bm1^2 ) print("TRUE") #
## End(Not run)

## Not run: 
# A demonstration of a special feature of blomCOP for sample data.
# Joe (2014, p. 60; table 60) has 0.749 for GHcop(tau=0.5); n*var(hatB) as n--&gt;infinity
set.seed(1)
theta &lt;- GHcop(tau=0.5)$para; B &lt;- blomCOP(cop=GHcop, para=theta); n &lt;- 1000
H &lt;- sapply(1:1000, function(i) { # Let us test that with pretty large sample size:
	                blomCOP(para=rCOP(n=n, cop=GHcop, para=theta), as.sample=TRUE) })
print(n*var(B-H)) # For 1,000 sims of size n : 0.789, nearly matches Joe's result 
## End(Not run)

## Not run: 
# Joe (2014, p. 57) says that sqrt(n)(B-HatBeta) is Norm(0, 1 - B^2)
set.seed(1)
n &lt;- 10000; B &lt;- blomCOP(cop=PSP) # Beta = 1/3
H &lt;- sapply(1:100, function(i) { message(i,"-", appendLF=FALSE)
	               blomCOP(para=rCOP(n=n, cop=PSP), as.sample=TRUE) })
lmomco::parnor(lmomco::lmoms(sqrt(n)*(H-B))) # mu = -0.038; sigma = 0.970
# Joe (2014) : sqrt(1-B^2) == standard deviation (sigma) : (1-(1/3)^2) approx 0.973 
## End(Not run)

## Not run: 
nn &lt;- 200; set.seed(1)
UV &lt;- simCOP(n=nn+1, cop=PSP, graphics=FALSE)
for(n in nn:(nn+1)) {
  if(as.logical(n %% 2)) { # in source \ percent \ percent for latex
    message("Blomquist Betas for an odd  sample size n=", n)
    uv &lt;- UV
  } else {
    message("Blomquist Betas for an even sample size n=", n)
    uv &lt;- UV[-(nn+1), ] # remove the last and 'odd' indexed value to make even
  }
  message(c(" Joe2014: ", blomCOP(as.sample=TRUE, para=uv, ctype="joe"         )))
  message(c(" Weibull: ", blomCOP(as.sample=TRUE, para=uv, ctype="weibull"     )))
  message(c(" Hazen:   ", blomCOP(as.sample=TRUE, para=uv, ctype="hazen"       )))
  message(c(" 1/n:     ", blomCOP(as.sample=TRUE, para=uv, ctype="1/n"         )))
  message(c(" Bernstn: ", blomCOP(as.sample=TRUE, para=uv, ctype="bernstein"   )))
  message(c(" ChckBrd: ", blomCOP(as.sample=TRUE, para=uv, ctype="checkerboard")))
}
# Blomquist Betas for an even sample size n=200
#  Joe2014: 0.32
#  Weibull: 0.32
#  Hazen:   0.32
#  1/n:     0.32
#  Bernstn: 0.323671819423416
#  ChckBrd: 0.32
# Blomquist Betas for an odd  sample size n=201
#  Joe2014: 0.323383084577114
#  Weibull: 0.333333333333333
#  Hazen:   0.333333333333333
#  1/n:     0.293532338308458
#  Bernstn: 0.327747577290946
#  ChckBrd: 0.313432835820896 #
## End(Not run)
</code></pre>

<hr>
<h2 id='blomCOPss'>Blomqvist (Schmid&ndash;Schmidt) Betas of a Copula</h2><span id='topic+blomCOPss'></span>

<h3>Description</h3>

<p>Compute the <em>Blomqvist (Schmid&ndash;Schmidt) Betas</em> <code class="reqn">\beta^\diamond_\mathbf{C}</code> (Schmid and Schmidt, 2007) defined for arbitrary dimension <code class="reqn">d</code> of a copula <code class="reqn">\mathbf{C}_(u_1, \cdots, u_d; \Theta)</code> (<code><a href="#topic+COP">COP</a></code>) for parameters <code class="reqn">\Theta</code>. The copula survival function is <code class="reqn">\overline{\mathbf{C}}(u_1, \cdots, u_d; \Theta)</code> (<code><a href="#topic+surfuncCOP">surfuncCOP</a></code>). The Beta, though the <span class="pkg">copBasic</span> package is built around bivariate copula only, is defined as
</p>
<p style="text-align: center;"><code class="reqn">\beta^\diamond_\mathbf{C} = h_d(\mathbf{u}, \mathbf{v})\bigl[
\bigl(\mathbf{C}(\mathbf{u}) + \overline{\mathbf{C}}(\mathbf{v})\bigr) - g_d(\mathbf{u}, \mathbf{v})
\bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">h_d</code> and <code class="reqn">g_d</code> are norming constants defined below. The superscript <code class="reqn">\diamond</code> (diamond) is chosen for <span class="pkg">copBasic</span> because of the alliteration to &ldquo;dimension.&rdquo; The bold face font for <code class="reqn">\mathbf{u}</code> and <code class="reqn">\mathbf{v}</code> shows these arguments as vectors of length <code class="reqn">d</code> reflecting &ldquo;cutting points&rdquo; on nonexceedance probabilities in each of the dimensions. The <code class="reqn">\mathbf{u}</code> functions as the arguments <code class="reqn">(u,v)</code> pair used in copula of this package and represents the first cutting point for a <code class="reqn">\mathrm{Pr}[U \le u, V \le v] = \mathbf{C}(u,v)</code>, and <code class="reqn">\mathbf{v}</code> functions as the arguments <code class="reqn">u,v</code> pair for this package and represents the second cutting point for a <code class="reqn">\mathrm{Pr}[U &gt; u, V &gt; v] = 1 - u - v + \mathbf{C}(u,v) = \overline{\mathbf{C}}(u,v)</code>. This notation of vectored (bold face) and nonvectored &ldquo;u&rdquo; and &ldquo;v&rdquo; is a little obtuse but as the properties of <code class="reqn">\beta^\diamond_\mathbf{C}</code> are summarized clarity for the reader is anticipated. In short, the <code class="reqn">\mathbf{u}</code> will reference the coordinate pairs in the lower right quadrant and the <code class="reqn">\mathbf{v}</code> will reference the coordinate pairs in the upper right quadrant.
</p>
<p>The norming constant <code class="reqn">h_d</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">h_d(\mathbf{u}, \mathbf{v}) = \frac{1}{\bigl( \mathrm{min}(u_1,   \cdots,   u_d) + \mathrm{min}(1-v_1, \cdots, 1-v_d) - g_d(\mathbf{u}, \mathbf{v})\bigr)}\mbox{,}</code>
</p>

<p>and <code class="reqn">g_d</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">g_d(\mathbf{u}, \mathbf{v}) = \prod^d_{i=1}u_i + \prod^d_{i=1}(1-v_i)\mbox{,}</code>
</p>

<p>where the cutting points <code class="reqn">\mathbf{u}</code> and <code class="reqn">\mathbf{v}</code> are in a domain <code class="reqn">D : \{(\mathbf{u}, \mathbf{v})\} \in [0,1]^{2d}</code> given <code class="reqn">\mathbf{u} \le \mathbf{v}</code> and <code class="reqn">\mathbf{u} &gt; 0</code> or <code class="reqn">\mathbf{v} &lt; \mathbf{1}</code>. The reader must careful remember that these <code class="reqn">\mathbf{u}</code> and <code class="reqn">\mathbf{v}</code> are vectors of probabilities.
</p>
<p>The norming constants provide for <code class="reqn">-1 \le \beta^\diamond_\mathbf{C} \le +1</code>. Using the function argument defaults for <code class="reqn">d=2</code> dimensions <code class="reqn">\mathbf{u} = (1,1)/2</code> for <code>uu</code> and <code class="reqn">\mathbf{v} = (1,1)/2</code> for <code>vv</code>, results in (1) <code class="reqn">\beta^\diamond_\mathbf{C} = 1</code> if <code class="reqn">\mathbf{C} = \mathbf{M}</code> <em>comonotonicity copula</em> (<code><a href="#topic+M">M</a></code>) (<code>blomCOPss(cop=M) == 1</code>), (2) <code class="reqn">\beta^\diamond_\mathbf{C} = 0</code> if <code class="reqn">\mathbf{C} = \mathbf{P}</code> <em>independence copula</em> (<code><a href="#topic+P">P</a></code>) (<code>blomCOPss(cop=P) == 0</code>), and (3) if <code class="reqn">\mathbf{C} = \mathbf{W}</code> <em>countermonotonicity copula</em> (<code><a href="#topic+W">W</a></code>)<code class="reqn">\beta^\diamond_\mathbf{C} = 1</code> (<code>blomCOPss(cop=W) == -1</code>).
</p>
<p>Schmid and Schmidt (2007) list three important cases extending the <code class="reqn">\mathbf{M}</code> and <code class="reqn">\mathbf{P}</code> examples. First, <code class="reqn">\beta^\diamond_\mathbf{C}(\mathbf{1/2}, \mathbf{1/2}) = \beta_\mathbf{C}(1/2, 1/2)</code>, which is <em>Blomqvist Beta</em> (<code class="reqn">\beta_\mathbf{C}(1/2, 1/2)</code>) (<code><a href="#topic+blomCOP">blomCOP</a></code>) and measures overall dependence.
</p>
<p>Second, <code class="reqn">\beta^\diamond_\mathbf{C}(\mathbf{u}, \mathbf{v})</code> with <code class="reqn">\mathbf{u} &lt; 1/2 &lt; \mathbf{v}</code>, which measures dependence in the tail regions. (Note, the author of <span class="pkg">copBasic</span> thinks &ldquo;regions&rdquo; as a plural is need in the previous sentence; Schmid and Schmidt (2007) use the singular &ldquo;region.&rdquo; This is potentially important as seemingly simultaneous tail dependency in the lower and upper perspectives would be provided. More discussion is provided in <b>Examples</b>.)
</p>
<p>Third and presumably very important in practical applications, <code class="reqn">\mathrm{lim}_{p\downarrow 0}\, \beta^\diamond_\mathbf{C}(\mathbf{p}, \mathbf{1}) = \lambda^L_{\beta^\diamond_\mathbf{C}}</code> for <code class="reqn">\mathbf{p} = \mathbf{u} = (p,\cdots,p)</code> measures lower-tail dependence. This measure is equal to the <em>lower-tail dependence parameter</em> <code class="reqn">\lambda^L_\mathbf{C} = \lambda^L_{\beta^\diamond_\mathbf{C}}</code> without some of the computational nuances required as  <code class="reqn">\lambda^L_\mathbf{C}</code> is defined at <code><a href="#topic+taildepCOP">taildepCOP</a></code>.
</p>
<p>Schmid and Schmidt (2007) do not list how the <em>upper-tail dependence parameter</em> <code class="reqn">\lambda^U_\mathbf{C}</code> could be computed in terms of <code class="reqn">\beta^\diamond_\mathbf{C}</code>. The expression for study of the upper-tail dependency is <code class="reqn">\lambda^U_{\beta^\diamond_\mathbf{C}} = \beta^\diamond_\mathbf{C}(\mathbf{0}, \mathbf{p})</code> for <code class="reqn">\mathbf{p} = \mathbf{v} = (p,\cdots,p)</code> as <code class="reqn">p \rightarrow 0^+</code>, and <code class="reqn">\lambda^U_\mathbf{C} = \lambda^U_{\beta^\diamond_\mathbf{C}}</code> without some of the computational nuances required as <code class="reqn">\lambda^U_\mathbf{C}</code> is defined at <code><a href="#topic+taildepCOP">taildepCOP</a></code>. These tail dependencies are computed and compared in the <b>Examples</b> and confirmation of this function being used to estimate both tail-dependency parameters is confirmed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blomCOPss(cop=NULL, para=NULL, uu=rep(0.5, 2), vv=rep(0.5, 2), trap.nan=TRUE,
          as.sample=FALSE, ctype=c("weibull", "hazen", "1/n",
                                   "bernstein", "checkerboard"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blomCOPss_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_uu">uu</code></td>
<td>
<p>The vector for <code class="reqn">\mathbf{u}</code> and the defaults with <code>vv</code> as such for same operation as <code><a href="#topic+blomCOP">blomCOP</a></code> (<code class="reqn">\beta^\diamond_\mathbf{C}(\mathbf{1/2}, \mathbf{1/2})</code>);</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_vv">vv</code></td>
<td>
<p>The vector for <code class="reqn">\mathbf{v}</code> and the defaults with <code>uu</code> as such for same operation as <code><a href="#topic+blomCOP">blomCOP</a></code> (<code class="reqn">\beta^\diamond_\mathbf{C}(\mathbf{1/2}, \mathbf{1/2})</code>);</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_trap.nan">trap.nan</code></td>
<td>
<p>A logical to trigger 0 if <code class="reqn">(0,0)</code> is <code>NaN</code> or if <code class="reqn">(1,1)</code> is <code>NaN</code>. This feature is present on a package-specific purpose because the <code><a href="#topic+PSP">PSP</a></code> copula deliberately retains edge <code>NaN</code> as a stress case;</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the  <code class="reqn">\hat\beta^\diamond_\mathbf{C}</code> at which point the <code>ctype</code> argument will be passed to <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>;</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_ctype">ctype</code></td>
<td>
<p>Argument of the same as <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>; and</p>
</td></tr>
<tr><td><code id="blomCOPss_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code class="reqn">\beta^\diamond_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>Sample estimation of the <code class="reqn">\beta^\diamond_\mathbf{C}</code> is possible. The <code>as.sample</code> triggers internally a call to the <em>empirical copula</em> (<code class="reqn">\mathbf{C}_n</code>) (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>) for the <code>ctype</code> for the copula and its survival function form. Expansive more details are provided by <code><a href="#topic+taildepCOP">taildepCOP</a></code> (section <b>Note</b>::<em>DEMONSTRATION (Tail Dependence)</em>). A comparison of the <code class="reqn">\hat\lambda^U_{\beta^\diamond_\mathbf{C}}</code> and <code class="reqn">\hat\lambda^U_{\beta^\diamond_\mathbf{C}}</code> is made.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Schmid, Friedrich, and Schmidt, Rafael, 2007, Nonparametric inference on multivariate versions of Blomqvist's beta and related measures of tail dependence: Metrika, v. 66, pp. 323&ndash;354, <a href="https://doi.org/10.1007/s00184-006-0114-3">doi:10.1007/s00184-006-0114-3</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+blomatrixCOP">blomatrixCOP</a></code>, <code><a href="#topic+taildepCOP">taildepCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>blomCOP(  cop=PSP) # [1] 0.3333333
blomCOPss(cop=PSP) # [1] 0.3333333

## Not run: 
# The calls below for blomCOPss() are technically the same for sample versions.
UV &lt;- simCOP(1000, cop=PSP, graphics=FALSE)  # HatBeta(0.1,0.9) = 0.277___
blomCOPss(para=UV, cop=EMPIRcop,   uu=c(0.1,0.1), vv=c(0.90,0.90))
blomCOPss(para=UV, as.sample=TRUE, uu=c(0.1,0.1), vv=c(0.90,0.90)) #
## End(Not run)

## Not run: 
set.seed(1)
para &lt;- c(3, 6) # define parameters of two-parameter GHcop
UV &lt;- simCOP(1000, cop=GHcop, para=para) # simulate to show general structure

# compute the tail dependencies from havling into the limits
taildepCOP(cop=GHcop, para=para, plot=TRUE)
# lower tail dependency = 0.96222
# upper tail dependency = 0.74008
# The two parameters influence how strongly the tail dependencies are.

# Schmid and Schmidt (2007, eq. 24) define the lower-tail dependency in terms of
# the Beta and p--&gt;0 Beta(c(p,p), c(1,1)). Lets compute these and produce content
# suitable to show on the tail-dependency plot that the assertion for the lower
# dependency by Beta() is correct, which it is and then extend to the upper-tail
# dependency parameter that the authors seem to not have defined.
usr &lt;- par()$usr[1:2]         # grab horizontal edges of the plot, and set up the
uuLO &lt;- rep(pnorm(usr[1]), 2) # the uu for the lower tail and the vv for the upper
vvUP &lt;- rep(pnorm(usr[2]), 2) # tail and then plot both with overplotting symbols
# lower-tail estimate and see how it plots along the value from taildepCOP()
SchmidsL &lt;- blomCOPss(cop=GHcop, para=para, uu=uuLO, vv=c(1,1))
points(usr[1], SchmidsL, col="darkgreen", cex=2, pch=1, lwd=2)
points(usr[1], SchmidsL, col="darkgreen", cex=2, pch=3, lwd=2)
points(usr[1], SchmidsL, col="darkgreen", cex=2, pch=4, lwd=2)
# upper-tail estimate and see how it plots along the value from taildepCOP()
SchmidsU &lt;- blomCOPss(cop=GHcop, para=para, uu=c(0,0), vv=vvUP)
points(usr[2], SchmidsU, col="darkgreen", cex=2, pch=1, lwd=2)
points(usr[2], SchmidsU, col="darkgreen", cex=2, pch=3, lwd=2)
points(usr[2], SchmidsU, col="darkgreen", cex=2, pch=4, lwd=2)
# SchmidsL lower tail dependency = 0.962224
# SchmidsU upper tail dependency = 0.740079
# The author has an expectation that the SchmidsL and SchmidsU values are
# more reliable than those stemming from taildepCOP() because of the limiting
# behavior (or its implementation therein) compared to direct computation by
# blomCOPss().

# Mow for sake of curiosity, let us see how the trajectory of the Blomqvist
# (Schmid--Schmidt) Betas at arriving at the tail dependencies as p--&gt;0|1.
# It is very informative that the trajectories of blomCOPss() and taildepCOP()
# as each hones towards the two dependency parameters are different and this
# highlights the fact that the computational underpinnings are different.
psl &lt;- pnorm(seq(0, usr[1], by=-diff(range(c(0, usr[1]))) / 1000))
lines(qnorm(psl), sapply(psl, function(p) {
              blomCOPss(cop=GHcop, para=para, uu=rep(p, 2), vv=c(1,1)) }),
      col="darkgreen", lty=2, lwd=2)
psu &lt;- pnorm(seq(0, usr[2], by= diff(range(c(0, usr[2]))) / 1000))
lines(qnorm(psu), sapply(psu, function(p) {
              blomCOPss(cop=GHcop, para=para, uu=c(0,0), vv=rep(p, 2)) }),
      col="darkgreen", lty=2, lwd=2) #
## End(Not run)
</code></pre>

<hr>
<h2 id='breveCOP'>Add Asymmetry to a Copula</h2><span id='topic+breveCOP'></span>

<h3>Description</h3>

<p>Adding <em>permutation asymmetry</em> (Chang and Joe, 2020, p. 1596) (<code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>) is simple for a bivariate copula family. Let <code class="reqn">\mathbf{C}</code> be a copula with respective vectors of parameters <code class="reqn">\Theta_\mathbf{C}</code>, then the permutation asymmetry is added through an asymmetry parameter <code class="reqn">\beta \in (-1, +1)</code> by
</p>
<p style="text-align: center;"><code class="reqn">\breve{\mathbf{C}}_{\beta;\Theta}(u,v) = v^{-\beta}\cdot\mathbf{C}(u, v^{(1+\beta)};\Theta)\mbox{, and}</code>
</p>

<p>for <code class="reqn">0 \le \beta \le +1</code> by
</p>
<p style="text-align: center;"><code class="reqn">\breve{\mathbf{C}}_{\beta;\Theta}(u,v) = u^{+\beta}\cdot\mathbf{C}(u^{(1-\beta)}, v;\Theta)\mbox{.}</code>
</p>

<p>The parameter <code class="reqn">\beta</code> clashes in name and symbology with a parameter used by functions <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, and <code><a href="#topic+composite3COP">composite3COP</a></code>. As a result, support for alternative naming is provided for compatibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breveCOP(u,v, para, breve=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="breveCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="breveCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="breveCOP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="breveCOP_+3A_breve">breve</code></td>
<td>
<p>An alternative way from <code>para</code> to set the <code class="reqn">\beta</code> for this function; and</p>
</td></tr>
<tr><td><code id="breveCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument where <code>cop1</code> and <code>cop</code> and <code>para1</code> and <code>para</code> are respectively synonymous to have some structural similarity to the various copula constructors (compositors) of the <span class="pkg">copBasic</span> package:
</p>

<dl>
<dt><code>beta</code></dt><dd><p>&mdash; The <code class="reqn">\beta</code> asymmetry parameter;</p>
</dd>
<dt><code>breve</code></dt><dd><p>&mdash; The <code class="reqn">\beta</code> asymmetry parameter and presence of <code>breve</code> will not cause the non-use of <code>beta</code>; this feature is present so that <code>beta</code> remains accessible to the compositors that use <code>beta</code> (see <b>Examples</b>);</p>
</dd>
<dt><code>cop </code></dt><dd><p>&mdash; Function of the copula <code class="reqn">\mathbf{C}</code>;</p>
</dd>
<dt><code>cop1</code></dt><dd><p>&mdash; Alternative naming of the function of the coupla <code class="reqn">\mathbf{C}</code>;</p>
</dd>
<dt><code>para </code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{C}</code> for  <code class="reqn">\mathbf{C}</code>; and</p>
</dd>
<dt><code>para1</code></dt><dd><p>&mdash; Alternative naming of the vector of parameters <code class="reqn">\Theta_\mathbf{C}</code> for  <code class="reqn">\mathbf{C}</code>.</p>
</dd>
</dl>

<p>The function silently restricts the <code class="reqn">\beta</code> to its interval as defined, but parameter transform might be useful in some numerical optimization schemes. The following recipes might be useful for transform from a parameter in numerical optimization to the asymmetry parameter:
</p>
<pre>
   #    transform into space for optimization
   BREVEtfunc &lt;- function(p) { return(   qnorm((p[1] + 1) / 2) ) } # [-Inf, +Inf]
   # re-transform back into space for the copula
   BREVErfunc &lt;- function(p) { return(2 * pnorm(p[1]) - 1)       } # [-1  , +1  ]
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Chang, B., and Joe, H., 2020, Copula diagnostics for asymmetries and conditional dependence: Journal of Applied Statistics, v. 47, no. 9, pp. 1587&ndash;1615, <a href="https://doi.org/10.1080/02664763.2019.1685080">doi:10.1080/02664763.2019.1685080</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+convex2COP">convex2COP</a></code>, <code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>, <code><a href="#topic+FRECHETcop">FRECHETcop</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- list(breve=0.24, cop1=FRECHETcop, para1=c(0.4, 0.56))
breveCOP(0.87, 0.35, para=para) # 0.282743

betas &lt;- seq(-1,1, by=0.01)
bloms &lt;- sapply(betas, function(b) {
             breveCOP(0.15, 0.25, para=list(cop=GLPMcop, para=c(2, 2), beta=b))
         } )
plot(betas, bloms, type="l", main="GLPMcop(u,v; 2,2) by breveCOP(beta)")

## Not run: 
  # Notice the argument cop and para name adjustments to show that
  # translation exists inside the function to have use flexibility.
  para &lt;- list(beta=+0.44, cop1=FRECHETcop, para1=c(0.2, 0.56))
  UV   &lt;- simCOP(1000, cop=breveCOP, para=para)
  para &lt;- list(beta=-0.44, cop= FRECHETcop, para= c(0.2, 0.56))
  UV   &lt;- simCOP(1000, cop=breveCOP, para=para) # 
## End(Not run)

## Not run: 
  # Testing on a comprehensive copula (Plackett)
  betas &lt;- rhos &lt;- thetas &lt;- brhos &lt;- NULL
  for(beta  in seq(-1, 1, by=0.1 )) {
    for(rho in seq(-1, 1, by=0.01))   {
       theta  &lt;- PLACKETTpar(rho=rho, byrho=TRUE)
       thetas &lt;- c(thetas, theta)
       para   &lt;- list(  cop=PLcop,    para=theta, beta=beta)
       brho   &lt;- rhoCOP(cop=breveCOP, para=para)
       betas  &lt;- c(betas, beta); rhos &lt;- c(rhos, rho)
       brhos  &lt;- c(brhos, brho)
    }
  }
  df &lt;- data.frame(beta=betas, theta=thetas, rho=rhos, brho=brhos)
  plot(df$theta, df$brho, log="x", pch=16, cex=0.9, col="seagreen",
       xlab="Plackett parameter", ylab="Spearman Rho")
  lines(df$theta[df$beta == 0], df$brho[df$beta == 0], col="red", lwd=2)
  # Red line is the Plackett in its permutation symmetric definition. #
## End(Not run)

## Not run: 
  # Here is an example for a test using mleCOP() to estimate a 5-parameter asymmetric
  # copula model to "some data" on transition from yesterday to today data for a very
  # large daily time series. The purpose of example here is to demonstrate interfacing
  # to the breveCOP() for it to add asymmetry to composition of two copula.
  myASYMCOP &lt;- function(u,v, para, ...) {
    subpara &lt;- list(alpha=para$alpha, beta=para$beta, cop1=GHcop, para1=para$para1,
                                                      cop2=PLcop, para2=para$para2)
    breveCOP(u,v, cop=convex2COP, para=subpara)
  }
  para &lt;- list(alpha=+0.16934027, cop1=GHcop, para1=c(1.11144148, 10.32292673),
                beta=-0.01923808, cop2=PLcop, para2=3721.82966727)
  UV &lt;- simCOP(30000, cop=myASYMCOP, para=para, pch=16, col=grey(0, 0.1))
  abline(0,1, lwd=3, col="red") #
## End(Not run)

## Not run: 
  # Here is a demonstration of the permutations of the passing of the
  # asymmetry parameter into the function and then by
  UV &lt;- simCOP(1E3, cop=breveCOP, para=list(cop=HRcop, para=5), breve=+0.5)
  UV &lt;- simCOP(1E3, cop=breveCOP, para=list(cop=HRcop, para=5), breve=-0.5)
  UV &lt;- simCOP(1E3, cop=breveCOP, para=list(cop=HRcop, para=5,  beta =+0.5))
  UV &lt;- simCOP(1E3, cop=breveCOP, para=list(cop=HRcop, para=5,  breve=+0.5))
  UV &lt;- simCOP(1E3, cop=breveCOP, para=list(cop=HRcop, para=5,  beta=-0.4, breve=+0.5))

  para &lt;- list(cop1=HRcop, para1=6, cop2=PSP, para2=NULL, alpha=1, beta=0.7)
  myCOP &lt;- function(u,v, para, ...) breveCOP(u,v, cop=composite2COP, para=para)
  para$breve &lt;- "here I am"
  UV &lt;- simCOP(1E3, cop=composite2COP, para=para, seed=1) # breve is not used
  para$breve &lt;- -0.16
  UV &lt;- simCOP(1E3, cop=myCOP,         para=para, seed=1)
  para$breve &lt;- +0.16
  UV &lt;- simCOP(1E3, cop=myCOP,         para=para, seed=1) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='CIRCcop'>Copula of Circular Uniform Distribution</h2><span id='topic+CIRCcop'></span>

<h3>Description</h3>

<p>The <em>Circular copula</em> of the coordinates <code class="reqn">(x, y)</code> of a point chosen at random on the unit circle (Nelsen, 2006, p. 56) is given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\mathrm{CIRC}}(u,v) = \mathbf{M}(u,v) \mathrm{\ for\ }|u-v| &gt; 1/2\mathrm{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\mathrm{CIRC}}(u,v) = \mathbf{W}(u,v) \mathrm{\ for\ }|u+v-1| &gt; 1/2\mathrm{,\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\mathrm{CIRC}}(u,v) = \frac{u+v}{2} - \frac{1}{4} \mathrm{\ otherwise\ }\mathrm{.}</code>
</p>

<p>The coordinates of the unit circle are given by
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{CIRC}(x,y) = \biggl(\frac{\mathrm{cos}\bigl(\pi(u-1)\bigr)+1}{2}, \frac{\mathrm{cos}\bigl(\pi(v-1)\bigr)+1}{2}\biggr)\mathrm{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>CIRCcop(u, v, para=NULL, as.circ=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CIRCcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="CIRCcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="CIRCcop_+3A_para">para</code></td>
<td>
<p>Optional parameter list argument that can contain the logical <code>as.circ</code> instead;</p>
</td></tr>
<tr><td><code id="CIRCcop_+3A_as.circ">as.circ</code></td>
<td>
<p>A logical, if true, to trigger the transformation <code class="reqn">u = 1 - \mathrm{acos}(2x - 1) / \pi</code> and <code class="reqn">v = 1 - \mathrm{acos}(2y - 1) / \pi</code> to convert <code class="reqn">(X,Y)</code> coordinates of a uniform unit circle to the <code class="reqn">(U,V)</code> in nonexceedance probability; and</p>
</td></tr>
<tr><td><code id="CIRCcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass, if ever needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CIRCcop(0.5, 0.5) # 0.25 quarterway along the diagonal upward to right
CIRCcop(0.5, 1  ) # 0.50 halfway across in horizontal direction
CIRCcop(1  , 0.5) # 0.50 halfway across in  vertical  direction

## Not run: 
  nsim &lt;- 2000
  rtheta &lt;- runif(nsim, min=0, max=2*pi) # polar coordinate simulation
  XY &lt;- data.frame(X=cos(rtheta)/2 + 1/2, Y=sin(rtheta)/2 + 1/2)
  plot(XY, lwd=0.8, col="lightgreen", xaxs="i", yaxs="i", las=1,
           xlab="X OF UNIT CIRCLE OR NONEXCEEDANCE PROBABILITY U",
           ylab="Y OF UNIT CIRCLE OR NONEXCEEDANCE PROBABILITY V")
  UV &lt;- simCOP(nsim, cop=CIRCcop, lwd=0.8, col="salmon3", ploton=FALSE)
  theta &lt;- 3/4*pi+0.1 # select a point on the upper left of the circle
  x &lt;- cos(theta)/2 + 1/2; y &lt;- sin(theta)/2 + 1/2 # coordinates
  H &lt;- CIRCcop(x, y, as.circ=TRUE) # 0.218169  # Pr[X &lt;= x &amp; Y &lt;= y]
  points(x, y, pch=16, col="forestgreen", cex=2)
  segments(0, y, x, y, lty=2, lwd=2, col="forestgreen")
  segments(x, 0, x, y, lty=2, lwd=2, col="forestgreen")
  Hemp1 &lt;- sum(XY$X &lt;= x &amp; XY$Y &lt;= y) / nrow(XY) # about 0.22 as expected
  u &lt;- 1-acos(2*x-1)/pi; v &lt;- 1-acos(2*y-1)/pi
  segments(0, v, u, v, lty=2, lwd=2, col="salmon3")
  segments(u, 0, u, v, lty=2, lwd=2, col="salmon3")
  points(u, v, pch=16, cex=2,        col="salmon3")
  arrows(x, y, u, v, code=2, lwd=2, angle=15) # arrow points from (X,Y) coordinate
  # specified by angle theta in radians on the unit circle to the corresponding
  # coordinate in (U,V) domain of uniform circular distribution copula
  Hemp2 &lt;- sum(UV$U &lt;= u &amp; UV$V &lt;= v) / nrow(UV) # about 0.22 as expected
  # Hemp1 and Hemp2 are about equal to each other and converge as nsim
  # gets very large, but the origin of the simulations to get to each
  # are different: (1) one in polar coordinates and (2) by copula.
  # Now, draw the level curve for the empirical Hs and as nsim gets large the two
  # lines will increasingly plot on top of each other.
  lshemp1 &lt;- level.setCOP(cop=CIRCcop, getlevel=Hemp1, lines=TRUE, col="blue", lwd=2)
  lshemp2 &lt;- level.setCOP(cop=CIRCcop, getlevel=Hemp2, lines=TRUE, col="blue", lwd=2)
  txt &lt;- paste0("level curves for Pr[X &lt;= x &amp; Y &lt;= y] and\n",
                "level curves for Pr[U &lt;= u &amp; V &lt;= v],\n",
                "which equal each other as nsim gets large")
  text(0.52, 0.52, txt, srt=-46, col="blue") # 
## End(Not run)

## Not run: 
  # Nelsen (2007, ex. 3.2, p. 57) # Singular bivariate distribution with
  # standard normal margins that is not bivariate normal.
  U &lt;- runif(500); V &lt;- simCOPmicro(U, cop=CIRCcop)
  X  &lt;- qnorm(U, mean=0, sd=1);    Y &lt;- qnorm(V, mean=0, sd=1)
  plot(X,Y, main="Nelsen (2007, ex. 3.2, p. 57)", xlim=c(-4,4), ylim=c(-4,4),
            lwd=0.8, col="turquoise")
  rug(X, side=1, col=grey(0,0.5), tcl=0.5)
  rug(Y, side=2, col=grey(0,0.5), tcl=0.5) #
## End(Not run)

## Not run: 
  DX &lt;- c(5, 5, -5, -5); DY &lt;- c(5, 5, -5, -5); D &lt;- 6; R &lt;- D/2
  plot(DX, DY, type="n", xlim=c(-10, 10), ylim=c(-10,10), xlab="X", ylab="Y")
  abline(h=DX, lwd=2, col="seagreen"); abline(v=DY, lwd=2, col="seagreen")
  for(i in seq_len(length(DX))) {
    for(j in seq_len(length(DY))) {
      UV &lt;- simCOP(n=30, cop=CIRCcop, pch=16, col="darkgreen", cex=0.5, graphics=FALSE)
      points(UV[,1]-0.5, UV[,2]-0.5, pch=16, col="darkgreen", cex=0.5)
      XY &lt;- data.frame(X=DX[i]+sign(DX[i])*D*(cos(pi*(UV$U-1))+1)/2-sign(DX[i])*R,
                       Y=DY[j]+sign(DY[j])*D*(cos(pi*(UV$V-1))+1)/2-sign(DY[j])*R)
      points(XY, lwd=0.8, col="darkgreen")
    }
    abline(h=DX[i]+R, lty=2, col="seagreen"); abline(h=DX[i]-R, lty=2, col="seagreen")
    abline(v=DY[i]+R, lty=2, col="seagreen"); abline(v=DY[i]-R, lty=2, col="seagreen")
  } #
## End(Not run)

## Not run: 
  para &lt;- list(cop1=CIRCcop, para1=NULL, cop2=W, para2=NULL, alpha=0.8, beta=0.8)
  UV &lt;- simCOP(n=2000, col="darkgreen", cop=composite2COP, para=para)
  XY &lt;- data.frame(X=(cos(pi*(UV$U-1))+1)/2, Y=(cos(pi*(UV$V-1))+1)/2)
  plot(XY, type="n", xlab=paste0("X OF CIRCULAR UNIFORM DISTRIBUTION OR\n",
                                 "NONEXCEEDANCD PROBABILITY OF U"),
                     ylab=paste0("Y OF CIRCULAR UNIFORM DISTRIBUTION OR\n",
                                 "NONEXCEEDANCD PROBABILITY OF V"))
  JK &lt;- data.frame(U=1 - acos(2*XY$X - 1)/pi, V=1 - acos(2*XY$Y - 1)/pi)
  segments(x0=UV$U, y0=UV$V, x1=XY$X, y1=XY$Y, col="lightgreen", lwd=0.8)
  points(XY, lwd=0.8, col="darkgreen")
  points(JK, pch=16,  col="darkgreen", cex=0.5)

  t &lt;- seq(0.001, 0.999, by=0.001)
  t &lt;- diagCOPatf(t, cop=composite2COP, para=para)
  AB &lt;- data.frame(X=(cos(pi*(t-1))+1)/2, Y=(cos(pi*(t-1))+1)/2)
  lines(AB, lwd=4, col="seagreen") #
## End(Not run)
</code></pre>

<hr>
<h2 id='CLcop'>The Clayton Copula</h2><span id='topic+CLcop'></span>

<h3>Description</h3>

<p>The <em>Clayton copula</em> (Joe, 2014, p. 168) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{CL}(u,v) = \mathrm{max}\bigl[(u^{-\Theta}+v^{-\Theta}-1; 0)\bigr]^{-1/\Theta}\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [-1,\infty), \Theta \ne 0</code>. The copula, as <code class="reqn">\Theta \rightarrow -1^{+}</code> limits, to the <em>countermonotonicity coupla</em> (<code class="reqn">\mathbf{W}(u,v)</code>; <code><a href="#topic+W">W</a></code>), as <code class="reqn">\Theta \rightarrow 0</code> limits to the <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>), and as <code class="reqn">\Theta \rightarrow \infty</code>, limits to the <em>comonotonicity copula</em> (<code class="reqn">\mathbf{M}(u,v)</code>;  <code><a href="#topic+M">M</a></code>). The parameter <code class="reqn">\Theta</code> is readily computed from a <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by <code class="reqn">\tau_\mathbf{C} = \Theta/(\Theta+2)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CLcop(u, v, para=NULL, tau=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CLcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="CLcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="CLcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="CLcop_+3A_tau">tau</code></td>
<td>
<p>Optional Kendall Tau; and</p>
</td></tr>
<tr><td><code id="CLcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned. Otherwise if <code>tau</code> is given, then the <code class="reqn">\Theta</code> is computed and a <code>list</code> having
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The parameter <code class="reqn">\Theta</code>, and</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Kendall Tau.</p>
</td></tr>
</table>
<p>and if <code>para=NULL</code> and <code>tau=NULL</code>, then the values within <code>u</code> and <code>v</code> are used to compute Kendall Tau and then compute the parameter, and these are returned in the aforementioned list.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>, <code><a href="#topic+W">W</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Lower tail dependency of Theta = pi --&gt; 2^(-1/pi) = 0.8020089 (Joe, 2014, p. 168)
taildepCOP(cop=CLcop, para=pi)$lambdaL # 0.80201
</code></pre>

<hr>
<h2 id='coCOP'>The Co-Copula Function</h2><span id='topic+coCOP'></span>

<h3>Description</h3>

<p>Compute the <em>co-copula (function)</em> from a copula (Nelsen, 2006, pp. 33&ndash;34), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U &gt; u \mathrm{\ or\ } V &gt; v] = \mathbf{C}^{\star}(u',v') = 1 - \mathbf{C}(u',v')\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}^{\star}(u',v')</code> is the co-copula and <code class="reqn">u'</code> and <code class="reqn">v'</code> are exceedance probabilities and are equivalent to <code class="reqn">1-u</code> and <code class="reqn">1-v</code> respectively. The co-copula is the expression for the probability that either <code class="reqn">U &gt; u</code> <b>or</b> <code class="reqn">V &gt; v</code> when the arguments to <code class="reqn">\mathbf{C}^{\star}(u',v')</code> are exceedance probabilities, which is unlike the <em>dual of a copula (function)</em> (see <code><a href="#topic+duCOP">duCOP</a></code>) that provides <code class="reqn">\mathrm{Pr}[U \le u \mathrm{\ or\ } V \le v]</code>.
</p>
<p>The co-copula is a function and not in itself a copula. Some rules of copulas mean that <code class="reqn">\mathbf{C}(u,v) + \mathbf{C}^{\star}(u',v') \equiv 1</code> or in <span class="pkg">copBasic</span> syntax that the functions <code>COP(u,v)</code> + <code>coCOP(u,v)</code> equal unity if the <code>exceedance</code> argument to <code>coCOP</code> is set to <code>FALSE</code>.
</p>
<p>The function <code>coCOP</code> gives &ldquo;risk&rdquo; against failure if failure is defined as either hazard source <code class="reqn">U</code> or <code class="reqn">V</code> occuring by themselves or if both occurred at the same time. Expressing this in terms of an annual probability of occurrence (<code class="reqn">q</code>), one has
</p>
<p style="text-align: center;"><code class="reqn">q = 1 - \mathrm{Pr}[U &gt; u \mathrm{\ or\ } V &gt; v] =  \mathbf{C}^{\star}(u',v') \mbox{\ or}</code>
</p>

<p>in <span class="rlang"><b>R</b></span> code <code>q &lt;- coCOP(u,v, exceedance=FALSE, ...)</code>. So, in yet other words and as a mnemonic: <em>A co-copula is the probabililty of exceedance if the hazard sources <b>collaborate</b> or <b>cooperate</b> to cause failure.</em> Also, <code class="reqn">q</code> can be computed by <code>q &lt;- </code><code>coCOP(1 - u, 1 - v,</code> <code>exceedance=TRUE, ...)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coCOP(u, v, cop=NULL, para=NULL, exceedance=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coCOP_+3A_u">u</code></td>
<td>
<p>Exceedance probability (<code class="reqn">u' = 1-u</code>) in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="coCOP_+3A_v">v</code></td>
<td>
<p>Exceedance probability (<code class="reqn">v' = 1-v</code>) in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="coCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="coCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="coCOP_+3A_exceedance">exceedance</code></td>
<td>
<p>A logical controlling the probability direction. Are <code>u</code> and <code>v</code> values given really <code class="reqn">u'</code> and <code class="reqn">v'</code>, respectively? If <code>FALSE</code>, then the complements of the two are made internally and the nonexceedances can thus be passed; and</p>
</td></tr>
<tr><td><code id="coCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value(s) for the co-copula are returned.
</p>


<h3>Note</h3>

<p>The author (Asquith) finds the use of exceedance probabilities delicate in regards to Nelsen's notation. The <code>coCOP</code> function and <code><a href="#topic+surCOP">surCOP</a></code> have the <code>exceedance</code> argument to serve as a reminder that the co-copula as defined in the literature uses <em>exceedance probabilities</em> as its arguments, although the arguments as code <code>u</code> and <code>v</code> do not mimic the overline nomenclature (<code class="reqn">\,\overline{\cdots}\,</code>) of the exceedance (survival) probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+surCOP">surCOP</a></code>, <code><a href="#topic+duCOP">duCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>u &lt;- 1 - runif(1); v &lt;- 1 - runif(1) # as exceedance, in order to reinforce the
# change to exceedance instead of nonexceedance that otherwise dominates this package
message("Exceedance probabilities u' and v' are ", u, " and ", v)
coCOP(u,v,cop=PLACKETTcop, para=10) # Positive association Plackett

# computation using  manual  manipulation to nonexceedance probability
1 - COP(cop=PSP,(1-u),(1-v))
# computation using internal manipulation to nonexceedance probability
  coCOP(cop=PSP,   u,    v)

# Next demonstrate COP + coCOP = unity.
"MOcop.formula" &lt;- function(u,v, para=para, ...) { # Marshall-Olkin copula
   alpha &lt;- para[1]; beta &lt;- para[2]; return(min(v*u^(1-alpha), u*v^(1-beta)))
}
"MOcop" &lt;- function(u,v, ...) { asCOP( u,  v, f=MOcop.formula, ...) }
u &lt;- 0.2; v &lt;- 0.75; ab &lt;- c(1.5, 0.3)
COP(u,v, cop=MOcop, para=ab) + coCOP(1-u,1-v, cop=MOcop, para=ab) # UNITY
</code></pre>

<hr>
<h2 id='composite1COP'>Composition of a Single Symmetric Copula with Two Compositing Parameters (Khoudraji Device with Pi Independence)</h2><span id='topic+composite1COP'></span><span id='topic+khoudraji1COP'></span><span id='topic+khoudrajiPCOP'></span>

<h3>Description</h3>

<p>The <em>composition of a single copula</em> (Salvadori <em>et al.</em>, 2006, p. 266, prop. C.3) is created by the following result related to &ldquo;composition of copulas&rdquo; in that reference.  This construction technique is named the <em>Khoudraji device</em> within the <span class="pkg">copula</span> package (see <code>khoudrajiCopula</code> therein) (Hofert <em>et al.</em>, 2018, pp. 120&ndash;121). Suppose <code class="reqn">\mathbf{C}(u,v)</code> is a <em>symmetric copula</em> (see <code><a href="#topic+COP">COP</a></code>) with parameters <code class="reqn">\Theta</code> and <code class="reqn">\mathbf{C} \ne \mathbf{\Pi}</code> (for <code class="reqn">\mathbf{\Pi}</code> see <code><a href="#topic+P">P</a></code>), then a family of generally <em>asymmetric copulas</em> <code class="reqn">\mathbf{C}_{\alpha,\beta; \Theta}</code> with <b>two</b> <em>compositing parameters</em> <code class="reqn">0 &lt; \alpha,\beta &lt; 1</code>, and <code class="reqn">\alpha \ne \beta</code>, which also includes just the copula <code class="reqn">\mathbf{C}(u,v)</code> as a limiting case for <code class="reqn">\alpha = \beta = 0</code> and is given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\alpha,\beta}(u,v) = u^\alpha v^\beta \cdot \mathbf{C}(u^{1-\alpha},v^{1-\beta})\mbox{.}</code>
</p>

<p>The <code>composite1COP</code> function provides the means for inserting <em>permutation asymmetry</em> from a <em>permutation symmetric</em> copula as described by Joe (2017, p. 124), but do so in a more general way through the provision of two and not just one parameter. Joe's description is supported herein if one of the <code class="reqn">\alpha</code> or <code class="reqn">\beta</code> is held at zero. Very loosely, the <code class="reqn">\alpha &gt; 0</code> kicks probability density down towards the lower right corner, whereas <code class="reqn">\beta &gt; 0</code> kicks density up towards the upper left corner. Finally, the <code><a href="#topic+composite2COP">composite2COP</a></code> function is based on a slighty more general result (see <code><a href="#topic+composite2COP">composite2COP</a></code> for further details of copula composition and more contextualization of Hofert <em>et al.</em> (2018) remarks on the <em>Khoudraji device</em>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>composite1COP(u, v, para, ...)
khoudraji1COP(u, v, para, ...)
khoudrajiPCOP(u, v, para, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="composite1COP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="composite1COP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="composite1COP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="composite1COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the composited copula are returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>alpha</code></dt><dd><p>&mdash; The <code class="reqn">\alpha</code> compositing parameter;</p>
</dd>
<dt><code>beta</code></dt><dd><p>&mdash; The <code class="reqn">\beta</code> compositing parameter;</p>
</dd>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the copula <code class="reqn">\mathbf{C}(u,v)</code>; and</p>
</dd>
<dt><code>para1</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{C}</code> for <code class="reqn">\mathbf{C}(u,v)</code>.</p>
</dd>
</dl>

<p>For the <code>para</code> argument, the same nomenclature as used for <code><a href="#topic+composite2COP">composite2COP</a></code> is used with obviously <code>cop2</code> and <code>para2</code> dropped for <code>composite1COP</code>. The <code>cop1</code> and <code>para1</code> names remain enumerated for <code>composite1COP</code> so that the <code>para</code> argument of the more general <code><a href="#topic+composite2COP">composite2COP</a></code> function could be used directly in <code><a href="#topic+composite1COP">composite1COP</a></code>. Albeit, the second copula and its parameters would not be used. A more complex (extended) composition in <code><a href="#topic+composite3COP">composite3COP</a></code> extends this basic parameter structure.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hofert, M., Kojadinovic, I., Mächler,  M., and Yan, J., 2018, Elements of copula modeling with R: Dordrecht, Netherlands, Springer.
</p>
<p>Joe, H., 2017, Parametric copula families for statistical models (chap. 8)  <em>in</em> Copulas and dependence models with applications&mdash;Contributions in honor of Roger B. Nelsen, <em>eds.</em> Flores, U.M., Amo Artero, E., Durante, F., Sánchez, J.F.: Springer, Cham, Switzerland, ISBN 978&ndash;3&ndash;319&ndash;64220&ndash;9, <a href="https://doi.org/10.1007/978-3-319-64221-5">doi:10.1007/978-3-319-64221-5</a>.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+breveCOP">breveCOP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>,
<code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
alpha &lt;- 0.24; beta &lt;- 0.23; Theta1 &lt;- NA;
# W() does not use a parameter, but show how a parameter would be set if needed.
para  &lt;- list(alpha=alpha, beta=beta, cop1=W, para1=Theta1)
t &lt;- composite1COP(0.4, 0.6, para)
if( t != W(0.4, 0.6)) message("Not equal as expected") #
## End(Not run)

## Not run: 
  # Hofert et al. (2018, p. 124, eq. 3.15)
  #   No matter what copula is chosen, Kendall tau must be
  #     Tau &lt;= (alpha*beta)/(alpha + beta - alpha*beta)
  #   and those authors report Tau &lt;= 0.5816. We can test this computation by
  para &lt;- list(cop=M, para=NULL, alpha=1-0.6, beta=1-0.95)
  tauCOP(khoudrajiPCOP, para=para) # 0.5816283 
## End(Not run)

## Not run: 
  # Next use this as a chance to check logic flow through the various
  # "compositing" operators and their as needed dispatch to COP().
  my.para &lt;- list(cop1=GHcop, para1=exp(+1.098612) + 1,
                  cop2=PLcop, para2=exp(-1.203973),
                  alpha=0.5,  beta=0.25, kappa=0.1, gamma=0.1,
                  weights=c(0.95, 0.05))
  # uses cop1/2, para1/2, only weights
  nustarCOP(cop=convexCOP,     para=my.para) # 0.8570434

  # uses cop1/2, para1/2, only alpha
  nustarCOP(cop=convex2COP,    para=my.para) # 0.2697063

  # uses cop1,   para1,   only alpha / beta
  nustarCOP(cop=composite1COP, para=my.para) # 0.5103119

  # uses cop1/2, para1/2, only alpha / beta
  nustarCOP(cop=composite2COP, para=my.para) # 0.0714571

  # uses cop1/2, para1/2, only alpha, beta, kappa, gamma
  nustarCOP(cop=composite3COP, para=my.para) # 0.0792634 
## End(Not run)

## Not run: 
  # Hofert et al. (2018, p. 121, fig. 3.20, left panel)
  #   The ordering of copula and the "1-" operations on alpha and beta in copBasic
  #   differ from that shown in Hofert et al. (2018), but instead of their
  #   "kho(0.6, 0.95)(CLcop(6), P)" notation for the their left panel, in copBasic
  #   we can reproduce their simulation by the following. So, swapping notation
  #   between the copula package (khoudarjiCopula) and copBasic would be required.
  para &lt;- list(cop=CLcop, para=6, alpha=1-0.95, beta=1-0.6)
  UV &lt;- simCOP(n=5000, cop=khoudrajiPCOP, para=para) # 
## End(Not run)

</code></pre>

<hr>
<h2 id='composite2COP'>Composition of Two Copulas with Two Compositing Parameters (Khoudraji Device)</h2><span id='topic+composite2COP'></span><span id='topic+khoudraji2COP'></span>

<h3>Description</h3>

<p>The <em>composition of two copulas</em> (Salvadori <em>et al.</em>, 2007, p. 266, prop. C.3) provides for more sophisticated structures of dependence between variables than many single parameter copula can provide. Further, <em>asymmetrical copulas</em> are readily obtained from <em>symmetrical copulas</em>. Let <code class="reqn">\mathbf{A}</code> and <code class="reqn">\mathbf{B}</code> be copulas with respective parameters <code class="reqn">\Theta_\mathbf{A}</code> and <code class="reqn">\Theta_\mathbf{B}</code>, then
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\alpha,\beta}(u,v) = \mathbf{A}(u^\alpha,    v^\beta) \cdot
                              \mathbf{B}(u^{1-\alpha},v^{1-\beta})\mbox{,}</code>
</p>

<p>defines a family of copulas <code class="reqn">\mathbf{C}_{\alpha,\beta; \Theta_\mathbf{A}, \Theta_\mathbf{B}}</code> with <b>two</b> <em>compositing parameters</em> <code class="reqn">\alpha,\beta \in \mathcal{I}:[0,1]</code>. In particular if <code class="reqn">\alpha = \beta = 1</code>, then <code class="reqn">\mathbf{C}_{1,1} = \mathbf{A}</code>, and if <code class="reqn">\alpha = \beta = 0</code>, then <code class="reqn">\mathbf{C}_{0,0} = \mathbf{B}</code>. For <code class="reqn">\alpha \ne \beta</code>, the <code class="reqn">\mathbf{C}_{\alpha,\beta}</code> is in general asymmetric that is <code class="reqn">\mathbf{C}(u,v) \ne \mathbf{C}(v,u)</code> for some <code class="reqn">(u,v) \in \mathcal{I}^2</code>. This construction technique is named the <em>Khoudraji device</em> within the <span class="pkg">copula</span> package (see <code>khoudrajiCopula</code> therein) (Hofert <em>et al.</em>, 2018, p. 120).
</p>
<p>It is important to stress that copulas <code class="reqn">\mathbf{A}_{\Theta_A}</code> and <code class="reqn">\mathbf{B}_{\Theta_B}</code> can be of different families and each copula parameterized accordingly by the vector of parameters <code class="reqn">\Theta_A</code> and <code class="reqn">\Theta_B</code>. This is an interesting feature in the context of building complex structures when pursuing asymmetric measures of dependency such as the <em>L-comoments</em>. Symmetry of the copula <code class="reqn">\mathbf{C}</code> is required for the situation that follows, however.
</p>
<p>It is possible to simplify the construction of an asymmetric copula from a symmetric copula by the following. Let <code class="reqn">\mathbf{C}(u,v)</code> be a symmetric copula, <code class="reqn">\mathbf{C} \ne \mathbf{\Pi}</code> (for <code class="reqn">\mathbf{\Pi}</code> see <code><a href="#topic+P">P</a></code>). A family of asymmetric copulas <code class="reqn">\mathbf{C}_{\alpha,\beta}</code> with <b>two</b> <em>composition parameters</em> <code class="reqn">0 &lt; \alpha,\beta &lt; 1, \mbox{and\ } \alpha \ne \beta</code> that also includes <code class="reqn">\mathbf{C}(u,v)</code> as a limiting case and is given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\alpha,\beta}(u,v) = u^\alpha v^\beta \cdot \mathbf{C}(u^{1-\alpha},v^{1-\beta})\mbox{.}</code>
</p>

<p>Hofert <em>et al.</em> (2018, p. 121) comment that &ldquo;from a practical perspective, a useful subset of families constructed from [the] Khoudraji device is obtained&rdquo; by choosing <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}</code>, <code><a href="#topic+P">P</a></code>) for one of the copula and that choosing [<code class="reqn">\alpha</code> or <code class="reqn">\beta</code>] relative close to <code class="reqn">1</code> produces nonexchangable [see <code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>] versions of <code class="reqn">\mathbf{C}(u,v)</code> (meaning <code class="reqn">\mathbf{C}(u,v) \ne \mathbf{C}(v,u)</code>). For the <span class="pkg">copBasic</span> package, the <code>khoudraji1COP()</code> and <code>khoudrajiPCOP()</code> (the <code>P</code> meaning <code><a href="#topic+P">P</a></code>) aliases are added for programming clarity for developers desiring to have contrasting copula calls to the three <em>compositing</em> copula: <code><a href="#topic+composite1COP">composite1COP</a></code>, <code>composite2COP()</code>, and <code><a href="#topic+composite3COP">composite3COP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>composite2COP(u, v, para, ...)
khoudraji2COP(u, v, para, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="composite2COP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="composite2COP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="composite2COP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="composite2COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copulas.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the composited copula is returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>alpha</code></dt><dd><p>&mdash; The <code class="reqn">\alpha</code> compositing parameter;</p>
</dd>
<dt><code>beta</code></dt><dd><p>&mdash; The <code class="reqn">\beta</code> compositing parameter;</p>
</dd>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the first copula <code class="reqn">\mathbf{A}</code>;</p>
</dd>
<dt><code>cop2</code></dt><dd><p>&mdash; Function of the second copula <code class="reqn">\mathbf{B}</code>;</p>
</dd>
<dt><code>para1</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{A}</code> for <code class="reqn">\mathbf{A}</code>; and</p>
</dd>
<dt><code>para2</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{B}</code> for <code class="reqn">\mathbf{B}</code>.</p>
</dd>
</dl>

<p>The <code>para</code> argument of this function also can be passed to <code><a href="#topic+composite1COP">composite1COP</a></code>; albeit, the second copula and its parameters would not be used. A more complex (extended) composition in <code><a href="#topic+composite3COP">composite3COP</a></code> extends this basic parameter structure.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hofert, M., Kojadinovic, I., Mächler,  M., and Yan, J., 2018, Elements of copula modeling with R: Dordrecht, Netherlands, Springer.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+breveCOP">breveCOP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>,
<code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>alpha &lt;- 0.24; beta &lt;- 0.23; Theta1 &lt;- NA; Theta2 &lt;- NA
# The W() and PSP() copulas do not take parameters, but example shows how the
# parameters would be set should either or both of the copulas require parameters.
para &lt;- list(alpha=alpha, beta=beta, cop1=W, cop2=PSP, para1=Theta1, para2=Theta2)
print(composite2COP(0.4, 0.6, para)) # 0.2779868

# In this example, the N4212cop uses "3" as its parameter value.
para &lt;- list(alpha=alpha, beta=beta, cop1=W, cop2=N4212cop, para1=Theta1, para2=3)
print(composite2COP(0.4, 0.6, para)) # 0.3387506

## Not run: 
  # This example does a great job of showing a composited copula with a near singularity,
  # but with leakage of chance to the upper left. The example is also critical because
  # it shows that gridCOP is returning a matrix in the proper orientation relative to
  # the level.curvesCOP and simCOP functions. Example is cross-ref'ed from gridCOP() docs.
  layout(matrix(1:2,byrow=TRUE))
  para &lt;- list(alpha=0.5, beta=0.90, cop1=M, cop2=N4212cop, para1=NA, para2=1.4)
  image(gridCOP(cop=composite2COP, para=para, delta=0.01), col=terrain.colors(30),
        xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
  D &lt;- simCOP(n=2000, cop=composite2COP, para=para, ploton=FALSE, pch=4, col=4, cex=0.75)
  level.curvesCOP(cop=composite2COP, para=para, ploton=FALSE, delt=0.05)
  mtext("Theoretical composited copula, level curves, and simulation")

  emp &lt;- EMPIRgrid(para=D, deluv=0.05)     # CPU heavy
  image(emp$empcop, col=terrain.colors(30) ) # image orientation is correct!
  # Depending on balance between sample size, deluv, delu, and delt, one or more:
  # Error in uniroot(func, interval = c(0, 1), u = u, LHS = t, cop = cop,  :
  #   f() values at end points not of opposite sign
  # warnings might be triggered. This is particularly true because of the flat derivative
  # above the near singularity in this example composited copula.
  points(D$U, D$V, pch=4, col=4, cex=0.75)
  level.curvesCOP(cop=EMPIRcop, para=D, ploton=FALSE, delu=0.02, delt=0.05)
  mtext("Empirical copula from n=2000 simulation") #
## End(Not run)
</code></pre>

<hr>
<h2 id='composite3COP'>(Extended) Composition of Two Copulas with Four Compositing Parameters</h2><span id='topic+composite3COP'></span>

<h3>Description</h3>

<p>The <em>(extended) composition of two copulas</em>  (Salvadori <em>et al.</em>, 2006, p. 266, prop. C.4) provides for even more sophisticated structures of dependence between variables than two-copula composition in <code><a href="#topic+composite2COP">composite2COP</a></code>. Let <code class="reqn">\mathbf{A}</code> and <code class="reqn">\mathbf{B}</code> be copulas with respective parameters <code class="reqn">\Theta_\mathbf{A}</code> and <code class="reqn">\Theta_\mathbf{B}</code>, then
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\alpha,\beta,\kappa,\gamma}(u,v) = u^\kappa v^\gamma \cdot
                              \mathbf{A}([u^{1-\kappa}]^\alpha,    [v^{1-\gamma}]^\beta) \cdot
                              \mathbf{B}([u^{1-\kappa}]^{1-\alpha},[v^{1-\gamma}]^{1-\beta})\mbox{,}</code>
</p>

<p>defines a family of copulas <code class="reqn">\mathbf{C}_{\alpha,\beta,\kappa,\gamma}</code> with <b>four</b> <em>compositing parameters</em> <code class="reqn">\alpha,\beta,\kappa,\gamma \in (0,1)</code>.
</p>
<p>It is important to stress that copulas <code class="reqn">\mathbf{A}_{\Theta_A}</code> and <code class="reqn">\mathbf{B}_{\Theta_B}</code> can be of different families and each parameterized accordingly by the vectors of parameters <code class="reqn">\Theta_A</code> and <code class="reqn">\Theta_B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>composite3COP(u, v, para, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="composite3COP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="composite3COP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="composite3COP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="composite3COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+composite2COP">composite2COP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value for the composited copula is returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>alpha</code></dt><dd><p>&mdash; The <code class="reqn">\alpha</code> compositing parameter;</p>
</dd>
<dt><code>beta</code></dt><dd><p>&mdash; The <code class="reqn">\beta</code> compositing parameter;</p>
</dd>
<dt><code>kappa</code></dt><dd><p>&mdash; The <code class="reqn">\kappa</code> compositing parameter;</p>
</dd>
<dt><code>gamma</code></dt><dd><p>&mdash; The <code class="reqn">\gamma</code> compositing parameter;</p>
</dd>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the first copula <code class="reqn">\mathbf{A}</code>;</p>
</dd>
<dt><code>cop2</code></dt><dd><p>&mdash; Function of the second copula <code class="reqn">\mathbf{B}</code>;</p>
</dd>
<dt><code>para1</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{A}</code> for <code class="reqn">\mathbf{A}</code>; and</p>
</dd>
<dt><code>para2</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{B}</code> for <code class="reqn">\mathbf{B}</code>.</p>
</dd>
</dl>
<p>The first example produces two plots. These are extremely informative for many nuances of copula theory. Whereas it is difficult in prose to describe, users are strongly encouraged that once full understanding of connection of red and green between the easier to understand bivariate plot and the plot showing the sections and derivatives of the sections is achieved that much of copula theory will be mastered&mdash;get a copy of Nelsen (2006) and (or) Salvadori <em>et al.</em> (2007).

</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+breveCOP">breveCOP</a></code>, <code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code>, <code><a href="#topic+simcomposite3COP">simcomposite3COP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- list(cop1=PLACKETTcop, cop2=N4212cop,
             para1=10^(runif(1,min=-5,max=5)), para2=runif(1,min=1,max=100),
             alpha=runif(1), beta=runif(1), kappa=runif(1), gamma=runif(1))
txts &lt;- c("Alpha=",    round(para$alpha,    digits=4),
          "; Beta=",   round(para$beta,     digits=4),
          "; Kappa=",  round(para$kappa,    digits=4),
          "; Gamma=",  round(para$gamma,    digits=4),
          "; Theta1=", round(para$para1[1], digits=5),
          "; Theta2=", round(para$para2[1], digits=2))
layout(matrix(1:2, byrow=TRUE))
D &lt;- simCOP(n=300, cop=composite3COP, para=para, cex=0.5, col=rgb(0,0,0,0.2), pch=16)
mtext(paste(txts,collapse=""))

f &lt;- round(runif(1),digits=2)
ftxt &lt;- c("Sectionals (thick) and derivatives (thin) at f=",f," nonexceedance prob.")
segments(f,0,f,1, col=3, lwd=2); segments(0,f,1,f, col=2, lwd=2)
t &lt;- sectionCOP(f,cop=composite3COP,para=para, col=3, lwd=4)
t &lt;- sectionCOP(f,cop=composite3COP,para=para, dercop=TRUE, ploton=FALSE,col=3)
t &lt;- sectionCOP(f,cop=composite3COP,para=para, wrtV=TRUE,   ploton=FALSE,col=2,lwd=4)
t &lt;- sectionCOP(f,cop=composite3COP,para=para, wrtV=TRUE,   ploton=FALSE,col=2,
                  dercop=TRUE)
mtext(paste(ftxt, collapse=""))#
## End(Not run)
</code></pre>

<hr>
<h2 id='convex2COP'>Convex Combination of Two Copulas</h2><span id='topic+convex2COP'></span>

<h3>Description</h3>

<p>The <em>convex composition of two copulas</em> (Joe, 2014, p. 155) provides for some simple complexity extension between copula families. Let <code class="reqn">\mathbf{A}</code> and <code class="reqn">\mathbf{B}</code> be copulas with respective vectors of parameters <code class="reqn">\Theta_\mathbf{A}</code> and <code class="reqn">\Theta_\mathbf{B}</code>, then the convex combination of these copulas is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^{\times}_{\alpha}(u,v) = \alpha\cdot\mathbf{A}(u, v; \Theta_\mathbf{A}) - (1-\alpha)\cdot\mathbf{B}(u,v; \Theta_\mathbf{B})\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le \alpha \le 1</code>. The generalization of this function for <code class="reqn">N</code> number of copulas is provided by <code><a href="#topic+convexCOP">convexCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convex2COP(u,v, para, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convex2COP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="convex2COP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="convex2COP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="convex2COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the convex combination copula is returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>alpha</code></dt><dd><p>&mdash; The <code class="reqn">\alpha</code> compositing parameter;</p>
</dd>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the first copula <code class="reqn">\mathbf{A}</code>;</p>
</dd>
<dt><code>cop2</code></dt><dd><p>&mdash; Function of the second copula  <code class="reqn">\mathbf{B}</code>;</p>
</dd>
<dt><code>para1</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{A}</code> for  <code class="reqn">\mathbf{A}</code>; and</p>
</dd>
<dt><code>para2</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{B}</code> for  <code class="reqn">\mathbf{B}</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+breveCOP">breveCOP</a></code>, <code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>, <code><a href="#topic+FRECHETcop">FRECHETcop</a></code>, <br /> <code><a href="#topic+glueCOP">glueCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- list(alpha=0.24, cop1=FRECHETcop, para1=c(0.4, 0.56),
                         cop2=PSP,        para2=NA)
convex2COP(0.87,0.35, para=para) # 0.3188711
## Not run: 
# Suppose we have a target Kendall Tau of 1/3 and a Gumbel-Hougaard copula seems
# attractive but the GH has just too much upper tail dependency for comfort. We
# think from data analysis that an upper tail dependency that is weaker and near
# 2/10 is the better. Let us convex mix in a Plackett copula and optimize.
TargetTau &lt;- tauCOP(cop=GHcop, para=1.5) # 1/3 (Kendall Tau)
taildepCOP(   cop=GHcop, para=1.5, plot = TRUE)$lambdaU  # 0.4126
TargetUpperTailDep &lt;- 2/10

# **Serious CPU time pending for this example**
par &lt;- c(-.10, 4.65) # Initial guess but the first parameter is in standard
# normal for optim() to keep us in the [0,1] domain when converted to probability.
# The guesses of -0.10 (standard deviation) for the convex parameter and 4.65 for
# the Plackett are based on a much longer search times as setup for this problem.
# The simplex for optim() is going to be close to the solution on startup.
"afunc" &lt;- function(par) {
   para &lt;- list(alpha=pnorm(par[1]), cop1=GHcop,       para1=1.5,
                                     cop2=PLACKETTcop, para2=par[2])
   tau  &lt;- tauCOP(cop=convex2COP, para=para)
   taildep &lt;- taildepCOP(cop=convex2COP, para=para, plot = FALSE)$lambdaU
   err &lt;- sqrt((TargetTau - tau)^2 + (TargetUpperTailDep - taildep)^2)
   print(c(pnorm(par[1]), par[2], tau, taildep, err))
   return(err)
}
mysolution &lt;- optim(par, afunc, control=list(abstol=1E-4))

para &lt;- list(alpha=.4846902, cop1=GHcop,       para1=1.5,
                             cop2=PLACKETTcop, para2=4.711464)
UV &lt;- simCOP(n=2500, cop=convex2COP, para=para, snv=TRUE) #
## End(Not run)
</code></pre>

<hr>
<h2 id='convexCOP'>Convex Combination of an Arbitrary Number of Copulas</h2><span id='topic+convexCOP'></span>

<h3>Description</h3>

<p>The <em>convex composition of <code class="reqn">N</code> number of copulas</em> (Salvadori <em>et al.</em>, p. 132, 2007) provides for complexity extension between coupla families. Let <code class="reqn">\mathbf{C}_{i}</code> be a copula with respective vector of parameters <code class="reqn">\Theta_i</code>, then the convex combination of these copulas is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^{\times}_{\omega}(u,v) = \sum_{i=1}^N \omega_i \mathbf{C}_{i}(u, v; \Theta_i)\mbox{,}</code>
</p>

<p>where <code class="reqn">\sum_{i=1}^N \omega_i = 1</code> for <code class="reqn">N</code> number of copulas. The weights <code class="reqn">\omega</code> are silently treated as <code class="reqn">1/N</code> if the <code>weights</code> element is absent in the <span class="rlang"><b>R</b></span> <code>list</code> argument <code>para</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convexCOP(u,v, para, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convexCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="convexCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="convexCOP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="convexCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the convex combination copula is returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument but please reference the <b>Examples</b> to see the <code>i</code> notation:
</p>

<dl>
<dt><code>copi</code></dt><dd><p>&mdash; The <code class="reqn">i</code>th copula;</p>
</dd>
<dt><code>parai</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_i</code>; and</p>
</dd>
<dt><code>weights</code></dt><dd><p>&mdash; Optional vector of weights whose sum will be rescaled to unity; default is <code class="reqn">1/N</code> for each weight.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+breveCOP">breveCOP</a></code>, <code><a href="#topic+convex2COP">convex2COP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># The copulas and parameters are named by sequence number appended to cop and para.
para1 &lt;- list(cop1=GHcop, cop2=PLcop, para1=8, para2=.03, weights=c(.8,.2))
para2 &lt;- list(cop1=GHcop, cop2=PLcop, para1=8, para2=.03, alpha=0.8)
H &lt;- convexCOP( 0.6,0.4, para=para1)
G &lt;- convex2COP(0.6,0.4, para=para2)
if( abs(H-G) &lt;= 1e-6 )  message("They are equal.")

## Not run: 
# A convex combination of three copulas. A GHcop with strong positive association and
# a Plackett with strong negative association, and independence. The weights favor the
# GHcop but a little outlier and expansive spread is superimposed on the core trend.
para &lt;- list(cop1=GHcop, cop2=PLcop, cop3=P,
             para1=8, para2=.03, para3=NA, weights=c(40,7,10))
UV &lt;- simCOP(1000, cop=convexCOP, para=para, lwd=0.8) #
## End(Not run)
</code></pre>

<hr>
<h2 id='COP'>The Copula</h2><span id='topic+COP'></span>

<h3>Description</h3>

<p>Compute the <em>copula</em> or <em>joint distribution function</em> through a copula as shown by Nelsen (2006, p. 18) is the joint probability
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le u, V \le v] = \mathbf{C}(u,v)\mbox{.}</code>
</p>

<p>The copula is an expression of the joint probability that both <code class="reqn">U \le u</code> and <code class="reqn">V \le v</code>.
</p>
<p>A copula is a type of <em>dependence function</em> that permits straightforward characterization of dependence from independence.  Joe (2014, p. 8) comments that &ldquo;copula families are usually given as cdfs [cumulative distribution functions.]&rdquo; A <em>radially symmetric</em> or <em>permutation symmetric copula</em> is one such that <code class="reqn">\mathbf{C}(u,v) = \mathbf{C}(v,u)</code> otherwise the copula is <em>asymmetric</em>.
</p>
<p>The copula <em>inversions</em> <code class="reqn">t = \mathbf{C}(u{=}U, v)</code> or <code class="reqn">t = \mathbf{C}(u, v{=}V)</code> for a given <code class="reqn">t</code> and <code class="reqn">U</code> or <code class="reqn">V</code> are provided by <code><a href="#topic+COPinv">COPinv</a></code> and <code><a href="#topic+COPinv2">COPinv2</a></code>, respectively. A copula exists in the domain of the unit square (<code class="reqn">\mathcal{I}^2 = [0, 1]\times [0,1]</code>) and is a <em>grounded</em> function meaning that
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,0) = 0 = \mathbf{C}(0,v) \mbox{\ and\ thus\ } \mathbf{C}(0,0) = 0\mbox{, }</code>
</p>

<p>and other properties of a copula are that
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,1) = u \mbox{\ and\ } \mathbf{C}(1,v) = v\mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{C}(1,1) = 1\mbox{.}</code>
</p>

<p>Copulas can be combined with each other (<code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+convex2COP">convex2COP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <br /> <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>, and <code><a href="#topic+glueCOP">glueCOP</a></code>) to form more complex and sophisticated dependence structures. Also copula multiplication&mdash;a special product of two copulas&mdash;yields another copula (see <code><a href="#topic+prod2COP">prod2COP</a></code>).
</p>
<p>Perhaps the one of the more useful features of this function is that in practical applications it can be used to take a copula formula and reflect or rotated it in fashions to attain association structures that the native definition of the copula can not acquire. The terminal demonstration in the <b>Examples</b> demonstrates this for the <em>Raftery copula</em> (<code><a href="#topic+RFcop">RFcop</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COP(u, v, cop=NULL, para=NULL,
          reflect=c("cop", "surv", "acute", "grave",
                      "1",    "2",     "3",     "4"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="COP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="COP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="COP_+3A_cop">cop</code></td>
<td>
<p>A copula function with vectorization as in <code>asCOP</code>;</p>
</td></tr>
<tr><td><code id="COP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structures, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="COP_+3A_reflect">reflect</code></td>
<td>
<p>The reflection of the copula form (see <b>Note</b>) and the default <code>"cop"</code> or <code>"1"</code> is the usual copula definition (also see <code><a href="#topic+simCOPmicro">simCOPmicro</a></code>). The numbered values correspond, respectively, to the named values; and</p>
</td></tr>
<tr><td><code id="COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p><em>REFLECTIONS OF VARIABLES (ROTATIONS OF THE COPULA)</em>&mdash;The copula of <code class="reqn">(1-U, 1-V)</code> is the survival copula (<code class="reqn">\hat{\mathbf{C}}(u,v)</code>; <code><a href="#topic+surCOP">surCOP</a></code>) and is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[\,U &gt; u, V &gt; v\,] = \hat{\mathbf{C}}(u,v) = u + v - 1 + \mathbf{C}(1-u,1-v)\:\rightarrow\mbox{\ \code{"surv"},}</code>
</p>

<p>whereas, following the notation of Joe (2014, p. 271), the copula of <code class="reqn">(1-U, V)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[\,U &gt; u, V \le v\,] = \acute{\mathbf{C}}(u,v) = v - \mathbf{C}(1-u,v)\:\rightarrow\mbox{\ \code{"acute"}, and}</code>
</p>

<p>the copula of <code class="reqn">(U, 1-V)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[\,U \le u, V &gt; v\,] = \grave{\mathbf{C}}(u,v) = u - \mathbf{C}(u,1-v)\:\rightarrow\mbox{\ \code{"grave"}.}</code>
</p>

<p>Here it is useful to stress the probability aspects that change with the reflections, but this section ends with the reflections themselves being graphically highlighted. The <b>Examples</b> stress simple variations on the probability aspects.
</p>
<p>To clarify the seemingly clunky nomenclature&mdash;Joe (2014) does not provide &ldquo;names&rdquo; for <code class="reqn">\acute{\mathbf{C}}(u,v)</code> or <code class="reqn">\grave{\mathbf{C}}(u,v)</code>&mdash;the following guidance is informative where the numbers in the list align to those for the <code>reflect</code> argument:<br />
<code class="reqn">\mbox{}\quad\mbox{}</code>(2) <code>"surv"</code> or <code class="reqn">\hat{\mathbf{C}}(u,v)</code> is a reflection of <code class="reqn">U</code> and <code class="reqn">V</code> on the horizontal <em>and</em> vertical axes, respectively,<br />
<code class="reqn">\mbox{}\quad\mbox{}</code>(3) <code>"acute"</code> or <code class="reqn">\acute{\mathbf{C}}(u,v)</code> is a reflection of <code class="reqn">U</code> on the horizontal axis, and<br />
<code class="reqn">\mbox{}\quad\mbox{}</code>(4) <code>"grave"</code> or <code class="reqn">\grave{\mathbf{C}}(u,v)</code> is a reflection of <code class="reqn">V</code> on the verical axis.<br />
The names <code>"acute"</code> and <code>"grave"</code> match those used in the <b>Rd</b>-format math typesetting instructions. Users are directed to the documentation of <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> for further discussion because the <code>COP</code> function is expected to be an early entry point for new users interested in the <span class="pkg">copBasic</span> API.
</p>
<p>For the <span class="pkg">copBasic</span> package and in order to keep some logic brief and code accessible for teaching and applied circumstances, reflections of copulas using analogs to the <code>reflect</code> argument are only natively supported in the <code>COP</code> and <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> functions. The interfaces of <span class="pkg">copBasic</span> should already be flexible enough for users to adapt and (or) specially name reflections of copulas for deployment. A caveat is that some individual copula implementations might have some self-supporting infrastructure. The reflection can also be set within the <code>para</code> argument when it is a list (see <b>Examples</b>).
</p>
<p>An example is warranted. Although the Gumbel&ndash;Hougaard copula (<code><a href="#topic+GHcop">GHcop</a></code>) can be reflected by <code>COP</code> and <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> and testing is made in the <b>Note</b> section of <code><a href="#topic+simCOPmicro">simCOPmicro</a></code>, it is suggested that a user generally requiring say a horizontal reflection <code>ru</code> (or vertical reflection <code>rv</code>) of the Gumbel&ndash;Hougaard copula write a function named perhaps <code>ruGHcop</code> (or <code>rvGHcop</code>).
</p>
<p>Such functions, consistent with the mathematics at the beginning of this <b>Note</b>, can be used throughout functions of <span class="pkg">copBasic</span> using the <code>cop</code> arguments. The author (Asquith) eschews implementing what is perceived as too much flexibility and overhead for the package to support the three reflection permutations universally across all copula functions of the package. This being said, <code>COP</code> can take an <span class="rlang"><b>R</b></span> <code>list</code> for the <code>para</code> argument for rotation/reflection:
</p>
<pre>
  set.seed(14)
  UV3 &lt;- simCOP(20, cop=COP, pch=16, col=3,
                para=list(cop=GLcop, para=pi+1, reflect="3"))
  set.seed(14)
  UV2 &lt;- simCOP(20, cop=COP, pch=16, col=4, ploton=FALSE,
                para=list(cop=GLcop, para=pi+1, reflect="2"))
  arrows(x0=UV3[,1], y0=UV3[,2], x=UV2[,1], y=UV2[,2])
</pre>
<p>and this type of interface is similar to <code><a href="#topic+composite1COP">composite1COP</a></code> as the following rotation and then asymmetric construction shows:
</p>
<pre>
  UV &lt;- simCOP(1000, cop=composite1COP,
                     para=list(cop1=COP,
                               para1=c(cop=GHcop, para=pi+1, reflect="4"),
                               alpha=0.1, beta=0.3))
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coCOP">coCOP</a></code>, <code><a href="#topic+duCOP">duCOP</a></code>, <code><a href="#topic+surCOP">surCOP</a></code>, <code><a href="#topic+surfuncCOP">surfuncCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>u &lt;- runif(1); v &lt;- runif(1)
COP(cop=W,u,v); COP(cop=P,u,v); COP(cop=M,u,v); COP(cop=PSP,u,v)

FF &lt;- 0.75 # 75th percentile, nonexceedance
GG &lt;- 0.20 # 25th percentile, nonexceedance
bF &lt;- 1 - FF; bG &lt;- 1 - GG     # exceedance
# What is the probability that both X and Y are less than
# 75th and 20th percentiles, respectively?
COP(cop=P, FF, GG)    # 0.15
# What is the probability that both X and Y are greater than
# 75th and 20th percentiles, respectively?
surCOP(cop=P, bF, bG) # 0.20
# What is the probability that either X or Y are less than
# the 75th and 20th percentiles, respectively?
duCOP(cop=P, FF, GG)  # 0.8
# What is the probability that either X or Y are greater than
# the 75th and 20th percentiles, respectively?
coCOP(cop=P, bF, bG)  # 0.85

# Repeat for the PSP copula:
# What is the probability that both X and Y are less than
# 75th and 20th percentiles, respectively?
COP(cop=PSP, FF, GG)    # 0.1875
# What is the probability that both X and Y are greater than
# 75th and 20th percentiles, respectively?
surCOP(cop=PSP, bF, bG) # 0.2375
# What is the probability that either X or Y are less than
# the 75th and 20th percentiles, respectively?
duCOP(cop=PSP, FF, GG)  # 0.7625
# What is the probability that either X or Y are greater than
# the 75th and 20th percentiles, respectively?
coCOP(cop=PSP, bF, bG)  # 0.8125
# Both of these summations equal unity
   COP(cop=PSP, FF, GG) + coCOP(cop=PSP, bF, bG) # 1
surCOP(cop=PSP, bF, bG) + duCOP(cop=PSP, FF, GG) # 1

FF &lt;- 0.99 # 99th percentile, nonexceedance
GG &lt;- 0.50 # 50th percentile, nonexceedance
bF &lt;- 1 - FF # nonexceedance
bG &lt;- 1 - GG # nonexceedance
# What is the probability that both X and Y are less than
# 99th and 50th percentiles, respectively?
COP(cop=P, FF, GG)    # 0.495
# What is the probability that both X and Y are greater than
# 99th and 50th percentiles, respectively?
surCOP(cop=P, bF, bG) # 0.005
# What is the probability that either X or Y are less than
# the 99th and 50th percentiles, respectively?
duCOP(cop=P, FF, GG)  # 0.995
# What is the probability that either X or Y are greater than
# the 99th and 50th percentiles, respectively?
coCOP(cop=P, bF, bG)  # 0.505

## Not run: 
  # MAJOR EXAMPLE FOR QUICKLY MODIFYING INHERENT ASSOCIATION STRUCTURES
  p &lt;- 0.5 # Reasonable strong positive association for the Raftery copula
  "RFcop1" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="1")
  "RFcop2" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="2")
  "RFcop3" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="3")
  "RFcop4" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="4")

  d &lt;- 0.01 # Just to speed up the density plots a bit
  densityCOPplot(RFcop1, para=p, contour.col=1, deluv=d) # Raftery in the literature
  densityCOPplot(RFcop2, para=p, contour.col=1, deluv=d, ploton=FALSE)
  densityCOPplot(RFcop3, para=p, contour.col=1, deluv=d, ploton=FALSE)
  densityCOPplot(RFcop4, para=p, contour.col=1, deluv=d, ploton=FALSE)
  # Now some text into the converging tail to show the reflection used.
  text(-2,-2, "reflect=1", col=2); text(+2,+2, "reflect=2", col=2)
  text(+2,-2, "reflect=3", col=2); text(-2,+2, "reflect=4", col=2) #
## End(Not run)

## Not run: 
  # ALTERNATIVE EXAMPLE FOR QUICKLY MODIFYING INHERENT ASSOCIATION STRUCTURES
  # To show how the reflection can be alternatively specified and avoid in this case
  # making four Raftery functions, pass by a list para argument. Also, demonstrate
  # that cop1 --&gt; cop and para1 --&gt; para are the same in use of the function. This
  # provides some nomenclature parallel to the other compositing functions.
  densityCOPplot(COP, para=list(reflect=1, cop1=RFcop, para=p ), deluv=d,
                            contour.col=1, drawlabels=FALSE)
  densityCOPplot(COP, para=list(reflect=2, cop= RFcop, para1=p), deluv=d,
                            contour.col=2, drawlabels=FALSE, ploton=FALSE)
  densityCOPplot(COP, para=list(reflect=3, cop1=RFcop, para1=p), deluv=d,
                            contour.col=3, drawlabels=FALSE, ploton=FALSE)
  densityCOPplot(COP, para=list(reflect=4, cop= RFcop, para=p ), deluv=d,
                            contour.col=4, drawlabels=FALSE, ploton=FALSE)
  # Now some text into the converging tail to show the reflection used.
  text(-2,-2, "reflect=1", col=2); text(+2,+2, "reflect=2", col=2)
  text(+2,-2, "reflect=3", col=2); text(-2,+2, "reflect=4", col=2) #
## End(Not run)

## Not run: 
  # Similar example to previous, but COP() can handle the reflection within a
  # parameter list ,and the reflect, being numeric here, is converted to
  # character internally.
  T12 &lt;- CLcop(tau=0.67)$para # Kendall Tau of 0.67
  T12 &lt;- list(cop=CLcop, para=T12, reflect=2) # reflected to upper tail dependency
  UV  &lt;- simCOP(n=1000, cop=COP, para=T12) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='copBasic.fitpara'>A Single or Multi-Parameter Optimization Engine (Beta Version)</h2><span id='topic+copBasic.fitpara.beta'></span>

<h3>Description</h3>

<p>An example of a general implementation of a parameter optimization scheme using core features of the <span class="pkg">copBasic</span> package. Because of the general complexity of the objectives for this function, the interface shown here is considered an &ldquo;beta version&rdquo; and nomenclature is subject to possibly sweeping changes in the future.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copBasic.fitpara.beta(uv=NULL, popstat=NULL, statf=NULL, cop=NULL,
                      paradim=1, interval=NULL, par.init=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copBasic.fitpara_+3A_uv">uv</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> two column <code>matrix</code> or <code>data.frame</code> of a sample of nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code>;</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_popstat">popstat</code></td>
<td>
<p>The population statistic(s) that will be used if <code>uv</code> is <code>NULL</code>;</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_statf">statf</code></td>
<td>
<p>A function responsible at the minimum for computation of the theoretical values of the population statistic(s) that the optimization will revolve around; This function, if supporting an <code>as.sample</code> interface (<em>e.g.</em> <code><a href="#topic+hoefCOP">hoefCOP</a></code>) and if <code>uv</code> has been provided, will be dispatched to compute the population statistic(s);</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_cop">cop</code></td>
<td>
<p>A copula function that is passed along to <code>statf</code> though of course the <code>statf</code> function can decide whether to use this argument or not;</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_paradim">paradim</code></td>
<td>
<p>The dimension of the parameters. In reality, the default triggers uni-dimensional root solving using the <code>uniroot()</code> function in <span class="rlang"><b>R</b></span> or otherwise the <code>optim()</code> function in <span class="rlang"><b>R</b></span> is used for multi-dimensional minimization with subtle changes in setup (see source code). Alternative logic could be have been used but it is felt that this is the most logical for future adaptations;</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_interval">interval</code></td>
<td>
<p>The <code>interval</code> argument by the same name for the <code>uniroot()</code> function;</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_par.init">par.init</code></td>
<td>
<p>The initial parameter vector for the <code>optim()</code> function; and</p>
</td></tr>
<tr><td><code id="copBasic.fitpara_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the values for the parameter variable is returned
</p>


<h3>Note</h3>

<p><em>One-Parameter Optimization</em>&mdash;A demonstration of one-dimensional parameter optimimization using the <em>Gini Gamma</em> (<code><a href="#topic+giniCOP">giniCOP</a></code>), which is a measure of bivariate association. There is no native support for Gini Gamma (and most of the other measures of association) in regards to being a parameter estimator at the copula function interface level in <span class="pkg">copBasic</span>. (A converse example is one provided internally by the <code><a href="#topic+GHcop">GHcop</a></code> copula.)
</p>
<pre>
  set.seed(24); n &lt;- 230 # sample size to draw from Galambos copula but a
  # different copula was chosen for the fitting.
  sampleUV &lt;- simCOP(n=n, cop=GLcop, para=1.5) # a random sample
  para &lt;- copBasic.fitpara.beta(uv=sampleUV, statf=giniCOP,
                                interval=c(.1,200), cop=HRcop) # 1.959521
</pre>
<p><em>Three-Parameter Optimization</em>&mdash;A demonstration of multi-dimensional parameter optimimization using the Gini Gamma (<code><a href="#topic+giniCOP">giniCOP</a></code>), <em>Nu-Skew</em> (<code><a href="#topic+nuskewCOP">nuskewCOP</a></code>), and <em>Nu-Star</em> (<code><a href="#topic+nustarCOP">nustarCOP</a></code>). This is substantially more complicated to implement. The <em>Hüsler&ndash;Reiss copula</em> (<code><a href="#topic+HRcop">HRcop</a></code>) is chosen both as part of the sample simulation for the study as well as the copula as part of the modeling.  Using composition by the <code><a href="#topic+composite1COP">composite1COP</a></code>, first establish a parent three parameter copula and simulate from it to create a bivariate sample in <code>sampleUV</code> that will be used for demonstration. A standard normal variate graphic of the simulation is generated by <code><a href="#topic+simCOP">simCOP</a></code> as well&mdash;later, additional results will be superimposed.
</p>
<pre>
  n &lt;- 610; set.seed(1999) # Seed value will be used again (see below)
  pop.para &lt;- list(cop1=HRcop, para1=4, alpha=0.14, beta=0.35)
  sampleUV &lt;- simCOP(n=n, cop=composite1COP, para=pop.para, col=3, snv=TRUE)
</pre>
<p>A custom objective function <code>objfunc</code> to serve as the <code>statf</code> for the <code>copBasic.fitpara.beta</code> call. The objective function has the <code>as.sample</code> interface (<em>e.g.</em> <code><a href="#topic+giniCOP">giniCOP</a></code>) implemented for sample estimation. The most subtle feature of function presumably is the use of the <code>pnorm()</code> function in <span class="rlang"><b>R</b></span> for the <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> parameters to keep each parameter in the range <code class="reqn">\alpha, \beta \in (0,1)</code>. Another subtly, which affects the choice of other copulas from <code><a href="#topic+HRcop">HRcop</a></code>, is how the parameter range of <code class="reqn">\Theta</code> (the <code>para[1]</code> variable) is controlled&mdash;here the parameter remains untransformed but the lower domain edge is truncated by the return of infinity (<code>return(Inf)</code>). The <code>getstat</code> argument is only for short circuiting the objective so that <code>objfunc</code> can be used to compute the three statistics after the optimal parameters are found.
</p>
<pre>
  "objfunc" &lt;- function(para, stat=NA, as.sample=FALSE, getstat=FALSE, ...) {
      if(as.sample) {
         return(c(  giniCOP(para=para, as.sample=TRUE),
                  nuskewCOP(para=para, as.sample=TRUE),
                  nustarCOP(para=para, as.sample=TRUE)))
      }
      para[1]   &lt;- ifelse(para[1] &lt; 0, return(Inf), para[1]) # edge check
      para[2:3] &lt;-  pnorm(para[2:3]) # detransform
      para &lt;- list(cop1=HRcop, para1=para[1], alpha=para[2], beta=para[3])
      hp &lt;- c(  giniCOP(composite1COP, para),
              nuskewCOP(composite1COP, para),
              nustarCOP(composite1COP, para))
      if(getstat) return(hp) # short circuit to get the statistics out
      dv &lt;- stat; dv[dv == 0] &lt;- 1 # changing dv "adapts" the error to
      return(sqrt(sum(((stat-hp)/dv)^2))) # trap division by zero
  }
</pre>
<p>The parameter estimation proceeds in the following code. The sample statistics (or <code>target.stats</code>) are computed and subsequently passed to the optimization using the <code>popstat</code> argument. Notice also the use of the <code>qnorm()</code> function in <span class="rlang"><b>R</b></span> to transform the initial guess <code class="reqn">\alpha = \beta = 1/2</code> into a domain more easily handled by the optimizer (<code>optim()</code> function in <span class="rlang"><b>R</b></span>). The transformed optimal parameters are computed, and then the values of the three statistics for the fit are computed. Lastly, a <span class="pkg">copBasic</span> parameter object <code>fit.para</code> is created, which can be used for later comparisons.
</p>
<pre>
  txt &lt;- c("GiniGamma", "NuSkew", "NuStar")
  target.stats &lt;- objfunc(sampleUV, as.sample=TRUE); names(target.stats) &lt;- txt
  raw.fit.para &lt;- copBasic.fitpara.beta(popstat=target.stats, statf=objfunc,
         par.init=c(1, qnorm(0.5), qnorm(0.5)), cop=composite1COP, paradim=3)
  fit.stats &lt;- objfunc(raw.fit.para, getstat=TRUE); names(fit.stats) &lt;- txt
  fit.para &lt;- list(cop1=HRcop, para1=raw.fit.para[1],
                   alpha=pnorm(raw.fit.para[2]), beta=pnorm(raw.fit.para[3]))
</pre>
<p>The optimization is completed. It is informative to see what the simulation of the fitted copula looks like. Note: this particular example suffers from identifiability problems between the parameters&mdash;meaning that local minima exist or that satisfactory solutions using different parameters than used to generate the random sample can occur. The same seed is used so that one-to-one comparison of points can visually be made with the <code><a href="#topic+simCOP">simCOP</a></code> function call.
</p>
<pre>
  set.seed(1999) # This value will be used again (see below)
  sampleUV &lt;- simCOP(n=n, cop=composite1COP, para=fit.para,
                ploton=FALSE, pch=16, cex=0.5, col=2, snv=TRUE) # red dots
</pre>
<p>The visual comparison is qualitative. The tabular comparison of the sample statistics to those of the fitted model shows that perhaps an acceptable local minima has been attained in terms of &ldquo;fit&rdquo; but the subsequent comparison of the parameters of the population used to generate the sample and those of the fitted model seemingly depart substantially in the <code class="reqn">\alpha \rightarrow 0</code> parameter of the copula composition. The tail dependency parameters are similar, but further goodness-of-fit check is not made.
</p>
<pre>
                       #   GiniGamma        NuSkew       NuStar
  print(target.stats)  #   0.5219027    -0.1940361    0.6108319
  print(fit.stats)     #   0.5182858    -0.1938848    0.6159566

                          # Parameter  Alpha       Beta
  print(ls.str(pop.para)) #      4.00   0.14      0.350  # given
  print(ls.str(fit.para)) #     11.2    0.187     0.427  # one solution

                                               # Tail Dependency Parameters
  taildepCOP(cop=composite1COP, para=pop.para) # lower=0 : upper=0.5838
  taildepCOP(cop=composite1COP, para=fit.para) # lower=0 : upper=0.5714(est.)
</pre>
<p>The demonstration ends with the comparison of the two asymmetrical density contours.
</p>
<pre>
  densityCOPplot(cop=composite1COP, para=pop.para, contour.col=3)
  densityCOPplot(cop=composite1COP, para=fit.para, contour.col=2,
                                    ploton=FALSE)
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Examples</h3>

<pre><code class='language-R'># See the Note section
</code></pre>

<hr>
<h2 id='COPinv'>The Inverse of a Copula for V with respect to U</h2><span id='topic+COPinv'></span>

<h3>Description</h3>

<p>Compute the <em>inverse of a copula</em> for <code class="reqn">V</code> with respect to <code class="reqn">U</code> given <code class="reqn">t</code> or
</p>
<p style="text-align: center;"><code class="reqn">t = \mathbf{C}(u{=}U,v) \rightarrow \mathbf{C}^{(-1)}(u{=}U, t) = v\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">v</code>. Nelsen (2006, p. 12) does not so name this function as an &ldquo;inverse.&rdquo; The <code>COPinv</code> function is internally used by <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code> and <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>. A common misapplication that will puzzle the user (including the developer after long breaks from package use) is that the following call and error message are often seen, if <code>silent=FALSE</code>:
</p>
<pre>
  COPinv(0.2, 0.25, cop=PSP)
  # Error in uniroot(func, interval = c(lo, 1), u = u, LHS = t, cop = cop,  :
  #  f() values at end points not of opposite sign
  # [1] NA
</pre>
<p>This is a harmless error in the sense that <code>COPinv</code> is functioning properly. One can not invert a copula for <code class="reqn">u &lt; t</code> and for <code class="reqn">u = t</code> the <code class="reqn">v = 1</code> because of fundamental copula properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COPinv(cop=NULL, u, t, para=NULL, silent=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="COPinv_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="COPinv_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="COPinv_+3A_t">t</code></td>
<td>
<p>Nonexceedance probability level <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="COPinv_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structures, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="COPinv_+3A_silent">silent</code></td>
<td>
<p>The argument of the same name given over to <code>try()</code> wrapping the <code>uniroot()</code> operation; and</p>
</td></tr>
<tr><td><code id="COPinv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for <code class="reqn">v</code> are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>,
<code><a href="#topic+COPinv2">COPinv2</a></code>,
<code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>,
<code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>COPinv(cop=N4212cop, para=2, u=0.5, t=0.2)
</code></pre>

<hr>
<h2 id='COPinv2'>The Inverse of a Copula for U with respect to V</h2><span id='topic+COPinv2'></span>

<h3>Description</h3>

<p>Compute the <em>inverse of a copula</em> for <code class="reqn">U</code> with respect to <code class="reqn">V</code> given <code class="reqn">t</code> or
</p>
<p style="text-align: center;"><code class="reqn">t = \mathbf{C}(u,v{=}V) \rightarrow \mathbf{C}^{(-1)}(v{=}V, t) = u\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">u</code>.  Nelsen (2006, p. 12) does not so name this function as an &ldquo;inverse.&rdquo; The <code>COPinv2</code> function is internally used by <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>. A common misapplication that will puzzle the user (including the developer after long breaks from package use) is that the following call and error message are often seen, if <code>silent=FALSE</code>:
</p>
<pre>
  COPinv2(0.2, 0.25, cop=PSP)
  # Error in uniroot(func, interval = c(lo, 1), u = u, LHS = t, cop = cop,  :
  #  f() values at end points not of opposite sign
  # [1] NA
</pre>
<p>This is a harmless error in the sense that <code>COPinv2</code> is functioning properly. One can  not invert a copula for <code class="reqn">v &lt; t</code> and for <code class="reqn">v = t</code> the <code class="reqn">u = 1</code> because of fundamental copula properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>COPinv2(cop=NULL, v, t, para=NULL, silent=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="COPinv2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="COPinv2_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="COPinv2_+3A_t">t</code></td>
<td>
<p>Nonexceedance probability in <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="COPinv2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structures, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="COPinv2_+3A_silent">silent</code></td>
<td>
<p>The argument of the same name given over to <code>try()</code> wrapping the <code>uniroot()</code> operation; and</p>
</td></tr>
<tr><td><code id="COPinv2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for <code class="reqn">u</code> are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+COPinv">COPinv</a></code>, <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>, <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See those for COPinv as they are the same by analogy.
</code></pre>

<hr>
<h2 id='densityCOP'>Density of a Copula</h2><span id='topic+densityCOP'></span>

<h3>Description</h3>

<p>Numerically estimate the <em>copula density</em> for a sequence of <code class="reqn">u</code> and <code class="reqn">v</code> probabilities for which each sequence has equal steps that are equal to <code class="reqn">\Delta(uv)</code>. The density <code class="reqn">c(u,v)</code> of a copula <code class="reqn">\mathbf{C}(u,v)</code> is numerically estimated by
</p>
<p style="text-align: center;"><code class="reqn">c(u,v) = \bigl[\mathbf{C}(u_2,v_2) - \mathbf{C}(u_2,v_1) - \mathbf{C}(u_1,v_2) + \mathbf{C}(u_1,v_1)\bigr]\, /\, \bigl[\Delta(uv)\times\Delta(uv)\bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">c(u,v) \ge 0</code> (see Nelsen, 2006, p. 10; <code><a href="#topic+densityCOPplot">densityCOPplot</a></code>). The <em>joint density</em> can be defined by the coupla density for continuous variables and is the ratio of the joint density funcion <code class="reqn">f(x,y)</code> for random variables <code class="reqn">X</code> and <code class="reqn">Y</code> to the product of the marginal densities (<code class="reqn">f_x(x)</code> and <code class="reqn">f_y(y)</code>):
</p>
<p style="text-align: center;"><code class="reqn">c\bigl(F_x(x), F_y(y)\bigr) = \frac{f(x,y)}{f_x(x)f_y(y)}\mbox{,}</code>
</p>

<p>where <code class="reqn">F_x(x)</code> and  <code class="reqn">F_y(y)</code> are the respective cumulative distribution functions of <code class="reqn">X</code> and <code class="reqn">Y</code>, and lastly <code class="reqn">u = F_x(x)</code> and <code class="reqn">v = F_y(y)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityCOP(u,v, cop=NULL, para=NULL, deluv=.Machine$double.eps^0.25,
                truncate.at.zero=TRUE, the.zero=0, sumlogs=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="densityCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_deluv">deluv</code></td>
<td>
<p>The change in the sequences <code class="reqn">\{u, v\} \mapsto \delta, \ldots, 1-\delta; \delta = \Delta(uv)</code> probabilities;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_truncate.at.zero">truncate.at.zero</code></td>
<td>
<p>A density must be <code class="reqn">c(u,v) \ge 0</code>, but because this computation is based on a rectangular approximation and not analytical, there exists a possibility that very small rectangles could result in numerical values in <span class="rlang"><b>R</b></span> that are less than zero. This usually can be blamed on rounding. This logical if <code>TRUE</code> truncates computed densities to zero, and the default assumes that the user is providing a proper copula. A <code>FALSE</code> value is used by the function <code><a href="#topic+isfuncCOP">isfuncCOP</a></code>;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_the.zero">the.zero</code></td>
<td>
<p>The value for &ldquo;the zero&rdquo; where a small number might be useful for pseudo-maximum likelihood estimation using <code>sumlogs</code>;</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_sumlogs">sumlogs</code></td>
<td>
<p>Return the <code class="reqn">\sum{\log c(u,v; \Theta)}</code> where <code class="reqn">\Theta</code> are the parameters in <code>para</code> and this feature is provided for <code><a href="#topic+mleCOP">mleCOP</a></code>; and</p>
</td></tr>
<tr><td><code id="densityCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for <code class="reqn">c(u,v)</code> are returned.
</p>


<h3>Note</h3>

<p>The <span class="pkg">copBasic</span> package does not currently have copula densities as analytical solutions implemented. This is because initial design decisions were entirely on cumulative distribution function (CDF) representations of the copula.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+densityCOPplot">densityCOPplot</a></code>, <code><a href="#topic+kullCOP">kullCOP</a></code>, <code><a href="#topic+mleCOP">mleCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Joe (2014, p. 164) shows the closed form copula density for the Plackett.
  "dPLACKETTcop" &lt;- function(u,v,para) {
     uv &lt;- u*v; upv &lt;- u + v; eta &lt;- para - 1
     A &lt;- para*(1+eta*(upv - 2*uv)); B &lt;- ((1+eta*upv)^2 - 4*para*eta*uv)^(3/2)
     return(A/B)
  }
  dPLACKETTcop(0.32, 0.74,            para=1.3) # 0.9557124
  densityCOP(  0.32, 0.74, cop=PLcop, para=1.3) # 0.9557153 
## End(Not run)

## Not run: 
  # Joe (2014, p. 165) shows the corner densities of the Plackett as Theta.
  # copBasic uses numerical density estimation and not analytical formula.
  eps &lt;- .Machine$double.eps
  densityCOP(0,0, cop=PLcop, para=4) # 3.997073  (default eps^0.25)
  densityCOP(1,1, cop=PLcop, para=4) # 3.997073  (default eps^0.25)
  densityCOP(1,1, cop=PLcop, para=4, deluv=eps)     # 0 (silent failure)
  densityCOP(1,1, cop=PLcop, para=4, deluv=eps^0.5) # 4.5
  densityCOP(1,1, cop=PLcop, para=4, deluv=eps^0.4) # 4.002069
  densityCOP(1,1, cop=PLcop, para=4, deluv=eps^0.3) # 3.999513
  # So, we see that the small slicing does have an effect, the default of 0.25 is
  # intented for general application by being away enough from machine limits.
## End(Not run)

## Not run: 
  # Joe (2014, p. 170) shows a closed form copula density for "Bivariate Joe/B5" copula
  "dJOEB5cop" &lt;- function(u, v, para) {
     up &lt;- (1-u)^para; vp &lt;- (1-v)^para; eta &lt;- para - 1
     A &lt;- (up + vp - up*vp); B &lt;- (1-u)^eta * (1-v)^eta; C &lt;- (eta + A)
     return(A^(-2 + 1/para) * B * C)
  }
  densityCOP(0.32, 0.74, cop=JOcopB5, para=1.3)  # 0.9410653
  dJOEB5cop( 0.32, 0.74, para=1.3)               # 0.9410973 
## End(Not run)
</code></pre>

<hr>
<h2 id='densityCOPplot'>Contour Density Plot of a Copula</h2><span id='topic+densityCOPplot'></span>

<h3>Description</h3>

<p>Generate a <em>contour density plot</em> after the advocation of Joe (2014, pp. 9&ndash;15). Such graphics are plots of <em>scaled copula densities</em> (<code class="reqn">c^\star(u,v)</code>, bivariate herein) that are copula densities scaled to the standard normal distribution <code class="reqn">\sim</code> N(0,1) margins. Joe (2014) repeatedly emphasizes such plots in contrast to the uniform distribution <code class="reqn">\sim</code> U(0,1) margins. Nelsen (2006) does not discuss such scaling but seemingly Nelsen's objectives for his book were somewhat different.
</p>
<p>The density of copula <code class="reqn">\mathbf{C}(u,v)</code> is numerically estimated by
</p>
<p style="text-align: center;"><code class="reqn">c(u,v) = \bigl[\mathbf{C}(u_2,v_2) - \mathbf{C}(u_2,v_1) - \mathbf{C}(u_1,v_2) + \mathbf{C}(u_1,v_1)\bigr]\, /\, \bigl[\Delta(uv)\times\Delta(uv)\bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">c(u,v) \ge 0</code> (see Nelsen, 2006, p. 10; <code><a href="#topic+densityCOP">densityCOP</a></code>). Given a numerically estimated quantity <code class="reqn">c^\star(u,v) = c(u,v)\times\phi(\Phi^{(-1)}(u))\times\phi(\Phi^{(-1)}(v))</code> for copula density <code class="reqn">c(u,v)</code>, a grid of the <code class="reqn">c^\star(u,v)</code> values can be contoured by the <code>contour()</code> function in <span class="rlang"><b>R</b></span>.  The density function of the N(0,1) is <code class="reqn">\phi(z)</code> for standard normal variate <code class="reqn">z</code> and the quantile function of the N(0,1) is <code class="reqn">\Phi^{(-1)}(t)</code> for nonexceedance probability <code class="reqn">t</code>.
</p>
<p>A grid (matrix) of <code class="reqn">c(u,v)</code> or <code class="reqn">c^\star(u,v)</code> is defined for sequence of <code class="reqn">u</code> and <code class="reqn">v</code> probabilities for which each sequence has equal steps that are equal to <code class="reqn">\Delta(uv)</code>. This function has as focus on plotting of the contour lines of <code class="reqn">c^\star(u,v)</code> but the <span class="rlang"><b>R</b></span> <code>matrix</code> of either <code class="reqn">c(u,v)</code> or <code class="reqn">c^\star(u,v)</code> can be requested on return. For either matrix, the <code>colnames()</code> and <code>rownames()</code> (the <span class="rlang"><b>R</b></span> functions) are set equal to the sequence of <code class="reqn">u</code> and <code class="reqn">v</code>, respectively. Neither the column or row names are set to the standard normal variates for the matrix of <code class="reqn">c^\star(u,v)</code>, the names remain in terms of nonexceedance probability.
</p>
<p>For plotting and other uses of normal scores of data, Joe (2014, p. 245) advocates that one should use the plotting position formula <code class="reqn">u_i = (i-1/2)/n</code> (<em>Hazen plotting position</em>) for normal scores <code class="reqn">z_i = \Phi^{-1}(u_i)</code> in preference to <code class="reqn">i/(n+1)</code> (<em>Weibull plotting position</em>) because <code class="reqn">n^{-1}\sum_{i=1}^{n} z^2_i</code> is closer to unity. Other examples of Joe's advocation for the Hazen plotting positions are available (Joe, 2014, pp. 9, 17, 245, 247&ndash;248).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityCOPplot(cop=NULL, para=NULL, deluv=0.002,
               getmatrix=c("none", "cdenzz", "cden"), n=0,
               ploton=TRUE, snv=TRUE, origins=TRUE,
               contour.col=1, contour.lwd=1.5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="densityCOPplot_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_deluv">deluv</code></td>
<td>
<p>The change in the sequences <code class="reqn">\{u, v\} \mapsto \delta, \ldots, 1-\delta; \delta = \Delta(uv)</code> probabilities;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_getmatrix">getmatrix</code></td>
<td>
<p>A trigger on whether the density matrix is to be returned. The option <code>cdenzz</code> returns the density scaled by the two standard normal densities (<code class="reqn">c^\star(u,v)</code>), whereas the option <code>cden</code> returns simply the copula density (<code class="reqn">c(u,v)</code>);</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_snv">snv</code></td>
<td>
<p>A logical to toggle standard normal variates for the axes;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_origins">origins</code></td>
<td>
<p>A logical to plot the origin lines, if and only if <code>snv</code> is true;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_contour.col">contour.col</code></td>
<td>
<p>The color of the contour lines, which corresponds to the <code>col</code> argument of the <code>contour</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_contour.lwd">contour.lwd</code></td>
<td>
<p>The width of the contour lines, which corresponds to the <code>lwd</code> argument of the <code>contour</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_n">n</code></td>
<td>
<p>An optional sample size for which simulation of this many values from the copula will be made by <code><a href="#topic+simCOP">simCOP</a></code> and drawn; and</p>
</td></tr>
<tr><td><code id="densityCOPplot_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function and to the <code>contour</code> function in <span class="rlang"><b>R</b></span> (<em>e.g.</em> to turn off labeling of contours add <code>drawlabels=FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This is a high-level function used for its side effects; an <span class="rlang"><b>R</b></span> <code>matrix</code> can be triggered, however, as a returned value.
</p>


<h3>Note</h3>

<p>Joe (2014, p. 244) says &ldquo;if [density] plots show multimodality, then multivariate techniques of mixture models, cluster analysis[,] and nonparametric functional data analysis might be more appropriate&rdquo; than relatively straightforward parametric copula models.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+densityCOP">densityCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Joe (2014, p. 5) names rMTCJ = reflected Mardia-Takahasi-Cook-Johnson copula
  "rMTCJ" &lt;- function(u, v, para, ...) {
     u + v - 1 + ((1-u)^(-para) + (1-v)^(-para) - 1)^(-1/para)
  } # Survival Copula ("reflected" in Joe's terms)
  densityCOPplot(cop=rMTCJ, para=1.0760, n=9000, snv=TRUE)
  # Density plot matches that shown by Joe (2014, p. 11, fig. 1.2, lower left plot)
  # for a Spearman Rho equaling 0.5. Let us compute then Rho:
  rhoCOP(cop=rMTCJ, para=1.076075) # 0.4999958

  # Now, let us get really wild with a composition with TWO modes!
  # This example also proves that the grid orientation is consistent with respect
  # to the orientation of the simulations.
  para &lt;- list(alpha=0.15, beta=0.90, kappa=0.06, gamma=0.96,
               cop1=GHcop, cop2=PLACKETTcop, para1=5.5, para2=0.07)
  densityCOPplot(cop=composite2COP, para=para, n=9000)

  # Now, let us hack back to a contour density plot with U(0,1) and not N(0,1) margins
  # just so show that capability exists, but emphasis of densityCOPplot is clearly
  # on Joe's advocation, because it does not have a default trigger to use U(0,1) margins.
  set.seed(12)
  H &lt;- densityCOPplot(cop=PLACKETTcop, para=41.25, getmatrix="cdenzz", n=1000, snv=FALSE)
  set.seed(12)
  UV &lt;- simCOP(cop=PLACKETTcop, para=41.25, n=1000, col=8, snv=FALSE)
  U  &lt;- as.numeric(colnames(H)); V &lt;- as.numeric(rownames(H))
  contour(x=U, y=V, z=t(H), lwd=1.5, cex=2, add=TRUE, col=2) #
## End(Not run)

## Not run: 
  set.seed(12)
  UV &lt;- rCOP(400,  cop=PSP, pch=16, col=8, n=400)
  CL &lt;- mleCOP(UV, cop=CLcop,   interval=c(1  , 20))
  JO &lt;- mleCOP(UV, cop=JOcopB5, interval=c(0.1, 20))
  PL &lt;- mleCOP(UV, cop=PLcop,   interval=c(0.1, 20))

  AICs &lt;- c(CL$AIC, JO$AIC, PL$AIC)
  names(AICs) &lt;- c("Clayton", "Joe(B5)", "Plackett")
  print(round(AICs, digits=2))
  #  Clayton    Joe(B5)   Plackett
  #  -156.77     -36.91    -118.38
  # So, we conclude Clayton is the best fit of the three.

  plot(qnorm(UV[,1]), qnorm(UV[,2]), pch=16, col=8, cex=0.5,
       xlab="Standard normal variate of U", xlim=c(-3, 3),
       ylab="Standard normal variate of V", ylim=c(-3, 3))
  densityCOPplot(cop=PSP, contour.col=grey(0.5), lty=2,
                 contour.lwd=3.5, ploton=FALSE, snv=TRUE)
  densityCOPplot(cop=CLcop,       para=CL$para,
                 contour.col=2,   ploton=FALSE, snv=TRUE)
  densityCOPplot(cop=JOcopB5,     para=JO$para,
                 contour.col=3,   ploton=FALSE, snv=TRUE)
  densityCOPplot(cop=PLcop,       para=PL$para,
                 contour.col=4,   ploton=FALSE, snv=TRUE) #
## End(Not run)
</code></pre>

<hr>
<h2 id='derCOP'>Numerical Derivative of a Copula for V with respect to U</h2><span id='topic+derCOP'></span>

<h3>Description</h3>

<p>Compute the numerical partial derivative of a copula, which is a <em>conditional distribution function</em>, according to Nelsen (2006, pp. 13, 40&ndash;41) with respect to <code class="reqn">u</code>:
</p>
<p style="text-align: center;"><code class="reqn">0 \le \frac{\delta}{\delta u} \mathbf{C}(u,v) \le 1\mbox{,}</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[V \le v\mid U=u] = \mathbf{C}_{2 \mid 1}(v \mid u) = \lim_{\Delta u \rightarrow 0}\frac{\mathbf{C}(u+\Delta u, v) - \mathbf{C}(u,v)}{\Delta u}\mbox{,}</code>
</p>

<p>which is to read as the probability that <code class="reqn">V \le v</code> given that <code class="reqn">U = u</code> and corresponds to the <br /> <code>derdir="left"</code> mode of the function. For <code>derdir="right"</code>, we have
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[V \le v\mid U=u] = \lim_{\Delta u \rightarrow 0}\frac{\mathbf{C}(u,v) - \mathbf{C}(u-\Delta u, v)}{\Delta u}\mbox{,}</code>
</p>

<p>and for <code>derdir="center"</code> (the usual method of computing a derivative), the following results
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[V \le v\mid U=u] = \lim_{\Delta u \rightarrow 0}\frac{\mathbf{C}(u+\Delta u,v) - \mathbf{C}(u-\Delta u, v)}{2 \Delta u}\mbox{.}</code>
</p>

<p>The &ldquo;<em>with respect to <code class="reqn">V</code></em>&rdquo; versions are available under <code><a href="#topic+derCOP2">derCOP2</a></code>.
</p>
<p>Copula derivatives (<code class="reqn">\delta \mathbf{C}/\delta u</code> or say  <code class="reqn">\delta \mathbf{C}/\delta v</code> <code><a href="#topic+derCOP2">derCOP2</a></code>) are non-decreasing functions meaning that if <code class="reqn">v_1 \le v_2</code>, then <code class="reqn">\mathbf{C}(u, v_2) - \mathbf{C}(u,v_1)</code> is a non-decreasing function in <code class="reqn">u</code>, thus
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta\bigl(\mathbf{C}(u, v_2) - \mathbf{C}(u,v_1)\bigr)}{\delta u}</code>
</p>

<p>is non-negative, which means
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta\mathbf{C}(u, v_2)}{\delta u} \ge \frac{\delta\mathbf{C}(u, v_1)}{\delta u}\mbox{\ for\ } v_2 \ge v_1\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>derCOP(cop=NULL, u, v, delu=.Machine$double.eps^0.50,
       derdir=c("left", "right", "center"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="derCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction. If the length of <code>u</code> is unity, then the length of <code>v</code> can be arbitrarily long. If the length of <code>u</code> is not unity, then the length of <code>v</code> should be the same, and if not, then  only the first value in <code>v</code> is silently used;</p>
</td></tr>
<tr><td><code id="derCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction (see previous comment on <code>u</code>);</p>
</td></tr>
<tr><td><code id="derCOP_+3A_delu">delu</code></td>
<td>
<p>The <code class="reqn">\Delta u</code> interval for the derivative;</p>
</td></tr>
<tr><td><code id="derCOP_+3A_derdir">derdir</code></td>
<td>
<p>The direction of the derivative as described above. Default is <code>left</code> but internally any setting can be temporarily suspended to avoid improper computations (see source code); and</p>
</td></tr>
<tr><td><code id="derCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass such as the parameters often described in <code>para</code> arguments of other copula functions. (The lack of <code>para=NULL</code> for <code>derCOP</code> and <code><a href="#topic+derCOP2">derCOP2</a></code> was either design oversight or design foresight but regardless it is too late to enforce package consistency in this matter.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the partial derivative are returned.
</p>


<h3>Note</h3>

<p>A known caveat of the current implementation of the copula derivative is that there is a chance that the <code class="reqn">\Delta u</code> will span a singularity or discontinuous (or nearly so) portion of a copula should it have a property of singularity (or nearly so). The <code>delu</code> is chosen small so the chance is mitigated to be a small change and certainly appear to work throughout the examples herein. It is not decided whether a derivative from the positive side (<code>dir="left"</code>), when failing should switch over to a computation from the negative side (<code>dir="right"</code>). The distinction is important for the computation of the inverse of the derivative <code><a href="#topic+derCOPinv">derCOPinv</a></code> because the solution finder needs a sign reversal to work.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+derCOPinv">derCOPinv</a></code>, <code><a href="#topic+derCOP2">derCOP2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>derCOP(cop=W, 0.4, 0.6); derCOP(cop=P, 0.4, 0.6); derCOP(cop=M, 0.4, 0.6)

lft &lt;- derCOP(cop=PSP,   0.4, 0.6, derdir="left"  )
rgt &lt;- derCOP(cop=PSP,   0.4, 0.6, derdir="right" )
cnt &lt;- derCOP(cop=PSP,   0.4, 0.6, derdir="center")
cat(c(lft,rgt,cnt,"\n"))
#stopifnot(all.equal(lft,rgt), all.equal(lft,cnt))

# Let us contrive a singularity through this NOT A COPULA in the function "afunc".
"afunc" &lt;- function(u,v, ...) return(ifelse(u &lt;= 0.5, sqrt(u^2+v^2), P(u,v,...)))
lft &lt;- derCOP(cop=afunc, 0.5, 0.67, derdir="left"  )
rgt &lt;- derCOP(cop=afunc, 0.5, 0.67, derdir="right" )
cnt &lt;- derCOP(cop=afunc, 0.5, 0.67, derdir="center")
cat(c(lft,rgt,cnt,"\n")) # The "right" version is correct.
</code></pre>

<hr>
<h2 id='derCOP2'>Numerical Derivative of a Copula for U with respect to V</h2><span id='topic+derCOP2'></span>

<h3>Description</h3>

<p>Compute the numerical partial derivative of a copula, which is a <em>conditional distribution function</em>, according to Nelsen (2006, pp. 13, 40&ndash;41) with respect to <code class="reqn">v</code>:
</p>
<p style="text-align: center;"><code class="reqn">0 \le \frac{\delta}{\delta v} \mathbf{C}(u,v) \le 1\mbox{,}</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le u\mid V=v] = \mathbf{C}_{1 \mid 2}(u \mid v) =  \lim_{\Delta v \rightarrow 0}\frac{\mathbf{C}(u, v+\Delta v) - \mathbf{C}(u,v)}{\Delta v}\mbox{,}</code>
</p>

<p>which is to read as the probability that <code class="reqn">U \le u</code> given that <code class="reqn">V = v</code> and corresponds to the <br /> <code>derdir="left"</code> mode of the function. For <code>derdir="right"</code>, the following results
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le u\mid V=v] = \lim_{\Delta v \rightarrow 0}\frac{\mathbf{C}(u,v) - \mathbf{C}(u, v-\Delta v)}{\Delta v}\mbox{,}</code>
</p>

<p>and for <code>derdir="center"</code> (the usual method of computing a derivative), the following results
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le u\mid V=v] = \lim_{\Delta v \rightarrow 0}\frac{\mathbf{C}(u,v+\Delta v) - \mathbf{C}(u, v-\Delta v)}{2 \Delta v}\mbox{.}</code>
</p>

<p>The &ldquo;<em>with respect to <code class="reqn">U</code></em>&rdquo; versions are under <code><a href="#topic+derCOP">derCOP</a></code>.
</p>
<p>Copula derivatives (<code class="reqn">\delta \mathbf{C}/\delta v</code> or say  <code class="reqn">\delta \mathbf{C}/\delta u</code> <code><a href="#topic+derCOP">derCOP</a></code>) are non-decreasing functions meaning that if <code class="reqn">u_1 \le u_2</code>, then <code class="reqn">\mathbf{C}(u_2, v) - \mathbf{C}(u_1,v)</code> is a non-decreasing function in <code class="reqn">v</code>, thus
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta\bigl(\mathbf{C}(u_2, v) - \mathbf{C}(u_1,v)\bigr)}{\delta v}</code>
</p>

<p>is non-negative, which means
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta\mathbf{C}(u_2, v)}{\delta v} \ge \frac{\delta\mathbf{C}(u_1, v)}{\delta v}\mbox{\ for\ } u_2 \ge u_1\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>derCOP2(cop=NULL, u, v, delv=.Machine$double.eps^0.50,
        derdir=c("left", "right", "center"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derCOP2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="derCOP2_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction. If the length of <code>u</code> is unity, then the length of <code>v</code> can be arbitrarily long. If the length of <code>u</code> is not unity, then the length of <code>v</code> should be the same and if not only the first value in <code>v</code> will be silently used;</p>
</td></tr>
<tr><td><code id="derCOP2_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction (see previous comment on <code>u</code>);</p>
</td></tr>
<tr><td><code id="derCOP2_+3A_delv">delv</code></td>
<td>
<p>The <code class="reqn">\Delta v</code> interval for the derivative;</p>
</td></tr>
<tr><td><code id="derCOP2_+3A_derdir">derdir</code></td>
<td>
<p>The direction of the derivative as described above. Default is <code>left</code> but internally any setting can be temporarily suspended to avoid improper computations (see source code); and</p>
</td></tr>
<tr><td><code id="derCOP2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass such as the parameters often described in <code>para</code> arguments of other copula functions. (The lack of <code>para=NULL</code> for <code><a href="#topic+derCOP">derCOP</a></code> and <code>derCOP2</code> was either design oversight or design foresight but regardless it is too late to enforce package consistency in this matter.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the partial derivative are returned.
</p>


<h3>Note</h3>

<p>A known caveat of the current implementation of the copula derivative is that there is a chance that the <code class="reqn">\Delta v</code> will span a singularity or discontinuous (or nearly so) portion of a copula should it have a property of singularity (or nearly so). The <code>delv</code> is chosen small so the chance is mitigated to be a small change and certainly seems to work throughout the examples herein. It is not decided whether a derivative from the positive side (<code>dir="left"</code>), when failing should switch over to a computation from the negative side (<code>dir="right"</code>). The distinction is important for the computation of the inverse of the derivative <code><a href="#topic+derCOPinv2">derCOPinv2</a></code> because the solution finder needs a sign reversal to work.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+derCOPinv2">derCOPinv2</a></code>, <code><a href="#topic+derCOP">derCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>derCOP2(cop=W, 0.4, 0.6); derCOP2(cop=P, 0.4, 0.6); derCOP2(cop=M, 0.4, 0.6)

lft &lt;- derCOP2(cop=P,     0.4,  0.6, derdir="left"  )
rgt &lt;- derCOP2(cop=P,     0.4,  0.6, derdir="right" )
cnt &lt;- derCOP2(cop=P,     0.4,  0.6, derdir="center")
cat(c(lft, rgt, cnt,"\n"))
# stopifnot(all.equal(lft, rgt), all.equal(lft, cnt))

# Let us contrive a singularity though this NOT A COPULA in the function "afunc".
"afunc" &lt;- function(u,v, ...) return(ifelse(u &lt;= 0.5, sqrt(u^2+v^2), P(u,v,...)))
lft &lt;- derCOP2(cop=afunc, 0.67, 0.5, derdir="left"  )
rgt &lt;- derCOP2(cop=afunc, 0.67, 0.5, derdir="right" )
cnt &lt;- derCOP2(cop=afunc, 0.67, 0.5, derdir="center")
cat(c(lft,rgt,cnt,"\n")) # For this example, all are correct (see derCOP examples)
</code></pre>

<hr>
<h2 id='derCOPinv'>Numerical Derivative Inverse  of a Copula for V with respect to U</h2><span id='topic+derCOPinv'></span>

<h3>Description</h3>

<p>Compute the inverse of a numerical partial derivative for <code class="reqn">V</code> with respect to <code class="reqn">U</code> of a copula, which is a <em>conditional quantile function</em> for nonexceedance probability <code class="reqn">t</code>, or
</p>
<p style="text-align: center;"><code class="reqn">t = c_u(v) = \mathbf{C}^{(-1)}_{2 \mid 1}(v \mid u) = \frac{\delta \mathbf{C}(u,v)}{\delta u}\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">v</code>. Nelsen (2006, pp. 13, 40&ndash;41) shows that this inverse is quite important for random variable generation using the <em>conditional distribution method</em>. This function is not vectorized and will not be so.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derCOPinv(cop=NULL, u, t, trace=FALSE,
          delu=.Machine$double.eps^0.50, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derCOPinv_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="derCOPinv_+3A_u">u</code></td>
<td>
<p>A single nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="derCOPinv_+3A_t">t</code></td>
<td>
<p>A single nonexceedance probability level <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="derCOPinv_+3A_trace">trace</code></td>
<td>
<p>A logical controlling a <code>message</code> on whether the signs on the <code>uniroot</code> are the same&mdash;this is helpful in exploring the numerical derivative limits of a given implementation of a copula.</p>
</td></tr>
<tr><td><code id="derCOPinv_+3A_delu">delu</code></td>
<td>
<p>The <code class="reqn">\Delta u</code> interval for the derivative;</p>
</td></tr>
<tr><td><code id="derCOPinv_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structures, if needed, to pass to <code>cop</code>; and</p>
</td></tr>
<tr><td><code id="derCOPinv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the derivative inverse are returned.
</p>


<h3>Note</h3>

<p><em>AN EDUCATIONAL OPPORTUNITY</em>&mdash;The Farlie-Gumbel-Morgenstern copula <code class="reqn">\mathbf{FGM}(u,v)</code> <br /> (<code><a href="#topic+FGMcop">FGMcop</a></code>) (Joe, 2014, p. 213) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{FGM}(u,v; \Theta) = uv[1+\Theta(1-u)(1-v)]\mbox{,}</code>
</p>

<p>where <code class="reqn">-1 \le \Theta \le 1</code> has analytical solutions to the conditional cumulative distribution function (CDF) <code class="reqn">\mathbf{C}_{2 \mid 1}(v \mid u)</code> as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{2 \mid 1}(v \mid u) = v[1 + \Theta(1-v)(1-2u)]\mbox{,}</code>
</p>

<p>and the inverse of the conditional CDF as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{2 \mid 1}(v \mid u) = \frac{[1 + \Theta(1-2u)] - \sqrt{[1+\Theta(1-2u)]^2 - 4t(1-2u)}}{2\Theta(1-2u)}\mbox{.}</code>
</p>

<p>These three functions for the copula can be defined in <span class="rlang"><b>R</b></span> by
</p>
<pre>
  "FGMcop"       &lt;- function(u,v, para=NULL, ...) u*v*(1 + para*(1-u)*(1-v)  )
  "joeFGMder"    &lt;- function(u,v, para=NULL, ...)   v*(1 + para*(1-v)*(1-2*u))
  "joeFGMderinv" &lt;- function(u,t, para=NULL, ...) {
      K &lt;- (1-2*u)
      ((1 + para*K) - sqrt((1 + para*K)^2 - 4*t*K))/(2*para*K)
  }
</pre>
<p>The <code class="reqn">\mathbf{C}^{(-1)}_{2 \mid 1}(v \mid u)</code> is critical for simulation by the conditional simulation method. Although exclusively for simulation, <span class="pkg">copBasic</span> uses inversion of the numerical derivative, the <code class="reqn">\mathbf{FGM}</code> copula has three representations of supposedly the same analytical algorithm for simulation in the literature (Durante, 2007; Johnson, 1987; Nelsen, 2006). An opportunity for comparison is thus available.
</p>
<p>The three analytical algorithms for nonexceedance probability <code class="reqn">t</code> given <code class="reqn">u</code> by mathematics and code, following Durante (2007, p. 245), are
</p>
<p style="text-align: center;"><code class="reqn">A = \Theta(1-2u) - 1\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B = \sqrt{A^2 - 4t(A+1)}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">v = 2t/(B-A)\mbox{,}</code>
</p>

<p>and in <span class="rlang"><b>R</b></span>, this &ldquo;Durante algorithm&rdquo; is
</p>
<pre>
  "durFGMderinv" &lt;- function(u,t, para=NULL, ...) { # Durante (2007, p. 245)
      A &lt;- para*(1-2*u) - 1; B &lt;- sqrt(A^2 - 4*t*(A+1)); return(2*t/(B - A))
  }
</pre>
<p>and, letting <code class="reqn">K = (2u - 1)</code>, following Johnson (1987, p. 185)
</p>
<p style="text-align: center;"><code class="reqn">A = K\Theta - 1</code>
</p>

<p style="text-align: center;"><code class="reqn">B = \sqrt{1 - 2K\Theta + (K\Theta)^2 + 4tK\Theta}</code>
</p>

<p style="text-align: center;"><code class="reqn">v = 2t/(B - A)</code>
</p>

<p>and in <span class="rlang"><b>R</b></span>, this &ldquo;Johnson algorithm&rdquo; is
</p>
<pre>
  "jonFGMderinv" &lt;- function(u,t, para=NULL, ...) { # Johnson (1987, p. 185)
      K &lt;- (2*u - 1)
      A &lt;- K*para - 1; B &lt;- sqrt(1 - 2*K*para + (K*para)^2 + 4*t*K*para)
      2*t/(B - A)
  }
</pre>
<p>and finally following Nelsen (2006, p. 87)
</p>
<p style="text-align: center;"><code class="reqn">A = 1 + \theta(1 - 2u)\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B = \sqrt{A^2 - 4t(A-1)}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">v = 2t/(B+A)\mbox{,}</code>
</p>

<p>and in <span class="rlang"><b>R</b></span>, this &ldquo;Nelsen algorithm&rdquo; is
</p>
<pre>
  "nelFGMderinv" &lt;- function(u,t, para=NULL, ...) { # Nelsen (2006, p. 87)
      A &lt;- 1 + para*(1-2*u); B &lt;- sqrt(A^2 - 4*t*(A-1)); return(2*t/(B + A))
  }
</pre>
<p>With appropriate code now available, two comparisons can be made in the following sections.
</p>
<p><em>CONDITIONAL DISTRIBUTION FUNCTION</em>&mdash;A comparison of the analytical <code class="reqn">\mathbf{FGM}(u,v)</code> derivative shows that Joe's equation is congruent with the numerical derivative of <span class="pkg">copBasic</span>:
</p>
<pre>
  joeFGMder(0.8, 0.44, para=0.78)             # 0.3246848      (Joe, 2014)
  derCOP(   0.8, 0.44, para=0.78, cop=FGMcop) # 0.3246848      (copBasic )
</pre>
<p>and the result will be used in the computations that follow.
</p>
<p>A comparison for <code class="reqn">t = 0.3246848</code> of the analytical inverse and the numerical optimization of the numerical derivative of <span class="pkg">copBasic</span> is
</p>
<pre>
  joeFGMderinv(0.8, 0.3246848, para=0.78)             # 0.5327603
  derCOPinv(   0.8, 0.3246848, para=0.78, cop=FGMcop) # 0.4399934 --&gt; 0.44
</pre>
<p>where obviously, the two results are not in agreement&mdash;so something is amiss. Because many examples in this documentation clearly demonstrate numerical reliability, a tentative conclusion is that Joe's listed equation must be in error. Let us check this hypothesis against the three other sources:
</p>
<pre>
  durFGMderinv(0.8, 0.3246848, para=0.78) # 0.2074546          (Durante, 2007)
  jonFGMderinv(0.8, 0.3246848, para=0.78) # 0.44               (Johnson, 1987)
  nelFGMderinv(0.8, 0.3246848, para=0.78) # 0.44               (Nelsen,  2006)
</pre>
<p>The result from Durante (2007) is different from both Joe (2014) and from <span class="pkg">copBasic</span>. However, the Johnson (1987) and Nelsen (2006) versions are equivalent and congruent to <span class="pkg">copBasic</span> with the <em>distinctly different</em> numerical methods of <code>derCOPinv</code>. These incongruent results demonstrate that care is needed when navigating the copula literature and the usefulness of the <span class="pkg">copBasic</span>-style implementation of copula theory. In words, these computations show that the <code class="reqn">t \approx 32</code>nd percentile of the <code class="reqn">\mathbf{FGM}</code> copula given that the 80th percentile in <code class="reqn">U</code> is about the 44th percentile of <code class="reqn">V</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Durante, F., 2007, Families of copulas, Appendix C, <em>in</em> Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Johnson, M.E., 1987, Multivariate statistical simulation: New York, John Wiley, 230 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Zhang, L., and Singh, V.P., 2019, Copulas and their applications in water resources engineering: Cambridge University Press, ISBN 978&ndash;1&ndash;108&ndash;47425&ndash;2.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+derCOP">derCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>u &lt;- runif(1); t &lt;- runif(1)
derCOPinv(u,t, cop=W)   # perfect negative dependence
derCOPinv(u,t, cop=P)   # independence
derCOPinv(u,t, cop=M)   # perfect positive dependence
derCOPinv(u,t, cop=PSP) # a parameterless copula example
## Not run: 
# Simulate 500 values from product (independent) copula
plot(NA,NA, type="n", xlim=c(0,1), ylim=c(0,1), xlab="U", ylab="V")
for(i in 1:500) {
   u &lt;- runif(1); t &lt;- runif(1)
   points(u, derCOPinv(cop=P, u, t), cex=0.5, pch=16) # black dots
}
# Now simulate 500 from the Nelsen 4.2.12 copula.
for(i in 1:500) {
   u &lt;- runif(1); t &lt;- runif(1)
   points(u,derCOPinv(cop=N4212cop,para=9.3,u,t), cex=2, pch=16, col=2) # red dots
} #
## End(Not run)

## Not run: 
# Zhang and Singh (2019) exam. 3.23, p. 105
# show the application of the derivative inversion C2|1
# for u=0.6036 and t=0.6036 ---&gt; v = 0.4719
derCOPinv( cop=CLcop, 0.6036, 0.4028, para=0.5) # 0.4719 for C2|1
derCOPinv2(cop=CLcop, 0.6036, 0.4028, para=0.5) # 0.4719 for C1|2
# and C2|1 and C1|2 are equal because the copula has permutation symmetry
isCOP.permsym(cop=CLcop, para=0.5) # TRUE
## End(Not run)
</code></pre>

<hr>
<h2 id='derCOPinv2'>Numerical Derivative Inverse of a Copula for U with respect to V</h2><span id='topic+derCOPinv2'></span>

<h3>Description</h3>

<p>Compute the inverse of a numerical partial derivative for <code class="reqn">U</code> with respect to <code class="reqn">V</code> of a copula, which is a <em>conditional quantile function</em> for nonexceedance probability <code class="reqn">t</code>, or
</p>
<p style="text-align: center;"><code class="reqn">t = c_v(u) = \mathbf{C}^{(-1)}_{1 \mid 2}(u \mid v) =  \frac{\delta \mathbf{C}(u,v)}{\delta v}\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">u</code>. Nelsen (2006, pp. 13, 40&ndash;41) shows that this inverse is quite important for random variable generation using the <em>conditional distribution method</em>. This function is not vectorized and will not be so.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derCOPinv2(cop=NULL, v, t, trace=FALSE,
           delv=.Machine$double.eps^0.50, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derCOPinv2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="derCOPinv2_+3A_v">v</code></td>
<td>
<p>A single nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="derCOPinv2_+3A_t">t</code></td>
<td>
<p>A single nonexceedance probability level <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="derCOPinv2_+3A_trace">trace</code></td>
<td>
<p>A logical controlling a <code>message</code> on whether the signs on the <code>uniroot</code> are the same&mdash;this is helpful in exploring the numerical derivative limits of a given implementation of a copula.</p>
</td></tr>
<tr><td><code id="derCOPinv2_+3A_delv">delv</code></td>
<td>
<p>The <code class="reqn">\Delta v</code> interval for the derivative;</p>
</td></tr>
<tr><td><code id="derCOPinv2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to <code>cop</code>; and</p>
</td></tr>
<tr><td><code id="derCOPinv2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the derivative inverse are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+derCOP2">derCOP2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>u &lt;- runif(1); t &lt;- runif(1)
derCOPinv2(u,t, cop=W)   # perfect negative dependence
derCOPinv2(u,t, cop=P)   # independence
derCOPinv2(u,t, cop=M)   # perfect positive dependence
derCOPinv2(u,t, cop=PSP) # a parameterless copula example
## Not run: 
# Simulate 500 values from product (independent) copula
plot(NA,NA, type="n", xlim=c(0,1), ylim=c(0,1), xlab="U", ylab="V")
for(i in 1:500) {
   v &lt;- runif(1); t &lt;- runif(1)
   points(derCOPinv2(cop=P, v, t),v, cex=0.5, pch=16) # black dots
}
# Simulate 500 of a Frechet Family copula and note crossing singularities.
for(i in 1:500) {
   v &lt;- runif(1); t &lt;- runif(1)
   u &lt;- derCOPinv2(v, t, cop=FRECHETcop, para=list(alpha=0.7, beta=0.169))
   points(u,v, cex=2, pch=16, col=2) # red dots
} #
## End(Not run)
</code></pre>

<hr>
<h2 id='diagCOP'>The Diagonals of a Copula</h2><span id='topic+diagCOP'></span>

<h3>Description</h3>

<p>Compute the <em>primary diagonal</em> or alternatively the <em>secondary diagonal</em>  (Nelsen, 2006, pp. 12 and 16) of copula <code class="reqn">\mathbf{C}(u,v)</code>.
The primary diagonal is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{\delta}_\mathbf{C}(t) = \mathbf{C}(t,t)\mbox{,}</code>
</p>

<p>and the secondary diagonal is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{\delta}^{\star}_\mathbf{C}(t) = \mathbf{C}(t,1-t)\mbox{.}</code>
</p>

<p>Plotting is provided by this function because the diagonals are such important visual attributes of a copula. This function computes whole diagonals. If individual values are desired, then users are asked to use function calls along the diagonal such as <code>COP(0.25,0.25, cop=P)</code> for the primary diagonal and <code>COP(0.25,1-0.25, cop=P)</code> for the secondary diagonal, where for both examples the <em>independence copula</em> (<code class="reqn">uv = \mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>) was chosen for purposes of clarification.
</p>
<p>The <code class="reqn">\mathbf{\delta}_\mathbf{C}(t)</code> is related to order statistics of the multivariate sample (here bivariate) (Durante and Sempi, 2015, p. 68). The probability for the maxima is
<code class="reqn">\mathrm{Pr}[\mathrm{max}(u, v) \le t] = \mathbf{C}(t,t) = \mathbf{\delta}_\mathbf{C}(t) \mbox{\ and }</code>
the probability for the minima is
<code class="reqn">\mathrm{Pr}[\mathrm{min}(u, v) \le t] = 2t - \mathbf{\delta}_\mathbf{C}(t)\mbox{.}</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagCOP(cop=NULL, para=NULL, secondary=FALSE,
        ploton=TRUE, lines=TRUE, delt=0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diagCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="diagCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="diagCOP_+3A_secondary">secondary</code></td>
<td>
<p>A logical to toggle the secondary diagonal;</p>
</td></tr>
<tr><td><code id="diagCOP_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="diagCOP_+3A_lines">lines</code></td>
<td>
<p>Draw the lines of diagonal to the current device;</p>
</td></tr>
<tr><td><code id="diagCOP_+3A_delt">delt</code></td>
<td>
<p>The increment of the diagonal curve to plot, defaults to 0.5-percent intervals, which should be small enough to resolve fine curvature for many copulas in practice; and</p>
</td></tr>
<tr><td><code id="diagCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>plot()</code> and <code>lines()</code> functions in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> of the <code class="reqn">t</code> values, <code class="reqn">\mathbf{\delta}_\mathbf{C}(t,t)</code> (primary) or <code class="reqn">\mathbf{\delta}^{\star}_\mathbf{C}(t,1-t)</code> (secondary diagonal), along with a tag as to which diagonal is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Durante, F., and Sempi, C., 2015, Principles of copula theory: Boca Raton, CRC Press, 315 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOPatf">diagCOPatf</a></code>, <code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+sectionCOP">sectionCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# The primary diagonal of the W, P, M, and PSP copulas on the same plot
D &lt;- diagCOP(cop=W,   lwd=2)
D &lt;- diagCOP(cop=P,   lty=2, ploton=FALSE)
D &lt;- diagCOP(cop=M,   col=2, ploton=FALSE)
D &lt;- diagCOP(cop=PSP, col=3, ploton=FALSE)
mtext("PRIMARY DIAGONAL OF SIMPLE COPULAS") # four primary diagonals 
## End(Not run)

## Not run: 
# The secondary diagonal of the W, P, M, and PSP copulas on the same plot
D &lt;- diagCOP(cop=W,   lwd=2, secondary=TRUE)
D &lt;- diagCOP(cop=P,   lty=2, secondary=TRUE, ploton=FALSE)
D &lt;- diagCOP(cop=M,   col=2, secondary=TRUE, ploton=FALSE)
D &lt;- diagCOP(cop=PSP, col=3, secondary=TRUE, ploton=FALSE)
mtext("SECONDARY DIAGONAL OF SIMPLE COPULAS") # four secondary diagonals 
## End(Not run)
</code></pre>

<hr>
<h2 id='diagCOPatf'>Numerical Rooting the Diagonal of a Copula</h2><span id='topic+diagCOPatf'></span><span id='topic+diagCOPinv'></span>

<h3>Description</h3>

<p>Compute a numerical root along the <em>primary diagonal</em> (Nelsen, 2006, pp. 12 and 16) of copula <code class="reqn">\mathbf{C}(u,v) = F = \mathbf{C}(t,t)</code> having joint probability <code class="reqn">F</code>. The diagonals treat the nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code> as equals (<code class="reqn">u=v=t</code>). The primary diagonal is defined for a joint nonexceedance probability <code class="reqn">t</code> as
</p>
<p style="text-align: center;"><code class="reqn">F = \mathbf{C}(t,t) \rightarrow t = \delta_{\mathbf{C}}^{(-1)}(f)\mbox{,}</code>
</p>

<p>where the function solves for <code class="reqn">t</code>. Examples using the concept behind <code>diagCOPatf</code> are available under <code><a href="#topic+duCOP">duCOP</a></code> and <code><a href="#topic+jointCOP">jointCOP</a></code>, thus the <code>diagCOPatf</code> function can be also called by either <code><a href="#topic+jointCOP">jointCOP</a></code> and <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code>. Internally, the function uses limits of the root finder that are not equal to the anticipated interval <code class="reqn">[0,1]</code>, but equal to &ldquo;small&rdquo; (see description for argument <code>interval</code>). The function does trap for <code>f = 0</code> by returning zero and <code>f = 1</code> by returning unity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagCOPatf(f, cop=NULL, para=NULL, interval=NULL, silent=TRUE, verbose=FALSE,
                                   tol=.Machine$double.eps/10, ...)
diagCOPinv(f, cop=NULL, para=NULL, interval=NULL, silent=TRUE, verbose=FALSE,
                                   tol=.Machine$double.eps/10, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diagCOPatf_+3A_f">f</code></td>
<td>
<p>Joint probability values as a nonexceedance probability <code class="reqn">F</code> for which to compute the root <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_interval">interval</code></td>
<td>
<p>An optional interval for the root search. The default is <code>interval=</code><code>c(lo, 1-lo)</code> for <code>lo=.Machine$double.eps</code> because of difficulties for an interval on <code class="reqn">[0,1]</code>;</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_silent">silent</code></td>
<td>
<p>The argument of the same name given over to <code>try()</code> wrapping the <code>uniroot()</code> operation;</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> then the whole output of the numerical root is returned using only the first value provided by argument <code>f</code>;</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_tol">tol</code></td>
<td>
<p>The <code>tol</code>erance to pass to <code>uniroot</code>. The default here is much smaller than the default of the <code>uniroot()</code> function in <span class="rlang"><b>R</b></span> because of possibility that <code>diagCOPatf</code> would be used at extremely large nonexceedance probabilities; and</p>
</td></tr>
<tr><td><code id="diagCOPatf_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> of the root by the <code>uniroot()</code> function in <span class="rlang"><b>R</b></span> is returned if <code>verbose</code> is <code>TRUE</code>, otherwise the roots (diagonal inverses) for <code class="reqn">t</code> are returned, and if an individual inverse operation fails, then a <code>NA</code> is returned instead.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOP">diagCOP</a></code>, <code><a href="#topic+jointCOP">jointCOP</a></code>, <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>diagCOPatf(0.67, cop=PSP) # 0.8023879
diagCOPatf(0.99, cop=M)   # 0.99 (now see the example below)

## Not run: 
# Several functions from the lmomco package are needed.
# Suppose we have two phenomena with these log10 L-moments:
lmrA &lt;- lmomco::vec2lmom(c(3.97, 0.485, -0.1178, 0.06857))
lmrB &lt;- lmomco::vec2lmom(c(3.77, 0.475, -0.1377, 0.08280))
# Suppose we think that the Gumbel-Hougaard copula is appropriate with a Tau=0.45
Tau &lt;- 0.45 #  Kendall Tau between A and B.
# Suppose that the F=0.99 for either A and B provides a common risk level when they
# are considered in isolation. But what if A and B are rivers that join and joint
# FF=0.99 at their union is of interest?
FF &lt;- 0.99
parA   &lt;- lmomco::lmom2par(lmrA, type="kap")
parB   &lt;- lmomco::lmom2par(lmrB, type="kap")
EventA &lt;- lmomco::qlmomco(FF, parA)
EventB &lt;- lmomco::qlmomco(FF, parB)
ApB &lt;- 10^(EventA) + 10^(EventB) # Purely an additive conceptualization
# The FF=0.99 event is assumed to occur simultaneously on both streams, which is
# equivalent to saying that the correlation between the two is absolute 1-to-1.

# Now consider including the association as measured by Kendall Tau:
Fjoint  &lt;- diagCOPatf(FF, cop=GHcop, para=GHcop(tau=Tau)$para)
EventAj &lt;- lmomco::qlmomco(Fjoint, parA)
EventBj &lt;- lmomco::qlmomco(Fjoint, parB)
AcB &lt;- 10^(EventAj) + 10^(EventBj) # Joint probability 0.99 at the union

# Now consider the association if the rivers are INDEPENDENT:
Fjoint  &lt;- diagCOPatf(FF, cop=GHcop, para=GHcop(tau=0)$para)
EventAj &lt;- lmomco::qlmomco(Fjoint, parA)
EventBj &lt;- lmomco::qlmomco(Fjoint, parB)
AiB &lt;- 10^(EventAj) + 10^(EventBj) # Joint probability 0.99 at the union

# ApB = 312,000 # The perfectly simultaneous addition makes too little.
# AcB = 323,000 # The copula preserves at least the known association.
# AiB = 330,000 # The independence conceptualization makes too much.
## End(Not run)
</code></pre>

<hr>
<h2 id='duCOP'>The Dual of a Copula Function</h2><span id='topic+duCOP'></span>

<h3>Description</h3>

<p>Compute the <em>dual of a copula (function)</em> from a copula (Nelsen, 2006, pp. 33&ndash;34), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = \tilde{\mathbf{C}}(u,v) = u + v - \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>where <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> is the dual of a copula and <code class="reqn">u</code> and <code class="reqn">v</code> are nonexceedance probabilities. The dual of a copula is the expression for the probability that either <code class="reqn">U \le u</code> <b>or</b> <code class="reqn">V \le v</code>, which is unlike the <em>co-copula (function)</em> (see <code><a href="#topic+coCOP">coCOP</a></code>) that provides <code class="reqn">\mathrm{Pr}[U &gt; u \mathrm{\ or\ } V &gt; v]</code>. The dual of a copula is a function and not in itself a copula. The dual of the  <em>survival copula</em> (<code><a href="#topic+surCOP">surCOP</a></code>) is the <em>co-copula (function)</em> (<code><a href="#topic+coCOP">coCOP</a></code>). Some rules of copulas mean that
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mathbf{C}}(u',v') + \tilde{\mathbf{C}}(u,v) = 1\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{\mathbf{C}}(u',v')</code> is the survival copula in terms of exceedance probabilities <code class="reqn">u'</code> and <code class="reqn">v'</code> or in <span class="pkg">copBasic</span> code that the functions <code><a href="#topic+surCOP">surCOP</a></code> + <code>duCOP</code> equal unity.
</p>
<p>The function <code>duCOP</code> gives &ldquo;protection&rdquo; against simultaneous (concurrent or dual) risk by failure if and only if failure is caused (defined) by both hazard sources <code class="reqn">U</code> and <code class="reqn">V</code> being by themselves responsible for failure. Expressing this in terms of an annual probability of occurrence (<code class="reqn">q</code>), one has
</p>
<p style="text-align: center;"><code class="reqn">q = 1 - \mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = 1 - \tilde{\mathbf{C}}(u,v)\mbox{\ or}</code>
</p>

<p>in <span class="rlang"><b>R</b></span> code <code>q &lt;- 1 - duCOP(u,v)</code>. So, as a mnemonic: <em>A dual of a copula is the probabililty of nonexceedance if the hazard sources must <b>dual</b> (concur, link, pair, twin, twain) between each other to cause failure.</em> An informative graphic is shown within <code><a href="#topic+copBasic-package">copBasic-package</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duCOP(u, v, cop=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="duCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="duCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="duCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="duCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula; and</p>
</td></tr>
<tr><td><code id="duCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass (such as parameters, if needed, for the copula in the form of a list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the dual of a copula are returned.
</p>


<h3>Note</h3>

<p>There can be confusion in the interpretation and implemenation of the <b>or</b> condition of <em>joint probability</em> provided by <code class="reqn">\tilde{\mathbf{C}}(u,v)</code>. Two types of <b>or</b>'s seemingly exist depending on one's concept of the meaning of &ldquo;or.&rdquo;  To start, there is the &ldquo;either or both&rdquo; conceptualization (<b>joint or</b>) that encompasses either &ldquo;event&rdquo; (say a loss) of importance for random variables <code class="reqn">U</code> and <code class="reqn">V</code> <em>as well as</em> the <b>joint and</b> conditions where both variables simultaneously are generating an event of importance.
</p>
<p>Let us continue by performing a massive simulation for the <code class="reqn">\mathbf{PSP}(u,v)</code> copula (<code><a href="#topic+PSP">PSP</a></code>) and set an either event standard on the margins as 10 percent for an arbitrary starting point. The <code class="reqn">\mathbf{PSP}</code> has positive association with lower tail dependency, and the example here considers the left tail as the risk tail.
</p>
<pre>
  Event &lt;- 0.1; nn &lt;- 100000; set.seed(9238)
  UV &lt;- simCOP(n=nn, cop=PSP, graphics=FALSE) # 1E5 realizations
</pre>
<p>Next, let us step through counting and then make theoretical comparisons using copula theory. The <b>joint and</b> condition as nonexceedances is
</p>
<pre>
  ANDs &lt;- length(UV$U[UV$U &lt;= Event &amp; UV$V &lt;= Event]) / nn
  ANDt &lt;- COP(Event, Event, cop=PSP)
  message(   "Joint AND by simulation = ", round(ANDs, digits=5),
           "\n    Joint AND by theory = ", round(ANDt, digits=5))
  # ANDs = 0.05348 and ANDt = 0.05263 (numerical congruence)
</pre>
<p>where it is obvious that the simulations and theory estimate about the same <b>joint and</b> condition. Now, the <b>joint or</b> condition as nonexceedances is
</p>
<pre>
  ORs &lt;- length(UV$U[UV$U &lt;= Event | UV$V &lt;= Event]) / nn
  ORt &lt;- duCOP(Event, Event, cop=PSP)
  message(   "Joint OR by simulation = ", round(ORs, digits=5),
           "\n    Joint OR by theory = ", round(ORt, digits=5))
  # ORs = 0.14779 and ORt = 0.14737 (numerical congruence)
</pre>
<p>where it is obvious that the simulations and theory estimate about the same <b>joint or</b> condition. Finally, the joint <b>mutually exclusive or</b> condition as nonexceedances is
</p>
<pre>
  eORs &lt;- length((UV$U[(UV$U &lt;= Event | UV$V &lt;= Event) &amp;
                     ! (UV$U &lt;= Event &amp; UV$V &lt;= Event)])) / nn
  eORt &lt;- ORt - ANDt # theoretical computation
  message(   "Joint exclusive OR by simulation = ", round(eORs, digits=5),
           "\n    Joint exclusive OR by theory = ", round(eORt, digits=5))
  # eORs = 0.09431 and eORt = 0.09474 (numerical congruence)
</pre>
<p>where it is obvious that the simulations and theory estimate about the same joint <b>mutually exclusive or</b> condition, and where it is shown that the prior two theoretical joint probabilities can be subtracted from each to yield the <b>mutually exclusive or</b> condition.
</p>
<p>Let us then play out a scenario in which it is judged that of the events causing damage that the simultaneous occurrance is worse but that engineering against about 5 percent of events not occurring at the same time represents the most funding available. Using numerical methods, it is possible to combine <code class="reqn">\tilde{\mathbf{C}}</code> and <code class="reqn">\mathbf{C}</code> and assume equal marginal risk in <code class="reqn">U</code> and <code class="reqn">V</code> as the following list shows:
</p>
<pre>
  "designf" &lt;- function(t) { # a one-off function just for this example
     duCOP(t, t, cop=PSP) - COP(t, t, cop=PSP) - 5/100 # 5 percent
  }
  dThres &lt;- uniroot(designf, c(.Machine$double.eps,0.5))$root
</pre>
<p>where the <code>uniroot</code> function performs the optimization and the <code>.Machine$double.eps</code> value is used because the <code class="reqn">\mathbf{PSP}</code> is <code>NaN</code> for zero probability. (It is unity for unity marginal probabilities.)
</p>
<p>The design threshold on the margins then is <code>dThres</code> <code class="reqn">\approx</code> 0.05135. In other words, the <code>designThres</code> is the marginal probability that results in about 5 percent of events not occurring at the same time. Then considering the simulated sample and counting the nonexceedances by code one achieves:
</p>
<pre>
  Damage       &lt;- length( UV$U[ UV$U &lt;= dThres | UV$V &lt;= dThres ])
  SimDamage    &lt;- length( UV$U[ UV$U &lt;= dThres &amp; UV$V &lt;= dThres ])
  NonSimDamage &lt;- length((UV$U[(UV$U &lt;= dThres | UV$V &lt;= dThres) &amp;
                             ! (UV$U &lt;= dThres &amp; UV$V &lt;= dThres)]) )
  message(  "                 Damaging Events (sim.) = ", Damage,
          "\n    Simultaneous damaging events (sim.) = ", SimDamage,
          "\n Nonsimultaneous damaging events (sim.) = ", NonSimDamage)
</pre>
<p>but also the theoretical expectations are readily computed using copula theory:
</p>
<pre>
  tDamage       &lt;- as.integer(duCOP(dThres, dThres, cop=PSP) * nn)
  tSimDamage    &lt;- as.integer(  COP(dThres, dThres, cop=PSP) * nn)
  tNonSimDamage &lt;- tDamage - tSimDamage
  message(  "                 Damaging Events (theory) = ", tDamage,
          "\n    Simultaneous damaging events (theory) = ", tSimDamage,
          "\n Nonsimultaneous damaging events (theory) = ", tNonSimDamage)
</pre>
<p>The counts from the former listing are 7,670; 2,669; and 5,001, whereas the respective counts from the later listing are 7,635; 2,635; and 5,000. Numerical congruency in the counts thus exists.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+coCOP">coCOP</a></code>, <code><a href="#topic+surCOP">surCOP</a></code>, <code><a href="#topic+jointCOP">jointCOP</a></code>, <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>u &lt;- runif(1); t &lt;- runif(1)
duCOP(cop=W,u,t)    # joint or probability for perfect negative dependence
duCOP(cop=P,u,t)    # joint or probability for perfect        independence
duCOP(cop=M,u,t)    # joint or probability for perfect positive dependence
duCOP(cop=PSP,u,t)  # joint or probability for some positive    dependence

# Next demonstrate COP + duCOP = unity.
"MOcop.formula" &lt;- function(u,v, para=para, ...) {
   alpha &lt;- para[1]; beta &lt;- para[2]; return(min(v*u^(1-alpha), u*v^(1-beta)))
}
"MOcop" &lt;- function(u,v, ...) { asCOP(u,v, f=MOcop.formula, ...) }

u &lt;- 0.2; v &lt;- 0.75; ab &lt;- c(1.5, 0.3)
surCOP(1-u,1-v, cop=MOcop, para=ab) + duCOP(u,v, cop=MOcop, para=ab) # UNITY

# See extended code listings and discussion in the Note section</code></pre>

<hr>
<h2 id='EMPIRcop'>The Bivariate Empirical Copula</h2><span id='topic+EMPIRcop'></span>

<h3>Description</h3>

<p>The <em>bivariate empirical copula</em> (Nelsen, 2006, p. 219) for a bivariate sample of length <code class="reqn">n</code> is defined for random variables <code class="reqn">X</code> and <code class="reqn">Y</code> as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_n\biggl(\frac{i}{n}, \frac{j}{n}\biggr) = \frac{\mathrm{number\ of\ pairs\ (}x,y\mathrm{)\ with\ }x \le x_{(i)}\mathrm{\ and\ }y \le y_{(j)}}{n}\mbox{,}</code>
</p>

<p>where <code class="reqn">x_{(i)}</code> and <code class="reqn">y_{(i)}</code>, <code class="reqn">1 \le i,j \le n</code> or expressed as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_n\biggl(\frac{i}{n}, \frac{j}{n}\biggr) =
     \frac{1}{n}\sum_{i=1}^n \mathbf{1}\biggl(\frac{R_i}{n} \le u_i, \frac{S_i}{n} \le v_i \biggr)\mbox{,}</code>
</p>

<p>where <code class="reqn">R_i</code> and <code class="reqn">S_i</code> are ranks of the data for <code class="reqn">U</code> and <code class="reqn">V</code>, and <code class="reqn">\mathbf{1}(.)</code> is an <em>indicator function</em> that score 1 if condition is true otherwise scoring zero. Using more generic notation, the empirical copula can be defined by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{n}(u,v) =
     \frac{1}{n}\sum_{i=1}^n \mathbf{1}\bigl(u^\mathrm{obs}_{i} \le u_i, v^\mathrm{obs}_{i} \le v_i \bigr)\mbox{,}</code>
</p>

<p>where <code class="reqn">u^\mathrm{obs}</code> and <code class="reqn">v^\mathrm{obs}</code> are thus some type of nonparametric nonexceedance probabilities based on counts of the underlying data expressed in probabilities.
</p>
<p><em>Hazen Empirical Copula</em>&mdash;The &ldquo;Hazen form&rdquo; of the empirical copula is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^\mathcal{H}_{n}(u,v) =
     \frac{1}{n}\sum_{i=1}^n \mathbf{1}\biggl(\frac{R_i - 0.5}{n} \le u_i, \frac{S_i - 0.5}{n} \le v_i \biggr)\mbox{,}</code>
</p>

<p>which can be triggered by <code>ctype="hazen"</code>. This form is named for this package because of direct similarity of the <em>Hazen plotting position</em> to the above definition. Joe (2014, pp. 247&ndash;248) uses the Hazen form. Joe continues by saying &ldquo;[the] adjustment of the uniform score [<code class="reqn">(R - 0.5)/n]</code>] could be done in an alternative form, but there is [asymptotic] equivalence[, and that] <code class="reqn">\mathbf{C}^\mathcal{H}_{n}</code> puts mass of <code class="reqn">n^{-1}</code> at the tuples <code class="reqn">([r_{i1} - 0.5]/n, \ldots, [r_{id} - 0.5]/n)</code> for <code class="reqn">i = 1, \ldots, n</code>.&rdquo; A footnote by Joe (2014) says that &ldquo;the conversion [<code class="reqn">R/(n+1)</code>] is commonly used for the empirical copula.&rdquo; This later form is the &ldquo;Weibull form&rdquo; described next. Joe's preference for the Hazen form is so that the sum of squared normal scores is closer to unity for large <code class="reqn">n</code> than such a sum would be attained using the Weibull form.
</p>
<p><em>Weibull Empirical Copula</em>&mdash;The &ldquo;Weibull form&rdquo; of the empirical copula is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^\mathcal{W}_{n}(u,v) =
     \frac{1}{n}\sum_{i=1}^n \mathbf{1}\biggl(\frac{R_i}{n+1} \le u_i, \frac{S_i}{n+1} \le v_i \biggr)\mbox{,}</code>
</p>

<p>which can be triggered by <code>ctype="weibull"</code>. This form is named for this package because of direct similarity of the <em>Weibull plotting position</em> to the definition, and this form is the default (see argument description).
</p>
<p><em>Bernstein Empirical Copula</em>&mdash;The empirical copula can be extended nonparametrically as the <em>Bernstein empirical copula</em> (Hernández-Maldonado, Díaz-Viera, and Erdely, 2012) and is formulated as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^\mathcal{B}_n(u,v; \eta) = \sum_{i=1}^n\sum_{j=1}^n \mathbf{C}_{n}\biggl(\frac{i}{n},\frac{j}{n}\biggr) \times \eta(i,j; u,v)\mbox{,}</code>
</p>

<p>where the individual <em>Bernstein weights</em> <code class="reqn">\eta(i,j)</code> for the <code class="reqn">k</code>th paired value of the <code class="reqn">u</code> and <code class="reqn">v</code> vectors are
</p>
<p style="text-align: center;"><code class="reqn">\eta(i,j; u,v) = {n \choose i} u^i (1-u)^{n-i} \times {n \choose j} u^j (1-u)^{n-j}\mbox{.}</code>
</p>

<p>The Bernstein extension, albeit conceptually pure in its shuffling by binomial coefficients and left- and right-tail weightings, is quite CPU intensive as inspection of the equations above indicates a nest of four <code>for()</code> loops in <span class="rlang"><b>R</b></span>. (The native <span class="rlang"><b>R</b></span> code of <span class="pkg">copBasic</span> uses the <code>sapply()</code> function in <span class="rlang"><b>R</b></span> liberally for substantial but not a blazing fast speed increase.) The Bernstein extension results in a smoother surface of the empirical copula and can be triggered by <code>ctype="bernstein"</code>.
</p>
<p><em>Checkerboard Empirical Copula</em>&mdash;A simple smoothing to the empirical copula is the <em>checkerboard empirical copula</em> (Segers et al., 2017) that has been adapted from the <span class="pkg">copula</span> package. It is numerically intensive like the Bernstein and possibly of limited usefulness for large sample sizes. The checkerboard extension can be triggered by <code>ctype="checkerboard"</code> and is formulated as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^\sharp_{n}(U) = \frac{1}{n+o} \sum_{i=1}^n\prod_{i=1}^d \mathrm{min}[\mathrm{max}[n U_j - R^{(n)}_{i,j} + 1,0],1]\mathrm{,}</code>
</p>

<p>where <code class="reqn">U</code> is a <code class="reqn">d=2</code> column matrix of <code class="reqn">u</code> and <code class="reqn">v</code>, <code class="reqn">R</code> is a rank function, and <code class="reqn">o</code> is an offset term on <code class="reqn">[0,1]</code>.
</p>
<p>The <em>empirical copula frequency</em> can be defined (Nelson, 2006, p. 219) as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{c}_n(u, v) = \mathbf{C}_n\biggl(\frac{i}{n}, \frac{j}{n}\biggr) -
                           \mathbf{C}_n\biggl(\frac{i-1}{n}, \frac{j}{n}\biggr) -
                           \mathbf{C}_n\biggl(\frac{i}{n}, \frac{j-1}{n}\biggr) +
                           \mathbf{C}_n\biggl(\frac{i-i}{n}, \frac{j-1}{n}\biggr)\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>EMPIRcop(u, v, para=NULL,
               ctype=c("weibull", "hazen", "1/n", "bernstein", "checkerboard"),
                          bernprogress=FALSE, checkerboard.offset=0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="EMPIRcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="EMPIRcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the U-statistics of the data (see <b>Examples</b>). Alternatively, <code>para</code> can be a <code>list</code> holding a <code>para</code> as would be done if it were a vector, but arguments <code>bernstein</code> and <code>bernprogress</code> can be optionally included&mdash;this feature is provided so that the Bernstein refinement can be controlled within the context of other functions calling <code>EMPIRcop</code> such as by <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRcop_+3A_ctype">ctype</code></td>
<td>
<p>An alternative means for trigging the definition of  <code class="reqn">\mathbf{C}_n</code>, <code class="reqn">\mathbf{C}^\mathcal{H}_n</code> (default), <code class="reqn">\mathbf{C}^\mathcal{W}_n</code>, <code class="reqn">\mathbf{C}^\mathcal{B}_n</code>, or <code class="reqn">\mathbf{C}^\sharp_n</code>. This argument of the same name is also used by <code><a href="#topic+blomCOP">blomCOP</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRcop_+3A_bernprogress">bernprogress</code></td>
<td>
<p>The Bernstein copula extension is CPU intensive(!), so a splash counter is pushed to the console via the <code>message()</code> function in <span class="rlang"><b>R</b></span> so as to not discourage the user;</p>
</td></tr>
<tr><td><code id="EMPIRcop_+3A_checkerboard.offset">checkerboard.offset</code></td>
<td>
<p>A scaling of the ratio <code>sum(....)/(n+offset)</code> for the checkerboard empirical copula; and</p>
</td></tr>
<tr><td><code id="EMPIRcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>Not all theoretical measures of copula dependence (both measures of association and measures of asymmetry), which use numerical integration by the <code>integrate()</code> function in <span class="rlang"><b>R</b></span>, can be used for all empirical copulas because of &ldquo;divergent&rdquo; integral errors; however, examples using <em>Hoeffding Phi</em> (<code class="reqn">\Phi_\mathbf{C}</code>; <code><a href="#topic+hoefCOP">hoefCOP</a></code>) and shown under <b>Examples</b>. Other measures of copula dependence include <code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>, <code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, and <code><a href="#topic+uvlmoms">uvlmoms</a></code>. Each of these measures fortunately has a built-in sample estimator.
</p>
<p>It is important to distinquish between a sample estimator and the estimation of the measure using the empirical copula itself via the <code>EMPIRcop</code> function. The sample estimators (triggered by the <code>as.sample</code> arguments for the measures) are reasonably fast and numerically preferred over using the empirical copula. Further, the generally slow numerical integrations for the theoretical definitions of these copula measures might have difficulties. Limited testing, however, suggests prevalence of numerical integration not erroring using the Bernstein extension of the empirical copula, which must be a by-product of the enhanced and sufficient smoothness for the <span class="rlang"><b>R</b></span> default numerical integration to succeed. Many of the measures have <code>brute</code> option for a brute-force numerical integration on a regular grid across the empirical copula&mdash;these are slow but should not trigger errors. As a general rule, users should still use the sample estimators instead.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hernández-Maldonado, V., Díaz-Viera, M., and Erdely, A., 2012, A joint stochastic simulation method using the Bernstein copula as a flexible tool for modeling nonlinear dependence structures between petrophysical properties: Journal of Petroleum Science and Engineering, v. 90&ndash;91, pp. 112&ndash;123.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>
<p>Segers, J., Sibuya, M., and Tsukahara, H., 2017, The empirical beta copula: Journal of Multivariate Analysis, v. 155, pp. 35&ndash;51.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOP">diagCOP</a></code>, <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>, <code><a href="#topic+simCOP">simCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(62)
EMPIRcop(0.321,0.78, para=simCOP(n=90, cop=N4212cop,
                                 para=2.32, graphics=FALSE)) # [1] 0.3222222
N4212cop(0.321,0.78, para=2.32)                              # [1] 0.3201281
## End(Not run)

## Not run: 
set.seed(62) # See note below about another seed to try.
psp &lt;- simCOP(n=34, cop=PSP, ploton=FALSE, points=FALSE) * 150
# Pretend psp is real data, the * 150 is to clearly get into an arbitrary unit system.

# The sort=FALSE is critical in the following two calls. Although the Weibull
# plotting positions are chosen, internally EMPIRcop uses ranks, but the model
# here is to imagine one having a sample in native units of the random variables
# and then casting them into probabilities for other purposes.
fakeU &lt;- lmomco::pp(psp[,1], sort=FALSE) # Weibull plotting position i/(n+1)
fakeV &lt;- lmomco::pp(psp[,2], sort=FALSE) # Weibull plotting position i/(n+1)
uv &lt;- data.frame(U=fakeU, V=fakeV); # our U-statistics

# The next four values should be very close if n above were say 1000, but the
# ctype="bernstein"" should not be used if n &gt;&gt; 34 because of inherently long runtime.
PSP(0.4,0.6)              # 0.3157895 (compare to listed values below)

# Two seeds are shown so that the user can see that depending on the distribution
# of the values given by para that different coincidences of which method is
# equivalent to another exist.
# For set.seed(62) --- "hazen" == "weibull" by coincidence
#    "hazen"     --&gt; 0.3529412
#    "weibull"   --&gt; 0.3529412
#    "1/n"       --&gt; 0.3235294
#    "bernstein" --&gt; 0.3228916
# For set.seed(85) --- "1/n" == "hazen" by coincidence
#    "hazen"     --&gt; 0.3529412
#    "weibull"   --&gt; 0.3823529
#    "1/n"       --&gt; 0.3529412
#    "bernstein" --&gt; 0.3440387

# For set.seed(62) --- not all measures of association can be used for all
# empirical copulas because of 'divergent' integral errors, but this is an example
# for Hoeffding Phi. These computations are CPU intensive, esp. Bernstein.
hoefCOP(as.sample=TRUE, para=uv) #  (sample estimator is fast)  # 0.4987755
hoefCOP(cop=EMPIRcop,   para=uv, ctype="hazen")                 # 0.5035348
hoefCOP(cop=EMPIRcop,   para=uv, ctype="weibull")               # 0.4977145
hoefCOP(cop=EMPIRcop,   para=uv, ctype="1/n")                   # 0.4003646
hoefCOP(cop=EMPIRcop,   para=uv, ctype="bernstein")             # 0.4563724
hoefCOP(cop=EMPIRcop,   para=uv, ctype="checkerboard")          # 0.4952427
## End(Not run)

# All other example suites shown below are dependent on the pseudo-data in the
# variable uv. It is suggested to not run with a sample size much larger than the
# above n=34 if the Bernstein comparison is intended (wanted) simply because of
# lengthy(!) run times, but the n=34 does provide a solid demonstration how the
# level curves for berstein weights are quite smooth.

## Not run: 
# Now let us construct as many as three sets of level curves to the sample
# resided in the uv sample from above using the PSP copula.
level.curvesCOP(cop=PSP); # TRUE, parametric, fast, BLACK CURVES

# Empirical copulas can consume lots of CPU.
# RED CURVES, if n is too small, uniroot() errors might be triggered and likely
# will be using the sample size of 34 shown above.
level.curvesCOP(cop=EMPIRcop, para=uv, delu=0.03, col=2, ploton=FALSE)

# GREEN CURVES (large CPU committment)
# Bernstein progress is uninformative because level.curvesCOP() has taken over control.
bpara &lt;- list(para=uv, ctype="bernstein", bernprogress=FALSE)
level.curvesCOP(cop=EMPIRcop, para=bpara, delu=0.03, col=3, ploton=FALSE)
# The delu is increased for faster execution but more important,
# notice the greater smoothness of the Bernstein refinement.
## End(Not run)

## Not run: 
# Experimental from R Graphics by Murrell (2005, p.112)
"trans3d" &lt;-                         # blackslashes seem needed for the package
function(x,y,z, pmat) {              # for user manual building but bad syntax
  tmat &lt;- cbind(x,y,z,1) %*% pmat    # because remember the percent sign is a
  return(tmat[,1:2] / tmat[,4])      # a comment character in LaTeX.
}

the.grid &lt;- EMPIRgrid(para=uv, ctype="checkerboard")
the.diag &lt;- diagCOP(cop=EMPIRcop, para=uv, ploton=FALSE, lines=FALSE)

the.persp &lt;- persp(the.grid$empcop, theta=-25, phi=20,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
the.trace &lt;- trans3d(the.diag$t, the.diag$t, the.diag$diagcop, the.persp)
lines(the.trace, lwd=2, col=2) # The diagonal of the copula

# The following could have been used as an alternative to call persp()
the.persp &lt;- persp(x=the.grid$u, y=the.grid$v, z=the.grid$empcop, theta=-25, phi=20,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
lines(the.trace, lwd=2, col=2) # The diagonal of the copula #
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRcopdf'>Data Frame Representation of the Bivariate Empirical Copula</h2><span id='topic+EMPIRcopdf'></span>

<h3>Description</h3>

<p>Generate an <span class="rlang"><b>R</b></span> <code>data.frame</code> representation of the <em>bivariate empirical copula</em> (Salvadori <em>et al.</em>, 2007, p. 140) using the coordinates as preserved in the raw data in the parameter object of the bivariate empirical copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRcopdf(para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRcopdf_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the U-statistics of the data (see example) to pass to <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>; and</p>
</td></tr>
<tr><td><code id="EMPIRcopdf_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of <code class="reqn">u</code>, <code class="reqn">v</code>, and <code class="reqn">\mathbf{C}_{n}(u, v)</code> values of the bivariate empirical copula is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
psp &lt;- simCOP(n=39, cop=PSP, ploton=FALSE, points=FALSE) * 150
# Pretend psp is real data, the * 150 is to clearly get into an arbitrary unit system.

# The sort=FALSE is critical in the following two calls to pp() from lmomco.
fakeU &lt;- lmomco::pp(psp[,1], sort=FALSE) # Weibull plotting position i/(n+1)
fakeV &lt;- lmomco::pp(psp[,2], sort=FALSE) # Weibull plotting position i/(n+1)
uv &lt;- data.frame(U=fakeU, V=fakeV) # our U-statistics

empcop &lt;- EMPIRcopdf(para=uv)
plot(empcop$u, empcop$v, cex=1.75*empcop$empcop, pch=16,
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
# Dot size increases with joint probability (height of the copulatic surface).
points(empcop$u, empcop$v, col=2) # red circles
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRgrid'>Grid of the Bivariate Empirical Copula</h2><span id='topic+EMPIRgrid'></span>

<h3>Description</h3>

<p>Generate a gridded representation of the <em>bivariate empirical copula</em> (see <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, Salvadori <em>et al.</em>, 2007, p. 140).  This function has the primary intention of supporting 3-D renderings or 2-D images of the <em>copulatic surface</em>, but many empirical copula functions in <span class="pkg">copBasic</span> rely on the grid of the empirical copula&mdash;unlike the functions that support parametric copulas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRgrid(para=NULL, deluv=0.05, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRgrid_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the U-statistics of the data (see example);</p>
</td></tr>
<tr><td><code id="EMPIRgrid_+3A_deluv">deluv</code></td>
<td>
<p>A delta value of the both the <code class="reqn">u</code> and <code class="reqn">v</code> axes (grid edges) for empirical copula estimation by the <code><a href="#topic+EMPIRcop">EMPIRcop</a></code> function;</p>
</td></tr>
<tr><td><code id="EMPIRgrid_+3A_verbose">verbose</code></td>
<td>
<p>A logical controlling whether the progress during grid building is to be shown; and</p>
</td></tr>
<tr><td><code id="EMPIRgrid_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> of the gridded values of <code class="reqn">u</code>, <code class="reqn">v</code>, and <code class="reqn">\mathbf{C}_{n}(u,v)</code> values of the bivariate empirical copula is returned. (Well only <code class="reqn">\mathbf{C}_{n}(u,v)</code> is in the form of a grid as an <span class="rlang"><b>R</b></span> <code>matrix</code>.) The <code>deluv</code> used to generated the grid also is returned.
</p>


<h3>Note</h3>

<p>The extensive suite of examples is included here because the various ways that algorithms involving empirical copulas can be tested. The figures also provide excellent tools for education on copulas.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+EMPIRcopdf">EMPIRcopdf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# EXAMPLE 1:
psp &lt;- simCOP(n=490, cop=PSP, ploton=FALSE, points=FALSE) * 150
# Pretend psp is real data, the * 150 is to clearly get into an arbitrary unit system.

# The sort=FALSE is critical in the following two calls to pp() from lmomco.
fakeU &lt;- lmomco::pp(psp[,1], sort=FALSE)   # Weibull plotting position i/(n+1)
fakeV &lt;- lmomco::pp(psp[,2], sort=FALSE)   # Weibull plotting position i/(n+1)
uv &lt;- data.frame(U=fakeU, V=fakeV) # our U-statistics

# The follow function is used to make 3-D --&gt; 2-D transformation
# From R Graphics by Murrell (2005, p.112)
"trans3d" &lt;-                         # blackslashes seem needed for the package
function(x,y,z, pmat) {              # for user manual building but bad syntax
  tmat &lt;- cbind(x,y,z,1) %*% pmat    # because remember the percent sign is a
  return(tmat[,1:2] / tmat[,4])      # a comment character in LaTeX.
}

the.grid &lt;- EMPIRgrid(para=uv)
cop.diag &lt;- diagCOP(cop=EMPIRcop, para=uv, ploton=FALSE, lines=FALSE)
empcop   &lt;- EMPIRcopdf(para=uv) # data.frame of all points

# EXAMPLE 1: PLOT NUMBER 1
the.persp &lt;- persp(the.grid$empcop, theta=-25, phi=20,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")

# EXAMPLE 1: PLOT NUMBER 2 (see change in interaction with variable 'the.grid')
the.persp &lt;- persp(x=the.grid$u, y=the.grid$v, z=the.grid$empcop, theta=-25, phi=20,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")

the.diag &lt;- trans3d(cop.diag$t, cop.diag$t, cop.diag$diagcop, the.persp)
lines(the.diag, lwd=4, col=3, lty=2)

points(trans3d(empcop$u, empcop$v, empcop$empcop, the.persp),
       col=rgb(0,1-sqrt(empcop$empcop),1,sqrt(empcop$empcop)), pch=16)
# the sqrt() is needed to darken or enhance the colors

S &lt;- sectionCOP(cop=PSP, 0.2, ploton=FALSE, lines=FALSE)
thelines &lt;- trans3d(rep(0.2, length(S$t)), S$t, S$seccop, the.persp)
lines(thelines, lwd=2, col=6)
S &lt;- sectionCOP(cop=PSP, 0.2, ploton=FALSE, lines=FALSE, dercop=TRUE)
thelines &lt;- trans3d(rep(0.2, length(S$t)), S$t, S$seccop, the.persp)
lines(thelines, lwd=2, col=6, lty=2)

S &lt;- sectionCOP(cop=PSP, 0.85, ploton=FALSE, lines=FALSE, wrtV=TRUE)
thelines &lt;- trans3d(S$t, rep(0.85, length(S$t)), S$seccop, the.persp)
lines(thelines, lwd=2, col=2)
S &lt;- sectionCOP(cop=PSP, 0.85, ploton=FALSE, lines=FALSE, dercop=TRUE)
thelines &lt;- trans3d(S$t, rep(0.85, length(S$t)), S$seccop, the.persp)
lines(thelines, lwd=2, col=2, lty=2)

empder &lt;- EMPIRgridder(empgrid=the.grid)
thelines &lt;- trans3d(rep(0.2, length(the.grid$v)), the.grid$v, empder[3,], the.persp)
lines(thelines, lwd=4, col=6) #
## End(Not run)

## Not run: 
# EXAMPLE 2:
# An asymmetric example to demonstrate that the grid is populated with the
# correct orientation---meaning U is the horizontal and V is the vertical.
"MOcop" &lt;- function(u,v, para=NULL) { # Marshall-Olkin copula
   alpha &lt;- para[1]; beta  &lt;- para[2]; return(min(v*u^(1-alpha), u*v^(1-beta)))
}
# EXAMPLE 2: PLOT NUMBER 1 # See the asymmetry
uv &lt;- simCOP(1000, cop=MOcop, para=c(0.4,0.9)) # The parameters cause asymmetry.
mtext("Simulation from a defined Marshall-Olkin Copula")
the.grid &lt;- EMPIRgrid(para=uv, deluv=0.025)

# EXAMPLE 2: PLOT NUMBER 2
# The second plot by image() will show a "hook" of sorts along the singularity.
image(the.grid$empcop, col=terrain.colors(40)) # Second plot is made
mtext("Image of gridded Empirical Copula")

# EXAMPLE 2: PLOT NUMBER 3
empcop &lt;- EMPIRcopdf(para=uv) # data.frame of all points
# The third plot is the 3-D version overlain with the data points.
the.persp &lt;- persp(x=the.grid$u, y=the.grid$v, z=the.grid$empcop, theta=240, phi=40,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
points(trans3d(empcop$u, empcop$v, empcop$empcop, the.persp),
       col=rgb(0,1-sqrt(empcop$empcop),1,sqrt(empcop$empcop)), pch=16)
mtext("3-D representation of gridded empirical copula with data points")

# EXAMPLE 2: PLOT NUMBER 4
# The fourth plot shows a simulation and the quasi-emergence of the singularity
# that of course the empirical perspective "knows" nothing about. Do not use
# the Kumaraswamy smoothing because in this case the singularity because
# too smoothed out relative to the raw empirical, but of course the sample size
# is large enough to see such things. (Try kumaraswamy=TRUE)
empsim &lt;- EMPIRsim(n=1000, empgrid = the.grid, kumaraswamy=FALSE)
mtext("Simulations from the Empirical Copula") #
## End(Not run)

## Not run: 
# EXAMPLE 3:
psp &lt;- simCOP(n=4900, cop=PSP, ploton=FALSE, points=FALSE) * 150
# Pretend psp is real data, the * 150 is to clearly get into an arbitrary unit system.

# The sort=FALSE is critical in the following two calls to pp() from lmomco.
fakeU &lt;- lmomco::pp(psp[,1], sort=FALSE)   # Weibull plotting position i/(n+1)
fakeV &lt;- lmomco::pp(psp[,2], sort=FALSE)   # Weibull plotting position i/(n+1)
uv &lt;- data.frame(U=fakeU, V=fakeV) # our U-statistics

# EXAMPLE 3: # PLOT NUMBER 1
deluv &lt;- 0.0125 # going to cause long run time with large n
# The small deluv is used to explore solution quality at U=0 and 1.
the.grid &lt;- EMPIRgrid(para=uv, deluv=deluv)
the.persp &lt;- persp(x=the.grid$u, y=the.grid$v, z=the.grid$empcop, theta=-25, phi=20,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")

S &lt;- sectionCOP(cop=PSP, 1, ploton=FALSE, lines=FALSE)
thelines &lt;- trans3d(rep(1, length(S$t)), S$t, S$seccop, the.persp)
lines(thelines, lwd=2, col=2)

S &lt;- sectionCOP(cop=PSP, 0, ploton=FALSE, lines=FALSE)
thelines &lt;- trans3d(rep(0, length(S$t)), S$t, S$seccop, the.persp)
lines(thelines, lwd=2, col=2)

S &lt;- sectionCOP(cop=PSP, 1, ploton=FALSE, lines=FALSE, dercop=TRUE)
thelines &lt;- trans3d(rep(1, length(S$t)), S$t, S$seccop, the.persp)
lines(thelines, lwd=2, col=2, lty=2)

S &lt;- sectionCOP(cop=PSP, 2*deluv, ploton=FALSE, lines=FALSE, dercop=TRUE)
thelines &lt;- trans3d(rep(2*deluv, length(S$t)), S$t, S$seccop, the.persp)
lines(thelines, lwd=2, col=2, lty=2)

empder &lt;- EMPIRgridder(empgrid=the.grid)
thelines &lt;- trans3d(rep(2*deluv,length(the.grid$v)),the.grid$v,empder[3,],the.persp)
lines(thelines, lwd=4, col=5, lty=2)

pdf("conditional_distributions.pdf")
  ix &lt;- 1:length(attributes(empder)$rownames)
  for(i in ix) {
     u &lt;- as.numeric(attributes(empder)$rownames[i])
     S &lt;- sectionCOP(cop=PSP, u, ploton=FALSE, lines=FALSE, dercop=TRUE)
     # The red line is the true.
     plot(S$t, S$seccop, lwd=2, col=2, lty=2, type="l", xlim=c(0,1), ylim=c(0,1),
          xlab="V, NONEXCEEDANCE PROBABILITY", ylab="V, VALUE")
     lines(the.grid$v, empder[i,], lwd=4, col=5, lty=2) # empirical
     mtext(paste("Conditioned on U=",u," nonexceedance probability"))
  }
dev.off() #
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRgridder'>Derivatives of the Grid of the Bivariate Empirical Copula for V with respect to U</h2><span id='topic+EMPIRgridder'></span>

<h3>Description</h3>

<p>Generate derivatives of <code class="reqn">V</code> with respect to <code class="reqn">U</code> of a gridded representation of the <em>bivariate empirical copula</em> (see <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>). This function is the empirical analog to <code><a href="#topic+derCOP">derCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRgridder(empgrid=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRgridder_+3A_empgrid">empgrid</code></td>
<td>
<p>The grid from <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>; and</p>
</td></tr>
<tr><td><code id="EMPIRgridder_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the derivatives of the bivariate empirical copula.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+EMPIRcopdf">EMPIRcopdf</a></code>, <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>, <code><a href="#topic+EMPIRgridder2">EMPIRgridder2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para   &lt;- list(alpha=0.15,  beta=0.65, cop1=PLACKETTcop, cop2=PLACKETTcop,
               para1=0.005, para2=1000)
uv &lt;- simCOP(n=1000, cop=composite2COP, para=para)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

"trans3d" &lt;-                         # blackslashes seem needed for the package
function(x,y,z, pmat) {              # for user manual building but bad syntax
  tmat &lt;- cbind(x,y,z,1) %*% pmat    # because remember the percent sign is a
  return(tmat[,1:2] / tmat[,4])      # a comment character in LaTeX.
}

the.grid &lt;- EMPIRgrid(para=uv, deluv=0.1)
the.diag &lt;- diagCOP(cop=EMPIRcop, para=uv, ploton=FALSE, lines=FALSE)
empcop &lt;- EMPIRcopdf(para=uv) # data.frame of all points

the.persp &lt;- persp(the.grid$empcop, theta=-25, phi=20,
                   xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
points(trans3d(empcop$u, empcop$v, empcop$empcop, the.persp),
       col=rgb(0,1-sqrt(empcop$empcop),1,sqrt(empcop$empcop)), pch=16, cex=0.75)

# Now extract the copula sections
some.lines &lt;- trans3d(rep(0.2, length(the.grid$v)),
                      the.grid$v, the.grid$empcop[3,], the.persp)
lines(some.lines, lwd=2, col=2)
some.lines &lt;- trans3d(the.grid$u, rep(0.6, length(the.grid$u)),
                      the.grid$empcop[,7], the.persp)
lines(some.lines, lwd=2, col=3)
some.lines &lt;- trans3d(rep(0.7, length(the.grid$v)), the.grid$v,
                      the.grid$empcop[8,], the.persp)
lines(some.lines, lwd=2, col=6)

# Now compute some derivatives or conditional cumulative
# distribution functions
empder &lt;- EMPIRgridder(empgrid=the.grid)
some.lines &lt;- trans3d(rep(0.2, length(the.grid$v)), the.grid$v, empder[3,], the.persp)
lines(some.lines, lwd=4, col=2)

empder &lt;- EMPIRgridder2(empgrid=the.grid)
some.lines &lt;- trans3d(the.grid$u, rep(0.6, length(the.grid$u)), empder[,7], the.persp)
lines(some.lines, lwd=4, col=3)

empder &lt;- EMPIRgridder(empgrid=the.grid)
some.lines &lt;- trans3d(rep(0.7, length(the.grid$v)), the.grid$v, empder[8,], the.persp)
lines(some.lines, lwd=4, col=6)

# Demonstrate conditional quantile function extraction for
# the 70th percentile of U and see how it plots on top of
# the thick purple line
empinv &lt;- EMPIRgridderinv(empgrid=the.grid)
some.lines &lt;- trans3d(rep(0.7, length(the.grid$v)), empinv[8,],
                      attributes(empinv)$colnames, the.persp)
lines(some.lines, lwd=4, col=5, lty=2)#
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRgridder2'>Derivatives of the Grid of the Bivariate Empirical Copula for U with respect to V</h2><span id='topic+EMPIRgridder2'></span>

<h3>Description</h3>

<p>Generate derivatives of <code class="reqn">U</code> with respect to <code class="reqn">V</code> of a gridded representation of the <em>bivariate empirical copula</em> (see <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>).  This function is the empirical analog to <code><a href="#topic+derCOP2">derCOP2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRgridder2(empgrid=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRgridder2_+3A_empgrid">empgrid</code></td>
<td>
<p>The grid from <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>; and</p>
</td></tr>
<tr><td><code id="EMPIRgridder2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the derivatives of the bivariate empirical copula.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+EMPIRcopdf">EMPIRcopdf</a></code>, <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>, <code><a href="#topic+EMPIRgridder">EMPIRgridder</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples under EMPIRgridder
</code></pre>

<hr>
<h2 id='EMPIRgridderinv'>Derivative Inverses of the Grid of the Bivariate Empirical Copula for V with respect to U</h2><span id='topic+EMPIRgridderinv'></span>

<h3>Description</h3>

<p>Generate a gridded representation of the inverse of the derivatives of the <em>bivariate empirical copula</em> of <code class="reqn">V</code> with respect to <code class="reqn">U</code>.  This function is the empirical analog to <code><a href="#topic+derCOPinv">derCOPinv</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRgridderinv(empgrid=NULL, kumaraswamy=FALSE, dergrid=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRgridderinv_+3A_empgrid">empgrid</code></td>
<td>
<p>The grid from <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRgridderinv_+3A_kumaraswamy">kumaraswamy</code></td>
<td>
<p>A logical to trigger Kumaraswamy smoothing of the conditional quantile function;</p>
</td></tr>
<tr><td><code id="EMPIRgridderinv_+3A_dergrid">dergrid</code></td>
<td>
<p>The results of <code><a href="#topic+EMPIRgridder">EMPIRgridder</a></code> and if left <code>NULL</code> then that function is called internally. There is some fragility at times in the quality of the numerical derivative and the author has provided this argument so that the derivative can be computed externally and then fed to this inversion function; and</p>
</td></tr>
<tr><td><code id="EMPIRgridderinv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the inverse of the derivative of <code class="reqn">V</code> with respect <code class="reqn">U</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+EMPIRcopdf">EMPIRcopdf</a></code>, <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>, <code><a href="#topic+EMPIRgridder2">EMPIRgridder2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
uv &lt;- simCOP(n=10000, cop=PSP, ploton=FALSE, points=FALSE)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

uv.grid &lt;- EMPIRgrid(para=uv, deluv=.1) # CPU hungry
uv.inv1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
uv.inv2 &lt;- EMPIRgridderinv2(empgrid=uv.grid)
plot(uv, pch=16, col=rgb(0,0,0,.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
lines(qua.regressCOP(f=0.5, cop=PSP), col=2)
lines(qua.regressCOP(f=0.2, cop=PSP), col=2)
lines(qua.regressCOP(f=0.7, cop=PSP), col=2)
lines(qua.regressCOP(f=0.1, cop=PSP), col=2)
lines(qua.regressCOP(f=0.9, cop=PSP), col=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

lines(qua.regressCOP2(f=0.5, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.2, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.7, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.1, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.9, cop=PSP), col=4)

med.wrtv &lt;- EMPIRqua.regress2(f=0.5, empinv=uv.inv2)
lines(med.wrtv, col=4, lwd=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.2, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.7, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.1, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.9, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)#
## End(Not run)

## Not run: 
# Now try a much more complex shape
para   &lt;- list(alpha=0.15,  beta=0.65, cop1=PLACKETTcop, cop2=PLACKETTcop,
               para1=0.005, para2=1000)
uv &lt;- simCOP(n=30000, cop=composite2COP, para=para)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

uv.grid &lt;- EMPIRgrid(para=uv, deluv=0.05) # CPU hungry
uv.inv1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
uv.inv2 &lt;- EMPIRgridderinv2(empgrid=uv.grid)
plot(uv, pch=16, col=rgb(0,0,0,0.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
lines(qua.regressCOP(f=0.5, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.2, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.7, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.1, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.9, cop=composite2COP, para=para), col=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

lines(qua.regressCOP2(f=0.5, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.2, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.7, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.1, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.9, cop=composite2COP, para=para), col=4)

med.wrtv &lt;- EMPIRqua.regress2(f=0.5, empinv=uv.inv2)
lines(med.wrtv, col=4, lwd=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.2, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.7, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.1, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.9, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)#
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRgridderinv2'>Derivative Inverses of the Grid of the Bivariate Empirical Copula for U with respect to V</h2><span id='topic+EMPIRgridderinv2'></span>

<h3>Description</h3>

<p>Generate a gridded representation of the inverse of the derivatives of the <em>bivariate empirical copula</em> of <code class="reqn">U</code> with respect to <code class="reqn">V</code>.  This function is the empirical analog to <code><a href="#topic+derCOPinv2">derCOPinv2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRgridderinv2(empgrid=NULL, kumaraswamy=FALSE, dergrid=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRgridderinv2_+3A_empgrid">empgrid</code></td>
<td>
<p>The grid from <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRgridderinv2_+3A_kumaraswamy">kumaraswamy</code></td>
<td>
<p>A logical to trigger Kumaraswamy smoothing of the conditional quantile function;</p>
</td></tr>
<tr><td><code id="EMPIRgridderinv2_+3A_dergrid">dergrid</code></td>
<td>
<p>The results of <code><a href="#topic+EMPIRgridder2">EMPIRgridder2</a></code> and if left <code>NULL</code> then that function is called internally. There is some fragility at times in the quality of the numerical derivative and the author has provided this argument so that the derivative can be computed externally and then fed to this inversion function; and</p>
</td></tr>
<tr><td><code id="EMPIRgridderinv2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the inverse of the derivative of <code class="reqn">U</code> with respect to <code class="reqn">V</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+EMPIRcopdf">EMPIRcopdf</a></code>, <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>, <code><a href="#topic+EMPIRgridder2">EMPIRgridder2</a></code>, <code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>, <code><a href="#topic+EMPIRgridderinv2">EMPIRgridderinv2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples under EMPIRgridderinv
</code></pre>

<hr>
<h2 id='EMPIRmed.regress'>Median Regression of the Grid of the Bivariate Empirical Copula for V with respect to U</h2><span id='topic+EMPIRmed.regress'></span>

<h3>Description</h3>

<p>Perform <em>median regression</em> from the gridded inversion of the <em>bivariate empirical copula</em> of <code class="reqn">V</code> with respect to <code class="reqn">U</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRmed.regress(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRmed.regress_+3A_...">...</code></td>
<td>
<p>Arguments to pass to <code><a href="#topic+EMPIRqua.regress">EMPIRqua.regress</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the median regression of <code class="reqn">V</code> with respect to <code class="reqn">U</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>, <code><a href="#topic+EMPIRqua.regress">EMPIRqua.regress</a></code>, <code><a href="#topic+EMPIRmed.regress2">EMPIRmed.regress2</a></code>, <code><a href="#topic+EMPIRmed.regress2">EMPIRmed.regress2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples under EMPIRqua.regress
</code></pre>

<hr>
<h2 id='EMPIRmed.regress2'>Median Regression of the Grid of the Bivariate Empirical Copula for U with respect to V</h2><span id='topic+EMPIRmed.regress2'></span>

<h3>Description</h3>

<p>Perform <em>median regression</em> from the gridded inversion of the <em>bivariate empirical copula</em> of <code class="reqn">U</code> with respect to <code class="reqn">V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRmed.regress2(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRmed.regress2_+3A_...">...</code></td>
<td>
<p>Arguments to pass to <code><a href="#topic+EMPIRqua.regress2">EMPIRqua.regress2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the median regression of <code class="reqn">U</code> with respect to <code class="reqn">V</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRgridderinv2">EMPIRgridderinv2</a></code>, <code><a href="#topic+EMPIRqua.regress">EMPIRqua.regress</a></code>, <code><a href="#topic+EMPIRmed.regress">EMPIRmed.regress</a></code>, <code><a href="#topic+EMPIRmed.regress2">EMPIRmed.regress2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples under EMPIRqua.regress
</code></pre>

<hr>
<h2 id='EMPIRqua.regress'>Quantile Regression of the Grid of the Bivariate Empirical Copula for V with respect to U</h2><span id='topic+EMPIRqua.regress'></span>

<h3>Description</h3>

<p>Perform <em>quantile regression</em> from the gridded inversion of the <em>bivariate empirical copula</em> of <code class="reqn">V</code> with respect to <code class="reqn">U</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRqua.regress(f=0.5, u=seq(0.01,0.99, by=0.01), empinv=NULL,
                 lowess=FALSE, f.lowess=1/5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRqua.regress_+3A_f">f</code></td>
<td>
<p>The nonexceedance probability <code class="reqn">F</code> to perform regression at and defaults to median regression <code class="reqn">F=1/2</code>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress_+3A_u">u</code></td>
<td>
<p>A vector of <code class="reqn">u</code> nonexceedance probabilities;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress_+3A_empinv">empinv</code></td>
<td>
<p>The grid from <code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress_+3A_lowess">lowess</code></td>
<td>
<p>Perform <code>lowess</code> smooth on the quantile regression using the smooth factor of <code>f.lowess</code>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress_+3A_f.lowess">f.lowess</code></td>
<td>
<p>Smooth factor of almost the same argument name fed to the <code>lowess()</code> function in <span class="rlang"><b>R</b></span>; and</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the quantile regression of <code class="reqn">V</code> with respect to <code class="reqn">U</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>, <code><a href="#topic+EMPIRqua.regress2">EMPIRqua.regress2</a></code>, <code><a href="#topic+EMPIRmed.regress">EMPIRmed.regress</a></code>, <code><a href="#topic+EMPIRmed.regress2">EMPIRmed.regress2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # EXAMPLE 1
theta &lt;- 25
uv &lt;- simCOP(n=1000, cop=PLACKETTcop, para=theta, ploton=FALSE, points=FALSE)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

uv.grid &lt;- EMPIRgrid(para=uv, deluv=0.05) # CPU hungry
uv.inv1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
plot(uv, pch=16, col=rgb(0,0,0,.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
lines(qua.regressCOP(f=0.5, cop=PLACKETTcop, para=theta), lwd=2)
lines(qua.regressCOP(f=0.2, cop=PLACKETTcop, para=theta), lwd=2)
lines(qua.regressCOP(f=0.7, cop=PLACKETTcop, para=theta), lwd=2)
lines(qua.regressCOP(f=0.1, cop=PLACKETTcop, para=theta), lwd=2)
lines(qua.regressCOP(f=0.9, cop=PLACKETTcop, para=theta), lwd=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

library(quantreg) # Quantile Regression by quantreg
U &lt;- seq(0.01, 0.99, by=0.01)
rqlm &lt;- rq(V~U, data=uv, tau=0.1)
rq.1 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.2)
rq.2 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.5)
rq.5 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.7)
rq.7 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.9)
rq.9 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U

lines(U, rq.1, col=4, lwd=2, lty=4)
lines(U, rq.2, col=4, lwd=2, lty=2)
lines(U, rq.5, col=4, lwd=4)
lines(U, rq.7, col=4, lwd=2, lty=2)
lines(U, rq.9, col=4, lwd=2, lty=4)#
## End(Not run)

## Not run:  # EXAMPLE 2
# Start again with the PSP copula
uv &lt;- simCOP(n=10000, cop=PSP, ploton=FALSE, points=FALSE)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

uv.grid &lt;- EMPIRgrid(para=uv, deluv=0.05) # CPU hungry
uv.inv1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
plot(uv, pch=16, col=rgb(0,0,0,0.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
lines(qua.regressCOP(f=0.5, cop=PSP), lwd=2)
lines(qua.regressCOP(f=0.2, cop=PSP), lwd=2)
lines(qua.regressCOP(f=0.7, cop=PSP), lwd=2)
lines(qua.regressCOP(f=0.1, cop=PSP), lwd=2)
lines(qua.regressCOP(f=0.9, cop=PSP), lwd=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

library(quantreg) # Quantile Regression by quantreg
U &lt;- seq(0.01, 0.99, by=0.01)
rqlm &lt;- rq(V~U, data=uv, tau=0.1)
rq.1 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.2)
rq.2 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.5)
rq.5 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.7)
rq.7 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U
rqlm &lt;- rq(V~U, data=uv, tau=0.9)
rq.9 &lt;- rqlm$coefficients[1] + rqlm$coefficients[2]*U

lines(U, rq.1, col=4, lwd=2, lty=4)
lines(U, rq.2, col=4, lwd=2, lty=2)
lines(U, rq.5, col=4, lwd=4)
lines(U, rq.7, col=4, lwd=2, lty=2)
lines(U, rq.9, col=4, lwd=2, lty=4)#
## End(Not run)

## Not run:  # EXAMPLE 3
uv &lt;- simCOP(n=10000, cop=PSP, ploton=FALSE, points=FALSE)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

uv.grid &lt;- EMPIRgrid(para=uv, deluv=0.1) # CPU hungry
uv.inv1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
uv.inv2 &lt;- EMPIRgridderinv2(empgrid=uv.grid)
plot(uv, pch=16, col=rgb(0,0,0,.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
lines(qua.regressCOP(f=0.5, cop=PSP), col=2)
lines(qua.regressCOP(f=0.2, cop=PSP), col=2)
lines(qua.regressCOP(f=0.7, cop=PSP), col=2)
lines(qua.regressCOP(f=0.1, cop=PSP), col=2)
lines(qua.regressCOP(f=0.9, cop=PSP), col=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

lines(qua.regressCOP2(f=0.5, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.2, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.7, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.1, cop=PSP), col=4)
lines(qua.regressCOP2(f=0.9, cop=PSP), col=4)

med.wrtv &lt;- EMPIRqua.regress2(f=0.5, empinv=uv.inv2)
lines(med.wrtv, col=4, lwd=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.2, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.7, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.1, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.9, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)#
## End(Not run)

## Not run:  # EXAMPLE 4
# Now try a much more complex shape
# lowess smoothing on quantile regression is possible,
# see next example
para   &lt;- list(alpha=0.15,  beta=0.65,
               cop1=PLACKETTcop, cop2=PLACKETTcop, para1=0.005, para2=1000)
uv &lt;- simCOP(n=20000, cop=composite2COP, para=para)
fakeU &lt;- lmomco::pp(uv[,1], sort=FALSE)
fakeV &lt;- lmomco::pp(uv[,2], sort=FALSE)
uv &lt;- data.frame(U=fakeU, V=fakeV)

uv.grid &lt;- EMPIRgrid(para=uv, deluv=0.025) # CPU hungry
uv.inv1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
uv.inv2 &lt;- EMPIRgridderinv2(empgrid=uv.grid)
plot(uv, pch=16, col=rgb(0,0,0,0.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILTIY")
lines(qua.regressCOP(f=0.5, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.2, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.7, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.1, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.9, cop=composite2COP, para=para), col=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

lines(qua.regressCOP2(f=0.5, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.2, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.7, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.1, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.9, cop=composite2COP, para=para), col=4)

med.wrtv &lt;- EMPIRqua.regress2(f=0.5, empinv=uv.inv2)
lines(med.wrtv, col=4, lwd=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.2, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.7, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.1, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.9, empinv=uv.inv2)
lines(qua.wrtv, col=4, lwd=2, lty=4)#
## End(Not run)

## Not run:  # EXAMPLE 5
plot(uv, pch=16, col=rgb(0,0,0,.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
lines(qua.regressCOP(f=0.5, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.2, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.7, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.1, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.9, cop=composite2COP, para=para), col=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1, lowess=TRUE)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1, lowess=TRUE)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1, lowess=TRUE)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1, lowess=TRUE)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1, lowess=TRUE)
lines(qua.wrtu, col=2, lwd=2, lty=4)

lines(qua.regressCOP2(f=0.5, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.2, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.7, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.1, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.9, cop=composite2COP, para=para), col=4)

med.wrtv &lt;- EMPIRqua.regress2(f=0.5, empinv=uv.inv2, lowess=TRUE)
lines(med.wrtv, col=4, lwd=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.2, empinv=uv.inv2, lowess=TRUE)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.7, empinv=uv.inv2, lowess=TRUE)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.1, empinv=uv.inv2, lowess=TRUE)
lines(qua.wrtv, col=4, lwd=2, lty=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.9, empinv=uv.inv2, lowess=TRUE)
lines(qua.wrtv, col=4, lwd=2, lty=4)#
## End(Not run)

## Not run:  # EXAMPLE 6 (changing the smoothing on the lowess)
plot(uv, pch=16, col=rgb(0,0,0,0.1), xlim=c(0,1), ylim=c(0,1),
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILTIY")
lines(qua.regressCOP(f=0.5, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.2, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.7, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.1, cop=composite2COP, para=para), col=2)
lines(qua.regressCOP(f=0.9, cop=composite2COP, para=para), col=2)

med.wrtu &lt;- EMPIRqua.regress(f=0.5, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(med.wrtu, col=2, lwd=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.2, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.7, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=2)
qua.wrtu &lt;- EMPIRqua.regress(f=0.1, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=4)
qua.wrtu &lt;- EMPIRqua.regress(f=0.9, empinv=uv.inv1, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtu, col=2, lwd=2, lty=4)

lines(qua.regressCOP2(f=0.5, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.2, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.7, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.1, cop=composite2COP, para=para), col=4)
lines(qua.regressCOP2(f=0.9, cop=composite2COP, para=para), col=4)

med.wrtv &lt;- EMPIRqua.regress2(f=0.5, empinv=uv.inv2, lowess=TRUE, f.lowess=0.1)
lines(med.wrtv, col=4, lwd=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.2, empinv=uv.inv2, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.7, empinv=uv.inv2, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtv, col=4, lwd=2, lty=2)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.1, empinv=uv.inv2, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtv, col=4, lwd=2, lty=4)
qua.wrtv &lt;- EMPIRqua.regress2(f=0.9, empinv=uv.inv2, lowess=TRUE, f.lowess=0.1)
lines(qua.wrtv, col=4, lwd=2, lty=4)#
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRqua.regress2'>Quantile Regression of the Grid of the Bivariate Empirical Copula for U with respect to V</h2><span id='topic+EMPIRqua.regress2'></span>

<h3>Description</h3>

<p>Generate quantile regression from the gridded inversion of the <em>bivariate empirical copula</em> of <code class="reqn">U</code> with respect to <code class="reqn">V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRqua.regress2(f=0.5, v=seq(0.01,0.99, by=0.01), empinv=NULL,
                  lowess=FALSE, f.lowess=1/5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRqua.regress2_+3A_f">f</code></td>
<td>
<p>The nonexceedance probability <code class="reqn">F</code> to perform regression at and defaults to median regression <code class="reqn">F=1/2</code>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress2_+3A_v">v</code></td>
<td>
<p>A vector of <code class="reqn">v</code> nonexceedance probabilities;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress2_+3A_empinv">empinv</code></td>
<td>
<p>The grid from <code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress2_+3A_lowess">lowess</code></td>
<td>
<p>Perform <code>lowess</code> smooth on the quantile regression using the smooth factor of <code>f=f.lowess</code>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress2_+3A_f.lowess">f.lowess</code></td>
<td>
<p>Smooth factor of almost the same argument name fed to the <code>lowess()</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="EMPIRqua.regress2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gridded values of the quantile regression of <code class="reqn">U</code> with respect to <code class="reqn">V</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRgridderinv2">EMPIRgridderinv2</a></code>, <code><a href="#topic+EMPIRqua.regress">EMPIRqua.regress</a></code>, <code><a href="#topic+EMPIRmed.regress">EMPIRmed.regress</a></code>, <code><a href="#topic+EMPIRmed.regress2">EMPIRmed.regress2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples under EMPIRqua.regress
</code></pre>

<hr>
<h2 id='EMPIRsim'>Simulate a Bivariate Empirical Copula</h2><span id='topic+EMPIRsim'></span>

<h3>Description</h3>

<p><em>EXPERIMENTAL</em>&mdash;Perform a simulation on a <em>bivariate empirical copula</em> to produce the random variates <code class="reqn">U</code> and <code class="reqn">V</code> and return an <span class="rlang"><b>R</b></span> <code>data.frame</code> of them.  The method is more broadly known as <em>conditional simulation method</em>. This function is an empirical parallel to <code><a href="#topic+simCOP">simCOP</a></code> that is used for parametric copulas. If circumstances require conditional simulation of <code class="reqn">V{\mid}U</code>, then function <code><a href="#topic+EMPIRsimv">EMPIRsimv</a></code>, which produces a vector of <code class="reqn">V</code> from a fixed <code class="reqn">u</code>, should be used.
</p>
<p>For the usual situation in which an individual <code class="reqn">u</code> during the simulation loops is not a value aligned on the grid, then the bounding conditional quantile functions are solved for each of the <code class="reqn">n</code> simulations and the following interpolation is made by
</p>
<p style="text-align: center;"><code class="reqn">v = \frac{v_1/w_1 + v_2/w_2}{1/w_1 + 1/w_2}\mbox{,}</code>
</p>

<p>which states that that the weighted mean is computed. The values <code class="reqn">v_1</code> and <code class="reqn">v_2</code> are ordinates of the conditional quantile function for the respective grid lines to the left and right of the <code class="reqn">u</code> value. The values <code class="reqn">w_1</code> <code class="reqn">=</code> <code class="reqn">u - u^\mathrm{left}_\mathrm{grid}</code> and <code class="reqn">w_2</code> <code class="reqn">=</code> <code class="reqn">u^\mathrm{right}_\mathrm{grid} - u</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRsim(n=100, empgrid=NULL, kumaraswamy=FALSE, na.rm=TRUE, keept=FALSE,
                graphics=TRUE, ploton=TRUE, points=TRUE, snv=FALSE,
                infsnv.rm=TRUE, trapinfsnv=.Machine$double.eps, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRsim_+3A_n">n</code></td>
<td>
<p>A sample size, default is 100;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_empgrid">empgrid</code></td>
<td>
<p>Gridded empirical copula from <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_kumaraswamy">kumaraswamy</code></td>
<td>
<p>A logical to trigger Kumaraswamy distribution smoothing of the conditional quantile function that is passed to <code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>. The Kumaraswamy distribution is a distribution having support <code class="reqn">[0,1]</code> with an explicit quantile function and takes the place of a Beta distribution (see <span class="pkg">lmomco</span> function <code>quakur()</code> for more details);</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical to toggle the removal of <code>NA</code> entries on the returned <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_keept">keept</code></td>
<td>
<p>Keep the <code class="reqn">t</code> uniform random variable for the simulation as the last column in the returned <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_graphics">graphics</code></td>
<td>
<p>A logical that will disable graphics by setting <code>ploton</code> and <code>points</code> to <code>FALSE</code> and overriding whatever their settings were;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_points">points</code></td>
<td>
<p>A logical to actually draw the simulations by the <code>points()</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_snv">snv</code></td>
<td>
<p>A logical to convert the <code class="reqn">\{u,v\}</code> to standard normal scores (variates) both for the optional graphics and the returned <code>data.frame</code>. Joe (2014) advocates extensively for use of normal scores, which is in  contrast to Nelsen (2006) who does not;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_infsnv.rm">infsnv.rm</code></td>
<td>
<p>A logical that will quietly strip out any occurrences of <code class="reqn">u = \{0,1\}</code> or <code class="reqn">v = \{0,1\}</code> from the simulations because these are infinity in magnitude when converted to standard normal variates is to occur. Thus, this logical only impacts logic flow when <code>snv</code> is <code>TRUE</code>. The <code>infsnv.rm</code> is mutually exclusive from <code>trapinfsnv</code>;</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_trapinfsnv">trapinfsnv</code></td>
<td>
<p>If <code>TRUE</code> and presumably small, the numerical value of this argument (<code class="reqn">\eta</code>) is used to replace <code class="reqn">u = \{0,1\}</code> and <code class="reqn">v = \{0,1\}</code> with <code class="reqn">u(0) =  v(0) = \eta</code> or <code class="reqn">u(1) = v(1) = 1 - \eta</code> as appropriate when conversion to standard normal variates is to occur. The setting of <code>trapinfsnv</code> only is used if <code>snv</code> is <code>TRUE</code> and <code>infsnv.rm</code> is <code>FALSE</code>; and</p>
</td></tr>
<tr><td><code id="EMPIRsim_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>points()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the simulated values is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>, <code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>,  <code><a href="#topic+EMPIRsimv">EMPIRsimv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See other examples under EMPIRsimv

## Not run: 
pdf("EMPIRsim_experiment.pdf")
  nsim &lt;- 5000
  para &lt;- list(alpha=0.15, beta=0.65,
               cop1=PLACKETTcop, cop2=PLACKETTcop, para1=0.005, para2=1000)
  set.seed(1)
  uv &lt;- simCOP(n=nsim, cop=composite2COP, para=para, snv=TRUE,
               pch=16, col=rgb(0,0,0,.2))
  mtext("A highly complex simulated bivariate relation")
  # set.seed(1) # try not resetting the seed
  uv.grid &lt;- EMPIRgrid(para=uv, deluv=0.025)

  uv2 &lt;- EMPIRsim(n=nsim, empgrid=uv.grid, kumaraswamy=FALSE, snv=TRUE,
                  col=rgb(1,0,0,0.1), pch=16)
  mtext("Resimulation without Kumaraswamy smoothing")

  uv3 &lt;- EMPIRsim(n=nsim, empgrid=uv.grid, kumaraswamy=TRUE, snv=TRUE,
                  col=rgb(1,0,0,0.1),pch=16)
  mtext("Resimulation but using the Kumaraswamy Distribution for smoothing")
dev.off()#
## End(Not run)
</code></pre>

<hr>
<h2 id='EMPIRsimv'>Simulate a Bivariate Empirical Copula For a Fixed Value of U</h2><span id='topic+EMPIRsimv'></span>

<h3>Description</h3>

<p><em>EXPERIMENTAL</em>&mdash;Perform a simulation on a <em>bivariate empirical copula</em> to extract the random variates <code class="reqn">V</code> from a given and fixed value for <code class="reqn">u=</code> constant. The purpose of this function is to return a simple vector of the <code class="reqn">V</code> simulations. This behavior is similar to <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> but differs from the general 2-D simulation implemented in the other functions: <code><a href="#topic+EMPIRsim">EMPIRsim</a></code> and <code><a href="#topic+simCOP">simCOP</a></code>&mdash;these two functions generate <span class="rlang"><b>R</b></span> <code>data.frame</code>s of simulated random variates <code class="reqn">U</code> and <code class="reqn">V</code> and optional graphics as well.
</p>
<p>For the usual situation in which <code class="reqn">u</code> is not a value aligned on the grid, then the bounding conditional quantile functions are solved for each of the <code class="reqn">n</code> simulations and the following interpolation is made by
</p>
<p style="text-align: center;"><code class="reqn">v = \frac{v_1/w_1 + v_2/w_2}{1/w_1 + 1/w_2}\mbox{,}</code>
</p>

<p>which states that that the weighted mean is computed. The values <code class="reqn">v_1</code> and <code class="reqn">v_2</code> are ordinates of the conditional quantile function for the respective grid lines to the left and right of the <code class="reqn">u</code> value. The values <code class="reqn">w_1</code> <code class="reqn">=</code> <code class="reqn">u - u^\mathrm{left}_\mathrm{grid}</code> and <code class="reqn">w_2</code> <code class="reqn">=</code> <code class="reqn">u^\mathrm{right}_\mathrm{grid} - u</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMPIRsimv(u, n=1, empgrid=NULL, kumaraswamy=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMPIRsimv_+3A_u">u</code></td>
<td>
<p>The fixed probability <code class="reqn">u</code> on which to perform conditional simulation for a sample of size <code class="reqn">n</code>;</p>
</td></tr>
<tr><td><code id="EMPIRsimv_+3A_n">n</code></td>
<td>
<p>A sample size, default is 1;</p>
</td></tr>
<tr><td><code id="EMPIRsimv_+3A_empgrid">empgrid</code></td>
<td>
<p>Gridded empirical copula from <code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>;</p>
</td></tr>
<tr><td><code id="EMPIRsimv_+3A_kumaraswamy">kumaraswamy</code></td>
<td>
<p>A logical to trigger Kumaraswamy distribution smoothing of the conditional quantile function that is passed to <code><a href="#topic+EMPIRgridderinv">EMPIRgridderinv</a></code>. The Kumaraswamy distribution is a distribution having support <code class="reqn">[0,1]</code> with an explicit quantile function and takes the place of a Beta distribution (see <span class="pkg">lmomco</span> function <code>quakur()</code> for more details); and</p>
</td></tr>
<tr><td><code id="EMPIRsimv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of simulated <code class="reqn">V</code> values is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRgrid">EMPIRgrid</a></code>, <code><a href="#topic+EMPIRsim">EMPIRsim</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
nsim &lt;- 3000
para &lt;- list(alpha=0.15,  beta=0.65,
             cop1=PLACKETTcop, cop2=PLACKETTcop, para1=.005, para2=1000)
set.seed(10)
uv &lt;- simCOP(n=nsim, cop=composite2COP, para=para, pch=16, col=rgb(0,0,0,0.2))
uv.grid &lt;- EMPIRgrid(para=uv, deluv=.1)
set.seed(1)
V1 &lt;- EMPIRsimv(u=0.6, n=nsim, empgrid=uv.grid)
set.seed(1)
V2 &lt;- EMPIRsimv(u=0.6, n=nsim, empgrid=uv.grid, kumaraswamy=TRUE)
plot(V1,V2)
abline(0,1)

invgrid1 &lt;- EMPIRgridderinv(empgrid=uv.grid)
invgrid2 &lt;- EMPIRgridderinv(empgrid=uv.grid, kumaraswamy=TRUE)
att &lt;- attributes(invgrid2); kur &lt;- att$kumaraswamy
# Now draw random variates from the Kumaraswamy distribution using
# rlmomco() and vec2par() provided by the lmomco package.
set.seed(1)
kurpar &lt;- lmomco::vec2par(c(kur$Alpha[7], kur$Beta[7]), type="kur")
Vsim &lt;- lmomco::rlmomco(nsim, kurpar)

print(summary(V1))   # Kumaraswamy not core in QDF reconstruction
print(summary(V2))   # Kumaraswamy core in QDF reconstruction
print(summary(Vsim)) # Kumaraswamy use of the kumaraswamy

# Continuing with a conditional quantile 0.74 that will not land along one of the
# grid lines, a weighted interpolation will be done.
set.seed(1) # try not resetting the seed
nsim &lt;- 5000
V &lt;- EMPIRsimv(u=0.74, n=nsim, empgrid=uv.grid)
# It is important that the uv.grid used to make V is the same grid used in inversion
# with kumaraswamy=TRUE to guarantee that the correct Kumaraswamy parameters are
# available if a user is doing cut and paste and exploring these examples.
set.seed(1)
V1 &lt;- lmomco::rlmomco(nsim, lmomco::vec2par(c(kur$Alpha[8], kur$Beta[8]), type="kur"))
set.seed(1)
V2 &lt;- lmomco::rlmomco(nsim, lmomco::vec2par(c(kur$Alpha[9], kur$Beta[9]), type="kur"))

plot( lmomco::pp(V),  sort(V), type="l", lwd=4, col=8) # GREY is empirical from grid
lines(lmomco::pp(V1), sort(V1), col=2, lwd=2) # Kumaraswamy at u=0.7 # RED
lines(lmomco::pp(V2), sort(V2), col=3, lwd=2) # Kumaraswamy at u=0.8 # GREEN

W1 &lt;- 0.74 - 0.7; W2 &lt;- 0.8 - 0.74
Vblend &lt;- (V1/W1 + V2/W2) / sum(1/W1 + 1/W2)
lines(lmomco::pp(Vblend), sort(Vblend), col=4, lwd=2) # BLUE LINE
# Notice how the grey line and the blue diverge for about F &lt; 0.1 and F &gt; 0.9.
# These are the limits of the grid spacing and linear interpolation within the
# grid intervals is being used and not direct simulation from the Kumaraswamy.
## End(Not run)
</code></pre>

<hr>
<h2 id='EuvCOP'>Expected value of U given V</h2><span id='topic+EuvCOP'></span>

<h3>Description</h3>

<p>Compute the <em>expected value</em> of <code class="reqn">U</code> given a <code class="reqn">V</code> (the <code class="reqn">Y</code> direction) through the <em>conditional distribution function</em> <code class="reqn">G(Y)</code> using the appropriate <em>partial derivative</em> of a copula (<code class="reqn">\mathbf{C}(u,v)</code>) with respect to <code class="reqn">V</code>. The inversion of the partial derivative is the <em>conditional quantile function</em>. Basic principles provide the expectation for a <code class="reqn">y \ge 0</code> is
</p>
<p style="text-align: center;"><code class="reqn">E[Y] = \int_0^\infty yf(y)\mathrm{d}y = \int_0^\infty \bigl(1-G_y(Y)\bigr)\mathrm{d}y\mbox{,}</code>
</p>

<p>which for the setting here becomes
</p>
<p style="text-align: center;"><code class="reqn">E[U \mid V = v] = \int_0^1 \bigl(1 - \frac{\delta}{\delta v} \mathbf{C}(u,v)\bigr)\mathrm{d}u\mbox{.}</code>
</p>

<p>This function solves the integral using the <code><a href="#topic+derCOP2">derCOP2</a></code> function. This avoids a call of the <code><a href="#topic+derCOPinv2">derCOPinv2</a></code> through its <code>uniroot()</code> inversion of the derivative. The example shown for <code>EuvCOP()</code> below does a validation check using conditional simulation, which is dependence (of course) of the design of the <span class="pkg">copBasic</span> package, as part of simple isolation of a horizontal slice of the simulation and computing the mean of the <code class="reqn">V</code> within the slice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EuvCOP(v=seq(0.01, 0.99, by=0.01), cop=NULL, para=NULL, asuv=FALSE, nsim=1E5,
    subdivisions=100L, rel.tol=.Machine$double.eps^0.25, abs.tol=rel.tol, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EuvCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function with vectorization as in <code>asCOP</code>;</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structures, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_asuv">asuv</code></td>
<td>
<p>Return a data frame of the <code class="reqn">U</code> and <code class="reqn">V</code>;</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_nsim">nsim</code></td>
<td>
<p>Number of simulations for Monte Carlo integration when the numerical integration fails (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_subdivisions">subdivisions</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>;</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>;</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_abs.tol">abs.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>; and</p>
</td></tr>
<tr><td><code id="EuvCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+derCOP2">derCOP2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the expectation are returned.
</p>


<h3>Note</h3>

<p>The author is well aware that the name of this function does not contain the number <code>2</code> as the family of functions also sharing this <em>with respect to <code class="reqn">v</code></em> nature. It was a design mistake in 2008 to have used the <code>2</code>. The <code>uv</code> in the function name is the moniker for this <em>with respect to <code class="reqn">v</code></em>.
</p>
<p>There can be the rare examples of the numerical integration failing. In such circumstances, Monte Carlo integration is performed and the returned vector becomes a named vector with the <code>sim</code> identifying values stemming from the simulation.
</p>
<pre>
  para &lt;- list(cop=RFcop, para=0.9)
  para &lt;- list(cop=COP, para=para, reflect=1, alpha=0, beta=0.3)
  EuvCOP(c(0.0001, 0.0002, 0.001, 0.01, 0.1), cop=composite1COP, para=para)
  #            sim
  #[1] 0.001319395 0.002238238 0.006905300 0.034608078 0.173451788
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EvuCOP">EvuCOP</a></code>, <code><a href="#topic+derCOP2">derCOP2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># We can show algorithmic validation using a highly asymmetric case of a
# copula having its parameter also nearly generating a singular component.
v &lt;- c(0.2, 0.8); n &lt;- 5E2; set.seed(1)
para &lt;- list(cop=HRcop, para=120, alpha=0.4, beta=0.05)
UV   &lt;- simCOP(n, cop=composite1COP, para=para, graphics=FALSE) # set TRUE to view

sapply(v, function(vv) EuvCOP(vv, cop=composite1COP, para=para))
# [1] 0.3051985 0.7059999

sapply(v, function(vv) mean( UV$U[UV$V &gt; vv - 50/n &amp; UV$V &lt; vv + 50/n] ) )
# [1] 0.2796518 0.7092755 # general validation is thus shown as n--&gt;large

# If visualized, we see in the lower corner than heuristics suggest a mean further
# to the right of the "singularity" for v=0.2 than v=0.80. For v=0.80, the
# "singularity" appears tighter given the upper tail dependency contrast of the
# coupla in the symmetrical case (alpha=0, beta=0) and changing the parameter to
# a Spearman Rho (say) similar to the para settting in this example. So, 0.70 for
# the mean given v=0.80 makes sense. Further notice that the two estimates of the
# mean are further apparent for v=0.2 relative to v=0.80. Again, this makes sense
# when the copula is visualized even at small n let alone large n.

# See additional Examples under EvuCOP().

## Not run: 
  set.seed(1)
  n &lt;- 5000; Vlo &lt;- rep(0.001, n); Vhi &lt;- rep(0.95, n); Theta &lt;- 3
  Ulo &lt;- simCOPmicro(Vlo, cop=JOcopB5, para=Theta); dlo &lt;- density(Ulo)
  Uhi &lt;- simCOPmicro(Vhi, cop=JOcopB5, para=Theta); dhi &lt;- density(Uhi)
  dlo$x[dlo$x &lt; 0] &lt;- 0; dhi$x[dhi$x &lt; 0] &lt;- 0
  dlo$x[dlo$x &gt; 1] &lt;- 1; dhi$x[dhi$x &gt; 1] &lt;- 1

  summary(Ulo)
  Ulomu &lt;- EuvCOP(Vlo[1], cop=JOcopB5, para=Theta); print(Ulomu)
  #      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
  # 0.0000669 0.0887330 0.2006123 0.2504796 0.3802847 0.9589315
  #                  Ulomu -----&gt; 0.2502145
  summary(Uhi)
  Uhimu &lt;- EuvCOP(Vhi[1], cop=JOcopB5, para=Theta); print(Uhimu)
  #      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
  #   0.01399  0.90603    0.93919 0.9157600   0.95946   0.99411
  #                  Uhimu -----&gt; 0.9154093

  UV &lt;- simCOP(n, cop=JOcopB5, para=Theta,
                  cex=0.6, pch=21, bg="palegreen", col="darkgreen")
  abline(h=Vlo[1], col="salmon", lty=3) # near the bottom to form datum for density
  abline(h=Vhi[1], col="purple", lty=3) # near the   top  to form datum for density
  lines(dlo$x,   dlo$y/max(dlo$y)/2 +    Vlo[1],  col="salmon", lwd=2)
  # re-scaled density along the line already drawn near the bottom (Vlo)
  # think rug plotting to bottom the values plotting very close to the line
  lines(dhi$x, 1-dhi$y/max(dhi$y)/2 - (1-Vhi[1]), col="purple", lwd=2)
  # re-scaled  density along the line already drawn near the  top  (Vhi)
  # think rug plotting to bottom the values plotting very close to the line
  uv &lt;- seq(0.001, 0.999, by=0.001) # for trajectory of E[U | V=v]
  lines(EuvCOP(uv, cop=JOcopB5, para=Theta), uv, col="blue", lwd=3.5, lty=2)
  points(Ulomu, Vlo[1], pch=16, col="salmon", cex=2)
  points(Uhimu, Vhi[1], pch=16, col="purple", cex=2) #
## End(Not run)
</code></pre>

<hr>
<h2 id='EvuCOP'>Expected value of V given U</h2><span id='topic+EvuCOP'></span>

<h3>Description</h3>

<p>Compute the <em>expected value</em> of <code class="reqn">V</code> given a <code class="reqn">U</code> (the <code class="reqn">X</code> direction) through the <em>conditional distribution function</em> <code class="reqn">F(X)</code> using the appropriate <em>partial derivative</em> of a copula (<code class="reqn">\mathbf{C}(u,v)</code>) with respect to <code class="reqn">U</code>. The inversion of the partial derivative is the <em>conditional quantile function</em>. Basic principles provide the expectation for a <code class="reqn">x \ge 0</code> is
</p>
<p style="text-align: center;"><code class="reqn">E[X] = \int_0^\infty xf(x)\mathrm{d}x = \int_0^\infty \bigl(1-F_x(X)\bigr)\mathrm{d}x\mbox{,}</code>
</p>

<p>which for the setting here becomes
</p>
<p style="text-align: center;"><code class="reqn">E[V \mid U = u] = \int_0^1 \bigl(1 - \frac{\delta}{\delta u} \mathbf{C}(u,v)\bigr)\mathrm{d}v\mbox{.}</code>
</p>

<p>This function solves the integral using the <code><a href="#topic+derCOP">derCOP</a></code> function. Verification study is provided in the <b>Note</b> section.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvuCOP(u=seq(0.01, 0.99, by=0.01), cop=NULL, para=NULL, asuv=FALSE, nsim=1E5,
    subdivisions=100L, rel.tol=.Machine$double.eps^0.25, abs.tol=rel.tol, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvuCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function with vectorization as in <code>asCOP</code>;</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structures, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_asuv">asuv</code></td>
<td>
<p>Return a data frame of the <code class="reqn">U</code> and <code class="reqn">V</code>;</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_nsim">nsim</code></td>
<td>
<p>Number of simulations for Monte Carlo integration when the numerical integration fails (see <b>Note</b> in <code><a href="#topic+EvuCOP">EvuCOP</a></code>);</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_subdivisions">subdivisions</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>;</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>;</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_abs.tol">abs.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>; and</p>
</td></tr>
<tr><td><code id="EvuCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+derCOP">derCOP</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the expectation are returned.
</p>


<h3>Note</h3>

<p>For the <code><a href="#topic+PSP">PSP</a></code> copula with no parameters, compute the the median and mean <code class="reqn">V</code> given <code class="reqn">U=0.4</code>, respectively:
</p>
<pre>
  U &lt;- 0.4; n &lt;- 1E4
  med.regressCOP(u=U, cop=PSP)                            # V = 0.4912752
  set.seed(1)
  median(replicate(n, derCOPinv(cop=PSP, U, runif(1)) ) ) # V = 0.4876440
  mean(  replicate(n, derCOPinv(cop=PSP, U, runif(1)) ) ) # V = 0.5049729
</pre>
<p>It is seen in the above that the median <code class="reqn">V</code> given <code class="reqn">U</code> is very close to the mean, but is not equal. Using the derivative inversion within <code><a href="#topic+med.regressCOP">med.regressCOP</a></code> the median is about 0.491 and then using large-sample simulation, about 0.491 too is computed. This confirms the median and long standing proven use of <code><a href="#topic+derCOP">derCOP</a></code> (conditional distribution function) and <code><a href="#topic+derCOPinv">derCOPinv</a></code> (conditional quantile function) within the package. The expectation (mean) by simulation provides the anchor point to check implementation of <code>EuvCOP()</code>. The mean for <code class="reqn">V</code> given <code class="reqn">U</code> is about 0.505. Continuing, the core logic of <code>EvuCOP()</code> is to use numerical integration of the conditional distribution function (the partial derivative) and not bother for speed purposes to use the inversion of the partial derivative:
</p>
<pre>
  integrate(function(v)                      1-derCOP(   cop=PSP, U, v),
            lower=0, upper=1) # 0.5047805 with absolute error &lt; 1.4e-11

  integrate(function(v) sapply(v, function(t)  derCOPinv(cop=PSP, U, t)),
            lower=0, upper=1) # 0.5047862 with absolute error &lt; 7.2e-05
</pre>
<p>The two integrals match, which functions as a confirmation of the <code class="reqn">(1-F)</code> term in the mathematical definition. Finally, the two integrals match the simulation results. The expectation or mean <code class="reqn">V \mid U=0.4</code> for the <code><a href="#topic+PSP">PSP</a></code> copula is about 0.5048.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EuvCOP">EuvCOP</a></code>, <code><a href="#topic+derCOP">derCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Highly asymmetric and reflected Clayton copula for which visualization
para &lt;- list(cop=CLcop, para=30, alpha=0.2, beta=0.6, reflect=3)
# UV &lt;- simCOP(5000, cop=breveCOP, para=para, cex=0.5); abline(v=0.25, col="red")
EvuCOP(0.25, cop=breveCOP, para=para)  # 0.5982261
# confirms that at U=0.25 that an intuitive estimate would be about 0.6.

## Not run: 
  # Secondary validation of the EvuCOP() and EuvCOP() implementation
  UV &lt;- simCOP(200, cop=PSP)
  u &lt;- seq(0.005, 0.995, by=0.005)
  v &lt;- sapply(u, function(t) integrate(function(k)
                         1 - derCOP(cop=PSP, t, k),  lower=0, upper=1)$value)
  lines(u,v, col="red", lwd=7, lty=1)   # red line
  v &lt;- seq(0.005, 0.995, by=0.005)
  u &lt;- sapply(v, function(t) integrate(function(k)
                         1 - derCOP2(cop=PSP, k, t), lower=0, upper=1)$value)
  lines(u,v, col="red", lwd=7, lty=2)   # dashed red line

  uv &lt;- seq(0.005, 0.995, by=0.005)     # solid and dashed white lines
  lines(EvuCOP(uv, cop=PSP, asuv=TRUE), col="white",  lwd=3,   lty=1)
  lines(EuvCOP(uv, cop=PSP, asuv=TRUE), col="white",  lwd=3,   lty=3)

  # median regression lines for comparison, green and green dashed lines
  lines(med.regressCOP( uv, cop=PSP), col="seagreen", lwd=1.5, lty=1)
  lines(med.regressCOP2(uv, cop=PSP), col="seagreen", lwd=1.5, lty=4) #
## End(Not run)

## Not run: 
  uv &lt;- seq(0.005, 0.995, by=0.005) # stress testing eample with singularity
  UV &lt;- simCOP(50, cop=M_N5p12b, para=2)
  lines(EvuCOP(uv, cop=M_N5p12b, para=2, asuv=TRUE), col="red",     lwd=5)
  lines(EuvCOP(uv, cop=M_N5p12b, para=2, asuv=TRUE), col="skyblue", lwd=1) #
## End(Not run)

## Not run: 
  uv &lt;- seq(0.005, 0.995, by=0.005) # more asymmetry ---- mean regression in UV and VU
  para &lt;- list(cop=GHcop, para=23, alpha=0.1, beta=0.6, reflect=3)
  para &lt;- list(cop=breveCOP, para=para)
  UV &lt;- simCOP(200, cop=COP, para=para)
  lines(EuvCOP(uv,  cop=COP, para=para, asuv=TRUE), col="red",  lwd=2)
  lines(EvuCOP(uv,  cop=COP, para=para, asuv=TRUE), col="blue", lwd=2) #
## End(Not run)

## Not run: 
  # Open questions? The derCOP() and derCOPinv() functions of the package have long
  # been known to work "properly." But let us think again on the situation of
  # permutation symmetry about the equal value line. Recalling that this symmetry is
  # orthogonal to the equal value line, it remains open whether there could be
  # asymmetry in the vertical (or horizontal). Let us draw some median regression lines
  # and see that the do not plot perfectly on the equal value line, but coudl this be
  # down to numerical issues and by association the simulation of the copula itself
  # that is also using derCOPinv() (conditional simulation method). Then, we can plot
  # the expections and we see that these are not equal to the medians, but again are
  # close. *** Do results here indicate edges of numerical performance? ***
  t &lt;- seq(0.01, 0.99, by=0.01)
  UV &lt;- simCOP(10000,   cop=N4212cop, para=4, pch=21, lwd=0.8, col=8, bg="white")
  lines(med.regressCOP( cop=N4212cop, para=4, asuv=TRUE), col="red")
  lines(med.regressCOP2(cop=N4212cop, para=4, asuv=TRUE), col="red")
  abline(0, 1, col="deepskyblue", lwd=3); abline(v=0.5, col="deepskyblue", lwd=4)
  lines(EvuCOP(t, cop=N4212cop, para=4, asuv=TRUE), pch=16, col="darkgreen")
  lines(EuvCOP(t, cop=N4212cop, para=4, asuv=TRUE), pch=16, col="darkgreen") #
## End(Not run)
</code></pre>

<hr>
<h2 id='FGMcop'>The Generalized Farlie&ndash;Gumbel&ndash;Morgenstern Copula</h2><span id='topic+FGMcop'></span><span id='topic+FGMicop'></span>

<h3>Description</h3>

<p>The <em>generalized Farlie&ndash;Gumbel&ndash;Morgenstern copula</em> (Bekrizade <em>et al.</em>, 2012) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta, \alpha, n}(u,v) = \mathbf{FGM}(u,v) = uv[1 + \Theta(1-u^\alpha)(1-v^\alpha)]^n\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [-\mathrm{min}\{1, 1/(n\alpha^2)\}, +1/(n\alpha)]</code>, <code class="reqn">\alpha &gt; 0</code>, and <code class="reqn">n \in 0,1,2,\cdots</code>. The copula <code class="reqn">\Theta = 0</code> or <code class="reqn">\alpha = 0</code> or <code class="reqn">n = 0</code> becomes the <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>). When <code class="reqn">\alpha = n = 1</code>, then the well-known, single-parameter Farlie&ndash;Gumbel&ndash;Morgenstern copula results, and <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) is <code class="reqn">\rho_\mathbf{C} = \Theta/3</code> but in general
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = 12\sum_{r=1}^n {n \choose r} \Theta^r \biggl[\frac{\phantom{\alpha}\Gamma(r+1)\Gamma(2/\alpha)}{\alpha\Gamma(r+1+2/\alpha)} \biggr]^2
\mbox{.}</code>
</p>

<p>The support of <code class="reqn">\rho_\mathbf{C}(\cdots;\Theta, 1, 1)</code> is <code class="reqn">[-1/3, +1/3]</code> but extends via <code class="reqn">\alpha</code> and <code class="reqn">n</code> to <code class="reqn">\approx [-0.50, +0.43]</code>, which shows that the generalization of the copula increases the range of dependency. The generalized version is implemented by <code>FGMcop</code>.
</p>
<p>The <em>iterated Farlie&ndash;Gumbel&ndash;Morgenstern copula</em> (Chine and Benatia, 2017) for the <code class="reqn">r</code>th iteration is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\beta}(u,v) = \mathbf{FGMi}(u,v) = uv + \sum_{j=1}^{r} \beta_j\cdot(uv)^{[j/2]}\cdot(u'v')^{[(j+1)/2]}\mbox{,}</code>
</p>

<p>where <code class="reqn">u' = 1-u</code> and <code class="reqn">v' = 1-v</code> for <code class="reqn">|\beta_j| \le 1</code> that has <code class="reqn">r</code> dimensions <code class="reqn">\beta = (\beta_1, \cdots, \beta_j, \cdots, \beta_r)</code> and <code class="reqn">[t]</code> is the integer part of <code class="reqn">t</code>. The copula <code class="reqn">\beta = 0</code> becomes the <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>). The support of <code class="reqn">\rho_\mathbf{C}(\cdots;\beta)</code> is approximately <code class="reqn">[-0.43, +0.43]</code>. The iterated version is implemented by <code>FGMicop</code>. Internally, the <code class="reqn">r</code> is determined from the length of the <code class="reqn">\beta</code> in the <code>para</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FGMcop( u, v, para=c(NA, 1,1), ...)
FGMicop(u, v, para=NULL,       ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FGMcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="FGMcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="FGMcop_+3A_para">para</code></td>
<td>
<p>A vector of parameters. For the generalized version, the <code class="reqn">\Theta</code>, <code class="reqn">\alpha</code>, and <code class="reqn">n</code> of the copula where the default argument shows the need to include the <code class="reqn">\Theta</code>. However, if a fourth parameter is present, it is treated as a logical to reverse the copula (<code class="reqn">u + v - 1 + \mathbf{FGM}(1-u,1-v; \Theta, \alpha, n)</code>). Also if a single parameter is given, then the <code class="reqn">\alpha = n = 1</code> are automatically set to produce the single-parameter Farlie&ndash;Gumbel&ndash;Morgenstern copula. For the iterated version, the <code class="reqn">\beta</code> vector of <code class="reqn">r</code> iterations;</p>
</td></tr>
<tr><td><code id="FGMcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Bekrizade, Hakim, Parham, G.A., Zadkarmi, M.R., 2012, The new generalization of Farlie&ndash;Gumbel&ndash;Morgenstern copulas: Applied Mathematical Sciences, v. 6, no. 71, pp. 3527&ndash;3533.
</p>
<p>Chine, Amel, and Benatia, Fatah, 2017, Bivariate copulas parameters estimation using the trimmed L-moments methods: Afrika Statistika, v. 12, no. 1, pp. 1185&ndash;1197.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+P">P</a></code>, <code><a href="#topic+mleCOP">mleCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Bekrizade et al. (2012, table 1) report for a=2 and n=3 that range in
# theta = [-0.1667, 0.1667] and range in rho = [-0.1806641, 0.4036458]. However,
# we see that they have seemingly made an error in listing the lower bounds of theta:
rhoCOP(FGMcop, para=c(  1/6, 2, 3))  #  0.4036458
rhoCOP(FGMcop, para=c( -1/6, 2, 3))  # Following error results
# In cop(u, v, para = para, ...) : parameter Theta &lt; -0.0833333333333333
rhoCOP(FGMcop, para=c(-1/12, 2, 3))  # -0.1806641 
## End(Not run)

## Not run: 
# Support of FGMrcop(): first for r=1 iterations and then for large r.
sapply(c(-1, 1), function(t) rhoCOP(cop=FGMrcop, para=rep(t, 1)) )
# [1] -0.3333333  0.3333333
sapply(c(-1, 1), function(t) rhoCOP(cop=FGMrcop, para=rep(t,50)) )
# [1] -0.4341385  0.4341385
## End(Not run)

## Not run: 
# Maximum likelihood estimation near theta upper bounds for a=3 and n=2.
set.seed(832)
UV &lt;- simCOP(300, cop=FGMcop, para=c(+0.16, 3, 2))
# Define a transform function for parameter domain, though mleCOP does
# provide some robustness anyway---not forcing n into the positive
# domain via as.integer(exp(p[3])) seems to not always be needed.
FGMpfunc &lt;- function(p) {
  d &lt;- p[1]; a &lt;- exp(p[2]); n &lt;- as.integer(exp(p[3]))
  lwr &lt;- -min(c(1,1/(n*a^2))); upr &lt;- 1/(n*a)
  d &lt;- ifelse(d &lt;= lwr, lwr, ifelse(d &gt;= upr, upr, d))
  return( c(d, a, n) )
}
para &lt;- c(0.16, 3, 2); init &lt;- c(0, 1, 1)
ML &lt;- mleCOP(UV$U, UV$V, cop=FGMcop, init.para=init, parafn=FGMpfunc)
print(ML$para) # [1] 0.1596361 3.1321228 2.0000000
# So, we have recovered reasonable estimates of the three parameters
# given through MLE estimation.
densityCOPplot(cop=FGMcop, para=   para, contour.col=2)
densityCOPplot(cop=FGMcop, para=ML$para, ploton=FALSE) #
## End(Not run)
</code></pre>

<hr>
<h2 id='footCOP'>The Spearman Footrule of a Copula</h2><span id='topic+footCOP'></span>

<h3>Description</h3>

<p>Compute the measure of association known as the <em>Spearman Footrule</em> <code class="reqn">\psi_\mathbf{C}</code> (Nelsen <em>et al.</em>, 2001, p. 281), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\psi_\mathbf{C} = \frac{3}{2}\mathcal{Q}(\mathbf{C},\mathbf{M}) - \frac{1}{2}\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}(u,v)</code> is the copula, <code class="reqn">\mathbf{M}(u,v)</code> is the <em>Fréchet&ndash;Hoeffding upper bound</em> (<code><a href="#topic+M">M</a></code>), and <code class="reqn">\mathcal{Q}(a,b)</code> is a <em>concordance function</em> (<code><a href="#topic+concordCOP">concordCOP</a></code>) (Nelsen, 2006, p. 158). The <code class="reqn">\psi_\mathbf{C}</code> in terms of a single integration pass on the copula is
</p>
<p style="text-align: center;"><code class="reqn">\psi_\mathbf{C} = 1 - \int_{\mathcal{I}^2} |u-v|\,\mathrm{d}\mathbf{C}(u,v) = 6 \int_0^1 \mathbf{C}(u,u)\,\mathrm{d}u - 2\mbox{.}</code>
</p>

<p>Note, Nelsen <em>et al.</em> (2001) use <code class="reqn">\phi_\mathbf{C}</code> but that symbol is taken in <span class="pkg">copBasic</span> for the <em>Hoeffding Phi</em> (<code><a href="#topic+hoefCOP">hoefCOP</a></code>), and Spearman Footrule does not seem to appear in Nelsen (2006). From the definition, Spearman Footrule only depends on the <em>primary diagnonal</em> (alt. <em>main diagonal</em>, Genest <em>et al.</em>, 2010) of the copula, <code class="reqn">\mathbf{C}(t,t)</code> (<code><a href="#topic+diagCOP">diagCOP</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>footCOP(cop=NULL, para=NULL, by.concordance=FALSE, as.sample=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="footCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="footCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="footCOP_+3A_by.concordance">by.concordance</code></td>
<td>
<p>Instead of using the single integral to compute <code class="reqn">\psi_\mathbf{C}</code>, use the concordance function method implemented through <code><a href="#topic+concordCOP">concordCOP</a></code>; and</p>
</td></tr>
<tr><td><code id="footCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat\psi</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="footCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass, which are dispatched to the copula function <code>cop</code> and possibly <code><a href="#topic+concordCOP">concordCOP</a></code>, such as <code>brute</code> or <code>delta</code> used by that function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\psi_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>Conceptually, the sample Spearman Footrule is a standardized sum of the absolute difference in the ranks (Genest <em>et al.</em>, 2010). The sample <code class="reqn">\hat\psi</code> is
</p>
<p style="text-align: center;"><code class="reqn">\hat\psi = 1 - \frac{3}{n^2 - 1}\sum_{i=1}^n |R_i - S_i|\mbox{,}</code>
</p>

<p>where <code class="reqn">R_i</code> and <code class="reqn">S_i</code> are the respective ranks of <code class="reqn">X</code> and <code class="reqn">Y</code> and <code class="reqn">n</code> is sample size. The sampling variance of <code class="reqn">\hat\psi</code> under <em>assumption of independence</em> between <code class="reqn">X</code> and <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{var}(\hat\psi) = \frac{2n^2 + 7}{5(n+1)(n-1)^2}\mbox{.}</code>
</p>

<p>Genest <em>et al.</em> (2010, p. 938) say that prior literature shows that in small samples, Spearman Footrule is less variable than the well-known <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>). For a copula having continuous partial derivatives, then as <code class="reqn">n \rightarrow \infty</code>, the quantity <code class="reqn">(\hat\psi - \psi_\mathbf{C})\sqrt{n} \sim \mathrm{Normal}(0, \mathrm{var}(\gamma_\mathbf{C}))</code>. Genest <em>et al.</em> (2010) show variance of <code class="reqn">\hat\psi</code> for the <em>independence copula</em> (<code class="reqn">\mathbf{C}(u,v) = \mathbf{\Pi}(u,v)</code>) (<code><a href="#topic+P">P</a></code>) as <code class="reqn">\mathrm{var}(\psi_\mathbf{C}) = 2/5</code>. For comparison, the <em>Gini Gamma</em> for independence is larger at <code class="reqn">\mathrm{var}(\gamma_\mathbf{C}) = 2/3</code> (see <code><a href="#topic+giniCOP">giniCOP</a></code> <b>Note</b>). Genest <em>et al.</em> (2010) also present additional material for estimation of the distribution <code class="reqn">\hat\psi</code> variance for conditions of dependence based on copulas. In Genest <em>et al.</em> independence and two examples of dependence (p. 941), <code class="reqn">\mathrm{var}(\hat\gamma) &gt; \mathrm{var}(\hat\psi)</code>, but those authors do not appear to remark on whether this inequality holds for all copula.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Genest, C., Nešlehová, J., and Ghorbal, N.B., 2010, Spearman's footrule and Gini's gamma&mdash;A review with complements: Journal of Nonparametric Statistics, v. 22, no. 8, pp. 937&ndash;954, <a href="https://doi.org/10.1080/10485250903499667">doi:10.1080/10485250903499667</a>.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Nelsen, R.B., Quesada-Molina, J.J., Rodríguez-Lallena, J.A., Úbeda-Flores, M., 2001, Distribution functions of copulas&mdash;A class of bivariate probability integral transforms: Statistics and Probability Letters, v. 54, no. 3, pp. 277&ndash;282, <a href="https://doi.org/10.1016/S0167-7152%2801%2900060-8">doi:10.1016/S0167-7152(01)00060-8</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+hoefCOP">hoefCOP</a></code>,
<code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>,  <code><a href="#topic+wolfCOP">wolfCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  footCOP(cop=PSP)                      # 0.3177662
# footCOP(cop=PSP, by.concordance=TRUE) # 0.3178025

## Not run: 
n &lt;- 2000; UV &lt;- simCOP(n=n, cop=GHcop, para=2.3, graphics=FALSE)
footCOP(para=UV, as.sample=TRUE)                  # 0.5594364 (sample version)
footCOP(cop=GHcop, para=2.3)                      # 0.5513380 (copula integration)
footCOP(cop=GHcop, para=2.3, by.concordance=TRUE) # 0.5513562 (concordance function)
# where the later issued warnings on the integration
## End(Not run)

## Not run: 
set.seed(1); nsim &lt;- 1000
varFTunderIndpendence &lt;- function(n) {
  (2*n^2 + 7) / (5*(n+1)*(n-1)^2) # Genest et al. (2010)
}
ns &lt;- c(10, 15, 20, 25, 50, 75, 100)
plot(min(ns):max(ns), varFTunderIndpendence(10:max(ns)), type="l",
     xlab="Sample size", ylab="Variance of Sample Estimator", col="salmon4")
mtext("Sample Spearman Footrule Under Independence", col="salmon4")
for(n in ns) {
  sFT &lt;- vector(length=nsim)
  for(i in seq_len(nsim)) {
    uv &lt;- simCOP(n=n, cop=P, para=2, graphics=FALSE)
    sFT[i] &lt;- footCOP(para=uv, as.sample=TRUE)
  }
  varFT &lt;- varFTunderIndpendence(n)
  zz &lt;- round(c(n, mean(sFT), var(sFT), varFT), digits=6)
  names(zz) &lt;- c("n", "mean_sim", "var_sim", "var_Genest")
  print(zz)
  points(n, zz[3], cex=2, pch=21, col="salmon4", bg="salmon1")
} # results show proper implementation and Genest et al. (2010, sec. 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='FRcop'>The Frank Copula</h2><span id='topic+FRcop'></span>

<h3>Description</h3>

<p>The <em>Frank copula</em> (Joe, 2014, p. 165) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{FR}(u,v) =
-\frac{1}{\Theta}\mathrm{log}\biggl[\frac{1 - \mathrm{e}^{-\Theta} - \bigl(1 - \mathrm{e}^{-\Theta u}\bigr) \bigl(1 - \mathrm{e}^{-\Theta v}\bigr)}{1 - \mathrm{e}^{-\Theta}}\biggr]\mbox{,}
</code>
</p>

<p>where <code class="reqn">\Theta \in [-\infty, +\infty], \Theta \ne 0</code>. The copula, as <code class="reqn">\Theta \rightarrow -\infty</code> limits, to the <em>countermonotonicity coupla</em> (<code class="reqn">\mathbf{W}(u,v)</code>; <code><a href="#topic+W">W</a></code>), as <code class="reqn">\Theta \rightarrow 0^{\pm}</code> limits to the <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>), and as <code class="reqn">\Theta \rightarrow +\infty</code>, limits to the <em>comonotonicity copula</em> (<code class="reqn">\mathbf{M}(u,v)</code>;  <code><a href="#topic+M">M</a></code>). The parameter <code class="reqn">\Theta</code> is readily computed from a <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by numerical methods as  <code class="reqn">\tau_{\mathbf{C}}(\Theta) = 1 + 4\Theta^{-1}[D_1(\Theta) - 1]</code>
or from a <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) as
<code class="reqn">\rho_{\mathbf{C}}(\Theta) = 1 + 4\Theta^{-1}[D_2(\Theta) - D_1(\Theta)]</code> for <em>Debye function</em> as
</p>
<p style="text-align: center;"><code class="reqn">
  D_k(x, k) = k x^{-k} \int_0^x t^k \bigl(\mathrm{e}^{t} - 1\bigr)^{-1}\, \mathrm{d}t\mbox{.}
</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>FRcop(u, v, para=NULL, rhotau=NULL, userhotau_chk=TRUE,
            cortype=c("kendall", "spearman", "tau", "rho"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FRcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="FRcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="FRcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="FRcop_+3A_rhotau">rhotau</code></td>
<td>
<p>Optional Kendall Tau or Spearman Rho and parameter <code>para</code> is returned depending on the setting of <code>cortype</code>. The <code>u</code> and <code>v</code> can be used for estimation of the parameter as computed through the setting of <code>cortype</code>;</p>
</td></tr>
<tr><td><code id="FRcop_+3A_cortype">cortype</code></td>
<td>
<p>A character string controlling, if the parameter is not given, to use a Kendall Tau or Spearman Rho for estimation of the parameter. The name of this argument is reflective of an internal call to <code>stats::cor()</code> to the correlation (association) setting for Kendall Tau or Spearman Rho;</p>
</td></tr>
<tr><td><code id="FRcop_+3A_userhotau_chk">userhotau_chk</code></td>
<td>
<p>A logical to trigger computation of Kendall Tau for the given parameter and used as a secondary check on numerical limits of the copula implementation for the package; and</p>
</td></tr>
<tr><td><code id="FRcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned. Otherwise if <code>tau</code> is given, then the <code class="reqn">\Theta</code> is computed and a <code>list</code> having
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The parameter <code class="reqn">\Theta</code>, and</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Kendall Tau.</p>
</td></tr>
</table>
<p>and if <code>para=NULL</code> and <code>tau=NULL</code>, then the values within <code>u</code> and <code>v</code> are used to compute Kendall Tau and then compute the parameter, and these are returned in the aforementioned list. Or if <code>rho</code> is given, then the <code class="reqn">\Theta</code> is computed and a similar <code>list</code> is returned having similar structure but with Spearman Rho instead.
</p>


<h3>Note</h3>

<p>Whether because of default directions of derivative in <code><a href="#topic+derCOP">derCOP</a></code> for partial derivative of the copula or other numerical challenges, the implementation uses the negative parameter whether positive or not and rotates the copula as needed for complete operation of <code><a href="#topic+simCOP">simCOP</a></code>. Several default limiting conditions are in the sources before conversion to independence, perfect positive dependence, or perfect negative dependence.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>, <code><a href="#topic+W">W</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>UV  &lt;- simCOP(n=1000, cop=FRcop, para=20, seed=1)
print(FRcop(UV[,1], UV[,2], cortype="kendall" )$tau) # 0.8072993
print(FRcop(UV[,1], UV[,2], cortype="spearman")$rho) # 0.9536648

## Not run: 
  # Joe (2014) example follows by extendinh the functionality of copBasic
  # into a 3-dimensional C-vine copula using Frank and Gumbel copulas and
  # Kendall Taus and Kendall Partial Taus. The example is expanded to show
  # how advanced features of copBasic can be incorporated for asymmetry
  # (if needed) and reflections (rotations) of copula:
  nsim &lt;- 5000 # number of simulations but not too large for long CPU
  d &lt;- 3       # three dimensions in Joe (2014, algorithm 15) implementation
  GHcop_para &lt;- GHcop(tau   =0.5                   )$para # theta = 2
  FRcop_para &lt;- FRcop(rhotau=0.7, cortype="kendall")$para # theta = 11.41155
  # Substantial notation complexity by structuring the C-vine by matrices for
  # copula families and their parameters then dial in asymmetry by "breves"
  # (see copBasic::breveCOP) and then reflection (rotation ability in the
  # copulas themselves). With zero breves, we have no asymmetry (permutation)
  # and we are going with the basic copula formula, so Reflects are all 1.
  Cops     &lt;- matrix(c(NA,    "GHcop",     "FRcop",
                       NA,         NA,         "M",
                       NA,         NA,         NA),  nrow=d, ncol=d, byrow=TRUE)
  Thetas   &lt;- matrix(c(NA, GHcop_para,  FRcop_para,
                       NA,         NA,          NA,
                       NA,         NA,          NA), nrow=d, ncol=d, byrow=TRUE)
  Breves   &lt;- matrix(c(NA,          0,           0,
                       NA,         NA,           0,
                       NA,         NA,          NA), nrow=d, ncol=d, byrow=TRUE)
  Reflects &lt;- matrix(c(NA,          1,           1,
                       NA,         NA,           1,
                       NA,         NA,          NA), nrow=d, ncol=d, byrow=TRUE)
  # see copBasic::breveCOP(), copBasic::GHcop(), copBasic::M()
  # see also copBasic::COP() for how reflection work within the package
  set.seed(1); U &lt;- NULL # seed and vector of the U_{(1,2,3)} probabilities
  for(i in 1:nsim) {
    w &lt;- runif(d); u &lt;- rep(NA, d); u[1] &lt;- w[1]
    # looks messy but just a way dump a host of "parameters" including family
    # itself down into copBasic logic
    para &lt;- list(cop=breveCOP, para=list(cop=eval(parse(text=Cops[1,2])),
            para=Thetas[1,2], breve=Breves[1,2], reflect=Reflects[1,2]))
    u[2] &lt;- derCOPinv(u[1], t=w[2], cop=COP, para=para) # conditional quantiles
    for(j in 3:d) {
      q &lt;- w[j]
      for(l in (j-1):1) { # Joe (2014, algorithm 16)
        para &lt;- list(cop=breveCOP, para=list(cop=eval(parse(text=Cops[l,j])),
                para=Thetas[l,j], breve=Breves[l,j], reflect=Reflects[l,j]))
        q &lt;- derCOPinv(w[l], t=q, cop=COP, para=para)   # conditional quantiles
       }
      u[j] &lt;- q
    }
    U &lt;- rbind(U, matrix(u, ncol=d, byrow=TRUE))
  }
  U &lt;- as.data.frame( U )
  names( U ) &lt;- paste0("U", seq_len(d))

  # Kendall Partial Tau; Joe (2014, p. 8.66, Theorem 8.66)
  "pc3dCOP" &lt;- function(taujk, tauhj, tauhk) { # close attention to h subscript!
    etajk &lt;- sin( pi*taujk / 2) # Expansion to trig by Joe (2014, theorem 8.19),
    etahj &lt;- sin( pi*tauhj / 2) # Joe says this definition "might be"
    etahk &lt;- sin( pi*tauhk / 2) # better than partial tau on scores.
    (2/pi) * asin( (etajk - etahj*etahk) / sqrt( (1-etahj^2) * (1-etahk^2) ) )
  }
  # Joe (2014, pp. 404-405)
  # Kendall partial tau but needs pairwise Kendall taus to compute partial tau.
  "PairwiseTaus" &lt;- function(U) {
    ktau &lt;- matrix(NA, nrow=d, ncol=d)
    for(j in 1:d) { for(l in 1:d) {
        if(j &lt;  l) next
        if(j == l) { ktau[l,j] &lt;- 1; next } # 1s on diagonal as required.
        ktau[l,j] &lt;- ktau[j,l] &lt;- cor(U[,l], U[,j], method="kendall") # symmetrical
    } }
    return(ktau)
  }
  PairwiseTaus  &lt;- PairwiseTaus(U) # [1,2] and [1,3] are 0.5 and 0.7 matching
  # requirement and more importantly for Joe (2014, table 8.3, p. 405). Now, [2,3] is
  # about 0.783 which again matches Joe's results of 0.782.
  Tau23given1pc &lt;- pc3dCOP(PairwiseTaus[2,3], PairwiseTaus[2,1], PairwiseTaus[3,1])
  # Joe (2014, table 8.3, p. 405) reports tau^{pc}_{jk;h} as 0.848 by giant
  # simulation and we get about 0.852199 for some modest nsim and set.seed(1). 
## End(Not run)
</code></pre>

<hr>
<h2 id='FRECHETcop'>The Fréchet Family Copula</h2><span id='topic+FRECHETcop'></span>

<h3>Description</h3>

<p>The <em>Fréchet Family copula</em> (Durante, 2007, pp. 256&ndash;259) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\alpha, \beta}(u,v) = \mathbf{FF}(u,v) = \alpha\mathbf{M}(u,v) + (1-\alpha-\beta)\mathbf{\Pi}(u,v)+\beta\mathbf{W}(u,v)\mbox{,}</code>
</p>

<p>where <code class="reqn">\alpha, \beta \ge 0</code> and <code class="reqn">\alpha + \beta \le 1</code>. The Fréchet Family copulas are <em>convex combinations</em> of the fundamental copulas <code class="reqn">\mathbf{W}</code> (<em>Fréchet&ndash;Hoeffding lower-bound copula</em>; <code><a href="#topic+W">W</a></code>), <code class="reqn">\mathbf{\Pi}</code> (independence; <code><a href="#topic+P">P</a></code>), and <code class="reqn">\mathbf{M}</code> (<em>Fréchet&ndash;Hoeffding upper-bound copula</em>; <code><a href="#topic+M">M</a></code>). The copula is <em>comprehensive</em> because both <code class="reqn">\mathbf{W}</code> and <code class="reqn">\mathbf{M}</code> can be obtained. The parameters are readily estimated using <em>Spearman Rho</em> (<code class="reqn">\rho_\mathbf{C}</code>; <code><a href="#topic+rhoCOP">rhoCOP</a></code>) and <em>Kendall Tau</em> (<code class="reqn">\tau_\mathbf{C}</code>; <code><a href="#topic+tauCOP">tauCOP</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = \frac{(\alpha - \beta)(\alpha + \beta + 2)}{3}\mbox{\ and\ } \rho_\mathbf{C} = \alpha - \beta\mbox{.}</code>
</p>

<p>The Fréchet Family copula virtually always has a visible <em>singular component</em> unless <code class="reqn">\alpha, \beta = 0</code>. The copula has respective <em>lower-</em> and <em>upper-tail dependency parameters</em> of <code class="reqn">\lambda^L = \alpha</code> and <code class="reqn">\lambda^U = \alpha</code> (<code><a href="#topic+taildepCOP">taildepCOP</a></code>). Durante (2007, p. 257) reports that the Fréchet Family copula can approximate any bivariate copula in a &ldquo;unique way&rdquo; and the error bound can be estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FRECHETcop(u,v, para=NULL, rho=NULL, tau=NULL, par2rhotau=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FRECHETcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="FRECHETcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="FRECHETcop_+3A_para">para</code></td>
<td>
<p>A vector (two element) of parameters <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>;</p>
</td></tr>
<tr><td><code id="FRECHETcop_+3A_rho">rho</code></td>
<td>
<p>Spearman Rho from which to estimate the parameters;</p>
</td></tr>
<tr><td><code id="FRECHETcop_+3A_tau">tau</code></td>
<td>
<p>Kendall Tau from which to estimate the parameters;</p>
</td></tr>
<tr><td><code id="FRECHETcop_+3A_par2rhotau">par2rhotau</code></td>
<td>
<p>A logical that if <code>TRUE</code> will return an <span class="rlang"><b>R</b></span> <code>list</code> of the <code class="reqn">\rho_\mathbf{C}</code> and <code class="reqn">\tau_\mathbf{C}</code> for the parameters; and</p>
</td></tr>
<tr><td><code id="FRECHETcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will check the consistency of the parameters whether given by argument or computed from <code class="reqn">\rho_\mathbf{C}</code> and <code class="reqn">\tau_\mathbf{C}</code>. The term &ldquo;Family&rdquo; is used with this particular copula in <span class="pkg">copBasic</span> so as to draw distinction to the Fréchet lower- and upper-bound copulas as the two limiting copulas are called.
</p>
<p>For no other reason than that it can be easily done and makes a nice picture, loop through a nest of <code class="reqn">\rho</code> and <code class="reqn">\tau</code> for the Fréchet Family copula and plot the domain of the resulting parameters:
</p>
<pre>
  ops &lt;- options(warn=-1) # warning supression because "loops" are dumb
  taus &lt;- rhos &lt;- seq(-1,1, by=0.01)
  plot(NA, NA, type="n", xlim=c(0,1), ylim=c(0,1),
       xlab="Frechet Copula Parameter Alpha",
       ylab="Frechet Copula Parameter Beta")
  for(tau in taus) {
    for(rho in rhos) {
      fcop &lt;- FRECHETcop(rho=rho, tau=tau)
      if(! is.na(fcop$para[1])) points(fcop$para[1], fcop$para[2])
    }
  }
  options(ops)
</pre>


<h3>Value</h3>

<p>Value(s) for the copula are returned using the <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> as set by argument <code>para</code>; however, if <code>para=NULL</code> and <code>rho</code> and <code>tau</code> are set and compatible with the copula, then <code class="reqn">\{\rho_\mathbf{C}, \tau_\mathbf{C}\} \rightarrow \{\alpha, \beta\}</code>, parameter estimation made, and an <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>


<h3>Note</h3>

<p>A convex combination (<code><a href="#topic+convex2COP">convex2COP</a></code>) of <code class="reqn">\mathbf{\Pi}</code> and <code class="reqn">\mathbf{M}</code>, which is a modification of the Fréchet Family, is the <em>Linear Spearman</em> copula:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_\alpha(u,v) = (1-\alpha)\mathbf{\Pi}(u,v) + \alpha\mathbf{M}(u,v)\mbox{,}</code>
</p>

<p>for <code class="reqn">0 \le \alpha \le 1</code>, and the parameter is equal to <code class="reqn">\rho_\mathbf{C}</code>. When the convex combination is used for construction, the complement of the parameter is equal to <code class="reqn">\rho_\mathbf{C}</code> (<em>e.g.</em> <code class="reqn">1-\alpha = \rho_\mathbf{C}</code>; <code><a href="#topic+rhoCOP">rhoCOP</a></code>), which can be validated by
</p>
<pre>
  rhoCOP(cop=convex2COP, para=list(alpha=1-0.48, cop1=P, cop2=M)) # 0.4799948
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Durante, F., 2007, Families of copulas, Appendix C, <em>in</em> Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>, <code><a href="#topic+W">W</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ppara &lt;- c(0.25, 0.50)
fcop &lt;- FRECHETcop(para=ppara, par2rhotau=TRUE)
RHO &lt;- fcop$rho; TAU &lt;- fcop$tau

level.curvesCOP(cop=FRECHETcop, para=ppara) # Durante (2007, Fig. C.27(b))
mtext("Frechet Family copula")
 UV &lt;- simCOP(n=50, cop=FRECHETcop, para=ppara, ploton=FALSE, points=FALSE)
tau &lt;- cor(UV$U, UV$V, method="kendall" ) # sample Kendall Tau
rho &lt;- cor(UV$U, UV$V, method="spearman") # sample Spearman Rho
spara &lt;- FRECHETcop(rho=rho, tau=tau) # a fitted Frechet Family copula
spara &lt;- spara$para
if(is.na(spara[1])) { # now a fittable combination is not guaranteed
   warning("sample rho and tau do not provide valid parameters, ",
           "try another simulation")
} else { # now if fit, draw some red-colored level curves for comparison
   level.curvesCOP(cop=FRECHETcop, para=spara, ploton=FALSE, col=2)
} #
## End(Not run)
</code></pre>

<hr>
<h2 id='gEVcop'>The Gaussian-based (Extreme Value) Copula</h2><span id='topic+gEVcop'></span>

<h3>Description</h3>

<p>The <em>g-EV copula</em> (Joe, 2014, p. 105) is a limiting form of the <em>Gaussian copula</em>:
</p>
<p style="text-align: center;"><code class="reqn">
\mathbf{C}_{\rho}(u,v) = \mathbf{gEV}(u,v; \rho) =
\mathrm{exp}\bigl(-A(x,y; \rho)\bigr)\mbox{,}
</code>
</p>

<p>where <code class="reqn">x = -\log(u)</code>, <code class="reqn">y = -\log(v)</code>, and
</p>
<p style="text-align: center;"><code class="reqn">
A(x,y; \rho) = y\mbox{,}
</code>
</p>

<p>for <code class="reqn">0 \le x/(x+y) \le \rho^2/(1+\rho^2)</code>,
</p>
<p style="text-align: center;"><code class="reqn">
A(x,y; \rho) = (x+y - 2\rho\sqrt{xy})/(1-\rho^2)\mbox{,}
</code>
</p>

<p>for <code class="reqn">\rho^2/(1+\rho^2) \le x/(x+y) \le 1/(1+\rho^2)</code>,
</p>
<p style="text-align: center;"><code class="reqn">
A(x,y; \rho) = x\mbox{,}
</code>
</p>

<p>for <code class="reqn">1/(1+\rho^2) \le x/(x+y) \le 1</code> and where <code class="reqn">\rho \in [0,1]</code>. A somewhat curious observation is that this copula has relative hard boundaries into the upper-left and lower-right corners when compared to the other copulas supported by the <span class="pkg">copBasic</span> package. In other words, the hull defined by the copula has a near hard (not fuzzy) curvilinear boundaries that adjust with the parameter <code class="reqn">\rho</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gEVcop(u, v, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gEVcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="gEVcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="gEVcop_+3A_para">para</code></td>
<td>
<p>The parameter <code class="reqn">\rho</code>; and</p>
</td></tr>
<tr><td><code id="gEVcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tEVcop">tEVcop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
UV &lt;- simCOP(200, cop=gEVcop, para=0.8) #
## End(Not run)

## Not run: 
# Joe (2014, p. 105) has brief detail indicating rho = [0,1] and though it seems
# Rho would be a Pearson correlation, this does not seem to be the case. The Rho
# seems to start with that of the Gaussian and then through the extreme-value
# transform, it just assumes the role of a parameter called Rho.
rho &lt;- 0.8
UV &lt;- simCOP(2000, cop=gEVcop, para=rho)
P &lt;- cor(UV[,1], UV[,2], method="pearson")
if(abs(P - rho) &lt; 0.001) {
  print("Yes same")
} else { print("nope not") } # 
## End(Not run)

## Not run: 
gEVparameter &lt;- seq(0.02, 1, by=0.02)
SpearmanRho &lt;- sapply(gEVparameter, function(k) rhoCOP(cop=gEVcop, para=k))
plot(gEVparameter, SpearmanRho)

for(rho in gEVparameter) UV &lt;- simCOP(n=1000, cop=gEVcop, para=rho) #
## End(Not run)
</code></pre>

<hr>
<h2 id='GHcop'>The Gumbel&ndash;Hougaard Extreme Value Copula</h2><span id='topic+GHcop'></span>

<h3>Description</h3>

<p><em>SYMMETRIC GUMBEL-HOUGAARD</em>&mdash;The <em>Gumbel&ndash;Hougaard copula</em> (Nelsen, 2006, pp. 118 and 164) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{GH}(u,v) = \mathrm{exp}\{-[(-\log u)^\Theta+(-\log v)^\Theta]^{1/\Theta}\}\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [1 , \infty)</code>. The copula here is a <em>bivariate extreme value copula</em> (<code class="reqn">BEV</code>). The parameter <code class="reqn">\Theta</code> is readily estimated using a <em>Kendall Tau</em> (say a sample version <code class="reqn">\hat\tau</code>) where the <code class="reqn">\tau</code> of the copula (<code class="reqn">\tau_\mathbf{C}</code>) is defined as
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = \frac{\Theta - 1}{\Theta} \rightarrow \Theta = \frac{1}{1-\tau}\mbox{.}</code>
</p>

<p>The copula is readily extended into <code class="reqn">d</code> dimensions by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathrm{exp}\{-[(-\log u_1)^\Theta+\cdots+(-\log u_d)^\Theta]^{1/\Theta}\}\mbox{.}</code>
</p>

<p>However, such an implementation is not available in the <span class="pkg">copBasic</span> package.
</p>
<p>Every Gumbel&ndash;Hougaard copula is a <em>multivariate extreme value</em> (<code class="reqn">MEV</code>) copula, and hence useful in analysis of extreme value distributions. The Gumbel&ndash;Hougaard copula is the <em>only</em> Archimedean <code class="reqn">MEV</code> (Salvadori <em>et al.</em>, 2007, p. 192). The Gumbel&ndash;Hougaard copula has respective <em>lower-</em> and <em>upper-tail dependency</em> parameters of <code class="reqn">\lambda^L = 0</code> and <code class="reqn">\lambda^U = 2 - 2^{1/\Theta}</code>, respectively. Nelsen (2006, p. 96) shows that <code class="reqn">\mathbf{C}^r_\theta(u^{1/r}, v^{1/r}) = \mathbf{C}_\theta(u,v)</code> so that every Gumbel&ndash;Hougaard copula has a property known as <em>max-stable</em>. A <em>dependence measure</em> uniquely defined for <code class="reqn">BEV</code> copulas is shown under <code><a href="#topic+rhobevCOP">rhobevCOP</a></code>.
</p>
<p>A comparison through simulation between Gumbel&ndash;Hougaard implementations by the <span class="rlang"><b>R</b></span> packages <span class="pkg">acopula</span>, <span class="pkg">copBasic</span>, <span class="pkg">copula</span>, and <span class="pkg">Gumbel</span> is shown in the <b>Examples</b> section. At least three divergent techniques for random variate generation are used amongst those packages. The simulations also use <span class="pkg">copBasic</span>-style random variate generation  (conditional simulation) using an analytical-numerical hybrid solution to conditional inverse described in the <span class="pkg">Note</span> section.
</p>
<p><em>TWO-PARAMETER GUMBEL&ndash;HOUGAARD</em>&mdash;A <em>permutation symmetric</em> (<code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>) but almost certainly <em>radial asymmetric</em> (<code><a href="#topic+isCOP.radsym">isCOP.radsym</a></code>) version of the copula is readily constructed (Brahimi <em>et al.</em>, 2015) into a two-parameter version:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,v; \beta_1, \beta_2) =
\biggl[
\biggl(\bigl(u^{-\beta_2} -1\bigr)^{\beta_1} +
       \bigl(v^{-\beta_2} -1\bigr)^{\beta_1}
\biggr)^{1/\beta_1} + 1
\biggr]^{-1/\beta_2}\mbox{,}</code>
</p>

<p>where <code class="reqn">\beta_1 \ge 1</code> and <code class="reqn">\beta_2 &gt; 0</code>. Both parameters controls the general level of association, whereas parameter <code class="reqn">\beta_2</code> can be thought of as controlling left-tail dependency (<code><a href="#topic+taildepCOP">taildepCOP</a></code>, <code class="reqn">\lambda^{[U\mid L]}_{(\beta_1, \beta_2)}</code>; <em>e.g.</em>
<code class="reqn">\lambda^U_{(1.5; \beta_2)} = 0.413</code> for all <code class="reqn">\beta_2</code> but
<code class="reqn">\lambda^L_{(1.5; 0.2)} = 0.811</code> and
<code class="reqn">\lambda^L_{(1.5; 2.2)} = 0.099</code>. Brahimi <em>et al.</em> (2015) report a <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) for a <code class="reqn">\mathbf{GH}_{(1.5, 0.2)}(u,v)</code> is 0.5, which is readily confirmed in <span class="pkg">copBasic</span> by the function call <code>rhoCOP(cop=GHcop, para=c(1.5,0.2))</code>. The two-parameter <code class="reqn">\mathbf{GH}</code> is triggered if the length of the <code>para</code> argument is exactly 2.
</p>
<p><em>ASYMMETRIC GUMBEL&ndash;HOUGAARD</em>&mdash;An asymmetric version of the copula is readily constructed (Joe, 2014, p. 185&ndash;186) into a three-parameter version with <em>Marshall&ndash;Olkin</em> copulas on the boundaries:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,v; \Theta, \pi_2, \pi_3) = \mathrm{exp}[-\mathcal{A}(-\log u, -\log v; \Theta, \pi_2, \pi_3)]\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \ge 1</code> as before, <code class="reqn">0 \le \pi_2,  \pi_3 \le 1</code>, and
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{A}(x, y; \Theta, \pi_2, \pi_3) = [(\pi_2 x)^\Theta + (\pi_3 y)^\Theta]^{1/\Theta} + (1-\pi_2)x + (1-\pi_3)y\mbox{.}</code>
</p>

<p>The asymmetric <code class="reqn">\mathbf{GH}</code> is triggered if the length of the <code>para</code> argument is exactly 3. The <code>GHcop</code> function provides no mechanism for estimation of the parameters for the asymmetric version. Reviewing simulations, the bounds on the <code class="reqn">\pi</code> parameters in Joe (2014, p. 185) &ldquo;[<code class="reqn">0 \le \pi_2 &lt; \pi_3 \le 1</code>]&rdquo; might be incorrect&mdash;by Joe back referencing to Joe (2014, eq. 4.35, p. 183) the <code class="reqn">\pi</code>-limits as stated for <span class="pkg">copBasic</span> are shown. An algorithm for parameter estimation for the asymmetric <code class="reqn">\mathbf{GH}</code> using two different measures of <em>bivariate skewness</em> as well as an arbitrary <em>measure of association</em> is shown in section <b>Details</b> in <code><a href="#topic+joeskewCOP">joeskewCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GHcop(u, v, para=NULL, tau=NULL, tau.big=0.985, cor=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GHcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="GHcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="GHcop_+3A_para">para</code></td>
<td>
<p>A vector (single element or triplet) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="GHcop_+3A_tau">tau</code></td>
<td>
<p>Kendall Tau <code class="reqn">\tau</code> from which to estimate the parameter <code class="reqn">\Theta</code>;</p>
</td></tr>
<tr><td><code id="GHcop_+3A_tau.big">tau.big</code></td>
<td>
<p>The largest value for <code class="reqn">\tau_\mathbf{C}</code> prior to switching to the <code class="reqn">\mathbf{M}</code> copula applicable to the the symmetric version of this copula;</p>
</td></tr>
<tr><td><code id="GHcop_+3A_cor">cor</code></td>
<td>
<p>A <span class="pkg">copBasic</span> syntax for &ldquo;the correlation coefficient&rdquo; suitable for the copula&mdash;a synonym for <code>tau</code>; and</p>
</td></tr>
<tr><td><code id="GHcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Numerical experiments seem to indicate for <code class="reqn">\tau_\mathbf{C} &gt; 0.985</code> that failures in the numerical partial derivatives in <code><a href="#topic+derCOP">derCOP</a></code> and <code><a href="#topic+derCOP2">derCOP2</a></code> result&mdash;a <code class="reqn">\tau_\mathbf{C}</code> this large is indeed <em>large</em>. As <code class="reqn">\Theta \rightarrow \infty</code> the Gumbel&ndash;Hougaard copula becomes the <em>Fréchet&ndash;Hoeffding upper-bound copula</em> <code class="reqn">\mathbf{M}</code> (see <code><a href="#topic+M">M</a></code>). A <code class="reqn">\tau_\mathbf{C} \approx 0.985</code> yields <code class="reqn">\Theta \approx 66 + 2/3</code>, then for <code class="reqn">\Theta &gt; 1/(1-\tau_\mathbf{C})</code> flips over to the <code class="reqn">\mathbf{M}</code> copula with a warning issued.
</p>


<h3>Value</h3>

<p>Value(s) for the copula are returned using the <code class="reqn">\Theta</code> as set by argument <code>para</code>. Alternative returned values are possible: (1) If <code>para=NULL</code> and <code>tau</code> is set, then <code class="reqn">\tau_\mathbf{C} \rightarrow \Theta</code> and an <span class="rlang"><b>R</b></span> <code>list</code> is returned. (2) If <code>para=NULL</code> and <code>tau=NULL</code>, then an attempt to estimate <code class="reqn">\Theta</code> from the <code>u</code> and <code>v</code> is made by <code class="reqn">\mathrm{cor}(u,v)_\tau \rightarrow \tau_\mathbf{C} \rightarrow \Theta</code> by either trigger using <code>cor(u,v, method="kendall")</code> in <span class="rlang"><b>R</b></span>, and an <span class="rlang"><b>R</b></span> <code>list</code> is returned. The possibly returned <code>list</code> has the following elements:
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The computed <code class="reqn">\Theta</code> from the given bivariate data in <code>para</code>; and</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>The sample estimate of <code class="reqn">\tau</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><em>SYMMETRIC GUMBEL&ndash;HOUGAARD</em>&mdash;A function for the derivative of the copula (Joe, 2014, p. 172) given <code class="reqn">u</code> is
</p>
<pre>
  "GHcop.derCOP" &lt;- function(u, v, para=NULL, ...) {
     x &lt;- -log(u); y &lt;- -log(v)
     A &lt;- exp(-(x^para + y^para)^(1/para)) * (1 + (y/x)^para)^(1/para - 1)
     return(A/u)
  }
</pre>
<p>that can be tested by the following
</p>
<pre>
  Theta &lt;- 1/(1-.15) # a Kendall Tau of 0.15
  GHcop.derCOP(     0.5, 0.75, para=Theta) # 0.7787597
  derCOP(cop=GHcop, 0.5, 0.75, para=Theta) # 0.7787597
  # The next two nearly return same value but conversion to GRVs
  # (Gumbel Reduced Variates) to magnify the numerical differences.
  # The GHcop.derCOP is expected to be the more accurate of the two.
  lmomco::prob2grv(GHcop.derCOP(     0.5, 0.9999999, para=Theta)) # 18.83349
  lmomco::prob2grv(derCOP(cop=GHcop, 0.5, 0.9999999, para=Theta)) # 18.71497
  lmomco::prob2grv(derCOP(cop=GHcop, 0.5, 0.9999999, para=Theta,
                                   delu=.Machine$double.eps^.25)) # 18.83341
</pre>
<p>where the last numerical approximation shows that tighter tolerance is needed. A function for the inverse of the derivative (Joe, 2014, p. 172) given <code class="reqn">u</code> by an analytical-numerical hybrid is
</p>
<pre>
  "GHcop.derCOPinv" &lt;- function(u,t, para=NULL, verbose=FALSE,
                                     tol=.Machine$double.eps, ...) {
    if(length(u) &gt; 1) warning("only the first value of u will be used")
    if(length(t) &gt; 1) warning("only the first value of t will be used")
    if(is.null(para)) { warning("para can not be NULL"); return(NA) }
    u &lt;- u[1]; t &lt;- t[1]; rt &lt;- NULL
    x &lt;- -log(u); A &lt;- (x + (para - 1)*log(x) - log(t))
    hz &lt;- function(z) { z + (para - 1)*log(z) - A }
    zmax &lt;- x; i &lt;- 0; hofz.lo &lt;- hz(zmax)
    if(sign(hofz.lo) != -1) warning("sign for h(z) is not negative!")
    while(1) {
       i &lt;- i + 1
       if(i &gt; 100) {
          warning("maximum iterations looking for zmax reached"); break
       }
       # increment zmax by 1/2 log cycle, sign(hofz.lo) should be negative!
       if(sign(hz(zmax &lt;- zmax + 1/2)) != sign(hofz.lo)) break
    }
    try(rt &lt;- uniroot(hz, c(x, zmax), tol=tol, ...), silent=FALSE)
    if(verbose) print(rt)
    if(is.null(rt)) {
       warning("NULL on the inversion of the GH copula derivative")
       return(NA)
    }
    zo &lt;- rt$root
    y &lt;- (zo^para - x^para)^(1/para)
    names(y) &lt;- NULL
    return(exp(-y))
  }
</pre>
<p>that can be tested by the following, which also shows how to increase the tolerance on the numerical implementation
</p>
<pre>
  u &lt;- 0.999; p &lt;- 0.999
  GHcop.derCOPinv(     u, p, para=1.56) # 0.999977
  derCOPinv(cop=GHcop, u, p, para=1.56) # 1 (unity), needs tighter tolerance
  derCOPinv(cop=GHcop, u, p, para=1.56, tol=.Machine$double.eps/10) # 0.999977
</pre>
<p><em>ASYMMETRIC GUMBEL&ndash;HOUGAARD</em>&mdash;Set <code class="reqn">\tau_\mathbf{C} = 0.35</code> then for a symmetric and then reflection on the 1:1 line of the asymmetric Gumbel&ndash;Hougaard copula and compute the primary parameter <code class="reqn">\Theta</code>, and lastly, compute three bivariate <code class="reqn">\nu_\mathbf{C}</code> skewnesses (<code><a href="#topic+nuskewCOP">nuskewCOP</a></code>):
</p>
<pre>
  Theta1 &lt;- uniroot(function(t) {
                0.35 - tauCOP(cop=GHcop, para=c(t)) },           c(1,10))$root
  Theta2 &lt;- uniroot(function(t) { # asymmetric
                0.35 - tauCOP(cop=GHcop, para=c(t, 0.6, 0.9)) }, c(1,30))$root
  Theta3 &lt;- uniroot(function(t) { # asymmetric reflection on 1:1
                0.35 - tauCOP(cop=GHcop, para=c(t, 0.9, 0.6)) }, c(1,30))$root
  # Theta1 = 1.538462   and   Theta2 = Theta3 = 2.132856
  # Three "skews" based on a combination of U, V, and C(u,v) [nuskew()]
  nuskewCOP(cop=GHcop,   1.538462) # zero bivariate skewness
  nuskewCOP(cop=GHcop, c(2.132856, 0.6, 0.9)) #  0.008245653
  nuskewCOP(cop=GHcop, c(2.132856, 0.9, 0.6)) # -0.008245653
</pre>
<p>So, we see, holding <code class="reqn">\tau_\mathbf{C}</code> constant, that the <code class="reqn">\mathbf{GH}</code> has a <code class="reqn">\nu_{\mathbf{GH}(1.538)} = 0</code> but the asymmetric case <code class="reqn">\nu_{\mathbf{GH}(2.133, 0.6, 0.9)} = 0.0082</code> and <code class="reqn">\nu_{\mathbf{GH}(2.133, 0.9, 0.6)} = -0.0082</code> where the change in sign represents reflection about the 1:1 line. Finally, compute <em>L-coskew</em> by large simulation and the adjective &ldquo;bow&rdquo; representing the direction of bowing or curvature of the principle copula density.
</p>
<pre>
  # Because the Tau's are all similar, there is nothing to learn from the
  # L-correlation, let us inspect the L-coskew instead:
  coT3.1&lt;-lmomco::lcomoms2(simCOP(n=8000, cop=GHcop, para=c(Theta1      )))$T3
  coT3.2&lt;-lmomco::lcomoms2(simCOP(n=8000, cop=GHcop, para=c(Theta2,.6,.9)))$T3
  coT3.3&lt;-lmomco::lcomoms2(simCOP(n=8000, cop=GHcop, para=c(Theta3,.9,.6)))$T3
  # The simulations for Theta1 have no curvature about the diagonal.
  # The simulations for Theta2 have curvature towards the upper left.
  # The simulations for Theta3 have curvature towards the lower right.
  message("# L-coskews: ",round(coT3.1[1,2],digits=4),"(symmetric) ",
                          round(coT3.2[1,2],digits=4),"(asym.--bow UL) ",
                          round(coT3.3[1,2],digits=4),"(asym.--bow UL)")
  message("# L-coskews: ",round(coT3.1[2,1],digits=4),"(symmetric) ",
                          round(coT3.2[2,1],digits=4),"(asym.--bow LR) ",
                          round(coT3.3[2,1],digits=4),"(asym.--bow LR)")
  # L-coskews: 0.0533(symmetric) 0.1055(asym.--bow UL) 0.0021(asym.--bow UL)
  # L-coskews: 0.0679(symmetric) 0.0112(asym.--bow LR) 0.1154(asym.--bow LR)
</pre>
<p>Thus, the <em>L-comoments</em> (Asquith, 2011) using their sample values measure something fundamental about the bivariate association between the three copulas choosen. The L-coskews for the symmetrical case are about equal and are
</p>
<p style="text-align: center;"><code class="reqn">\tau^{\mathbf{GH}(\Theta_1)}_{3[12]} \approx \tau^{\mathbf{GH}(\Theta_1)}_{3[21]} \rightarrow (0.0533 + 0.0679)/2 = 0.0606\mbox{,}</code>
</p>

<p>whereas the L-coskew for the curvature to the upper left are
</p>
<p style="text-align: center;"><code class="reqn">\tau^{\mathbf{GH}(\Theta_2, 0.6, 0.9)}_{3[12]} = 0.1055\mbox{\ and\ } \tau^{\mathbf{GH}(\Theta_2, 0.6, 0.9)}_{3[12]} = 0.0112\mbox{,}</code>
</p>

<p>whereas the L-coskew for the curvature to the lower right are
</p>
<p style="text-align: center;"><code class="reqn">\tau^{\mathbf{GH}(\Theta_3, 0.9, 0.6)}_{3[12]} = 0.0021\mbox{\ and\ } \tau^{\mathbf{GH}(\Theta_3, 0.6, 0.9)}_{3[12]} = 0.1154\mbox{.}</code>
</p>

<p>Thus, the <code class="reqn">\pi_2</code> and <code class="reqn">\pi_3</code> parameters as choosen add about (<code class="reqn">(0.1154+0.1055)/2 - 0.0606 \rightarrow</code> <code class="reqn">0.1105 - 0.0606 = 0.05</code>) L-coskew units to the bivariate distribution.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Brahimi, B., Chebana, F., and Necir, A., 2015, Copula representation of bivariate L-moments&mdash;A new estimation method for multiparameter two-dimensional copula models: Statistics, v. 49, no. 3, pp. 497&ndash;521.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>
<p>Zhang, L., and Singh, V.P., 2007, Gumbel&ndash;Hougaard copula for trivariate rainfall frequency analysis: Journal Hydrologic Engineering, v. 12, Special issue&mdash;Copulas in Hydrology, pp. 409&ndash;419.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+GLcop">GLcop</a></code>, <code><a href="#topic+HRcop">HRcop</a></code>, <code><a href="#topic+tEVcop">tEVcop</a></code>, <code><a href="#topic+rhobevCOP">rhobevCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Theta    &lt;- 2.2 # Let us see if numerical and analytical tail deps are the same.
del.lamU &lt;- abs( taildepCOP(cop=GHcop, para=Theta)$lambdaU - (2-2^(1/Theta)) )
as.logical(del.lamU &lt; 1E-6) # TRUE
## Not run: 
# The simulations match Joe (2014, p. 72) for Gumbel-Hougaard
n &lt;- 600; nsim &lt;- 1000; set.seed(946) # see for reproducibility
SM &lt;- sapply(1:nsim, function(i) { rs &lt;- semicorCOP(cop=GHcop, para=1.35, n=n)
                                 c(rs$botleft.semicor, rs$topright.semicor) })
RhoM     &lt;- round(mean(SM[1,]),          digits=3)
RhoP     &lt;- round(mean(SM[2,]),          digits=3)
SE.RhoM  &lt;- round(  sd(SM[1,]),          digits=3)
SE.RhoP  &lt;- round(  sd(SM[2,]),          digits=3)
SE.RhoMP &lt;- round(  sd(SM[2,] - SM[1,]), digits=3)
# Semi-correlations (sRho) and standard errors (SEs)
message("# sRho[-]=", RhoM, " (SE[-]=", SE.RhoM, ") Joe(p.72)=0.132 (SE[-]=0.08)")
message("# sRho[+]=", RhoP, " (SE[+]=", SE.RhoP, ") Joe(p.72)=0.415 (SE[+]=0.07)")
message("# SE(sRho[-] - sRho[+])=", SE.RhoMP, " Joe(p.72) SE=0.10")
# sRho[-]=0.134 (SE[-]=0.076) Joe(p.72)=0.132 (SE[-]=0.08)
# sRho[+]=0.407 (SE[+]=0.074) Joe(p.72)=0.415 (SE[+]=0.07)
# SE(sRho[-] - sRho[+])=0.107 Joe(p.72) SE=0.10
# Joe (2014, p. 72) reports the values 0.132, 0.415, 0.08, 0.07, 0.10, respectively.
## End(Not run)

## Not run: 
file &lt;- "Lcomom_study_of_GHcopPLACKETTcop.txt"
x &lt;- data.frame(tau=NA, trho=NA, srho=NA, PLtheta=NA, PLT2=NA, PLT3=NA, PLT4=NA,
                                          GHtheta=NA, GHT2=NA, GHT3=NA, GHT4=NA )
write.table(x, file=file, row.names=FALSE, quote=FALSE)
n &lt;- 250 # Make a large number for very long CPU run but seems stable
for(tau in seq(0,0.98, by=0.005)) {
   thetag &lt;- GHcop(u=NULL, v=NULL, tau=tau)$para
   trho   &lt;- rhoCOP(cop=GHcop, para=thetag)
   GH     &lt;- simCOP(n=n, cop=GHcop, para=thetag, points=FALSE, ploton=FALSE)
   srho   &lt;- cor(GH$U, GH$V, method="spearman")
   thetap &lt;- PLACKETTpar(rho=trho)
   PL     &lt;- simCOP(n=n, cop=PLACKETTcop, para=thetap, points=FALSE, ploton=FALSE)
   GHl    &lt;- lmomco::lcomoms2(GH, nmom=4); PLl &lt;- lmomco::lcomoms2(PL, nmom=4)
   x &lt;- data.frame(tau=tau, trho=trho, srho=srho,
                   GHtheta=thetag, PLtheta=thetap,
                   GHT2=mean(c(GHl$T2[1,2], GHl$T2[2,1])),
                   GHT3=mean(c(GHl$T3[1,2], GHl$T3[2,1])),
                   GHT4=mean(c(GHl$T4[1,2], GHl$T4[2,1])),
                   PLT2=mean(c(PLl$T2[1,2], PLl$T2[2,1])),
                   PLT3=mean(c(PLl$T3[1,2], PLl$T3[2,1])),
                   PLT4=mean(c(PLl$T4[1,2], PLl$T4[2,1])) )
   write.table(x, file=file, row.names=FALSE, col.names=FALSE, append=TRUE)
}

# After a processing run with very large "n", then meaningful results exist.
D &lt;- read.table(file, header=TRUE); D &lt;- D[complete.cases(D),]
plot(D$tau, D$GHT3, ylim=c(-0.08,0.08), type="n",
     xlab="KENDALL TAU", ylab="L-COSKEW OR NEGATED L-COKURTOSIS")
points(D$tau,  D$GHT3, col=2);             points(D$tau,  D$PLT3, col=1)
points(D$tau, -D$GHT4, col=4, pch=2);      points(D$tau, -D$PLT4, col=1, pch=2)
LM3 &lt;- lm(D$GHT3~I(D$tau^1)+I(D$tau^2)+I(D$tau^4)-1)
LM4 &lt;- lm(D$GHT4~I(D$tau^1)+I(D$tau^2)+I(D$tau^4)-1)
LM3c &lt;- LM3$coe; LM4c &lt;- LM4$coe
Tau &lt;- seq(0,1, by=.01); abline(0,0, lty=2, col=3)
lines(Tau,   0 + LM3c[1]*Tau^1 + LM3c[2]*Tau^2 + LM3c[3]*Tau^4,  col=4, lwd=3)
lines(Tau, -(0 + LM4c[1]*Tau^1 + LM4c[2]*Tau^2 + LM4c[3]*Tau^4), col=2, lwd=3) #
## End(Not run)

## Not run: 
# Let us compare the conditional simulation method of copBasic by numerics and by the
# above analytical solution for the Gumbel-Hougaard copula to two methods implemented
# by package gumbel, a presumed Archimedean technique by package acopula, and an
# Archimedean technique by package copula. Setting seeds by each "method" below does
# not appear diagnostic because of the differences in which the simulations are made.
nsim &lt;- 10000; kn &lt;- "kendall" #  The theoretical KENDALL TAU is (1.5-1)/1.5 = 1/3
# Simulate by conditional simulation using numerical derivative and then inversion
A &lt;- cor(copBasic::simCOP(nsim, cop=GHcop, para=1.5, graphics=FALSE), method=kn)[1,2]
U &lt;- runif(nsim) # GHcop.derCOPinv() comes from earlier in this documentation.
V &lt;- sapply(1:nsim, function(i) { GHcop.derCOPinv(U[i], runif(1), para=1.5) })
# Simulate by conditional simulation using exact analytical solution
B &lt;- cor(U, y=V, method=kn);  rm(U, V)
# Simulate by the "common frailty" technique
C &lt;- cor(gumbel::rgumbel(nsim, 1.5, dim=2, method=1), method=kn)[1,2]
# Simulate by "K function" (Is the K function method, Archimedean?)
D &lt;- cor(gumbel::rgumbel(nsim, 1.5, dim=2, method=2), method=kn)[1,2]
# Simulate by an Archimedean implementation (presumably)
E &lt;- cor(acopula::rCopula(nsim, pars=1.5), method=kn)[1,2]
# Simulate by an Archimedean implementation
G &lt;- cor(copula::rCopula(nsim, copula::gumbelCopula(1.5)), method=kn)[1,2]
K &lt;- round(c(A, B, C, D, E, G), digits=5); rm(A, B, C, D, E, G, kn); tx &lt;- ", "
message("Kendall Tau: ", K[1], tx, K[2], tx, K[3], tx, K[4], tx, K[5], tx, K[6])
# Kendall Tau: 0.32909, 0.32474, 0.33060, 0.32805, 0.32874, 0.33986 -- run 1
# Kendall Tau: 0.33357, 0.32748, 0.33563, 0.32913, 0.32732, 0.32416 -- run 2
# Kendall Tau: 0.34311, 0.33415, 0.33815, 0.33224, 0.32961, 0.33008 -- run 3
# Kendall Tau: 0.32830, 0.33573, 0.32756, 0.33401, 0.33567, 0.33182 -- nsim=50000!
# All solutions are near 1/3 and it is unknown without further study which of the
# six methods would result in the least bias and (or) sampling variability.
## End(Not run)
</code></pre>

<hr>
<h2 id='giniCOP'>The Gini Gamma of a Copula</h2><span id='topic+giniCOP'></span>

<h3>Description</h3>

<p>Compute the measure of association known as the <em>Gini Gamma</em> <code class="reqn">\gamma_\mathbf{C}</code> (Nelsen, 2006, pp. 180&ndash;182), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\gamma_\mathbf{C} = \mathcal{Q}(\mathbf{C},\mathbf{M}) + \mathcal{Q}(\mathbf{C},\mathbf{W})\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}(u,v)</code> is the copula, <code class="reqn">\mathbf{M}(u,v)</code> is the <code><a href="#topic+M">M</a></code> function, and <code class="reqn">\mathbf{W}(u,v)</code> is the <code><a href="#topic+W">W</a></code> function. The function <code class="reqn">\mathcal{Q}(a,b)</code> (<a href="#topic+concordCOP">concordCOP</a>) is a <em>concordance function</em> (Nelsen, 2006, p. 158). Nelsen also reports that &ldquo;Gini Gamma measures a concordance relation of &ldquo;distance&rdquo; between <code class="reqn">\mathbf{C}(u,v)</code> and monotone dependence, as represented by the <em>Fréchet&ndash;Hoeffding lower bound</em> and <em>Fréchet&ndash;Hoeffding upper bound</em> copulas [<code class="reqn">\mathbf{M}(u,v)</code>, <code><a href="#topic+M">M</a></code> and <code class="reqn">\mathbf{W}(u,v)</code>, <code><a href="#topic+W">W</a></code> respectively]&rdquo;
</p>
<p>A simpler method of computation and the default for <code>giniCOP</code> is to compute <code class="reqn">\gamma_\mathbf{C}</code> by
</p>
<p style="text-align: center;"><code class="reqn">\gamma_\mathbf{C}  = 4\biggl[\int_\mathcal{I} \mathbf{C}(u,u)\,\mathrm{d}u +
                             \int_\mathcal{I} \mathbf{C}(u,1-u)\,\mathrm{d}u\biggr] -
                           2\mbox{,}</code>
</p>

<p>or in terms of the <em>primary diagonal</em> (alt. <em>main diagonal</em>, Genest <em>et al.</em>, 2010) <code class="reqn">\delta(t)</code> and <em>secondary diagonal</em> <code class="reqn">\delta^\star(t)</code> (see <code><a href="#topic+diagCOP">diagCOP</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">\gamma_\mathbf{C}  = 4\biggl[\int_\mathcal{I} \mathbf{\delta}(t)\,\mathrm{d}t +
                             \int_\mathcal{I} \mathbf{\delta^\star
                             }(t)\,\mathrm{d}t\biggr] -
                           2\mbox{.}</code>
</p>

<p>The simpler method is more readily implemented because single integration is fast. Lastly, Nelsen <em>et al.</em> (2001, p. 281) show that <code class="reqn">\gamma_\mathbf{C}</code> also is computable by
</p>
<p style="text-align: center;"><code class="reqn">\gamma_\mathbf{C} = 2\,\mathcal{Q}(\mathbf{C},\mathbf{A})\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{A}</code> is a <em>convex combination</em> (<code><a href="#topic+convex2COP">convex2COP</a></code>, using <code class="reqn">\alpha = 1/2</code>) of the copulas <code class="reqn">\mathbf{M}</code> and <code class="reqn">\mathbf{W}</code> or <code class="reqn">\mathbf{A} = (\mathbf{M}+\mathbf{W})/2</code>. However, integral convergence errors seem to trigger occasionally, and the first definition by summation <code class="reqn">\mathcal{Q}(\mathbf{C},\mathbf{M}) + \mathcal{Q}(\mathbf{C},\mathbf{W})</code> thus is used. The convex combination is demonstrated in the <b>Examples</b> section.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>giniCOP(cop=NULL, para=NULL, by.concordance=FALSE, as.sample=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="giniCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="giniCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="giniCOP_+3A_by.concordance">by.concordance</code></td>
<td>
<p>Instead of using the single integrals (Nelsen, 2006, pp. 181&ndash;182) to compute <code class="reqn">\gamma_\mathbf{C}</code>, use the concordance function method implemented through <code><a href="#topic+concordCOP">concordCOP</a></code>;</p>
</td></tr>
<tr><td><code id="giniCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat\gamma_\mathbf{C}</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="giniCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass, which are dispatched to the copula function <code>cop</code> and possibly <code><a href="#topic+concordCOP">concordCOP</a></code> if <code>by.concordance=TRUE</code>, such as <code>delta</code> used by that function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\gamma_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>Conceptually, the sample Gini Gamma (<code class="reqn">\hat\gamma</code>; Genest <em>et al.</em>, 2010) is
</p>
<p style="text-align: center;"><code class="reqn">\hat\gamma = \frac{1}{\lfloor n^2/2 \rfloor}\sum_{i=1}^n \mid (n+1-R_i) - S_i \mid- \mid R_i - S_i\mid\mbox{,}</code>
</p>

<p>where <code class="reqn">{\lfloor m \rfloor}</code> denotes the integer part of arbitrary <code class="reqn">m &gt; 0</code>, <code class="reqn">R_i</code> and <code class="reqn">S_i</code> are the respective ranks of <code class="reqn">X</code> and <code class="reqn">Y</code> and <code class="reqn">n</code> is sample size. The sampling variance of <code class="reqn">\hat\gamma</code> under <em>assumption of independence</em> between <code class="reqn">X</code> and <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{var}(\hat\gamma)_{n\ \mathrm{even}} = \frac{2}{3}\frac{(n^2 + 2)}{(n-1)n^2}\mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathrm{var}(\hat\gamma)_{n\ \mathrm{odd}} = \frac{2}{3}\frac{(n^2 + 3)}{(n-1)(n^2-1)}\mbox{.}</code>
</p>

<p>Genest <em>et al.</em> (2010) present additional equations for estimation of the distribution <code class="reqn">\hat\gamma</code> variance for conditions of dependence based on copulas. For a copula having continuous partial derivatives, then as <code class="reqn">n \rightarrow \infty</code>, the quantity <code class="reqn">(\hat\gamma - \gamma_\mathbf{C})\sqrt{n} \sim \mathrm{Normal}(0, \mathrm{var}(\gamma_\mathbf{C}))</code>. Genest <em>et al.</em> (2010) show variance of <code class="reqn">\hat\gamma</code> for the <em>independence copula</em> (<code class="reqn">\mathbf{C}(u,v) = \mathbf{\Pi}(u,v)</code>) (<code><a href="#topic+P">P</a></code>) as <code class="reqn">\mathrm{var}(\gamma_\mathbf{C}) = 2/3</code>. For comparison, the <em>Spearman Footrule</em> for independence is smaller at <code class="reqn">\mathrm{var}(\psi_\mathbf{C}) = 2/5</code> (see <code><a href="#topic+footCOP">footCOP</a></code> <b>Note</b>). In Genest <em>et al.</em> independence and two examples of dependence (p. 941), <code class="reqn">\mathrm{var}(\hat\gamma) &gt; \mathrm{var}(\hat\psi)</code>, but those authors do not appear to remark on whether this inequality holds for all copula.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Genest, C., Nešlehová, J., and Ghorbal, N.B., 2010, Spearman's footrule and Gini's gamma&mdash;A review with complements: Journal of Nonparametric Statistics, v. 22, no. 8, pp. 937&ndash;954, <a href="https://doi.org/10.1080/10485250903499667">doi:10.1080/10485250903499667</a>.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Nelsen, R.B., Quesada-Molina, J.J., Rodríguez-Lallena, J.A., Úbeda-Flores, M., 2001, Distribution functions of copulas&mdash;A class of bivariate probability integral transforms: Statistics and Probability Letters, v. 54, no. 3, pp. 277&ndash;282, <a href="https://doi.org/10.1016/S0167-7152%2801%2900060-8">doi:10.1016/S0167-7152(01)00060-8</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+hoefCOP">hoefCOP</a></code>,
<code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>,
<code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>giniCOP(cop=PSP)                                 #                 = 0.3819757
## Not run: 
giniCOP( cop=PSP, by.concordance=TRUE)           # Q(C,M) + Q(C,W) = 0.3820045
# use convex combination ---triggers integration warning but returns anyway
cxpara &lt;- list(alpha=1/2, cop1=M, cop2=W) # parameters for convex2COP()
2*tauCOP(cop=PSP, cop2=convex2COP, para2=cxpara) #    2*Q(C,A)     = 0.3819807
# where the later issued warnings on the integration
## End(Not run)

## Not run: 
n &lt;- 2000; UV &lt;- simCOP(n=n, cop=N4212cop, para=9.3, graphics=FALSE)
giniCOP(para=UV, as.sample=TRUE)                     # 0.9475900 (sample version)
giniCOP(cop=N4212cop, para=9.3)                      # 0.9479528 (copula integration)
giniCOP(cop=N4212cop, para=9.3, by.concordance=TRUE) # 0.9480267 (concordance function)
# where the later issued warnings on the integration
## End(Not run)

## Not run: 
# The canoncial example of theoretical and sample estimators of bivariate
# association for the package: Blomqvist Beta, Spearman Footrule, Gini Gamma,
# Hoeffding Phi, Kendall Tau, Spearman Rho, and Schweizer-Wolff Sigma
# and comparison to L-correlation via lmomco::lcomoms2().
n &lt;- 9000; set.seed(56)
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop, para1=1.45, para2=21.9,
             alpha=0.41, beta=0.08)
D &lt;- simCOP(n=n, cop=composite2COP, para=para, cex=0.5, col=rgb(0,0,0,0.2), pch=16)
blomCOP(cop=composite2COP, para=para)         # 0.4037908 (theoretical)
blomCOP(para=D, as.sample=TRUE)               # 0.4008889 (sample)
footCOP(cop=composite2COP, para=para)         # 0.3721555 (theoretical)
footCOP(para=D, as.sample=TRUE)               # 0.3703623 (sample)
giniCOP(cop=composite2COP, para=para)         # 0.4334687 (theoretical)
giniCOP(para=D, as.sample=TRUE)               # 0.4311698 (sample)
tauCOP(cop=composite2COP,  para=para)         # 0.3806909 (theoretical)
tauCOP(para=D,  as.sample=TRUE)               # 0.3788139 (sample)
rhoCOP(cop=composite2COP,  para=para)         # 0.5257662 (theoretical)
rhoCOP(para=D,  as.sample=TRUE)               # 0.5242380 (sample)
lmomco::lcomoms2(D)$T2      # 1               # 0.5242388 (sample matrix)
                            # 0.5245154 1
hoefCOP(cop=composite2COP, para=para)         # 0.5082776 (theoretical)
subsample &lt;- D[sample(1:n, n/5),] # subsampling for speed
hoefCOP(para=subsample, as.sample=TRUE)       # 0.5033842 (re-sample)
#hoefCOP(para=D, as.sample=TRUE) # major CPU hog, n too big
# because the Ds are already "probabilities" just resample as shown above
wolfCOP(cop=composite2COP, para=para)         # 0.5257662 (theoretical)
#wolfCOP(para=D, as.sample=TRUE) # major CPU hog, n too big
wolfCOP(para=subsample, as.sample=TRUE)       # 0.5338009 (re-sample)
## End(Not run)


## Not run: 
set.seed(1); nsim &lt;- 1000
varGIunderIndpendence &lt;- function(n) {
  if(3 %/% 2 == 3 / 2) { # even
    (2/3)*( (n^2 + 2) ) / ( (n-1)* n^2    ) # Genest et al. (2010)
  } else {
    (2/3)*( (n^2 + 3) ) / ( (n-1)*(n^2-1) ) # Genest et al. (2010)
  }
}
ns &lt;- c(10, 15, 20, 25, 50, 75, 100)
plot(min(ns):max(ns), varGIunderIndpendence(10:max(ns)), type="l",
     xlab="Sample size", ylab="Variance of Sample Estimator", col="darkgreen")
mtext("Sample Gini Gamma Under Independence", col="darkgreen")
for(n in ns) {
  sGI &lt;- vector(length=nsim)
  for(i in seq_len(nsim)) {
    uv &lt;- simCOP(n=n, cop=P, para=2, graphics=FALSE)
    sGI[i] &lt;- giniCOP(para=uv, as.sample=TRUE)
  }
  varGI &lt;- varGIunderIndpendence(n)
  zz &lt;- round(c(n, mean(sGI), var(sGI), varGI), digits=6)
  names(zz) &lt;- c("n", "mean_sim", "var_sim", "var_Genest")
  print(zz)
  points(n, zz[3], cex=2, pch=21, col="darkgreen", bg="lightgreen")
} # results show proper implementation and Genest et al. (2010, sec. 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='GLcop'>The Galambos Extreme Value Copula (with Gamma Power Mixture [Joe/BB4] and Lower Extreme Value Limit)</h2><span id='topic+GLcop'></span><span id='topic+GLEVcop'></span><span id='topic+GLPMcop'></span><span id='topic+JOcopBB4'></span>

<h3>Description</h3>

<p>The <em>Galambos copula</em> (Joe, 2014, p. 174) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{GL}(u,v) = uv\,\mathrm{exp}\bigl[\bigl(x^{-\Theta} + y^{-\Theta}\bigr)^{-1/\Theta}\bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [0, \infty)</code>, <code class="reqn">x = -\log u</code>, and <code class="reqn">y = -\log v</code>. As <code class="reqn">\Theta \rightarrow 0^{+}</code>, the copula limits to <em>independence</em> (<code class="reqn">\mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>) and as  <code class="reqn">\Theta \rightarrow \infty</code>, the copula limits to perfect association (<code class="reqn">\mathbf{M}</code>; <code><a href="#topic+M">M</a></code>). The copula here is a <em>bivariate extreme value copula</em> (<code class="reqn">BEV</code>), and parameter estimation for <code class="reqn">\Theta</code> requires numerical methods.
</p>
<p>There are two other genetically related forms. Joe (2014, p. 197) describes an extension of the Galambos copula as a <em>Galambos gamma power mixture</em> (GLPM), which is Joe's <em>BB4 copula</em>, with the following form
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta,\delta}(u,v) = \mathbf{GLPM}(u,v) =
\biggl(x + y - 1 - \bigl[(x - 1)^{-\delta} + (y - 1)^{-\delta} \bigr]^{-1/\delta} \biggr)^{-1/\Theta}\mbox{,}</code>
</p>

<p>where <code class="reqn">x = u^{-\Theta}</code>, <code class="reqn">y = v^{-\Theta}</code>, and <code class="reqn">\Theta \ge 0, \delta \ge 0</code>. (Joe shows <code class="reqn">\delta &gt; 0</code>, but zero itself seems to work without numerical problems in practical application.) As <code class="reqn">\delta \rightarrow 0^{+}</code>, the &ldquo;MTCJ family&rdquo; (Mardia&ndash;Takahasi&ndash;Cook&ndash;Johnson) results (implemented internally with <code class="reqn">\Theta</code> as the incoming parameter). As <code class="reqn">\Theta \rightarrow 0^{+}</code> the Galambos above results with <code class="reqn">\delta</code> as the incoming parameter.
</p>
<p>This second copula in turn has a <em>lower extreme value limit form</em> that leads to a <em>min-stable bivariate exponential</em> having <em>Pickand dependence function</em> of
</p>
<p style="text-align: center;"><code class="reqn">A(x,y; \Theta, \delta) = x + y - \bigl[x^{-\Theta} + y^{-\Theta} - (x^{\Theta\delta} + y^{\Theta\delta})^{-1/\delta} \bigr]^{-1/\Theta}\mbox{,}</code>
</p>

<p>where this third copula is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}^{LEV}_{\Theta,\delta}(u,v) = \mathbf{GLEV}(u,v) =
\mathrm{exp}[-A(-\log u, -\log v; \Theta, \delta)]\mbox{,}</code>
</p>

<p>for <code class="reqn">\Theta \ge 0, \delta \ge 0</code> and is known as the <em>two-parameter Galambos</em>. (Joe shows <code class="reqn">\delta &gt; 0</code>, but <code class="reqn">\delta = 0</code> itself seems to work without numerical problems in practical application.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLcop(   u, v, para=NULL, ...)
GLEVcop( u, v, para=NULL, ...)
GLPMcop( u, v, para=NULL, ...) # inserts third parameter automatically
JOcopBB4(u, v, para=NULL, ...) # inserts third parameter automatically
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GLcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="GLcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="GLcop_+3A_para">para</code></td>
<td>
<p>To trigger <code class="reqn">\mathbf{GL}(u,v)</code>, a vector (single element) of <code class="reqn">\Theta</code>, to trigger <code class="reqn">\mathbf{GLEV}(u,v)</code>, a two element vector of <code class="reqn">\Theta</code> and <code class="reqn">\delta</code> and alias is <code>GLEVcop</code>, and to trigger <code class="reqn">\mathbf{GLPM}(u,v)</code>, a three element vector of <code class="reqn">\Theta</code>, <code class="reqn">\delta</code>, and any number (the presence of the third entry alone is the triggering mechanism) though aliases <code>GLPM</code> or <code>JOcopBB4</code> will insert the third parameter automatically for convenience; and</p>
</td></tr>
<tr><td><code id="GLcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>Joe (2014, p. 198) shows <code class="reqn">\mathbf{GLEV}(u,v; \Theta, \delta)</code> as a two-parameter Galambos, but its use within the text seemingly is not otherwise obvious. However, testing of the implementation here seems to show that this copula is really not broader in form than <code class="reqn">\mathbf{GL}(u,v; \alpha)</code>. The <code class="reqn">\alpha</code> can always(?) be chosen to mimic the <code class="reqn">\{\Theta, \delta\}</code>. This assertion can be tested from a semi-independent direction. First, define an alternative style of one-parameter Galambos:
</p>
<pre>
  GL1cop &lt;- function(u,v, para=NULL, ...) {
     GL1pA &lt;- function(x,y,t) { # Pickend dependence func form 1p Galambos
        x + y - (x^-t + y^-t)^(-1/t)
     }
     if(length(u) == 1) { u &lt;- rep(u, length(v)) } else
     if(length(v) == 1) { v &lt;- rep(v, length(u)) }
     exp(-GL1pA(-log(u), -log(v), para[1]))
  }
</pre>
<p>Second, redefine the two-parameter Galambos:
</p>
<pre>
  GL2cop &lt;- function(u,v, para=NULL, ...) {
     GL2pA &lt;- function(x,y,t,d) { # Pickend dependence func form 2p Galambos
        x + y - (x^-t + y^-t - (x^(t*d) + y^(t*d))^(-1/d))^(-1/t)
     }
     if(length(u) == 1) { u &lt;- rep(u, length(v)) } else
     if(length(v) == 1) { v &lt;- rep(v, length(u)) }
     exp(-GL2pA(-log(u), -log(v), para[1], para[2]))
  }
</pre>
<p>Next, we can combine the Pickend dependence functions into an objective function. This objective function will permit the computation of the <code class="reqn">\alpha</code> given a pair <code class="reqn">\{\Theta, \delta\}</code>.
</p>
<pre>
  objfunc &lt;- function(a,t=NA,d=NA, x=0.7, y=0.7) {
     lhs &lt;- (x^-t + y^-t - (x^(t*d) + y^(t*d))^(-1/d))^(-1/t)
     rhs &lt;- (x^-a + y^-a)^(-1/a); return(rhs - lhs) # to be uniroot'ed
  }
</pre>
<p>A demonstration can now be made:
</p>
<pre>
  t &lt;- 0.6; d &lt;- 4; lohi &lt;- c(0,100)
  set.seed(3); UV &lt;- simCOP(3000, cop=GL2cop, para=c(t,d), pch=16,col=3,cex=0.5)
  a &lt;- uniroot(objfunc, interval=lohi, t=t, d=d)$root
  set.seed(3); UV &lt;- simCOP(3000, cop=GL1cop, para=a, lwd=0.5, ploton=FALSE)
</pre>
<p>The graphic so produced shows almost perfect overlap in the simulated values. To date, the author has not really found that the two parameters can be chosen such that the one-parameter version can not attain. Extensive numerical experiments using simulated parameter combinations through the use of various copula metrics (tail dependencies, L-comoments, etc) have not found material differences. <b>Has the author of this package missed something?</b>
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>, <code><a href="#topic+GHcop">GHcop</a></code>, <code><a href="#topic+HRcop">HRcop</a></code>, <code><a href="#topic+tEVcop">tEVcop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Theta = pi for GLcop and recovery through Blomqvist Beta     (Joe, 2014, p. 175)
log(2)/(log(log(2)/log(1+blomCOP(cop=GLcop, para=pi))))

# Theta = 2 and delta = 3 for the GLPM form and Blomqvist Beta (Joe, 2014, p. 197)
t &lt;- 2; Btheo &lt;- blomCOP(GLPMcop, para=c(t,3))
Bform &lt;- (2^(t+1) - 1 - taildepCOP(GLPMcop, para=c(t,3))$lambdaU*(2^t -1))^(-1/t)
print(c(Btheo, 4*Bform-1)) # [1] 0.8611903 0.8611900

## Not run: 
  # See the Note section but check Blomqvist Beta here:
  blomCOP(cop=GLcop, para=c(6.043619))  # 0.8552863 (2p version)
  blomCOP(cop=GLcop, para=c(5.6, 0.3))  # 0.8552863 (1p version) 
## End(Not run)
</code></pre>

<hr>
<h2 id='glueCOP'>Gluing Two Copulas</h2><span id='topic+glueCOP'></span>

<h3>Description</h3>

<p>The <em>gluing copula</em> technique (Erdely, 2017, p. 71), given two bivariate copulas <code class="reqn">\mathbf{C}_A</code> and <code class="reqn">\mathbf{C}_B</code> and a fixed value <code class="reqn">0 \le \gamma \le 1</code> is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\gamma}(u,v) = \gamma\cdot\mathbf{C}_A(u/\gamma, v)</code>
</p>

<p>for <code class="reqn">0 \le u \le \gamma</code> and
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\gamma}(u,v) = (1-\gamma)\cdot\mathbf{C}_B((u-\gamma)
\,/\,(1-\gamma), v)</code>
</p>

<p>for <code class="reqn">\gamma \le u \le 1</code> and <code class="reqn">\gamma</code> represents the <em>gluing point</em> in <code class="reqn">u</code> (horizontal axis). The logic is simply the rescaling of <code class="reqn">\mathbf{C}_A</code> to <code class="reqn">[0,\gamma] \times [0,1]</code> and <code class="reqn">\mathbf{C}_B</code> to <code class="reqn">[\gamma,1] \times [0,1]</code>. Copula gluing is potentially useful in circumstances for which regression is non-monotone.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glueCOP(u, v, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glueCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="glueCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="glueCOP_+3A_para">para</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>) with a mandatory element of <code>glue</code>  parameter <code class="reqn">\gamma</code>; and</p>
</td></tr>
<tr><td><code id="glueCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copulas.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>glue</code></dt><dd><p>&mdash; The <code class="reqn">\gamma</code> gluing parameter;</p>
</dd>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the first copula <code class="reqn">\mathbf{A}</code>;</p>
</dd>
<dt><code>cop2</code></dt><dd><p>&mdash; Function of the second copula  <code class="reqn">\mathbf{B}</code>;</p>
</dd>
<dt><code>para1</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{A}</code> for  <code class="reqn">\mathbf{A}</code>; and</p>
</dd>
<dt><code>para2</code></dt><dd><p>&mdash; Vector of parameters <code class="reqn">\Theta_\mathbf{B}</code> for  <code class="reqn">\mathbf{B}</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Erdely, A., 2017, Copula-based piecewise regression (chap. 5)  <em>in</em> Copulas and dependence models with applications&mdash;Contributions in honor of Roger B. Nelsen, <em>eds.</em> Flores, U.M., Amo Artero, E., Durante, F., Sánchez, J.F.: Springer, Cham, Switzerland, ISBN 978&ndash;3&ndash;319&ndash;64220&ndash;9, <a href="https://doi.org/10.1007/978-3-319-64221-5">doi:10.1007/978-3-319-64221-5</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+breveCOP">breveCOP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>, <code><a href="#topic+convexCOP">convexCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- list(cop1=PLACKETTcop, para1=.2, cop2=GLcop, para2=1.2, glue=0.6)
densityCOPplot(cop=glueCOP, para=para) # 
## End(Not run)

## Not run: 
# Concerning Nelsen (2006, exam. 3.3, pp. 59-61)
# Concerning Erdely (2017, exam. 5.1, p. 71)
# Concerning Erdely (2017, exam. 5.2, p. 75)
# Nelsen's example is a triangle with vertex at [G, 1].
# Erdley's example permits the construction using glueCOP from M and W.
"coptri" &lt;- function(u,v, para=NA, ...) {
   p &lt;- para[1]; r &lt;- 1 - (1-p)*v
   if(length(u) &gt; 1 | length(v) &gt; 1) stop("only scalars for this function")
   if(0 &lt;= u &amp; u &lt;= p*v &amp; p*v &lt;= p) {            return(u)
   } else if(  0 &lt;= p*v &amp; p*v &lt;  u &amp; u &lt;  r) {   return(p*v)
   } else if(  p &lt;= r   &amp; r   &lt;= u &amp; u &lt;= 1 ) {  return(u+v-1)
   } else { stop("should not be here in logic") }
}
"UsersCop" &lt;- function(u,v, ...) { asCOP(u,v, f=coptri, ...) }
# Demonstrate Nelsen's triangular copula    (black dots )
UV &lt;- simCOP(cop=UsersCop, para=0.35, cex=0.5, pch=16)
# Add Erdley's gluing of M() and W() copula (red circles)
para &lt;- list(cop1=M, cop2=W, para1=NA, para2=NA, glue=0.35)
UV &lt;- simCOP(cop=glueCOP,  para=para, col=2,   ploton=FALSE)
# We see in the plot that the triangular copulas are the same.

# For G = 0.5, Erdley shows Spearman Rho = 2*G-1 = 0, but
#  Schweizer-Wolff = G^2 + (G-1)^2 = 0.5, let us check these:
para &lt;- list(cop1=M, cop2=W, para1=NA, para2=NA, glue=0.5)
rhoCOP( cop=glueCOP, para=para) # -2.181726e-17
wolfCOP(cop=glueCOP, para=para) #  0.4999953
# So, rhoCOP() indicates independence, but wolfCOP() indicates
# dependence at the minimum value possible for a triangular copula. 
## End(Not run)
</code></pre>

<hr>
<h2 id='gridCOP'>Compute a Copula on a Grid</h2><span id='topic+gridCOP'></span>

<h3>Description</h3>

<p>Compute a grid of copula values. This function has the primary intention of supporting 3D renderings or 2D images of the <em>copulatic surface</em>. Users should be aware of the convention of the placement of the plotting origin and the various plotting mechanisms available to them in <span class="rlang"><b>R</b></span>. By convention copulatic surfaces start in lower left corner for <code class="reqn">u = v = 0</code>, but matrix conventions (or at least how some functions plot matrices) start with the origin in the upper left.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gridCOP(cop=NULL, para=NULL, delta=0.05, transpose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gridCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="gridCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="gridCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\Delta u = \Delta v</code> of the grid edges;</p>
</td></tr>
<tr><td><code id="gridCOP_+3A_transpose">transpose</code></td>
<td>
<p>A logical to transpose the returned grid. This is needed if functions such as <code>image()</code> in <span class="rlang"><b>R</b></span> are to be used for visualization (see last example in <b>Examples</b> with <code><a href="#topic+composite2COP">composite2COP</a></code>); and</p>
</td></tr>
<tr><td><code id="gridCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The values for <code class="reqn">\mathbf{C}(u,v)</code> are returned as a grid as an <span class="rlang"><b>R</b></span> <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcopdf">EMPIRcopdf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
the.grid &lt;- gridCOP(cop=PSP)
the.grid[1,1] &lt;- 0 # replace the NaN
image(the.grid) # ramps to the upper right 
## End(Not run)

## Not run: 
# See this composite copula also used in densityCOPplot() documentation.
para &lt;- list(alpha=0.15, beta=0.90, kappa=0.06, gamma=0.96,
             cop1=GHcop, cop2=PLACKETTcop, para1=5.5, para2=0.07)
GR &lt;- gridCOP(cop=composite2COP, para=para, delta=0.005)
image(GR, col=terrain.colors(20)) # asymmetric, high curvature in top half 
## End(Not run)
</code></pre>

<hr>
<h2 id='hoefCOP'>The Hoeffding Phi of a Copula or Lp Distances (Independence, Radial Asymmetry, or Reflection Symmetry Forms)</h2><span id='topic+hoefCOP'></span><span id='topic+LpCOP'></span><span id='topic+LpCOPradsym'></span><span id='topic+LpCOPpermsym'></span>

<h3>Description</h3>

<p>Compute the measure of association known as the <em>Hoeffding Phi</em> <code class="reqn">\Phi_\mathbf{C}</code> of a copula from <em>independence</em> (<code class="reqn">uv = \mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>) according to Cherunbini <em>et al.</em> (2004, p. 164) by
</p>
<p style="text-align: center;"><code class="reqn">\Phi_\mathbf{C} = 3 \sqrt{10\int\!\!\int_{\mathcal{I}^2} \bigl(\mathbf{C}(u,v) - uv\bigr)^2\,\mathrm{d}u\mathrm{d}v}\mbox{,}</code>
</p>

<p>and Nelsen (2006, p. 210) shows this as (and absolute value notation by Nelsen helps in generalization)
</p>
<p style="text-align: center;"><code class="reqn">\Phi_\mathbf{C} = \biggl(90\int\!\!\int_{\mathcal{I}^2} |\mathbf{C}(u,v) - uv|^2\,\mathrm{d}u\mathrm{d}v\biggr)^{1/2}\mbox{,}</code>
</p>

<p>for which <code class="reqn">\Phi^2_\mathbf{C}</code> (the square of the quantity) is known as the <em>dependence index</em>. Gaißer <em>et al.</em> (2010, eq. 1) have <code class="reqn">\Phi^2_\mathbf{C}</code> as the <em>Hoeffding Phi-Square</em>, and their definition, when square-rooted, matches Nelsen's listing.
</p>
<p>A generalization (Nelsen, 2006) to <code class="reqn">L_p</code> distances from independence (<code class="reqn">uv = \mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>) through the <code>LpCOP</code> function is
</p>
<p style="text-align: center;"><code class="reqn">L_p \equiv \Phi_\mathbf{C}(p) = \biggl(k(p)\int\!\!\int_{\mathcal{I}^2} |\mathbf{C}(u,v) - uv|^p\,\mathrm{d}u\mathrm{d}v\biggr)^{1/p}\mbox{,}</code>
</p>

<p>for a <code class="reqn">p: 1 \le p \le \infty</code> and where <code class="reqn">k(p)</code> is a normalization constant such that <code class="reqn">\Phi_\mathbf{C}(p) = 1</code> when the copula <code class="reqn">\mathbf{C}</code> is <code class="reqn">\mathbf{M}</code> (see <code><a href="#topic+M">M</a></code>) or <code class="reqn">\mathbf{W}</code> (see <code><a href="#topic+W">W</a></code>). The <code class="reqn">k(p)</code> (bivariate definition only) for other powers is given (Nelsen, 2006, exer. 5.44, p. 213) in terms of the <em>complete gamma function</em> <code class="reqn">\Gamma(t)</code> by
</p>
<p style="text-align: center;"><code class="reqn">k(p) = \frac{\Gamma(2p+3)}{2[\Gamma(p + 1)]^2}\mbox{,}</code>
</p>

<p>which is implemented by the <code>hoefCOP</code> function. It is important to realize that the <code class="reqn">L_p</code> distances are all <em>symmetric nonparametric measures of dependence</em> (Nelsen, 2006, p. 210). These are symmetric because distance from independence is used as evident by &ldquo;<code class="reqn">uv</code>&rdquo; in the above definitions.
</p>
<p><em>Reflection/Radial and Permutation Asymmetry</em>&mdash;Asymmetric forms similar to the above distances exist. Joe (2014, p. 65) shows two measures of bivariate <em>reflection asymmetry</em> or <em>radial asymmetry</em> (term favored in <span class="pkg">copBasic</span>) as the distance between <code class="reqn">\mathbf{C}(u,v)</code> and the survival copula <code class="reqn">\hat{\mathbf{C}}(u,v)</code> (<code><a href="#topic+surCOP">surCOP</a></code>) measured by
</p>
<p style="text-align: center;"><code class="reqn">L_\infty^{\mathrm{radsym}} = \mathrm{sup}_{0\le u,v\le1}|\mathbf{C}(u,v) - \hat{\mathbf{C}}(u,v)|\mbox{,}</code>
</p>

<p>or its <code class="reqn">L_p^{\mathrm{radsym}}</code> counterpart
</p>
<p style="text-align: center;"><code class="reqn">L_p^{\mathrm{radsym}} = \biggl[\int\!\!\int_{\mathcal{I}^2} |\mathbf{C}(u,v) - \hat{\mathbf{C}}(u,v)|^p\,\mathrm{d}u\mathrm{d}v\biggr]^{1/p}\,\mathrm{with}\, p \ge 1\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{\mathbf{C}}(u,v) = u + v - 1 + \mathbf{C}(1-u, 1-v)</code> and again <code class="reqn">p: 1 \le p \le \infty</code>. Joe (2014) does not seem to discuss and normalization constants for these two radial asymmetry distances.
</p>
<p>Joe (2014, p. 66) offers analogous measures of bivariate <em>permutation asymmetry</em> (<code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>) (<code class="reqn">\mathbf{C}(u,v) \not= \mathbf{C}(v,u)</code>) defined as
</p>
<p style="text-align: center;"><code class="reqn">L_\infty^{\mathrm{permsym}} = \mathrm{sup}_{0\le u,v\le1}|\mathbf{C}(u,v) - \hat{\mathbf{C}}(v,u)|\mbox{,}</code>
</p>

<p>or its <code class="reqn">L_p^{\mathrm{permsym}}</code> counterpart
</p>
<p style="text-align: center;"><code class="reqn">L_p^{\mathrm{permsym}} = \biggl[\int\!\!\int_{\mathcal{I}^2} |\mathbf{C}(u,v) - \hat{\mathbf{C}}(v,u)|^p\,\mathrm{d}u\mathrm{d}v\biggr]^{1/p}\,\mathrm{with}\, p \ge 1\mbox{,}</code>
</p>

<p>where <code class="reqn">p: 1 \le p \le \infty</code>. Again, Joe (2014) does not seem to discuss and normalization constants for these two permutation symmetry distances. Joe (2014, p. 65) states that the &ldquo;simplest one-parameter bivariate copula families [and] most of the commonly used two-parameter bivariate copula families are permutation symmetric.&rdquo; The <code class="reqn">L_\infty^{\mathrm{permsym}}</code> (or rather a similar form) is implemented by <code><a href="#topic+LzCOPpermsym">LzCOPpermsym</a></code> and demonstration made in that documentation.
</p>
<p>The asymmetrical <code class="reqn">L_\infty</code> and <code class="reqn">L_p</code> measures identified by Joe (2014, p. 66) are nonnegative with an upper bounds that depends on <code class="reqn">p</code>. The bound dependence on <code class="reqn">p</code> is caused by the lack of normalization constant <code class="reqn">k(p)</code>. In an earlier paragraph, Joe (2014) indicates an upper bounds of 1/3 for both (likely?) concerning <code class="reqn">L_\infty^{\mathrm{radsym}}</code> and <code class="reqn">L_\infty^{\mathrm{permsym}}</code>. Discussion of this 1/3 or rather the integer 3 is made within <code><a href="#topic+LzCOPpermsym">LzCOPpermsym</a></code>.
</p>
<p>The numerical integrations for <code class="reqn">L_p^{\mathrm{radsym}}</code> and <code class="reqn">L_p^{\mathrm{permsym}}</code> can readily return zeros. Often inspection of the formula for the <code class="reqn">\mathbf{C}(u,v)</code> itself would be sufficient to judge whether symmetry exists and hence the distances are uniquely zero.
</p>
<p>Joe (2014, p. 66) completes the asymmetry discussion with three definitions of skewness of combinations of random variables <code class="reqn">U</code> and <code class="reqn">V</code>: Two definitions are in <code><a href="#topic+uvlmoms">uvlmoms</a></code> (for <code class="reqn">U + V - 1</code> and <code class="reqn">U - V</code>) and two are for <code class="reqn">V-U</code> (<code><a href="#topic+nuskewCOP">nuskewCOP</a></code>) and <code class="reqn">U+V-1</code> (<code><a href="#topic+nustarCOP">nustarCOP</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hoefCOP(     cop=NULL, para=NULL, p=2, as.sample=FALSE,
                                       sample.as.prob=TRUE,
                                       brute=FALSE, delta=0.002, ...)

LpCOP(       cop=NULL, para=NULL, p=2, brute=FALSE, delta=0.002, ...)
LpCOPradsym( cop=NULL, para=NULL, p=2, brute=FALSE, delta=0.002, ...)
LpCOPpermsym(cop=NULL, para=NULL, p=2, brute=FALSE, delta=0.002, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hoefCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_p">p</code></td>
<td>
<p>The value for <code class="reqn">p</code> as described above with a default to 2 to match the discussion of Nelsen (2006) and the <em>Hoeffding Phi</em> of Cherubini <em>et al.</em> (2004). Do not confuse <code class="reqn">p</code> with <code class="reqn">d</code> described in <b>Note</b>;</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat{\Phi}_\mathbf{C}</code> (see <b>Note</b>). If set to <code>-1</code>, then the message concerning CPU effort will be surpressed;</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_sample.as.prob">sample.as.prob</code></td>
<td>
<p>When <code>as.sample</code> triggered, what are the units incoming in <code>para</code>? If they are probabilities, the default is applicable. If they are not, then the columns are re-ranked and divided simply by <code class="reqn">1/n</code>&mdash;more sophisticated <em>empirical copula</em> probabilities are not used (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>);</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_brute">brute</code></td>
<td>
<p>Should brute force be used instead of two nested <code>integrate()</code> functions in <span class="rlang"><b>R</b></span> to perform the double integration;</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\mathrm{d}u</code> and <code class="reqn">\mathrm{d}v</code> for the brute force (<code>brute=TRUE</code>) integration; and</p>
</td></tr>
<tr><td><code id="hoefCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\Phi_\mathbf{C}(p)</code> is returned.
</p>


<h3>Note</h3>

<p>Concerning the distance from independence, when <code class="reqn">p = 1</code>, then the <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) of a copula is computed where is it seen in that documentation that the <code class="reqn">k_p(1) = 12</code>. The respective values of <code class="reqn">k(p)</code> for select integers <code class="reqn">p</code> are
</p>
<p style="text-align: center;"><code class="reqn">p \mapsto [1, 2, 3, 4, 5] \equiv k(p) \mapsto \{12, 90, 560, 3150, 16600\}\mbox{,}</code>
</p>

<p>and these values are hardwired into <code>hoefCOP</code> and <code>LpCOP</code>. The integers for <code class="reqn">k_p</code> ensures that the equality in the second line of the examples is <code>TRUE</code>, but the <code class="reqn">p</code> can be a noninteger as well. Nelsen (2006, p. 211) reports that when <code class="reqn">p = \infty</code> that <code class="reqn">L_\infty</code> is
</p>
<p style="text-align: center;"><code class="reqn">L_\infty \equiv \Phi_\mathbf{C}(\infty) = \Lambda_\mathbf{C} = 4\;\mathrm{sup}_{u,v \in \mathcal{I}}|\mathbf{C}(u,v) - uv|\mbox{.}</code>
</p>

<p>A sample <code class="reqn">\hat{\Phi}_\mathbf{C}</code> (square root of the <em>Hoeffding Phi-Square</em>) based on nonparametric estimation generalized for <code class="reqn">d</code> dimensions (<code class="reqn">d = 2</code> for bivariate) is presented by Gaißer <em>et al.</em> (2010, eq. 10) for estimated probabilities <code class="reqn">\hat{U}_{ij}</code> for the <code class="reqn">i</code>th dimension and <code class="reqn">j</code>th row (observation) for sample of size <code class="reqn">n</code>. Those authors suggest that the <code class="reqn">\hat{U}_{ij}</code> be estimated from the empirical copula:
</p>
<p style="text-align: center;"><code class="reqn">\hat\Phi_\mathbf{C} = \sqrt{h(d)[A + B]}\mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">A = \biggl(\frac{1}{n}\biggr)^2\sum_{j=1}^n\sum_{k=1}^n\prod_{i=1}^d
                    \bigl[1 - \mathrm{max}\bigl(\hat{U}_{ij}, \hat{U}_{ik}\bigr)\bigr]\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B = \biggl(\frac{1}{3}\biggr)^d - \biggl(\frac{2}{n}\biggr)\biggl(\frac{1}{2}\biggr)^d
               \sum_{j=1}^n\prod_{i=1}^d  [1 - \hat{U}_{ij}^2]\mbox{.}</code>
</p>

<p>The normalization constant is a function of dimension and is
</p>
<p style="text-align: center;"><code class="reqn">h(d)^{-1} = \frac{2}{(d+1)(d+2)} - \biggl(\frac{1}{2}\biggr)^d\frac{d\,!}{\prod_{i=0}^d\bigl(i+(1/2)\bigr)}+\biggl(\frac{1}{3}\biggr)^d\mbox{.}</code>
</p>

<pre>
  set.seed(1); UV &lt;- simCOP(n=1000, cop=PSP)
  hoefCOP(cop=PSP)                                       # 0.4547656 (theo.)
  hoefCOP(para=UV, as.sample=TRUE)                       # 0.4892757
  set.seed(1); UV &lt;- simCOP(n=1000, cop=PSP, snv=TRUE) # std normal variates
  hoefCOP(para=UV, as.sample=TRUE, sample.as.prob=FALSE) # 0.4270324
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Cherubini, U., Luciano, E., and Vecchiato, W., 2004, Copula methods in finance: Hoboken, NJ, Wiley, 293 p.
</p>
<p>Gaißer, S., Ruppert, M., and Schmid, F., 2010, A multivariate version of Hoeffding's Phi-Square: Journal of Multivariate Analysis, v. 101, no. 10, pp. 2571&ndash;2586.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>,
<code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>,
<code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>,
<code><a href="#topic+LzCOPpermsym">LzCOPpermsym</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example (ii) Gaisser et al. (2010, p. 2574)
Theta &lt;- 0.66 # Phi^2 = Theta^2 ---&gt; Phi == Theta as shown
hoefCOP(cop=convex2COP, para=c(alpha=Theta, cop1=M, cop2=P)) # 0.6599886

rhoCOP(cop=PSP) == hoefCOP(cop=PSP, p=1) # TRUE
LpCOP(cop=PLACKETTcop, para=1.6, p=2.6)  # 0.1445137 (Fractional p)
## End(Not run)

## Not run: 
set.seed(938) # Phi(1.6; Plackett) = 0.1184489; L_1 = 0.1168737
UV &lt;- simCOP(cop=PLACKETTcop, para=1.6, n=2000, ploton=FALSE, points=FALSE)
hoefCOP(cop=PLACKETTcop, para=1.6, p=200)  # Large p near internal limits
L_1 &lt;- 4*max(abs(PLACKETTcop(UV$U, UV$V, para=1.6) - UV$U*UV$V)) # p is infty
# and finite n and arguably a sample-like statistic here, now on intuition try
# a more sample-like means
U &lt;- runif(10000); V &lt;- runif(10000)
L_2 &lt;- 4*max(abs(EMPIRcop(U, V, para=UV) - U*V)) # 0.1410254 (not close enough)
## End(Not run)

## Not run: 
para &lt;- list(alpha=0.15, beta=0.90, kappa=0.06, gamma=0.96,
             cop1=GHcop, cop2=PLACKETTcop, para1=5.5, para2=0.07)
LpCOPradsym( cop=composite2COP, para=para) # 0.02071164
LpCOPpermsym(cop=composite2COP, para=para) # 0.01540297
## End(Not run)

## Not run: 
"MOcop.formula" &lt;- function(u,v, para=para, ...) {
   alpha &lt;- para[1]; beta &lt;- para[2]; return(min(v*u^(1-alpha), u*v^(1-beta)))
}
"MOcop" &lt;- function(u,v, ...) { asCOP(u,v, f=MOcop.formula, ...) }
   LpCOPradsym( cop=MOcop, para=c(0.8, 0.5)) # 0.0261843
   LpCOPpermsym(cop=MOcop, para=c(0.8, 0.5)) # 0.0243912 
## End(Not run)
</code></pre>

<hr>
<h2 id='HRcop'>The Hüsler&ndash;Reiss Extreme Value Copula</h2><span id='topic+HRcop'></span>

<h3>Description</h3>

<p>The <em>Hüsler&ndash;Reiss copula</em> (Joe, 2014, p. 176) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{HR}(u,v) = \mathrm{exp}\bigr[-x \Phi(X) - y\Phi(Y)\bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \ge 0</code>, <code class="reqn">x = - \log(u)</code>, <code class="reqn">y = - \log(v)</code>, <code class="reqn">\Phi(.)</code> is the cumulative distribution function of the standard normal distribution, <code class="reqn">X</code> and <code class="reqn">Y</code> are defined as:
</p>
<p style="text-align: center;"><code class="reqn">X = \frac{1}{\Theta} + \frac{\Theta}{2}  \log(x/y)\mbox{\ and\ } Y = \frac{1}{\Theta} + \frac{\Theta}{2} \log(y/x)\mbox{.}</code>
</p>

<p>As <code class="reqn">\Theta \rightarrow 0^{+}</code>, the copula limits to <em>independence</em> (<code class="reqn">\mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>). The copula here is a <em>bivariate extreme value copula</em> (<code class="reqn">BEV</code>), and the parameter <code class="reqn">\Theta</code> requires numerical methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HRcop(u, v, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HRcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="HRcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="HRcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula; and</p>
</td></tr>
<tr><td><code id="HRcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+P">P</a></code>, <code><a href="#topic+GHcop">GHcop</a></code>, <code><a href="#topic+GLcop">GLcop</a></code>, <code><a href="#topic+tEVcop">tEVcop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Parameter Theta = pi recovery through the Blomqvist Beta (Joe, 2014, p. 176)
qnorm(1 - log( 1 + blomCOP(cop=HRcop, para=pi) ) / ( 2 * log(2) ) )^(-1)
</code></pre>

<hr>
<h2 id='isCOP.LTD'>Is a Copula Left-Tail Decreasing</h2><span id='topic+isCOP.LTD'></span>

<h3>Description</h3>

<p>Numerically set a logical whether a copula is <em>left-tail decreasing</em> (LTD) as described by Nelsen (2006, pp. 192&ndash;193) and Salvadori <em>et al.</em> (2007, p. 222).  A copula <code class="reqn">\mathbf{C}(u,v)</code> is left-tail decreasing for <code class="reqn">\mathrm{LTD}(V{\mid}U)</code> if and only if for any <code class="reqn">v \in [0,1]</code> that the following holds
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta \mathbf{C}(u,v)}{\delta u} \le \frac{\mathbf{C}(u,v)}{u}</code>
</p>

<p>for almost all <code class="reqn">u \in [0,1]</code>. Similarly, a copula <code class="reqn">\mathbf{C}(u,v)</code> is left-tail decreasing for <code class="reqn">\mathrm{LTD}(U{\mid}V)</code> if and only if for any <code class="reqn">u \in [0,1]</code> that the following holds
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta \mathbf{C}(u,v)}{\delta v} \le \frac{\mathbf{C}(u,v)}{v}</code>
</p>

<p>for almost all <code class="reqn">v \in [0,1]</code> where the later definition is controlled by the <code>wrtV=TRUE</code> argument.
</p>
<p>The LTD concept is associated with the concept of <em>tail monotonicity</em> (Nelsen, 2006, p. 191). Specifically, but reference to Nelsen (2006) definitions and geometric interpretations is recommended, <code class="reqn">\mathrm{LTD}(V{\mid}U)</code> (or <code class="reqn">\mathrm{LTD}(V{\mid}U)</code>) means that the probability <code class="reqn">P[Y \le y \mid X \le x]</code> (or <code class="reqn">P[X \le x \mid Y \le y]</code>) is a nonincreasing function of <code class="reqn">x</code> (or <code class="reqn">y</code>) for all <code class="reqn">y</code> (or <code class="reqn">x</code>).
</p>
<p>A positive LTD of either <code class="reqn">\mathrm{LTD}(V{\mid}U)</code> or <code class="reqn">\mathrm{LTD}(U{\mid}V)</code> implies positively quadrant dependency (PQD, <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code>) but the condition of PQD does not imply LTD. Finally, the accuracy of the numerical assessment of the returned logical by <code>isCOP.LTD</code> is dependent on the the &ldquo;smallness&rdquo; of the <code>delta</code> argument passed into the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isCOP.LTD(cop=NULL, para=NULL, wrtV=FALSE, delta=0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isCOP.LTD_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="isCOP.LTD_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="isCOP.LTD_+3A_wrtv">wrtV</code></td>
<td>
<p>A logical to toggle between with respect to <code class="reqn">v</code> or <code class="reqn">u</code> (default);</p>
</td></tr>
<tr><td><code id="isCOP.LTD_+3A_delta">delta</code></td>
<td>
<p>The increment of <code class="reqn">\{u,v\} \mapsto [0+\Delta\delta, 1-\Delta\delta, \Delta\delta]</code> set by <code>wrtV</code>; and</p>
</td></tr>
<tr><td><code id="isCOP.LTD_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula or derivative of a copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical <code>TRUE</code> or <code>FALSE</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in nature&mdash;An approach using copulas: Dordrecht, Netherlands, Springer, Water Science and Technology Library 56, 292 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+isCOP.RTI">isCOP.RTI</a></code>, <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
isCOP.LTD(cop=P, delta=0.01) # independence should be FALSE
# Positive association
isCOP.LTD(cop=PSP)                               # TRUE
# Negative association Plackett
isCOP.LTD(cop=PLACKETTcop, para=0.15)            # FALSE
# Positive association Plackett
isCOP.LTD(cop=PLACKETTcop, para=15)              # TRUE
# Negative association Plackett
isCOP.LTD(cop=PLACKETTcop, wrtv=TRUE, para=0.15) # FALSE
# Positive association Plackett
isCOP.LTD(cop=PLACKETTcop, wrtV=TRUE, para=15)   # TRUE
## End(Not run)
</code></pre>

<hr>
<h2 id='isCOP.permsym'>Is a Copula Permutation Symmetric</h2><span id='topic+isCOP.permsym'></span>

<h3>Description</h3>

<p>Numerically set a logical whether a copula is <em>symmetric</em> (Nelsen, 2006, p. 38), or has <em>exchangable</em> variables, or is <em>permutation symmetric</em> (Joe, 2014, p. 66). A copula <code class="reqn">\mathbf{C}(u,v)</code> is permutation symmetric if and only if for any <code class="reqn">\{u,v\} \in [0,1]</code> the following holds
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,v) = \mathbf{C}(v, u)\mbox{.}</code>
</p>

<p>The computation is (can be) CPU intensive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isCOP.permsym(cop=NULL, para=NULL, delta=0.005, tol=1e-4, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isCOP.permsym_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="isCOP.permsym_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="isCOP.permsym_+3A_delta">delta</code></td>
<td>
<p>The increment of  <code class="reqn">\{u,v\} \mapsto [0+\Delta\delta, 1-\Delta\delta, \Delta\delta]</code>;</p>
</td></tr>
<tr><td><code id="isCOP.permsym_+3A_tol">tol</code></td>
<td>
<p>A tolerance on the check for symmetry, default 1 part in 10,000, which is the test for the <code class="reqn">\equiv 0</code> (zero equivalence, see source code); and</p>
</td></tr>
<tr><td><code id="isCOP.permsym_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical <code>TRUE</code> or <code>FALSE</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LzCOPpermsym">LzCOPpermsym</a></code>, <code><a href="#topic+isCOP.radsym">isCOP.radsym</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
isCOP.permsym(cop=GHcop, para=1.3) # TRUE
## End(Not run)
</code></pre>

<hr>
<h2 id='isCOP.PQD'>The Positively Quadrant Dependency State of a Copula</h2><span id='topic+isCOP.PQD'></span>

<h3>Description</h3>

<p>Numerically determine the global property of the <em>positively quadrant dependency</em> (PQD) characteristic of a copula as described by Nelsen (2006, p. 188). The random variables <code class="reqn">X</code> and <code class="reqn">Y</code> are PQD if for all <code class="reqn">(x,y)</code> in <code class="reqn">\mathcal{R}^2</code> when
<code class="reqn">H(x,y) \ge F(x)G(x)</code> for all <code class="reqn">(x,y)</code> in <code class="reqn">\mathcal{R}^2</code>
and thus by the copula <code class="reqn">\mathbf{C}(u,v) \ge uv</code> for all <code class="reqn">(u,v)</code> in <code class="reqn">\mathcal{I}^2</code>. Alternatively, this means that <code class="reqn">\mathbf{C}(u,v) \ge \mathbf{\Pi}</code>, and thus it can be said that it is globally &ldquo;greater&rdquo; than independence (<code class="reqn">uv = \Pi</code>; <code><a href="#topic+P">P</a></code>).
</p>
<p>Nelsen (2006) shows that a copula is PQD when
</p>
<p style="text-align: center;"><code class="reqn">0 \le \beta_\mathbf{C} \mbox{,\ } 0 \le \gamma_\mathbf{C}\mbox{,\ and\ } 0 \le \rho_\mathbf{C} \le 3\tau_\mathbf{C}\mbox{,}</code>
</p>

<p>where <code class="reqn">\beta_\mathbf{C}</code>, <code class="reqn">\gamma_\mathbf{C}</code>, <code class="reqn">\rho_\mathbf{C}</code>, and <code class="reqn">\tau_\mathbf{C}</code> are various copula measures of association or concordance that are respectively described in <code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, and <code><a href="#topic+tauCOP">tauCOP</a></code>.
The concept of negatively quadrant dependency (NQD) is the reverse: <code class="reqn">\mathbf{C}(u,v) \le \mathbf{\Pi}</code> for all <code class="reqn">(u,v)</code> in <code class="reqn">\mathcal{I}^2</code>; so NQD is globally &ldquo;smaller&rdquo; than independence.
</p>
<p>Conceptually, PQD is related to the probability that two random variables are simultaneously small (or simultaneously large) is at least as great as it would be if they were <em>independent</em>. The graph of a PQD copula lies on or above the copulatic surface of the <em>independence copula</em> <code class="reqn">\mathbf{\Pi}</code>, and conversely a NQD copula lies on or below <code class="reqn">\mathbf{\Pi}</code>.
</p>
<p>Albeit a &ldquo;global&rdquo; property of a copula, there can be &ldquo;local&rdquo; variations in the PQD/NQD state. Points in <code class="reqn">\mathcal{I}^2</code> where <code class="reqn">\mathbf{C}(u,v) - \mathbf{\Pi} \ge 0</code> are locally PQD, whereas points in <code class="reqn">\mathcal{I}^2</code> where <code class="reqn">\mathbf{C}(u,v) - \mathbf{\Pi} \le 0</code> and locally NQD. Lastly, readers are directed to the last examples in <code><a href="#topic+wolfCOP">wolfCOP</a></code> because as those examples involve the copulatic difference from independence <code class="reqn">\mathbf{C}(u,v) - \mathbf{\Pi} = \mathbf{C}(u,v) - \mathbf{\Pi}</code> with 3-D renderings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isCOP.PQD(cop=NULL, para=NULL, uv=NULL, empirical=FALSE, verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isCOP.PQD_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="isCOP.PQD_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="isCOP.PQD_+3A_uv">uv</code></td>
<td>
<p>An optional <span class="rlang"><b>R</b></span> <code>data.frame</code> of <code class="reqn">U</code> and <code class="reqn">V</code> nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code> for the random variables <code class="reqn">X</code> and <code class="reqn">Y</code>. This argument triggers different value return behavior (see <b>Value</b>);</p>
</td></tr>
<tr><td><code id="isCOP.PQD_+3A_empirical">empirical</code></td>
<td>
<p>A logical that will use sample versions for <em>Gini Gamma</em>, <em>Spearman Rho</em>, and <em>Kendall Tau</em>. This feature is <em>only</em> applicable if the copula is empirical and therefore the <code>para</code> argument is the <code>data.frame</code> of <code class="reqn">u</code> and <code class="reqn">v</code>, which will be passed along to sample version functions instead of copula (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="isCOP.PQD_+3A_verbose">verbose</code></td>
<td>
<p>A logical that will report the four concordance measures; and</p>
</td></tr>
<tr><td><code id="isCOP.PQD_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass, which are then passed to subordinate functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>uv=NULL</code> then a logical for the global property of PQD is returned but if argument <code>uv</code> is a <code>data.frame</code>, then an <span class="rlang"><b>R</b></span> <code>list</code> is returned, and that list holds the global condition in <code>global.PQD</code> and  local condition assessments in <code>local.PQD</code> and <code>local.NQD</code>.
</p>


<h3>Note</h3>

<p>The function <code>isCOP.PQD</code> will try <code>brute</code> force computations if subordinate calls to one or more functions fails. The user can use <code>...</code> to set the <code>delta</code> argument for <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, and (or) <code><a href="#topic+tauCOP">tauCOP</a></code>.
</p>
<p>This function is not guaranteed to work using a <em>bivariate empirical copula</em> such as the following operation: <code>copPQD(cop=EMPIRcop, para=the.data)</code>. An evidently open problem for <span class="pkg">copBasic</span> is how to support PQD assessment (either globally or locally) for empirical copulas. The <code class="reqn">\tau_\mathbf{C}</code> for the bivariate empirical copula example <code>brute=TRUE|FALSE</code> to unity and <code class="reqn">\gamma_\mathbf{C}</code> and <code class="reqn">\rho_\mathbf{C}</code> reach maximum number of subdivisions on the numerical integration and thus fail. If an empirical bivariate copula is &ldquo;Tau'd&rdquo; to itself, is <code class="reqn">\tau_\mathbf{C} \equiv 1</code> guaranteed? The <code class="reqn">\tau_\mathbf{C}</code> computation relies on numerical partial derivatives of the copula, whereas the <code class="reqn">\gamma_\mathbf{C}</code> and <code class="reqn">\rho_\mathbf{C}</code> use the copula itself. It seems in the end that use of sample versions of <code class="reqn">\gamma_\mathbf{C}</code>, <code class="reqn">\rho_\mathbf{C}</code>, and <code class="reqn">\tau_\mathbf{C}</code> would be appropriate and leave the <code class="reqn">\beta_\mathbf{C}</code> as either copula or direct sample computation (see <b>Examples</b>).
</p>
<p><em>SPECIAL DEMONSTRATION 1</em>&mdash;Given the following,
</p>
<pre>
  para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop, para1=c(14.5),para2=c(1.45),
               alpha=0.51, beta=0.15, kappa=0.45, gamma=0.78)
  D &lt;- simCOP(n=500, cop=composite3COP, para=para, cex=0.5, col=1, pch=16)
</pre>
<p>the two different call types to <code>isCOP.PQD</code> for an empirical copula are illustrative:
</p>
<pre>
  global.only &lt;- isCOP.PQD(cop=EMPIRcop, para=D, empirical=TRUE)
</pre>
<p>and
</p>
<pre>
  PQD.list &lt;- isCOP.PQD(cop=EMPIRcop, para=D, empirical=TRUE, uv=D)
  points(D, col=PQD.list$local.PQD+2, lwd=2) # red (if present) is local NQD
</pre>
<p>which in the former only returns the global PQD and the later returns an <span class="rlang"><b>R</b></span> <code>list</code> with global (<code>global.PQD</code>), local (<code>local.PQD</code> as well as <code>local.NQD</code>), and the four statistics (<code>beta</code> <code class="reqn">\beta_\mathbf{C}</code>, <code>gamma</code> <code class="reqn">\gamma_\mathbf{C}</code>, <code>rho</code> <code class="reqn">\rho_\mathbf{C}</code>, <code>tau</code> <code class="reqn">\tau_\mathbf{C}</code>) used to determine global PQD.
</p>
<p><em>SPECIAL DEMONSTRATION 1</em>&mdash;Lastly, the <code>ctype=</code><code>"bernstein"</code> argument to the empirical copula can be used. Repeated iterations of the following will show that local quadrant dependency can appear slightly different when the <code>bernstein</code> argument is present. The simulation sample size is reduced considerably for this second example because of the CPU effort triggered by the <em>Bernstein extension</em> (see <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>) having been turned on.
</p>
<pre>
  para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop, para1=14.5, para2=1.45,
               alpha=0.51, beta=0.15, kappa=0.45, gamma=0.78)
  D &lt;- simCOP(n=50, cop=composite3COP, para=para, cex=0.5, col=1, pch=16)
  PQD.A&lt;- isCOP.PQD(cop=EMPIRcop, para=D, empirical=TRUE, uv=D)
  points(D, col=PQD.A$local.PQD+2, lwd=2) # red (if present) is local NQD
  PQD.B&lt;- isCOP.PQD(cop=EMPIRcop,para=D,empirical=TRUE,uv=D,ctype="bernstein")
  points(D, col=PQD.B$local.PQD+2, lwd=1, pch=3, cex=1.5)
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+isCOP.LTD">isCOP.LTD</a></code>, <code><a href="#topic+isCOP.RTI">isCOP.RTI</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
isCOP.PQD(cop=PSP) # TRUE
## End(Not run)

## Not run: 
# Example concerning Empirical Bivariate Copula and sample versions for comparison.
set.seed(10); n &lt;- 1000
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop, para1=0.145,  para2=1.45,
             alpha=0.81, beta=0.8)
D &lt;- simCOP(n=n, cop=composite2COP, para=para, cex=0.5, col=rgb(0,0,0,0.2), pch=16)
#tauCOP(cop=EMPIRcop, para=D)   # ??? but == 1
cor(D$U, D$V, method="kendall") # -0.3224705
blomCOP(cop=EMPIRcop, para=D)   # -0.332
giniCOP(cop=EMPIRcop, para=D)   # -0.3692037
GINI &lt;- sum(abs(rank(D$U)+rank(D$V)-n-1)) - sum(abs(rank(D$U)-rank(D$V)))
print(GINI/as.integer(n^2/2))   # -0.369996
rhoCOP(cop=EMPIRcop, para=D)    # ??? but fails
cor(D$U, D$V, method="spearman")      # -0.456694
lmomco::lcomoms2(D)$T2     #  1.0000000 -0.4568357
                           # -0.4567859  1.0000000
## End(Not run)
</code></pre>

<hr>
<h2 id='isCOP.radsym'>Is a Copula Radially Symmetric</h2><span id='topic+isCOP.radsym'></span>

<h3>Description</h3>

<p>Numerically set a logical whether a copula is <em>radially symmetric</em> (Nelsen, 2006, p. 37) [<em>reflection symmetric</em>, Joe (2014, p. 64)]. A copula <code class="reqn">\mathbf{C}(u,v)</code> is radially symmetric if and only if for any <code class="reqn">\{u,v\} \in [0,1]</code> either of the following hold
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,v) = u + v - 1 + \mathbf{C}(1-u, 1-v)</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">u + v - 1 + \mathbf{C}(1-u, 1-v) - \mathbf{C}(u,v) \equiv 0\mbox{.}</code>
</p>

<p>Thus, if the equality of the copula <code class="reqn">\mathbf{C}(u,v) = \hat{\mathbf{C}}(u,v)</code> (the <em>survival copula</em>), then radial symmetry exists: <code><a href="#topic+COP">COP</a></code> <code class="reqn">=</code> <code><a href="#topic+surCOP">surCOP</a></code> or <code class="reqn">\mathbf{C}(u,v) = \hat{\mathbf{C}}(1-u,1-v)</code>. The computation is (can be) CPU intensive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isCOP.radsym(cop=NULL, para=NULL, delta=0.005, tol=1e-4, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isCOP.radsym_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="isCOP.radsym_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="isCOP.radsym_+3A_delta">delta</code></td>
<td>
<p>The increments of  <code class="reqn">\{u,v\} \mapsto [0+\Delta\delta, 1-\Delta\delta, \Delta\delta]</code>;</p>
</td></tr>
<tr><td><code id="isCOP.radsym_+3A_tol">tol</code></td>
<td>
<p>A tolerance on the check for symmetry, default 1 part in 10,000, which is the test for the <code class="reqn">\equiv 0</code> (zero equivalence, see source code); and</p>
</td></tr>
<tr><td><code id="isCOP.radsym_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula or derivative of a copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical <code>TRUE</code> or <code>FALSE</code> is returned.
</p>


<h3>Note</h3>

<p>An open research question possibly exists: <em>Is a radially symmetric copula characterized by the L-comoments for orders</em> <code class="reqn">r{\ge}3</code> <em>as having values of zero</em>? The author asks this question partly out of intuition stemming from numerical experiments (some not show here) suggesting this condition, and review of copula literature does not seem to directly address this question. Let us consider the two symmetrical copulas: the parameterless <code class="reqn">\mathbf{PSP}(u,v)</code> (see <code><a href="#topic+PSP">PSP</a></code>) and the single parameter <code class="reqn">\mathbf{PL}(u,v; \Theta)</code> (see <code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>) with the <code class="reqn">\Theta_\mathbf{PL} = 4.708664</code> (see <code><a href="#topic+rhoCOP">rhoCOP</a></code>). The two copulas have different radial symmetries as shown below.
</p>
<pre>
  plackpar &lt;- PLACKETTpar(rho=rhoCOP(cop=PSP)) # Spearman Rho = 0.4784176
  isCOP.radsym(cop=PSP)                        # FALSE
  isCOP.radsym(cop=PLACKETTcop, para=plackpar) # TRUE
</pre>
<p>Now, let us compute the L-comoments from the <span class="pkg">lmomco</span> <span class="rlang"><b>R</b></span> package for <code class="reqn">n=10{,}000</code> simulations from each copula. The L-correlations are each about 0.48, which agree with the given <code class="reqn">\rho_\mathbf{C}</code>.
</p>
<pre>
  set.seed(639)
  UVa &lt;- simCOP(n=10000, cop=PSP,         para=NA,       graphics=FALSE)
  set.seed(639)
  UVb &lt;- simCOP(n=10000, cop=PLACKETTcop, para=plackpar, graphics=FALSE)
  lmomco::lcomoms2(UVa, nmom=4)$T3[2,1] # Only show L-coskew of V wrt U.
  lmomco::lcomoms2(UVb, nmom=4)$T3[2,1] # Only show L-coskew of V wrt U.
</pre>
<p>The L-coskew for the <code class="reqn">\mathbf{PSP}</code> is about <code class="reqn">-0.129</code> and that for the <code class="reqn">\mathbf{PL}</code> copula is about zero (<code class="reqn">&lt;0.0029</code>). L-cokurtosis provides a similar result if <code>T3</code> is changed to <code>T4</code>. The <code class="reqn">\mathbf{PSP}</code> L-cokurtosis is about <code class="reqn">0.041</code>, whereas the <code class="reqn">\mathbf{PL}</code> L-cokurtosis is about <code class="reqn">&lt;0.0037</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Radially symmetry is computationally intensive and relies on a gridded [0,1]x[0,1]
# space and laborious check on equality. Thus these examples are commented out for
# R --timings check. Note, the proof of radial symmetry absent of algebraic
# manipulation or verification is difficult and subject to the fineness of the grid
# to find a nonequality from which to immediately conclude FALSE.
## Not run: 
isCOP.radsym(cop=P) # TRUE

para &lt;- list(cop1=PLACKETTcop, cop2=M, para1=c(.3), para2=NA, alpha=0.8, beta=0.5)
isCOP.radsym(composite2COP, para=para) # FALSE

## End(Not run)
## Not run: 
gh &lt;- simCOP(n=34, cop=GHcop, para=theta, ploton=FALSE, points=FALSE) * 150
# Pretend gh is real data, the * 150 is to clearly get into an arbitrary unit system.

# The sort=FALSE is critical in the following two calls
fakeU &lt;- lmomco::pp(gh[,1], sort=FALSE) # Weibull plotting position i/(n+1)
fakeV &lt;- lmomco::pp(gh[,2], sort=FALSE) # Weibull plotting position i/(n+1)
uv &lt;- data.frame(U=fakeU, V=fakeV); # our U-statistics

set.seed(120); theta &lt;- 2
gh &lt;- simCOP(n=34, cop=GHcop, para=theta, ploton=FALSE, points=FALSE) * 150
# Pretend psp is real data, the * 150 is to clearly get into an arbitrary unit system.

# The sort=FALSE is critical in the following two calls
fakeU &lt;- lmomco::pp(gh[,1], sort=FALSE) # Weibull plotting position i/(n+1)
fakeV &lt;- lmomco::pp(gh[,2], sort=FALSE) # Weibull plotting position i/(n+1)
uv &lt;- data.frame(U=fakeU, V=fakeV); # our U-statistics

isCOP.radsym(cop=EMPIRcop, para=uv) # FALSE
isCOP.LTD(cop=EMPIRcop,    para=uv) # TRUE
isCOP.RTI(cop=EMPIRcop,    para=uv) # FALSE
isCOP.PQD(cop=EMPIRcop,    para=uv,
                    empirical=TRUE) # TRUE
  # Blomqvist's Beta = 0.2941
  #     Gini's Gamma = 0.5606
  #   Spearman's Rho = 0.6584
  #    Kendall's Tau = 0.5045

isCOP.radsym(cop=GHcop, para=theta) # FALSE
isCOP.LTD(cop=GHcop,    para=theta) # TRUE
isCOP.RTI(cop=GHcop,    para=theta) # TRUE
isCOP.PQD(cop=GHcop,    para=theta) # TRUE
  # Blomqvist's Beta = 0.5009
  #     Gini's Gamma = 0.5591
  #   Spearman's Rho = 0.6822
  #    Kendall's Tau = 0.5000

# Notice that isCOP.RTI is not the same for empirical and theoretical.
# This shows the difficulty in tail dependence parameter estimation for
# small samples (see Salvadori et al., 2007 p. 175).
## End(Not run)
</code></pre>

<hr>
<h2 id='isCOP.RTI'>Is a Copula Right-Tail Increasing</h2><span id='topic+isCOP.RTI'></span>

<h3>Description</h3>

<p>Numerically set a logical whether a copula is <em>right-tail increasing</em> (RTI) as described by Nelsen (2006, pp. 192&ndash;193) and Salvadori <em>et al.</em> (2007, p. 222). A copula <code class="reqn">\mathbf{C}(u,v)</code> is right-tail decreasing for <code class="reqn">\mathrm{RTI}(V{\mid}U)</code> if and only if for any <code class="reqn">v \in [0,1]</code>,
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta \mathbf{C}(u,v)}{\delta u} \le \frac{v - \mathbf{C}(u,v)}{1 - u}</code>
</p>

<p>for almost all <code class="reqn">u \in [0,1]</code>. Similarly, a copula <code class="reqn">\mathbf{C}(u,v)</code> is right-tail decreasing for <code class="reqn">\mathrm{RTI}(U{\mid}V)</code> if and only if for any <code class="reqn">u \in [0,1]</code>,
</p>
<p style="text-align: center;"><code class="reqn">\frac{\delta \mathbf{C}(u,v)}{\delta v} \le \frac{u - \mathbf{C}(u,v)}{1 - v}</code>
</p>

<p>for almost all <code class="reqn">v \in [0,1]</code> where the later definition is controlled by the <code>wrtV=TRUE</code> argument.
</p>
<p>The RTI concept is associated with the concept of <em>tail monotonicity</em> (Nelsen, 2006, p. 191). Specifically, but reference to Nelsen (2006) definitions and geometric interpretations is recommended, <code class="reqn">\mathrm{RTI}(V{\mid}U)</code> (or <code class="reqn">\mathrm{RTI}(V{\mid}U)</code>) means that the probability <code class="reqn">P[Y &gt; y \mid X &gt; x]</code> (or <code class="reqn">P[X &gt; x \mid Y &gt; y]</code>) is a nondecreasing function of <code class="reqn">x</code> (or <code class="reqn">y</code>) for all <code class="reqn">y</code> (or <code class="reqn">x</code>).
</p>
<p>A positive RTI of either <code class="reqn">\mathrm{RTI}(V{\mid}U)</code> or <code class="reqn">\mathrm{RTI}(U{\mid}V)</code> implies positively quadrant dependency (PQD, <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code>) but the condition of PQD does not imply RTI. Finally, the accuracy of the numerical assessment of the returned logical by <code>isCOP.RTI</code> is dependent on the the smallness of the <code>delta</code> argument passed into the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isCOP.RTI(cop=NULL, para=NULL, wrtV=FALSE, delta=0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isCOP.RTI_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="isCOP.RTI_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="isCOP.RTI_+3A_wrtv">wrtV</code></td>
<td>
<p>A logical to toggle between with respect to <code class="reqn">v</code> or <code class="reqn">u</code> (default);</p>
</td></tr>
<tr><td><code id="isCOP.RTI_+3A_delta">delta</code></td>
<td>
<p>The increment of  <code class="reqn">\{u,v\} \mapsto [0+\Delta\delta, 1-\Delta\delta, \Delta\delta]</code> set by <code>wrtV</code>; and</p>
</td></tr>
<tr><td><code id="isCOP.RTI_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula or derivative of a copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical <code>TRUE</code> or <code>FALSE</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in nature&mdash;An approach using copulas: Dordrecht, Netherlands, Springer, Water Science and Technology Library 56, 292 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+isCOP.LTD">isCOP.LTD</a></code>, <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
isCOP.RTI(cop=P, delta=0.01) # independence should be FALSE
# but function returns TRUE. Note, same logic for isCOP.LTD returns FALSE.
isCOP.RTI(cop=PSP)                              # TRUE  : positive assoc.
isCOP.RTI(cop=PLACKETTcop, para=.15)            # FALSE : negative assoc. Plackett
isCOP.RTI(cop=PLACKETTcop, para=15)             # TRUE  : positive assoc. Plackett
isCOP.RTI(cop=PLACKETTcop, wrtv=TRUE, para=.15) # FALSE : negative assoc. Plackett
isCOP.RTI(cop=PLACKETTcop, wrtV=TRUE, para=15)  # TRUE  : positive assoc. Plackett
## End(Not run)
</code></pre>

<hr>
<h2 id='isfuncCOP'>Is a General Bivariate Function a Copula by Gridded Search?</h2><span id='topic+isfuncCOP'></span>

<h3>Description</h3>

<p>Is a general bivariate function a copula? Three properties are identified by Nelsen (2006, p. 10) for a bivariate copula <code class="reqn">\mathbf{C}(u,v)</code>:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,0) = 0 = \mathbf{C}(0,v)\mbox{\quad Nelsen 2.2.2a,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{C}(u,1) = u \mbox{\ and\ } \mathbf{C}(1,v) = v\mbox{\quad Nelsen 2.2.2b, and}</code>
</p>

<p>for every <code class="reqn">u_1, u_2, v_1, v_2</code> in <code class="reqn">\mathcal{I}^2</code> such that <code class="reqn">u_1 \le u_2</code> and <code class="reqn">v_1 \le v_2</code>,
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}(u_2, v_2) - \mathbf{C}(u_2, v_1) - \mathbf{C}(u_1, v_2) + \mathbf{C}(u_1, v_1) \ge 0 \mbox{\quad Nelsen 2.2.2c.}</code>
</p>

<p>The last condition is known also as &ldquo;2-increasing.&rdquo; The <code>isfuncCOP</code> works along a gridded search in the domain <code class="reqn">\mathcal{I}^2 = [0,1]\times[0,1]</code> for the 2-increasing check with a resolution <code class="reqn">\Delta u = \Delta v</code> <code class="reqn">=</code> <code>delta</code>. Because there are plenty of true copula functions available in the literature it seems unlikely that this function provides much production utility in investigations. This function is provided because part of the objectives of the <span class="pkg">copBasic</span> package is for instructional purposes. The computational overhead is far too great for relative benefit to somehow dispatch to this function all the time using the other copula utilities in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isfuncCOP(cop=NULL, para=NULL, delta=0.002, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isfuncCOP_+3A_cop">cop</code></td>
<td>
<p>A potential bivariate copula function that accepts two arguments for the <code class="reqn">u</code> and <code class="reqn">v</code> and parameters along argument <code>para</code> with option of additional arguments through the <code>...</code> argument;</p>
</td></tr>
<tr><td><code id="isfuncCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="isfuncCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\Delta u = \Delta v</code> of the grid edges; and</p>
</td></tr>
<tr><td><code id="isfuncCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical value of <code>TRUE</code> or <code>FALSE</code> is returned.
</p>


<h3>Author(s)</h3>

<p>S. Kloibhofer (idea and most code) and W.H. Asquith (documentation)</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityCOP">densityCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
"NelsenEx2.11" &lt;- function(u,v, ...) { # Nelsen (2006, exer. 2.11, p. 16)
  if(length(u) &gt; 1 &amp; length(v) &gt; 1 &amp; length(u) != length(v)) return(NA)
  if(length(u) == 1) u &lt;- rep(u, length(v))
  if(length(v) == 1) v &lt;- rep(v, length(u))
  return(sapply(1:length(u), function(i) { upv &lt;- u[i] + v[i]
                 if(2/3 &lt;= upv &amp; upv &lt;= 4/3) return(min(c(u,v,1/3,upv-(2/3))))
                 max(u[i]+v[i]-1, 0) }))
}
isfuncCOP(cop=NelsenEx2.11) # FALSE
## End(Not run)
</code></pre>

<hr>
<h2 id='JOcopB5'>The Joe/B5 Copula (B5)</h2><span id='topic+JOcopB5'></span>

<h3>Description</h3>

<p>The <em>Joe/B5 copula</em> (Joe, 2014, p. 170) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{B5}(u,v) = 1 - \bigl((1-u)^\Theta + (1-v)^\Theta - (1-u)^\Theta (1-v)^\Theta\bigr)^{1/\Theta}\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [1,\infty)</code>.
The copula as <code class="reqn">\Theta \rightarrow \infty</code> limits to the <em>comonotonicity coupla</em> (<code class="reqn">\mathbf{M}(u,v)</code> and <code><a href="#topic+M">M</a></code>), as <code class="reqn">\Theta \rightarrow 1^{+}</code> limits to <em>independence copula</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>). Finally, the parameter <code class="reqn">\Theta</code> is readily computed from a <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = 1 + \frac{2}{2-\Theta}\bigl(\psi(2) - \psi(1 + 2/\Theta)\bigr)\mbox{,}</code>
</p>

<p>where <code class="reqn">\psi</code> is the <code>digamma()</code> function and as <code class="reqn">\Theta \rightarrow 2</code> then </p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C}(\Theta \rightarrow 2) = 1 - \psi'(2)</code>
</p>
<p> where <code class="reqn">\psi'</code> is the <code>trigamma()</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JOcopB5(u, v, para=NULL, tau=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="JOcopB5_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="JOcopB5_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="JOcopB5_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="JOcopB5_+3A_tau">tau</code></td>
<td>
<p>Optional Kendall Tau; and</p>
</td></tr>
<tr><td><code id="JOcopB5_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned. Otherwise if <code>tau</code> is given, then the <code class="reqn">\Theta</code> is computed and a <code>list</code> having
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The parameter <code class="reqn">\Theta</code>, and</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Kendall Tau.</p>
</td></tr>
</table>
<p>and if <code>para=NULL</code> and <code>tau=NULL</code>, then the values within <code>u</code> and <code>v</code> are used to compute Kendall Tau and then compute the parameter, and these are returned in the aforementioned list.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Upper tail dependency of Theta = pi --&gt; 2 - 2^(1/pi) = 0.753131 (Joe, 2014, p. 171).
taildepCOP(cop=JOcopB5, para=pi)$lambdaU # 0.75313

# Blomqvist Beta of Theta = pi (Joe, 2014, p. 171).
blomCOP(cop=JOcopB5, para=pi)        # 0.5521328
3 - 4*(2*(1/2)^pi - (1/4)^pi)^(1/pi) # 0.5521328

## Not run: 
  # A test near the limiting Theta for trigamma()
  UV   &lt;- simCOP(cop=JOcopB5, para=2, n=10000)
  para &lt;- JOcopB5(UV[,1], UV[,2])$para
  message("Tau difference ", round(2-para, digits=2), " is small.") #
## End(Not run)

## Not run: 
   # embeddment of parameters for permutation asymmetry and rotation
   para &lt;- list(cop=JOcopB5, para=30, reflect=3, breve=0.5)
   UV &lt;- simCOP(cop=COP, para=list(cop=breveCOP, para=para), n=1000) #
## End(Not run)
</code></pre>

<hr>
<h2 id='joeskewCOP'>Joe's Nu-Skew and the copBasic Nu-Star of a Copula</h2><span id='topic+joeskewCOP'></span><span id='topic+nuskewCOP'></span><span id='topic+nustarCOP'></span>

<h3>Description</h3>

<p>Compute the measure of <em>permutation asymmetry</em>, which can be thought of as <em>bivariate skewness</em>, named for the <span class="pkg">copBasic</span> package as <em>Nu-Skew</em> <code class="reqn">\nu_\mathbf{C}</code> of a copula according to Joe (2014, p. 66) by
</p>
<p style="text-align: center;"><code class="reqn">\nu_\mathbf{C} = 3\mathrm{E}[UV^2 - U^2V] = 6\int\!\!\int_{\mathcal{I}^2} (v-u)\mathbf{C}(u,v)\, \mathrm{d}u\mathrm{d}v\mbox{.}</code>
</p>

<p>This definition is effectively the <code>type="nu"</code> for the function for which the multiplier <code class="reqn">6</code> has been converted to <code class="reqn">96</code> as explained in the <b>Note</b>.
</p>
<p>Numerical results indicate <code class="reqn">\nu_\mathbf{W} \approx 0</code> (<code><a href="#topic+W">W</a></code>), <code class="reqn">\nu_\mathbf{\Pi} = 0</code> (<code><a href="#topic+P">P</a></code>), <code class="reqn">\nu_\mathbf{M} \approx 0</code> (<code><a href="#topic+M">M</a></code>), <code class="reqn">\nu_\mathbf{PL} \approx 0</code> for all <code class="reqn">\Theta</code> (<code><a href="#topic+PLcop">PLcop</a></code>), and the <code class="reqn">\nu^\star_\mathbf{GH} = 0</code> (<code><a href="#topic+GHcop">GHcop</a></code>); copulas with mirror symmetry across the equal value line have <code class="reqn">\nu_\mathbf{C} = 0</code>.
</p>
<p>Asymmetric copulas do exist. For example, consider an asymmetric Gumbel&ndash;Hougaard <code class="reqn">\mathbf{GH}</code> copula with <code class="reqn">\Theta_p = (5,0.8,p)</code>:
</p>
<pre>
  optimize(function(p) { nuskewCOP(cop=GHcop, para=c(5,0.8, p)) },
           c(0,0.99) )$minimum
  UV &lt;- simCOP(n=10000, cop=GHcop, c(5,0.8, 0.2836485)) # inspect the graphics
  48*mean(UV$U*$V^2 - UV$U^2*UV$V) # -0.2847953 (not the 3rd parameter)
</pre>
<p>The minimization yields <code class="reqn">\nu_{\mathbf{GH}(5, 0.8, 0.2836485)} = -0.2796104</code>, which is close the expectation computed where <code class="reqn">48 = 96/2</code>.
</p>
<p>A complementary definition is supported, triggered by <code>type="nustar"</code>, and is computed by
</p>
<p style="text-align: center;"><code class="reqn">\nu^\star_\mathbf{C} = 12\int\!\!\int_{\mathcal{I}^2} (v+u)\mathbf{C}(u,v)\, \mathrm{d}u\mathrm{d}v - 4\mbox{,}</code>
</p>

<p>which has been for the <span class="pkg">copBasic</span> package, <code class="reqn">\nu^\star_\mathbf{C}</code> is named as <em>Nu-Star</em>, which the <code class="reqn">12</code> and the <code class="reqn">-4</code> have been chosen so that numerical results indicate <code class="reqn">\nu^\star_\mathbf{W} = -1</code> (<code><a href="#topic+W">W</a></code>), <code class="reqn">\nu^\star_\mathbf{\Pi} = 0</code> (<code><a href="#topic+P">P</a></code>), and <code class="reqn">\nu^\star_\mathbf{M} = +1</code> (<code><a href="#topic+M">M</a></code>).
</p>
<p>Lastly, the <code><a href="#topic+uvlmoms">uvlmoms</a></code> function provides for a quantile-based measure of bivariate skewness based on the difference <code class="reqn">U - V</code> that also is discussed by Joe (2014, p. 66).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joeskewCOP(cop=NULL, para=NULL, type=c("nu", "nustar", "nuskew"),
                               as.sample=FALSE, brute=FALSE, delta=0.002, ...)

nuskewCOP(cop=NULL, para=NULL, as.sample=FALSE, brute=FALSE, delta=0.002, ...)
nustarCOP(cop=NULL, para=NULL, as.sample=FALSE, brute=FALSE, delta=0.002, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="joeskewCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="joeskewCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="joeskewCOP_+3A_type">type</code></td>
<td>
<p>The type of metric to compute (<code>nu</code> and <code>nuskew</code> are synonymous for <code class="reqn">\nu_\mathbf{C}</code> and <code>nustar</code> is for <code class="reqn">\nu^\star_\mathbf{C}</code>);</p>
</td></tr>
<tr><td><code id="joeskewCOP_+3A_brute">brute</code></td>
<td>
<p>Should brute force be used instead of two nested <code>integrate()</code> functions to perform the double integration;</p>
</td></tr>
<tr><td><code id="joeskewCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\mathrm{d}u</code> and <code class="reqn">\mathrm{d}v</code> for the brute force integration using <code>brute</code>;</p>
</td></tr>
<tr><td><code id="joeskewCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the sample <code class="reqn">\hat\nu</code> or <code class="reqn">\hat\nu^\star</code> (see <b>Note</b>). If set to <code>-1</code>, then the message concerning CPU effort will be surpressed; and</p>
</td></tr>
<tr><td><code id="joeskewCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation of <code>joeskewCOP</code> for <span class="pkg">copBasic</span> provides the second metric of asymmetry, but why?  Consider the results that follow:
</p>
<pre>
  joeskewCOP(cop=GHcop, para=c(5, 0.8,    0.2836485), type="nu")
     # -0.2796104
  joeskewCOP(cop=GHcop, para=c(5, 0.2836485,    0.8), type="nu")
     # +0.2796103
  joeskewCOP(cop=GHcop, para=c(5, 0.8,    0.2836485), type="nu")
     #  0.3571276
  joeskewCOP(cop=GHcop, para=c(5, 0.2836485,    0.8), type="nu")
     #  0.3571279
  tauCOP(    cop=GHcop, para=c(5, 0.2836485,    0.8))
     #  0.2443377
</pre>
<p>The demonstration shows&mdash;at least for the symmetry (switchability) of the 2nd and 3rd parameters (<code class="reqn">\pi_2</code> and <code class="reqn">\pi_3</code>) of the asymmetric <code class="reqn">\mathbf{GH}</code> copula&mdash;that the first definition <code class="reqn">\nu</code> is magnitude symmetric but carries a sign change. The demonstration shows magnitude and sign stability for <code class="reqn">\nu^\star</code>, and ends with <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>). Collectively, Kendall Tau (or the other <em>symmetric measures of association</em>, <em>e.g.</em> <code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+hoefCOP">hoefCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>) when combined with <code class="reqn">\nu</code> and <code class="reqn">\nu^\star</code> might provide a framework for parameter optimization of the asymmetric <code class="reqn">\mathbf{GH}</code> copula (see below).
</p>
<p>The asymmetric <code class="reqn">\mathbf{GH}_{(5, 0.2836485, 0.8)}</code> is not radial (<code><a href="#topic+isCOP.radsym">isCOP.radsym</a></code>) or permutation (<code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>), but if <code class="reqn">\pi_2 = \pi_3</code> then the resulting <code class="reqn">\mathbf{GH}</code> copula is not radially symmetric but is permutation symmetric:
</p>
<pre>
  isCOP.radsym( cop=GHcop, para=c(5, 0.2836485, 0.8)) # FALSE
  isCOP.permsym(cop=GHcop, para=c(5, 0.2836485, 0.8)) # FALSE
  isCOP.radsym( cop=GHcop, para=c(5, 0.8,       0.8)) # FALSE
  isCOP.permsym(cop=GHcop, para=c(5, 0.8,       0.8)) # TRUE
</pre>
<p>The use of <code class="reqn">\nu_\mathbf{C}</code> and <code class="reqn">\nu^\star_\mathbf{C}</code> with a <em>measure of association</em> is just suggested above for parameter optimization. Suppose we have <code class="reqn">\mathbf{GH}_{(5,0.5,0.7)}</code> with <em>Spearman Rho</em> <code class="reqn">\rho = 0.4888</code>, <code class="reqn">\nu = 0.001475</code>, and <code class="reqn">\nu^\star = 0.04223</code>, and the asymmetric <code class="reqn">\mathbf{GH}</code> coupla is to be fit. Parameter estimation for the asymmetric <code class="reqn">\mathbf{GH}</code> is accomplished by
</p>
<pre>
  "fitGHcop" &lt;- function(hats, assocfunc=rhoCOP, init=NA, eps=1E-4, ...) {
     H &lt;- GHcop # shorthand for the copula
     "objfunc" &lt;- function(par) {
        par[1]   &lt;- ifelse(par[1] &lt; 1, return(Inf), exp(par[1])) # edge check
        par[2:3] &lt;-  pnorm(par[2:3]) # detransform
        hp &lt;- c(assocfunc(H, par), nuskewCOP(H, par), nustarCOP(H, par))
        return(sum((hats-hp)^2))
     }
     # Theta=1 and Pi2 = Pi3 = 1/2 # as default initial estimates
     if(is.na(init)) init &lt;- c(1, rep(1/2, times=2))
     opt  &lt;- optim(init, objfunc, ...); par &lt;- opt$par
     para &lt;- c( exp(par[1]), pnorm(par[2:3]) )
     names(para) &lt;- c("Theta", "Pi2", "Pi3")
     fit &lt;- c(assocfunc(H, para), nuskewCOP(H, para), nustarCOP(H, para))
     txt &lt;- c("AssocMeasure", "NuSkew", "NuStar")
     names(fit) &lt;- txt; names(hats) &lt;- txt
     if(opt$value &gt; eps) warning("inspect the fit")
     return(list(para=para, fit=fit, given=hats, optim=opt))
  }
  father &lt;- c(5,.5,.7)
  densityCOPplot(cop=GHcop, para=father, contour.col=8)
  fRho  &lt;- rhoCOP(   cop=GHcop, father)
  fNu   &lt;- nuskewCOP(cop=GHcop, father)
  fStar &lt;- nustarCOP(cop=GHcop, father)

  child &lt;- fitGHcop(c(fRho, fNu, fStar))$para
  densityCOPplot(cop=GHcop, para=child, ploton=FALSE)

  cRho  &lt;- rhoCOP(   cop=GHcop, child)
  cNu   &lt;- nuskewCOP(cop=GHcop, child)
  cStar &lt;- nustarCOP(cop=GHcop, child)
  message("Father stats: ", paste(fRho, fNu, fStar, sep=", "))
  message("Child  stats: ", paste(cRho, cNu, cStar, sep=", "))
  message("Father para: ",  paste(father,      collapse=", "))
  message("Child  para: ",  paste(child,       collapse=", "))
</pre>
<p>The initial parameter estimate has the value <code class="reqn">\Theta = 1</code>, which is <em>independence</em> for the one parameter <code class="reqn">\mathbf{GH}</code>. The two other parameters are set as <code class="reqn">\pi_2 = \pi_3 = 1/2</code> to be in the mid-point of their domain. The transformations using the <code>log()</code> <code class="reqn">\leftrightarrow</code> <code>exp()</code> and <code>qnorm()</code> <code class="reqn">\leftrightarrow</code> <code>pnorm()</code> functions in <span class="rlang"><b>R</b></span> are used to keep the optimization in the viable parameter domain. The results produce a fitted copula of <code class="reqn">\mathbf{GH}_{(4.907, 0.5006, 0.7014)}</code>. This fit aligns well with the parent, and the three statistics are essentially matched during the fitting.
</p>
<p>The <code class="reqn">\nu^\star_\mathbf{C}</code> can be similar to <code><a href="#topic+rhoCOP">rhoCOP</a></code>, but differences do exist. In the presence of radial symmetry, (<code class="reqn">\nu_\mathbf{C} == 0</code>), the <code class="reqn">\nu^\star_\mathbf{C}</code> is nearly equal to <em>Spearman Rho</em> for some copulas. Let us test further:
</p>
<pre>
  p &lt;- 10^seq(0,2,by=.01)
  s &lt;- sapply(p, function(t) nustarCOP(cop=GHcop, para=c(t)))
  r &lt;- sapply(p, function(t)    rhoCOP(cop=GHcop, para=c(t)))
  plot(p,s, log="x", type="l", col=3, lwd=3); lines(p,r)
</pre>
<p>Now let us add some asymmetry
</p>
<pre>
  s &lt;- sapply(p, function(t) nustarCOP(cop=GHcop, para=c(t, 0.25, 0.75)))
  r &lt;- sapply(p, function(t)    rhoCOP(cop=GHcop, para=c(t, 0.25, 0.75)))
  plot(p,s, log="x", type="l", col=3, lwd=3); lines(p,r)
</pre>
<p>Now let us choose a different (the <em>Clayton</em>) copula
</p>
<pre>
  s &lt;- sapply(p, function(t) nustarCOP(cop=CLcop, para=c(t)))
  r &lt;- sapply(p, function(t)    rhoCOP(cop=CLcop, para=c(t)))
  plot(p,s, log="x", type="l", col=3, lwd=3); lines(p,r)
</pre>


<h3>Value</h3>

<p>The value for <code class="reqn">\nu_\mathbf{C}</code> or <code class="reqn">\nu^\star_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>The <code class="reqn">\nu_\mathbf{C}</code> definition is given with a multiplier of <code class="reqn">6</code> on the integrals in order to agree with Joe (2014) relation that is also shown. However, in mutual parameter estimation experiments using a simple sum-of-square errors as shown in the <b>Details</b>, it is preferred to have <code class="reqn">\nu_\mathbf{C}</code> measured on a larger scale. Where does the <code class="reqn">96</code> then come from? It is heuristically made so that the upright and rotated <code>cophalf</code> (see <b>Examples</b> under <code><a href="#topic+asCOP">asCOP</a></code> and <code><a href="#topic+bilmoms">bilmoms</a></code> for this copula) acquires <code class="reqn">\nu_\mathbf{C}</code> values of <code class="reqn">+1</code> and <code class="reqn">-1</code>, respectively. As a result to make back comparisons to Joe results, the ratios of <code class="reqn">96</code> are made in this documentation.
</p>
<p>The source code shows slightly different styles of division by the sample size as part of the sample estimation of the statistics. The <code class="reqn">\hat\nu</code> using just division by the sample size as testing indicates that this statistic is reasonably unbiased for simple copula. The <code class="reqn">\hat\nu^\star</code> with similar division is a biased statistic and the bias is not symmetrical in magnitude or sign it seems whether the <code class="reqn">\hat\nu^\star</code> is positive or negative. The salient code is <code>spm &lt;- ifelse(corsgn == -1, +2.4, +1.1)</code> within the sources for which the corrections were determined heuristically through simulation, and <code>corsgn</code> is the sign of the sample Spearman Rho through the <code>cor()</code> function of <span class="rlang"><b>R</b></span>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uvskew">uvskew</a></code>, <code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>,
<code><a href="#topic+hoefCOP">hoefCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nuskewCOP(cop=GHcop,para=c(1.43,1/2,1))*(6/96) # 0.005886 (Joe, 2014, p. 184; 0.0059)

## Not run: 
joeskewCOP(            cop=GHcop, para=c(8, .7, .5)) # -0.1523491
joeskewCOP(            cop=GHcop, para=c(8, .5, .7)) # +0.1523472
# UV &lt;- simCOP(n=1000, cop=GHcop, para=c(8, .7, .5)) # see the switch in
# UV &lt;- simCOP(n=1000, cop=GHcop, para=c(8, .5, .7)) # curvature
## End(Not run)

## Not run: 
para=c(19,0.3,0.8); set.seed(341)
nuskew &lt;-  nuskewCOP( cop=GHcop, para=para) # 0.3057744
UV &lt;- simCOP(n=10000, cop=GHcop, para=para) #   a large simulation
mean((UV$U - UV$V)^3)/(6/96)                # 0.3127398

# Two other definitions of skewness follow and are not numerically the same.
uvskew(u=UV$U, v=UV$V, umv=TRUE)  # 0.3738987  (see documentation uvskew)
uvskew(u=UV$U, v=UV$V, umv=FALSE) # 0.3592739  ( or documentation uvlmoms)
# Yet another definition of skew, which requires large sample approximation
# using the L-comoments (3rd L-comoment is L-coskew).
lmomco::lcomoms2(UV)$T3 # L-coskew of the simulated values [1,2] and [2,1]
#             [,1]        [,2]
#[1,]  0.007398438  0.17076600
#[2,] -0.061060260 -0.00006613
# See the asymmetry in the two L-coskew values and consider this in light of
# the graphic produced by the simCOP() called for n=10,000. The T3[1,1] is
# the sampled L-skew (univariate) of the U margin and T3[2,2] is the same
# but for the V margin. Because the margins are uniform (ideally) then these
# for suitable large sample must be zero because the L-skew of the uniform
# distribution is by definition zero.
#
# Now let us check the sample estimator for sample of size n=300, and the
# t-test will (should) result in acceptance of the NULL hypothesis.
S &lt;- replicate(60, nuskewCOP(para=simCOP(n=300, cop=GHcop, para=para,
                                         graphics=FALSE), as.sample=TRUE))
t.test(S, mu=nuskew)
# t = 0.004633, df = 59, p-value = 0.9963
# alternative hypothesis: true mean is not equal to 0.3057744
# 95 percent confidence interval:
#  0.2854282 0.3262150
# sample estimates:
# mean of x
# 0.3058216 
## End(Not run)

## Not run: 
# Let us run a large ensemble of copula properties that use the whole copula
# (not tail properties). We composite a Plackett with a Gumbel-Hougaard for
# which the over all association (correlation) sign is negative, but amongst
# these statistics with nuskew and nustar at the bottom, there are various
# quantities that can be extracted. These could be used for fitting.
set.seed(873)
para &lt;- list(cop1=PLcop, cop2=GHcop, alpha=0.6, beta=0.9,
             para1=.005, para2=c(8.3,0.25,0.7))
UV &lt;- simCOP(1000, cop=composite2COP, para=para) # just to show
  blomCOP(composite2COP, para)            # -0.4078657
  footCOP(composite2COP, para)            # -0.2854227
  hoefCOP(composite2COP, para)            # +0.5713775
  lcomCOP(composite2COP, para)$lcomUV[3]  # +0.1816084
  lcomCOP(composite2COP, para)$lcomVU[3]  # +0.1279844
   rhoCOP(composite2COP, para)            # -0.5688417
rhobevCOP(composite2COP, para)            # -0.2005210
   tauCOP(composite2COP, para)            # -0.4514693
  wolfCOP(composite2COP, para)            # +0.5691933
nustarCOP(composite2COP, para)            # -0.5172434
nuskewCOP(composite2COP, para)            # +0.0714987 
## End(Not run)
</code></pre>

<hr>
<h2 id='joint.curvesCOP'>Compute Coordinates of the Marginal Probabilities given joint AND or OR Probabilities</h2><span id='topic+joint.curvesCOP'></span>

<h3>Description</h3>

<p>Compute the coordinates of the bivariate marginal probabilities for variables <code class="reqn">U</code> and <code class="reqn">V</code> given selected probabilities levels <code class="reqn">t</code> for a copula <code class="reqn">\mathbf{C}(u,v)</code> for <code class="reqn">v</code> with respect to <code class="reqn">u</code>. For the case of a <b>joint and</b> probability, symbolically the solution is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v,\ V \le v] = t = \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>where <code class="reqn">U \mapsto [t_i, u_{j}, u_{j+1}, \cdots, 1; \Delta t]</code> (an irregular sequence of <code class="reqn">u</code> values from the <code class="reqn">i</code>th value of <code class="reqn">t_i</code> provided through to unity) and thus
</p>
<p style="text-align: center;"><code class="reqn">t_i \mapsto \mathbf{C}(u=U, v)\mbox{,}</code>
</p>

<p>and solving for the sequence of <code class="reqn">v</code>. The index <code class="reqn">j</code> is to indicate that a separate loop is involved and is distinct from <code class="reqn">i</code>. The pairings <code class="reqn">\{u(t_i), v(t_i)\}</code> for each <code class="reqn">t</code> are packaged as an <span class="rlang"><b>R</b></span> <code>data.frame</code>. This operation is very similiar to the plotting capabilities in <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code> for <em>level curves</em> (Nelsen, 2006, pp. 12&ndash;13) but implemented in the function <code>joint.curvesCOP</code> for alternative utility.
</p>
<p>For the case of a <b>joint or</b> probability, the <em>dual of a copula (function)</em> or <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> from a copula (Nelsen, 2006, pp. 33&ndash;34) is used and symbolically the solution is:
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = t = \tilde{\mathbf{C}}(u,v) = u + v - \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>where <code class="reqn">U \mapsto [0, u_j, u_{j+1}, \cdots, t_i; \Delta t]</code> (an irregular sequence of <code class="reqn">u</code> values from zero through to the <code class="reqn">i</code>th value of <code class="reqn">t</code>) and thus
</p>
<p style="text-align: center;"><code class="reqn">t_i \mapsto \tilde{\mathbf{C}}(u=U, v)\mbox{,}</code>
</p>

<p>and solving for the sequence of <code class="reqn">v</code>.  The index <code class="reqn">j</code> is to indicate that a separate loop is involved and is distinct from <code class="reqn">i</code>. The pairings <code class="reqn">\{u(t_i), v(t_i)\}</code> for each <code class="reqn">t</code> are packaged as an <span class="rlang"><b>R</b></span> <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joint.curvesCOP(cop=NULL, para=NULL, type=c("and", "or"),
                probs=c(0.5, 0.8, 0.90, 0.96, 0.98, 0.99, 0.995, 0.998),
                zero2small=TRUE, small=1E-6, divisor=100, delu=0.001, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="joint.curvesCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_type">type</code></td>
<td>
<p>What type of joint probability is to be computed;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_probs">probs</code></td>
<td>
<p>The joint probabilities <code class="reqn">t_i</code> from which to compute the coordinates. The default values represent especially useful annual return period equivalents that are useful in hydrologic risk analyses;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_zero2small">zero2small</code></td>
<td>
<p>A logical controlling whether exactly zero value for probability are converted to a <code>small</code> value and exactly unity values for probability are converted to the value <code>1 - small</code>; this logical is useful if transformation from probability space into standard normal variates or <em>Gumbel reduced variates</em> (see function <code>prob2grv()</code> in package <span class="pkg">lmomco</span>) is later desired by the user for attendant graphics (see <b>Examples</b> section);</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_small">small</code></td>
<td>
<p>The value for <em>small</em> described for <code>zero2small</code>;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_divisor">divisor</code></td>
<td>
<p>A divisor on a computation of a <code class="reqn">\Delta t</code> for incrementing through the irregularly-spaced <code class="reqn">u</code> domain as part of the coordinate computation (see source code);</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_delu">delu</code></td>
<td>
<p>A <code class="reqn">\Delta u</code> for setup of the incrementing through the irregularly-space <code class="reqn">u</code> domain as part of the coordinate computation (see source code); and</p>
</td></tr>
<tr><td><code id="joint.curvesCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+duCOP">duCOP</a></code> function of <span class="pkg">copBasic</span> or <code>uniroot()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned with elements each of the given <code>probs</code>.
</p>


<h3>Note</h3>

<p>The arguments <code>divisor</code> and <code>delu</code> provide flexibility to obtain sufficient smoothness in the coordinate curvatures for a given <code class="reqn">t</code>. The pairings <code class="reqn">\{u(t_i), v(t_i)\}</code> for each <code class="reqn">t</code> packaged as <code>data.fame</code>s within the returned <code>list</code> each have their own unique length, and this is the reason that a single &ldquo;master&rdquo; <code>data.frame</code> is not returned by this function.
</p>
<p><em>Extended Example</em>&mdash;The code below shows both types of joint probability being computed using the default <code>probs</code>. The plotting is made in <em>Gumbel reduced variates</em> (GRV; see <code>prob2grv</code> in package <span class="pkg">lmomco</span>). This transformation is somewhat suitable for the magnitude variation in and at tail depth of the <code>probs</code>. Also with transformation is being used, the <code>zero2small</code> logical is kept at <code>TRUE</code>, which is appropriate. The <code>zero2small</code> being set is also useful if standard normal variate transformation (by the <code>qnorm()</code> function in <span class="rlang"><b>R</b></span>) were used instead.
</p>
<p>The <em>Gumbel&ndash;Hougaard</em> copula (<code><a href="#topic+GHcop">GHcop</a></code>) and a reversed Gumbel&ndash;Hougaard copula <code>rGH</code> are composited together by <code><a href="#topic+composite2COP">composite2COP</a></code>. These were chosen so that some asymmetry in the solutions by <code>joint.curvesCOP</code> could be seen. We begin by specifying symmetrical plotting limits for later use and then creating a function for the reversed Gumbel&ndash;Hougaard and setting the parameters and composition weights:
</p>
<pre>
  grvlim &lt;- lmomco::prob2grv(c(0.25,0.999)) # out to 1,000 years
  "rGHcop" &lt;- function(u,v, ...) { u + v - 1 + GHcop(1-u, 1-v, ...) }
  para &lt;- list(alpha=0.16, beta=0.67, cop1 =GHcop, cop2 =rGHcop,
                                      para1=4.5,   para2=2.2)
  tau    &lt;- tauCOP(    cop=composite2COP, para=para) # Tau    = 0.351219
  nuskew &lt;- nuskewCOP(cop=composite2COP, para=para)  # Nuskew = 0.084262
  UV &lt;- simCOP(n=1000,  cop=composite2COP, para=para, snv=TRUE)
</pre>
<p>The code also computed the <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) and <em>Nu-Skew</em> (<code><a href="#topic+nuskewCOP">nuskewCOP</a></code>) and the results shown. The code finishes with a simulation by <code><a href="#topic+simCOP">simCOP</a></code> of the copula composition just for reference.
</p>
<p>Next, we compute and plot the joint probability curves. The <code>tol</code>erance for the <code>uniroot</code> calls is reset from the <span class="rlang"><b>R</b></span> defaults because slight wooble in the numerical solutions exists otherwise.  The <code>AND</code> and <code>OR</code> <code>lists</code> each provide <code>data.frame</code>s from which successive graphic calls plot the lines. The second <code>plot()</code> call is commented out so that both sets of joint probability curves are drawn on the same plot.
</p>
<pre>
  AND &lt;- joint.curvesCOP(cop=composite2COP, para=para, type="and",
                         divisor=1000, tol=.Machine$double.eps)
  plot(grvlim, grvlim, type="n",
       xlab="GUMBEL REDUCED VARIATE IN U", ylab="GUMBEL REDUCED VARIATE IN V")
  for(t in sort(as.numeric(names(AND)))) {
      UV &lt;- get(as.character(t), AND)
      lines(lmomco::prob2grv(UV$U),         lmomco::prob2grv(       UV$V))
      text( lmomco::prob2grv(median(UV$U)), lmomco::prob2grv(median(UV$V)),
           as.character(round(1/(1-t)), digits=0))
  }

  OR &lt;- joint.curvesCOP(cop=composite2COP, para=para, type="or",
                        divisor=1000, tol=.Machine$double.eps)
  for(t in sort(as.numeric(names(OR)))) {
     UV &lt;- get(as.character(t), OR)
     lines(lmomco::prob2grv(UV$U), lmomco::prob2grv(UV$V), col=2)
     text( lmomco::prob2grv(median(UV$U)), lmomco::prob2grv(median(UV$V)),
          as.character(round(1/(1-t)), digits=0), col=2)
  }
  mtext("Return Periods: black=cooperative risk, red=dual risk")
  abline(0,1, lty=2) # dash line is simply and equal value line
</pre>
<p><em>Black Curves</em>&mdash;The black curves represent the nonexceedance <b>joint and</b> condition. The black curves are a form of <em>level curve</em> (see <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>), but it seems appropriate to not name them as such because Nelsen's examples and others usually have the level curves on an even step interval of probability such as 10-percent level curves. The complement of nonexceedance <b>joint and</b> is the probability level that either or both random variables (say &ldquo;hazards&rdquo;) <code class="reqn">U</code> or <code class="reqn">V</code> causes &ldquo;failure&rdquo; at the respective return period.
</p>
<p><em>Red Curves</em>&mdash;The red curves represent the nonexceedance <b>joint or</b> (inclusive) condition. The complement of nonexceedance <b>joint or</b> (inclusive) is the probability level that both random variables (say &ldquo;hazards&rdquo;) <code class="reqn">U</code> or <code class="reqn">V</code> must simultaneously (or dually) occur for &ldquo;failure&rdquo; at the respective return period. Note, there is obviously asymmetry in the <b>joint or</b> curves.
</p>
<p><em>Interpretation</em>&mdash;Because the two hazards can &ldquo;cooperate&rdquo; to cause failure (see <code><a href="#topic+coCOP">coCOP</a></code>) for an equal level of protection (say 500-year event) relative to the complement of nonexceedance <b>joint or</b> (inclusive) condition (see <code>surCOP</code>), the marginal probabilities must be considerably higher. Users are encouraged to review <code><a href="#topic+copBasic-package">copBasic-package</a></code> and the figure therein.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOPatf">diagCOPatf</a></code>, <code><a href="#topic+duCOP">duCOP</a></code>, <code><a href="#topic+jointCOP">jointCOP</a></code>, <code><a href="#topic+joint.curvesCOP2">joint.curvesCOP2</a></code>, <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See Note section
</code></pre>

<hr>
<h2 id='joint.curvesCOP2'>Compute Coordinates of the Marginal Probabilities given joint AND or OR Probability</h2><span id='topic+joint.curvesCOP2'></span>

<h3>Description</h3>

<p>Compute the coordinates of the bivariate marginal probabilities for variables <code class="reqn">U</code> and <code class="reqn">V</code> given selected probabilities levels <code class="reqn">t</code> for a copula <code class="reqn">\mathbf{C}(u,v)</code> for <code class="reqn">u</code> with respect to <code class="reqn">v</code>. For the case of a <b>joint and</b> probability, symbolically the solution is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v,\ V \le v] = t = \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>where <code class="reqn">V \mapsto [t_i, t_{j}, t_{j+1}, \cdots, 1; \Delta]</code> (an irregular sequence of <code class="reqn">v</code> values from the <code class="reqn">i</code>th value of <code class="reqn">t_i</code> provided through to unity) and thus
</p>
<p style="text-align: center;"><code class="reqn">t_i \mapsto \mathbf{C}(u, v=V)\mbox{,}</code>
</p>

<p>and solving for the sequence of <code class="reqn">u</code>. The index <code class="reqn">j</code> is to indicate that a separate loop is involved and is distinct from <code class="reqn">i</code>. The pairings <code class="reqn">\{u(t_i), v(t_i)\}</code> for each <code class="reqn">t</code> are packaged as an <span class="rlang"><b>R</b></span> <code>data.frame</code>. This operation is very similiar to the plotting capabilities in <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code> for <em>level curves</em> (Nelsen, 2006, pp. 12&ndash;13) but implemented in the function <code>joint.curvesCOP2</code> for alternative utility.
</p>
<p>For the case of a <b>joint or</b> probability, the <em>dual of a copula (function)</em> or <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> from a copula (Nelsen, 2006, pp. 33&ndash;34) is used and symbolically the solution is:
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = t = \tilde{\mathbf{C}}(u,v) = u + v - \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>where <code class="reqn">V \mapsto [0, v_j, v_{j+1}, \cdots, t_i; \Delta]</code> (an irregular sequence of <code class="reqn">v</code> values from zero through to the <code class="reqn">i</code>th value of <code class="reqn">t</code>) and thus
</p>
<p style="text-align: center;"><code class="reqn">t_i \mapsto \tilde{\mathbf{C}}(u, v=V)\mbox{,}</code>
</p>

<p>and solving for the sequence of <code class="reqn">u</code>.  The index <code class="reqn">j</code> is to indicate that a separate loop is involved and is distinct from <code class="reqn">i</code>. The pairings <code class="reqn">\{u(t_i), v(t_i)\}</code> for each <code class="reqn">t</code> are packaged as an <span class="rlang"><b>R</b></span> <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joint.curvesCOP2(cop=NULL, para=NULL, type=c("and", "or"),
                 probs=c(0.5, 0.8, 0.90, 0.96, 0.98, 0.99, 0.995, 0.998),
                 zero2small=TRUE, small=1E-6, divisor=100, delv=0.001, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="joint.curvesCOP2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_type">type</code></td>
<td>
<p>What type of joint probability is to be computed;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_probs">probs</code></td>
<td>
<p>The joint probabilities for which to compute the coordinates. The default values represent especially useful annual return period equivalents that are useful in hydrologic risk analyses;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_zero2small">zero2small</code></td>
<td>
<p>A logical controlling whether precise zero value for probability are converted to a <code>small</code> value and precise unity values for probability are converted to the value <code>1 - small</code>; this logical is useful if transformation from probability space into standard normal variates or <em>Gumbel reduced variates</em> (GRV; see function <code>prob2grv()</code> in package <span class="pkg">lmomco</span>) is later desired by the user for attendant graphics (see <b>Examples</b> section);</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_small">small</code></td>
<td>
<p>The value for <em>small</em> described for <code>zero2small</code>;</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_divisor">divisor</code></td>
<td>
<p>A divisor on a computation of a <code class="reqn">\Delta</code> for incrementing through the <code class="reqn">v</code> domain as part of the coordinate computation (see source code);</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_delv">delv</code></td>
<td>
<p>A <code class="reqn">\Delta v</code> for setup of the incrementing through the <code class="reqn">v</code> domain as part of the coordinate computation (see source code); and</p>
</td></tr>
<tr><td><code id="joint.curvesCOP2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+duCOP">duCOP</a></code> function of <span class="pkg">copBasic</span> or <code>uniroot()</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned with elements each of the given <code>probs</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOPatf">diagCOPatf</a></code>, <code><a href="#topic+duCOP">duCOP</a></code>, <code><a href="#topic+jointCOP">jointCOP</a></code>, <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code>, <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See Note for joint.curvesCOP()
## Not run: 
# Approach the joint curves from both "with respect two" perspectives---results same.
JCvwrtu &lt;- joint.curvesCOP( cop=PSP, prob=0.98)$"0.98"
JCuwrtv &lt;- joint.curvesCOP2(cop=PSP, prob=0.98)$"0.98"; lim &lt;- c(2,5)
plot(qnorm(JCvwrtu$U), qnorm(JCvwrtu$V), type="l", lwd=6, col=8, xlim=lim, ylim=lim,
     xlab="STANDARD NORMAL VARIATE OF U", ylab="STANDARD NORMAL VARIATE OF V")
lines(qnorm(JCuwrtv$U), qnorm(JCuwrtv$V), col=2, lwd=2)
mtext("98th Joint Percentile Level Curve for PSP Copula")#
## End(Not run)
</code></pre>

<hr>
<h2 id='jointCOP'>Compute Equal Marginal Probabilities Given a Single Joint AND or OR Probability for a Copula</h2><span id='topic+jointCOP'></span>

<h3>Description</h3>

<p>Given a single <em>joint probability</em> denoted as <code class="reqn">t</code> for a copula <code class="reqn">\mathbf{C}(u,v)</code> numerically solve for bivariate marginal probabilities <code class="reqn">U</code> and <code class="reqn">V</code> such that they are also equal to each other (<code class="reqn">u = v = w</code>). For the case of a <b>joint and</b> probability, the primary diagonal of the copula (Nelsen, 2006, pp. 12 and 16) is solved for by a simple dispatch to the <code><a href="#topic+diagCOPatf">diagCOPatf</a></code> function instead. Symbolically the solution is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v,\ V \le v] = t = \mathbf{C}(w,w)\mbox{.}</code>
</p>

<p>For the case of a <b>joint or</b> probability, the <em>dual of a copula (function)</em> or <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> from a copula (Nelsen, 2006, pp. 33&ndash;34; <code><a href="#topic+duCOP">duCOP</a></code>) is used where symbolicaly the solution is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = t = \tilde{\mathbf{C}}(u,v) = u + v - \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = t = 2w - \mathbf{C}(w,w)\mbox{.}</code>
</p>

<p>The function for <code>type="or"</code> tests <code class="reqn">\tilde{\mathbf{C}}(0,0)</code> and if it returns <code>NA</code> or <code>NaN</code> then the lower limit for the rooting is treated as <code>.Machine$double.eps</code> instead of 0 (zero).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jointCOP(t, cop=NULL, para=NULL, type=c("and", "or"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jointCOP_+3A_t">t</code></td>
<td>
<p>The joint probability level <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="jointCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="jointCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="jointCOP_+3A_type">type</code></td>
<td>
<p>The type of joint probability is to be computed; and</p>
</td></tr>
<tr><td><code id="jointCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+duCOP">duCOP</a></code> function of <span class="pkg">copBasic</span> or <code>uniroot()</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the equal <code class="reqn">u</code> and <code class="reqn">v</code> probabilties for the given <code>type</code> at the joint probability level of <code class="reqn">t</code>. The vector includes the <code class="reqn">t</code> as the third element.
</p>


<h3>Note</h3>

<p><em>ENSEMBLE 1&mdash;Counting and Copula Probabilities from a Massive Sample Size:</em> Simulations can be used to check and verify select copula concepts. Begin with a <em>Gumbel&ndash;Hougaard</em> copula <code class="reqn">\mathbf{GH}(u,v) = \mathbf{C}_{\Theta}(u,v)</code> having parameter <code class="reqn">\Theta = 1.5</code>, which corresponds to a <em>Kendall Tau</em> <code class="reqn">\tau_\mathbf{C} = 1/3</code> (<code><a href="#topic+GHcop">GHcop</a></code>). Next, simulate and count the number of either <code class="reqn">U</code> or <code class="reqn">V</code> exceeding the 99th percentile &ldquo;event.&rdquo; The event can occur either from the random variable <code class="reqn">U</code> or from <code class="reqn">V</code> with equal &ldquo;loss.&rdquo; If the event occurs in both <code class="reqn">U</code> and <code class="reqn">V</code>, the loss is just the same as if <code class="reqn">U</code> or <code class="reqn">V</code> occurred. So, if a design were at the 100-year level and thus a 0.01 chance of loss each year, then 500 losses in 50,000 years would be expected.
</p>
<pre>
  set.seed(89); n &lt;- 50000
  UV &lt;- simCOP(n, cop=GHcop, para=1.5, graphics=FALSE)
  length(UV$U[UV$U &gt; 0.99    | UV$V &gt; 0.99])     # 799 times (losses)
  length(UV$U[UV$U &gt; 0.99356 | UV$V &gt; 0.99356])  # 500 times (losses)
</pre>
<p>Letting <code>JP</code> equal 0.99356, which forces the required acceptance of 500 losses for the design, has conditions of <code>UV$U &gt; JP</code> <b>or</b> <code>UV$V &gt; JP</code> as well as condition of <code>UV$U &gt; JP</code> <b>and</b> <code>UV$V &gt; JP</code>. These three conditions are captured using the structure of the <span class="rlang"><b>R</b></span> code listed. Manual searching resulted in a value for <code>JP</code> equaling 0.99356, which produces the 500 count losses (acceptable losses). Thus, <code>JP</code> is a marginal bivariate probability (in this case equality between <code class="reqn">U_{\mathrm{crit.}} = V_{\mathrm{crit.}}</code> declared) necessary to attain a 99th percentile joint protection from loss. The magnitude for either <code class="reqn">U</code> or <code class="reqn">V</code> thus must exceed the 99th percentile, and this is what the code shows with 799 losses.
</p>
<p>It is important to consider that unless <code class="reqn">U</code> and <code class="reqn">V</code> are in perfect positive correlation (<em>e.g.</em> <code class="reqn">\mathbf{M}(u,v)</code>, <code><a href="#topic+M">M</a></code>, <em>Fréchet&ndash;Hoeffding upper-bound copula</em>), that protection from loss needs to be higher than 0.99 if the marginal risk is set at that level. Continuing, if the 99th percentile is the 100-year event, then design criteria should be about 155 years instead [<code>lmomco::prob2T(0.99356)</code>]. The user can readily see this with the switch to perfect independence with the <code class="reqn">\mathbf{GH}(u,v)</code> copula with <code class="reqn">\Theta = 1</code> and produce quite different results or extreme correlation with say <code class="reqn">\Theta &gt; 20</code>.
</p>
<p>To provide the protection for 500 exceedances in <code class="reqn">n =</code> 50,000 trials and for purposes of demonstration, balance the protection between <code class="reqn">U</code> and <code class="reqn">V</code> by setting their probabilities equal, then the theoretical joint probability is
</p>
<pre>
  diagCOPatf(0.99, 0.99, cop=GHcop, para=1.5)             # 0.9936887
  jointCOP(  0.99,       cop=GHcop, para=1.5, type="and") # 0.9936887
</pre>
<p>and these two probabilities, which in reality are actually based on same computation (<code><a href="#topic+diagCOPatf">diagCOPatf</a></code>), and nearly are the same as <code>JP</code> <code class="reqn">=</code> 0.99356 that was determined by the manual searching on the simulated data.
</p>
<p>A <b>mutually inclusive and</b> condition can be arranged as follows, and it is implicit in the definition that both loss events occur at the same time:
</p>
<pre>
  length(UV$U[UV$U &gt; 0.99 &amp; UV$V &gt; 0.99])            # 208 losses ( simulated )
  surCOP(  1-0.99, 1-0.99, cop=GHcop, para=1.5) * n  # 209 losses (theoretical)
  surfuncCOP(0.99,   0.99, cop=GHcop, para=1.5) * n  # 209 losses (theoretical)
</pre>
<p>What are the expected number of exceedances if designs for <code class="reqn">U</code> and <code class="reqn">V</code> are built at <code class="reqn">U =</code> <code class="reqn">V = 0.99</code> marginal probabilities for protection?
</p>
<pre>
   coCOP(1-0.99, 1-0.99, cop=GHcop, para=1.5)  * n  # 791 losses (theoretical)
  # by the co-copula which from the copula as nonexceedances is
  (1-COP(  0.99,   0.99, cop=GHcop, para=1.5)) * n  # 791 losses (theoretical)
</pre>
<p>Note, the 791 losses is nearly equal to 799, but obviously not 500 as one might incorrectly have imagined strictly in a univariate world.
</p>
<p>Now, a couple of questions can be asked about the <b>joint and</b> and <b>joint or</b> probabilities using the definition of a copula <code><a href="#topic+COP">COP</a></code> and the <em>dual of a copula (function)</em> (<code class="reqn">\tilde{\mathbf{C}}(u,v)</code>, <code><a href="#topic+duCOP">duCOP</a></code>), respectively:
</p>
<pre>
  # The AND nonexceedances:
  length(UV$U[UV$U &lt;= 0.99 &amp; UV$V &lt;= 0.99]) / n    # 0.98402   ( simulated )
    COP(0.99, 0.99, cop=GHcop, para=1.5)           # 0.9841727 (theoretical)

  # The OR nonexceedances:
  length(UV$U[UV$U &lt;= 0.99 | UV$V &lt;= 0.99]) / n    # 0.99584   ( simulated )
  duCOP(0.99, 0.99, cop=GHcop, para=1.5)           # 0.9958273 (theoretical)
</pre>
<p>How about inversion of <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> by <code>jointCOP</code> and check against the simulation?
</p>
<pre>
  jointCOP(0.99, cop=GHcop, para=1.5, type="or")[1]      # 0.9763951 ( theor. )
  length(UV$U[UV$U &lt;= 0.9763951 | UV$V &lt;= 0.9763951])/n  # 0.98982 ( simulated)
</pre>
<p>The second probability is a value quite near to 0.99. So, if one wants mutual loss protection, compute the inversion of the dual of a copula using <code>jointCOP(..., type="or")</code>. Let us say that 0.80 mutual loss protection is wanted
</p>
<pre>
  jointCOP(0.80, cop=GHcop, para=1.5, type="or")[1]      # 0.6561286
  n - length(UV$U[UV$U &lt;= 0.6561286 | UV$V &lt;= 0.6561286])# 10049 losses ( sim.)
  n - (1-0.8)*n                                    # 10000 losses (theoretical)
</pre>
<p>The example here shows numerical congruence of 10,049 <code class="reqn">\approx</code> 10,000. An opposing question is useful. How about a <b>mutually exclusive or</b> condition as nonexceedances?
</p>
<pre>
  # The mutually exclusive OR as nonexceedances:
  length((UV$U[  (UV$U &lt;= 0.99 | UV$V &lt;= 0.99) &amp;
               ! (UV$U &lt;= 0.99 &amp; UV$V &lt;= 0.99)]))        # 591 losses ( simulated )
  # The mutually exclusive OR as exceedances:
  length(UV$U[   (UV$U &gt;  0.99 | UV$V &gt;  0.99) &amp;
               ! (UV$U &gt;  0.99 &amp; UV$V &gt;  0.99)])         # 591 losses ( simulated )
</pre>
<p>It is clear that 208 <code class="reqn">+</code> 591 <code class="reqn">=</code> 799 as shown earlier; notice how there are two ways to get at the 591 count. There are 208 mutual loss events and 591 occassions where either <code class="reqn">U</code> or <code class="reqn">V</code> is the causation of loss. For comparison, how many observed events by random variable were observed?
</p>
<pre>
  length(UV$U[  (UV$U &gt; 0.99)]) # 519 ( simulated )
  length(UV$U[  (UV$V &gt; 0.99)]) # 491 ( simulated )
</pre>
<p>If the variables were perfectly uncorrelated (<code class="reqn">\mathbf{P}(u,v)</code>, <code><a href="#topic+P">P</a></code>, <em>independence copula</em>) would be 519 <code class="reqn">+</code> 491 <code class="reqn">=</code> 1,007 losses. But for the simulations here, 799 losses occurred, so 1,007 <code class="reqn">-</code> 799 <code class="reqn">=</code> 208 losses were at the same time caused by <code class="reqn">U</code> and <code class="reqn">V</code>.
</p>
<p>Both of the following lengths <code>A</code> and <code>B</code> are 799 and both represent a <b>joint or</b> condition&mdash;the operations do not represent a <b>mutually exclusive or</b> condition.
</p>
<pre>
  A &lt;- length(UV$U[UV$U &gt; 0.99]) + length(UV$U[UV$V &gt; 0.99]) -
       length(UV$U[UV$U &gt; 0.99 &amp; UV$V &gt; 0.99])
  B &lt;- length(UV$U[UV$U &gt; 0.99 | UV$V &gt; 0.99]) # A == B == 799
</pre>
<p><em>ENSEMBLE 2&mdash;Simulation Study using a Real-World Sample Size:</em> Now with identities of sorts shown and described above, let us test a theoretically consistent version of a sample of size 150 repeated 1,000 times at the 98th percentile against loss by one or the other random variables or both for slightly correlated <code class="reqn">U</code> or <code class="reqn">V</code> again following the Gumbel&ndash;Hougaard copula. The losses incurred by mutual event occurrence is the same as if one or the other variables produced an event causing loss.
</p>
<pre>
  n &lt;- 250; nsim &lt;- 1000; EitherEvent &lt;- 0.98; MutualEvent &lt;- 0.99; Theta&lt;- 1.5
  PT &lt;- jointCOP(EitherEvent, cop=GHcop, para=Theta, type="and")[1] # 0.9873537
  DU &lt;- jointCOP(MutualEvent, cop=GHcop, para=Theta, type="or" )[1] # 0.9763951
</pre>
<p>This next code listing is a redundant example to the one that follows, but it is shown because a slight possibility of confusion in the vectorized conditional evaluations in <span class="rlang"><b>R</b></span>. This first example concretely changes the loss events into binary states and adds them up prior to the condition.
</p>
<pre>
  set.seed(894234)
  EX1a &lt;- sapply(1:nsim, function(i) {
                 uv &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
          length(uv$U[ as.numeric(uv$U &gt; PT) + as.numeric(uv$V &gt; PT) &gt;= 1 ]) })
  t.test(EX1a, mu=(1-EitherEvent) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX1a</code><code class="reqn">] =</code> 5 and the simulation run yielded 5.058. The <code>t.test()</code> function in <span class="rlang"><b>R</b></span> results in a statistically insignificant difference. The following two example use a similar there. For sake of both code brevity and clarity, the examples here all restart the simulations at the expense of computation time.
</p>
<pre>
  set.seed(894234)
  EX1b &lt;- sapply(1:nsim, function(i) {
                uv  &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
                length(uv$U[uv$U &gt; PT | uv$V &gt; PT])  })
  t.test(EX1b, mu=(1-EitherEvent) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX1b</code><code class="reqn">] =</code> 5&mdash;the same results are shown as in the first example listing.
</p>
<p>Next, let us demonstrate the dual of a copula for mutually occurring events.
</p>
<pre>
  set.seed(894234)
  EX2 &lt;- sapply(1:nsim, function(i) {
                uv  &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
                length(uv$U[uv$U &gt; DU &amp; uv$V &gt; DU]) })
  t.test(EX2, mu=(1-MutualEvent) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX2</code><code class="reqn">] =</code> 2.5 and the simulation run yielded 2.49. The <code>t.test()</code> again results in a statistically insignificant difference.
</p>
<p>The <code class="reqn">U = V = 0.9873537</code> for the &ldquo;and&rdquo; and <code class="reqn">U = V = 0.9763951</code> for the &ldquo;or&rdquo; are not equal marginal probabilities. Taking the larger of the two marginal probabilities, the actual joint protection from mutual event occurrance can be computed:
</p>
<pre>
  duCOP(0.9873537, 0.9873537, cop=GHcop, para=Theta) # 0.9947075
  (1-0.9947075)*n  # which is about 1.32 events per 250 trials.
</pre>
<p>So, the larger protection in terms of joint probabilities provided by <code>EitherEvent</code> at 0.98 instead of <code>MutualEvent</code> at 0.99 with respective protection at the 0.9873537 provides a <code>MutualEvent</code> protection of 0.9947075.
</p>
<pre>
  set.seed(894234)
  EX3 &lt;- sapply(1:nsim, function(i) {
                uv  &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
                length(uv$U[uv$U &gt; 0.9873537 &amp; uv$V &gt; 0.9873537]) })
  t.test(EX3, mu=(1-0.9947075) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX3</code><code class="reqn">] =</code> 1.32 and the simulation run yielded 1.31. The <code>t.test()</code> again results in a statistically insignificant difference, and thus the result indistinguishable from the expectation.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagCOPatf">diagCOPatf</a></code>, <code><a href="#topic+duCOP">duCOP</a></code>, <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code>, <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>jointCOP(0.50, cop=GHcop, para=1.5, type="and") # 0.6461941  0.6461941  0.5000000
jointCOP(2/3,  cop=GHcop, para=1.5, type="or" ) # 0.4994036  0.4994036  0.6666667

# See extended code listings and discussion in the Note section
</code></pre>

<hr>
<h2 id='kfuncCOP'>The Kendall (Distribution) Function of a Copula</h2><span id='topic+kfuncCOP'></span><span id='topic+kmeasCOP'></span>

<h3>Description</h3>

<p>To begin, there are at least three terms in the literature for what appear as the same function supported by the <code>kfuncCOP</code> function. The <em>Kendall Function</em> also is known as <em>Kendall Distribution Function</em> (Nelsen, 2006, p. 163) and <em>Kendall Measure</em> (Salvadori <em>et al.</em>, 2007, p. 148). Each of these is dealt with in sequel to set the manner of the rather lengthy documentation for this function.
</p>
<p><em>KENDALL FUNCTION</em>&mdash;The <em>Kendall Function</em> (<code class="reqn">F_K</code>) (Joe, 2014, pp. 419&ndash;422) is the cumulative distribution function (CDF) of the vector <code class="reqn">\mathbf{U} = (U_1, U_2, \ldots)</code> or <code class="reqn">\mathbf{U} = (u,v)</code> (bivariate) where <code class="reqn">\mathbf{U}</code> is distributed as the copula: <code class="reqn">\mathbf{U} \sim \mathbf{C}(u,v)</code>. Letting <code class="reqn">Z</code> be the random variable for <code class="reqn">\mathbf{C}(u,v): Z = \mathbf{C}(u,v)</code>, the Kendall Function is defined as
</p>
<p style="text-align: center;"><code class="reqn">F_K(z; \mathbf{C}) = \mathrm{Pr}[Z \le z; \mathbf{U} \sim \mathbf{C}(u,v)]\mbox{,}</code>
</p>

<p>where <code class="reqn">F_K</code> is the nonexceedance probability of the joint probability <code class="reqn">z</code> stemming from the <code class="reqn">\mathbf{C}</code>. Note, unlike its univariate counterpart, <code class="reqn">F_K(z)</code> is rarely uniformly distributed (Nelsen <em>et al.</em>, 2001, p. 278). The inverse <code class="reqn">F_K^{(-1)}(z)</code> is implemented by the <code><a href="#topic+kfuncCOPinv">kfuncCOPinv</a></code> function, which could be used for simulation of the correct joint probability using a single unformly distributed <code class="reqn">\sim</code> U(0,1) random variable. A reminder is needed that <code class="reqn">Z</code> is the <b>joint probability</b> and <code class="reqn">F_K(z)</code> is the Kendall Function.
</p>
<p>Joe (2014) and others as cited list various special cases of <code class="reqn">F_K(z)</code>, inequalities, and some useful identities suitable for validation study:<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For <code class="reqn">\mathbf{M}(u,v)</code> (see <code><a href="#topic+M">M</a></code>): <code class="reqn">F_K(z) = z</code> for all <code class="reqn">0 &lt; z &lt; 1</code> for all <code class="reqn">d \ge 2</code> dimensions;<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For <code class="reqn">\mathbf{W}(u,v)</code> (see <code><a href="#topic+W">W</a></code>): <code class="reqn">F_K(z) = 1</code> for all <code class="reqn">0 &lt; z &lt; 1</code> for <code class="reqn">d = 2</code> (bivariate only);<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For <code class="reqn">\mathbf{\Pi}(u,v)</code> (see <code><a href="#topic+P">P</a></code>): <code class="reqn">F_K(z) = z - z \log z</code> for <code class="reqn">0 &lt; z &lt; 1</code> for <code class="reqn">d = 2</code> (bivariate only);<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For any <code class="reqn">\mathbf{C}</code>: <code class="reqn">z \le F_K(z)</code> for <code class="reqn">0 &lt; z &lt; 1</code>; and<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For any <code class="reqn">\mathbf{C}</code>: <code class="reqn">\mathrm{E}[Z] = 1 - \int_0^1 F_K(t)\,\mathrm{d}t \ge z</code> (Nelsen, 2001, p. 281) &mdash; Z expectation, not <code class="reqn">F_K</code>!<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For any <code class="reqn">\mathbf{C}</code>: <code class="reqn">\tau_\mathbf{C} = 3 - 4\int_0^1 F_K(t)\,\mathrm{d}t</code> (Nelsen, 2006, p. 163; see <code><a href="#topic+tauCOP">tauCOP</a></code> [<b>Examples</b>]).<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>For any <code class="reqn">\mathbf{C}</code>: <code class="reqn">F_K(t)</code> does not uniquely determine the copula.
</p>
<p>The last item is from Durante and Sempi (2015, p. 118), and later discussion herein will concern an example of theirs. By coincidence within a few days before receipt of the Durante and Sempi book, experiments using <code>kfuncCOP</code> suggested that numerically the Galambos (<code><a href="#topic+GLcop">GLcop</a></code>), Gumbel&ndash;Hougaard (<code><a href="#topic+GHcop">GHcop</a></code>), and Hüsler&ndash;Reiss (<code><a href="#topic+HRcop">HRcop</a></code>) extreme value copulas for the same <em>Kendall Tau</em> (<code class="reqn">\tau_\mathbf{C}</code>) all have the same <code class="reqn">F_K(t)</code>. Therefore, do all <em>EV</em>-copulas have the same Kendall Function? Well in fact, they do and Durante and Sempi (2015, p. 207) show that <code class="reqn">F_K(z) = z - (1 - \tau_\mathbf{C})z \log(z)</code> for an <em>EV</em>-copula.
</p>
<p>Joe (2014, p. 420) also indicates that strength of <em>lower-tail dependence</em> (<code><a href="#topic+taildepCOP">taildepCOP</a></code>) affects <code class="reqn">F_K(z)</code> as <code class="reqn">z \rightarrow 0^{+}</code>, whereas strength of <em>upper-tail dependence</em> affects <code class="reqn">F_K(z)</code> as <code class="reqn">z \rightarrow 1^{-}</code>. (A demonstration of tail dependence dependence is made in section <b>Note</b>.) Also compared to <em>comonotonicity copula</em> [<code class="reqn">\mathbf{M}</code>] there are no <em>countermonotonicity copula</em> (<code class="reqn">\mathbf{W}_{d &gt; 2}</code>) for dimensions greater the bivariate (Joe, 2014, p. 214)
</p>
<p>Joe (2014) does not explicitly list an expression of <code class="reqn">F_K(z)</code> that is computable directly for any <code class="reqn">\mathbf{C}(u,v)</code>, and Nelsen (2006, p. 163) only lists a form (see later in documentation) for <em>Archimedean copulas</em>. Salvadori <em>et al.</em> (2007, eq. 3.47, p. 147) also list the Archimedean form; however, Salvadori <em>et al.</em> (2007, eq. 3.49, p. 148) <b>also list a form computable directly for any</b> <code class="reqn">\mathbf{C}(u,v)</code>. Considerable numerical experiments and derivations involving the <code class="reqn">\mathbf{\Pi}(u,v)</code> copula and results for <code class="reqn">K_\mathbf{C}(z)</code> shown later, indicate that the correct Kendall form for any <code class="reqn">\mathbf{C}(u,v)</code> is
</p>
<p style="text-align: center;"><code class="reqn">F_K(z) \equiv z + \int_z^1 \frac{\delta\mathbf{C}(u,t)}{\delta u}\,\mathrm{d}u\mbox{,}</code>
</p>

<p>where <code class="reqn">t = \mathbf{C}^{(-1)}(u,z)</code> for <code class="reqn">0 \le z \le 1</code>, <code class="reqn">t</code> can be computed by the <code><a href="#topic+COPinv">COPinv</a></code> function, and the partial derivative <code class="reqn">\delta\mathbf{C}(u,t)/\delta u</code> can be computed by the <code><a href="#topic+derCOP">derCOP</a></code> function. It is a curiosity that this form is not in Joe (2014), Nelsen <em>et al.</em> (2001, 2003), or Nelsen (2006), but actually in Salvadori <em>et al.</em> (2007).<br />
</p>
<p><em>KENDALL MEASURE</em>&mdash;The actual expression for any <code class="reqn">\mathbf{C}(u,v)</code> by Salvadori <em>et al.</em> (2007, eq. 3.49, p. 148) is for <em>Kendall Measure</em> (<code class="reqn">K_\mathbf{C}</code>) of a copula:
</p>
<p style="text-align: center;"><code class="reqn">K_\mathbf{C}(z) = z - \int_z^1 \frac{\delta\mathbf{C}(u,t)}{\delta u}\,\mathrm{d}u\mbox{,}</code>
</p>

<p>where <code class="reqn">t = \mathbf{C}^{(-1)}(u,z)</code> for <code class="reqn">0 \le z \le 1</code>. Those authors report that <code class="reqn">K_\mathbf{C}(z)</code> is the CDF of a random variable <code class="reqn">Z</code> whose distribution is <code class="reqn">\mathbf{C}(u,v)</code>. This is clearly appears to be the same meaning as Joe (2014) and Nelsen (2006). The minus &ldquo;<code class="reqn">-</code>&rdquo; in the above equation is very important.
</p>
<p>Salvadori <em>et al.</em> (2007, p. 148) report that &ldquo;the function <code class="reqn">K_\mathbf{C}(z)</code> represents a fundamental tool for calculating the return period of extreme events.&rdquo; The complement of <code class="reqn">K_\mathbf{C}(z)</code> is <code class="reqn">\overline{K}_\mathbf{C}(z) = 1 - K_\mathbf{C}(z)</code>, and the <code class="reqn">\overline{K}_\mathbf{C}(z)</code> inverse
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{1 - K_\mathbf{C}(z)} = \frac{1}{\overline{K}_\mathbf{C}(z)} = T_{\mathrm{KC}}</code>
</p>

<p>is referred to as a <em>secondary return period</em> (Salvadori <em>et al.</em>, 2007, pp. 161&ndash;170).<br />
</p>
<p><em>KENDALL DISTRIBUTION FUNCTION</em>&mdash;Nelsen (2006, p. 163) defines the <em>Kendall Distribution Function</em> (say <code class="reqn">K^\star_\mathbf{C}(t)</code>) as
</p>
<p style="text-align: center;"><code class="reqn">K^\star_\mathbf{C}(t) = t - \frac{\phi(t)}{\phi'(t^{+})}\mbox{,}</code>
</p>

<p>where <code class="reqn">\phi(t)</code> is a <em>generator function</em> of an <em>Archimedean copula</em> and <code class="reqn">\phi'(t^{+})</code> is a one-sided derivative (Nelsen, 2006, p. 125), and <code class="reqn">\phi(t)</code> is <code class="reqn">\phi(\mathbf{C}(u,v)) = \phi(u) + \phi(v)</code>. This same form is listed by Salvadori <em>et al.</em> (2007, eq. 3.47).
</p>
<p>Nelsen (2006) does not seem to list a more general definition for any <code class="reqn">\mathbf{C}(u,v)</code>. Because there is considerable support for Archimedean copulas in <span class="rlang"><b>R</b></span>, <span class="pkg">copBasic</span> has deliberately been kept from being yet another Archimedean-based package. This is made for more fundamental theory and pedogogic reasons without the algorithmic efficiency relative to the many convenient properties of Archimedean copulas.
</p>
<p>The similarity of <code class="reqn">F_K(z)</code>, <code class="reqn">K_\mathbf{C}(z)</code>, and <code class="reqn">K^\star_\mathbf{C}(t)</code>, however, is obvious&mdash;research shows that there are no syntatic differences between <code class="reqn">F_K(z)</code> and <code class="reqn">K_\mathbf{C}(t)</code> and <code class="reqn">K^\star_\mathbf{C}(z)</code>&mdash;they all are the CDF of the joint probability <code class="reqn">Z</code> of the copula. Consider now that Salvadori <em>et al.</em> show <code class="reqn">K_\mathbf{C}</code> having the form <code class="reqn">a - b</code> and not a form <code class="reqn">a + b</code> as previously shown for <code class="reqn">F_K(z)</code>. Which form is thus correct? The greater bulk of this documentation seeks to answer that question, and it must be concluded that Salvadori <em>et al.</em> (2007, eq. 3.49) definition for <code class="reqn">K_\mathbf{C}(z)</code> has a typesetting error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfuncCOP(z, cop=NULL, para=NULL, wrtV=FALSE, as.sample=FALSE,
            verbose=FALSE, subdivisions=100L,
            rel.tol=.Machine$double.eps^0.25, abs.tol=rel.tol, ...)
kmeasCOP(z, cop=NULL, para=NULL, wrtV=FALSE, as.sample=FALSE,
            verbose=FALSE, subdivisions=100L,
            rel.tol=.Machine$double.eps^0.25, abs.tol=rel.tol, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfuncCOP_+3A_z">z</code></td>
<td>
<p>The values for <code class="reqn">z</code>;</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_wrtv">wrtV</code></td>
<td>
<p>A logical to toggle between with respect to <code class="reqn">v</code> or <code class="reqn">u</code> (default);</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A control on whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the empirical <code class="reqn">\hat{F}_K(z)</code>. Let vector length of <code>para</code> be denoted <code class="reqn">m</code> and <code class="reqn">i = (1,\ldots,m)</code>, if <code>as.sample=TRUE</code>, then for each of the probability pairs in <code>para</code>, the <em>empirical copula</em> (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>) function with additional arguments <code>...</code> is used to generate a vector <code class="reqn">(0, F^\sharp_{K,m}, 1)</code> of length <code class="reqn">m+2</code>, then a vector of <code class="reqn">(0, z^\sharp_m, 1)</code> again of length <code class="reqn">m+2</code> where <code class="reqn">z^\sharp = (i-0.5)/m</code> is created and linear interpolation by the <code>approx()</code> function in <span class="rlang"><b>R</b></span> for each of the <code class="reqn">z</code> values in <code>z</code> is used to estimate <code class="reqn">\hat{F}_K(z)</code> (see source code). If <code>as.sample="genest"</code>, then the <code class="reqn">\hat{F}_K(z)</code> is estimated without interpolation using a simple empirical copula basis and &ldquo;pseudo-observations&rdquo; after Genest <em>et al.</em> (2006, p. 339). The default <code class="reqn">\hat{F}_K</code> (<code>as.sample=TRUE</code>) is the linear interpolation based on the default call of Weibull form of the empirical copula, but that can be confirmed by <code>ctype="weibull"</code> (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_verbose">verbose</code></td>
<td>
<p>A logical supressing warnings from <code>integrate()</code> in <span class="rlang"><b>R</b></span> that are usually related to &ldquo;integral divergence&rdquo; for <code class="reqn">z \rightarrow 0^{+}</code>. The constructed behavior of <code>kfuncCOP</code> is to return <code class="reqn">F_K(z \rightarrow 0^{+}) = 0</code> if numerical integration returns <code>NULL</code>, and such a construction is made to avoid &ldquo;end points not of opposite sign&rdquo; during <code class="reqn">F_K(z)</code> inversion by <code><a href="#topic+kfuncCOPinv">kfuncCOPinv</a></code>;</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_subdivisions">subdivisions</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>,</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>,</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_abs.tol">abs.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code>, and</p>
</td></tr>
<tr><td><code id="kfuncCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value(s) for <code class="reqn">F_K(z)</code> is returned.
</p>


<h3>Note</h3>

<p><em>VALIDATION STUDY</em>&mdash;A validation study using the <em>Independence copula</em> (<code class="reqn">\mathbf{\Pi =}</code> <code class="reqn">uv</code>; <code><a href="#topic+P">P</a></code>) with theoretical results of Joe (2014) and empiricism is readily performed using the expression for <code class="reqn">F_K(z)</code>:
</p>
<pre>
  Z &lt;- sort(c(0.01, seq(0,1, by=0.05), 0.99))       # ** Joint probabilities **
  UV &lt;- simCOP(n=4000, cop=P, graphics=FALSE);      kendF &lt;- Z - Z*log(Z)
  emp.kendF  &lt;- kfuncCOP(Z, para=UV, as.sample="genest") # emp. Kendall func
  theo.kendF &lt;- kfuncCOP(Z, cop=P) # theo. Kendall func, numeric integration
  plot(Z, kendF, type="l", col=3, lwd=4, lty=2, xlim=c(0,1), ylim=c(0,1),
       xlab="COPULA(u,v) VALUE [JOINT PROBABILITY]",
       ylab="KENDALL FUNCTION, AS NONEXCEEDANCE PROBABILITY") # analytical
  points(Z,     kendF, col="green", lwd=1, lty=2, pch=16) # theoretical values
  points(Z, emp.kendF, col="blue" , lwd=2, cex=1.5)       #  empirical  values
  lines(Z, theo.kendF, col="red")  # theoretical line by numerical integration
  mtext("Kendall Functions: Independence Copula")
</pre>
<p>The figure produced shows that the theoretical relation in Joe (2014) is correct because the empirical values from the simulated sample (<em>Empirical Kendall Function</em>; Nelsen <em>et al.</em>, 2003) match other curves quite well. Rerunning the above code with either <code class="reqn">\mathbf{M}</code> (<code><a href="#topic+M">M</a></code>) or <code class="reqn">\mathbf{W}</code> (<code><a href="#topic+W">W</a></code>) copulas will show that the special cases listed above are consistent with the empirical estimates. The case of <code class="reqn">\mathbf{W}(u,v)</code> is degenerate at <code class="reqn">z=0</code>; so, the empirical computation is in error for the smallest <code class="reqn">z</code> given because of interpolation. The <code class="reqn">\mathbf{M}</code> copula has <code class="reqn">F_K</code> along the equal value line (1:1) line.
</p>
<p>Now, consider a more comprehensive demonstration using the <code><a href="#topic+N4212cop">N4212cop</a></code> copula with some relatively weak dependence in <code class="reqn">\Theta = 1.17</code>.
</p>
<pre>
  Theta &lt;- 1.17; print(rhoCOP(cop=N4212cop, para=Theta)) # Spearman Rho = 6/10
  Z &lt;- sort(c(0.01, seq(0,1, by=0.05), 0.99))      # ** Joint probabilities **
  UV &lt;- simCOP(n=16000,      cop=N4212cop,   para=Theta, graphics=TRUE)
  empir.kendF &lt;- kfuncCOP(Z, as.sample=TRUE, para=UV, ctype="weibull")
  kwrtU       &lt;- kfuncCOP(Z, cop=N4212cop,   para=Theta, wrtV=FALSE)
  kwrtV       &lt;- kfuncCOP(Z, cop=N4212cop,   para=Theta, wrtV=TRUE )
  plot(Z, empir.kendF, type="p", col=2, lwd=7, lty=2, xlim=c(0,1),ylim=c(0,1),
       xlab="COPULA(u,v) VALUE [JOINT PROBABILITY]",
       ylab="KENDALL FUNCTION, AS NONEXCEEDANCE PROBABILITY")
  abline(0,1, lty=2, lwd=0.8); mtext("Kendall Functions: N4212(1.17) Copula")
  lines(Z, kwrtU, col="blue" , lwd=4, lty=2)
  lines(Z, kwrtV, col="green", lwd=1, lty=2)
</pre>
<p>The figure produced again shows congruence between the two theoretical computations and the empirical curve. Now, consider another comprehensive demonstration using the <code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code> copula with some strong negative dependence in <code class="reqn">\Theta = 0.04</code>.
</p>
<pre>
  Theta &lt;- 0.04
  Z &lt;- sort(c(0.01, seq(0,1, by=0.05), 0.99))      # ** Joint probabilities **
  UV &lt;- simCOP(n=2600,       cop=PLACKETTcop,   para=Theta, graphics=TRUE)
  empir.kendF &lt;- kfuncCOP(Z, as.sample="hazen", para=UV)
  kwrtU       &lt;- kfuncCOP(Z, cop=PLACKETTcop,   para=Theta, wrtV=FALSE)
  kwrtV       &lt;- kfuncCOP(Z, cop=PLACKETTcop,   para=Theta, wrtV=TRUE )
  plot(Z, empir.kendF, type="p", col=2, lwd=7, lty=2, xlim=c(0,1),ylim=c(0,1),
       xlab="COPULA(u,v) VALUE [JOINT PROBABILITY]",
       ylab="KENDALL FUNCTION, AS NONEXCEEDANCE PROBABILITY")
  abline(0,1, lty=2, lwd=0.8); mtext("Kendall Function: Plackett Copula")
  lines(Z, kwrtU, col=4, lwd=4, lty=2); lines(Z, kwrtV, col=3, lwd=1, lty=2)
</pre>
<p>The figure so produced again shows congruence between the two theoretical computations and the empirical curve.
</p>
<p>Another comparison of <code class="reqn">F_K(z)</code> is useful and concerns <em>lower-</em> and <em>upper-tail dependency</em> parameters (<code><a href="#topic+taildepCOP">taildepCOP</a></code>) with a comparison of three different copula all having the same Kendall Tau. The following code computes and draws the respective <code class="reqn">F_K(z)</code>:
</p>
<pre>
  # Given a Kendall Tau of 0.4 and the GHcop, N4212, and Plackett copulas
  # parameters respectively are:
  Phi &lt;- 1.666667; Nu &lt;- 1.111119; Mu &lt;- 6.60344
  Z &lt;- seq(0.005, 0.995, by=0.005) #  ** Joint probabilities **
  GHkenf    &lt;- kfuncCOP(Z, cop=GHcop,       para=Phi, wrtV=FALSE)
  N4212kenf &lt;- kfuncCOP(Z, cop=N4212cop,    para=Nu,  wrtV=FALSE)
  PLkenf    &lt;- kfuncCOP(Z, cop=PLACKETTcop, para=Mu,  wrtV=FALSE)
  plot(qnorm(GHkenf), Z, type="l", col=1, lwd=2, xlim=c(-3,3), ylim=c(0,1),
       xlab="KENDALL FUNCTION, AS STANDARD NORMAL VARIATES",
       ylab="COPULA(u,v) VALUE, AS NONEXCEEDANCE PROBABILITY") # black curve
  lines(qnorm(N4212kenf), Z, col=2, lwd=2)                     # red   curve
  lines(qnorm(PLkenf),    Z, col=4, lwd=2)                     # blue  curve
</pre>
<p>The red curve for the <code class="reqn">\mathbf{N4212}(\Theta{=}1.1)</code> copula (<code><a href="#topic+N4212cop">N4212cop</a></code>) is higher on the left, which shows the impact of its larger lower-tail dependency (<code class="reqn">\lambda_\mathbf{GH}^L{=}0 &lt; \lambda_\mathbf{N4212}^L{=}0.535</code>), whereas the black curve for the <code class="reqn">\mathbf{GH}(\Theta{=}1.67)</code> copula (<code><a href="#topic+GHcop">GHcop</a></code>) is similarly (about same magnitude) higher on the right, which shows the impact of its larger upper-tail dependency (<code class="reqn">\lambda_\mathbf{N4212}^L{=}0 &lt; \lambda_\mathbf{GH}^U{=}0.484</code>). The blue curve for the <code class="reqn">\mathbf{PL}(\Theta = 6.60)</code> copula (<code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>) nearly overwrites on the left the <code class="reqn">\mathbf{GH}</code> curve, which is a reflection of both copulae having zero lower-tail dependencies (<code class="reqn">\lambda_\mathbf{GH}^L = \lambda_\mathbf{PL}^L = 0</code>). Finally, as anticipated by <code class="reqn">\lambda^U</code>, the curve on the right for the <code class="reqn">\mathbf{N4212}</code> is just slightly larger for the <code class="reqn">\mathbf{PL}</code> because the <code class="reqn">\lambda_\mathrm{PL}^U{=}0 &lt; \lambda_\mathbf{N4212}^U{=}0.134</code> (a small difference however), and again on the right, the <code class="reqn">\mathbf{N4212}</code> curve is considerably smaller than the <code class="reqn">\mathbf{GH}</code> because <code class="reqn">\lambda_\mathbf{N4212}^U{=}0 &lt; \lambda_\mathbf{GH}^U{=}0.484</code>.
</p>
<p>Durante and Sempi (2015, p. 118) provide an example of two copula (<code class="reqn">\mathbf{C}_1</code> and <code class="reqn">\mathbf{C}_2</code>) having the same <code class="reqn">F_K(z) = \mathrm{min}(2z, 1)</code>. Let us check that out:
</p>
<pre>
  "C1" &lt;- function(u,v, ...) {
      if (length(u) == 1) { u &lt;- rep(u, length(v)) } else
      if (length(v) == 1) { v &lt;- rep(v, length(u)) }
      sapply(1:length(u), function(i) {
            min(c(u[i], max(c(v[i]/2, u[i]+v[i]-1)))) })
  }
  "C2" &lt;- function(u,v, ...) {
      if (length(u) == 1) { u &lt;- rep(u, length(v)) } else
      if (length(v) == 1) { v &lt;- rep(v, length(u)) }
      sapply(1:length(u), function(i) { g &lt;- 1/2
       max(c(0, u[i]+v[i]-1, min(c(u[i], v[i]-g)), min(c(u[i]-g, v[i])))) })
  }
  DSkf &lt;- function(t) sapply(t, function(z) min(c(2*z, 1)))
  zs &lt;- seq(0,1, by=.01); plot(zs, DSkf(zs), col=2, cex=3) # red dots (theory)
  lines(zs, kfuncCOP(zs, cop=C1), lwd=4, col=7) # thick yellow line
  lines(zs, kfuncCOP(zs, cop=C2), lwd=1, col=1) # thin black line
</pre>
<p>The plot so produced shows indeed that the numerical operations by <code>kfuncCOP</code> solidly work on these two strictly singular copulas <code class="reqn">\mathbf{C}_1</code> and <code class="reqn">\mathbf{C}_2</code> that are different from the two singular <code class="reqn">\mathbf{M}</code> and <code class="reqn">\mathbf{W}</code> copulas. The <code class="reqn">F_K(z)</code> curves exactly matching the theoretical curve provided by Durante and Sempi are produced.
</p>
<p><em>CONVERSATIONAL ASIDE</em>&mdash;Interestingly, Durante and Sempi (2015, pp. 115&ndash;121), like other authors of major works cited herein, do not list a general expression for the <code class="reqn">F_K(z)</code> as a function of any <code class="reqn">\mathbf{C}(u,v)</code>. Those authors well develop the idea of Kendall Function and show results, but for the author (Asquith), the jump based of Theorem 3.9.2 to an expression, such as shown above for <code class="reqn">F_K(z)</code> based on <code class="reqn">\mathbf{C}(u,t)/\delta u</code>, as an usable form for any <code class="reqn">\mathbf{C}(u,v)</code> is difficult.
</p>
<p>This is a fascinating topic because, if the Kendall Function is a reasonably important component of copula theory, then why so much difficulty in finding a canonical reference? For this one piece, whereas so much of <span class="pkg">copBasic</span> features are quite nomenclaturely clear in say Nelsen (2006) or Joe (2014) but somehow not for the Kendall Function.
</p>
<p>Perhaps to the professional mathematicians, the descriptions (nomenclature) used in all but Salvadori <em>et al.</em> (2007) are clear to intended readers. But even Salvadori <em>et al.</em> seemingly show theirs in error&mdash;perhaps the author (Asquith) has missed something fundamental, but the validations shown in this documentation prove at least that <code>kfuncCOP</code> does what it is supposed to be doing but perhaps for the wrong reasoning. Lastly, Durante and Sempi have an error in their expression for Kendall Tau as a function of <code class="reqn">F_K(z)</code> (see <code><a href="#topic+tauCOP">tauCOP</a></code>).
</p>
<p><em>SECONDARY RETURN PERIOD</em>&mdash;As for &ldquo;Kendall Measure&rdquo; (after the lead of Salvadori <em>et al.</em> [2007, pp. 161&ndash;170]), the following code shows for purposes of discussing <em>secondary return period</em> that <code class="reqn">F_K(z)</code> is correct and once and for all as defined in this documentation <code class="reqn">F_K(z) \not\equiv  K_\mathbf{C}(z)</code>. The secondary return period (<code class="reqn">T_K</code>) is the expected interarrival time between events exceeding a <code class="reqn">T</code>-year joint probability either from <code class="reqn">U</code>, from <code class="reqn">V</code>, or both. Let us use the 100-year level (primary return period; <code class="reqn">T = 100</code>), the Gumbel&ndash;Hougaard copula (<code><a href="#topic+GHcop">GHcop</a></code>) <code class="reqn">F^{\mathbf{GH}(3.055)}_K(z)</code> where the choice of <code class="reqn">\Theta = 3.055</code> is made to match discussion in <code><a href="#topic+copBasic-package">copBasic-package</a></code> and Salvadori <em>et al.</em> (2007, table 3.3, p. 166).
</p>
<pre>
  # Gumbel-Hougaard [Kendall Tau=0.67267 (Salvadori et al. [2007])]
  Tyear &lt;- 100; ANEP &lt;- 1-1/Tyear; nsim &lt;- 30000; ix &lt;- 1:nsim
  1/(1-kfuncCOP(ANEP, cop=GHcop, para=3.055)) # 148.28 years
  BarT &lt;- sapply(1:20, function(i) {
                   UV &lt;- simCOP(n=nsim, cop=GHcop, para=3.055, graphics=FALSE)
                   nsim/sum(GHcop(UV$U, UV$V, para=3.055) &gt; ANEP) })
  message("# BarBarT=",               round(mean(BarT), digits=2),
          " years and StdDev(BarT)=", round(  sd(BarT), digits=2)," years")
  # BarBarT=149.61 years and StdDev(BarT)=11.12 years
</pre>
<p>The mean of some 20 repeats of a large sample simulation run for <code class="reqn">F^\mathbf{GH}(\Theta{=}3.055)_K{(z{=}0.99)}</code> demonstrates empirical results that closely approximate theory <code class="reqn">149.61 \approx 148.28</code>, and thus congruence is shown that the definition for <code class="reqn">F_K(z)</code> must be correct and that for <code class="reqn">K_\mathbf{C}(z)</code> is incorrect. The table 3.3 in Salvadori <em>et al.</em> (2007, table 3.3) lists the secondary return period as 148.3 years, which matches the output of <code>kfuncCOP</code> and empirical results shown.
</p>
<p>Some additional details on secondary return period from Salvadori <em>et al.</em> (2007). Letting <code class="reqn">t_\star</code> be some critical joint exceedance probability level, <code class="reqn">\overline{F}_K(z)</code> be the complement of <code class="reqn">F_K(z)</code>, those authors (p. 166) name <em>super-critical events</em> having <code class="reqn">\overline{F}_K(t_\star) &lt; 1 - t_\star</code>. Thus, the secondary return period  (<code class="reqn">\overline{F}_K(t_\star)^{-1} = T_K</code>) must be greater than the primary return period (<code class="reqn">t_\star^{-1}</code>), which is the case here (<code class="reqn">T_K{=}148.3 &gt; T{=}100</code>) (Salvadori <em>et al.</em>, 2007, p. 166).
</p>
<p>Salvadori <em>et al.</em> (2007) provide considerable discussion of <code class="reqn">T_K</code> and some highlights are:<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>(p. 162) events equally or exceeding probability <code class="reqn">F_K(1 - 1/t_\star)</code> or having return intervals <code class="reqn">\ge T_K</code> &ldquo;represent [a] class of potentially dangerous events, the <em>outliers</em>, and [<code class="reqn">F_K</code> can be used to] introduce an <em>ad hoc</em> return period for such destructive events.&rdquo;<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>(p. 162) &ldquo;primary return period [<code class="reqn">T</code>] ... only takes into account the fact that a prescribed critical event is expected to appear once in a given time interval [<code class="reqn">T</code>] ... <code class="reqn">\overline{F}_K(t_\star)</code> provides the <em>exact probability</em> that a potentially destructive event will happen at any given realization of <code class="reqn">Z</code> ... and <code class="reqn">T_K</code> gives the expected time for such an outlier to occur.&rdquo;<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>(p. 164) &ldquo;[<code class="reqn">T</code>] only predicts that a critical event is <em>expected</em> to appear once in a given time interval ... would be more important to be able to calculate (1) the probability that a super-critical [sic.] event will occur at any given realization of [<code class="reqn">Z</code>], and (2) how long it takes, <em>on average</em>, for a super-critical event to appear.&rdquo;<br />
<code class="reqn">\mbox{}\quad\bullet\quad\mbox{}</code>(p. 164) &ldquo;the function <code class="reqn">\overline{F}_K</code> turns the difficult analysis of bivariate dynamics of <code class="reqn">X</code> and <code class="reqn">Y</code> into a simpler one-dimensional problem.&rdquo;
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Source</h3>

<p>The comprehensive demonstrations are shown in the <b>Note</b> because of a sign convention and (or) probability convention incompatibility with the equation shown by Salvadori <em>et al.</em> (2007, p. 148).  Initial source code development for <span class="pkg">copBasic</span> was based on an hypothesis that the terms the &ldquo;Kendall Function&rdquo; and &ldquo;Kendall Measure&rdquo; might somehow have separate meanings&mdash;that the author must be blamed for misunderstanding the requisite nomenclature&mdash;this is evidently not true.
</p>
<p>The <code class="reqn">K_\mathbf{C}(z)</code> as shown herein simply can not reproduce <code class="reqn">F_K(z; \mathbf{\Pi}) = z - z\log z</code> for the <code class="reqn">\mathbf{\Pi}</code> copula unless the &ldquo;<code class="reqn">-</code>&rdquo; sign in the <code class="reqn">K_\mathbf{C}(z)</code> equation is changed to a &ldquo;<code class="reqn">+</code>&rdquo; to become the <code class="reqn">F_K(z)</code> definition as shown. The detective work needed for a valid function <code>kmeasCOP</code> was further complicated by fact that neither Durante and Sempi (2015), Joe (2014), Nelsen (2006), and others do not actually present a general equation for <code class="reqn">F_K(z)</code> computation for any <code class="reqn">\mathbf{C}(u,v)</code>.
</p>
<p>Because of the subtle differences evidently between &ldquo;Kendall functions&rdquo; (lower case), an explict derivation for <code class="reqn">F_K(z; \mathbf{\Pi})</code> is informative to confirm what is meant by the <em>Kendall Function</em> as defined by <code class="reqn">F_K(z)</code>. Starting with <code class="reqn">z = \mathbf{\Pi}(u,v) = uv</code>, then </p>
<p style="text-align: center;"><code class="reqn">v(z) = t = \mathbf{\Pi}^{(-1)}(u, z) = z/u\mbox{,\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{\delta}{\delta u} \mathbf{\Pi}(u,t) = \frac{\delta }{\delta u} u\,v \rightarrow v = \frac{z}{u}\mbox{,}</code>
</p>

<p>substitution can now proceed:
</p>
<p style="text-align: center;"><code class="reqn">F_K(z; \mathbf{\Pi}) = z + \int_z^1 \frac{\delta}{\delta u}\mathbf{\Pi}(u,t)\,\mathrm{d}u\, = z + \int_z^1 \frac{z}{u}\,\mathrm{d}u{,}</code>
</p>

<p>which simplfies to
</p>
<p style="text-align: center;"><code class="reqn">F_K(z; \mathbf{\Pi}) = z + \bigl[z\log(u)\bigr]\bigg|^1_z  = z + z[\log(1) - \log(z)] = z - z\log z\mbox{,}</code>
</p>

<p>which matches the special case shown by Joe (2014) for the independence copula (<code class="reqn">\mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>). It is obvious thus that the &ldquo;<code class="reqn">+</code>&rdquo; is needed in the <code class="reqn">F_K(z)</code> definition in order to stay consistent with the basic form and integration limits shown by Salvadori <em>et al.</em> (2007) for <code class="reqn">K_\mathbf{C}(z)</code>.
</p>


<h3>References</h3>

<p>Durante, F., and Sempi, C., 2015, Principles of copula theory: Boca Raton, CRC Press, 315 p.
</p>
<p>Genest, C., Quessy, J.F., Rémillard, B., 2006, Goodness-of-fit procedures for copula models based on the probability integral transformation: Scandinavian Journal of Statistics, v. 33, no. 2, pp. 337&ndash;366.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Nelsen, R.B., Quesada-Molina, J.J., Rodríguez-Lallena, J.A., Úbeda-Flores, M., 2001, Distribution functions of copulas&mdash;A class of bivariate probability integral transforms: Statistics and Probability Letters, v. 54, no. 3, pp. 277&ndash;282.
</p>
<p>Nelsen, R.B., Quesada-Molina, J.J., Rodríguez-Lallena, J.A., Úbeda-Flores, M., 2003, Kendall distribution functions: Statistics and Probability Letters, v. 65, no. 3, pp. 263&ndash;268.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in nature&mdash;An approach using copulas: Dordrecht, Netherlands, Springer, Water Science and Technology Library 56, 292 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kfuncCOPinv">kfuncCOPinv</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+derCOP">derCOP</a></code>, <code><a href="#topic+derCOP2">derCOP2</a></code>, <code><a href="#topic+derCOPinv">derCOPinv</a></code>, <code><a href="#topic+derCOPinv2">derCOPinv2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Salvadori et al. (2007, p. 148, fig. 3.5 [right])
zs &lt;- c(0.0001, seq(0.01, 1, by=0.01), 0.9999)
plot(zs, kmeasCOP(zs, cop=GHcop, para=5), log="y", type="l", lwd=4,
     xlab="Z &lt;= z", ylab="Kendall Function", xlim=c(0,1), ylim=c(0.001,1)) #
## End(Not run)
</code></pre>

<hr>
<h2 id='kfuncCOPinv'>The Inverse Kendall Function of a Copula</h2><span id='topic+kfuncCOPinv'></span>

<h3>Description</h3>

<p>Compute the (numerical) inverse <code class="reqn">F^{(-1)}_K(z) \equiv z(F_K)</code> of the <em>Kendall Function</em> <code class="reqn">F_K(z; \mathbf{C})</code> (<code><a href="#topic+kfuncCOP">kfuncCOP</a></code>) of a copula <code class="reqn">\mathbf{C}(u,v)</code> given nonexceedance probability <code class="reqn">F_K</code>. The <code class="reqn">z</code> is the joint probability of the random variables <code class="reqn">U</code> and <code class="reqn">V</code> coupled to each other through the copula <code class="reqn">\mathbf{C}(u,v)</code> and the nonexceedance probability of the probability <code class="reqn">z</code> is <code class="reqn">F_K</code>&mdash;statements such as &ldquo;probabilities of probabilities&rdquo; are rhetorically complex so pursuit of word precision is made herein.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfuncCOPinv(f, cop=NULL, para=NULL, subdivisions=100L,
               rel.tol=.Machine$double.eps^0.25, abs.tol=rel.tol, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfuncCOPinv_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">(0 \le F_K \le 1)</code>;</p>
</td></tr>
<tr><td><code id="kfuncCOPinv_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="kfuncCOPinv_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="kfuncCOPinv_+3A_subdivisions">subdivisions</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code> through <code><a href="#topic+kfuncCOP">kfuncCOP</a></code>,</p>
</td></tr>
<tr><td><code id="kfuncCOPinv_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code> through <code><a href="#topic+kfuncCOP">kfuncCOP</a></code>,</p>
</td></tr>
<tr><td><code id="kfuncCOPinv_+3A_abs.tol">abs.tol</code></td>
<td>
<p>Argument of same name passed to <code>integrate()</code> through <code><a href="#topic+kfuncCOP">kfuncCOP</a></code>, and</p>
</td></tr>
<tr><td><code id="kfuncCOPinv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value(s) for <code class="reqn">z(F_K)</code> are returned.
</p>


<h3>Note</h3>

<p>The L-moments of Kendall Functions appear to be unresearched. Therefore, the <code><a href="#topic+kfuncCOPlmom">kfuncCOPlmom</a></code> and <code><a href="#topic+kfuncCOPlmoms">kfuncCOPlmoms</a></code> functions were written. These compute L-moments on the CDF <code class="reqn">F_K(z)</code> and not the quantile function <code class="reqn">z(F_K)</code> and thus are much faster than trying to use <code><a href="#topic+kfuncCOPinv">kfuncCOPinv</a></code> in the more common definitions of L-moments. A demonstration of the mean (first L-moment) of the Kendall Function numerical computation follows:
</p>
<pre>
  # First approach
  "afunc" &lt;- function(f) kfuncCOPinv(f, cop=GHcop, para=pi)
  integrate(afunc, 0, 1) # 0.4204238 with absolute error &lt; 2.5e-05
  # Second approach
  kfuncCOPlmom(1, cop=GHcop, para=pi)  # 0.4204222
</pre>
<p>where the first approach uses <code class="reqn">z(F_K)</code>, whereas the second method uses integration for the mean on <code class="reqn">F_K(z)</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kfuncCOP">kfuncCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Z &lt;- c(0,0.25,0.50,0.75,1) # Joint probabilities of a N4212cop
kfuncCOPinv(kfuncCOP(Z, cop=N4212cop, para=4.3), cop=N4212cop, para=4.3)
# [1] 0.0000000 0.2499984 0.5000224 0.7500112 1.0000000
## End(Not run)
</code></pre>

<hr>
<h2 id='kfuncCOPlmoms'>The L-moments of the Kendall Function of a Copula</h2><span id='topic+kfuncCOPlmoms'></span><span id='topic+kfuncCOPlmom'></span>

<h3>Description</h3>

<p>Compute the L-moments of the <em>Kendall Function</em> (<code class="reqn">F_K(z; \mathbf{C})</code>) of a copula <code class="reqn">\mathbf{C}(u,v)</code> where the <code class="reqn">z</code> is the joint probability of the <code class="reqn">\mathbf{C}(u,v)</code>. The Kendall Function (or <em>Kendall Distribution Function</em>) is the cumulative distribution function (CDF) of the joint probability <code class="reqn">Z</code> of the coupla. The expected value of the <code class="reqn">z(F_K)</code> (mean, first L-moment <code class="reqn">\lambda_1</code>), because <code class="reqn">Z</code> has nonzero probability for <code class="reqn">0 \le Z \le \infty</code>, is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{E}[Z] = \lambda_1 = \int_0^\infty \bigl[1 - F_K(t)\bigr]\,\mathrm{d}t = \int_0^1 \bigl[1 - F_K(t)\bigr] \,\mathrm{d}t\mbox{,}</code>
</p>

<p>where for circumstances here <code class="reqn">0 \le Z \le 1</code>. The <code class="reqn">\infty</code> is mentioned only because expectations of such CDFs are usually shown using <code class="reqn">(0,\infty)</code> limits, whereas integration of quantile functions (CDF inverses) use limits <code class="reqn">(0, 1)</code>. Because the support of <code class="reqn">Z</code> is <code class="reqn">(0, 1)</code>, like the probability <code class="reqn">F_K</code>, showing just it (<code class="reqn">\infty</code>) as the upper limit could be confusing&mdash;statements such as &ldquo;probabilities of probabilities&rdquo; are rhetorically complex. So, pursuit of word precision is made herein.
</p>
<p>An expression for <code class="reqn">\lambda_r</code> for <code class="reqn">r \ge 2</code> in terms of the <code class="reqn">F_K(z)</code> is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_r = \frac{1}{r}\sum_{j=0}^{r-2} (-1)^j {r-2 \choose j}{r \choose j+1} \int_{0}^{1} \! \bigl[F_K(t)\bigr]^{r-j-1}\times \bigl[1 - F_K(t)\bigr]^{j+1}\, \mathrm{d}t\mbox{,}
</code>
</p>

<p>where because of these circumstances the limits of integration are <code class="reqn">(0, 1)</code> and not <code class="reqn">(-\infty, \infty)</code> as in the usual definition of L-moments in terms of a distribution's CDF. (Note, such expressions did not make it into Asquith (2011), which needs rectification if that monograph ever makes it to a 2nd edition.)
</p>
<p>The mean, L-scale, coefficient of L-variation (<code class="reqn">\tau_2</code>, LCV, L-scale/mean), L-skew (<code class="reqn">\tau_3</code>, TAU3), L-kurtosis (<code class="reqn">\tau_4</code>, TAU4), and <code class="reqn">\tau_5</code> (TAU5) are computed. In usual nomenclature, the L-moments are
<code class="reqn"> \lambda_1 = \mbox{mean,}</code>
<code class="reqn"> \lambda_2 = \mbox{L-scale,}</code>
<code class="reqn"> \lambda_3 = \mbox{third L-moment,}</code>
<code class="reqn"> \lambda_4 = \mbox{fourth L-moment, and}</code>
<code class="reqn"> \lambda_5 = \mbox{fifth L-moment,}</code>
whereas the L-moment ratios are
<code class="reqn"> \tau_2 = \lambda_2/\lambda_1 = \mbox{coefficient of L-variation, }</code>
<code class="reqn"> \tau_3 = \lambda_3/\lambda_2 = \mbox{L-skew, }</code>
<code class="reqn"> \tau_4 = \lambda_4/\lambda_2 = \mbox{L-kurtosis, and}</code>
<code class="reqn"> \tau_5 = \lambda_5/\lambda_2 = \mbox{not named.}</code>
It is common amongst practitioners to lump the L-moment ratios into the general term &ldquo;L-moments&rdquo; and remain inclusive of the L-moment ratios. For example, L-skew then is referred to as the 3rd L-moment when it technically is the 3rd L-moment ratio. There is no first L-moment ratio (meaningless); so, results from <code>kfuncCOPlmoms</code> function will canoncially show a <code>NA</code> in that slot. The coefficient of L-variation is <code class="reqn">\tau_2</code> (subscript 2) and not <em>Kendall Tau</em> (<code class="reqn">\tau</code>). Sample L-moments are readily computed by several packages in <span class="rlang"><b>R</b></span> (<em>e.g.</em> <span class="pkg">lmomco</span>, <span class="pkg">lmom</span>, <span class="pkg">Lmoments</span>, <span class="pkg">POT</span>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfuncCOPlmom(r, cop=NULL, para=NULL, ...)

kfuncCOPlmoms(cop=NULL, para=NULL, nmom=5, begin.mom=1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfuncCOPlmoms_+3A_r">r</code></td>
<td>
<p>The <code class="reqn">r</code>th order of a single L-moment to compute;</p>
</td></tr>
<tr><td><code id="kfuncCOPlmoms_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="kfuncCOPlmoms_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="kfuncCOPlmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of L-moments to compute;</p>
</td></tr>
<tr><td><code id="kfuncCOPlmoms_+3A_begin.mom">begin.mom</code></td>
<td>
<p>The <code class="reqn">r</code>th order to begin the sequence <code>lambegr:nmom</code> for L-moment computation. The rarely used argument is means to bypass the computation of the mean if the user has an alternative method for the mean or other central tendency characterization in which case <code>begin.mom = 2</code>; and</p>
</td></tr>
<tr><td><code id="kfuncCOPlmoms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned by <code>kfuncCOPlmoms</code> and only the scalar value of <code class="reqn">\lambda_r</code> by <code>kfuncCOPlmom</code>.
</p>
<table role = "presentation">
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is <code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on;</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is <code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on; and</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;kfuncCOPlmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The L-moments of Kendall Functions appear to be not yet fully researched. An interesting research direction would be the trajectories of the L-moments or <em>L-moment ratio diagrams</em> for the Kendall Function and the degree to which distinction between copulas becomes evident&mdash;such diagrams are in wide-spread use for distinquishing between univariate distributions. It is noted, however, that <em>Kendall Function L-moment ratio diagrams</em> might be of less utility that in the univariate world&mdash;recalling that a univariate distribution is unique characteristized by its L-moments&mdash;because different copulas can have the same <code class="reqn">F_K(z)</code>, such as all bivariate extreme value copulas (see also <b>Examples</b>).
</p>
<pre>
  Rhos &lt;- c(0.001, 0.01, seq(0.05, 0.95, by=0.05), 0.99, 0.999)
  L1 &lt;- T2 &lt;- T3 &lt;- T4 &lt;- Thetas &lt;- vector(mode="numeric", length(Rhos))
  for(i in 1:length(Thetas)) {
     Thetas[i] &lt;- uniroot(function(p)
                 Rhos[i] - rhoCOP(cop=PARETOcop, para=p), c(0,200))$root
     message("Rho = ", Rhos[i], " and Pareto theta = ",
                                             round(Thetas[i], digits=4))
     lmr &lt;- kfuncCOPlmoms(cop=PARETOcop, para=Thetas[i], nmom=4)
     L1[i] &lt;- lmr$lambdas[1]; T2[i] &lt;- lmr$ratios[2]
     T3[i] &lt;- lmr$ratios[3];  T4[i] &lt;- lmr$ratios[4]
  }
  LMR &lt;- data.frame(Rho=Rhos, Theta=Thetas, L1=L1, T2=T2, T3=T3, T4=T4)
  plot(LMR$Rho, LMR$T2, ylim=c(-0.04, 0.5), xlim=c(0, 1),
       xlab="Spearman Rho or coefficient of L-variation",
       ylab="L-moment ratio", type="l", col="black")
  lines(LMR$Rho, LMR$T3, lty=1, col="red"         )
  lines(LMR$Rho, LMR$T4, lty=1, col="green"       )
  lines(LMR$T2,  LMR$T3, lty=2, col="blue"        )
  lines(LMR$T2,  LMR$T4, lty=2, col="deepskyblue2")
  lines(LMR$T3,  LMR$T4, lty=2, col="purple"      )
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kfuncCOP">kfuncCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
kfuncCOPlmom(1, cop=P) # 0.5 * 0.5 = 0.25 is expected joint prob. of independence
#[1] 0.2499999  (in agreement with theory)

ThetaGH &lt;- 4.21
Rho &lt;- rhoCOP(cop=GHcop, para=ThetaGH)
ThetaHR &lt;- uniroot(function(p) Rho - rhoCOP(cop=HRcop, para=p), c(0, 100))$root
ThetaHR &lt;- uniroot(function(p) Rho - rhoCOP(cop=HRcop, para=p), c(0, 100))$root
ThetaGL &lt;- uniroot(function(p) Rho - rhoCOP(cop=GLcop, para=p), c(0, 100))$root
ls.str(kfuncCOPlmoms(cop=GHcop, para=ThetaGH)) # Gumbel-Hougaard copula
# lambdas :  num [1:5] 0.440617 0.169085 0.011228 -0.000797 0.000249
# ratios  :  num [1:5]       NA 0.383750 0.066400 -0.004720 0.001470
#                               L-skew = 0.066400
ls.str(kfuncCOPlmoms(cop=HRcop, para=ThetaHR)) # Husler-Reiss copula
# lambdas :  num [1:5] 0.439627 0.169052 0.011427 -0.000785 0.000249
# ratios  :  num [1:5]       NA 0.384540 0.067590 -0.004640 0.001470
#                               L-skew = 0.067590
ls.str(kfuncCOPlmoms(cop=GLcop, para=ThetaGL)) # Galambos copula
# lambdas :  num [1:5] 0.440415 0.169079 0.011268 -0.000795 0.000248
# ratios  :  num [1:5]       NA 0.383910 0.066650 -0.004700 0.001470
#                               L-skew = 0.066650
# These L-moments are extremely similar and within the numerics used.
# Extreme value copula all have the same Kendall Distribution function.
## End(Not run)

## Not run: 
UV &lt;- simCOP(200, cop=PLcop, para=1/pi, graphics=FALSE)
theta &lt;- PLpar(UV[,1], UV[,2])
zs &lt;- c(0.001, seq(0.01, 0.99, by=0.01), 0.999) # for later

# Take the sample estimated parameter and convert to joint probabilities Z
# Convert the Z to the Kendall Function estimates again with the sample parameter
Z  &lt;- PLcop(UV[,1], UV[,2], para=theta); KF &lt;- kfuncCOP(Z, cop=PLcop, para=theta)

# Compute L-moments of the "Kendall function" and the sample versions
# and again see that the L-moment are for the distribution of the Z!
KNFlmr &lt;- kfuncCOPlmoms(cop=PLcop, para=theta); SAMlmr &lt;- lmomco::lmoms(Z)
knftxt &lt;- paste0("Kendall L-moments: ",
                 paste(round(KNFlmr$lambdas, digits=4), collapse=", "))
samtxt &lt;- paste0("Sample L-moments: " ,
                 paste(round(SAMlmr$lambdas, digits=4), collapse=", "))

plot(Z, KF, xlim=c(0,1), ylim=c(0,1), col="black",
     xlab="COPULA(u,v) VALUE [JOINT PROBABILITY]",
     ylab="KENDALL DISTRIBUTION FUNCTION (KDF), AS NONEXCEEDANCE PROBABILITY")
rug(Z, side=1, col="red", lwd=0.5); rug(KF, side=2, col="red", lwd=0.5) # rug plots
lines(zs, kfuncCOP(zs, cop=PLcop, para=1/pi), col="darkgreen")
knf_meanZ &lt;- KNFlmr$lambdas[1]; sam_meanZ &lt;- SAMlmr$lambdas[1]
knf_mean  &lt;- kfuncCOP(knf_meanZ, cop=PLcop, para=theta) # theo. Kendall function
sam_mean  &lt;- kfuncCOP(sam_meanZ, cop=PLcop, para=theta) # sam. est. of Kendall func
points(knf_meanZ, knf_mean, pch=16, col="blue", cex=3)
points(sam_meanZ, sam_mean, pch=16, col="cyan", cex=2)
lines(zs, zs-zs*log(zs), lty=2, lwd=0.8) # dash ref line for independence
text(0.2, 0.30, knftxt, pos=4, cex=1); text(0.2, 0.25, samtxt, pos=4, cex=1)
text(0.2, 0.18, paste0("Notice uniform distribution of vertical axis rug.\n",
                       "A Critical remark with respect to to KDFs."), cex=1, pos=4)
legend("bottomright", c("Independence copula", "KDF of Plackett copula",
                        "Theoretical mean", "Sample mean"), bty="n", y.intersp=1.5,
       lwd=c(1, 1, NA, NA), lty=c(2, 1, NA, NA), pch=c(NA, NA, 16, 16),
       col=c("black", "darkgreen", "blue", "cyan"), pt.cex=c(NA, NA, 3, 2)) #
## End(Not run)
</code></pre>

<hr>
<h2 id='kullCOP'>Kullback&ndash;Leibler Divergence, Jeffrey Divergence, and Kullback&ndash;Leibler Sample Size</h2><span id='topic+kullCOP'></span><span id='topic+kullCOPint'></span>

<h3>Description</h3>

<p>Compute the <em>Kullback&ndash;Leibler Divergence</em>, <em>Jeffrey Divergence</em>, and <em>Kullback&ndash;Leibler sample size</em> following Joe (2014, pp. 234&ndash;237). Consider two densities <code class="reqn">f = c_1(u,v; \Theta_f)</code> and <code class="reqn">g = c_2(u,v; \Theta_g)</code> for two different bivariate copulas <code class="reqn">\mathbf{C}_1(\Theta_1)</code> and <code class="reqn">\mathbf{C}_2(\Theta_2)</code> having respective parameters <code class="reqn">\Theta</code>, then the Kullback&ndash;Leibler Divergence of <code class="reqn">f</code> relative to <code class="reqn">g</code> is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{KL}(f {\mid} g) = \int\!\!\int_{\mathcal{I}^2} g\, \log(g/f)\,\mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>and Kullback&ndash;Leibler Divergence of <code class="reqn">g</code> relative to <code class="reqn">f</code> is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{KL}(g {\mid} f) = \int\!\!\int_{\mathcal{I}^2} f\, \log(f/g)\,\mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>where the limits of integration <code class="reqn">\mathcal{I}^2</code> theoretically are closed on <code class="reqn">[0,1]^2</code> but an open interval <code class="reqn">(0,1)^2</code> might be needed for numerical integration. Note, in general <code class="reqn">\mathrm{KL}(f {\mid} g) \ne \mathrm{KL}(g {\mid} f)</code>. The <code class="reqn">\mathrm{KL}(f {\mid} g)</code> is the expected log-likelihood ratios of <code class="reqn">g</code> to <code class="reqn">f</code> when <code class="reqn">g</code> is the true density (Joe, 2014, p. 234), whereas <code class="reqn">\mathrm{KL}(g {\mid} f)</code> is the opposite.
</p>
<p>This asymmetry leads to Jeffrey Divergence, which is defined as a symmetrized version of the two Kullback&ndash;Leibler Divergences, and is
</p>
<p style="text-align: center;"><code class="reqn">J(f,g) = \mathrm{KL}(f {\mid} g) + \mathrm{KL}(g {\mid} f) = \int\!\!\int_{\mathcal{I}^2} (g-f)\, \log(g/f)\,\mathrm{d}u\mathrm{d}v\mbox{.}</code>
</p>

<p>The variances of the Kullback&ndash;Leibler Divergences are defined as
</p>
<p style="text-align: center;"><code class="reqn">\sigma^2_{\mathrm{KL}(f {\mid} g)} = \int\!\!\int_{\mathcal{I}^2} g\,[\log(g/f)]^2\,\mathrm{d}u\mathrm{d}v - [\mathrm{KL}(f|g)]^2\mbox{,}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\sigma^2_{\mathrm{KL}(g {\mid} f)} = \int\!\!\int_{\mathcal{I}^2} f\,[\log(f/g)]^2\,\mathrm{d}u\mathrm{d}v - [\mathrm{KL}(g|f)]^2\mbox{.}</code>
</p>

<p>For comparison of copula families <code class="reqn">f</code> and <code class="reqn">g</code> and taking an <code class="reqn">\alpha = 0.05</code>, the Kullback&ndash;Leibler sample size is defined as
</p>
<p style="text-align: center;"><code class="reqn">n_{f\!g} = \bigl[\Phi^{(-1)}(1-\alpha) \times \eta_\mathrm{KL}\bigr]^2\mbox{,}</code>
</p>

<p>where <code class="reqn">\Phi^{(-1)}(t)</code> is the quantile function for the standard normal distribution <code class="reqn">\sim</code> N(0,1) for nonexceedance probability <code class="reqn">t</code>, and <code class="reqn">\eta_\mathrm{KL}</code> is the maximum of
</p>
<p style="text-align: center;"><code class="reqn">\eta_\mathrm{KL} = \mathrm{max}\bigl[\sigma_{\mathrm{KL}(f {\mid} g)}/\mathrm{KL}(f {\mid} g),\, \sigma_{\mathrm{KL}(g {\mid} f)}/\mathrm{KL}(g {\mid} f)\bigr]\mbox{.}</code>
</p>

<p>The <code class="reqn">n_{f\!g}</code> gives an indication of the sample size needed to distinguish <code class="reqn">f</code> and <code class="reqn">g</code> with a probability of at least <code class="reqn">1 - \alpha = 1 - 0.05 = 0.95</code> or 95 percent.
</p>
<p>The <span class="pkg">copBasic</span> features a naïve <em>Monte Carlo integration</em> scheme in the primary interface <code>kullCOP</code>, although the function <code>kullCOPint</code> provides for nested numerical integration. This later function is generally fast but suffers too much for general application from integral divergencies issued from the <code>integrate()</code> function in <span class="rlang"><b>R</b></span>&mdash;this must be judged in the light that the <span class="pkg">copBasic</span> package focuses only on implementation of the function of the copula itself and numerical estimation of copula density (<code><a href="#topic+densityCOP">densityCOP</a></code>) and not analytical copula densities or hybrid representations thereof. Sufficient &ldquo;bread crumbs&rdquo; are left among the code and documentation for users to re-implement if speed is paramount. Numerical comparison to the results of Joe (2014) (see <b>Examples</b>) suggests that the default Monte Carlo sample size should be more than sufficient for general inference with the expense of considerable CPU time; however, a couple of repeated calls of <code>kullCOP</code> would be advised and compute say the mean of the resulting sample sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kullCOP(cop1=NULL, cop2=NULL, para1=NULL, para2=NULL, alpha=0.05,
           del=0, n=1E5, verbose=TRUE, sobol=FALSE, scrambling=0, ...)

kullCOPint(cop1=NULL, cop2=NULL, para1=NULL, para2=NULL, alpha=0.05,
           del=.Machine$double.eps^0.25, verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kullCOP_+3A_cop1">cop1</code></td>
<td>
<p>A copula function corresponding to copula <code class="reqn">f</code> in Joe (2014);</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_para1">para1</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula <code class="reqn">f</code>;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_cop2">cop2</code></td>
<td>
<p>A copula function corresponding to copula <code class="reqn">g</code> in Joe (2014);</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_para2">para2</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula <code class="reqn">g</code>;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_alpha">alpha</code></td>
<td>
<p>The <code class="reqn">\alpha</code> in the Kullback&ndash;Leibler sample size equation;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_del">del</code></td>
<td>
<p>A small value used to denote the <code>lo</code> and <code>hi</code> values of the numerical integration: <code>lo = del</code> and <code>hi = 1 - del</code>. If <code>del == 0</code>, then <code>lo = 0</code> and <code>hi = 1</code>, which corresponds to the theoretical limits <code class="reqn">\mathcal{I}^2 = [0,1]^2</code> and are defaulted here to <code class="reqn">[0,1]^2</code> because the Monte Carlo algorithm is preferred for general application. The end point control, however, is maintained just in case pathological situations should arise;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_n">n</code></td>
<td>
<p><code>kullCOP</code> (Monte Carlo integration) only&mdash;the Monte Carlo integration simulation size;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_verbose">verbose</code></td>
<td>
<p>A logical trigging a couple of status lines of output through the <code>message()</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_sobol">sobol</code></td>
<td>
<p>A logical trigging <em>Sobol sequences</em> for the Monte Carlo integration instead of the bivariate uniform distribution. The Sobol sequences are dependent on the <span class="pkg">randtoolbox</span> package and the <code>sobol()</code> function of the <span class="pkg">randtoolbox</span> package, and the Sobol sequences canvas the <code class="reqn">\mathcal{I}^2</code> domain for smaller <code class="reqn">n</code> values than required if statistical independence is used for the Monte Carlo integration. Note, the <span class="pkg">randtoolbox</span> at least at version 2.0.+ has &ldquo;scrambling&rdquo; of Sobol sequences temporarily disabled, and hence <code>scrambling=0</code> as default for <code>kullCOP</code>;</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_scrambling">scrambling</code></td>
<td>
<p>The argument of the same name for <code>randtoolbox::sobol</code>; and</p>
</td></tr>
<tr><td><code id="kullCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+densityCOP">densityCOP</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned having the following components:
</p>
<table role = "presentation">
<tr><td><code>MonteCarlo.sim.size</code></td>
<td>
<p><code>kullCOP</code> (Monte Carlo integration) only&mdash;The simulation size for numerical integration;</p>
</td></tr>
<tr><td><code>divergences</code></td>
<td>
<p>A vector of the Kullback&ndash;Leibler Divergences and their standard deviations: <code class="reqn">\mathrm{KL}(f {\mid} g)</code>, <code class="reqn">\sigma_{\mathrm{KL}(f {\mid} g)}</code>, <code class="reqn">\mathrm{KL}(g {\mid} f)</code>, and <code class="reqn">\sigma_{\mathrm{KL}(g {\mid} f)}</code>, respectively;</p>
</td></tr>
<tr><td><code>stdev.divergences</code></td>
<td>
<p><code>kullCOP</code> (Monte Carlo integration) only&mdash;The standard deviation of the divergences and the variances;</p>
</td></tr>
<tr><td><code>Jeffrey.divergence</code></td>
<td>
<p>Jeffrey Divergence <code class="reqn">J(f,g)</code>;</p>
</td></tr>
<tr><td><code>KL.sample.size</code></td>
<td>
<p>Kullback&ndash;Leibler sample size <code class="reqn">n_{f\!g}</code>; and</p>
</td></tr>
<tr><td><code>integrations</code></td>
<td>
<p><code>kullCOPint</code> (numerical integration) only&mdash;An <span class="rlang"><b>R</b></span> <code>list</code> of the outer call of the <code>integrate()</code> function for the respective numerical integrals shown in this documentation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityCOP">densityCOP</a></code>, <code><a href="#topic+vuongCOP">vuongCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See another demonstration under the Note section of statTn().
## Not run: 
# Joe (2014, p. 237, table 5.2)
# Gumbel-Hougaard and Plackett copulas below each have a Kendall Tau of about 0.5, and
# Joe (2014) lists in the table that Jeffrey Divergence is about 0.110 and Kullback-Leibler
# sample size is 133. Joe (2014) does not list the copula parameters just says Tau = 0.5.
# Joe (2014) likely did the numerical integrations using analytical solutions to probability
# densities and not rectangular approximations as in copBasic::densityCOP().
set.seed(1)
KL &lt;- kullCOP(cop1=GHcop,       para1=2,
              cop2=PLACKETTcop, para2=11.40484, sobol=FALSE)
message("Jeffery Divergence is ",          round(KL$Jeffrey.divergence, digits=4),
        " and Kullback-Leibler sample size is ", KL$KL.sample.size, ".")
# Jeffery Divergence is 0.1106 and Kullback-Leibler sample size is 137.
set.seed(1)
KL &lt;- kullCOP(cop1=GHcop,       para1=2,
              cop2=PLACKETTcop, para2=11.40484, sobol=TRUE )
message("Jeffery Divergence is ",          round(KL$Jeffrey.divergence, digits=4),
        " and Kullback-Leibler sample size is ", KL$KL.sample.size, ".")
# Jeffery Divergence is 0.3062 and Kullback-Leibler sample size is 136.


set.seed(1)
S &lt;- replicate(20, kullCOP(cop1=GHcop, para1=2, cop2=PLACKETTcop, sobol=FALSE,
                           para2=11.40484, verbose=FALSE)$KL.sample.size)
print(as.integer(c(mean(S), sd(S)))) # 132 plus/minus 5
S &lt;- replicate(2 , kullCOP(cop1=GHcop, para1=2, cop2=PLACKETTcop,  sobol=TRUE,
                           para2=11.40484, verbose=FALSE)$KL.sample.size)
# The two S in the later replication are both the same (136) for a sobol=TRUE
# does not produce variation and this is thought (June 2023) as a result
# of the disabled scrambling in the randtoolbox::sobol() function. 
## End(Not run)

## Not run: 
# Joe (2014, p. 237, table 5.3)
# Gumbel-Hougaard and Plackett copulas below each have a Spearman Rho of about 0.5, and
# Joe (2014) lists in the table that Jeffrey Divergence is about 0.063 and Kullback-Leibler
# sample size is 210. Joe (2014) does not list the parameters and just says that Rho = 0.5.
# Joe (2014) likely did the numerical integrations using analytical solutions to probability
# densities and not rectangular approximations as in copBasic::densityCOP().
set.seed(1)
KL &lt;- kullCOP(cop1=GHcop,       para1=1.541071,
              cop2=PLACKETTcop, para2=5.115658, sobol=FALSE)
message("Jeffery Divergence is ",          round(KL$Jeffrey.divergence, digits=4),
        " and Kullback-Leibler sample size is ", KL$KL.sample.size, ".")
# Jeffery Divergence is 0.0642 and Kullback-Leibler sample size is 213.
set.seed(1)
KL &lt;- kullCOP(cop1=GHcop,       para1=1.541071,
              cop2=PLACKETTcop, para2=5.115658, sobol=TRUE )
message("Jeffery Divergence is ",          round(KL$Jeffrey.divergence, digits=4),
        " and Kullback-Leibler sample size is ", KL$KL.sample.size, ".")
# Jeffery Divergence is 0.2001 and Kullback-Leibler sample size is 206.


set.seed(1)
S &lt;- replicate(20, kullCOP(cop1=GHcop, para1=1.541071, cop2=PLACKETTcop,
                           para2=5.115658, verbose=FALSE)$KL.sample.size)
print(as.integer(c(mean(S), sd(S))))  # 220 plus/minus 19 
## End(Not run)

## Not run: 
# Compare Jeffery Divergence estimates as functions of sample size when computed
# using Sobol sequences or not for Gumbel-Hougaard and Pareto copulas.
GHpar &lt;- PApar &lt;- 2 # Spearman Rho = 0.6822339
Ns &lt;- as.integer(10^c(seq(2.0, 3.5, by=0.01), seq(3.6, 5, by=0.05)))
JDuni &lt;- sapply(1:length(Ns), function(i) {
                  kullCOP(cop1=GHcop, para1=GHpar, verbose=FALSE,
                          cop2=PAcop, para2=PApar, n=Ns[i],
                          sobol=FALSE)$Jeffrey.divergence })
JDsob &lt;- sapply(1:length(Ns), function(i) {
                  kullCOP(cop1=GHcop, para1=GHpar, verbose=FALSE,
                          cop2=PAcop, para2=PApar, n=Ns[i],
                          sobol=TRUE )$Jeffrey.divergence })
plot(Ns, JDuni, type="l", log="x", # black line, notice likely outliers too
     xlab="Simulation Sample Size", ylab="Jeffery Divergence")
lines(Ns, JDsob, col="red") # red line
legend("topright", c("Monte Carlo", "Sobol sequence"),
                   lwd=c(1,1), col=c("black", "red"), bty="n")
print( c( mean(JDuni), sd(JDuni) ) ) # [1] 0.05915608 0.01284682
print( c( mean(JDsob), sd(JDsob) ) ) # [1] 0.07274190 0.01838939

# The developer notes that plotting KL.sample.size for sobol=TRUE shows
# what appears to be numerical blow up but the Jeffery Divergence does not.
KLuni &lt;- sapply(1:length(Ns), function(i) {
                  kullCOP(cop1=GHcop, para1=GHpar, verbose=FALSE,
                          cop2=PAcop, para2=PApar, n=Ns[i],
                          sobol=FALSE)$KL.sample.size })
KLsob &lt;- sapply(1:length(Ns), function(i) {
                  kullCOP(cop1=GHcop, para1=GHpar, verbose=FALSE,
                          cop2=PAcop, para2=PApar, n=Ns[i],
                          sobol=TRUE )$KL.sample.size })
plot(Ns, KLuni, type="l", log="xy", # black line, notice likely outliers too
     xlab="Simulation Sample Size", ylab="Kullback-Leibler Sample Size")
lines(Ns, KLsob, col="red") # red line
nideal &lt;- kullCOPint(cop1=GHcop, para1=GHpar, cop2=PAcop, para2=PApar)$KL.sample.size
abline(h=nideal, col="green", lwd=3) # nideal sample size is about 210
legend("topright", c("Monte Carlo", "Sobol sequence", "Judged ideal sample size"),
                   lwd=c(1,1,3), col=c("black", "red", "green"), bty="n")

# Let us attempt a visualization to highlight the differences in the two copula by
# simulation. First, using this n = nideal, being the apparent sample size to distinguish
# generally between the two copula having the same Spearman Rho. Do the segments help
# to visually highlight the differences? Next, ask would one judge the parents in the
# simulation being different knowing same Spearman Rho? (Note, the segments are all
# vertical because the U axis is the simulation and the V axis is the conditional
# probability given the U.)
set.seed(1); UVgh &lt;- simCOP(nideal, GHcop, para=GHpar, graphics=FALSE)
set.seed(1); UVpa &lt;- simCOP(nideal, PAcop, para=PApar, graphics=FALSE)
plot(c(0,1), c(0,1), type="n", xlab="U, nonexceedance probability",
                               ylab="V, nonexceedance probability")
segments(UVgh[,1], UVgh[,2], x1=UVpa[,1], y1=UVpa[,2])
points(UVgh, col="lightgreen", pch=16, cex=0.8) # dots
points(UVpa, col="darkgreen",  pch= 1, lwd=0.8) # circles
# Repeat the above n = nideal visualizations but with a change to n = nideal*10, and see
# then that there are visually striking shifts systematically in both both tails but also
# in the U in the interval (0.3, 0.7) belt but to a smaller degree than seen in the tails. 
## End(Not run)
</code></pre>

<hr>
<h2 id='lcomCOP'>L-comoments and Bivariate L-moments of a Copula</h2><span id='topic+lcomCOP'></span>

<h3>Description</h3>

<p>Compute the <em>L-comoments</em> (Serfling and Xiao, 2007; Asquith, 2011) through the <em>bivariate L-moments (ratios)</em> (<code class="reqn">\delta^{[\ldots]}_{k;\mathbf{C}}</code>) of a copula <code class="reqn">\mathbf{C}(u,v; \Theta)</code>  The L-comoments include <em>L-correlation</em> (<em>Spearman Rho</em>), <em>L-coskew</em>, and <em>L-cokurtosis</em>.  As described by Brahimi <em>et al.</em> (2015), the first four bivariate L-moments <code class="reqn">\delta^{[12]}_k</code> for random variable <code class="reqn">X^{(1)}</code> or <code class="reqn">U</code> with respect to (<em>wrt</em>) random variable <code class="reqn">X^{(2)}</code> or <code class="reqn">V</code> are defined as
</p>
<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{1;\mathbf{C}} = 2\int\!\!\int_{\mathcal{I}^2}
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{2;\mathbf{C}} = \int\!\!\int_{\mathcal{I}^2}
(12v - 6)
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{3;\mathbf{C}} = \int\!\!\int_{\mathcal{I}^2}
(60v^2 - 60v + 12)
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\delta^{[12]}_{4;\mathbf{C}} = \int\!\!\int_{\mathcal{I}^2}
(280v^3 - 420v^2 + 180v - 20)
\mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v - \frac{1}{2}\mbox{,}</code>
</p>

<p>where the bivariate L-moments are related to the L-comoment ratios by
</p>
<p style="text-align: center;"><code class="reqn">6\delta^{[12]}_k = \tau^{[12]}_{k+1}\mbox{\quad and \quad}6\delta^{[21]}_k = \tau^{[21]}_{k+1}\mbox{,}</code>
</p>

<p>where in otherwords, &ldquo;the third bivariate L-moment <code class="reqn">\delta^{[12]}_3</code> is one sixth the L-cokurtosis <code class="reqn">\tau^{[12]}_4</code>.&rdquo; The first four bivariate L-moments yield the first five L-comoments. The terms and nomenclature are not easy and also the English grammar adjective &ldquo;ratios&rdquo; is not always consistent in the literature. The <code class="reqn">\delta^{[\ldots]}_{k;\mathbf{C}}</code> are <b>ratios</b>. The sample L-comoments are supported by the <span class="pkg">lmomco</span> package, and in particular for the bivariate case, they are supported by the <code>lcomoms2()</code> function of that package.
</p>
<p>Similarly, the <code class="reqn">\delta^{[21]}_k</code> are computed by switching <code class="reqn">u \rightarrow v</code> in the polynomials within the above integrals multiplied to the copula in the system of equations with <code class="reqn">u</code>. In general, <code class="reqn">\delta^{[12]}_k \not= \delta^{[21]}_k</code> for <code class="reqn">k &gt; 1</code> unless in the case of <em>permutation symmetric</em> (<code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code>) copulas. By theory, <code class="reqn">\delta^{[12]}_1 = \delta^{[21]}_1 = \rho_\mathbf{C}/6</code> where <code class="reqn">\rho_\mathbf{C}</code> is the <em>Spearman Rho</em> <code><a href="#topic+rhoCOP">rhoCOP</a></code>.
</p>
<p>The integral for <code class="reqn">\delta^{[12]}_{4;\mathbf{C}}</code> does not appear in Brahimi <em>et al.</em> (2015) but this and the other forms are verified in the <b>Examples</b> and discussion in <b>Note</b>. The four <code class="reqn">k \in (1,2,3,4)</code> for <code class="reqn">U</code> <em>wrt</em> <code class="reqn">V</code> and <code class="reqn">V</code> <em>wrt</em> <code class="reqn">U</code> comprise a full spectrum of system of seven (not eight) equations. One equation is lost because <code class="reqn">\delta^{[12]}_1 = \delta^{[21]}_1</code>.
</p>
<p>Chine and Benatia (2017) describe <em>trimmed L-comoments</em> as the multivariate extensions of the univariate <em>trimmed L-moments</em> (Elamir and Seheult, 2003) that are implemented in <span class="pkg">lmomco</span>. These are not yet implemented in <span class="pkg">copBasic</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcomCOP(cop=NULL, para=NULL, as.bilmoms=FALSE, orders=2:5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lcomCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="lcomCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="lcomCOP_+3A_as.bilmoms">as.bilmoms</code></td>
<td>
<p>A logical to trigger return of the <code class="reqn">\delta_k</code> and the return vectors will be named differently;</p>
</td></tr>
<tr><td><code id="lcomCOP_+3A_orders">orders</code></td>
<td>
<p>The orders of the L-comoments to return, which is internally adjusted if the argument <code>as.bilmoms</code> is set. There is no first order L-comoment and the first index on returned values is set to <code>NA</code> to remain index consistent with the <span class="pkg">lmomco</span> package. An order greater than 5 is not supported; and</p>
</td></tr>
<tr><td><code id="lcomCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+densityCOP">densityCOP</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> of the L-comoments or bivariate L-moments is returned depending on <code>as.bilmoms</code> setting.
</p>
<table role = "presentation">
<tr><td><code>bilmomUV</code></td>
<td>
<p>The bivariate L-moments <code class="reqn">\delta^{[12]}_k</code> of <code class="reqn">U</code> with respect to <code class="reqn">V</code> for <code class="reqn">k \in [1,2,3,4]</code> if <code>orders</code> is <code>2:5</code> and there is no <code>NA</code> index as for the L-comoments;</p>
</td></tr>
<tr><td><code>bilmomVU</code></td>
<td>
<p>The bivariate L-moments <code class="reqn">\delta^{[21]}_k</code> of <code class="reqn">V</code> with respect to <code class="reqn">U</code> for <code class="reqn">k \in [1,2,3,4]</code> if <code>orders</code> is <code>2:5</code> and there is no <code>NA</code> index as for the L-comoments;</p>
</td></tr>
<tr><td><code>lcomUV</code></td>
<td>
<p>The L-comoments <code class="reqn">\tau^{[12]}_k</code> of <code class="reqn">V</code> with respect to <code class="reqn">U</code> for <code class="reqn">k \in [2,3,4,5]</code> if <code>orders</code> is <code>2:5</code> and index 1 is <code>NA</code>; and</p>
</td></tr>
<tr><td><code>lcomVU</code></td>
<td>
<p>The L-comoments <code class="reqn">\tau^{[21]}_k</code> of <code class="reqn">V</code> with respect to <code class="reqn">U</code> for <code class="reqn">k \in [2,3,4,5]</code> if <code>orders</code> is <code>2:5</code> and index 1 is <code>NA</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The documention here is highly parallel to <code><a href="#topic+bilmoms">bilmoms</a></code> for which that function was developed some years before <code>lmomCOP</code> was developed in January 2019. Also, <code><a href="#topic+bilmoms">bilmoms</a></code> is based on gridded or Monte Carlo integration, and <code><a href="#topic+bilmoms">bilmoms</a></code> is to be considered <b>deprecated</b>. However, it is deliberate that related background and various algorithm testing are still documented in <code><a href="#topic+bilmoms">bilmoms</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Brahimi, B., Chebana, F., and Necir, A., 2015, Copula representation of bivariate L-moments&mdash;A new estimation method for multiparameter two-dimensional copula models: Statistics, v. 49, no. 3, pp. 497&ndash;521.
</p>
<p>Chine, Amel, and Benatia, Fatah, 2017, Bivariate copulas parameters estimation using the trimmed L-moments methods: Afrika Statistika, v. 12, no. 1, pp. 1185&ndash;1197.
</p>
<p>Elamir, E.A.H, and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, p. 299&ndash;314.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bilmoms">bilmoms</a></code>, <code><a href="#topic+lcomCOPpv">lcomCOPpv</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- list(alpha=0.5, beta=0.93, para1=4.5, cop1=GLcop, cop2=PSP)
copBasic:::lcomCOP(cop=composite2COP, para=para)$lcomUV[3]
# Lcomom:T3[12]=  +0.156
copBasic:::lcomCOP(cop=composite2COP, para=para)$lcomVU[3]
# Lcomom:T3[21]=  -0.0668
bilmoms(cop=composite2COP, n=10000, para=para, sobol=TRUE)$bilcomoms$T3
# Tau3[12]=+0.1566, Tau3[21]=-0.0655
# The numerical default Monte Carlo integration of bilmoms()
# matches the numerical integration of lcomCOP albeit with a
# substantially slower and less elegant means in bilmoms().
## End(Not run)

## Not run: 
# The following Spearman Rho and L-coskew values are predicted for a monitoring
# location of the relation between peak streamflow (V) and time into the
# water year (U) where U and V are "U-statistics."
site_srho  &lt;-  0.15536430
site_T3_12 &lt;-  0.03866056
site_T3_21 &lt;- -0.03090144

# Create an objective function for 3D optimization with some explicit intention that
# transforms are used to keep the parameters in acceptable parameter space for the
# alpha [0,1] and beta [0,1] and theta for the Plackett copula and the composite1COP
# used to add two more parameters to the Plackett.
ofunc &lt;- function(par, srho=NA, T3_12=NA, T3_21=NA) {
  alpha &lt;- pnorm(par[1]) # takes -Inf to +Inf ---&gt; 0 to 1 # compositing domain
  beta  &lt;- pnorm(par[2]) # takes -Inf to +Inf ---&gt; 0 to 1 # compositing domain
  theta &lt;-   exp(par[3]) # takes -Inf to +Inf ---&gt; 0 to +Inf # Plackett domain
  lmr &lt;- lcomCOP(cop=composite1COP,
                 para=list(alpha=alpha, beta=beta, para1=theta, cop1=PLcop))
  return((lmr$lcomUV[2] - srho )^2 + # look carefully, the 2, 3, 3 index
         (lmr$lcomUV[3] - T3_12)^2 + # use on the lmr list are correct, so do not
         (lmr$lcomVU[3] - T3_21)^2)  # expect to see 1, 2, 3 or 2, 3, 4.
}
# initial parameter guess ('middle' [0.5] compositing and independence [1]) and
# showing the transformations involved.
para_init &lt;- c(qnorm(0.5), qnorm(0.5), log(1))
rt &lt;- optim(par=para_init, ofunc,
            srho=site_srho, T3_12=site_T3_12, T3_21=site_T3_21)
lcom_para &lt;- list(alpha=pnorm(rt$par[1]), beta=pnorm(rt$par[2]),
                  para1=exp(rt$par[3]), cop1=PLcop)
sUV &lt;- simCOP(10000, cop=composite1COP, para=lcom_para, col=grey(0, 0.2), pch=16)
# Now as an exercise, consider increasing site_srho or negating it. Consider
# switching the signs on the L-coskews or increasing their magnitudes and study
# the resulting simulation to develop a personal feeling for L-coskew meaning. #
## End(Not run)
</code></pre>

<hr>
<h2 id='lcomCOPpv'>Simulating the Sample Distribution(s) of L-correlation, L-coskew, and L-cokurtosis for a Copula</h2><span id='topic+lcomCOPpv'></span>

<h3>Description</h3>

<p><em>EXPERIMENTAL:</em> The function provides two themes of sampling distribution characterization by simulation of the first three L-comoment ratios (L-correlation <code class="reqn">\tau_{2[\ldots]}</code>, L-coskew <code class="reqn">\tau_{3[\ldots]}</code> and L-cokurtosis <code class="reqn">\tau_{4[\ldots]}</code>) of a copula. Subsequently, the sampling distribution can be used for inference.
</p>
<p>First, semi-optional Monte Carlo integration estimation of the L-comoments of the parent copula are computed. Second, simulations involving the sample size <code class="reqn">n</code> presumed the size of the actual sample from which the estimates of the sample L-comoments given as arguments. These simulations result in a report of the L-moments (not L-comoments) of the sampling distribution and these then are used to compute p-values for the L-comoment matrices provided by the user as a function argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcomCOPpv(n, lcom, cop=NULL, para=NULL, repcoe=5E3, type="gno",
                   mcn=1E4, mcrep=10, usemcmu=FALSE, digits=5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lcomCOPpv_+3A_n">n</code></td>
<td>
<p>The sample size <code class="reqn">n</code>. This argument is semi-optional because <code class="reqn">n = 0</code> can be given to skip corresponding simulations and the <code>ntable</code> on return will only contain <code>NA</code>; this feature permits rapid extraction of the <code>Ntable</code> and thus the <code>lcom</code> contents are simply not used;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_lcom">lcom</code></td>
<td>
<p>The sample L-comoments (see below);</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_repcoe">repcoe</code></td>
<td>
<p>The replication coefficient <code class="reqn">\phi</code> affecting the number of simulations of size <code>n</code>;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_type">type</code></td>
<td>
<p>The distribution type used for modeling the distribution of the sampling values. The generalized normal (see distribution type <code>"gno"</code> in package <span class="pkg">lmomco</span>) accommodates some skewness compared to the symmetry of the normal (<code>"nor"</code>) just in case situations arise in which non-ignorable skewness in the sample distribution exists. The distribution abbreviations of package <span class="pkg">lmomco</span> are recognized for the <code>type</code> argument, but in reality the <code>"nor"</code> and <code>"gno"</code> should be more than sufficient;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_mcn">mcn</code></td>
<td>
<p>The sample size <code class="reqn">N</code> passed to the <code><a href="#topic+bilmoms">bilmoms</a></code> function for the Monte Carlo integration. If <code class="reqn">N = 0</code> then the Monte Carlo integration is not used, otherwise the minimum sample size is internally reset to <code class="reqn">N=4</code> so that first four L-moments are computable;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_mcrep">mcrep</code></td>
<td>
<p>The number of replications of the Monte Carlo simulation by <code><a href="#topic+bilmoms">bilmoms</a></code>;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_usemcmu">usemcmu</code></td>
<td>
<p>A logical toggling whether the mean value computed from the replicated Monte Carlo integrations is used instead of the mean values for the small sample simulation for the p-value computations;</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_digits">digits</code></td>
<td>
<p>The number of digits to round numerical entries in the returned tables and can be <code>NA</code> for no rounding; and</p>
</td></tr>
<tr><td><code id="lcomCOPpv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+bilmoms">bilmoms</a></code> function or to the copula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The notation <code class="reqn">r[\ldots]</code> refers to two specific types of L-comoment definitions and a blend between the two. The notation <code class="reqn">r[12]</code> means that the <code class="reqn">r</code>th L-comoment for random variables <code class="reqn">\{X^{(1)}, X^{(2)}\}</code> where <code class="reqn">X^{(2)}</code> is the sorted variable and <code class="reqn">X^{(1)}</code> is shuffled by the sorting index. Conversely, the notation <code class="reqn">r[21]</code> means that the <code class="reqn">r</code>th L-comoment for random variables <code class="reqn">\{X^{(1)}, X^{(2)}\}</code> where <code class="reqn">X^{(1)}</code> is the sorted variable and <code class="reqn">X^{(2)}</code> is shuffled by the sorting index. The notation <code class="reqn">r[12:21]</code> means that the average between the <code class="reqn">r[21]</code> and <code class="reqn">r[21]</code> is computed, which might prove useful in circumstances of known or expected symmetry of the L-comoments.
</p>
<p>Continuing, <code class="reqn">\hat\tau_{2[12]}</code> is the sample L-correlation, <code class="reqn">\hat\tau_{3[12]}</code> is the sample L-coskew, and <code class="reqn">\hat\tau_{4[12]}</code> is the sample L-cokurtosis all with respect to the sorting of the second variable. The computation of these L-comoment matricies can be made by functions such as function <code>lcomoms2()</code> in the <span class="pkg">lmomco</span> package. The number of replications for the simulations involving the <code class="reqn">n</code> sample size is computed by
</p>
<p style="text-align: center;"><code class="reqn">m = \phi/\sqrt{n}\mbox{,}</code>
</p>

<p>where <code class="reqn">\phi</code> is the <code>repcoe</code> replication factor or coefficient. If <code>usemcmu</code> is <code>TRUE</code> then <code>mcn</code> <code class="reqn">&gt; 0</code> else <code>usemcmu</code> is reset to <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table role = "presentation">
<tr><td><code>text</code></td>
<td>
<p>A string functioning as a label for the remaining tables;</p>
</td></tr>
<tr><td><code>Ntable</code></td>
<td>
<p>Another <span class="rlang"><b>R</b></span> <code>list</code> holding tables of the L-moments of the L-comoments derived from Monte Carlo integration for samples of size <code class="reqn">N =</code> <code>mcn</code>. The simulations are replicated <code>mcrep</code> times; and</p>
</td></tr>
<tr><td><code>ntable</code></td>
<td>
<p>Another <span class="rlang"><b>R</b></span> <code>list</code> holding tables of the L-moments of the L-comoments derived from the small sample simulations for samples of size <code class="reqn">n =</code> <code>n</code> as well as the p-values estimated by a generalized normal distribution (see <span class="pkg">lmomco</span> package documentation) of the L-moments using either the small sample means or the mean of the replicated Monte Carlo integrations as dictated by <code>usemcmu</code>. In all circumstances, however, the results for the small sample simluations are tabulated in <code>ntable</code> only the p-value will be reflective the setting of <code>usemcmu</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>A significance column for the p-values is added to the right side of the returned <code>ntable</code> and is used to guide the eye in interpretation of results. The significant codes having the following definitions for a two-tailed form:
</p>
<pre>
  "_" &gt; 0.1;  ".", 0.1;  "*", 0.05;  "**", 0.01;  "***", 0.001
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lcomCOP">lcomCOP</a></code>, <code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+kullCOP">kullCOP</a></code>, <code><a href="#topic+vuongCOP">vuongCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See Note section of vuongCOP() for an extended discussion of copula inference
## Not run: 
Tau &lt;- 0.6410811; para &lt;- GHcop(tau=Tau)$para # This Tau is from a situation of
# two river tributaries. These three L-comoments with univariate L-moments on the
T2 &lt;- c(1,  0.79908960, 0.79908960, 1) # diagonals are derived from those river
# tributaries and downstream of the junction data.
T3 &lt;- c(0, -0.04999318, 0.07689082, 0)
T4 &lt;- c(0,  0.01773833, 0.04756257, 0) # Is the Ho:GHcop rejectable?
LCOM &lt;- list(T2=matrix(T2, nrow=2), T3=matrix(T3, nrow=2), T4=matrix(T4, nrow=2))
set.seed(30312)
ZZ1 &lt;- lcomCOPpv(75, LCOM, cop=GHcop, para=para, repcoe=2000, usemcmu=FALSE)
print(ZZ1)
set.seed(30312)
ZZ2 &lt;- lcomCOPpv(75, LCOM, cop=GHcop, para=para, repcoe=2000, usemcmu=TRUE)
print(ZZ2)
# The results here suggest that the GHcop is not rejectable.
## End(Not run)
</code></pre>

<hr>
<h2 id='lcomoms2.ABcop2parameter'>Convert L-comoments to Parameters of Alpha-Beta Compositions of Two One-Parameter Copulas</h2><span id='topic+lcomoms2.ABcop2parameter'></span>

<h3>Description</h3>

<p><em>EXPERIMENTAL</em>&mdash;This function converts the <em>L-comoments</em> of a bivariate sample to the four parameters of a composition of two one-parameter copulas. Critical inputs are of course the first three dimensionless L-comoments: <em>L-correlation</em>, <em>L-coskew</em>, and <em>L-cokurtosis</em>. The most complex input is the <code>solutionenvir</code>, which is an <code>environment</code> containing arbitrarily long, but individual tables, of L-comoment and parameter pairings. These pairings could be computed from the examples in <code><a href="#topic+simcompositeCOP">simcompositeCOP</a></code>.
</p>
<p>The individual tables are prescanned for potentially acceptable solutions and the absolute additive error of both L-comoments for a given order is controlled by the <code>tNeps</code> arguments. The default values seem acceptable. The purpose of the prescanning is to reduce the computation space from perhaps millions of solutions to a few orders of magnitude. The computation of the solution error can be further controlled by <code class="reqn">X</code> or <code class="reqn">u</code> with respect to <code class="reqn">Y</code> or <code class="reqn">v</code> using the <code>comptNerrXY</code> arguments, but experiments thus far indicate that the defaults are likely the most desired. A solution &ldquo;matching&rdquo; the L-correlation is always sought; thus there is no <code>uset2err</code> argument. The arguments <code>uset3err</code> and <code>uset4err</code> provide some level of granular control on addition error minimization; the defaults seek to &ldquo;match&rdquo; L-coskew and ignore L-cokurtosis. The <code>setreturn</code> controls which rank of computed solution is returned; users might want to manually inspect a few of the most favorable solutions, which can be done by the <code>setreturn</code> or inspection of the returned object from the <code>lcomoms2.cop2parameter</code> function. The examples are detailed and self-contained to the <span class="pkg">copBasic</span> package; curious users are asked to test these.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcomoms2.ABcop2parameter(solutionenvir=NULL,
                         T2.12=NULL, T2.21=NULL,
                         T3.12=NULL, T3.21=NULL,
                         T4.12=NULL, T4.21=NULL,
                         t2eps=0.1, t3eps=0.1, t4eps=0.1,
                         compt2erruv=TRUE, compt2errvu=TRUE,
                         compt3erruv=TRUE, compt3errvu=TRUE,
                         compt4erruv=TRUE, compt4errvu=TRUE,
                         uset3err=TRUE, uset4err=FALSE,
                         setreturn=1, maxtokeep=1e5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_solutionenvir">solutionenvir</code></td>
<td>
<p>The environment containing solutions;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t2.12">T2.12</code></td>
<td>
<p>L-correlation <code class="reqn">\tau_2^{[12]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t2.21">T2.21</code></td>
<td>
<p>L-correlation <code class="reqn">\tau_2^{[21]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t3.12">T3.12</code></td>
<td>
<p>L-coskew <code class="reqn">\tau_3^{[12]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t3.21">T3.21</code></td>
<td>
<p>L-coskew <code class="reqn">\tau_3^{[21]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t4.12">T4.12</code></td>
<td>
<p>L-cokurtosis <code class="reqn">\tau_4^{[12]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t4.21">T4.21</code></td>
<td>
<p>L-cokurtosis <code class="reqn">\tau_4^{[21]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t2eps">t2eps</code></td>
<td>
<p>An error term in which to pick a potential solution as close enough on preliminary processing for <code class="reqn">\tau_2^{[1 \leftrightarrow 2]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t3eps">t3eps</code></td>
<td>
<p>An error term in which to pick a potential solution as close enough on preliminary processing for <code class="reqn">\tau_3^{[1 \leftrightarrow 2]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_t4eps">t4eps</code></td>
<td>
<p>An error term in which to pick a potential solution as close enough on preliminary processing for <code class="reqn">\tau_4^{[1 \leftrightarrow 2]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_compt2erruv">compt2erruv</code></td>
<td>
<p>Compute an L-correlation error using the 1 with respect to 2 (or <code class="reqn">u</code> wrt <code class="reqn">v</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_compt2errvu">compt2errvu</code></td>
<td>
<p>Compute an L-correlation error using the 2 with respect to 1 (or <code class="reqn">v</code> wrt <code class="reqn">u</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_compt3erruv">compt3erruv</code></td>
<td>
<p>Compute an L-coskew error using the 1 with respect to 2 (or <code class="reqn">u</code> wrt <code class="reqn">v</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_compt3errvu">compt3errvu</code></td>
<td>
<p>Compute an L-coskew error using the 2 with respect to 1 (or <code class="reqn">v</code> wrt <code class="reqn">u</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_compt4erruv">compt4erruv</code></td>
<td>
<p>Compute an L-cokurtosis error using the 1 with respect to 2 (or <code class="reqn">u</code> wrt <code class="reqn">v</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_compt4errvu">compt4errvu</code></td>
<td>
<p>Compute an L-cokurtosis error using the 2 with respect to 1 (or <code class="reqn">v</code> wrt <code class="reqn">u</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_uset3err">uset3err</code></td>
<td>
<p>Use the L-coskew error in the determination of the solution. The L-correlation error is always used;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_uset4err">uset4err</code></td>
<td>
<p>Use the L-cokurtosis error in the determination of the solution. The L-correlation error is always used;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_setreturn">setreturn</code></td>
<td>
<p>Set (index) number of the solution to return. The default of 1 returns the preferred solutions based on the controls for the minimization; and</p>
</td></tr>
<tr><td><code id="lcomoms2.ABcop2parameter_+3A_maxtokeep">maxtokeep</code></td>
<td>
<p>The value presets the number of rows in the solution matrix. This matrix is filled with potential solutions as the various subfiles of the <code>solutionenvir</code> are scanned. The matrix is trimmed of <code>NA</code>s and error trapping is in place for too small values of <code>maxtokeep</code>. The default value appears appropriate for the feeding of massively large simulated parameter spaces.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+simcompositeCOP">simcompositeCOP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Build an initial parameter to L-comoment mapping table.
  mainpara &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
                   para1gen=function() { return(10^runif(1, min=-5, max=0)) },
                   para2gen=function() { return(10^runif(1, min=0,  max=5)) })
  nsim &lt;- 1E4
  sample.size.for.estimation &lt;- 1000 # really use vastly larger sample size
  PlackettPlackettNP &lt;-
      simcompositeCOP(n=sample.size.for.estimation, nsim=nsim, parent=mainpara)
  save(PlackettPlackettNP, file="PlackettPlackettNP.RData", compress="xz")

# Plackett-Plackett composited copula from the copBasic package
# Then create an environment to house the "table."
PlackettPlackett &lt;- new.env()
assign("NeedToCreateForDemo", PlackettPlackettNP, envir=PlackettPlackett)
# Now that the table is assigned into the environment, the parameter
# estimation function can be used. In reality, a much much larger
# solution set is needed, but this effort is experimental.

# Now grab the closest Plackett-Plackett solution having the following six
# arbitrary L-comoments. Then simulate 1000 values and plot them to show
# the underlying bivariate distribution.
PPcop &lt;- lcomoms2.ABcop2parameter(solutionenvir=PlackettPlackett,
                                  T2.12=-0.5059, T2.21=-0.5110,
                                  T3.12= 0.1500, T3.21= 0.1700,
                                  T4.12=-0.0500, T4.21= 0.0329,
                                  uset3err=TRUE, uset4err=TRUE)
# A user in encouraged to inspect the contents of PPcop to "assess" the
# solution by a method of L-comoments, we will now proceed with showing the
# copula via a simulation of the fitted version.
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop, alpha=PPcop$alpha, beta=PPcop$beta,
             para1=PPcop$Cop1Thetas, para2=PPcop$Cop2Thetas)

D &lt;- simCOP(n=5000, cop=composite2COP, para=para, col=rgb(0,0,0,0.1), pch=16)
# The sample L-comoments of the fitted Plackett-Plackett may be found by
lmomco::lcomoms2(D, nmom=4) # from the lmomco package, and six sample values shown
T2.12 &lt;- -0.5151547; T2.21 &lt;- -0.5139863
T3.12 &lt;-  0.1502336; T3.21 &lt;-  0.1721355
T4.12 &lt;- -0.0326277; T4.21 &lt;-  0.0233979
PPcop &lt;- lcomoms2.ABcop2parameter(solutionenvir=PlackettPlackett,
                                  T2.12=T2.12, T2.21=T2.21,
                                  T3.12=T3.12, T3.21=T3.21,
                                  T4.12=T4.12, T4.21=T4.21, uset4err=TRUE)
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop, alpha=PPcop$alpha, beta=PPcop$beta,
             para1=PPcop$Cop1Thetas, para2=PPcop$Cop2Thetas)
D &lt;- simCOP(n=5000, cop=composite2COP, para=para, col=rgb(0,0,0,0.1), pch=16)
level.curvesCOP(cop=composite2COP, para=para, delt=.1, ploton=FALSE)
qua.regressCOP.draw(cop=composite2COP, para=para,
                    ploton=FALSE, f=seq(0.05, 0.95, by=0.05))
qua.regressCOP.draw(cop=composite2COP, para=para, wrtV=TRUE,
                    ploton=FALSE, f=seq(0.05, 0.95, by=0.05), col=c(3,2))
diag &lt;- diagCOP(cop=composite2COP, para=para, ploton=FALSE, lwd=4)

image(gridCOP(cop=composite2COP, para=para), col=terrain.colors(20))
# One can inspect alternative solutions like this
# S &lt;- PPcop$solutions$solutions[,1:16]
# B &lt;- S[abs(S$t2.12res) &lt; 0.02 &amp; abs(S$t2.21res) &lt; 0.02 &amp;
#        abs(S$t3.12res) &lt; 0.02 &amp; abs(S$t3.21res) &lt; 0.02, ]
#print(B)
## End(Not run)
</code></pre>

<hr>
<h2 id='lcomoms2.ABKGcop2parameter'>Convert L-comoments to Parameters of Alpha-Beta-Kappa-Gamma Compositions of Two One-Parameter Copulas</h2><span id='topic+lcomoms2.ABKGcop2parameter'></span>

<h3>Description</h3>

<p><em>EXPERIMENTAL</em>&mdash;This function converts the <em>L-comoments</em> of a bivariate sample to the four parameters of a composition of two one-parameter copulas. Critical inputs are of course the first three dimensionless L-comoments: <em>L-correlation</em>, <em>L-coskew</em>, and <em>L-cokurtosis</em>. The most complex input is the <code>solutionenvir</code>, which is an <code>environment</code> containing arbitrarily long, but individual tables, of L-comoment and parameter pairings. These pairings could be computed from the examples in <code><a href="#topic+simcompositeCOP">simcompositeCOP</a></code>.
</p>
<p>The individual tables are prescanned for potentially acceptable solutions and the absolute additive error of both L-comoments for a given order is controlled by the <code>tNeps</code> arguments. The default values seem acceptable. The purpose of the prescanning is to reduce the computation space from perhaps millions of solutions to a few orders of magnitude. The computation of the solution error can be further controlled by <code class="reqn">X</code> or <code class="reqn">u</code> with respect to <code class="reqn">Y</code> or <code class="reqn">v</code> using the <code>comptNerrXY</code> arguments, but experiments thus far indicate that the defaults are likely the most desired. A solution &ldquo;matching&rdquo; the L-correlation is always sought; thus there is no <code>uset2err</code> argument. The arguments <code>uset3err</code> and <code>uset4err</code> provide some level of granular control on addition error minimization; the defaults seek to &ldquo;match&rdquo; L-coskew and ignore L-cokurtosis. The <code>setreturn</code> controls which rank of computed solution is returned; users might want to manually inspect a few of the most favorable solutions, which can be done by the <code>setreturn</code> or inspection of the returned object from the <code>lcomoms2.ABKGcop2parameter</code> function. The examples are detailed and self-contained to the <span class="pkg">copBasic</span> package; curious users are asked to test these.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcomoms2.ABKGcop2parameter(solutionenvir=NULL,
                           T2.12=NULL, T2.21=NULL,
                           T3.12=NULL, T3.21=NULL,
                           T4.12=NULL, T4.21=NULL,
                           t2eps=0.1, t3eps=0.1, t4eps=0.1,
                           compt2erruv=TRUE, compt2errvu=TRUE,
                           compt3erruv=TRUE, compt3errvu=TRUE,
                           compt4erruv=TRUE, compt4errvu=TRUE,
                           uset3err=TRUE, uset4err=FALSE,
                           setreturn=1, maxtokeep=1e5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_solutionenvir">solutionenvir</code></td>
<td>
<p>The environment containing solutions;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t2.12">T2.12</code></td>
<td>
<p>L-correlation <code class="reqn">\tau_2^{[12]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t2.21">T2.21</code></td>
<td>
<p>L-correlation <code class="reqn">\tau_2^{[21]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t3.12">T3.12</code></td>
<td>
<p>L-coskew <code class="reqn">\tau_3^{[12]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t3.21">T3.21</code></td>
<td>
<p>L-coskew <code class="reqn">\tau_3^{[21]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t4.12">T4.12</code></td>
<td>
<p>L-cokurtosis <code class="reqn">\tau_4^{[12]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t4.21">T4.21</code></td>
<td>
<p>L-cokurtosis <code class="reqn">\tau_4^{[21]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t2eps">t2eps</code></td>
<td>
<p>An error term in which to pick a potential solution as close enough on preliminary processing for <code class="reqn">\tau_2^{[1 \leftrightarrow 2]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t3eps">t3eps</code></td>
<td>
<p>An error term in which to pick a potential solution as close enough on preliminary processing for <code class="reqn">\tau_3^{[1 \leftrightarrow 2]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_t4eps">t4eps</code></td>
<td>
<p>An error term in which to pick a potential solution as close enough on preliminary processing for <code class="reqn">\tau_4^{[1 \leftrightarrow 2]}</code>;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_compt2erruv">compt2erruv</code></td>
<td>
<p>Compute an L-correlation error using the 1 with respect to 2 (or <code class="reqn">u</code> wrt <code class="reqn">v</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_compt2errvu">compt2errvu</code></td>
<td>
<p>Compute an L-correlation error using the 2 with respect to 1 (or <code class="reqn">v</code> wrt <code class="reqn">u</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_compt3erruv">compt3erruv</code></td>
<td>
<p>Compute an L-coskew error using the 1 with respect to 2 (or <code class="reqn">u</code> wrt <code class="reqn">v</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_compt3errvu">compt3errvu</code></td>
<td>
<p>Compute an L-coskew error using the 2 with respect to 1 (or <code class="reqn">v</code> wrt <code class="reqn">u</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_compt4erruv">compt4erruv</code></td>
<td>
<p>Compute an L-cokurtosis error using the 1 with respect to 2 (or <code class="reqn">u</code> wrt <code class="reqn">v</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_compt4errvu">compt4errvu</code></td>
<td>
<p>Compute an L-cokurtosis error using the 2 with respect to 1 (or <code class="reqn">v</code> wrt <code class="reqn">u</code>);</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_uset3err">uset3err</code></td>
<td>
<p>Use the L-coskew error in the determination of the solution. The L-correlation error is always used;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_uset4err">uset4err</code></td>
<td>
<p>Use the L-cokurtosis error in the determination of the solution. The L-correlation error is always used;</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_setreturn">setreturn</code></td>
<td>
<p>Set (index) number of the solution to return. The default of 1 returns the preferred solutions based on the controls for the minimization; and</p>
</td></tr>
<tr><td><code id="lcomoms2.ABKGcop2parameter_+3A_maxtokeep">maxtokeep</code></td>
<td>
<p>The value presets the number of rows in the solution matrix. This matrix is filled with potential solutions as the various subfiles of the <code>solutionenvir</code> are scanned. The matrix is trimmed of <code>NA</code>s and error trapping is in place for too small values of <code>maxtokeep</code>. The default value appears appropriate for the feeding of massively large simulated parameter spaces.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+simcompositeCOP">simcompositeCOP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  mainpara &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
                   para1gen=function() { return(10^runif(1, min=-5, max=5)) },
                   para2gen=function() { return(10^runif(1, min=-5, max=5)) })
  nsim &lt;- 1E4
  sample.size.for.estimation &lt;- 1000
  PlackettPlackettABKGtest &lt;-
      simcomposite3COP(n=sample.size.for.estimation, nsim=nsim, parent=mainpara)
  save(PlackettPlackettABKGtest,file="PlackettPlackettABKG.RData",compress="xz")

# Plackett-Plackett composited copula from the copBasic package
# Then create an environment to house the "table".
PlackettPlackettABKG &lt;- new.env()
assign("NeedToCreateForDemo", PlackettPlackettABKGtest, envir=PlackettPlackettABKG)

# Now that the table is assigned into the environment, the parameter estimation
# function can be used. In reality a much much larger solution set is needed.
# Assume one had the following six L-comoments, extract a possible solution.
PPcop &lt;- lcomoms2.ABKGcop2parameter(solutionenvir=PlackettPlackettABKG,
                                    T2.12=-0.5059, T2.21=-0.5110,
                                    T3.12= 0.1500, T3.21= 0.1700,
                                    T4.12=-0.0500, T4.21= 0.0329,
                                    uset3err=TRUE, uset4err=TRUE)
# Now take that solution and setup a parameter object.
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
             alpha=PPcop$alpha, beta=PPcop$beta, kappa=PPcop$kappa, gamma=PPcop$gamma,
             para1=PPcop$Cop1Thetas, para2=PPcop$Cop2Thetas)

# Example Plot Number 1
D &lt;- simCOP(n=2000, cop=composite3COP,  para=para, col=rgb(0,0,0,0.1), pch=16)
print(lmomco::lcomoms2(D, nmom=4)) # See the six extacted sample values for this seed.
T2.12 &lt;- -0.4877171; T2.21 &lt;- -0.4907403
T3.12 &lt;-  0.1642508; T3.21 &lt;-  0.1715944
T4.12 &lt;- -0.0560310; T4.21 &lt;- -0.0350028
PPcop &lt;- lcomoms2.ABKGcop2parameter(solutionenvir=PlackettPlackettABKG,
                                    T2.12=T2.12, T2.21=T2.21,
                                    T3.12=T3.12, T3.21=T3.21,
                                    T4.12=T4.12, T4.21=T4.21, uset4err=TRUE)
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
             alpha=PPcop$alpha, beta=PPcop$beta, kappa=PPcop$kappa, gamma=PPcop$gamma,
             para1=PPcop$Cop1Thetas, para2=PPcop$Cop2Thetas)

# Example Plot Number 2
D &lt;- simCOP(n=1000, cop=composite3COP, para=para, col=rgb(0,0,0,0.1), pch=16)
level.curvesCOP(cop=composite3COP, para=para, delt=0.1, ploton=FALSE)
qua.regressCOP.draw(cop=composite3COP, para=para,
                    ploton=FALSE, f=c(seq(0.05, 0.95, by=0.05)))
qua.regressCOP.draw(cop=composite3COP, para=para, wrtV=TRUE,
                    ploton=FALSE, f=c(seq(0.05, 0.95, by=0.05)), col=c(3,2))
diag &lt;- diagCOP(cop=composite3COP, para=para, ploton=FALSE, lwd=4)
# Compare plots 1 and 2, some generalized consistency between the two is evident.
# One can inspect alternative solutions like this
# S &lt;- PPcop$solutions$solutions[,1:18]
# B &lt;- S[abs(S$t2.12res) &lt; 0.02 &amp; abs(S$t2.21res) &lt; 0.02 &amp;
#        abs(S$t3.12res) &lt; 0.02 &amp; abs(S$t3.21res) &lt; 0.02, ]
#print(B)
## End(Not run)
</code></pre>

<hr>
<h2 id='level.curvesCOP'>Compute and Plot Level Curves of a Copula V with respect to U</h2><span id='topic+level.curvesCOP'></span>

<h3>Description</h3>

<p>Compute and plot <em>level curves</em> or <em>level sets</em> of a copula for <code class="reqn">V</code> with respect to <code class="reqn">U</code> (Nelsen, 2006, pp. 12&ndash;13). The level curves at levels <code class="reqn">t \mapsto [0+\Delta t, 1-\Delta t, \Delta t]</code> are defined for <code class="reqn">U \mapsto [0+\Delta u, 1-\Delta u, \Delta u]</code> by
</p>
<p style="text-align: center;"><code class="reqn">t \mapsto \mathbf{C}(u=U, v)\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">v</code>. Plotting is provided by this function because level curves are such an important visual attribute of a copula and highly useful for pedagogic purposes. The above equation is implemented by the <em>inverse of a copula</em> using <code><a href="#topic+COPinv">COPinv</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>level.curvesCOP(cop=NULL, para=NULL, ploton=TRUE, lines=TRUE,
                plotMW=FALSE, ramp=TRUE, delu=0.001, delt=0.10,
                getlevel=NULL, silent=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="level.curvesCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_lines">lines</code></td>
<td>
<p>A logical to toggle calls to the <code>lines()</code> function in <span class="rlang"><b>R</b></span> to draw the lines;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_plotmw">plotMW</code></td>
<td>
<p>A logical to toggle to use the <code>abline()</code> function in <span class="rlang"><b>R</b></span> to plot cross lines for the <code class="reqn">\mathbf{M}</code> (<code><a href="#topic+M">M</a></code>) and  <code class="reqn">\mathbf{W}</code> (<code><a href="#topic+W">W</a></code>) copulas;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_ramp">ramp</code></td>
<td>
<p>A logical to toggle whether the level curves are ramped in thickness according to the probability of the line;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_delu">delu</code></td>
<td>
<p>The increment for <code class="reqn">\Delta u</code>. The default is 1 part in 1,000, which should often provide enough smoothness for many copulas in practice;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_delt">delt</code></td>
<td>
<p>The increment <code class="reqn">\Delta t</code> for the level curves to plot, defaults to 10-percent intervals. If <code>delt=0.5</code>, then only the median plus the consequences of a defined <code>getlevel</code> is used. If <code>NULL</code>, then a sequence of <code class="reqn">t</code> values is not made and only <code>getlevel</code> is used (if available);</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_getlevel">getlevel</code></td>
<td>
<p>If defined, then it is inserted into the sequence of levels <code class="reqn">t</code> and that level <code class="reqn">t</code> <code class="reqn">=</code> <code>getlevel</code> is returned in an <span class="rlang"><b>R</b></span> <code>list</code> data structure. If more than one level is desired, then instead of repeated calls to this function, the <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code> function could be considered;</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_silent">silent</code></td>
<td>
<p>The argument of the same name given over to <code>try()</code> wrapping the <code>try()</code> operation on forming sequences of <code class="reqn">t</code> for the curves (see sources); and</p>
</td></tr>
<tr><td><code id="level.curvesCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>lines()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Typically no values are returned because this function is used for its side effects, but the arguments can be such that the <code class="reqn">\{u, v\}</code> for <code class="reqn">\mathbf{C}(u,v) = t</code> are returned within an <span class="rlang"><b>R</b></span> <code>list</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COPinv">COPinv</a></code>, <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>, <code><a href="#topic+level.setCOP">level.setCOP</a></code>, <code><a href="#topic+joint.curvesCOP">joint.curvesCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
level.curvesCOP(cop=M, para=NULL, delt=0.02) # Upper bounds copula
## End(Not run)
## Not run: 
D &lt;- level.curvesCOP(cop=P,   getlevel=0.56)
str(D) # empty
D &lt;- level.curvesCOP(cop=P,   getlevel=0.5)
str(D) # contains stuff
D &lt;- level.curvesCOP(cop=PSP, getlevel=0.8)
str(D) # contains stuff
## End(Not run)
</code></pre>

<hr>
<h2 id='level.curvesCOP2'>Compute and Plot Level Curves of a Copula U with respect to V</h2><span id='topic+level.curvesCOP2'></span>

<h3>Description</h3>

<p>Compute and plot <em>level curves</em> or <em>level sets</em> of a copula for <code class="reqn">U</code> with respect to <code class="reqn">V</code> (Nelsen, 2006, pp. 12&ndash;13). The level curves at a levels <code class="reqn">t \mapsto [0+\Delta t, 1-\Delta t, \Delta t]</code> are defined for <code class="reqn">V \mapsto [0+\Delta v, 1-\Delta v, \Delta v]</code> by
</p>
<p style="text-align: center;"><code class="reqn">t = \mathbf{C}(u, v=V)\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">u</code>. Plotting is provided by this function because level curves are such an important visual attribute of a copula and highly useful for pedagogic  purposes. The above equation is implemented by the <em>inverse of a copula</em> using <code><a href="#topic+COPinv2">COPinv2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>level.curvesCOP2(cop=NULL, para=NULL, ploton=TRUE, lines=TRUE,
                 plotMW=FALSE, ramp=TRUE, delv=0.001, delt=0.10,
                 getlevel=NULL, silent=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="level.curvesCOP2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_lines">lines</code></td>
<td>
<p>A logical to toggle calls to the <code>lines()</code> function in <span class="rlang"><b>R</b></span> to draw the lines;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_plotmw">plotMW</code></td>
<td>
<p>A logical to toggle to use <code>abline()</code> function in <span class="rlang"><b>R</b></span> to plot cross lines for the <code class="reqn">\mathbf{M}</code> (<code><a href="#topic+M">M</a></code>) and  <code class="reqn">\mathbf{W}</code> (<code><a href="#topic+W">W</a></code>) copulas;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_ramp">ramp</code></td>
<td>
<p>A logical to toggle whether the level curves are ramped in thickness according to the probability of the line;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_delv">delv</code></td>
<td>
<p>The increment of <code class="reqn">\Delta v</code>. The default is 1 part in 1,000, which should often provide enough smoothness for many copulas in practice;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_delt">delt</code></td>
<td>
<p>The increment of <code class="reqn">\Delta t</code> for the level curves to plot, defaults to 10-percent intervals;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_getlevel">getlevel</code></td>
<td>
<p>If defined and level exists upon stepping through using <code>delt</code>, then the level curve at the <code>getlevel</code> is returned in an <span class="rlang"><b>R</b></span> <code>list</code> data structure;</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_silent">silent</code></td>
<td>
<p>The argument of the same name given over to <code>try()</code> wrapping the <code>try()</code> operation on forming sequences of <code class="reqn">t</code> for the curves (see sources); and</p>
</td></tr>
<tr><td><code id="level.curvesCOP2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>lines()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Typically no values are returned because this function is used for its side effects, but the arguments can be such that the <code class="reqn">\{u, v\}</code> for <code class="reqn">\mathbf{C}(u,v) = t</code> are returned within an <span class="rlang"><b>R</b></span> <code>list</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COPinv2">COPinv2</a></code>, <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>, <code><a href="#topic+level.setCOP2">level.setCOP2</a></code>, <code><a href="#topic+joint.curvesCOP2">joint.curvesCOP2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
level.curvesCOP2(cop=M, para=NULL, delt=0.02) # Upper bounds copula
## End(Not run)
</code></pre>

<hr>
<h2 id='level.setCOP'>Compute a Level Set of a Copula V with respect to U</h2><span id='topic+level.setCOP'></span>

<h3>Description</h3>

<p>Compute a <em>level curve</em> or <em>level set</em> of a copula for <code class="reqn">V</code> with respect to <code class="reqn">U</code> (Nelsen, 2006, pp. 12&ndash;13). The level curve at level <code class="reqn">t</code> is defined for <code class="reqn">U \mapsto [0+\Delta u, 1-\Delta u, \Delta u]</code> by
</p>
<p style="text-align: center;"><code class="reqn">t \mapsto \mathbf{C}(u{=}U, v)\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">v</code>. The function is largely a dispatcher to features implemented in <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>level.setCOP(cop=NULL, para=NULL, getlevel=NULL, delu=0.001, lines=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="level.setCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="level.setCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="level.setCOP_+3A_getlevel">getlevel</code></td>
<td>
<p>The level set for <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="level.setCOP_+3A_delu">delu</code></td>
<td>
<p>The increment for <code class="reqn">\Delta u</code>. The default is 1 part in 1,000, which should often in practice provide enough smoothness for many copulas;</p>
</td></tr>
<tr><td><code id="level.setCOP_+3A_lines">lines</code></td>
<td>
<p>A logical that matches the argument of the same name in <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>; and</p>
</td></tr>
<tr><td><code id="level.setCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>lines()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The level set for <code class="reqn">t</code> <code class="reqn">=</code> <code>getlevel</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+level.setCOP2">level.setCOP2</a></code>, <code><a href="#topic+level.curvesCOP">level.curvesCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set &lt;- level.setCOP(cop=PSP, getlevel=0.23, delu=0.005)
level.curvesCOP(cop=PSP)
lines(set$U, set$V, col=2, lwd=2) # manually draw the 23rd percentile
set &lt;- level.setCOP(cop=PSP, para=3.1, getlevel=0.67, lines=TRUE, col=4, lwd=4)
# Notice the change in the lines argument and using levelsetCOP2 to draw.
mtext("Level Curves and Special Level Sets for PSP copula") #
## End(Not run)
</code></pre>

<hr>
<h2 id='level.setCOP2'>Compute a Level Set of a Copula U with respect to V</h2><span id='topic+level.setCOP2'></span>

<h3>Description</h3>

<p>Compute a <em>level curve</em> or <em>level set</em> of a copula for <code class="reqn">U</code> with respect to <code class="reqn">V</code> (Nelsen, 2006, pp. 12&ndash;13). The level curve at level <code class="reqn">t</code> is defined for <code class="reqn">V \mapsto [0+\Delta v, 1-\Delta v, \Delta v]</code> by
</p>
<p style="text-align: center;"><code class="reqn">t \mapsto \mathbf{C}(u, v{=}V)\mbox{,}</code>
</p>

<p>and solving for <code class="reqn">u</code>. The function is largely a dispatcher to features of <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>level.setCOP2(cop=NULL, para=NULL, getlevel=NULL, delv=0.001, lines=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="level.setCOP2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="level.setCOP2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="level.setCOP2_+3A_getlevel">getlevel</code></td>
<td>
<p>The level set for <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="level.setCOP2_+3A_delv">delv</code></td>
<td>
<p>The increment for <code class="reqn">\Delta v</code>. The default is 1 part in 1,000, which should often in practice provide enough smoothness for many copulas;</p>
</td></tr>
<tr><td><code id="level.setCOP2_+3A_lines">lines</code></td>
<td>
<p>A logical that matches the argument of the same name in <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>; and</p>
</td></tr>
<tr><td><code id="level.setCOP2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>lines()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The level set for <code class="reqn">t</code> <code class="reqn">=</code> <code>getlevel</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+level.setCOP">level.setCOP</a></code>, <code><a href="#topic+level.curvesCOP2">level.curvesCOP2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set &lt;- level.setCOP2(cop=N4212cop, para=3.1, getlevel=0.23, delu=0.005)
level.curvesCOP2(cop=N4212cop, para=3.1, delv=0.001, delt=0.02)
lines(set$U, set$V, col=2, lwd=2) # manually draw the 23rd percentile
set &lt;- level.setCOP2(cop=N4212cop, para=3.1, getlevel=0.17, lines=TRUE, col=4, lwd=4)
# Notice the change in the lines argument and using levelsetCOP2 to draw.
mtext("Level Curves and Special Level Sets for N4212 copula") #
## End(Not run)
</code></pre>

<hr>
<h2 id='LzCOPpermsym'>Maximum Asymmetry Measure (or Vector) of a Copula by Exchangability</h2><span id='topic+LzCOPpermsym'></span>

<h3>Description</h3>

<p>Compute a measure of maximum exchangable asymmetry of a copula <code class="reqn">\mathbf{C}_\Theta</code> using <em>exchangability</em> (<em>permutation symmetry</em>) according to De Baets and De Meyer (2017) by
</p>
<p style="text-align: center;"><code class="reqn">\mu_{\infty\mathbf{C}}^{\mathrm{permsym}} = \mu_\infty^{\mathrm{permsym}} = 3 \times \mathrm{max}\bigl(\,|\,\mathbf{C}_\Theta(u,v) -
                       \mathbf{C}_\Theta(v,u)\,|\,\bigr)</code>
</p>

<p>for <code class="reqn">(u,v) \in \mathcal{I}^2</code>. De Baets and De Meyer comment that among many asymmetric metrics with copulas that <code class="reqn">\mu_\infty^{\mathrm{permsym}}</code> is &ldquo;by far the most interesting&rdquo; (De Baets and De Meyer, 2017, p. 36). The <code class="reqn">3</code> multiplier in the definition ensures that <code class="reqn">\mu_\infty^{\mathrm{permsym}} \in [0, 1]</code>. Those authors also conclude that exchangability of random variables, in general, is not a desired property in statistical models, and they use the <code class="reqn">\mu_\infty</code> notation in lieu of <code class="reqn">L_\infty^{\mathrm{permsym}}</code> (see documentation related to <code><a href="#topic+LpCOPpermsym">LpCOPpermsym</a></code>). The term &ldquo;Permutation-Mu&rdquo; is used for this measure in <code><a href="#topic+copBasic-package">copBasic-package</a></code> and in similar contexts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LzCOPpermsym(cop=NULL, para=NULL, n=5E4,
             type=c("halton", "sobol", "torus", "runif"),
             as.abs=TRUE, as.vec=FALSE, as.mat=FALSE, plot=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LzCOPpermsym_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if and as needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_n">n</code></td>
<td>
<p>The simulation size. The default seems sufficient for many practical applications but is suboptimal because the maximum operator in the definition is expected to potentially underestimate the true maximum. When a vector is returned, the default simulation size appears sufficient for many parameter estimation schemes;</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_type">type</code></td>
<td>
<p>The type of random number generator on <code class="reqn">\mathcal{I}^2</code> for computing the maximum (apparent) (see argument <code>n</code>) or a vector of signed differences (see <b>Details</b>);</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_as.abs">as.abs</code></td>
<td>
<p>A logical controlling whether the absolute value operation in the <code class="reqn">\mu_\infty^{\mathrm{permsym}}</code> definition is used. This feature permits flexibility retaining the sign of asymmetry;</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_as.vec">as.vec</code></td>
<td>
<p>A logical to disable the maximum operation but instead return the a vector of signed differences in the exchanged variables. If this argument is set true, then <code>as.abs</code> will be set false. The return of a vector of signed differences (still multiplied by 3) could be useful in parameter estimation schemes with a similar vector from an <em>empirical copula</em> (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>) (see <b>Details</b>);</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_as.mat">as.mat</code></td>
<td>
<p>A logical to disable the maximum operation (like <code>as.vec</code>), but instead return a matrix of the <code class="reqn">\mathcal{I}^2</code> values with third column as the vector of signed differences. If this argument is set true, then <code>as.abs</code> will be set false;</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_plot">plot</code></td>
<td>
<p>A logical to create a plot of the <code class="reqn">\mathcal{I}^2</code> domain used in the simulation with a plot title showing the <code>type</code> argument setting;</p>
</td></tr>
<tr><td><code id="LzCOPpermsym_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to support flexible implementation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>EFFECT OF RANDOM NUMBER GENERATION</em>&mdash;Package <span class="pkg">randtoolbox</span> provides for random number generation on forms different than simply simulating <em>uniform independent random variables</em> for <code class="reqn">\mathcal{I}^2</code>. The <em>Halton</em>, <em>Sobol</em>, and <em>Torus</em> types are implemented. The <code>plot</code> argument is useful for the user to see the differences in how these generators canvas the <code class="reqn">\mathcal{I}^2</code> domain.
</p>
<p>The default is Halton, which visually appears to better canvas <code class="reqn">\mathcal{I}^2</code> without the clumping that simple uniform random variables does and without the larger gaps of Sobol or Torus. Testing indicates that Halton might generally require the smallest simulation size of the others with simple uniform random variables potentially being the worst and hence such is not the default. Exceptions surely exist depending on the style of the asymmetry. Nevertheless, Halton, Sobol, and Torus produce more consistent estimation behavior with each having a monotone approach towards the true maximum than simple uniform random variables.
</p>
<p>The following example is a useful illustration of an asymmetrical <em>Clayton copula</em> (<code class="reqn">\mathbf{CL}(u,v; \Theta)</code>, <code><a href="#topic+CLcop">CLcop</a></code>) by <em>composition of a single copula</em> (<code><a href="#topic+composite1COP">composite1COP</a></code>) with the theorical <code class="reqn">\mu_\infty^{\mathrm{permsym}}</code> maxima computed by large sample simulation. A user might explore the effect of the random number generation by changing the <code>type</code> variable.
</p>
<pre>
  type &lt;- "halton"
  para &lt;- list(cop=CLcop, para=20, alpha=0.3, beta=0.1) # asymmetrical Clayton
  ti &lt;- LzCOPpermsym(cop=composite1COP, para=para, n=2E6, type=type) # large
  ns &lt;- as.integer( 10^seq(1, 4, by=0.05) ) # sequence of simulation sizes
  mi &lt;- sapply(ns, function(n) { # produce vector of maxima for simulation size
               LzCOPpermsym(cop=composite1COP, para=para, n=n, type=type) })
  ylim &lt;- range(c(0.06, mi, ti)) # vertical limits to ensure visibility
  plot(ns, mi, log="x", pch=21, bg=grey(0.9), ylim=ylim, main=type,
       xlab="Simulation size", ylab="Maximum asymmetry measure")
  abline(h=ti, lwd=3, col="seagreen") # large sample size estimate in green
</pre>
<p><em>COPULA PARAMETER ESTIMATION</em>&mdash;Parameter estimation using <em>signed permutation asymmetry vector</em> can readily be accomplished. In the self-contained example below, we will assume a parent of <em>Gumbel&ndash;Hougaard</em> (<code class="reqn">\mathbf{GH}(u,v; \Theta)</code>, <code><a href="#topic+GHcop">GHcop</a></code>) extended to asymmetry by using three parameters (<code class="reqn">\Theta = (10, 0.8, 0.6)</code>. Imagine that we unfortunately have a very small sample size (<code class="reqn">n = 100</code>) as &ldquo;hundred years of data.&rdquo; The small sample size facilitates the use of the <em>checkboard empirical copula</em> (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>); the sample size is small enough that the checkerboard helps smooth through ties. The simulation size for <code>LzCOPpermsym</code> is set &ldquo;large&rdquo; as presumed by the existing default.
</p>
<pre>
  para &lt;- c(10, 0.8, 0.6)                       # parameters of the parent
  nsam &lt;- 100; seed &lt;- 2; nsim &lt;- 5000          # note a change from default
  as.vec &lt;- TRUE       # set to FALSE to use just Permutation-Mu
  rhoP &lt;- rhoCOP(cop=GHcop, para=para)          # parent Spearman Rho
  UVsS &lt;- simCOP(cop=GHcop, para=para, n=nsam, seed=seed) # simulate a sample
  rhoS &lt;- rhoCOP(as.sample=TRUE,     para=UVsS) # sample Spearman Rho
  infS &lt;- LzCOPpermsym(cop=EMPIRcop, para=UVsS, n=nsim, type="halton",
                       as.vec=as.vec, ctype="checkerboard")
  # empirical copula used and returning signed asymmetry vector
  # transformation and re-transformation, GHcop paras &gt;1; [0,1]; and [0,1]
  tparf &lt;- function(par) c(exp(par[1]) + 1,  pnorm( par[2] ), pnorm( par[3] ))
  rparf &lt;- function(par) c(log(par[1]  - 1), qnorm( par[2] ), qnorm( par[3] ))

  ofunc &lt;- function(par, norho=FALSE) { # objective function
    mypara &lt;- tparf(par)
    rhoT   &lt;- rhoCOP(cop=GHcop, para=mypara)    # simulated Spearman Rho
    infT   &lt;- LzCOPpermsym(cop=GHcop, para=mypara, n=nsim, type="halton",
                           as.vec=as.vec)
    err    &lt;-    mean( (infT - infS)^2 )        # mean squared errors
    ifelse(norho, err, (rhoT - rhoS)^2 + err)   # with Spearman Rho or not
  }

  init.par &lt;- rparf(c(2, 0.5, 0.5)); rt &lt;- NULL # initial parameter guess
  try( rt &lt;- optim(init.par, ofunc, norho=FALSE) ) # 3D optimization
  if(is.null(rt)) stop("fatal, optim() returned NULL")
  # construct GHcop parameters from optimization with re-transformation
  sara &lt;- tparf(rt$par)
  rhoT &lt;- rhoCOP(cop=GHcop, para=sara)          # theoretical Spearman Rho
  UVsT &lt;- simCOP(cop=GHcop, para=sara, n=nsam, seed=seed,  # same seed sim by
                 cex=0.3, pch=16, col="red", ploton=FALSE) # est. parameters

  mara &lt;- mleCOP(UVsS, cop=GHcop, init.para=init.par, parafn=tparf)$para

  level.curvesCOP(cop=GHcop, para=para)
  level.curvesCOP(cop=GHcop, para=sara, ploton=FALSE, col="red" ) # perm diffs
  level.curvesCOP(cop=GHcop, para=mara, ploton=FALSE, col="blue") #   mleCOP()
</pre>
<p>Comparison of level curves between the known parent, the parameter estimation using function <code>LzCOPpermsym</code>, and the <em>maximum likelihood</em> by <code><a href="#topic+mleCOP">mleCOP</a></code> shows that signed asymmetry differences can be used for parameter estimation. One could use the maximum as in the definition, but for purposes of high-dimensional optimization, using the vector might be better to prevent local minima (less optimal solutions) being found if the <code class="reqn">\mu_\infty^{\mathrm{permsym}}</code> was used. Because vectors of differences between empirical copula and the fitted copula are involved, measures of fit using such differences are expected to be more favorable to optimization than using <code>LzCOPpermsym</code> than say maximum likelihood. The measures of fit AIC (<code><a href="#topic+aicCOP">aicCOP</a></code>), BIC (<code><a href="#topic+bicCOP">bicCOP</a></code>), and RMSE (<code><a href="#topic+rmseCOP">rmseCOP</a></code>), for example, are often, smaller for the <code>sara</code> fitted parameters than for the <code>mara</code> fitted (maximum likelihood). Finally, setting <code>as.vec &lt;- FALSE</code>, re-running, and thus using <code class="reqn">\mu_\infty^{\mathrm{permsym}}</code>, will likely show parameter estimates, visible through the level curves, that are much less favorable.
</p>
<p><em>RELATION TO ANOTHER DISTANCES</em>&mdash;The documentation for <code><a href="#topic+LpCOPpermsym">LpCOPpermsym</a></code> lists a supremum definition <code class="reqn">L_\infty^{\mathrm{permsym}}</code>, which is like <code class="reqn">\mu_\infty^{\mathrm{permsym}}</code> but lacks the multiplier of 3. However, that documentation mentions a ratio of 1/3 being as upper bounds and hence the De Baets and De Meyer (2017) reasoning for the 3 multiplier to rescale <code class="reqn">\mu_\infty^{\mathrm{permsym}} \in (0,1)</code>. The simple interrelations between the two functions are explored in the following example:
</p>
<pre>
  para &lt;- c(30, 0.2, 0.95); n &lt;- 5E4
  p &lt;- 1
  mean(abs(LzCOPpermsym(cop=GHcop, para=para, n=n,
                          as.vec=TRUE)/3)^p)^(1/p)   # 0.01867929
           LpCOPpermsym(cop=GHcop, para=para, p=p)   # 0.01867940
  p &lt;- 3
  mean(abs(LzCOPpermsym(cop=GHcop, para=para, n=n,
                          as.vec=TRUE)/3)^p)^(1/p)   # 0.02649376
           LpCOPpermsym(cop=GHcop, para=para, p=p)   # 0.02649317
</pre>
<p>The critical note is that <code><a href="#topic+LpCOPpermsym">LpCOPpermsym</a></code> is the integral of the absolute differences in permuted differences across <code class="reqn">\mathcal{I}^2</code>. Hence, it is an expectation. The <code>LzCOPpermsym</code> is difference because of the maximum of the differences. The computations in the example above show how the same information can be extracted from the two functions. De Baets and De Meyer (2017) do not make reference to raising and then rooting by the power <code class="reqn">p</code> as shown. The examples here provide credence to the default setting of <code>n</code> (simulation size) for several significant figures of similarity.
</p>


<h3>Value</h3>

<p>A scalar value for the measure is returned or other as dictated by arguments.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>De Baets, B., and De Meyer, H., 2017, Chapter 3&mdash;A look at copulas in a curved mirror: New York, Springer, ISBN 978&ndash;3&ndash;319&ndash;64221&ndash;5, pp. 33&ndash;47.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LpCOPpermsym">LpCOPpermsym</a></code>, <code><a href="#topic+isCOP.permsym">isCOP.permsym</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>LzCOPpermsym(cop=PSP)                            # 0, permutation symmetric
LzCOPpermsym(cop=GHcop, para=c(10, 0.9, 0.3))    # 0.17722861

# See also results of
# isCOP.permsym(cop=PSP)                         # TRUE
# isCOP.permsym(cop=GHcop, para=c(10, 0.9, 0.3)) # FALSE

## Not run: 
  sapply(1:4, function(r) { # Four rotations of a Galambos copula
    Lz &lt;- LzCOPpermsym(cop=COP, para=list(cop=GLcop, para=2, reflect=r))
    UV &lt;- simCOP(1000, cop=COP, para=list(cop=GLcop, para=2, reflect=r))
    mtext(paste0("Reflection ", r, " : Permutation-Mu =", Lz)); Lz })
  # [1] 0.00000000 0.00000000 0.07430326 0.07430326 
## End(Not run)
</code></pre>

<hr>
<h2 id='M'>The Fréchet&ndash;Hoeffding Upper-Bound Copula</h2><span id='topic+M'></span>

<h3>Description</h3>

<p>Compute the <em>Fréchet&ndash;Hoeffding upper-bound copula</em> (Nelsen, 2006, p. 11), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{M}(u,v) = \mathrm{min}(u,v)\mbox{.}</code>
</p>

<p>This is the copula of perfect association (<em>comonotonicity</em>, <em>perfectly positive dependence</em>) between <code class="reqn">U</code> and <code class="reqn">V</code> and is sometimes referred to as the <em>comonotonicity copula</em>. Its opposite is the <code class="reqn">\mathbf{W}(u,v)</code> copula (<em>countermonotonicity copula</em>; <code><a href="#topic+W">W</a></code>), and statistical <em>independence</em> is the <code class="reqn">\mathbf{\Pi}(u,v)</code> copula (<code><a href="#topic+P">P</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M(u, v, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="M_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="M_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; and</p>
</td></tr>
<tr><td><code id="M_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+W">W</a></code>, <code><a href="#topic+P">P</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>M(0.4,0.6)
M(0,0)
M(1,1)
</code></pre>

<hr>
<h2 id='M_N5p12b'>Shuffles of Upper-Bound Copula, Example 5.12b of Nelsen's Book</h2><span id='topic+M_N5p12b'></span>

<h3>Description</h3>

<p>Compute shuffles of <em>Fréchet&ndash;Hoeffding upper-bound copula</em> (Nelsen, 2006, p. 173), which is defined by partitioning <code class="reqn">\mathbf{M}</code> within <code class="reqn">\mathcal{I}^2</code> into <code class="reqn">n</code> subintervals:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{M}_n(u,v) = \mathrm{min}\biggl(u-\frac{k-1}{n}, v-\frac{n-k}{n} \biggr)</code>
</p>

<p>for points within the partitions
</p>
<p style="text-align: center;"><code class="reqn">(u,v) \in \biggl[\frac{k-1}{n}, \frac{k}{n}\biggr]\times \biggl[ \frac{n-k}{n}, \frac{n-k+1}{n}\biggr]\mbox{,\ }k = 1,2,\cdots,n</code>
</p>

<p>and for points otherwise out side the partitions
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{M}_n(u,v) = \mathrm{max}(u+v-1,0)\mbox{.}</code>
</p>

<p>The support of <code class="reqn">\mathbf{M}_n</code> consists of <code class="reqn">n</code> line segments connecting coordinate pairs <code class="reqn">\{(k-1)/n,\, (n-k)/n\}</code> and <code class="reqn">\{k/n,\, (n-k+1)/n\}</code> as stated by Nelsen (2006). It is useful that Nelsen stated such as this helps to identify that Nelsen's typesetting of the terms in the second square brackets&mdash;the <code class="reqn">V</code> direction&mdash;is reversed from that shown in this documentation. The <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) is defined by <code class="reqn">\rho_\mathbf{C} = (2/n^2) - 1</code>, and the <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by <code class="reqn">\tau_\mathbf{C} = (2/n) - 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M_N5p12b(u, v, para=1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="M_N5p12b_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="M_N5p12b_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="M_N5p12b_+3A_para">para</code></td>
<td>
<p>A positive integer <code class="reqn">n \in 1, 2, \cdots</code>; and</p>
</td></tr>
<tr><td><code id="M_N5p12b_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code>, <code><a href="#topic+W_N5p12a">W_N5p12a</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>M_N5p12b(0.4, 0.6, para=3)

## Not run: 
  # Nelsen (2006, exer. 5.12b, p. 173, fig. 5.3b)
  UV &lt;- simCOP(1000, cop=M_N5p12b, para=4) #
## End(Not run)
</code></pre>

<hr>
<h2 id='med.regressCOP'>Perform Median Regression using a Copula by Numerical Derivative Method for V with respect to U</h2><span id='topic+med.regressCOP'></span>

<h3>Description</h3>

<p>Perform <em>median regression</em> (Nelsen, 2006, pp. 217&ndash;218) of a copula by inversion of numerical derivatives of the copula (<code><a href="#topic+derCOPinv">derCOPinv</a></code>). The documentation for <code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code> provides mathematical details. The <code><a href="#topic+qua.regressCOP.draw">qua.regressCOP.draw</a></code> supports so-called <em>quantile regression</em> along various probability levels (see <b>Examples</b>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>med.regressCOP(u=seq(0.01,0.99, by=0.01), cop=NULL, para=NULL, level=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="med.regressCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="med.regressCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="med.regressCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="med.regressCOP_+3A_level">level</code></td>
<td>
<p>The level of the prediction interval to compute. For example, <code>level=0.95</code> will compute the 95-percent prediction interval as will <code>level=0.05</code> because internally a reflection check is made; and</p>
</td></tr>
<tr><td><code id="med.regressCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass such <code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code> and <code><a href="#topic+derCOPinv">derCOPinv</a></code> that are called in succession.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the median regressed probabilities of <code class="reqn">V</code> and provided <code class="reqn">U</code> values is returned. Note: if <code>level</code> is used, then the column ordering of the returned <code>data.frame</code> changes&mdash;please access the columns by the named idiom. The lower- and upper-prediction interval is contained in the columns repectively titled <code>Vlwr</code> and <code>Vupr</code> to mimic nomenclature somewhat of function <code>predict.lm()</code> in <span class="rlang"><b>R</b></span>.
</p>


<h3>Note</h3>

<p>An extended demonstration is needed concerning prediction intervals by median regression and a comparison to well-known linear regression. This also affords and opportunity to have <span class="pkg">copBasic</span> interact with the <span class="pkg">copula</span> package to gain access to the <em>Gaussian copula</em> and a <em>maximum pseudo-likelihood</em> estimation of the parameter.
</p>
<p>First, a function <code>NORMcop()</code> is defined to form the interconnect between the two packages. It is critically important that the user recognize that the so-called <code>copula</code> object as built by the <span class="pkg">copula</span> package is treated as the canonical <code>para</code> argument in <span class="pkg">copBasic</span> calls herein.
</p>
<pre>
  "NORMcop" &lt;-  # pCoupla() from package copula is analogous to COP()
  function(u,v, para=NULL, ...) {
    if(length(u) == 1) u &lt;- rep(u, length(v)) # see asCOP() for reasoning of
    if(length(v) == 1) v &lt;- rep(v, length(u)) # this "vectorization" hack
    return(copula::pCopula(matrix(c(u,v), ncol=2), para))
  }
</pre>
<p>The parameter <code class="reqn">\Theta \in [-1, 1]</code> (<em>Pearson R</em>) and <code class="reqn">\rho_\mathbf{C}(\Theta)</code> (<em>Spearman Rho</em>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>) and <code class="reqn">\tau_\mathbf{C}(\Theta)</code> (<em>Kendall Tau</em>, <code><a href="#topic+tauCOP">tauCOP</a></code>) are according to Salvadori <em>et al.</em> (2007, p. 255) the values
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C}(\Theta) = \frac{2}{\pi}\,\mathrm{arcsin}(\Theta)</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C}(\Theta) = \frac{6}{\pi}\,\mathrm{arcsin}(\Theta/2)\mbox{.}</code>
</p>

<p>Second, a bivariate <em>Gaussian copula</em> is defined with a parameter <code class="reqn">\Theta = 0.7</code> (thus <code class="reqn">\rho_\mathbf{C} = 0.6829105</code>, <code>rhoCOP(NORMcop, norm.cop)</code>) and then <code class="reqn">n=255</code> samples simulated from it. These are then cast into standard normal variates to mimic the idea of bivariate data in nonprobability units and facilitation regression comparison.
</p>
<pre>
  norm.cop &lt;- copula::normalCopula(c(0.7), dim = 2) # define a Gaussian copula
  UVs      &lt;- copula::rCopula(255, norm.cop) # draw 255 samples
  UVs      &lt;- as.data.frame(UVs); X &lt;- qnorm(UVs[,1]); Y &lt;- qnorm(UVs[,2])
</pre>
<p>Third, the <em>Weibull plotting positions</em> from the <code>pp()</code> function of package <span class="pkg">lmomco</span> are used to estimate the empirical probababilities of the data in <code>UV</code> that are casted into an <span class="rlang"><b>R</b></span> <code>matrix</code> because the <span class="pkg">copula</span> package expects the data as a <code>matrix</code> for the default parameter estimation. The code is completed by the specification of the fitted <em>Gaussian copula</em> in <code>fnorm.cop</code>.
</p>
<pre>
  UV &lt;- as.matrix(data.frame(U=lmomco::pp(X, sort=FALSE),
                             V=lmomco::pp(Y, sort=FALSE)))
  para &lt;- copula::fitCopula(copula::normalCopula(dim=2), UV)
  para &lt;- summary(para)$coefficients[1] # maximum pseudo-likelihood est.
  fnorm.cop &lt;- copula::normalCopula(para, dim=2)
</pre>
<p>Fourth, ordinary-least-squares (OLS) linear regression for <code class="reqn">Y\mid X</code> and <code class="reqn">X\mid Y</code> is computed, and the results plotted on top of the data points. The 2/3rd-prediction limits are computed by <code>predict.lm()</code> and also shown.
</p>
<pre>
  # Classical linear regressions from two perspectives.
  LMyx &lt;- lm(Y~X);       LMxy &lt;- lm(X~Y)
  YonX &lt;- summary(LMyx); XonY &lt;- summary(LMyx)

  QUorV &lt;- seq(-3,3, by=0.05) # vector for graphical operations
  plot(X, Y, col=8, pch=21)
  lines(QUorV, YonX$coefficients[1]+YonX$coefficients[2]*QUorV, col=2, lwd=4)
  tmp &lt;- predict.lm(LMyx, list(X=X), level=2/3, interval="prediction")
  lines(X, tmp[,2], col=2); lines(X, tmp[,3], col="red"  )

  lines(XonY$coefficients[1]+XonY$coefficients[2]*QUorV, QUorV, col=3, lwd=4)
  tmp &lt;- predict.lm(LMxy, list(Y=Y), level=2/3, interval="prediction")
  lines(tmp[,2], Y, col="green"); lines(tmp[,3], Y, col="green")
</pre>
<p>Finally, the demonstration ends with plotting of the median regression for the Gaussian copula and drawing the regression lines. The two median regression lines are nearly coincident with the OLS regression lines as anticipated with a reasonably large sample size albeit maximum pseudo-likelihood was used to estimate the copula parameter. The mean of a uniform distributed variable given say <code class="reqn">U = u</code> (horizontal axis) is 1/2, which coincides with the median. The median regression lines thus are coincident with the OLS lines even though OLS and real-space (native units of <code class="reqn">X</code> and <code class="reqn">Y</code>) were not used for their computation. The 2/3-prediction intervals also are plotted for comparison.
</p>
<pre>
  UorV    &lt;- c(0.001, seq(.02,0.98, by=.02), 0.999)
  MEDreg  &lt;- med.regressCOP( u=UorV, level=2/3, cop=NORMcop, para=fnorm.cop)
  MEDreg2 &lt;- med.regressCOP2(v=UorV, level=2/3, cop=NORMcop, para=fnorm.cop)
  lines(qnorm(UorV),         qnorm(MEDreg$V),    col="blue",    lty=2)
  lines(qnorm(UorV),         qnorm(MEDreg$Vlwr), col="blue",    lty=2)
  lines(qnorm(UorV),         qnorm(MEDreg$Vupr), col="blue",    lty=2)
  lines(qnorm(MEDreg2$U),    qnorm(UorV),        col="magenta", lty=2)
  lines(qnorm(MEDreg2$Ulwr), qnorm(UorV),        col="magenta", lty=2)
  lines(qnorm(MEDreg2$Uupr), qnorm(UorV),        col="magenta", lty=2)
</pre>
<p>A curious aside (Joe, 2014, p. 164) about the <em>Gaussian copula</em> is that <em>Blomqvist Beta</em> (<code><a href="#topic+blomCOP">blomCOP</a></code>) is equal to <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>), which can be checked by
</p>
<pre>
  blomCOP(cop=NORMcop, para=norm.cop) # 0.4936334
  tauCOP( cop=NORMcop, para=norm.cop) # 0.493633
</pre>
<p>and obviously the <code class="reqn">\beta_\mathbf{C} = \tau_\mathbf{C}</code> are numerically the same.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+med.regressCOP2">med.regressCOP2</a></code>, <code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code>, <code><a href="#topic+qua.regressCOP.draw">qua.regressCOP.draw</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# INDEPENDENCE YIELDS STRAIGHT LINES, RED IS THE MEDIAN REGRESSION
FF &lt;- seq(0.1, 0.9, by=0.1)
plot(c(0,1),c(0,1), type="n", lwd=3,
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
# Draw the regression of V on U and then U on V (wrtV=TRUE)
qua.regressCOP.draw(f=FF, cop=P, para=NA, ploton=FALSE)
qua.regressCOP.draw(f=FF, cop=P, para=NA, ploton=FALSE, wrtV=TRUE, lty=2)#
## End(Not run)

## Not run: 
# NEGATIVE PLACKETT THETA YIELDS CURVES DOWN TO RIGHT, RED IS THE MEDIAN REGRESSION
theta &lt;- 0.5; FF &lt;- seq(0.1, 0.9, by=0.1)
plot(c(0,1),c(0,1), type="n", lwd=3,
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
# Draw the regression of V on U and then U on V (wrtV=TRUE)
qua.regressCOP.draw(f=FF, cop=PLACKETTcop, ploton=FALSE, para=theta)
qua.regressCOP.draw(f=FF, cop=PLACKETTcop, ploton=FALSE, para=theta, wrtV=TRUE, lty=2)#
## End(Not run)
</code></pre>

<hr>
<h2 id='med.regressCOP2'>Perform Median Regression using a Copula by Numerical Derivative Method for U with respect to V</h2><span id='topic+med.regressCOP2'></span>

<h3>Description</h3>

<p>Perform <em>median regression</em> of a copula (Nelsen, 2006, pp. 217&ndash;218) by inversion of numerical derivatives of the copula (<code><a href="#topic+derCOPinv2">derCOPinv2</a></code>). The documentation for <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code> provides mathematical details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>med.regressCOP2(v=seq(0.01,0.99, by=0.01), cop=NULL, para=NULL, level=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="med.regressCOP2_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="med.regressCOP2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="med.regressCOP2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="med.regressCOP2_+3A_level">level</code></td>
<td>
<p>The level of the prediction interval to compute. For example, <code>level=0.95</code> will compute the 95-percent prediction interval as will <code>level=0.05</code> because internally a reflection check is made; and</p>
</td></tr>
<tr><td><code id="med.regressCOP2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass such <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code> and <code><a href="#topic+derCOPinv2">derCOPinv2</a></code> that are called in succession.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the median regressed probabilities of <code class="reqn">U</code> and provided <code class="reqn">V</code> values is returned. Note: if <code>level</code> is used, the column ordering of the returned <code>data.frame</code> changes&mdash;please access the columns by the named idiom. The lower- and upper-prediction interval bounds are contained in the columns repectively titled <code>Ulwr</code> and <code>Uupr</code> to mimic nomenclature somewhat of function <code>predict.lm()</code> in <span class="rlang"><b>R</b></span>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+med.regressCOP">med.regressCOP</a></code>, <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code>, <code><a href="#topic+qua.regressCOP.draw">qua.regressCOP.draw</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples under med.regressCOP
</code></pre>

<hr>
<h2 id='mleCOP'>Maximum Pseudo-Log-Likelihood Estimation for Copula Parameter Estimation</h2><span id='topic+mleCOP'></span>

<h3>Description</h3>

<p>Perform maximum pseudo-log-likelihood estimation (pMLE) for copula parameters by maximizing the function:
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{L}(\Theta_p) = \sum_{i=1}^n \log\bigl[ c(F_x(x_i), F_y(y_i); \Theta_p)\bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathcal{L}(\Theta_p)</code> is the log-likelihood for parameter vector <code class="reqn">\Theta_p</code> of dimension <code class="reqn">p</code>, and <code class="reqn">c(u,v; \Theta_p)</code> is the bivariate copula density. The <code class="reqn">u</code> and <code class="reqn">v</code> are estimated by the respective empirical cumulative distribution functions <code class="reqn">u = F_x(\cdots)</code> and <code class="reqn">v = F_y(\cdots)</code> for each of the joint realizations of a sample of size <code class="reqn">n</code>. The <code class="reqn">c(u,v)</code> is numerically estimated by the copula using the <code><a href="#topic+densityCOP">densityCOP</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mleCOP(u, v=NULL, cop=NULL, parafn=function(k) return(k),
          interval=NULL, init.para=NULL, verbose=FALSE, control=list(),
          the.zero=.Machine$double.eps^0.25, s=0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mleCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction and if <code>NULL</code> then <code>u</code> is treated as a two column <span class="rlang"><b>R</b></span> <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_parafn">parafn</code></td>
<td>
<p>A function responsible for generating the parameters. This is often just a simple return of a parameter vector as <span class="pkg">copBasic</span> uses this style of parameterization, but this function can take over parameter remapping to handle boundary conditions to benefit the search or provide an interface into other copula packages in <span class="rlang"><b>R</b></span> (see <b>Examples</b>);</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_interval">interval</code></td>
<td>
<p>The search interval for root finding, by <code>stats::optimise()</code>, if the parameter dimension of the copula is <code class="reqn">p = 1</code>. The interval is not used for <code class="reqn">p \ge 2</code>;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_init.para">init.para</code></td>
<td>
<p>The initial guesses for the parameters for the <code class="reqn">p</code>-dimensional optimization for <code class="reqn">p \ge 2</code>. The initial guess is used, by <code>stats::optim()</code>, if the parameter dimension of the copula is <code class="reqn">p = 1</code> and <code>interval</code> is <code>NULL</code> (see <b>Examples</b>);</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_verbose">verbose</code></td>
<td>
<p>A logical that internally is converted to integer to trigger 1 (sum of logs of <code><a href="#topic+densityCOP">densityCOP</a></code> shown), 2 (add reporting of the copula parameter on each iteration), or more levels of verbose reporting scheme within the objective function. This is independent from the <code>control$trace</code> of function <code>optim()</code>;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_control">control</code></td>
<td>
<p>This argument is the argument of the same name for <code>optim()</code>;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_the.zero">the.zero</code></td>
<td>
<p>The value for &ldquo;the zero&rdquo; of the copula density function. This argument is the argument of the same name for <code><a href="#topic+densityCOP">densityCOP</a></code>. The default here is intended to suggest that a tiny nonzero value for density will trap the numerical zero densities;</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_s">s</code></td>
<td>
<p>A vector of at least two presumably uniformly distributed or regular sequence of nonexceedance probabilities in <code class="reqn">U</code> for simulation of <code class="reqn">V</code> by <code><a href="#topic+simCOPv">simCOPv</a></code> and plotting of these <code class="reqn">U</code> and <code class="reqn">V</code>. This plotting is only made if the length of <code class="reqn">s</code> is nonzero and <code>verbose</code> is greater than or equal to 2. This plotting feature for the <code>s</code> is pedagogical  and intended for demonstration or teaching opportunities. This feature has no utility for the optimization itself; and</p>
</td></tr>
<tr><td><code id="mleCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass, see source code for the internally used functions that can pick these additional arguments up.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value(s) for the estimated parameters are returned within an <span class="rlang"><b>R</b></span> <code>list</code> where the elements listed below are populated unique to this package. The other elements of the returned list are generated from either the <code>optimise()</code> (1D, <code class="reqn">p = 1</code>) or <code>optim()</code> (pD, <code class="reqn">p \ge 2</code>) functions of <span class="rlang"><b>R</b></span>.
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The parameter(s) in a canonical element after the one-dimensional root finding (<code class="reqn">p = 1</code>) or multi-dimensional optimization (<code class="reqn">p \ge 2</code>) solutions are passed through <code>parafn</code> so that these are in the parameter units of the copula and not necessarily those transformed for the optimization;</p>
</td></tr>
<tr><td><code>packagetext</code></td>
<td>
<p>A helpful message unique to the <span class="pkg">copBasic</span> package;</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The maximum of the log-likelihood matching the name for the same quantity by the function <code>fitCopula</code> in package <span class="pkg">copula</span> though a separate implementation is used in <span class="pkg">copBasic</span>;</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike information criterion (AIC) (see also <code><a href="#topic+aicCOP">aicCOP</a></code>): <code class="reqn">\mathrm{AIC} = 2p - 2\mathcal{L}(\Theta_p)</code>; and</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Bayesian information criterion (BIC) (see also <code><a href="#topic+bicCOP">bicCOP</a></code>): <code class="reqn">\mathrm{BIC} = p\log(n) - 2\mathcal{L}(\Theta_p)</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This section provides for a more thorough assessment of pMLE than shown in the <b>Examples</b>.
</p>
<p><em>INTERFACE TO THE <span class="pkg">COPULA</span> PACKAGE</em>&mdash;A not uncommon question to the author is how can <span class="pkg">copBasic</span> support copulas from other packages?  A <span class="pkg">copBasic</span> pMLE implementation to the <em>Gaussian copula</em> from the <span class="pkg">copula</span> package is thus useful for instruction.
</p>
<p>Two interface functions are required for the pMLE situation. First, interface the <span class="pkg">copula</span> package in a generic form for the <span class="pkg">copBasic</span> package:
</p>
<pre>
  "cB2copula" &lt;-  # pCoupla() from package copula is analogous to COP()
  function(u,v, para=NULL, ...) {
    if(length(u) == 1) u &lt;- rep(u, length(v)) # see asCOP() for reasoning of
    if(length(v) == 1) v &lt;- rep(v, length(u)) # this "vectorization" hack
    return(copula::pCopula(matrix(c(u,v), ncol=2), para))
  }
</pre>
<p>where the <code>para</code> argument above must be built by the features of the <span class="pkg">copula</span> package. The following function then provides for parameter setup specific to the <em>Gaussian copula</em> having parameter <code class="reqn">\rho</code>:
</p>
<pre>
  copula2cBpara &lt;- function(rho) return(copula::normalCopula(rho, dim = 2))
</pre>
<p>Now, let us perform a parameter estimate for a sample of size <code class="reqn">n=900</code>:
</p>
<pre>
  set.seed(162); UV &lt;- simCOP(n=900, cop=cB2copula, para=copula2cBpara(0.45))
  mleCOP(UV, cop=cB2copula, parafn=copula2cBpara, interval=c(-1,1))$para
  #   rho.1  =  0.4248822
</pre>
<p>The search interval for the <em>Gaussian copula</em> is <code class="reqn">\rho \in [-1, 1]</code>, and the final result is <code class="reqn">\rho = 0.4458822</code>.
</p>
<p><em>MULTI-DIMENSIONAL EXAMPLE OF pMLE</em>&mdash;Consider a 2-parameter <em>Gumbel&ndash;Hougaard copula</em> (<code class="reqn">\mathbf{GH}(\Theta_1, \Theta_2)</code>) but now use the <code>parafn</code> argument to provide boundary condition assistance through function <code>GH2pfunc</code> to the <code>optim()</code> function that performs the maximization.
</p>
<pre>
  set.seed(162); UV &lt;- simCOP(n=890, cop=GHcop, para=c(2.4, .06))
  GH2pfunc &lt;- function(p) { return(c(exp(p[1])+1, exp(p[2]))) }
  ML &lt;- mleCOP(UV$U, UV$V, cop=GHcop, init.para=c(1,1), parafn=GH2pfunc)
  print(ML$para) # [1] 2.2755018 0.1194788
</pre>
<p>and the result is <code class="reqn">\Theta_{1,2} = (2.2755018, 0.1194788)</code>. Next, consider now a 3-parameter <code class="reqn">\mathbf{GH}(\Theta, \pi_1, \pi_2)</code> copula and again use the <code>parafn</code> argument through function <code>GH3pfunc</code>  but notice that the 2nd and 3rd parameters are now mapped into <code class="reqn">0 \le \pi_1, \pi_2 \le 1</code> domain using the <code>pnorm()</code> function.
</p>
<pre>
  set.seed(162); UV &lt;- simCOP(n=500, cop=GHcop, para=c(5.5, .6, .9))
  GH3pfunc &lt;- function(p) { return(c(exp(p[1])+1, pnorm(p[2]), pnorm(p[3]))) }
  ML &lt;- mleCOP(UV$U, UV$V, cop=GHcop, init.para=c(1, .5, .5), parafn=GH3pfunc)
  print(ML$para) # [1] 5.3742229 0.6141652 0.9382638
</pre>
<p>and the result is <code class="reqn">\Theta = 5.3742229</code> and <code class="reqn">\pi_{1,2} = (0.6141652, 0.9382638)</code>.
</p>
<p><em>ANOTHER MULTI-DIMENSIONAL EXAMPLE OF pMLE</em>&mdash;Finally, an experiment can be made fitting a 3-parameter <code class="reqn">\mathbf{GH}(\Theta, \pi_1, \pi_2)</code> to a simulation from a 2-parameter <code class="reqn">\mathbf{GH}(\beta_1, \beta_2)</code>, where the seed is just arbitrary and the <em>Vuong Procedure</em> (<code><a href="#topic+vuongCOP">vuongCOP</a></code>) is used to compare fits and make inference. The parameter functions <code>GH2pfunc</code> and <code>GH3pfunc</code> are as before.
</p>
<pre>
  set.seed(10); UV &lt;- simCOP(n=500, cop=GHcop, para=c(1.7, 1.86))
  GH2pfunc &lt;- function(p) { return(c(exp(p[1])+1,   exp(p[2])              )) }
  GH3pfunc &lt;- function(p) { return(c(exp(p[1])+1, pnorm(p[2]), pnorm(p[3]) )) }
  para1 &lt;- mleCOP(UV, cop=GHcop, init.para=c(1,1),     parafn=GH2pfunc)$para
  para2 &lt;- mleCOP(UV, cop=GHcop, init.para=c(1,.5,.5), parafn=GH3pfunc)$para
  vuongCOP(UV, cop1=GHcop, para1=para1, cop2=GHcop, para2=para2)$message
  #[1] "Copula 1 has better fit than Copula 2 at 100 x (1-alpha) level"
</pre>
<p>The results show the 2-p <code class="reqn">\mathbf{GH}</code> is a better fit to the simulated data than the 3-p <code class="reqn">\mathbf{GH}</code>, which seems a bit self evident?  Plot some same-seeded simulations just to confirm.
</p>
<pre>
  set.seed(67) # First the estimated parameters but with the correct model.
  UV &lt;- simCOP(n=200, GHcop, para=para1, snv=TRUE, pch=16, col=2)
  set.seed(67) # Second, the estimated incorrect model.
  UV &lt;- simCOP(n=200, GHcop, para=para2, snv=TRUE, ploton=FALSE)
</pre>
<p>Yes, differences in form are manifest in the produced graphic. Now, let us try another set of parameters and again an arbitrarily-chosen seed.
</p>
<pre>
  set.seed(10); UV &lt;- simCOP(n=500, cop=GHcop, para=c(1.91, 0.16))
  para1 &lt;- mleCOP(UV, cop=GHcop, init.para=c(1,1),     parafn=GH2pfunc)$para
  para2 &lt;- mleCOP(UV, cop=GHcop, init.para=c(1,.5,.5), parafn=GH3pfunc)$para
  vuongCOP(UV, cop1=GHcop, para1=para1, cop2=GHcop, para2=para2)$message
  #[1] "Copulas 1 and 2 are not significantly different at 100 x (1-alpha)"
</pre>
<p>The results show equivalence, let us now check a graphic.
</p>
<pre>
  set.seed(67); z &lt;- simCOP(n=200, GHcop, para=para1, snv=TRUE, pch=16, col=2)
  set.seed(67); z &lt;- simCOP(n=200, GHcop, para=para2, snv=TRUE, ploton=FALSE)
</pre>
<p>The differences are small but the differences might be inflating into the lower left corner. What sample size could conceivably begin to distinguish between the copula?
</p>
<pre>
  kullCOP(cop1=GHcop, cop2=GHcop, para1=para1, para2=para2) # 625 on this run

  nsim &lt;- 20; set.seed(67)
  Results &lt;- sapply(1:nsim, function(i) {
    UV &lt;- simCOP(n=625, cop=GHcop, para=c(1.91, .16), graphics=FALSE)
    p1 &lt;- mleCOP(UV, cop=GHcop, init.para=c(1,1),     parafn=GH2pfunc)$para
    p2 &lt;- mleCOP(UV, cop=GHcop, init.para=c(1,.5,.5), parafn=GH3pfunc)$para
    vuongCOP(UV, cop1=GHcop, para1=p1, cop2=GHcop, para2=p2)$result })
  sum(Results)
</pre>
<p>The summation yields 6 of 20 for which copula 1 has the better fit, but with <code class="reqn">n=1{,}000</code> instead of <code class="reqn">n=625</code>, the sum of the <code>Results</code> is 13 of 20 (so better than half the time). This seems to be in conflict with what the <code class="reqn">n_{fg}</code> sample size from <code><a href="#topic+kullCOP">kullCOP</a></code> should be telling. The author thinks it should be 18 to 19 of 20 (95th percentile) based on what the <code><a href="#topic+kullCOP">kullCOP</a></code> is reported to do (NEED TO LOOK INTO THIS).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityCOP">densityCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See also extended code listings and discussion in the Note section

## Not run: 
  # Here, we study the trajectory of the objective function in a simple
  # 1-dimensional optimization. See how we must provide the interval.
  set.seed(162); UV &lt;- simCOP(n=188, cop=PLcop, para=5.6)
  ML &lt;- mleCOP(UV$U, UV$V, cop=PLcop, interval=c(0.1, 40)) # 5.225459 estimated

  Thetas &lt;- 10^(seq(log10(0.001), log10(100), by=0.005))
  MLs &lt;- sapply(Thetas, function(k)
                densityCOP(UV$U, UV$V, cop=PLcop, para=k, sumlogs=TRUE))
  plot(Thetas, MLs, log="x", type="l", # draw the pMLE solution process
       xlab="Plackett Theta", ylab="sum of log densities")
  lines(rep(ML$para, 2), c(ML$objective, par()$usr[3]), col="red")
  points(ML$para, ML$objective, pch=16, col="red") #
## End(Not run)

## Not run: 
  # Here, we study again 1-dimensional optimization but use the
  # multidimensional version with an alert issued.
  set.seed(149); UV &lt;- simCOP(1000, cop=CLcop, para=pi)
  # Warning messages about using optim() for 1D solution
  mleCOP(UV, cop=CLcop, init.para=2)$para          # 3.082031
  # No warning message, optimise() called instead.
  mleCOP(UV, cop=CLcop, interval=c(0,1E2))$para    # 3.081699 
## End(Not run)

## Not run: 
  # Here, we evaluate a 2-dimensional problem using a Plackett again but with
  # the addition of asymmetry towards high V outliers from the Plackett cloud.
  # This example also adds the internal verbose and graphic diagnostics for
  # the iterations of the optimizer. Here, we learn that we need on a time have
  # some idea where the solution might lay so that we can provide a suitable
  # set of initial parameters for the algorithm.
  para &lt;- list(beta=-0.1, cop=PLcop, para1=1000)
  UV &lt;- simCOP(2000, cop=breveCOP, para=para); abline(0, 1, col="red", lwd=3)
  PL2pfunc &lt;- function(p) { # see here example of parameter transform
    list(beta=2*pnorm(p[1])-1, para=exp(p[2]), cop=PLcop) # [-1,+1], &gt;=0
  }
  init.para &lt;- c(0.2535, log(0.02)) # These will not find a solution with this
  # guess of negative association, but the next works by using an external
  # estimate of the Plackett parameters and here we test with a positive
  # skewness (beta for breveCOP &gt; 0) although we know the parent had negative.
  init.para &lt;- c(0.2535, log(PLACKETTpar(UV$U, UV$V, byrho=TRUE))) # beta=0.200
  rt &lt;- mleCOP(u=UV$U, v=UV$V, init.para=init.para, cop=breveCOP,
               parafn=PL2pfunc, verbose=2, s=seq(0,1, by=0.005)) #
## End(Not run)
</code></pre>

<hr>
<h2 id='N4212cop'>The Copula of Equation 4.2.12 of Nelsen's Book</h2><span id='topic+N4212cop'></span>

<h3>Description</h3>

<p>The <em>N4212 copula</em> (Nelsen, 2006, p. 91; eq. 4.2.12) is named by the author (Asquith) for the <span class="pkg">copBasic</span> package and is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\mathrm{N4212}}(u,v; \Theta) = \biggl(1 + \bigl[(u^{-1} -1)^\Theta + (v^{-1} -1)^\Theta\bigr]^{1/\Theta}\biggr)^{-1}\mbox{.}</code>
</p>

<p>The <code class="reqn">\mathbf{N4212}(u,v)</code> copula is <em>not comprehensive</em> because for <code class="reqn">\Theta = 1</code> the copula becomes the so-called <code class="reqn">\mathbf{PSP}(u,v)</code> copula (see <code><a href="#topic+PSP">PSP</a></code>) and as <code class="reqn">\Theta \rightarrow \infty</code> the copula becomes <code class="reqn">\mathbf{M}(u,v)</code> (see <code><a href="#topic+M">M</a></code>). The copula is undefined for <code class="reqn">\Theta &lt; 1</code>. The N4212 copula has respective <em>lower-</em> and <em>upper-tail dependency</em> (see <code><a href="#topic+taildepCOP">taildepCOP</a></code>).
</p>
<p>Although <span class="pkg">copBasic</span> is intended to not implement or &ldquo;store house&rdquo; the enormous suite of copula functions available in the literature, the N4212 copula is included to give the package another copula to test or test in numerical examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>N4212cop(u, v, para=NULL, infis=100, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="N4212cop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="N4212cop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="N4212cop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="N4212cop_+3A_infis">infis</code></td>
<td>
<p>What is infinity? Testing shows that <code>infis =</code> <code class="reqn">\Theta &gt; 100</code> is about right to consider the copula as becoming <code class="reqn">\mathbf{M}(u,v)</code> (see <code><a href="#topic+M">M</a></code>); and</p>
</td></tr>
<tr><td><code id="N4212cop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N4212cop(0.4,0.6, para=1) == PSP(0.4,0.6) # TRUE
N4212cop(0.4,0.6, para=10) # 0.3999928
taildepCOP(cop=N4212cop, para=10) # LamL = 0.93303; LamU = 0.92823
## Not run: 
D &lt;- simCOP(n=400, cop=N4212cop, para=2)
D &lt;- simCOP(n=400, cop=N4212cop, para=10,  ploton=FALSE, col=2)
D &lt;- simCOP(n=400, cop=N4212cop, para=100, ploton=FALSE, col=3)#
## End(Not run)
</code></pre>

<hr>
<h2 id='ORDSUMcop'>Ordinal Sums of M-Copula</h2><span id='topic+ORDSUMcop'></span>

<h3>Description</h3>

<p>Compute <em>ordinal sums of a copula</em> (Nelsen, 2006, p. 63) or <em>M-ordinal sum of the summands</em> (Klement <em>et al.</em>, 2017) within <code class="reqn">\mathcal{I}^2</code> into <code class="reqn">n</code> partitions (possibly infinite) within <code class="reqn">\mathcal{I}^2</code>. According to Nelsen, letting <code class="reqn">\mathcal{J}</code> denote a <em>partition</em> of <code class="reqn">\mathcal{I}^2</code> and <code class="reqn">\mathcal{J}_i = [a_i,\, b_i]</code> be the <code class="reqn">i</code>th partition that does not overlap with others and letting also <code class="reqn">\mathbf{C}_i</code> be a copula for the <code class="reqn">i</code>th partition, then the <em>ordinal sum</em> of these <code class="reqn">\mathbf{C}_i</code> with parameters <code class="reqn">\Theta_i</code> <em>with respect to</em> <code class="reqn">\mathcal{J}_i</code> is the copula <code class="reqn">\mathbf{C}</code> given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}\bigl(u,v; \mathcal{J}_i, \mathbf{C}_i, \Theta_i, i \in 1,2,\cdots,n\bigr) = a_i + (b_i-a_i)\mathbf{C}_i\biggl(\frac{u-a_i}{b_i-a_i},\, \frac{v-a_i}{b_i-a_i};  \Theta_i\biggr)\  \mbox{for}\ (u,v) \in \mathcal{J}^2\mbox{,}</code>
</p>

<p>for points within the partitions, and for points otherwise outside the partitions the coupla is given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}\bigl(u,v; \mathcal{J}_i, \mathbf{C}_i, i \in 1,2,\cdots,n\bigr) = \mathbf{M}(u,v)\  \mathrm{for}\ (u,v) \ni \mathcal{J}^2\mbox{, and}</code>
</p>

<p>let <code class="reqn">\mathbf{C}_\mathcal{J}(u,v)</code> be a convenient abbreviation for the copula. Finally, Nelsen (2006, theorem 3.2.1) states that a copula is an ordinal sum if and only if for a <code class="reqn">t</code> if <code class="reqn">\mathbf{C}(t,t)=t</code> for <code class="reqn">t \in (0,1)</code>. The <em>diagonal of a coupla</em> can be useful for quick assessment (see <b>Examples</b>) of this theorem. (See <code><a href="#topic+ORDSUWcop">ORDSUWcop</a></code>, <em>W-ordinal sum of the summands</em>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ORDSUMcop(u,v, para=list(cop=W, para=NA, part=c(0,1)), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ORDSUMcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="ORDSUMcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="ORDSUMcop_+3A_para">para</code></td>
<td>
<p>A list of sublists for the coupla, parameters, and partitions (see <b>Examples</b>) and some attempt for intelligent in-fill of <code>para</code> is made within the sources (the default <code>para</code> is an example for which <code>cop</code> and <code>para</code> elements are converted to lists). The user is responsible that <code>part</code> element properly canvases by end-point alignment all of <code class="reqn">\mathcal{I}^2</code>; and</p>
</td></tr>
<tr><td><code id="ORDSUMcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Klement, E.P., Kolesárová, A., Mesiar, R., Saminger-Platz, S., 2017, Copula constructions using ultramodularity (chap. 9) <em>in</em> Copulas and dependence models with applications&mdash;Contributions in honor of Roger B. Nelsen, <em>eds.</em> Flores, U.M., Amo Artero, E., Durante, F., Sánchez, J.F.: Springer, Cham, Switzerland, ISBN 978&ndash;3&ndash;319&ndash;64220&ndash;9, <a href="https://doi.org/10.1007/978-3-319-64221-5">doi:10.1007/978-3-319-64221-5</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+copBasic-package">copBasic-package</a></code>, <code><a href="#topic+W_N5p12a">W_N5p12a</a></code>, <code><a href="#topic+ORDSUWcop">ORDSUWcop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  para &lt;- list(cop=c(CLcop, M, PLcop, GHcop), para=list(4, NA, 0.1, c(3,4)),
              part=list(c(0,0.25), c(0.25,0.35), c(0.35,0.85), c(0.85,1)))
  UV &lt;- simCOP(n=100, cop=ORDSUMcop, para=para, ploton=FALSE)
  plot(c(0,1), c(0,1), xlab="U, NONEXCEEDANCE PROBABILITY", type="n",
                       ylab="V, NONEXCEEDANCE PROBABILITY")
  for(k in seq_len(length(para$part))) {         #  to draw the partitions
    a &lt;- para$part[[k]][1]; b &lt;- para$part[[k]][2]
    polygon(c(a, b, b, a, a), c(a,a,b,b,a), lty=2, lwd=0.8, col="lightgreen")
    text((a+b)/2, (a+b)/2, k, cex=3, col="blue") # numbered by partition
  }
  points(UV, pch=21, cex=0.8, col=grey(0.1), bg="white") #
## End(Not run)

## Not run: 
  para &lt;- list(cop=c(GHcop), para=list(c(2,3)), # internally replicated
               part=list(c(0,0.2), c(0.2,0.3), c(0.3,0.5), c(0.5,0.7), c(0.7,1)))
  UV &lt;- simCOP(n=100, cop=ORDSUMcop, para=para, ploton=FALSE)
  plot(c(0,1), c(0,1), xlab="U, NONEXCEEDANCE PROBABILITY", type="n",
                       ylab="V, NONEXCEEDANCE PROBABILITY")
  for(k in seq_len(length(para$part))) {         #  to draw the partitions
    a &lt;- para$part[[k]][1]; b &lt;- para$part[[k]][2]
    polygon(c(a, b, b, a, a), c(a,a,b,b,a), lty=2, lwd=0.8, col="lightgreen")
    text((a+b)/2, (a+b)/2, k, cex=3, col="blue") # numbered by partition
  }
 points(UV, pch=21, cex=0.8, col=grey(0.1), bg="white") #
## End(Not run)

## Not run: 
  # In this example, it is important that the delt is of the resolution
  # matching the  edges of the partitions.
  para &lt;- list(cop=P, para=list(NULL),
               part=list(c(0,0.257), c(0.257,0.358), c(0.358,1)))
  DI &lt;- diagCOP(cop=ORDSUMcop, para=para, delt=0.001)
  if(sum(DI$diagcop == DI$t) &gt;= 1) {
    message("The ORDSUMcop() operation is an ordinal sum if there exists\n",
            "a t=(0,1) exists such that C(t,t)=t by Nelsen (2006, theorem 3.2.1).")
  }
  abline(0,1, col="red") #
## End(Not run)
</code></pre>

<hr>
<h2 id='ORDSUWcop'>Ordinal Sums of W-Copula</h2><span id='topic+ORDSUWcop'></span>

<h3>Description</h3>

<p>Compute <em>W-ordinal sum of the summands</em> (Klement  <em>et al.</em>, 2017) within <code class="reqn">\mathcal{I}^2</code> into <code class="reqn">n</code> partitions (possibly infinite) within <code class="reqn">\mathcal{I}^2</code>. Letting <code class="reqn">\mathcal{J}</code> denote a <em>partition</em> of <code class="reqn">\mathcal{I}^2</code> and <code class="reqn">\mathcal{J}_i = [a_i,\, b_i]</code> be the <code class="reqn">i</code>th partition that does not overlap with others and letting also <code class="reqn">\mathbf{C}_i</code> be a copula for the <code class="reqn">i</code>th partition, then the <em>ordinal sum</em> of these <code class="reqn">\mathbf{C}_i</code> with parameters <code class="reqn">\Theta_i</code> <em>with respect to</em> <code class="reqn">\mathcal{J}_i</code> is the copula <code class="reqn">\mathbf{C}</code> given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}\bigl(u,v; \mathcal{J}_i, \mathbf{C}_i, \Theta_i, i \in 1,2,\cdots,n\bigr) = a_i + (b_i-a_i)\mathbf{C}_i\biggl(\frac{u-a_i}{b_i-a_i},\, \frac{v-1+b_i}{b_i-a_i};  \Theta_i\biggr)\  \mbox{for}\ (u,v) \in \mathcal{J}^2\mbox{,}</code>
</p>

<p>for points within the partitions, and for points otherwise outside the partitions the coupla is given by
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}\bigl(u,v; \mathcal{J}_i, \mathbf{C}_i, i \in 1,2,\cdots,n\bigr) = \mathbf{W}(u,v)\  \mathrm{for}\ (u,v) \ni \mathcal{J}^2\mbox{, and}</code>
</p>

<p>let <code class="reqn">\mathbf{C}_\mathcal{J}(u,v)</code> be a convenient abbreviation for the copula. (See <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code>, <em>M-ordinal sum of the summands</em>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ORDSUWcop(u,v, para=list(cop=M, para=NA, part=c(0,1)), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ORDSUWcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="ORDSUWcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="ORDSUWcop_+3A_para">para</code></td>
<td>
<p>A list of sublists for the coupla, parameters, and partitions (see <b>Examples</b>) and some attempt for intelligent in-fill of <code>para</code> is made within the sources (the default <code>para</code> is an example for which <code>cop</code> and <code>para</code> elements are converted to lists). The user is responsible that <code>part</code> element properly canvases by end-point alignment all of <code class="reqn">\mathcal{I}^2</code>; and</p>
</td></tr>
<tr><td><code id="ORDSUWcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Klement, E.P., Kolesárová, A., Mesiar, R., Saminger-Platz, S., 2017, Copula constructions using ultramodularity (chap. 9) <em>in</em> Copulas and dependence models with applications&mdash;Contributions in honor of Roger B. Nelsen, <em>eds.</em> Flores, U.M., Amo Artero, E., Durante, F., Sánchez, J.F.: Springer, Cham, Switzerland, ISBN 978&ndash;3&ndash;319&ndash;64220&ndash;9, <a href="https://doi.org/10.1007/978-3-319-64221-5">doi:10.1007/978-3-319-64221-5</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+copBasic-package">copBasic-package</a></code>, <code><a href="#topic+W_N5p12a">W_N5p12a</a></code>, <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- list(cop=c(CLcop, GHcop), para=list(5, 2), part=c(0,0.25,1)) # break points
UV &lt;- simCOP(n=100, cop=ORDSUMcop, seed=1, para=para, ploton=TRUE, pch=16)
UV &lt;- simCOP(n=100, cop=ORDSUWcop, seed=1, para=para, ploton=FALSE)

## Not run: 
  para &lt;- list(cop=c(CLcop, M, PLcop, GHcop), para=list(4, NA, 0.1, c(3,4)),
              part=list(c(0,0.25), c(0.25,0.35), c(0.35,0.85), c(0.85,1)))
  UV &lt;- simCOP(n=100, cop=ORDSUWcop, para=para, ploton=FALSE)
  plot(c(0,1), c(0,1), xlab="U, NONEXCEEDANCE PROBABILITY", type="n",
                       ylab="V, NONEXCEEDANCE PROBABILITY")
  for(k in seq_len(length(para$part))) {         #  to draw the partitions
    a &lt;- para$part[[k]][1]; b &lt;- para$part[[k]][2]
    polygon(c(a, b, b, a, a), c(1-a,1-a,1-b,1-b,1-a), lty=2, lwd=0.8, col="lightgreen")
    text((a+b)/2, (1-a+1-b)/2, k, cex=3, col="blue") # numbered by partition
  }
  points(UV, pch=21, cex=0.8, col=grey(0.1), bg="white") #
## End(Not run)

## Not run: 
  para = list(cop=c(GHcop), para=list(c(2,3)), # internally replicated
              part=list(c(0,0.2), c(0.2,0.3), c(0.3,0.5), c(0.5,0.7), c(0.7,1)))
  UV &lt;- simCOP(n=100, cop=ORDSUWcop, para=para, ploton=FALSE)
  plot(c(0,1), c(0,1), xlab="U, NONEXCEEDANCE PROBABILITY", type="n",
                       ylab="V, NONEXCEEDANCE PROBABILITY")
  for(k in seq_len(length(para$part))) {         #  to draw the partitions
    a &lt;- para$part[[k]][1]; b &lt;- para$part[[k]][2]
    polygon(c(a, b, b, a, a), c(1-a,1-a,1-b,1-b,1-a), lty=2, lwd=0.8, col="lightgreen")
    text((a+b)/2, (1-a+1-b)/2, k, cex=3, col="blue") # numbered by partition
  }
  points(UV, pch=21, cex=0.8, col=grey(0.1), bg="white") #
## End(Not run)
</code></pre>

<hr>
<h2 id='P'>The Product (Independence) Copula</h2><span id='topic+P'></span>

<h3>Description</h3>

<p>Compute the <em>product copula</em> (Nelsen, 2006, p. 12), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{\Pi}(u,v) = uv\mbox{.}</code>
</p>

<p>This is the copula of statistical independence between <code class="reqn">U</code> and <code class="reqn">V</code> and is sometimes referred to as the <em>independence copula</em>.  The two extreme antithesis copulas are the <em>Fréchet&ndash;Hoeffding upper-bound</em> (<code><a href="#topic+M">M</a></code>) and <em>Fréchet&ndash;Hoeffding lower-bound</em> (<code><a href="#topic+W">W</a></code>) copulas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>P(u, v, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="P_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="P_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; and</p>
</td></tr>
<tr><td><code id="P_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+W">W</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>P(c(0.4, 0, 1), c(0, 0.6, 1))

## Not run: 
n &lt;- 100000 # giant sample size, L-comoments are zero
# PERFECT INDEPENDENCE
UV &lt;- simCOP(n=n, cop=P, graphics=FALSE)
lmomco::lcomoms2(UV, nmom=4)
# The following are Taus_r^{12} and Taus_r^{21}
# L-corr:        0.00265 and  0.00264 ---&gt; ZERO
# L-coskew:     -0.00121 and  0.00359 ---&gt; ZERO
# L-cokurtosis:  0.00123 and  0.00262 ---&gt; ZERO

# MODEST POSITIVE CORRELATION
rho &lt;- 0.6; # Spearman Rho
theta &lt;- PLACKETTpar(rho=rho) # Theta = 5.115658
UV &lt;- simCOP(n=n, cop=PLACKETTcop, para=theta, graphics=FALSE)
lmomco::lcomoms2(UV, nmom=4)
# The following are Taus_r^{12} and Taus_r^{21}
# L-corr        0.50136 and  0.50138 ---&gt; Pearson R == Spearman Rho
# L-coskews    -0.00641 and -0.00347 ---&gt; ZERO
# L-cokurtosis -0.00153 and  0.00046 ---&gt; ZERO 
## End(Not run)
</code></pre>

<hr>
<h2 id='PARETOcop'>The Pareto Copula</h2><span id='topic+PARETOcop'></span><span id='topic+PAcop'></span>

<h3>Description</h3>

<p>The <em>Pareto copula</em> (Nelsen, 2006, pp. 33) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{PA}(u,v) = \bigl[(1-u)^{-\Theta}+(1-v)^{-\Theta}\bigr]^{-1/\Theta}\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in [0, \infty)</code>. As <code class="reqn">\Theta \rightarrow 0^{+}</code>, the copula limits to the <code class="reqn">\mathbf{\Pi}</code> copula (<code><a href="#topic+P">P</a></code>) and the <code class="reqn">\mathbf{M}</code> copula (<code><a href="#topic+M">M</a></code>). The parameterization here has assocation increasing with increasing <code class="reqn">\Theta</code>, which differs from Nelsen (2006), and also the Pareto copula is formed with right-tail increasing reflection of the Nelsen (2006) presentation because it is anticipated that <span class="pkg">copBasic</span> users are more likely to have right-tail dependency situations (say large maxima [right tail] coupling in earth-system data but not small maxima [left tail] coupling).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PARETOcop(u, v, para=NULL, ...)
    PAcop(u, v, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PARETOcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="PARETOcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="PARETOcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula; and</p>
</td></tr>
<tr><td><code id="PARETOcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>The Pareto copula is used in a demonstration of <em>Kendall Function L-moment ratio diagram</em> construction (see <code><a href="#topic+kfuncCOPlmoms">kfuncCOPlmoms</a></code>).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
z &lt;- seq(0.01,0.99, by=0.01) # Both copulas have Kendall Tau = 1/3
plot( z, kfuncCOP(z, cop=PAcop, para=1), lwd=2, col="black",
                                xlab="z &lt;= Z", ylab="F_K(z)", type="l")
lines(z, kfuncCOP(z, cop=GHcop, para=1.5), lwd=2, col="red") # red line
# All extreme value copulas have the same Kendall Function [F_K(z)], the
# Gumbel-Hougaard is such a copula and the F_K(z) for the Pareto does not
# plot on top and thus is not an extreme value but shares a "closeness."
## End(Not run)
</code></pre>

<hr>
<h2 id='PLACKETTcop'>The Plackett Copula</h2><span id='topic+PLACKETTcop'></span><span id='topic+PLcop'></span>

<h3>Description</h3>

<p>The <em>Plackett copula</em> (Nelsen, 2006, pp. 89&ndash;92) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_\Theta(u,v) = \mathbf{PL}(u,v) = \frac{[1+(\Theta-1)(u+v)]-\sqrt{[1+(\Theta-1)(u+v)]^2 - 4uv\Theta(\Theta-1)}}{2(\Theta - 1)}\mbox{.}</code>
</p>

<p>The Plackett copula (<code class="reqn">\mathbf{PL}(u,v)</code>) is <em>comprehensive</em> because as <code class="reqn">\Theta \rightarrow 0</code> the copula becomes <code class="reqn">\mathbf{W}(u,v)</code> (see <code><a href="#topic+W">W</a></code>, <em>countermonotonicity</em>), as <code class="reqn">\Theta \rightarrow \infty</code> the copula becomes <code class="reqn">\mathbf{M}(u,v)</code> (see <code><a href="#topic+M">M</a></code>,  <em>comonotonicity</em>) and for <code class="reqn">\Theta = 1</code> the copula is <code class="reqn">\mathbf{\Pi}(u,v)</code> (see <code><a href="#topic+P">P</a></code>,  <em>independence</em>).
</p>
<p>Nelsen (2006, p. 90) shows that
</p>
<p style="text-align: center;"><code class="reqn">\Theta = \frac{H(x,y)[1 - F(x) - G(y) + H(x,y)]}{[F(x) - H(x,y)][G(y) - H(x,y)]}\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> and <code class="reqn">G(y)</code> are cumulative distribution function for random variables <code class="reqn">X</code> and <code class="reqn">Y</code>, respectively, and <code class="reqn">H(x,y)</code> is the joint distribution function. Only Plackett copulas have a constant <code class="reqn">\Theta</code> for any pair <code class="reqn">\{x,y\}</code>. Hence, Plackett copulas are also known as <em>constant global cross ratio</em> or <em>contingency-type</em> distributions. The copula therefore is intimately tied to <em>contingency tables</em> and in particular the bivariate Plackett defined herein is tied to a <code class="reqn">2\times2</code> contingency table. Consider the <code class="reqn">2\times 2</code> contingency table shown at the end of this section, then <code class="reqn">\Theta</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\Theta = \frac{a/c}{b/d} = \frac{\frac{a}{a+c}/\frac{c}{a+c}}{\frac{b}{b+d}/\frac{d}{b+d}}\mbox{\ and\ }\Theta = \frac{a/b}{c/d} = \frac{\frac{a}{a+b}/\frac{b}{a+b}}{\frac{c}{c+d}/\frac{d}{c+d}}\mbox{,}</code>
</p>

<p>where it is obvious that <code class="reqn">\Theta = ad/bc</code> and <code class="reqn">a</code>, <code class="reqn">b</code>, <code class="reqn">c</code>, and <code class="reqn">d</code> can be replaced by proporations for a sample of size <code class="reqn">n</code> by <code class="reqn">a/n</code>, <code class="reqn">b/n</code>, <code class="reqn">c/n</code>, and <code class="reqn">d/n</code>, respectively. Finally, this copula has been widely used in modeling and as an alternative to bivariate distributions and has respective <em>lower-</em> and <em>upper-tail dependency parameters</em> of <code class="reqn">\lambda^L = 0</code> and <code class="reqn">\lambda^U = 0</code> (<code><a href="#topic+taildepCOP">taildepCOP</a></code>).
</p>

<table>
<tr>
 <td style="text-align: right;">
<code class="reqn">{-}{-}</code>     </td><td style="text-align: center;"> <b>Low</b> </td><td style="text-align: center;"> <b>High</b> </td><td style="text-align: center;"> <b>Sums</b></td>
</tr>
<tr>
 <td style="text-align: right;">
<b>Low</b>  </td><td style="text-align: center;"> <code class="reqn">a</code>    </td><td style="text-align: center;"> <code class="reqn">b</code>     </td><td style="text-align: center;"> <code class="reqn">a+b</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<b>High</b> </td><td style="text-align: center;"> <code class="reqn">c</code>    </td><td style="text-align: center;"> <code class="reqn">d</code>     </td><td style="text-align: center;"> <code class="reqn">c+d</code></td>
</tr>
<tr>
 <td style="text-align: right;">
<b>Sums</b> </td><td style="text-align: center;"> <code class="reqn">a+c</code>  </td><td style="text-align: center;"> <code class="reqn">b+d</code>   </td><td style="text-align: center;"> <code class="reqn">{-}{-}</code>
</td>
</tr>

</table>



<h3>Usage</h3>

<pre><code class='language-R'>PLACKETTcop(u, v, para=NULL, ...)
      PLcop(u, v, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PLACKETTcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="PLACKETTcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="PLACKETTcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula; and</p>
</td></tr>
<tr><td><code id="PLACKETTcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>The Plackett copula was the first (2008) copula implemented in <span class="pkg">copBasic</span> as part of initial development of the code base for instructional purposes. Thus, this particular copula has a separate parameter estimation function in <code><a href="#topic+PLACKETTpar">PLACKETTpar</a></code> as a historical vestige of a class project.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PLACKETTpar">PLACKETTpar</a></code>, <code><a href="#topic+PLpar">PLpar</a></code>, <code><a href="#topic+PLACKETTsim">PLACKETTsim</a></code>, <code><a href="#topic+W">W</a></code>, <code><a href="#topic+M">M</a></code>, <code><a href="#topic+densityCOP">densityCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PLACKETTcop(0.4, 0.6, para=1)
P(0.4, 0.6) # independence copula, same two values because Theta == 1
PLcop(0.4, 0.6, para=10.25) # joint probability through positive association

## Not run: 
# Joe (2014, p. 164) shows the closed form copula density of the Plackett.
"dPLACKETTcop" &lt;- function(u,v,para) {
   eta &lt;- para - 1; A &lt;- para*(1 + eta*(u+v-2*u*v))
   B &lt;- ((1 + eta*(u+v))^2 - 4*para*eta*u*v)^(3/2); return(A/B)
}
u &lt;- 0.08; v &lt;- 0.67 # Two probabilities to make numerical evaluations.
del &lt;- 0.0001 # a 'small' differential value of probability
u1 &lt;- u; u2 &lt;- u+del; v1 &lt;- v; v2 &lt;- v+del
# Density following (Nelsen, 2006, p. 10)
dCrect &lt;- (PLcop(u2, v2, para=10.25) - PLcop(u2, v1, para=10.25) -
           PLcop(u1, v2, para=10.25) + PLcop(u1, v1, para=10.25)) / del^2
dCanal &lt;- dPLACKETTcop(u, v, para=10.25)
dCfunc &lt;-   densityCOP(u, v, para=10.25, cop=PLcop, deluv = del)
R &lt;- round(c(dCrect, dCanal, dCfunc), digits=6)
message("Density: ", R[1], "(manual), ", R[2], "(analytical), ", R[3], "(function)");
# Density: 0.255377(manual), 0.255373(analytical), 0.255377(function)

# Comparison of partial derivatives
dUr &lt;- (PLcop(u2, v2, para=10.25) - PLcop(u1, v2, para=10.25)) / del
dVr &lt;- (PLcop(u2, v2, para=10.25) - PLcop(u2, v1, para=10.25)) / del
dU  &lt;- derCOP( u, v, cop=PLcop, para=10.25)
dV  &lt;- derCOP2(u, v, cop=PLcop, para=10.25)
R   &lt;- round(c(dU, dV, dUr, dVr), digits=6)
message("Partial derivatives dU=", R[1], " and dUr=", R[3], "\n",
        "                    dV=", R[2], " and dVr=", R[4]) #
## End(Not run)
</code></pre>

<hr>
<h2 id='PLACKETTpar'>Estimate the Parameter of the Plackett Copula</h2><span id='topic+PLACKETTpar'></span><span id='topic+PLpar'></span>

<h3>Description</h3>

<p>The parameter <code class="reqn">\Theta</code> of the <em>Plackett copula</em> (Nelsen, 2006, pp. 89&ndash;92) (<code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code> or <code><a href="#topic+PLcop">PLcop</a></code>) is related to the <em>Spearman Rho</em> (<code class="reqn">\rho_S \ne 1</code>, see <code><a href="#topic+rhoCOP">rhoCOP</a></code>)
</p>
<p style="text-align: center;"><code class="reqn">\rho_S(\Theta) = \frac{\Theta + 1}{\Theta - 1} - \frac{2\Theta\log(\Theta)}{(\Theta - 1)^2}\mbox{.}</code>
</p>

<p>Alternatively, the parameter can be estimated using a <em>median-split estimator</em>, which is best shown as an algorithm. First, compute the two medians:
</p>
<pre>
  medx &lt;- median(x); medy &lt;- median(y)
</pre>
<p>Second and third, compute the number of occurrences where both values are less than their medians and express that as a probability:
</p>
<pre>
  k &lt;- length(x[x &lt; medx &amp; y &lt; medy]); m &lt;- k / length(x)
</pre>
<p>Finally, the median-split estimator of  <code class="reqn">\Theta</code> is computed by
</p>
<p style="text-align: center;"><code class="reqn">\Theta = \frac{4m^2}{(1-2m)^2}\mbox{.}</code>
</p>

<p>Nelsen (2006, p. 92) and Salvadori <em>et al.</em> (2007, p. 247) provide further details. The input values <code>x</code> and <code>y</code> are <em>not used</em> for the median-split estimator if <em>Spearman Rho</em> (see <code><a href="#topic+rhoCOP">rhoCOP</a></code>) is provided by <code>rho</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLACKETTpar(x, y, rho=NULL, byrho=FALSE, cor=NULL, ...)
      PLpar(x, y, rho=NULL, byrho=FALSE, cor=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PLACKETTpar_+3A_x">x</code></td>
<td>
<p>Vector of values for random variable <code class="reqn">X</code>;</p>
</td></tr>
<tr><td><code id="PLACKETTpar_+3A_y">y</code></td>
<td>
<p>Vector of values for random variable <code class="reqn">Y</code>;</p>
</td></tr>
<tr><td><code id="PLACKETTpar_+3A_rho">rho</code></td>
<td>
<p>Spearman Rho and <code>byrho</code> is set to <code>TRUE</code> automatically;</p>
</td></tr>
<tr><td><code id="PLACKETTpar_+3A_byrho">byrho</code></td>
<td>
<p>Should Spearman Rho be used instead of the median-split estimator;</p>
</td></tr>
<tr><td><code id="PLACKETTpar_+3A_cor">cor</code></td>
<td>
<p>A <span class="pkg">copBasic</span> syntax for &ldquo;the correlation coefficient&rdquo; suitable for the copula&mdash;a synonym for <code>rho</code>; and</p>
</td></tr>
<tr><td><code id="PLACKETTpar_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value for the Plackett copula <code class="reqn">\Theta</code> is returned.
</p>


<h3>Note</h3>

<p>Evidently there &ldquo;does not appear to be a closed form for <code class="reqn">\tau(\Theta)</code>&rdquo; (Fredricks and Nelsen, 2007, p. 2147),  but given <code class="reqn">\rho(\Theta)</code>, the equivalent <code class="reqn">\tau(\Theta)</code> can be computed by either the <code><a href="#topic+tauCOP">tauCOP</a></code> function or by approximation. One of the Examples sweeps through <code class="reqn">\rho \mapsto [0,1; \Delta\rho{=}\delta]</code>, fits the Plackett <code class="reqn">\theta(\rho)</code>, and then solves for Kendall Tau <code class="reqn">\tau(\theta)</code> using <code><a href="#topic+tauCOP">tauCOP</a></code>. A polynomial is then fit between <code class="reqn">\tau</code> and <code class="reqn">\rho</code> to provide rapid conversion between <code class="reqn">|\rho|</code> and <code class="reqn">\tau</code>, where the residual standard error is 0.0005705, adjusted R-squared is <code class="reqn">\approx 1</code>, the maximum residual is <code class="reqn">\epsilon &lt; 0.006</code>. Because of symmetry, it is only necessary to fit positive association and reflect the result by the sign of <code class="reqn">\rho</code>. This polynomial is from the <code>Examples</code> is
</p>
<pre>
  rho &lt;- 0.920698
  "getPLACKETTtau" &lt;- function(rho) {
     taupoly &lt;-   0.6229945*abs(rho)   +   1.1621854*abs(rho)^2 -
                 10.7424188*abs(rho)^3 +  48.9687845*abs(rho)^4 -
                119.0640264*abs(rho)^5 + 160.0438496*abs(rho)^6 -
                111.8403591*abs(rho)^7 +  31.8054602*abs(rho)^8
     return(sign(rho)*taupoly)
  }
  getPLACKETTtau(rho) # 0.7777726
</pre>
<p>The following code might be useful in some applications for the inversion of the polynomial for the <code class="reqn">\rho</code> as a function of <code class="reqn">\tau</code>:
</p>
<pre>
  "fun" &lt;- function(rho, tau=NULL) {tp &lt;- getPLACKETTtau(rho); return(tau-tp)}
   tau  &lt;- 0.78
   rho  &lt;- uniroot(fun, interval=c(0, 1), tau=tau)$root # 0.9220636
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Fredricks, G.A, and Nelsen, R.B., 2007, On the relationship between Spearman's rho and Kendall's tau for pairs of continuous random variables: Journal of Statistical Planning and Inference, v. 137, pp. 2143&ndash;2150.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>, <code><a href="#topic+PLcop">PLcop</a></code>, <code><a href="#topic+PLACKETTsim">PLACKETTsim</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Q1 &lt;- rnorm(1000); Q2 &lt;- Q1 + rnorm(1000)
PLpar(Q1, Q2); PLpar(Q1, Q2, byrho=TRUE) # two estimates for same data
PLpar(rho= 0.76) # positive association
PLpar(rho=-0.76) # negative association
tauCOP(cop=PLcop, para=PLpar(rho=-0.15, by.rho=TRUE)) #
## End(Not run)

## Not run: 
RHOS &lt;- seq(0, 0.990, by=0.002); TAUS &lt;- rep(NA, length(RHOS))
for(i in 1:length(RHOS)) {
   #message("Spearman Rho: ", RHOS[i])
   theta &lt;- PLACKETTpar(rho=RHOS[i], by.rho=TRUE); tau &lt;- NA
   try(tau &lt;- tauCOP(cop=PLACKETTcop, para=theta), silent=TRUE)
   TAUS[i] &lt;- ifelse(is.null(tau), NA, tau)
}
LM &lt;- lm(TAUS~  RHOS    + I(RHOS^2) + I(RHOS^3) + I(RHOS^4) +
              I(RHOS^5) + I(RHOS^6) + I(RHOS^7) + I(RHOS^8) - 1)
plot(RHOS,TAUS, type="l", xlab="abs(Spearman Rho)", ylab="abs(Kendall Tau)")
lines(RHOS,fitted.values(LM), col=3)#
## End(Not run)
</code></pre>

<hr>
<h2 id='PLACKETTsim'>Direct Simulation of a Plackett Copula</h2><span id='topic+PLACKETTsim'></span>

<h3>Description</h3>

<p><em>Plackett copula</em> simulation (Nelsen, 2006, pp. 89&ndash;92) (<code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>) is made by this function using analytical formula (Durante, 2007, p. 247; see source code). The <code>PLACKETTsim</code> function exists for comparison against the numerical derivative (<em>conditional distribution method</em>) methods (<code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+simCOPmicro">simCOPmicro</a></code>) otherwise used in <span class="pkg">copBasic</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLACKETTsim(n, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PLACKETTsim_+3A_n">n</code></td>
<td>
<p>Sample size;</p>
</td></tr>
<tr><td><code id="PLACKETTsim_+3A_para">para</code></td>
<td>
<p>The <code class="reqn">\Theta</code> parameter of the Plackett copula; and</p>
</td></tr>
<tr><td><code id="PLACKETTsim_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the values <code class="reqn">U</code> and <code class="reqn">V</code> for the nonexceedance probabilities is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Durante, F., 2007, Families of copulas, Appendix C, <em>in</em> Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>, <code><a href="#topic+PLACKETTpar">PLACKETTpar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>PLACKETTsim(10, para= 1  ) # simulate P (independence) copula through a Plackett
PLACKETTsim(10, para=20.3) # simulate strong positive Plackett
</code></pre>

<hr>
<h2 id='prod2COP'>The Product of Two Copulas</h2><span id='topic+prod2COP'></span>

<h3>Description</h3>

<p>Perform copula multiplication (so-called &ldquo;<code class="reqn">\ast</code>-product&rdquo; or <em>Markov Product</em>) (Darsow and others, 1992) is a continuous analog of matrix multiplication and yields another copula:
</p>
<p style="text-align: center;"><code class="reqn">\bigl(\mathbf{C}_1 \ast \mathbf{C}_2 \bigr)(u,v) = \mathbf{C}_3(u,v) = \int_\mathcal{I} \frac{\delta \mathbf{C}_1(u, t)}{\delta v} \frac{\delta \mathbf{C}_2(t, v)}{\delta u}\,\mathrm{d}t\mbox{,}</code>
</p>

<p>for copulas <code class="reqn">\mathbf{C}_1(u, v)</code> and <code class="reqn">\mathbf{C}_2(u, v)</code> are copulas whose <code class="reqn">\ast</code>-product yields copula <code class="reqn">\mathbf{C}_3(u, v)</code> in terms of partial derivatives (<code><a href="#topic+derCOP">derCOP</a></code> and <code><a href="#topic+derCOP2">derCOP2</a></code>) of the other two. Nelsen (2006, p. 245) lists several identities of the <code class="reqn">\ast</code>-product involving the product (<code class="reqn">\mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>), lower bound (<code class="reqn">\mathbf{W}</code>; <code><a href="#topic+W">W</a></code>), and upper bound (<code class="reqn">\mathbf{M}</code>; <code><a href="#topic+M">M</a></code>) copulas:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{\Pi} \ast \mathbf{C} = \mathbf{C} \ast \mathbf{\Pi} = \mathbf{\Pi}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{M} \ast \mathbf{C} = \mathbf{C} \ast \mathbf{M} = \mathbf{M}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\bigl(\mathbf{W} \ast \mathbf{C}\bigr)(u,v) = v - \mathbf{C}(1-u, v)\mbox{\ and\ } \bigl(\mathbf{C} \ast \mathbf{W}\bigr)(u,v) = u - \mathbf{C}(u, 1-v)\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathbf{W} \ast \mathbf{W} = \mathbf{M}\mbox{ and } \mathbf{W} \ast \mathbf{C} \ast \mathbf{W} = \hat{\mathbf{C}}\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{\mathbf{C}}</code> is the <em>survival copula</em> (<code><a href="#topic+surCOP">surCOP</a></code>). The <code class="reqn">\ast</code>-product is associative:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{A} \ast (\mathbf{B} \ast \mathbf{C}) = (\mathbf{A} \ast \mathbf{B}) \ast \mathbf{C}\mbox{,}</code>
</p>

<p>but <code class="reqn">\ast</code>-product is not commutative (order independent). Nelsen (2006, p. 245) reports that &ldquo;if we view <code class="reqn">\ast</code> as a binary operation on the set of copulas, then <code class="reqn">\mathbf{\Pi}</code> is the null element, and <code class="reqn">\mathbf{M}</code> is the identity.&rdquo; Copula mulitiplication is closely linked to <em>Markov Processes</em> (Nelsen, 2006, pp. 244&ndash;248).
</p>
<p>For other descriptions and computations of copula combination are possible using the <span class="pkg">copBasic</span> package, see <code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+convex2COP">convex2COP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code>, and <code><a href="#topic+convexCOP">convexCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prod2COP(u,v, cop1=NULL, para1=NULL, cop2=NULL, para2=NULL, para=NULL,
              pinterval=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prod2COP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_cop1">cop1</code></td>
<td>
<p>The <code class="reqn">\mathbf{C}_1(u,v; \Theta_1)</code> copula function with vectorization as in <code>asCOP</code>;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_para1">para1</code></td>
<td>
<p>Vector of parameters or other data structures for <code class="reqn">\Theta_1</code>, if needed, to pass to copula <code class="reqn">\mathbf{C}_1(u,v; \Theta_1)</code>;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_cop2">cop2</code></td>
<td>
<p>The <code class="reqn">\mathbf{C}_2(u,v; \Theta_2)</code> copula function with vectorization as in <code>asCOP</code>;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_para2">para2</code></td>
<td>
<p>Vector of parameters or other data structures for <code class="reqn">\Theta_2</code>, if needed, to pass to copula <code class="reqn">\mathbf{C}_2(u,v; \Theta_2)</code>;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_para">para</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>list</code> that can take the place of the <code>cop1</code>, <code>para1</code>, <code>cop2</code>, and <code>para2</code> arguments. These four will be populated from same named elements of the <code>list</code>, and if the other four arguments were specified through the function interface, these are silently ignored;</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_pinterval">pinterval</code></td>
<td>
<p>An optional interval for the above integral. The default is <code class="reqn">\mathcal{I} = [0,1]</code> but the option of the user to replace exact end points with &ldquo;small&rdquo; numbers is possible (<em>e.g.</em> <code>interval=</code><code>c(lo, 1-lo)</code> for say <code>lo=.Machine$double.eps</code>). This interval is uniquely picked up for the interval in the above definition of <code>prod2COP</code>. The <code>pinterval</code> can also be set within the <code>para</code> and the function will pick it up from there; and</p>
</td></tr>
<tr><td><code id="prod2COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copulas.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>The <em>Farlie&ndash;Gumbel&ndash;Morgenstern copula</em> (<code class="reqn">\mathbf{FGM}(u,v; \Theta)</code>; <code><a href="#topic+FGMcop">FGMcop</a></code>) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{FGM}(u,v; \Theta) = uv[1+\Theta(1-u)(1-v)]\mbox{,}</code>
</p>

<p>where <code class="reqn">-1 \le \Theta \le 1</code>. Nelsen (2006, exer. 6.12, p. 249) asserts that for <code class="reqn">\mathbf{FGM}_{(\Theta = \alpha)}</code> and <code class="reqn">\mathbf{FGM}_{(\Theta = \beta)}</code> with <code class="reqn">\ast</code>-product as <code class="reqn">\mathbf{FGM}_\alpha \ast \mathbf{FGM}_\beta</code> that a closed-form solution exists and is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{FGM}_\alpha \ast \mathbf{FGM}_\beta = \mathbf{FGM}_{(\alpha\beta) / 3}\mbox{.}</code>
</p>

<p>This assertion is numerically true as readily verified using the <code>prod2COP</code> function:
</p>
<pre>
  u &lt;- c(0.41, 0.87); v &lt;- c(0.13,0.35); A &lt;- -0.532; B &lt;- 0.235
  FGMcop(  u,v, para= A*B / 3)
  # 0.0521598638574___   0.3034277347150___
  prod2COP(u,v, cop1=FGMcop, para1=A, cop2=FGMcop, para2=B)
  # 0.0521598638312605   0.3034277344807909
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Darsow, W.F., Nguyen, B., and Olsen, E.T., 1992, Copulas and Markov processes: Illinois Journal of Mathematics, v. 26, pp. 600&ndash;624, <a href="https://doi.org/10.1215/IJM/1255987328">doi:10.1215/IJM/1255987328</a>.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, <code><a href="#topic+composite3COP">composite3COP</a></code>,
<code><a href="#topic+convexCOP">convexCOP</a></code>, <code><a href="#topic+convex2COP">convex2COP</a></code>, <code><a href="#topic+glueCOP">glueCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Product P * N4212 ---&gt; P (by identity)
u &lt;- c(0.41, 0.87); v &lt;- c(0.13, 0.35)
prod2COP(u,v, cop1=P, cop2=N4212cop, para1=NA, para2=2.12) # 0.0533 and 0.3045
COP(u,v, cop=P)                                            # 0.0533 and 0.3045
## End(Not run)

## Not run: 
para &lt;- list(cop1=PLcop, para1=0.19, cop2=PLcop, para2=34.5)
UV &lt;- simCOP(n=1000, cop=prod2COP, para=para, resamv01=FALSE, showresamv01=FALSE)
# This is large simulation run (with a lot of numerical operations) is expected
# at least for the Placketts and chosen parameters to trigger one or more NAs
# from derCOPinv(). The simCOP() function simply continues on with ignoring the
# solution or lack thereof for certain combinations, and simCOP() will report how
# many of the simulated values for sample of size n were computed. For example,
# for one n=1000, some 965 simulated values were returned. The defaults require
# that NAs, empty simulations, remain intact. We can try resampling:
UV &lt;- simCOP(n=1000, cop=prod2COP, para=para, resamv01=TRUE, showresamv01=TRUE)
rhoCOP(cop=prod2COP, para=para) # -0.4271195 (theoretical)
rhoCOP(para=UV, as.sample=TRUE) # -0.4274703 #
## End(Not run)

## Not run: 
para &lt;- list(cop1=PLcop, para1=0.19, cop2=PLcop, para2=34.5)
# The prod2COP() might be one of the more sensitive to NAs in simulation because
# of the two partial numerical derivatives involved.
para$pinterval &lt;- c(0.4, 0.6) # totally inappropriate interval for the integral
# for the prod2COP() definition. Because the ... are used so extensively, we have
# the "pinterval" for this function so that interval itself can be passed also.
UV &lt;- simCOP(n=1000, cop=prod2COP, para=para, resamv01=TRUE, showresamv01=TRUE,
                     pinterval=c(0,   1  ))
UV &lt;- simCOP(n=1000, cop=prod2COP, para=para, resamv01=TRUE, showresamv01=TRUE,
                     pinterval=c(0.4, 0.6)) #
## End(Not run)
</code></pre>

<hr>
<h2 id='psepolar'>Pseudo-Polar Representation of Bivariate Data</h2><span id='topic+psepolar'></span>

<h3>Description</h3>

<p>Kiriliouk <em>et al.</em> (2016, pp. 358&ndash;360) describe a <em>pseudo-polar</em> representation of bivariate data as a means to explore right-tail extremal dependency between the variables. Let <code class="reqn">(X_i, Y_i)</code> (real values) or <code class="reqn">(U_i, V_i)</code> (as probabilities) for <code class="reqn">i = 1, \ldots, n</code> be a bivariate sample of size <code class="reqn">n</code>. When such data are transformed into a &ldquo;unit-Pareto&rdquo; scale by
</p>
<p style="text-align: center;"><code class="reqn">\widehat{X}^\star_i = n/(n+1-R_{X,i}) \mbox{\ and\ } \widehat{Y}^\star_i = n/(n+1-R_{Y,i})\mbox{,}</code>
</p>

<p>where <code class="reqn">R</code> is <code>rank()</code>, then letting each <em>component sum</em> or <em>pseudo-polar radius</em> be defined as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{S}_i = \widehat{X}^\star_i + \widehat{Y}^\star_i\mbox{,}</code>
</p>

<p>and each respective <em>pseudo-polar angle</em> be defined as 
</p>
<p style="text-align: center;"><code class="reqn">\widehat{W}_i = \widehat{X}^\star_i / (\widehat{X}^\star_i + \widehat{Y}^\star_i) = \widehat{X}^\star_i / \widehat{S}_i\mbox{,}</code>
</p>

<p>a pseudo-polar representation is available for study.
</p>
<p>A scatter plot of <code class="reqn">\widehat{W}_i</code> (horizontal) versus <code class="reqn">\widehat{S}_i</code> (vertical) will depict a <em>pseudo-polar plot</em> of the data. Kiriliouk <em>et al.</em> (2016) approach the pseudo-polar concept as a means to study extremal dependency in the sense of what are the contributions of the <code class="reqn">X</code> and <code class="reqn">Y</code> to their sum conditional on the sum being large. The <em>largeness</em> of <code class="reqn">\widehat{S}_i</code> is assessed by its empirical cumulative distribution function and a threshold <code class="reqn">S_f</code> stemming from <code class="reqn">f</code> as a nonexceedance probability <code class="reqn">f \in [0,1]</code>.
</p>
<p>A density plot of the <code class="reqn">\widehat{W}_i</code> is a representation of extremal dependence. If the density plot shows low density for pseudo-polar angles away from 0 and 1 or bimodality on the edges then weak extremal dependency is present. If the density is substantial and uniform away from the the angles 0 and 1 or if the density peaks near <code class="reqn">\widehat{W} \approx 0.5</code> then extremal dependency is strong.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psepolar(u, v=NULL, f=0.90, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="psepolar_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction (actually the ranks are used so this can be a real-value argument as well);</p>
</td></tr>
<tr><td><code id="psepolar_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction  (actually the ranks are used so this can be a real-value argument as well) and if <code>NULL</code> then <code>u</code> is treated as a two column <span class="rlang"><b>R</b></span> <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="psepolar_+3A_f">f</code></td>
<td>
<p>The nonexceedance probability of the distal <code class="reqn">\widehat{S}</code> to flag in <code>Shat_ge_Sf</code> column of the output; and</p>
</td></tr>
<tr><td><code id="psepolar_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>dat2bernqua()</code> function of the <span class="pkg">lmomco</span> package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> is returned in the <code>table</code> element and the <code class="reqn">S_f</code> is in the <code>Sf</code> element.
</p>
<table role = "presentation">
<tr><td><code>U</code></td>
<td>
<p>An echo of the <code>u</code> input;</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>An echo of the <code>v</code> input;</p>
</td></tr>
<tr><td><code>Xstar</code></td>
<td>
<p>The <code class="reqn">\widehat{X}^\star_i</code> (Kiriliouk <em>et al.</em>, 2016, eq. 17.8, p. 359);</p>
</td></tr>
<tr><td><code>Ystar</code></td>
<td>
<p>The <code class="reqn">\widehat{Y}^\star_i</code> (Kiriliouk <em>et al.</em>, 2016, eq. 17.8, p. 359);</p>
</td></tr>
<tr><td><code>FXhat1</code></td>
<td>
<p>The <code class="reqn">F_{X,i} = 1 - 1/X^\star_i</code>, which is the inverse of Kiriliouk <em>et al.</em> (2016, eq. 17.1, p. 354);</p>
</td></tr>
<tr><td><code>FYhat1</code></td>
<td>
<p>The <code class="reqn">F_{Y,i} = 1 - 1/Y^\star_i</code>, which is the inverse of Kiriliouk <em>et al.</em> (2016, eq. 17.1, p. 354);</p>
</td></tr>
<tr><td><code>FXhat3</code></td>
<td>
<p>The <code class="reqn">F_{3,X,i} = (R_{X,i} - 0.5)/n</code> corresponding to the &ldquo;3&rdquo; alternative identified by Kiriliouk <em>et al.</em> (2016, p. 365);</p>
</td></tr>
<tr><td><code>FYhat3</code></td>
<td>
<p>The <code class="reqn">F_{3,Y,i} = (R_{Y,i} - 0.5)/n</code> corresponding to the &ldquo;3&rdquo; alternative identified by Kiriliouk <em>et al.</em> (2016, p. 365);</p>
</td></tr>
<tr><td><code>What</code></td>
<td>
<p>The <code class="reqn">\widehat{W}_i</code> (Kiriliouk <em>et al.</em>, 2016, eq. 17.9, p. 359);</p>
</td></tr>
<tr><td><code>Shat</code></td>
<td>
<p>The <code class="reqn">\widehat{S}_i</code> (Kiriliouk <em>et al.</em>, 2016, eq. 17.9, p. 359); and</p>
</td></tr>
<tr><td><code>Shat_ge_Sf</code></td>
<td>
<p>A logical on whether the <code class="reqn">\widehat{S}_i</code> are larger than <code class="reqn">S_f</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The default of <code>f=0.90</code> means that the upper 90th percentile of the component sum will be identified in the output. This percentile is computed by the Bernstein empirical distribution function provided by the <span class="pkg">lmomco</span> package through the <code>dat2bernqua()</code> function. Suggested arguments for <code>...</code> are <code>poly.type="Bernstein"</code> and <code>bound.type="Carv"</code> though the former is redundant because it is the default of <code>dat2bernqua()</code>.
</p>


<h3>Author(s)</h3>

<p>William Asquith <a href="mailto:william.asquith@ttu.edu">william.asquith@ttu.edu</a></p>


<h3>References</h3>

<p>Kiriliouk, Anna, Segers, Johan, Warchoł, Michał, 2016, Nonparameteric estimation of extremal dependence: <em>in</em> Extreme Value Modeling and Risk Analysis, D.K. Dey and Jun Yan <em>eds.</em>, Boca Raton, FL, CRC Press, ISBN 978&ndash;1&ndash;4987&ndash;0129&ndash;7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spectralmeas">spectralmeas</a></code>, <code><a href="#topic+stabtaildepf">stabtaildepf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pse &lt;- psepolar(simCOP(n=799, cop=PARETOcop, para=4.3,graphics=FALSE),bound.type="Carv")
pse &lt;- pse$table # The Pareto copula has right-tail extreme dependency
plot(1/(1-pse$U), 1/(1-pse$V), col=pse$Shat_ge_Sf+1, lwd=0.8, cex=0.5, log="xy", pch=16)
plot(pse$What, pse$Shat, log="y", col=pse$Shat_ge_Sf+1, lwd=0.8, cex=0.5, pch=16)
plot(density(pse$What[pse$Shat_ge_Sf]), pch=16, xlim=c(0,1)) # then try the
# non-right tail extremal copula PSP as cop=PSP in the above psepolar() call.
## End(Not run)
</code></pre>

<hr>
<h2 id='PSP'>The Ratio of the Product Copula to Summation minus Product Copula</h2><span id='topic+PSP'></span>

<h3>Description</h3>

<p>Compute <em>PSP copula</em> (Nelsen, 2006, p. 23) is named by the author (Asquith) for the <span class="pkg">copBasic</span> package and is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{PSP}(u,v) = \frac{\mathbf{\Pi}}{\mathbf{\Sigma} - \mathbf{\Pi}} = \frac{uv}{u + v - uv}\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{\Pi}</code> is the <em>indpendence</em> or <em>product copula</em> (<code><a href="#topic+P">P</a></code>) and <code class="reqn">\mathbf{\Sigma}</code> is the sum <code class="reqn">\mathbf{\Sigma} = u + v</code>. The <code class="reqn">\mathbf{PSP}(u,v)</code> copula is a special case of the <code class="reqn">\mathbf{N4212}(u,v)</code> copula (<code><a href="#topic+N4212cop">N4212cop</a></code>). The <code class="reqn">\mathbf{PSP}</code> is included in <span class="pkg">copBasic</span> because of its simplicity and for pedagogical purposes. The name &ldquo;PSP&rdquo; comes from &ldquo;Product, Summation, Product&rdquo; to loosely reflect the mathematical formula shown.  Nelsen (2006, p. 114) notes that the PSP copula shows up in several families and designates it as &ldquo;<code class="reqn">\mathbf{\Pi}/(\mathbf{\Sigma}-\mathbf{\Pi})</code>.&rdquo; The PSP is undefined for <code class="reqn">u = v = 0</code> but no internal trapping is made; calling functions will have to intercept the <code>NaN</code> so produced for <code class="reqn">\{0, 0\}</code>. The <code class="reqn">\mathbf{PSP}</code> is left internally untrapping <code>NaN</code> so as to be available to stress other copula utility functions within the <span class="pkg">copBasic</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PSP(u, v, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PSP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="PSP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; and</p>
</td></tr>
<tr><td><code id="PSP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass, which for this copula are not needed, but given here to support flexible implementation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+P">P</a></code>, <code><a href="#topic+N4212cop">N4212cop</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>PSP(0.4,0.6)
PSP(0,0)
PSP(1,1)
</code></pre>

<hr>
<h2 id='qua.regressCOP'>Perform Quantile Regression using a Copula by Numerical Derivative Method for V with respect to U</h2><span id='topic+qua.regressCOP'></span>

<h3>Description</h3>

<p>Perform <em>quantile regression</em> (Nelsen, 2006, pp. 217&ndash;218) using a copula by numerical derivatives of the copula (<code><a href="#topic+derCOPinv">derCOPinv</a></code>). If <code class="reqn">X</code> and <code class="reqn">Y</code> are random variables having quantile functions <code class="reqn">x(F)</code> and <code class="reqn">y(G)</code> and letting <code class="reqn">y=\tilde{y}(x)</code> denote a solution to <code class="reqn">\mathrm{Pr}[Y \le y\mid X = x] = F</code>, where <code class="reqn">F</code> is a nonexceedance probability. Then the curve <code class="reqn">y=\tilde{y}(x)</code> is the quantile regression curve of <code class="reqn">V</code> or <code class="reqn">Y</code> with respect to <code class="reqn">U</code> or <code class="reqn">X</code>, respectively. If <code class="reqn">F=1/2</code>, then <em>median regression</em> is performed (<code><a href="#topic+med.regressCOP">med.regressCOP</a></code>). Using copulas, the quantile regression is expressed as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[Y \le y\mid X = x] = \mathrm{Pr}[V \le G(y) \mid U = F(x)] = \mathrm{Pr}[V \le v\mid U = v] = \frac{\delta \mathbf{C}(u,v)}{\delta u}\mbox{,}</code>
</p>

<p>where <code class="reqn">v = G(y)</code> and <code class="reqn">u = F(x)</code>. The general algorithm is
</p>

<ol>
<li><p> Set <code class="reqn">\delta \mathbf{C}(u,v)/\delta u = F</code>,
</p>
</li>
<li><p> Solve the regression curve <code class="reqn">v = \tilde{v}(u)</code> (provided by <code><a href="#topic+derCOPinv">derCOPinv</a></code>), and
</p>
</li>
<li><p> Replace <code class="reqn">u</code> by <code class="reqn">x(u)</code> and <code class="reqn">v</code> by <code class="reqn">y(v)</code>.
</p>
</li></ol>

<p>The last step is optional as step two produces the regression in probability space, which might be desired, and step 3 actually transforms the probability regressions into the quantiles of the respective random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qua.regressCOP(f=0.5, u=seq(0.01,0.99, by=0.01), cop=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qua.regressCOP_+3A_f">f</code></td>
<td>
<p>A single value of nonexceedance probability <code class="reqn">F</code> to perform regression at and defaults to median regression <code class="reqn">F=1/2</code>;</p>
</td></tr>
<tr><td><code id="qua.regressCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="qua.regressCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="qua.regressCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula; and</p>
</td></tr>
<tr><td><code id="qua.regressCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the regressed probabilities of <code class="reqn">V</code> and provided <code class="reqn">U=u</code> values is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+med.regressCOP">med.regressCOP</a></code>, <code><a href="#topic+derCOPinv">derCOPinv</a></code>, <code><a href="#topic+qua.regressCOP.draw">qua.regressCOP.draw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Use a positively associated Plackett copula and perform quantile regression
theta &lt;- 10
R &lt;- qua.regressCOP(cop=PLACKETTcop, para=theta) # 50th percentile regression

plot(R$U,R$V, type="l", lwd=6, xlim=c(0,1), ylim=c(0,1), col=8)
lines(R$U,(1+(theta-1)*R$U)/(theta+1), col=4, lwd=1) # theoretical for Plackett, see
#                                                             (Nelsen, 2006, p. 218)
R &lt;- qua.regressCOP(f=0.90, cop=PLACKETTcop, para=theta) # 90th-percentile regression
lines(R$U,R$V, col=2, lwd=2)
R &lt;- qua.regressCOP(f=0.10, cop=PLACKETTcop, para=theta) # 10th-percentile regression
lines(R$U,R$V, col=3, lty=2)
mtext("Quantile Regression V wrt U for Plackett copula")#
## End(Not run)

## Not run: 
# Use a composite copula with two Placketts with compositing parameters alpha and beta.
para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
             para1=0.04, para2=5, alpha=0.9, beta=0.6)
plot(c(0,1),c(0,1), type="n", lwd=3,
     xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY")
# Draw the regression of V on U and then U on V (wrtV=TRUE)
qua.regressCOP.draw(cop=composite2COP, para=para, ploton=FALSE)
qua.regressCOP.draw(cop=composite2COP, para=para, wrtV=TRUE, lty=2, ploton=FALSE)
mtext("Composition of Two Plackett Copulas and Quantile Regression")#
## End(Not run)

## Not run: 
# Use a composite copula with two Placketts with compositing parameters alpha and beta.
para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
             para1=0.34, para2=50, alpha=0.63, beta=0.47)
D &lt;- simCOP(n=3000, cop=composite2COP, para=para, cex=0.5)
qua.regressCOP.draw(cop=composite2COP, para=para, ploton=FALSE)
qua.regressCOP.draw(cop=composite2COP, para=para, wrtV=TRUE, lty=2, ploton=FALSE)
level.curvesCOP(cop=composite2COP, para=para, ploton=FALSE)
mtext("Composition of Two Plackett Copulas, Level Curves, Quantile Regression")

para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop, # Note the singularity
             para1=0, para2=500, alpha=0.63, beta=0.47)
D &lt;- simCOP(n=3000, cop=composite2COP, para=para, cex=0.5)
qua.regressCOP.draw(cop=composite2COP, para=para, ploton=FALSE)
qua.regressCOP.draw(cop=composite2COP, para=para, wrtV=TRUE, lty=2, ploton=FALSE)
level.curvesCOP(cop=composite2COP, para=para, ploton=FALSE)
mtext("Composition of Two Plackett Copulas, Level Curves, Quantile Regression")

pdf("quantile_regression_test.pdf")
for(i in 1:10) {
  para &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop, alpha=runif(1), beta=runif(1),
               para1=10^runif(1,min=-4,max=0), para2=10^runif(1,min=0,max=4))
  txts &lt;- c("Alpha=",    round(para$alpha,    digits=4),
            "; Beta=",   round(para$beta,     digits=4),
            "; Theta1=", round(para$para1[1], digits=5),
            "; Theta2=", round(para$para2[1], digits=2))

  D &lt;- simCOP(n=3000, cop=composite2COP, para=para, cex=0.5, col=3)
  mtext(paste(txts, collapse=""))
  qua.regressCOP.draw(f=c(seq(0.05, 0.95, by=0.05)),
                      cop=composite2COP, para=para, ploton=FALSE)
  qua.regressCOP.draw(f=c(seq(0.05, 0.95, by=0.05)),
                      cop=composite2COP, para=para, wrtV=TRUE, ploton=FALSE)
  level.curvesCOP(cop=composite2COP, para=para, ploton=FALSE)
}
dev.off() # done
## End(Not run)
</code></pre>

<hr>
<h2 id='qua.regressCOP.draw'>Draw Quantile Regressions using a Copula by Numerical Derivative Method for V with respect to U or U with respect to V</h2><span id='topic+qua.regressCOP.draw'></span>

<h3>Description</h3>

<p>Draw a suite of lines for specified nonexceedance probabilities representing the <em>quantile regression</em> (Nelsen, 2006, pp. 217&ndash;218) of either <code class="reqn">V</code> with respect to <code class="reqn">U</code> or <code class="reqn">U</code> with respect to <code class="reqn">V</code> depending upon an argument setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qua.regressCOP.draw(f=seq(0.1, 0.9, by=0.1), fs=0.5, cop=NULL, para=NULL,
                    ploton=TRUE, wrtV=FALSE, col=c(4,2), lwd=c(1,2), lty=1,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qua.regressCOP.draw_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">F</code> to perform quantile regression at and defaults to a 10-percent-interval sequence. This vectorization of <code>f</code> for this function differs from that in <code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code> and <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code>;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_fs">fs</code></td>
<td>
<p>A special value of nonexceedance probability to draw with second values to arguments <code>col</code> and <code>lwd</code> and defaults to the median (<code class="reqn">F = 1/2</code>);</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_wrtv">wrtV</code></td>
<td>
<p>If <code>wrtV=FALSE</code> call <code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code> and perform quantile regression of <code class="reqn">V</code> with respect to <code class="reqn">U</code> and if <code>wrtV=TRUE</code> call <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code> and perform regression of <code class="reqn">U</code> with respect to <code class="reqn">V</code>;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_col">col</code></td>
<td>
<p>A vector of two values for the color of the line to draw, where the first value is used for the <code>f</code> probabilities and the second value is used for the <code>fs</code> probability;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_lwd">lwd</code></td>
<td>
<p>A vector of two values for the line width of the line to draw, where the first value is used for the <code>f</code> probabilities and the second value is used for the <code>fs</code> probability;</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_lty">lty</code></td>
<td>
<p>The line type to draw; and</p>
</td></tr>
<tr><td><code id="qua.regressCOP.draw_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No values are returned, this function is used for its side effects.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qua.regressCOP">qua.regressCOP</a></code>, <code><a href="#topic+qua.regressCOP2">qua.regressCOP2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See example in qua.regressCOP documentation
</code></pre>

<hr>
<h2 id='qua.regressCOP2'>Perform Quantile Regression using a Copula by Numerical Derivative Method for U with respect to V</h2><span id='topic+qua.regressCOP2'></span>

<h3>Description</h3>

<p>Perform <em>quantile regression</em> (Nelsen, 2006, pp. 217&ndash;218) using a copula by numerical derivatives of the copula (<code><a href="#topic+derCOPinv2">derCOPinv2</a></code>). If <code class="reqn">X</code> and <code class="reqn">Y</code> are random variables having quantile functions <code class="reqn">x(F)</code> and <code class="reqn">y(G)</code> and letting <code class="reqn">x=\tilde{x}(y)</code> denote a solution to <code class="reqn">\mathrm{Pr}[X \le x\mid Y = y] = F</code>, where <code class="reqn">F</code> is a nonexceedance probability. Then the curve <code class="reqn">x=\tilde{x}(y)</code> is the quantile regression curve of <code class="reqn">U</code> or <code class="reqn">X</code> with respect to  <code class="reqn">V</code> or <code class="reqn">Y</code>, respectively. If <code class="reqn">F=1/2</code>, then <em>median regression</em> is performed (<code><a href="#topic+med.regressCOP2">med.regressCOP2</a></code>). Using copulas, the quantile regression is expressed as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[X \le x\mid Y = y] = \mathrm{Pr}[U \le F(x) \mid V = F] = \mathrm{Pr}[U \le u\mid V = F] = \frac{\delta \mathbf{C}(u,v)}{\delta v}\mbox{,}</code>
</p>

<p>where <code class="reqn">v = G(y)</code> and <code class="reqn">u = F(x)</code>. The general algorithm is
</p>

<ol>
<li><p> Set <code class="reqn">\delta \mathbf{C}(u,v)/\delta v = F</code>,
</p>
</li>
<li><p> Solve the regression curve <code class="reqn">u = \tilde{u}(v)</code> (provided by <code><a href="#topic+derCOPinv2">derCOPinv2</a></code>), and
</p>
</li>
<li><p> Replace <code class="reqn">u</code> by <code class="reqn">x(u)</code> and <code class="reqn">v</code> by <code class="reqn">y(v)</code>.
</p>
</li></ol>

<p>The last step is optional as step two produces the regression in probability space, which might be desired, and step 3 actually transforms the probability regressions into the quantiles of the respective random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qua.regressCOP2(f=0.5, v=seq(0.01,0.99, by=0.01), cop=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qua.regressCOP2_+3A_f">f</code></td>
<td>
<p>A single value of nonexceedance probability <code class="reqn">F</code> to perform regression at and defaults to median regression <code class="reqn">F=1/2</code>;</p>
</td></tr>
<tr><td><code id="qua.regressCOP2_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="qua.regressCOP2_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="qua.regressCOP2_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula; and</p>
</td></tr>
<tr><td><code id="qua.regressCOP2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the regressed probabilities of <code class="reqn">U</code> and <code class="reqn">V=v</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+med.regressCOP2">med.regressCOP2</a></code>, <code><a href="#topic+derCOPinv2">derCOPinv2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Use a positively associated Plackett copula and perform quantile regression
theta &lt;- 0.10
R &lt;- qua.regressCOP2(cop=PLACKETTcop, para=theta) # 50th percentile regression
plot(R$U,R$V, type="l", lwd=6, xlim=c(0,1), ylim=c(0,1), col=8)
lines((1+(theta-1)*R$V)/(theta+1),R$V, col=4, lwd=1) # theoretical for Plackett,
# compare the theoretical form to that in qua.regressCOP---just switch terms around
# because of symmetry
R &lt;- qua.regressCOP2(f=0.90, cop=PLACKETTcop, para=theta) # 90th-percentile regression
lines(R$U,R$V, col=2, lwd=2)
R &lt;- qua.regressCOP2(f=0.10, cop=PLACKETTcop, para=theta) # 10th-percentile regression
lines(R$U,R$V, col=2, lty=2)
mtext("Quantile Regression U wrt V for Plackett copula")#
## End(Not run)
</code></pre>

<hr>
<h2 id='RAYcop'>The Rayleigh Copula</h2><span id='topic+RAYcop'></span>

<h3>Description</h3>

<p>The <em>Rayleigh copula</em> (Boškoskia and others, 2018) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{RAY}(u,v; \Theta) = 1 + A - B\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">A = e^{\Theta a_2 - a_2}\biggl(e^{-a_1}\int_0^{\Theta a_2} e^{-s}I_0\bigl(2\sqrt{a_1 s}\bigr)\,\mathrm{d}s - 1\biggr)\,\mathrm{d}s\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B = e^{-a_1}\int_0^{a_2}e^{-s}I_0\bigl(2\sqrt{\Theta a_1 s}\bigr)\,\mathrm{d}s\mbox{,}</code>
</p>

<p>where <code class="reqn">a1 = -\log(1-u)/(1-\Theta)</code>, <code class="reqn">a2 = -\log(1-v)/(1-\Theta)</code>, <code class="reqn">I_\nu(x)</code> is the modified Bessel function of the first kind of order <code class="reqn">\nu</code> (see <code>base::besselI()</code>), and <code class="reqn">\Theta \in (0,1]</code>. The copula, as <code class="reqn">\Theta \rightarrow 0^{+}</code> limits, to the <em>independence coupla</em> (<code class="reqn">\mathbf{\Pi}(u,v)</code>; <code><a href="#topic+P">P</a></code>) and as <code class="reqn">\Theta \rightarrow 1^{-}</code> limits to the <em>comonotonicity copula</em> (<code class="reqn">\mathbf{M}(u,v)</code>; <code><a href="#topic+M">M</a></code>). Finally, there are formulations of the Rayleigh copula using the <em>Marcum-Q function</em>, but the <span class="pkg">copBasic</span> developer has not been able to make such work. If the Marcum-Q function could be used, then only one integration and not the two involving the modified Bessel function are possible. Infinite integrations begin occurring in the upper right corner for about <code class="reqn">\Theta &gt; 0.995</code> at which point the <code class="reqn">\mathbf{M}(u,v)</code> copula is called in the source code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAYcop(u, v, para=NULL, rho=NULL, method=c("default"),
             rel.tol=.Machine$double.eps^0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RAYcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="RAYcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="RAYcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="RAYcop_+3A_rho">rho</code></td>
<td>
<p>Value for Spearman Rho from which parameter <code class="reqn">\Theta</code> is computed by polynomial approximation and returned. The estimation appears sufficient for most pratical applications (see <b>Examples</b>);</p>
</td></tr>
<tr><td><code id="RAYcop_+3A_method">method</code></td>
<td>
<p>The computational method of integrals associated with the definition of the copula; this is designed for the ability to switch eventually in sources to Marcum-Q function implementation. The definition in January 2023 and default is to call the two Bessel function integrals shown for the definition in this documentation;</p>
</td></tr>
<tr><td><code id="RAYcop_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Argument of the same name for <code>integrate()</code> call; and</p>
</td></tr>
<tr><td><code id="RAYcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>Documentation in Zeng and others [Part II] appear to have corrected the Marcum-Q function solution to the copula. The essence of that solution is with a Chi-distribution computation the Marcum-Q. Testing indictates that they have the correct solution, but the derivative for the conditional simulation as built into the design of <span class="pkg">copBasic</span> has difficulties. Perhaps this is related to numerical precision of the Marcum-Q?
</p>
<pre>
  sapply(seq_len(length((u))), function(i) {
    a1 &lt;- -log(1-u[i])
    if(is.infinite(a1)) return(v[i])
    a2 &lt;- -log(1-v[i])
    if(is.infinite(a2)) return(u[i])
    a1 &lt;- exp(log(a1) - log(1-p))
    a2 &lt;- exp(log(a2) - log(1-p))
    a3 &lt;- marcumq.chi(sqrt(2*  a1), sqrt(2*p*a2)) # Zeng and others (Part II)
    a4 &lt;- marcumq.chi(sqrt(2*p*a1), sqrt(2*  a2)) # Zeng and others (Part II)
    zz &lt;- 1 + (1-v[i])*a3 - (1-u[i])*(1-a4)       # Zeng and others (Part II)
    zz[zz &lt; 0] &lt;- 0
    zz[zz &gt; 1] &lt;- 1
    return(zz)
  })
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Boškoskia, P., Debenjaka, A., Boshkoskab, B.M., 2018, Rayleigh copula for describing impedance data with application to condition monitoring of proton exchange membrane fuel cells: European Journal of Operational Research, v. 266, pp. 269&ndash;277, <a href="https://doi.org/10.1016/j.ejor.2017.08.058">doi:10.1016/j.ejor.2017.08.058</a>.
</p>
<p>Zeng, X., Ren, J., Wang, Z., Marshall, S., and Durrani, T., [undated], Copulas for statistical signal processing (Part I)&mdash;Extensions and generalization, accessed January 14, 2024, at <a href="https://pure.strath.ac.uk/ws/portalfiles/portal/34078849/Copulas_Part1_v2_6.pdf">https://pure.strath.ac.uk/ws/portalfiles/portal/34078849/Copulas_Part1_v2_6.pdf</a>.
</p>
<p>Zeng, X., Ren, J., Sun, M., Marshall, S., and Durrani, T., [undated], Copulas for statistical signal processing (Part II)&mdash;Simulation, optimal selection and practical applications, accessed January 14, 2024, at <a href="https://strathprints.strath.ac.uk/48371/1/Copulas_Part2s_v2_5_2.pdf">https://strathprints.strath.ac.uk/48371/1/Copulas_Part2s_v2_5_2.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RAYcop(0.2, 0.8, para=0.8) # [1] 0.1994658  (by the dual Bessel functions)

RAYcop(0.8, 0.2, para=RAYcop(rho=rhoCOP(cop=RAYcop, para=0.8)))
# [1] 0.1994651 from polynomial conversion of Rho to Theta

## Not run: 
  # Recipe for assembling the Spearman Rho to Theta polynomial in sources.
  Thetas &lt;- seq(0, 0.999, by=0.001); RHOs &lt;- NULL
  for(p in Thetas)  RHOs &lt;- c(RHOs, rhoCOP(cop=RAYcop, para=p))
  LM &lt;- lm(Thetas ~ RHOs  + I(RHOs^2) + I(RHOs^4) + I(RHOs^6) - 1 )
  Rho2Theta &lt;- function(rho) {
    coes &lt;- c(1.32682824, -0.38876290, 0.09072305, -0.02921836)
    sapply(rho, function(r) coes[1]*r^1 + coes[2]*r^2 + coes[3]*r^4 + coes[4]*r^6)
  }
  plot(RHOs, Thetas, type="l", col=grey(0.8), lwd=12, lend=1,
       xlab="Spearman Rho", ylab="Rayleigh Copula Parameter Theta")
  lines(RHOs, Rho2Theta(RHOs), col="red", lwd=2) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='ReineckeWell266'>Porosity and Permeability Data for Well-266 of the Reinecke Oil Field, Horseshoe Atoll, Texas</h2><span id='topic+ReineckeWell266'></span>

<h3>Description</h3>

<p>These data represent porosity and permeability data from laboratory analysis for Well-266 Reinecke Oil Field, Horseshoe Atoll, Texas as used for the outstanding article by Saller and Dickson (2011). Dr. A.H. Saller shared a CSV file with the author of the <span class="pkg">copBasic</span> package sometime in 2011. These data are included in this package because of the instruction potential of the bivariate relation between the geologic properties of permeability and porosity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ReineckeWell266)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>WELLNO</dt><dd><p>The number of the well, no. 266;</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth in feet to the center of the incremental spacings of the data;</p>
</dd>
<dt>FRACDOLOMITE</dt><dd><p>The fraction of the core sample that is dolomite, 0 is 100 percent limestone;</p>
</dd>
<dt>Kmax</dt><dd><p>The maximum permeability without respect to orientation in millidarcies;</p>
</dd>
<dt>POROSITY</dt><dd><p>The porosity of the core sample; and</p>
</dd>
<dt>DOLOMITE</dt><dd><p>Is the interval treated as dolomite (1) or limestone (0).</p>
</dd>
</dl>



<h3>References</h3>

<p>Saller, A.H., Dickson, J.A., 2011, Partial dolomitization of a Pennsylvanian limestone buildup by hydrothermal fluids and its effect on reservoir quality and performance: AAPG Bulletin, v. 95, no. 10, pp. 1745&ndash;1762.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(ReineckeWell266)
summary(ReineckeWell266) # show summary statistics
## End(Not run)
</code></pre>

<hr>
<h2 id='ReineckeWells'>Porosity and Permeability Data for the Reinecke Oil Field, Horseshoe Atoll, Texas</h2><span id='topic+ReineckeWells'></span>

<h3>Description</h3>

<p>These data represent porosity and permeability data from laboratory analysis for the Reinecke Oil Field, Horseshoe Atoll, Texas as used for the outstanding article by Saller and Dickson (2011). Dr. A.H. Art Saller shared a CSV file with the author of the <span class="pkg">copBasic</span> package sometime in 2011.  These data are included in this package because of the instruction potential of the bivariate relation between the geologic properties of permeability and porosity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ReineckeWells)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>DOLOMITE</dt><dd><p>The fraction of the core sample that is dolomite, 0 is 100 percent limestone;</p>
</dd>
<dt>Kmax</dt><dd><p>The maximum permeability without respect to orientation in millidarcies;</p>
</dd>
<dt>K90</dt><dd><p>The horizontal (with respect to 90 degrees of the borehole) permeability in millidarcies;</p>
</dd>
<dt>Kvert</dt><dd><p>The vertical permeability in millidarcies; and</p>
</dd>
<dt>POROSITY</dt><dd><p>The porosity of the core sample.</p>
</dd>
</dl>



<h3>References</h3>

<p>Saller, A.H., Dickson, J.A., 2011, Partial dolomitization of a Pennsylvanian limestone buildup by hydrothermal fluids and its effect on reservoir quality and performance: AAPG Bulletin, v. 95, no. 10, pp. 1745&ndash;1762.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(ReineckeWells)
summary(ReineckeWells) # show summary statistics
## End(Not run)
</code></pre>

<hr>
<h2 id='RFcop'>The Raftery Copula</h2><span id='topic+RFcop'></span>

<h3>Description</h3>

<p>The <em>Raftery copula</em> (Nelsen, 2006, p. 172) is
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{\Theta}(u,v) = \mathbf{RF}(u,v) = \mathbf{M}(u,v) + \frac{1-\Theta}{1+\Theta}\biggl(uv\biggr)^{1/(1-\Theta)}\biggl[1-\bigl(\mathrm{max}\{u,v\}\bigr)^{-(1+\Theta)/(1-\Theta)}\biggr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\Theta \in (0,1)</code>. The copula, as <code class="reqn">\Theta \rightarrow 0^{+}</code> limits, to the <em>independence coupla</em> (<code class="reqn">\mathbf{P}(u,v)</code>; <code><a href="#topic+P">P</a></code>), and as <code class="reqn">\Theta \rightarrow 1^{-}</code>, limits to the <em>comonotonicity copula</em> (<code class="reqn">\mathbf{M}(u,v)</code>;  <code><a href="#topic+M">M</a></code>). The parameter <code class="reqn">\Theta</code> is readily computed from <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) by <code class="reqn">\rho_\mathbf{C} = \Theta(4-3\Theta)/(2-\Theta)^2</code> or from <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by <code class="reqn">\tau_\mathbf{C} = 2\Theta/(3-\Theta)</code>. However, this copula like others within the <span class="pkg">copBasic</span> package can be reflected (rotated) at will with the <code><a href="#topic+COP">COP</a></code> abstraction layer to acquire negative or inverse dependency (<em>countermonotonicity</em>) (see the <b>Examples</b>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RFcop(u, v, para=NULL, rho=NULL, tau=NULL, fit=c("rho", "tau"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RFcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="RFcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="RFcop_+3A_para">para</code></td>
<td>
<p>A vector (single element) of parameters&mdash;the <code class="reqn">\Theta</code> parameter of the copula;</p>
</td></tr>
<tr><td><code id="RFcop_+3A_rho">rho</code></td>
<td>
<p>Optional Spearman Rho from which the parameter will be estimated and presence of <code>rho</code> trumps <code>tau</code>;</p>
</td></tr>
<tr><td><code id="RFcop_+3A_tau">tau</code></td>
<td>
<p>Optional Kendall Tau from which the parameter will be estimated;</p>
</td></tr>
<tr><td><code id="RFcop_+3A_fit">fit</code></td>
<td>
<p>If <code>para</code>, <code>rho</code>, and <code>tau</code> are all <code>NULL</code>, then the <code>u</code> and <code>v</code> represent the sample. The measure of association by the <code>fit</code> declaration will be computed and the parameter estimated subsequently. The <code>fit</code> has no other utility than to trigger which measure of association is computed internally by the <code>cor</code> function in <span class="rlang"><b>R</b></span>; and</p>
</td></tr>
<tr><td><code id="RFcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned. Otherwise if either <code>rho</code> or <code>tau</code> is given, then the <code class="reqn">\Theta</code> is computed and a <code>list</code> having
</p>
<table role = "presentation">
<tr><td><code>para</code></td>
<td>
<p>The parameter <code class="reqn">\Theta</code>;</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>Spearman Rho if the <code>rho</code> is given; and</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Kendall Tau if the <code>tau</code> is given but also if both <code>rho</code> and <code>tau</code> are <code>NULL</code> as mentioned next.</p>
</td></tr>
</table>
<p>and if <code>para=NULL</code> and <code>rho</code> and <code>tau=NULL</code>, then the values within <code>u</code> and <code>v</code> are used to compute Kendall Tau and then compute the parameter, and these are returned in the aforementioned list.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Lower tail dependency of Theta = 0.5 --&gt; 2*(0.5)/(1+0.5) = 2/3 (Nelsen, 2006, p. 214)
taildepCOP(cop=RFcop, para=0.5)$lambdaL # 0.66667

## Not run: 
  # Simulate for a Spearman Rho of 0.7, then extract estimated Theta that internally
  # is based on Kendall Tau of U and V, then convert estimate to equivalent Rho.
  set.seed(1)
  UV &lt;- simCOP(1000, cop=RFcop, RFcop(rho=0.7)$para)
  Theta &lt;- RFcop(UV$U, UV$V, fit="tau")$para # 0.607544
  Rho   &lt;- Theta*(4-3*Theta)/(2-Theta)^2     # 0.682255 (nearly 0.7) #
## End(Not run)

## Not run: 
  set.seed(1)
  UV &lt;- simCOP(1000, cop=COP, para=list(cop=RFcop, para=RFcop(rho=0.5)$para, reflect=3))
  cor(UV$U, UV$V, method="spearman") # -0.492677 as expected with reversal of V #
## End(Not run)
</code></pre>

<hr>
<h2 id='rhobevCOP'>A Dependence Measure for a Bivariate Extreme Value Copula based on the Expectation of the Product of Negated Log-Transformed Random Variables U and V</h2><span id='topic+rhobevCOP'></span>

<h3>Description</h3>

<p>Compute a dependence measure based on the expectation of the product of transformed random variables <code class="reqn">U</code> and <code class="reqn">V</code>, which unnamed by Joe (2014, pp. 383&ndash;384) but symbolically is <code class="reqn">\rho_E</code>, having a <em>bivariate extreme value copula</em> <code class="reqn">\mathbf{C}_{BEV}(u,v)</code> by
</p>
<p style="text-align: center;"><code class="reqn">\rho_E = \mathrm{E}\bigl[(-\log U) \times (-\log V)\bigr] - 1 = \int_0^1 \bigl[B(w)\bigr]^{-2}\,\mathrm{d}w - 1\mbox{,}</code>
</p>

<p>where <code class="reqn">B(w) = A(w, 1-w)</code>, <code class="reqn">B(0) = B(1) = 1</code>, <code class="reqn">B(w) \ge 1/2</code>, and <code class="reqn">0 \le w \le 1</code>, and where only bivariate extreme value copulas can be written as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}_{BEV}(u,v) = \mathrm{exp}[-A(-\log u, -\log v)]\mbox{,}</code>
</p>

<p>and thus in terms of the coupla
</p>
<p style="text-align: center;"><code class="reqn">B(w) = -\log\bigl[\mathbf{C}_{BEV}(\mathrm{exp}[-w], \mathrm{exp}[w-1])\bigr]\mbox{.}</code>
</p>

<p>Joe (2014, p. 383) states that <code class="reqn">\rho_E</code> is the correlation of the &ldquo;survival function of a bivariate min-stable exponential distribution,&rdquo; which can be assembled as a function of <code class="reqn">B(w)</code>. Joe (2014, p. 383) also shows the following expression for <em>Spearman Rho</em>
</p>
<p style="text-align: center;"><code class="reqn">\rho_S = 12 \int_0^1 \bigl[1 + B(w)\bigr]^{-2}\,\mathrm{d}w - 3\mbox{,}</code>
</p>

<p>in terms of <code class="reqn">B(w)</code>. This expression, in conjunction with <code><a href="#topic+rhoCOP">rhoCOP</a></code>, was used to confirm the prior expression shown here for <code class="reqn">B(w)</code> in terms of <code class="reqn">\mathbf{C}_{BEV}(u,v)</code>. Lastly, for <em>independence</em> (<code class="reqn">uv = \mathbf{\Pi}</code>; <code><a href="#topic+P">P</a></code>), <code class="reqn">\rho_E = 0</code> and for the <em>Fréchet&ndash;Hoeffding upper-bound copula</em> (perfect positive association), <code class="reqn">\rho_E = 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhobevCOP(cop=NULL, para=NULL, as.sample=FALSE, brute=FALSE, delta=0.002, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhobevCOP_+3A_cop">cop</code></td>
<td>
<p>A bivariate extreme value copula function&mdash;the function <code>rhobevCOP</code> makes <b>no provision</b> for verifying whether the copula in <code>cop</code> is actually an <em>extreme value copula</em>;</p>
</td></tr>
<tr><td><code id="rhobevCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="rhobevCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute a <code class="reqn">\hat\rho_E</code> by <code>mean()</code> of the product of negated <code>log()</code>'s in <span class="rlang"><b>R</b></span>. The user is required to cast <code>para</code> into estimated probabilities (see <b>Examples</b>);</p>
</td></tr>
<tr><td><code id="rhobevCOP_+3A_brute">brute</code></td>
<td>
<p>Should brute force be used instead of two nested <code>integrate()</code> functions in <span class="rlang"><b>R</b></span> to perform the double integration;</p>
</td></tr>
<tr><td><code id="rhobevCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\mathrm{d}w</code> for the brute force (<code>brute=TRUE</code>) integration; and</p>
</td></tr>
<tr><td><code id="rhobevCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\rho_E</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Theta &lt;- GHcop(tau=1/3)$para     # Gumbel-Hougaard copula with Kendall Tau = 1/3
rhobevCOP(cop=GHcop, para=Theta) # 0.3689268 (RhoE after Joe [2014])
rhoCOP(   cop=GHcop, para=Theta) # 0.4766613 (Spearman Rho)

## Not run: 
set.seed(394)
Theta &lt;- GHcop(tau=1/3)$para     # Gumbel-Hougaard copula with Kendall Tau = 1/3
simUV &lt;- simCOP(n=30000, cop=GHcop, para=Theta, graphics=FALSE) # large simulation
samUV &lt;- simUV * 150; n &lt;- length(samUV[,1]) # convert to fake unit system
samUV[,1] &lt;- rank(simUV[,1]-0.5)/n; samUV[,2] &lt;- rank(simUV[,2]-0.5)/n # hazen
rhobevCOP(para=samUV, as.sample=TRUE) # 0.3708275
## End(Not run)
</code></pre>

<hr>
<h2 id='rhoCOP'>The Spearman Rho of a Copula</h2><span id='topic+rhoCOP'></span>

<h3>Description</h3>

<p>Compute the measure of association known as the <em>Spearman Rho</em> <code class="reqn">\rho_\mathbf{C}</code> of a copula according to Nelsen (2006, pp. 167&ndash;170, 189, 208) by
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = 12\int\!\!\int_{\mathcal{I}^2} \mathbf{C}(u,v)\, \mathrm{d}u\mathrm{d}v - 3\mbox{,}</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = 12\int\!\!\int_{\mathcal{I}^2} \bigl[\mathbf{C}(u,v) - uv\bigr]\, \mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>where the later equation is implemented by <code>rhoCOP</code> as the default method (<code>method="default"</code>). This equation, here having <code class="reqn">p = 1</code> and <code class="reqn">k_p(1) = 12</code>, is generalized under <code><a href="#topic+hoefCOP">hoefCOP</a></code>. The absence of the <code class="reqn">12</code> in the above equation makes it equal to the <em>covariance of a copula</em> defined by the <em>Hoeffding Identity</em> (Joe, 2014, p. 54):
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{cov}(U, V) = \int\!\!\int_{\mathcal{I}^2} \bigl[\mathbf{C}(u,v) - uv\bigr]\, \mathrm{d}u\mathrm{d}v\mbox{ or}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathrm{cov}(U, V) = \int\!\!\int_{\mathcal{I}^2} \bigl[\hat{\mathbf{C}}(u,v) - uv\bigr]\, \mathrm{d}u\mathrm{d}v\mbox{, which\ is}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathrm{cov}(U, V) = \int\!\!\int_{\mathcal{I}^2} \bigl[u+v-1+\mathbf{C}(1-u,1-v) - uv\bigr]\, \mathrm{d}u\mathrm{d}v\mbox{.}</code>
</p>

<p>Depending on copula family (Joe, 2014, pp. 56 and 267), the alternative formulation for <code class="reqn">\rho_\mathbf{C}</code> could be used
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = 3 - 12\int\!\!\int_{\mathcal{I}^2} u \frac{\delta\mathbf{C}(u,v)}{\delta u} \, \mathrm{d}u\mathrm{d}v = 3 - 12\int\!\!\int_{\mathcal{I}^2} v\frac{\delta\mathbf{C}(u,v)}{\delta v} \, \mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>where the first integral form corresponds to Joe (2014, eq. 248, p. 56) and is the <code>method="joe21"</code>, and the second integral form is the <code>method="joe12"</code>.
</p>
<p>The integral
</p>
<p style="text-align: center;"><code class="reqn">\int\!\!\int_{\mathcal{I}^2} \mathbf{C}(u,v)\,\mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>represents the &ldquo;volume under the graph of the copula and over the unit square&rdquo; (Nelsen, 2006, p. 170) and therefore <code class="reqn">\rho_\mathbf{C}</code> is simple a rescaled volume under the copula. The second equation for <code class="reqn">\rho_\mathbf{C}</code> expresses the &ldquo;average distance&rdquo; between the joint distribution and statistical <em>independence</em> <code class="reqn">\mathbf{\Pi} = uv</code>. Nelsen (2006, pp. 175&ndash;176) shows that the following relation between <code class="reqn">\rho_\mathbf{C}</code> and <code class="reqn">\tau_\mathbf{C}</code> (<code><a href="#topic+tauCOP">tauCOP</a></code>) exists
</p>
<p style="text-align: center;"><code class="reqn">-1 \le 3\tau - 2\rho \le 1\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>rhoCOP(cop=NULL, para=NULL, method=c("default", "joe21", "joe12"),
                            as.sample=FALSE, brute=FALSE, delta=0.002, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhoCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="rhoCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="rhoCOP_+3A_method">method</code></td>
<td>
<p>The form of integration used to compute (see above);</p>
</td></tr>
<tr><td><code id="rhoCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat\rho</code> by dispatch to <code>cor()</code> function in <span class="rlang"><b>R</b></span> with <code>method = "spearman"</code>;</p>
</td></tr>
<tr><td><code id="rhoCOP_+3A_brute">brute</code></td>
<td>
<p>Should brute force be used instead of two nested <code>integrate()</code> functions in <span class="rlang"><b>R</b></span> to perform the double integration;</p>
</td></tr>
<tr><td><code id="rhoCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\mathrm{d}u</code> and <code class="reqn">\mathrm{d}v</code> for the brute force integration using <code>brute</code>; and</p>
</td></tr>
<tr><td><code id="rhoCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\rho_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>Technically, Nelsen (2006) also shows that these definitions are a form of call to a <em>concordance function</em> <code class="reqn">\mathcal{Q}(\mathbf{C}_1,\mathbf{C}_2)</code> of two copulas that involve <code class="reqn">\mathbf{C}_1{=}\mathbf{C}(u,v)</code> and <code class="reqn">\mathbf{C}_2{=}\mathbf{\Pi}</code>. As such in order to keep <code>rhoCOP</code> a small function when <code>brute=TRUE</code>, <code class="reqn">\rho_\mathbf{C}</code> is computed by a special call to <code><a href="#topic+tauCOP">tauCOP</a></code>, which by itself and although titled for computation of <em>Kendall Tau</em>, does support the concordance function <code class="reqn">\mathcal{Q}(\mathbf{C}_1, \mathbf{C}_2)</code> [see Nelsen (2006, pp. 158&ndash;159)] when given two different copulas and respective parameters as arguments. The well-known <em>Pearson correlation coefficient</em> equals Spearman rho value if random variables <code class="reqn">X</code> and <code class="reqn">Y</code> are both uniformly distributed on <code class="reqn">[0,1]</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>,
<code><a href="#topic+hoefCOP">hoefCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>,  <code><a href="#topic+wolfCOP">wolfCOP</a></code>,
<code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rhoCOP(cop=PSP)             # 0.4784176

## Not run: 
  rhoCOP(cop=PSP, brute=TRUE) # 0.4684063
  # CPU heavy example showing that the dual-integration (fast) results in
  # a Spearman Rho that mimics a sample version
  do_rho &lt;- function(n) {
    uv &lt;- simCOP(n=n, cop=PSP, ploton=FALSE, points=FALSE)
    return(cor(uv$U, uv$V, method="spearman"))
  }
  set.seed(1)
  rhos &lt;- replicate(200, do_rho(1000))
  rho_sample &lt;- mean(rhos); print(rho_sample) # 0.4764914
## End(Not run)

## Not run: 
  para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
               para1=0.00395,    para2=4.67,     alpha=0.9392, beta=0.5699)
  rhoCOP(cop=composite2COP, para=para) # -0.5924796

  para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
               para1=0.14147,    para2=20.96,    alpha=0.0411, beta=0.6873)
  rhoCOP(cop=composite2COP, para=para) # 0.2818874

  para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
               para1=0.10137,     para2=4492.87, alpha=0.0063, beta=0.0167)
  rhoCOP(cop=composite2COP, para=para)             # 0.9812919
  rhoCOP(cop=composite2COP, para=para, brute=TRUE) # 0.9752155
## End(Not run)

## Not run: 
  # This is the same composited copula used in a highly asymmetric multi-modal
  # plotting example under densityCOPplot(). Let us use that copula as a means to
  # check on the Spearman Rho from alternative formulations by Joe (2014).
  para &lt;- list(alpha=0.15, beta=0.90, kappa=0.06, gamma=0.96,
               cop1=GHcop, cop2=PLACKETTcop, para1=5.5, para2=0.07)
  "rhoCOPbyJoe21" &lt;- function(cop=NULL, para=NULL, ...) { # Joe (2014, eq. 2.48)
     myint &lt;- NULL
     try(myint &lt;- integrate(function(u) {
         sapply(u,function(u) { integrate(function(v) {
         u * derCOP( u, v, cop=cop, para=para, ...)},  0, 1)$value })}, 0, 1))
     ifelse(is.null(myint), return(NA), return(3 - 12*myint$value))
  }
  "rhoCOPbyJoe12" &lt;- function(cop=NULL, para=NULL, ...) { # Not in Joe (2014)
     myint &lt;- NULL
     try(myint &lt;- integrate(function(u) {
         sapply(u,function(u) { integrate(function(v) {
         v * derCOP2( u, v, cop=cop, para=para, ...)}, 0, 1)$value })}, 0, 1))
     ifelse(is.null(myint), return(NA), return(3 - 12*myint$value))
  }
  rhoCOP(       cop=composite2COP, para=para) # 0.1031758
  rhoCOPbyJoe21(cop=composite2COP, para=para) # 0.1031803
  rhoCOPbyJoe12(cop=composite2COP, para=para) # 0.1031532
## End(Not run)
</code></pre>

<hr>
<h2 id='rmseCOP'>Root Mean Square Error between a Fitted Copula and an Empirical Copula</h2><span id='topic+rmseCOP'></span>

<h3>Description</h3>

<p>Compute the <em>root mean square error</em> <code class="reqn">\mathrm{RMSE}_\mathbf{C}</code> (Chen and Guo, 2019, p. 29), which is computed using <em>mean square error</em> <code class="reqn">\mathrm{MSE}</code> as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{MSE}_\mathbf{C} = \frac{1}{n}\sum_{i=1}^n \bigl(\mathbf{C}_n(u_i,v_i) - \mathbf{C}_{\Theta_m}(u_i, v_i)\bigr)^2\mbox{ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathrm{RMSE}_\mathbf{C} = \sqrt{\mathrm{MSE}_\mathbf{C}}\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}_n(u_i,v_i)</code> is the <em>empirical copula</em> (empirical joint probability) for the <code class="reqn">i</code>th observation, <code class="reqn">\mathbf{C}_{\Theta_m}(u_i, v_i)</code> is the fitted copula having <code class="reqn">m</code> parameters in <code class="reqn">\Theta</code>. The <code class="reqn">\mathbf{C}_n(u_i,v_i)</code> comes from <code><a href="#topic+EMPIRcop">EMPIRcop</a></code>. The <code class="reqn">\mathrm{RMSE}_\mathbf{C}</code> is in effect saying that the best copula will have its joint probabilities plotting on a 1:1 line with the empirical joint probabilities, which is an <code class="reqn">\mathrm{RMSE}_\mathbf{C}=0</code>. From the <code class="reqn">\mathrm{MSE}_\mathbf{C}</code> shown above, the <em>Akaike information criterion</em> (AIC) <code><a href="#topic+aicCOP">aicCOP</a></code> and <em>Bayesian information criterion</em> (BIC) <code><a href="#topic+bicCOP">bicCOP</a></code> can be computed, which add a penalty for <code class="reqn">m</code> parameters. These goodness-of-fits can assist in deciding one copula favorability over another, and another goodness-of-fit using the absolute differences between <code class="reqn">\mathbf{C}_n(u,v)</code> and <code class="reqn">\mathbf{C}_{\Theta_m}(u, v)</code> is found under <code><a href="#topic+statTn">statTn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmseCOP(u, v=NULL, cop=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmseCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="rmseCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; If not given, then a second column from argument <code>u</code> is attempted;</p>
</td></tr>
<tr><td><code id="rmseCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="rmseCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula; and</p>
</td></tr>
<tr><td><code id="rmseCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to either copula (likely most commonly to the empirical copula).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\mathrm{RMSE}_\mathbf{C}</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Chen, Lu, and Guo, Shenglian, 2019, Copulas and its application in hydrology and water resources: Springer Nature, Singapore, ISBN 978&ndash;981&ndash;13&ndash;0574&ndash;0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EMPIRcop">EMPIRcop</a></code>, <code><a href="#topic+aicCOP">aicCOP</a></code>, <code><a href="#topic+bicCOP">bicCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
S &lt;- simCOP(80, cop=GHcop, para=5) # Simulate some probabilities, but we
# must then treat these as data and recompute empirical probabilities.
U &lt;- lmomco::pp(S$U, sort=FALSE); V &lt;- lmomco::pp(S$V, sort=FALSE)
# The parent distribution is Gumbel-Hougaard extreme value copula.
# But in practical application we do not know that but say we speculate that
# perhaps the Galambos extreme value might be the parent. Then maximum
# likelihood is used to fit the single parameter.
pGL &lt;- mleCOP(U,V, cop=GLcop, interval=c(0,20))$par

rmses &lt;- c(rmseCOP(U,V, cop=GLcop, para=pGL),
           rmseCOP(U,V, cop=P),
           rmseCOP(U,V, cop=PSP))
names(rmses) &lt;- c("GLcop", "P", "PSP")
print(rmses) # We will see that the first RMSE is the smallest as the
# Galambos has the nearest overall behavior than the P and PSP copulas.
## End(Not run)
</code></pre>

<hr>
<h2 id='sectionCOP'>The Sections or Derivative of the Sections of a Copula</h2><span id='topic+sectionCOP'></span>

<h3>Description</h3>

<p>Compute the <em>copula sections</em> or the <em>(partial) derivatives of copula sections</em> of a copula (Nelsen, 2006, pp. 12&ndash;14). The <em>horizontal section</em> at <code class="reqn">V=a</code> (a constant) is
</p>
<p style="text-align: center;"><code class="reqn">t \mapsto \mathbf{C}(t,a)\mbox{, and}</code>
</p>

<p>the <em>vertical  section</em> at <code class="reqn">U=a</code> (a constant, with respect to <code class="reqn">V</code> or <code>wrtV=TRUE</code>) is
</p>
<p style="text-align: center;"><code class="reqn">t \mapsto \mathbf{C}(a,t)\mbox{.}</code>
</p>

<p>The partial derivatives of the copula sections are <em>conditional cumulative distribution functions</em> (see <code><a href="#topic+derCOP">derCOP</a></code> and <code><a href="#topic+derCOP2">derCOP2</a></code>). The derivatives are constrained as
</p>
<p style="text-align: center;"><code class="reqn">0 \le \frac{\delta}{\delta u}\mathbf{C}(u,v) \le 1\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 \le \frac{\delta}{\delta v}\mathbf{C}(u,v) \le 1\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>sectionCOP(f, cop=NULL,  para=NULL, wrtV=FALSE, dercop=FALSE, delt=0.005,
              ploton=TRUE, lines=TRUE, xlab="NONEXCEEDANCE PROBABILITY", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sectionCOP_+3A_f">f</code></td>
<td>
<p>A single value of nonexceedance probability <code class="reqn">u</code> or <code class="reqn">v</code> along the horizontal <code class="reqn">U</code> axis or vertical <code class="reqn">V</code> axis of the unit square <code class="reqn">\mathcal{I}^2</code>;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_wrtv">wrtV</code></td>
<td>
<p>A logical to toggle between with respect to <code class="reqn">v</code> or <code class="reqn">u</code> (default). The default provides the vertical section whereas the horizontal comes from <code>wrtV = TRUE</code>;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_dercop">dercop</code></td>
<td>
<p>A logical that triggers the derivative of the section;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_delt">delt</code></td>
<td>
<p>The increment of the level curves to plot, defaults to 5-percent intervals;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_lines">lines</code></td>
<td>
<p>Draw the lines of diagonal to the current device;</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_xlab">xlab</code></td>
<td>
<p>A label for the x-axis title passed to <code>plot()</code> in <span class="rlang"><b>R</b></span>; and</p>
</td></tr>
<tr><td><code id="sectionCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>plot()</code> and <code>lines()</code> functions in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table role = "presentation">
<tr><td><code>t</code></td>
<td>
<p>The nonexceedance probability along the section. The nomenclature <code class="reqn">t</code> mimics Nelsen (2006) and is <em>not</em> the same as the <code class="reqn">u</code> or <code class="reqn">v</code>;</p>
</td></tr>
<tr><td><code>seccop</code></td>
<td>
<p>The section of the copula or its derivative;</p>
</td></tr>
<tr><td><code>wrt</code></td>
<td>
<p>A text string declaring what the setting for <code>wrtV</code> was;</p>
</td></tr>
<tr><td><code>fvalue</code></td>
<td>
<p>The provided value of nonexceedance probability; and</p>
</td></tr>
<tr><td><code>isderivative</code></td>
<td>
<p>A logical stating whether the derivative of the section is <code>seccop</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+diagCOP">diagCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# EXAMPLE 1, plot the v=0.55 section and then u=0.55 section, which will overlay
# the other because the PSP is a symmetrical copula
tmp &lt;- sectionCOP(0.55, cop=PSP, ylab="COPULA SECTIONS",  lwd=5, col=2)
tmp &lt;- sectionCOP(0.55, cop=PSP, wrtV=TRUE, ploton=FALSE, lwd=2, col=3)
# now add the v=0.85 section and the u=0.85, again overlay each other
tmp &lt;- sectionCOP(0.85, cop=PSP, ploton=FALSE,             lwd=5, col=2, lty=2)
tmp &lt;- sectionCOP(0.85, cop=PSP, wrtV=TRUE, ploton=FALSE,  lwd=2, col=3, lty=2)#
## End(Not run)

## Not run: 
# EXAMPLE 2, v=0.35 section and derivative (the conditional distribution) function
tmp &lt;- sectionCOP(0.35, cop=PSP, ylab="COPULA SECTIONS OR DERIV.", lwd=5, col=3)
tmp &lt;- sectionCOP(0.35, cop=PSP, dercop=TRUE, ploton=FALSE,               col=3)
# The thin green line represents the cumulative distribution function conditional
# on u = 0.35 from the derCOP function.  Then see Example 3
## End(Not run)

## Not run: 
# EXAMPLE 3 (random selection commented out)
#para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop, alpha=runif(1), beta=runif(1),
#             para1=10^runif(1,min=-4, max=0), para2=10^runif(1,min= 0, max=4))
para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop, alpha=0.7, beta=0.22,
             para1=0.0155, para2=214.4)
txts &lt;- c("Alpha=",    round(para$alpha,    digits=4),
          "; Beta=",   round(para$beta,     digits=4),
          "; Theta1=", round(para$para1[1], digits=5),
          "; Theta2=", round(para$para2[1], digits=2))
layout(matrix(1:2,byrow=TRUE))
D &lt;- simCOP(n=1000, cop=composite2COP, para=para, cex=0.5, col=rgb(0,0,0,0.2), pch=16)
mtext(paste(txts,collapse=""))
#f &lt;- c(runif(1),runif(1))
f &lt;- c(0.2,0.9) # RED is the horizontal section and BLACK is the vertical section
segments(f[1],0,f[1],1, col=2, lwd=2); segments(0,f[2],1,f[2], lwd=2)
ftxt &lt;- c("Sections (thick) and derivatives (thin) at ", f, " nonexceed. prob.")
tmp &lt;- sectionCOP(f[1],cop=composite2COP,para=para, col=2, lwd=4)
tmp &lt;- sectionCOP(f[1],cop=composite2COP,para=para, dercop=TRUE, ploton=FALSE, col=2)
tmp &lt;- sectionCOP(f[2],cop=composite2COP,para=para,wrtV=TRUE,ploton=FALSE,lwd=4)
tmp &lt;- sectionCOP(f[2],cop=composite2COP,para=para,wrtV=TRUE,ploton=FALSE,dercop=TRUE)
mtext(paste(ftxt, collapse=""))
# The thin lines are the CDFs conditional on the respective values of "f". Carefully
# compare the point densities along and near the sections in the top plot to the
# respective shapes of the CDFs in the bottom plot. If the bottom plot were rotated
# 90 degrees clockwise and then reflected top to bottom, the conditional quantile
# function QDF results. Reflection is needed because, by convention, QDFs are monotonic
# increasing to right---functions derCOPinv() and derCOPinv2() provide the CDF inversion.
## End(Not run)
</code></pre>

<hr>
<h2 id='semicorCOP'>Lower and Upper Semi-Correlations of a Copula</h2><span id='topic+semicorCOP'></span>

<h3>Description</h3>

<p>Compute the <em>lower semi-correlations</em> (bottom-left)
</p>
<p style="text-align: center;"><code class="reqn">\rho^{N{-}{-}}_\mathbf{C}(u,v; a) = \rho_N^{{-}{-}}(a) \mbox{ and}</code>
</p>

<p>compute the <em>upper semi-correlations</em> (top-right)
</p>
<p style="text-align: center;"><code class="reqn">\rho^{N{+}{+}}_\mathbf{C}(u,v; a) = \rho_N^{{+}{+}}(a)</code>
</p>

<p>of a copula <code class="reqn">\mathbf{C}(u,v)</code> (Joe, 2014, p. 73) using numerical simulation. The semi-correlations are defined as
</p>
<p style="text-align: center;"><code class="reqn">\rho_N^{{-}{-}}(a) = \mathrm{cor}[Z_1, Z_2 \mid Z_1 &lt; -a, Z_2 &lt; -a]\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\rho_N^{{+}{+}}(a) = \mathrm{cor}[Z_1, Z_2 \mid Z_1 &gt; +a, Z_2 &gt; +a]\mbox{,\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\rho_N(a &gt; -\infty) = \mathrm{cor}[Z_1, Z_2]\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathrm{cor[z_1, z_2]}</code> is the familiar <em>Pearson correlation function</em>, which is in <span class="rlang"><b>R</b></span> the syntax <code>cor(...,</code> <code>method="pearson")</code>, parameter <code class="reqn">a \ge 0</code> is a truncation point that identifies <em>truncated tail regions</em> (Joe, 2014, p. 73), and lastly <code class="reqn">(Z_1, Z_2) \sim \mathbf{C}(\Phi, \Phi)</code> and thus from the standard normal distribution <code class="reqn">(Z_1, Z_2) = (\Phi^{-1}(u), \Phi^{-1}(v))</code> where the random variables <code class="reqn">(U,V) \sim \mathbf{C}</code>.
</p>
<p>The semi-correlations are extended for the <span class="pkg">copBasic</span> package into bottom right and top left versions as well by
</p>
<p style="text-align: center;"><code class="reqn">\rho_N^{{+}{-}}(a) = \mathrm{cor}[Z_1, Z_2 \mid Z_1 &gt; +a, Z_2 &lt; -a]\mbox{,\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\rho_N^{{-}{+}}(a) = \mathrm{cor}[Z_1, Z_2 \mid Z_1 &lt; -a, Z_2 &gt; +a]\mbox{.}</code>
</p>

<p>As a result, the notations <code class="reqn">{-}{-}</code>, <code class="reqn">{+}{+}</code>, <code class="reqn">{+}{-}</code>, and <code class="reqn">{-}{+}</code> can be used to represent each of the respective corners bottom-left, top-right, bottom-right, and top-left of the <code class="reqn">(u,v)</code> domain with the respective truncation. These words are used in the variable names of the returned list from the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semicorCOP(cop=NULL, para=NULL, truncation=0, n=0, as.sample=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="semicorCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="semicorCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="semicorCOP_+3A_truncation">truncation</code></td>
<td>
<p>The truncation value for <code class="reqn">a</code>, which is in standard normal variates, and the default of zero is the origin (medians);</p>
</td></tr>
<tr><td><code id="semicorCOP_+3A_n">n</code></td>
<td>
<p>The sample size <code class="reqn">n</code> for simulation estimates of the <code class="reqn">\rho_N</code>;</p>
</td></tr>
<tr><td><code id="semicorCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat\rho_N</code> (see <b>Note</b>); and</p>
</td></tr>
<tr><td><code id="semicorCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value(s) for <code class="reqn">\rho_N</code>, <code class="reqn">\rho_N^{{-}{-}}</code>, <code class="reqn">\rho_N^{{+}{+}}</code>, <code class="reqn">\rho_N^{{+}{-}}</code>, and <code class="reqn">\rho_N^{{-}{+}}</code> are returned.
</p>


<h3>Note</h3>

<p>The sample semi-correlations can be computed from a two-column table that is passed into the function using the <code>para</code> argument. Although the truncation point <code class="reqn">a \ge 0</code>, as <code class="reqn">a</code> increases and focus is increasingly made into one or the other truncated tail regions, the sample version with data becomes decreasing well estimated because the available sample size diminishes. The <code>para</code> argument can contain probabilities or raw data because internally the function computes the <em>Hazen plotting positions</em> (<em>e.g.</em> <code class="reqn">u_i = (i-0.5) / n</code> for rank <code class="reqn">i</code> and sample size <code class="reqn">n</code>) because Joe (2014, pp. 9, 17, 245, 247&ndash;248) repeatedly emphasizes this form of plotting position when normal scores are involved.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+giniCOP">giniCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>, <code><a href="#topic+COP">COP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Gumbel-Hougaard copula with Pearson rhoN = 0.4 (by definition)
run &lt;- sapply(1:50, function(i) semicorCOP(cop=GHcop, para=1.350, n=600))
mean(unlist(run[1,])) # cor.normal.scores
mean(unlist(run[2,])) #  botleft.semicor
mean(unlist(run[3,])) # topright.semicor
sd(  unlist(run[1,])) # cor.normal.scores (These are our sampling variations
sd(  unlist(run[2,])) #  botleft.semicor   for the n=600 used as a Monte
sd(  unlist(run[3,])) # topright.semicor   Carlo simulation.)
# The function returns:    rhoN = 0.392112, rhoN--= 0.117674, rhoN++= 0.404733
#  standard deviations           (0.038883)        (0.073392)        (0.073942)
# Joe (2014, p. 72) shows: rhoN = 0.4_____, rhoN--= 0.132___, rhoN++= 0.415___
#  standard deviations           (not avail)       (0.08____)        (0.07____)
# We see alignment with the results of Joe with his n=600. #
## End(Not run)

## Not run: 
p &lt;- 0.5 # Reasonable strong positive association for the Raftery copula,
# but then we are going to be reflecting and rotating the copula.
# See similar Example under COP() function.
"RFcop1" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="1")
"RFcop2" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="2")
"RFcop3" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="3")
"RFcop4" &lt;- function(u,v, para) COP(u,v, cop=RFcop, para=para, reflect="4")
RF &lt;- NULL; n &lt;- 10000
RF &lt;- rbind(RF, as.data.frame(semicorCOP(cop=RFcop1, para=p, n=n))[,1:5])
RF &lt;- rbind(RF, as.data.frame(semicorCOP(cop=RFcop2, para=p, n=n))[,1:5])
RF &lt;- rbind(RF, as.data.frame(semicorCOP(cop=RFcop3, para=p, n=n))[,1:5])
RF &lt;- rbind(RF, as.data.frame(semicorCOP(cop=RFcop4, para=p, n=n))[,1:5])
print(RF[,1:3]) # total sample and lower and upper semi-correlations
#   cor.normal.scores botleft.semicor topright.semicor
# 1         0.5587837      0.74124686       0.10027641
# 2         0.5567889      0.10302772       0.73729702
# 3        -0.5807201     -0.04683536      -0.01714573 # see near zeros --,++
# 4        -0.5698139      0.03040520       0.05125916 # see near zeros --,++
print(RF[,2:5]) # now look at all four corners
#   botleft.semicor topright.semicor topleft.semicor botright.semicor
# 1      0.74124686       0.10027641      0.01529508       0.02046530
# 2      0.10302772       0.73729702     -0.05195628       0.01747874
# 3     -0.04683536      -0.01714573     -0.11106842      -0.74077321
# 4      0.03040520       0.05125916     -0.74516061      -0.07636233
# Notice how the tight tail of the copula, being reflected and rotated
# into each of the four corners, shows semi-correlation magnitude of 0.74.
# See the copula density plots of COP() Examples section. 
## End(Not run)
</code></pre>

<hr>
<h2 id='simcomposite3COP'>Compute the L-comoments of a Four-Value Composited Copula by Simulation</h2><span id='topic+simcomposite3COP'></span>

<h3>Description</h3>

<p>Simulate copula parameters and compute <em>L-comoments</em> and provision for plotting features for a composited copula using four compositing parameters (see <code><a href="#topic+composite3COP">composite3COP</a></code>). The compositing parameters are each independent and uniformly distributed:
</p>
<p style="text-align: center;"><code class="reqn">\alpha \sim \mathrm{U}[0,1];\ \beta \sim \mathrm{U}[0,1];\ \kappa \sim \mathrm{U}[0,1];\ \gamma \sim \mathrm{U}[0,1]\mbox{.}</code>
</p>

<p>L-comoment estimation is provided by the <code><a href="#topic+lcomCOP">lcomCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simcomposite3COP(nsim=100, compositor=composite3COP,
                 parents=NULL, ploton=FALSE, points=FALSE,
                 showpar=FALSE, showresults=FALSE, digits=6, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simcomposite3COP_+3A_nsim">nsim</code></td>
<td>
<p>Number of simulations to perform;</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_compositor">compositor</code></td>
<td>
<p>The compositing function that could be either <code><a href="#topic+composite1COP">composite1COP</a></code>, <code><a href="#topic+composite2COP">composite2COP</a></code>, and <code><a href="#topic+composite3COP">composite3COP</a></code>;</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_parents">parents</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on intermediate plotting;</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_points">points</code></td>
<td>
<p>A logical to actually draw the simulations on the <code>ploton</code> by the <code>points()</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_showpar">showpar</code></td>
<td>
<p>Print the simulated parameter set with each iteration;</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_showresults">showresults</code></td>
<td>
<p>Print the results (useful if harvest results from a batch operation in <span class="rlang"><b>R</b></span>);</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_digits">digits</code></td>
<td>
<p>The number digits to pass to <code>round</code> if <code>showresults</code> is true; and</p>
</td></tr>
<tr><td><code id="simcomposite3COP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> matrix of results is returned. Each row represents a single simulation run. The first four columns are the <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\kappa</code>, and <code class="reqn">\gamma</code> <em>compositing parameters</em> and are labeled as such. The next two columns are the opposing diagonals, by first row and then second, of the <em>L-comoment correlation</em>. The following two columns are the opposing diagonals, by row and then second, of the <em>L-coskew</em>. The following two columns are the opposing diagonals, by row and then second, of the <em>L-cokurtosis</em>. The L-comoment columns are labeled to reflect the L-comoment matrix: <code>T2.21</code> means the L-comoment correlation row 2 column 1 and <code>T3.12</code> mean the L-coskew row 1 column 2. The remaining columns represent the <code class="reqn">\Theta_n</code> parameters for copula 1, the <code class="reqn">\Theta_m</code> parameters for copula 2. The columns are labeled <code>Cop1Thetas</code> or <code>Cop2Thetas</code>.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the <code>parents</code> argument structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the first copula;</p>
</dd>
<dt><code>cop2</code></dt><dd><p>&mdash; Function of the second copula;</p>
</dd>
<dt><code>para1gen</code></dt><dd><p>&mdash; Function to generate random parameters for the first copula; and</p>
</dd>
<dt><code>para2gen</code></dt><dd><p>&mdash; Function to generate random parameters for the second copula.</p>
</dd>
</dl>

<p>The <code>para</code> argument of this function are passed to the function contained in <code>compositor</code> and are therefore subject to further constraints in items should such constraints exist.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lcomCOP">lcomCOP</a></code>, <code><a href="#topic+simcompositeCOP">simcompositeCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# EXAMPLE 1: Make a single simulation result.
mainpara &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
                 para1gen=function() { return(c(10^runif(1, min=-5, max=0))) },
                 para2gen=function() { return(c(10^runif(1, min= 0, max=5))) })
v &lt;- simcompositeCOP(nsim=1, parent=mainpara, showresults=TRUE)
print(v)

# EXAMPLE 2: Make 1000 "results" and plot two columns.
mainpara &lt;- list(cop1=PLACKETTcop, cop2=N4212cop,
                 para1gen=function() { return(c(10^runif(1, min=-5, max=5))) },
                 para2gen=function() { return(c(10^runif(1, min= 0, max=2))) })
v &lt;- simcomposite3COP(nsim=100, parent=mainpara); labs &lt;- colnames(v)
plot(v[,5], v[,7],           # open circles are 1 with respect to 2
     xlab=paste(c(labs[5], "and", labs[6]), collapse=" "),
     ylab=paste(c(labs[6], "and", labs[8]), collapse=" "))
points(v[,6], v[,8], pch=16) # black dots are 2 with respect to 1
## End(Not run)
</code></pre>

<hr>
<h2 id='simcompositeCOP'>Compute the L-comoments of a Two-Value Composited Copula by Simulation</h2><span id='topic+simcompositeCOP'></span><span id='topic+simcomposite2COP'></span>

<h3>Description</h3>

<p>Simulate copula parameters and compute <em>L-comoments</em> and provision for plotting features for a composited copula using using two compositing parameters (see <code><a href="#topic+composite1COP">composite1COP</a></code> as well as <code><a href="#topic+composite2COP">composite2COP</a></code>).  The compositing parameters are each independent and uniformly distributed:
</p>
<p style="text-align: center;"><code class="reqn">\alpha \sim \mathrm{U}[0,1];\ \beta \sim \mathrm{U}[0,1]\mbox{.}</code>
</p>

<p>L-comoment estimation is provided by the <code><a href="#topic+lcomCOP">lcomCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simcompositeCOP(nsim=100, compositor=composite2COP,
                parents=NULL, ploton=FALSE, points=FALSE,
                showpar=FALSE, showresults=FALSE, digits=6, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simcompositeCOP_+3A_nsim">nsim</code></td>
<td>
<p>Number of simulations to perform;</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_compositor">compositor</code></td>
<td>
<p>The compositing function, could be either <code><a href="#topic+composite1COP">composite1COP</a></code> or <code><a href="#topic+composite2COP">composite2COP</a></code>. Each of these is acceptable because two compositing parameters are used;</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_parents">parents</code></td>
<td>
<p>A special parameter <code>list</code> (see <b>Note</b>);</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on intermediate plotting;</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_points">points</code></td>
<td>
<p>A logical to actually draw the simulations on the <code>ploton</code> by <code>points()</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_showpar">showpar</code></td>
<td>
<p>Print the simulated parameter set with each iteration;</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_showresults">showresults</code></td>
<td>
<p>Print the results (useful if harvest results from a batch operation in <span class="rlang"><b>R</b></span>);</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_digits">digits</code></td>
<td>
<p>The number digits to pass to <code>round</code> if <code>showresults</code> is true; and</p>
</td></tr>
<tr><td><code id="simcompositeCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> matrix of results is returned. Each row represents a single simulation run. The first two columns are the <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> <em>compositing parameters</em> and are labeled as such. The next two columns are the opposing diagonals, by first row and then second, of the <em>L-comoment correlation</em>. The following two columns are the opposing diagonals, by row and then second, of the <em>L-coskew</em>. The following two columns are the opposing diagonals, by row and then second, of the <em>L-cokurtosis</em>. The L-comoment columns are labeled to reflect the L-comoment matrix: <code>T2.21</code> means the L-comoment correlation row 2 column 1 and <code>T3.12</code> mean the L-coskew row 1 column 2. The remaining columns represent the <code class="reqn">\Theta_n</code> parameters for copula 1, the <code class="reqn">\Theta_m</code> parameters for copula 2. The columns are labeled <code>Cop1Thetas</code> or <code>Cop2Thetas</code>.
</p>


<h3>Note</h3>

<p>The following descriptions list in detail the <code>parents</code> argument structure and content of the <code>para</code> argument:
</p>

<dl>
<dt><code>cop1</code></dt><dd><p>&mdash; Function of the first copula;</p>
</dd>
<dt><code>cop2</code></dt><dd><p>&mdash; Function of the second copula;</p>
</dd>
<dt><code>para1gen</code></dt><dd><p>&mdash; Function to generate random parameters for the first copula; and</p>
</dd>
<dt><code>para2gen</code></dt><dd><p>&mdash; Function to generate random parameters for the second copula.</p>
</dd>
</dl>

<p>The <code>para</code> argument of this function are passed to the function contained in <code>compositor</code> and are therefore subject to further constraints in items should such constraints exist.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lcomCOP">lcomCOP</a></code>, <code><a href="#topic+simcomposite3COP">simcomposite3COP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# A single simulation result.
mainpara &lt;- list(cop1=PLACKETTcop, cop2=PLACKETTcop,
                 para1gen=function() { return(c(10^runif(1,min=-5,max=0))) },
                 para2gen=function() { return(c(10^runif(1,min= 0,max=5))) })
v &lt;- simcompositeCOP(nsim=1, parent=mainpara, showresults=TRUE)
print(v) # for review
## End(Not run)
</code></pre>

<hr>
<h2 id='simCOP'>Simulate a Copula by Numerical Derivative Method</h2><span id='topic+simCOP'></span><span id='topic+rCOP'></span>

<h3>Description</h3>

<p>Perform a simulation and visualization of a copula using numerical partial derivatives of the copula (Nelsen, 2006, p. 32). The method is more broadly known as <em>conditional simulation method</em>. Because a focus of <span class="pkg">copBasic</span> is on copula theory for pedagogic purposes, the coupling between simulation and subsequent visualization is emphasized by this function by it providing for both simulation and plotting operations by default.
</p>
<p>The <code>simCOP</code> function is based on a uniformly simulating nonexceedance probability <code class="reqn">u</code> and then conditioning the <code class="reqn">v</code> from the inverse of the sectional derivative for <code class="reqn">V</code> with respect to <code class="reqn">U</code> (see <code><a href="#topic+derCOPinv">derCOPinv</a></code>). The function for speed will only report a warning if at least one of the requested simulations in <code>n</code> could not be made because of <code>uniroot</code>'ing problems in <code><a href="#topic+derCOPinv">derCOPinv</a></code>. The returned <code>data.frame</code> will be shortened automatically, but this can be controlled by <code>na.rm</code>. Failure of a simulation is purely dependent failure of the derivative inversion. In general, inversion should be quite robust for continuous or near continuous copulas and even copulas with singularities should be more or less okay. Lastly, the logical combination <code>na.rm=FALSE</code> and <code>keept=TRUE</code> could be used to isolate those combinations giving <code><a href="#topic+derCOPinv">derCOPinv</a></code> problems. The implemented simulation method in the <span class="pkg">copBasic</span> package is known as the <em>conditional distribution method</em> (Nelsen, 2006; pp. 40&ndash;41), <em>conditional method</em>, or <em>Rosenblatt transform</em> (Joe, 2014, p. 270).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simCOP(n=100, cop=NULL, para=NULL, na.rm=TRUE, seed=NULL, keept=FALSE,
              graphics=TRUE, ploton=TRUE, points=TRUE, snv=FALSE,
              infsnv.rm=TRUE, trapinfsnv=.Machine$double.eps,
              resamv01=FALSE, showresamv01=FALSE, ...)
rCOP(n, cop=NULL, para=NULL, na.rm=TRUE, seed=NULL,
              resamv01=FALSE, showresamv01=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simCOP_+3A_n">n</code></td>
<td>
<p>A sample size, default is <code class="reqn">n = 100</code>;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical to toggle the removal of <code>NA</code> entries should they form on the returned <code>data.frame</code>. A well implemented copula should accommodate and not return <code>NA</code> but because this package relies on numerical derivation, it was decided to have a mechanism to handle this;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_seed">seed</code></td>
<td>
<p>The integer seed to pass immediately to <code>set.seed()</code>;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_keept">keept</code></td>
<td>
<p>Keep the <code class="reqn">t</code> uniform random variable for the simulation as the last column in the returned <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_graphics">graphics</code></td>
<td>
<p>A logical that will disable graphics by setting <code>ploton</code> and <code>points</code> to <code>FALSE</code> and overriding whatever their settings were;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_ploton">ploton</code></td>
<td>
<p>A logical to toggle on the plot (see <b>Examples</b> in <code><a href="#topic+vuongCOP">vuongCOP</a></code>);</p>
</td></tr>
<tr><td><code id="simCOP_+3A_points">points</code></td>
<td>
<p>A logical to actually draw the simulations by the <code>points()</code> function in <span class="rlang"><b>R</b></span>;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_snv">snv</code></td>
<td>
<p>A logical to convert the <code class="reqn">\{u,v\}</code> to standard normal scores (variates) both for the optional graphics and the returned <span class="rlang"><b>R</b></span> <code>data.frame</code>. Curiously, Joe (2014) advocates extensively for use of normal scores, which is in contrast to Nelsen (2006) who does not;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_infsnv.rm">infsnv.rm</code></td>
<td>
<p>A logical that will quietly strip out any occurrences of <code class="reqn">u = \{0,1\}</code> or <code class="reqn">v = \{0,1\}</code> from the simulations because these are infinity in magnitude when converted to standard normal variates has been selected. Thus, this logical only impacts logic flow when <code>snv</code> is <code>TRUE</code>. The <code>infsnv.rm</code> is mutually exclusive from <code>trapinfsnv</code>;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_trapinfsnv">trapinfsnv</code></td>
<td>
<p>If <code>TRUE</code> and presumably small, the numerical value of this argument (<code class="reqn">\eta</code>) is used to replace <code class="reqn">u = \{0,1\}</code> and <code class="reqn">v = \{0,1\}</code> with <code class="reqn">u(0) =  v(0) = \eta</code> or <code class="reqn">u(1) = v(1) = 1 - \eta</code> as appropriate when conversion to standard normal variates has been selected. The setting of <code>trapinfsnv</code> only is used if <code>snv</code> is <code>TRUE</code> and <code>infsnv.rm</code> is <code>FALSE</code>;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_resamv01">resamv01</code></td>
<td>
<p>A logical triggering resampling for the elements of <code class="reqn">v=0</code> and <code class="reqn">v=1</code> (see <b>Examples</b>). This is a relatively late addition to <span class="pkg">copBasic</span> logic and hence is disabled by default. If this is set to true, then the operations related to <code>infsnv.rm</code> and <code>trapinfsnv</code> are never to be involved later down in the functions' logic;</p>
</td></tr>
<tr><td><code id="simCOP_+3A_showresamv01">showresamv01</code></td>
<td>
<p>A logical providing a trigger to display a <code>message()</code> within the resampling loops for <code class="reqn">v &lt;= 0, v &gt;= 1</code>; and</p>
</td></tr>
<tr><td><code id="simCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>points()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the simulated values is returned.
</p>


<h3>Note</h3>

<p>Function <code>rCOP</code> is a light-weight implementation for bivariate copula random variates that dispatches to <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> and bypasses the graphical and other features of <code>simCOP</code>. Finally, an experimental parallel for the empirical copula is <code><a href="#topic+EMPIRsim">EMPIRsim</a></code>. Note, the equivalent of a <code>resamv01</code> is not implemented at the level of <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> because it is better to do such at the abstraction level of <code>rCOP</code> and <code>simCOP</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+derCOPinv">derCOPinv</a></code>, <code><a href="#topic+simCOPmicro">simCOPmicro</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>simCOP(n=5, cop=PARETOcop, para=2.4)

# We can find some unusual simulation combinations for which V == 0 or 1 and might have
# downstream operations simply not able to handle infinite quantiles (say) at the edges.
# We can readily offload the issue back to the rCOP() or simCOP() with resamv01 argument.
nsim &lt;- 800; para &lt;- list(cop=PLcop, para=150, alpha=0.8, beta=0.3)
JK &lt;- rCOP(nsim, cop=composite1COP, para=para, seed=1, resamv01=FALSE)
print(JK[JK[,2] == 1,]) # 189 0.9437248 1.   So, row 189 in this example has V=1, and
UV &lt;- rCOP(nsim, cop=composite1COP, para=para, seed=1, resamv01=TRUE ) # changing the
# resamv01 argument to TRUE, we get this message and no V=1 in the returned data frame.
# rCOP() has some v &gt;= 1, resampling those     &lt;---- This is the message output.

## Not run: 
# The simCOP function is oft used in other Examples sections through this package.
simCOP(n=10, cop=W)            # Frechet lower-bound copula
simCOP(n=10, cop=P)            # Independence copula
simCOP(n=10, cop=M, col=2)     # Frechet upper-bound copula
simCOP(n=10, cop=PSP)          # The PSP copula
## End(Not run)

## Not run: 
# Now simulate the PSP copula, add the level curves of the copula, and demonstrate
# the uniform distribution of marginals on the correct axes (U [top] and V [left]).
D &lt;- simCOP(n=400, cop=PSP) # store simulated values in D
level.curvesCOP(cop=PSP, ploton=FALSE)
rug(D$U, side=3, col=2); rug(D$V, side=4, col=2)

# Now let us get more complicated and mix two Plackett copulas together using the
# composite2COP as a "compositor." The parameter argument becomes more complex, but
# is passed as shown into composite2COP.
para &lt;- list(cop1=PLACKETTcop,cop2=PLACKETTcop, alpha=0.3,beta=0.5, para1=0.1,para2=50)
D &lt;- simCOP(n=950, cop=composite2COP, para=para, col=grey(0, 0.2), pch=16, snv=TRUE) #
## End(Not run)
</code></pre>

<hr>
<h2 id='simCOPmicro'>Simulate V from U through a Copula by Numerical Derivative Method</h2><span id='topic+simCOPmicro'></span><span id='topic+simCOPv'></span>

<h3>Description</h3>

<p>Perform bivariate simulation of random but coupled variables <code class="reqn">V</code> from <code class="reqn">U</code> through a copula (Nelsen, 2006, p. 32) by inversion of the numerical derivatives of the copula (<code><a href="#topic+derCOPinv">derCOPinv</a></code>, <code><a href="#topic+derCOPinv2">derCOPinv2</a></code>). The method is more broadly known as <em>conditional simulation method</em>. An elaborate implementation is available in <code><a href="#topic+simCOP">simCOP</a></code>, which unlike <code>simCOPmicro</code>, has provisions (default) for graphical support. The <code>simCOPmicro</code> function is intended to be a minimalist version for copula simulation, and such a version is useful for pedagogic purposes including <em>conditional distributions</em>, <em>conditional quantile functions</em>, and <em>copula reflection</em> (see <b>Note</b> and <code><a href="#topic+COP">COP</a></code>). An extended educational discussion of simulation using the conditional method is available in the <b>Note</b> section of <code><a href="#topic+derCOPinv">derCOPinv</a></code>.
</p>
<p>Some definitions are needed. The copula of <code class="reqn">(1-U, 1-V)</code> is the <em>survival copula</em> (<code><a href="#topic+surCOP">surCOP</a></code>) and is defined as
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mathbf{C}}(u,v) = u + v - 1 + \mathbf{C}(1-u, 1-v)\mbox{,}</code>
</p>

<p>whereas, following the notation of Joe (2014, pp. 271&ndash;272), the copula of <code class="reqn">(1-U, V)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\acute{\mathbf{C}}(u,v) = v - \mathbf{C}(1-u, v)\mbox{, and}</code>
</p>

<p>the copula of <code class="reqn">(U, 1-V)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\grave{\mathbf{C}}(u,v) = u - \mathbf{C}(u, 1-v)\mbox{.}</code>
</p>

<p>Careful consideration of the nomenclature is necessary as confusion with the occurrences of <code class="reqn">1-u</code> and <code class="reqn">1-v</code> easily conflate meaning. The nomenclature for the <em>survival copula</em> is more elaborately shown under <code><a href="#topic+surCOP">surCOP</a></code>. The difficulty is that the bivariate arguments to the <em>survival copula</em> are <em>exceedance probabilities</em>.
</p>
<p>For simulation, again following the nomenclature of Joe (2014, p. 272), the conditional distribution functions (numerical derivatives; <code><a href="#topic+derCOP">derCOP</a></code> <code class="reqn">\equiv</code> <code class="reqn">\mathbf{C}_{2 \mid 1}(v \mid u)</code> and <code><a href="#topic+derCOP2">derCOP2</a></code> <code class="reqn">\equiv</code> <code class="reqn">\mathbf{C}_{1 \mid 2}(u \mid v)</code>) can be written in terms of <code class="reqn">\mathbf{C}(u \mid v) = \mathbf{C}_{2 \mid 1}(v \mid u)</code> as
</p>
<p style="text-align: center;"><code class="reqn">  \hat{\mathbf{C}}_{2 \mid 1}(v \mid u) = 1 - \mathbf{C}_{2 \mid 1}(1-v \mid 1-u)\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\acute{\mathbf{C}}_{2 \mid 1}(v \mid u) =     \mathbf{C}_{2 \mid 1}(  v \mid 1-u)\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\grave{\mathbf{C}}_{2 \mid 1}(v \mid u) = 1 - \mathbf{C}_{2 \mid 1}(1-v \mid   u)\mbox{,}</code>
</p>

<p>where the respective <code>"surv"</code>, <code>"acute"</code>, and <code>"grave"</code> are inverses (conditional quantile functions; inverses of numerical derivatives; <code><a href="#topic+derCOPinv">derCOPinv</a></code> <code class="reqn">\equiv</code> <code class="reqn">\mathbf{C}^{(-1)}_{2 \mid 1}(v \mid u)</code> and <code><a href="#topic+derCOPinv2">derCOPinv2</a></code> <code class="reqn">\equiv</code> <code class="reqn">\mathbf{C}^{(-1)}_{1 \mid 2}(u \mid v)</code>) are
</p>
<p style="text-align: center;"><code class="reqn">  \hat{\mathbf{C}}^{(-1)}_{2 \mid 1}(t \mid u) = 1 - \mathbf{C}^{(-1)}_{2 \mid 1}(1-t \mid 1-u)\:\rightarrow\mbox{\ \code{"sur"},}</code>
</p>

<p style="text-align: center;"><code class="reqn">\acute{\mathbf{C}}^{(-1)}_{2 \mid 1}(t \mid u) =     \mathbf{C}^{(-1)}_{2 \mid 1}(  t \mid 1-u)\:\rightarrow\mbox{\ \code{"acute"}, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\grave{\mathbf{C}}^{(-1)}_{2 \mid 1}(t \mid u) = 1 - \mathbf{C}^{(-1)}_{2 \mid 1}(1-t \mid   u)\:\rightarrow\mbox{\ \code{"grave"},}</code>
</p>

<p>where <code class="reqn">t</code> is a uniformly distributed variable.
</p>
<p>To clarify the seemingly clunky nomenclature&mdash;Joe (2014) does not provide &ldquo;names&rdquo; for <code class="reqn">\acute{\mathbf{C}}(u,v)</code> or <code class="reqn">\grave{\mathbf{C}}(u,v)</code>&mdash;the following guidance is informative:<br />
<code class="reqn">\mbox{}\quad\mbox{}</code>(1) <code>"surv"</code> or <code class="reqn">\hat{\mathbf{C}}(u,v)</code> is a reflection of <code class="reqn">U</code> and <code class="reqn">V</code> on the horizontal <em>and</em> vertical axes, respectively<br />
<code class="reqn">\mbox{}\quad\mbox{}</code>(2) <code>"acute"</code> or <code class="reqn">\acute{\mathbf{C}}(u,v)</code> is a reflection of <code class="reqn">U</code> on the horizontal axis, and<br />
<code class="reqn">\mbox{}\quad\mbox{}</code>(3) <code>"grave"</code> or <code class="reqn">\grave{\mathbf{C}}(u,v)</code> is a reflection of <code class="reqn">V</code> on the verical axis.<br />
The names <code>"acute"</code> and <code>"grave"</code> match those used in the <b>Rd</b>-format math typesetting instructions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simCOPmicro(u, cop=NULL, para=NULL, seed=NULL,
               reflect=c("cop", "surv", "acute", "grave",
                           "1",    "2",     "3",     "4"), ...)
simCOPv(u, cop=NULL, para=NULL,
               reflect=c("cop", "surv", "acute", "grave",
                           "1",    "2",     "3",     "4"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simCOPmicro_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction. The <code>runif()</code> function in <span class="rlang"><b>R</b></span> can be used to drive conditional simulation using the <code>simCOPmicro</code> function (see <b>Examples</b>);</p>
</td></tr>
<tr><td><code id="simCOPmicro_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="simCOPmicro_+3A_para">para</code></td>
<td>
<p>Vector of parameters, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="simCOPmicro_+3A_seed">seed</code></td>
<td>
<p>The integer seed to pass immediately to <code>set.seed()</code> and setting it for the <code>simCOPv</code> version will dispatch through the triple dots down to <code>simCOPmicro</code>;</p>
</td></tr>
<tr><td><code id="simCOPmicro_+3A_reflect">reflect</code></td>
<td>
<p>The reflection of the copula (see above) and the default <code>"cop"</code> or <code>"1"</code> is the usual copula definition.  The numbered values correspond, respectively, to the named values; and</p>
</td></tr>
<tr><td><code id="simCOPmicro_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass should they be needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Simulated value(s) of nonexceedance probability <code class="reqn">v</code> are returned based on the nonexceedance probabilities <code class="reqn">u</code> in argument <code>u</code>.
</p>


<h3>Note</h3>

<p>The advanced features of <code>simCOPmicro</code> permit simulation of the three permutations of <em>variable reflection</em>. The first code simply produce four different &ldquo;copulas&rdquo; based on the <em>Gumbel&ndash;Hougaard</em> copula (<code class="reqn">\mathbf{GH}(u,v; \Theta)</code>; <code><a href="#topic+GHcop">GHcop</a></code>), which has substantial upper tail dependency but no lower tail dependency for <code class="reqn">\Theta = 2.512</code> as quantified by the <code><a href="#topic+taildepCOP">taildepCOP</a></code> function call.
</p>
<pre>
  U &lt;- runif(1500); G &lt;- 2.512; u &lt;- 0.1; up &lt;- 1-u; v &lt;- 0.2; vp &lt;- 1-v
  UV   &lt;- data.frame(U, simCOPmicro(U, cop=GHcop, para=G                 ))
  sUsV &lt;- data.frame(U, simCOPmicro(U, cop=GHcop, para=G, reflect="surv" ))
  sUV  &lt;- data.frame(U, simCOPmicro(U, cop=GHcop, para=G, reflect="acute"))
  UsV  &lt;- data.frame(U, simCOPmicro(U, cop=GHcop, para=G, reflect="grave"))
  taildepCOP(cop=GHcop, para=G) # lambdaL = 2e-05; lambdaU = 0.68224
</pre>
<p>The following code example will verify that the simulations produce values of <code class="reqn">U</code> and <code class="reqn">V</code> that are consistent with the <em>empirical copula</em> (<code><a href="#topic+EMPIRcop">EMPIRcop</a></code>) results as well as consistent with the variable reflections provided through the <code><a href="#topic+COP">COP</a></code> interface. Notice the combinations of nonexceedance and exceedance probabilities blended so that the two returned values for the four different copulas are numerically congruent.
</p>
<pre>
  c(EMPIRcop(u, v,  para=UV  ), COP(u, v,  cop=GHcop, para=G, reflect="cop"  ))
  c(EMPIRcop(up,vp, para=sUsV), COP(up,vp, cop=GHcop, para=G, reflect="surv" ))
  c(EMPIRcop(up,v,  para=sUV ), COP(up,v,  cop=GHcop, para=G, reflect="acute"))
  c(EMPIRcop(u, vp, para=UsV ), COP(u, vp, cop=GHcop, para=G, reflect="grave"))
</pre>
<p>The user can verify the reflections graphically using code such as this
</p>
<pre>
  xlab &lt;- "PROBABILITY IN U"; ylab &lt;- "PROBABILITY IN V"
  layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE));
  plot(UV,   xlab=xlab, ylab=ylab, pch=3, lwd=0.5, col=1)
    mtext("no reflection")
  plot(sUV,  xlab=xlab, ylab=ylab, pch=3, lwd=0.5, col=3)
    mtext("horizontal reflection")
  plot(UsV,  xlab=xlab, ylab=ylab, pch=3, lwd=0.5, col=4)
    mtext("vertical reflection")
  plot(sUsV, xlab=xlab, ylab=ylab, pch=3, lwd=0.5, col=2)
    mtext("double reflection")
</pre>
<p>in which inspection of tails exhibiting the dependency is readily seen on the four plots: upper right tail dependency (no reflection), upper left tail dependency (horizontal reflection), lower right tail dependency (vertical reflection), and lower left tail dependency (double reflection). It is important to stress that these descriptions and graphical depictions of single tail dependency are specific to the <code class="reqn">\mathbf{GH}(u,v; \Theta)</code> copula chosen for the demonstration.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simCOP">simCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>simCOPmicro(runif(1), cop=W  ) # Frechet lower-bound copula
simCOPmicro(runif(1), cop=P  ) # Independence copula
simCOPmicro(runif(1), cop=M  ) # Frechet upper-bound copula
simCOPmicro(runif(1), cop=PSP) # The PSP copula

## Not run: 
# Now let us get more complicated and mix two Plackett copulas together using the
# composite2COP as a "compositor." The parameter argument becomes more complex, but is
# passed as shown into composite2COP.
para &lt;- list(cop1=PLACKETTcop,cop2=PLACKETTcop, alpha=0.3,beta=0.5, para1=0.1,para2=50)
simCOPmicro(runif(5), cop=composite2COP, para=para) #
## End(Not run)

## Not run: 
# Now let us implement "our" own version of features of simCOP() but using
# the micro version to manually create just the simulation vector of V.
U &lt;- runif(1500)
UV &lt;- data.frame(U, simCOPmicro(U, cop=N4212cop, para=4))
plot(UV, xlab="PROBABILITY IN U", ylab="PROBABILITY IN V", pch=3, col=2) #
## End(Not run)
</code></pre>

<hr>
<h2 id='spectralmeas'>Estimation of the Spectral Measure</h2><span id='topic+spectralmeas'></span>

<h3>Description</h3>

<p>Kiriliouk <em>et al.</em> (2016, pp. 360&ndash;364) describe estimation of the <em>spectral measure</em> of bivariate data. Standardize the bivariate data as <code class="reqn">X^\star</code> and <code class="reqn">Y^\star</code> as in <code><a href="#topic+psepolar">psepolar</a></code> and select a &ldquo;large&rdquo; value for the <em>pseudo-polar radius</em> <code class="reqn">S_f</code> for nonexceedance probability <code class="reqn">f</code>. Estimate the spectral measure <code class="reqn">H(w)</code>, which is the limiting distribution of the <em>pseudo-polar angle</em> component <code class="reqn">W</code> given that the corresponding radial component <code class="reqn">S</code> is large:
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[W \in \cdot | S &gt; S_f] \rightarrow H(w) \mbox{\ as\ } S_f \rightarrow \infty\mbox{.}</code>
</p>

<p>So, <code class="reqn">H(w)</code> is the <em>cumulative distribution function</em> of the spectral measure for angle <code class="reqn">w \in (0,1)</code>. The <code class="reqn">S_f</code> can be specified by a nonexceedance probability <code class="reqn">F</code> for <code class="reqn">S_f(F)</code>.
</p>
<p>The estimation proceeds as follows:
</p>
<p><b>Step 1:</b> Convert the bivariate data <code class="reqn">(X_i, Y_i)</code> into <code class="reqn">(\widehat{S}_i, \widehat{W}_i)</code> by <code><a href="#topic+psepolar">psepolar</a></code> and set the threshold <code class="reqn">S_f</code> according to &ldquo;<code class="reqn">n/k</code>&rdquo; (this part involving <code class="reqn">k</code> does not make sense in Kiriliouk <em>et al.</em> (2016)) where for present implementation in <span class="pkg">copBasic</span> the <code class="reqn">S_f</code> given the <code class="reqn">f</code> by the user is based on the empirical distribution of the <code class="reqn">\widehat{S}_i</code>. The empirical distribution is estimated by the <em>Bernstein empirical distribution</em> function from the <span class="pkg">lmomco</span> package.
</p>
<p><b>Step 2:</b> Let <code class="reqn">I_n</code> denote the set of indices that correspond to the observations when <code class="reqn">\widehat{S}_i \ge S_f</code> and compute <code class="reqn">N_n</code> as the cardinality of <code class="reqn">N_n = |I_n|</code>, which simply means the length of the vector <code class="reqn">I_n</code>.
</p>
<p><b>Step 3:</b> Use the <em>maximum Euclidean likelihood estimator</em>, which is the third of three methods mentioned by Kiriliouk <em>et al.</em> (2016):
</p>
<p style="text-align: center;"><code class="reqn">\widehat{H}_3(w) = \sum_{i \in I_n} \hat{p}_{3,i} \times \mathbf{1}[\widehat{W}_i \le w ]\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{1}[\cdot]</code> is an <em>indicator function</em> that is only triggered if <code>smooth=FALSE</code>, and following the notation of Kiriliouk <em>et al.</em> (2016), the &ldquo;3&rdquo; represents maximum <em>Euclidean likelihood</em> estimation. The <code class="reqn">\hat{p}_{3,i}</code> are are the weights
</p>
<p style="text-align: center;"><code class="reqn">\hat{p}_{3,i} = \frac{1}{N_n}\bigl[ 1 - (\overline{W} - 1/2)S^{-2}_W(\widehat{W}_i - \overline{W}) \bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\overline{W}</code> is the <em>sample mean</em> and <code class="reqn">S^2_W</code> is the <em>sample variance</em> of <code class="reqn">\widehat{W}_i</code>
</p>
<p style="text-align: center;"><code class="reqn">\overline{W} = \frac{1}{N_n} \sum_{i \in I_n} \widehat{W}_i\mbox{\quad and\quad } S^2_W = \frac{1}{N_n - 1} \sum_{i \in I_n} (\widehat{W}_i - \overline{W})^2\mbox{,}</code>
</p>

<p>where Kiriliouk <em>et al.</em> (2016, p. 363) do not show the <code class="reqn">N_n - 1</code> in the denominator for the variance but <span class="pkg">copBasic</span> uses it because those authors state that the <em>sample variance</em> is used.
</p>
<p><b>Step 4:</b> A smoothed version of <code class="reqn">\hat{H}_3(w)</code> is optionally available by
</p>
<p style="text-align: center;"><code class="reqn">\tilde{H}_3(w) = \sum_{i \in I_n} \hat{p}_{3,i} \times \mathcal{B}(w;\, \widehat{W}_i\nu,\, (1-\widehat{W}_i)\nu)\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathcal{B}(x; p, q)</code> is the cumulative distribution function of the <em>Beta distribution</em> for <code class="reqn">p, q &gt; 0</code> and where <code class="reqn">\nu &gt; 0</code> is a smoothing parameter that can be optimized by cross validation.
</p>
<p><b>Step 5:</b> The <em>spectral density</em> lastly can be computed optionally as
</p>
<p style="text-align: center;"><code class="reqn">\tilde{h}_3(w) = \sum_{i \in I_n} \hat{p}_{3,i} \times \beta(w;\, \widehat{W}_i\nu,\, (1-\widehat{W}_i)\nu)</code>
</p>

<p>where <code class="reqn">\beta(x; p, q)</code> is the probability density function (pdf) of the Beta distribution. Readers are alerted to the absence of the <code class="reqn">\mathbf{1}[\cdot]</code> indicator function in the definitions of <code class="reqn">\tilde{H}_3(w)</code> and <code class="reqn">\tilde{h}_3(w)</code>. This is correct and matches Kiriliouk <em>et al.</em> (2016, eqs. 17.21 and 17.22) though this author was confused for a day or so by the indicator function in what is purported to be the core definition of <code class="reqn">\hat{H}_l(w)</code> where <code class="reqn">l = 3</code> in Kiriliouk <em>et al.</em> (2016, eq. 17.21 and 17.17).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectralmeas(u, v=NULL, w=NULL, f=0.90, snv=FALSE,
                                smooth=FALSE, nu=100, pdf=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spectralmeas_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction (actually the ranks are used so this can be a real-value argument as well);</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction  (actually the ranks are used so this can be a real-value argument as well) and if <code>NULL</code> then <code>u</code> is treated as a two column <span class="rlang"><b>R</b></span> <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_w">w</code></td>
<td>
<p>A vector of polar angle values <code class="reqn">W \in [0,1]</code> on which to compute the <code class="reqn">H(w)</code>;</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_f">f</code></td>
<td>
<p>The nonexceedance probability <code class="reqn">F(S_f)</code> of the <em>pseudo-polar radius</em> in <code><a href="#topic+psepolar">psepolar</a></code>;</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_snv">snv</code></td>
<td>
<p>Return the standard normal variate of the <code class="reqn">H</code> by the well-known transform through the quantile function of the standard normal, <code>qnorm()</code>;</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_smooth">smooth</code></td>
<td>
<p>A logical to return <code class="reqn">\tilde{H}_3(w)</code> instead of <code class="reqn">H_3(w)</code>;</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_nu">nu</code></td>
<td>
<p>The <code class="reqn">\nu &gt; 0</code> smoothing parameter;</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_pdf">pdf</code></td>
<td>
<p>A logical to return the smoothed probability density <code class="reqn">\tilde{h}_3(w)</code>. If <code>pdf=TRUE</code>, then internally <code>smooth=TRUE</code> will be set; and</p>
</td></tr>
<tr><td><code id="spectralmeas_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+psepolar">psepolar</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> of <code class="reqn">H_3(w)</code>, <code class="reqn">\tilde{H}_3(w)</code>, or <code class="reqn">\tilde{h}_3(w)</code> is returned.
</p>


<h3>Note</h3>

<p>The purpose of this section is to describe a CPU-intensive study of goodness-of-fit between a <em>Gumbel&ndash;Hougaard copula</em> (<code><a href="#topic+GHcop">GHcop</a></code>, <code class="reqn">\mathbf{GH}(u,v; \Theta_1)</code>) parent and a fitted <em>Hüsler&ndash;Reiss copula</em> (<code><a href="#topic+HRcop">HRcop</a></code>, <code class="reqn">\mathbf{HR}(u,v; \Theta_2)</code>). Both of these copulas are extreme values and are somewhat similar to each other, so sample sizes necessary for detection of differences should be large. A two-sided Kolmogorov&ndash;Smirnov tests (KS test, <code>ks.test()</code>) is used to measure significance in the differences between the estimated spectral measure distributions at <code class="reqn">f=0.90</code> (the 90th percentile, <code class="reqn">F(S_f)</code>) into the right tail.
</p>
<p>The true copula will be the <code class="reqn">\mathbf{GH}(\Theta_1)</code> having parameter <code class="reqn">\Theta_1 = 3.3</code>. The number of simulations per sample size <code>n</code> <code class="reqn">\in</code> <code>seq(50,1000, by=25)</code> is <code>nsim = 500</code>. For each sample size, a sample from the true parent is drawn, and a <code class="reqn">\mathbf{HR}(\Theta_2)</code> fit by maximum likelihood (<code><a href="#topic+mleCOP">mleCOP</a></code>). The two spectral measure distributions (<code class="reqn">\widehat{H}_{\mathbf{GH}}(w)</code>, <code>Htru</code> and <code class="reqn">\widehat{H}_{\mathbf{HR}}(w)</code>, <code>Hfit</code>) are estimated for a uniform variate of the angle <code>W</code> having length equal to the applicable sample size. The Kolmogorov&ndash;Smirnov (KS) test is made between <code>Htru</code> and <code>Hfit</code>, and number of p-values less than the <code class="reqn">\beta = 0.05</code> (Type II error because alternative hypothesis is rigged as true) and simulation count are returned and written in file <code>Results.txt</code>. The sample sizes initially are small and traps of <code>NaN</code> (abandonment of a simulation run) are made. These traps are needed when the empirical distribution of <code>Htru</code> or <code>Hfit</code> degenerates.
</p>
<pre>
  Results &lt;- NULL
  true.par &lt;- 3.3; true.cop &lt;- GHcop; fit.cop &lt;- HRcop; search &lt;- c(0,100)
  nsim &lt;- 20000; first_time &lt;- TRUE; f &lt;- 0.90; beta &lt;- 0.05
  ns &lt;- c(seq(100,1000, by=50), 1250, 1500, 1750, 2000)
  for(n in ns) {
    W &lt;- sort(runif(n)); PV &lt;- vector(mode="numeric")
    for(i in 1:(nsim/(n/2))) {
      UV      &lt;- simCOP(n=n, cop=true.cop, para=true.par, graphics=FALSE)
      fit.par &lt;- mleCOP(UV,  cop= fit.cop, interval=search)$para
      UVfit   &lt;- simCOP(n=n, cop= fit.cop, para=fit.par,  graphics=FALSE)
      Htru    &lt;- spectralmeas(UV,    w=W, bound.type="Carv", f=f)
      Hfit    &lt;- spectralmeas(UVfit, w=W, bound.type="Carv", f=f)
      if(length(Htru[! is.nan(Htru)]) != length(Hfit[! is.nan(Hfit)]) |
         length(Htru[! is.nan(Htru)]) == 0 |
         length(Hfit[! is.nan(Hfit)]) == 0) {
         PV[i] &lt;- NA; next
      }   # suppressWarnings() to silence ties warnings from ks.test()
      KS &lt;- suppressWarnings( stats::ks.test(Htru, Hfit)$p.value )
      #plot(FF, H, type="l"); lines(FF, Hfit, col=2); mtext(KS)
      message("-",i, appendLF=FALSE)
      PV[i] &lt;- KS
    }
    message(":",n)
    zz &lt;- data.frame(SampleSize=n, NumPVle0p05=sum(PV[! is.na(PV)] &lt;= beta),
                            SimulationCount=length(PV[! is.na(PV)]))
    if(first_time) { Results &lt;- zz; first_time &lt;- FALSE; next }
    Results &lt;- rbind(Results, zz)
  }

  plot(Results$SampleSize, 100*Results$NumPVle0p05/Results$SimulationCount,
       type="b", cex=1.1, xlab="Sample size",
       ylab="Percent simulations with p-value &lt; 0.05")
</pre>
<p>The <code>Results</code> show a general increase in the counts of p-value <code class="reqn">\le</code> 0.05 as sample size increases. There is variation of course and increasing <code>nsim</code> would smooth that considerably. The results show for <code class="reqn">n \approx 1{,}000</code> that the detection of statistically significant differences for extremal <code class="reqn">F(S_f) = 0.90</code> dependency between the <code class="reqn">\mathbf{GH}(\Theta_1{=}3.3)</code> and <code class="reqn">\mathbf{HR}(\Theta_2)</code> are detected at the error rate implied by the specified <code class="reqn">\beta = 0.05</code>.
</p>
<p>This range in sample size can be compared to the Kullback&ndash;Leibler sample size (<code class="reqn">n_{fg}</code>):
</p>
<pre>
  UV      &lt;- simCOP(n=10000, cop=true.cop, para=true.par, graphics=FALSE)
  fit.par &lt;- mleCOP(UV,      cop= fit.cop, interval=search)$para
  kullCOP(cop1=true.cop, para1=true.par,
          cop2=fit.cop,  para2=fit.par)$KL.sample.size
  # The Kullback-Leibler (integer) sample size for detection of differences at
  # alpha=0.05 are n_fg = (742, 809, 815, 826, 915, 973, 1203) for seven runs
  # Do more to see variation.
</pre>
<p>where the Kullback&ndash;Leilber approach is to measure density departures across the whole <code class="reqn">\mathcal{I}^2</code> domain as opposed to extremal dependency in the right tail as does the spectral measure.
</p>
<p>Different runs of the above code will result in different <code class="reqn">n_{fg}</code> in part because of simulation differences internal to <code><a href="#topic+kullCOP">kullCOP</a></code> but also because the <code class="reqn">\Theta_2</code> has its own slight variation in its fit to the large sample simulation (<code class="reqn">n=10{,}000</code>) of the parent. However, it seems that <code class="reqn">n_{fg} \approx 900</code> will be on the order of the <code class="reqn">n</code> for which the KS test on the spectral measure determines statistical significance with similar error rate.
</p>
<p>Now if the aforementioned simulation run is repeated for <code class="reqn">F(S_f) = 0.95</code> or <code>f=0.95</code>, the <code class="reqn">n_{fg}</code> obviously remains unchanged at about <code class="reqn">900</code> but the <code class="reqn">n</code> for which the error rate is about <code class="reqn">\beta = 0.05</code> is <code class="reqn">n \approx 600</code>. This sample size is clearly smaller than before and smaller than <code class="reqn">n_{fg}</code>, therefore, the analysis of the empirical spectral measure deeper into the tail <code class="reqn">F(S_f) = 0.95</code> requires a smaller sample size to distinguish between the two copula. Though the analysis does not address the question as to whether one or both copula are adequate for the problem at hand. For a final comparison, if the aforementioned simulation run is repeated for <code class="reqn">F(S_f) = 0.80</code> or <code>f=0.80</code>, then the <code class="reqn">n</code> for which the error rate is about <code class="reqn">\beta = 0.05</code> is <code class="reqn">n \approx 1{,}700</code>. Thus as analysis is made further away from the tail into the center of the distribution, the sample size to distinguish between these two similar copula increases substantially.
</p>


<h3>Author(s)</h3>

<p>William Asquith <a href="mailto:william.asquith@ttu.edu">william.asquith@ttu.edu</a></p>


<h3>References</h3>

<p>Kiriliouk, Anna, Segers, Johan, Warchoł, Michał, 2016, Nonparameteric estimation of extremal dependence: <em>in</em> Extreme Value Modeling and Risk Analysis, D.K. Dey and Jun Yan <em>eds.</em>, Boca Raton, FL, CRC Press, ISBN 978&ndash;1&ndash;4987&ndash;0129&ndash;7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psepolar">psepolar</a></code>, <code><a href="#topic+stabtaildepf">stabtaildepf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
UV &lt;- simCOP(n=500, cop=HRcop, para=1.3, graphics=FALSE)
W &lt;- seq(0,1,by=0.005)
Hu &lt;- spectralmeas(UV, w=W)
Hs &lt;- spectralmeas(UV, w=W, smooth=TRUE, nu=100)
plot(W,Hu, type="l", ylab="Spectral Measure H", xlab="Angle")
lines(W, Hs, col=2) #
## End(Not run)

## Not run: 
"GAUScop" &lt;- function(u,v, para=NULL, ...) {
  if(length(u)==1) u&lt;-rep(u,length(v)); if(length(v)==1) v&lt;-rep(v,length(u))
  return(copula::pCopula(matrix(c(u,v), ncol=2), para))
}
GAUSparfn &lt;- function(rho) return(copula::normalCopula(rho, dim = 2))
n &lt;- 2000 # The PSP parent has no upper tail dependency
uv    &lt;- simCOP(n=n, cop=PSP,      para=NULL, graphics=FALSE)
PLpar &lt;- mleCOP(uv,  cop=PLcop,    interval=c(0,100))$para
PLuv  &lt;- simCOP(n=n, cop=PLcop,    para=PLpar, graphics=FALSE)
GApar &lt;- mleCOP(uv,  cop=GAUScop,  parafn=GAUSparfn, interval=c(-1,1))$para
GAuv  &lt;- simCOP(n=n, cop=GAUScop,  para=GApar, graphics=FALSE)
GLpar &lt;- mleCOP(uv,  cop=GLcop,    interval=c(0,100))$para
GLuv  &lt;- simCOP(n=n, cop=GLcop,    para=GLpar, graphics=FALSE)
FF &lt;- c(0.001,seq(0.005,0.995, by=0.005),0.999); qFF &lt;- qnorm(FF)
f &lt;- 0.90 # Seeking beyond the 90th percentile pseudo-polar radius
PSPh &lt;- spectralmeas(  uv, w=FF, f=f, smooth=TRUE, snv=TRUE)
PLh  &lt;- spectralmeas(PLuv, w=FF, f=f, smooth=TRUE, snv=TRUE)
GAh  &lt;- spectralmeas(GAuv, w=FF, f=f, smooth=TRUE, snv=TRUE)
GLh  &lt;- spectralmeas(GLuv, w=FF, f=f, smooth=TRUE, snv=TRUE)
plot(qFF, PSPh, type="l", lwd=2, xlim=c(-3,3), ylim=c(-2,2),
     xlab="STANDARD NORMAL VARIATE OF PSEUDO-POLAR ANGLE",
     ylab="STANDARD NORMAL VARIATE OF SPECTRAL MEASURE PROBABILITY")
lines(qFF, PLh, col=2) #  red  line is the Plackett copula
lines(qFF, GAh, col=3) # green line is the Gaussian copula
lines(qFF, GLh, col=4) #  blue line is the Galambos copula
# Notice the flat spot and less steep nature of the PSP (black line), which is
# indicative of no to even spreading tail dependency. The Plackett and Gaussian
# copulas show no specific steepening near the middle, which remains indicative
# of no tail dependency with the Plackett being less steep because it has a more
# dispersed copula density at the right tail is approached than the Gaussian.
# The Galambos copula has upper tail dependency, which is seen by
# the mass concentration and steepening of the curve on the plot.
## End(Not run)
</code></pre>

<hr>
<h2 id='stabtaildepf'>Estimation of the Stable Tail Dependence Function</h2><span id='topic+stabtaildepf'></span>

<h3>Description</h3>

<p>Kiriliouk <em>et al.</em> (2016, pp. 364&ndash;366) describe a technique for estimation of a <em>empirical stable tail dependence function</em> for a random sample. The function is defined as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{l}(x,y) = \frac{1}{k}\sum_{i=1}^n \mathbf{1}\bigl[ R_{i,x,n} &gt; n + 1 - kx \mbox{\ or\ } R_{i,y,n} &gt; n + 1 - ky \bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{1}[\cdot]</code> is an <em>indicator function</em>, <code class="reqn">R</code> denotes the <code>rank()</code> of the elements and <code class="reqn">k \in [1,\ldots,n]</code> and <code class="reqn">k</code> is intended to be &ldquo;large enough&rdquo; that <code class="reqn">\widehat{l}(x,y)</code> has converged to a limit.
</p>
<p>The &ldquo;Capéraà&ndash;Fougères smooth&rdquo; of the empirical stable tail dependence function is defined for a coordinate pair <code class="reqn">(x,y)</code> as
</p>
<p style="text-align: center;"><code class="reqn">\widehat{l}_{CF}(x,y) = 2 \sum_{i \in I_n} \widehat{p}_{3,i} \times \mathrm{max}\bigl[\widehat{W}_i x,\, (1-\widehat{W}_i) y \bigr]\mbox{,}</code>
</p>

<p>where <code class="reqn">\widehat{p}_{3,i}</code> are the weights for the <em>maximum Euclidean likelihood</em> estimator (see <code><a href="#topic+spectralmeas">spectralmeas</a></code>) and <code class="reqn">\widehat{W}_i</code> are the <em>pseudo-polar angles</em> (see <code><a href="#topic+spectralmeas">spectralmeas</a></code>) for the index set <code class="reqn">I_n</code> defined by <code class="reqn">I_n = \{i = 1, \ldots, n : \widehat{S}_i &gt; \widehat{S}_{(k{+}1)}\}</code>, where <code class="reqn">\widehat{S}_{(k+1)}</code> denotes the <code class="reqn">(k{+}1)</code>-th largest observation of the pseudo-polar radii <code class="reqn">\widehat{S}_i</code> where the cardinality of <code class="reqn">I_n</code> is exactly <code class="reqn">k</code> elements long. (Tentatively, then this definition of <code class="reqn">I_n</code> is ever so slightly different than in <code><a href="#topic+spectralmeas">spectralmeas</a></code>.)  Lastly, see the multiplier of <code class="reqn">2</code> on the smooth form, and this multiplier is missing in Kiriliouk <em>et al.</em> (2016, p. 365) but shown in Kiriliouk <em>et al.</em> (2016, eq. 17.14, p. 360). Numerical experiments indicate that the <code class="reqn">2</code> is needed for <code class="reqn">\widehat{l}_{CF}(x,y)</code> but evidently not in <code class="reqn">\widehat{l}(x,y)</code>.
</p>
<p>The visualization of <code class="reqn">l(x,y)</code> commences by setting a constant (<code class="reqn">c &gt; 0</code>) as <code class="reqn">c_i \in 0.2,0.4,0.6,0.8</code> (say). The <code class="reqn">y</code> are solved for <code class="reqn">x \in [0,\ldots,c_i]</code> through the <code class="reqn">l(x,y)</code> for each of the <code class="reqn">c_i</code>. Each solution set constitutes a <em>level set</em> for the stable tail dependence function. If the bivariate data have <em>asymptotic independence</em> (to the right), then a level set or the level sets for all the <code class="reqn">c</code> are equal to the lines <code class="reqn">x + y = c</code>. Conversely, if the bivariate data have <em>asymptotic dependence</em> (to the right), then the level sets will make 90-degree bends for <code class="reqn">\mathrm{max}(x,y) = c</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stabtaildepf(uv=NULL, xy=NULL, k=function(n) as.integer(0.5*n), levelset=TRUE,
             ploton=TRUE, title=TRUE, delu=0.01, smooth=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stabtaildepf_+3A_uv">uv</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of <code class="reqn">u</code> and <code class="reqn">v</code> nonexceedance probabilities in the respective <code class="reqn">X</code> (horizontal) and <code class="reqn">Y</code> (vertical) directions. Note, <code>rank()</code>s are called on these so strictly speaking this need not be as nonexceedance probabilities. This is not an optional argument;</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_xy">xy</code></td>
<td>
<p>A vector of the scalar coordinates <code class="reqn">(x,y)</code>, which are &ldquo;the relative distances to the upper endpoints of [these respective] variables&rdquo; (Kiriliouk <em>et al.</em>, 2016, p. 356). This is a major point of nomenclature confusion. If these are in probability units, they are <em>exceedance probabilities</em>. Though tested for <code>NULL</code> and a warning issued, these can be <code>NULL</code> only if <code>levelset=TRUE</code> but can be set to <code>xy=NA</code> if <code>levelset=FALSE</code> and <code>smooth=TRUE</code> (see discussion in <b>Note</b>);</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_k">k</code></td>
<td>
<p>The <code class="reqn">k</code> for both the <code class="reqn">\widehat{l}(x,y)</code> and <code class="reqn">\widehat{l}_{CF}</code>, though the effect of <code class="reqn">k</code> might not quite be the same for each. The default seems to work fairly well;</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_levelset">levelset</code></td>
<td>
<p>A logical triggering the construction of the level sets for <code class="reqn">c</code> <code class="reqn">=</code> <code>seq(0.1,</code> <code>1,</code> <code>by=0.1)</code>;</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_ploton">ploton</code></td>
<td>
<p>A logical to call the <code>plot()</code> function;</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_title">title</code></td>
<td>
<p>A logical to trigger a title for the plot if <code>ploton=TRUE</code>;</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_delu">delu</code></td>
<td>
<p>The <code class="reqn">\Delta x</code> for a sequence of <code class="reqn">x</code> <code class="reqn">=</code> <code>seq(0,c,by=delu)</code>;</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_smooth">smooth</code></td>
<td>
<p>A logical controlling whether <code class="reqn">\widehat{l}(x,y)</code> or the Capéraà&ndash;Fougères smooth function <code class="reqn">\widehat{l}_{CF}(x,y)</code> is used; and</p>
</td></tr>
<tr><td><code id="stabtaildepf_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Varies according to argument settings. In particular, the <code>levelset=TRUE</code> will cause an <span class="rlang"><b>R</b></span> <code>list</code> to be returned with the elements having the character string of the respective <code class="reqn">c</code> values and the each holding a <code>data.frame</code> of the <code class="reqn">(x,y)</code> coordinates.
</p>


<h3>Note</h3>

<p>This function is also called in a secondary recursion mode. The default <code>levelset=TRUE</code> makes a secondary call with <code>levelset=FALSE</code> to compute the <code class="reqn">\widehat{l}(x,y)</code> for the benefit of the looping on the one-dimensional root to solve for a single <code class="reqn">y</code> in <code class="reqn">\widehat{l}(x,y) = c</code> given a single <code class="reqn">x</code>. If <code>levelset=TRUE</code> and <code>smooth=TRUE</code>, then a secondary call with <code>smooth=TRUE</code> and <code>levelset=FALSE</code> is made to internally return an <span class="rlang"><b>R</b></span> <code>list</code> containing scalar <code class="reqn">N_n</code> and vectors <code class="reqn">\widehat{W}_n</code> and <code class="reqn">\widehat{p}_{3,i}</code> for similar looping and one-dimensional rooting for <code class="reqn">\widehat{l}_{CF}(x,y)</code>.
</p>
<p>If <code>levelset=FALSE</code>, then <code>xy</code> is required to hold the <code class="reqn">(x,y)</code> coordinate pair of interest. A demonstration follows and shows the limiting behavior of a random sample from the <code><a href="#topic+N4212cop">N4212cop</a></code> copula.
</p>
<pre>
  n &lt;- 2000 # very CPU intensive this and the next code snippet
  UV &lt;- simCOP(n=n, cop=N4212cop, para=pi); k &lt;- 1:n
  lhat &lt;- sapply(k, function(j)
                 stabtaildepf(xy=c(0.1, 0.1), uv=UV, levelset=FALSE, k=j))
  plot(k, lhat, xlab="k in [1,n]", cex=0.8, lwd=0.8, type="b",
                ylab="Empirical Stable Tail Dependence Function")
  mtext("Empirical function in the 0.10 x 0.10 Pr square (upper left corner)")
</pre>
<p>The <span class="rlang"><b>R</b></span> <code>list</code> that can be used to compute <code class="reqn">\widehat{l}_{CF}(x,y)</code> is retrievable by
</p>
<pre>
  x &lt;- 0.1; y &lt;- 0.1; k &lt;- 1:(n-1)
  lhatCF &lt;- sapply(k, function(j) {
     Hlis &lt;- stabtaildepf(xy=NA, uv=UV, levelset=FALSE, smooth=TRUE, k=j)
     2*sum(Hlis$p3 * sapply(1:Hlis$Nn, function(i) {
                 max(c(Hlis$Wn[i]*x, (1-Hlis$Wn[i])*y)) }))
  })
  lines(k, lhatCF, col="red")
</pre>
<p>The smooth line (red) of <code>lhatCF</code> is somewhat closer to the limiting behavior of <code>lhat</code>, but it is problematic to determine computational consistency. Mathematical consistency with Kiriliouk <em>et al.</em> (2016) appears to be achieved. The <b>Examples</b> section TODO.
</p>


<h3>Author(s)</h3>

<p>William Asquith <a href="mailto:william.asquith@ttu.edu">william.asquith@ttu.edu</a></p>


<h3>References</h3>

<p>Beirlant, J., Escobar-Bach, M., Goegebeur, Y., Guillou, A., 2016, Bias-corrected estimation of stable tail dependence function: Journal Multivariate Analysis, v. 143, pp. 453&ndash;466, <a href="https://doi.org/10.1016/j.jmva.2015.10.006">doi:10.1016/j.jmva.2015.10.006</a>.
</p>
<p>Kiriliouk, Anna, Segers, Johan, Warchoł, Michał, 2016, Nonparameteric estimation of extremal dependence: <em>in</em> Extreme Value Modeling and Risk Analysis, D.K. Dey and Jun Yan <em>eds.</em>, Boca Raton, FL, CRC Press, ISBN 978&ndash;1&ndash;4987&ndash;0129&ndash;7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psepolar">psepolar</a></code>, <code><a href="#topic+spectralmeas">spectralmeas</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
UV &lt;- simCOP(n=1200, cop=GLcop, para=2.1) # Galambos copula
tmp1 &lt;- stabtaildepf(UV) # the lines are curves (strong tail dependence)
tmp2 &lt;- stabtaildepf(UV, smooth=TRUE, ploton=FALSE, col="red") #
## End(Not run)
</code></pre>

<hr>
<h2 id='statTn'>The Tn Statistic of a Fitted Copula to an Empirical Copula</h2><span id='topic+statTn'></span>

<h3>Description</h3>

<p>Compute the <code class="reqn">T_n(p)</code> statistic of Genest <em>et al.</em> (2011) that is defined as
</p>
<p style="text-align: center;"><code class="reqn">T_n(p) = \sum_{i=1}^n \big|\mathbf{C}_n(u_i, v_i) - \mathbf{C}_{\Theta_n}(u_i, v_i)\big|^p\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}_n(u,v)</code> is the <em>empirical copula</em>, <code class="reqn">\mathbf{C}_{\Theta_n}(u,v)</code> is the <em>fitted copula</em> with estimated parameters <code class="reqn">\Theta_n</code> from the sample of size <code class="reqn">n</code>. The <code class="reqn">T_n</code> for <code class="reqn">p = 2</code> is reported by those authors to be of general purpose and overall performance in large scale simulation studies. The extension here for arbitary exponent <code class="reqn">p</code> is made for flexibility. Alternatively the definition could be associated with the statistic <code class="reqn">T_n(p)^{1/p}</code> in terms of a root <code class="reqn">1/p</code> of the summation as shown above.
</p>
<p>The <code class="reqn">T_n</code> statistic is obviously a form of deviation between the empirical (nonparametric) and parametric fitted copula. The distribution of this statistic through Monte Carlo simulation could be used for inference. The inference is based on that a chosen parametric model is suitably close to the empirical copula. The <code class="reqn">T_n(p)</code> statistic has an advantage of being relatively straightforward to understand and explain to stakeholders and decision makers, is attractive for being suitable in a wide variety of circumstances, but intuitively might have limited statistical power in some situations for it looks at whole copula structure and not say at tail dependency. Finally, other goodness-of-fits using the squared differences between <code class="reqn">\mathbf{C}_n(u,v)</code> and <code class="reqn">\mathbf{C}_{\Theta_m}(u, v)</code> are <code><a href="#topic+aicCOP">aicCOP</a></code>, <code><a href="#topic+bicCOP">bicCOP</a></code>, and <code><a href="#topic+rmseCOP">rmseCOP</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>statTn(u, v=NULL, cop=NULL, para=NULL, p=2, proot=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="statTn_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="statTn_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction. If not given, then a second column from argument <code>u</code> is attempted;</p>
</td></tr>
<tr><td><code id="statTn_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="statTn_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="statTn_+3A_p">p</code></td>
<td>
<p>The value for <code class="reqn">p</code>, and the default follows that of Genest <em>et al.</em> (2011);</p>
</td></tr>
<tr><td><code id="statTn_+3A_proot">proot</code></td>
<td>
<p>A logical controling whether the <code class="reqn">T_n</code> returned be rooted by <code class="reqn">1/p</code>, and the default follows that of Genest <em>et al.</em> (2011); and</p>
</td></tr>
<tr><td><code id="statTn_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function and (or) the empirical copula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">T_n</code> is returned dependent on the specification of <code class="reqn">p</code> and whether rooting of the result is desired.
</p>


<h3>Note</h3>

<p>The <b>Examples</b> section shows a simple computation of the <code class="reqn">\hat T_n</code> statistic for a sample and a fitted copula to that sample. Ideally <code>statTn</code> would be wrapped in a Monte Carlo process of fitting the apparent &ldquo;parent&rdquo; distribution from the sample data, then for some large replication count, generate <code class="reqn">N</code> samples of size <code class="reqn">n</code> from the parent and from these samples compute the empirical copula and also fit parameter(s) of the chosen copula and repeatedly solve for <code class="reqn">T_n</code>. Given a total of <code class="reqn">N</code> values of <code class="reqn">T_n</code>, then the sample <code class="reqn">T_n</code> or <code class="reqn">\hat{T}_n</code> can be compared to the distribution, and if <code class="reqn">\hat{T}_n</code> is greater than say the 95th percentile, then the assumed form of the copula could be rejected.
</p>
<p>The <code>distTn</code> defined below and is dependent on the <code><a href="#topic+copBasic.fitpara.beta">copBasic.fitpara.beta</a></code> function can be used to demonstrate concepts. (The process is complex enough that user-level implementation of <code>distTn</code> in <span class="pkg">copBasic</span> is not presently (2019) thought appropriate.)
</p>
<pre>
  "distTn" &lt;- function(n, N=1000, statf=NULL,
                       cop=NULL, para=para, interval=NULL, ...) {
      opts &lt;- options(warn=-1)
      message("Estimating Tn distribution: ", appendLF=FALSE)
      Tn &lt;- vector(mode="numeric", N)
      for(i in 1:N) {
         showi &lt;- as.logical(length(grep("0+$", i, perl=TRUE)))
         if(showi) message(i, "-", appendLF=FALSE)
         ruv &lt;- simCOP(n=n, cop=cop, para=para, graphics=FALSE, ...)
         rpara &lt;- copBasic.fitpara.beta(ruv, statf=statf,
                             interval=interval, cop=cop)
         Tn[i] &lt;- ifelse(is.na(rpara), NA, statTn(ruv, cop=cop, para=rpara))
      }
      numNA &lt;- length(Tn[is.na(Tn)])
      message("done: Number of failed parameter estimates=", numNA)
      options(opts)
      return(Tn[! is.na(Tn)])
  }
</pre>
<p>Let us imagine an <code class="reqn">n=400</code> sample size of a <em>Galambos copula</em> (<code class="reqn">\mathbf{GL}(u,v)</code>; <code><a href="#topic+GLcop">GLcop</a></code>) and then treat the <em>Plackett copula</em> (<code class="reqn">\mathbf{PL}(u,v)</code>; <code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>) as the proper (chosen) model. The estimated parameter by the sample <em>Blomqvist Beta</em> of <code class="reqn">\hat\beta_\mathbf{C} = 0.64</code> using the <code><a href="#topic+blomCOP">blomCOP</a></code> function called from within <code>copBasic.fitpara.beta</code> is then placed in variable <code>para</code>. The <code class="reqn">\hat\beta_\mathbf{C}</code> is not the most efficient estimator but for purposes here, but it is fast.  The parameter for the given seed is estimated as about <code class="reqn">\mathbf{PL}(\hat\Theta{=}20.75)</code>.
</p>
<pre>
  n &lt;- 400 # sample size
  correctCopula &lt;- GLcop; set.seed(1596)
  sampleUV &lt;- simCOP(n=n, cop=correctCopula, para=1.9) # a random sample
  para.correctCopula &lt;- copBasic.fitpara.beta(uv=sampleUV, statf=blomCOP,
                                interval=c(1,5),      cop=correctCopula)
  chosenCopula &lt;- PLACKETTcop
  para &lt;- copBasic.fitpara.beta(uv=sampleUV, statf=blomCOP,
                                interval=c(.001,200), cop=chosenCopula )
</pre>
<p>Next, compute the sample <code class="reqn">\hat T_n = 0.063</code> from <code>sampleUV</code>. The distribution of the <code class="reqn">T_n</code> is estimated using the <code>distTn</code> function, and an estimate of the <code class="reqn">\hat T_n</code> p-value is in turn estimated. A large simulation run <code class="reqn">N = 1{,}000</code> for a sample of size of <code class="reqn">n = 400</code> is selected. The <code>distTn</code> function internally will simulated for <code>N</code>-replicates from the assumed parent and estimate the parameter. A computation run yields a p-value of approximately 0.01 (depending upon the seed) and is statistically significant at an alpha of 0.05, and therefore, the <code class="reqn">\mathbf{PL}(\Theta{=}20.75)</code> should be rejected for fitting to these data.
</p>
<pre>
  sampleTn   &lt;- statTn(sampleUV, cop=chosenCopula, para=para)
  Tns        &lt;- distTn(n=n,      cop=chosenCopula, para=para,
                       interval=c(0.001, 100), statf=blomCOP)
  Tns_pvalue &lt;- 1 - sum(Tns &lt;= sampleTn) / length(Tns) # estimate p-value
</pre>
<p>The demonstration is furthered with a check on the <em>Kullback&ndash;Leibler sample size</em> <code class="reqn">n_{f\!g}</code> at the 5-percent significance level (alpha = 0.05) by the <code><a href="#topic+kullCOP">kullCOP</a></code> function, which yields <code class="reqn">100</code>. Given the parent copula as <code class="reqn">\mathbf{GL}(\Theta{=}1.9)</code>, therefore, it would take approximately 100 samples to distinguish between that copula and a <code class="reqn">\mathbf{PL}(\Theta{=}20.75)</code> where in this case the fit was through the <code class="reqn">\hat\beta_\mathbf{C} = 0.64</code>.
</p>
<pre>
  kullCOP(cop1=correctCopula, para1=1.9,
          cop2=chosenCopula,  para2=para)$KL.sample.size # KL sample size = 100
  vuongCOP(sampleUV, cop1=correctCopula, para1=para.correctCopula,
                     cop2=chosenCopula,  para2=para)$message
  # [1] "Copula 1 has better fit than Copula 2 at 100x(1-alpha) level"
</pre>
<p>The available sample size <code class="reqn">n = 400</code> is then about four times larger than <code class="reqn">n_{f\!g}</code> so the sample size <code class="reqn">n</code> should be sufficient to judge goodness-of-fit. This is a large value but with the sample variability of <code class="reqn">\hat\beta_\mathbf{C}</code>, it seems that other measures of association such as <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) or <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) and others cross-referenced therein might be preferable.
</p>
<p>The prior conclusion is supported by the p-value of the <code class="reqn">\hat T_n</code> being about 0.01, which suggests that the <code class="reqn">\mathbf{PL}(u,v)</code> is not a good model of the available sample data in <code>sampleUV</code>. Lastly, these judgments are consistent with the <em>Vuoug Procedure</em> performed by the <code><a href="#topic+vuongCOP">vuongCOP</a></code> function, which reports at the 5-percent significance level that &ldquo;copula number 1&rdquo;&mdash;in this case, the <code class="reqn">\mathbf{GL}(u,v)</code>&mdash;has the better fit, and this is obviously consistent with the problem setup because the random sample for investigation was drawn from the Galambos coupla (the parent form).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Genest, C., Kojadinovic, I., Nešlehová, J., and Yan, J., 2011, A goodness-of-fit test for bivariate extreme-value copulas: Bernoulli, v. 17, no. 1, pp. 253&ndash;275.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aicCOP">aicCOP</a></code>, <code><a href="#topic+bicCOP">bicCOP</a></code>, <code><a href="#topic+rmseCOP">rmseCOP</a></code>, <code><a href="#topic+vuongCOP">vuongCOP</a></code>, <code><a href="#topic+kullCOP">kullCOP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example here is just for Tn. For the example below, the PSP copula is quite different
# from the Gumbel-Hougaard copula and thus, the hatTn would be expected to be different
# from those of the Gumbel-Hougaard and certainly not too near to zero.
samUV  &lt;- simCOP(n=60, cop=PSP, graphics=FALSE, seed=1)   # random sample
hatTau &lt;- cor(samUV$U, samUV$V, method="kendall")         # Kendall Tau
hatTn  &lt;- statTn(samUV, cop=GHcop, para=GHcop(tau=hatTau)$para,
                 ctype="bernstein", bernprogress=TRUE)    # 0.03328789
# hatTn in this case is by itself is somewhat uninformative and requires
# Monte Carlo to put an individual value into context.
## End(Not run)
</code></pre>

<hr>
<h2 id='surCOP'>The Survival Copula</h2><span id='topic+surCOP'></span>

<h3>Description</h3>

<p>Compute the <em>survival copula</em> from a copula (Nelsen, 2006, pp. 32&ndash;34), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mathbf{C}}(1-u,1-v) = \hat{\mathbf{C}}(u',v') = \mathrm{Pr}[U &gt; u, V &gt; v] = u' + v' - 1 + \mathbf{C}(1-u', 1-v')\mbox{,}</code>
</p>

<p>where <code class="reqn">u'</code> and <code class="reqn">v'</code> are exceedance probabilities and <code class="reqn">\mathbf{C}(u,v)</code> is the copula (<code><a href="#topic+COP">COP</a></code>). The <em>survivial copula</em> is a reflection of both <code class="reqn">U</code> and <code class="reqn">V</code>.
</p>
<p>The <em>survival copula</em> is an expression of the joint probability that both <code class="reqn">U &gt; v</code> and <code class="reqn">U &gt; v</code> when the arguments <code class="reqn">a</code> and <code class="reqn">b</code> to <code class="reqn">\hat{\mathbf{C}}(a,b)</code> are exceedance probabilities as shown. This is unlike a copula that has <code class="reqn">U \le u</code> and <code class="reqn">V \le v</code> for nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code>. Alternatively, the joint probability that both <code class="reqn">U &gt; u</code> and <code class="reqn">V &gt; v</code> can be solved using just the copula <code class="reqn">1 - u - v + \mathbf{C}(u,v)</code>, as shown below where the arguments to <code class="reqn">\mathbf{C}(u,v)</code> are nonexceedance probabilities. The later formula is the <em>joint survival function</em> <code class="reqn">\overline{\mathbf{C}}(u,v)</code> (<code><a href="#topic+surfuncCOP">surfuncCOP</a></code>) defined for a copula (Nelsen, 2006, p. 33) as
</p>
<p style="text-align: center;"><code class="reqn">\overline{\mathbf{C}}(u,v) = \mathrm{Pr}[U &gt; u, V &gt; v] = 1 - u - v + \mathbf{C}(u,v)\mbox{.}</code>
</p>

<p>Users are directed to the collective documentation in <code><a href="#topic+COP">COP</a></code> and <code><a href="#topic+simCOPmicro">simCOPmicro</a></code> for more details on copula reflection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surCOP(u, v, cop=NULL, para=NULL, exceedance=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="surCOP_+3A_u">u</code></td>
<td>
<p>Exceedance probability <code class="reqn">u' = 1 - u</code> (<code class="reqn">u</code> nonexceedance based on <code>exceedance</code>) in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="surCOP_+3A_v">v</code></td>
<td>
<p>Exceedance probability <code class="reqn">v' = 1 - v</code> (<code class="reqn">v</code> nonexceedance based on <code>exceedance</code>) in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="surCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="surCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="surCOP_+3A_exceedance">exceedance</code></td>
<td>
<p>A logical affirming whether <code>u</code> and <code>v</code> are really in exceedance probability or not? If <code>FALSE</code>, then the complements of the two are made internally and the nonexceedances can thus be passed; and</p>
</td></tr>
<tr><td><code id="surCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass (such as parameters, if needed, for the copula in the form of an <span class="rlang"><b>R</b></span> <code>list</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the survival copula are returned.
</p>


<h3>Note</h3>

<p>The author (Asquith) finds the use of exceedance probabilities delicate in regards to Nelsen's notation. This function and <code><a href="#topic+coCOP">coCOP</a></code> have the <code>exceedance</code> argument to serve as a reminder that the survival copula as usually defined uses exceedance probabilities as its arguments.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+coCOP">coCOP</a></code>, <code><a href="#topic+duCOP">duCOP</a></code>, <code><a href="#topic+surfuncCOP">surfuncCOP</a></code>, <code><a href="#topic+simCOPmicro">simCOPmicro</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>u  &lt;-  0.26; v  &lt;- 0.55   # nonexceedance probabilities
up &lt;- 1 - u; vp &lt;- 1 - v  #    exceedance probabilities
surCOP(up, vp,   cop=PSP, exceedance=TRUE)  # 0.4043928
surCOP(u, v,     cop=PSP, exceedance=FALSE) # 0.4043928 (same because of symmetry)
surfuncCOP(u, v, cop=PSP)                   # 0.4043928
# All three examples show joint prob. that U &gt; u and V &gt; v.

## Not run: 
# A survival copula is a copula so it increases to the upper right with increasing
# exceedance probabilities. Let us show that by hacking the surCOP function into
# a copula for feeding back into the algorithmic framework of copBasic.
UsersCop &lt;- function(u,v, para=NULL) {
     afunc &lt;- function(u,v, theta=para) { surCOP(u, v, cop=N4212cop, para=theta)}
     return(asCOP(u,v, f=afunc)) }
image(gridCOP(cop=UsersCop, para=1.15), col=terrain.colors(20),
      xlab="U, EXCEEDANCE PROBABILITY", ylab="V, EXCEEDANCE PROBABILITY") #
## End(Not run)
</code></pre>

<hr>
<h2 id='surfuncCOP'>The Joint Survival Function</h2><span id='topic+surfuncCOP'></span>

<h3>Description</h3>

<p>Compute the <em>joint survival function</em> for a copula (Nelsen, 2006, p. 33), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\overline{\mathbf{C}}(u,v) = \mathrm{Pr}[U &gt; u, V &gt; v] = 1 - u - v + \mathbf{C}(u,v) = \hat{\mathbf{C}}(1-u, 1-v)\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{\mathbf{C}}(u',v')</code> is the <em>survival copula</em> (<code><a href="#topic+surCOP">surCOP</a></code>), which is defined by
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mathbf{C}}(u',v') = \mathrm{Pr}[U &gt; u, V &gt; v] =  u' + v' - 1 + \mathbf{C}(1-u',1-v')\mbox{.}</code>
</p>

<p>Although the joint survival function is an expression of the probability that both <code class="reqn">U &gt; v</code> and <code class="reqn">U &gt; v</code>, <code class="reqn">\overline{\mathbf{C}}(u,v)</code> is not a copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surfuncCOP(u, v, cop=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="surfuncCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="surfuncCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="surfuncCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="surfuncCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula; and</p>
</td></tr>
<tr><td><code id="surfuncCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass (such as parameters, if needed, for the copula in the form of a list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the joint survival function are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+surCOP">surCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>"MOcop.formula" &lt;- function(u,v, para=para, ...) {
   alpha &lt;- para[1]; beta &lt;- para[2]; return(min(v*u^(1-alpha), u*v^(1-beta)))
}
"MOcop" &lt;- function(u,v, ...) { asCOP(u,v, f=MOcop.formula, ...) }
u &lt;- 0.2; v &lt;- 0.75; ab &lt;- c(1.5, 0.3)
# U **and** V are less than or equal to a threshold +
# U **or**  V are less than or equal to a threshold
surCOP(1-u,1-v, cop=MOcop, para=ab) + duCOP(u,v, cop=MOcop, para=ab) # UNITY
surfuncCOP(u,v, cop=MOcop, para=ab) + duCOP(u,v, cop=MOcop, para=ab) # UNITY

## Not run: 
# The joint survival function is not a copula. So, it does not increases to the upper
# right with increasing exceedance probabilities. Let us show that by hacking the surCOP
# function into a copula for feeding back into the algorithmic framework of copBasic.
UsersCop &lt;- function(u,v, para=NULL) {
     afunc &lt;- function(u,v, theta=para) { surfuncCOP(u, v, cop=N4212cop, para=theta) }
     return(asCOP(u,v, f=afunc)) }
image(gridCOP(cop=UsersCop, para=1.15), col=terrain.colors(20),
      xlab="U, NONEXCEEDANCE PROBABILITY", ylab="V, NONEXCEEDANCE PROBABILITY") #
## End(Not run)

## Not run: 
# Conditional return period (Salvadori et al., 2007, p. 159)
UV &lt;- simCOP(n=100000, cop=PLACKETTcop, para=5, graphics=FALSE)
u &lt;- 0.5; v &lt;- 0.99; cd &lt;- UV$V[UV$U &gt; u]
by.counting &lt;- length(cd[cd &gt; v]) / length(cd)                  # 0.0172
by.theo     &lt;- surfuncCOP(u,v, cop=PLACKETTcop, para=5) / (1-u) # 0.0166
by.ec       &lt;- surfuncCOP(u,v, cop=EMPIRcop, para=UV)   / (1-u) # 0.0189
print(1/by.theo) # conditional return period for V &gt; 0.99 given U &gt; 0.5 
## End(Not run)
</code></pre>

<hr>
<h2 id='tailconCOP'>The Tail Concentration Function of a Copula</h2><span id='topic+tailconCOP'></span>

<h3>Description</h3>

<p>Compute the <em>tail concentration function</em> (<code class="reqn">q_\mathbf{C}</code>) of a copula <code class="reqn">\mathbf{C}(u,v)</code> (<code><a href="#topic+COP">COP</a></code>) or diagnonal (<code><a href="#topic+diagCOP">diagCOP</a></code>) of a copula <code class="reqn">\delta_\mathbf{C}(t) = \mathbf{C}(t,t)</code>  according to Durante and Semp (2015, p. 74):
</p>
<p style="text-align: center;"><code class="reqn">q_\mathbf{C}(t) = \frac{\mathbf{C}(t,t)}{t} \cdot \mathbf{1}_{[0,0.5)}  + \frac{1 - 2t + \mathbf{C}(t,t)}{1-t} \cdot \mathbf{1}_{[0.5, 1]}\mbox{\quad or}</code>
</p>

<p style="text-align: center;"><code class="reqn">q_\mathbf{C}(t) = \frac{\delta_\mathbf{C}(t)}{t} \cdot \mathbf{1}_{[0,0.5)} + \frac{1 - 2t + \delta_\mathbf{C}(t)}{1-t}   \cdot \mathbf{1}_{[0.5, 1]}\mbox{,}</code>
</p>

<p>where <code class="reqn">t</code> is a nonexceedance probability on the margins and <code class="reqn">\mathbf{1}(.)</code> is an <em>indicator function</em> scoring 1 if condition is true otherwise zero on what interval <code class="reqn">t</code> resides: <code class="reqn">t \in [0,0.5)</code> or <code class="reqn">t \in [0.5,1]</code>. The <code class="reqn">q_\mathbf{C}(t; \mathbf{M}) = 1</code> for all <code class="reqn">t</code> for the <code><a href="#topic+M">M</a></code> copula and  <code class="reqn">q_\mathbf{C}(t; \mathbf{W}) = 0</code> for all <code class="reqn">t</code> for the <code><a href="#topic+W">W</a></code> copula. Lastly, the function is related to the <em>Blomqvist Beta</em> (<code class="reqn">\beta_\mathbf{C}</code>; <code><a href="#topic+blomCOP">blomCOP</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">q_\mathbf{C}(0.5) = (1 + \beta_\mathbf{C})/2\mbox{,}</code>
</p>

<p>where <code class="reqn">\beta_\mathbf{C} = 4\mathbf{C}(0.5, 0.5) - 1</code>. Lastly, the <code class="reqn">q_\mathbf{C}(t)</code> for <code class="reqn">0,1 = t</code> is <code>NaN</code> and no provision for alternative return is made. Readers are asked to note some of the mathematical similarity in this function to Blomqvist Betas in <code><a href="#topic+blomCOPss">blomCOPss</a></code> in regards to tail dependency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tailconCOP(t, cop=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tailconCOP_+3A_t">t</code></td>
<td>
<p>Nonexceedance probabilities <code class="reqn">t</code>;</p>
</td></tr>
<tr><td><code id="tailconCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="tailconCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula; and</p>
</td></tr>
<tr><td><code id="tailconCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for <code class="reqn">q_\mathbf{C}</code> are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Durante, F., and Sempi, C., 2015, Principles of copula theory: Boca Raton, CRC Press, 315 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+taildepCOP">taildepCOP</a></code>, <code><a href="#topic+tailordCOP">tailordCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>tailconCOP(0.5, cop=PSP) == (1 + blomCOP(cop=PSP)) / 2 # TRUE
</code></pre>

<hr>
<h2 id='taildepCOP'>The Lower- and Upper-Tail Dependency Parameters of a Copula</h2><span id='topic+taildepCOP'></span>

<h3>Description</h3>

<p>Compute the <em>lower-</em> and <em>upper-tail dependency parameters</em> (if they exist), respectively, of a copula according to Nelsen (2006, pp. 214&ndash;215). Graphical confirmation of the computations is important, and therefore, the function can also generate a plot. The dependency parameters are expressions of conditional probability that <code class="reqn">Y</code> is greater than the <code class="reqn">100{\times}</code>th percentile of its distribution <code class="reqn">G</code> given that <code class="reqn">X</code> is greater than the <code class="reqn">100{\times}t</code>-th percentile of its distribution <code class="reqn">F</code> as <code class="reqn">t</code> approaches unity. Specifics in terms of quantile functions <code class="reqn">G^{(-1)}(t) = y(t)</code> and <code class="reqn">F^{(-1)}(t) = x(t)</code> follow.
</p>
<p>The <em>lower-tail dependence parameter</em> <code class="reqn">\lambda^L_\mathbf{C}</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\lambda^L_\mathbf{C} = \lim_{t{\rightarrow 0^{+}}} \mathrm{Pr}[Y \le y(t)\mid X \le x(t)]\mbox{, and}</code>
</p>

<p>the <em>upper-tail dependence parameter</em> <code class="reqn">\lambda^U_\mathbf{C}</code> with reversed inequalities is defined as
</p>
<p style="text-align: center;"><code class="reqn">\lambda^U_\mathbf{C} = \lim_{t{\rightarrow 1^{-}}} \mathrm{Pr}[Y &gt; y(t)\mid X &gt; x(t)]\mbox{.}</code>
</p>

<p>Nelsen (2006, p. 214) also notes that both <code class="reqn">\lambda^L_\mathbf{C}</code> and <code class="reqn">\lambda^U_\mathbf{C}</code> are nonparametric and depend only on the copula of <code class="reqn">X</code> and <code class="reqn">Y</code>, and Nelsen shows that each can be computed if the above limits exist as follows:
</p>
<p style="text-align: center;"><code class="reqn">\lambda^L_\mathbf{C} = \lim_{t{\rightarrow 0^{+}}} \frac{\mathbf{C}(t,t)}{t} = \delta_\mathbf{C}'(0^{+})\mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^U_\mathbf{C} = \lim_{t{\rightarrow 1^{-}}} \frac{1 - 2t - \mathbf{C}(t,t)}{1 - t} = 2 - \lim_{t{\rightarrow 1^{-}}} \frac{1 - \mathbf{C}(t,t)}{1-t} = 2 - \delta_\mathbf{C}'(1^{-})\mbox{,}</code>
</p>

<p>where <code class="reqn">\delta_\mathbf{C}'(t)</code> is the derivative of the diagonal of the copula. Multiple presentations are shown because algebraic variants are shown across the literature.
</p>
<p>If <code class="reqn">\lambda^L_\mathbf{C} \in (0,1]</code>, then <code class="reqn">\mathbf{C}</code> has lower-tail dependence but if <code class="reqn">\lambda^L_\mathbf{C} = 0</code>, then <code class="reqn">\mathbf{C}</code> has <em>no</em> lower-tail dependence. Likewise, if <code class="reqn">\lambda^U_\mathbf{C} \in (0,1]</code>, then <code class="reqn">\mathbf{C}</code> has upper-tail dependence but if <code class="reqn">\lambda^U_\mathbf{C} = 0</code>, then <code class="reqn">\mathbf{C}</code> has <em>no</em> upper-tail dependence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taildepCOP(cop=NULL, para=NULL, tol=1e-6, divisor=2, plot=FALSE, ylim=NULL,
                                verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="taildepCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_tol">tol</code></td>
<td>
<p>A tolerance on convergence;</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_divisor">divisor</code></td>
<td>
<p>The divisor on the incremental reductions towards <code class="reqn">0^+</code> and <code class="reqn">0^-</code> by the algorithm;</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_plot">plot</code></td>
<td>
<p>A logical plotting a diagnostic plot of the diagonal derivatives and label the limits;</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_ylim">ylim</code></td>
<td>
<p>Optional vertical limits if the plot is turned on. Although the dependence parameters are bounded as described above, numerical stability can be a problem. Stability is especially a problem if an empirical copula is being used; theefore, the bounds of the plot are left open unless the user locks them down with this argument;</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_verbose">verbose</code></td>
<td>
<p>Show incremental progress; and</p>
</td></tr>
<tr><td><code id="taildepCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> list is returned.
</p>
<table role = "presentation">
<tr><td><code>lambdaL</code></td>
<td>
<p>The rounded value of <code class="reqn">\lambda^L_\mathbf{C}</code>;</p>
</td></tr>
<tr><td><code>lambdaU</code></td>
<td>
<p>The rounded value of <code class="reqn">\lambda^U_\mathbf{C}</code>;</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source: &ldquo;taildepCOP&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><em>IMPLEMENTED ALGORITHM</em>&mdash;The algorithm implemented for <code>taildepCOP</code> is based on halves (or alternatives by the setting of <code>divisor</code> argument) and uses the copula function (not an analytical or even numeric derivative of the diagonal, <code class="reqn">\delta_\mathbf{C}'(t)</code>). Starting from the median or <code class="reqn">t = 0.5</code>, each limit is respectively computed by successive halving (or the setting of argument <code>divisor</code>) of the distance towards <code class="reqn">0^{+}</code> and <code class="reqn">1^{-}</code> and checking the change in computed value against the tolerance <code>tol</code> argument. After the change becomes less than the tolerance, convergence is assumed. Other tests are made for <code>NaN</code> to aid in breaking the successive halvings. The rounding for the numerical results for <code class="reqn">\lambda^U_\mathbf{C}</code> and <code class="reqn">\lambda^L_\mathbf{C}</code> is an order of magnitude larger than the tolerance.
</p>
<p>Users are encouraged to plot the results and further verify whether the convergence makes sense. The plot produced when <code>plot=TRUE</code> shows the probability <code class="reqn">t</code> transformed into standard normal variates by the <code>qnorm()</code> function in <span class="rlang"><b>R</b></span> so that the distal reaches of each tail and thus limit are readily seen. The terminal points of each limit computation are shown by a small dot and the letter &ldquo;L&rdquo; and &ldquo;U&rdquo; also are plotted at the terminal points.
</p>
<p>Joe (2014, p. 63) reports that &ldquo;the empirical measure of tail dependence [<code class="reqn">\hat\lambda_\mathbf{C}^L</code> or <code class="reqn">\hat\lambda_\mathbf{C}^U</code>] for data does not really exist because of the limit.&rdquo;  Joe (2014) suggests that other sources in the literature are the &ldquo;best that can be done&rdquo; (Dobrić and Schmid, 2005; Frahm <em>et al.</em>, 2005). Another source of discussion is by Schmidt and Stadtmüller (2006). The results therein are not yet followed up for the <span class="pkg">copBasic</span> package. Picking up the simulation dealt with extensively in the <b>Note</b> section of <code><a href="#topic+vuongCOP">vuongCOP</a></code>, a user might try this:
</p>
<pre>
  set.seed(385); n &lt;- 390
  UV &lt;- simCOP(cop=PSP, n=n, col=8, pch=16, graphics=FALSE)
  taildepCOP(cop=EMPIRcop, para=UV, plot=TRUE, divisor=8, ylim=c(0,1))
  taildepCOP(cop=PSP) # lower=0.5, upper=0
</pre>
<p>The returned tail dependency parameters are numerically of little importance and in strict terms likely misleading. What should be of interest are the plotted trajectories of the lower and upper lines. Note: the lower tail wobbles but seems to show stability towards near <code class="reqn">\hat\lambda_\mathbf{C}^L = 0.5</code> and upper-tail line wobbles downward towards <code class="reqn">\hat\lambda_\mathbf{C}^U = 0</code>. These values are, respectively, the tail dependencies of the <code class="reqn">\mathbf{PSP}</code> copula (<code><a href="#topic+PSP">PSP</a></code>). A user might try increasing the sample size by an order of magnitude and rerunning the above code. Lastly, Salvadori <em>et al.</em> (2006, pp. 173&ndash;175) caution on the difficulties of nonparametric tail dependency estimation. Given objectives of the <span class="pkg">copBasic</span> package, estimation of <code class="reqn">\hat\lambda_\mathbf{C}^L</code> and <code class="reqn">\hat\lambda_\mathbf{C}^U</code>, therefore, is an open development opportunity.
</p>
<p><em>DEMONSTRATION (Tail Dependence)</em>&mdash;The following example shows a comparison between early code examples by Charpentier (2012) concerning copulas and tail dependence using real-world data. Consider the <code>lossalae</code> data set and the following code requiring the <span class="pkg">evd</span> package:
</p>
<pre>
  library(evd); X &lt;- lossalae # Charpentier (2012)
  library(copBasic)
  fakeU &lt;- lmomco::pp(X[,1],sort=FALSE,a=0) # Weibull plotting position i/(n+1)
  fakeV &lt;- lmomco::pp(X[,2],sort=FALSE,a=0) # Weibull plotting position i/(n+1)
  uv &lt;- data.frame(U=fakeU, V=fakeV)  # parameter "object" for Empirical copula
  plot(uv)
  TD &lt;- taildepCOP(cop=EMPIRcop, para=uv, divisor=25,
                   plot=TRUE, ylim=c(0, 7/10))
  U &lt;- rank(X[,1])/(nrow(X)+1); V &lt;- rank(X[,2])/(nrow(X)+1)# Charpentier(2012)
  Lemp &lt;- function(z) sum((U&lt;=z)   &amp; (V&lt;=z))   / sum(U&lt;=z  )# Charpentier(2012)
  Remp &lt;- function(z) sum((U&gt;=1-z) &amp; (V&gt;=1-z)) / sum(U&gt;=1-z)# Charpentier(2012)
  u &lt;- seq(0.001, 0.5, by=.001)                             # Charpentier(2012)
  L &lt;- Vectorize(Lemp)(u); R &lt;- Vectorize(Remp)(rev(u))     # Charpentier(2012)
  lines(qnorm(c(u, u + 0.5 - u[1])), c(L,R)) # modified after Charpentier(2012)
  legend("bottomright", c("Lower-tail dependency by taildepCOP()",
                          "Upper-tail dependency by taildepCOP()",
                          "Charpentier (2012)"), bty="n", cex=0.9,
                          lwd=1, lty=1, col=c("red", "blue", "black"))
</pre>
<p>The figure that will have been generated shows considerably similarity to that from the algorithms of Charpentier. Now, let us extend the discussion by using the <em>Blomqvist (Schmid&ndash;Schmidt) Betas</em> (<code><a href="#topic+blomCOPss">blomCOPss</a></code>) that have a formulation permitting lower- and upper-tail dependency parameters in a different manner than the definitions of this documentation for <code>taildepCOP</code>.
</p>
<pre>
  edge &lt;- 30 * 1 / (1+nrow(X)) # as few as 30 samples into the tails
  psl &lt;- pnorm(seq(0, qnorm(  edge), by=-0.005))
  psu &lt;- pnorm(seq(0, qnorm(1-edge), by= 0.005))
  lines(qnorm(psl),
        sapply(psl, function(p) { blomCOPss(as.sample=TRUE, para=uv,
                    ctype="checkerboard", uu=rep(p, 2), vv=c(1,1)) }),
                    col="darkgreen", lty=1, lwd=2)
  lines(qnorm(psu),
        sapply(psu, function(p) { blomCOPss(as.sample=TRUE, para=uv,
                    ctype="checkerboard", uu=c(0,0), vv=rep(p, 2)) }),
                    col="darkgreen", lty=1, lwd=2)
  points(0, blomCOP(as.sample=TRUE, para=uv), pch=16, col="magenta", cex=2)
  legend("topleft", c("Tail dependency by Blomqvist (Schmid-Schmidt) Betas",
                      "Blomqvist Beta C(1/2, 1/2)"),
                    bty="n", cex=0.9, lwd=2, lty=c(1,NA), pch=c(NA,16),
                    pt.cex=c(NA,2), col=c("darkgreen", "magenta"))
</pre>
<p>The thick green lines show that the dependency parameters to the left and right are approached along a different trajectory using the definitions in <code><a href="#topic+blomCOPss">blomCOPss</a></code>. It seems at some stage in analysis that the practioner will need to decide how deep into the tail the sample will permit for a reliable estimate of the dependency parameters. <em>Blomqvist Beta</em> (<code class="reqn">\hat\beta_\mathbf{C}</code>) (<code><a href="#topic+blomCOP">blomCOP</a></code> is shown as the magenta dot at the median and henceforth from do the trajectories of <code class="reqn">\hat\lambda^L_{\beta^\diamond_\mathbf{C}}</code> and <code class="reqn">\hat\lambda^U_{\beta^\diamond_\mathbf{C}}</code> extend as their <code class="reqn">\mathrm{lim} p \rightarrow 0^+</code>. Ultimately, for the data shown in the figure, perhaps the <code class="reqn">\hat\lambda_\mathbf{C}^L = 0.1</code> and the <code class="reqn">\hat\lambda_\mathbf{C}^U = 0.3</code> and a parametric copula fitted in part to such values.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Charpentier, A., 2012, Copulas and tail dependence, part 1: R-bloggers, dated Sept. 17, 2012, accessed on February 2, 2019 at <br />
<a href="https://www.r-bloggers.com/2012/09/copulas-and-tail-dependence-part-1/">https://www.r-bloggers.com/2012/09/copulas-and-tail-dependence-part-1/</a>
</p>
<p>Dobrić, J. and Schmid, F., 2005, Nonparametric estimation of the lower tail dependence <code class="reqn">\lambda^L</code> in bivariate copulas: Journal of Applied Statistics, v. 32, no. 4, pp. 387&ndash;407.
</p>
<p>Frahm, G., Junker, M., and Schmidt, R., 2005, Estimating the tail-dependence coefficient&mdash;<br /> Properties and pitfalls: Insurance&mdash;Mathematics and Economics, v. 37, no. 1, pp. 80&ndash;100.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>
<p>Schmidt, R., and Stadtmüller, U., 2006, Nonparametric estimation of tail dependence: The Scandinavian Journal of Statistics, v. 33, pp. 307&ndash;335.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+tailconCOP">tailconCOP</a></code>, <code><a href="#topic+tailordCOP">tailordCOP</a></code>, <code><a href="#topic+blomCOPss">blomCOPss</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot the tail dependencies by nonexceedance probability for a
# for a positive association Plackett copula and see that both are zero.
taildepCOP(cop=PLACKETTcop, para=3, plot=TRUE)
# So, Plackett has no tail dependency, as Nelsen (2006, p. 215) shows.

## Not run: 
"MOcop" &lt;- function(u,v, para=NULL) { # Marshall-Olkin copula
   alpha &lt;- para[1]; beta &lt;- para[2]; return(min(v*u^(1-alpha), u*v^(1-beta)))
} # The results that follow match those reported by Nelsen (2006, p. 215).
taildepCOP(cop=MOcop, para=c(0.4, 0.9)) # LambL = 0, LambU = 0.4 [min(alpha,beta)]
## End(Not run)

## Not run: 
# Analytical solution to Gumbel-Hougaard copula from the copula package:
copula::lambda(copula::gumbelCopula(3))
#   lower    upper
# 0.000000 0.740079
# Numerical approximation (see copBasic::GHcop for analytical formula):
as.data.frame(taildepCOP(GHcop, para=3))
#  lambdaL lambdaU     source
#1 0.00012 0.74008 taildepCOP
## End(Not run)

## Not run: 
# Plot the tail dependencies by nonexceedance probability
# for the PSP copula, which has lower but no upper-tail dependence.
taildepCOP(cop=PSP, para=NULL, plot=TRUE) # LambL=0.5, LambU=0
# which is readily confirmed by simCOP(1000, cop=PSP)
# Nelsen (2006, p. 216) reports that this copula has LambL=1/2 and LambU=0,
# and we get the same results here.

# How about some composited Plackett-Plackett copulas?
# Each has upper- and lower-tail dependence parameters equal to zero.
para &lt;- list( cop1=PLACKETTcop,  cop2=PLACKETTcop, alpha=0.9392,
             para1=0.00395,     para2=4.67,         beta=0.5699)
taildepCOP(cop=composite2COP, para=para, plot=TRUE, verbose=TRUE) #
## End(Not run)

## Not run: 
# This next Plackett-Plackett is interesting because at its core it looks
# like it should be both tail dependent like M() but the shapes of the curves
# are quite different from those of M(). This example shows numerical
# instability for the upper tail but not the lower tail. So, we extend the
# example to shown the tail dependency trajectories by blomCOPss(). And again
# it is seen that the lower tail as a stable solution but the upper tail
# has instability at 6 standard deviations into the upper tail.
para &lt;- list(  cop1=PLACKETTcop,  cop2=PLACKETTcop, alpha=0.0063,
             para1=0.101,        para2=4493,         beta=0.0167)
taildepCOP(cop=composite2COP, para=para, plot=TRUE)
lsu &lt;- pnorm(seq(-7, 0, by=.01))
psu &lt;- pnorm(seq( 0, 7, by=.01))
lines(qnorm(lsu), sapply(lsu, function(p) {
        blomCOPss(cop=composite2COP, para=para, vv=c(1,1), uu=rep(p, 2)) }),
                    col="darkgreen", lty=2, lwd=1)
lines(qnorm(psu), sapply(psu, function(p) {
        blomCOPss(cop=composite2COP, para=para, uu=c(0,0), vv=rep(p, 2)) }),
                    col="darkgreen", lty=2, lwd=1) #
## End(Not run)
</code></pre>

<hr>
<h2 id='tailordCOP'>The Lower- and Upper-Tail Orders of a Copula</h2><span id='topic+tailordCOP'></span>

<h3>Description</h3>

<p>Compute the <em>lower-</em> and <em>upper-tail orders</em> (if they exist), respectively, of a copula <code class="reqn">\mathbf{C}(u,v)</code> according to Joe (2014, pp. 67&ndash;70). The <em>tail order</em> is a concept for the strength of dependence in the joint tails of a multivariate distribution. The opposing tails can be compared to assess tail order or <em>reflection symmetry</em> (term by Joe (2014) for Nelsen's (2006, p. 36) term <em>radial symmetry</em>). Joe (2014) provides extensively analytical details but sufficient for the <span class="pkg">copBasic</span> package, the tail orders can be numerically explored.
</p>
<p>The <em>lower-tail order</em> maybe numerically approximated by
</p>
<p style="text-align: center;"><code class="reqn">\kappa^L_\mathbf{C} = \frac{\log[\mathbf{C}(t,t)]}{\log(t)}\mbox{,}</code>
</p>

<p>for some small positive values of <code class="reqn">t</code>, and similarly the <em>upper-tail order</em> maybe numerically approximated by
</p>
<p style="text-align: center;"><code class="reqn">\kappa^U_\mathbf{C} = \frac{\log[\hat{\mathbf{C}}(t,t)]}{\log(t)}\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{\mathbf{C}}(u,v)</code> is the <em>survival copula</em> (<code><a href="#topic+surCOP">surCOP</a></code>). Joe (2014) has potentially(?) conflicting notation in the context of the upper-tail order; the term &ldquo;reflection&rdquo; is used (p. 67) and &ldquo;lower tail order of the reflected copula is the same as the upper tail order of the original copula&rdquo; (p. 69), but Joe (2014, p. 67) only uses the joint survival function (<code><a href="#topic+surfuncCOP">surfuncCOP</a></code>) in the definition of <code class="reqn">\kappa^U_\mathbf{C}</code>.
</p>
<p>As a note, the author of this package was not able to get <code>tailordCOP</code> to function properly for the upper-tail order using the joint survival function as implied on the bottom of Joe (2014, p. 67) and fortunately the fact that &ldquo;reflection&rdquo; is used in other contexts and used in analytical examples, the <code>tailordCOP</code> function uses the lower-tail order of the reflection (survival copula). Joe (2014) also defines <em>tail order parameter</em> <code class="reqn">\Psi</code> but that seems to be a result of analytics and not implemented in this package. Lastly, the tail orders are extendable into <code class="reqn">d</code> dimensions, but only a bivariate (<code class="reqn">d = 2</code>) is provided in <span class="pkg">copBasic</span>. The tail orders have various classifications for <code class="reqn">\kappa = \kappa_L = \kappa_U</code>:
</p>

<dl>
<dt><code class="reqn">\bullet</code></dt><dd><p><em>Intermediate tail dependence</em> for <code class="reqn">1 &lt; \kappa &lt; d</code> or <code class="reqn">\kappa = 1, \Psi = 0</code>;</p>
</dd>
<dt><code class="reqn">\bullet</code></dt><dd><p><em>Strong tail dependence</em> for <code class="reqn">\kappa = 1</code> with <code class="reqn">\Psi &gt; 0</code>; and</p>
</dd>
<dt><code class="reqn">\bullet</code></dt><dd><p><em>Tail orthant independence</em> or <em>tail quadrant independence</em> for <code class="reqn">\kappa = d</code>.</p>
</dd>
</dl>

<p>Joe (2014) provides additional properties:
</p>

<dl>
<dt><code class="reqn">\bullet</code></dt><dd><p><code class="reqn">\kappa_L = \kappa_U = d</code> for the <code class="reqn">d</code>-dimensional <em>independence copula</em> (<code><a href="#topic+P">P</a></code>; <em>e.g.</em> <code>tailordCOP(cop=P)</code>);</p>
</dd>
<dt><code class="reqn">\bullet</code></dt><dd><p>It is not possible for <code class="reqn">\kappa_L &lt; 1</code> or <code class="reqn">\kappa_U &lt; 1</code> but each can be <code class="reqn">&gt; 1</code> for a <code class="reqn">\mathbf{C}(u,v)</code> having some negative dependence (<em>e.g.</em> <code>tailordCOP(cop=PLACKETTcop, para=0.2)</code>; see <code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>); and</p>
</dd>
<dt><code class="reqn">\bullet</code></dt><dd><p>For the bivariate <em>Fréchet&ndash;Hoeffding lower-bound copula</em> (<code><a href="#topic+W">W</a></code>; <em>countermonotonicity copula</em>) the <code class="reqn">\kappa_L = \kappa_U</code> and can be considered <code class="reqn">+\infty</code>. (A special trap in the <code>tailordCOP</code> provides consistency on <code><a href="#topic+W">W</a></code> but does not test that the copula is actually that function itself.)</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>tailordCOP(cop=NULL, para=NULL, tol=1e-6, plot=FALSE, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tailordCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="tailordCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="tailordCOP_+3A_tol">tol</code></td>
<td>
<p>A tolerance on convergence;</p>
</td></tr>
<tr><td><code id="tailordCOP_+3A_plot">plot</code></td>
<td>
<p>A logical plotting a diagnostic plot of the diagonal derivatives and label the limits;</p>
</td></tr>
<tr><td><code id="tailordCOP_+3A_verbose">verbose</code></td>
<td>
<p>Show incremental progress; and</p>
</td></tr>
<tr><td><code id="tailordCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the copula function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> list is returned.
</p>
<table role = "presentation">
<tr><td><code>kappaL</code></td>
<td>
<p>The rounded value of <code class="reqn">\kappa^L_\mathbf{C}</code>;</p>
</td></tr>
<tr><td><code>kappaU</code></td>
<td>
<p>The rounded value of <code class="reqn">\kappa^U_\mathbf{C}</code>;</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source: &ldquo;tailordCOP&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The algorithm implemented for <code>tailordCOP</code> is based on halves (or alternatives by the setting of the <code>divisor</code> argument) and uses the copula function (not an analytical or even numerical derivative of the diagonal, <code class="reqn">\delta_\mathbf{C}'(t)</code>). Starting from the median or <code class="reqn">t = 0.5</code>, each limit is respectively computed by successive halving of the distance towards <code class="reqn">0^{+}</code> and checking the change in computed value against the tolerance <code>tol</code> argument. After the change becomes less than the the <code>tol</code>erance, convergence is assumed. Other tests are made for <code>NaN</code> to aid in breaking the successive halvings. The rounding for the numerical results for <code class="reqn">\kappa^U_\mathbf{C}</code> and <code class="reqn">\kappa^L_\mathbf{C}</code> is an order of magnitude larger than the tolerance.
</p>
<p>Users are encouraged to plot the results and further verify whether the convergence makes sense. The plot produced when <code>plot=TRUE</code> shows the probability <code class="reqn">t</code> transformed into standard normal variates by the <code>qnorm()</code> function in <span class="rlang"><b>R</b></span> so that the distal reaches of each tail and thus limit are readily seen. The terminal points of each limit computation are shown by a small dot, and the letter &ldquo;L&rdquo; and &ldquo;U&rdquo; also are plotted at the terminal points.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>, <code><a href="#topic+tailconCOP">tailconCOP</a></code>, <code><a href="#topic+taildepCOP">taildepCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Joe (2014, p. 5) names MTCJ = Mardia-Takahasi-Cook-Johnson copula
"MTCJ" &lt;- function(u,v, para) { (u^(-para) + v^(-para) - 1)^(-1/para) }
# The results that follow match those reported by Joe (2014, p. 69) who
# analytically derives KappaL = 1 and KappaU = 2.
# TAIL ORDER:
tailordCOP(cop=MTCJ, para=3, plot=TRUE) # kappaL  = 1.00667, kappaU  = 1.96296
# TAIL DEPENDENCY:
taildepCOP(cop=MTCJ, para=3, plot=TRUE) # lambdaL = 0,       lambdaU = 0.7937
# Joe (2014) reports lambdaL = 2^(-1/para) = 2^(-1/3) = 0.7937005
## End(Not run)
</code></pre>

<hr>
<h2 id='tauCOP'>The Kendall Tau and Concordance Function of a Copula</h2><span id='topic+tauCOP'></span><span id='topic+concordCOP'></span>

<h3>Description</h3>

<p>Compute the measure of association known as the <em>Kendall Tau</em> (<code class="reqn">\tau_\mathbf{C}</code>) of a copula (<code class="reqn">\tau_\mathbf{C}</code>) according to Nelsen (2006, sec. 5.1.1 and p. 161) by
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = \mathcal{Q}(\mathbf{C}, \mathbf{C}) = 4\int\!\!\int_{\mathcal{I}^2}
                         \mathbf{C}(u,v)\,\mathrm{d}\mathbf{C}(u,v) - 1\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathcal{Q}(\mathbf{C}, \mathbf{C})</code> is a <em>concordance function</em> (<code>concordCOP</code>) of a copula with itself. Nelsen (2006, p. 164) reports however that this form is often not amenable to computation when there is a singular component to the copula and that the expression
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = 1 - 4\int\!\!\int_{\mathcal{I}^2}
                         \frac{\delta\mathbf{C}(u,v)}{\delta u}
                         \frac{\delta\mathbf{C}(u,v)}{\delta v}\,
                         \mathrm{d}u\mathrm{d}v</code>
</p>

<p>is to be preferred. Such an expression hence relies on the partial numerical derivatives of the copula provided by <code><a href="#topic+derCOP">derCOP</a></code> and <code><a href="#topic+derCOP2">derCOP2</a></code>. The Nelsen (2006) preferred expression is used by the <code>tauCOP</code> function. Nelsen (2006, pp. 175&ndash;176) reports that the relation between <code class="reqn">\tau_\mathbf{C}</code> and <code class="reqn">\rho_\mathbf{C}</code> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) is
<code class="reqn">-1 \le 3\tau - 2\rho \le 1</code> (see <code><a href="#topic+rhoCOP">rhoCOP</a></code> for more details).
</p>
<p>Nelsen (2006, pp. 160&ndash;161) lists some special identities involving <code class="reqn">\mathcal{Q}(\mathbf{C}_1,\mathbf{C}_2)</code>:
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{Q}(\mathbf{M}, \mathbf{M}) = 4\int_0^1 u\,\mathrm{d}u - 1 = 1\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathcal{Q}(\mathbf{M}, \mathbf{\Pi}) = 4\int_0^1 u^2\,\mathrm{d}u - 1 = 1/3\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathcal{Q}(\mathbf{M}, \mathbf{W}) = 4\int_{1/2}^1 (2u-1)\,\mathrm{d}u - 1 = 0\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathcal{Q}(\mathbf{W}, \mathbf{\Pi}) = 4\int_0^1 u(1-u)\,\mathrm{d}u - 1 = -1/3\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathcal{Q}(\mathbf{W}, \mathbf{W}) = 4\int_0^1 0\,\mathrm{d}u - 1 = -1\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mathcal{Q}(\mathbf{\Pi}, \mathbf{\Pi}) = 4\int\!\!\int_{\mathcal{I}^2} uv\,\mathrm{d}u\mathrm{d}v - 1 = 0\mbox{.}</code>
</p>

<p>Kendall Tau also can be expressed in terms of the <em>Kendall Function</em> (<code class="reqn">F_K(z)</code>; <code><a href="#topic+kfuncCOP">kfuncCOP</a></code>):
</p>
<p style="text-align: center;"><code class="reqn">\tau_\mathbf{C} = 3 - 4\int_0^1 F_K(t)\,\mathrm{d}t\mbox{,}</code>
</p>

<p>which is readily verified by code shown in <b>Examples</b>. This definition might be useful if integration errors are encountered for some arbitrary copula and arbitrary parameter set. In fact, should two attempts (see source code) at dual integration of the partial derivatives occur, the implementation switches over to integration of the Kendall Function (<em>e.g.</em> <code>tauCOP(cop=N4212cop, para=2)</code>). Note, Durante and Sempi have erroneously dropped the multiplication by &ldquo;<code class="reqn">4</code>&rdquo; as shown above in their definition of <code class="reqn">\tau_\mathbf{C}</code> as a function of <code class="reqn">F_K(t)</code> (Durante and Sempi, 2015, eq. 3.9.4, p. 121).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tauCOP( cop=NULL,  para=NULL,
       cop2=NULL, para2=NULL, as.sample=FALSE, brute=FALSE, delta=0.002, ...)

concordCOP(cop=NULL,  para=NULL, cop2=NULL, para2=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tauCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_cop2">cop2</code></td>
<td>
<p>A second copula function;</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_para2">para2</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the second copula;</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat\tau</code> by dispatch to <code>cor()</code> function in <span class="rlang"><b>R</b></span> with <code>method = "kendall"</code>;</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_brute">brute</code></td>
<td>
<p>Should brute force be used instead of two nested <code>integrate()</code> functions in <span class="rlang"><b>R</b></span> to perform the double integration;</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\mathrm{d}u</code> and <code class="reqn">\mathrm{d}v</code> for the brute force integration using <code>brute</code>; and</p>
</td></tr>
<tr><td><code id="tauCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass on to <code><a href="#topic+derCOP">derCOP</a></code> and <code><a href="#topic+derCOP2">derCOP2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\tau_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>Although titled for computation of the Kendall Tau, the <code>tauCOP</code> function also is the implementation of the <em>concordance function</em> <code class="reqn">\mathcal{Q}(\mathbf{C}_1, \mathbf{C}_2)</code> (see Nelsen (2006, pp. 158&ndash;159) when given two different copulas and respective parameters as arguments. The function <code>concordCOP</code> just dispatches to <code>tauCOP</code>. A useful relation is
</p>
<p style="text-align: center;"><code class="reqn">\int\!\!\int_{\mathcal{I}^2} \mathbf{C}_1(u,v)\,\mathrm{d}\mathbf{C}_2(u,v) =
      \frac{1}{2} - \int\!\!\int_{\mathcal{I}^2} \frac{\delta}{\delta u}\mathbf{C}_1(u,v)\,\frac{\delta}{\delta v}\mathbf{C}_2(u,v)\,\mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathbf{C}_1(u,v)</code> is the first copula and <code class="reqn">\mathbf{C}_2(u,v)</code> is the second copula.
</p>
<p>Nelsen <em>et al.</em> (2001, p. 281) lists several measures of association defined by the concordance function:<br />
<code class="reqn">\mbox{}\quad\mathrm{1.}\quad\mbox{}</code><code class="reqn">\tau_\mathbf{C} = \quad\ \mathcal{Q}(\mathbf{C}, \mathbf{C})</code> : (Kendall Tau; <code>tauCOP</code>);<br />
<code class="reqn">\mbox{}\quad\mathrm{2.}\quad\mbox{}</code><code class="reqn">\rho_\mathbf{C} = 3\cdot\mathcal{Q}(\mathbf{C}, \mathbf{\Pi})</code> : (Spearman Rho; <code><a href="#topic+rhoCOP">rhoCOP</a></code>);<br />
<code class="reqn">\mbox{}\quad\mathrm{3.}\quad\mbox{}</code><code class="reqn">\gamma_\mathbf{C} = 2\cdot\mathcal{Q}(\mathbf{C}, [\mathbf{M}+\mathbf{W}]/2)</code> : (Gini Gamma; <code><a href="#topic+giniCOP">giniCOP</a></code>); and<br />
<code class="reqn">\mbox{}\quad\mathrm{4.}\quad\mbox{}</code><code class="reqn">\psi_\mathbf{C} = \frac{3}{2}\cdot\mathcal{Q}(\mathbf{C}, \mathbf{M}) - \frac{1}{2}</code> : (Spearman Footrule; <code><a href="#topic+footCOP">footCOP</a></code>).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Durante, F., and Sempi, C., 2015, Principles of copula theory: Boca Raton, CRC Press, 315 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Nelsen, R.B., Quesada-Molina, J.J., Rodríguez-Lallena, J.A., and Úbeda-Flores, M., 2001, Distribution functions of copulas&mdash;A class of bivariate probability integral transforms: Statistics and Probability Letters, v. 54, no. 3, pp. 277&ndash;282.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>,
<code><a href="#topic+hoefCOP">hoefCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+wolfCOP">wolfCOP</a></code>,
<code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>,
<code><a href="#topic+derCOP">derCOP</a></code>, <code><a href="#topic+derCOP2">derCOP2</a></code>, <code><a href="#topic+kfuncCOP">kfuncCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tauCOP(cop=PSP) # 1/3
# Now compute Kendall Tau via integration of the Kendall Function.
# 3 - 4*integrate(function(t) kfuncCOP(t, cop=PSP), 0, 1)$value # 0.3333314
## End(Not run)

## Not run: 
tauCOP(cop=PSP, brute=TRUE) # 0.3306625
# CPU heavy example showing that the dual-integration (fast) results in
# a Kendall Tau that matches a sample version
dotau &lt;- function(n) {
   uv &lt;- simCOP(n=n, cop=PSP, ploton=FALSE, points=FALSE)
   return(cor(uv$U, uv$V, method="kendall"))
}
set.seed(817600)
taus &lt;- replicate(100, dotau(100))
tau.sample &lt;- mean(taus); print(tau.sample) # 0.3342034
## End(Not run)

## Not run: 
# Nelsen (2006, pp. 160-161, numeric results shown thereine)
# The rational values or integers may be derived analytically.
tauCOP(cop=M, cop2=M) #   1, correct
tauCOP(cop=M, cop2=P) # 1/3, correct
tauCOP(cop=P, cop2=M) # 1/3, correct
tauCOP(cop=M, cop2=W) #   0, correct
tauCOP(cop=W, cop2=M) # throws warning, swaps copulas, == tauCOP(M,W)
tauCOP(cop=W, cop2=P) # throws warning, swaps copulas, approx. -1/3
tauCOP(cop=P, cop2=W) # -1/3, correct
tauCOP(cop=P, cop2=P) #    0, correct
tauCOP(cop=M, cop2=W, brute=TRUE) #    0, correct
## End(Not run)

## Not run: 
para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
             para1=0.00395, para2=4.67, alpha=0.9392, beta=0.5699)
tauCOP(cop=composite2COP, para=para) # -0.4671213

para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
             para1=0.14147, para2=20.96, alpha=0.0411, beta=0.6873)
tauCOP(cop=composite2COP, para=para) # +0.1950727

para &lt;- list(cop1=PLACKETTcop,  cop2=PLACKETTcop,
             para1=0.10137, para2=4492.87, alpha=0.0063, beta=0.0167)
# Theoretical attempt fails because para2 is large and thus a singularity
# is emerging and internal copula swapping does not help.
tauCOP(cop=composite2COP, para=para) # fails (0.94+-.01)
tauCOP(cop=composite2COP, para=para, brute=TRUE) # about 0.94+-.01
## End(Not run)
</code></pre>

<hr>
<h2 id='tEVcop'>The t-EV (Extreme Value) Copula</h2><span id='topic+tEVcop'></span>

<h3>Description</h3>

<p>The <em>t-EV copula</em> (Joe, 2014, p. 189) is a limiting form of the <em>t-copula</em> (multivariate t-distribution):
</p>
<p style="text-align: center;"><code class="reqn">
\mathbf{C}_{\rho,\nu}(u,v) = \mathbf{tEV}(u,v; \rho, \nu) =
\mathrm{exp}\bigl(-(x+y) \times B(x/(x+y); \rho, \nu)\bigr)\mbox{,}
</code>
</p>

<p>where <code class="reqn">x = -\log(u)</code>, <code class="reqn">y = -\log(v)</code>, and letting <code class="reqn">\eta = \sqrt{(\nu+1)/(1-\rho^2)}</code> define
</p>
<p style="text-align: center;"><code class="reqn">
B(w; \rho, \nu) = w \times T_{\nu+1}\bigl(\eta[(w/[1-w])^{1/\nu}-\rho]\bigr) + (1-w) \times T_{\nu+1}\bigl(\eta[([1-w]/w)^{1/\nu}-\rho]\bigr)\mbox{,}
</code>
</p>

<p>where <code class="reqn">T_{\nu+1}</code> is the cumulative distribution function of the <em>univariate t-distribution</em> with <code class="reqn">\nu-1</code> degrees of freedom. As <code class="reqn">\nu \rightarrow \infty</code>, the copula weakly converges to the <em>Hüsler&ndash;Reiss copula</em> (<code><a href="#topic+HRcop">HRcop</a></code>) because the t-distribution converges to the normal (see <b>Examples</b> for a study of this copula).
</p>
<p>The <code class="reqn">\mathbf{tEV}(u,v; \rho, \nu)</code> copula is a two-parameter option when working with extreme-value copula. There is a caveat though. Demarta and McNeil (2004) conclude that &ldquo;the parameter of the Gumbel [<code><a href="#topic+GHcop">GHcop</a></code>] or Galambos [<code><a href="#topic+GLcop">GLcop</a></code>] A-functions [the <em>Pickend dependence function</em> and B-function by association] can always be chosen so that the curve is extremely close to that of the t-EV A-function for any values of <code class="reqn">\nu</code> and <code class="reqn">\rho</code>. The implication is that in all situations where the t-EV copula might be deemed an appropriate model then the practitioner can work instead with the simpler Gumbel or Galambos copulas.&rdquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tEVcop(u, v, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tEVcop_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="tEVcop_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="tEVcop_+3A_para">para</code></td>
<td>
<p>A vector (two element) of parameters in <code class="reqn">\rho</code> and <code class="reqn">\nu</code> order; and</p>
</td></tr>
<tr><td><code id="tEVcop_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Note</h3>

<p>Note, Joe (2014) shows <code class="reqn">x = \log(u)</code> (note absence of the minus sign)&mdash;this is not correct.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Demarta, S., and McNeil, A.J., 2004, The t copula and related copulas: International Statistical Review, v. 33, no. 1, pp. 111&ndash;129, <a href="https://doi.org/10.1111/j.1751-5823.2005.tb00254.x">doi:10.1111/j.1751-5823.2005.tb00254.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GHcop">GHcop</a></code>, <code><a href="#topic+GLcop">GLcop</a></code>, <code><a href="#topic+HRcop">HRcop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  tau &lt;- 1/3 # Example from copula::evCopula.Rd
  tev.cop &lt;- copula::tevCopula(copula::iTau(copula::tevCopula(), tau))
  copula::pCopula(c(0.1,.5), copula=tev.cop)         # 0.07811367
  tEVcop(0.1, 0.5, para=slot(tev.cop, "parameters")) # 0.07811367
## End(Not run)

## Not run: 
  nsim &lt;- 2000; pargh &lt;- c(5, 0.5, 0.5)
  UV &lt;- simCOP(nsim, cop=GHcop, para=pargh)
  U &lt;- lmomco::pp(UV[,1], sort=FALSE)
  V &lt;- lmomco::pp(UV[,2], sort=FALSE)
  RT &lt;- mleCOP(u=U, v=V, cop=tEVcop, init.para=c(0.5, log(4)),
               parafn=function(k) return( c(k[1], exp(k[2])) ) )
  partev &lt;- RT$para

  FT &lt;- simCOP(nsim, cop=tEVcop, para=RT$para)

  tauCOP(cop=GHcop,  para=pargh )
  tauCOP(cop=tEVcop, para=partev)

  tauCOP(cop=GHcop,  para=pargh ) # [1] 0.3003678
  tauCOP(cop=tEVcop, para=partev) # [1] 0.3178904

  densityCOPplot(cop=GHcop,  para=pargh)
  densityCOPplot(cop=tEVcop, para=partev, ploton=FALSE, contour.col="red") #
## End(Not run)

## Not run: 
  # A demonstration Joe (2014, p. 190) for which tEvcop() has
  # upper tail dependence parameter as
  para &lt;- c(0.8, 10)
  lamU &lt;- 2 * pt( -sqrt( (para[2]+1) * (1-para[1]) / (1+para[1]) ), para[2]+1)
  "tEVcop.copula" &lt;- function(u,v, para=NULL, ...) {
        if(length(u) == 1) u &lt;- rep(u,length(v)); if(length(v)==1) v &lt;- rep(v,length(u))
        return(copula::pCopula(matrix(c(u,v), ncol=2),
               copula::tevCopula(param=para[1], df=para[2])))
  }
  lamU.copBasic &lt;- taildepCOP(cop=tEVcop,        para)$lambdaU
  lamU.copula   &lt;- taildepCOP(cop=tEVcop.copula, para)$lambdaU
  print(c(lamU, lamU.copBasic, lamU.copula))
  #[1] 0.2925185 0.2925200 0.2925200 # So, we see that they all match.
## End(Not run)

## Not run: 
  # Convergence of tEVcop to HRcop as nu goes to infinity.
  nu &lt;- 10^(seq(-4, 2, by=0.1)) # nu right end point rho dependent
  rho &lt;- 0.7 # otherwise, expect to see 'zeros' errors on the plot()
  # Compute Blomqvist Beta (fast computation is reason for choice)
  btEV &lt;- sapply(nu, function(n) blomCOP(tEVcop, para=c(rho, n)))
  limit.thetas &lt;- sqrt(2 / (nu*(1-rho))) # for nu --&gt; infinity HRcop
  thetas &lt;- sapply(btEV, function(b) {
       uniroot(function(l, blom=NA) { blom - blomCOP(HRcop, para=l) },
       interval=c(0,10), blom=b)$root })
  plot(limit.thetas, thetas, log="xy", type="b",
       xlab="Theta of HRcop via limit nu --&gt; infinity",
       ylab="Theta from Blomqvist Beta equivalent HRcop to tEVcop")
  abline(0,1)
  mtext(paste0("Notice the 'weak' convergence to lower left, and \n",
               "convergence increasing with rho"))
  # Another reference of note
  # https://mediatum.ub.tum.de/doc/1145695/1145695.pdf (p.39) #
## End(Not run)
</code></pre>

<hr>
<h2 id='uvlmoms'>Bivariate Skewness after Joe (2014) or the Univariate L-moments of Combined U and V</h2><span id='topic+uvlmoms'></span><span id='topic+uvskew'></span>

<h3>Description</h3>

<p>Joe (2014, pp. 65&ndash;66) suggests two quantile-based measures of <em>bivariate skewness</em> defined for uniform random variables <code class="reqn">U</code> and <code class="reqn">V</code> combined as either <code class="reqn">\psi_{u+v-1} = u + v - 1</code> or <code class="reqn">\psi_{u-v} = u - v</code> for which the <code class="reqn">\mathrm{E}[u] = \mathrm{E}[v] = 0</code>. The bivariate skewness is the quantity <code class="reqn">\eta</code>:
</p>
<p style="text-align: center;"><code class="reqn">\eta(p; \psi) = \frac{x(1-p) - 2x(\frac{1}{2}) + x(p)}{x(1-p) - x(p)} \mbox{,}</code>
</p>

<p>where <code class="reqn">0 &lt; p &lt; \frac{1}{2}</code>, <code class="reqn">x(F)</code> is the quantile function for nonexceedance probability <code class="reqn">F</code> for either the quantities <code class="reqn">X = \psi_{u+v-1}</code> or <code class="reqn">X = \psi_{u-v}</code> using either the empirical quantile function or a fitted distribution. Joe (2014, p. 66) reports that <code class="reqn">p = 0.05</code> to &ldquo;achieve some sensitivity to the tails.&rdquo;  How these might be related (intuitively) to L-coskew (see function <code>lcomoms2()</code> of the <span class="pkg">lmomco</span> package) of the L-comoments or bivariate L-moments (<code><a href="#topic+bilmoms">bilmoms</a></code>) is unknown, but see the <b>Examples</b> section of <code><a href="#topic+joeskewCOP">joeskewCOP</a></code>.
</p>
<p>Structurally the above definition for <code class="reqn">\eta</code> based on quantiles is oft shown in comparative literature concerning L-moments. But why stop there? Why not compute the L-moments themselves to arbitrary order for <code class="reqn">\eta</code> by either definition (the <code>uvlmoms</code> variation)? Why not fit a distribution to the computed L-moments for estimation of <code class="reqn">x(F)</code>? Or simply compute &ldquo;skewness&rdquo; according to the definition above (the <code>uvskew</code> variation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uvlmoms(u,v=NULL, umv=TRUE, p=NA,   type="gno", getlmoms=TRUE,  ...)

uvskew( u,v=NULL, umv=TRUE, p=0.05, type=6,     getlmoms=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="uvlmoms_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="uvlmoms_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction and if <code>NULL</code> then <code>u</code> is treated as a two column <span class="rlang"><b>R</b></span> <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="uvlmoms_+3A_umv">umv</code></td>
<td>
<p>A logical controlling the computation of <code class="reqn">\psi</code>: <code class="reqn">\psi = u - v</code>  (<code>umv = TRUE</code>) or <code class="reqn">\psi = u + v - 1</code> (<code>umv = FALSE</code>). The <code>"m"</code> is to read &ldquo;minus&rdquo;;</p>
</td></tr>
<tr><td><code id="uvlmoms_+3A_p">p</code></td>
<td>
<p>A suggested <code class="reqn">p</code> value is <code>p = 0.05</code>. If <code>is.na(NA)</code>, then <code>getlmoms</code> is set to <code>TRUE</code> (see below);</p>
</td></tr>
<tr><td><code id="uvlmoms_+3A_type">type</code></td>
<td>
<p>The <code>type</code> argument is mutable, and is a syntax match to the canoncial use in package <span class="pkg">lmomco</span>. Variation from that package however is permitted. Either <code>type</code> is an integer between 1 and 9 selecting one of the nine quantile algorithms described for the <code>quantile</code> function in <span class="rlang"><b>R</b></span>. The default 6 uses the <em>Weibull plotting positions</em> and differs from the <span class="rlang"><b>R</b></span> default of 7. Otherwise <code>type</code> must be a valid distribution abbreviation for the <span class="pkg">lmomco</span> package as in the abbreviation list <code>dist.list</code> function of that package. The <code>gno</code> shown as a default for the generalized normal distribution (see distribution type <code>"gno"</code> in package <span class="pkg">lmomco</span>);</p>
</td></tr>
<tr><td><code id="uvlmoms_+3A_getlmoms">getlmoms</code></td>
<td>
<p>A logical triggering whether the L-moments of either <code class="reqn">\psi_{u+v-1}</code> or <code class="reqn">\psi_{u - v}</code> are returned instead computing the above definition of &ldquo;skewness;&rdquo; and</p>
</td></tr>
<tr><td><code id="uvlmoms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <span class="pkg">lmomco</span> function <code>lmoms</code>, such as the number of L-moments <code>nmoms</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> of the univariate L-moments of <code class="reqn">\eta</code> is returned (see documentation for <code>lmoms</code> in the <span class="pkg">lmomco</span> package). Or the skewness of <code class="reqn">\eta</code> can be either (1) based on the empirical distribution based on plotting positions by the <code>quantile</code> function in <span class="rlang"><b>R</b></span> using the <code>type</code> as described, or (2) based on the fitted quantile function for the parameters of a distribution for the <span class="pkg">lmomco</span> package.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+COP">COP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(234)
UV &lt;- simCOP(n=100, cop=GHcop, para=1.5, graphics=FALSE)
lmr &lt;- uvlmoms(UV); print(lmr) # L-kurtosis = 0.16568268
uvskew(UV, p=0.10)             # -0.1271723
uvskew(UV, p=0.10, type="gno") # -0.1467011
## End(Not run)

## Not run: 
pss &lt;- seq(0.01,0.49, by=0.01)
ETA &lt;- sapply(1:length(pss), function(i) uvskew(UV, p=pss[i], type=5, uvm1=FALSE) )
plot(pss, ETA, type="l", xlab="P FACTOR", ylab="BIVARIATE SKEWNESS") #
## End(Not run)
</code></pre>

<hr>
<h2 id='vuongCOP'>The Vuong Procedure for Parametric Copula Comparison</h2><span id='topic+vuongCOP'></span>

<h3>Description</h3>

<p>Perform the <em>Vuong Procedure</em> following Joe (2014, pp. 257&ndash;258). Consider two copula densities <code class="reqn">f_1 = c_1(u,v; \Theta_1)</code> and <code class="reqn">f_2 = c_2(u,v; \Theta_2)</code> for two different bivariate copulas <code class="reqn">\mathbf{C}_1(\Theta_1)</code> and <code class="reqn">\mathbf{C}_2(\Theta_2)</code> having respective parameters <code class="reqn">\Theta_1</code> and <code class="reqn">\Theta_2</code> that provide the &ldquo;closest&rdquo; <em>Kullback&ndash;Leibler Divergence</em> from the true copula density <code class="reqn">g(u,v)</code>.
</p>
<p>The difference of the Kullback&ndash;Leibler Divergence (<code><a href="#topic+kullCOP">kullCOP</a></code>) of the two copulas from the true copula density can be measured for a sample of size <code class="reqn">n</code> and bivariate sample realizations <code class="reqn">\{u_i, v_i\}</code> by
</p>
<p style="text-align: center;"><code class="reqn">\hat{D}_{12} = n^{-1}\sum_{i=1}^n D_i\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{D}_{12}</code> is referred to in the <span class="pkg">copBasic</span> package as the &ldquo;Vuong <code class="reqn">D</code>&rdquo; and <code class="reqn">D_i</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">D_i = \log\biggl[\frac{f_1(u_i, v_i; \Theta_2)}{f_2(u_i, v_i; \Theta_1)}\biggr]\mbox{.}</code>
</p>

<p>The variance of <code class="reqn">\hat{D}_{12}</code> can be estimated by
</p>
<p style="text-align: center;"><code class="reqn">\hat\sigma^2_{12} = (n-1)^{-1}\sum_{i=1}^n (D_i - \hat{D}_{12})^2\mbox{.}</code>
</p>

<p>The sample estimate and variance are readily turned into the <code class="reqn">100{{\times}}(1 - \alpha)</code> confidence interval by
</p>
<p style="text-align: center;"><code class="reqn">\hat{D}^{(\mathrm{lo})}_{12} &lt; \hat{D}_{12} &lt; \hat{D}^{(\mathrm{hi})}_{12}\mbox{,}</code>
</p>

<p>where, using the quantile (inverse) function of the t-distribution <code class="reqn">\sim</code> <code class="reqn">\mathcal{T}^{(-1)}(F; \mathrm{df}{=}(n-2))</code> for nonexceedance probability <code class="reqn">F</code> and <code class="reqn">n-2</code> degrees of freedom for <code class="reqn">n</code> being the sample size, the confidence interval is
</p>
<p style="text-align: center;"><code class="reqn">\hat{D}_{12}-\mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n} &lt; \hat{D}_{12} &lt; \hat{D}_{12}+\mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n}\mbox{.}</code>
</p>

<p>Joe (2014, p. 258) reports other interval forms based (1) on the Akaike (AIC) correction and (2) on the Schwarz (BIC) correction, which are defined for AIC as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{AIC} = \hat{D}_{12} - (2n)^{-1}\log(n)\biggl[\mathrm{dim}(\Theta_2) - \mathrm{dim}(\Theta_1)\biggr]\pm \mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n}\mbox{,}</code>
</p>

<p>and for BIC as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{BIC} = \hat{D}_{12} - (2n)^{-1}\log(n)\biggl[\mathrm{dim}(\Theta_2) - \mathrm{dim}(\Theta_1)\biggr]\pm \mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n}\mbox{.}</code>
</p>

<p>The AIC and BIC corrections incorporate the number of parameters in the copula and for all else being equal the copula with the fewer parameters is preferable. If the two copulas being compared have equal number of parameters than the AIC and BIC equate to <code class="reqn">\hat{D}_{12}</code> and the same confidence interval because the difference <code class="reqn">[\mathrm{dim}(\Theta_2) - \mathrm{dim}(\Theta_1)]</code> is zero.
</p>
<p>Joe (2014, p. 258) reports that these three intervals can be used for <em>diagnostic inference</em> as follows. If an interval contains 0 (zero), then copulas <code class="reqn">\mathbf{C}_1(\Theta_1)</code> and <code class="reqn">\mathbf{C}_2(\Theta_2)</code> are not considered significantly different. If the interval does not contain 0, then copula <code class="reqn">\mathbf{C}_1(\Theta_1)</code> or <code class="reqn">\mathbf{C}_2(\Theta_2)</code> is the better fit depending on whether the interval is completely below 0 (thus <code class="reqn">\mathbf{C}_1(\Theta_1)</code> better fit) or above 0 (thus <code class="reqn">\mathbf{C}_2(\Theta_2)</code> better fit), respectively. Joe (2014) goes on the emphasize that &ldquo;the procedure compares different [copulas] and assesses whether they provide similar fits to the data. [The procedure] does not assess whether [either copula] is a good enough fit.&rdquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vuongCOP(u, v=NULL, cop1=NULL, cop2=NULL, para1=NULL, para2=NULL,
                    alpha=0.05, method=c("D12", "AIC", "BIC"),
                    the.zero=.Machine$double.eps^0.25, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vuongCOP_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction and if <code>NULL</code> then <code>u</code> is treated as a two column <span class="rlang"><b>R</b></span> <code>data.frame</code>;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_cop1">cop1</code></td>
<td>
<p>A copula function corresponding to copula <code class="reqn">f_1</code> in the Vuong Procedure;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_para1">para1</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula <code class="reqn">f_1</code>;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_cop2">cop2</code></td>
<td>
<p>A copula function corresponding to copula <code class="reqn">f_2</code> in the the Vuong Procedure;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_para2">para2</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula <code class="reqn">f_2</code>;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_alpha">alpha</code></td>
<td>
<p>The <code class="reqn">\alpha</code> in the Vuong Procedure, which results in the <code class="reqn">100{\times}(1 - \alpha)</code> confidence interval (two sided);</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_method">method</code></td>
<td>
<p>The interval to evaluate as to position of the respective statistic form the comparison of the two copulas;</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_the.zero">the.zero</code></td>
<td>
<p>The value for &ldquo;the zero&rdquo; of the copula density function. This argument is the argument of the same name for <code><a href="#topic+densityCOP">densityCOP</a></code>. The default here is intended to suggest that a tiny nonzero value for density will trap the numerical zero densities; and</p>
</td></tr>
<tr><td><code id="vuongCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code><a href="#topic+densityCOP">densityCOP</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned having the following components:
</p>
<table role = "presentation">
<tr><td><code>title</code></td>
<td>
<p>A descriptive title of the procedure;</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>A textual description of the <code>method</code> setting;</p>
</td></tr>
<tr><td><code>result.text</code></td>
<td>
<p>A textual description of the result of the Vuong Procedure;</p>
</td></tr>
<tr><td><code>result</code></td>
<td>
<p>A value 1 if <code class="reqn">\mathbf{C}_1(\Theta_1)</code> is better fit, 2 if copula <code class="reqn">\mathbf{C}_2(\Theta_2)</code> is better fit, and <code>0</code> if neither is better (<code class="reqn">\hat{D}_{12} = 0</code>), and <code>NA</code> including the likely(?) erroneous situation of <code class="reqn">\mathbf{C}_1(\Theta_1) \equiv \mathbf{C}_2(\Theta_2)</code>;</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The two-sided p-values of the Vuong Procedure inclusive of <code class="reqn">\mathrm{AIC}</code> and <code class="reqn">\mathrm{BIC}</code>;</p>
</td></tr>
<tr><td><code>D12</code></td>
<td>
<p>A named vector of the lower and upper bounds of Vuong <code class="reqn">D</code> at the respective confidence interval percentage along with <code class="reqn">\hat{D}_{12}</code> and <code class="reqn">\sigma^2_{12}</code>;</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>A named vector of the lower and upper bounds of Vuong <code class="reqn">\mathrm{AIC}</code> at the respective confidence interval percentage;</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>A named vector of the lower and upper bounds of Vuong <code class="reqn">\mathrm{BIC}</code> at the respective confidence interval percentage; and</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A named vector of the alpha, sample size, value for the t-distribution quantile <code>qt(1-alpha/2, df=n)</code>, and <code class="reqn">\hat\sigma_{12}</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>vuongCOP</code> function along with <code><a href="#topic+kullCOP">kullCOP</a></code> and features of function <code><a href="#topic+densityCOPplot">densityCOPplot</a></code> represent collective milestones towards <em>copula inference</em> and diagnostics post fitting of copulas to the usual measures of association such as the <em>Kendall Tau</em> (<code class="reqn">\tau_K</code>) and <em>Spearman Rho</em> (<code class="reqn">\rho_S</code>) and their copula counterparts <code class="reqn">\tau_\mathbf{C}</code> (<code><a href="#topic+tauCOP">tauCOP</a></code>) and <code class="reqn">\rho_\mathbf{C}</code> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>).
</p>
<p>For an example application, imagine a problem of say low springflow risk at &ldquo;nearby springs&rdquo; that jointly should converge in the lower tail because drought usually has a strong regional impact. First, it is necessary to form a reflection of the <em>Gumbel&ndash;Hougaard copula</em> (<code class="reqn">\mathbf{GH}(u,v; \Theta_{\mathbf{GH}})</code>; <code><a href="#topic+GHcop">GHcop</a></code>) but parameter estimation using <code class="reqn">\tau_\mathbf{C}</code> is the same because sample <code class="reqn">\hat\tau_K</code> is invariant to reflection.
</p>
<pre>
  "rGHcop" &lt;- function(u,v, ...) { u + v - 1 + GHcop(1-u, 1-v, ...) }
  set.seed(385) # setting so that reported quantities here are reproducible
</pre>
<p>The prior code also sets a seed on the pseudo-random number generator so that reported values here are reproducible. The reflected <code class="reqn">\mathbf{GH}(u,v; \Theta_{\mathbf{GH}})</code> is denoted <code class="reqn">\mathbf{rGH}(u,v; \Theta_{\mathbf{rGH}})</code>.
</p>
<p>Second, the <code class="reqn">\mathbf{PSP}(u,v)</code> copula (<code><a href="#topic+PSP">PSP</a></code>) is chosen as the parent distribution, and this copula has no parameter. The <code class="reqn">\mathbf{PSP}</code> has lower-tail dependency, which will be important as discussion unfolds. The following two lines of code establish a sample size to be drawn from the <code class="reqn">\mathbf{PSP}</code> and then simulates a sample from that copula. The color grey is used for the simulated values on the figure produced by <code><a href="#topic+simCOP">simCOP</a></code>, which forms a background example of the joint structure of the <code class="reqn">\mathbf{PSP}</code> copula.
</p>
<pre>
  n &lt;- 390
  UV &lt;- simCOP(cop=PSP, n=n, col=8, pch=16) # simulate and form the base image
</pre>
<p>By inspection of the so-produced graphic, it is obvious that there is contraction in the lower-left corner of the plot, which is a geometric representation of tail dependency. The lower-tail dependency thus phenomenalogically says that there is joint interconnect during low springflow conditions&mdash;both springs are likely to be at low flow simultaneously. The variable <code>UV</code> contains the bivariate data as uniform variables (nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code>).
</p>
<p>The <em>Plackett copula</em> (<code class="reqn">\mathbf{PL}(u,v; \Theta_{\mathbf{PL}})</code>; <code><a href="#topic+PLACKETTcop">PLACKETTcop</a></code>) and the <code class="reqn">\mathbf{rGH}(u,v; \Theta_{\mathbf{rGH}})</code> copula are chosen as candidate models of the &ldquo;unknown&rdquo; parent. Both <code class="reqn">\mathbf{PL}</code> and <code class="reqn">\mathbf{rGH}</code> copulas use different &ldquo;measures of association&rdquo; for their parameter estimation. Next, sample estimates of the copula parameters using <em>Schweizer and Wolff Sigma</em> <code class="reqn">\hat\sigma_\mathbf{C}</code>. The sample value computations and parameter estimates also are set as shown in the following code:
</p>
<pre>
  Wolf   &lt;- wolfCOP(para=UV, as.sample=TRUE) # 0.496943
  paraPL &lt;- uniroot(function(p)
                Wolf - wolfCOP(cop=PLACKETTcop, para=p), c(1,30))$root
  paraGH &lt;- uniroot(function(p)
                Wolf - wolfCOP(cop=rGHcop,      para=p), c(1,30))$root
</pre>
<p><em>STEP 1&mdash;Compute Kullback&ndash;Leibler sample size:</em> The Kullback&ndash;Leibler Divergences (<code class="reqn">\mathrm{KL}(f {\mid} g)</code> and <code class="reqn">\mathrm{KL}(g {\mid} f)</code>) are computed (<code><a href="#topic+kullCOP">kullCOP</a></code>) for the evaluation of the sample size as appropriate for distinguishing between the two candidate copulas 95 percent of the time. The Kullback&ndash;Leibler sample size (<code class="reqn">n_{f\!g}</code>) also is computed as the following code illustrates and provides additional commentary.
</p>
<pre>
  KL &lt;- replicate(20, kullCOP(cop1=PLcop,  para1=paraPL,       # CPU intensive
                              cop2=rGHcop, para2=paraGH, n=1E5)$KL.sample.size)
  print(round(mean(KL))) #         n_{fg} = 221   sample size
  print(     range(KL))  # 204 &lt;-- n_{fg} --&gt; 252 sample size range
</pre>
<p>Depending on the sample <code class="reqn">\hat\sigma_\mathbf{C}</code> coming from the simulation of the parent <code class="reqn">\mathbf{PSP}</code> copula, the call to <code><a href="#topic+kullCOP">kullCOP</a></code> will likely report different <code class="reqn">n_{f\!g}</code> values because <code class="reqn">n_{f\!g}(\mathbf{C}_1(\Theta_1), \mathbf{C}_1(\Theta_1)</code>. These sample sizes have a range for 20 replications of about <code class="reqn">n_{f\!g}=204{-}252</code>. The result here is <code class="reqn">n_{f\!g}=221</code> and thus <b>the sample size <code class="reqn">n=390</code> should be more than large enough to generally distinguish between the <code class="reqn">\mathbf{PL}</code> and <code class="reqn">\mathbf{rGH}</code> copulas at the respective sample measure of association.</b>
</p>
<p><em>STEP 2&mdash;Perform the Vuong Procedure:</em> The Vuong Procedure can now be completed. Now watch the copula and parameter order in the next code for mistakes, the author has purposefully switched order here to draw attention to the need to make sure argument <code>cop1</code> has the correct parameter(s) for copula 1 (the <code class="reqn">\mathbf{PL}</code>). The two calls to <code><a href="#topic+simCOP">simCOP</a></code> are made to graphically superimpose these simulations on top of the parent <code class="reqn">\mathbf{PSP}</code>.
</p>
<pre>
  VD &lt;- vuongCOP(UV, cop2=rGHcop, para2=paraGH, cop1=PLcop, para1=paraPL)
  print(VD) # "Copula 2 better" or rGHcop (Gumbel-Hougaard is better)
  set.seed(385) # seems harmless enough to reuse the seed to emphasize "fit"
  TMP &lt;-simCOP(cop=PLcop, para=paraPL,n=n,plot=FALSE,col="red",  pch=16,cex=0.5)
  set.seed(385) # seems harmless enough to reuse the seed to emphasize "fit"
  TMP &lt;-simCOP(cop=rGHcop,para=paraGH,n=n,plot=FALSE,col="green",pch=16,cex=0.5)
  rm(TMP) # just cleaning up the workspace.
</pre>
<p>Further discussion of the Vuong Procedure is informative. Simply speaking, the result is that <b>the <code class="reqn">\mathbf{rGH}</code> (copula 2) has better fit than <code class="reqn">\mathbf{PL}</code> (copula 1).</b> The 95-percent confident limits from the procedure for <code class="reqn">\hat{D}_{12} = 0.049</code> with p-value <code class="reqn">0.0012</code>, <code class="reqn">\hat\sigma_{12} = 0.297</code>, and <code class="reqn">n=390</code> are <code class="reqn">0.0194 &lt; \hat{D}_{12} &lt; 0.0786</code>. This interval does not contain zero and is greater than zero and therefore a conclusion may be drawn that copula 2 has the better fit.
</p>
<p><em>STEP 3&mdash;Comparison of lower-tail dependency parameters:</em> What does the tail dependency do for inference? This can be checked by computing the lower-tail dependency parameters (<code class="reqn">\lambda^L_\mathbf{C}</code>; <code><a href="#topic+taildepCOP">taildepCOP</a></code>) in the code that follows for each of the three copulas and the empirical copula with acknowledgment that true sample estimators do not quite exist. Numeric focus need only be on the lower tail, but the four graphics are informative.
</p>
<pre>
  taildepCOP(cop=PSP,                   plot=TRUE)$lambdaL # = 1/2
  taildepCOP(cop=PLcop,    para=paraPL, plot=TRUE)$lambdaL # = ZERO
  taildepCOP(cop=rGHcop,   para=paraGH, plot=TRUE)$lambdaL # = 0.429
  taildepCOP(cop=EMPIRcop, para=UV,     plot=TRUE)$lambdaL # = 0.328
</pre>
<p>The important aspect of the graphics by <code><a href="#topic+taildepCOP">taildepCOP</a></code> is that the <code class="reqn">\mathbf{rGH}</code> has lower-tail dependency whereas the <code class="reqn">\mathbf{PL}</code> does not. So, based on inspection <code class="reqn">\mathbf{rGH}</code> is superior given that we known <code class="reqn">\mathbf{PSP}</code> was the true parent.  The empirical estimate of the <code class="reqn">\hat\lambda^L_\mathbf{C} = 0.328</code> through the <code><a href="#topic+EMPIRcop">EMPIRcop</a></code> copula indicates that its lower-tail dependency is closer to that of the <code class="reqn">\mathbf{rGH}</code> relative to <code class="reqn">\mathbf{PL}</code> and thus <b>quantitatively by lower-tail dependency the <code class="reqn">\mathbf{rGH}</code> has a superior fit.</b>
</p>
<p>Therefore the <code class="reqn">\mathbf{rGH}</code> has a tail dependency more similar to the true model compared to the <code class="reqn">\mathbf{PL}</code>. Hence for this example, the <code class="reqn">\mathbf{rGH}</code> is clearly a superior fitting model in terms of the <em>Vuong Procedure</em> (fit alone) and the <code class="reqn">\lambda^L_\mathbf{C}</code> then is used as a follow up to shown that the <code class="reqn">\mathbf{rGH}</code> might be &ldquo;good enough&rdquo; an approximation to the <code class="reqn">\mathbf{PSP}</code>. The efficacy of reflecting the <code class="reqn">\mathbf{GH}</code> copula into a &ldquo;new&rdquo; form as <code class="reqn">\mathbf{rGH}</code> is demonstrated. Users are strongly encouraged to review the so-produced graphic from the <code><a href="#topic+simCOP">simCOP</a></code> call several listings back for <code class="reqn">n=390</code>, and lastly, this example is one for which absence of the argument <code>snv</code> (standard normal variate [scores]) by <code><a href="#topic+simCOP">simCOP</a></code> makes the tail dependency issue for the sample size more prominent in the graphic.
</p>
<p><em>STEP 4&mdash;Qualitatively compare using copula density plots:</em> Graphical depiction of copula density contours by the <code><a href="#topic+densityCOPplot">densityCOPplot</a></code> function supports the conclusion that the <code class="reqn">\mathbf{rGH}</code> is the superior model relative to the <code class="reqn">\mathbf{PL}</code>. The so-produced graphic obviously shows that <b>the <code class="reqn">\mathbf{rGH}</code> strongly mimics the shape of the parent <code class="reqn">\mathbf{PSP}</code>.</b>
</p>
<pre>
  densityCOPplot(cop=PSP, contour.col=8) # grey is the parent bivariate density
  densityCOPplot(cop=PLcop,  para=paraPL, contour.col="green", ploton=FALSE)
  densityCOPplot(cop=rGHcop, para=paraGH, contour.col="red",   ploton=FALSE)
</pre>
<p><em>STEP 5&mdash;Compute L-comoments of the data via simulation and estimate the sampling distributions:</em> An open research problem is the what if any role that <em>L-comoments</em> might play in either copula estimation or inference. (There being very little literature on the topic?) Because a measure of association was used for parameter estimation, the L-correlation is uniformative, but a comparison is conceptually useful. The <code class="reqn">\hat\sigma_\mathbf{C} = 0.4969</code> and <em>Spearman Rho</em> of the data <code class="reqn">\hat\rho_S</code> and the L-correlations <code class="reqn">\hat\rho_S \approx \tau^{[12]}_{2} \approx \tau^{[21]}_{2} \approx 0.497</code> are all similar as mandated by the mathematics.
</p>
<p>Inference using L-coskew and L-cokurtosis seems possible. The following code listing is CPU intensive. First, the L-correlation, L-coskew, and L-cokurtosis values are computed from the simulated sample by the <code>lcomoms2()</code> function of the <span class="pkg">lmomco</span> package. Second and third, the respective sampling distributions of these L-comoments (<code><a href="#topic+lcomCOPpv">lcomCOPpv</a></code>) for the two copulas are estimated.
</p>
<pre>
  UVlmr &lt;- lmomco::lcomoms2(UV, nmom=4) # The sample L-comoments
  # This execution will result in nonrejection of rGH copula.
  GHlmr &lt;- lcomCOPpv(n, UVlmr, cop=rGHcop,      para=paraGH) # NONREJECTION
  # LcomType      n     Mean  Lscale    Lskew   Lkurt sample.est p.value signif
  #    Tau3[12] 390 -0.06952 0.01819  0.04505 0.12024   -0.11188 0.08795      .
  #    Tau3[21] 390 -0.06739 0.02084  0.04104 0.12917   -0.10673 0.14162      -
  # Tau3[12:21] 390 -0.06845 0.01713  0.04930 0.11696   -0.10931 0.08161      .
  #    Tau4[12] 390  0.04970 0.01682 -0.01635 0.10150    0.04183 0.38996      -
  #    Tau4[21] 390  0.05129 0.01606 -0.06833 0.13798    0.07804 0.17470      -
  # Tau4[12:21] 390  0.05049 0.01329 -0.02045 0.12001    0.05994 0.35069      -

  # This execution will result in rejection of Plackett copula.
  PLlmr &lt;- lcomCOPpv(n, UVlmr, cop=PLACKETTcop, para=paraPL) # REJECT PLACKETT
  #  LcomType     n     Mean  Lscale    Lskew   Lkurt sample.est p.value signif
  #    Tau3[12] 390 -0.00267 0.02133  0.01556 0.09581   -0.11188 0.00129     **
  #    Tau3[21] 390 -0.00112 0.02022 -0.00663 0.13338   -0.10673 0.00189     **
  # Tau3[12:21] 390 -0.00189 0.01757  0.00906 0.10226   -0.10931 0.00019    ***
  #    Tau4[12] 390  0.00153 0.01652 -0.03320 0.12468    0.04183 0.07924      .
  #    Tau4[21] 390  0.00361 0.01851 -0.01869 0.12052    0.07804 0.00929     **
  # Tau4[12:21] 390  0.00257 0.01362 -0.01194 0.10796    0.05994 0.00744     **
</pre>
<p>Because each copula was fit to a measure of association, the p-values for the L-correlations are all nonsignificant (noninformative because of how the copulas were fit), and therefore p-values quite near to the 50th percentile should be produced. So here, the L-correlation is noninformative on fit even though it might have some role because it is asymmetrical unlike that statistics <code class="reqn">\tau_K</code> and <code class="reqn">\rho_S</code>. The results in variable <code>GHlmr</code> show no statistically significant entries (all p-values <code class="reqn">{&gt;}0.05 = (\alpha=0.1)/2)</code>) for L-coskew and L-cokurtosis&mdash;<b>the <code class="reqn">\mathbf{rGH}</code> copula is not rejected.</b> The results in <code>PLlmr</code> show many p-values <code class="reqn">{&lt;}0.05 = (\alpha=0.1)/2</code> for both L-coskew and L-cokurtosis&mdash;<b>the <code class="reqn">\mathbf{PL}</code> copula is rejected</b>. The experimental L-comoment inference shown is consistent with results with the Vuong Procedure.
</p>
<p>The Vuong Procedure, however, does not address adequacy of fit&mdash;it just evaluates which copula fits better. The inspection of the lower tail dependency results previously shown (<code class="reqn">\lambda^L_\mathbf{PSP} = 1/2 \approx \lambda^U_\mathbf{rGH}</code> = 0.429) along with the L-coskew and L-cokurtosis of the sample being well within the sample distribution suggests that the <code class="reqn">\mathbf{rGH}</code> is a adequate mimic of the <code class="reqn">\mathbf{PSP}</code> copula.
</p>
<p>Some open research questions concern the numerical performance of the L-comoments as simulation sample size becomes large and whether or not the L-comoments should be computed on the probabilities <code class="reqn">\{u, v\}</code>. Also should conversion to normal scores be made and if so, should adjustment by the <em>Hazen plotting positions</em> (<code class="reqn">u_i = (r_i - 0.5)/n</code> for rank <code class="reqn">r_i</code>) be made that Joe (2014) repeatedly advocates when standard normal variates (scores) [<code class="reqn">z_i = \Phi^{(-1)}(u_i)</code> for quantile function of standard normal distribution <code class="reqn">\Phi(0,1)</code>]? Collectively, Nelsen (2006) and Salvadori <em>et al.</em> (2007) are both silent on the matter of normal score conversion, and in conclusion Nelsen (2006), Salvadori <em>et al.</em> (2007), and Joe (2014) also are all silent on L-comoment applications with copulas.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature&mdash;An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityCOP">densityCOP</a></code>, <code><a href="#topic+kullCOP">kullCOP</a></code>, <code><a href="#topic+simCOP">simCOP</a></code>, <code><a href="#topic+statTn">statTn</a></code>, <code><a href="#topic+mleCOP">mleCOP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See extended code listings and discussion in the Note section
# See Examples in mleCOP() (Last example therein might suggest a problem in the
# implied 95th percentile associated with n_fg above.
</code></pre>

<hr>
<h2 id='W'>The Fréchet&ndash;Hoeffding Lower-Bound Copula</h2><span id='topic+W'></span>

<h3>Description</h3>

<p>Compute the <em>Fréchet&ndash;Hoeffding lower-bound copula</em> (Nelsen, 2006, p. 11), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{W}(u,v) = \mathrm{max}(u+v-1,0)\mbox{.}</code>
</p>

<p>This is the copula of perfect anti-association (<em>countermonotonicity</em>, <em>perfectly negative dependence</em>) between <code class="reqn">U</code> and <code class="reqn">V</code> and is sometimes referred to as the <em>countermonotonicity copula</em>. Its opposite is the <code class="reqn">\mathbf{M}(u,v)</code> copula (<em>comonotonicity copula</em>; <code><a href="#topic+M">M</a></code>), and statistical <em>independence</em> is the <code class="reqn">\mathbf{\Pi}(u,v)</code> copula (<code><a href="#topic+P">P</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W(u, v, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="W_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="W_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction; and</p>
</td></tr>
<tr><td><code id="W_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+M">M</a></code>, <code><a href="#topic+P">P</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>W(0.41, 0.60) # just barely touching the support, so small, 0.01
W(0.25, 0.45) # no contact with the support, so 0
W(1,    1   ) # total consumption of the support, so 1
</code></pre>

<hr>
<h2 id='W_N5p12a'>Ordinal Sums of Lower-Bound Copula, Example 5.12a of Nelsen's Book</h2><span id='topic+W_N5p12a'></span>

<h3>Description</h3>

<p>Compute shuffles of <em>Fréchet&ndash;Hoeffding lower-bound copula</em> (Nelsen, 2006, p. 173), which is defined by partitioning <code class="reqn">\mathbf{W}</code> within <code class="reqn">\mathcal{I}^2</code> into <code class="reqn">n</code> subintervals:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{W}_n(u,v) = \mathrm{max}\biggl(\frac{k-1}{n}, u+v-\frac{k}{n} \biggr)</code>
</p>

<p>for points within the partitions
</p>
<p style="text-align: center;"><code class="reqn">(u,v) \in \biggl[\frac{k-1}{n}, \frac{k}{n}\biggr]\times \biggl[ \frac{k-1}{n}, \frac{k}{n}\biggr]\mbox{,\ }k = 1,2,\cdots,n</code>
</p>

<p>and for points otherwise out side the partitions
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{W}_n(u,v) = \mathrm{min}(u,v)\mbox{.}</code>
</p>

<p>The support of <code class="reqn">\mathbf{W}_n</code> consists of <code class="reqn">n</code> line segments connecting coordinate pairs <code class="reqn">\{(k-1)/n,\, k/n\}</code> and <code class="reqn">\{k/n,\, (k-1)/n\}</code> as stated by Nelsen (2006). The <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) is defined by <code class="reqn">\rho_\mathbf{C} = 1 - (2/n^2)</code>, and the <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>) by <code class="reqn">\tau_\mathbf{C} = 1 - (2/n)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W_N5p12a(u, v, para=1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="W_N5p12a_+3A_u">u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td></tr>
<tr><td><code id="W_N5p12a_+3A_v">v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction;</p>
</td></tr>
<tr><td><code id="W_N5p12a_+3A_para">para</code></td>
<td>
<p>A positive integer <code class="reqn">n \in 1, 2, \cdots</code>; and</p>
</td></tr>
<tr><td><code id="W_N5p12a_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value(s) for the copula are returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+W">W</a></code>, <code><a href="#topic+ORDSUMcop">ORDSUMcop</a></code>, <code><a href="#topic+ORDSUWcop">ORDSUWcop</a></code>, <code><a href="#topic+M_N5p12b">M_N5p12b</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>W_N5p12a(0.4, 0.6, para=5)

## Not run: 
  # Nelsen (2006, exer. 5.12a, p. 172, fig. 5.3a)
  UV &lt;- simCOP(1000, cop=W_N5p12a, para=4) # which is the same as
  para &lt;- list(cop=c(W, W, W, W), para=NULL, part=c(0,0.25,0.50,0.75,1))
  UV &lt;- simCOP(1000, cop=ORDSUMcop, para=para) 
## End(Not run)
</code></pre>

<hr>
<h2 id='wolfCOP'>The Schweizer and Wolff Sigma of a Copula</h2><span id='topic+wolfCOP'></span>

<h3>Description</h3>

<p>Compute the measure of association known as <em>Schweizer&ndash;Wolff Sigma</em> <code class="reqn">\sigma_\mathbf{C}</code> of a copula according to Nelsen (2006, p. 209) by
</p>
<p style="text-align: center;"><code class="reqn">\sigma_\mathbf{C} = 12\int\!\!\int_{\mathcal{I}^2} \bigl|\mathbf{C}(u,v) - uv\bigr|\,\mathrm{d}u\mathrm{d}v\mbox{,}</code>
</p>

<p>which is <code class="reqn">0 \le \sigma_\mathbf{C} \le 1</code>. It is obvious that this measure of association, without the positive sign restriction, is similar to the following form of <em>Spearman Rho</em> (<code><a href="#topic+rhoCOP">rhoCOP</a></code>) of a copula:
</p>
<p style="text-align: center;"><code class="reqn">\rho_\mathbf{C} = 12\int\!\!\int_{\mathcal{I}^2} \bigl[\mathbf{C}(u,v) - uv\bigr]\,\mathrm{d}u\mathrm{d}v\mbox{.}</code>
</p>

<p>If a copula is <em>positively quadrant dependent</em> (PQD, see <code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code>), then <code class="reqn">\sigma_\mathbf{C} = \rho_\mathbf{C}</code>; conversely if a copula is <em>negatively quadrant dependent</em> (NQD), then <code class="reqn">\sigma_\mathbf{C} = -\rho_\mathbf{C}</code>. However, a feature making <code class="reqn">\sigma_\mathbf{C}</code> especially attractive is that for random variables <code class="reqn">X</code> and <code class="reqn">Y</code>, which are not PQD or NQD&mdash;copulas that are neither larger nor smaller than <code class="reqn">\mathbf{\Pi}</code>&mdash;is that &ldquo;<code class="reqn">\sigma_\mathbf{C}</code> is often a better measure of [dependency] than <code class="reqn">\rho_\mathbf{C}</code>&rdquo; (Nelsen, 2006, p. 209).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wolfCOP(cop=NULL, para=NULL, as.sample=FALSE, brute=FALSE, delta=0.002, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wolfCOP_+3A_cop">cop</code></td>
<td>
<p>A copula function;</p>
</td></tr>
<tr><td><code id="wolfCOP_+3A_para">para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td></tr>
<tr><td><code id="wolfCOP_+3A_as.sample">as.sample</code></td>
<td>
<p>A logical controlling whether an optional <span class="rlang"><b>R</b></span> <code>data.frame</code> in <code>para</code> is used to compute the <code class="reqn">\hat{\sigma}_\mathbf{C}</code> (see <b>Note</b>). If set to <code>-1</code>, then the message concerning CPU effort will be suppressed;</p>
</td></tr>
<tr><td><code id="wolfCOP_+3A_brute">brute</code></td>
<td>
<p>Should brute force be used instead of two nested <code>integrate()</code> functions in <span class="rlang"><b>R</b></span> to perform the double integration;</p>
</td></tr>
<tr><td><code id="wolfCOP_+3A_delta">delta</code></td>
<td>
<p>The <code class="reqn">\mathrm{d}u</code> and <code class="reqn">\mathrm{d}v</code> for the brute force (<code>brute=TRUE</code>) integration; and</p>
</td></tr>
<tr><td><code id="wolfCOP_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for <code class="reqn">\sigma_\mathbf{C}</code> is returned.
</p>


<h3>Note</h3>

<p>A natural estimator for <code class="reqn">\sigma_\mathbf{C}</code> is through the <em>empirical copula</em> (Póczos <em>et al.</em>, 2015) and can be computed as
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}_\mathbf{C} = \frac{12}{n^2 - 1}
        \sum_{i=1}^n\sum_{j=1}^n \bigg|\hat{\mathbf{C}}_n\biggl(\frac{i}{n}, \frac{j}{n}\biggr) -
                 \frac{i}{n}\times\frac{j}{n}\bigg|\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{\mathbf{C}}_n</code> is the simplest empirical copula of
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mathbf{C}}_n\biggl(\frac{i}{n}, \frac{j}{n}\biggr) =
	\frac{1}{n}\{\# \mathrm{\ of\ } (U_k \le U_i, V_k \le V_j)\}</code>
</p>

<p>An extended example is informative. First, declare a composite of two different Plackett copulas (<code><a href="#topic+PLcop">PLcop</a></code>) and simulate a few hundred values:
</p>
<pre>
   para &lt;- list(cop1 =PLcop,  cop2=PLcop,
                para1=0.145, para2=21.9,  alpha=0.81, beta=0.22)
   D &lt;- simCOP(n=300, cop=composite2COP, para=para,
               cex=0.5, col=rgb(0,0,0,0.2), pch=16)
</pre>
<p>Second, show that this copula is globally PQD (<code><a href="#topic+isCOP.PQD">isCOP.PQD</a></code>), but there is a significant local NQD part of <code class="reqn">\mathcal{I}^2</code> space that clearly is NQD.
</p>
<pre>
  PQD &lt;- isCOP.PQD(cop=composite2COP, para=para, uv=D)
  message(PQD$global.PQD) # TRUE
  points(D, col=PQD$local.PQD+2, lwd=2)
</pre>
<p>This composited copula intersects, that is, passes through, the <code><a href="#topic+P">P</a></code> copula. By the logic of Nelsen (2006), then the <code class="reqn">\sigma_\mathbf{C}</code> should be larger than <code class="reqn">\rho_\mathbf{C}</code> as shown below
</p>
<pre>
  wolfCOP(cop=composite2COP, para=para) # 0.08373378 (theoretical)
   rhoCOP(cop=composite2COP, para=para) # 0.02845131 (theoretical)
  hoefCOP(cop=composite2COP, para=para) # 0.08563823 (theoretical)
</pre>
<p>In fact, the output above also shows Schweizer&ndash;Wolff Sigma to be larger than <em>Blomqvist Beta</em> (<code><a href="#topic+blomCOP">blomCOP</a></code>), <em>Gini Gamma</em> (<code><a href="#topic+giniCOP">giniCOP</a></code>), and <em>Kendall Tau</em> (<code><a href="#topic+tauCOP">tauCOP</a></code>). Schweizer&ndash;Wolff Sigma has captured the fact that although the symbols plot near randomly on the figure, the symbol coloring for PQD and NQD clearly shows local dependency differences. The sample version of Sigma is triggered by
</p>
<pre>
  wolfCOP(para=D, as.sample=TRUE) # 0.09278467 (an example sample)
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Póczos, Barnabás, Krishner, Sergey, Pál, Szepesvári, Csaba, and Schneider, Jeff, 2015, Robust nonparametric copula based dependence estimators, accessed on August 11, 2015, at <a href="https://www.cs.cmu.edu/~bapoczos/articles/poczos11nipscopula.pdf">https://www.cs.cmu.edu/~bapoczos/articles/poczos11nipscopula.pdf</a>.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blomCOP">blomCOP</a></code>, <code><a href="#topic+footCOP">footCOP</a></code>, <code><a href="#topic+giniCOP">giniCOP</a></code>,
<code><a href="#topic+hoefCOP">hoefCOP</a></code>, <code><a href="#topic+rhoCOP">rhoCOP</a></code>, <code><a href="#topic+tauCOP">tauCOP</a></code>,
<code><a href="#topic+joeskewCOP">joeskewCOP</a></code>, <code><a href="#topic+uvlmoms">uvlmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
wolfCOP(cop=PSP) # 0.4784176
## End(Not run)

## Not run: 
  n &lt;- 1000; UV &lt;- simCOP(n=n, cop=N4212cop, para=7.53, graphics=FALSE, seed=1)
  wolfCOP(cop=N4212cop, para=7.53) # 0.9884666 (theoretical)
  wolfCOP(para=UV, as.sample=TRUE) # 0.9873274 (  sample   ) 
## End(Not run)

## Not run: 
  # Redo D from Note section above
  para &lt;- list(cop1 =PLcop,  cop2=PLcop,
               para1=0.145, para2=21.9,  alpha=0.81, beta=0.22)
  D &lt;- simCOP(n=300, cop=composite2COP, para=para,
              cex=0.5, col=rgb(0, 0, 0, 0.2), pch=16)
  PQD &lt;- isCOP.PQD(cop=composite2COP, para=para, uv=D)
  the.grid  &lt;- EMPIRgrid(para=D)
  the.persp &lt;- persp(the.grid$empcop, theta=-25, phi=20, shade=TRUE,
                     xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
  empcop &lt;- EMPIRcopdf(para=D) # data.frame of all points
  points(trans3d(empcop$u, empcop$v, empcop$empcop, the.persp),  cex=0.7,
         col=rgb(0, 1-sqrt(empcop$empcop), 1, sqrt(empcop$empcop)), pch=16)
  points(trans3d(empcop$u, empcop$v, empcop$empcop, the.persp),
         col=PQD$local.PQD+1, pch=1)

  layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE), respect = TRUE)
  PQD.NQD.cop &lt;- gridCOP(cop=composite2COP, para=para)
  Pi &lt;- gridCOP(cop=P)
  RHO &lt;- PQD.NQD.cop - Pi; SIG &lt;- abs(RHO)
  the.persp &lt;- persp(PQD.NQD.cop, theta=-25, phi=20, shade=TRUE, cex=0.5,
                 xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
  mtext("The Copula that has local PQD and NQD", cex=0.5)
  the.persp &lt;- persp(Pi, theta=-25, phi=20, shade=TRUE, cex=0.5,
                 xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
  mtext("Independence (Pi)", cex=0.5)
  the.persp &lt;- persp(RHO, theta=-25, phi=20, shade=TRUE, cex=0.5,
                 xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
  mtext("Copula delta: Integrand of Spearman Rho", cex=0.5)
  the.persp &lt;- persp(SIG, theta=-25, phi=20, shade=TRUE, cex=0.5,
                 xlab="U VARIABLE", ylab="V VARIABLE", zlab="COPULA C(u,v)")
  mtext("abs(Copula delta): Integrand of Schweizer-Wolff Sigma", cex=0.5) #
## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
