<!DOCTYPE html><html><head><title>Help for package sdwd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sdwd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sdwd-package'>
<p>Sparse Distance Weighted Discrimination</p></a></li>
<li><a href='#coef.cv.sdwd'><p>compute coefficients from a &quot;cv.sdwd&quot; object</p></a></li>
<li><a href='#coef.sdwd'><p>compute coefficients for the sparse DWD</p></a></li>
<li><a href='#colon'><p>simplified gene expression data from Alon et al. (1999)</p></a></li>
<li><a href='#cv.sdwd'><p>cross-validation for the sparse DWD</p></a></li>
<li><a href='#plot.cv.sdwd'><p>plot the cross-validation curve of the sparse DWD</p></a></li>
<li><a href='#plot.sdwd'><p>plot coefficients for the sparse DWD</p></a></li>
<li><a href='#predict.cv.sdwd'><p>make predictions from a &quot;cv.sdwd&quot; object</p></a></li>
<li><a href='#predict.sdwd'><p>make predictions for the sparse DWD</p></a></li>
<li><a href='#print.sdwd'><p>print an sdwd object</p></a></li>
<li><a href='#sdwd'><p>fit the sparse DWD</p></a></li>
<li><a href='#sdwd-internal'><p>internal sdwd functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sparse Distance Weighted Discrimination</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-10-24</td>
</tr>
<tr>
<td>Author:</td>
<td>Boxiang Wang and Hui Zou</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Boxiang Wang &lt;boxiang-wang@uiowa.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Formulates a sparse distance weighted discrimination (SDWD) for high-dimensional classification and implements a very fast algorithm for computing its solution path with the L1, the elastic-net, and the adaptive elastic-net penalties. More details about the methodology SDWD is seen on Wang and Zou (2016) (&lt;<a href="https://doi.org/10.1080%2F10618600.2015.1049700">doi:10.1080/10618600.2015.1049700</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>Matrix</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, stats, methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-24 07:00:42 UTC; boxiangw</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-27 14:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='sdwd-package'>
Sparse Distance Weighted Discrimination
</h2><span id='topic+sdwd-package'></span>

<h3>Description</h3>

<p>This package implements the generalized coordinate descent (GCD) algorithm to efficiently compute the solution path of the sparse distance weighted discrimination (DWD) at a given fine grid of regularization parameters. Sparse distance weighted discrimination is a high-dimensional margin-based classifier.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> sdwd</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2020-02-16</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Suppose <code>x</code> is the predictors and <code>y</code> is the binary response. With a fixed value <code>lambda2</code>, the package produces the solution path of the sparse DWD over a grid of <code>lambda</code> values. The value of <code>lambda2</code> can be further tuned by cross-validation.
</p>
<p>The package <code><a href="#topic+sdwd">sdwd</a></code> contains five main functions:<br />
<code>sdwd</code><br />
<code>cv.sdwd</code><br />
<code>coef.sdwd</code><br />
<code>plot.sdwd</code><br />
<code>plot.cv.sdwd</code><br />
</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a> <br />
<br />
Marron, J.S., Todd, M.J., Ahn, J. (2007)
&ldquo;Distance-Weighted Discrimination&quot;&quot;, 
<em>Journal of the American Statistical Association</em>, <b>102</b>(408), 1267&ndash;1271.<br />
<a href="https://www.tandfonline.com/doi/abs/10.1198/016214507000001120">https://www.tandfonline.com/doi/abs/10.1198/016214507000001120</a><br />
<br />
Tibshirani, Robert., Bien, J., Friedman, J.,Hastie, T.,Simon,
N.,Taylor, J., and Tibshirani, Ryan. (2012)
Strong Rules for Discarding Predictors in Lasso-type Problems,
<em>Journal of the Royal Statistical Society, Series B</em>, <b>74</b>(2), 245&ndash;266.<br />
<a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2011.01004.x">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2011.01004.x</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
</p>

<hr>
<h2 id='coef.cv.sdwd'>compute coefficients from a &quot;cv.sdwd&quot; object</h2><span id='topic+coef.cv.sdwd'></span>

<h3>Description</h3>

<p>Computes coefficients at chosen values of <code>lambda</code> from the <code><a href="#topic+cv.sdwd">cv.sdwd</a></code> object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.sdwd'
coef(object, s=c("lambda.1se", "lambda.min"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.sdwd_+3A_object">object</code></td>
<td>
<p>A fitted <code><a href="#topic+cv.sdwd">cv.sdwd</a></code> object, obtained by conducting the cross-validation to the sparse DWD model.</p>
</td></tr>
<tr><td><code id="coef.cv.sdwd_+3A_s">s</code></td>
<td>
<p>Value(s) of the L1 tuning parameter <code>lambda</code> for computing coefficients. Default value is <code>"lambda.1se"</code>, which represents the largest <code>lambda</code> value achieving the cross-validation error within one standard error of the minimum. An alternative value is <code>"lambda.min"</code>, which is the <code>lambda</code> incurring the least cross-validation error. <code>s</code> can also be numeric, being taken as the value(s) to be used.</p>
</td></tr>
<tr><td><code id="coef.cv.sdwd_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code><a href="#topic+sdwd">sdwd</a></code>. </p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This function computes the coefficients at the values of <code>lambda</code> suggested by the cross-validation. This function is modified based on the <code>coef.cv</code> function from the <code>glmnet</code> and the <code>gcdnet</code> packages.</p>


<h3>Value</h3>

<p>The returned object depends on the choice of <code>s</code> and the <code>...</code> argument passed on to the <code><a href="#topic+sdwd">sdwd</a></code> method.</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br /></p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.sdwd">cv.sdwd</a></code> and <code><a href="#topic+predict.cv.sdwd">predict.cv.sdwd</a></code> methods.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
colon$x = colon$x[ , 1:100] # this example only uses the first 100 columns 
set.seed(1)
cv = cv.sdwd(colon$x, colon$y, lambda2=1, nfolds=5)
c1 = coef(cv, s="lambda.1se")
</code></pre>

<hr>
<h2 id='coef.sdwd'>compute coefficients for the sparse DWD</h2><span id='topic+coef.sdwd'></span>

<h3>Description</h3>

<p>Computes the coefficients or returns the indices of nonzero coefficients at chosen values of <code>lambda</code> from a fitted <code><a href="#topic+sdwd">sdwd</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdwd'
coef(object, s=NULL, type=c("coefficients","nonzero"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.sdwd_+3A_object">object</code></td>
<td>
<p>A fitted <code><a href="#topic+sdwd">sdwd</a></code> object.</p>
</td></tr>
<tr><td><code id="coef.sdwd_+3A_s">s</code></td>
<td>
<p>Value(s) of the L1 tuning parameter <code>lambda</code> for computing coefficients. Default is the entire <code>lambda</code> sequence obtained by <code><a href="#topic+sdwd">sdwd</a></code>.</p>
</td></tr>
<tr><td><code id="coef.sdwd_+3A_type">type</code></td>
<td>
<p><code>"coefficients"</code> or <code>"nonzero"</code>? <code>"coefficients"</code> computes the coefficients at given values for <code>s</code>; <code>"nonzero"</code> returns a list of the indices of the nonzero coefficients for each value of <code>s</code>. Default is <code>"coefficients"</code>.</p>
</td></tr>
<tr><td><code id="coef.sdwd_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to <code>predict</code>. </p>
</td></tr> 
</table>


<h3>Details</h3>

<p><code>s</code> is the new vector at which predictions are requested. If <code>s</code> is not in the lambda sequence used for fitting the model, the <code>coef</code> function will use linear interpolation to make predictions. The new values are interpolated using a fraction of coefficients from both left and right <code>lambda</code> indices. This function is modified based on the <code>coef</code> function from the <code>gcdnet</code> and the <code>glmnet</code> packages.
</p>


<h3>Value</h3>

<p>Either the coefficients at the requested values of <code>lambda</code>, or a list of the indices of the nonzero coefficients for each <code>lambda</code>.</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.sdwd">predict.sdwd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
fit = sdwd(colon$x, colon$y, lambda2=1)
c1 = coef(fit, type="coef",s=c(0.1, 0.005))
c2 = coef(fit, type="nonzero")
</code></pre>

<hr>
<h2 id='colon'>simplified gene expression data from Alon et al. (1999)</h2><span id='topic+colon'></span>

<h3>Description</h3>

<p>Gene expression data (2000 genes for 62 samples) from a DNA
microarray experiments of colon tissue samples (Alon et al., 1999). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(colon)
</code></pre>


<h3>Details</h3>

<p> This data set contains 62 colon tissue samples with 2000 gene expression levels. Among 62 samples, 40 are tumor tissues (coded 1) and 22 are normal tissues (coded -1).  
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>A matrix of 2000 columns and 62 rows standing for 2000 gene expression levels and 62 colon tissue samples. Each row corresponds to a patient.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>A numeric vector of length 62 representing the tissue type (1 for tumor; -1 for normal).</p>
</td></tr>
</table>


<h3>Source</h3>

<p>The data were introduced in Alon et al. (1999).</p>


<h3>References</h3>

<p>Alon, U., Barkai, N., Notterman, D.A., Gish, K., Ybarra, S., Mack, D., and Levine, A.J. (1999).
&ldquo;Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays&rdquo;,
<em>Proceedings of the National Academy of Sciences</em>, <b>96</b>(12), 6745&ndash;6750.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load sdwd library
library(sdwd)

# load data set
data(colon)

# how many samples and how many predictors?
dim(colon$x)

# how many samples of class -1 and 1 respectively?
sum(colon$y == -1)
sum(colon$y == 1)
</code></pre>

<hr>
<h2 id='cv.sdwd'>cross-validation for the sparse DWD</h2><span id='topic+cv.sdwd'></span>

<h3>Description</h3>

<p>Conducts a k-fold cross-validation for <code><a href="#topic+sdwd">sdwd</a></code> and returns the suggested values of the L1 parameter <code>lambda</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.sdwd(x, y, lambda = NULL, pred.loss = c("misclass", "loss"), nfolds = 5, foldid, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.sdwd_+3A_x">x</code></td>
<td>
<p>A matrix of predictors, i.e., the <code>x</code> matrix used in <code><a href="#topic+sdwd">sdwd</a></code>.</p>
</td></tr>
<tr><td><code id="cv.sdwd_+3A_y">y</code></td>
<td>
<p>A vector of binary class labels, i.e., the <code>y</code> used in <code><a href="#topic+sdwd">sdwd</a></code>.</p>
</td></tr>
<tr><td><code id="cv.sdwd_+3A_lambda">lambda</code></td>
<td>
<p>Default is <code>NULL</code>, and the sequence generated by <code><a href="#topic+sdwd">sdwd</a></code> is used. User can also provide a new <code>lambda</code> sequence to use in cross-validation.</p>
</td></tr>
<tr><td><code id="cv.sdwd_+3A_pred.loss">pred.loss</code></td>
<td>
<p><code>misclass</code> for classification error, <code>loss</code> for DWD loss.</p>
</td></tr>
<tr><td><code id="cv.sdwd_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds. Default value is 5. The allowable range is from 3 to the sample size. Larger <code>nfolds</code> needs more timing.</p>
</td></tr>
<tr><td><code id="cv.sdwd_+3A_foldid">foldid</code></td>
<td>
<p>An optional vector with values between 1 and <code>nfold</code>, representing the folder indices for each observation. If supplied, <code>nfold</code> can be missing.</p>
</td></tr>
<tr><td><code id="cv.sdwd_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code><a href="#topic+sdwd">sdwd</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function runs <code><a href="#topic+sdwd">sdwd</a></code> to the sparse DWD by excluding every fold alternatively, and then computes the mean cross-validation error and the standard deviation. This function is modified based on the <code>cv</code> function from the <code>gcdnet</code> and the <code>glmnet</code> packages.
</p>


<h3>Value</h3>

<p>A <code><a href="#topic+cv.sdwd">cv.sdwd</a></code> object is returned, which includes the cross-validation fit.
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The <code>lambda</code> sequence used in <code><a href="#topic+sdwd">sdwd</a></code>.</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>A vector of length <code>length(lambda)</code> for the mean cross-validated error.</p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>A vector of length <code>length(lambda)</code> for estimates of standard error of <code>cvm</code>.</p>
</td></tr>
<tr><td><code>cvupper</code></td>
<td>
<p>The upper curve: <code>cvm + cvsd</code>.</p>
</td></tr>
<tr><td><code>cvlower</code></td>
<td>
<p>The lower curve: <code>cvm - cvsd</code>.</p>
</td></tr>
<tr><td><code>nzero</code></td>
<td>
<p>Numbers of non-zero coefficients at each <code>lambda</code>.</p>
</td></tr>
<tr><td><code>name</code></td>
<td>
<p>&ldquo;Mis-classification error&quot;, for plotting purposes.</p>
</td></tr>
<tr><td><code>sdwd.fit</code></td>
<td>
<p>A fitted <code><a href="#topic+sdwd">sdwd</a></code> object using the full data.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>The <code>lambda</code> incurring the minimum cross validation error <code>cvm</code>.</p>
</td></tr>
<tr><td><code>lambda.1se</code></td>
<td>
<p>The largest value of <code>lambda</code> such that error is within one standard error of the minimum.</p>
</td></tr>
<tr><td><code>cv.min</code></td>
<td>
<p>The minimum cross-validation error.</p>
</td></tr>
<tr><td><code>cv.1se</code></td>
<td>
<p>The cross-validation error associated with <code>lambda.1se</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br />
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sdwd">sdwd</a></code>, <code><a href="#topic+plot.cv.sdwd">plot.cv.sdwd</a></code>, <code><a href="#topic+predict.cv.sdwd">predict.cv.sdwd</a></code>, and <code><a href="#topic+coef.cv.sdwd">coef.cv.sdwd</a></code> methods.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
colon$x = colon$x[ , 1:100] # this example only uses the first 100 columns 
n = nrow(colon$x)
set.seed(1)
id = sample(n, trunc(n/3))
cvfit = cv.sdwd(colon$x[-id, ], colon$y[-id], lambda2=1, nfolds=5)
plot(cvfit)
predict(cvfit, newx=colon$x[id, ], s="lambda.min")
</code></pre>

<hr>
<h2 id='plot.cv.sdwd'>plot the cross-validation curve of the sparse DWD</h2><span id='topic+plot.cv.sdwd'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve against a function of <code>lambda</code> values. The function also provides the upper and lower standard deviation curves.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.sdwd'
plot(x, sign.lambda, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.sdwd_+3A_x">x</code></td>
<td>
<p>A fitted <code><a href="#topic+cv.sdwd">cv.sdwd</a></code> object.</p>
</td></tr>
<tr><td><code id="plot.cv.sdwd_+3A_sign.lambda">sign.lambda</code></td>
<td>
<p>Whether to plot against <code>log(lambda)</code> (default) or its negative if <code>sign.lambda=-1</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.sdwd_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function depicts the cross-validation curves. This function is modified based on the <code>plot.cv</code> function from the <code>glmnet</code> and the <code>gcdnet</code> packages.</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br /></p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.sdwd">cv.sdwd</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
colon$x = colon$x[ , 1:100] # this example only uses the first 100 columns 
set.seed(1)
cv = cv.sdwd(colon$x, colon$y, lambda2=1, nfolds=5)
plot(cv)
</code></pre>

<hr>
<h2 id='plot.sdwd'>plot coefficients for the sparse DWD</h2><span id='topic+plot.sdwd'></span>

<h3>Description</h3>

<p>Plots the solution paths for a fitted <code><a href="#topic+sdwd">sdwd</a></code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdwd'
plot(x, xvar=c("norm", "lambda"), color=FALSE, label=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sdwd_+3A_x">x</code></td>
<td>
<p>A fitted <code><a href="#topic+sdwd">sdwd</a></code> model.</p>
</td></tr>
<tr><td><code id="plot.sdwd_+3A_xvar">xvar</code></td>
<td>
<p>Specifies the X-axis. If <code>xvar == "norm"</code>, plots against the  L1-norm of the coefficients; if <code>xvar == "lambda"</code> against the log-lambda  sequence.</p>
</td></tr>
<tr><td><code id="plot.sdwd_+3A_color">color</code></td>
<td>
<p>If <code>TRUE</code>, plots the curves with rainbow colors; otherwise, with gray colors (default).</p>
</td></tr>
<tr><td><code id="plot.sdwd_+3A_label">label</code></td>
<td>
<p>If <code>TRUE</code>, labels the curves with variable sequence numbers. Default is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="plot.sdwd_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots the solution paths as a coefficient profile plot. This function is modified based on the <code>plot</code> function from the <code>gcdnet</code> and the <code>glmnet</code> packages.
</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
</p>


<h3>See Also</h3>

<p><code>print.sdwd</code>, <code>predict.sdwd</code>, <code>coef.sdwd</code>, <code>plot.sdwd</code>, and <code>cv.sdwd</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
fit = sdwd(colon$x, colon$y)
par(mfrow=c(1,3))
# plots against the L1-norm of the coefficients
plot(fit) 
# plots against the log-lambda sequence
plot(fit, xvar="lambda", label=TRUE)
# plots with colors
plot(fit, color=TRUE)
</code></pre>

<hr>
<h2 id='predict.cv.sdwd'>make predictions from a &quot;cv.sdwd&quot; object</h2><span id='topic+predict.cv.sdwd'></span>

<h3>Description</h3>

<p>This function predicts the class labels of new observations by the sparse DWD at the <code>lambda</code> values suggested by <code><a href="#topic+cv.sdwd">cv.sdwd</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.sdwd'
predict(object, newx, s=c("lambda.1se","lambda.min"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.sdwd_+3A_object">object</code></td>
<td>
<p>A fitted <code><a href="#topic+cv.sdwd">cv.sdwd</a></code> object.</p>
</td></tr>
<tr><td><code id="predict.cv.sdwd_+3A_newx">newx</code></td>
<td>
<p>A matrix of new values for <code>x</code> at which predictions are
to be made. Must be a matrix. See documentation for <code>predict.sdwd</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.sdwd_+3A_s">s</code></td>
<td>
<p>Value(s) of the L1 tuning parameter <code>lambda</code> for making predictions.  Default is the <code>s="lambda.1se"</code> saved on the <code><a href="#topic+cv.sdwd">cv.sdwd</a></code> object. An alternative choice is <code>s="lambda.min"</code>. <code>s</code> can also be numeric, being taken as the value(s) to be used.</p>
</td></tr>
<tr><td><code id="predict.cv.sdwd_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to <code>predict</code>. </p>
</td></tr> </table>


<h3>Details</h3>

<p>This function uses the cross-validation results to making predictions. This function is modified based on the <code>predict.cv</code> function from the <code>glmnet</code> and the <code>gcdnet</code> packages.</p>


<h3>Value</h3>

<p>Predicted class labels or fitted values, depending on the choice of <code>s</code> and the ... argument passed on to the <code><a href="#topic+sdwd">sdwd</a></code> method.</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br /></p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.sdwd">cv.sdwd</a></code>, and <code><a href="#topic+coef.cv.sdwd">coef.cv.sdwd</a></code> methods.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
colon$x = colon$x[ , 1:100] # this example only uses the first 100 columns 
set.seed(1)
cv = cv.sdwd(colon$x, colon$y, lambda2=1, nfolds=5)
predict(cv$sdwd.fit, newx=colon$x[2:5, ], 
  s=cv$lambda.1se, type="class")
</code></pre>

<hr>
<h2 id='predict.sdwd'>make predictions for the sparse DWD</h2><span id='topic+predict.sdwd'></span>

<h3>Description</h3>

<p>This function predicts the binary class labels or the fitted values of an <code><a href="#topic+sdwd">sdwd</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdwd'
predict(object, newx, s=NULL, type=c("class", "link"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sdwd_+3A_object">object</code></td>
<td>
<p>A fitted <code><a href="#topic+sdwd">sdwd</a></code> object.</p>
</td></tr>
<tr><td><code id="predict.sdwd_+3A_newx">newx</code></td>
<td>
<p>A matrix of new values for <code>x</code> at which predictions are to be made. We note that <code>newx</code> must be a matrix, <code>predict</code> function does not accept a vector or other formats of <code>newx</code>.</p>
</td></tr>
<tr><td><code id="predict.sdwd_+3A_s">s</code></td>
<td>
<p>Value(s) of the L1 tuning parameter <code>lambda</code> for computing coefficients. Default is the entire <code>lambda</code> sequence obtained by <code><a href="#topic+sdwd">sdwd</a></code>.</p>
</td></tr>
<tr><td><code id="predict.sdwd_+3A_type">type</code></td>
<td>
<p><code>"class"</code> or <code>"link"</code>? <code>"class"</code> produces the predicted binary class labels.<code>"link"</code> returns the fitted values. Default is <code>"class"</code>.</p>
</td></tr>
<tr><td><code id="predict.sdwd_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to <code>predict</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p><code>s</code> stands for the new <code>lambda</code> values for making predictions. If <code>s</code> is not in the original <code>lambda</code> sequence generated by <code><a href="#topic+sdwd">sdwd</a></code>, the <code>predict.sdwd</code> function will use linear interpolation by using a fraction of predicted values from the <code>lambda</code> values in the original sequence adjacent to the <code>s</code> to make predictions. The <code><a href="#topic+predict.sdwd">predict.sdwd</a></code> function is modified based on the <code>predict</code> function from the <code>glmnet</code> and the <code>gcdnet</code> packages.</p>


<h3>Value</h3>

<p>Returns either the predicted class labels or the fitted values, depending on the choice of <code>type</code>.</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.sdwd">coef.sdwd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
fit = sdwd(colon$x, colon$y, lambda2=1)
print(predict(fit ,type="class",newx=colon$x[2:5,]))
</code></pre>

<hr>
<h2 id='print.sdwd'>print an sdwd object</h2><span id='topic+print.sdwd'></span>

<h3>Description</h3>

<p>Print a summary of the <code><a href="#topic+sdwd">sdwd</a></code> solution paths.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdwd'
print(x, digits=max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sdwd_+3A_x">x</code></td>
<td>
<p>A fitted <code><a href="#topic+sdwd">sdwd</a></code> object.</p>
</td></tr>
<tr><td><code id="print.sdwd_+3A_digits">digits</code></td>
<td>
<p>Specify the significant digits.</p>
</td></tr>
<tr><td><code id="print.sdwd_+3A_...">...</code></td>
<td>
<p>Additional print arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function prints a two-column matrix with columns <code>Df</code> and <code>Lambda</code>, where the <code>Df</code> column exhibits the number of nonzero coefficients and the <code>Lambda</code> column displays the corresponding <code>lambda</code> value. This function is modified based on the <code>print</code> function from the <code>gcdnet</code> and the <code>glmnet</code> packages.
</p>


<h3>Value</h3>

<p>A two-column matrix with one column of the number of nonzero coefficients and a second column of <code>lambda</code> values.</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br /> 
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br />
</p>


<h3>See Also</h3>

<p><code>print.sdwd</code>, <code>predict.sdwd</code>, <code>coef.sdwd</code>, <code>plot.sdwd</code>, and <code>cv.sdwd</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(colon)
fit = sdwd(colon$x, colon$y)
print(fit)
</code></pre>

<hr>
<h2 id='sdwd'>fit the sparse DWD</h2><span id='topic+sdwd'></span>

<h3>Description</h3>

<p>Fits the sparse distance weighted discrimination (SDWD) model with imposing L1, elastic-net, or adaptive elastic-net penalties. The solution path is computed at a grid of values of tuning parameter <code>lambda</code>. This function is modified based on the <code>glmnet</code> and the <code>gcdnet</code> packages.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdwd(x, y, nlambda=100, 
     lambda.factor=ifelse(nobs &lt; nvars, 0.01, 1e-04), 
     lambda=NULL, lambda2=0, pf=rep(1, nvars), 
     pf2=rep(1, nvars), exclude, dfmax=nvars + 1, 
     pmax=min(dfmax * 1.2, nvars), standardize=TRUE, 
     eps=1e-8, maxit=1e6, strong=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdwd_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">N</code> rows and <code class="reqn">p</code> columns for predictors.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_y">y</code></td>
<td>
<p>A vector of length <code class="reqn">p</code> for binary responses. The element of <code>y</code> is either -1 or 1.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values, i.e., length of the <code>lambda</code> sequence. Default is 100.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_lambda.factor">lambda.factor</code></td>
<td>
<p>The ratio of the smallest to the largest <code>lambda</code> in the sequence: <code>lambda.factor</code> = <code>min(lambda)</code> / <code>max(lambda)</code>.  <code>max(lambda)</code> is the least <code>lambda</code> to make all coefficients to be zero. The default value of <code>lambda.factor</code> is 0.0001 if <code class="reqn">N &gt;= p</code> or 0.01 if <code class="reqn">N &lt; p</code>. Takes no effect when user specifies a <code>lambda</code> sequence.</p>
</td></tr> 
<tr><td><code id="sdwd_+3A_lambda">lambda</code></td>
<td>
<p>An optional user-supplied <code>lambda</code> sequence. If <code>lambda = NULL</code> (default), the program computes its own <code>lambda</code> sequence based on <code>nlambda</code> and <code>lambda.factor</code>; otherwise, the program uses the user-specified one. Since the program will automatically sort user-defined <code>lambda</code> sequence in decreasing order, it is better to supply a decreasing sequence.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_lambda2">lambda2</code></td>
<td>
<p>The L2 tuning parameter <code class="reqn">\lambda_2</code>.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_pf">pf</code></td>
<td>
<p>A vector of length <code class="reqn">p</code> representing the L1 penalty weights to each coefficient of <code class="reqn">\beta</code> for adaptive L1 or adaptive elastic net. <code>pf</code> can be 0 for some predictor(s), leading to including the predictor(s) all the time. One suggested choice of <code>pf</code> is <code class="reqn">{(\beta + 1/n)}^{-1}</code>, where <code class="reqn">n</code> is the sample size and <code class="reqn">\beta</code> is the coefficents obtained by L1 DWD or enet DWD. Default is 1 for all predictors (and infinity if some predictors are listed in <code>exclude</code>).</p>
</td></tr>
<tr><td><code id="sdwd_+3A_pf2">pf2</code></td>
<td>
<p>A vector of length <code class="reqn">p</code> for L2 penalty factor for adaptive L1 or adaptive elastic net. To allow different L2 shrinkage, user can set <code>pf2</code> to be different L2 penalty weights for each coefficient of <code class="reqn">\beta</code>. <code>pf2</code> can be 0 for some variables, indicating no L2 shrinkage. Default is 1 for all predictors.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_exclude">exclude</code></td>
<td>
<p>Whether to exclude some predictors from the model. This is equivalent to adopting an infinite penalty factor when excluding some predictor. Default is none. </p>
</td></tr>
<tr><td><code id="sdwd_+3A_dfmax">dfmax</code></td>
<td>
<p>Restricts at most how many predictors can be incorporated in the model. Default is <code class="reqn">p+1</code>. This restriction is helpful when <code class="reqn">p</code> is large, provided that a partial path is acceptable. </p>
</td></tr>
<tr><td><code id="sdwd_+3A_pmax">pmax</code></td>
<td>
<p>Restricts the maximum number of variables ever to be nonzero; e.g, once some <code class="reqn">\beta</code> enters the model, it counts once. The count will not change when the <code class="reqn">\beta</code> exits or re-enters the model. Default is <code>min(dfmax*1.2,p)</code>.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_standardize">standardize</code></td>
<td>
<p>Whether to standardize the data. If <code>TRUE</code>, <code><a href="#topic+sdwd">sdwd</a></code> normalizes the predictors such that each column has sum squares<code class="reqn">\sum^N_{i=1}x_{ij}^2/N=1</code> of one. Note that x is always centered (i.e. <code class="reqn">\sum^N_{i=1}x_{ij}=0</code>) no matter <code>standardize</code> is <code>TRUE</code> or <code>FALSE</code>. <code><a href="#topic+sdwd">sdwd</a></code> always returns coefficient <code>beta</code> on the original scale.  Default value is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_eps">eps</code></td>
<td>
<p>The algorithm stops when (i.e. <code class="reqn">4\max_j(\beta_j^{new}-\beta_j^{old})^2</code> is less than <code>eps</code>, where <code class="reqn">j=0,\ldots, p</code>. Defaults value is <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_maxit">maxit</code></td>
<td>
<p>Restricts how many outer-loop iterations are allowed. Default is 1e6. Consider increasing <code>maxit</code> when the algorithm does not converge.</p>
</td></tr>
<tr><td><code id="sdwd_+3A_strong">strong</code></td>
<td>
<p>If <code>TRUE</code>, adopts the strong rule to accelerate the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+sdwd">sdwd</a></code> minimizes the sparse penalized DWD loss function, 
</p>
<p style="text-align: center;"><code class="reqn">L(y, X, \beta)/N + \lambda_1||\beta||_1 + 0.5\lambda_2||\beta||_2^2,</code>
</p>

<p>where <code class="reqn">L(u)=1-u</code> if <code class="reqn">u \le 1/2</code>, <code class="reqn">1/(4u)</code> if <code class="reqn">u &gt; 1/2</code> is the DWD loss. The value of <code>lambda2</code> is user-specified.
</p>
<p>To use the L1 penalty (lasso), set <code>lambda2=0</code>. To use the elastic net, set <code>lambda2</code> as nonzero. To use the adaptive L1, set <code>lambda2=0</code> and specify <code>pf</code> and <code>pf2</code>. To use the adaptive elastic net, set <code>lambda2</code> as nonzero and specify <code>pf</code> and <code>pf2</code> as well.  
</p>
<p>When the algorithm do not converge or run slow, consider increasing <code>eps</code>, decreasing
<code>nlambda</code>, or increasing <code>lambda.factor</code> before increasing
<code>maxit</code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code><a href="#topic+sdwd">sdwd</a></code>.
</p>
<table>
<tr><td><code>b0</code></td>
<td>
<p>A vector of length <code>length(lambda)</code> representing the intercept at each <code>lambda</code> value.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A matrix of dimension <code>p*length(lambda)</code> representing the coefficients at each <code>lambda</code> value. The matrix is stored as a sparse matrix  (<code>Matrix</code> package). To convert it into normal type matrix use <code>as.matrix()</code>.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The number of nonzero coefficients at each <code>lambda</code>.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>The dimension of coefficient matrix, i.e., <code>p*length(lambda)</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The <code>lambda</code> sequence that was actually used.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>Total number of iterations for all lambda values. </p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>Warnings and errors; 0 if no error.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produced this object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent&quot;, <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a><br />
<br />
Marron, J.S., Todd, M.J., and Ahn, J. (2007)
&ldquo;Distance-Weighted Discrimination&quot;, 
<em>Journal of the American Statistical Association</em>, <b>102</b>(408), 1267&ndash;1271.<br />
<a href="https://www.tandfonline.com/doi/abs/10.1198/016214507000001120">https://www.tandfonline.com/doi/abs/10.1198/016214507000001120</a><br />
<br />
Tibshirani, Robert., Bien, J., Friedman, J.,Hastie, T.,Simon,
N.,Taylor, J., and Tibshirani, Ryan. (2012)
Strong Rules for Discarding Predictors in Lasso-type Problems,
<em>Journal of the Royal Statistical Society, Series B</em>, <b>74</b>(2), 245&ndash;266.<br />
<a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2011.01004.x">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2011.01004.x</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
</p>


<h3>See Also</h3>

<p><code>print.sdwd</code>, <code>predict.sdwd</code>, <code>coef.sdwd</code>, <code>plot.sdwd</code>, and <code>cv.sdwd</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the data
data(colon)
# fit the elastic-net penalized DWD with lambda2=1
fit = sdwd(colon$x, colon$y, lambda2=1)
print(fit)
# coefficients at some lambda value
c1 = coef(fit, s=0.005)
# make predictions
predict(fit, newx=colon$x[1:10, ], s=c(0.01, 0.005))

</code></pre>

<hr>
<h2 id='sdwd-internal'>internal sdwd functions</h2><span id='topic+coef.sdwdNET'></span><span id='topic+cv.sdwdNET'></span><span id='topic+cvcompute'></span><span id='topic+err'></span><span id='topic+error.bars'></span><span id='topic+getmin'></span><span id='topic+getoutput'></span><span id='topic+lambda.interp'></span><span id='topic+lamfix'></span><span id='topic+nonzero'></span><span id='topic+sdwdpath'></span><span id='topic+zeromat'></span>

<h3>Description</h3>

<p>Internal sdwd functions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.sdwdNET(outlist, lambda, x, y, foldid, pred.loss)
cvcompute(mat, foldid, nlams)
err(n, maxit, pmax)
error.bars(x, upper, lower, width=0.02, ...)
getmin(lambda, cvm, cvsd)
getoutput(fit, maxit, pmax, nvars, vnames)
lambda.interp(lambda, s)
lamfix(lam)
nonzero(beta, bystep=FALSE)
zeromat(nvars, nalam, vnames, stepnames)
</code></pre>


<h3>Details</h3>

<p>These internal functions are not intended for use by users. <code>coef.sdwdNET</code> computes the coefficient of the <code>sdwd</code> object. <code>cv.sdwdNET</code> does cross-validation for the <code>sdwd</code> object. <code>cvcompute</code> computes the mean and the standard deviation of the cross-validation error. <code>err</code> obtains the error message from fortran code. <code>error.bars</code> helps to plot the cross-validation error curve. <code>getmin</code> addresses the best lambda through the cross-validation either using or not using the one-standard-deviation rule. <code>getoutput</code> organizes the output of the <code>sdwd</code> object. <code>lambda.interp</code> conducts the linear interpolation of the lambdas values to obtain the coefficients at new lambda values. Note the obtained coefficients are not the exact values. <code>lamfix</code> fixes the largest lambda value in the lambda sequence. <code>nonzero</code> and <code>zeromat</code> organize the nonzero coefficients. Most of the aforementioned functions are modified or directly copied from the <code>gcdnet</code> and the <code>glmnet</code> packages.
</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br />
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2016)
&ldquo;Sparse Distance Weighted Discrimination&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>25</b>(3), 826&ndash;838.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700">https://www.tandfonline.com/doi/full/10.1080/10618600.2015.1049700</a><br />
<br />
Yang, Y. and Zou, H. (2013)
&ldquo;An Efficient Algorithm for Computing the HHSVM and Its Generalizations&quot;, 
<em>Journal of Computational and Graphical Statistics</em>, <b>22</b>(2), 396&ndash;415.<br />
<a href="https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324">https://www.tandfonline.com/doi/full/10.1080/10618600.2012.680324</a><br />
<br />
Friedman, J., Hastie, T., and Tibshirani, R. (2010), &quot;Regularization paths for generalized
linear models via coordinate descent,&quot; <em>Journal of Statistical Software</em>, <b>33</b>(1), 1&ndash;22.<br />
<a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
<br />
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
