<!DOCTYPE html><html lang="en"><head><title>Help for package CMLS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CMLS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CMLS-package'>
<p>Constrained Multivariate Least Squares</p></a></li>
<li><a href='#cmls'>
<p>Solve a Constrained Multivariate Least Squares Problem</p></a></li>
<li><a href='#CMLS-internal'><p>Internal 'CMLS' Functions</p></a></li>
<li><a href='#const'>
<p>Print or Return Constraint Options for cmls</p></a></li>
<li><a href='#cv.cmls'>
<p>Cross-Validation for cmls</p></a></li>
<li><a href='#IsplineBasis'>
<p>I-Spline Basis for Monotonic Polynomial Splines</p></a></li>
<li><a href='#mlsei'>
<p>Multivariate Least Squares with Equality/Inequality Constraints</p></a></li>
<li><a href='#mlsun'>
<p>Multivariate Least Squares with Unimodality (and E/I) Constraints</p></a></li>
<li><a href='#MsplineBasis'>
<p>M-Spline Basis for Polynomial Splines</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Constrained Multivariate Least Squares</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>quadprog, parallel</td>
</tr>
<tr>
<td>Description:</td>
<td>Solves multivariate least squares (MLS) problems subject to constraints on the coefficients, e.g., non-negativity, orthogonality, equality, inequality, monotonicity, unimodality, smoothness, etc. Includes flexible functions for solving MLS problems subject to user-specified equality and/or inequality constraints, as well as a wrapper function that implements 24 common constraint options. Also does k-fold or generalized cross-validation to tune constraint options for MLS problems. See ten Berge (1993, ISBN:9789066950832) for an overview of MLS problems, and see Goldfarb and Idnani (1983) &lt;<a href="https://doi.org/10.1007%2FBF02591962">doi:10.1007/BF02591962</a>&gt; for a discussion of the underlying quadratic programming algorithm.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-29 15:23:47 UTC; nate</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-31 17:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='CMLS-package'>
Constrained Multivariate Least Squares
</h2><span id='topic+CMLS-package'></span><span id='topic+CMLS'></span>

<h3>Description</h3>

<p>Solves multivariate least squares (MLS) problems subject to constraints on the coefficients, e.g., non-negativity, orthogonality, equality, inequality, monotonicity, unimodality, smoothness, etc. Includes flexible functions for solving MLS problems subject to user-specified equality and/or inequality constraints, as well as a wrapper function that implements 24 common constraint options. Also does k-fold or generalized cross-validation to tune constraint options for MLS problems. See ten Berge (1993, ISBN:9789066950832) for an overview of MLS problems, and see Goldfarb and Idnani (1983) &lt;doi:10.1007/BF02591962&gt; for a discussion of the underlying quadratic programming algorithm.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> CMLS</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Constrained Multivariate Least Squares</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0-1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-03-29</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> quadprog, parallel</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Solves multivariate least squares (MLS) problems subject to constraints on the coefficients, e.g., non-negativity, orthogonality, equality, inequality, monotonicity, unimodality, smoothness, etc. Includes flexible functions for solving MLS problems subject to user-specified equality and/or inequality constraints, as well as a wrapper function that implements 24 common constraint options. Also does k-fold or generalized cross-validation to tune constraint options for MLS problems. See ten Berge (1993, ISBN:9789066950832) for an overview of MLS problems, and see Goldfarb and Idnani (1983) &lt;doi:10.1007/BF02591962&gt; for a discussion of the underlying quadratic programming algorithm.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
CMLS-package            Constrained Multivariate Least Squares
IsplineBasis            I-Spline Basis for Monotonic Polynomial Splines
MsplineBasis            M-Spline Basis for Polynomial Splines
cmls                    Solve a Constrained Multivariate Least Squares
                        Problem
const                   Print or Return Constraint Options for cmls
cv.cmls                 Cross-Validation for cmls
mlsei                   Multivariate Least Squares with
                        Equality/Inequality Constraints
mlsun                   Multivariate Least Squares with Unimodality
                        (and E/I) Constraints
</pre>
<p>The <code><a href="#topic+cmls">cmls</a></code> function provides a user-friendly interface for solving the MLS problem with 24 common constraint options (the <code><a href="#topic+const">const</a></code> function prints or returns the different contraint options). The <code><a href="#topic+cv.cmls">cv.cmls</a></code> function does k-fold or generalized cross-validation to tune the constraint options of the <code><a href="#topic+cmls">cmls</a></code> function. The <code><a href="#topic+mlsei">mlsei</a></code> function solves the MLS problem subject to user-specified equality and/or inequality (E/I) constraints on the coefficients. The <code><a href="#topic+mlsun">mlsun</a></code> function solves the MLS problem subject to unimodality constraints and user-specified E/I constraints on the coefficients.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>
<p>Maintainer: Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Goldfarb, D., &amp; Idnani, A. (1983). A numerically stable dual method for solving strictly convex quadratic programs. Mathematical Programming, 27, 1-33. <a href="https://doi.org/10.1007/BF02591962">doi:10.1007/BF02591962</a>
</p>
<p>Helwig, N. E. (in prep). Constrained multivariate least squares in R.
</p>
<p>Ten Berge, J. M. F. (1993). Least Squares Optimization in Multivariate Analysis. Volume 25 of M &amp; T Series. DSWO Press, Leiden University. ISBN: 9789066950832
</p>
<p>Turlach, B. A., &amp; Weingessel, A. (2019). quadprog: Functions to solve Quadratic Programming Problems. R package version 1.5-8. https://CRAN.R-project.org/package=quadprog
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for cmls, cv.cmls, mlsei, and mlsun
</code></pre>

<hr>
<h2 id='cmls'>
Solve a Constrained Multivariate Least Squares Problem
</h2><span id='topic+cmls'></span>

<h3>Description</h3>

<p>Finds the <code class="reqn">p</code> x <code class="reqn">m</code> matrix <code>B</code> that minimizes the multivariate least squares problem
</p>

<table>
<tr>
 <td style="text-align: center;">
<code> sum(( Y - X %*% B )^2) </code>
</td>
</tr>

</table>
 
<p>subject to the specified constraints on the rows of <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmls(X, Y, const = "uncons", struc = NULL, 
     z = NULL, df = 10, degree = 3, intercept = TRUE,
     backfit = FALSE, maxit = 1e3, eps = 1e-10, 
     del = 1e-6, XtX = NULL, mode.range = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cmls_+3A_x">X</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="cmls_+3A_y">Y</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">m</code>.</p>
</td></tr>
<tr><td><code id="cmls_+3A_const">const</code></td>
<td>
<p>Constraint code. See <code><a href="#topic+const">const</a></code> for the 24 available options.</p>
</td></tr>
<tr><td><code id="cmls_+3A_struc">struc</code></td>
<td>
<p>Structural constraints (defaults to unstructured). See Note.</p>
</td></tr>
<tr><td><code id="cmls_+3A_z">z</code></td>
<td>
<p>Predictor values for the spline basis (for smoothness constraints). See Note.</p>
</td></tr>
<tr><td><code id="cmls_+3A_df">df</code></td>
<td>
<p>Degrees of freedom for the spline basis (for smoothness constraints). See Note.</p>
</td></tr>
<tr><td><code id="cmls_+3A_degree">degree</code></td>
<td>
<p>Polynomial degree for the spline basis (for smoothness constraints). See Note.</p>
</td></tr>
<tr><td><code id="cmls_+3A_intercept">intercept</code></td>
<td>
<p>Logical indicating whether the spline basis should contain an intercept (for smoothness constraints). See Note.</p>
</td></tr>
<tr><td><code id="cmls_+3A_backfit">backfit</code></td>
<td>
<p>Estimate <code>B</code> via back-fitting (<code>TRUE</code>) or vectorization (<code>FALSE</code>). See Details.</p>
</td></tr>
<tr><td><code id="cmls_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cmls_+3A_eps">eps</code></td>
<td>
<p>Convergence tolerance for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cmls_+3A_del">del</code></td>
<td>
<p>Stability tolerance for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cmls_+3A_xtx">XtX</code></td>
<td>
<p>Crossproduct matrix:  <code>XtX = crossprod(X)</code>.</p>
</td></tr>
<tr><td><code id="cmls_+3A_mode.range">mode.range</code></td>
<td>
<p>Mode search ranges (for unimodal constraints). See Note.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>backfit = FALSE</code> (default), a closed-form solution is used to estimate <code>B</code> whenever possible. Otherwise a back-fitting algorithm is used, where the rows of <code>B</code> are updated sequentially until convergence. The backfitting algorithm is determined to have converged when 
</p>
<p><code>mean((B.new - B.old)^2) &lt; eps * (mean(B.old^2) + del)</code>, 
</p>
<p>where <code>B.old</code> and <code>B.new</code> denote the parameter estimates at iterations <code class="reqn">t</code> and <code class="reqn">t+1</code> of the backfitting algorithm.
</p>


<h3>Value</h3>

<p>Returns the estimated matrix <code>B</code> with attribute &quot;df&quot; (degrees of freedom), which gives the df for each row of <code>B</code>.
</p>


<h3>Note</h3>

<p>Structure constraints (<code>struc</code>) should be specified with a <code class="reqn">p</code> x <code class="reqn">m</code> matrix of logicals (TRUE/FALSE), such that FALSE elements indicate a weight should be constrained to be zero. Default uses unstructured weights, i.e., a <code class="reqn">p</code> x <code class="reqn">m</code> matrix of all TRUE values.
</p>
<p>Inputs <code>z</code>, <code>df</code>, <code>degree</code>, and <code>intercept</code> are only applicable when using one of the 12 constraints that involves a spline basis, i.e., &quot;smooth&quot;, &quot;smonon&quot;, &quot;smoper&quot;, &quot;smpeno&quot;, &quot;ortsmo&quot;, &quot;orsmpe&quot;, &quot;monsmo&quot;, &quot;mosmno&quot;, &quot;unismo&quot;, &quot;unsmno&quot;, &quot;unsmpe&quot;, &quot;unsmpn&quot;.
</p>
<p>Input <code>mode.range</code> is only applicable when using one of the 8 constraints that enforces unimodality: &quot;unimod&quot;, &quot;uninon&quot;, &quot;uniper&quot;, &quot;unpeno&quot;, &quot;unismo&quot;, &quot;unsmno&quot;, &quot;unsmpe&quot;, &quot;unsmpn&quot;. Mode search ranges (<code>mode.range</code>) should be specified with a 2 x <code class="reqn">p</code> matrix of integers such that 
</p>
<p><code>1 &lt;= mode.range[1,j] &lt;= mode.range[2,j] &lt;= m</code> for all <code>j = 1:p</code>. 
</p>
<p>Default is  <code>mode.range = matrix(c(1, m), 2, p)</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Goldfarb, D., &amp; Idnani, A. (1983). A numerically stable dual method for solving strictly convex quadratic programs. Mathematical Programming, 27, 1-33. <a href="https://doi.org/10.1007/BF02591962">doi:10.1007/BF02591962</a>
</p>
<p>Helwig, N. E. (in prep). Constrained multivariate least squares in R.
</p>
<p>Ten Berge, J. M. F. (1993). Least Squares Optimization in Multivariate Analysis. Volume 25 of M &amp; T Series. DSWO Press, Leiden University. ISBN: 9789066950832
</p>
<p>Turlach, B. A., &amp; Weingessel, A. (2019). quadprog: Functions to solve Quadratic Programming Problems. R package version 1.5-8. https://CRAN.R-project.org/package=quadprog
</p>


<h3>See Also</h3>

<p><code><a href="#topic+const">const</a></code> prints/returns the contraint options.
</p>
<p><code><a href="#topic+cv.cmls">cv.cmls</a></code> performs k-fold cross-validation to tune the constraint options.
</p>
<p><code><a href="#topic+mlsei">mlsei</a></code> and <code><a href="#topic+mlsun">mlsun</a></code> are used to implement several of the constraints.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   GENERATE DATA   ######***######

# make X
set.seed(2)
n &lt;- 50
m &lt;- 20
p &lt;- 2
Xmat &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)

# make B (which satisfies all constraints except monotonicity)
x &lt;- seq(0, 1, length.out = m)
Bmat &lt;- rbind(sin(2*pi*x), sin(2*pi*x+pi)) / sqrt(4.75)
struc &lt;- rbind(rep(c(TRUE, FALSE), each = m / 2),
               rep(c(FALSE, TRUE), each = m / 2))
Bmat &lt;- Bmat * struc

# make noisy data
set.seed(1)
Ymat &lt;- Xmat %*% Bmat + rnorm(n*m, sd = 0.25)


######***######   UNCONSTRAINED   ######***######

# unconstrained
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "uncons")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unconstrained and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "uncons", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   NON-NEGATIVITY   ######***######

# non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "nonneg")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "nonneg", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   PERIODICITY   ######***######

# periodic
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "period")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# periodic and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "period", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# periodic and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "pernon")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# periodic and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "pernon", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   SMOOTHNESS   ######***######

# smooth
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smooth")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smooth", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and periodic
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smoper")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and periodic and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smoper", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smonon")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smonon", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and periodic and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smpeno")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# smooth and periodic and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "smpeno", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   ORTHOGONALITY   ######***######

# orthogonal
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "orthog")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthogonal and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "orthog", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthgonal and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "ortnon")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthgonal and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "ortnon", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthogonal and smooth
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "ortsmo")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthogonal and smooth and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "ortsmo", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthogonal and smooth and periodic
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "orsmpe")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# orthogonal and smooth and periodic and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "orsmpe", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   UNIMODALITY   ######***######

# unimodal
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unimod")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unimod", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "uninon")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "uninon", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and periodic
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "uniper")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and periodic and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "uniper", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and periodic and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unpeno")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and periodic and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unpeno", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   UNIMODALITY AND SMOOTHNESS   ######***######

# unimodal and smooth
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unismo")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unismo", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unsmno")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unsmno", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and periodic
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unsmpe")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and periodic and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unsmpe", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and periodic and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unsmpn")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# unimodal and smooth and periodic and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "unsmpn", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")


######***######   MONOTONICITY   ######***######

# make B
x &lt;- 1:m
Bmat &lt;- rbind(1 / (1 + exp(-(x - quantile(x, 0.5)))), 
              1 / (1 + exp(-(x - quantile(x, 0.8)))))
struc &lt;- rbind(rep(c(FALSE, TRUE), c(1 * m, 3 * m) / 4),
               rep(c(FALSE, TRUE), c(m, m) / 2))
Bmat &lt;- Bmat * struc               

# make noisy data
set.seed(1)
Ymat &lt;- Xmat %*% Bmat + rnorm(m*n, sd = 0.25)

# monotonic increasing
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "moninc")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "moninc", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "monnon")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "monnon", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and smooth
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "monsmo")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and smooth and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "monsmo", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and smooth and non-negative
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "mosmno")
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

# monotonic increasing and smooth and non-negative and structured
Bhat &lt;- cmls(X = Xmat, Y = Ymat, const = "mosmno", struc = struc)
mean((Bhat - Bmat)^2)
attr(Bhat, "df")

</code></pre>

<hr>
<h2 id='CMLS-internal'>Internal 'CMLS' Functions</h2><span id='topic+gcvfun'></span><span id='topic+kcvmae'></span><span id='topic+kcvmse'></span><span id='topic+list2bdiag'></span><span id='topic+PseudoInverse'></span><span id='topic+rsinvsqrt'></span><span id='topic+solveQP'></span><span id='topic+solveQPerror'></span>

<h3>Description</h3>

<p>Internal functions for 'CMLS' package.
</p>


<h3>Details</h3>

<p>These functions are not to be called by the user.
</p>

<hr>
<h2 id='const'>
Print or Return Constraint Options for cmls
</h2><span id='topic+const'></span>

<h3>Description</h3>

<p>Prints or returns six letter constraint codes for <code><a href="#topic+cmls">cmls</a></code>, along with corresponding descriptions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>const(x, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="const_+3A_x">x</code></td>
<td>

<p>Vector of six letter constraint codes. If missing, prints/returns all 24 options.
</p>
</td></tr>
<tr><td><code id="const_+3A_print">print</code></td>
<td>

<p>Should constraint information be printed (<code>print = TRUE</code>) or returned as a data frame (<code>print = FALSE</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints (or returns) constraint codes and descriptions.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (in prep). Constrained multivariate least squares in R.
</p>


<h3>See Also</h3>

<p>Constraints are used in the <code><a href="#topic+cmls">cmls</a></code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># print some constraints
const(c("uncons", "smpeno"))

# return some constraints
const(c("uncons", "smpeno"), print = FALSE)

# print all constraints
const()

# return all constraints
const(print = FALSE)

</code></pre>

<hr>
<h2 id='cv.cmls'>
Cross-Validation for cmls
</h2><span id='topic+cv.cmls'></span>

<h3>Description</h3>

<p>Does k-fold or generalized cross-validation to tune the constraint options for <code><a href="#topic+cmls">cmls</a></code>. Tunes the model with respect to any combination of the arguments <code>const</code>, <code>df</code>, <code>degree</code>, and/or <code>intercept</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.cmls(X, Y, nfolds = 2, foldid = NULL, parameters = NULL,
        const = "uncons", df = 10, degree = 3, intercept = TRUE,
        mse = TRUE, parallel = FALSE, cl = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.cmls_+3A_x">X</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_y">Y</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">m</code>.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for k-fold cross-validation. Ignored if <code>foldid</code> argument is provided. Set <code>nfolds=1</code> for generalized cross-validation (GCV).</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_foldid">foldid</code></td>
<td>
<p>Factor or integer vector of length <code class="reqn">n</code> giving the fold identification for each observation.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_parameters">parameters</code></td>
<td>
<p>Parameters for tuning. Data frame with columns <code>const</code>, <code>df</code>, <code>degree</code>, and <code>intercept</code>. See Details.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_const">const</code></td>
<td>
<p>Parameters for tuning. Character vector specifying constraints for tuning. See Details.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_df">df</code></td>
<td>
<p>Parameters for tuning. Integer vector specifying degrees of freedom for tuning. See Details.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_degree">degree</code></td>
<td>
<p>Parameters for tuning. Integer vector specifying polynomial degrees for tuning. See Details.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_intercept">intercept</code></td>
<td>
<p>Parameters for tuning. Logical vector specifying intercepts for tuning. See Details.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_mse">mse</code></td>
<td>
<p>If <code>TRUE</code> (default), the mean squared error is used as the CV loss function. Otherwise the mean absolute error is used.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_parallel">parallel</code></td>
<td>
<p>Logical indicating if <code><a href="parallel.html#topic+parSapply">parSapply</a></code> should be used. See Examples.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_cl">cl</code></td>
<td>
<p>Cluster created by <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>. Only used when <code>parallel = TRUE</code>. Recommended usage: <code>cl = makeCluster(detectCores())</code></p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, tuning progress is printed via <code><a href="utils.html#topic+txtProgressBar">txtProgressBar</a></code>. Ignored if <code>parallel = TRUE</code>.</p>
</td></tr>
<tr><td><code id="cv.cmls_+3A_...">...</code></td>
<td>
<p>Additional arguments to the <code><a href="#topic+cmls">cmls</a></code> function, e.g., <code>z</code>, <code>struc</code>, <code>backfit</code>, etc.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters for tuning can be supplied via one of two options: 
</p>
<p>(A) Using the <code>parameters</code> argument. In this case, the argument <code>parameters</code> must be a data frame with columns <code>const</code>, <code>df</code>, <code>degree</code>, and <code>intercept</code>, where each row gives a combination of parameters for the CV tuning.
</p>
<p>(B) Using the <code>const</code>, <code>df</code>, <code>degree</code>, and <code>intercept</code> arguments. In this case, the <code><a href="base.html#topic+expand.grid">expand.grid</a></code> function is used to create the <code>parameters</code> data frame, which contains all combinations of the arguments <code>const</code>, <code>df</code>, <code>degree</code>, and <code>intercept</code>. Duplicates are removed before the CV tuning.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>best.parameters</code></td>
<td>
<p>Best combination of parameters, i.e., the combination that minimizes the <code>cvloss</code>.</p>
</td></tr>
<tr><td><code>top5.parameters</code></td>
<td>
<p>Top five combinations of parameters, i.e., the combinations that give the five smallest values of the <code>cvloss</code>.</p>
</td></tr>
<tr><td><code>full.parameters</code></td>
<td>
<p>Full set of parameters. Data frame with <code>cvloss</code> (GCV, MSE, or MAE) for each combination of <code>parameters</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (in prep). Constrained multivariate least squares in R.
</p>


<h3>See Also</h3>

<p>See the <code><a href="#topic+cmls">cmls</a></code> and <code><a href="#topic+const">const</a></code> functions for further details on the available constraint options.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># make X
set.seed(1)
n &lt;- 50
m &lt;- 20
p &lt;- 2
Xmat &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)


# make B (which satisfies all constraints except monotonicity)
x &lt;- seq(0, 1, length.out = m)
Bmat &lt;- rbind(sin(2*pi*x), sin(2*pi*x+pi)) / sqrt(4.75)
struc &lt;- rbind(rep(c(TRUE, FALSE), each = m / 2),
               rep(c(FALSE, TRUE), each = m / 2))
Bmat &lt;- Bmat * struc


# make noisy data
Ymat &lt;- Xmat %*% Bmat + rnorm(n*m, sd = 0.5)


# 5-fold CV:  tune df (5,...,15) for const = "smooth"
kcv &lt;- cv.cmls(X = Xmat, Y = Ymat, nfolds = 5,
               const = "smooth", df = 5:15)
kcv$best.parameters
kcv$top5.parameters
plot(kcv$full.parameters$df, kcv$full.parameters$cvloss, t = "b")


## Not run: 

# sample foldid for 5-fold CV
set.seed(2)
foldid &lt;- sample(rep(1:5, length.out = n))


# 5-fold CV:  tune df (5,...,15) w/ all 20 relevant constraints (no struc)
#             using sequential computation (default)
myconst &lt;- as.character(const(print = FALSE)$label[-c(13:16)])
system.time({
  kcv &lt;- cv.cmls(X = Xmat, Y = Ymat, foldid = foldid,
                 const = myconst, df = 5:15)
})
kcv$best.parameters
kcv$top5.parameters


# 5-fold CV:  tune df (5,...,15) w/ all 20 relevant constraints (no struc)
#             using parallel package for parallel computations
myconst &lt;- as.character(const(print = FALSE)$label[-c(13:16)])
system.time({
   cl &lt;- makeCluster(2L)  # using 2 cores
   kcv &lt;- cv.cmls(X = Xmat, Y = Ymat, foldid = foldid,
                  const = myconst, df = 5:15,
                  parallel = TRUE, cl = cl)
   stopCluster(cl)                  
})
kcv$best.parameters
kcv$top5.parameters


# 5-fold CV:  tune df (5,...,15) w/ all 20 relevant constraints (w/ struc)
#             using sequential computation (default)
myconst &lt;- as.character(const(print = FALSE)$label[-c(13:16)])
system.time({
  kcv &lt;- cv.cmls(X = Xmat, Y = Ymat, foldid = foldid,
                 const = myconst, df = 5:15, struc = struc)
})
kcv$best.parameters
kcv$top5.parameters


# 5-fold CV:  tune df (5,...,15) w/ all 20 relevant constraints (w/ struc)
#             using parallel package for parallel computations
myconst &lt;- as.character(const(print = FALSE)$label[-c(13:16)])
system.time({
  cl &lt;- makeCluster(2L)  # using 2 cores
  kcv &lt;- cv.cmls(X = Xmat, Y = Ymat, foldid = foldid,
                 const = myconst, df = 5:15, struc = struc,
                 parallel = TRUE, cl = cl)
  stopCluster(cl)
})
kcv$best.parameters
kcv$top5.parameters


## End(Not run) 

</code></pre>

<hr>
<h2 id='IsplineBasis'>
I-Spline Basis for Monotonic Polynomial Splines
</h2><span id='topic+IsplineBasis'></span>

<h3>Description</h3>

<p>Generate the I-spline basis matrix for a monotonic polynomial spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsplineBasis(x, df = NULL, knots = NULL, degree = 3, intercept = FALSE,
             Boundary.knots = range(x))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IsplineBasis_+3A_x">x</code></td>
<td>

<p>the predictor variable. Missing values are <b>not</b> allowed.
</p>
</td></tr>
<tr><td><code id="IsplineBasis_+3A_df">df</code></td>
<td>

<p>degrees of freedom; if specified the number of <code>knots</code> is defined as <code>df - degree - ifelse(intercept, 1, 0)</code>; the <code>knots</code> are placed at the quantiles of <code>x</code>
</p>
</td></tr>
<tr><td><code id="IsplineBasis_+3A_knots">knots</code></td>
<td>

<p>the internal breakpoints that define the spline (typically the quantiles of <code>x</code>) 
</p>
</td></tr>
<tr><td><code id="IsplineBasis_+3A_degree">degree</code></td>
<td>

<p>degree of the M-spline basis&mdash;default is 3 for cubic splines
</p>
</td></tr>
<tr><td><code id="IsplineBasis_+3A_intercept">intercept</code></td>
<td>

<p>if <code>TRUE</code>, the basis includes an intercept column  
</p>
</td></tr>
<tr><td><code id="IsplineBasis_+3A_boundary.knots">Boundary.knots</code></td>
<td>

<p>boundary points for M-spline basis; defaults to min and max of <code>x</code>  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Syntax is adapted from the <code>bs</code> function in the <b>splines</b> package (R Core Team, 2021).
</p>
<p>Used for implementing monotonic smoothness constraints in the <code><a href="#topic+cmls">cmls</a></code> fucntion.
</p>


<h3>Value</h3>

<p>A matrix of dimension <code>c(length(x), df)</code> where either <code>df</code> was supplied or <code>df = length(knots) + degree + ifelse(intercept, 1, 0)</code>
</p>


<h3>Note</h3>

<p>I-spline basis functions are created by integrating M-spline basis functions.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>R Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/
</p>
<p>Ramsay, J. O. (1988). Monotone regression splines in action. <em>Statistical Science, 3</em>, 425-441. <a href="https://doi.org/10.1214/ss/1177012761">doi:10.1214/ss/1177012761</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MsplineBasis">MsplineBasis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0, 1, length.out = 101)
I &lt;- IsplineBasis(x, df = 8, intercept = TRUE)
plot(x, I[,1], ylim = c(0, 1), t = "l")
for(j in 2:8) lines(x, I[,j], col = j)
</code></pre>

<hr>
<h2 id='mlsei'>
Multivariate Least Squares with Equality/Inequality Constraints
</h2><span id='topic+mlsei'></span>

<h3>Description</h3>

<p>Finds the <code class="reqn">q</code> x <code class="reqn">p</code> matrix <code>B</code> that minimizes the multivariate least squares problem
</p>

<table>
<tr>
 <td style="text-align: center;">
<code> sum(( Y - X %*% t(Z %*% B) )^2) </code>
</td>
</tr>

</table>
 
<p>subject to <code>t(A) %*% B[,j] &gt;= b</code> for all <code>j = 1:p</code>. Unique basis functions and constraints are allowed for each column of <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlsei(X, Y, Z, A, b, meq,
      backfit = FALSE, maxit = 1000, 
      eps = 1e-10, del = 1e-6,
      XtX = NULL, ZtZ = NULL, 
      simplify = TRUE, catchError = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlsei_+3A_x">X</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_y">Y</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">m</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_z">Z</code></td>
<td>
<p>Matrix of dimension <code class="reqn">m</code> x <code class="reqn">q</code>. Can also input a list (see Note). If missing, then <code>Z = diag(m)</code> so that <code class="reqn">q = m</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_a">A</code></td>
<td>
<p>Constraint matrix of dimension <code class="reqn">q</code> x <code class="reqn">r</code>. Can also input a list (see Note). If missing, no constraints are imposed.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_b">b</code></td>
<td>
<p>Consraint vector of dimension <code class="reqn">r</code> x 1. Can also input a list (see Note). If missing, then <code>b = rep(0, r)</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_meq">meq</code></td>
<td>
<p>The first <code>meq</code> columns of <code>A</code> are equality constraints, and the remaining <code>r - meq</code> are inequality constraints. Can also input a vector (see Note). If missing, then <code>meq = 0</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_backfit">backfit</code></td>
<td>
<p>Estimate <code>B</code> via back-fitting (<code>TRUE</code>) or vectorization (<code>FALSE</code>). See Details.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_eps">eps</code></td>
<td>
<p>Convergence tolerance for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_del">del</code></td>
<td>
<p>Stability tolerance for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_xtx">XtX</code></td>
<td>
<p>Crossproduct matrix:  <code>XtX = crossprod(X)</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_ztz">ZtZ</code></td>
<td>
<p>Crossproduct matrix:  <code>ZtZ = crossprod(Z)</code>.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_simplify">simplify</code></td>
<td>
<p>If <code>Z</code> is a list, should <code>B</code> be returned as a matrix (if possible)? See Note.</p>
</td></tr>
<tr><td><code id="mlsei_+3A_catcherror">catchError</code></td>
<td>
<p>If <code>catchError = FASLE</code>, an error induced by <code><a href="quadprog.html#topic+solve.QP">solve.QP</a></code> will be returned. Otherwise <code><a href="base.html#topic+tryCatch">tryCatch</a></code> will be used in attempt to catch the error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>backfit = FALSE</code> (default), a closed-form solution is used to estimate <code>B</code> whenever possible. Otherwise a back-fitting algorithm is used, where the columns of <code>B</code> are updated sequentially until convergence. The backfitting algorithm is determined to have converged when 
</p>
<p><code>mean((B.new - B.old)^2) &lt; eps * (mean(B.old^2) + del)</code>, 
</p>
<p>where <code>B.old</code> and <code>B.new</code> denote the parameter estimates at iterations <code class="reqn">t</code> and <code class="reqn">t+1</code> of the backfitting algorithm.
</p>


<h3>Value</h3>

<p>If <code>Z</code> is a list with <code class="reqn">q_j = q</code> for all <code class="reqn">j = 1,\ldots,p</code>, then...
</p>
<table role = "presentation">
<tr><td><code>B</code></td>
<td>
<p>is returned as a <code class="reqn">q</code> x <code class="reqn">p</code> matrix when <code>simplify = TRUE</code></p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>is returned as a list of length <code class="reqn">p</code> when <code>simplify = FALSE</code></p>
</td></tr>
</table>
<p>If <code>Z</code> is a list with <code class="reqn">q_j \neq q</code> for some <code class="reqn">j</code>, then <code>B</code> is returned as a list of length <code class="reqn">p</code>.
</p>
<p>Otherwise <code>B</code> is returned as a <code class="reqn">q</code> x <code class="reqn">p</code> matrix.
</p>


<h3>Note</h3>

<p>The <code>Z</code> input can also be a list of length <code class="reqn">p</code> where <code>Z[[j]]</code> contains a <code class="reqn">m</code> x <code class="reqn">q_j</code> matrix. If <code class="reqn">q_j = q</code> for all <code class="reqn">j = 1,\ldots,p</code> and <code>simplify = TRUE</code>, the output <code>B</code> will be a matrix. Otherwise <code>B</code> will be a list of length <code class="reqn">p</code> where <code>B[[j]]</code> contains a <code class="reqn">q_j</code> x 1 vector.
</p>
<p>The <code>A</code> and <code>b</code> inputs can also be lists of length <code class="reqn">p</code> where <code>t(A[[j]]) %*% B[,j] &gt;= b[[j]]</code> for all <code class="reqn">j = 1,\ldots,p</code>. If <code>A</code> and <code>b</code> are lists of length <code class="reqn">p</code>, the <code>meq</code> input should be a vector of length <code class="reqn">p</code> indicating the number of equality constraints for each element of <code>A</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Goldfarb, D., &amp; Idnani, A. (1983). A numerically stable dual method for solving strictly convex quadratic programs. Mathematical Programming, 27, 1-33. <a href="https://doi.org/10.1007/BF02591962">doi:10.1007/BF02591962</a>
</p>
<p>Helwig, N. E. (in prep). Constrained multivariate least squares in R.
</p>
<p>Ten Berge, J. M. F. (1993). Least Squares Optimization in Multivariate Analysis. Volume 25 of M &amp; T Series. DSWO Press, Leiden University. ISBN: 9789066950832
</p>
<p>Turlach, B. A., &amp; Weingessel, A. (2019). quadprog: Functions to solve Quadratic Programming Problems. R package version 1.5-8. https://CRAN.R-project.org/package=quadprog
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cmls">cmls</a></code> calls this function for several of the constraints.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   GENERATE DATA   ######***######

# make X
set.seed(2)
n &lt;- 50
m &lt;- 20
p &lt;- 2
Xmat &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)

# make B (which satisfies all constraints except monotonicity)
x &lt;- seq(0, 1, length.out = m)
Bmat &lt;- rbind(sin(2*pi*x), sin(2*pi*x+pi)) / sqrt(4.75)
struc &lt;- rbind(rep(c(TRUE, FALSE), each = m / 2),
               rep(c(FALSE, TRUE), each = m / 2))
Bmat &lt;- Bmat * struc

# make noisy data
set.seed(1)
Ymat &lt;- Xmat %*% Bmat + rnorm(n*m, sd = 0.25)


######***######   UNCONSTRAINED   ######***######

# unconstrained
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "uncons")
Bhat.mlsei &lt;- t(mlsei(X = Xmat, Y = Ymat))
mean((Bhat.cmls - Bhat.mlsei)^2)

# unconstrained and structured (note: cmls is more efficient)
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "uncons", struc = struc)
Amat &lt;- vector("list", p)
meq &lt;- rep(0, p)
for(j in 1:p){
   meq[j] &lt;- sum(!struc[j,])
   if(meq[j] &gt; 0){
      A &lt;- matrix(0, nrow = m, ncol = meq[j])
      A[!struc[j,],] &lt;- diag(meq[j])
      Amat[[j]] &lt;- A
   } else {
      Amat[[j]] &lt;- matrix(0, nrow = m, ncol = 1)
   }
}
Bhat.mlsei &lt;- t(mlsei(X = Xmat, Y = Ymat, A = Amat, meq = meq))
mean((Bhat.cmls - Bhat.mlsei)^2)


######***######   NON-NEGATIVITY   ######***######

# non-negative
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "nonneg")
Bhat.mlsei &lt;- t(mlsei(X = Xmat, Y = Ymat, A = diag(m)))
mean((Bhat.cmls - Bhat.mlsei)^2)

# non-negative and structured (note: cmls is more efficient)
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "nonneg", struc = struc)
eye &lt;- diag(m)
meq &lt;- rep(0, p)
for(j in 1:p){
   meq[j] &lt;- sum(!struc[j,])
   Amat[[j]] &lt;- eye[,sort(struc[j,], index.return = TRUE)$ix]
}
Bhat.mlsei &lt;- t(mlsei(X = Xmat, Y = Ymat, A = Amat, meq = meq))
mean((Bhat.cmls - Bhat.mlsei)^2)


# see internals of cmls.R for further examples

</code></pre>

<hr>
<h2 id='mlsun'>
Multivariate Least Squares with Unimodality (and E/I) Constraints
</h2><span id='topic+mlsun'></span>

<h3>Description</h3>

<p>Finds the <code class="reqn">q</code> x <code class="reqn">p</code> matrix <code>B</code> that minimizes the multivariate least squares problem
</p>

<table>
<tr>
 <td style="text-align: center;">
<code> sum(( Y - X %*% t(Z %*% B) )^2) </code>
</td>
</tr>

</table>
 
<p>subject to <code>Z %*% B[,j]</code> is unimodal and <code>t(A) %*% B[,j] &gt;= b</code> for all <code>j = 1:p</code>. Unique basis functions and constraints are allowed for each column of <code>B</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlsun(X, Y, Z, A, b, meq,
      mode.range = NULL, maxit = 1000, 
      eps = 1e-10, del = 1e-6,
      XtX = NULL, ZtZ = NULL, 
      simplify = TRUE, catchError = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlsun_+3A_x">X</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_y">Y</code></td>
<td>
<p>Matrix of dimension <code class="reqn">n</code> x <code class="reqn">m</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_z">Z</code></td>
<td>
<p>Matrix of dimension <code class="reqn">m</code> x <code class="reqn">q</code>. Can also input a list (see Note). If missing, then <code>Z = diag(m)</code> so that <code class="reqn">q = m</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_a">A</code></td>
<td>
<p>Constraint matrix of dimension <code class="reqn">q</code> x <code class="reqn">r</code>. Can also input a list (see Note). If missing, no equality/inequality (E/I) constraints are imposed.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_b">b</code></td>
<td>
<p>Consraint vector of dimension <code class="reqn">r</code> x 1. Can also input a list (see Note). If missing, then <code>b = rep(0, r)</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_meq">meq</code></td>
<td>
<p>The first <code>meq</code> columns of <code>A</code> are equality constraints, and the remaining <code>r - meq</code> are inequality constraints. Can also input a vector (see Note). If missing, then <code>meq = 0</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_mode.range">mode.range</code></td>
<td>
<p>Mode search ranges, which should be a 2 x <code class="reqn">p</code> matrix of integers such that <code>1 &lt;= mode.range[1,j] &lt;= mode.range[2,j] &lt;= m</code> for all <code>j = 1:p</code>. Default is  <code>mode.range = matrix(c(1, m), 2, p)</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_eps">eps</code></td>
<td>
<p>Convergence tolerance for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_del">del</code></td>
<td>
<p>Stability tolerance for back-fitting algorithm. Ignored if <code>backfit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_xtx">XtX</code></td>
<td>
<p>Crossproduct matrix:  <code>XtX = crossprod(X)</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_ztz">ZtZ</code></td>
<td>
<p>Crossproduct matrix:  <code>ZtZ = crossprod(Z)</code>.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_simplify">simplify</code></td>
<td>
<p>If <code>Z</code> is a list, should <code>B</code> be returned as a matrix (if possible)? See Note.</p>
</td></tr>
<tr><td><code id="mlsun_+3A_catcherror">catchError</code></td>
<td>
<p>If <code>catchError = FASLE</code>, an error induced by <code><a href="quadprog.html#topic+solve.QP">solve.QP</a></code> will be returned. Otherwise <code><a href="base.html#topic+tryCatch">tryCatch</a></code> will be used in attempt to catch the error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A back-fitting algorithm is used to estimate <code>B</code>, where the columns of <code>B</code> are updated sequentially until convergence (outer loop). For each column of <code>B</code>, (the inner loop of) the algorithm searches for the j-th mode across the search range specified by the j-th column of <code>mode.range</code>. The backfitting algorithm is determined to have converged when 
</p>
<p><code>mean((B.new - B.old)^2) &lt; eps * (mean(B.old^2) + del)</code>, 
</p>
<p>where <code>B.old</code> and <code>B.new</code> denote the parameter estimates at outer iterations <code class="reqn">t</code> and <code class="reqn">t+1</code> of the backfitting algorithm.
</p>


<h3>Value</h3>

<p>If <code>Z</code> is a list with <code class="reqn">q_j = q</code> for all <code class="reqn">j = 1,\ldots,p</code>, then...
</p>
<table role = "presentation">
<tr><td><code>B</code></td>
<td>
<p>is returned as a <code class="reqn">q</code> x <code class="reqn">p</code> matrix when <code>simplify = TRUE</code></p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>is returned as a list of length <code class="reqn">p</code> when <code>simplify = FALSE</code></p>
</td></tr>
</table>
<p>If <code>Z</code> is a list with <code class="reqn">q_j \neq q</code> for some <code class="reqn">j</code>, then <code>B</code> is returned as a list of length <code class="reqn">p</code>.
</p>
<p>Otherwise <code>B</code> is returned as a <code class="reqn">q</code> x <code class="reqn">p</code> matrix.
</p>


<h3>Note</h3>

<p>The <code>Z</code> input can also be a list of length <code class="reqn">p</code> where <code>Z[[j]]</code> contains a <code class="reqn">m</code> x <code class="reqn">q_j</code> matrix. If <code class="reqn">q_j = q</code> for all <code class="reqn">j = 1,\ldots,p</code> and <code>simplify = TRUE</code>, the output <code>B</code> will be a matrix. Otherwise <code>B</code> will be a list of length <code class="reqn">p</code> where <code>B[[j]]</code> contains a <code class="reqn">q_j</code> x 1 vector.
</p>
<p>The <code>A</code> and <code>b</code> inputs can also be lists of length <code class="reqn">p</code> where <code>t(A[[j]]) %*% B[,j] &gt;= b[[j]]</code> for all <code class="reqn">j = 1,\ldots,p</code>. If <code>A</code> and <code>b</code> are lists of length <code class="reqn">p</code>, the <code>meq</code> input should be a vector of length <code class="reqn">p</code> indicating the number of equality constraints for each element of <code>A</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Goldfarb, D., &amp; Idnani, A. (1983). A numerically stable dual method for solving strictly convex quadratic programs. Mathematical Programming, 27, 1-33. <a href="https://doi.org/10.1007/BF02591962">doi:10.1007/BF02591962</a>
</p>
<p>Helwig, N. E. (in prep). Constrained multivariate least squares in R.
</p>
<p>Ten Berge, J. M. F. (1993). Least Squares Optimization in Multivariate Analysis. Volume 25 of M &amp; T Series. DSWO Press, Leiden University. ISBN: 9789066950832
</p>
<p>Turlach, B. A., &amp; Weingessel, A. (2019). quadprog: Functions to solve Quadratic Programming Problems. R package version 1.5-8. https://CRAN.R-project.org/package=quadprog
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cmls">cmls</a></code> calls this function for the unimodality constraints.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   GENERATE DATA   ######***######

# make X
set.seed(2)
n &lt;- 50
m &lt;- 20
p &lt;- 2
Xmat &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)

# make B (which satisfies all constraints except monotonicity)
x &lt;- seq(0, 1, length.out = m)
Bmat &lt;- rbind(sin(2*pi*x), sin(2*pi*x+pi)) / sqrt(4.75)
struc &lt;- rbind(rep(c(TRUE, FALSE), each = m / 2),
               rep(c(FALSE, TRUE), each = m / 2))
Bmat &lt;- Bmat * struc

# make noisy data
set.seed(1)
Ymat &lt;- Xmat %*% Bmat + rnorm(n*m, sd = 0.25)


######***######   UNIMODALITY   ######***######

# unimodal
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "unimod")
Bhat.mlsun &lt;- t(mlsun(X = Xmat, Y = Ymat))
mean((Bhat.cmls - Bhat.mlsun)^2)

# unimodal and structured
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "unimod", struc = struc)
Amat &lt;- vector("list", p)
meq &lt;- rep(0, p)
for(j in 1:p){
   meq[j] &lt;- sum(!struc[j,])
   if(meq[j] &gt; 0){
      A &lt;- matrix(0, nrow = m, ncol = meq[j])
      A[!struc[j,],] &lt;- diag(meq[j])
      Amat[[j]] &lt;- A
   } else {
      Amat[[j]] &lt;- matrix(0, nrow = m, ncol = 1)
   }
}
Bhat.mlsun &lt;- t(mlsun(X = Xmat, Y = Ymat, A = Amat, meq = meq))
mean((Bhat.cmls - Bhat.mlsun)^2)

# unimodal and non-negative
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "uninon")
Bhat.mlsun &lt;- t(mlsun(X = Xmat, Y = Ymat, A = diag(m)))
mean((Bhat.cmls - Bhat.mlsun)^2)

# unimodal and non-negative and structured
Bhat.cmls &lt;- cmls(X = Xmat, Y = Ymat, const = "uninon", struc = struc)
eye &lt;- diag(m)
meq &lt;- rep(0, p)
for(j in 1:p){
   meq[j] &lt;- sum(!struc[j,])
   Amat[[j]] &lt;- eye[,sort(struc[j,], index.return = TRUE)$ix]
}
Bhat.mlsun &lt;- t(mlsun(X = Xmat, Y = Ymat, A = Amat, meq = meq))
mean((Bhat.cmls - Bhat.mlsun)^2)


# see internals of cmls.R for further examples

</code></pre>

<hr>
<h2 id='MsplineBasis'>
M-Spline Basis for Polynomial Splines
</h2><span id='topic+MsplineBasis'></span>

<h3>Description</h3>

<p>Generate the M-spline basis matrix for a polynomial spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MsplineBasis(x, df = NULL, knots = NULL, degree = 3, intercept = FALSE,
             Boundary.knots = range(x), periodic = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MsplineBasis_+3A_x">x</code></td>
<td>

<p>the predictor variable. Missing values are <b>not</b> allowed.
</p>
</td></tr>
<tr><td><code id="MsplineBasis_+3A_df">df</code></td>
<td>

<p>degrees of freedom; if specified the number of <code>knots</code> is defined as <code>df - degree - ifelse(intercept, 1, 0)</code>; the <code>knots</code> are placed at the quantiles of <code>x</code>
</p>
</td></tr>
<tr><td><code id="MsplineBasis_+3A_knots">knots</code></td>
<td>

<p>the internal breakpoints that define the spline (typically the quantiles of <code>x</code>) 
</p>
</td></tr>
<tr><td><code id="MsplineBasis_+3A_degree">degree</code></td>
<td>

<p>degree of the piecewise polynomial&mdash;default is 3 for cubic splines
</p>
</td></tr>
<tr><td><code id="MsplineBasis_+3A_intercept">intercept</code></td>
<td>

<p>if <code>TRUE</code>, the basis includes an intercept column  
</p>
</td></tr>
<tr><td><code id="MsplineBasis_+3A_boundary.knots">Boundary.knots</code></td>
<td>

<p>boundary points for M-spline basis; defaults to min and max of <code>x</code>  
</p>
</td></tr>
<tr><td><code id="MsplineBasis_+3A_periodic">periodic</code></td>
<td>

<p>if <code>TRUE</code>, the M-spline basis is constrained to be periodic  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Syntax is adapted from the <code>bs</code> function in the <b>splines</b> package (R Core Team, 2021).
</p>
<p>Used for implementing various types of smoothness constraints in the <code><a href="#topic+cmls">cmls</a></code> fucntion.
</p>


<h3>Value</h3>

<p>A matrix of dimension <code>c(length(x), df)</code> where either <code>df</code> was supplied or <code>df = length(knots) + degree + ifelse(intercept, 1, 0)</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>R Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/
</p>
<p>Ramsay, J. O. (1988). Monotone regression splines in action. <em>Statistical Science, 3</em>, 425-441. <a href="https://doi.org/10.1214/ss/1177012761">doi:10.1214/ss/1177012761</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IsplineBasis">IsplineBasis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0, 1, length.out = 101)
M &lt;- MsplineBasis(x, df = 8, intercept = TRUE)
M &lt;- scale(M, center = FALSE)
plot(x, M[,1], ylim = range(M), t = "l")
for(j in 2:8) lines(x, M[,j], col = j)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
